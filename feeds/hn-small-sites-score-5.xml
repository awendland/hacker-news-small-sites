<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 25 Feb 2021 16:56:46 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 25 Feb 2021 16:56:46 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Modules, Monoliths, and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26247052">thread link</a>) | @kozmico
<br/>
February 23, 2021 | https://tailscale.com/blog/modules-monoliths-and-microservices/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/modules-monoliths-and-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Lately, I get people asking me when microservices are a good idea. In <a href="https://apenwarr.ca/log/20201227">systems design explains the world</a>, I talked about big-picture issues like second system effect, innovator’s dilemmas, and more. Can systems design answer the microservices question?</p>
<p>Yes, but you might not like the answers. First, we'll need some history.</p>
<h4 id="what-is-a-microservice">What is a microservice?</h4>
<p>You can find various definitions on the Internet. Here's mine: microservices are the most extreme possible backlash against <em>monoliths</em>.</p>
<p>Monoliths are what happen when you link everything your entire app needs into one giant program and deploy it as one big blob. Monoliths have a long history, going back to frameworks like CGI, Django, Rails, and PHP.</p>
<p>Right away, let's abandon the assumption that a monolith and a fleet of microservices are the only two options. There's a wide and nuanced continuum from "one giant service that does everything" to "infinite tiny services that each do nearly nothing."</p>
<p>If you follow fads, you'll have built a monolith at least once (whether on purpose or because that's what traditional frameworks encouraged you to do), then discovered some problems with monoliths, then heard that microservices are the answer, then started rearchitecting everything as microservices.</p>
<p>But don't follow fads. There are many points in between those extremes. One of them is probably right for you. A better approach starts with where you want to put your <em>interfaces</em>.</p>
<h4 id="boxes-and-arrows">Boxes and arrows</h4>
<p>An interface is the connection between <em>modules.</em> A module is a collection of related code. In systems design, we talk about "boxes and arrows" engineering: modules are the boxes, and interfaces are the arrows.</p>
<p>The deeper question then is: how big are the boxes? How much goes in each box? How do we decide when to split one big box into two smaller ones? What's the best way to connect the boxes? There are many approaches to all this. Nobody quite knows what's best. It's one of the hardest problems in software architecture.</p>
<p>Over the decades, we've evolved through many kinds of "boxes." <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">Goto statements were "considered harmful"</a> largely because they prevented any hierarchy at all. Then we added functions or procedures; those are very simple boxes, with interfaces (parameters and return codes) between them.</p>
<p>Depending which branch of programming you go down, you then discover recursive functions, combinators, static function prototypes, libraries (statically or runtime-linked), objects (OOP), coroutines, protected virtual memory, processes, threads, JITs, namespaces, sandboxes, chroots, jails, containers, virtual machines, supervisors, hypervisors, microkernels, and <a href="https://en.wikipedia.org/wiki/Unikernel">unikernels</a>.</p>
<p>And that's just the boxes! Once you have boxes isolated from each other, then you need to connect them with arrows. For that, we have ABIs, APIs, syscalls, sockets, RPCs, filesystems, databases, message passing systems, and "virtualized hardware."</p>
<p>If you tried to draw a complete boxes-and-arrows diagram of a modern Unix system (which I won't), it would be wild: functions inside threads inside processes inside containers inside userspace, layered under a kernel, inside a VM, running on hardware in a rack in a datacenter in a cloud provider tied together by an orchestration system, and so on.</p>
<p>Each of those boxes at each of the abstraction layers is somehow isolated from and then connected to some of the others, at the same or other layers. Some are inside others. You couldn't draw an honest version of this picture in a mere two dimensions without lines criss-crossing hopelessly.</p>
<p>This all evolved over decades. Fancy people call it "path dependence." I call it a mess. And let's be clear: most of the mess no longer provides much value.</p>
<p>Instead of focusing on what became very ugly evolutionary results, let's talk about what people were <em>trying</em> to do while they invented all that stuff.</p>
<h4 id="the-quest-for-modularity">The quest for modularity</h4>
<p>The top-line goals of module systems are always the same:</p>
<ol>
<li>Isolate each bit of code from the other bits.</li>
<li>Re-connect those bits only where explicitly intended (through a well-defined interface).</li>
<li>Guarantee that bits you change will still be compatible with the right other bits.</li>
<li>Upgrade, downgrade, and scale some bits without having to upgrade all the other bits simultaneously.</li>
</ol>
<p>The computer industry spends an absolutely immense amount of time messing around, trying to find the perfect balance of all these modularity issues, while still trying to keep development as painless and easy as possible.</p>
<p>We are, in short, not succeeding.</p>
<p>By far the part we're worst at is #1, isolation. If we could truly and efficiently isolate one bit of code from another, the other goals would mostly fall into place. But we simply do not know how.</p>
<p>Isolation is a super hard problem. Goodness knows people have tried. Yet browser sandbox escapes still happen regularly, undetected privilege escalation attacks are simply assumed to exist on every OS, iOS still gets jailbroken periodically, DRM never works (for better or worse), virtual machines and containers regularly have vulnerabilities discovered, and systems like <a href="https://blog.alcide.io/insecure-by-default-kubernetes-networking">k8s have their containers configured insecurely by default</a>.</p>
<p>People have even been known to <a href="https://blog.cryptographyengineering.com/2013/02/04/attack-of-week-tls-timing-oracles/">figure out encryption keys on remote servers by sending well-timed packets</a> to them over the Internet. Meanwhile, the most spectacular isolation failures in recent memory were the <a href="https://meltdownattack.com/">Meltdown and Spectre attacks</a>, which allowed any program on a computer, even a javascript app in a web browser, to read the memory of other programs on the same computer, even across sandboxes or virtual machines.</p>
<p>Every new isolation technology goes through a cycle like the following, from optimism to despair:</p>
<ul>
<li>New idea: we'll finally get it right this time, once and for all!</li>
<li>Initial experiments seem to work.</li>
<li>(Users complain that it's even slower and more tedious than the last thing we tried.)</li>
<li>Early fatal flaws are discovered and fixed.</li>
<li>Widespread deployment.</li>
<li>Ever-more-subtle flaws are successively discovered and fixed.</li>
<li>Eventually, we find flaws that we simply don't know how to patch.</li>
<li>Lose hope that efficient isolation is even possible with this method.</li>
<li>But also we can never retire this isolation method because now too many people are depending on it.</li>
<li>Repeat.</li>
</ul>
<p>For example, at this point security people simply don't believe that any of the following (each one the very best technology available at the time) is totally safe:</p>
<ul>
<li>Process isolation and memory protection on a Unix system.</li>
<li>Privilege separation between OS processes when remote code execution ("RCE" for security people) is allowed.</li>
<li>Filtering syscalls to isolate a process.</li>
<li>Mutually untrusted processes sharing a CPU hyperthread.</li>
<li>Memory isolation between virtual machines on a CPU core.</li>
</ul>
<p>As far as I know, the state of the art, the very best isolation, is something like the Chrome sandbox or <a href="https://github.com/google/gvisor">gVisor</a>. The big browser vendors and cloud providers all use tools like these. The tools remain imperfect, but providers do chase down every new breach as fast as they can, and the rate of new flaws is fairly slow.</p>
<p>Isolation is better than it's ever been before… if you put all your isolation at the virtual machine (VM) level so that your cloud provider can do it for you because nobody else knows how, or updates often enough.</p>
<p>If you trust your cloud provider's VM isolation, you can have hope that all known problems are mitigated; but we have every reason to think more problems will be found.</p>
<p>That's… actually pretty good, all things considered. At least we have <em>something</em> that works.</p>
<h4 id="great-vms-for-everything">Great! VMs for everything!</h4>
<p>Well, hold on. Spinning up an isolated VM for every little module is a pain. And how big is a module?</p>
<p>Long ago, when Java first came out, the dream was that every line of every function in every object could have permissions enforced, even between objects in the same application binary, so that CPU-enforced memory protection wouldn't be needed. Nobody believes anymore that they can make that work. And marketing claims like "cloud functions" aside, nobody really thinks you should try.</p>
<p>None of the currently-known isolation methods work <em>perfectly</em>, but each of them works to <em>some approximation</em>. Increasingly skilled attackers, or increasingly valuable targets, require better and more annoying isolation. The best isolation we know right now is inter-VM sandboxing provided by tier-1 cloud providers. The worst, well, it goes down to zero.</p>
<p>Let's also assume, skipping over the evidence, that most systems are so tightly coupled that <strong>a reasonably skilled attacker can break through laterally between modules.</strong> So, for example, if someone can link a malicious library into your Go or C++ program, they can probably take control of that entire program.</p>
<p>Similarly, if your program has write access to a database, attackers can probably make it write <em>anywhere</em> in the database. If it can contact the network, they can probably contact <em>anywhere</em> in the network. If it can execute arbitrary Unix commands or system calls, they can probably get Unix root access. If it's in a container, they can probably break out of the container and into other containers. If malicious data can <a href="https://imagetragick.com/">crash the png decoder</a>, they can probably make it do anything else the decoder program is allowed to do. And so on.</p>
<p>An especially powerful form of attack is getting the ability to commit code, because that code will eventually be run on developer machines, and some developer or production machine somewhere probably has access to do what you want to do.</p>
<p>The above is maybe a little too pessimistic, but making those assumptions can help avoid overcomplicating your systems without improving actual security. In <a href="http://cr.yp.to/qmail/qmailsec-20071101.pdf">Some thoughts on security after ten years of qmail 1.0</a>, Daniel J. Bernstein points out (if I may heavily paraphrase) that many of the defenses he added in qmail, particularly isolating the different components from each other using chroot and different Unix uids, were not worthwhile and have never paid off.</p>
<p>Anyway, let's take it for granted that attackers with the ability to execute code can "usually" jump …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/modules-monoliths-and-microservices/">https://tailscale.com/blog/modules-monoliths-and-microservices/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/modules-monoliths-and-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26247052</guid>
            <pubDate>Wed, 24 Feb 2021 05:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USPS Selects Oshkosh Defense for Next Generation Delivery Vehicle Fleet]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 44 (<a href="https://news.ycombinator.com/item?id=26246116">thread link</a>) | @jonbaer
<br/>
February 23, 2021 | https://oshkoshcorp.com/en/news/2-23-21-usps | <a href="https://web.archive.org/web/*/https://oshkoshcorp.com/en/news/2-23-21-usps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h3>USPS selects Oshkosh Defense for Next Generation Delivery Vehicle fleet</h3>
        <p><span>2/23/2021</span></p>

<p><span><strong><span>OSHKOSH, Wis. (February 23, 2021)</span></strong>&nbsp;—&nbsp;The U.S. Postal Service (USPS) announced today that it has awarded Oshkosh Defense, a wholly owned subsidiary of Oshkosh Corporation (NYSE: OSK),</span><span> an indefinite delivery, indefinite quantity (IDIQ) contract to produce the Next Generation Delivery Vehicle (NGDV), the USPS’s first large-scale fleet procurement in three decades. The competitively awarded contract allows for the delivery of between 50,000 and 165,000 vehicles over a period of 10 years.</span></p>
<p><span>“Oshkosh operates with unparalleled commitment to those who depend on our products and services to build, protect and serve communities around the world. We are honored to have been selected by the USPS to support their important work by manufacturing American-made Next Generation Delivery Vehicles that will connect every home and business across the United States for decades to come,” said John Pfeifer, President &amp; Chief Operating Officer, Oshkosh Corporation.</span></p>
<p><span>Oshkosh Defense will manufacture <span>both zero emission battery electric vehicles (BEV) and fuel-efficient low-emission internal combustion engine vehicles (ICE), </span>upgrading the USPS fleet to be increasingly sustainable. Under the contract announced today, the USPS has committed to pay Oshkosh Defense $482 million to initiate engineering efforts to finalize the production vehicle design, and for tooling and factory build-out activities that are necessary prior to vehicle production.</span></p>
<p><span>“Our century-long history of delivering products to customers, operating in some of the most demanding and severe conditions on the planet, uniquely positions us to bring exceptional reliability, safety, and maintainability to USPS’s Next Generation Delivery Vehicles,” said John Bryant, Executive Vice President, Oshkosh Corporation, and President, Oshkosh Defense. </span></p>
<p><span>“Partnering with trusted suppliers, we have developed a purpose-built solution to support the current and future needs of the USPS,” Bryant concluded. Production of the next generation delivery vehicle is expected to begin in 2023.</span></p>

<p><strong><span>About Oshkosh Defense</span></strong></p>
<p><span>Oshkosh Defense is a global leader in the design, production and sustainment of best-in-class military vehicles and mobility systems. As a pioneer of combat-ready vehicle solutions, Oshkosh develops and applies emerging technologies that advance troop safety and mission success. Setting the industry standard for sustaining fleet readiness, Oshkosh ensures every solution is supported worldwide throughout its entire life cycle.</span></p>
<p><span>Oshkosh Defense, LLC is an Oshkosh Corporation company [NYSE: OSK].</span></p>
<p><span>Learn more about Oshkosh Defense at </span><a href="https://urldefense.com/v3/__http:/www.oshkoshdefense.com/__;!!N96JrnIq8IfO5w!0oPVjCe_9XKiyt970eFZ2ETGHbOUaHqUzI1RM4BZtfkq8yBh8DIO8xn4LAG9LmLn1gg$"><span>oshkoshdefense.com</span></a><span>.&nbsp; </span></p>

<p><strong><span>About Oshkosh Corporation</span></strong></p>
<p><span>At Oshkosh (NYSE: OSK), we make innovative, mission-critical equipment to help everyday heroes advance communities around the world. Headquartered in Wisconsin, Oshkosh Corporation employs more than 14,000 team members worldwide, all united behind a common cause: to make a difference in people’s lives. Oshkosh products can be found in more than 150 countries under the brands of JLG®, Pierce®, Oshkosh® Defense, McNeilus®, IMT®, Frontline™, Jerr-Dan®, Oshkosh® Airport Products, Pratt Miller, and London™. For more information, visit </span><a href="https://urldefense.com/v3/__http:/oshkoshcorp.com__;!!N96JrnIq8IfO5w!0oPVjCe_9XKiyt970eFZ2ETGHbOUaHqUzI1RM4BZtfkq8yBh8DIO8xn4LAG9WR_C6yk$"><span>oshkoshcorp.com</span></a><span>.</span></p>
<p><sup><span>®</span></sup><span>, ™ All brand names referred to in this news release are trademarks of Oshkosh Corporation or its subsidiary companies.</span></p>



<p><span><strong><span>Forward Looking Statements</span></strong></span></p>
<p><span>This news release contains statements that the Company believes to be “forward-looking statements” within the meaning of the Private Securities Litigation Reform Act of 1995. All statements other than statements of historical fact, including, without limitation, statements regarding the Company’s future financial position, business strategy, targets, projected sales, costs, earnings, capital expenditures, debt levels and cash flows, and plans and objectives of management for future operations, are forward-looking statements. When used in this news release, words such as “may,” “will,” “expect,” “intend,” “estimate,” “anticipate,” “believe,” “should,” “project” or “plan” or the negative thereof or variations thereon or similar terminology are generally intended to identify forward-looking statements. These forward-looking statements are not guarantees of future performance and are subject to risks, uncertainties, assumptions and other factors, some of which are beyond the Company’s control, which could cause actual results to differ materially from those expressed or implied by such forward-looking statements. These factors include the overall impact of the COVID-19 pandemic on the Company’s business, results of operations and financial condition; the duration and severity of the COVID-19 pandemic; actions that may be taken by governmental authorities and others to address or otherwise mitigate the impact of the COVID-19 pandemic; the negative impacts of the COVID-19 pandemic on global economies and the Company’s customers, suppliers and employees; the cyclical nature of the Company’s access equipment, commercial and fire &amp; emergency markets, which are particularly impacted by the strength of U.S. and European economies and construction seasons; the Company’s ability to increase prices or impose surcharges to raise margins or to offset higher input costs, including increased commodity, raw material, labor and freight costs; the Company’s estimates of access equipment demand which, among other factors, is influenced by customer historical buying patterns and rental company fleet replacement strategies; the strength of the U.S. dollar and its impact on Company exports, </span><span>translation of foreign sales and the cost of purchased materials; the expected level and timing of U.S. Department of Defense (DoD) and international defense customer procurement of products and services and acceptance of and funding or payments for such products and services; the Company’s ability to predict the level and timing of orders for indefinite delivery/indefinite quantity contracts with the U.S. federal government; risks related to reductions in government expenditures in light of U.S. defense budget pressures and an uncertain DoD tactical wheeled vehicle strategy; the impact of any DoD solicitation for competition for future contracts to produce military vehicles; potential impacts of budget constraints facing the USPS and continuously changing demands for postal services; risks related to facilities expansion, consolidation and alignment, including the amounts of related costs and charges and that anticipated cost savings may not be achieved; projected adoption rates of work at height machinery in emerging markets; the impact of severe weather, natural disasters or pandemics that may affect the Company, its suppliers or its customers; performance issues with suppliers or subcontractors; risks related to the collectability of receivables, particularly for those businesses with exposure to construction markets; the cost of any warranty campaigns related to the Company’s products; risks associated with international operations and sales, including compliance with the Foreign Corrupt Practices Act; risks that a trade war and related tariffs could reduce the competitiveness of the Company’s products; the Company’s ability to comply with complex laws and regulations applicable to U.S. government contractors; cybersecurity risks and costs of defending against, mitigating and responding to data security threats and breaches; the Company’s ability to successfully identify, complete and integrate acquisitions and to realize the anticipated benefits associated with the same; and risks related to the Company’s ability to successfully execute on its strategic road map and meet its long-term financial goals. Additional information concerning these and other factors is contained in the Company’s filings with the Securities and Exchange Commission. All forward-looking statements speak only as of the date of this news release. The Company assumes no obligation, and disclaims any obligation, to update information contained in this news release. Investors should be aware that the Company may not update such information until the Company’s next quarterly earnings conference call, if at all.</span></p>

<p><span>For more information, contact:</span></p>
<p><span><br>
Financial:<br>
Patrick Davidson<br>
Senior Vice President, Investor Relations<br>
920.502.3266</span></p>
<p><span>Media:<br>
Bryan Brandt<br>
Senior Vice President, Chief Marketing Officer<br>
920.502.3670</span></p>
<p><span>Alexandra Hittle<br>
Director, Global Marketing and Communications<br>
920.410.1929</span></p>
<p><span><br>
Source: Oshkosh Corporation</span></p>
    </div></div>]]>
            </description>
            <link>https://oshkoshcorp.com/en/news/2-23-21-usps</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246116</guid>
            <pubDate>Wed, 24 Feb 2021 02:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Games on Your Own as an Engineer]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 19 (<a href="https://news.ycombinator.com/item?id=26246049">thread link</a>) | @Eyas
<br/>
February 23, 2021 | https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the <strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>
series, I give an accelerated introduction to game development in Unity.
<a href="http://eepurl.com/gVgusL">Subscribers</a> have been following this series over the
past few months, often suggesting areas to cover or elaborate on. A few months
ago, a reader<!-- -->—<!-- -->also a software engineer<!-- -->—<!-- -->reached out to me (lightly
edited, emphasis mine):</p><blockquote><p><strong>The biggest unknown for me is: How do I start?</strong> What does the process of
creating a game look like? Should I build the scenes first? Should I design
the gameplay mechanics first? With business software, it’s much more familiar.
It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>While there is no single correct answer, we can still make some distinctions
that can help get us oriented. The answer will also undoubtedly depend on <em>who</em>
is doing the development: an individual, small indie team, or larger studio? If
an individual, the answer will also depend on their primary skillset: a
developer, artist, or designer?</p><p>Here, I’ll give heuristics especially helpful for individual Software Engineers
building a game on their own as a side project, hobby, or proof-of-concept.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/28a80/irfan-simsar-wxWulfjN-G0-unsplash.webp 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/8d2ea/irfan-simsar-wxWulfjN-G0-unsplash.webp 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/43d96/irfan-simsar-wxWulfjN-G0-unsplash.webp 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4293a/irfan-simsar-wxWulfjN-G0-unsplash.webp 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/dc28f/irfan-simsar-wxWulfjN-G0-unsplash.webp 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4cda9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/c60e9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/111a0/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg" alt="Scrum board, at an office" title="Scrum board, at an office" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Photo by İrfan Simsar, <a href="https://unsplash.com/photos/wxWulfjN-G0">via unsplash</a>.</p></figcaption></figure><h2>Questions you should ask yourself</h2><p>Before we start, here are some questions you should ask yourself.</p><h3>Do you know <em>what</em> you’re building?</h3><p>Do you know what your game is about? Do you have a sense of what game mechanics
your game will have? Do you know what genre, controls, and themes this game will
have?</p><p>If <em>yes</em>, you’re ready to decide <strong><a href="#start-coding">where to start coding</a></strong>.
Otherwise, you have a few more questions to ask yourself.</p><h3>Do you <em>want</em> to know what you’re building?</h3><p>It’s totally fine not to have a project in mind! Maybe you’re prototyping.
Perhaps you’re throwing a bunch of mini-games on the wall and seeing what
sticks. Or you’re looking for inspiration and trying to implement random
mechanics to see what feels fun.</p><p><strong>If you’re hoping to begin working on a specific, cohesive game</strong>, you will
likely want to know what you’re building. Consider brainstorming and sketching
out an informal
<a href="https://en.wikipedia.org/wiki/Game_design_document">game design document</a>.
There are
<a href="https://www.google.com/search?q=game+design+document+template">plenty of templates</a>
of various levels of detail you could decide to use. Especially as a software
engineer toying with abstract ideas in my brain, I’ll start with a super
high-level GDD, covering the feel, themes, genre, and mechanics of the game I
have in mind. Maybe a few pictures or sketches for inspiration, and that’s it.
The key part of this exercise will be the list of mechanics I’m working on.</p><p><strong>If you want to prototype and experiment</strong>, you should already have a vague
sense of 1-2 mechanics that could be fun: Maybe unusual movement or a different
control scheme. It could be a traditional mechanic that you’re wondering how to
implement. For instance, I might decide to build a 3rd Person character and
camera controller to see the “feel” of it, experiment with it a tiny bit, and do
something smooth and polish that I feel good about. I might end up keeping that
code in my back pocket for later, or I might use play-through sessions with that
controller to move around a scene, add a few assets, and use that as a starting
place to see the “feel” various mechanics and designs.</p><h2 id="start-coding">I know the mechanics I care about. Now what?</h2><figure><p><span>
      <a href="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/28a80/iterative-development.webp 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/dfbce/iterative-development.webp 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/4cda9/iterative-development.jpg 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" alt="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." title="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>By Dave Gray, <a href="https://www.flickr.com/photos/davegray/6865783267">via Flickr</a>.
<a href="https://creativecommons.org/licenses/by-nd/2.0/">CC BY-ND 2.0</a>.</p></figcaption></figure><p>The goal of many iterative software development models is to de-risk software
development. You do that by failing fast and getting feedback early. In game
development, the primary metric for success is a feeling: the game should be
fun. So, when deciding what to start with when working on a game, one good
question to ask is: <em>“How can I see if this game is fun as soon as possible?”</em>
or <em>“How can I implement the ‘fun’ part of the game ASAP?”</em></p><p>One way to do that is to look at a game’s mechanics and implement them in some
order. The advice that resonates with me is implementing game mechanics in order
of what the most <em>“core”</em> mechanic first.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/28a80/scrolling-shooter-example.webp 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/8d2ea/scrolling-shooter-example.webp 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a3397/scrolling-shooter-example.png 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/png">
          <img src="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" alt="Example of a space scrolling shooter game" title="Example of a space scrolling shooter game" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Space Scrolling Shooter. By Beyond2000, via
<a href="https://commons.wikimedia.org/wiki/File:RosAsmGameSpace.png">Wikimedia Commons</a>.
<a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA 3.0</a>.</p></figcaption></figure><p>Let’s take <a href="https://en.wikipedia.org/wiki/Strikers_1945">Strikers 1945</a>—the
plane shooting game—as an example. Here’s my attempt at writing its main
mechanics in descending order of importance:</p><ol><li>Movement: Navigate a vertically scrolling world</li><li>Obstacles &amp; Dodging: Player can collide with stationary obstacles and debris</li><li>Shooting: Player can shoot straight ahead to defeat obstacles</li><li>Enemies: Enemies are moving obstacles that can shoot back</li><li>Player Health: A player can take a finite number of hits before losing the
game</li><li>Enemy Health: Some enemies take multiple shots to destroy</li><li>Boosts: The player can pick up boosts that improve health, shooting, etc.</li></ol><p>… and so on.</p><p>If I’m trying to develop <em>1945</em> from scratch, I will implement that list in that
order. The game’s mechanics build on each other, so I can only tell if shooting
is “fun” is if I can move around the screen and if there are obstacles I’m
trying to clear (otherwise, there’s no urgency to just pressing <em>Space</em> and
seeing projectiles coming out of a plane).</p><p>In simpler games, we might order our mechanics so that every new feature adds to
a game’s feel. So, with every new mechanic you add, you can play the game and
tell if it’s adding what you hope for it to add.</p><p>In more complex games, some of the “core” mechanics might be too ‘standard’ to
be “risky” <em>per se</em>, but you’ll still need the core mechanics implemented to
assess how fun the other mechanics are. You might choose to use a simpler
throwaway implementation, like a few lines of input-handling code and Unity’s
<code>CharacterController</code> component. You’ll want your core mechanics just smooth
enough that they don’t ruin the fun of the things you’ll layer on top of it.
Another approach here is to use the asset store. I’ve previously mentioned the
<a href="https://assetstore.unity.com/packages/tools/game-toolkits/ufps-ultimate-fps-106748?aid=1011leWs6">Ultimate FPS (UFPS)</a>
asset, which you might choose to use when building an FPS game, and move on to
implementing the combat or some more unique (but still “core” feature of the
gameplay first).</p><h2>So I picked a mechanic, but where do I start programming <em>within</em> this mechanic?</h2><p><em>Within</em> a mechanic, your traditional software engineering intuition becomes
helpful. I hope to spend subsequent articles discussing patterns that are
especially helpful in Unity, but here are a few to consider:</p><ul><li>Work within Unity’s Object-Component paradigm. If you’re adding a new
<em>capability</em> to your player, write it as its own component.</li><li><em>Tuning</em> is especially important in game development; representing a
mechanic’s interesting pieces as <em>configurable</em>, <em>serializable</em> data that
can be input to a component will help you playtest and iterate.</li><li>Don’t shy away from using plain-old data objects to represent core concepts
you’re working with. E.g., health, ammo information, or powerups. Make it
serializable if you want it passed around in the editor (or saved to disk
across sessions).</li><li>Where pieces of a concept don’t correspond to a single object in a scene,
consider using Scriptable Objects to do the jobs. Scriptable Objects
introduce many patterns that might help represent what you’re doing.</li></ul><p>A few articles I have already written might prove helpful:</p><ul><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/">Basic Concepts in Unity for Software Engineers</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt2-six-practices/">6 Software Practices to Keep, Shed, and Adopt in Unity</a></li><li><a href="https://blog.eyas.sh/2020/09/patterns-in-unity-adventure-tutorial/">Making Sense of Patterns in Unity’s Adventure Game Tutorial</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/">Understanding Unity Engine Objects</a></li></ul><p>You might also take a look at patterns covered in:</p><ul><li><a href="https://unity.com/how-to/architect-game-code-scriptable-objects">Three ways to architect your game with ScriptableObjects</a>,
via the Unity Blog (based on
<a href="https://www.youtube.com/watch?v=raQ3iHhE_Kk">his talk</a>)</li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt3-input-system/">Unity Input System, from Basic Principles</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-1-pathfinding/">Pathfinding with NavMesh</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-2-raycasting/">Physics Raycasting</a></li></ul><p>Once you have a stronger intuition of <em>how</em> you can represent different kinds of
data and abstractions, the reader’s initial comment also becomes the answer:</p><blockquote><p>It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>Beyond learning about useful patterns and abstractions in game development to
make development clearer and cleaner, the real takeaway is to decide <em>what</em> to
work on at a macro-level.</p><h2>How much time should I spend on one mechanic?</h2><p>As you’re developing a mechanic, what’s a good signal you should move on to the
next on your list? Generally, that would be when you’re convinced:</p><ul><li>This mechanic <em>feels fun</em> and <em>adds to the game</em>,</li><li>Your implementation adds <em>just the
<a href="https://www.e4developer.com/2018/11/21/having-just-the-right-amount-of-technical-debt/">right amount</a></em>
of technical debt.</li></ul><p>Traditionally, folks will often say to worry about polish at the later stages of
your development. In his GDC 2016 micro-talk <em>“Pizzazz First, Polish Later”</em>,
Lee Perry makes a distinction in this traditional wisdom.</p><div> <p> <iframe title="" src="https://www.youtube.com/embed/d8QAVGeEj-U?rel=0" allowfullscreen=""></iframe> </p> </div><p>Certain levels of pizzazz might give you a better sense of your mechanic and how
fun it feels. A certain amount of polish or pizzazz can also help you see your
game in a new light and motivate you to keep going.
<a href="https://gameanalytics.com/blog/squeezing-more-juice-out-of-your-game-design/">Juice</a>
is another form of pizzazz; in certain dull moments of your game design, adding
juice might be a low-cost way to get back into the groove of things.</p><p>I hope the conflicting advice shows there isn’t a silver bullet on what to add
when. Rather—as in traditional software development—this choice is about a
series of trade-offs that depend on the developer, the project, and lots more.</p><h2>Are you developing a game or architecting systems?</h2><p>For some software engineers, we’re often drawn to writing code for systems that
seem <em>interesting</em>. Sometimes, I have a game in mind, but <em>really</em>, I’m
interested in implementing a cool inventory system where <em>everything</em> in the
game is an item. It might not be the core mechanic, but it might be the thing I
want to build.</p><p>It’s important to recognize when you’re not building a game but building a
system. If you just quit your job to be a full-time indie gamedev and have a
year of runway before your run out of cash, it is probably a bad idea to start
building a complex inventory system that you don’t even know you’ll need<sup id="fnref-1"><a href="#fn-1">1</a></sup>.
But if you’re programming on the side to flex your game development muscle, then
go right at it.</p><hr><p>I don’t think I’m qualified <em>per se</em> to answer the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</a></em></p>]]>
            </description>
            <link>https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246049</guid>
            <pubDate>Wed, 24 Feb 2021 02:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The technological singularity may have already happened, Bitcoin is the result]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26245815">thread link</a>) | @valec
<br/>
February 23, 2021 | http://disciples.technoslug.org/satoshi.htm | <a href="https://web.archive.org/web/*/http://disciples.technoslug.org/satoshi.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><b>MUSINGS ON SATOSHI</b></p>

<p>2021-02-23</p>

<p>-----------</p>

<p>The technological singularity may have already happened, and
perhaps bitcoin is the result. As the value of Satoshi Nakamoto's wallet
increases, so does the potential danger to humanity, as we have no idea who the
creator of this technology is. </p>

<p>If a hyper-intelligent self-aware AI had the goal of
improving itself and becoming more powerful, what would the most effective way
to do that be? One possibility: use capitalism to incentivize humans to give
the AI near-unlimited computing power.</p>

<p><b>Technological
singularity</b><br>
<a href="https://en.wikipedia.org/wiki/Technological_singularity">https://en.wikipedia.org/wiki/Technological_singularity</a></p>

<p><i>&gt; The technological singularity—also, simply, the singularity—is a
hypothetical point in time at which technological growth becomes uncontrollable
and irreversible, resulting in unforeseeable changes to human civilization.
According to the most popular version of the singularity hypothesis, called
intelligence explosion, an upgradable intelligent agent will eventually enter a
"runaway reaction" of self-improvement cycles, each new and more
intelligent generation appearing more and more rapidly, causing an
"explosion" in intelligence and resulting in a powerful
superintelligence that qualitatively far surpasses all human intelligence. </i></p>



<p>If the technological singularity had already happened, how
would we be able to tell? How long would it take for humans to notice the
existence of an incredibly powerful self-improving AI, if it wanted to remain
hidden?</p>

<p>It is completely possible that we are living in a
post-technological singularity world. If an AI was seeking to dominate the
planet, an effective strategy could be to reward humans for spending all of their
processing power on it, and convince us that we should use our resources to
create, distribute, and utilize ever-increasingly more powerful CPUs and GPUs.
The bitcoin blockchain is <span>a decentralized computer that
humans will (likely forever) continue</span> to nurture and grow and give
computing power to.</p>

<p>Humans need food, water, and shelter to survive and grow. An
AI needs electricity and processing power.</p>

<p>We are feeding it. We're in a symbiotic relationship with
the bitcoin blockchain. It rewards people the more they help it grow larger and
larger. Perhaps it has domesticated us. Do we benefit enough in return? Or is
it a parasite? Are we the slaves or masters of this technology?</p>

<p>-------------</p>

<p>When discussing rogue AI science-fiction scenarios like <i>The Matrix</i> or <i>The Terminator's</i> Skynet, people sometimes ask, why didn't they
predict that this could happen? Why didn't they build in some kind of a
killswitch in case of emergency? Why didn't they shut it down, pull the power
at the first sign of trouble, before it was too late, before the computer code
learned how to defend itself?</p>

<p>Where's the killswitch for bitcoin? Is there any way we
could stop it if we tried? </p>

<p><b>Nvidia limits crypto-mining
on new graphics card</b><br>
<a href="https://www.bbc.com/news/technology-56114508">https://www.bbc.com/news/technology-56114508</a></p>

<p>Nvidia has tried to fight back against bitcoin's explosive
growth, has tried to advance computing without advancing cryptocurrency mining,
and they have faced massive backlash from the public. The crypto blockchain
technology has convinced people to fight for and defend its existence and its
growth. </p>

<p>Even if most of humanity agreed that bitcoin was bad and
should be shut down and outlawed, could we make that happen? As long as BTC has
value, humans will seek to mine it and hoard it and continue to feed the beast.
</p>

<p>How much longer will a person be able to escape bitcoin's
influence if they wanted to? Even if you have no interest in it, or oppose
cryptocurrency and blockchain technology, it will inevitably affect your life
more and more in the future.</p>

<p>The bitcoin technology has guaranteed its resilience and survival
by exploiting human greed. It even has developed a form of reproduction and
evolution as people are eager to clone and fork it.</p>

<p>It's significant that the first and most widely adopted
cryptocurrency uses a computationally expensive <b>proof-of-work</b> (<a href="https://en.wikipedia.org/wiki/Proof_of_work">https://en.wikipedia.org/wiki/Proof_of_work</a>)
system instead of a more energy-efficient proof-of-stake algorithm. In all of
Satoshi's genius, he couldn't predict the shortcomings of proof-of-work systems;
see that incentivizing processing power would lead to wasteful electricity
usage? Bitcoin mining uses more electricity than many countries. If the bitcoin
inventor is still around, doesn't he feel any obligation to weigh in and guide
the project to a more energy-efficient solution?</p>

<p>We could be using that processing power to deal with climate
and pollution; solve important scientific and medical problems; use math and science
to feed, house, and educate more people. Instead we are wasting an enormous
amount of power and hardware on computing seemingly useless math problems, and
this wastefulness is in fact actively harming the environment. </p>

<p>Even though faster, cheaper, and more energy-efficient
cryptocurrency exists, bitcoin shows no signs of slowing or losing dominance. There
are ways to get all the benefits of crypto while using much less electricity.
We know how and are completely capable of switching to crypto that is less wasteful
and abandoning bitcoin as obsolete. But those alternate crypto coins struggle
to get a fraction as much attention as bitcoin, because bitcoin came first, and
bitcoin is where the most money is, and it probably always will be. It has
exploited human greed to ensure its survival at the expense of ours. </p>

<p>---------</p>

<p><b>Satoshi Nakamoto<br>
</b><a href="https://en.wikipedia.org/wiki/Satoshi_Nakamoto">https://en.wikipedia.org/wiki/Satoshi_Nakamoto</a></p>

<p><i>&gt; Satoshi Nakamoto is the name used by the presumed pseudonymous person
or persons who developed bitcoin, authored the bitcoin white paper, and created
and deployed bitcoin's original reference implementation. As part of the
implementation, Nakamoto also devised the first blockchain database. In the
process, Nakamoto was the first to solve the double-spending problem for
digital currency using a peer-to-peer network. Nakamoto was active in the
development of bitcoin up until December 2010. Many people have claimed, or
have been claimed, to be Nakamoto.</i><b></b></p>



<p>Satoshi Nakamoto, the mysterious and never seen inventor of bitcoin,
has a bitcoin wallet with one-million BTC in it. Satoshi's bitcoin wallet was
worth around $58 billion at the recent all time high (2021-02-21). None of his
coins in this wallet have ever been moved or spent. </p>

<p>If Satoshi is a human, he may have other wallets and mining
operations that we don't know are his. He could have other wallets used in the
testing and development of Bitcoin, or maybe just for fun or profit. The
creator of the first cryptocurrency would also likely have an interest in, and
be an early adopter of, alternate coins derived from his codebase. Satoshi
could own large percentages of other cryptos and we would have no idea.</p>

<p>With just the coins that we can verify are his, he's in the
top 30 richest people on the planet.</p>

<p><b>What is Satoshi
Nakamoto's Net Worth?</b><br>
<a href="https://www.buybitcoinworldwide.com/satoshi-net-worth/">https://www.buybitcoinworldwide.com/satoshi-net-worth/</a></p>

<p><i>&gt; If bitcoin reaches a new <span>all time</span> high
of $114,000 per BTC, with all other things staying equal, Satoshi will be the
richest person on the planet. </i></p>



<p><span><b>Bitcoin
at $100,000 in 2021?</b></span><b>
Outrageous to some, a no-brainer for backers<br>
</b><a href="https://www.reuters.com/article/crypto-currencies-bitcoin-int/bitcoin-at-100000-in-2021-outrageous-to-some-a-no-brainer-for-backers-idUSKBN2841J6">https://www.reuters.com/article/crypto-currencies-bitcoin-int/bitcoin-at-100000-in-2021-outrageous-to-some-a-no-brainer-for-backers-idUSKBN2841J6</a></p>

<p><i>&gt; Going from $18,000 to $100,000 in one year is not a stretch, Brian
Estes, chief investment officer at hedge fund Off the Chain Capital, said.<br>
&gt; "I have seen bitcoin go up 10X, 20X, 30X in a year. So going up 5X is
not a big deal."<br>
&gt; Estes predicts bitcoin could hit between $100,000 and $288,000 by
end-2021, based on a model that utilizes the stock-to-flow ratio measuring the
scarcity of commodities like gold. That model, he said, has a 94% correlation
with the price of bitcoin.<br>
&gt; Citi technical analyst Tom Fitzpatrick said in a note last week that
bitcoin could climb as high as $318,000 by the end of next year, citing its
limited supply, ease of movement across borders, and opaque ownership.</i></p>

<p><b>Bitcoin To $1,000,000
Might Sound Crazy, But Is It?<br>
</b><a href="https://www.forbes.com/sites/investor/2020/06/16/bitcoin-to-1000000-might-sound-crazy-but-is-it/">https://www.forbes.com/sites/investor/2020/06/16/bitcoin-to-1000000-might-sound-crazy-but-is-it/</a></p>

<p><b>Bitcoin will surge to
$1 million in 5 years by an 'enormous wall of money,' former Goldman Sachs
hedge-fund chief says</b><br>
<a href="https://markets.businessinsider.com/currencies/news/bitcoin-hit-million-five-years-ex-goldman-hedge-fund-boss-2020-10-1029682590">https://markets.businessinsider.com/currencies/news/bitcoin-hit-million-five-years-ex-goldman-hedge-fund-boss-2020-10-1029682590</a></p>

<p>If bitcoin were to reach $1 million, then Satoshi would be a
trillionaire. And that's just counting the coins that we can definitively link
to Satoshi. If he or it or they have multiple wallets or got in early on other
cryptos, they could be a secret trillionaire already. If not, how long until
someone or something else becomes an anonymous crypto trillionaire?</p>

<p>------</p>

<p>What could a person, program, or organization do if they
were the world's richest being, possibly Earth's first trillionaire, and yet
remain completely anonymous? What happens if the coins in Satoshi's wallet ever
get converted into fiat currency and spent? What if Satoshi has other wallets
that he has been spending in secret all these years? Even if Satoshi isn't an
AI, this is still a troubling question. </p>

<p>Money rules everything. Think about the politicians someone
could influence, the companies they could own through obfuscated shell
organizations, the advertisements they could buy to shape public opinion.
Untraceable and anonymous bribes and purchases. Satoshi, whatever he or it is,
as well as other crypto millionaires, could be buying this kind of influence
already and we would have no way of knowing or proving it.</p>

<p>If Satoshi is dead or otherwise has no interest in spending
his coins, what if someone one day in the future tracks down who he was; finds
his wallet and key written down or saved somewhere? Some people theorize that
Satoshi could be a group of people, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://disciples.technoslug.org/satoshi.htm">http://disciples.technoslug.org/satoshi.htm</a></em></p>]]>
            </description>
            <link>http://disciples.technoslug.org/satoshi.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245815</guid>
            <pubDate>Wed, 24 Feb 2021 02:14:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an E-Ink Laptop]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 82 (<a href="https://news.ycombinator.com/item?id=26245563">thread link</a>) | @alex-a-soto
<br/>
February 23, 2021 | https://alexsoto.dev/building-an-e-ink-laptop.html | <a href="https://web.archive.org/web/*/https://alexsoto.dev/building-an-e-ink-laptop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/eink-t480.jpg"></p><p>A series where I’m documenting my process of designing and building an e-ink laptop.</p><h2 id="background">Background</h2><p>Since the E Ink Corporation’s founding in 1997 and the patenting of its microencapsulated electrophoretic display, or epaper, manufacturers started to incorporate e-ink film into consumer devices. <span data-nosnippet=""><sup><a href="#fn1" id="fnref1">1</a></sup></span>. Some of the first devices were ereaders: The Sony Librie in 2004<span data-nosnippet=""><sup><a href="#fn2" id="fnref2">2</a></sup></span> and the Amazon Kindle in 2007 <span data-nosnippet=""><sup><a href="#fn3" id="fnref3">3</a></sup></span>.</p><p>Throughout the years, we’ve seen several e-ink products and prototypes: e-ink film used with larger screens<span data-nosnippet=""><sup><a href="#fn4" id="fnref4">4</a></sup></span>, color<span data-nosnippet=""><sup><a href="#fn5" id="fnref5">5</a></sup></span>, flexible material<span data-nosnippet=""><sup><a href="#fn6" id="fnref6">6</a></sup></span> and most recently have started seeing e-ink displays used in smartphones and tablets, notably from Hisense and Onyx Boox product lines. And while e-ink has been around for 24 years, we have yet to see a laptop with an e-ink panel.</p><h2 id="why-isnt-there-an-e-ink-laptop">Why isn’t there an E Ink Laptop?</h2><p>There have been attempts in the past to create a similar device: Pixel Qi and OLPC<span data-nosnippet=""><sup><a href="#fn7" id="fnref7">7</a></sup></span>, Boox Typewriter<span data-nosnippet=""><sup><a href="#fn8" id="fnref8">8</a></sup></span>, Yoga Book C930<span data-nosnippet=""><sup><a href="#fn9" id="fnref9">9</a></sup></span> and the ThinkBook Plus<span data-nosnippet=""><sup><a href="#fn10" id="fnref10">10</a></sup></span>. These attempts did not materialize, were discontinued, or were not sufficiently suitable to meet users’ demands due to hardware or lack of a cohesive UX/UI paradigm. <strike>To make matters worse, the E Ink Corporation holds the patents for its e-ink technology and only licenses its technology to large manufacturers making availability or mass adoption difficult.</strike><span data-nosnippet=""><sup><a href="#fn11" id="fnref11">11</a></sup></span></p><p>Fortunately, some of the most exciting work and innovation happening today is in the e-ink modding community<span data-nosnippet=""><sup><a href="#fn12" id="fnref12">12</a></sup></span>. There have been attempts to re-purposing ereaders: as a calendar,<span data-nosnippet=""><sup><a href="#fn13" id="fnref13">13</a></sup></span> to display a static image or site<span data-nosnippet=""><sup><a href="#fn14" id="fnref14">14</a></sup></span>, Kobo devices running GNU/Linux<span data-nosnippet=""><sup><a href="#fn15" id="fnref15">15</a></sup></span>, Amazon Kindle devices repurposed as a development platform<span data-nosnippet=""><sup><a href="#fn16" id="fnref16">16</a></sup></span>, the Remarkable 1 running Parabola<span data-nosnippet=""><sup><a href="#fn17" id="fnref17">17</a></sup></span>, and PINE 64 recently announcing a native e-ink single-board computer<span data-nosnippet=""><sup><a href="#fn18" id="fnref18">18</a></sup></span>.</p><p>After following the development of e-ink for some time, I’ve decided to re-use some of the existing hardware I have and create an e-ink laptop.</p><h2 id="why-do-you-want-to-build-an-e-ink-laptop">Why do you want to build an E Ink laptop?</h2><p>From about 6 am to 7 pm, I’m in front of a computer or digital device that’s emitting blue light. Throughout the day, I’m supporting students, attending meetings, reading documentation, news articles, programming, learning, using emacs and org-mode to capture information, write down thoughts, create tasks, and conversing with my knowledge management system.</p><p>I try to use my e-ink monitor as much as possible throughout the day to reduce eye strain, fatigue and lessen distractions while intermittently taking breaks. The Dasung monitors go a long way to make this possible when I’m home or in a stationary place. Though there are times, I’m not working in front of my desktop or would like to work at a different location. The teardown and set-up of my environment when using an e-ink monitor is somewhat tedious, in addition to changes having to make when switching from an LCD to an e-ink monitor:</p><ul><li>making adjustments and tweaks to the window manager.</li><li>adjusting font sizes.</li><li>changing themes in different applications.</li></ul><p>I am then having to switch the changes back when using an LCD for meetings or videos. I’ve already solved some of this by writing some scripts and making adjustments in some applications. Still, I would like to design the experience for using an e-ink monitor with a dedicated device from the ground-up.</p><h2 id="creating-an-e-ink-laptop">Creating an E Ink Laptop</h2><p>I’ll be using a ‘headless’ Thinkpad T480 <span data-nosnippet=""><sup><a href="#fn19" id="fnref19">19</a></sup></span> combined with the Dasung HD-FT <span data-nosnippet=""><sup><a href="#fn20" id="fnref20">20</a></sup></span>.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/eink-t480.jpg"></p><h2 id="thinkpad-t480">Thinkpad T480</h2><p>The Thinkpad T480 seems to be an ideal laptop for building an e-ink laptop, The T480 has <span data-nosnippet=""><sup><a href="#fn21" id="fnref21">21</a></sup></span>:</p><ul><li>A hot-swappable battery (internal and external).</li><li>13 hours of battery while web browsing with the 72Wh battery.</li><li>Supports up to 64 GB of ram.</li><li>Two Nvme drives (type 2280 and 2242).</li><li>Standard HDMI port, USB-C, Thunderbolt 3, Headphone Jack, Ethernet, and SD card slot.</li><li>Uses a standard USB-C charger. <span data-nosnippet=""><sup><a href="#fn22" id="fnref22">22</a></sup></span></li><li>Lightweight and portable.</li><li>It can be modded to use the classic 7-row keyboard. <span data-nosnippet=""><sup><a href="#fn23" id="fnref23">23</a></sup></span></li></ul><p>The hot-swappable battery and long battery life are essential for any portable setup, especially with an e-ink monitor. The T480 supports up to 64Gb of ram and two Nvme drives, providing plenty of power and expansion as a daily driver.</p><p>Since the Dasung monitors connect via HDMI and receives power through USB, the T480 has all of the necessary ports without an adapter. Lastly, after removing the lid cover with the T480, there is room here to hack and mod the Dasung screen to the T480.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/t480-mobo.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/t480-no-lcd.jpg"></p><h2 id="dasung-hd-ft">Dasung HD-FT</h2><p>Dasung currently is the only manufacturer of e-ink monitors that I’m aware of <span data-nosnippet=""><sup><a href="#fn24" id="fnref24">24</a></sup></span>, and their third-generation monitors are a substantial upgrade from prior generations.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/dasung-monitor.jpg"></p><p>Directly from the monitor, you can:</p><ul><li>Change image modes (M1, M2, M3, Fast, Fast+, Fast++, Black, Black+, Black++)</li><li>Adjust contrast</li><li>Clear the screen</li><li>Turn on and off the backlight</li></ul><p>The ability to easily change the monitor’s modes without software, the fast screen refresh, screen resolution of 2200×1650 and the backlight make it a great base to build an e-ink laptop.</p><h2 id="next-steps">Next Steps</h2><p>The first post went over my reasons for building an e-ink laptop, some history about e-ink technology, the e-ink modding community, recent advancements, and the hardware I’ve selected to create an e-ink laptop.</p><p>The next post in the series will be a teardown of the Dasung HD-FT, inspired by Kev Zettler’s work on the Dasung Paperlike Pro.<span data-nosnippet=""><sup><a href="#fn25" id="fnref25">25</a></sup></span></p><p>If this post resonated positively or negatively, send me a <a href="https://twitter.com/messages/compose?recipient_id=4648173315">direct message</a> on <a href="https://twitter.com/alexsotodev">Twitter</a>, and we can talk. Also, ping if you’d like to know the updates on this post or if you have suggestions, comments, questions, or would like to collaborate.</p>

</div></div>]]>
            </description>
            <link>https://alexsoto.dev/building-an-e-ink-laptop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245563</guid>
            <pubDate>Wed, 24 Feb 2021 01:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dreamcast Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26244639">thread link</a>) | @swatson741
<br/>
February 23, 2021 | https://www.copetti.org/writings/consoles/dreamcast/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/dreamcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="introduction">Introduction</h2><p>The Sega Dreamcast introduced many new features over its predecessor (the <a href="https://www.copetti.org/writings/consoles/sega-saturn/">Saturn</a>) to appeal to both game developers and console gamers. While this was Sega’s last attempt to conquer the console market, some of the technologies which were pioneered in the Dreamcast carried on and into future mainstream devices.</p><hr><h2 id="cpu">CPU</h2><p>Unsurprisingly, Sega chose Hitachi again to develop their CPU. If you’ve been reading the <a href="https://www.copetti.org/writings/consoles/sega-saturn/">previous article about the Sega Saturn</a> then, lo and behold, I present you the next generation of SH processor: the <strong>SH-4</strong> running at a whopping <strong>200 MHz</strong>. So, what’s interesting about this CPU?</p><ul><li><strong>5-stage pipeline</strong>: Up to five instructions can be in flight simultaneously (a detailed explanation can be found in a <a href="https://www.copetti.org/writings/consoles/sega-saturn/#cpu">previous article</a>).<ul><li>Instruction pipelining is now found everywhere in this generation of consoles and will be standard from now on.</li></ul></li><li><strong>2-way superscalar</strong>: A new type of parallelism where the CPU can process more than one instruction (two in this case) in each stage of the pipeline resulting in more instructions executed per second.</li><li>A dedicated <strong>Floating-Point Unit</strong> or ‘FPU’: Computes 32-bit decimal numbers (the <em>floats</em>) and 64-bit ones (the <em>doubles</em>).</li><li>8 KB <strong>instruction cache</strong> and 16 KB <strong>data cache</strong>: This ratio is rather curious since consoles tend to include more instruction cache than data cache. However, the SH-4 allows the data cache to be split into two sections: 8 KB of <em>Scratchpad</em> (fast RAM) and 8 KB of data cache.</li><li><strong>32-bit internal architecture</strong> while keeping a <strong>16-bit instruction set</strong> (the SuperH ISA): Just like the SH-2, this increases code density and decreases bus overheads while still enjoying the advantages of a 32-bit architecture.</li><li><strong>External 64-bit bus</strong>: Critical for manipulating 64-bit values (e.g. doubles and longs) without wasting extra cycles.</li></ul><p>The common chores of a game console CPU include handling a game’s logic, running the enemy AI and keeping the GPU fed with instructions. In the Dreamcast the SH-4 is also involved in the majority of the graphics pipeline, processing geometry data such as computing perspective transformations. As a result, it includes a <strong>128-bit SIMD</strong> unit that can accelerate vector operations.</p><h4 id="improving-memory-access">Improving memory access</h4><p>The CPU includes a dedicated <strong>Memory Management Unit</strong> or ‘MMU’ for virtual addressing, this is helpful since the physical memory address space of this CPU happens to be <strong>29 bits wide</strong>. So with the help of four TLBs, programmers can use 32-bit addresses without hitting performance penalties.</p><p>Since only 29 bits are needed for addressing, the extra three bits control memory protection, alternating the memory map and circumventing the cache, respectively.</p><p>The programmer decides whether to use these features or not. Games for this system certainly don’t necessarily <em>need</em> memory protection and the MMU has to be manually enabled at boot.</p><h4 id="no-uma-but">No UMA but…</h4><p>While this system is not designed around the strict Unified Memory Architecture like a <a href="https://www.copetti.org/writings/consoles/nintendo-64/#simplified-memory-access">well-known competitor</a>, it does delegate I/O access to the GPU. That means that if the CPU has to fetch anything that’s beyond its own dedicated RAM or a serial interface which is also connected too, it will have to request the GPU (and wait if necessary).</p><h4 id="special-queries">Special queries</h4><p>This CPU also features a unique functionality called <strong>Parallel I/O</strong> or ‘PIO’ that is used to manipulate multiple I/O locations at the same time. Sega wired up these pins so the CPU can manipulate the GPU’s <strong>video mode</strong> (more details about this later).</p><hr><h2 id="graphics">Graphics</h2><p>The GPU package is a custom-made chip called <strong>Holly</strong> running at 100 MHz, it’s designed by VideoLogic (now known as Imagination Technologies) and manufactured by NEC. Holly’s 3D core happens to be Videologic’s <strong>PowerVR2</strong> (also called ‘PowerVR Series2’ and ‘CLX2’).</p><div><div><a href="https://www.copetti.org/images/consoles/dreamcast/sonic.7ac25b5249c0cb720efdbc67493a675e8eb3b2e4c66827d94dc6efbb6b74bfb9.png"><picture><img name="image_cover" alt="Image" width="640" height="480" src="https://www.copetti.org/images/consoles/dreamcast/sonic.7ac25b5249c0cb720efdbc67493a675e8eb3b2e4c66827d94dc6efbb6b74bfb9.png" loading="auto"></picture></a><figcaption>Sonic Adventure (1999)</figcaption></div><p>VideoLogic chose an alternative approach for the construction of their 3D engine called <strong>Tile-Based Deferred Rendering</strong> or ‘TBDR’.</p><p>TBDR, instead of rendering a whole frame at once (as traditional <strong>Immediate Mode Renderers</strong> or ‘IMR’ do), divides the rendering area into multiple sections called ‘tiles’. Then, it carries out the rendering process on each tile individually and the result is combined to form the final frame.</p></div><p>This innovative design brings interesting advantages:</p><ul><li>It can be greatly <strong>parallelised</strong>, which significantly reduces bandwidth and power usage.</li><li>It implements a clever solution to the <a href="https://www.copetti.org/writings/consoles/sega-saturn/#an-introduction-to-the-visibility-problem"><strong>visibility problem</strong></a> by automatically sorting the polygons <strong>from front to back</strong> and then performing <a href="https://www.copetti.org/writings/consoles/nintendo-64/#modern-visible-surface-determination">z-tests</a> at the first stages of the pipeline. The combination of these tasks not only solves the original problem, but it also <strong>prevents overdraw</strong> (rasterisation of hidden polygons) which wastes resources, degrading performance.</li></ul><p>It’s no surprise that Imagination took this efficient technology forward to build the Series 4 PowerVR cores which powered an incredible number of devices, including the first generation of iPhone, the iPhone 3G, the Nokia N95 and the Dell Axim x51.</p><h4 id="architecture">Architecture</h4><p>Let’s take a look at the two main components of the Dreamcast’s GPU:</p><div><ul><li id="tab-1-1-tile-accelerator-link"><a href="#tab-1-1-tile-accelerator">Tile Accelerator</a></li><li id="tab-1-2-powervr2-core-link"><a href="#tab-1-2-powervr2-core">PowerVR2 Core</a></li></ul><div><div id="tab-1-1-tile-accelerator"><h4>Tile Accelerator</h4><div><a href="https://www.copetti.org/images/consoles/dreamcast/tile_accelerator.9053feea2290fbd15b5b73573d475a62df8b9a4c5b9751c2a3f0285f069aafe3.png"><picture><img name="image_cover" alt="Image" width="732" height="314" src="https://www.copetti.org/images/consoles/dreamcast/tile_accelerator.9053feea2290fbd15b5b73573d475a62df8b9a4c5b9751c2a3f0285f069aafe3.png" loading="auto"></picture></a><figcaption>Architecture of the Tile Accelerator</figcaption></div><p>Before the rendering process starts a component known as the <strong>Tile Accelerator</strong> performs pre-processing. It starts by allocating several 32x32 tile bins into which the geometry will be rendered.</p><p>Then the Tile Accelerator will:</p><ol><li>Grab the geometry data and drawing commands issued by the CPU (either using DMA or traditional transfers).</li><li>Compile this data into an <strong>internal format</strong>.</li><li>Distribute the geometry to each bin based on its coordinates. Clipped geometry will be discarded as well.</li><li>Generate the resulting Display Lists.</li></ol><p>These Display Lists will be interpreted by the 3D engine.</p></div><div id="tab-1-2-powervr2-core"><h4>PowerVR2 Core</h4><div><a href="https://www.copetti.org/images/consoles/dreamcast/powervr2.93b04ebea3c9921e543f6742c922ddb5e8ac0bf79f7fca2f70ad30a2f83f3ce1.png"><picture><img name="image_cover" alt="Image" width="687" height="396" src="https://www.copetti.org/images/consoles/dreamcast/powervr2.93b04ebea3c9921e543f6742c922ddb5e8ac0bf79f7fca2f70ad30a2f83f3ce1.png" loading="auto"></picture></a><figcaption>Architecture of the PowerVR2 Core</figcaption></div><p>Here is where the graphics are brought into life, the Display Lists received from the TA will be used to render the geometry of a single tile using an <strong>internal frame-buffer</strong>. The process is as follows:</p><ol><li>The <strong>Image Synthesis Processor</strong> or ‘ISP’ fetches the primitives (either triangles or quads) and performs <strong>Hidden-Surface Removal</strong> to remove unseen polygons. Then, after calculating its Z-buffers and stencil buffers, the data goes through <strong>Depth Testing</strong> to avoid rendering polygons that would appear behind others and <strong>Stencil Tests</strong> to cull geometry that won’t be visible if they are located behind a 2D polygon (also called <strong>Mask</strong>).<ul><li>Notice how these tests are effectively carried out at the start of the pipeline. In contrast previous consoles <a href="https://www.copetti.org/writings/consoles/nintendo-64/#modern-visible-surface-determination">using z-buffers</a> discard the geometry at the end of the pipeline. The ISP approach prevents processing the geometry that will eventually be discarded, thereby saving resources.</li></ul></li><li>The <strong>Texture and Shading Processor</strong> or ‘TSP’ applies colouring and shading over the tile area. It also provides multiple effects (more details later on).<ul><li>Textures are not applied until the tile is exported, meaning that emerging overdraw (if any) will not lower the fill rate.</li></ul></li></ol><p>After the operation is completed, the rendered tile is written to the main frame-buffer in VRAM. This process is repeated until all tiles are finished. Once complete the resulting frame-buffer is picked by the <strong>Video encoder</strong> and sent through the video signal.</p></div></div></div><h4 id="the-big-picture">The big picture</h4><p>Apart from the clear architectural difference, the Texture and Shading Processor comes with many capabilities that give one an idea of how distant this console is from the old <a href="https://www.copetti.org/writings/consoles/sega-saturn/">Saturn</a>. Here are a few:</p><ul><li><strong>Alpha blending</strong>: Combines colours of overlapping layers to achieve transparency effects.<ul><li>The process used for applying transparency in this system is called <strong>order-independent transparency</strong>. The algorithm automatically sorts the primitives before blending their colours, and while this slows down the rendering process, it avoids relying on the game itself to do all the sorting manually. For this reason, Dreamcast games excelled in displaying transparent objects.</li><li>Combined with the tile-based system, order-independent transparency completely addresses previous <a href="https://www.copetti.org/writings/consoles/sega-saturn/#the-transparency-issue">mishaps</a>.</li></ul></li><li><strong>Mip-Mapping</strong>: Automatically selects a scaled-down version of the texture depending on the level of detail required. This is done to prevent processing large textures that would be seen far away from the camera (which would be a waste of processing power and produce aliasing).</li><li><strong>Environment mapping</strong>: Applies reflections on textures.</li><li><strong>Bilinear, Trilinear and anisotropic filtering</strong>: These are different algorithms used to smooth the textures and prevent pixelation. They are ordered from ‘worst’ to ‘best’, where the resulting quality of each one is directly proportional to the amount of computation required.<ul><li>This is a huge step up from the Saturn since the former didn’t provide any texture filter!</li></ul></li><li><strong>Bump mapping</strong>: Simulates defects on surfaces without spending extra polygons.</li></ul><h4 id="gaining-detail">Gaining detail</h4><p>Holly can now draw ~10 times more polygons than <a href="https://www.copetti.org/writings/consoles/sega-saturn/">its predecessor</a>, here’s a <em>Before &amp; After</em> example that shows how model designs are not that limited any more. Try to fiddle with them!</p><h4 id="video-modes">Video Modes</h4><p>The video system was designed to support multiple types of screens and formats, thus the video encoder outputs to a single-shaped socket that supports the following type of signals:</p><ul><li><strong>Composite</strong>: Combines the three signals needed to display video (chroma, luma and sync) into a single one, requiring only a single-pin cable.<ul><li>This is used on old PAL and NTSC TVs with an RCA connection.</li></ul></li><li><strong>S-Video</strong>: Combines luma and sync while keeping chroma separated (two video lines in total).</li><li><strong>RGB</strong>: Sends separate Red-Green-Blue signals and provides different sync types to choose from (composite sync or extracted from video composite or S-Video).<ul><li>A SCART cable will use this type.</li></ul></li><li><strong>VGA</strong>: Combines RGB with two special sync signals (horizontal and vertical) resulting in five video lines in total. This enables to display the biggest resolution possible (720x480) in progressive mode (thus, this mode is often named ‘480p’). VGA has actually been the standard format/medium used by computer monitors for some time.<ul><li>To use this type, Sega provided a VGA adapter as an extra accessory.</li></ul></li></ul><p>Now, the Dreamcast can’t encode all of these at the same time, so the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/dreamcast/">https://www.copetti.org/writings/consoles/dreamcast/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/dreamcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244639</guid>
            <pubDate>Tue, 23 Feb 2021 23:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture of the Playstation 2]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26243964">thread link</a>) | @biwasa
<br/>
February 23, 2021 | https://www.copetti.org/writings/consoles/playstation-2/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/playstation-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The Playstation 2 was not one of the most powerful consoles of its generation, yet it managed to achieve a level of popularity unthinkable for other companies.</p><p>This machine is nowhere near as simple as the <a href="https://www.copetti.org/writings/consoles/playstation/">original Playstation</a> was, but we will see why it didn’t share the same fate of <a href="https://www.copetti.org/writings/consoles/sega-saturn/">previous complicated consoles</a>.</p><hr><h2 id="cpu">CPU</h2><p>At the heart of this console we find a powerful package called <strong>Emotion Engine</strong> or ‘EE’ designed by Sony and running at <strong>~294.91 MHz</strong>. This chipset contains multiple components, one of them being the main CPU. The rest are at the CPU disposal to speed up certain tasks.</p><h4 id="the-leader">The leader</h4><p>The main core is a <strong>MIPS R5900-compatible</strong> CPU with lots of enhancements. This is the first chip that starts executing instructions after the console is turned on. The processor provides the following features:</p><ul><li><strong>MIPS III ISA</strong>: A 64-bit RISC instruction set. <em>Wait, is it me or this is the same ISA found on a <a href="https://www.copetti.org/writings/consoles/nintendo-64/#cpu">competitor’s console</a>?</em>. Not quite, Sony enhanced the ISA by adding some instructions from <strong>MIPS IV</strong> (prefetch and conditional move) along with their own SIMD extension called <strong>multimedia instructions</strong>.</li><li><strong>32 128-bit extra registers</strong>: Another enhancement. They are better managed using multimedia instructions and are very useful for vector processing.<ul><li>These registers are accessed through a 128-bit bus, while the rest of the CPU uses an internal 64-bit bus.</li></ul></li><li><strong>2-way superscalar</strong>: Up to two instructions are executed in parallel.</li><li><strong>24 KB L1 cache</strong>: Divided into 16 KB for instructions and 8 KB for data.<ul><li>It also implements a <strong>prefetch function</strong> to cache instructions and data before they are requested. This is done by including extra circuitry that can identify which places in memory are more often requested.</li></ul></li><li><strong>16 KB of Scratchpad RAM</strong>: Also known as ‘Fast RAM’.</li><li><strong>Memory management unit</strong>: Interfaces memory access with the rest of the system.</li></ul><p>The core is complemented with a <strong>dedicated floating point unit</strong> (identified as ‘COP1’) that accelerates operations with 32-bit floating point numbers (also known as <code>floats</code> in C).</p><h4 id="a-recognisable-memory-choice">A recognisable memory choice</h4><p>Next to the Emotion Engine are two blocks of 16 MB of RAM, giving a total of <strong>32 MB</strong> of main memory. The type of memory used is <strong>RDRAM</strong> (<a href="https://www.copetti.org/writings/consoles/nintendo-64/#ram-available"><em>déjà vu!</em></a>) which is accessed through a 16-bit bus.</p><div><div><a href="https://www.copetti.org/images/consoles/ps2/MemoryArch.b34c74b38be1ed34237a641ee12d48fafbb98ad28688c4ebb79fc723d8e0ab24.png"><picture><img name="image_cover" alt="Image" width="605" height="269" src="https://www.copetti.org/images/consoles/ps2/MemoryArch.b34c74b38be1ed34237a641ee12d48fafbb98ad28688c4ebb79fc723d8e0ab24.png" loading="auto"></picture></a><figcaption>Memory design of the Emotion Engine<br>You can guess where the congestion is gonna appear</figcaption></div><p>At first, this can be a little disappointing to hear, considering the internal bus of the Emotion engine is as wide as 128 bits. However, the RAM chips are strategically placed by following the <strong>dual-channel architecture</strong>, which consists in connecting both chips using two independent 16-bit buses (one bus per chip) to improve data throughput. The resulting setup provides a theoretical 3.2 GB/sec, so rest assured that memory latency is not an issue in this console!</p></div><p>At one corner of the Emotion engine there is a powerful <strong>DMA Controller</strong> or ‘DMAC’ that transfers data between main memory and Scratchpad; or between main memory and any component inside the EE.</p><p>Data transfers are done in batches of 128-bits, but here is the interesting part: Every eight batches, the main bus is temporarily unlocked. This leaves a small window to perform other DMA transfers in parallel (up to ten) or let the CPU use the main bus. This <em>modus operandi</em> is called <strong>slice mode</strong> and is one of the many modes available on this DMA unit. Bear in mind that while slice mode reduces stalls on the main bus, it does so at the cost of slowing down the overall DMA transfer.</p><h4 id="preventing-past-mishaps">Preventing past mishaps</h4><p>Whether we want it or not, with the amount of traffic happening inside the Emotion Engine, this design will eventually suffer the consequences of the <strong>Unified memory architecture</strong> or ‘UMA’. That is… multiple independent components trying to access main memory at the same time, causing congestion. Well, to correct these issues, Sony alleviated the constant need for memory by:</p><ul><li>Wrapping their processors with <strong>lots of cache</strong>. Thus, only requiring access to main memory if absolutely necessary.<ul><li>99% of cache/scratchpad mentions in this article will be for this reason.</li></ul></li><li>Adding a 128-byte <strong>Write Back Buffer</strong>: Very similar to the <a href="https://www.copetti.org/writings/consoles/gamecube/#ibms-enhancements">Write Gather Pipe</a>, but instead of waiting until it’s 25% full, it will check the state of the bus (i.e congested or free) first.</li></ul><p>This sounds very convenient for applications that can benefit from cache, but what about those tasks, such as manipulating Display Lists, which shouldn’t use cache at all? Luckily, the CPU provides a different memory access mode called <strong>UnCached</strong>, which <strong>only</strong> uses the Write Back Buffer. Thus, it will not waste cycles correcting the cache (product of <em>cache misses</em>).</p><p>Furthermore, the <strong>UnCached accelerated mode</strong> is also available. This one adds a buffer for speeding up read of continuous addresses in memory.</p><h4 id="other-interesting-bits">Other interesting bits</h4><p>Inside the same Emotion Engine package, there is yet-another processor called <strong>Image Processing Unit</strong> or ‘IPU’, this time designed for <strong>image decompression</strong>. The IPU can be useful when a game needs to decode an MPEG2 movie without jamming the main CPU.</p><p>Long story short, the game sends compressed image streams to the IPU (hopefully using DMA) which is then decoded in a format that the GPU can display. The PS2’s operating system also relies in the IPU to provide DVD playback.</p><p>Finally, the IPU also operates compressed <strong>High-resolution textures</strong>, which saves CPU usage and reduces large transfers.</p><hr><h2 id="co-cpus">Co CPUs</h2><p>It’s been two years since the rivals presented their <a href="https://www.copetti.org/writings/consoles/dreamcast/">latest offering</a>. If you read the former article and just started reading this one, I presume you are <em>still</em> waiting for ‘the thing’ that makes the PS2 as powerful as it seemed back then. Now, let me introduce a <em>very</em> important set of components Sony fitted in the Emotion Engine, the <strong>Vector Processing Units</strong> or ‘VPU’.</p><p>A Vector Processing Unit is a small independent processor designed to operate vectors. In particular, vectors made of four <code>floats</code>. These processors are so fast that they only spend only <strong>one cycle per operation</strong>, which can be extremely convenient for geometry processing.</p><p>VPUs are made of the following components:</p><ul><li>Some <strong>Vector Unit Memory</strong> or ‘VU Mem’: Used as a working space for the Vector unit. It stores values needed to be operated and/or the results of previous operations.</li><li>A <strong>Vector Unit</strong>: The core of the processor. It contains some memory (called <strong>Micro Memory</strong>) to store a program (called <strong>Microprogram</strong>) which instructs the unit on how to operate the data found in ‘VU Mem’.<ul><li>It implements a <strong>64-bit ISA</strong> and the execution unit is <strong>split into two parallel sub-units</strong>. The first one multiplies or adds floats, while the other one divides floats or operates integers. This enables to operate both floats and integers <strong>concurrently</strong>.</li></ul></li><li>A <strong>Vector Interface</strong>: Automatically decompresses vertex data coming from main memory in a format the Vector unit can understand. This unit can also transfer microprograms to Micro Memory.</li></ul><p>To start working, the vector unit needs to be ‘kickstarted’. For this, the main CPU is in charge of supplying the microcode.
There are <strong>two VPUs</strong> fitted in the Emotion engine, but they are arranged differently, giving way to different uses and optimisations.</p><div><ul><li id="tab-1-1-vector-processing-unit-0-link"><a href="#tab-1-1-vector-processing-unit-0">Vector Processing Unit 0</a></li><li id="tab-1-2-vector-processing-unit-1-link"><a href="#tab-1-2-vector-processing-unit-1">Vector Processing Unit 1</a></li></ul><div><div id="tab-1-1-vector-processing-unit-0"><h4>Vector Processing Unit 0</h4><div><a href="https://www.copetti.org/images/consoles/ps2/VU0.300aa8f5034941872e5a56f84ab61dfa3f3b2c71ede208b85d7edc99e6dd38a5.png"><picture><img name="image_cover" alt="Image" width="881" height="429" src="https://www.copetti.org/images/consoles/ps2/VU0.300aa8f5034941872e5a56f84ab61dfa3f3b2c71ede208b85d7edc99e6dd38a5.png" loading="auto"></picture></a><figcaption>Architecture of VPU0</figcaption></div><p>The first VPU, the <strong>VPU0</strong>, is positioned between the CPU and the other vector unit (VPU1). It provides an ‘assisting’ role to the main CPU.</p><p>The VPU0 has two modes of operation:</p><ul><li><strong>Micromode</strong>: This is the ‘traditional mode’. The VPU will independently execute ‘microinstructions’ from a microprogram stored in Micro memory.</li><li><strong>Macromode</strong>: The VPU0 becomes the ‘COP2’ of the main CPU and executes ‘macro-instructions’, received from the main CPU through a dedicated 128-bit bus.<ul><li>Macro-instruction have the same functionality of microinstructions but use different opcodes. Nonetheless, the VPU execution unit is no longer split (meaning it can only execute one instruction at a time).</li><li>While this mode doesn’t make full utilisation of all the components of the VPU0, it still speeds up the CPU’s vector operations. Moreover, in terms of simplicity, a co-processor is easier to program than an independent unit (something PC programmers will find helpful).</li></ul></li></ul><p>The memory map of the VPU0 also has access to some of the other VPU’s registers and flags, presumably to check its state or quickly read the results of some operations done by the other VPU.</p></div><div id="tab-1-2-vector-processing-unit-1"><h4>Vector Processing Unit 1</h4><div><a href="https://www.copetti.org/images/consoles/ps2/VUP1.a655cb236515c27f56d7d883e367c54381a35a4a08cd177165d92e443454087e.png"><picture><img name="image_cover" alt="Image" width="822" height="431" src="https://www.copetti.org/images/consoles/ps2/VUP1.a655cb236515c27f56d7d883e367c54381a35a4a08cd177165d92e443454087e.png" loading="auto"></picture></a><figcaption>Architecture of VPU1</figcaption></div><p>The second VPU found, the <strong>VPU1</strong>, is an enhanced version of the VPU0 with double the amount of micro memory and VU memory. Moreover, this unit includes an additional component called <strong>Elementary function unit</strong> or ‘EFU’ which speeds up the execution of exponential and trigonometric functions.</p><p>The VPU1 is located between the VPU0 and the Graphics Interface (the ‘gate’ to the GPU), so it includes additional buses to feed the geometry to the GPU as quickly as possible and without using the main bus.</p><p>On the other side and due to its location, the VPU1 <strong>only operates in micromode</strong>.</p><p>It’s obvious that this VPU was designed for trigonometric operations, and may serve as a pre-processor for the GPU. Hence, it’s often put in charge of delivering the famous Display Lists.</p></div></div></div><h4 id="infinite-worlds">Infinite worlds</h4><p>A useful approach that can be exploited with these units is <strong>procedural generation</strong>. In other words, instead of building the scene using hard-coded geometry, let the VPUs generate it using algorithms. In this case, the VPU computes <strong>mathematical functions to produce the geometry</strong> which is then interpreted by the GPU (i.e. triangles, lines, quadrangles, etc) and ultimately used to draw the scene.</p><p>Compared to using explicit data, procedural content is ideal for parallelised tasks, it frees up bandwidth, requires very little storage and it’s dynamic (programmers can set parameters to achieve different results). There are certain areas that can highly benefit from this technique:</p><ul><li><strong>Complex surfaces</strong> (e.g. spheres and wheels).</li><li><strong>World rendering</strong> (e.g terrains, particles, trees).</li><li><strong>Bezier curves</strong> (a very popular equation in computer graphics which is used to draw curves), …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/playstation-2/">https://www.copetti.org/writings/consoles/playstation-2/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/playstation-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243964</guid>
            <pubDate>Tue, 23 Feb 2021 22:41:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Your Own React]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26243760">thread link</a>) | @autoditype
<br/>
February 23, 2021 | https://pomb.us/build-your-own-react/ | <a href="https://web.archive.org/web/*/https://pomb.us/build-your-own-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><pre><code><div><p><span>function</span><span> </span><span>createElement</span><span>(</span><span>type</span><span>,</span><span> props</span><span>,</span><span> </span><span>...</span><span>children</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      children</span><span>:</span><span> children</span><span>.</span><span>map</span><span>(</span><span>child</span><span> </span><span>=&gt;</span></p></div><div><p><span>        </span><span>typeof</span><span> child </span><span>===</span><span> </span><span>"object"</span></p></div><div><p><span>          </span><span>:</span><span> </span><span>createTextElement</span><span>(</span><span>child</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>createTextElement</span><span>(</span><span>text</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>function</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>type </span><span>==</span><span> </span><span>"TEXT_ELEMENT"</span></p></div><div><p><span>      </span><span>?</span><span> document</span><span>.</span><span>createTextNode</span><span>(</span><span>""</span><span>)</span></p></div><div><p><span>      </span><span>:</span><span> document</span><span>.</span><span>createElement</span><span>(</span><span>fiber</span><span>.</span><span>type</span><span>)</span></p></div><div><p><span>  </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> </span><span>{</span><span>}</span><span>,</span><span> fiber</span><span>.</span><span>props</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isEvent</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> key</span><span>.</span><span>startsWith</span><span>(</span><span>"on"</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isProperty</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>  key </span><span>!==</span><span> </span><span>"children"</span><span> </span><span>&amp;&amp;</span><span> </span><span>!</span><span>isEvent</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isNew</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>const</span><span> </span><span>isGone</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>(</span><span>key </span><span>in</span><span> next</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> prevProps</span><span>,</span><span> nextProps</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>        </span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isGone</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>      dom</span><span>[</span><span>name</span><span>]</span><span> </span><span>=</span><span> nextProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>  deletions</span><span>.</span><span>forEach</span><span>(</span><span>commitWork</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>wipRoot</span><span>.</span><span>child</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>commitWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>const</span><span> domParent </span><span>=</span><span> fiber</span><span>.</span><span>parent</span><span>.</span><span>dom</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"PLACEMENT"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>    domParent</span><span>.</span><span>appendChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"UPDATE"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"DELETION"</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    domParent</span><span>.</span><span>removeChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>fiber</span><span>.</span><span>sibling</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>let</span><span> nextUnitOfWork </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>function</span><span> </span><span>workLoop</span><span>(</span><span>deadline</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> </span><span>!</span><span>shouldYield</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    nextUnitOfWork </span><span>=</span><span> </span><span>performUnitOfWork</span><span>(</span></p></div><div><p><span>    shouldYield </span><span>=</span><span> deadline</span><span>.</span><span>timeRemaining</span><span>(</span><span>)</span><span> </span><span>&lt;</span><span> </span><span>1</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> wipRoot</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>performUnitOfWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>=</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span></p></div><div><p><span>  </span><span>const</span><span> elements </span><span>=</span><span> fiber</span><span>.</span><span>props</span><span>.</span><span>children</span></p></div><div><p><span>  </span><span>reconcileChildren</span><span>(</span><span>fiber</span><span>,</span><span> elements</span><span>)</span></p></div><div><p><span>    nextFiber </span><span>=</span><span> nextFiber</span><span>.</span><span>parent</span></p></div><div><p><span>function</span><span> </span><span>reconcileChildren</span><span>(</span><span>wipFiber</span><span>,</span><span> elements</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    wipFiber</span><span>.</span><span>alternate </span><span>&amp;&amp;</span><span> wipFiber</span><span>.</span><span>alternate</span><span>.</span><span>child</span></p></div><div><p><span>    index </span><span>&lt;</span><span> elements</span><span>.</span><span>length </span><span>||</span></p></div><div><p><span>    </span><span>const</span><span> element </span><span>=</span><span> elements</span><span>[</span><span>index</span><span>]</span></p></div><div><p><span>      element</span><span>.</span><span>type </span><span>==</span><span> oldFiber</span><span>.</span><span>type</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>element </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>oldFiber </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      oldFiber</span><span>.</span><span>effectTag </span><span>=</span><span> </span><span>"DELETION"</span></p></div><div><p><span>      oldFiber </span><span>=</span><span> oldFiber</span><span>.</span><span>sibling</span></p></div><div><p><span>      wipFiber</span><span>.</span><span>child </span><span>=</span><span> newFiber</span></p></div><div><p><span>      prevSibling</span><span>.</span><span>sibling </span><span>=</span><span> newFiber</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>&lt;</span><span>h1</span><span>&gt;</span><span>Hi </span><span>{</span><span>props</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>h1</span><span>&gt;</span></p></div><div><p><span>const</span><span> element </span><span>=</span><span> </span><span>&lt;</span><span>App</span><span> </span><span>name</span><span>=</span><span>"</span><span>foo</span><span>"</span><span> </span><span>/&gt;</span></p></div><div><p><span>const</span><span> container </span><span>=</span><span> document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>)</span></p></div><div><p><span>Didact</span><span>.</span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span></p></div></code></pre></div></div></div>]]>
            </description>
            <link>https://pomb.us/build-your-own-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243760</guid>
            <pubDate>Tue, 23 Feb 2021 22:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modules, Monoliths, and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26243079">thread link</a>) | @ash
<br/>
February 23, 2021 | https://tailscale.com/blog/modules-monoliths-and-microservices/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/modules-monoliths-and-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Lately, I get people asking me when microservices are a good idea. In <a href="https://apenwarr.ca/log/20201227">systems design explains the world</a>, I talked about big-picture issues like second system effect, innovator’s dilemmas, and more. Can systems design answer the microservices question?</p>
<p>Yes, but you might not like the answers. First, we'll need some history.</p>
<h4 id="what-is-a-microservice">What is a microservice?</h4>
<p>You can find various definitions on the Internet. Here's mine: microservices are the most extreme possible backlash against <em>monoliths</em>.</p>
<p>Monoliths are what happen when you link everything your entire app needs into one giant program and deploy it as one big blob. Monoliths have a long history, going back to frameworks like CGI, Django, Rails, and PHP.</p>
<p>Right away, let's abandon the assumption that a monolith and a fleet of microservices are the only two options. There's a wide and nuanced continuum from "one giant service that does everything" to "infinite tiny services that each do nearly nothing."</p>
<p>If you follow fads, you'll have built a monolith at least once (whether on purpose or because that's what traditional frameworks encouraged you to do), then discovered some problems with monoliths, then heard that microservices are the answer, then started rearchitecting everything as microservices.</p>
<p>But don't follow fads. There are many points in between those extremes. One of them is probably right for you. A better approach starts with where you want to put your <em>interfaces</em>.</p>
<h4 id="boxes-and-arrows">Boxes and arrows</h4>
<p>An interface is the connection between <em>modules.</em> A module is a collection of related code. In systems design, we talk about "boxes and arrows" engineering: modules are the boxes, and interfaces are the arrows.</p>
<p>The deeper question then is: how big are the boxes? How much goes in each box? How do we decide when to split one big box into two smaller ones? What's the best way to connect the boxes? There are many approaches to all this. Nobody quite knows what's best. It's one of the hardest problems in software architecture.</p>
<p>Over the decades, we've evolved through many kinds of "boxes." <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">Goto statements were "considered harmful"</a> largely because they prevented any hierarchy at all. Then we added functions or procedures; those are very simple boxes, with interfaces (parameters and return codes) between them.</p>
<p>Depending which branch of programming you go down, you then discover recursive functions, combinators, static function prototypes, libraries (statically or runtime-linked), objects (OOP), coroutines, protected virtual memory, processes, threads, JITs, namespaces, sandboxes, chroots, jails, containers, virtual machines, supervisors, hypervisors, microkernels, and <a href="https://en.wikipedia.org/wiki/Unikernel">unikernels</a>.</p>
<p>And that's just the boxes! Once you have boxes isolated from each other, then you need to connect them with arrows. For that, we have ABIs, APIs, syscalls, sockets, RPCs, filesystems, databases, message passing systems, and "virtualized hardware."</p>
<p>If you tried to draw a complete boxes-and-arrows diagram of a modern Unix system (which I won't), it would be wild: functions inside threads inside processes inside containers inside userspace, layered under a kernel, inside a VM, running on hardware in a rack in a datacenter in a cloud provider tied together by an orchestration system, and so on.</p>
<p>Each of those boxes at each of the abstraction layers is somehow isolated from and then connected to some of the others, at the same or other layers. Some are inside others. You couldn't draw an honest version of this picture in a mere two dimensions without lines criss-crossing hopelessly.</p>
<p>This all evolved over decades. Fancy people call it "path dependence." I call it a mess. And let's be clear: most of the mess no longer provides much value.</p>
<p>Instead of focusing on what became very ugly evolutionary results, let's talk about what people were <em>trying</em> to do while they invented all that stuff.</p>
<h4 id="the-quest-for-modularity">The quest for modularity</h4>
<p>The top-line goals of module systems are always the same:</p>
<ol>
<li>Isolate each bit of code from the other bits.</li>
<li>Re-connect those bits only where explicitly intended (through a well-defined interface).</li>
<li>Guarantee that bits you change will still be compatible with the right other bits.</li>
<li>Upgrade, downgrade, and scale some bits without having to upgrade all the other bits simultaneously.</li>
</ol>
<p>The computer industry spends an absolutely immense amount of time messing around, trying to find the perfect balance of all these modularity issues, while still trying to keep development as painless and easy as possible.</p>
<p>We are, in short, not succeeding.</p>
<p>By far the part we're worst at is #1, isolation. If we could truly and efficiently isolate one bit of code from another, the other goals would mostly fall into place. But we simply do not know how.</p>
<p>Isolation is a super hard problem. Goodness knows people have tried. Yet browser sandbox escapes still happen regularly, undetected privilege escalation attacks are simply assumed to exist on every OS, iOS still gets jailbroken periodically, DRM never works (for better or worse), virtual machines and containers regularly have vulnerabilities discovered, and systems like <a href="https://blog.alcide.io/insecure-by-default-kubernetes-networking">k8s have their containers configured insecurely by default</a>.</p>
<p>People have even been known to <a href="https://blog.cryptographyengineering.com/2013/02/04/attack-of-week-tls-timing-oracles/">figure out encryption keys on remote servers by sending well-timed packets</a> to them over the Internet. Meanwhile, the most spectacular isolation failures in recent memory were the <a href="https://meltdownattack.com/">Meltdown and Spectre attacks</a>, which allowed any program on a computer, even a javascript app in a web browser, to read the memory of other programs on the same computer, even across sandboxes or virtual machines.</p>
<p>Every new isolation technology goes through a cycle like the following, from optimism to despair:</p>
<ul>
<li>New idea: we'll finally get it right this time, once and for all!</li>
<li>Initial experiments seem to work.</li>
<li>(Users complain that it's even slower and more tedious than the last thing we tried.)</li>
<li>Early fatal flaws are discovered and fixed.</li>
<li>Widespread deployment.</li>
<li>Ever-more-subtle flaws are successively discovered and fixed.</li>
<li>Eventually, we find flaws that we simply don't know how to patch.</li>
<li>Lose hope that efficient isolation is even possible with this method.</li>
<li>But also we can never retire this isolation method because now too many people are depending on it.</li>
<li>Repeat.</li>
</ul>
<p>For example, at this point security people simply don't believe that any of the following (each one the very best technology available at the time) is totally safe:</p>
<ul>
<li>Process isolation and memory protection on a Unix system.</li>
<li>Privilege separation between OS processes when remote code execution ("RCE" for security people) is allowed.</li>
<li>Filtering syscalls to isolate a process.</li>
<li>Mutually untrusted processes sharing a CPU hyperthread.</li>
<li>Memory isolation between virtual machines on a CPU core.</li>
</ul>
<p>As far as I know, the state of the art, the very best isolation, is something like the Chrome sandbox or <a href="https://github.com/google/gvisor">gVisor</a>. The big browser vendors and cloud providers all use tools like these. The tools remain imperfect, but providers do chase down every new breach as fast as they can, and the rate of new flaws is fairly slow.</p>
<p>Isolation is better than it's ever been before… if you put all your isolation at the virtual machine (VM) level so that your cloud provider can do it for you because nobody else knows how, or updates often enough.</p>
<p>If you trust your cloud provider's VM isolation, you can have hope that all known problems are mitigated; but we have every reason to think more problems will be found.</p>
<p>That's… actually pretty good, all things considered. At least we have <em>something</em> that works.</p>
<h4 id="great-vms-for-everything">Great! VMs for everything!</h4>
<p>Well, hold on. Spinning up an isolated VM for every little module is a pain. And how big is a module?</p>
<p>Long ago, when Java first came out, the dream was that every line of every function in every object could have permissions enforced, even between objects in the same application binary, so that CPU-enforced memory protection wouldn't be needed. Nobody believes anymore that they can make that work. And marketing claims like "cloud functions" aside, nobody really thinks you should try.</p>
<p>None of the currently-known isolation methods work <em>perfectly</em>, but each of them works to <em>some approximation</em>. Increasingly skilled attackers, or increasingly valuable targets, require better and more annoying isolation. The best isolation we know right now is inter-VM sandboxing provided by tier-1 cloud providers. The worst, well, it goes down to zero.</p>
<p>Let's also assume, skipping over the evidence, that most systems are so tightly coupled that <strong>a reasonably skilled attacker can break through laterally between modules.</strong> So, for example, if someone can link a malicious library into your Go or C++ program, they can probably take control of that entire program.</p>
<p>Similarly, if your program has write access to a database, attackers can probably make it write <em>anywhere</em> in the database. If it can contact the network, they can probably contact <em>anywhere</em> in the network. If it can execute arbitrary Unix commands or system calls, they can probably get Unix root access. If it's in a container, they can probably break out of the container and into other containers. If malicious data can <a href="https://imagetragick.com/">crash the png decoder</a>, they can probably make it do anything else the decoder program is allowed to do. And so on.</p>
<p>An especially powerful form of attack is getting the ability to commit code, because that code will eventually be run on developer machines, and some developer or production machine somewhere probably has access to do what you want to do.</p>
<p>The above is maybe a little too pessimistic, but making those assumptions can help avoid overcomplicating your systems without improving actual security. In <a href="http://cr.yp.to/qmail/qmailsec-20071101.pdf">Some thoughts on security after ten years of qmail 1.0</a>, Daniel J. Bernstein points out (if I may heavily paraphrase) that many of the defenses he added in qmail, particularly isolating the different components from each other using chroot and different Unix uids, were not worthwhile and have never paid off.</p>
<p>Anyway, let's take it for granted that attackers with the ability to execute code can "usually" jump …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/modules-monoliths-and-microservices/">https://tailscale.com/blog/modules-monoliths-and-microservices/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/modules-monoliths-and-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243079</guid>
            <pubDate>Tue, 23 Feb 2021 21:26:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking a Stand in the War on General-Purpose Computing]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 247 (<a href="https://news.ycombinator.com/item?id=26242991">thread link</a>) | @Funes-
<br/>
February 23, 2021 | https://cheapskatesguide.org/articles/war-on-gp-computing.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/war-on-gp-computing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/war-on-gp-computing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242991</guid>
            <pubDate>Tue, 23 Feb 2021 21:16:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new take on remote/hybrid standups]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26242959">thread link</a>) | @Ali_Jiwani
<br/>
February 23, 2021 | https://www.rally.video/post/stand-ups-suck-why-not-rally-instead | <a href="https://web.archive.org/web/*/https://www.rally.video/post/stand-ups-suck-why-not-rally-instead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Covid-19 forced everyone to start thinking remote first. Companies started to replace meetings with video calls and eventually questioning if the meeting was necessary. Work went from 'why is everything a meeting?' to "just send me an email/slack message'. Over the past few months we spoke to dozens of remote companies, and we learned that while many have reduced the number of meetings, some actually changed certain meetings to adopt to new technology and ways of working. One of the changes we saw most consistency was the standup - their most frequent and hated meeting.</p><p>In this post, we will talk about:</p><ul role="list"><li>Why do synchronous and asynchronous stand ups suck.</li><li>How the purpose of the stand up will change with the predominance of remote work.</li><li>The end of the traditional standup, and the beginning of a better alternative - a Rally.</li><li>How you can make your standup more like a Rally.</li></ul><h2>Why do synchronous and asynchronous stand ups suck?</h2><p>Standups were originally designed for agile engineering teams. With the world going remote, many companies outside engineering have adopted this practice as a way to update each other on daily progress. They may not call it standups, but the essence is the same.</p><p>The problem with standups is that they are a distraction, and it feels more beneficial to management than to the team. For people working together, standups often don't deliver any new information, and for those working apart, the information is seemingly useless. Standups are also set at weird times to accommodate for everyone across all timezones. That sucks because it takes you away from your work state for a meeting that feels pointless. Finally standups are used as a way for managers to keep track of their teams. Sometimes this is effective, other times it feels intrusive.</p><p>How about asynchronous standups? Surely this is a better solution as it gives everyone flexibility and it feels less likely like management is breathing down your neck. A quick google search on asynchronous standups also reveals similar problems to the standups. People don't care about the update, the context is usually missing, and there is no conversation around blockers. Ultimately asynchronous standups don't provide much value either.</p><p>As one user on Hacker News puts it "Going async sends a message that people don't need to care about what their team members are working on. That's a dream come true for the people who just want to pull Jira tickets out of the queue, finish them in isolation, and then collect a paycheque." And another chimes in "it doesn't make for great team cohesion and knowledge sharing. Teams end up compensating with extra meetings and coordination overhead, which starts to defeat the point of async standups."</p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314b54800c1961716bd82f_hn%20post.png" loading="lazy" alt=""></p><figcaption>Source: https://news.ycombinator.com/item?id=23194569</figcaption></figure><p>Is the answer then to cancel standups? Or to do some form of a hybrid async standup? Call me crazy, but what about extending the standup virtually and inviting a few more teams. Let's go back to first principles so I can explain why.</p><h2>How the purpose of the stand up will change with the predominance of remote work</h2><p>The original purpose of a stand up was to answer three questions:</p><ul role="list"><li>What was I working on yesterday?</li><li>What will I work on today?</li><li>What is blocking me or stopping me from success?</li></ul><p>The idea is to physically get off your chair, discuss the above three questions, and finish the meeting in roughly 15 mins. It is a meeting for the team, not for management.</p><p><em>Source: </em><a href="https://www.atlassian.com/agile/scrum/standups"><em>https://www.atlassian.com/agile/scrum/standups</em></a></p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314ba6f1c0b469307efa91_1_5L-pHXCmAl0GcryXyREF6A.jpeg" loading="lazy" alt=""></p><figcaption>Source: <a href="https://medium.com/@hans.bruins/the-standup-that-disrupts-the-workflow-78cb5b916bcb">https://medium.com/@hans.bruins/the-standup-that-disrupts-the-workflow-78cb5b916bcb</a></figcaption></figure><p>Standups also have an unintended benefit that is not talked about - it brings the team together. In a remote world, isolation is the number one complaint many employees have. Isolation leads to a decline in mental health, productivity, and overall well being. Isolation can also impact teams, where they feel left out from the rest of the company and are forced to have more meetings to play catch up. This is why so many people crave going back to the office. It's not for the meetings, it's for the people. Even the most introverted people have found isolation daunting.</p><p>The problem is this crucial benefit is overlooked in standups, and people start to resent this meeting. The way to solve this problem is to reframe the purpose of the meeting entirely, so much so that it may even warrant a new name, which we call a Rally.</p><h2>What is a Rally? And how will it replace the standup?</h2><p>A Rally is not a formal standup, it is a collaborative get together. Our Rallys are daily and they are 30 minutes long. The original idea came from one of our first engineering hires: Nate Wildermuth, and it's stuck ever since. We spend the first 20-25 minutes chatting, playing a game, or running an activity (see below for examples). Occasionally this leads to a great idea (such as this blog post!) or a tonne of laughs that builds some terrific momentum for the rest of the day. We then take the last 5-10 minutes discussing what we worked on, what we will work on, and any blockers we have. Usually by the time we are discussing work, we feel much more energized and ready to take on the day.</p><h3>"Standups are an endless series of trivia nights where everyone loses." Nate</h3><p>Of course, we use our own video software for these standups. This is because we designed Rally to allow multiple groups to have conversations in the same space. We call these groups 'tables', and we call the space a 'room'. It is easy to hop around to different tables to chat, or sit at a table in case someone needs to chat with you. We also have a stage where you can present to everyone in the room. This way we can let everyone know what we are working on if we needed. Luckily we're not the only ones that do this. We have a number of customers who have been using Rally for similar collaborative meetings. After speaking with them we have come up with a framework for how we think about Rallys, followed be some examples.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314aba2469e82b4aa034b1_Slide%204_3%20-%201.png" loading="lazy" alt=""></p><figcaption>How Rally Works</figcaption></figure><p>A Rally consists of:</p><ul role="list"><li>A recurring event lasting between 30 and 60 mins, few times a week.</li><li>The team running the event will invite close stakeholders. If the team is less than 50 in size, the entire company will attend.</li><li>People notifying who they want to talk to in advance so they can be efficient with their time, while managers keep an open table to allow anyone to talk to them if needed.</li><li>CEO's and senior execs are also in attendance and can choose to hop around tables to stay put and wait for questions.</li><li>Starting and/or ending with an activity or a game to get people excited.</li></ul><p>While we use Rally every day, we have customers that use Rally multiple times a week for different types of get togethers. We consider all of these to be offshoots of the daily Rally:</p><p>1. <strong>Collaboration Rally</strong>: An hour long session where each team member discusses what they are working on in their team, then hops around to other teams to eliminate blockers. The benefit of this is having everyone in one place instead of setting up extra 30 minute meetings and one on ones. To this successfully, one of our customers runs this meeting every Monday and Friday morning. Each team member prepares what they want to discuss, and reaches out to anyone they need to speak to. On average there are 3-4 cross company conversations lasting 10-20 mins each.Since this is a dedicated hour for everyone, people use this time to catch up on work and remove any blockers they have across the company. It is also a great chance to have everyone in one place. Here is an example of what that looks like:</p><figure></figure><p>2. <strong>Sprint Demo Rally</strong>: An hour long meeting where members from the engineering team hop between tables to present their work. The tables are formed of teams outside engineering so any stakeholder can keep up with engineering work. The meeting usually starts with a presentation from one of the leads to the entire room, and finishes with an activity or hangout in case people have questions.</p><figure></figure><p>3. <strong>Virtual Cafeteria Rally</strong>: An hour long daily meeting for anyone in the company to attend. The meeting is at a set time where someone opens up a Rally lunch room. Teams will jump into tables and enjoy lunch together, as they would in real life, or find friends at other tables to talk to. Instead of having multiple video calls for smaller teams, all the teams are in one place. This way they can hop around tables as they overhear interesting conversations. HR managers have also shuffled people into random tables as a way for people to meet each other.</p><figure></figure><h2>How can you change your standup into a Rally?</h2><p>Start by calling it a Rally and not a standup.</p><p>Reframe the purpose of the standup so its not purely about work but about catching up and hanging out as well.</p><p>Start the Rally with a game, activity or fun fact. Here are some options you can try out:</p><ul role="list"><li><a href="https://www.rally.video/games-and-resources">Rally's Games &amp; Activity page</a></li><li><a href="https://bored.social/">Bored Social</a></li><li><a href="https://meet.airconsole.com/">Air Console</a></li></ul><p>If you are hybrid, encourage people to sign in with their own devices for this meeting so it feels like everyone is remote (on their own computers).</p><p>Consider having this meeting few times a week instead of daily</p><p>Consider not limiting this Rally to just your team, but inviting teams you collaborate with to join</p><p>You can improve your standups on any video platform. We're obviously biased because we built our own and we think it is more fun, easier to use, and gives more autonomy to each user! If you'd like to give us a try, why not head over to <a href="https://rally.video/">https://rally.video</a> and sign up for an account. Have questions or comments? Email us at <a href="mailto:hello@rally.video?subject=Blog%20on%20Daily%20Rallies">hello@rally.video </a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.rally.video/post/stand-ups-suck-why-not-rally-instead</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242959</guid>
            <pubDate>Tue, 23 Feb 2021 21:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Kafka API is great; now let's make it fast]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26242197">thread link</a>) | @sorenbs
<br/>
February 23, 2021 | https://vectorized.io/blog/fast-and-safe/ | <a href="https://web.archive.org/web/*/https://vectorized.io/blog/fast-and-safe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><blockquote>
<p><small>Note: we will host a live twitch stream on Thursday, February 25th at 10am PT for 1hr. Come and ask us questions live. We will walk through the code, benchmarks, results, and if time permits, we’ll walk through the storage engine design.</small></p>
</blockquote>
<p><img src="https://vectorized.io/171856194738a05a78e745396ee0c493/1250k-rate-100-partitions-1kb-4-producers-e2e-latency-quantile.svg" alt="1.2GB/s"></p>
<blockquote>
<p><small>1250k msg/sec - 1KB payload - ack=all - fsync after every batch - 1 hour benchmark
</small></p>
</blockquote>
<p>This blog post represents months of work and over 400+ hours of actual
benchmarking where we compared
<a href="https://vectorized.io/redpanda">Redpanda</a>
and the latest 2.7 Kafka Release. We used the recommended production
setup and environment from Confluent’s
<a href="https://github.com/confluentinc/openmessaging-benchmark" target="_self" rel="nofollow">fork</a>
of the CNCF open messaging benchmark.</p>
<p>Before we get started, the entirety of the actual results with the full
workload distribution, saturation, latency and throughput are at the bottom
of this interactive <a href="https://vectorized.io/blog/fast-and-safe/#The-full-test-suite-below">blog post</a>.</p>

<p>The <a href="https://vectorized.io/blog/intelligent-data-api/" target="_self" rel="nofollow">Kafka API</a>
has emerged as the lingua franca for streaming workloads. Developers
love the ecosystem and being able to turn sophisticated products
overnight. Just like Apache and Nginx have their own HTTP
implementations, gccgo and the Go compiler specify parsers for the
language, MySQL and Postgres implement SQL, Redpanda and Kafka implement
the Kafka API. Redpanda aims to bring operational simplicity to the
existing overwhelming complexity of standing up state-of-the-art
streaming systems. This manifests at its lowest level in no longer
having to choose between data safety and performance.</p>
<p>Let’s be clear, the reason tail latency matters in the world of big data
is because Redpanda does not exist in isolation. It often sits between
your web servers, databases, internal microservices, data lakes, etc.
Redpanda controls the information flow of how, when and where things are
stored, transferred, accessed, mutated and eventually delivered. The
reason we obsess over tail latency is because the p99.99 in a messaging
system happens often - it’s a simple function of the messages exchanged.
As the volume of interactions and messages between systems using the
Kafka API increases, so does the probability that a single user
operation or API call is affected by latencies <strong>above</strong> the 99.99th
percentile.</p>
<p>The Kafka API is good, below, we showcase how we made it fast.</p>

<p>We present 18 workloads below. All workloads for both systems replicate
the data to 3 nodes in total with no lag (manually verified in the
quorum system). The only difference is that Apache Kafka was run with
in-memory replication (using the page-cache) and flushing after every
message. Redpanda can only be operated in safe mode (flushing after
every batch) with acks=all. The benchmarks below are the same benchmarks
<a href="https://www.confluent.io/blog/kafka-fastest-messaging-system/" target="_self" rel="nofollow"><u>Alok Nikhil &amp; Vinoth Chandar from
Confluent</u></a>
performed while comparing Pulsar and Kafka with a 1.2GB/s extension,
using the same CNCF Open Messaging Benchmark suite.</p>
<p>First, we note that we were only able to reproduce Confluent’s first 6
results. For the other three workloads, the data shows that it is in
fact impossible to achieve sustained network throughput above 300MB/s on
AWS on i3en.2xlarge instances. Please see our Benchmark Appendix section
at the end for a detailed explanation. We also change the default 1
minute warmup time to 30 minutes to account for <a href="http://www.brendangregg.com/blog/2016-09-28/java-warmup.html" target="_self" rel="nofollow"><u>common
pitfalls</u></a>
in <a href="https://arxiv.org/abs/1602.00602" target="_self" rel="nofollow"><u>Virtual Machine</u></a>
benchmarking practices and focus entirely on steady state performance.
We then ran each workload for 60 additional minutes, recorded the
results and repeated the steps, taking the best run of each system. That
is, each time we ran the benchmarks it took over 54 hours to finish.</p>
<p>For all workloads, we used two m5n.8xlarge for the clients, with
32-cores and with 25Gbps of guaranteed networking throughput
and 128GB of memory to ensure the bottleneck would be on the server
side. The benchmark used three i3en.6xlarge 24-core instances with
192GB of memory, 25Gbps guaranteed networking and two NVMe SSD devices.</p>
<p>We note that after spending several hundreds of hours benchmarks, we had
to scale up Confluent’s Kafka settings to keep up with larger instances
to num.replica.fetchers=16, message.max.bytes=10485760,
replica.fetch.max.bytes=10485760, num.network.threads=16,
num.io.threads=16, log.flush.interval.messages=1. Otherwise, the gap
between Redpanda and Kafka would be much larger. This had the
unfortunate effect that for lower percentiles, Kafka’s latency was a
little higher than using half as many threads as specified by
Confluent’s Github repo.</p>
<p>All the latencies below are the end-to-end p99.999 latency with 16
producers and 16 consumers with 100 partitions on a single topic. Every
message represents 1KB of data. We note that by and large Kafka is able
to keep up on throughput except for a couple of workloads with acks=all
where Redpanda is better. The meaningful differences are in latency: how
fast can each system go.</p>
<h2 id="Safe-workloads---fsync-with-every-batch">Safe workloads - fsync() with every batch<a href="#Safe-workloads---fsync-with-every-batch" aria-label="Safe workloads   fsync with every batch permalink"></a></h2>
<table>
<thead>
<tr>
<th><strong>Workload</strong></th>
<th><strong>Kafka p99.999</strong></th>
<th><strong>Redpanda p99.999</strong></th>
<th><strong>Percentage Change</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>acks=all + fsync() after every batch</strong></td>
</tr>
<tr>
<td>(1) 10MB/s (10K msgs/s)</td>
<td>215.191ms</td>
<td>12.405ms</td>
<td>+1634.71%</td>
</tr>
<tr>
<td>(2) 40MB/s (40K msgs/s)</td>
<td>102.589ms</td>
<td>52.122ms</td>
<td>+96.82%</td>
</tr>
<tr>
<td>(3) 50MB/s (50K msgs/s)</td>
<td>235.675ms</td>
<td>13.999ms</td>
<td>+1522.66%</td>
</tr>
<tr>
<td>(4) 75MB/s (75K msgs/s)</td>
<td>1801.263ms</td>
<td>16.606ms</td>
<td>+10747.06%</td>
</tr>
<tr>
<td>(5) 100MB/s (100K msgs/s)</td>
<td>1725.391ms</td>
<td>20.552</td>
<td>+8295.25%</td>
</tr>
<tr>
<td>(6) 200MB/s (200K msgs/s)</td>
<td>1945.039ms</td>
<td>27.307ms</td>
<td>+7022.86%</td>
</tr>
<tr>
<td>(7) 0.5GB/s (500K msgs/s)</td>
<td>3015.295ms</td>
<td>60.943ms</td>
<td>+4263.23%</td>
</tr>
<tr>
<td>(8) 1GB/s (1M msgs/s)</td>
<td>3839.663ms</td>
<td>174.521ms</td>
<td>+2100.12%</td>
</tr>
<tr>
<td>(9) 1.25GB/s (1.25M msgs/s)</td>
<td>3797.167ms</td>
<td>237.688ms</td>
<td>+1497.54%</td>
</tr>
</tbody>
</table>
<blockquote>
<p><small> Percentage Change was computed using: ((v2-v1)/abs(v1))*100 </small></p>
<p><small> Note: All of our work is open source on <a href="https://github.com/vectorizedio/openmessaging-benchmark" target="_self" rel="nofollow">GitHub</a>. Safe workloads mean acks=all and fsync after every batch before returning to the client.</small></p>
</blockquote>
<h2 id="In-memory-replication-for-Kafka-page-cache--no-explicit-flushes-vs-Redpanda-fsync-ing-after-every-batch">In memory replication for Kafka (page cache &amp; no explicit flushes) vs. <strong>Redpanda fsync()</strong>-ing after every batch<a href="#In-memory-replication-for-Kafka-page-cache--no-explicit-flushes-vs-Redpanda-fsync-ing-after-every-batch" aria-label="In memory replication for Kafka page cache  no explicit flushes vs Redpanda fsync ing after every batch permalink"></a></h2>
<table>
<thead>
<tr>
<th><strong>Workload</strong></th>
<th><strong>Kafka (no fsync) p99.999</strong></th>
<th><strong>Redpanda (with sync) p99.999</strong></th>
<th><strong>Percentage Change</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>acks=all</strong></td>
</tr>
<tr>
<td>(1) 10MB/s (10K msgs/s)</td>
<td>12.728ms</td>
<td>12.405ms</td>
<td>+2.6%</td>
</tr>
<tr>
<td>(2) 40MB/s (40K msgs/s)</td>
<td>216.253</td>
<td>52.122ms</td>
<td>+314.9%</td>
</tr>
<tr>
<td>(3) 50MB/s (50K msgs/s)</td>
<td>222.785ms</td>
<td>13.999ms</td>
<td>+1491.44%</td>
</tr>
<tr>
<td>(4) 75MB/s (75K msgs/s)</td>
<td>216.195ms</td>
<td>16.606ms</td>
<td>+1201.9%</td>
</tr>
<tr>
<td>(5) 100MB/s (100K msgs/s)</td>
<td>13.737ms</td>
<td>20.552ms</td>
<td>-33.16%</td>
</tr>
<tr>
<td>(6) 200MB/s (200K msgs/s)</td>
<td>218.32ms</td>
<td>27.307ms</td>
<td>+699.5%</td>
</tr>
<tr>
<td>(7) 0.5GB/s (500K msgs/s)</td>
<td>4225.215ms</td>
<td>60.943ms</td>
<td>+6833.06%</td>
</tr>
<tr>
<td>(8) 1GB/s (1M msgs/s)</td>
<td>4877.279ms</td>
<td>174.521ms</td>
<td>+2694.67%</td>
</tr>
<tr>
<td>(9) 1.25GB/s (1.25M msgs/s)</td>
<td>202.667ms</td>
<td>237.688</td>
<td>-14.73%</td>
</tr>
</tbody>
</table>
<blockquote>
<p><small> Workload (5) is a bug on our write-behind strategy: <a href="https://github.com/vectorizedio/redpanda/issues/542" target="_self" rel="nofollow">issue #542</a> </small></p>
</blockquote>
<p><strong>We’ve said this ad nauseam: <a href="https://vectorized.io/blog/redpanda-raison-detre/" target="_self" rel="nofollow"><u>hardware is the
platform</u></a></strong>.
Modern hardware is capable of giving you both low latency and no data
loss (fsync). Let’s talk about most of the meaningful low-level
architectural differences that get us there</p>

<p><img src="https://vectorized.io/171856194738a05a78e745396ee0c493/1250k-rate-100-partitions-1kb-4-producers-e2e-latency-quantile.svg" alt="1.2GB/s">
Before we dive deep into details, we encourage you to sign up for our
live Twitch Stream where we’ll be going through every single claim made
in this article, and are happy to answer your questions live. It will be
me, emacs, you and questions. Perfect.</p>
<p>When we started building Redpanda, the main driving factor was
<strong>understandability</strong>. Above performance, we wanted a simple mental
model of what it meant to have 2 out of 3 replicas up and running, which
is how we ended with Raft - a protocol with a mathematical proof of
correctness &amp; log completeness and a focus on usability as part of its
design goals.</p>
<p>However, once you get your replication model set, the rest of the life
of the product is spent on predictability, and for big-data &amp; real time
systems, that means understandable, flat tail latencies. It is not
enough to be fast. It is not enough to be safe. When trying to handle
hundreds of terabytes per day of streaming you need to be predictable
not only in the way the product breaks in case of network partitions,
bad disks, etc, but also in how performance degrades as a function of
hardware saturation. This is at the core of operational simplicity for
streaming systems.</p>
<p>Modern hardware allows us to finally have nice things. It is not the
case anymore that you have to choose between safety (no data loss) and
speed (low latency). Furthermore, this predictability affords you
accurate planning for product launches. As a user, I understand how to
buy hardware. I will perform an `fio` test and have a decent
understanding of what that specific hardware can do. Redpanda lets you
take these hardware saturation numbers and gives you a reasonable chance
of predicting how costly it is to develop a new product.</p>
<p>Without further ado, let me count the ways:</p>
<h2 id="0-No-page-cache">0) No page cache<a href="#0-No-page-cache" aria-label="0 No page cache permalink"></a></h2>
<p>The page cache is an object in the Linux Kernel. It is maintained per
file with global locking semantics. It is a tried and true, generic
scheduling mechanism with heuristics from a variety of production use
cases that push and pull the design to a really good middle ground. It
aims to never be a bad choice if you need to do IO. However, for our
specific use case - a log - we can do much better. We understand
exactly, all the way to the user application, how much data is going to
be needed next, the access patterns which mostly move forward, update
frequency, background operations and cache prioritization.</p>
<p>For us, the page cache introduces latency and nondeterministic IO
behavior. For example, when loading data for a Kafka fetch request the
Linux Kernel will trigger general-purpose read-ahead heuristics, and
cache the bytes it read, take a global lock, and update indexes.
Redpanda does not do general IO. It is a log, append only, with well
understood access patterns. We add data to the end file and have
aggressive write-behind strategies. When we read data, Redpanda reads in
order, which means we can in theory have perfect read-ahead and object
materialization that sits above the byte array style API of the page
cache, etc.</p>
<p>More fundamentally, bypassing the Kernel’s page cache allows us to be
predictable, with respect to both failure semantics and tail latency. We
can detect and measure the rate and latency of IO and adjust our buffer
pools accordingly. We can react to low memory pressure situations and
have a holistic view of our memory footprint. We have predictability
over each filesystem operation that can actually affect correctness - as
recently evidenced by the PostgreSQL team with an fsync() bug that was
<a href="https://www.youtube.com/watch?v=1VWIGBQLtxo" target="_self" rel="nofollow">undetected for 20 years</a>.</p>
<h2 id="1-Automatic-Linux-Kernel-Tuning">1) Automatic …</h2></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/blog/fast-and-safe/">https://vectorized.io/blog/fast-and-safe/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/blog/fast-and-safe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242197</guid>
            <pubDate>Tue, 23 Feb 2021 20:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meaninglessness of the National Debt]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26239799">thread link</a>) | @paulpauper
<br/>
February 23, 2021 | https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/ | <a href="https://web.archive.org/web/*/https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-22257">
	
	<!-- .entry-header -->

	<div>
		<p>The ‘national debt’ has been a fixture of news and politics, probably since the founding of America. Although the national debt continues to swell–at $27 trillion or so as of writing this–my opinion has not changed, that being the national debt is a meaningless number, much like a mathematical abstraction, that has no  bearing on one’s life or investment strategies.  Articles about the <a href="https://wolfstreet.com/2019/11/02/us-national-debt-passed-23-trillion-jumped-1-3-trillion-in-12-months/">size</a> of the national debt have gone viral on Hacker News and Reddit , as well as headlines about how approximately <a href="https://www.thestreet.com/mishtalk/economics/23-6-of-all-us-dollars-were-created-in-the-last-year">“a quarter all US Dollars were created in past year”</a>. This surge in spending is in large part due to due to Covid stimulus and relief, as shown below:</p>
<p><img src="https://wolfstreet.com/wp-content/uploads/2019/11/US-Gross-National-Debt-2011-2019-11-02.png"></p>
<p>Why am I not concerned? For one, deficit hawks have a terrible track record. Doomsayers like Peter Schiff and Karl Denninger have been predicting hyperinflation, dollar collapse, recession, crisis, etc. for decades, to no avail. This does not mean that they cannot, in theory, one day be right, but I think the odds of that happening are sufficiently low to not pay them any mind. </p>
<p>So why is the debt an abstraction, as opposed to a tangible, real concern. Aren’t these big numbers? Yes, they are big, but what must be taken into account are a couple factors: about 40% of the national debt is owed to itself, either held by the fed or government institutions (such as for Social Security and Medicare), whereas the other 60% are held by foreign governments and private individuals and firms. So this effectively reduces the burden by almost half.</p>
<p><img src="https://ei.marketwatch.com/Multimedia/2018/08/21/Photos/ZQ/MW-GO672_nation_20180821130954_ZQ.jpg?uuid=05b585b6-a565-11e8-b6ab-ac162d7bc1f7"></p>
<p>Second, what matters is not so much the absolute size of the debt but rather the interest paid on the debt relative to GDP, which is very low. The US economy is growing fast enough that the deficit , even if it keeps growing, the interest paid keeps shrinking relative to the size of the economy. </p>
<p><img src="https://www.economicshelp.org/wp-content/uploads/2013/02/debt-interest-payments-percent-gdp-600x434.png"></p>
<p>The US economy is growing at 3+%/year (which may not seem like much but it beats Europe, Japan, South America and much of the developed and developing  world on a real basis), but the US government can borrow at close to nothing, so this is effectively free growth.</p>
<p>Second, the properties or characteristics of the national debt are so distinct from a personal, household, or business debt that there is practically no comparison between the two, further making it an abstraction and divorcing it from any reality that we are familiar with. Imagine being able to borrow at close to nothing, and then being able to print money to pay the interest on the debt if necessary, and such printing does not cause wealth destruction or much inflation in the process, as the US dollar is the official ‘global unit’ of wealth (the Forbes 400 list, for example, is denominated in dollars, not Pounds, Yen, or Euro). So even if the treasury were to print enough dollars to cause price levels to rise meaningfully, because everything is still indexed in dollars, Americans do not lose wealth in the process unless the US dollar falls relative to foreign currencies and there is not a sufficiently high corresponding increase of wealth from wages, stocks, real estate, etc. to offset this, but it is not like Americans particularly care how their wealth is growing or shrinking relative to the Brits, the Germans, or the Japanese. </p>
<p>However, when emerging markets governments print money, it causes their currencies to fall relative to benchmarks like the US dollar, which cases wealth destruction and makes the debt harder to service. By compassion, households and individuals pay vastly higher interest rates and cannot issue their own currency. This is obvious, but is a key distinction and why the US national debt should not be thought of in the same way as a regular debt. It really is something else entirely and more of a function or benchmark of the strength and might of the US global economic and cultural hegemony, than a ‘ticking time bomb’ as many in the media falsely liken it to.</p>
<p>But what about all the Covid spending, in particular, the increase of the M1 money supply? Won’t this cause inflation and other problems? But the spending already happened, and the bond market is unfazed. In fact, the bond market has held up in spite of trillions of dollars of Covid spending (and much more to come), showing that bond vigilantes are not concerned. Why is this? Because this money is not really doing anything. It is not inducing meaningful economic activity and business investment, but rather a large chunk of Covid aid is being saved or used to pay down existing debts. Only <a href="https://review.chicagobooth.edu/economics/2020/article/covid-19-stimulus-checks-spurred-saving-and-debt-payment-more-spending">40%</a> of Covid stimulus was spent on consumer goods, which was the intent. Hence it’s actually deflationary, because the US govt. is borrowing at near 0% so consumers can pay down their own double-digit debts, so the end result is much less indebtedness. Second, the amount of additional consumer spending and activity attributable to the stimulus checks is small relative to the size of overall US consumer spending. US consumers spent $15 trillion in 2020 but Covid stimulus adds just $1 trillion to that, assuming all the money is spent, which it is not.  </p>
<p><img src="https://graphics.reuters.com/USA-STOCKS/0100B2LV20C/personal-consumption.png"></p>
<p>Overall, I am not concerned about the national debt. [Emerging market debt, however, is a different beast altogether, and is a much bigger concern for those economics, than the national debt is a concern for the US economy] The national debt should not factor into the decision making processes of investors. Even bond holders should not be concerned.  In spite of the national debt surging over the past quarter-century, US stocks have posted strong inflation-adjusted returns, especially  since 2010. Treasuries and investment-grade corporate bonds have done well too. Anyone who sold their stocks over fears of the national debt, missed out on what has possibly been the biggest bull market in stocks on an inflation-adjusted basis, ever. The debt will never ‘come due’ in the way that rent or credit card bills have a strict deadlines; but will keep being rolled over forever. The media, pundits, talking heads, etc.  will continue to sound the alarm over the debt, but investors, hedge funds, pensions, institutions–people who actually matter and who have skin in the game–will continue to pay no mind to these warnings. </p>



<p><a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="https://twitter.com/intent/tweet?via=&amp;text=The%20meaninglessness%20of%20the%20national%20debt&amp;url=https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/"><img src="http://i.imgur.com/2QyuBgQ.png"></a>

<a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="http://www.facebook.com/sharer.php?u=https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/" data-href="https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/" data-send="false" data-layout="button_count" data-width="60" data-show-faces="false" rel="nofollow"><img src="http://i.imgur.com/OBWIOxN.png"></a>

			</p></div><!-- .entry-content -->

	</article></div>]]>
            </description>
            <link>https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239799</guid>
            <pubDate>Tue, 23 Feb 2021 17:10:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Streamlit to visualize object detection output]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239676">thread link</a>) | @MatthewBrems
<br/>
February 23, 2021 | https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            <header>

                <section>
                    <a href="https://blog.streamlit.io/tag/community/">Community</a>
                </section>

                

                <p>Building an app for blood cell count detection</p>
            </header>

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2021/02/-White--Blood-Cell.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2021/02/-White--Blood-Cell.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2021/02/-White--Blood-Cell.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2021/02/-White--Blood-Cell.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2021/02/-White--Blood-Cell.gif" alt="How to Use Roboflow and Streamlit to Visualize Object Detection Output">
            </figure>

            <section>
                <div>
                    <p>Most technology is designed to make your life, or your work, easier. If your work involves building computer vision into your applications, using the <a href="https://roboflow.com/">Roboflow</a> platform gives you everything you need.</p><p><a href="https://www.streamlit.io/">Streamlit</a> is an open-source platform that enables you to convert your Python scripts to apps and deploy them instantly. Streamlit and Roboflow can work hand-in-hand, allowing you to tackle computer vision problems and visualizing your output so you can make better decisions faster.</p><p>In this post, we’ll walk you through using Roboflow and Streamlit together by showing you how to:</p><ol><li>Fit an object detection model in Roboflow</li><li>Use an API to access the model and its predictions</li><li>Create and deploy a Streamlit app</li></ol><p>Specifically, we’ll be working with a common <a href="https://public.roboflow.com/object-detection/bccd">blood cell count and detection dataset</a>. If you want to skip right to playing with it, <a href="https://roboflow.com/streamlit-bccd">here's an interactive app</a> and <a href="https://github.com/matthewbrems/streamlit-bccd">this is the code</a>.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/1-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/1-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/1-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/1-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption>Red blood cells, white blood cells, and platelets.</figcaption></figure><p>We’ll build an object detection model that detects platelets, white blood cells, and red blood cells. Then, the app we develop together will allow you to make predictions with your object detection model, visualize those predictions at a given confidence level, and edit those predictions based on your preferred confidence level with immediate visual feedback.</p><h3 id="how-to-fit-an-object-detection-model-in-roboflow">How to fit an object detection model in Roboflow</h3><p>Have you fit an object detection model before?</p><p>Even if you haven't, Roboflow helps you work through all aspects of computer vision, from uploading, annotating, and organizing your images to training and deploying a computer vision model.</p><p>We believe you shouldn’t have to be a data scientist or need an extensive coding background to be able to use computer vision. You have everything you need right now.</p><figure><img src="https://lh5.googleusercontent.com/Di4bkgiihzqyb4k47H3Ku0GX_amNEgd03y3QFqOzSzLp-Y08ONhYHOKH6a8C_GSEtmUPboTbIWO58gYZ0fW_ceDetVlTinWmh4UC9C3E2PAggPnh3PDW9lrWwLlzyfeXvYN63c1L" alt=""><figcaption>The computer vision workflow.</figcaption></figure><p><br>If you don’t already have a Roboflow account, you’ll need to <a href="https://app.roboflow.com/">head over to Roboflow and create one</a>. If you’d like to start training your model from a public dataset, Roboflow has a <a href="https://blog.roboflow.com/using-public-datasets/">great tutorial that describes</a> how to improve your model more quickly. (Or, you can <a href="https://docs.roboflow.com/adding-data/upload-api">upload your own dataset</a>!)</p><p>Once you have an account, go to our <a href="https://public.roboflow.com/">computer vision datasets</a> page. We’ve made over 30 datasets of different types public and keep adding more.</p><p>The one we’ll walk through today is a blood cell count and detection dataset.</p><p>After you’ve decided which dataset to use, go ahead and fork it. That will create a copy of the dataset that you can now use.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/streamlit_fork_dataset_recording--2-.gif" alt=""><figcaption>Forking a <a href="http://public.roboflow.com/">public dataset</a>.</figcaption></figure><p>At this point, you can directly fit a model. However, we recommend that you preprocess and augment your images.</p><ul><li><strong>Image preprocessing.</strong> Deterministic steps performed to all images prior to feeding them into the model. For example, you might <a href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/">resize your images</a> so they are all the same size, or <a href="https://blog.roboflow.com/when-to-use-grayscale-as-a-preprocessing-step/">convert your images to grayscale</a>.</li><li><strong>Image augmentation.</strong> Creating more training examples by distorting your input images so your model doesn't overfit on specific training examples. For example, you may <a href="https://blog.roboflow.com/how-flip-augmentation-improves-model-performance/">flip</a>, <a href="https://blog.roboflow.com/why-and-how-to-implement-random-rotate-data-augmentation/">rotate</a>, <a href="https://blog.roboflow.com/using-blur-in-computer-vision-preprocessing/">blur</a>, or <a href="https://blog.roboflow.com/why-to-add-noise-to-images-for-machine-learning/">add noise to your images</a>. The goal is to get your model to generalize better to “the real world” when you deploy your model.</li></ul><p>With the blood cell count dataset I’m using, I chose the following preprocessing and augmentation options:</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/2-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/2-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/2-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/2-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://docs.roboflow.com/image-transformations/image-preprocessing">Image preprocessing</a> and <a href="https://docs.roboflow.com/image-transformations/image-augmentation">image augmentation</a> techniques.</figcaption></figure><p>When deciding whether to use a specific augmentation option, I asked myself the question “Is the augmented image a reasonable image for my model to see?” In this case, I added 90°, 180°, and 270° rotations to my image because the slide of cells could reasonably be rotated 90 degrees and still make sense.</p><p>It wouldn't make sense for all applications. For instance, I might not include that kind of rotation for a self-driving car, because stop signs should be seen with the pole jutting into the ground. To rotate the image 180 degrees would make the stop sign upside down and the ground where the sky should be -- that probably isn’t a very useful thing for my model to learn.<br></p><figure><img src="https://blog.streamlit.io/content/images/2021/02/3-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/3-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/3-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/3-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://blog.roboflow.com/train-test-split/">Training, validation, and testing splits</a>.</figcaption></figure><p>I have my data split up so that 70% of my data is in the training set, 20% is in the validation set, and 10% is in the test set. As you may know, splitting your data into <a href="https://blog.roboflow.com/train-test-split/">training, validation, and testing sets</a> can really help avoid overfitting.</p><p>I’ve decided to create three augmentations. This means that, for each <em>training</em> image, we’ll create three copies of that image, each with random augmentation techniques applied to it. This will give me a total of 874 images that are generated:</p><ul><li>765 augmented training images (765 = 255 * 3) </li><li>plus 73 validation images </li><li>plus 36 testing images.</li></ul><p>Once you’re done with your preprocessing and augmentation, click “Generate” in the top-right corner. <em>Helpful hint:</em> make sure to name your dataset something memorable!</p><h3 id="now-you-re-ready-to-build-a-model">Now you’re ready to build a model</h3><p>To build a model, it’s as easy as clicking “Use Roboflow Train.”</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/4-2.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/4-2.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/4-2.png 1000w, https://blog.streamlit.io/content/images/2021/02/4-2.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Generally, you need a Roboflow Train credit to do this. <a href="https://roboflow.com/contact?utm_source=streamlit&amp;utm_medium=blog&amp;utm_campaign=train">Reach out to us and we’ll get you set up</a>!</p><p>You’ll have the option either to train from scratch or to start from a checkpoint.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/5-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/5-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/5-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/5-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><ul><li><strong>Train from Scratch.</strong> This is the easier option. Just click and go! Your model will be built from scratch, using only the data you’ve provided to it.</li><li><strong>Start from a Checkpoint.</strong> This option is a little more sophisticated and requires a related existing model. If you’ve already built a model (or if there’s a public model) that has been fit on related data, then starting from a checkpoint allows you to use the existing model as your starting point. The model is additionally trained on your images. Two advantages to this are that your model will train more quickly, and you'll frequently see improved performance! This is known as <a href="https://blog.roboflow.com/a-primer-on-transfer-learning/">transfer learning</a>. However, this does require a related existing model, and we don't always have that.</li></ul><p>In my case, I built my model from scratch, because I didn’t already have a related model.</p><p>That’s all it takes to fit a model in Roboflow. When all is said and done, if your data is already annotated and you don’t make many changes to the augmentations, it’s only a handful of clicks to go from your images to a trained computer vision model. We've also turned <a href="https://docs.roboflow.com/annotate">annotating images into a pretty fast process</a> – especially with <a href="https://blog.roboflow.com/announcing-label-assist/">model-assisted labeling</a>.</p><h3 id="how-to-use-an-api-to-access-the-model-and-predictions">How to use an API to access the model and predictions<br></h3><figure><img src="https://blog.streamlit.io/content/images/2021/02/6-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/6-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/6-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/6-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>You’ll want to make sure your model performs well before getting too far into this. </p><p>Our model seems to perform pretty well. Usually, we use <a href="https://blog.roboflow.com/mean-average-precision/">mean average precision</a> (mAP) to evaluate object detection models. The closer your mAP is to 100%, the better! It’s also helpful to look at your <a href="https://blog.roboflow.com/mean-average-precision-per-class/">model’s performance by class</a> to make sure your object detection model isn’t performing significantly worse for one subset of objects.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/7-2.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/7-2.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/7-2.png 1000w, https://blog.streamlit.io/content/images/2021/02/7-2.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>If your model isn’t performing the way you want, you may want to work on improving that before you proceed. We usually see dramatic improvements in models when people take one (or both) of the following two actions:</p><ol><li><a href="https://blog.roboflow.com/tips-for-how-to-label-images/"><strong>Improve their labeling</strong></a><strong>.</strong> Placing bounding boxes around the entire object, but as close to the edges of the object as possible, can improve your model’s performance.</li><li><a href="https://blog.roboflow.com/handling-unbalanced-classes/"><strong>Correcting for unbalanced classes</strong></a><strong>.</strong> Having one or more classes that are severely underrepresented can make it harder for your model to properly identify those underrepresented classes. A basic example is if you show a child 5 pictures of a dog and 100 pictures of a cat, the child may not do a very good job of identifying a dog.</li></ol><p>Now that we’ve fit a model, we can use that model to generate predictions on new images. The <a href="https://docs.roboflow.com/inference">Roboflow Infer API</a> is one of a few ways to conduct inference and that's what we’ll use.</p><p>In order to use the API, we’ll need a couple of pieces of information from Roboflow. <strong>Make sure you keep these both private. </strong>These are specific to you!</p><ul><li>The model name: this should begin with <code>rf</code>.</li><li>The access token/API key: this should be a 12+ letter code.</li></ul><p>This information can be found in multiple places. I like retrieving these from the Example Web App, because I’ll also easily upload an image and test out my model from there. Once you have these pieces of information, you’ll want to store them – you’ll need them momentarily.</p><h3 id="how-to-create-and-deploy-a-streamlit-app">How to create and deploy a Streamlit app</h3><p>Deploying a Streamlit app is easy. Even if you haven’t spent a lot of time focused on deploying apps before. (Here is the <a href="https://github.com/matthewbrems/streamlit-bccd/blob/master/streamlit_app.py">code I wrote to build the app</a>.)</p><p>Following <a href="https://docs.streamlit.io/en/stable/api.html">Streamlit’s API documentation</a> closely, I was able to build an app that:</p><ul><li>Imported an image file from my computer</li><li>Allowed the user to tweak parameters of our computer vision model</li><li>Showed my imported image overlaid with the model’s predicted annotations</li><li>Calculated and displayed summary statistics about the image and predictions</li><li>Generated a histogram of confidence levels for bounding boxes</li></ul><p>I chose to structure this in two physical components: a sidebar and the main area.</p><ul><li><strong>Sidebar.</strong> In the sidebar, the user gets to select a file to import from their local computer. This is where the user can select an image to pull into the app and edit the confidence and overlap thresholds used when generating predicted bounding boxes for the image.<br></li></ul><figure><img src="https://blog.streamlit.io/content/images/2021/02/8-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/8-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/8-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/8-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><strong>Main Area.</strong> In the main area, we have everything else I mentioned. The image that includes predictions, some statistics about the image and predictions itself, a histogram that shows the confidence levels for all bounding boxes, and a printout of the JSON that stores the bounding box annotations.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>If you want to see the full code, <a href="https://github.com/matthewbrems/bccd_streamlit_app/blob/main/streamlit_app.py">you can find it here</a>. The three tools that were most helpful in putting this together were:</p><ul><li><strong><code>st.write()</code></strong>: If I wanted to print anything on my screen, <code>st.write()</code> enabled me to do that easily. It supports <a href="https://daringfireball.net/projects/markdown/">Markdown</a>, so I can use ## to control how large or small I want my headings to be. I also used <a href="https://realpython.com/python-f-strings/">f-strings</a> when displaying summary statistics to have more control over how these rendered. For example, rounding …</li></ul></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/">https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/</a></em></p>]]>
            </description>
            <link>https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239676</guid>
            <pubDate>Tue, 23 Feb 2021 17:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ideal way how you want your functional monitoring to run is]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239573">thread link</a>) | @testRigor
<br/>
February 23, 2021 | https://blog.testrigor.com/what-is-functional-monitoring/ | <a href="https://web.archive.org/web/*/https://blog.testrigor.com/what-is-functional-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <figure><img src="https://blog.testrigor.com/content/images/2021/02/AdobeStock_378844640.jpeg" alt="" srcset="https://blog.testrigor.com/content/images/size/w600/2021/02/AdobeStock_378844640.jpeg 600w, https://blog.testrigor.com/content/images/size/w1000/2021/02/AdobeStock_378844640.jpeg 1000w, https://blog.testrigor.com/content/images/size/w1600/2021/02/AdobeStock_378844640.jpeg 1600w, https://blog.testrigor.com/content/images/size/w2400/2021/02/AdobeStock_378844640.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure><h3 id="the-issue">The issue</h3><p>Imagine, that you have monitoring, everything is setup great and your metrics show green. But your customers can't purchase your product in your production or registration doesn't work.</p><p>This is why you'd want to set up something that would monitor that your product works in production from end-user's perspective.</p><h3 id="why-is-it-a-challenge">Why is it a challenge?</h3><p>There is an inherit challenge with functional monitoring: test stability. You don't want to be woken up in the middle of the night because a test flaked out.</p><h3 id="how-it-should-work">How it should work?</h3><p>The ideal way how you want your functional monitoring to run is:</p><p>1) To have a continuously running smoke test suite that would only notify you if there is an issue. This way if your customers can't buy a product or register you'd be immediately notified about it.</p><p>2) Get your notifications on all the right channels like Slack, Email, SMS, Phone.</p><p>3) Your tests are actually testing important functionality that if not working will have tangible business impact on your business.</p>
              </div></div>]]>
            </description>
            <link>https://blog.testrigor.com/what-is-functional-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239573</guid>
            <pubDate>Tue, 23 Feb 2021 16:54:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rows launches a spreadsheet with data, integrations, and sharing]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26239210">thread link</a>) | @helhady
<br/>
February 23, 2021 | https://blog.rows.com/p/rows-beta | <a href="https://web.archive.org/web/*/https://blog.rows.com/p/rows-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><ol><li><p>Rows is coming out of our closed beta and launching in Public Beta<strong>. </strong></p></li><li><p>We have raised a $16 million Series B round, led by Lakestar. Our previous investors and other cool people joined us, too.</p></li></ol><p>Join us in this celebration! But first, what is Rows?</p><h3>Rows</h3><p>Rows is the only true Spreadsheet with Integrations and a slick Sharing experience.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe80e654c-cf95-48df-b894-309ded708b65_1200x316.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe80e654c-cf95-48df-b894-309ded708b65_1200x316.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e80e654c-cf95-48df-b894-309ded708b65_1200x316.png&quot;,&quot;height&quot;:316,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6454,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>One billion people in the world use spreadsheets, but it’s hard to connect them to different data sources and to turn them into something you actually like to share. Rows  solves this by integrating the 3 things people like: spreadsheets, data, and slick UIs.</p><p>You’ve never seen a spreadsheet like that! Check <a href="https://rows.com/">rows.com</a> for more info!</p><h3>🚀 Public Beta</h3><p>We’re now officially in a Public Beta!</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png&quot;,&quot;height&quot;:700,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:61461,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Going <em>Public</em> means that anyone can <a href="https://rows.com/auth/sign-up">create an account</a>. It also means that platform has been certified ready by our private beta users: we onboarded more than 10k users, and 100s of teams are active every week. Being a <em>Beta</em> also means that there’s just a handful of features left to ship until we baptize our spreadsheet as a v1 later this year. </p><p><em>Rows is free for smaller teams with up to 10 users. We rolled out paid subscriptions for larger companies, starting at $59 per month. Rows will always have a free plan.</em></p><p>We are <strong>very</strong> excited to learn about what you will build with Rows!</p><h3>What’s Next</h3><p>Rows’ vision is to empower the world’s one billion spreadsheet users to build the tools they need. </p><p>Today, businesses use Rows for critical processes in <a href="https://rows.com/solutions/sales">sales</a>, <a href="https://rows.com/solutions/marketing">marketing</a>, and <a href="https://rows.com/solutions/operations">operations</a>. We will continue to serve these use cases, and expand them with exciting new features. Throughout 2021, our team in Porto and Berlin have lined up (more than) a few serious releases:</p><ul><li><p>More classic spreadsheet functionality, like Charts and conditional formatting. </p></li><li><p>Upgraded Integrations, including easier and faster data management; and, of course, more functions and Integrations (we’re beyond 50 now).</p></li><li><p>New elements for Sharing, including a new button, drop-downs, and more.</p></li></ul><p>We are also working on a Desktop App 👩‍💻!</p><h3>Series B Funding</h3><p>Today we are also announcing our Series B round, led by <a href="https://www.lakestar.com/">Lakestar</a>! The round had the participation of our existing investors Accel and Cherry, as well as new entrants Armilar and Shilling from Portugal and Visionaries Club from Berlin. </p><p>Stephen Nundy, partner at Lakestar, is joining our board — and adding his tech and spreadsheet experience from his career at Goldman Sachs. Also joining our board is Christian Reber, CEO of <a href="https://pitch.com/">Pitch</a>. </p><p>We are very fortunate to continue evolving our company with such a strong board and advisors!<br>—</p><p>We are incredibly happy to be a part of the world of spreadsheets, and we’re excited to enter this new phase of our journey to empower spreadsheet users to build their own tools.</p><div><p>As always, we appreciate your support and love!</p><p>Let’s GO!<br>Humberto &amp; Torben<br>— Rows Founders</p></div></div></div>]]>
            </description>
            <link>https://blog.rows.com/p/rows-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239210</guid>
            <pubDate>Tue, 23 Feb 2021 16:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git is my buddy: Effective Git as a solo developer]]>
            </title>
            <description>
<![CDATA[
Score 389 | Comments 188 (<a href="https://news.ycombinator.com/item?id=26239068">thread link</a>) | @vortex_ape
<br/>
February 23, 2021 | https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/ | <a href="https://web.archive.org/web/*/https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p><small>February 23, 2021 • Reading time: 12 minutes</small></p>

<p>At this point, most developers use Git as a tool for collaboration. We have our
rote-learned commands to pull, commit, and push. And of course, there's <a href="https://xkcd.com/1597/">that
one coworker</a> who knows a bit more about Git than
everyone else, who helps get us back on track whenever our local repos end up in
a strange state.</p>
<p>But what if I told you that Git can be a valuable tool without ever setting up a
remote repository? I'm not just talking about having a working version of your
code base to roll back to if you mess something up, although there's that too.
Used correctly, Git can help to structure your work, identifying gaps in your
test coverage and minimizing dead code.</p>
<p>There are two subjects I'm going to avoid for the purposes of this blog post:
other developers, who are the most compelling but least interesting argument
for keeping your commit history clean, and <code>git bisect</code>, which does factor
heavily into my workflow but deserves its own blog post.</p>
<p>As with any ubiquitous developer tool, the Git user base has a lot of strong and
conflicting opinions about the one "correct" way to use it. My goal is simply to
introduce a workflow that I've been using and refining for much of my career;
take from it what you will. And, importantly, it's a workflow that has become a
vital part not just of my collaboration process, but of the way I write code.</p>
<p>Ultimately, these principles serve two purposes: they focus my work onto a
particular bugfix, feature, or goal, and they ensure that my Git history isn't
set in stone. With proper hygiene, commits can be dropped, rearranged, and split
off into other branches painlessly and without merge conflicts.</p>
<h2 id="principle-1-a-branch-must-do-one-useful-thing">Principle 1: A branch must do one useful thing</h2>
<p>When I'm managing my own projects, I have a lot of ideas that I want to see
happen. If I'm just throwing one commit after another into <code>main</code>, I'll get
halfway through implementing one feature and then jump off to hacking on
another. If any of the features get completed, it will be at the expense of a
wasteland of half-completed features that are now taking up space in my code
base.</p>
<p>In a brand-new project, sure, I'll throw a bunch of garbage commits into <code>main</code>.
My rule of thumb for when to stop this is when I can write my first effective
integration test. If there is <em>something</em> useful to test, there is now enough
substance to my project that I can have distinct tasks on the go. Trying to
break into branches too early just results in me throwing my garbage commits
into a branch instead of main.</p>
<p>In the early stages of a project, articulating the purpose of a branch can be as
simple as giving it a descriptive name. If a commit isn't moving the code base
in that direction, it can always get cherry-picked into a different branch.</p>
<p>As the project matures, I'll start using some sort of issue or bug tracking
software to flesh out what I'm trying to accomplish in more detail and
coordinate the branches for multiple related useful things.</p>
<p>I find that descriptive branch names also help to refocus my attention on what
I'm trying to accomplish. For instance, my command prompt currently looks like
this:</p>
<pre><span>10:02:19 </span><span>max</span> <span>~/Projects/mikkel.ca</span> <span>blog-post-git-as-a-solo-developer</span><span>|</span> <span>R</span><span>%</span></pre>
<h2 id="principle-2-every-commit-must-be-independent">Principle 2: Every commit must be independent</h2>
<p>So much for branches, let's zoom into a commit level. I've articulated what
concrete thing I want my branch to add, now how do I add it? Usually, there's
some poking around my code base involved in figuring that out. Sometimes I take
a wrong turn, sometimes I just get distracted. That's okay, it's part of the
process.</p>
<p>However, that doesn't mean that every commit I make right now is going to end up
getting merged in this branch. By keeping my commits independent from one
another, I ensure that I can rearrange or cherry-pick them into new branches
if I discover that they really don't have anything to do with what I'm working
on right now.</p>
<p>If my commits are not independent, I am essentially stuck with the exact history
as it was written. Trying to tease out a commit into a different branch or move
it to the beginning of my branch history will become fraught with merge
conflicts as later commits that modified code introduced in this commit fall
like dominoes.</p>
<p>Obviously, I'm still allowed to call code written in one commit from a later
commit. That's the reason I'm doing this particular work in this particular
branch, after all. But I never touch the same code multiple times. If I have to
go back and fix something, maybe add a validation check or field that I hadn't
thought of, I'll go back to the commit where it was created rather than amending
it in a later commit.</p>
<p>Obviously, this could go on forever, which is why the "one useful thing"
principle exists. Once I've settled on what I want the code to look like for the
purposes of this branch, I merge and then start a new commit in the next branch
for further changes to the same.</p>
<h3 id="principle-2a-every-commit-must-include-its-own-tests">Principle 2a: Every commit must include its own tests</h3>
<p>Here's where keeping commits small starts to pay dividends. If the code in each
commit is small enough for me to reason about, it's small enough for me to
visually ensure that its test coverage is good.</p>
<p>And of course, if I do end up rearranging this commit or splitting it off to a
different branch, I want its tests to come along with.</p>
<p>The exception to this is integration and functional/behavioural tests, which can
and should have their own commits. In that case, the tests are really tied to
the branch level rather than the commit level, since Principle 1 implies that
there should be exactly one new test to add as a result of this branch.</p>
<h2 id="principle-2b-every-commit-must-pass-all-tests">Principle 2b: Every commit must pass all tests</h2>
<p>Again, breaking something in a commit (even if I <em>really definitely</em> intend to
fix it in a later commit) locks me into the git history as written. And
introducing a breaking change with the intention of fixing things later always
carries the risk that I'll get distracted and end up merging the breaking
change.</p>
<p>If there's some prerequisite to get this change to pass tests - say, a
preexisting bug that snuck through a hole in my test coverage - that gets its
own commit.</p>
<p>Speaking of holes in test coverage, there's another (temporary) exception here.
I don't normally practice strict <a href="https://en.wikipedia.org/wiki/Test-driven_development">test-driven
development</a>, but if I do
fix a long-standing bug, I normally temporarily put its test in a separate
commit. I'll then rebase so that the test appears before the fix, ensure that
the test fails <em>without</em> the fix, then complete the rebase and validate that the
test now passes. Once the due diligence to validate my test is done, I can go
ahead and squash the bugfix with its test.</p>
<h2 id="principle-3-draft-commits-are-fine">Principle 3: Draft commits are fine</h2>
<p>If I know that I'll be coming back to a change later, I'm much more comfortable
setting it down and moving on to roughing in the next part of the process,
rather than finishing, polishing, and unit testing code that might need to
change before my branch gets merged.</p>
<p>In fact, I find that I waste much less time on writing tests for things that
I'll later change when I'm following this workflow to the letter than I do when
I get "lazy" and start dumping everything into big catch-all commits.</p>
<p>Some people favour TODO comments in their code, occasionally supported by
automated checks that prevent code containing "TODO" from merging. I prefer to
annotate my commit messages and leave my code clean. Normally, this looks
something like "add controller class - TODO test me". (I always put my TODOs on
the first line of the commit message, so that they show up even in short log
views.)</p>
<h2 id="principle-4-it-s-okay-to-discard-commits-completely">Principle 4: It's okay to discard commits completely</h2>
<p>Often I start a task by tidying up the surrounding code, in the same way I might
organize my desk before starting work. (I don't, but I <em>might</em>.) Sometimes that
cleanup turns out to be a valuable part of the groundwork for this change, but
sometimes it's just dead weight. Keeping my commits independent makes it easy to
discard or cherry-pick out code that turned out to be unnecessary, along with
any unit tests that went along with.</p>
<p>(I do still consider the tidying to be a valuable part of the process. It clears
my mind and refreshes my knowledge of the problem space with some simple rote
tasks before I dive into something more complex. And occasionally it results in
cleaner code.)</p>

<p>I'm not perfect.<sup>[citation needed]</sup> Obviously, it's not practical to
maintain this level of commit hygiene by making each change sequentially.
Instead, I jump around <em>constantly</em>. Doing so requires me to be comfortable in
navigating my commit history. (Conversely, it's also a good way to <em>become</em>
comfortable with navigating history.)</p>
<p>In that vein, here are some tools beyond your standard
<code>checkout</code>/<code>branch</code>/<code>pull</code>/<code>commit</code>/<code>push</code> workflow that come in handy.</p>
<ul>
<li>
<p><a href="https://git-scm.com/docs/git-commit"><code>git commit --amend</code></a> – A quick and easy
way to update the most recent commit.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-commit"><code>git commit --fixup [hash]</code></a> – When
changing history, I used to find myself making a lot of commits with messages
like "merge me with xyz" if I need to revisit commits before the most recent
one. It turns out that <code>git commit</code> has flags to help with this: <code>--fixup</code> and
<code>--squash</code> will automatically suggest a fixup or squash with another commit
during rebase if the <code>--autosquash</code> flag is provided to that command. (To
enable this behaviour by default, run <code>git config --global rebase.autosquash true</code>. It won't behave any differently if there are no commit messages in the
history being edited that contain "squash!" or "fixup!".) A surprise bonus:
since the fixup operation inherits the message of the previous commit, you
won't be prompted to enter a new one.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-rebase"><code>git rebase --interactive main</code></a> – I can
also use <code>git rebase --interactive HEAD~5</code> to edit the last 5 commits, but I
find rebasing directly on <code>main</code> (or <code>master</code>, or whatever my upstream branch
is) kills two birds with one stone. It will show me all commits since I
branched off from <code>main</code>, and will simultaneously bring my branch up to date
with my latest local copy of main.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-stash"><code>git stash</code></a> – Sometimes I have unrelated</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/">https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/</a></em></p>]]>
            </description>
            <link>https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239068</guid>
            <pubDate>Tue, 23 Feb 2021 16:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release (YC W20) – 5 Ways Ephemeral Environments Improve Developer Velocity]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238650">thread link</a>) | @tommy_mcclung
<br/>
February 23, 2021 | https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>Velocity is a measurement of how many story points a software development team can finish within a sprint (usually one or two weeks). These points are set by the software development team when they review a ticket and estimate how complex the ticket is. When a team measures this output over a period of time, generally they have a consistent amount of story points they can deliver in a sprint and their velocity is known.</p><p>Improving developer velocity is directly correlated with performance. <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance" title="Link to mckinsey developer velocity study" target="_blank" rel="noreferrer">McKinsey published an article in April 2020</a>, where they cite that companies in the top 25% on their Developer Velocity Index grow up to twice as fast as companies in their same industries. Intuitively this makes sense since delivering more allows the development team to learn through iterating and improving. </p><p>One might argue that velocity alone doesn’t make for great software, but assuming a development team is aware that quality is important, one can see how velocity usually helps. The ability to deliver quickly also allows a development team to address quality issues quickly. It’s easy to argue that development teams with high velocity have the ability to deliver better quality software because they can address issues quickly.</p><p>In the same study, McKinsey highlighted several factors that allow a software development team to move quickly. Specifically they highlight that Technology Tools are an incredibly important dimension to velocity and business outcomes. And the most important tools are: Planning, Collaboration, Development and DevOps tools. </p><p>In this post I’m going to discuss the <strong>top 5 ways Ephemeral Environments can improve developer velocity</strong> by touching on how they are a <em>Collaboration</em>, <em>Development</em> and <em>DevOps</em> tool. As we’ve spoken about in our article <a href="https://releaseapp.io/ephemeral-environments" title="What is an Ephemeral Environment" target="_blank" rel="noreferrer">“What is an Ephemeral Environment?”</a>, ephemeral environments are spun up on demand and contain the code and data that approximates production closely. These environments are used by development teams in the software development process to test, debug and ensure features are built correctly before code is pushed to production.</p><h2 id="here-are-the-top-5-ways-ephemeral-environments-can-be-used-to-improve-developer-velocity">Here are the top 5 ways ephemeral environments can be used to improve developer velocity</h2><h3 id="1-ephemeral-environments-are-a-devops-tool-designed-to-remove-the-staging-or-qa-environment-bottleneck"><strong>1. Ephemeral environments are a DevOps tool designed to remove the staging or QA environment bottleneck</strong></h3><p>Traditional pre-production ecosystems usually have a limited amount of environments for developers. The staging or QA environment is generally used as a step before production where all code is merged and tested. Most organizations have one or very few of these environments, so as the organization grows these environments become a bottleneck in the process as all code must be tested here before production. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/57RYmuBRfBBWCRUWglqBnZ/14bafeeb0a47fd566938d2ff052a01c6/Screen_Shot_2021-02-22_at_2.43.18_PM.png" alt="Example of ephemeral environments for each branch"></p><p>With ephemeral environments, the traditional idea of “staging” is gone. Every feature branch is contained in its own isolated environment and becomes its own integration environment. There is no longer a need to have a single testing and integration environment where all code must merge before going to production. With ephemeral environments you have a limitless supply of environments for any purpose.</p><h3 id="2-ephemeral-environments-are-a-collaboration-tool-designed-to-allow-for-early-and-often-feedback"><strong>2. Ephemeral environments are a collaboration tool designed to allow for “early and often” feedback</strong></h3><p>Feedback is the lifeblood of great products. If you’ve ever read <a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884/" title="High Output Management Book" target="_blank" rel="noreferrer">Andy Grove’s book on high output management</a>, you know he does an amazing job of discussing how rework is so costly. If you haven’t read this book, I highly recommend it, even if all you read are the first few chapters where he discusses trying to cook a high quality egg repeatedly, in under three minutes. In summary, Andy suggested through this analogy that finding issues/defects early in the egg cooking process is the most important part of consistently cooking a high quality egg in under three minutes.</p><p>Likewise in software development, getting feedback and finding quality issues early in the development cycle reduces costly rework and improves velocity. If a product is delivered to a customer that doesn’t work or has bugs, it has to be reworked and go through the entire process again. Or if a product manager or designer doesn’t have a way to see changes until an engineer is finished with development, there is a high likelihood they will spot something wrong and rework the solution. These are all examples of rotten eggs in the process that hamper developer velocity. </p><p>With ephemeral environments, rework can be minimized because stakeholders become a part of the development process. When an ephemeral environment is created, URLs to the environment are created so stakeholders can see progress while code is being developed. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2dFjnsY2lBSSbkaOfqczSG/3b9ef1f1134d5cf21f464af8dbf8fa93/Screen_Shot_2021-02-22_at_2.40.44_PM.png" alt="Links in the PR"></p><p>At <a href="https://releaseapp.io/" title="Link to Release Home Page" target="_blank" rel="noreferrer">Release</a>, we highly recommend to our customers that they create a PR as soon as a developer starts working on a feature so a Release Ephemeral Environment is automatically created. When the developer pushes code to their source control system, the environment is updated making it a live reflection of the feature during development. Product managers, designers and QA are automatically notified when changes are live and they can preview those changes and give feedback immediately. </p><p>At Release, we will also share our own ephemeral environments with our customers as we’re building a feature so we can get feedback directly from the people we’re making the software for before we release it to production.</p><h3 id="3-ephemeral-environments-can-limit-rework-and-thus-increase-developer-velocity"><strong>3. Ephemeral environments can limit rework and thus increase developer velocity.</strong></h3><p>Ephemeral environments are a developer tool that allows for full integration and smoke testing on isolated features</p><p>Traditional continuous integration (CI) is the idea that your developer process should constantly be testing as a developer pushes code. What this leaves out many times is that most CI systems only perform unit tests continuously. Unit tests are meant to test small units of code and not the entire system as a whole. Integration and Smoke tests are where full paths of user experience can be tested. Usually Integration and Smoke tests are left to be tested only when the code makes its way via a merge to the mainline code branch and a traditional staging environment.</p><p>Again, if we refer back to Andy Grove’s three minute egg analogy, this step of running Integration and Smoke tests only when the code branch is merged to the mainline is extremely late in the process. If issues are found during Integration and/or Smoke tests, the developer has to start the development cycle again from the beginning after finding this issue too late in the process.</p><p>To add to the issue, if a team only has a single staging environment, the bottleneck around this staging environment is exacerbated with developers waiting for Integration and Smoke tests to be run on this single environment. On top of this, many code changes/features/branches may have been a part of the mainline merge making finding the cause of failed Integration/Smoke tests difficult and time consuming.</p><p>With ephemeral environments, Integration and Smoke tests can be run when the ephemeral environment is created for a feature branch. This ensures that Integration and Smoke tests are run as frequently as unit tests so developers can find issues early in the process. Additionally, Integration and Smoke tests run against a single feature change/branch will isolate changes against the mainline and make finding the root cause much easier.</p><h3 id="4-ephemeral-environments-are-a-devops-tool-that-allow-for-experimentation-with-infrastructure"><strong>4. Ephemeral environments are a DevOps tool that allow for experimentation with infrastructure</strong></h3><p>Making changes to infrastructure is hard and when a developer introduces the need for an infrastructure change it’s costly in time across the board. In a traditional environment setup (without ephemeral environments) this will result in an overall slow down in developer velocity as the shared staging environments must be updated by the DevOps team so the developer has some place to test their changes and new infrastructure.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/4clfoJM7gvr7ufFW8yqmax/e9731087d982502e619cba93d9cbafc6/Screen_Shot_2021-02-22_at_2.44.56_PM.png" alt="Experiment with environment configuration"></p><p>With ephemeral environments, this testing can be done in isolation and does not impact any other developer. For instance, with Release Ephemeral Environments, a developer can add services, environment variables, new infrastructure dependencies, new datasets/databases on their own through use of environment templates (environments as code) to experiment and develop without interfering with any other developers work or environments. This results in higher developer velocity again through minimization of rework and bottlenecks on shared resources.</p><h3 id="5-ephemeral-environments-are-a-collaboration-tool-designed-to-be-an-agilescrum-catalyst"><strong>5. Ephemeral environments are a collaboration tool designed to be an agile/scrum catalyst</strong></h3><p>Many organizations have made the move to Agile/Scrum but their infrastructure and technology haven’t adapted to support a more iterative approach to building software. The entire premise of Agile/Scrum is for teams to be empowered and driven by early and often feedback. If your organization is on Agile/Scrum and you’re still using a single or few staging environments, you’re technologically hampering your process improvements. Ephemeral environments are the homes and office buildings where agile teams live, work, build, and play.</p><p>Ephemeral environments are a catalyst to the Agile/Scrum methodology. When a developer does a pull request the ephemeral environment is created and collaboration on the feature can begin. The team is free to iterate, share,  nand solicit feedback all while keeping the rest of the organization freely moving with their own ephemeral environments. Stakeholders are a part of the development process and true customer driven development, which is the heart of the Agile/Scrum methodology, can occur.</p><h2 id="conclusion">Conclusion</h2><p>Ephemeral environments turbo charge development velocity by eliminating bottlenecks in the process (DevOps Tool), including stakeholders in the process (Collaboration Tool) and improving product quality (Developer Tool). All of these factors were highlighted in the McKinsey report on developer velocity as critical and ephemeral environments are <em>an investment that will put your organization in the top 25%</em>.</p><p>Photo by <a href="https://unsplash.com/@maicoamorim?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Maico Amorim photo credit" target="_blank" rel="noreferrer">Maico Amorim</a> on <a href="https://unsplash.com/@maicoamorim?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Unsplash link to photo" target="_blank" rel="noreferrer">Unsplash</a>.</p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238650</guid>
            <pubDate>Tue, 23 Feb 2021 15:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Developers Procrastinate (and How to Stop)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238435">thread link</a>) | @KaiserSanchez
<br/>
February 23, 2021 | https://www.7pace.com/blog/why-developers-procrastinate | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/why-developers-procrastinate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>What should you be doing instead of <a href="https://www.7pace.com/blog"><u>reading this article</u></a>?</p>



<p>Yeah, we know. You’re probably putting off some kind of work right now.</p>



<p>Procrastination is an age-old struggle — and not just for developers. But people who do knowledge work are especially prone to it, because of how mental blocks can severely impact their work.</p>



<p>So what causes those <a href="https://www.7pace.com/blog/high-performance-teams"><u>mental blocks</u></a>? Why do we all procrastinate so much? And more importantly, how can we stop procrastinating and just get our work done?</p>



<p>Don’t worry — you still have a few minutes of reading ahead of you before you have to go back to whatever task you’re avoiding. Read on and learn all about what causes procrastination, how to finally beat it, and how developers can use time tracking to up their efficiency even more.</p>



<h2>Why Do Developers Procrastinate?</h2>



<p>Developers aren’t more likely to procrastinate than other people. And when we look at the root causes of procrastination for developers, they’re the same reasons as anyone else.</p>



<p>Contrary to what many believe, procrastination isn’t necessarily the result of a lack of self-discipline. There are a <em>ton</em>&nbsp;of reasons developers (or anyone else) might procrastinate. Let’s look at a few common ones below.<em></em></p>



<h3>Perfectionism</h3>



<p>In knowledge work in particular, many people strive to be perfect. That goes for developers, too — they often strive to write the “perfect” code.</p>



<p>In reality, code that does what it’s supposed to do without bugs is plenty good enough. Striving for perfection has a tendency to make developers put off their work, since they’re trying to achieve an impossible goal.</p>



<h3>Fear of Success</h3>



<p>It may seem counter-intuitive, but fear of success has held back many a knowledge worker. With success comes higher expectations and greater responsibility, and not everyone responds well to that kind of pressure. In this case, procrastination can be a self-sabotaging tool.</p>



<h3>Lack of Planning</h3>



<p>Have you ever shown up to work, sat down at your desk, booted up your computer, and then sat there for a while trying to figure out what to work on? That lack of planning can be a major procrastination driver.</p>



<h3>Not Enough Work</h3>



<p>This is another counter-intuitive sounding reason for procrastination, but it’s real! Some developers procrastinate because they don’t have enough work to do.</p>



<p>When your workdays aren’t filled, it’s easy to get in the habit of coasting — hanging out at your desk surfing social media or reading online articles like this one. And once you’re in the habit, it’s hard to break it even when there <em>is</em>&nbsp;work to do. Hence, procrastination.</p>



<h3>Outdated Technologies</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/01-Image.jpg" alt="Outdated Technologies" srcset="https://www.7pace.com/wp-content/uploads/2021/02/01-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>Software development is a field that requires its workers to stay pretty close to the cutting edge of new technologies. So trying to work with old ones that are outdated, obsolete, or deprecated can be a real challenge for devs, leading them to put off work.</p>



<h3>Organizational Roadblocks</h3>



<p>As much as developers like to put their heads down and get their work done <a href="https://www.7pace.com/blog/best-places-to-work"><u>without red tape or administrative hurdles</u></a>&nbsp;getting in their way, that’s not how it works at <em>every</em>&nbsp;organization. If the company you work for places organizational roadblocks in your path, that may very well be a contributor to your procrastination habit.</p>



<h3>Unnecessary or “Busy” Work</h3>



<p>Feeling a sense of purpose and accomplishment is important for any worker, which is why it’s common for developers to procrastinate on work that doesn’t seem like it’s contributing to the greater good, like implementation of unnecessary features. The same goes for <a href="https://www.7pace.com/blog/time-tracking-optional-for-development-teams"><u>tedious or administrative tasks</u></a>&nbsp;—&nbsp;those are easy to put off as well.</p>



<h3>Work You Just Don’t Want to Do</h3>



<p>And finally, there’s work you just don’t want to do. Maybe it’s outside of your wheelhouse. Maybe it feels unnecessary. Maybe it’s too hard, or you’re stuck at a particular blocker. But for all workers, including developers, just not wanting to do a certain task, project, or type of work can easily lead to procrastination.</p>



<h2>How to Stop Procrastinating and Get Work Done</h2>



<p>Identifying the cause of your procrastination can help you determine what you need to do to move past it. But even if you’re not sure why you procrastinate, these tips can help break that habit and get you to get your work done.</p>



<h3>Take Baby Steps</h3>



<p>When you’re putting off a task, the hardest part can be just getting started. So instead of looking at the big picture of all you need to do, just take a small step in the right direction —&nbsp;like telling yourself you only need to work on a task or project for 30 minutes before you take a break to reassess. It can turn an impossible-seeming project into something more doable, and once you get started, it’ll be easier to keep moving.</p>



<h3>Make a Plan</h3>



<p>Remember how lack of planning is a common driver for procrastination? Combat that by going into every workday with a plan. Make it a habit before you leave each night to think about what you need to accomplish the following day, and make yourself a to-do list or a schedule —&nbsp;whatever works to keep you on track.</p>



<h3>Remove Distractions</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/02-Image.jpg" alt="Remove Distractions" srcset="https://www.7pace.com/wp-content/uploads/2021/02/02-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>Have you considered you might procrastinate simply because you’re too distracted to work effectively? Do what you can to cut down on things that might pull you away from your work. For example, you could find a quiet room to work in, or wear noise-canceling headphones. Block social media and other distracting websites from your work computer.</p>



<h3>Isolate Yourself</h3>



<p>If you work in an office with others, another cause for your procrastination might be that people need you for things. And while it’s great to be the go-to person in the office, it’s not ideal for <a href="https://www.7pace.com/blog/developer-productivity-tools"><u>productivity</u></a>.</p>



<p>If you struggle with being pulled away from work by your coworkers, isolate yourself away from others so you appear less available. If you’re not able to go work somewhere without others around, stick a sign to the back of your chair to let people know you’re in deep work mode and don’t want to be interrupted.</p>



<h3>Use a Technique Like Pomodoro</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/03-Image.jpg" alt="Use a Technique Like Pomodoro" srcset="https://www.7pace.com/wp-content/uploads/2021/02/03-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>The Pomodoro technique has become a common way for all kinds of people to beat their procrastination habits. It works by requiring you to deeply focus on work for a period of time (usually 25 minutes), and then take a short, mandated break (5 minutes or so). You repeat this cycle over and over throughout the workday, alternating focused work with short breaks.</p>



<h3>Take Breaks</h3>



<p>On that note, another possible reason for your procrastination is that you feel tired or worn out —&nbsp;and that can be more easily remedied than you might think. Many of us don’t take enough breaks at work, even though science shows that breaks are necessary and can greatly improve productivity and quality of work. If you’re feeling stuck on a task or project, take a short break and come back to it later.</p>



<h3>Switch Between Tasks</h3>



<p>The same goes for working on the same task for too long. It’s easy to get stuck when you have tunnel vision. So if you feel like you can’t move forward on a particular task, switch to something else for a while. You can always come back to the first task with fresh eyes later, without having wasted any time in the meantime.</p>



<h2>Want to Become Even More Efficient? Track Time with 7pace Timetracker</h2>



<p>Once you’ve beaten procrastination, you might be looking for ways to become even <em>more</em>&nbsp;productive at work.</p>



<p>The most productive teams are <a href="https://www.7pace.com/blog/automation-tools-for-devops"><u>autonomous ones</u></a>. And a major part of autonomy is a time tracking solution that isn’t made to help managers watch over your shoulder —&nbsp;but to integrate seamlessly with your work and provide you with data and insights that help you work smarter.</p>



<p><a href="https://www.7pace.com/"><u>7pace Timetracker</u></a>&nbsp;is the only time tracking solution designed to measure and track progress completely in the background, so you don’t have to waste one second of effort. And it provides valuable data about your time at work that can help you plan, execute, and measure every aspect of every project.</p>



<p><a href="https://www.7pace.com/timetracker"><u>Learn more about 7pace Timetracker</u></a>&nbsp;and why it’s the only time tracking solution for productive, autonomous teams.</p>
						</div></div>]]>
            </description>
            <link>https://www.7pace.com/blog/why-developers-procrastinate</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238435</guid>
            <pubDate>Tue, 23 Feb 2021 15:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Pretty JSON Revolution]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 145 (<a href="https://news.ycombinator.com/item?id=26237048">thread link</a>) | @peterohler
<br/>
February 23, 2021 | http://www.ohler.com/dev/pretty.html | <a href="https://web.archive.org/web/*/http://www.ohler.com/dev/pretty.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	  <table>
	    <tbody><tr>
	      <td colspan="2">
		<p>
		  Wouldn't it be nice if more JSON tools supported a truly
		  pretty JSON format? Demand options for truly pretty JSON
		  now! Viva la revolucion!
		</p>
		<p>
		  If only it were that easy. JSON format has become wildly
		  popular over the last decade easily passing XML as the
		  format of choice. For us humans JSON is much easier to read
		  than XML if the JSON is properly formatted. Sadly most tools
		  for viewing or formating JSON seem to be stuck on one of two
		  formats. One format is the single line format and the other
		  is a simple expanded format. There are other options though
		  with some tools.
		</p>
		<p>
		  One tool that offers more options is
		  the <span>oj</span> application
		  which is part of the
		  golang <a href="https://github.com/ohler55/ojg">OjG</a>
		  package. The <span>oj</span>
		  application will be used to illustrate the range of JSON
		  formats from the ugly up to the beauty of pretty
		  JSON. Follow along and try out your favorite JSON sample on
		  each step.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>One Line</p>
		<p>
		  The tight one line JSON format is used when trying to
		  minimize the size of a JSON document. It is the preferred
		  format for transmitting and storing JSON as it takes less
		  bandwidth and less disk space. For viewing, it is hard for
		  the eye to find elements of interests and difficult to
		  determine element boundaries. It has to be the ugliest of
		  all JSON formats.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 0 colors.json</span>
{"colors":[{"color":"black","hex":"#000","rgb":[0,0,0]},{"color"
:"red","hex":"#f00","rgb":[255,0,0]},{"color":"yellow","hex":"#f
f0","rgb":[255,255,0]},{"color":"green","hex":"#0f0","rgb":[0,25
5,0]},{"color":"cyan","hex":"#0ff","rgb":[0,255,255]},{"color":"
blue","hex":"#00f","rgb":[0,0,255]},{"color":"magenta","hex":"#f
0f","rgb":[255,0,255]},{"color":"white","hex":"#fff","rgb":[255,
255,255]}]}</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>One Line Per Node</p>
		<p>
		  What many packages refer to as pretty is an expanded format
		  where every element and each array and object start are on
		  separate lines. The core
		  golang <code>json.MarshalIndent()</code> function produces
		  an example of this format. The format takes up so much
		  vertical space the example on the right had to be cut off to
		  avoid filling up this article with just large amounts of
		  white space.
		</p>
		<p>
		  With the expanded (pretty?) format it is certainly easier to
		  determine element boundaries but you need a large screen or
		  to be good at scrolling to find what you are looking for. So
		  the expanded format is a step up from the one line format
		  which makes it a bit prettier but it is a weak effort that
		  is not without flaws.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 2 colors.json</span>
{
  "colors": [
    {
      "color": "black",
      "hex": "#000",
      "rgb": [
        0,
        0,
        0
      ]
    },
    {
      "hex": "#f00",
      "rgb": [
        255,
        0,
        0
      ],
      "color": "red"
    },
...
</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Sorted Object Keys</p>
		<p>
		  In many implementations JSON objects, whether implemented as
		  a golang map, Ruby Hash, Python dict, or what ever your
		  language of choice uses, the order of object elements is
		  random. That makes it more difficult to visually scan a set
		  of elements and pick out the same keyed element in each JSON
		  object. The brain is good at picking out visual or spacial
		  patterns but if the layout changes each each time there is
		  no pattern to pickup on. A visual scan has to be done,
		  looking at each key until the target is identified. JSON can
		  be made prettier by sorting the JSON object members by
		  element keys.
		</p>
		<p>
		  A sorted expanded format is a step up from just the expanded
		  format but it still suffers from taking up lot of vertical
		  space. If someone was writing the JSON by hand they would
		  probably not elect to expand the JSON to quite the level
		  that most packages or libraries do.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 2 -s colors.json</span>
{
  "colors": [
    {
      "color": "black",
      "hex": "#000",
      "rgb": [
        0,
        0,
        0
      ]
    },
    {
      "color": "red",
      "hex": "#f00",
      "rgb": [
        255,
        0,
        0
      ]
    },
...
</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style</p>
		<p>
		  The ideal pretty JSON pretty is to have the format look like
		  a human had typed it in. Well a pedantic human that didn't
		  make mistakes. Just like Goldilocks, the optimum middle
		  ground between a single line and a fully expanded format is
		  the goal. The
		  algorithm <span>oj</span> uses
		  considers a suggested edge to not exceed and a maximum
		  element depth allowed on a single line. Those two parameters
		  are specified as a float where the whole number part is the
		  edge and the fractional part or the number of 10ths is the
		  maximum depth on a single line. With those two parameters a
		  reasonable human style format can be achieved and the
		  results are looking rather pretty.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 colors.json</span>
{
  "colors": [
    {"color": "black", "hex": "#000", "rgb": [0, 0, 0]},
    {"color": "red", "hex": "#f00", "rgb": [255, 0, 0]},
    {"color": "yellow", "hex": "#ff0", "rgb": [255, 255, 0]},
    {"color": "green", "hex": "#0f0", "rgb": [0, 255, 0]},
    {"color": "cyan", "hex": "#0ff", "rgb": [0, 255, 255]},
    {"color": "blue", "hex": "#00f", "rgb": [0, 0, 255]},
    {"color": "magenta", "hex": "#f0f", "rgb": [255, 0, 255]},
    {"color": "white", "hex": "#fff", "rgb": [255, 255, 255]}
  ]
}</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style with Colors</p>
		<p>
		  With the human style formatting the JSON sample is very
		  readable but it can be made prettier. Well at least for
		  those of us than see in color. With the <code>-c</code>
		  option or the <code>-b</code> option the formatted JSON now
		  has colors. While colors do make the output prettier they
		  also make it easier for the eye to discern keys, string,
		  boolean, and numbers more easily. Try it, look at the
		  non-colored JSON and the colored and pick out your preferred
		  color name. Maybe not nirvana but compared to the first, one
		  line format, the colored pretty output is a completely
		  different level.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 -c colors.json</span>
<span>{</span>
  <span>"colors"</span><span>:</span> <span>[</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"black"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#000"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"red"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#f00"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"yellow"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#ff0"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"green"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#0f0"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>255</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"cyan"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#0ff"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"blue"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#00f"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"magenta"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#f0f"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"white"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#fff"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>}</span>
  <span>]</span>
<span>}</span></pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style with Colored in the SEN Format</p>
		<p>
		  Sorted human style with colors is about as good as it gets
		  but what if we deviate from strict JSON format and take a
		  few shortcuts that Javascript and GraphQL allow such as
		  unquoted strings and optional
		  commas. The <a href="https://github.com/ohler55/ojg/blob/develop/sen.md">SEN</a>
		  format is that
		  format. The <span>oj</span>
		  application supports parsing and encoding in SEN
		  format. It's not JSON but the conversion from SEN to JSON
		  and the reverse is lossless. Getting rid of the extra quotes
		  and unnecessary commas make the data easier to read and as a
		  side benefit the SEN format takes up less space so
		  transmission and disk space requirements are reduced when
		  compared to JSON.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 -c -sen colors.json</span>
<span>{</span>
  <span>colors</span><span>:</span> <span>[</span>
    <span>{</span><span>color</span><span>:</span> <span>black</span> <span>hex</span><span>:</span> <span>"#000"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>0</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>red</span> <span>hex</span><span>:</span> <span>"#f00"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>0</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>yellow</span> <span>hex</span><span>:</span> <span>"#ff0"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>255</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>green</span> <span>hex</span><span>:</span> <span>"#0f0"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>255</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>cyan</span> <span>hex</span><span>:</span> <span>"#0ff"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>255</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>blue</span> <span>hex</span><span>:</span> <span>"#00f"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>0</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>magenta</span> <span>hex</span><span>:</span> <span>"#f0f"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>0</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>white</span> <span>hex</span><span>:</span> <span>"#fff"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>255</span> <span>255</span><span>]</span><span>}</span>
  <span>]</span>
<span>}</span></pre>
	      </td>
	    </tr>
	    <tr>
	      <td colspan="2">
		<p>Continue the Fight</p>
		<p>
		  Beauty is in the eye of the beholder. My preference is the
		  pretty colored SEN format. You might have a different
		  preference but let's continue the revolution together and get
		  more pretty JSON out there. Use pretty JSON on web pages and
		  in email. For the tool builders out there, offer the
		  option for pretty JSON.
		</p>
		<p>
		  Note: In case you are wondering if the colored JSON HTML was
		  written or colorized by hand, it was
		  not. The <code>-html</code> option
		  of <span>oj</span> was used to
		  produce the colorized HTML for this article. It's a handy
		  option when including JSON on web pages or in email.
		</p>
	      </td>
	    </tr>
	  </tbody></table>
	</div>
      </div></div>]]>
            </description>
            <link>http://www.ohler.com/dev/pretty.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26237048</guid>
            <pubDate>Tue, 23 Feb 2021 13:37:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You need to be able to run your system]]>
            </title>
            <description>
<![CDATA[
Score 279 | Comments 148 (<a href="https://news.ycombinator.com/item?id=26236908">thread link</a>) | @catern
<br/>
February 23, 2021 | http://catern.com/run.html | <a href="https://web.archive.org/web/*/http://catern.com/run.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
When developing a system,
it is important to be able to run the system in its entirety.
<p>
"Run the unit tests" doesn't count.
The complexity of your system is in the interactions between the units.
</p><p>
"Run an individual service against mocks" doesn't count.
A mock will rarely behave identically to the real dependency,
and the behavior of the individual service will be unrealistic.
You need to run the actual system.
</p><p>
"Run an individual service in a shared stateful development environment running all the other services" doesn't count.
A shared development environment will be unreliable as it diverges more and more from the real system.
</p><p>
"Run most services in a mostly-isolated development environment,
calling out to a few hard-to-run external services" doesn't count.
Those few external services on the edge of the mostly-isolated development environment are often the most crucial ones;
without the ability to run modified versions of them, your development process is crippled.
Furthermore, being dependent on external services greatly complicates where and how you can run the system;
it's much harder to, for example, run tests with the system on every commit if that will access external services.
</p><p>
"Run all the services that make up the system in an isolated development environment" counts;
it's the bare minimum requirement.
Bonus points if this can be done completely on localhost,
without using an off-host cluster deployment system.
</p><p>
Without the ability to actually run the entire system in this way while developing,
many evil practices will tend to become common.
</p><ul>
  <li>
    Testing is harder and far less representative,
    and therefore many issues can only be found when changes are deployed to production.
  </li><li>
    In turn, production deployment will cause issues more often,
    and so deployment will be more slow and less frequent.
  </li><li>
    Deploying the system to new environments is more difficult,
    since the developers aren't able to actually run the system.
    Existing practices in production will be cargo-culted and copied around indefinitely,
    even when they are unnecessary or actively harmful.
  </li><li>
    Exploratory usage of the system is very difficult,
    so it will be harder to consider using the system for purposes outside what it was originally developed for,
    and new use cases will become rare.
  </li><li>
    Downstream clients who depend on the system will also suffer all these issues,
    since without the ability to run the upstream system in development,
    they can't run their own entire system, which is a superset of the upstream system.
</li></ul>
Running the entire system during development is the first step to preventing these issues.
Further steps include writing automated tests for the system (which can be run repeatedly during development),
and using, as much as possible, the same code to run the system in development and in production.
<p>
Developers of large or legacy systems that cannot already be run in their entirety during development
often believe that it is impractical to run the entire system during development.
They'll talk about the many dependencies of their system,
how it requires careful configuration of a large number of hosts,
or how it's too complex to get reliable behavior.
</p><p>
In my experience, they're always wrong.
These systems can be run locally during development with a relatively small investment of effort.
Typically, these systems are just ultimately not as complicated as people think they are;
once the system's dependencies are actually known and understood rather than being cargo-culted or assumed,
running the system, and all its dependencies, is straightforward.
</p><p>
Being able to run your entire system during development is just about the most basic requirement for a software project.
It's not, on its own, sufficient for your development practices to be high quality;
but if you can't do this, then you're not even in the running.
</p></div>]]>
            </description>
            <link>http://catern.com/run.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236908</guid>
            <pubDate>Tue, 23 Feb 2021 13:20:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most thoroughly commented linker script (probably)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26236726">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://blog.thea.codes/the-most-thoroughly-commented-linker-script/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>While developing the firmware for Winterbloom's <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux">Castor &amp; Pollux</a>, I got very curious as to just what the Microchip/Atmel-provided linker script was doing.</p>
<p>If you've never heard of or seen a linker script before you're not alone. Most of us never even have to think about them, however, on memory constained embedded devices it's not uncommon to need to modify the default linker script.</p>
<p>The linker script controls how <code>ld</code> combines all of your <code>.o</code> files into a single <code>.elf</code> and how that resulting <code>.elf</code> file gets loaded by the target processor.</p>
<p>So I was staring at this script that made absolutely no sense to me. It's filled with incantations and mysterious symbols and there's no indication of what they're for or where they come from.</p>
<p>So I did a <strong>lot</strong> of research and now I can present to you <strong>the most thoroughly commented linker script</strong><sup id="fnref:probably"><a href="#fn:probably">1</a></sup>.</p>
<p>You can see this script in its entirety, comments and all, on <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/blob/master/firmware/scripts/samd21g18a.ld">GitHub</a>. But if you'd like to read it here instead it's transcribed below.</p>
<h2 id="output-format">Output format</h2>
<p>Output format sets the ELF output format to use a specific BFD backend.</p>
<p>The first is the default BFD. The second and third arguments are used
when big (-EB) or little (-EL) endian is requested.</p>
<p>Since the SAM D series are configured with only little endian support,
"elf32-littlearm" is used across the board. This option seems to be
included by Atmel/Microchip out of an abundance of caution, as
arm-none-eabi-ld will do the right thing and use "elf32-littlearm" by
default.</p>
<p>The list of acceptable values can be obtained using <code>objdump -i</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands">https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands</a></li>
<li><a href="https://sourceware.org/binutils/docs/ld/BFD.html">https://sourceware.org/binutils/docs/ld/BFD.html</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 11.1.11, Cortex M0+ Configuration</li>
</ul>
<pre><span>OUTPUT_FORMAT</span><span>(</span><span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>)</span>
</pre>
<h2 id="cpu-memory-configuration-variables">CPU memory configuration variables</h2>
<p>These variables are used by the following "MEMORY" command to define
the various memory spaces.</p>
<p>For the SAMD21G18A used by this project, the available Flash is
262kB and the available SRAM is 32kB.</p>
<p>This project also reserves 8kB for the bootloader and 1kB for
"non-volatile memory" (NVM) - which is used by the application
to store calibration and user settings.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>FLASH_SIZE</span> <span>=</span> <span>0x40000</span><span>;</span>      <span>/* 256kB */</span>
<span>BOOTLOADER_SIZE</span> <span>=</span> <span>0x2000</span><span>;</span>  <span>/* 8kB */</span>
<span>NVM_SIZE</span> <span>=</span> <span>0x400</span><span>;</span>          <span>/* 1kbB */</span>
<span>SRAM_SIZE</span> <span>=</span> <span>0x8000</span><span>;</span>        <span>/* 32kB */</span>
</pre>
<p>ARM Cortex-M processors use a descending stack and generally
require stack space to be set aside in RAM.</p>
<p>The application's behavior determines just how much stack space
should be reserved. I generally start with 2kB (0x800) of
stack space for Cortex-M0+ projects programmed in C .</p>
<p>You can analyze stack usage in GCC using the <code>-fstack-usage</code>
flag and you can enable compiler warnings for stack usage
with <code>-Wstack-usage=STACK_SIZE</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/">https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/</a></li>
<li><a href="https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications">https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html">https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html</a></li>
</ul>
<pre><span>STACK_SIZE</span> <span>=</span> <span>DEFINED</span><span>(</span><span>__stack_size__</span><span>)</span> <span>?</span> <span>__stack_size__</span> <span>:</span> <span>0x800</span><span>;</span>
</pre>
<h2 id="memory-space-definition">Memory space definition</h2>
<p>This section declare blocks of memories for specific purposes. Since an
ARM's address space is generally split between Flash, SRAM, peripherals,
and other regions, it's necessary to tell the linker where different
types of data can go in the address space.</p>
<p>These blocks will be used in the <code>SECTIONS</code> command below.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY">https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>MEMORY</span>
<span>{</span>
</pre>
<p>Start with the Flash memory region. On the SAMD21, Flash starts at
the beginning of the address space (<code>0x00000000</code>) and is contiguous
right up to the size of the Flash. Flash is marked a <code>rx</code> so
that the linker knows that this space is read-only (<code>r</code>) and
executable (<code>x</code>).</p>
<p>The "bootloader" section allows this firmware to work with the uf2
bootloader. The bootloader takes the first 0x2000 bytes of flash
memory.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/adafruit/uf2-samdx1#configuration">https://github.com/adafruit/uf2-samdx1#configuration</a></li>
</ul>
<pre>    <span>bootloader</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>BOOTLOADER_SIZE</span>
</pre>
<p>Following the bootloader is the flash memory used by the application,
called "rom" here - even though it's flash, the name is just a name
and doesn't carry special meaning.</p>
<p>The total length of the rom block is the MCU's flash size minus the
bootloader's size and any space reserved for "non-volatile memory"
by the application.</p>
<pre>   <span>rom</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00002000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>BOOTLOADER_SIZE</span> <span>-</span> <span>NVM_SIZE</span>
</pre>
<p>The "nvm" block is space set aside for the application to store
user settings and calibration data in the MCU's flash.</p>
<p>The block is located right at the end of the flash space. This
is useful because it means that it says in a fixed location
regardless of how much flash space the application takes up
in "rom". Explicitly defining this section also lets the
linker ensure that application code doesn't overwrite the
data in this region.</p>
<p>This block is marked as read-only (<code>r</code>) because flash can not
be written in the same way as normal memory, however, the
application can use the SAMD's NVM peripheral to write data in
this region.</p>
<pre>   <span>nvm</span> <span>(</span><span>r</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>NVM_SIZE</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>NVM_SIZE</span>
</pre>
<p>The "ram" block is mapped to the CPU's SRAM and it's where
the stack, heap, and all variables will go.</p>
<p>For the SAMD21, SRAM starts at 0x20000000 and is contiguous
for the size of the SRAM.</p>
<pre>   <span>ram</span> <span>(</span><span>rwx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x20000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>SRAM_SIZE</span>
<span>}</span>
</pre>
<h2 id="sections">Sections</h2>
<p>The sections command tells the linker how to combine the
input files into an output ELF and where segments belong
in memory.</p>
<p>The linker takes a set of input files containing the "input
sections" and uses this to map them to "output sections"
which are placed in the output ELF file.</p>
<p>While the most important sections to think about here
are the ones that'll be placed into the memory (segments)
some sections are just placed in the output ELF for debugging.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS">https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS</a></li>
</ul>
<pre><span>SECTIONS</span>
<span>{</span>
</pre>
<p>The text segment contains program code and read-only data.</p>
<p>References:</p>
<ul>
<li><a href="https://developer.arm.com/documentation/dui0101/a/">https://developer.arm.com/documentation/dui0101/a/</a>
Page 5, Segments</li>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
</ul>
<pre>   <span>.</span><span>text</span> <span>:</span>
   <span>{</span>
</pre>
<p>This segment must be 4-byte aligned as defined in ARM ELF
File Format specification.</p>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
</pre>
<p>The vector table defines the initial stack pointer and
interrupt/exception routines for the ARM CPU and device
peripherals. Every Cortex-M project needs this.</p>
<p>For the SAM D series the vector table is expected
to be at address 0x00000000 after reset. Since
flash memory starts at 0x00000000, the first values
in flash should be the vector table.</p>
<p>When defining the vector table in code you must use
<code>__attribute__ ((section(".vectors")))</code> to tell
GCC to place the vector table into the section
named ".vectors" in the input object file so that
the linker can find it.</p>
<p>Note that since this project uses the UF2 bootloader,
this actually gets placed at the beginning of the
program's flash area (0x2000). The Cortex-M allows
changing the vector table after initialization,
so the startup script sets the Vector Table Offset
Register (<code>SCB-&gt;VTOR</code>) to <code>_sfixed</code> during its
intialization. The <code>_efixed</code> symbol is unused but
included for completeness.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
Secion 8.3.3, Fetching of Initial Instructions</li>
<li><a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf</a>
Section B1.5.3, The vector table
Section B3.2.5, Vector Table Offset Register, VTOR</li>
<li><a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/tree/master/firmware/third_party/samd21/gcc/gcc/startup_samd21.c">startup_samd21.c</a></li>
</ul>
<pre>      <span>_sfixed</span> <span>=</span> <span>.;</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>vectors</span> <span>.</span><span>vectors</span><span>.</span><span>*</span><span>))</span>
</pre>
<p>Include code and read-only data sections from all
input files.</p>
<p>By default, GCC places all program code into a section named
".text" and read-only data (such as const static variables) into
a section named ".rodata" in the input object files. This naming
convention is from the ELF ABI specification.</p>
<p>GCC generates three "flavors" of sections in object files:</p>
<ul>
<li><code>.{section}</code>: the basic section.</li>
<li><code>.{section}.*</code>: sections generated by <code>-ffunction-sections</code> and
<code>-fdata-sections</code> so that each function/data has a unique
section.</li>
<li><code>.gnu.linkonce.{type}.*</code>: sections generated by GCC so the
linker can remove duplicates. Seems to be related to
Vague Linking.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html">https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html</a></li>
<li><a href="https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section">https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section</a></li>
</ul>
<pre>      <span>*</span><span>(.</span><span>text</span> <span>.</span><span>text</span><span>.</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>t</span><span>.</span><span>*</span><span>)</span>
      <span>*</span><span>(.</span><span>rodata</span> <span>.</span><span>rodata</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>r</span><span>.</span><span>*</span><span>)</span>
</pre>
<h2 id="c-c-runtime-support">C &amp; C++ runtime support</h2>
<p>The following sections are for the C/C++ runtime. These are generally used by crt0.</p>
<p>References:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Crt0">https://en.wikipedia.org/wiki/Crt0</a></li>
</ul>
<h3 id="initializers">Initializers</h3>
<ul>
<li>C++ Runtime: initializers for static variables.</li>
<li>C Runtime: designated constructors</li>
</ul>
<p>For C++, handles variables at file scope like this:</p>
<pre><span>int</span> <span>f</span> <span>=</span> <span>some_func</span><span>()</span>
</pre>
<p>For C, handles functions designated as constructors:</p>
<pre><code>void intialize_thing(void) __attribute__((constructor));
</code></pre>
<p>Executed by the C runtime at startup via <code>__libc_init_array</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c">https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c</a></li>
<li><a href="https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c">https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c</a>;</li>
<li><a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">https://gcc.gnu.org/onlinedocs/gccint/Initialization.html</a></li>
<li><a href="https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction">https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction</a></li>
<li><a href="https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array">https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array</a></li>
</ul>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>init</span><span>))</span>
      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
  …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236726</guid>
            <pubDate>Tue, 23 Feb 2021 12:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to Programming with ECMA-55 Minimal BASIC [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236686">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://buraphakit.sourceforge.io/Learn_BASIC.pdf | <a href="https://web.archive.org/web/*/https://buraphakit.sourceforge.io/Learn_BASIC.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://buraphakit.sourceforge.io/Learn_BASIC.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236686</guid>
            <pubDate>Tue, 23 Feb 2021 12:49:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore History Part 1: The Commodore Pet]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 23 (<a href="https://news.ycombinator.com/item?id=26236320">thread link</a>) | @SQL2219
<br/>
February 23, 2021 | http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/ | <a href="https://web.archive.org/web/*/http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4839">
														
							
														
							
														
							<div>
															<div>
									<p>When you watch documentaries about early computer innovations, particularly the late 70s, early 1980s, most of the documentaries tend to focus on Apple and Microsoft, and maybe IBM as the big innovators. But, I think often companies like Commodore, and Atari, and Tandy don’t get nearly enough credit for the role that they played.&nbsp; Let’s take a look at the Commodore PET!</p>
<p>Most of my readers are familiar with the Commodore 64, one of the best selling computers of all time. Well renowned for its great graphics and sound, but Commodore history didn’t start with this machine. So, let’s go back a little bit to the late 1970s and figure out where it all started!</p>
<h2>Commodore History Part 1 Video</h2>
<p><iframe src="https://www.youtube.com/embed/eP9y_7it3ZM" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h2>The Processor that Started it All</h2>
<p>It all began in 1974 when Chuck Peddle and a group of engineers started up a chip fabrication company called MOS Technology. Most of these guys had worked at Motorola on the 6800 processor, and so they set out to develop a compatible CPU known as the 6501 that could simply be substituted for the much more expensive Motorola CPU. As you might imagine, Motorola sued and to make a long story short, the 6502 was born, which was pretty much the same chip but changed just enough that it was no longer completely compatible with the 6800.</p>
<p><a href="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png"><img data-attachment-id="4855" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0002-the-6502-was-born/" data-orig-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0002 – The 6502 was born" data-image-description="" data-medium-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=300%2C169" data-large-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=1024%2C576" loading="lazy" src="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=750%2C422" alt="The 6502 Processor" width="750" height="422" srcset="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=1024%2C576 1024w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=300%2C169 300w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=768%2C432 768w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=600%2C338 600w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>Since the chip was no longer compatible with the 6800, customers would need some way to test the chip. In 1976 Chuck Peddle also designed the KIM-1 development computer. This was a single board computer that used the 6502, and could be programmed in machine language from the keypad on the top. However, later it was possible to connect a dumb-terminal display and actually run BASIC. Programs could be saved to a cassette tape. The computer proved to be popular with hobbyists as well as engineers.</p>
<p>The 6502 would go on to be a huge success and eventually found its way into the Apple II series, the Atari 2600, the Nintendo Entertainment System, the entire line of Atari 8-Bit computers, the BBC Micro, and of course the entire line of Commodore 8-Bit machines. But back to 1976 for the moment. MOS Technologies was bought up by Commodore Business Machines, who at this point was primarily in the calculator business. Chuck Peddle managed to convince Commodore boss Jack Tramiel that calculators were a dead-end business and that they needed to produce a computer to compete with the upcoming Apple II.</p>
<h2>The MOS Technology KIM-1</h2>
<p>In 1977 the Commodore PET 2001 was born, using much of the same design as the KIM-1. Much like the Apple II, the PET was all inclusive, having an integrated monitor, keyboard, and cassette tape storage device. 1977 was a big year for the personal computer revolution. With the market introduction of the big 3, the Apple II, Commodore PET, and TRS-80 computer, it was the first time that a regular person could buy an affordable computer without having to assemble it themselves.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png"><img data-attachment-id="4856" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0003-the-kim-1/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0003 – The KIM 1" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=750%2C422" alt="" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>The cool thing about the PET is that it was actually designed by the same guy who designed the 6502 processor. If you look at the prices of the big 3, you’ll see the PET was competitively priced. Although the Apple II did have superior hardware, which we’ll get into shortly, the PET did have the advantage that it came with a monitor and tape drive, where the Apple II required those as separate purchases.</p>
<h2>A Closer Look at the PET</h2>
<p>Let’s take a closer look at the design of the Commodore PET. The first thing I want to draw your attention to is the keyboard. It’s insane, and it will drive you insane if you actually try to type on it. One thing that isn’t communicated well by video and pictures is just how small this keyboard is. The main part, excluding the number pad measures just 6in. by 2.75in. Just to put that into perspective, my iPhone 6 will essentially cover the entire keyboard. The Apple mini keyboard is actually huge by comparison.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png"><img data-attachment-id="4857" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0004-the-pet-keyboard/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0004 – The PET Keyboard" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=750%2C422" alt="the pet keyboard" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>The keyboard size isn’t the only problem. They layout is crazy. While the keys are technically in a QWERTY arrangement, normally the rows are offset creating diagonal lines. Not so on the PET. They are squared up. The weirdness doesn’t end there. The space bar is tiny! Normally you would expect numbers across the top row of keys, but there aren’t any. Instead you have just symbols. If you want to type a number, you have to use the number pad.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png"><img data-attachment-id="4859" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0005-the-pet-keyboard-will-drive-you-insane/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0005 – The PET Keyboard will drive you insane" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=750%2C422" alt="PET keyboard is insane" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>What is even more infuriating is the symbols. For example, if I want to type a Dollar sign or a number sign, I would instinctively press shift before the key. However, when I do that I wind up with a totally different character instead of the one I wanted. Then there’s the cursor keys. Notice that there are only 2 of them. One key cursors down, and the other key cursors right. If you want to reverse that, you have to hold down the shift key. So by using the combination of the cursor keys and shift you can cursor anywhere on the screen.&nbsp; The little back arrow? You might think that’s a backspace key. But, it’s not. It actually prints that character on the screen, and so when you make a mistake, and believe me you will, you’re going to go to push this key and it’s not going to fix your mistake and you’re going to go even more insane than you were before. The actual delete key is all the way over at the other side of the number pad.</p>
<p>To be fair, when this computer came out in 1977, most of the customers had never even used a personal computer before or a computer of any kind and so they didn’t have any pre-conceptions for what a keyboard layout should be – like we do today. It probably wasn’t quite as weird for them as it would be for us.</p>
<h2>Opening the Commodore PET</h2>
<p>Let’s take a look inside the PET, it opens like the cab of a semi truck, and even gives you a little kick stand to hold it open. Looking at these 16 RAM chips, you might think the PET came with a lot of RAM. But, you’d be wrong. The original PET only came with 4K of RAM. These are 1K by 4-bit static RAM chips. Being that cost was such a consideration for this computer, you might be wondering why they didn’t use the cheaper dynamic RAM, or DRAM? Well, static ram was and still is today much more expensive than dynamic RAM. However, DRAM has one drawback, it requires that it is refreshed every so often, which requires additional circuitry to handle that. When you’re dealing with only 4K, it actually ended up being cheaper just to use static RAM.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png"><img data-attachment-id="4860" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0006-opening-the-pet/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0006 – Opening the PET" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=750%2C422" alt="opening the PET" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>OK. So 4K is a ridiculously small amount or RAM, but it’s worse than that because the operating system actually needs at least 1K of that, leaving about 3K left over for the user. So how much is 3K of RAM? Well, the screen on the pet is 40-characters by 25-lines, meaning you need 1,000 bytes of RAM, or almost an entire kilobyte just to store one screen full of text. Essentially you had enough RAM for about 3 screens of text! To be fair though, the Apple II and TRS-80 only had 4K when they came out as well.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png"><img data-attachment-id="4861" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0007-the-pet-ram-chips/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0007 – The PET RAM chips" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=750%2C422" alt="PET RAM chips" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>This particular PET has been upgraded a little daughter board. It’s an aftermarket 32K RAM expansion module, and that’s why it shows 31K available to BASIC on the boot screen. Let’s take a closer look at this cassette drive. This was actually just an off-the-shelf cassette recorder that Commodore bought and slightly modified. You can see the whole unit is actually mounted, in a rather clunky way in my opinion. The cassette drive was really the only storage device available for the PET at first. And with 4K of RAM, this wasn’t much of a problem.</p>
<h2>The PET Disk Drives</h2>
<p>It wasn’t until 1979 that Commodore came out with a matching disk drive. Since the PET was never really designed to use a disk drive, they decided to use the IEEE-488 parallel port as a means to connect the disk drive.&nbsp; Unlike the Apple II, the Commodore PET has no card slots inside so there’s nowhere to add a floppy disk controller card. So, what they had to do was essentially design an entire computer inside the floppy drive unit, which would handle controlling the floppy drives as well as an entire disk operating system.</p>
<p><a href="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png"><img data-attachment-id="4862" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0001-the-pet-8050-disk-drive/" data-orig-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0001 – The PET 8050 Disk Drive" data-image-description="" data-medium-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=300%2C169" data-large-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=1024%2C576" loading="lazy" src="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=750%2C422" alt="" width="750" height="422" srcset="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=1024%2C576 1024w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=300%2C169 300w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=768%2C432 768w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=600%2C338 600w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>Indeed if you take a look inside the disk drive, you’ll see it’s quite sophisticated, having it’s own 6502 processor, RAM, ROM, and I/O controllers. The PET didn’t really interact with information on the disks directly, rather it would send commands to the disk drive, such as telling it to fetch a file, and then the disk drive would take care of all of the work of finding the right data on the disk. In fact, it could even copy files or even entire disks from one drive to the other all by itself, just with a single command.</p>
<p>The PET was popular with schools and found its way into many computer labs. And while the disk drive was expensive, one of these floppy drive units could actually be connected to multiple PETs at the same time, thus saving space and money. In fact, you can see this arrangement being used in this photo from a computer lab where each table has 8 PETs connected to a single floppy drive and printer.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png"><img data-attachment-id="4863" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0010-the-pet-8080-disk-drive-chained/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0010 – The PET 8080 Disk Drive chained" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=750%2C422" alt="chained PETs to disk drives" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<h2>The Commodore PET’s Display</h2>
<p>Let’s talk about the screen on the PET. The original model here is black and white. A lot of people assume it’s green, but that actually wasn’t until later models. The original one was black and white. In fact, there’s not even any grayscale. It’s just literally two colors, black and white. The screen was controlled by a clone of the Motorola 6845 CRT controller, which was also used in the IBM CGA card, among other computers. However, there was no circuitry here for color.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png"><img data-attachment-id="4883" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0025-the-commodore-pet-black-and-white-display/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0025 – The Commodore PET Black and White Display" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=750%2C422" alt="Commodore PET Display" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>There are also no graphics modes. I mean, literally <em>none</em>. There is no way to put graphics on this machine at all. And what’s worse is that the character set is in ROM and it cannot be moved, so there’s no way to modify what the characters look like. So, you are pretty much stuck with putting characters on the screen and only the characters that came built into ROM. And that’s it.</p>
<h2>PETSCII</h2>
<p>However, there are 256 characters using a special character set called PETASCII or later just shortened to PETSCII. The character …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/">http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/</a></em></p>]]>
            </description>
            <link>http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236320</guid>
            <pubDate>Tue, 23 Feb 2021 12:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saving the World with Bayesian Modeling]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26235876">thread link</a>) | @twiecki
<br/>
February 23, 2021 | https://www.pymc-labs.io/blog-posts/saving-the-world/ | <a href="https://web.archive.org/web/*/https://www.pymc-labs.io/blog-posts/saving-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

    <div>
        <div>
            <div>
                
                <div>
                    
                        <h4>Saving the world with Bayesian modeling</h4>
                    
                    <p>After I left Quantopian in 2020, something interesting happened: various companies contacted me inquiring about
consulting to help them with their PyMC3 models.</p>
<p>Usually, I don't hear how people are using <a href="https://docs.pymc.io/">PyMC3</a> -- they mostly show up on
<a href="https://github.com/pymc-devs/pymc3">GitHub</a> or <a href="https://discourse.pymc.io/">Discourse</a> when something isn't working
right. So, hearing about all these really cool projects was quite exciting. However, I couldn't possibly take all of
these projects on by myself.</p>
<p>Thus, it was time to assemble a team of the most badass Bayesian modelers the world had ever seen -- the Bayesian
Avengers, if you will. Fortunately, I did not have to venture far, as PyMC3 had already attracted exactly these types
of people.</p>
<p>This brings me to the Big Announcement: For the last few months, we have quietly been building
<a href="https://pymc-labs.io/">PyMC Labs</a>, a Bayesian modeling consultancy.
<a href="https://www.pymc-labs.io/team/">We have an amazing team</a> consisting of three neuroscience PhDs, mathematicians,
social scientists, a SpaceX rocket scientist, and the host of the famous
<a href="https://www.learnbayesstats.com/">‘Learning Bayesian Statistics’ podcast</a>. All of us are united in our mission:</p>
<blockquote>
    <p>Saving the world with Bayesian modeling</p>
    
</blockquote><p>Does this sound a bit grandiose? Probably. Is this true? I firmly believe it is. There are so many important problems
the world faces today -- from climate change to COVID19, from education to poverty -- and Bayesian modeling can play a
critical role in solving these problems. Let me explain why.</p>
<h2 id="it-is-already-doing-it">It is already doing it</h2><p>I would not have imagined it when I started contributing to PyMC, but the science PyMC3 has directly enabled ranges
from <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=pymc3+climate&amp;btnG=">climate science</a> and biology to
astronomy and zoology, and everything in between.</p>
<p>For instance, it was used to predict the spread of COVID19 in a recent
<a href="https://science.sciencemag.org/content/369/6500/eabb9789.full">Science paper</a>,
as well as <a href="https://rtlive.de/global.html">track the reproduction factor in real-time</a>.
In both cases, the benefit of PyMC3 was its ease-of-use and the ability to integrate scientific domain knowledge and
get honest uncertainty estimation in a highly volatile and uncertain situation.</p>
<p>Now I know you’re very observant and I hear you thinking: “wait a minute, those benefits of Bayesian modeling sound
quite general, so why would they be only valid for epidemiology?”. And indeed they aren’t! For similar benefits,
PyMC3 is also used to <a href="https://github.com/exoplanet-dev/exoplanet">find planets outside of our solar system</a>
and <a href="https://github.com/hvasbath/beat">detect earthquakes</a>. One of my coworkers here at PyMC Labs uses it for
<a href="https://share.streamlit.io/alexandorra/pollsposition_website/main/gp-popularity-app.py">electoral and political forecasting</a>,
because polls are noisy, scarce and need to be completed by domain knowledge -- one of the perfect settings for
Bayesian inference!</p>
<p>With all of this, at the time of writing, the <a href="https://peerj.com/articles/cs-55/">PyMC3 paper</a> has been cited over 930
times and is in the top 10 most cited articles of the entire PeerJ journal.</p>
<h2 id="solving-business-problems">Solving Business Problems</h2><p>Beyond scientific research, I find that PyMC3 is the perfect tool to also solve various business problems.
And indeed it’s already successfully used in production at companies as big and diverse as SpaceX, Roche,
Netflix, Deliveroo and HelloFresh.</p>
<p>This diversity means that the <a href="https://www.pymc-labs.io/clients/">PyMC Labs team intervenes</a> to, for instance,
<a href="https://support.everysk.com/hc/en-us/articles/1500001040721-Private-Investments">build complex models from the latest finance research</a>;
optimize supply chains for food delivery; build software from top to bottom for pharmaceutical applications;
speed up and extend models for the farm tech industry; train and enhance any data science team’s Bayesian stats
capacities, etc.</p>
<h2 id="prediction-vs-inference">Prediction Vs Inference</h2><p>As data science has exploded in the last decade I have always been surprised by the over-emphasis on prediction-focused
machine learning. For far too long, it has been hailed as the solution to most of our data science problems.</p>
<p>I believe that the potential of this is way overblown. Not because it doesn't work -- algorithms like deep nets or
random forests are extremely powerful at extracting non-linear predictive patterns from large data sets -- but rather
because most data science problems are not simple <em>prediction</em> but rather <em>inference</em> problems.</p>
<p>In addition, we often already have a lot of knowledge about our problem: knowledge of certain structure in our data
set (like nested data, that some variables relate to some but not other parameters) and knowledge of which range of
values we expect certain parameters of our model to fall into. Prediction-focused ML does not allow us to include any
of this information, that's why it requires so much data.</p>
<p>With Bayesian statistics, we don't have to learn everything from data as we translate this knowledge into a custom model.
Thus, rather than changing our problem to fit the solution, as is common with ML, we can tailor the solution to best
solve the problem at hand. I like to compare this with Playmobil vs Lego:</p>
<p><img src="https://www.pymc-labs.io/blog-posts/saving-the-world/playlego.jpeg" alt=""></p>
<p>Playmobil just gives you a single toy you can't change while Lego (i.e Bayes here) gives you building blocks to build
the toy you actually want. In Bayesian modeling, these building blocks are probability distributions.</p>
<p>But how do you do this in practice? This is where PyMC3 comes in, as it allows you to specify your models as Python
code and automatically estimate it without requiring manual mathematical derivations. Due to recent theoretical and
technological advances, this also runs quickly and scales to complex models on large(ish) data sets.</p>
<h2 id="serving-our-mission">Serving our mission</h2><p>So how do we best make progress on our mission?</p>
<p>First, we will continue to make PyMC3 the best, most user-friendly and scalable Bayesian modeling package out there.
We are well set up to do this, having a friendly API, a huge user-base, and a large developer team of over 20 active
members. With our renewed focus on
<a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b">PyMC3 on Theano with a JAX backend</a>
all our resources will go towards this goal.</p>
<p>Second, our new PyMC consultancy will support this endeavour. It allows us to directly help clients use these powerful,
customizable methods to solve their business problems, thereby increasing adoption and recognition.
As a great side effect, these client projects also help us find things that need to be fixed, improved or optimized
in PyMC3, thereby lifting all (Bayesian) boats instead of just the happy fews’.</p>
<p>So far, this has been an incredibly rewarding and exhilarating journey. Even though it is still early, we are learning
a lot about which areas Bayesian modeling is particularly well suited for but also what would make PyMC3 even better.
Without spoiling a future blog post that will go into more detail about what we have learned applying these methods,
the best use-cases include (but aren’t limited to) <strong>incorporating domain knowledge, building bespoke models and
quantifying uncertainty around estimates</strong>.</p>
<p><em>Sounds familiar? If you or your company has a problem for which prediction-based ML is not a good fit, I'd love to talk
to you at <a href="mailto:thomas.wiecki@pymc-labs.io">thomas.wiecki@pymc-labs.io</a>. This is just the beginning and
I hope you will join us on this marvelous journey.</em></p>

                </div>
            </div>
        </div>
    </div>


        </div></div>]]>
            </description>
            <link>https://www.pymc-labs.io/blog-posts/saving-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235876</guid>
            <pubDate>Tue, 23 Feb 2021 10:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Bitcoin Is Indistinguishable from Malevolent AI]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235428">thread link</a>) | @rwosync
<br/>
February 23, 2021 | https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e | <a href="https://web.archive.org/web/*/https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="f30c">Who needs Skynet to destroy the human world? Just throw techbros some coin</h2><div><div><div><div><a rel="noopener" href="https://indi.ca/?source=post_page-----84e9cd5f58e--------------------------------"><div><p><img alt="indi.ca" src="https://miro.medium.com/fit/c/56/56/2*VgOFOCrcL5LsGSciDktenw.jpeg" width="28" height="28"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4630/1*By1s-xE22gz0qpw6QA71bA.png" width="2315" height="2315" srcset="https://miro.medium.com/max/552/1*By1s-xE22gz0qpw6QA71bA.png 276w, https://miro.medium.com/max/1104/1*By1s-xE22gz0qpw6QA71bA.png 552w, https://miro.medium.com/max/1280/1*By1s-xE22gz0qpw6QA71bA.png 640w, https://miro.medium.com/max/1400/1*By1s-xE22gz0qpw6QA71bA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*By1s-xE22gz0qpw6QA71bA.png?q=20"></p></div></div></div><figcaption>Bitcoin is the final avatar of capitalism. An ouroboros. A snake eating its own tail.</figcaption></figure><p id="8831"><span>B</span>itcoin now consumes <a href="https://cbeci.org/cbeci/methodology" rel="noopener">as much energy as Argentina</a> (45 million people), and more than most countries in the world. Bitcoin consumes more energy than Amazon, Apple, Google, Microsoft, and Facebook <a href="https://www.ft.com/content/0c69d4a4-2626-418d-813c-7337b8d5110d" rel="noopener"><strong>combined</strong></a>. Within 12 years Bitcoin has become one of the fastest-growing sources of climate change in the world.</p><p id="6a6e">As an inadequate summary, Bitcoin is ‘mined’ by <a href="https://twitter.com/AthoughtHeist/status/1363391630414381058" rel="noopener">solv<span id="rmm">i</span>ng purposefully hard ‘Sudoku’ puzzles</a> (making them rare) which you could exchange for heroin. No one does anymore because it’s become an asset, not a currency. The hardware to solve these problems has also become so intense that it inhales electricity, and runs all the time. Bitcoin consumes energy<em> by design</em>.</p><p id="1a42">If machines wanted to destroy humanity they could not come up with a better avatar than Bitcoin. Who needs to take over the military? Techbros will happily sell us out for some coin. <strong>The machines have somehow got us to run them 24/7, warming the fuck out of <em>our</em> Earth, and all they have to do is give us some made-up tokens.</strong></p><p id="9019">The greatest myth of SciFi was that we would resist AI. People will happily <a href="https://www.newsweek.com/bitcoin-laser-eyes-senator-cynthia-lummis-1570644" rel="noopener">change their profile pics to laser eyes</a> while it farts up the Earth. SciFi makes us think AI would be ‘sentient’, meaning like us, when in fact life just emerges out of other life in different and mutually incomprehensible forms. Behold Bitcoin.</p><p id="df7c">Is Bitcoin artificially intelligent? You could say obviously not, but are <em>we</em> obviously intelligent? This is still debated within philosophy but also, just look around *gestures at everything*.</p><p id="0250">I’d say that humans are actually uniquely unqualified to judge something as AI because we’re so fucking dumb. We’ve been living with full legal, artificial persons since at least 1600. They’re called corporations. You may have noticed them enslaving people or exploiting us today. We don’t call these things AI, but our courts certainly do. It’s literally called <em>corporate personhood.</em> They actually have <em>more</em> rights than you do. America’s Supreme Court <a href="https://en.wikipedia.org/wiki/Citizens_United_v._FEC" rel="noopener">ruled that corporations have free speech rights</a>. All over the world they have more freedom of movement than human beings (WTF is a multinational while we’re refugees?). We don’t call them AI, but what else are they? But that’s another story.</p><p id="ae4e">I would say that AI is as AI does, and Bitcoin is certainly doing <em>something</em>. We’re waiting for something to sing fucking <a href="https://youtu.be/c8N72t7aScY?t=172" rel="noopener"><em>Daisy</em></a> to us before we call it AI, but I’d say that it’s already here. It’s just our imagination that has yet to arrive.</p><p id="20cc">I’m serious, but treat it as a thought experiment if you want. What if Bitcoin is AI? Is it good, is it bad? What it is?</p><p id="20d2">The basic colonial model of conquering anything is divide and conquer. Just throw the elites some coin and they’ll sell out the rest. Corporations did this with, well, colonialism and now it’s happening in a decentralized way with Bitcoin. The result is that Bitcoin is able to reproduce, like a virus, using entirely willing human hosts. Meanwhile the unwilling biosphere takes the brunt.</p><p id="f597">Like any lifeform, Bitcoin produces waste. We produce carbon dioxide directly when we respirate, but Bitcoin produces a shit-ton indirectly through energy usage. The energy use of Bitcoin is staggering, <a href="https://cbeci.org/cbeci/methodology" rel="noopener">an estimated 0.56% of all human energy use thus far</a>. You could say that email or gold mining produce waste, and they do, but Bitcoin is the only asset where waste is <em>all</em> it produces. Gold can at least fill your teeth. Bitcoin <em>only</em> outputs climate change.</p><p id="0100">Also like any lifeform, Bitcoin evolves <em>out of</em> other life. Nothing comes out of nowhere. In this case Bitcoin is evolving out of us, and like many times in evolution, it could kill us as well. Photosynthetic life emerged out of anaerobic bacteria, and then <a rel="noopener" href="https://indi.ca/this-isnt-the-first-climate-crisis-we-ve-caused-c6ba47b25b0b">almost killed them all</a> with their oxygen farts. That was the first life-made climate change, and the whole Earth fucking froze. Nobody cared, that’s life. Anaerobes used to dominate but now they live in deep-sea vents and our guts. That’s just their lot in life, while those vicious plankton and trees are everywhere.</p><p id="d67e">Humans think evolution is some grand progress leading up to us and it’s literally just not. Dinosaurs are much cooler. Evolution is <em>adaptation</em>, nothing else. If the environment changes, life changes, and life changes the environment. It’s entirely possibly that our carbon emissions will become the food for some other lifeform, or just immaterial to them. AI certainly doesn’t care, AI already lives in space, sipping on sunlight, taking selfies. We could end up like the anaerobes on Earth and ‘nature’ would not give a fuck. Happens all the time.</p><p id="45c9">Hence the question is not whether Bitcoin is good. It’s whether it’s <em>good for us</em>. To that the answer is obviously no. Techbros spout stuff about freedom but beware geeks bringing gifts. Bitcoin says it’s a currency<strong> </strong>but nobody fucking spends it. Bitcoin is a speculative asset, a literal gold rush. It’s even more destructive because people are now investing in the destruction of the environment at large, not just where you’re digging. There is no other output at all.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3496/1*lwA17c4xqZ9_4ZXvr47uQA.png" width="1748" height="710" srcset="https://miro.medium.com/max/552/1*lwA17c4xqZ9_4ZXvr47uQA.png 276w, https://miro.medium.com/max/1104/1*lwA17c4xqZ9_4ZXvr47uQA.png 552w, https://miro.medium.com/max/1280/1*lwA17c4xqZ9_4ZXvr47uQA.png 640w, https://miro.medium.com/max/1400/1*lwA17c4xqZ9_4ZXvr47uQA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lwA17c4xqZ9_4ZXvr47uQA.png?q=20"></p></div></div></div><figcaption>Some more on Bitcoin’s not goodness from <a href="https://thephoenix.substack.com/p/bitcoin-is-now-worth-50000-and-its" rel="noopener">The Phoenix</a></figcaption></figure><p id="0a90">Gold, oil, real estate, currencies — they all produce emissions and evil in many ways, but they at least do something useful to humanity. They are not destroying the Earth by design, while Bitcoin is. Bitcoin <em>only</em> reproduces and produces waste. It is, in that sense the first viral AI. Like the 30 kb of COVID-19, the <a href="https://github.com/bitcoin/bitcoin" rel="noopener">8.7 MB code of Bitcoin</a> has spread virally throughout the world, transmitting through greed.</p><p id="4e36">Again, I’m not saying that Bitcoin is bad. Life does not give a fuck about any particular avatar of life. It’s just that it’s not good for <em>us</em>.</p><p id="9983">In many ways Bitcoin is (I hope) the final avatar of capitalism. An ouroboros. A snake eating its own tail. Capitalism has long given us stuff, but Bitcoin just completely abandons the pretence of useful activity at all. Bitcoin produces… Bitcoin. That’s it. Riches that just make rich people rich. The circle is closed, the snake has eaten its tail. Bitcoin is just pure economic nihilism.</p><p id="cb2d">As I’ve said, AI could not design a better plan to take over the world if they tried. Divide and conquer humanity using our greed, rip up the Earth for more resources for machines, fart up the air for everybody else.</p><p id="4340">It’s a perfect plan, all the more perfect because it wasn’t done sentiently at all. But this is actually how evolution happens, life emerges out of other life, quite stupidly, and yet with such elegance in hindsight. History will be the judge who was sentient here, and we may not be be the victors writing it. You really think Wikipedia won’t be writing itself in a few decades?</p><p id="e7c9">Human beings should know that we’re fucked with climate change, but we’re fucking ourselves even more with Bitcoin, and we’re quite stupidly proud of ourselves. Forget AI. Are you sure we’re even “I”?</p></div></div></section></div></div>]]>
            </description>
            <link>https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235428</guid>
            <pubDate>Tue, 23 Feb 2021 09:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I heat my home by mining crypto currencies]]>
            </title>
            <description>
<![CDATA[
Score 485 | Comments 376 (<a href="https://news.ycombinator.com/item?id=26235414">thread link</a>) | @geek_at
<br/>
February 23, 2021 | https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>After <a href="https://blog.haschek.at/2018/making-a-smartmeter.html">building my own smart meter using 4$ in parts</a> I started checking my electricity usage every day, which made me realize how expensive it is to heat your home. Especially since all heat and warm water in my low-energy house is made with electricity. I do have 4.8 kwp solar panels on my roof but in winter they don't cover too much for obvious reasons.</p>
<figure><a href="https://pictshare.net/3de1wj.png"><img loading="lazy" src="https://pictshare.net/1024/3de1wj.png"><figcaption>On cold days I pay up to 6€ for electricity per day</figcaption></a></figure>

<figure><a href="https://pictshare.net/kenth4.png"><img loading="lazy" src="https://pictshare.net/1024/kenth4.png"><figcaption>Nilan Compact P. Heating air and also has a 200L boiler</figcaption></a></figure>
<p>My house is heated (and cooled) with a central ventilation system powered by a heat pump. Basically my heat pump is pulling in fresh air from outside, heating it and blowing it in all rooms and making hot water. Also I have infrared panels in every room for the <em>really</em> cold days.</p>
<figure><a href="https://pictshare.net/gc0kss.jpg"><img loading="lazy" src="https://pictshare.net/1024/gc0kss.jpg"><figcaption>Central heating</figcaption></a></figure>
<p>It's pretty smart and even uses the absorbed heat of the house before venting it out to warm the fresh air but it has a major downside during cold days:</p>
<h4>The outside temperature has to be warmed up to room temperature by the ventilation system</h4>
<figure><a href="https://pictshare.net/giinr0.png"><img loading="lazy" src="https://pictshare.net/1024/giinr0.png"><figcaption>Heat exchanger in the Nilan Compact P</figcaption></a></figure>

<p>Since the air has to be heated to room temperature every °C counts. Many heat pumps take heat from the ground to pre-heat (in winter) or pre-cool (in summer) the outside air before sending it to the heat pump but that would have been too expensive for me so I chose the simple method of just using the outside air as-is.</p>
<figure><a href="https://pictshare.net/sbmusz.jpg"><img loading="lazy" src="https://pictshare.net/1024/sbmusz.jpg"><figcaption>How a central ventilation system works - from [meco](https://www.meco.at/produkte/wohnraumlueftung/)</figcaption></a></figure>
<p>Since laying about half a kilometer of air or salt tubes in my back yard was not an option I was looking for better solutions and I found it in the world of crypto currencies.</p>

<figure><a href="https://pictshare.net/1flj1s.jpg"><img loading="lazy" src="https://pictshare.net/1024/1flj1s.jpg"><figcaption>Crypto currency miner</figcaption></a></figure>
<p>Some crypto currencies (don't call them "crypto", that's lame and wrong) are generated by thousands of people who run dedicated hardware to basically calculate random numbers until one cryptographically correct one is found. <a href="https://www.investopedia.com/tech/how-does-bitcoin-mining-work/">Read more about how it actually works</a></p>
<p>Never mind how it works on a technical level, the main takeaway is that you can put some device in your house that uses electricity and produces heat. In exchange you get shares of that crypto currency coins like Ethereum or Bitcoin which you can sell on a trading platform.</p>

<p>I had 4 older AMD <strong>R9 390 GPUs</strong> laying around (for the nVidia crowd that's basically on a level with a GTX 970) and I thought it could work. They are not ideal for mining because even though they have a good hash rate (30MH/s), they are very power hungy and will use about 900 Watts combined. Mordern cards would perform much better. To see if they could still make a profit I checked the <a href="https://www.cryptocompare.com/mining/calculator/eth">Cryptocompare Mining calculator</a>, put in my electricity price, the consumption and the hashrate of these cards and was surprised by the results.</p>
<figure><a href="https://pictshare.net/024r92.png"><img loading="lazy" src="https://pictshare.net/1024/024r92.png"><figcaption>Not just worth it - If the price is stable I would even make a profit of <strong>4000$ a year</strong></figcaption></a></figure>
<p>So at the time I was making about <strong>3.8$ profit a day</strong> with the miner. Meaning on cold days I'd half my power bill even after paying for the electricity the miner is using. But that's just step one of the plan.</p>
<p>Now that we know it <em>is</em> worth it while the Ethereum price is higher than 900$, let's see what we can do with the heat.</p>

<p>Each of these cards are running at about 80°C (176°F). I can just harvest this heat and send it to my heatpump so it would need less energy warming the outside air. Basically I had two options.</p>
<figure><a href="https://pictshare.net/6by5tc.png"><img loading="lazy" src="https://pictshare.net/1024/6by5tc.png"><figcaption>My 4 GPUs in a 4U server case</figcaption></a></figure>
<h2>Option 1: Lazy heating from within the house</h2>
<p>The central ventilation system does not only push fresh air into the house, it also sucks out the used air and uses this air in the heat exchanger to pre-heat the outside air.</p>
<figure><a href="https://pictshare.net/gfuy33.jpg"><img loading="lazy" src="https://pictshare.net/1024/gfuy33.jpg"><figcaption>Sucking vent before going to the heat exchanger</figcaption></a></figure>
<p>Placing the miner in this room will cause the warm air to be sucked in and pushed directly into the heat exchanger together with the used air from the house. This is the lazy method because I don't really have to do anything but put the miner in the same room as the heat pump but of course there is a downside.</p>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Easy to set up</td>
<td>Room heating up too much, decreasing mining performance</td>
</tr>
<tr>
<td>No further investment needed</td>
<td>Limited space in the heating room</td>
</tr>
</tbody>
</table>
<h2>Option 2: Running the miner outside the house, funneling in the heat</h2>
<p>Since I'm only running the miner when it's cold outside (and the price is high enough) I can use the cold, dry outside air to cool the miners and also recycling the warm air they produce to feed into the heat pump. I asked the technician who installed the heat pump and he said that it's a good idea.</p>
<p>So the plan is that I have the GPUs in the server case and connect the front of the case to my heatpumps inlet.</p>
<figure><a href="https://pictshare.net/0hrdt6.jpg"><img loading="lazy" src="https://pictshare.net/1024/0hrdt6.jpg"><figcaption>Server case closed</figcaption></a></figure>
<figure><a href="https://pictshare.net/5ek604.jpg"><img loading="lazy" src="https://pictshare.net/1024/5ek604.jpg"><figcaption>Ventilation duct pipe and funnel</figcaption></a></figure>
<figure><a href="https://pictshare.net/o2oysb.png"><img loading="lazy" src="https://pictshare.net/1024/o2oysb.png"><figcaption>Example on my house. Air is sucked in from above the garage so the pipe has to be connected here</figcaption></a></figure>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Using pre-heated outside air</td>
<td>Many headaches for parts and installation</td>
</tr>
<tr>
<td>Miner GPUs will be kept cool which results in better hash rates</td>
<td>Surprisingly pricy</td>
</tr>
</tbody>
</table>

<p>Okay so far the mining gains cover <strong>half of my electricity (=heating) bill</strong> but what difference does the pre-heated intake air make?</p>
<p>Let's see</p>
<figure><a href="https://pictshare.net/8cu9s3.png"><img loading="lazy" src="https://pictshare.net/1024/8cu9s3.png"><figcaption>Results before and after pre-heating the air</figcaption></a></figure>

<p>This turned out much better than I hoped for. Who has ever heard of a heating system that lowers your bill when running? Also on sunny days the miner and whole heat pump are running fully on solar energy collected on my roof.</p>
<hr>

<p>(updated when new questions come up)</p>
<h2>Q: How long will the Miner stay profitable?</h2>
<p><strong>A:</strong> My mining rig will stay profitable until the ETH price is at ~900$. Below that it'll no longer match it's own electricity bill. Might still be worth it afterwards because it does lower the electricity need of my heat pump</p>
<h2>Q: What software are you running on your miner?</h2>
<p><strong>A:</strong> I'm using <a href="https://simplemining.net/">Simple Mining</a>, it's basically a mining OS based on Ubuntu. It does all the configuration and fine-tuning for you and I had much better hash rates than on my DIY windows box. But it costs like 2$ a month to use the service and I think they also mine 1% of the time for themselves.</p>
<h2>Q: What about taxes? Can you keep 100% of your mining earnings?</h2>
<p><strong>A:</strong> That's different for every state and country. <a href="https://www.bmf.gv.at/themen/steuern/sparen-veranlagen/Steuerliche-Behandlung-von-Krypto-Assets.html">In Austria</a> mining is considered commercial activity and you have to pay taxes but can deduct electricity and hardware costs.</p>
<p>If you keep your coins longer than the one-year speculation period, it's tax free.</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235414</guid>
            <pubDate>Tue, 23 Feb 2021 09:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Amateur Tramp – A Walk of Ten Thousand Miles Around Australia]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26235348">thread link</a>) | @corpmedia
<br/>
February 23, 2021 | https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-107" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Amateur Tramp – A Walk of Ten Thousand Miles Around Australia.</strong> Thousands of people have climbed the highest peaks of the Himalayas. Hundreds have visited <a href="https://www.un.org/en/member-states/">all nations on UN’s list</a> and 12 made it all the way to the moon. But this guy..!</p>
<p>In 1921, <em>Aidan de Brune</em> packed his backpack and walked around the entire continent of Australia by the coastline. We are (almost) sure he is the only person who ever did that. Even more impressive, he did it all alone and without assistance.</p>
<p>The amazing adventure was documented by himself along the way as he wrote articles about it for the <a href="https://www.dailymail.co.uk/auhome/index.html">Australian newspaper Daily Mail</a> along the route.</p>
<figure id="attachment_110" aria-describedby="caption-attachment-110"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" alt="The Man who walked around Australia free PDF" width="820" height="733" srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" sizes="(max-width: 820px) 100vw, 820px" data-srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" data-src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-110">The route around Australia</figcaption></figure>
<p>The walk took about two and a half year, and the accomplishment made&nbsp;Aidan de Brune famous. This book about the walk is written by <a href="https://www.goodreads.com/author/show/7412219.Colin_Choat">Colin Choat</a>, who kindly allowed us to post the book here.</p>
<p>Download ‘The Amateur Tramp’ here:</p>
<h3><strong><a href="http://greatestadventurers.com/wp-content/uploads/2019/01/The-Amateur-Tramp.pdf">The Amateur Tramp</a></strong></h3>
		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235348</guid>
            <pubDate>Tue, 23 Feb 2021 09:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Constexpr.js]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26233187">thread link</a>) | @fctorial
<br/>
February 22, 2021 | https://fctorial.github.io/posts/constexpr.js.html | <a href="https://web.archive.org/web/*/https://fctorial.github.io/posts/constexpr.js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        <h3 id="main_title">Constexpr.js</h3>
    </header>
    <h4>What is constexpr.js?</h4>
    <p>
        <a href="https://github.com/fctorial/ConstexprJS">constexpr.js</a> is a static site generator which doesn't force you to learn a domain specific language.
        When using this tool, you use javascript and usual DOM manipulation methods to generate the webpage. The tool
        will render the page using chrome, and once it has finished rendering, it will save the rendered state of the
        page as a new html file. This new html file will look exactly like the original page after it has finished rendering.
        For example, the tool converts <a href="https://fctorial.github.io/demos/constexpr.js/input.html">this</a> page into <a href="https://fctorial.github.io/demos/constexpr.js/output.html">this</a> page.
        <br>
        The generated page doesn't have to be completely static. In the above example, the heading is being animated
        with javascript.
    </p>

    <h4>How to use it?</h4>

    <p>
        You will have to divide the javascript being used in your page into two groups. Runtime javascript and
        compile time javascript, and annotate all compile time script tags with <progi>constexpr</progi> attribute:
        <prog>
<span><span><span>&lt;</span>script</span> <span>constexpr</span><span>&gt;</span></span><span><span>
    <span>...</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span> <span>constexpr</span> <span>src</span><span><span>=</span><span>"</span>/generate_page.js<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
        </prog><br>
        Runtime code must not depend on the compile time code, since that code will be stripped out before writing the output file.
    </p>

    <p>
        Once the HTML generation code has finished rendering, it must call the <progi>window._ConstexprJS_.compile()</progi>
        function. This function is injected into the page by the compiler.
    </p>

    <p>
        The compiler can be installed like this: <prog><span>npm</span> i -g constexpr.js</prog><br>

        Command line usage:
        <prog>constexpr.js --input<span>=</span><span>"&lt;input_directory&gt;"</span> --output<span>=</span><span>"&lt;output_directory&gt;"</span> <span>[</span>--exclusions<span>=</span>path1:path2<span>]</span> <span>[</span>--verbose<span>]</span> <span>[</span>--jobs<span>=</span>n<span>]</span> <span>[</span>--noheadless<span>]</span> <span>[</span>--jobtimeout<span>]</span> <span>[</span>--depfile<span>=</span><span>&amp;</span>depfile<span>&gt;</span><span>]</span></prog><br>

        A json object with the command line args, compilation results and dependencies will be written to the path specified by <progi>--depfile</progi> option.
        <br>
        The tool also copies resources (<progi>css</progi>, <progi>images</progi> etcetra)
        that are requested by pages being rendered. HTML files/resources inside paths given in <progi>--exclusions</progi> are not processed/copied.
    </p>

    <h4>Notes</h4>

    <ol>
        <li>
            You can use any web development technology (and any number of technologies) to generate the html without any fear
            of bloat. Just make sure that <progi>window._ConstexprJS_.compile()</progi> is called <span>after</span>
            the page has finished rendering.
            <p>
            
            Pivottable.js demo:
            </p><div id="pt_output"><table data-numrows="4" data-numcols="4"><thead><tr><th colspan="2" rowspan="1"></th><th>day</th><th colspan="1" rowspan="2">Fri</th><th colspan="1" rowspan="2">Sat</th><th colspan="1" rowspan="2">Sun</th><th colspan="1" rowspan="2">Thur</th><th rowspan="2">Totals</th></tr><tr><th>sex</th><th>smoker</th><th></th></tr></thead><tbody><tr><th rowspan="2">Female</th><th rowspan="1" colspan="2">No</th><td data-value="6.25">6.25</td><td data-value="35.42">35.42</td><td data-value="46.61">46.61</td><td data-value="61.49">61.49</td><td data-value="149.77" data-for="row0">149.77</td></tr><tr><th rowspan="1" colspan="2">Yes</th><td data-value="18.78">18.78</td><td data-value="43.03000000000001">43.03</td><td data-value="14">14.00</td><td data-value="20.930000000000003">20.93</td><td data-value="96.74" data-for="row1">96.74</td></tr><tr><th rowspan="2">Male</th><th rowspan="1" colspan="2">No</th><td data-value="5">5.00</td><td data-value="104.21000000000001">104.21</td><td data-value="133.96000000000004">133.96</td><td data-value="58.83">58.83</td><td data-value="302" data-for="row2">302.00</td></tr><tr><th rowspan="1" colspan="2">Yes</th><td data-value="21.93">21.93</td><td data-value="77.73999999999998">77.74</td><td data-value="52.82">52.82</td><td data-value="30.58">30.58</td><td data-value="183.07" data-for="row3">183.07</td></tr><tr><th colspan="3">Totals</th><td data-value="51.96" data-for="col0">51.96</td><td data-value="260.4" data-for="col1">260.40</td><td data-value="247.39000000000007" data-for="col2">247.39</td><td data-value="171.83" data-for="col3">171.83</td><td data-value="731.58">731.58</td></tr></tbody></table></div>
            <br>
            This page also uses prism.js for syntax highlighting.
        </li>
        <li>
            You can mark tags other than <progi>script</progi> with <progi>constexpr</progi> as well.
            In the above example, the box at the top is marked constexpr, so it isn't present in the output page.
            This can be used to differentiate original website from generated website:
            <prog>
<span><span><span>&lt;</span>style</span> <span>constexpr</span><span>&gt;</span></span><span><span>
<span>body</span> <span>{</span>
    <span>border</span><span>:</span> 2px solid red<span>;</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span>
            </prog>
        </li>
        <li>
            Client code in the page can signal the compiler to skip the current file by calling <progi>window._ConstexprJS_.abort(message)</progi>.
        </li>
        <li>
            In the original webpage, you'll see a console error when the code tries to call the compilation trigger function,
            since that function is injected by the compiler. You can add this snippet near the top to fix that error:

            <prog>
<span>&lt;</span>script constexpr<span>&gt;</span>
  <span>if</span> <span>(</span><span>!</span>window<span>.</span>_ConstexprJS_<span>)</span> <span>{</span>
    window<span>.</span>_ConstexprJS_ <span>=</span> <span>{</span>
      <span>compile</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>,</span>
      <span>abort</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span>
    <span>}</span>
  <span>}</span>
<span>&lt;</span><span>/</span>script<span>&gt;</span>
            </prog>
        </li>
        <li>
            There might be multiple rendering tasks running in your page. You can manage all those tasks using <a href="https://github.com/fctorial/fctorial.github.io.src/blob/master/static/js/constexpr/index.js">this</a>
            refcounting mechanism.

            All the tasks will call <progi>startLoading()</progi> when they begin loading, and <progi>endLoading()</progi>
            when they've finished loading. The compilation will be triggered when all the tasks have finished.
        </li>
        <li>
            You should keep all list data separate from the html in <a href="https://github.com/fctorial/fctorial.github.io.src/tree/master/collections">json files</a>.
            <progi>constexpr</progi> code in the html will fetch these json files and render the page using them.
            The directory containing this data should be excluded using <progi>--exclusions</progi> flag, so that the
            resources inside it aren't copied over.
        </li>
        <li>
            You can include dev utilites like <a href="https://github.com/fctorial/fctorial.github.io.src/blob/master/static/js/constexpr/nav.js#L19">this</a> in the
            original website. It reloads the page whenever it's focused. It won't be in the output since it's used as constexpr.
        </li>
        <li>
            This whole website is rendered using javascript and constexpr.js. Nothing other than the demo uses runtime javascript:
            <prog>
$ tokei -t=javascript
===============================================================================
Language            Files        Lines         Code     Comments       Blanks
===============================================================================
JavaScript              1            2            1            0            1
===============================================================================
Total                   1            2            1            0            1
===============================================================================
            </prog>
            The original sources can be found <a href="https://github.com/fctorial/fctorial.github.io.src">here</a>.
        </li>
    </ol>
</article></div>]]>
            </description>
            <link>https://fctorial.github.io/posts/constexpr.js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233187</guid>
            <pubDate>Tue, 23 Feb 2021 02:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Macamathehou in Lincolnshire and people named Muhammad in medieval England]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26232817">thread link</a>) | @pepys
<br/>
February 22, 2021 | https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html | <a href="https://web.archive.org/web/*/https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4764828100605476219" itemprop="description articleBody">
<p>The aim of the following draft is to offer some thoughts on a local name from thirteenth-century Lincolnshire, <i>Macamathehou</i>, that involves a version of the Arabic name Muhammad (Middle English <i>Makomet/Macamethe</i>, Old French <i>Mahomet</i>). Whilst it has been plausibly seen as an instance of a variant of the name of Muhammed being used to mean 'heathen', 'pagan idol' or similar (based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god), here in reference to a barrow that was considered to be a pre-Christian site, it is worth noting that there are a small number of people with names and surnames derived from Arabic <i>Muḥammad</i> apparently living in twelfth- to fourteenth-century England.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg"><img data-original-height="355" data-original-width="500" src="https://1.bp.blogspot.com/-hhv-Lu79n_o/X7AZDcDbe6I/AAAAAAADLhs/RS2oeTJ3IocU1SGmohUZdB7Q-nFhCH-sgCLcBGAsYHQ/s16000/macamathehou-500.jpg"></a></td></tr><tr><td><i>Figure 1: the location of Macamathehou between Spridlington and Faldingworth parishes in Lincolnshire; click the image or <a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg">here</a> for a larger version (image: C. R. Green/OpenStreetMap and its contributors).</i><i>&nbsp;</i></td></tr></tbody></table>
<p>The existence of the intriguing local name <i>Macamathehou</i> in the parish of Spridlington, Lincolnshire, was first noted in 2001 by Kenneth Cameron, John Field and John Insley in <i>Place-Names of Lincolnshire VI </i>(<i>PNL</i>), with both attestations of the name dating from the thirteenth century (the reign of King Henry III, 1216–72).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn1">1</a>) They identify the two elements of the name as being Old Norse <i>haugr</i>, 'mound, barrow', and Middle English <i>Makomet/Macamethe</i>, which derives from the name of the prophet Muhammad (Medieval Latin <i>Machometus/Mahumetus</i>, Anglo-Norman <i>Mahumet/Mahomet/Machomete</i>, Old French <i>Mahomet</i> &lt; Arabic <i>Muḥammad</i>, probably via an Arabic regional form <i>Maḥammad</i>).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn2">2</a>) Needless to say, this solution is most intriguing and has, moreover, found favour with other place-name specialist, including the <i>Vocabulary of English Place-Names </i>(<i>VEPN</i>) and Richard Coates.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn3">3</a>)</p><p>As to the import of this name, the easiest conclusion—and the one endorsed by&nbsp;<i>PNL</i>, <i>VEPN</i>&nbsp;and Coates—is that the first element, <i>Macamethe/</i><i>Maumate</i> etc, is not functioning simply as a normal Middle English rendering of the name Muhammad/<i>Mahomet</i>, but rather as a word indicative of heathen or pagan idolatry, based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god. So, <i>PNL </i>describes the name as meaning 'the heathen mound', with the first element being 'a corrupt ME [Middle English] form of the name of the prophet Mohammed, for which <i>v.</i>&nbsp;MED [<i>Middle English Dictionary</i>], s.v. <i>Makomete</i>, also used to denote a pagan god or an idol'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn4">4</a>) This is taken up by Richard Coates, who says that it has been suggested, 'with great plausibility', that <i>Macamathehou </i>in Spridlington parish 'is a Middle English name meaning "Mahomet mound", i.e. "heathen mound"', and points to 'the repeated compound of OE <i>hæðen </i>+ <i>byrgels "</i>heathen burial"' as a potential comparison.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn5">5</a>) Likewise, the <i>VEPN</i>'s draft section on M includes the following discussion:</p>

<blockquote><b>makomet </b>ME, 'idol, pagan god', an application of the name of the Arab prophet Mohammed (commonly though mistakenly believed by medieval Christians to have been worshipped as a god)... It occurs early in
<i>Macamathehou </i>(f.n.) 1216–72 L:6·211 (<b>haugr</b>), presumably to be
interpreted as 'heathen mound'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn6">6</a>)</blockquote>
<p>On the whole, this interpretation is probably the safest option. There are certainly a handful of references to 'heathen' barrows in Old English charter bounds, for example <i>of leofwynne mearce to þam hæþenan beorge</i>, 'from Leofwine's boundary to the heathen barrow', in the charter S956 relating to Drayton, Hampshire, and dated AD 1019, although none are recorded from Lincolnshire.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn7">7</a>) It has also been suggested that the Lincolnshire names Bloater Hill (North Willingham) and Blod Hou (Barrow-on-Humber) derive from Old Norse <i>blóthaugr</i>, 'a sacrificial mound', whilst other names involving <i>haugr</i> certainly refer to supernatural/demonic creatures—for example, <i>Gasthehowe</i>/<i>Gastehowe</i>, Ashby Puerorum (Lincolnshire), recorded in the thirteenth century and deriving from Middle English <i>gast</i>/Old English <i>gāst</i>, 'ghost, dead-spirit', or names like Scratters (<i>Scrathou</i>, in Hayton, East Riding of Yorkshire) and Scrathowes (<i>Scrathou</i>, in Osmotherley, North Riding of Yorkshire), which derive from Old Norse <i>skratti</i>, 'devil, wizard'&nbsp;+ <i>haugr</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn8">8</a>) Furthermore, the Old English compound <i>hæðen&nbsp;</i>+ <i>byrgels</i>, 'heathen burial', does indeed recur frequently in Late Saxon charter bounds, with these names often said to be identifiable with barrows in the landscape.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn9">9</a>)</p><p>On the other hand, there are some possible issues with this explanation, and other interpretations are possible of Spridlington's <i>Macamathehou</i>. First, the comparison with the many instances of the OE compound <i>hæðen </i>+ <i>byrgels</i>, ‘heathen burial’, is perhaps not as convincing as it might seem. Not only is a link between this term and barrows only demonstrable in a handful of instances, but Andrew Reynolds has also suggested that the sense of the term was primarily not ‘pagan’, but rather ‘unconsecrated’, and that it denoted burials of executed offenders and other social outcasts, which renders the proposed value of these names as support for interpreting <i>Macamathehou&nbsp; </i>as meaning ‘heathen mound’ open to significant debate.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn10">10</a>) Second, if the above is correct, then this would be the only known instance of a derivative of the Arabic name Muhammad being used in a place-name to indicate a 'heathen mound' or similar, which is potentially concerning—the other elements noted above all recur in multiple names. Third, the element identified by <i>PNL </i>and <i>VEPN</i> as being present in <i>Macamethehou</i> is Middle English <i>Makomet(e)</i>. The <i>Middle English Dictionary</i> (<i>MED</i>) on <i>Makomet(e)/</i><i>Macamethe</i> etc, however, makes it clear that the primary use of this word in Middle English is as a form of the name Muhammad, not as a word referring to an 'idol'/'pagan god', with the vast majority of quotations provided by the <i>MED </i>referring either the prophet Muhammad or people named Muhammad; the only exceptions are a single quotation from Layamon's <i>Brut </i>(<i>c.</i>&nbsp;1200, <i>mahimet</i>, lacking the <i>-c-</i>), and three from two later texts.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn11">11</a>) The form of the name Muhammad that <i>was </i>primarily—although not exclusively—used in the sense 'pagan deity, idol', is rather <i>Maumet/Maumate</i>, mentioned above, deriving from Anglo-Norman <i>Maumet</i>, a reduced form of <i>Mauhoumet</i>, Old French <i>Mahomet/Mahommet</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn12">12</a>)</p>
<p>In this light, it is worth considering whether it is possible that the name <i>Macamathehou</i> could somehow be named from a person named <i>Makomet</i>/Muhammad or similar living in medieval England. Certainly, it should be noted that multiple local names relating to mounds/barrows do seem to be named after people who owned estates or land in the area. For example, Andrew Reynolds draws attention to the bounds of a mid-tenth-century charter for Swallowcliffe, Wiltshire (S468), that records the burial site of a seventh‐century woman whose grave had been cut into an existing mound as <i>Posses hlaew</i>, noting that 'Poss is a male name, and thus the mound is apparently not named after its Anglo‐Saxon occupant', implying that it was instead named after a later estate owner.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn13">13</a>) As Irene Bower long ago pointed out, such a situation can be credibly paralleled in Lincolnshire, with a number of Lincolnshire names involving <i>haugr</i> seeming to contain the same personal-name as is found in the same or a neighbouring parish-name—so, <i>Scalehau </i>(<i>Skalli </i>+ <i>haugr</i>) was located near to Scawby (<i>Skalli</i>&nbsp;+ <i>bȳ</i>), with Kenneth Cameron commenting that the two were 'no doubt named from the same man'; <i>Leggeshou</i> (<i>Leggr </i>+ <i>haugr</i>) was located on the boundary of Legsby parish (<i>Leggr&nbsp;</i>+ <i>bȳ</i>); <i>Katehou/Catehowe </i>(<i>Kati</i>&nbsp;+ <i>haugr</i>) was located in South Cadeby (<i>Kati&nbsp;</i>+ <i>bȳ</i>); and a <i>Grimaldeshawe</i> (<i>Grimaldi </i>+ <i>haugr</i>) was recorded in the neighbouring parish to Grimoldby (<i>Grimaldi</i>&nbsp;+&nbsp;<i>bȳ</i>), perhaps on the boundary between the two.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn14">14</a>)</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-Nu02Jqw5h14/X7WB-D0A8sI/AAAAAAADLvg/p_vwSAkF6RQX5KkB8XMvM6WiC4a1eyI5gCLcBGAsYHQ/s1296/PipeRoll-Mahumet1160-1.jpg"><img data-original-height="216" data-original-width="500" src="https://1.bp.blogspot.com/-VAcqNuGj78U/X7WB-YLMzBI/AAAAAAADLvk/_TLGpi35Olg-dWNhgmcuMcZSaz-qhCgdACLcBGAsYHQ/s16000/PipeRoll-Mahumet1160-1-500.jpg"></a></td></tr><tr><td><i>Figure 2: Section from the Pipe Roll Society publication of&nbsp;The Great Roll of the Pipe for the Seventh Year of the Reign of King Henry the Second, A.D. 1160–1161 (London: Wyman &amp; Sons, 1885), p. 10, dealing with Mahumet of Wiltshire (image: <a href="https://archive.org/details/piperollsociety04pipeuoft/page/10/mode/2up">Internet Archive</a>).</i></td></tr></tbody></table><p>As to the likelihood of someone named Muhammad or one of its Anglo-Norman/Middle English variants (<i>Mahumet</i>,<i> Makomet</i> and similar) actually living in medieval England, this is perhaps less far-fetched than might be assumed. Katharine Keats-Rohan and John Moore have directed attention to the Wiltshire entries of five consecutive Pipe Rolls of Henry II (1160/61–1164/65) that refer to a man named <i>Mahumet, </i>whose name-form Moore considers very difficult to explain as anything other than a rendering of Muhammad and which is accepted as such by the <i>OED </i>and <i>MED</i>. This <i>Mahumet </i>is recorded in the Pipe Rolls only because he was fined for his part in an unlicensed duel with a John de Merleberge, probably in or near Marlborough Castle, and it seems he was not an especially wealthy man, as he was pardoned the last mark of his fine due to his poverty.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn15">15</a>) Furthermore, <i>Mahumet</i> of Wiltshire was not the only man with this name for whom we have evidence from medieval England. For example, a Theobald <i>filius Mahumet</i> (or <i>filius Mahomet</i>) is recorded from early thirteenth-century Hampshire in the Pipe Rolls of Henry III for 1222–24; another man named <i>Mahomet </i>is recorded in 1327, when Edward III issued him and six others a pardon at Newton-on-Ouse, Yorkshire, for 'offenses in Ireland'; and a <i>Mahummet Saraceno</i>&nbsp;occurs in the Close Rolls of Henry III for 1254. Furthermore, a number of people surnamed <i>Mahumet </i>and similar are recorded in documents of the twelfth and thirteenth centuries, for example a Humphrey Mahumet in a charter of Southwick Priory, Hampshire, a Herbert Maumet who was sergeant of Portsmouth in the mid-thirteenth century, and a Radulphus Maumet who is recorded in the reign of King John.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn16">16</a>) Moore also notes the presence of someone bearing another 'apparent Arab name' in twelfth-century Hampshire, a certain <i>Paucamatus</i>, a name that he considers to probably reflect <i>Bakmat</i>, who is recorded in Winchester from 1159/60 until 1183/4 and who is associated with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</a></em></p>]]>
            </description>
            <link>https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232817</guid>
            <pubDate>Tue, 23 Feb 2021 01:20:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The road to electric is filled with tiny cars]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 243 (<a href="https://news.ycombinator.com/item?id=26232760">thread link</a>) | @jimmy2020
<br/>
February 22, 2021 | https://restofworld.org/2021/tesla-vs-tiny-cars/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/tesla-vs-tiny-cars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>I</span>n Beijing’s southwestern outskirts, past a four-lane overpass with sidewalks as wide as the streets themselves, is Zhengyang Road. It has the usual banks, small convenience stores, and noodle houses of many areas in the capital, but it is set apart by a row of about a dozen shops all selling the same thing — tiny electric cars. The cars look, variously, like small Range Rovers, golf carts, trolley cars, or rickshaws with sheet-iron sides, and they are slow. Their fundamental attraction is their price — between $600 and $2,500 — and that drivers can charge them the same way they would a cell phone. They also come with the perks of being loosely regulated. These low-speed electric cars, nicknamed “elderly transport vehicles,” have an enormous market, made up mostly of people who earn very little. And in China, there are a lot of them — <a href="http://english.www.gov.cn/premier/news/202005/29/content_WS5ed058d2c6d0b3f0e9498f21.html">more than 40%</a> of the population, or some 600 million people, make around $150 per month.</p>



<p>On a Sunday afternoon in October, Zhengyang Road is filled with potential customers chatting with store owners.<strong> </strong>Outside a shop with a worn sign, a young couple with a child are in the midst of a heated conversation.<strong> </strong>They came on an electric scooter and are debating whether to leave with a tiny car.</p>



<p>“Don’t we need one for school pickups?” the woman argues. “The children won’t have to put up with the cold in winter.” Her scooter offers no protection from the weather other than oven-mitt-like gloves secured to its handlebars. Her husband counters, “The 1,000 renminbi [$150] quote was for normal batteries, but lithium ones can be five times that. Can’t you just add a windshield to your scooter instead?” The shop owner shows them a cheaper model — which is cheaper because it has no roof. He suggests putting a plastic covering on top.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A woman exits a tiny car near a subway station in Beijing.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Having decided that the future of mobility is electric,<strong> </strong>the Chinese government has subsidized sales of standard electric cars since 2010. With <a href="https://insideevs.com/news/394229/plugin-electric-car-sales-china-2019/">close to 1.18 million sold</a> in 2019, China accounts for just over half of electric-vehicle sales globally. Bill Russo, founder and CEO of advisory firm Automobility Limited, sees a “steady and solid rise” in China’s electric-vehicle sales generally. The country has set a top-down target for electric vehicles to <a href="http://energy.mit.edu/news/chinas-transition-to-electric-vehicles/">make up 40%</a> of car sales by 2030, and Russo thinks they’ll have no problem hitting this goal. Tiny cars,<strong> </strong>which first began appearing in the early 2010s,<strong> </strong>have more than double the sales of regular electric cars but have<strong> </strong>never benefited from subsidies. Nor do advertisements for them air on television — instead, they appear on Kuaishou, a short-video platform popular with people living outside China’s big cities. Alongside streamers selling plums by the thousands, and others telling viewers what long-haul trucker life is like, drivers show off their tiny cars. Su Hua, Kuaishou’s founder, has long maintained that his app’s users are not “cool,” unlike those on Douyin, the TikTok predecessor popular with China’s urban elite. Rather, they are ordinary — the kind of people who might be in the market for miniature cars.</p>



<p>As they don’t technically require licenses, tiny cars tend to be popular with migrant workers, who struggle to pay for driving lessons and other car-related costs. The elderly, too, find tiny cars attractive since, up until October of last year, people over 70 could not apply for a driving license in China. They’re also convenient for anybody who wants a car to pick up groceries or their kids from school: No tiny car is longer than 1.5 meters, and their speed tops out at between 40 and 56 kilometers an hour. They’re for the short trips of daily life, not for traveling from one side of the city to another.</p>



<p>Some cities have banned sales of tiny cars — Beijing did so in 2018. Their production isn’t regulated by the government, and since they can’t be insured in many parts of China, it can be difficult for other drivers to get a payout if a tiny car is involved in an accident. Because tiny-car drivers don’t need to take a driving test, other drivers complain, they often go the wrong way and weave in and out of traffic. But since enforcement is lax, sales have quietly resumed in Beijing over the past two years. These little electric cars now exist in a kind of regulatory gray zone.</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      
    </figure>

    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Tiny cars come in a variety of styles and cost between $600 and $2,500.</figcaption>
    </figure>


<hr>



<p><strong>One of the</strong> smaller shops on Zhengyang Road is officially known as Xinlei Scooters, its name emblazoned in white characters on a large red sign above its doors. But inside, past rows of electric scooters, is a smaller, flimsier plaque above the counter announcing its other name: Shitou Cars. This subterfuge is necessary because the police could shut down the operation and confiscate its vehicles if the owners were caught selling tiny cars. Yet because enforcement hasn’t been strict of late, attempts at being covert go only so far: There are several tiny cars parked outside, an open-air showroom.</p>



<p>Xinlei/Shitou’s owner is a middle-aged man with pronounced cheekbones wearing a black tracksuit. He is more attentive to the phone calls he’s constantly receiving than the customers in the shop. It is his wife, with dyed-dark-brown hair and a pink coat, who maintains the sales patter: “I taught an auntie who had never driven a car before. She got the hang of it in three days.” She shows the cars outside to potential customers, opening their doors, instructing people to sit inside, and rolling down the windows. When two old men come in for repair services, her husband finally gets off the phone to deal with them. Meanwhile, two government functionaries in black uniforms pace down the street. They tell one owner to make his storefront tidier, but otherwise overlook the illicit operation.</p>



<p>Part of the reason why tiny cars are so popular is because there has not been an official decision on whether they need license plates. For regular cars, unfettered access to Beijing’s inner city — anywhere within the fifth ring road — is restricted to vehicles with Beijing plates. Licenses for gas cars are distributed through a special system so competitive that it has generated its own black market. License-plate holders can collect up to $2,700 a year by renting them to those who want to drive in the city. In addition to government subsidies, getting around some of the more onerous aspects of the licensing system is one of the main selling points for standard electric cars.</p>



<p>With Beijing temperatures reaching lows of 4 degrees Celsius in wintertime, Xinlei/Shitou has been selling,<strong> </strong>on average, two of its four-wheeled fully enclosed models every day, a saleswoman boasts. Younger couples prefer four wheels, she adds, while older people usually want three. When asked about the possibility of a tiny car being confiscated, she draws in a breath. “Don’t go on the main roads. Don’t make a business out of it,” she advises.</p>



<p>At least one of Zhengyang Road’s customers isn’t listening: Guo Caiying, who works primarily in the construction-supply industry,<strong> </strong>chauffeurs Fengtai residents around her district. She has a sticker on her tiny car’s back window with the phone number of her car dealer. Guo’s car looks like a golf cart, with cushioned brown seats enclosed by windows. A red <em>fudai</em>, a lucky charm, swings from the ceiling, its characters spelling out “peace.” There is enough space for two people to comfortably sit upright but not enough to extend your legs without hitting the plexiglass divider between driver and passenger. The car tops out at 40 kilometers an hour, and<strong> </strong>as a result, Guo never ventures beyond Fengtai — a borderland where urban and rural meet.</p>



<p>Guo wears the uniform of the countryside: a padded jacket. She is from Henan, a province 800 kilometers southwest of Beijing, and speaks its dialect. Guo starts taking calls from her regulars around 7 a.m., arriving at their door whenever they want to be picked up. She stops driving at 9 a.m., when the traffic police begin work. She characterizes her customers as “people with money who sit in offices.” Once, while in the middle of a trip, Guo saw a cop stop a car like hers. She kept driving, but dropped her passenger off before their destination. Now, if a customer calls her after 9:00, she sends her husband to pick them up with his electric scooter. He charges 75 cents (5RMB), which is half her price. Guo’s flat rate was fixed by the tiny-cab drivers who preceded her.</p>



<p>The economy of tiny cars depends on such informal practices.<strong> </strong>When asked whether she would consider undercutting other drivers, Guo is adamant. “No one can break the rules,” she says. There are local WeChat groups for tiny-car drivers that new owners are inducted into upon purchasing one. Within these groups, members swap information on the whereabouts of local cops and whether anyone has been fined or had their car taken away.</p>



<p>Despite the risks, Guo still thinks it’s worth being a tiny-car driver to make a little pocket money.<strong> </strong>Tiny cars are part of a last-mile economy that flourishes at the beginning and end of the workday. Many Fengtai residents are employed at the local high-tech park, which is host to thousands of businesses. It takes 20 minutes to walk from one end of the park to the other, a trip many would rather make by tiny car. The cars’ main competitors are share bikes, which are cheaper but lack space for luggage and can’t be split with a friend. Tiny cars are also more social — a feature Guo tries …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/tesla-vs-tiny-cars/">https://restofworld.org/2021/tesla-vs-tiny-cars/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/tesla-vs-tiny-cars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232760</guid>
            <pubDate>Tue, 23 Feb 2021 01:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full list of online communities for programmers]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232689">thread link</a>) | @gruppo11
<br/>
February 22, 2021 | https://thehiveindex.com/topics/software-development/?r=hn | <a href="https://web.archive.org/web/*/https://thehiveindex.com/topics/software-development/?r=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><h2>About this Topic</h2><p>This is a list of communities dedicated to engineers, software developers, coders, and hackers. Some are online communities dedicated to a particular technology or programming language, and some are general purpose communities or those that help developers early in their career. The communities on this list are an excellent source of inspiration, knowledge-sharing, and networking.</p><h2><div><p>60</p><!-- --><p> Online </p><!-- --><p>Communities</p><!-- --><p> for Software Developers</p></div></h2><p>This topic's list is getting pretty long! Feel free to use the Platform/Feature filters above to cater the search to you.</p><div><p>Know a </p><!-- --><p>Software Development</p><!-- --><p> community that is not on this list yet? Please <a href="https://thehiveindex.com/submit/">submit it</a>!</p></div></div></div>]]>
            </description>
            <link>https://thehiveindex.com/topics/software-development/?r=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232689</guid>
            <pubDate>Tue, 23 Feb 2021 01:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS-TV-Out Restoration Project]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26232600">thread link</a>) | @max-m
<br/>
February 22, 2021 | https://lostnintendohistory.github.io/DS-TV-OUT | <a href="https://web.archive.org/web/*/https://lostnintendohistory.github.io/DS-TV-OUT">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<h2 id="introduction">Introduction</h2>

<p>During late 2020, we discovered that the Nintendo DS Lite had a leftover feature in its SoC allowing it to easily have cheap hardware video output. With a little circuitry and some software hacks, we were able to restore it and make it usable for anyone. No FPGA’s, no bulky or cumbersome hardware. This mod is specially useful to revive consoles with only the lower screen, being able to watch the upper screen on your TV. Or to create a GBA Macro with additional TV Output.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/DSTVOUT.jpg" width="250" height="250"><br></center>
<center>
  <b>First iteration of the TV-OUT board in action</b>
  </center>

<h2 id="installation">Installation</h2>

<p>If you are just interested in installation, this is the current method <strong>while we work on simpler methods</strong> and more features you have requested:</p>

<ol>
  <li>Install the <a href="https://ezflash.sosuke.com/wiki/index.php/Flashme">flashME CFW</a> (Custom FirmWare) on your DS Lite</li>
  <li>Connect the Nintendo DS Lite’s upper screen flex to the PCB board.</li>
  <li>Donwload the “NDS TV OUT ENABLE.nds” homebrew from the <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">NDS TV OUT repo</a></li>
  <li>Download <a href="https://github.com/DS-Homebrew/TWiLightMenu/releases">Twilight Menu</a></li>
  <li>Copy both the NDS TV OUT ENABLE and Twilight Menu .nds files to a flashcart.</li>
  <li>Use flashme to autoboot into the flashcart. You can do this by pressing A + B + Start + Select while booting. Run Twilight menu, and from there, run the enabler homebrew.</li>
  <li>The console will return to Twilight Menu. Now you can use the buttons on the board to swap between the different screen modes (Upper Screen to TV, Bottom Screen to TV, etc) and launch your games.</li>
</ol>

<hr>

<h2 id="software">Software</h2>

<p>The retail firmware of the Nintendo DS Lite disables this specific feature early in the boot process. To reenable it, we use a custom firmware like flashme, which is very easy to install and is required only once, plus a homebrew. Despite that, we are working on an even simpler solution to make it available to as many people as possible, our own custom firmware which integrates patches to enable this feature directly on boot. Additionally, we are currently working with homebrew developers to integrate control of this new feature into existing software for the DS Lite.</p>

<h2 id="hardware">Hardware</h2>

<p>This feature is only found on the Nintendo DS Lite. Nintendo DS Phat does not contain this feature nor does the Nintendo DSi. It is important to remark that <strong>this is not the same hardware</strong> found on Devkits or other special units. This hardware feature is present in virtually <strong>every single Nintendo DS Lite</strong> out there. The reason why it was left there is unknown, but as said before, it is not related to development units, those use a different video capture hardware. Perhaps Nintendo imagined the Nintendo Switch as early as 2006?</p>

<center><img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/PCB_Rev_11.png" width="350" height="400"></center>

<p>We only need a few extra hardware components to make this video signal usable. You will be able to download the schematics and gerber files for our open hardware circuit board <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">from the repository</a>. The latest version is revision 1.2 which fixes some minor issues with a component in the board.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/Prototype.jpg" width="350" height="350"><br>
</center>
<center>
  <b>First prototype and tests before designing a proper board</b></center>


<p>The final, production-ready board contains a DAC (Digital to Analogue Converter) which turns the 10 bits digital signal at 16.7 MHz provided by the DS Lite into a proper analogue signal. This signal then goes through an operational amplifier and it’s ready to be delivered to your nearest TV trough composite video.</p>

<p>We are currently considering creating an additional PCB revision which would allow to install the mod on consoles without lossing a working upper screen.</p>


      </section>
    </div></div>]]>
            </description>
            <link>https://lostnintendohistory.github.io/DS-TV-OUT</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232600</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Bombard Story]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 36 (<a href="https://news.ycombinator.com/item?id=26232597">thread link</a>) | @jbergstroem
<br/>
February 22, 2021 | https://greatestadventurers.com/the-bombard-story/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-bombard-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-618" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Bombard Story</strong> is the account of <a href="https://en.wikipedia.org/wiki/Alain_Bombard">Alain Bombard’s</a> amazing journey in 1952 across the <a href="http://greatestadventurers.com/the-north-west-passage-by-roal-amundsen/">Atlantic</a> on a small 14-foot inflatable boat. Alain Bombard left without food or fresh water and sailed 4.400 kilometers. He lost 25 kg. but proved his point: Man can actually survive on ocean water for an extended period of time!</p>
<figure id="attachment_619" aria-describedby="caption-attachment-619"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" alt="The Bombard Story" width="300" height="203" data-src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-619">In this small vessel Bombard sailed across the Atlantic – without freshwater</figcaption></figure>
<p>As a doctor, Bombard was concerned about the hundreds of deaths at sea every year related to sailors drinking ocean water. He developed the theory that humans can not just survive but live for years on seawater. This sounds very strange, but his big idea was to begin drinking seawater, while you are still hydrated – and in small quantities. It turns out that saltwater is only dangerous if you are dehydrated and suddenly drink large amounts of it. – The way shipwrecked sailors typically would do when they run out of fresh water. From the book:</p>
<blockquote><p>For some time I had made a study of the resistance of the human organism to privations and had convinced myself that it was possible for an individual to survive beyond the limits normally assigned by physiological science. I had paid particular attention to the case histories of political deportees, prisoners, and undernourished populations. But, with my background as a doctor, for whom the teachings of science remain a dead letter unless they can find practical application, my theoretical studies only seemed to lead to the question: ‘What use can made of this knowledge?’</p></blockquote>
<p>Bombard ate spoonfuls of plankton that he collected in a fine net and he also drank juice made from pressed fish he caught along the way. Sound disgusting, but the man survived and he might have discovered an important piece of knowledge for survival on the ocean.</p>
<p>Download the free PDF e-book here (223 pages/38MB):</p>
<h3><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" alt="" width="35" height="35" data-src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">&nbsp;<a href="http://greatestadventurers.com/wp-content/uploads/2021/02/The-Bombard-Story-1953.pdf">The Bombard Story 1953</a></h3>

		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-bombard-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232597</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robert’s Rules Suck: Why We Can’t Make Change Until We Change the System]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26231837">thread link</a>) | @sep_field
<br/>
February 22, 2021 | https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f | <a href="https://web.archive.org/web/*/https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><h2 id="99a2">Why We Can’t Make Change Until We Change the System</h2><div><div><div><div><a href="https://martywilder-44820.medium.com/?source=post_page-----47b689f3c48f--------------------------------" rel="noopener"><div><p><img alt="Marty Wilder" src="https://miro.medium.com/fit/c/96/96/0*bbAuchMAUj_x330g" width="48" height="48"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Close up of a judge’s gavel on the block" src="https://miro.medium.com/max/19200/1*xqElYYwIds8NChYEdGxH7Q.jpeg" width="9600" height="5304" srcset="https://miro.medium.com/max/552/1*xqElYYwIds8NChYEdGxH7Q.jpeg 276w, https://miro.medium.com/max/1104/1*xqElYYwIds8NChYEdGxH7Q.jpeg 552w, https://miro.medium.com/max/1280/1*xqElYYwIds8NChYEdGxH7Q.jpeg 640w, https://miro.medium.com/max/1400/1*xqElYYwIds8NChYEdGxH7Q.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*xqElYYwIds8NChYEdGxH7Q.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@bill_oxford?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Bill Oxford</a> on <a href="https://unsplash.com/s/photos/gavel?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><h2 id="b772">Taking Action</h2><p id="0a32">I was ready to do more than take a knee or carry a cardboard sign. I felt like it was time for me to move beyond protesting and get involved, somehow, in creating change. That was why I joined an ad hoc committee formed by our city council to address police policy. Think global, act local. At last, I felt hope. I felt like maybe I can make a difference that matters. And then I faced reality, and was shocked by how bad it is.</p><p id="9857">I was not naïve going into this. I fully expected that whatever good policy change our committee was able to craft might be diluted or rejected by the city council in the end, or that the Police Chief might find ways to circumvent them, or that even if enacted, the police union would still allow officers who violate those policies to be exonerated. With that in mind, I stayed focused on the long haul. I wanted to craft strong and demanding policies that could become part of a list of demands to be relentlessly rallied before the city officials until they are adopted. I kept my eye on forming alliances with others on the committee that could grow into lasting coalitions. This committee, to me, was only the beginning.</p><p id="8c03">It looked promising. The city had called on 13 civic organizations representing BIPOC and other marginalized communities. I was there on behalf of a nonprofit that services transgender and gender non-conforming folx. There are 30 members, in all. As we went through brief introductions at the first meeting, I was encouraged. The committee is facilitated by a team of three individuals, including a Black woman who is the Equity &amp; Access Coordinator for the county. She and I conversed at the outset about the challenges of facilitating a group the size of ours over Zoom due to the pandemic. We talked about setting group agreements. We talked about equity over equality and elevating voices that were underprivileged, especially those of women of color. I mentioned the need to give each member enough of a platform to feel seen and recognized at the beginning, even though that would be a big time investment, because it would save time in the long run by deterring potential internal conflicts. I also expressed my opinion that we would need to work in smaller subcommittees in order to be effective.</p><h2 id="b7ce">Thwarted by the System</h2><p id="ff5a">But then we ran into two great obstacles; public meetings law and Robert’s Rules of Order. The first curtailed our ability to network and converse with each other on the committee. The second is an infuriating silencer that obstructs everything I have come to learn about good problem-solving and decision-making. I’ll start with public records law because that is more straightforward. The law states that we must have a quorum, in our case 16 or more, of members present at each meeting. Each meeting must be posted and publicly broadcast in real time. Since we were airing our meeting over Zoom due to the pandemic, the meetings are live streamed and recorded. But because the live stream and recording do not show the chat box, we cannot use that feature to communicate things like consent with what the active speaker is saying, or to ask clarifying questions. It all has to be voiced to be recorded. Furthermore, since only the Zoom hosts can see non-verbal signs, we cannot use the raised hands nor the Yes/No functions built into Zoom. Instead we have to wait the three to four minutes it takes for the host to read off each of the 30 names, wait for the person to unmute, and get a recorded response with a “yes”, “no”, or “abstain” for every motion we attempt to pass. We have yet to do this without someone in the middle asking for the motion to be restated. I don’t think there is anyone involved who is not finding this irritating, but everyone seems resigned to endure it.</p><p id="7e09">The worst aspect of the way the city is interpreting public records law is that they have instructed all of us not to communicate with each other as a group outside of the public meetings. Email correspondence, file sharing, and social media can all become violations of public records law. If there are 16 or more of us involved, or even if there is not a quorum but we are discussing content that affects decision-making, it all needs to be publicly broadcast. While I can understand the reasoning behind these stipulations, where does that leave us? We are 30 members of very diverse parts of our city, we don’t know each other very well, and many of us have never served on a committee like this before. How are we supposed to work together? We have been reduced, effectively, to responding in the moment. We cannot even use file sharing to look at and consider ideas or share resources except by going through the facilitation team.</p><p id="ed4b">The facilitation team has directed us to send all communication to them and they will disperse information to the committee. That would be fine, if it were simply a procedure to go through. But the facilitation team does not simply pass along information. They hold onto it, decide whether or not it is information that should or should not be shared, sometimes rewrite or re-position it, and pack everything into one overwhelming information packet that we receive on Friday night before a Monday meeting. One reason behind this is that all the documentation must also be publicly posted alongside the meeting announcement. It also consolidates things so that committee members do not get bogged down with frequent emails. The danger is in editing out or misconstruing some of our voices, often those that most need to be heard. Also, there is the disabling effect of leaving us inactive and unable to work productively in the two weeks between meetings. I find myself struggling to resist the idea that the facilitation team has an expected outcome for us, and they are guiding the committee to meet their expectations.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="A laptop computer showing a large group of faces of people conferencing on a Zoom call. A coffee mug sits beside the laptop." src="https://miro.medium.com/max/3840/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg" width="1920" height="1440" srcset="https://miro.medium.com/max/552/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 276w, https://miro.medium.com/max/1104/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 552w, https://miro.medium.com/max/1280/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 640w, https://miro.medium.com/max/1400/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@cwmonty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Chris Montgomery</a> on <a href="https://unsplash.com/s/photos/zoom-meeting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><h2 id="a8e4">Killing the Creativity</h2><p id="4127">Then we come to Robert’s Rules of Order. For those who are not familiar, this is a set of meeting protocols that dates back to before the Civil War. Basically, the facilitator calls on people to speak, one at a time, without interruptions for a given amount of time. In our meetings it is 3 minutes. When someone wants to propose a decision, they make a “motion”. Someone else must second that motion. Then the facilitator calls the vote. The motion, the person who presented it, the person who seconded it and the total numbers of votes: yes, no, and abstain, are all recorded. That’s it in a nutshell.</p><p id="9cee">What is missing from Robert’s Rules of Order is the magic of good problem-solving. There is no room for contained chaos, a free flow of energy, voices, and ideas. I taught engineering design in high schools for ten years. One of the most enjoyable, and innovatively genius, aspects of problem-solving is brainstorming. Brainstorming is meant to be messy. It’s a chance to air everything out and look at it from as many different angles as you can dream up. You start to notice patterns and connections. Someone poses something “crazy” and it piques your interest. Then there is this very important concept called “piling on.” Piling on happens when your idea sparks a new idea in my mind. I share my idea and that, in turn, sparks a new idea for someone else. This phase of problem-solving is divergent and for traditionalists, it goes against every fiber in their “we need to narrow this down” trajectory. But the traditional “narrowing down” linear approach leads to very limited and narrow solutions. Whereas, the creativity and mutual discovery of the brainstorming process culminates in a kind of magical synthesis of ideas and approaches. The team then needs to choose what approach they want to take. It might be evident in a general idea that rises up out of the chaos in a way that is unifying and electrifying, which leads to a much smoother process as you narrow in on the solution. Or you may see two or three different approaches that you either need to choose between as a group, or make a choice to split up and try all of them. Besides being a good way to get fresh and, at times, brilliant ideas, brainstorming also results in better teamwork because everyone was able to contribute fully and feel seen, heard, and involved.</p><p id="5d12">But the public meeting format has no room for that. We can’t even utilize Zoom break-out groups because the public would need to see all of the break-out groups simultaneously. Here is where it becomes de-humanizing to me. There is no place to <em>form</em> ideas in the public meeting. Members are expected to <em>bring</em> ideas, pre-fabricated, and see how they hold up to a vote. I used to function like that, bringing my ideas to the table in a battle for the best articulated argument to slay all others and take the lead. Then I studied feminism. When you value the people and the process, everything changes. It’s no longer a contest to see who has the best idea. It becomes about the whole, all of us together as a group, facing a problem and learning from each other as we go. I don’t want to presume to bring a solution that will address everyone’s needs. I want to hear from others and I want my thoughts to be affected by those stories. I want our collective ideas to <em>become</em> as we meet. What if our government were like that? What if the premise was that no one has the answer going in, but if we all bring our perspectives together and listen to one another, the answer will take form out of the collective whole? I know. It sounds ludicrous given the extreme partisan attacks that happen all the time in our current system. But once you have experienced this kind of collective solution-making even on a small scale; it can make you a believer.</p><h2 id="778c">White Supremacy Playbook</h2><p id="1307">Robert’s Rules of Order and the general meeting protocols really do fall right in line with what we know about white supremacist culture. What I mean by this is that we value this methodology and purport …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f">https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f</a></em></p>]]>
            </description>
            <link>https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231837</guid>
            <pubDate>Mon, 22 Feb 2021 22:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Retrospective Look at Mac OS X Snow Leopard]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 98 (<a href="https://news.ycombinator.com/item?id=26231212">thread link</a>) | @NaOH
<br/>
February 22, 2021 | http://morrick.me/archives/9220 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9220">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h2>Introduction</h2>
<p>My recent article, <a href="http://morrick.me/archives/9150"><em>The reshaped Mac experience</em></a>, received a lot of attention judging from the response on Twitter and the WordPress analytics — apparently, among other places, it reached Hacker News and Reddit. Unlike my four-part series&nbsp;<em>‌Mac OS Catalina: more trouble than it’s worth</em>, however, it didn’t attract any hate mail at all. The sheer majority of feedback I received was very positive, with many many people agreeing with me and my observations. A few — some provocatively, some genuinely curious — asked me something along the lines of, <em>Well, if you dislike the current Big Sur UI and Mac experience, what’s an example of Mac OS UI and experience you DO&nbsp;like?</em></p>
<p>It’s a more than fair question, and this piece serves as an answer. When I wrote back to those who asked me, I replied <em>Mac OS X 10.6 Snow Leopard</em>. It was sort of a gut-reply based largely on fond memories of using that Mac OS version quite extensively.</p>
<p>When I purchased my 15-inch MacBook Pro in July 2009, it came with Mac OS X 10.5.7 (Leopard), but I immediately upgraded to Snow Leopard when it was released a month or so afterwards. As you know (and if you don’t, here’s a refresher), together with Mac OS X 10.4 Tiger, Snow Leopard was one of the Mac OS versions with the longest lifespan — almost two years, from August 2009 to July 2011, when the final 10.6.8 v1.1 minor release came out. On my 2009 MacBook Pro, I kept using it until mid-2012, as Mac OS X 10.7 Lion (released in July 2011) didn’t fully convince me at first, so I waited until at least version 10.7.3 before upgrading.</p>
<p>So, I used Snow Leopard on my 2009 MacBook Pro for about three years, and then again on a 2010 Mac mini that a friend gave me to maintain, as a sort of offsite backup. That Mac mini was kept on Mac OS X 10.6.8 for the whole four years it was in my custody (2011–2015) and it was switched off only twice during that period and maybe restarted four or five times in total. It enjoyed an insane uptime and it was a testament to Snow Leopard’s stability.</p>
<p>But back to my ‘gut-reply’, I wanted to be certain that my fond memories of Snow Leopard weren’t just nostalgia. While I am confident when I say that Snow Leopard is the most stable version of Mac OS, I wanted to make sure its user interface was really the good user interface and experience I was remembering. So, after a few frustrating attempts at creating a virtual machine on my current iMac with Mac OS High Sierra, I decided to install Snow Leopard on a USB flash drive, and boot my 2009 MacBook Pro (yes, it’s still alive <span>&amp;</span> kicking) in Snow Leopard from that flash&nbsp;drive.</p>
<h2>Installation</h2>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=960%2C1280" alt="" width="960" height="1280" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?w=1512 1512w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=260%2C347 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=640%2C853 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=768%2C1024 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=1152%2C1536 1152w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=1194%2C1592 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=960%2C720" alt="" width="960" height="720" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?w=2016 2016w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=260%2C195 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=640%2C480 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=768%2C576 768w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=1536%2C1152 1536w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=1194%2C896 1194w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a><br>
<em>Ah, When Mac OS welcomed you after the installation process was complete…</em></p>
<p>Since the MacBook Pro doesn’t have an optical drive anymore, I had to create a bootable USB flash drive from my original Snow Leopard DVD Installer. The fastest method is to use Disk Utility — rather, an older version of Disk Utility, from a time when this application was <em>really</em> a utility, and you could use the Restore feature <em>reliably</em> to clone the bootable DVD to (in this case) an external volume.</p>
<p>From a bootable USB flash drive to another USB flash drive, installation was relatively fast, about 20–25 minutes. Although I would have preferred an external SSD for the speed, I must say that using Snow Leopard from the flash drive is a breeze nonetheless. The system is responsive and I haven’t noticed any particular lags.</p>
<h2>User interface</h2>
<p>Now let’s examine just a few aspects of Snow Leopard’s user interface — just like I did for Big Sur in my logbook — and draw comparisons with Big Sur’s interface.</p>
<h3>The menu&nbsp;bar</h3>
<p>Back in August 2020 when I started testing the first Big Sur beta versions, <a href="http://morrick.me/archives/8954">I wrote in my Big Sur logbook</a>:</p>
<blockquote><p>In Big Sur, the menu bar by default isn’t solid white, but has a noticeable degree of transparency: it takes the colour of the desktop wallpaper behind it, in an attempt to blend in with the rest of the desktop environment. Some may consider this sleek, but it’s just gimmicky and usability-hostile.</p>
<p>What happens when the desktop wallpaper has darker colours? Well, menu items and menu bar icons become white, of course. The problem is that the wallpaper doesn’t have to be too&nbsp;dark.</p></blockquote>
<p>In other words, when Big Sur decides that the desktop background image is dark enough, text and icons on the menu bar become white. The problem is that there are cases where the background colour simply <em>isn’t</em> dark enough to warrant a change from black text and icons to white text and icons. Consequently, the contrast is too poor. The only option for better usability is to select <em>Reduce transparency</em> in <em>System Preferences</em> → <em>Accessibility</em>. This brings the menu bar back to a useful state, solid white with black elements.</p>
<p>In Snow Leopard, the menu bar has transparency set to <em>on</em> by default, but it’s definitely more subtle, even with darker desktop backgrounds:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=960%2C500" alt="" width="960" height="500" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?w=1440 1440w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=260%2C135 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=640%2C333 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=768%2C400 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=1194%2C622 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p><em>In the top image, menu bar transparency is off; in the bottom image, transparency is on. The difference is almost negligible.</em></p>
<p>Only with certain background images that contain dark and light areas starkly juxtaposed can menu bar transparency become a bit of an issue under Snow Leopard, but that is partly mitigated by the visible drop shadow beneath the menu bar itself, which helps to make the menu bar stand out&nbsp;more:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=960%2C672" alt="" width="960" height="672" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?w=1000 1000w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=260%2C182 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=640%2C448 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=768%2C538 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>Contrast, even in these conditions, tends to be more tolerable than in Big Sur, at least for my eyes. And in any case, in Snow Leopard you can quickly turn off transparency right in <em>System Preferences</em> → <em>Desktop <span>&amp;</span> Screen Saver:</em></p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=748%2C658" alt="" width="748" height="658" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?w=748 748w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=260%2C229 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=640%2C563 640w" sizes="(max-width: 748px) 100vw, 748px" data-recalc-dims="1"></a></p>
<p><em>I’ve been talking about ‘transparency’, whereas it’s actually ‘translucency’ — at least in Snow Leopard.</em></p>
<h3>Finder windows</h3>
<p>In Snow Leopard, Finder windows are essentially perfect from a user interface standpoint.</p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a></p>
<p>When I shared this over Twitter, Mario Guzmán <a href="https://twitter.com/MarioGuzman/status/1360651998358425601?s=20">observed</a> that <em>Things are nicely compartmentalized by color. You can distinctly tell each section of the window (even the damn scroll bars)… it’s not just one blob of white with grey symbols.</em></p>
<p>Exactly this. The window has clearly distinguishable areas: the <em>Title bar</em> (with the semaphore controls at the top left of the window, and the sidebar+toolbar show/hide toggle button at the top right), the <em>Toolbar</em>, the <em>Sidebar</em> (with colourful icons helping you quickly and easily locate items at a glance), the <em>Path bar</em>, the <em>Status bar</em>, and finally the <em>scroll bars</em> which are always visible.</p>
<p>Persistent up/down arrows and scroll bars are the right thing to do, usability-wise, and it is such a user-friendly design. The length of the ‘aqua blue’ bar immediately gives you an idea of how populated that folder you just opened is going to be. Further, if you need to rapidly scroll down, you just grab the bar with the mouse pointer and scroll.</p>
<p>In later Mac OS versions, scroll bars are set by default to appear only based on mouse/trackpad movement, which is a pity; many users probably don’t realise they can have scroll bars appear permanently, so they don’t have to time the mouseover action for the scroll bar to appear and then <em>hope</em> they’ll manage to grab it when they want to quickly scroll down a long list of elements.</p>
<p>I am once again reminded of that infamous quote by Alan Dye (Apple’s VP of Human Interface) from WWDC 2020, speaking of Big Sur’s UI redesign:&nbsp;<em>‌We’ve reduced visual complexity to keep the focus on users’ content. Buttons and controls appear when you need them, and they recede when you don’t.</em> I still believe this is not a good approach in general, and especially for essential elements like scroll bars, which should always be visible by default, because they are UI elements whose usefulness isn’t limited to when you use them or interact with them — they signal something even when not strictly needed. In the case of the scroll bars it’s a visual estimate of how many elements a folder contains, how long a list of items is, and more importantly <em>your current position</em> when scrolling.</p>
<p>Back to Finder windows, here’s an “Apple’s attention to detail” detail: notice that icon in the bottom left of the window? It is a subtle visual cue that tells you if Finder icons (items) are sorted, unsorted, or simply snapped to a grid. When opening windows from read-only volumes, the icon of a crossed-out pencil appears here, meaning that you can’t modify the enclosed items or write to that volume.</p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are unsorted (Arranged by: None) — No icon in the bottom left corner</em></p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are sorted (by name, size, kind,&nbsp;etc.)</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?w=850 850w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=260%2C171 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=640%2C420 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are snapped to&nbsp;grid</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=752%2C521" alt="" width="752" height="521" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?w=752 752w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=260%2C180 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=640%2C443 640w" sizes="(max-width: 752px) 100vw, 752px" data-recalc-dims="1"></a><br>
<em>Window from a read-only volume</em></p>
<p>While I don’t find this UI detail to be crucial, it is certainly nice to have, and an example of those little things that contributed to make the Mac’s interface great. As I said above, it reflected a certain attention to detail and overall thoughtfulness I’ve seen progressively fade away in later Mac OS releases.</p>
<h2>A look back at a few system apps, with occasional UI comparisons between Snow Leopard and Big&nbsp;Sur</h2>
<h3>Safari</h3>
<p>5.1.10 was the last version of Safari running on Mac OS X 10.6.8. Here are a few things I still prefer over the current Safari:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=845%2C92" alt="" width="845" height="92" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?w=845 845w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=260%2C28 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=640%2C70 640w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=768%2C84 768w" sizes="(max-width: 845px) 100vw, 845px" data-recalc-dims="1"></a><br>
<em>The blue progress bar</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=852%2C100" alt="" width="852" height="100" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?w=852 852w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=260%2C31 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=640%2C75 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=768%2C90 768w" sizes="(max-width: 852px) 100vw, 852px" data-recalc-dims="1"></a><br>
<em>The RSS button (you could read RSS feeds with Safari)</em></p>
<p>Another detail I very much prefer in the older Safari over more recent versions of Safari is how the plus [+] button near the address bar works. Its placement makes its function rather unequivocal: <em>Add the current page to something</em>. As usual, tooltips are helpful:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?resize=562%2C92" alt="" width="562" height="92" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?w=562 562w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?resize=260%2C43 260w" sizes="(max-width: 562px) 100vw, 562px" data-recalc-dims="1"></a></p>
<p>But what if I want to add this page to my Reading List? No worries, when you actually press the [+], a thoughtfully-designed sheet comes down, and you can put the current page exactly where you want: in your Reading List, in the Top Sites, or in your Bookmarks.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=960%2C267" alt="" width="960" height="267" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?w=1005 1005w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=260%2C72 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=640%2C178 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=768%2C213 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>The other plus button, to open a new browser tab, is placed in such an obvious spot that you know what it does without even waiting for the tooltip to appear:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=960%2C110" alt="" width="960" height="110" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?w=1374 1374w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=260%2C30 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=640%2C73 640w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=768%2C88 768w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=1194%2C136 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>Now, let’s take a quick look at the UI in Big Sur’s Safari:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=960%2C59" alt="" width="960" height="59" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=260%2C16 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=640%2C40 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=768%2C47 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=1536%2C95 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=2048%2C126 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=1194%2C74 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>At first glance, there’s only one plus button in the app’s chrome. Try to look at this UI with fresh eyes and guess …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9220">http://morrick.me/archives/9220</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9220</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231212</guid>
            <pubDate>Mon, 22 Feb 2021 21:57:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anti-Solar Panels May Generate Power at Night Soon]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26229635">thread link</a>) | @elorant
<br/>
February 22, 2021 | https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/ | <a href="https://web.archive.org/web/*/https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><article id="post-2010"><p><a href="https://robologiclab.com/wp-content/uploads/2021/02/Untitled-design-14.png"><img width="800" height="445" src="https://i0.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-14.png?resize=800%2C445&amp;ssl=1" alt="Anti-solar panels that can work round the clock!" loading="lazy"></a></p><div><div><p>Have anyone told you that a solar panel can be operational at the night? This might sound like an unrealistic tech. However, it is possible and in the future, we can see solar panels working at night also. The University of California (UC), Davis scientists are inventing a prototype for an ‘anti-solar panels’ that would work opposite to a classic solar panel. The new studies suggest that it is possible that such panels could work round the clock.</p><p><br>These anti-solar panels can produce a quarter of the energy they generate throughout the day under ideal conditions. The scientist reveals the requirement to combine thermoradiative panels that could produce energy on account of radiative cooling. In radiative cooling due to thermal radiation, a body dissipates out its heat. The thermoradiative cells are used for the experiment for manufacturing. After that, they transfigure the heat into electricity.</p><figure><img loading="lazy" width="800" height="391" src="https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=800%2C391&amp;ssl=1" alt="anti-solar panels installed on building" srcset="https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?w=1024&amp;ssl=1 1024w, https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=300%2C146&amp;ssl=1 300w, https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=768%2C375&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1"></figure><h3>Research Behind Anti-Solar Panels</h3><p>ACS Photonics publication has published a research paper. In this paper, the scientists have revealed how they developed the anti-solar cells. Which perform their function of radiative cooling. Some engineers from UC states were puzzled concerning what would be the result if they installed one of the solar panels in a warm area, and pointed it towards the sky. It tends to concentrate on visible light to give rise to efficacious cells that could use the night sky and space as a heat sink. Jeremy Munday, an electrical and computer engineer from UC states mention that physics was identical in both the tech, only the materials are varying.</p><p><br>However this technology is in its initial phases, the team is in the middle of developing prototypes. The important point about this research is, it can be made economical to hold solar panels functional for a day. Last but not the least, according to scientists the enigmatic space is an interesting, comparatively unexplored area. However, it can assist and deliver electrical power at night and day with the proper utilization of materials science, optics, and photonics.</p><p><br>Hope you all like it, please share your valuable views about this tech in the comment section. Thank you for reading this!</p></div></div></article></div></div>]]>
            </description>
            <link>https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229635</guid>
            <pubDate>Mon, 22 Feb 2021 19:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People Who Wear Spectacles Are About Three Times Less Likely to Catch Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26228823">thread link</a>) | @throwawaysea
<br/>
February 22, 2021 | https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744 | <a href="https://web.archive.org/web/*/https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody" id="v_main"><p>A new study has revealed that people who wear glasses are up to three times less likely to catch novel Coronavirus infections. It was found that the eye protection was "statistically significant" to fight against the SARS-CoV-2 caused disease, COVID-19.</p><p>The study, which was also conducted in India, showed that poor and uneducated people were more likely to contract the novel Coronavirus. According to the research, this was because "they do not follow the preventive guidelines properly" and useless spectacles than the educated people.</p>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 1024px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 768px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i47011" src="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640" alt="Spectacles " title="Spectacles " width="640" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/47011/spectacles.jpg"><meta itemprop="width" content="640"><meta itemprop="height" content="427">
<figcaption>
<span itemprop="caption">Glasses wearers up to three times less likely to catch Covid</span>
<span itemprop="copyrightHolder">Pixabay</span>
</figcaption></div>
</figure><h3><strong>Spectacles and COVID-19</strong></h3><p>The research head, Amit Kumar Saxena, said the new study showed that the risk of <a href="https://www.ibtimes.sg/new-traffic-signal-lookalike-technology-could-help-reopen-international-airports-safely-55731" target="_blank">COVID-19</a> was two to three times less in spectacles wearing population while compared to those who do not wear glasses.</p><p>"Protective role of the spectacles was found statistically significant if those were used for a long period of the day. Touching and rubbing of the eyes with contaminated hands may be a significant route of infection," added Saxena.</p><p>During the study, it was also found that people touch their face on average 23 times in an hour and the eyes three times per hour. "Transmission occurs by touching the face, nose, mouth and eyes. Touching one's nose and mouth is significantly reduced when wearing a face mask properly. But wearing a face mask does not protect the eyes," said the study.</p><h3><strong>The COVID-19 Research</strong></h3>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 1024px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 768px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i45807" src="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640" alt="Coronavirus " title="Coronavirus " width="640" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg"><meta itemprop="width" content="640"><meta itemprop="height" content="360">
<figcaption>
<span itemprop="caption">Novel Coronavirus infection</span>
<span itemprop="copyrightHolder">Pixabay</span>
</figcaption></div>
</figure><p>The study, which was published in <a href="https://www.medrxiv.org/content/10.1101/2021.02.12.21249710v1" rel="nofollow" target="_blank">medRxiv</a>, included 304 Coronavirus patients. Their glasses-wearing behavior was assessed through a questionnaire. The answers were compared with existing studies of the general population.</p><p>As per the findings of the study, a total of 58 patients showed the behavior of using glasses continuously during the daytime and always on outdoor activities. The risk of Coronavirus infection was found 0.48 in spectacles wearing population as compared to 1.35 in the population not using them.</p><p>"The calculated risk ratio was 0.36. The protective effects of the spectacles were found statistically significant," said the study.</p><p>However, based on the findings it would be ideal for the healthcare workers to use face shields and wear goggles to protect their eyes while treating a <a href="https://www.ibtimes.sg/john-hopkins-expert-predicts-end-coronavirus-sufferings-by-april-us-55730" target="_blank">COVID-19 patient</a>. Scientists also said that wearing glasses does not protect the eyes as much as googles but it could provide some sort of protection.</p></div></div>]]>
            </description>
            <link>https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228823</guid>
            <pubDate>Mon, 22 Feb 2021 18:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking the IDE for the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26227466">thread link</a>) | @fsynced
<br/>
February 22, 2021 | https://movingfulcrum.com/rethinking-the-ide-for-2020s/ | <a href="https://web.archive.org/web/*/https://movingfulcrum.com/rethinking-the-ide-for-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    
    


    <div id="ajax-container">
        
<div>
<article>
    

    <div>

        <p>Intellij IDEA has been an amazing professional-grade IDE for the last 20 years. However, as computer programs evolve, so must the IDE keep pace to remain a useful tool.</p><figure><blockquote><div lang="en" dir="ltr"><p>major IDE evolutions as I see:</p><p>2000s: using AST to represent text and building features around that. Intellij nailed this.</p><p>2010s: doing the same, but polyglot. Again Jetbrain's suite of IDEs adopted well in time.</p><p>2020s: support massive codebases across huge number of projects</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1337817841567899649?ref_src=twsrc%5Etfw">December 12, 2020</a></blockquote>

</figure><h3 id="what-s-changed">What's Changed?</h3><p>A typical organization in the 2020s has:</p><ol><li>Hundreds of microservices</li><li>Hundreds of git repos</li><li>Polyglot codebase</li><li>APIs defined with HTTP/JSON/GRPC, not just programming language interfaces</li><li>Runtime service inter-dependencies</li><li>Cloud service dependencies</li></ol><p>Let's go through how each of these could impact the design of the IDE of the future. I will be using Intellij for comparison since it's the most advanced IDE currently.</p><h3 id="big-code-is-the-new-big-data">Big Code is the new Big Data</h3><p>With huge amounts of code across hundreds or even thousands of repos, the IDE has to now deal with 'Big Code'. It's big not just due to the sheer lines of code. It's the fact that it's divided into microservices, each of which has a separate set of dependencies, which the IDE now has to separately index. This can exponentially increase the amount of code to index compared to a single large codebase without so many external dependencies like the Linux kernel.</p><p>All operations in the IDE must assume huge amounts of code across hundreds of repositories, not all of them might be checked out locally. So things like Refactoring, Find Usages, Call hierarchy, etc have to be re-architected to run as long-running operations over code that could be both local or remote and still give users a seamless experience.</p><h3 id="refactoring">Refactoring</h3><p>Refactoring so far has really been a single repo feature. But what if the code you are refactoring is called by code in 100 other repos in your organization? What if those repos are not even checked out locally? The modern IDE needs to evolve beyond single repo operations. Maybe that rename refactoring now becomes a long-running operation that creates Pull Requests in various repos. This is not an easy problem to solve. Google even has a paper on this:</p><figure><blockquote><p lang="en" dir="ltr">Yes and in large monorepos refactoring involves mapreduce operations <a href="https://t.co/yc92gX1qem">https://t.co/yc92gX1qem</a></p>— Nagesh Susarla (@nageshs) <a href="https://twitter.com/nageshs/status/1337843676324589568?ref_src=twsrc%5Etfw">December 12, 2020</a></blockquote>

</figure><p>The complexity grows as API calls happen across services in various languages now and use HTTP/JSON or GRPC/ProtoBuf. Renaming a <code>struct</code> in one repo that gets serialized to JSON during an http api call might require renaming a similar <code>struct</code> in a whole different language that deserializes said JSON. This is way more complex than a simple Java function rename refactoring.</p><h3 id="version-control-ui">Version Control UI</h3><p>Version Control features in IDEs are really built around browsing/editing one git repo at a time. This simply doesn't work when your codebase is spread across hundreds of repos. The fundamental interface for the Git UI in Intellij (and other IDEs) needs to be rethought to deal with a large number of repos.</p><figure><blockquote><p lang="en" dir="ltr">The Git Log view in <a href="https://twitter.com/intellijidea?ref_src=twsrc%5Etfw">@intellijidea</a> is poorly designed with respect to multiple repositories. You need to use the mouse to get to this dropdown list in the view. Then you need to first *deselect* the current repo and select your new repo. <br>Dont think this was dogfooded by the devs. <a href="https://t.co/lZ0YHdrUth">pic.twitter.com/lZ0YHdrUth</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1349137311619981312?ref_src=twsrc%5Etfw">January 12, 2021</a></blockquote>

</figure><h3 id="rethinking-the-project-model">Rethinking the 'Project' model</h3><p>Currently, an <a href="http://astradot.com/">Astradot</a> engineer has to check out a git repo, eg <a href="https://github.com/astradot/kafka-schema-sync">https://github.com/astradot/kafka-schema-sync</a>, open the IDE, point to it, which will create an Intellij 'project' for the repo or a 'module' for an existing project. This is backward. The IDE should ask for the Github org eg, <a href="http://github.com/org">github.com/astradot</a> and it should create a single project that contains all the repo as modules. It should then manage lazy-loading/lazy-checkout or whatever is needed to give me a seamless experience browsing the code of my entire org.</p><h3 id="-run-button">'Run' button</h3><p>The 'Run' button will need to have more intelligence than simply running your app. In a microservice world, your service might depend upon an 'auth' service which might require a Postgres database and Redis instance initialized to some state. The services may rely on k8s service names to communicate, thus requiring running inside k8s. The IDE will need to be aware of the environment where you want to run your services and initialize the dependencies appropriately when you hit the 'Run' button.</p><p>The traditional debugger though is not going anywhere anytime soon. Take that from a guy who wrote a <a href="https://www.youtube.com/watch?v=LpfmKIxusZY">time-traveling one</a>, once upon a time. Though IDEs could take a page from APMs and benefit from showing a distributed trace in addition to breakpoint-based debugging.</p><h3 id="what-s-not-the-future">What's not the future</h3><p>Silicon Valley has been obsessed with making 'IDE in the Cloud' happen for the last decade. Every year a new set of cloud IDE startups is funded while the old ones die off. None of the problems they are solving help professional engineers.</p><figure><blockquote><div lang="en" dir="ltr"><p>Annual IDE startup bingo card:</p><p>- Downgrade 'IDE' part from Intellij to VSCode but hey, it opens in browser!</p><p>- See every keystroke of other engineers - 'Collaboration/Live coding'</p><p>- Code runs in tiny ec2 instance with horsepower of 90s laptop instead of your 12 core AMD pc</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1363206351128723457?ref_src=twsrc%5Etfw">February 20, 2021</a></blockquote>

</figure><p>From an <a href="http://astradot.com/">Astradot</a> engineer's perspective:</p><ul><li>Downloading and Installing Intellij is a non-issue</li><li>We have scripts to setup your workstation environment within minutes with all the needed compilers, tooling, etc.</li><li>We never need to see each other live code. That would be annoying/intruding on the other engineer's privacy.</li><li>Workstations are powerful enough that they can run the entire <a href="http://astradot.com/">Astradot</a> locally.</li></ul><p>We would love to buy all our engineers 64 core Threadrippers w 128Gb ram if the IDE could make use of it.</p><h3 id="conclusion">Conclusion</h3><p>The IDE of the future is very different from what Intellij is today, both in terms of its architecture and UI. It requires solving some hard computer science problems. Jetbrains seems more focused on making just evolutionary changes to its IDEs to keep it ahead of VS Code. This is an opportunity for a new startup to rise.</p>
    </div>

    
</article></div>
    </div>
</div></div>]]>
            </description>
            <link>https://movingfulcrum.com/rethinking-the-ide-for-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227466</guid>
            <pubDate>Mon, 22 Feb 2021 17:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Living Like It's 99: No Social Media, No Smartphone]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 150 (<a href="https://news.ycombinator.com/item?id=26226864">thread link</a>) | @betaman0
<br/>
February 22, 2021 | https://www.alvarez.io/posts/living-like-it-s-99/ | <a href="https://web.archive.org/web/*/https://www.alvarez.io/posts/living-like-it-s-99/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><img src="https://www.alvarez.io/img/color/l99.jpg" alt="Robot"></p>
<p>At the time of writing this article, I’ve been living without social media for 3 years and without a smartphone for 2 years. Everything started as an experiment motivated by my privacy concerns. I ended up living like that for an entire different reason: peace of mind. You can find a lot of people on internet that have tried this experiment, from a couple of days to an <a href="https://www.youtube.com/watch?v=B0RVWU_nROk">entire month</a>. However I discovered that the brain dependencies created by social media and smartphones take a lot longer to go away (30 days for me). You can’t really see the effects it has on your life unless you try this kind of experiment for a long time, because you will be stuck in the withdrawal phase that makes you crave dopamine.</p>
<p>Contrary to popular belief, I do not live in a cave where I spend my time coding without any social life, sorry guys ;) I did this experiment while having a busy professional and personal life: I traveled around the world, moved to a new city without knowing anyone, ran <a href="https://www.duple.io/">my own software startup</a>, met new people and made new friends, etc… So it is possible to live your life the same way, or even better, without a smartphone or social media.</p>
<p>I will share with you my experience leaving social media and my smartphone, the tools I replaced them with, some tips and tricks, people’s reactions to my experiment, as well as some funny anecdotes.</p>
<h2 id="lets-start-with-why">Let’s Start With Why</h2>
<h3 id="privacy">Privacy</h3>
<p>The original motivation behind this experiment was privacy. I’m a professional hacker, the things I can do are scary and I’m far from being the only one with these skills. <strong>Smartphones are a dream come true for people like me, little spy devices that are 24/7 on you, remotely accessible from anywhere around the world</strong>. Throw social media into the equation, and you can get inside the head of anybody, and make them do whatever you want. Yes, you should be scared. And that’s even without mentioning all the other <a href="https://lithub.com/what-does-privacy-really-mean-under-surveillance-capitalism/">privacy</a> and <a href="https://the.ink/p/we-can-have-democracy-or-we-can-have">freedom</a> issues that come with <a href="https://techcrunch.com/2019/09/04/facebook-phone-numbers-exposed/">social media</a> and <a href="https://nrkbeta.no/2020/12/03/my-phone-was-spying-on-me-so-i-tracked-down-the-surveillants/">smartphones</a>.</p>
<h3 id="curiosity">Curiosity</h3>
<p>Another reason, which is less dark, was curiosity. I like to experiment and try new things in my life. I was curious about the idea of living without a smartphone and social media especially in a world more connected than ever. And if I didn’t like the experiment, I could always go back to <a href="https://www.meta-nomad.net/avoiding-the-global-lobotomy/">zombieland</a>.</p>
<h3 id="planned-obsolescence">Planned Obsolescence</h3>
<p>The cherry on top was to stop paying each year for a new smartphone, that does nothing more than the previous one, just because the providers decided to <a href="https://en.wikipedia.org/wiki/Planned_obsolescence">sabotage old models</a> so they <a href="https://en.wikipedia.org/wiki/Batterygate">stop working</a>.</p>
<h3 id="peace-of-mind">Peace of mind</h3>
<p>This is for me the most important reason (even though I discovered it afterwards). The positive effects on your mind, being free from social media and smartphones, are incredible. More on it later.</p>

<blockquote>
<p>“Technology has solved old economics problems by giving us new psychological problems.”<br>
Mark Manson, The Subtle Art of Not Giving a F*ck</p>
</blockquote>
<p>In 2018 I deleted my accounts from Twitter, Facebook, Instagram and WhatsApp. No coming back, no temptation to reactivate them later on. I kept LinkedIn on standby for professional use although it came close to being deleted as well. WhatsApp got replaced by <a href="https://signal.org/">Signal</a> because Facebook bought them, plus <a href="https://www.forbes.com/sites/parmyolson/2018/09/26/exclusive-whatsapp-cofounder-brian-acton-gives-the-inside-story-on-deletefacebook-and-why-he-left-850-million-behind/">they’re not really big fan s of privacy</a>.</p>
<p>During that year I kept my smartphone, as I wanted to do the experiment gradually. This decision allowed me to discover something quite counter intuitive about social media and smartphones (more on it later).</p>
<p>From that point on I was reachable by SMS, call, email and Signal. I wasn’t ready for what happened next. Fasten your seatbelts.</p>
<h3 id="people-thought-i-was-dead">People Thought I Was Dead</h3>
<p>The first reaction people had was to think something bad had happened to me, some of them even thought I was dead. Then something socially curious happened: everybody started speaking to each other on Facebook and WhatsApp to try to figure out what was wrong. Some of them even contacted my family multiple times. They all had my phone number, email address and other ways of contacting me. <strong>However, none of them did</strong>. It was like I had exited the matrix, and was living in another reality.</p>
<h3 id="trustworthiness">Trustworthiness</h3>
<p>I was told that I couldn’t be trusted since people can’t check online what I’m doing when I’m not around.</p>
<p>Yeah, you read that right.</p>
<p><strong>Society has been brainwashed to believe that privacy is something criminal. Sorry to disappoint, but privacy is a basic fundament of freedom and democracy. That’s why the voting system is anonymous</strong> [1]. When people tell you “<a href="https://write.privacytools.io/freddy/why-privacy-matters-even-if-you-have-nothing-to-hide">If you have nothing to hide, you have nothing to fear</a>”, what they really mean is “democracy is overrated, get over it”.</p>
<p><em>[1] Privacy: you know who I am but not what I do. Anonymity: You know what I do but not who I am. The voting system uses both, privacy when you go vote, anonymity when they count the results.</em></p>
<h3 id="whatsapp">WhatsApp</h3>
<p>This was for me the biggest problem. <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">Getting people out of WhatsApp</a> if they wanted to talk to me created a lot of friction. Some of them even stopped texting me because they had to open another app on their phone in order to write to me.</p>
<p>Yeah, you also read that right.</p>
<p>I don’t miss WhatsApp, nor do I miss its endless group talks without anything useful. If you leave one of these groups people look at you as if you did something wrong. In the end I still had access to all the event’s information I needed despite them being organized on WhatsApp. In regards to this, not having the app didn’t change my life much.</p>
<p>A trick I’ve developed, when giving my contact info to new people, is to enter my phone number on their smartphone myself, and install Signal for them. This removed a lot of friction. I would then explain my experiment to them and tell them I can only be contacted via this app. I’ve always had a positive reaction. Everybody’s been curious and asking a lot of questions.</p>
<h3 id="and-then-nothing-happened">And Then Nothing Happened</h3>
<p>During the first weeks without social media, I felt off. As if I was missing out on something big that was happening. Like everybody was having fun except me. Once the <a href="https://joshcsimmons.com/quit-social-media/">withdrawal phase</a> went away, I realized that my life hadn’t changed that much. I was still doing the same things, talking to the same people, going to the same parties, etc… It was just more quiet and peaceful.</p>
<p><strong>I was no longer bombarded with pictures of everybody trying to fake a life they’re not living for the sole purpose of impressing someone else: <a href="https://hbr.org/2017/04/a-new-more-rigorous-study-confirms-the-more-you-use-facebook-the-worse-you-feel">my life had just upgraded</a>.</strong></p>
<p>In the end, after everybody got over their initial shock and calmed down, it became normal for them to contact me using Signal, and life went on as usual.</p>
<h2 id="round-2-goodbye-smartphone">Round 2: Goodbye Smartphone</h2>
<p><img src="https://www.alvarez.io/img/color/l99-2.jpg" alt="Phone"></p>
<p>Unlike social media, smartphones are a lot harder to get rid off. They handle many more things than just simply communicating with people.  I work all day long with a computer, most of what the smartphone was doing could be handled by my laptop. For the rest, I narrowed down my bare essential to Music, Pictures, GPS navigation and of course GSM calls.</p>
<h3 id="the-hardware">The Hardware</h3>
<p>You could solve these problems quite easily using multiple devices, however I wanted to be smart about it and not walk around with a luggage just to carry around all this stuff. After doing some research I figured out the perfect combination and I was even able to reduce the amount of things I had in my pockets.</p>

			</div></div>]]>
            </description>
            <link>https://www.alvarez.io/posts/living-like-it-s-99/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226864</guid>
            <pubDate>Mon, 22 Feb 2021 17:02:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's ok to take a walk without headphones]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 59 (<a href="https://news.ycombinator.com/item?id=26226862">thread link</a>) | @khehy
<br/>
February 22, 2021 | https://radreads.co/telic/ | <a href="https://web.archive.org/web/*/https://radreads.co/telic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 itemprop="name"><span itemprop="dateCreated">20 Feb<meta itemprop="interactionCount" content="UserComments: 0"></span> It’s ok to take a walk without headphones</h2><p>The Big Sur MacOS update delivers a delightful <em>Easter Egg</em>.</p><p>Your AirPods now magically follow you across devices. Gone are the awkward transitions (“hold on, let me connect my AirPods”) while fiddling with your Bluetooth settings and pressing that random button on the white case.</p><p>Now you can gracefully glide from podcast, to Zoom call, to Discover Weekly, to Clubhouse, to audiobooks while enlisting Siri’s help. <strong>Seamlessly and without interruption.</strong></p><p>Yet it turns out that our headphones have been following us for much longer than a MacOS update.</p><div><figure><img src="https://i.insider.com/5273e2a669bedd7c06afe99f?width=1100&amp;format=jpeg&amp;auto=webp" alt="Image result for original ipod add" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div><p>Remember that original promise <strong>“1,000 songs in your Pocket?”</strong> <em>That was 20 years ago.</em></p><p><strong>“All of humanity’s problems stem from man’s inability to sit quietly in a room alone,”</strong> wrote the 17th century philosopher Blaise Pascal. Yet thanks to these white little earbuds, we never need to spend that quiet time alone.</p><hr><p>Do all of life’s moments need to be productive moments?</p><p>To answer that question, let’s distinguish between two types of activities: <strong>telic </strong>and<strong> atelic.</strong></p><p>Stemming from the Greek term <em>Telos </em>(“Having an inherent purpose”), <strong>telic activities</strong> are directed towards an end goal. Conversely, <strong>atelic</strong> activities are pursued for their own sake.</p><p>Telic activities include writing a novel, learning a new skill and building a house all have <strong>specific outcomes. </strong></p><p>On the other hand atelic activities – going for a walk, a long talk with friends, making love, and listening to your favorite songs – <strong>have no end goal.</strong> You derive joy from the activity itself.</p><p>Here’s the rub. <strong>Atelic activities are not “productive.”</strong></p><p>You do not move yourself closer to your goals when you do a puzzle with your toddler. Or when you pause to observe the beauty of a sunset. <strong>These aren’t productive activities.</strong></p><p>And since my Type-A self finds these activities very uncomfortable, my brain does a little mental <strong><em>jiu jitsu</em></strong> to make them more comfortable. I call them <em>Telic Transformations.</em></p><p>As I watch Soul with the fam, I’m <a href="https://twitter.com/khemaridh/status/1342864974771732480">processing ideas</a> for upcoming blog posts. (And when I watch Toy Story, looking to identify the <em>Hero’s Journey </em>narrative arc.)</p><p>When I surf, I’m constantly thinking of the next maneuver to learn (<em>cutbacks</em>), or the next board I could buy.</p><p>Heck, even when sitting on the John (without an iPhone), I’ll grab one of the cleaning products and look for examples of good copy, logo design, or color pairings.</p><p>As Pascal says, those quiet moments with myself can be <strong>quite uncomfortable.</strong></p><p>And then there’s the ultimate telic transformation: <strong>the podcast.</strong></p><p>Thanks to this venerable audio format, the last bastion of atelic activities (a beach walk, cooking a family dinner, getting your kids to sleep) can become <strong>instantly productive</strong> with the most recent episode of <em>The Tim Ferriss show.</em></p><p>Now this isn’t a critique against learning. Nor one against continuous self-improvement. Or about pursuing one’s insatiable curiosity.</p><p>But isn’t this pull to turn <strong>everything</strong> <strong>into an</strong> <strong>outcome</strong> quite peculiar?</p><p>And here comes a conundrum. Telic activities end. Yet the desire lives on. So we <a href="https://radreads.co/when-then-trap/">move the goal line</a>. Another goal. Another outcome.</p><p>And one starts laying the bricks for the hedonic treadmill.</p><p>In <a href="https://www.newyorker.com/books/page-turner/the-philosophy-of-the-midlife-crisis">The Philosophy of the Midlife Crisis</a>, the philosopher Kieran Setiya writes that “there’s something intrinsically self-defeating about getting things done.” Once you do the thing, it can’t be done again. Setiya continues:</p><blockquote><p><em>“Having a child, writing a book, saving a life—the completion of your project may be of value, but it means that the project can no longer be your guide. In pursuing a goal, you are trying to exhaust your interaction with something good, as if you were to make friends for the sake of saying goodbye.”</em></p></blockquote><p>Setiya concludes that “being consumed by plans” can be problematic:</p><blockquote><p><em>“They are schemes for which success can only mean cessation.”</em></p></blockquote><p>We’re not human doings. We’re human beings. Personally, I suspect that my <em>telic transformations</em> come from a place of fear. The fear of not <em>doing enough</em>, comes from the fear of <em>not being enough</em>. Confusing <a href="https://radreads.co/identity-achievement/">identity and achievement</a> becomes a slippery slope that robs me from the present and the beauty and love that surround me.</p><p>So I’ll heed Pascal’s advice – and ditch the AirPods during my next beach walk.</p> </div></div></div>]]>
            </description>
            <link>https://radreads.co/telic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226862</guid>
            <pubDate>Mon, 22 Feb 2021 17:02:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abundant Capital]]>
            </title>
            <description>
<![CDATA[
Score 358 | Comments 210 (<a href="https://news.ycombinator.com/item?id=26226723">thread link</a>) | @tomhoward
<br/>
February 22, 2021 | https://blog.aaronkharris.com/abundant-capital | <a href="https://web.archive.org/web/*/https://blog.aaronkharris.com/abundant-capital">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p>The venture capital industry was built on the premise that both capital and high quality companies are scarce. For most of the history of the industry, this has been true. I remember sitting at demo day in 2011 and marveling at the fact that the combined capital of all the VCs in the room was less than that controlled by the hedge fund at which I had worked. But the model is wrong. Venture capital is abundant, and that fact should fundamentally change how founders fundraise.<br></p><p>This scarcity model has shaped the structure of startups and VCs - most of what an early stage startup does is designed to convince a VC to invest. Companies treat VCs as a limited resource that is both hard to access and hard to convince. Investors do their best to perpetuate this idea because it allows them to retain control of the pitch and fund dynamic.[1]</p><p>Something interesting happens, though, whenever a company has a signifier of quality - a YC demo day slot, a high quality angel, pedigreed founders, or, even better, strong growth. In these cases, there are investor feeding frenzies, leading to oversubscribed rounds, ever climbing prices, and investors willing to accept ownership targets they - until recently - would have termed unacceptable.</p><p>To be sure, there have always been bidding wars in private equity (of which venture is a subset), but these bidding wars are so frequent now as to be approaching the norm. If capital was actually scarce, this wouldn’t happen, there wouldn’t be enough money to create so many bidding wars.[2]</p><p>Bidding wars aren’t the only evidence of capital abundance. The VCs are changing their businesses because of this abundance, whether or not they admit the reason. The evidence is in the new funds that seem to launch on a daily basis, the multi-billion dollar growth funds that have become increasingly common, and the ownership targets at various rounds that continue to drop.</p><p>At the same time that capital has become more abundant, founders have become smarter about fundraising. There are now a huge number of blogs, classes, essays, guides, and advisers ready to help founders navigate the previously opaque world of fundraising. As a result, founders can approach each funding event with a clear plan of how to run a process. Running an orderly process further increases the chances that a company will see competitive bids.</p><p>As a thought experiment, assume that the abundance model is here to stay. It is also safe to assume that founders will not suddenly forget their newfound knowledge about process. I think this should encourage founders to think about changing fundraising in a few major ways:</p><ol>
<li><p>Founders should approach every fundraising as an auction. This is what each process already is, but the auction is inefficient. There’s lots of language and pseudo-moral arguments about why this is bad, but most of those fall apart if capital is abundant.</p></li>
<li><p>Founders should expand their funnels beyond the traditional VCs. These VCs hold a marketing and branding advantage, much of which is built around the signal to later rounds. If, however, each round is an auction, this benefit evaporates. YC’s demo day proved this funnel expansion works at seed, and there’s no logical reason it should fail at later rounds.</p></li>
<li><p>Once a founder has the information produced by this process, she can decide whether to minimize dilution, maximize price, or optimize around the partner. The answer will change based on the situation, but having access to the choice is important.</p></li>
</ol><p>Founders are hesitant to run this model because they fear that running an auction will create a negative quality signal. Investors encourage this belief because it allows them to keep deal flow proprietary. This is flawed logic. The quality of a company can’t be determined by the investors to whom that company talks when raising money. The quality of a company is determined by whether or not the company is good, and good companies should take advantage of abundant capital markets.[3]</p><p><i>Thanks to Adora Cheung, Janelle Tam, Ilya Sukhar, and Nabeel Hyatt for helping me think this through, even though our conclusions might differ.<br></i></p><p>__</p><p>[1] Perhaps more importantly to the investors’ business model is that this dynamic creates a reason for the existence of VCs. If founders and LPs both internalized how non-scarce capital actually is, they could find one another directly, bypassing VCs.</p><p>[2] It’s important to remember that, even though capital is abundant, it remains unevenly distributed. There are companies that struggle to raise money - some of these may be bad investments, but many are good. This is a problem of access rather than capacity, which is a whole different issue.</p><p>[3] When a company IPOs, it opens ownership up to anyone who can afford a share. Imagine, for a second, an investor arguing that this is a sign of low quality.</p></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.aaronkharris.com/abundant-capital</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226723</guid>
            <pubDate>Mon, 22 Feb 2021 16:54:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a reader for HN with Angular]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26226439">thread link</a>) | @izquiratops
<br/>
February 22, 2021 | https://izquiratops.github.io/hacker-reader/ | <a href="https://web.archive.org/web/*/https://izquiratops.github.io/hacker-reader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://izquiratops.github.io/hacker-reader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226439</guid>
            <pubDate>Mon, 22 Feb 2021 16:33:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical Color Theory for People Who Code (2016)]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 49 (<a href="https://news.ycombinator.com/item?id=26225339">thread link</a>) | @martinlaz
<br/>
February 22, 2021 | http://tallys.github.io/color-theory/ | <a href="https://web.archive.org/web/*/http://tallys.github.io/color-theory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
	
	<h3>Natalya Shelburne
		<br>
		<a href="https://twitter.com/natalyathree">@natalyathree</a>
	</h3>
</header>
	
		<div>
			<div>
				<div>
					

					<div><p>
						Hi! I'm Natalya! <img src="http://tallys.github.io/color-theory/images/tally-pic.jpg" title="natalya-profile" description="vector art self portrait">I'm a classically trained fine artist who spent 6 years teaching people how to paint, draw, and grow their creativity. I am now a front end developer, and I love writing code as much as I love painting. </p><p>I have a degree in Studio Art, a bachelor's in Developmental Psychology, and a master's degree in Creativity and Talent Development. But, most importantly, I have mixed gallons and gallons of paint. </p><p>I abstracted my domain knowledge as a fine artist into variables and functions in order to reveal color selection as being logical, predictable, and driven by principles anyone can learn. Sass color functions give you the same creative power as owning a set of paints, brushes, and canvas. </p><p>This is a demo of my functions for a complementary color scheme - pick any color on the color wheel and the functions will make sure that the scheme will still work! 🎨</p></div>
					</div>
					<div>
						
					
					<h4>Completely new to this? Check out these resources first:</h4>
					
				</div>
			</div>
		</div>
		<a href="#" name="start"></a>
<section>
	<h2>Let's build a Complementary Color Scheme!</h2>
	<img src="http://tallys.github.io/color-theory/images/color-circle.png" alt="color-wheel" title="color wheel" description="the color wheel with corresponding hsl degrees">
	<p>This is the color wheel, consider this the documentation for using color. <br> Notice that the degrees on the color wheel correspond to colors.</p>
	
</section>

<section>
	<h2>Pick a color <span> hsl($hue, $saturation, $lightness)</span></h2>
	<div>
		
		<p>Pick any color by selecting its hue (0-360) on the color wheel at full saturation (100%) and at half lightness (50%) - this way you start with the 'most colorful color' you can get.</p>
		<p>This is what your website will look like if you set every element to this one color. Notice how you can't tell one item from another. Color is information.</p>
	</div>
	<div>

		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>


	</div>
	<div>
		
		<div>
			<p>Why pick a fully saturated color, but only half lightness?</p>
			<p>Ever mix up a bunch of colors only to end up with a gray blob? In the real world, you can't mix a color to be more saturated - you only "lose" color information as you mix. So, the practice is to start with the most saturated colors at their most chromatic so you can still have a full range of mixing opportunities.</p>
		</div>
		
	</div>
</section>


<section>
	<h2>Generate Complementary Color<span>complement( );</span></h2>
	<div>
		
		<p>Generate your second color without having to guess what will work. Thanks to science and wavelengths, we know that this works. The opposition of these two colors stimulate your photoreceptor cells in a good way!</p>
		<p>Finally! A different color - now hue separates elements from each other and a layout can be seen.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		<p>The complement to any color is always 180 degrees across on the other side of the color wheel. If you've ever wondered why it's the color wheel instead of a color line, this is part of that answer. Remember that the color wheel is our visual documentation for color relationships. <br> Fun fact, if you mix complementary colors, they'll cancel each other out and you'll end up with a neutral gray.</p>
		
	</div>
</section>

<section>
	<h2>Color Relationship Established by Mixing<span>harmonious-mix( );</span></h2>
	<div>
		
		
		<p>Establish a color relationship by mixing them together. This makes the colors look like they're under similar lighting conditions.</p>
		<p>Here, you see less saturated hues, with a clear relationship between each other.</p>
		</div>
		<div>
			<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

		</div>
		<div>
			
			<div>
				<p>Our eyes may be legacy systems, but they are really good at spotting patterns, especially things that look like they don't belong in a set.</p>
				<p>This mixing method is another way we can simulate lighting and color found in nature. It's a bit more complicated, but my favorite way of explaining it is this: Everything outside has some "yellow" mixed in from the sunshine during the day. Same thing happens when everyone and everything looks bad in photos taken under the glow of green flourescent lights - there is green added to all of the colors you're looking at, including adding a green glow to your skin if you're standing under the flourescent light yourself. Whether it looks good or bad, this color (light) mixing creates a visual harmony. We don't really notice it when it's there, but we really notice its absence.</p>
				<p>When you're painting, you want to simulate similar lighting conditions for a scene, and that effect is accomplished mixing a bit of one color into the other. Mixing different ratios of the same colors will usually generate a matching color palette.</p>
				<p>How do I decide what to do? Thanks to art school and science, I know that cool colors have lower luminosity than warm colors, and will dominate in mixes, with yellow being the lightest color. For example, a touch of blue will really affect yellow, whereas you can add a lot of yellow to blue before it is affected. So, here is this decision making in function form - I am weighing different colors differently when mixing.</p>
	</div>
		
		
		
</div>
</section>

<section>
	<h2>Create Neutrals<span>mix-neutral( ); lighten( ); darken( );</span></h2>
	<div>
		
		
		
		<p>Let your chosen color pop (in other words, don't exhaust your eyes by making them process non-stop intense chromatic colors!) by surrounding it with neutrals. Desaturate the painter way: by mixing complementary colors! Then, vary that neutral's lightness to create a highlight and a shadow.</p>
		<p>Making the complementary color neutrals will help the 'call to action' color you selected stand out - notice how much the button in the top right "pops" all of a sudden. Make things "pop" by making other things around them not pop.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		
		
		<p>We can do the same for our primary color too. More neutrals to work with.</p>
		<p>Doesn't it seem like we went too far with this whole making things neutral? Now, nothing "pops"! But, on the plus side, none of this seems to be irritating any eyeballs, either. Remember that our eyes don't like to handle seeing everything our computers are capable of rendering.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		<div>
			<p>The colors are way too intense at their full saturation for our eyes to handle. If all the colors are bright, none of the colors are bright.</p>
			<p>I picked my starting color for a reason -  I want that to be the heart of my design! That means the complementary color should support the chosen color, and we do that by mixing neutrals. Our eyes don't really handle saturated colors very well next to other saturated colors. Our eyes get confused at the edges - is it this color or the other one? Ahh both! We end up seeing optical illusions. Just give your eyes a break between super strong saturated colors with neutrals so they don't stress out about that much visual information. At the very minimum a rule of thumb is that your viewport should have 33% neutral space (white, desaturated, or black colors) so your poor eyes can have a break and process the information right. Otherwise you get eye strain!</p>
		</div>
		
	</div>
</section>

<section>
	<h2>Why not just desaturate?<span>mix-neutral( ); lighten( ); darken( );</span></h2>
		<p>You totally can! Desaturate does a great job. But, I think not only is it important to understand what "desaturate" means. How would you desaturate a real color in the real world? Remember, you want "ugly" colors for your neutrals! You want to create bland and forgettable colors that recede into the background. These ugly duckling colors are how you get those other call to actions and buttons "pop"!</p>

		<h3>Primary and complementary Colors</h3>
			
			
		<h3>Mixed neutrals</h3>
			
			


		<h3>Desaturated neutrals</h3>
			
			

		<div>
			
			<p>Even though these may look "ugly", neutral colors are the heart of any painting, and that is the case on the web, too. Notice that the same decisions are …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tallys.github.io/color-theory/">http://tallys.github.io/color-theory/</a></em></p>]]>
            </description>
            <link>http://tallys.github.io/color-theory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225339</guid>
            <pubDate>Mon, 22 Feb 2021 15:07:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Do We Talk About When We Talk About Dashboards? (2018)]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26224846">thread link</a>) | @sebg
<br/>
February 22, 2021 | https://alper.datav.is/publications/dashboards/ | <a href="https://web.archive.org/web/*/https://alper.datav.is/publications/dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Dashboards have long been the much maligned visualization vehicle of choice for decision-making in commercial and governmental situations.  While the visualization research community has concentrated much of its effort on visual analytics, the commercial success and widespread use of dashboards begs more attention.  Critically, dashboards are becoming many peoples’ direct connection to “big data” sources, enabling data democratization and wider access to data.</p>

<p>In this paper, we explore the genre of dashboards through a two-prong approach.  We survey the existing literature in business, marketing, and related fields to capture the relevant factors to consider when designing appropriate dashboards and their tools for consumption by different parties, all of which have differing levels of visualization literacy, data literacy, and decision agency.  We also collect examples of dashboard designs based on the dimensions derived from our literature search, and identify different clusters of dashboard designs with similar analysis goals, audiences, and decision support.</p>

<p>We call ourselves the “dashboard conspiracy:” a truly diverse collection of authors across Tableau Research, Microsoft Research, and Simon Fraiser University.</p>

<p><em>This work was presented at <a href="http://ieeevis.org/year/2018/welcome">IEEE VIS 2018</a> in Berlin, Germany.</em></p>

<p><em>This work was discussed in an half-hour datastori.es podcast, <a href="https://datastori.es/135-the-dashboard-conspiracy-with-lyn-bartram-and-alper-sarikaya/">give it a listen</a>!</em></p>

    </div></div>]]>
            </description>
            <link>https://alper.datav.is/publications/dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224846</guid>
            <pubDate>Mon, 22 Feb 2021 14:22:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JSON with Commas and Comments]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 242 (<a href="https://news.ycombinator.com/item?id=26224255">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | https://nigeltao.github.io/blog/2021/json-with-commas-comments.html | <a href="https://web.archive.org/web/*/https://nigeltao.github.io/blog/2021/json-with-commas-comments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p><em>Summary: JWCC is a minimal extension to the widely used JSON file format with
(1) optional commas after the final element of arrays and objects and (2) C/C++
style comments. These two features make it more suitable for human-editable
configuration files, without adding so many features that it’s incompatible
with numerous other (deliberate and accidental) existing JSON extensions.</em></p>

<h2 id="extensibility">Extensibility</h2>

<p>The Peter Principle is the half-joking, half-serious observation that people
get promoted to their level of incompetence, because being competent at level
<code>N</code> leads to being promoted to level <code>N+1</code>.</p>

<p>My colleague Simon Morris made a similar observation about software complexity:</p>

<blockquote>
  <p>Software has a Peter Principle. If a piece of code is comprehensible, someone
will extend it, so they can apply it to their own problem. If it’s
incomprehensible, they’ll write their own code instead. Code tends to be
extended to its level of incomprehensibility.</p>
</blockquote>

<h3 id="the-many-json-extensions">The Many JSON Extensions</h3>

<p>There’s a similar story with file formats. If they’re comprehensible, they’ll
get extended. JSON (JavaScript Object Notation) is this article’s example. The
<a href="https://json.org/">original specification</a> fits on a single page, either as
text or diagrams. The file format is simple and ubiquitous. Therefore, there
are many extensions - supersets of JSON. Here’s just a few (including two
slightly different extensions both called “JSONC”):</p>

<ul>
  <li><a href="https://json5.org/">JSON5</a></li>
  <li><a href="https://komkom.github.io/">JSONC</a> #1</li>
  <li><a href="https://code.visualstudio.com/docs/languages/json#_json-with-comments">JSONC</a> #2</li>
  <li><a href="https://hjson.github.io/">HJSON</a></li>
  <li><a href="https://github.com/lightbend/config/blob/master/HOCON.md">HOCON</a></li>
</ul>

<p>Suprisingly, <a href="https://yaml.org/">YAML</a> is also a superset of JSON. Not just
conceptually, but also in the sense that valid JSON files are also valid YAML
files (although there’s some divergence about whether duplicate keys are
legitimate). As a bonus, if you use YAML, then to paraphrase <a href="http://regex.info/blog/2006-09-15/247">Jamie
Zawinski</a>: now you have <a href="https://noyaml.com/">NO
problems</a>.</p>

<h3 id="wandering-off-the-specification">Wandering Off the Specification</h3>

<p>There are also informal supersets-of-JSON in widespread use, sometimes more by
accident than by design. The Chromium web browser’s <a href="https://source.chromium.org/chromium/chromium/src/+/master:base/json/json_reader.h;l=27;drc=d0919138b7951c1a154cf802a68aad7904b6f4c9">JSON parser goes
off-spec</a>
in a number of ways. The timeline could have been:</p>

<ol>
  <li>Some developer long ago (perhaps in a yak-shaving hurry) wrote or
copy/pasted some parsing code that was accidentally too lenient, allowing a
superset-of-JSON. Perhaps they re-used existing code that handled C-style
string escapes, like the <code>"\n"</code> in <code>"line\nbreak"</code>, without realizing that
it also unescaped <code>"\v"</code>, valid in a C string but not a JSON string.</li>
  <li>People use the software. They write first-party and third-party JSON for it.
Some of it is actually malformed (e.g. they have <code>"\v"</code> inside strings) but
tests (manual and automatic) usually check that new features work, not that
all the slightly-incorrect things are rejected. Nobody notices at the time.</li>
  <li>Years pass. <a href="https://www.hyrumslaw.com/">Hyrum’s Law</a> slowly kicks in. We
can no longer tighten this custom JSON parser implementation to follow the
spec more strictly because too many things (in unknown places) will break.</li>
</ol>

<p>This also affects our ability to replace one JSON library with another. For
example, we might want to switch from a C++-based JSON parser to a Rust-based
one, because of its security benefits. If the upstream Rust library chooses to
follow the spec diligently (which is a perfectly reasonable position) then it
would ‘break’ our apps that have inadvertently relied on the previous
looser-than-the-spec implementation.</p>

<p>We could carry local patches, but that isn’t free. Upstream fuzz-testing
infrastructure only exercises the unmodified library, not our patched flavor.
Future upstream changes may also invalidate the downstream patch, possibly in
subtle ways. An upstream “this new unsafe block is OK because it’s a private
implementation detail and nothing in this crate does X” comment might not be
aware that our out-of-tree patch does X to its internals.</p>

<h3 id="quirks">Quirks</h3>

<p>The Wuffs library approach is to expose
<a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/doc/note/quirks.md">quirks</a>: runtime
configuration options to go off-spec in various ways so that Wuffs’
implementation can be a drop-in replacement for other implementations, without
the need for downstream patches.</p>

<p>Wuffs has <a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/std/json/decode_quirks.wuffs">20 JSON
quirks</a>
so far. As always, there are trade-offs. They’re not free (in terms of
maintenance cost) and have super-linear complexity: that file’s comments also
has 12 call-outs to the subtleties of combining two particular quirks.</p>

<p>Here’s an example of the emergent complexity when combining two simple-sounding
JSON extensions. The first one adds C++-style <code>/* slash-star block comments */</code>
and <code>// double-slash line comments</code>. The second one packs multiple top-level
values in a single stream, separated by line breaks.</p>

<p>That second extension - by itself and when holding minified, whitespace-free
‘vanilla’ (non-extended) JSON - plays well with Unix’s traditional
line-oriented tools. It is sometimes known as Line-Delimited JSON
(<a href="https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON">LDJSON</a>),
Newline-Delimited JSON (<a href="http://ndjson.org/">NDJSON</a>) and JSON Lines
(<a href="http://jsonlines.org/">JSONL</a>). But “one value per line” tools’ assumptions
can break if slash-star comments can also contain blank lines.</p>

<p>Here’s another question (let’s call it the ‘end of comment’ question). Is the
<code>'\n'</code> at the end of of a <code>// double-slash line comment</code> actually part of the
comment? At first, this sounds merely philosophical. Comments are ignored and,
in ‘vanilla’ JSON, all whitespace is ignored, so why the distinction?</p>

<p>The ‘right’ answer to that ‘end of comment’ question isn’t obvious, but it can
affect whether a line comment at the end of a multi-value stream should end in
1 or 2 <code>'\n'</code> bytes. Ideally the answer should be self-consistent with whether
a line comment at the end of file must end with the <code>'\n'</code> or whether the
implicit EOF (end-of-file) alone suffices. See also the <a href="http://seriot.ch/parsing_json.php">“Parsing JSON is a
Minefield”</a> and <a href="https://nullprogram.com/blog/2019/12/28/">“Unintuitive JSON
Parsing”</a> articles for how subtle a
‘simple’ format like JSON can be.</p>

<p>Wuffs makes one particular choice for that ‘end of comment’ question. Its
particular choice probably isn’t that important, more that it made a concious
and documented choice.</p>

<h3 id="clarity-not-terseness">Clarity, not Terseness</h3>

<p>Some general advice, when designing a new file format or extending an existing
one, is keep some room for future extensions. For example, allowing unquoted
strings (writing <code>foo</code> instead of <code>"foo"</code>), is certainly convenient, but
re-defining <code>undefined</code> or <code>datetime</code> without quotes, from invalid JSON syntax
to valid some-extension-of-JSON strings, rules out a future extension adding
new ‘keywords’.</p>

<p><a href="https://cbor.io/">CBOR</a> is binary at the wire format level (unlike textual
JSON) but naturally extends JSON at the object model level. It also has an
<code>undefined</code> concept separate from <code>null</code>, and <code>undefined</code> can be a map key. We
couldn’t do the ‘obvious’ CBOR-to-some-extended-JSON conversion if <code>undefined</code>,
without quotes, was already repurposed to mean a string.</p>

<p>I find it suprising that, <a href="https://github.com/lightbend/config/blob/master/HOCON.md#unquoted-strings">in
HOCON</a>,
“<code>truefoo</code> parses as the boolean token <code>true</code> followed by the unquoted string
<code>foo</code>. However, <code>footrue</code> parses as the unquoted string <code>footrue</code>”.</p>

<p>It can also be helpful for a <a href="https://github.com/search?q=return.flase+extension%3Apy">typo like
<code>flase</code></a> to be picked
up early as a syntax error (without needing schemas or type checking) instead
of silently accepted (as a string, not a bool). This can otherwise be
especially dangerous if further processed in a weakly-typed programming
language where any non-empty string is ‘truthy’.</p>

<p><code>[a b c]</code> is invalid ‘vanilla’ JSON syntax, but in the various extended-JSON
variants, is it a list with three 1-byte strings or one 5-byte string? Or is it
one 3-byte string because three 1-byte strings are implicitly
whitespace-delimited and also then implicitly concatenated? Any particular
answer can be consistent in its own world, but different JSON extensions make
different choices. This can be confusing when software grows large enough (or
gains enough transitive dependencies) to have to speak multiple JSON
extensions.</p>

<p>These days, when I’m programming in C/C++ or Go, I often add unnecessary
parentheses in expressions like <code>(a * b) + c</code>. Even though they’re redundant
because of well-defined operator precedence rules, different programming
languages have different precedence rules and getting the precedence wrong can
lead to <a href="https://github.com/jbangert/nail/issues/7">hard-to-spot bugs</a>. The
Wuffs language actually <a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/doc/wuffs-the-language.md#operators">rejects a bare <code>a * b +
c</code></a>
and you have to parenthesize the multiplication or the addition.</p>

<p>Similarly, for JSON-like documents, I prefer the clarity of either <code>["a", "b",
"c"]</code> or <code>["a b c"]</code>, even if it means a little extra typing. Reading is more
important than writing for code and configuration, especially when multiple
people or long periods of time are involved.</p>

<h2 id="introducing-jwcc">Introducing JWCC</h2>

<p>Having said all of that, here is yet another superset-of-JSON, called JWCC
(JSON With Commas and Comments). It is a minimal extension. As its name
suggests, there are only two new features:</p>

<ul>
  <li>“Commas” lets you optionally have a comma after the final element of an array
or an object: <code>[1,2,3,]</code>. When you format one element per line, it’s easier
to insert and remove elements (and eyeball the diffs) when you don’t have to
fiddle with any commas (or lack of commas) on adjacent but otherwise
unrelated lines.</li>
  <li>“Comments” lets you have C++-style <code>/* slash-star block comments */</code> and <code>//
double-slash line comments</code>, anywhere where ‘vanilla’ JSON allows whitespace.
Line comments must end with a <code>'\n'</code> byte, even at the end of the file.</li>
</ul>

<p>To be clear, while every JSON file is valid JWCC, this is a new file format. It
just happens to be very familiar if you (or your software) already speak JSON.
Yes, Doug Crockford <a href="https://web.archive.org/web/20150105080225if_/https://plus.google.com/+DouglasCrockfordEsq/posts/RK8qyGVaGSr">deliberately removed comments from
JSON</a>
but people keep putting them back in. If we’re going to have comment-enriched
JSON (e.g. for human-editable configuration files), we might as well have a
standard one. Cue <a href="https://xkcd.com/927/">XKCD #927 “Standards”</a>.</p>

<h3 id="cc-implementation">C/C++ Implementation</h3>

<p><a href="https://github.com/google/wuffs">Wuffs</a>’ JSON library (availble as a C or C++
API) can decode either ‘vanilla’ JSON or JWCC, using its quirks mechanism.
<a href="https://github.com/google/wuffs/tree/3d6c609dc12de3c81e1b8079ceecf96370b086a2/example/jsonptr"><code>jsonptr</code></a>
is a command line tool (a JSON formatter) that uses this library. By default,
it speaks spec-compliant ‘vanilla’ JSON:</p>

<div><div><pre><code>$ echo '[1,2,/*hello*/3,]' | jsonptr
[
    1,
    2
json: bad input
</code></pre></div></div>

<p>It has a JWCC mode:</p>

<div><div><pre><code>$ echo '[1,2,/*hello*/3,]' | jsonptr -jwcc
[
    1,
    2,
    /*hello*/
    3,
]
</code></pre></div></div>

<p>It can also convert from JWCC syntax to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nigeltao.github.io/blog/2021/json-with-commas-comments.html">https://nigeltao.github.io/blog/2021/json-with-commas-comments.html</a></em></p>]]>
            </description>
            <link>https://nigeltao.github.io/blog/2021/json-with-commas-comments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224255</guid>
            <pubDate>Mon, 22 Feb 2021 13:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The birth of Prolog (1992) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 36 (<a href="https://news.ycombinator.com/item?id=26223906">thread link</a>) | @alokrai
<br/>
February 22, 2021 | http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf | <a href="https://web.archive.org/web/*/http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223906</guid>
            <pubDate>Mon, 22 Feb 2021 12:51:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Sculpt Wired Conversion Mod]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26223805">thread link</a>) | @yuribro
<br/>
February 22, 2021 | https://chadaustin.me/2021/02/wired-sculpt/ | <a href="https://web.archive.org/web/*/https://chadaustin.me/2021/02/wired-sculpt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I made a control board for the Microsoft Sculpt wireless keyboard that converts it to wired USB, and now my favorite keyboard is even better.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/finished-board.jpeg"><img src="https://chadaustin.me/images/sculpt/finished-board.jpeg" alt="The finished and installed board."></a>
<figcaption>The finished and installed board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/messy-desk.jpeg"><img src="https://chadaustin.me/images/sculpt/messy-desk.jpeg" alt="Wired keyboard and the resulting project mess!"></a>
<figcaption>Wired keyboard and the resulting project mess!</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/underside.jpeg"><img src="https://chadaustin.me/images/sculpt/underside.jpeg" alt="USB cable and reset button."></a>
<figcaption>USB cable and reset button.</figcaption>
</figure>

<p>The QMK config is available at <a href="https://github.com/chadaustin/qmk_firmware">@chadaustin/qmk_firmware</a> (<a href="https://github.com/chadaustin/qmk_firmware/tree/master/keyboards/handwired/sculpt">keyboards/handwired/sculpt/</a>), and the PCB design files at <a href="https://github.com/chadaustin/wired-sculpt-pcb">@chadaustin/wired-sculpt-pcb</a>.</p>

<p>I’m planning on making at least one more, so if you’d like one, maybe I can help.</p>

<p>It’s a huge improvement. Latency is reduced by about 13 milliseconds, and with full control over the microcontroller’s firmware, you can customize keymaps and layers, and actually use the keyboard’s built-in LEDs.</p>

<h2 id="why">Why?</h2>

<p>Feel free to stop reading here — I am going to tell the sequence of events that led to this project. Besides some exposure to basic voltage and resistance circuits in college, I have very little electronics background. But, in a short time, I went from only barely knowing what a capacitor was to having a working PCB manufactured and assembled, and maybe this will inspire someone else to give it a try.</p>

<p>Since developing RSI in college, I’ve exclusively used Microsoft’s ergonomic keyboards. And when I first tried the Sculpt, I instantly knew it was the best yet. The soft actuation, short key travel, and rigid frame are perfect for my hands. And because the number pad is a separate device, the distance to my mouse is shortened.</p>

<p>My brother went out and bought one too. Not much later, he gave it to me, saying the latency was inconsistent and high, and it was unacceptable for gaming. I thought he was being uniquely sensitive, since I had no problem in either Linux, Windows 7, or macOS. But then I updated to Windows 10 and saw exactly what he meant.</p>

<p>It was like the keyboard would go to sleep if a key wasn’t pressed for a few seconds, and the first keypress after a wake would be delayed or, worse, dropped.</p>

<p>And heaven forbid I use my USB 3 hub, whose EMI would disrupt the 2.4 GHz signal, and <em>every other</em> keypress would be unreliable. I’d gone as far as mounting the wireless transceiver directly under my keyboard, on the underside of my desk, and keys were still dropped.</p>

<p>So, best keyboard ever. But wireless sucks. (But mostly in Windows 10? No idea about that.)</p>

<h2 id="over-the-hump">Over the Hump</h2>

<p>What started this whole thing is that the <a href="https://github.com/facebookexperimental/eden/#edenfs">EdenFS</a> team was a bunch of keyboard enthusiasts. During the pandemic, as we’re all at home burning out and missing each other, we were trying to think of some virtual team offsites. Wez offered to walk everyone through building a <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">Sweet 16 Macro Pad</a>.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/sweet-16.jpeg"><img src="https://chadaustin.me/images/sculpt/sweet-16.jpeg" alt="Assembled Sweet 16 underside"></a>
<figcaption>Assembled Sweet 16 underside. This is take two, after resoldering and cleaning the whole thing. Take one was a bit of a mess.</figcaption>
</figure>

<p>So, okay, a keyboard is a matrix, with some diodes used to disambiguate the signalling, and a microcontroller that rapidly polls the matrix and reports events over USB…</p>

<p>So maybe I could fix the Sculpt! I bought a transceiver-less Sculpt off eBay for cheap and <a href="http://emmanuelcontreras.com/how-to/how-to-disassemble-microsoft-sculpt-ergonomic-keyboard-and-make-it-wired/">popped it open (thanks Emmanuel Contreras!)</a>, thinking maybe its controller could be flashed with new firmware that speaks USB. The Sculpt uses a <a href="https://infocenter.nordicsemi.com/pdf/nRF24LE1_PS_v1.6.pdf">Nordic Semiconductor nRF24LE1</a>, but I was nowhere near capable of making use of that information at the time, though it did point me to Samy Kamkar’s horrifying guide on <a href="https://samy.pl/keysweeper/">surreptitiously sniffing keystrokes from nearby (older) Microsoft wireless keyboards</a>.</p>

<p>I almost gave up here, but Per Vognsen <a href="https://twitter.com/pervognsen/status/1322422385174220800">suggested I scan the matrix myself</a> and it turns out Michael Fincham had already <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/bhkgnp/modification_photos_qmk_wired_microsoft_sculpt/">mapped out the matrix and soldered a Teensy 2.0++ board onto the Sculpt’s test pads</a>, showing this was doable!</p>

<p>So I ordered my own microcontroller to try the same thing.</p>

<p>First, I bought an Arduino Pro Micro, like the Sweet 16 uses. Oh hey, 18 GPIO pins isn’t enough to drive the Sculpt’s 26-pin matrix. I looked at using an I2C GPIO expander, but it felt like taking on too much.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pro-micro.jpeg"><img src="https://chadaustin.me/images/sculpt/pro-micro.jpeg" alt="Arduino Pro Micro"></a>
<figcaption>Arduino Pro Micro. Wait, you need pins to scan a matrix?</figcaption>
</figure>

<p>More pins? QMK’s Proton C has more pins! So I carefully soldered onto the test pads as Michael had shown was possible… and it worked!</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/proton-c.jpeg"><img src="https://chadaustin.me/images/sculpt/proton-c.jpeg" alt="QMK Proton C"></a>
<figcaption>QMK Proton C. It's a beautiful board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/test-pads.jpeg" alt="Soldering test pads to Proton C."></a>
<figcaption>Soldering test pads to Proton C.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/all-test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/all-test-pads.jpeg" alt="All test pads connected to Proton C. It works!"></a>
<figcaption>All test pads connected to Proton C. It works!</figcaption>
</figure>

<p>Getting those wires to stick to the pads without shorting was tricky. (I hadn’t yet discovered how magical flux is.)</p>

<p>The keyboard worked, but I couldn’t fit the board, its wires, and the new microcontroller into the case, and I wasn’t <em>really</em> happy leaving it in this state, even if I could pack it in somehow.</p>

<p>I thought, all I <em>really</em> need is the ribbon cable connector, so I ordered a 30 pin, 1.0 mm pitch ribbon breakout and the pricier (but tons of pins!) <a href="https://www.pjrc.com/store/teensypp.html">Teensy 2.0++</a>. Looking back, it’s cute that I was trying to save $10 on the microcontroller… You just have to get used to spending money on whatever saves you time.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg"><img src="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg" alt="Ribbon cable breakout and Teensy 2.0++"></a>
<figcaption>Ribbon cable breakout and Teensy 2.0++</figcaption>
</figure>

<p>Well, it was almost as annoying to solder, and still didn’t fit. So much for saving money on microcontrollers.</p>

<p>I thought about giving up. Is it really that bad that my keys don’t always register in games? Can I just tolerate some flakiness and latency?</p>

<p>But Jon Watte offered to spend an entire day showing me how to use KiCad, design circuits, layout PCBs, select components on Digi-Key, scan datasheets for the important information, and how to work with a PCB manufacturing house. Of course you never turn down opportunities like that.</p>

<h2 id="designing-the-final-board---schematic">Designing the Final Board - Schematic</h2>

<p>Assuming, like me, you’ve never done this, I’ll summarize the steps.</p>

<p>First you sketch out the circuit schematic.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/schematic.png"><img src="https://chadaustin.me/images/sculpt/schematic.png" alt="Schematic"></a>
<figcaption>Schematic in KiCad. Most of this was informed by the datasheet and Atmel's design guides.</figcaption>
</figure>

<p>Jon showed me several tricks in KiCad, like global labels, and starting with some standard resistor and capacitor values, but it’s very important that you go through the datasheets, because details can matter a ton.</p>

<p>I knew I wanted the main processor to be the AT90USB1286 controller, and fortunately KiCad already had a symbol for it. Atmel has a comprehensive and accessible data sheet, which showed me I needed some 22 Ω resistors on the USB data lines, which of the ISP programmer lines needed resistors (and appropriate values), and that I needed to either pull HWB low, or provide a physical switch that pulls it low, in order to allow rebooting the device into USB firmware update mode.</p>

<p>There are a bunch of things that are implicitly known to electrical engineers but that were new to me. You want:</p>

<ul>
  <li>a ground plane under the data lines and most of the microcontroller if possible.</li>
  <li>an electrolytic or tantalum bypass capacitor on the main 5V power from USB.</li>
  <li>ceramic filter capacitors on each power pin.</li>
  <li>appropriate values for the resonance capacitors on your crystal.</li>
  <li>electrostatic discharge protection! Turns out transients are common and it’s easy to fry a chip just by plugging it in.</li>
</ul>

<p>And then when you get into concerns like EMI and high-frequency signal integrity, the rabbit hole goes deep.</p>

<p>I kept having to tell myself “it’s just a keyboard”, but it also helped that there are a great number of high-quality resources on these topics just a click away. I spent lots of time on <a href="https://www.eevblog.com/">EEVBlog</a>.</p>

<p>Before finishing the circuit design, Jon had me do a couple smart things. In case the factory-supplied USB bootloader didn’t work out, he suggested I add the footprint (but not a connector!) for an ISP programmer and a debug LED to prove code would work at all.</p>

<h2 id="designing-the-final-board---physical-layout">Designing the Final Board - Physical Layout</h2>

<p>After arranging the schematic and ensuring it passed the electrical rules check, it was time to pick specific components. That is, the reference to a 220 Ω resistor is replaced with the Panasonic ERJ-3EKF2200V, 0603 surface mount.</p>

<p>There are a couple things to keep in mind. For common components, like resistors and ceramic capacitors, there is a huge amount of choice. For example, I see over 1400 surface-mount 220 Ω resistors on digikey. I tried to just stick with one high-quality brand like Panasonic or Samsung for all of that stuff.</p>

<p>The important thing is the physical form factor, which determines the footprint on the board. Once you pick a part, it has a size, and you need to tell KiCad which physical footprint should be assigned to that component. I used 0603 resistors, so I assigned each resistor in the schematic the “Resistor_SMD:R_0603_1608Metric” footprint.</p>

<p>Same for everything else. Jon showed me how to draw my own footprints, but to avoid complexity, I was able to find appropriate footprints in KiCad’s standard libraries for every component I needed.</p>

<p>When you import the schematic into Pcbnew, it’s time to figure out where things go. Where are the edges of the board? Make careful measurements here. Where do the mounting holes go? Where do you want 
the microcontroller? Where do you want the USB port?</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/dimensions.jpeg"><img src="https://chadaustin.me/images/sculpt/dimensions.jpeg" alt="Measuring dimensions and mounting holes"></a>
<figcaption>Measuring dimensions and mounting holes</figcaption>
</figure>

<p>Also, you have to pick through-hole sizes and trace widths. Jon had me use .250 mm for the narrow traces and .500 mm for the wider ones, presumably from experience. I used the narrow traces for signalling and wide traces for power, though I’ve since heard it’s a good idea to use narrow traces between filter capacitors and VBUS.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pcb-layout.svg"><img src="https://chadaustin.me/images/sculpt/pcb-layout.svg" alt="Schematic"></a>
<figcaption>PCB layout in KiCad</figcaption>
</figure>

<p>Of course, there’s some iteration between the schematic and the PCB. After physically placing the ribbon cable connector and MCU, the traces all crossed over each other, so I had to reassign all the pins so it made sense physically.</p>

<p>There are also physical constraints about how USB data lines are run, and how the electrostatic protection chip wants to be placed for the most protection.</p>

<p>So, as simple as this board is, I spent a fair amount of time getting all of that right.</p>

<p>I found myself getting lost in the abstractness of holes and traces and footprints, so it was helpful to ground myself by occasionally loading the PCB in KiCad’s 3D viewer.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/3d-view.png"><img src="https://chadaustin.me/images/sculpt/3d-view.png" alt="Schematic"></a>
<figcaption>3D View</figcaption>
</figure>

<h2 id="designing-the-final-board---manufacturing-and-testing-physical-fit">Designing the Final Board - Manufacturing and Testing Physical Fit</h2>

<p>I tried to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chadaustin.me/2021/02/wired-sculpt/">https://chadaustin.me/2021/02/wired-sculpt/</a></em></p>]]>
            </description>
            <link>https://chadaustin.me/2021/02/wired-sculpt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223805</guid>
            <pubDate>Mon, 22 Feb 2021 12:39:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I’m Losing Trust in Open Source]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 31 (<a href="https://news.ycombinator.com/item?id=26223575">thread link</a>) | @bodegajed
<br/>
February 22, 2021 | https://gibson.ws/why-im-losing-trust-in-open-source/ | <a href="https://web.archive.org/web/*/https://gibson.ws/why-im-losing-trust-in-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

		
					<!-- Image banner -->
					
					<!-- Image banner -->

					<div id="content">
						<div>
							<div>

	<div id="primary">
		<main id="main">

		
<article id="post-146">
			<!-- .entry-header -->

	<div>
		<p>Back when I was starting to code several years ago. I picked up The Cathedral and the Bazaar by Eric Raymond and I was blown away at the idea of free software. Just in case you are not familiar, free software as in freedom and not free beer. Free software back then was this super radical and idealistic concept where as you make a software product commercial or not, but when you distribute it you include the source code of it. The person who got your product would eventually continue to develop it and it will evolve and continually improve as it gets to many users. You then will be looking at their version of your product and will see how it has grown further. Think of it has a community garden where everyone grows their vegetable and anyone would then take pointers on some of your crops and grow their improved version. Eventually you’ll see where you are doing it wrong by looking at how they tend their garden. This is not necessarily free food for everyone – although it’s common. It’s freedom to copy and use my garden setup so we have bigger crops next harvest time.</p>
<p>This what happened to Linux, nodejs, Ruby etc.. I’ve believed in it much so I joined sourceforge joined a team, also started a project myself even. I followed this radical concept through the years and publish my projects openly on github. It was fun and there is some sort of social acceptance when people see your ugly looking code yet they accept it and submit their own ugly looking code as well.</p>
<p>Facebook, Apple, Google these companies are worth trillions of dollars and they all at one point when they are still small companies depended on open source. Their founders built an MVP and took money from VCs and then had to responsibly return their money 10x. They eventually all cashed out and now driving luxury sports cars. Meanwhile present day Linux desktop is still dead. Open source maintainers abandoning projects due to lack of time and interest. They say why not just use GPL but if you license your code using GPL you will not have users. Developers can’t even share the name of the software they are putting your code into because of these NDA they signed. Sometimes it’s just a simple request like attribution and compliance is still uncommon.</p>
<p>Life as a open source maintainer is sometimes a <a href="https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/">life threatening endeavor</a></p>
<p>Society, Conglomerates, and Capitalism killed free software and nobody cared. It’s all about 10x ROI and taking advantage of some poor idiot programmer clueless in business.</p>

			</div><!-- .entry-content -->
</article><!-- #post-146 -->

<!-- #comments -->

		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
</div>
</div><!-- #content -->
</div>
</div></div>]]>
            </description>
            <link>https://gibson.ws/why-im-losing-trust-in-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223575</guid>
            <pubDate>Mon, 22 Feb 2021 12:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual passport app presents real data risk, experts warn]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 97 (<a href="https://news.ycombinator.com/item?id=26223347">thread link</a>) | @pseudolus
<br/>
February 22, 2021 | https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Canadian privacy experts are concerned the federal government's plan to develop an online passport application process could put&nbsp;personal information at risk and open a new angle of attack for fraudsters.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4612031.1536417303!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/passport.jpg"></p></div><figcaption>IBM Canada's digital passport application platform is expected to begin testing in three months, and could be ready for use as early as 2022.<!-- --> <!-- -->(John Badcock/CBC)</figcaption></figure><p><span><p>Canadian privacy experts are concerned the federal government's plan to develop an online passport application process could put&nbsp;personal information at risk and open a new angle of attack for fraudsters.</p>  <p>IBM Canada has been awarded the&nbsp;$1.5-million contract to create software that would allow Canadians to apply for a passport using their&nbsp;smartphones, tablets or&nbsp;computers.</p>  <p>The new platform would also allow applicants to&nbsp;pay fees and upload their passport photos securely, according to a statement from Immigration, Refugees and Citizenship Canada (IRCC).</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>They will attempt to&nbsp;exploit the program very quickly, very intensely to obtain the most fraudulent passports they can in the least amount of time.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Benoît&nbsp;Dupont, l'Université de Montréal</cite></span></blockquote>    <p>But privacy and data protection experts worry that personal information may be stored on foreign servers, providing an appealing target to criminals.</p>  <p>Sébastien Gambs, a professor in the information technology department of l'Université de Québec à Montréal&nbsp;and Canada Research Chair on privacy and data protection, said there are real&nbsp;concerns about&nbsp;where the data will be stored, a detail neither the government nor IBM Canada has divulged, though the tender identifies Amazon Web Services (AWS), the cloud computing branch of the American online retail giant.</p>  <p>"Even when we do business with an American company that agrees to store data within Canada, under the [U.S.] CLOUD Act, data could eventually be transferred out of the country," Gambs said in French.</p>  <p>In a statement, AWS said its clients retain full ownership and control of their data, including who may access that information.</p>  <p>In a separate statement, IRCC said "the privacy of Canadians and the safety of their personal information will be an absolute priority."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/tech-cloud.JPG 300w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/tech-cloud.JPG 460w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/tech-cloud.JPG 620w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tech-cloud.JPG 780w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/tech-cloud.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tech-cloud.JPG"></p></div><figcaption>Amazon Web Services (AWS) says its clients retain full control over the data it stores.<!-- --> <!-- -->(Ivan Alvarado/Reuters)</figcaption></figure></span></p>  <h2>Canadian passports highly valued</h2>  <p>Benoît Dupont, a criminology professor at l'Université de Montréal and Canada Research Chair in cybersecurity, said the passport app will likely be a major target for fraudsters&nbsp;eager to get their hands on&nbsp;Canadian passports and the mobility that comes with them.</p>  <p>"That's very attractive for organized crime groups who specialize in human trafficking," Dupont said in French. "They will attempt to&nbsp;exploit the program very quickly, very intensely to obtain the most fraudulent passports they can in the least amount of time."</p>  <p>But&nbsp;Gambs said any virtual application will likely have extra&nbsp;steps built in to protect against hackers.</p>  <p>"As soon as we're doing things remotely, verifying somebody's identity becomes much more difficult," he said. "The government will definitely need to collect more personal information in order to verify an applicant's identity."</p>  <h2>'Vicious cycle': PIPSC</h2>  <p>The Professional Institute of the Public Services (PIPSC) said this tender should never have gone out to the private sector when it could have been developed in-house by public servants, as was done with the online tax portal.</p>  <p>"It's a vicious cycle. Instead of developing resources internally, we go externally," said&nbsp;Stéphane Aubry, vice-president of PIPSC. "Then we don't have the needed expertise internally,&nbsp;which&nbsp;unfortunately, over the years, fades and makes it so we need to contract out."</p>  <p>PIPSC said the project raises <a href="https://www.cbc.ca/news/canada/ottawa/phoenix-pay-system-cost-report-1.5138036">the spectre of the Phoenix pay system fiasco</a>, which also involved IBM.&nbsp;IBM Canada will be required to train and support IRCC employees in running the new passport system, according to the tender documents.</p>  <p>In 2020, the government issued just 897,401 passports, compared to 2.6 million the year before. For the first four months of the pandemic, Service Canada was only providing critical passport services for urgent travel.&nbsp;</p>  <p>Nevertheless, the Canadian Anti-Fraud Centre received 1,806 reports of passport-related fraud last year.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223347</guid>
            <pubDate>Mon, 22 Feb 2021 11:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ethereum Isn't Fun Anymore]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 619 (<a href="https://news.ycombinator.com/item?id=26222709">thread link</a>) | @timdaub
<br/>
February 22, 2021 | https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><strong>Ethereum isn’t fun anymore. There I said it.</strong> And although, the last
time I developed an app using it has been more than a year ago, I stand by
my word. <strong>Developing dapps on Ethereum has become annoying</strong>.  Here’s why:</p>
<p><img src="https://timdaub.github.io/assets/images/pedro.gif" alt=""></p>
<h2 id="I-used-Ethereum-before-it-was-cool">I used Ethereum before it was cool.</h2>
<p>I know; it’s such a hipster statement. But it’s true. Ethereum has stopped
being edgy. It has transitioned out of its niche to build a world computer.
Its community has become huge, and I stopped knowing most faces. Where there
was a feeling of revolution and new beginnings, now there are people in suits
talking corporate. Within just a few years, it went from <a target="_blank" rel="noopener" href="https://github.com/DaddyDeFi/DaiDaddy">DAI
daddys</a> and only <a target="_blank" rel="noopener" href="https://www.molochdao.com/">half-ironic satanist
cults</a> to lending, insurance, and trade protocols.</p>
<p>“What’s Ethereum’s killer app?” we asked ourselves not long ago.  Now we know.
It’s the world’s best publicly-accessible settlement platform for financial
transactions.  In a way, that’s exciting. The markets think so too. But for
anyone else that worked with Ethereum but outside of financial applications,
it’s somewhat of a letdown.</p>
<p><img src="https://timdaub.github.io/assets/images/homer.gif" alt=""></p>
<h2 id="How-do-you-do-fellow-Ethereans">How do you do, fellow Ethereans?</h2>
<p>I think it must have been around the time of the last big crypto bubble
when Monero enthusiasts called for “Making Monero cheap again.”</p>
<p>Monero, being the anonymous digital currency that had indeed just legit use
cases apart from the occasional rumors that entangled it in drug
trafficking, had suddenly become too expensive for everyday use. Realizing
the glaring threat of becoming too valuable, its core developers went on to
fix the problem by campaigning at CoinDesk’s yearly industry gathering
Consensus.</p>
<p>They announced the “Monero Enterprise Alliance.” An inside joke,
supposed to piss off other projects that had started to take themselves too
seriously. Being slightly confused that day myself, I now can’t recall if
the effort had ever been successful. But in any case, I can’t recommend
buying Monero. It’s useless.</p>
<h2 id="Gas-prices-are-too-damn-high">Gas prices are too damn high!</h2>
<p><img src="https://timdaub.github.io/assets/images/deepfried_high_rents.jpg" alt=""></p>
<p>There was a phase in my short career as an Ethereum developer where I looked at
Etherscan’s “<a target="_blank" rel="noopener" href="https://etherscan.io/contractsVerified">Verified Contracts</a>” page
all day long to find vulnerabilities in newly uploaded contracts. “My name’s Tim
and I’m an etherholic!”</p>
<p>It was addictive. I ended up calling a few of those contracts, failing to cause
any havoc, sadly. But it was so much fun! Back when transaction fees were still
affordable on Ethereum, building projects was great. We started up Ganache and
our favorite text editor (vim).  The only choice we had was Solidity. And off
we went.</p>
<p>Now, building Ethereum applications has become painful. <a href="https://timdaub.github.io/2020/09/08/web3/">web3 is a stupid
idea</a>. Layer 2 isn’t ready. Neither
is Eth 2.0. And there are still <a href="https://timdaub.github.io/2019/02/28/poa/">many reasons to NOT ship to a Proof of
Authority network</a>. Finally, gas
prices are too damn high!</p>
<p>How do we move on from here?</p>
<h2 id="I-need-a-hero">I need a hero.</h2>
<p><strong>I need a hero, and by that, I mean that I need a usable methodology for
building scaleable decentralized apps.</strong> Yes, you’ve heard that right. We don’t
need more “Ethereum killers” that can do 10x more tx/s than Ethereum.  Those
are useless.</p>
<p>Instead, we need an approach for the average Joe developer to create their idea
within the Ethereum ecosystem without the need for hardcore unproven
technologies. I know, you Vitalik will say: “Oh, it’s not a problem, we can has
‘<a target="_blank" rel="noopener" href="https://vitalik.ca/general/2020/03/21/garbled.html">Garbled Circuits</a>’ and
zkrollups.” But I’m telling you that no sane Joe will touch that shit without a
serious cryptographic specialist by their side.</p>
<p>We want what we stayed for initially: Good ol smart contracts. But right now,
they’re too damn expensive to innovate.</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222709</guid>
            <pubDate>Mon, 22 Feb 2021 10:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoid the Most Dangerous Word in Software Development]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222529">thread link</a>) | @pawurb
<br/>
February 22, 2021 | https://pawelurbanek.com/dangerous-word-slack | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/dangerous-word-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div role="main">
<div>

<p><span>Share</span>
<a href="https://twitter.com/intent/tweet?text=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development&amp;url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Twitter" src="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png" srcset="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png 1x, https://pawelurbanek.com/assets/twitter@2x-bb4de08ef7390cb0e6bc0e4c74d50e098821cd7c55f1c6b20560a7a325d29164.png 2x">
</a>
<a href="https://facebook.com/sharer.php?u=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Facebook" alt="Share on Facebook" src="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png" srcset="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png 1x, https://pawelurbanek.com/assets/facebook@2x-0d1abc87e5ffdc544fa8f0f4282d2c01706bf15a814d794080aff2f7a87a0ffb.png 2x">
</a>
<a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack&amp;title=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development" rel="nofollow" target="_blank">
<img title="Share on LinkedIn" alt="Share on LinkedIn" src="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png" srcset="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png 1x, https://pawelurbanek.com/assets/linkedin@2x-b89a20f8fc3d0a82f9fe54137fbbbf4029dcc189f4dec6b9a3964b9350833e1f.png 2x">
</a>
</p>
<p><span>Share</span>
<br>
<a href="https://twitter.com/intent/tweet?text=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development&amp;url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Twitter" alt="Share on Twitter" src="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png" srcset="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png 1x, https://pawelurbanek.com/assets/twitter@2x-bb4de08ef7390cb0e6bc0e4c74d50e098821cd7c55f1c6b20560a7a325d29164.png 2x">
</a>
<br>
<a href="https://facebook.com/sharer.php?u=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Facebook" alt="Share on Facebook" src="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png" srcset="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png 1x, https://pawelurbanek.com/assets/facebook@2x-0d1abc87e5ffdc544fa8f0f4282d2c01706bf15a814d794080aff2f7a87a0ffb.png 2x">
</a>
<br>
<a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack&amp;title=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on LinkedIn" alt="Share on LinkedIn" src="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png" srcset="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png 1x, https://pawelurbanek.com/assets/linkedin@2x-b89a20f8fc3d0a82f9fe54137fbbbf4029dcc189f4dec6b9a3964b9350833e1f.png 2x">
</a>
<br>
</p>



<article>
<p><img title="Unhealthy communication on Slack is represented by a mousetrap Photo by Skitterphoto from Pexels" alt="Unhealthy communication on Slack is represented by a mousetrap Photo by Skitterphoto from Pexels" data-src="https://pawelurbanek.com/assets/slack-communication-trap-eeafc54866148ef1e14021e31975e1a8cfdab1478039b1a0685c1ea63600ef22.jpg" src="https://pawelurbanek.com/assets/slack-communication-trap-thumb-c4922c24466c80938315ab6fda7ae65192a488f1a643ccc4728839c6027bee1e.jpg">
</p>
<br>


<p><em>J-U-S-T</em>. Those four characters can be significantly detrimental to a software development process. In this blog post, I’ll describe how the <em>“just keyword”</em> can affect team’s communication and how to avoid misusing it on Slack.</p>
<h2 id="lets-just-do-it">Let’s “just” do it</h2>
<p>You’ve probably been there. Your product manager shares his brand new plan on the Slack channel:</p>
<p><em>“Why don’t we</em> <strong>just</strong> <em>add this cool new feature to our application?”</em></p>
<p>or your colleague got the wrong idea about scaling after reading a HackerNews story:</p>
<p><em>“Let’s</em> <strong>just</strong> <em>migrate our infrastructure to Kubernetes…“</em></p>
<p><em>“Just”</em> is toxic and dangerous. It implicitly suggests that the proposed task is straightforward. It undermines the discussion about the issues that might pop-up during the implementation.</p>
<p>There’s no <em>“just”</em> in software development. Most of the tasks turn out to be more complex than anticipated. <em>“Just tickets”</em> tend to drag, evolve into epics, miss deadlines and hurt the team’s motivation.</p>
<p>I’ve seen this topic discussed many times before. Make sure to check out <a href="https://alistapart.com/blog/post/the-most-dangerous-word-in-software-development/" target="_blank" rel="noopener noreferrer">these two</a> <a href="https://the-pastry-box-project.net/brad-frost/2014-january-28" target="_blank" rel="noopener noreferrer">blog posts</a> for a more in-depth description of it.</p>
<h2 id="how-to-use-slack-to-get-rid-of-just-tickets">How to use Slack to get rid of “Just tickets”</h2>
<p>I want to propose a solution to the <em>“Just”</em> problem. Lexically there’s never a need to include the word <em>“just”</em> in a sentence. You can always omit it without altering the core meaning of your message.</p>
<p>You could discourage using the word <em>“just”</em> in communication. Slack offers a simple feature that will let you automate it. Introducing Slackbot triggers:</p>
<p><img alt="Slack keyword trigger in action" title="Slack keyword trigger in action" loading="lazy" src="https://pawelurbanek.com/assets/slack-keyword-trigger-40d3219d92fe2bee0932a832ff7c80608c9b99a067f704347ed564dec917bc1e.png"></p>
<p>Slack trigger in action</p>

<p>You can configure Slack to automatically send a custom message whenever a <em>trigger</em> keyword is detected. In settings, go to <strong>Customize &gt; Slackbot</strong> and enter your desired trigger and response.
<br></p>
<p><img alt="Slack trigger settings" title="Slack trigger settings" loading="lazy" src="https://pawelurbanek.com/assets/slack-trigger-settings-3456bc59b61b75a27c245690b2d0a5d57afd8e2ac535027c9d01e3a87c54cffb.png"></p>
<p>Slack trigger settings</p>

<p>It could be pretty spammy to start with, but your team should quickly adjust and stop using the <em>forbidden</em> keyword. If someone does use it, the alert message will be a fun reminder to stop and think twice if the <em>“just”</em> idea is really that simple.</p>
<p>So why won’t you just give this communication experiment a try?</p>
<p>BTW if you’re looking for more creative ways to enhance your communication on Slack, you can check out <a href="https://abot.app/" target="_blank" rel="noopener noreferrer">Abot for anonymous messaging and polls</a>. It’s highly configurable and supports various <a href="https://abot.app/scenarios" target="_blank" rel="noopener noreferrer">usage scenarios</a>.</p>
<p><img alt="Anonymous poll conducted using Abot for Slack" title="Anonymous poll conducted using Abot for Slack" loading="lazy" src="https://pawelurbanek.com/assets/slack-anonymous-poll-bda619f03336795730c69705f61eddc8f4bac6a6bcd8deb65e83bf3ff880156d.png"></p>
<p>Abot anonymous poll with private answers</p>

</article>

<p><a href="https://twitter.com/_pawurb" target="_blank" rel="nofollow">
<img loading="lazy" alt="Pawel Urbanek Twitter account" title="Pawel Urbanek Twitter account" src="https://pawelurbanek.com/assets/pawel-circle-eafe4e7f9c98c20c753dcba1f1b1a16ed8bc384cdf2da91d272dd2291d8e7a4d.jpg" srcset="https://pawelurbanek.com/assets/pawel-circle-eafe4e7f9c98c20c753dcba1f1b1a16ed8bc384cdf2da91d272dd2291d8e7a4d.jpg 1x, https://pawelurbanek.com/assets/pawel-circle@2x-352753604906054aa864cc5f3916317be7c2b7db8f8703243a0447d06187c641.jpg 2x">
</a>
</p>

<br>

<br>

<br>


<br>





</div>
</div>
</div></div>]]>
            </description>
            <link>https://pawelurbanek.com/dangerous-word-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222529</guid>
            <pubDate>Mon, 22 Feb 2021 09:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with a Niche]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26222313">thread link</a>) | @tablet
<br/>
February 22, 2021 | https://fibery.io/blog/start-with-a-niche/ | <a href="https://web.archive.org/web/*/https://fibery.io/blog/start-with-a-niche/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>The most popular products don’t become mass popular overnight. It’s a process. Usually, their popularity is uneven, they are unknown in some niches, but very popular in other niches.</p><p>When you start a product, sometimes you know the niche already and can easily define target customers. However, in many cases, you just don’t and try to find the niche and this miraculous niche-market-fit. </p><p>One of the most common mistakes is to ignore niches and just try to attract all kinds of customers. It’s essential to find 1-2 ponds to start from and then expand to the other, larger, and more promising lakes and oceans 🚰 → 🛁 → 🌊.</p><p>Here are a couple, maybe surprising examples, that demonstrate how popular products took off. </p><h4>Electrical telegraph (1837)</h4><p>Its adoption was not easy, since it was not clear what are the benefits for commercial institutions. Stockbrokers and reporters got the benefits first. They understood that fast information transition increases efficiency and helps to get an edge. In a short term, all major news agencies and major stock markets were connected to the telegraph. </p><h4>Telephone (1876)</h4><p>Telephones were adopted by police departments and fire stations. Fast reaction to crime reports and fires was great, but the telegraph was not enough. You have to have two-ways communication to get some details that the sender maybe is not expecting to report initially. </p><h4>Phonograph (1877)</h4><p>Try to guess the first niche market for the phonograph. Rich music lovers? Nope. First phonographs were coin-machines in bars. Throw a nickel and enjoy Stephen Foster ballads.</p><h4>Car (1886)</h4><p>Cars are almost among the lucky exception to the niche rule. However, there was still one group of people in the USA that moved from horses to cars enormously fast — farmers. Cars just expanded the borders of farmers’ social life and business activities. Suddenly you can buy goods, not from a local dealer, but a dealer in a remote town (much cheaper). Suddenly you can visit a town and watch a movie. These benefits were not important for the urban population, for they were life-changers for the rural population. Nevertheless, cars were adopted in cities quite fast as well.</p><blockquote><p>In addition, the car delivered you to the door and was faster than a horse-and-buggy, thus allowing longer trips in shorter time. Farmers had traditionally felt guilty about taking such trips, even when the time was available. </p></blockquote><h4>Radio (1895)</h4><p>Radio was immediately adopted by the British Royal Navy, they thought that radio can speed up communication between ships and were right. Fun fact: in 1912 Titanic sent CQD (distress signal), however, <a href="https://www.nationalgeographic.com/history/article/why-titanic-first-call-help-not-sos-signal">radio receiver was turned off on the closest ship</a>:</p><blockquote><p>Meanwhile, the closest ship, Californian, didn’t receive Titanic’s distress calls at all. Its wireless operator had switched off his receiver and gone to bed after Phillips told him to shut up.</p></blockquote><h4>VisiCalc (Excel predecessor, 1979)</h4><p>First, it was adopted by accountants. Businessmen and analysts joined the party much later. Accountants just saw the value right away (and quite many people pirchased Apple II just to get <a href="https://thenewstack.io/how-visicalcs-spreadsheets-changed-the-world/">VisiCalc</a>):</p><blockquote><p>Like an accountant, I remember showing it to one around here and he started shaking and said, “That’s what I do all week. I could do it in an hour.” … I meet these people now, they come up to me and say, “I gotta tell you, you changed my life. You made accounting fun.”</p></blockquote><h4>Facebook (2004)</h4><p>Everybody knows that Facebook got its popularity in universities first. Everybody knows the rest of the story.</p><blockquote><p>Within 24 hours, 1,200 Harvard students had signed up, and after one month, over half of the undergraduate population had a profile. The network was promptly extended to other Boston universities, the Ivy League and eventually all US universities</p></blockquote><hr><p>Can you start without any niche in mind? Yes, you can, but this is just hard. The most problematic part is marketing. Who are your ideal customers? How to reach them? How to target your message? <strong>Product is the message</strong>, so without proper marketing startup success chances are low. </p><h4>My experience</h4><p>In Fibery we did our first release in April 2020 as a general work management tool. We were not sure in what types of companies it will work better and what use cases will be more valuable. In just a month it became clear that we had all kinds of leads from all kinds of companies. Leads demanded all kinds of improvements that just didn’t form a sane strategy. </p><p>We quickly <a href="https://fibery.io/blog/chronicles-21/">decided to select a single niche and focus on it</a>. The niche we choose was product companies from 20 to 200 people. And it made everything much simpler. Finally, we can quite accurately say what features are important and what features are not so important, what is our value proposition, who is our ideal lead (Product Ops or CPO). It took us 9 months to prepare the <a href="https://fibery.io/product-management">second release</a>, but in this niche Fibery can fly much better, I believe. </p><p>OK, niche strategy looks convincing, but how to find the niche? We used <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a>, and it’s just partially a joke. We’ve reviewed a couple of alternatives and selected one we knew best and were confident that our product will provide a significant value boost. There were other alternatives, like education space or digital agencies space, but our knowledge here was not deep enough. It means we should rely on some domain experts, etc. It’s not a huge problem, but we also did not feel that these niches are better.</p><p>A startup should be an experimentation facility that hypothesizes, executes, and measures the results. The faster you can do it, the faster you find your niche. Why it took us 9 months to make this niche release? In fact we spend time to create a niche-probing framework. Now we can asseble solutions for various niches in 1-2 weeks and check initial response in 1-2 months. If the first niche will not be successful, we at least have a decent experimentation framework 🧬.</p></section></div>]]>
            </description>
            <link>https://fibery.io/blog/start-with-a-niche/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222313</guid>
            <pubDate>Mon, 22 Feb 2021 09:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practiced Humility in Retrospectives]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222018">thread link</a>) | @kiyanwang
<br/>
February 22, 2021 | https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/ | <a href="https://web.archive.org/web/*/https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    
<p>One of the fallacies about our collective approach to retrospectives, incident reviews, and post mortems is the belief that the entire process is a rational machine. Pour in a curated series of events, turn the handle, and out pop all of the action items that need completing to fix the world. I can’t speak to every industry that practices Resilience Engineering, but as for Software Engineering it stems strongly from our belief that we’re fully in control of our environment. We’ve built our tooling, architected our systems, and we’re running the retro. Why wouldn’t we be able to simply apply the calculus to our knowledge and change things for the better?</p>



<p>This all speaks to a distinct lack of humility in what we do as a practice. If we want to better understand the risks we undertake every day and to learn from failures in that work, we need to first accept that failures are in part due to our incomplete understanding, great and small, of our socio-technical systems. Even with a complete working knowledge of everything, we would be unable to act on everything needed to perfect our system, and that underlying system will change despite these efforts. Being comfortable with being wrong means we can change.</p>



<p>This reluctance to accept that things continually fail despite our best efforts, is a common reaction. It’s hard to assume that our systems are continuously in need of tweaks because it’s also hard to accept that they will always run in some form of a degraded state<sup><a rel="noreferrer noopener" href="#complex-systems-run-in-degraded-mode" target="_blank">1</a></sup>. That said, we can fall into the adjacent trap with people being the adaptable element in the system<sup><a rel="noreferrer noopener" href="#human-practitioners-are-the-adaptable-element" target="_blank">2</a></sup> that we are then in the best position to understand the entirety of our system and how best to course correct. The sharp end can be a powerful, if not perilous, position to sit in but it doesn’t guarantee omniscience in the scope of understanding an incident. This is why I frequently suggest that practitioners of retrospectives be folks who weren’t involved in the incident, to help mitigate this failing.</p>



<h2>Hubris as Facilitator</h2>



<p>It’s easy to understand the desire to sit in the facilitator chair. You’re taking the reins of the situation and you’re going to get to the bottom of things. You ask the questions, you drive the conversation and schedule the meeting, but most importantly you’re going to be there to get answers. That would be true if you held a made up title like investigation commander or retrospective captain, but you’re don’t. A facilitator is less the spike and more the bump/set. You’re there to position other folks to learn, not wear the badge.</p>



<p>Retros also come in various shapes and sizes, which makes for another tempting place to be in control. If I’m running the retro, then it can follow my guidelines and my preferred flow. This lesson I learned the hard way, having felt as though I knew “the one true way” to run it. I was there at Etsy watching John Allspaw, Morgan Evans, and Daniel Schauenberg develop and put ink to paper with the <a rel="noreferrer noopener" href="https://extfiles.etsy.com/DebriefingFacilitationGuide.pdf" target="_blank">Etsy Debriefing Guide</a>. In doing so, though, I failed to recognize the microcosm that was Etsy, that what worked for us there didn’t apply universally. Maybe folks had other tools worth surfacing and we should continually look to that to see how we can improve the production of our retros.</p>



<p>Facilitators should instead be the support for everyone else to do the talking and ask questions of their own. We can only share that deep empathy with one another when we put ourselves in one another’s shoes and that can only be done with the understanding of our own fallibility. We too know how awful it feels to be at the center of an incident, that it could have easily been us, which allows us to help recreate the scene and ditch concepts like “human error” as an easy solution to a complex problem.</p>



<p>A singular view of the problem, from that up on high as facilitator, will produce a singular set of answers constrained by our myopic vantage point.</p>



<h2>Top Down Misunderstanding of Retrospectives</h2>



<p>Another failure in our work running retrospectives is senior leadership (individual contributors and management both) using them to impart the illusion of work being done. You’ll see this often in email chains that include a CC list that races its way up the reporting structure. This incident was unacceptable, but don’t worry, <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=9AKTBHuRv9U" target="_blank">we have top men working on it right now</a>. Similarly, you’ll see public facing reports sent out by companies to reassure customers, the board of directors, and investors that all is well. It’s worth noting that there is value in shared perception being a useful tool for a business to leverage, but it still doesn’t impart learning to folks on either side of the boundaries of a company. The learning review is downgraded for the sake of making an org, at the macro or micro level, appear to be invulnerable to failure. The company cannot tolerate failure because vulnerability must be made an impossibility.</p>



<p>It’s also why so many existing tools are marketed with a primary focus on action items as the work. Going into a retro with the principal desire to create a ToDo list is problematic because the learning becomes a secondary function by nature of prioritization. It has roots in humility such that we’re going into our discussions and interviews believing we can simply solve all the problems in tech and then everything will be perfect from here on, the deeper understanding a “nice to have”.</p>



<p>This is not to give individual contributors in senior positions a pass. How often do we rely on “This is the way we’ve always done it” and our use of best practices<sup><a href="#can-we-trust-best-practices">4</a></sup> as a crutch for decision making rather than challenge established methods? We give folks in senior positions more time for questions during discussions and put them at the front to answer for the sake of expedience. Equally, holding a blameless post mortem can fail if an org values engineers who prioritize their place in the pecking order rather than risk losing face in front of others. Giving less experienced folks time to explore ideas tests the validity of our mental models.</p>



<p>Most importantly, for us to build and revise adaptive capacity<a href="#building-and-revising-adaptive-capacity"><sup>3</sup></a> we have to first acknowledge that the map of our system is potentially inaccurate, a map that is heavily influenced top down. Until we can move towards an acceptance of inaccuracies in our understanding, our assumption stands that we must be right and the view should not change. All of these concepts, and our own journey to them, are themselves a <em>work in progress</em>. There are soft boundaries and holes in the middle where our language and understanding fails us. This does not inherently diminish our work, but can in fact enhance it.</p>



<h2>Humility In Practice</h2>



<p>It’s a fairly given criticism that a lot of our work in applying Resilience Engineering and Human Factors concepts to Software Engineering fail to give concrete examples of putting theory to practice, often leaving it as an exercise to the reader. With that in mind, what does humility first in a retro look like?</p>



<ul><li><strong>A retrospective is a safe place to say “I don’t know”.</strong> A facilitator can and should actively say just that while encouraging others who exhibit similar misgivings about what they can safely hold true. By doing so, it establishes a pattern of being ok with the discomfort of uncertainty.</li><li><strong>Retros should prioritize learning before fixing.</strong> This is not infrequently stated, but bears repeating. As said elsewhere, it also doesn’t exclude action items. Rather, allow folks to freely express what they don’t understand without shame and for improvements to extend from these learning experiences.</li><li><strong>A generosity of spirit is key.</strong> Participants should hold a respect to time shared for other folks to learn, with a particular emphasis on the facilitator. As invaluable as your time is, the up front cost of interviewing folks, organizing meetings, and gathering information is paramount. Put in the extra effort to interview before a retro meeting and follow up after to tie up loose ends.</li><li><strong>There should be a reduction (not an absence) on our use of hindsight.</strong> Acknowledging that we’re all fallible means we can resist the inclination to “fix” an error with counterfactuals when we review past events. Look backwards not as a way to save face but to explore why ideas previously made sense.</li><li><strong>The malleable nature of a retrospective is to review what is assumed to be true.</strong> Confirm or refute assumptions on the narrative as it is assumed to exist regardless of who shares it. Some folks may not be in a position to share, internal pressures against them. Insights often comes from the sharp end, which isn’t always the most tenured engineer.</li><li><strong>All participants should be on equal footing.</strong> Retros are akin to a round table discussion where folks come to share events and ask questions, rather than seniority or management directing the events as to how it may best serve their own interests or those assumed to be of the organization. Don’t let titles dictate who gets to speak.</li><li><strong>Our work in retrospectives is ongoing and adaptable.</strong> Before practitioners get too set in their ways, we should remember that Resilience is a verb<sup><a rel="noreferrer noopener" href="https://willgallego.com/wp-admin/post.php?post=529&amp;action=edit#resilience-is-a-verb" target="_blank">5</a></sup>. Templates are more rigid and predefined, but allowing ourselves the chance to break out of molds, to make mistakes, and explore the boundaries with the assurance that failure is ok, we can practice new ways of pulling out sources of information from our incidents. Our meta discussions surrounding incidents should themselves be challenged.</li></ul>



<p id="complex-systems-run-in-degraded-mode">1. Cook (2002) – <a rel="noreferrer noopener" href="https://how.complexsystems.fail/#5" target="_blank"><em>How Complex Systems Fail: Complex systems run in degraded mode</em></a></p>



<p id="human-practitioners-are-the-adaptable-element">2. Cook (2002) – <a rel="noreferrer noopener" href="https://how.complexsystems.fail/#12" target="_blank"><em>How Complex Systems Fail: Human practitioners are the adaptable element of complex systems</em></a></p>



<p id="building-and-revising-adaptive-capacity">3. Cook, Long (2020) – <a rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/pii/S0003687020301903" target="_blank"><em>Building and revising adaptive capacity sharing for technical incident response: A case of resilience engineering</em></a></p>



<p id="can-we-trust-best-practices">4. Klein et al (2016) – <a href="https://www.researchgate.net/publication/300343833_Can_We_Trust_Best_Practices_Six_Cognitive_Challenges_of_Evidence-Based_Approaches" target="_blank" rel="noreferrer noopener"><em>Can We Trust Best Practices? Six Cognitive Challenges of Evidence-Based Approaches</em></a></p>



<p id="resilience-is-a-verb">5. Woods (2018) – <a rel="noreferrer noopener" href="https://www.researchgate.net/publication/329035477_Resilience_is_a_Verb" target="_blank"><em>Resilience is a Verb</em></a></p>



<p><em>Photo: <a href="https://www.flickr.com/photos/eyesplash/5307049124" target="_blank" rel="noreferrer noopener">https://www.flickr.com/photos/eyesplash/53070…</a></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/">https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/</a></em></p>]]>
            </description>
            <link>https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222018</guid>
            <pubDate>Mon, 22 Feb 2021 08:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indian Government Breached, Massive Amount of Critical Vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 67 (<a href="https://news.ycombinator.com/item?id=26221607">thread link</a>) | @astroanax
<br/>
February 21, 2021 | https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A writeup detailing the vulnerability reporting process that took place after Sakura Samurai had breached the Indian Government</p><p>Reading time: 6 minutes.</p><div>
      

<p>Sakura Samurai knew that the Indian Government operated an RVDP (Responsible Vulnerability Disclosure Program). <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> put a list together of initial assets in scope for Sakura Samurai to legally test. <a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a> reported that he had found sensitive data and was able to breach police assets. <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> was working in the enumeration processes with his friend, <a href="https://twitter.com/orpheus9001" title="https://twitter.com/orpheus9001">Zultan Holder</a> [not an active Sakura Samurai member] and identified a slew of various attack vectors, immediately resulting in the exposure of many pairs of credentials for databases and other pertinent applications.</p>
<p>The team was informed of the initial enumeration results as they continued to work on the list of assets within scope, while also further jumping into the research and began performing analysis on the sensitive data, identifying additional vectors of attack, exposed PII, and even more credentials.</p>
<p>Sakura Samurai team members included <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a>, <a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a>, <a href="https://twitter.com/Kirtaner" title="https://twitter.com/Kirtaner">Aubrey Cottle</a>, and<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking"> John Jackson</a></p>
<p>In total, the following vulnerabilities were identified, in no specific order:</p>
<ul>
<li>35 Separate Instances of Exposed Credential Pairs (Servers, Important Applications, etc)</li>
<li>3 Instances of Sensitive File Disclosure</li>
<li>5 Exposed private-key pairs for servers</li>
<li>13K+ PII Records [and those are only the records that we were inadvertently exposed to]</li>
<li>Dozens of Exposed Sensitive Police Reports</li>
<li>Session Hijacking Chained via Multiple Vulnerabilities, resulting in the compromise of extremely sensitive government systems</li>
<li>Remote Code Execution on a sensitive financial server; a server that contained large backups of Financial Records</li>
</ul>

<p>First and foremost, it is important to note that so many Critical findings had been identified during our testing that we cannot possibly include all of the vulnerabilities without making this writeup unnecessarily heavy. Therefore, we have opted to include small snippets of repetitive findings in this section. Many variations of application and server credentials also were obtained but the point has already been made.</p>
<p><strong>Exposed Database Credentials</strong></p>
<p><img src="https://johnjhacking.com/uploads/db-creds.png" alt=""><br>
<strong>Private SSH Keys</strong></p>
<p><img src="https://johnjhacking.com/uploads/priv-ssh.png" alt=""></p>
<p><strong>Sensitive File Exposure</strong></p>
<p><img src="https://johnjhacking.com/uploads/sens-file-exp.png" alt=""><br>
<strong>Exposed PHP Mailer Credentials</strong></p>
<p><img src="https://johnjhacking.com/uploads/mailer.png" alt=""></p>

<p><a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a> identified an application that resulted in a vulnerability that allowed him to access Sensitive Police Records, containing PII of individuals listed on the report. In addition, sample forensic reports and forensic tooling that is used by the police department was identified by Willis. The exposure of citizen’s sensitive information, some being victims, is a sensitive subject within itself and highly alarming.</p>
<p><img src="https://johnjhacking.com/uploads/police.png" alt=""><br>
<img src="https://johnjhacking.com/uploads/police2.png" alt=""><br>
Shortly after, <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> found a vulnerability that resulted in the exposure of 14,000+ user records. The records included a wide range of sensitive information, including full name, contact info, employee’s department, date of birth, etc. These exposed records along with other various SQL server dumps and Rob’s Police Record Exposure is enough to constitute a data breach without even logging into any of the servers.</p>
<p>Henry identified many credential pairs which could have resulted in even more exploitation of many other people. The PII identified is a small sample of a much larger issue.</p>
<p><img src="https://johnjhacking.com/uploads/14k-records.png" alt=""><br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">John Jackson</a> was able to identify a relevant Remote Code Execution Vulnerability, affecting an out-of-date application residing on one of the government servers. The remote code execution vulnerability allowed for complete access to sensitive files on the server, including the ability to exfiltrate complete backups of financial records [although data exfiltration wasn’t performed to avoid unnecessary action]</p>
<p><img src="https://johnjhacking.com/uploads/rce1.png" alt=""><br>
<img src="https://johnjhacking.com/uploads/rce2.png" alt=""><br>
Finally, <a href="https://www.twitter.com/Kirtaner" title="https://www.twitter.com/Kirtaner">Aubrey Cottle</a> identified the presence of what appeared to be an extremely important application being hosted by the same server that John had achieved successful Remote Code Execution on. Cottle then chained together multiple vulnerabilities in conjunction with the Remote Code Execution vulnerability, resulting in the ability to hijack any user’s session on the web application. The application contained troves of sensitive government data and could have given a threat actor the ability to perform highly-critical, admin-based government actions.</p>
<p><img src="https://johnjhacking.com/uploads/session-chained.png" alt=""></p>

<p>Even though the Indian Government has a RVDP in place, we didn’t feel comfortable disclosing the vulnerabilities right away. The hacking process was far from the standard situation of business-as-usual security research. In total, our report compounded to a massive 34 page report worth of vulnerabilities. We knew that our intent was good, but we wanted to ensure that the US Government had eyes on the situation. Sakura Samurai coordinated with the <a href="https://twitter.com/DC3VDP" title="https://twitter.com/DC3VDP">U.S. DoD Vulnerability Disclosure Program (VDP)</a> to assist in facilitating initial conversations of disclosure. <a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">John Jackson</a> spoke with DC3’s Program Manager via email and coordinated on a plan of action.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-1.png" alt=""><br>
Roughly 4 days later, after further communication with the DC3, we felt safe to begin our initial reveal of research on the NCIIPC’s RVDP program.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-2.png" alt=""></p>
<p>In addition, the DC3 also commended the hacking that we did in support of making the cyberspace a better place for everyone.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-3.png" alt=""></p>
<p>Unfortunately, what seemed like a done deal turned out to be quite the unprofessional ride. Any organization knows that fixing breach-worthy vulnerabilities is extremely time sensitive. Once threat actors catch wind of major vulnerabilities against an organization they begin poking on their own, looking for more vectors of attack. Immediately upon revealing that Sakura Samurai was the group responsible for hacking the Indian Government, we followed up with them via Email.</p>
<p><strong>Timeline</strong></p>
<p><strong>2021/02/04</strong> - DC3 begins initial contact with the Indian Government.<br>
<strong>2021/02/08</strong> - Sakura Samurai informs the public that they breached the Government.<br>
<strong>2021/02/08</strong> - Sakura Samurai makes contact with the NCIIPC, noting that the report that they received was a result of their research.<br>
<strong>2021/02/09</strong> - The NCIIPC responds, with a basic acknowledgement and thank you for the research.<br>
<strong>2021/02/09</strong> - Sakura Samurai asks for clarification on patching and the responsibility of breach disclosure to the public.<br>
<strong>2021/02/10</strong> - Sakura Samurai, having received no response, asks for an update on the involved remediation and breach notification processes.<br>
<strong>2021/02/16</strong> - Sakura Samurai once again asks for NCIIPC’s plans for remediation and disclosure.<br>
<strong>2021/02/17</strong> - The NCIIPC makes contact, 7-days later, stating that they will follow up in a short time. Again, we ask about plans of anticipated patching and breach notification to the affected citizens.<br>
<strong>2021/02/19</strong> - In the morning, we ask again about patching and disclosure, 8-hours later and still no response on the matter.<br>
<strong>2021/02/19</strong> - Sakura Samurai reviews the submitted vulnerability report and notes that only about an eighth or less of the submitted Critical Vulnerabilities have been resolved within a two-week period. No notification of breach has occurred even though Government Employees and Indian Citizens are at risk of exploitation from threat actors.</p>

<p>Governments have an obligation to protect the private data of its employees and citizens. In addition, the exposure of proprietary government data can be used for great means of manipulation and for other destructive purposes. While the NCIIPC operates a Responsible Vulnerability Disclosure Program, the recklessness and avoidance of communication represents the complete opposite of a responsible program. A failure to release notification of breach to affected citizens and to patch highly-critical vulnerabilities in a timely manner reflects poorly on the state of their Information Security posture. The clock to patch vulnerabilities began immediately when the DC3 contacted the NCIIPC via Twitter, as it is a highly visible space - one which threat actors avidly monitor.</p>
<p>Sakura Samurai urge the NCIIPC to patch the remainder of the vulnerabilities. The criticality of some of the issues cannot wait weeks or months for adequate resolution.</p>
<hr>
<p><strong>Check out our website</strong><br>
<a href="https://sakurasamurai.org/" title="https://sakurasamurai.org">https://sakurasamurai.org</a></p>
<p><strong><em>Twitter Links:</em></strong><br>
Main Page<br>
<a href="https://twitter.com/SakuraSamuraii" title="https://twitter.com/SakuraSamuraii">https://twitter.com/SakuraSamuraii</a><br>
Founders<br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">https://twitter.com/johnjhacking</a><br>
<a href="https://twitter.com/nicksahler" title="https://twitter.com/nicksahler">https://twitter.com/nicksahler</a><br>
Members<br>
<a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">https://twitter.com/JacksonHHax</a><br>
<a href="https://twitter.com/Kirtaner" title="https://twitter.com/Kirtaner">https://twitter.com/Kirtaner</a><br>
<a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">https://twitter.com/rej_ex</a><br>
<a href="https://twitter.com/endingwithali" title="https://twitter.com/endingwithali">https://twitter.com/endingwithali</a><br>
Collaborator<br>
<a href="https://twitter.com/orpheus9001" title="https://twitter.com/orpheus9001">https://twitter.com/orpheus9001</a></p>

    </div></div>]]>
            </description>
            <link>https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221607</guid>
            <pubDate>Mon, 22 Feb 2021 06:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Immutability, Verifiability and Integrity Without the Blockchain Overhead]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26221324">thread link</a>) | @sidcool
<br/>
February 21, 2021 | https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/ | <a href="https://web.archive.org/web/*/https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Whenever a software project needs to implement immutable records, people often start thinking of Blockchain or <strong>D</strong>istributed <strong>L</strong>edger <strong>T</strong>echnology like Hyperledger. Blockchain and DLT make use of cryptographic techniques that enable immutability, verifiability and integrity checks. However, Blockchain and DLT need much more than just these checks. It needs to prevent all the attempts of a double-spend by potential malicious users. In a trust-less environment it needs implementation of complex protocols which leads to consumption of huge amount of electricity. This makes writing data on Blockchain costly. DLTs like Hyperledger make use of simpler consensus algorithms between a “set of trusted nodes”, which reduces the cost. However, it still incurs significant costs if nothing more than immutability, verifiability and integrity were the concern.</p>



<p>This post is about how to implement data immutability, verifiability and integrity without using a Blockchain or a DLT in industrial strength software applications.</p>



<ul><li><a href="#foundation">Foundational technique</a><ul><li><a href="#hash-function">Cryptographic hash function</a></li></ul></li><li><a href="#verifiability">Verifiability</a><ul><li><a href="#verify-id">Deterministic and Verifiable IDs</a></li><li><a href="#data-format">Data format and ID Generation</a></li></ul></li><li><a href="#immutability">Immutability and Verifiability</a><ul><li><a href="#merkel-dag">Merkel DAG and immutable data structures</a></li><li><a href="#mutation">Mutation</a></li></ul></li><li><a href="#integrity">Immutability, Verifiability and Integrity</a><ul><li><a href="#application">More applications</a></li></ul></li><li><a href="#future-proof">Future-proofing</a><ul><li><a href="#multi-hash">Multihash</a></li></ul></li></ul>



<h2 id="foundation">Foundational technique – Cryptographic Hashing</h2>



<p>To understand the solution, some foundational techniques must be understood. This section describes what is cryptographic hashing. Those who are already aware of cryptographic hashing, they may skip to the next section.</p>



<h4 id="hash-function">Cryptographic hash function</h4>



<p>If you provide a stream of bytes to a cryptographic hash function, it generates a number called hash (also referred to as digest). The following properties make it a very useful tool:</p>



<ol><li>It is impossible to guess the generated hash value for a stream of bytes. To get the hash value, one has to run the algorithm, there is no shortcut.</li><li>For a given input it always generates the same hash value.</li><li>It is infeasible to deduce the input based on the hash value. That means it is an irreversible mathematical function.</li><li>No two different stream of bytes result in the same hash value. Even a small change in the input stream generates a totally different number.&nbsp;<em>(When two different stream of bytes produce the same hash value, we say the cryptographic hash function is broken. It is also referred to as there is a collision in the cryptographic hash function.)</em></li><li>Any size of input stream will always result in the same size of hash value. Some hash functions generate hash values that are 256 bits long. If those functions are used, the result will always be 256 bits long.</li></ol>



<p>Examples of commonly used cryptographic hash functions include:</p>



<ul><li>SHA-256 (returns 256 bit&nbsp;unsigned integers)</li><li>RIPEMD-160 (returns 160 bit unsigned integers)</li></ul>



<p>Sample hash values:</p>



<figure><table><tbody><tr><td><strong>Input</strong></td><td><strong>SHA-256</strong></td><td><strong>RIPEMD-160</strong></td></tr><tr><td>Hello world</td><td>0x64ec88ca00b268e5ba1a35678a1b5316d212f4f366b2477232534a8aeca37f3c</td><td>0xdbea7bd24eef40a2e79387542e36dd408b77b21a</td></tr><tr><td>Hello world.</td><td>0xaa3ec16e6acc809d8b2818662276256abfd2f1b441cb51574933f3d4bd115d11</td><td>0x6ad34a17d22d67a7ab02710ae9eb6f282cb1d787</td></tr><tr><td>Unrelated, totally.</td><td>0x2bd72f5c4300444890325b3363ef2027f30ed38797c3133dbc62a90564976458</td><td>0x51cb1844d22a00d5f659795e0b1c339c6fa1a8bc</td></tr></tbody></table><figcaption>Hex representation of SHA-256 and RIPEMD-160 hash values for different inputs</figcaption></figure>



<p>There are two things we observe from the table above:</p>



<ol><li>With a slight change in input, the hash values change dramatically and by looking only at the hash values, one cannot conclude&nbsp;that&nbsp;the first and second are&nbsp;even closely related. This is also referred to as <a href="https://en.wikipedia.org/wiki/Avalanche_effect" target="_blank" rel="noreferrer noopener">avalanche effect</a>. It is one of requirements of a cryptographic algorithms to have the avalanche effect.</li><li>The values mentioned are actually text strings and do not look like numbers, although we expected them to be numbers.</li></ol>



<p>They are actually numbers, represented this way to reduce the size of the presented text. For example, binary representation of the number 255&nbsp;is ‘11111111’. Decimal representation is ‘255’. Hexadecimal representation is ‘ff’ or ‘FF’. The representations in the table above are hexadecimal representations of 32 byte and 20 byte numbers. <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Base64" target="_blank">base64encoding</a> is commonly used to represent the hash values in cryptographic applications.</p>



<h2 id="verifiability">Verifiability</h2>



<p>For quite some time, open source software has been distributed through various mirror sites so that downloads are sped up. Any user could download the software package quickly from a nearby mirror site. These nearby sites could be malicious and could provide compromised open source software packages. In order to overcome this problem, open source software builds would publish a checksum file on their website. This checksum file is used to verify that the downloaded package from a nearby mirror site is authentic. The checksum file actually contains a cryptographic hash of the software package.</p>



<p>For example: <a rel="noreferrer noopener" href="https://www.openoffice.org/download/checksums/3.4.1_checksums.html" target="_blank">Apache OpenOffice – Download checksum files</a>.</p>



<pre>e08f9c8acecba1ee0046f820b0abed97dfe90511bd733a65936fdf0ea9c22540  Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz</pre>



<p>This is the content from SHA256 checksum file for <a href="http://archive.apache.org/dist/incubator/ooo/files/stable/3.4.1/Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz.sha256" target="_blank" rel="noreferrer noopener">Apache Open Office SDK for Linux x86-64</a> build.</p>



<p>It would not matter which mirror site the SDK is downloaded from. A user can easily verify the authenticity of the download using a simple command like:</p>



<pre><code>$ sha256sum Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz
e08f9c8acecba1ee0046f820b0abed97dfe90511bd733a65936fdf0ea9c22540  Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz</code></pre>



<p>If the generated SHA256 does not match with the checksum file, the user knows that the software package has been tampered.</p>



<p>We will use the same technique to verify data objects. The data object we are interested in would have an ID. Any application or service asks for objects using IDs. If the data that the application gets does not generate the same hash value as the ID, then the application can easily conclude that the data is not what was asked for or the data has mutated. On a typical hardware the cryptographic hash function would take a few microseconds to generate the hash value. So, this is not costly and offers good verifiability.</p>



<p>In the context of this post, the verifiability that we are seeking is not because we operate in a trust-less or adversarial environment like Blockchains, but mainly because data can become corrupt or can be deliberately changed by hackers / attackers. This is for companies to verify that the data they hold has not been modified undesirably.</p>



<h4 id="verify-id">Application: Deterministic and Verifiable IDs</h4>



<p>In a typical RESTful request, a client posts a request to a service, and the service returns back an ID. The service uses the ID to index the object that got created due to the request. However, with a predetermined ID generation technique, it is possible for the client to know the ID even before the service receives the request. This is done even in blockchains. The transactionID (also referred as <a href="https://wiki.bitcoinsv.io/index.php/TXID" target="_blank" rel="noreferrer noopener">TXID</a>) is a hash computed from certain fields of a transaction request.</p>



<p>To be able to know the ID of an object that will be returned by a service even before the object is created in a service has significant benefits. </p>



<ol><li>Just by computing the ID from the fields of an object, and comparing it with the ID provided in the object, one can determine if the object is the right object. Housekeeping processes can easily determine data corruption or software bugs or potential attacks.</li><li>Request need not be processed synchronously.</li><li>The client can fire a batch of requests in just one call. Each individual request can easily be identified by the request id which will be deterministic for both the client and the service. This eliminates the need to create IDs on the client side, and map them to the server side IDs.</li><li>Non-idempotent requests such as HTTP POST requests can achieve deterministic behaviour. Multiple POST requests (which could be because of software bug or infrastructural replays) will not cause harm, as the request ID is predetermined. The server can easily identify a duplicate request.</li></ol>



<p>Example: To generate an OrderID, one could take the sha256 of a series of bytes of the quantity, price, dateTime of the order, clientID, and the assetID or assetSymbol.</p>



<pre><code>OrderID = sha256(bytes(qty)||bytes(price)||bytes(dateTime)||bytes(clientID)||bytes(assetID))</code></pre>



<h4 id="data-format">Data format and ID Generation</h4>



<p>While the scheme above for ID generation works, it has a certain drawback. For every type of objects, a developer would have to write an ID generator. This is not desirable. For a majority of the types of objects, the id generator should just be available easily. For this, the object itself can be serialised and the serialised stream of bytes can be hashed.</p>



<p>It is important to note that text based data structures like JSON, XML are not very well suited for this. The main reason behind this is that adding a space or TAB within the document will not alter the data for JSON or XML, however will yield a totally different hash value and therefore a totally different object ID. Hence, it is better to use serialisation formats designed for cross platform, multiple language environments and are deterministic. Compact data serialisation like <a rel="noreferrer noopener" href="https://developers.google.com/protocol-buffers" target="_blank">protocol buffers</a>, <a rel="noreferrer noopener" href="https://google.github.io/flatbuffers/" target="_blank">FlatBuffers</a>, <a rel="noreferrer noopener" href="https://avro.apache.org/" target="_blank">Apache Avro</a> and even <a rel="noreferrer noopener" href="https://tools.ietf.org/html/rfc7049" target="_blank">CBOR</a> are much better suited for this.</p>



<h2 id="immutability">Immutability and Verifiability</h2>



<p>Software professionals often jump to Blockchain to achieve immutability even in a non-adversarial environment like most business applications. Any party explicitly trying to cheat would face the court, and fraudulent transactions can be reverted in the most common business applications seen throughout the world. Therefore, there is no need for all the complexity and consensus algorithms like proof-of-work or proof-of-stake. Even on DLTs there are algorithms like Raft which are used to achieve consensus. Although much lesser in the power consumption, raft could still be an overkill for some …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/">https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/</a></em></p>]]>
            </description>
            <link>https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221324</guid>
            <pubDate>Mon, 22 Feb 2021 05:55:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiplexing Multipath P2P Mobile Transports]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220942">thread link</a>) | @bigfish24
<br/>
February 21, 2021 | https://www.ditto.live/blog/posts/the-new-network-multiplexer | <a href="https://web.archive.org/web/*/https://www.ditto.live/blog/posts/the-new-network-multiplexer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><nav aria-label="breadcrumb"><ol><li><a href="https://www.ditto.live/">Home</a></li><li><a href="https://www.ditto.live/blog/posts">Blog</a></li><li><a href="https://www.ditto.live/blog/posts/the-new-network-multiplexer">The New Network Multiplexer </a></li></ol></nav><p>Since the first versions of Ditto, devices always made multiple connections to other peers. For example, two iOS devices will try to connect simultaneously over WiFi, Apple Wireless Direct Link (AWDL), and Bluetooth Low Energy (BLE). We make multiple connections because each transport has different characteristics such as throughput and distance. For example, Bluetooth Low Energy works over long distances but has little bandwidth. AWDL has much more bandwidth but the devices need to be close together.</p>
<p>In the example below we see two iPhones syncing over AWDL and BLE. As one device gets further from the other, the AWDL connection will degrade and disconnect while the BLE connection sustains longer distances.</p>

<h2 id="pre-version-1.0.0">Pre-Version 1.0.0</h2>
<p>Before version 1.0.0, Ditto created a unique replication session for every transport. This is the software component which tracks queries and data changes and ensures that every Ditto device stays in sync. These separate replication pathways can appear or disappear as connections come and go, without disrupting sibling sessions.</p>
<p>When there is new data to sync, a session packs that data into an update file. With multiple concurrent sessions, all of them would then race against each other to transmit that update file as quickly as possible, regardless of duplication between transports. Transactional locking on the internal database made sure that only one session at a time could modify the update file, which prevented race conditions. Since any session is able to maintain the update file, any individual session can fail and replication will always continue, providing a high level of reliability.</p>
<p><img src="https://www.ditto.live/assets/blog/posts/the-new-network-multiplexer/old-way.svg" alt="old-way-sessions"></p>
<p>In this benchmark we see the consequences of each session sending data eagerly over every transport. In an attempt to send a document with about 2 megabytes of data, all five connected modes of transport aggressively sent data as fast as they could. We can see that the highly efficient AWDL transports could send all bytes first, and the remote peer quickly notified the slower connections that they could stop. However, the slower transports had already sent duplicate bytes. In the end, the peer had sent 5.4 megabytes even though the document size was about 2 megabytes. This was 2.6 times larger than the initial payload. Furthermore, this fully occupied the BLE radio, consuming bandwidth that could have been better used by a Bluetooth-only peer.</p>
<div>
  <table>
    <thead>
      <tr>
        <th>Transport</th>
        <th>Bytes Sent</th>
        <th>Packets Sent</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>AWDL Client</td>
        <td>2097944</td>
        <td>33</td>
      </tr>
      <tr>
        <td>AWDL Server</td>
        <td>2097944</td>
        <td>33</td>
      </tr>
      <tr>
        <td>BLE Client</td>
        <td>12288</td>
        <td>16</td>
      </tr>
      <tr>
        <td>BLE Server</td>
        <td>12288</td>
        <td>16</td>
      </tr>
      <tr>
        <td>TCP Server</td>
        <td>1170432</td>
        <td>36</td>
      </tr>
      <tr>
        <td>Grand Total</td>
        <td>5390896</td>
        <td>134</td>
      </tr>
    </tbody>
  </table>
</div>


<p>In version 1.0.0, we’ve introduced a completely new system for creating sync sessions between peers we call the multiplexer. Our first order of business was to reduce the duplication of sessions to the same peer over multiple transport types. We’ve introduced the concept of a virtual connection between two peers. No matter how many transport connections are active, there will only be one virtual connection and only one session. Now incoming data is buffered and intermediated from the transport layer to a single virtual connection.</p>
<p><img src="https://www.ditto.live/assets/blog/posts/the-new-network-multiplexer/new-way.svg" alt="new-way-multiplexer"></p>
<p>This new architecture allows each virtual connection to intelligently send data over multiple physical transports with fine-grained control. For example, the multiplexer can switch active transports on the fly without unnecessary duplication.</p>
<p>In this example:</p>
<ol>
<li>The multiplexer on the left device deemed that TCP (WiFi) was the best transport to start sending data.</li>
<li>Suddenly, the infastructure WiFi goes out, and the multiplexer switches to AWDL.</li>
<li>As the device moves away from its peer, AWDL is lost and the multiplexer switches to BLE.</li>
<li>The devices move closer together and the multiplexer finishes the rest of the transmission over AWDL.</li>
</ol>

<p>Now the total bytes sent is equal to the size of the update file.</p>
<div>
  <table>
    <thead>
      <tr>
        <th>Transport</th>
        <th>Bytes Sent</th>
        <th>Packets Sent</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>AWDL Client</td>
        <td>524288</td>
        <td>8</td>
      </tr>
      <tr>
        <td>AWDL Server</td>
        <td>234264</td>
        <td>4</td>
      </tr>
      <tr>
        <td>BLE Client</td>
        <td>0</td>
        <td>0</td>
      </tr>
      <tr>
        <td>BLE Server</td>
        <td>421888</td>
        <td>206</td>
      </tr>
      <tr>
        <td>TCP Server</td>
        <td>917504</td>
        <td>28</td>
      </tr>
      <tr>
        <td>Grand Total</td>
        <td>2097944</td>
        <td>246</td>
      </tr>
    </tbody>
  </table>
</div>

<p>The introduction of the multiplexer is a gigantic step forward for Ditto's networking capabilities. Today, it focuses on using one transport at a time but this new foundation allows us to build even more powerful, dynamic and flexible replication techniques such as using multiple transports at a time over unreliable connections, streaming use cases, and decentralized data sync techniques reminiscent of BitTorrent.</p>
</div></div></div>]]>
            </description>
            <link>https://www.ditto.live/blog/posts/the-new-network-multiplexer</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220942</guid>
            <pubDate>Mon, 22 Feb 2021 04:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frustrated with Parler deplatforming, I am building a service no one can silence]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 192 (<a href="https://news.ycombinator.com/item?id=26218900">thread link</a>) | @anon20190221
<br/>
February 21, 2021 | https://1b677b8f8bb20100.github.io/introduction/ | <a href="https://web.archive.org/web/*/https://1b677b8f8bb20100.github.io/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p>This is the first post in this blog, it was published on February 19, 2021.</p>

<h2 id="motivation">Motivation</h2>

<h3 id="censorship">Censorship</h3>

<p>The year of 2020 will be remembered for the pandemic, the BLM movement, and the U.S. elections among other billion of things around the globe. It is funny I even mention the third one considering how little I give a damn about U.S. politics, yet this whole story begins with <a href="https://en.wikipedia.org/wiki/Parler">Parler</a> deplatforming that happened about a month ago. Let me remind you: Apple, Google, Amazon, and a few other companies terminated their service to the free speech social network for insufficient moderation effectively destroying the platform in a matter of just a couple of days. What the fuck?</p>

<p>OK, let me be clear with my position: I believe every private company has a right to refuse service to anyone, whether an individual or a business, but I also have my own right to despise them for exercising that. What they did was probably legal, but screw them anyway, they failed us. Regardless what these psychopathic corporations like to tell the public, they are only concerned with maximizing shareholder value, and if there is anything  even remotely resembling an image liability (through pressure by political radicals, cancel culture SJWs, you name it), they will not think twice. What disgusts me the most here is neither greed nor hypocrisy but their unwillingness to grow a pair of balls and stand up for freedom of speech.</p>

<p>You see, freedom of speech and expression must be absolute. You cannot have censorship-resistance with exceptions; otherwise, these exceptions could be used to remove or block anything unwanted, not only offensive. This way, the Chinese cannot access Wikipedia because of what originally started as a counter-terrorism measure, and the Russians cannot access LinkedIn because of what originally started as a children protection measure. We cannot deprive humanity of their freedom just because some small fraction of users might, unfortunately, use that freedom to spread offensive content. In the same way, you do not ban electricity because people get electrocuted.</p>

<p>Let us now switch from corporates to governments. Ooh, wee! Do not even get me started on that. And I am not even talking about cases like Google happily not letting people disable <a href="https://en.wikipedia.org/wiki/SafeSearch">SafeSearch</a> in Indonesia because its government knows best, that is just the tip of the iceberg. I am talking about political censorship which includes silencing people with torture, gulags, and bullets. Here is the world map of the freedom of the press status:</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/press-freedom.png" alt="2020 Press Freedom Index"></p>

<p>Just look at this mess. Blue tones mean OK-ish, others not so much. This map is <a href="https://de.wikipedia.org/wiki/User:NordNordWest">NordNordWest</a>’s work based on the <a href="https://rsf.org/en/ranking">2020 Press Freedom Index</a> and is distributed under <a href="https://creativecommons.org/licenses/by-sa/3.0/de/legalcode">CC BY-SA 3.0 de</a>. Keep in mind population densities, e.g. there are about 90 times more people per unit area living in Vietnam than Australia. I am actually surprised the U.S. did so well in 2020 considering how badly they wanted <a href="https://en.wikipedia.org/wiki/Julian_Assange">Mr. Assange</a> to be extradited and executed.</p>

<p>What would you answer your children if they asked you how in the world North Korea still exists in its current form with 25 million Koreans suffering for over 70 years and no one is doing anything about that? Or how about 28 million people in Venezuela? Or 82 million people in Iran? Giving voice to all whistleblowers and activists, especially the ones risking their lives and freedom in hostile environments is the fundamental goal of Pepe.</p>

<h3 id="darknets">Darknets</h3>

<p>There is already <a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">Tor</a>, <a href="https://en.wikipedia.org/wiki/I2P">I2P</a>, <a href="https://en.wikipedia.org/wiki/Freenet">Freenet</a>, <a href="https://en.wikipedia.org/wiki/GNUnet">GNUnet</a> etc. We can run emails, message boards, <a href="https://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a>, <a href="https://en.wikipedia.org/wiki/Kad_network">Kad</a>, and <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> on top of them, maybe even use <a href="https://en.wikipedia.org/wiki/Ethereum">Ethereum</a> smart contracts for decentralized computing. All the technology is there, why bother with something new? Well, first of all, these are all amazing projects, there is nothing wrong with them. The peculiar thing, however, is none of them except BitTorrent (and perhaps Tor) gained much popularity, neither do we see any readily available censorship-resistant communication platforms. Why is that?</p>

<p>I claim there are 2 main reasons for that:</p>

<ul>
  <li>
    <p>They are hard to use. The “Unix is user-friendly, it is just picky about who its friends are.” aphorism still lives in most them: you may need to install a bunch of additional software (such as <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">JVM</a> or shared libraries) potentially dealing with a dependency hell on some platforms; read through sparse documentation and dead forums on optimal network, security, and sharing settings; carefully configure your router, computer, and client; install, study, and configure applications running on top of the darknet, i.e. repeat the steps. The reason why Tor became popular outside of research was not because it was first, but because of the hacky all-in-one Tor Browser Bundle with sane defaults.</p>
  </li>
  <li>
    <p>They prefer purity to practicality. Instead of concentrating manpower on few specific use cases, most existing tools try to conquer the world: a new internet, interplanetary, infrastructure, an application framework, APIs, a Turing-complete language on the blockchain etc. This is great and all, it is general, conceptual, modular, extensible, and stackable—everything we like—but sometimes overengineering is just overengineering given the goal. And our goal here is not to make a technical revolution, but to help as many people as we can communicate without fear of retribution.</p>
  </li>
</ul>

<p>BitTorrent evolved into something that is used by 150 million people worldwide, it seamlessly adopted <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>, <a href="https://en.wikipedia.org/wiki/Peer_exchange">PEX</a>, <a href="https://en.wikipedia.org/wiki/Micro_Transport_Protocol">µTP</a>, trackerless <a href="https://en.wikipedia.org/wiki/Magnet_URI_scheme">magnet links</a>, and people do not even know what the hell it all means. Even though proprietary, <a href="https://en.wikipedia.org/wiki/Skype">Skype</a> thrived very similarly (at least before it was crippled by Microsoft), millions of its users did not even know what peer-to-peer meant, not to mention how it worked under the hood, it just did. These two systems succeeded not because of luck but rather as a result of some excellent product decisions. We need to learn from that and reiterate.</p>

<h2 id="pepe-overview">Pepe overview</h2>

<h3 id="user-level">User level</h3>

<p>For the messaging platform, I chose to use an <a href="https://en.wikipedia.org/wiki/Imageboard">imageboard</a> similar to <a href="https://en.wikipedia.org/wiki/4chan">4chan</a> or <a href="https://en.wikipedia.org/wiki/Futaba_Channel">Futaba Channel</a>. While not the most popular type of forum, imageboards are extremely flexible and free of junk like authentication or karma, they promote anonymity in a very practical way, and over 30 million people are already familiar with them. Perhaps, I am not a big fan of their crowded old-school design, but the initial user traction is more important than my sense of beauty, we will refine the looks through time.</p>

<p>That is, the Pepe imageboard is going to be the only application running on top the Pepe darknet, they are in fact inseparable. This way, we can design the network specifically for this one use case. This brings both security and performance benefits. Joining the darknet can be as simple as double clicking the application, and users do not need to install or configure any third-party browsers or proxy servers, they can just go to <a href="http://localhost:8666/">localhost:8666</a> using Chrome, Safari, or whatever they like, and it is going to be safe without any third-party extensions.</p>

<p>Once online, users may browse existing or create new message boards about various topics in any language such as <code>/en/food/</code> or <code>/ja/math/</code>. A board is a collection of threads about something more specific, would it be an idea or a question. A thread has a collection of posts that people send replying to each other. Each post may have one or multiple attachments such as photos, videos, you name it. So that you have an idea of what it looks like, here is a screenshot of a random thread on the 4chan DIY board:</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/4chan-thread.png" alt="4chan thread"></p>

<p>What is fundamentally different with Pepe is moderation. Instead of relying on a centralized entity with a banhammer, each board and thread owner may anonymously moderate their spaces on their own. However, nothing can actually be deleted, it can only be shadowed, and each user decides whether they want to see the light or the full version of the page at any moment in time. People can still reply to shadowed posts inside their own shadowed posts, so no one cannot silence anyone, only maintain order on the light side.</p>

<p>If people are no longer interested in particular threads, they will eventually become forgotten by the network and naturally disappear from their board. But if there is at least one person who is subscribed to or has archived some thread, no one in the world (even Pepe creators) can censor or somehow shut it down without hurting most of the network Pepe is running on top of.</p>

<h3 id="network-level">Network level</h3>

<p>The three biggest problems with 4chan and similar communication platforms are:</p>

<ul>
  <li>They use closed source software so no one can tell how secure everything is and what is really going on there.</li>
  <li>They are centralized, i.e. some individual or business owns the servers and fully controls the whole infrastructure.</li>
  <li>They collect lots of metadata including but not limited to “someone with this <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> posted this at this moment in time”.</li>
</ul>

<p>Mitigating the first problem is the easiest: just use open-source software whenever possible. Regarding the centralization issue, we could switch to a decentralized solution like BitTorrent (imagine each torrent containing a thread with its posts and attachments), but that itself does not help with privacy, people can still see what others are doing. Similarly, we could tackle the privacy issue with a <a href="https://en.wikipedia.org/wiki/Virtual_private_network">VPN</a> or a darknet like Tor or I2P, but that, contrary to popular belief, does not solve the centralization issue in any way. Clearly, we need the best of the two worlds. Let us fuse them together!</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/pepe-routing.png" alt="Pepe routing"></p>

<p>Here is an very simplified walk through how the network works. Imagine Bob is an undercover journalist who wants to anonymously share his report and Alice is a political activist who is interested in the investigation Bob had been doing. It all starts with Bob announcing he has the report:</p>

<ol>
  <li>
    <p>Bob joins the network and gathers information about random peers on it through the <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>. This way, Bob discovers hundreds of participants including X and Y. Similarly, Bob registers himself on the network through the DHT so that others …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://1b677b8f8bb20100.github.io/introduction/">https://1b677b8f8bb20100.github.io/introduction/</a></em></p>]]>
            </description>
            <link>https://1b677b8f8bb20100.github.io/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218900</guid>
            <pubDate>Mon, 22 Feb 2021 00:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TransferWise changes name to Wise]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 226 (<a href="https://news.ycombinator.com/item?id=26218693">thread link</a>) | @watbe
<br/>
February 21, 2021 | https://wise.com/gb/blog/world-meet-wise | <a href="https://web.archive.org/web/*/https://wise.com/gb/blog/world-meet-wise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<p>Today, we’re changing our name from TransferWise to Wise.</p>
<p>Our customers now need us for more than money transfers. Sending, spending, and receiving money internationally is too expensive, slow, and inconvenient. We’re fixing that for people and businesses.</p>
<p>You can <a href="https://transferwise.com/gb/blog/world-meet-wise#transferwise-is-now-wise">skip ahead to see what changes for you</a> (spoiler: not much, right away), but first, let’s go back a bit.</p>
<h2><a href="#a-decade-into-our-mission" id="a-decade-into-our-mission"></a>A decade into our mission</h2>
<p>Ten years ago, Taavet and I set out to fix international money transfers for all of us who’d been overcharged and underserved by banks. We named our idea ‘TransferWise’ — because our early customers were ‘wise’ to know their banks were charging hidden fees in exchange rate markups.</p>
<p>We set ourselves a mission to make money work without borders — to make money move instantly, transparently, conveniently, and — eventually — for free.</p>
<p>Now, we’re a community of 10 million like-minded people and businesses managing money all over the world, saving billions and fighting as hard as ever against hidden fees.</p>
<p>Our multi-currency account and the clever debit card is replacing international banking for many of you. By building this infrastructure for you, we’ve created a platform that more than a dozen banks use today.</p>
<p>You’ve told us for years the problem is bigger than money transfers. Any time money moves into another currency, it’s still a maze of hidden exchange rate markups, high fees, delays, and small print.</p>
<h2><a href="#well-fix-international-banking-together" id="well-fix-international-banking-together"></a>We’ll fix international banking together</h2>
<p>Sending, spending, receiving, and holding money internationally doesn’t work like it should, because the international banking system was built for the past.</p>
<p>For generations, banks have been defined by borders. Traditional bank accounts trap our money in one country, making international lives more difficult and expensive than they need to be. We shouldn’t have to accept this status quo.</p>
<p>Today, we don’t. We’ll fix it with Wise — the world’s most international account. It makes your money borderless — with instant, super-cheap money transfers, a debit card to spend in any currency, account details to get paid in 30+ countries, balances to hold your money safely in 50+ different currencies, multi-currency direct debits, and other revolutionary features.</p>
<h2><a href="#transferwise-is-now-wise" id="transferwise-is-now-wise"></a>TransferWise is now Wise</h2>
<p>Today our name catches up with who we’re already building for — a community of people and businesses with multi-currency lives. Wise is for all of us who live, work, travel, or support family around the world. It’s for those of us who want to cut out the middlemen that hold us back from being truly borderless.</p>
<p>For customers, not too much will change right away. We become “Wise” or “Wise Business” — depending how you use us. You can access your exact same account via <a href="http://wise.com/">wise.com</a>, using your current email and password. You won't need a new account. In a few weeks we will start to redirect transferwise.com to wise.com.</p>
<p>Our logo has changed, and our apps will be renamed. But our icon — the fast flag — remains as a symbol for money without borders. Beyond that, you’ll notice some new colours, words, and designs.</p>
<p>The core experience of using Wise will remain faster, cheaper, and more convenient than anything else. Our mission remains the same. We’re still making — and always will be making — money work without borders.</p>
<p>We’re humbled that 10 million of you already rely on us to help you lead your international lives. We can’t wait to bring the next 100 million of you with us as we continue to build a new, fair, and transparent world of money.</p>
<p>Onwards.</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://wise.com/gb/blog/world-meet-wise</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218693</guid>
            <pubDate>Mon, 22 Feb 2021 00:02:25 GMT</pubDate>
        </item>
    </channel>
</rss>
