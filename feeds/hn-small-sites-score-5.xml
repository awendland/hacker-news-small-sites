<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 23 Sep 2020 16:26:07 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 23 Sep 2020 16:26:07 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Security September: Cataclysms in the Cloud Formations]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552986">thread link</a>) | @boyter
<br/>
September 22, 2020 | https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations | <a href="https://web.archive.org/web/*/https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

		<div data-page-title="Security September: Cataclysms in the Cloud Formations – One Cloud Please">

			<section>

	

</section>

<section>

	<p><img src="https://onecloudplease.com/images/posts/security-september-1.jpg" alt=""></p>

<p><em>This is the fourth of a 5-part series on AWS exploits and similar findings discovered over the course of 2020. All findings discussed in this series have been <a href="https://aws.amazon.com/security/vulnerability-reporting/">disclosed</a> to the AWS security team and had patches rolled out to all affected regions, where necessary. A big thanks to my friend and fellow Australian <a href="https://twitter.com/__steele">Aidan Steele</a> for co-authoring this series with me. This post was written by Aidan.</em></p>

<p>Back in November 2019, AWS CloudFormation <a href="https://aws.amazon.com/about-aws/whats-new/2019/11/now-extend-aws-cloudformation-to-model-provision-and-manage-third-party-resources/">added support</a> for “resource providers” - a new and improved way of extending CloudFormation with user-authored resources. Not just that, it is also the way that all new resources are added to CloudFormation by AWS themselves. This was a substantial improvement over “custom resources”, which hadn’t seen any change since at least 2013 other than <a href="https://aws.amazon.com/about-aws/whats-new/2015/04/aws-cloudformation-supports-aws-lambda-backed-custom-resources/">Lambda support in 2015</a>. This post won’t get into the differences or benefits of resource providers, for that check out <a href="https://aws.amazon.com/blogs/mt/managing-resources-using-aws-cloudformation-resource-types/">this AWS blog post</a>.</p>

<p>On January 17th, <a href="https://twitter.com/ben11kehoe">Ben Kehoe</a> CloudFormation extraordinaire sent me a Twitter DM with a link to a GitHub <a href="https://github.com/aws-cloudformation/cloudformation-cli-python-plugin/pull/71">pull request</a> that set off his spidey-senses. I was excited to receive this because a) Ben thought of me! and b) it combined CloudFormation and credentials in the cloud in a novel way, two of my favourite things. This was the excuse I needed to finally dig into resource providers - albeit not until the 21st when I had some time.</p>

<h2 id="pulling-things-apart">Pulling things apart</h2>

<p>The first thing I noticed is that (unlike custom resources) the Lambda function you are authoring ends up not running in your AWS account - it runs in an AWS-managed account. I was immediately curious about what permissions <strong>my</strong> code had in <strong>their</strong> account - you’d hope it’s locked down! I was also curious about how the code I wrote appeared to have a role in my account - where was the role being assumed?</p>

<p>Rather than try to understand the framework provided by CloudFormation and how things are <strong>meant</strong> to work, I decided to drop down a level and log the raw input to the Lambda function, to see how things <strong>actually</strong> work. This is an excerpt of the input passed to the Lambda when a resource is being created:</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-2.png" alt=""></p>

<p>So there are at least <strong>four</strong> different sets of credentials in play here:</p>

<ul>
  <li>The <code>callerCredentials</code>: These are the credentials that I am expected to use. They are for the role assumed in <strong>my</strong> account to actually create, update, delete, etc the resource in question.</li>
  <li>The <code>providerCredentials</code>: These are the credentials for the <code>LogAndMetricsDeliveryRole</code> role in the <code>CloudFormationManagedUploadInfrastructure</code> stack, i.e. for writing logs that appear in <strong>my</strong> account.</li>
  <li>The (not pictured) Lambda execution role’s credentials: this appears to have permission only to write logs within the AWS-managed account.</li>
  <li>The <code>platformCredentials</code>: These are the interesting ones. They are for a role in the AWS-managed account. That role has permission to call a handful of permissions, but the ones that caught my eye were <code>events:PutRule</code>, <code>events:PutTarget</code>, <code>events:RemoveTarget</code>, <code>events:DeleteRule</code>.</li>
</ul>

<p>Why does the Lambda function need permission to invoke those EventBridge APIs? Resource creation might take a long time and Lambda is limited to 15 minutes, so the service has support for reinvoking the Lambda periodically to ask “is it done yet?” and EventBridge cron jobs are a great fit for this. The way it works is by creating a one-off rule scheduled to run one minute in the future, with a target of the same Lambda. It specifies that the Lambda should be reinvoked with a hardcoded input string - namely the input that <strong>this</strong> invocation of the Lambda received.</p>

<h2 id="curiosity-intensifies">Curiosity intensifies</h2>

<p>This piqued my curiosity. What if I used the API to trigger a different target, like a Lambda in my account? No luck, they must have used the <code>events:TargetArn</code> condition key to restrict the target to only this Lambda. So I tried something else: what if instead I tried a different rule? I tried to create a rule that would invoke my Lambda in their account that matched events with <code>{"detail-type": ["AWS API Call via CloudTrail"]}</code>. I was immediately inundated with a firehose of events. I rushed to turn it off as it wasn’t my intention to break things, just curiosity.</p>

<p>I looked at the events. Was this really a security issue or more a “that’s cute” kind of thing? Most events were uninteresting. But one caught my eye. It was a call to <code>events:PutTarget</code>. The CloudTrail event included the payload. I’ve highlighted the noteworthy part.</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-3.png" alt=""></p>

<p>In order to reinvoke the function a minute later with the same payload, we established earlier that the target was created with a constant JSON input. That input includes credentials for a role in the customer’s account. Multiple (all?) customers are serviced by the AWS-managed account. So I could see credentials for other AWS customers using resource providers. They might be using it without realising: AWS are using this pattern for first-party types - I saw <code>AWS::WAFv2::RuleGroup</code> fly by in the logs.</p>



<p>That afternoon I reported the issue to the <a href="https://aws.amazon.com/security/vulnerability-reporting/">AWS security team</a>. They got back to me within 9 hours. They asked for some clarification (fair, I was a bit frazzled when I wrote the first email!) and any reproduction steps I could provide. Given I’d slapped together a very manual proof-of-concept, I set about creating a more useful reproduction for them.</p>

<p>The CloudFormation service team also reached out to me. They indicated that they had actually already caught this internally and a fix was underway. A few days later on January 25th, they told me that a fix had been deployed to a couple of regions and asked if I could try again. A few minutes later, I got a follow up from the AWS security team with the same request - things move surprisingly quickly at AWS!</p>

<p>I tried again. After creating my rule I got a few events, but it quickly dried up without me even needing to turn it off. I looked through the events recorded. I didn’t see any of those problematic ones before, no matter how many times I tried. I did see this interesting one though:</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-4.png" alt=""></p>

<p>Clever! They had created an alarm that would trigger whenever a malicious rule was created. This was a solid tactical mitigation. Unfortunately the IAM policy conditions available on <code>events:PutRule</code> weren’t rich enough to block me outright, but this stopped the bleeding. I also noticed the unusual absence of any of the <code>events:PutTarget</code> API call events. I don’t know how they did this as omitting those from CloudTrail/EventBridge isn’t possible for customers’ accounts. I guess AWS have some secret sauce.</p>

<h2 id="closing-out">Closing out</h2>

<p>On January 31st I got a follow up email from AWS Security letting me know that the issue has been resolved.</p>

<p>On June 30th the CloudFormation team released version 2 of the resource provider protocol. It came with a number of benefits, but the change most visible to me was that the <code>platformCredentials</code> field had disappeared. It is no longer necessary as CloudFormation itself handles the reinvocation of the Lambda function.</p>

<p>Finally, on August 26th AWS sent out the following email, gently encouraging people to migrate to the new protocol for resource providers. I wouldn’t be surprised if this was followed by an eventual deprecation of v1.</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-5.png" alt=""></p>

<h2 id="thanks">Thanks</h2>

<p>I’d like to thank Ben Kehoe for pointing this out to me in the first place. Without his keen eye and intuition for sensible security, I would have never noticed this. I’d like to thank Ian for being a great sounding board throughout the process. His <a href="https://twitter.com/iann0036/status/1161871038336028672">tweets</a> last year about Lake Formation issues made me feel confident that AWS would respond positively to my email. I’d also like to thank the AWS Security team who made me feel very comfortable both reporting my first issue and that it was being addressed in a thorough and impressively timely fashion. And a second thanks to Ian for motivating me to write my first blog posts in years!</p>


</section>

		</div>

	</div></div>]]>
            </description>
            <link>https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552986</guid>
            <pubDate>Tue, 22 Sep 2020 10:48:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypassing ESP32 Encrypted Secure Boot]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24552482">thread link</a>) | @mleonhard
<br/>
September 22, 2020 | https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/ | <a href="https://web.archive.org/web/*/https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>We arrived at the last post about our <strong>Fault Injection</strong> research on the <strong>ESP32</strong>. Please read our previous posts as it provides context to the results described in this post.</p>
<ul>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-bypassing-sb-using-emfi/">Espressif ESP32: Bypassing Secure Boot using EMFI</a></li>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-controlling-pc-during-sb/">Espressif ESP32: Controlling PC during Secure Boot</a></li>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-bypassing-flash-encryption/">Espressif ESP32: Bypassing Flash Encryption (CVE-2020-15048)</a></li>
</ul>
<p>During our <strong>Fault Injection</strong> research on the <strong>ESP32</strong>, we gradually took steps forward in order to identify the required vulnerabilities that allowed us to bypass <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> with a single <strong>EM</strong> glitch. Moreover, we did not only achieve <strong>code execution</strong>, we also extracted the <strong>plain-text flash</strong> data from the chip.</p>
<p><strong>Espressif</strong> requested a <strong>CVE</strong>  for the attack described in this post: <a href="https://www.espressif.com/sites/default/files/advisory_downloads/Security%20Advisory%20CVE-2020-15048%2C%2013629%20EN%26CN.pdf" target="_blank">CVE-2020-13629</a>. Please note, that the attack as described in this post, is only applicable to <strong>ESP32</strong> silicon revision 0 and 1. The newer <strong>ESP32 V3</strong> silicon supports functionality to disable the <strong>UART bootloader</strong> that we leveraged for the attack.</p>

<p>The <strong>ESP32</strong> implements an <strong>UART bootloader</strong> in its <strong>ROM code</strong>. This feature allows, among other functionality, to program the external flash. It's not uncommon that such functionality is implemented in the <strong>ROM code</strong> as it's quite robust as the code cannot get corrupt easily. If this functionality would be implemented by code stored in the external flash, any corruption of the flash may result in a bricked device.</p>
<p>Typically, this type of functionality is accessed by booting the chip in a special <strong>boot mode</strong>. The <strong>boot mode</strong> selection is often done using one or more external strap pin(s) which are set before resetting the chip. On the <strong>ESP32</strong> it works exactly like this pin <code>G0</code> which is exposed externally.</p>
<p>The <strong>UART bootloader</strong> supports many interesting <a href="https://github.com/espressif/esptool/wiki/Serial-Protocol#command-opcodes" target="_blank">commands</a> that can be used to read/write memory, read/write registers and even execute a stub from <strong>SRAM</strong>.</p>
<h4 id="executing-arbitrary-code">Executing arbitrary code</h4>
<p>The <strong>UART bootloader</strong> supports loading and executing arbitrary code using the <code>load_ram</code> command. The <strong>ESP32</strong>'s SDK includes all the tooling required to compile the code that can be executed from <strong>SRAM</strong>. For example, the following code snippet will print <code>SRAM CODE\n</code> on the serial interface.</p>
<div><pre><code data-lang="C"><span>void</span> <span>__attribute__</span><span>((</span><span>noreturn</span><span>))</span> <span>call_start_cpu0</span><span>()</span>
<span>{</span>
    <span>ets_printf</span><span>(</span><span>"SRAM CODE</span><span>\n</span><span>"</span><span>);</span>
    <span>while</span> <span>(</span><span>1</span><span>);</span>
<span>}</span>
</code></pre></div><p>The <code>esptool.py</code> tool, which is part of the <strong>ESP32</strong>'s SDK, can be used to load the compiled binary into the <strong>SRAM</strong> after which it will be executed.</p>
<pre><code>esptool.py --chip esp32 --no-stub --port COM3 load_ram code.bin
</code></pre><p>Interestingly, the <strong>UART bootloader</strong> cannot disabled and therefore always accessible, even when <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> are enabled.</p>
<h4 id="additional-measures">Additional measures</h4>
<p>Obviously, if no additional security measures would be taken, leaving the <strong>UART bootloader</strong> always accessible would render <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> likely useless. Therefore, <strong>Espressif</strong> implemented additional security measures which are enabled using dedicated <strong>eFuses</strong>.</p>
<p>These are security configuration bits implemented in special memory, often referred to as <strong>OTP memory</strong>, which can typically only change from 0 to 1. This guarantees, that once enabled, is enabled forever. The following <strong>OTP memory</strong> bits are used to disable specific functionality when the <strong>ESP32</strong> is in the <strong>UART bootloader</strong> boot mode.</p>
<ul>
<li><strong>DISABLE_DL_ENCRYPT</strong>: disables flash encryption operation</li>
<li><strong>DISABLE_DL_DECRYPT</strong>: disables transparent flash decryption</li>
<li><strong>DISABLE_DL_CACHE</strong>: disables the entire MMU flash cache</li>
</ul>
<p>The most relevant <strong>OTP memory</strong> bit is <strong>DISABLE_DL_DECRYPT</strong> as it disables the transparent decryption of the flash data.</p>
<p>If not set, it would be possible to simply access the plain-text flash data while the <strong>ESP32</strong> is in its <strong>UART bootloader</strong> boot mode.</p>
<p>If set, any access to the flash, when the chip is in <strong>UART bootloader</strong> boot mode, will yield just the encrypted data. The <strong>Flash Encryption</strong> feature, which is fully implemented in hardware and transparent to the processor,  is only enabled in when the <strong>ESP32</strong> is in <strong>Normal</strong> boot mode.</p>
<p>The attacks described in this post have all these bits set to 1.</p>

<p>The <strong>SRAM</strong> memory that's used by the <strong>ESP32</strong> is typical technology that's used by many chips. It's commonly used to the <strong>ROM</strong>'s stack and executing the first bootloader from flash. It's convenient to use at early boot as it typically require no configuration before it can be used.</p>
<p>We know from previous experience that the data stored in <strong>SRAM</strong> memory is persistent until it's overwritten or the required power is removed from the physical cells. After a <strong>cold reset</strong> (i.e. power-cycle) of the chip, the <strong>SRAM</strong> will be reset to its default state. This often semi-random and unique per chip as the default value for each bit (i.e. 0 or 1) is different.</p>
<p>However, after a <strong>warm reset</strong>, where the entire chip is reset without removing the power, it may happen that the data stored in <strong>SRAM</strong> remains unaffected. This persistence of the data is visualized in the picture below.</p>
<p>
    <a href="https://raelize.com/img/esp32/esp32-sram-persistence.png">
        <img src="https://raelize.com/img/esp32/esp32-sram-persistence.png" width="700px">
    </a>
</p>
<p>We decided to figure out if this behavior holds up for the <strong>ESP32</strong> as well. We identified that the hardware <a href="https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/system/wdts.html" target="_blank">watchdog</a> can be used to issue a <strong>warm reset</strong> from software. This <strong>watchdog</strong> can also be issued when the chip is in <strong>UART bootloader</strong> boot mode and therefore we can use it to reset the <strong>ESP32</strong> back into <strong>Normal</strong> boot mode.</p>
<p>Using some test code, loaded and executed in <strong>SRAM</strong> using the <strong>UART bootloader</strong>, we determined that the data in <strong>SRAM</strong> is indeed persistent after issuing a <strong>warm reset</strong> using the <strong>watchdog</strong>. Effectively this means we can boot the <strong>ESP32</strong> in <strong>Normal</strong> boot mode with the <strong>SRAM</strong> filled with controlled data.</p>
<p>But… how can we (ab)use this?</p>

<p>We envisioned that we may be able to leverage the persistence of data in <strong>SRAM</strong> across <strong>warm resets</strong> for an attack. The first attack we came up with is to fill the <strong>SRAM</strong> with code using the <strong>UART bootloader</strong> and issue a <strong>warm reset</strong> using the <strong>watchdog</strong>. Then, we inject a glitch while the <strong>ROM code</strong> is overwriting this code with the <strong>flash bootloader</strong> during a normal boot.</p>
<p>We got this ideas as during our previous experiments, where we <a href="">turned data transfers into code execution</a>, we noticed that for some experiments the chip started executing from the entry address before the bootloader was finished copying.</p>
<p>Sometimes you just need to try it…</p>
<h4 id="attack-code">Attack code</h4>
<p>The code that we load into the <strong>SRAM</strong> using the <strong>UART bootloader</strong> is shown below.</p>
<div><pre><code data-lang="C"><span>#define a "addi a6, a6, 1;"
</span><span>#define t a a a a a a a a a a
</span><span>#define h t t t t t t t t t t
</span><span>#define d h h h h h h h h h h
</span><span></span>
<span>void</span> <span>__attribute__</span><span>((</span><span>noreturn</span><span>))</span> <span>call_start_cpu0</span><span>()</span> <span>{</span>
    <span>uint8_t</span> <span>cmd</span><span>;</span>

    <span>ets_printf</span><span>(</span><span>"SRAM CODE</span><span>\n</span><span>"</span><span>);</span>

    <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{</span>

        <span>cmd</span> <span>=</span> <span>0</span><span>;</span>
        <span>uart_rx_one_char</span><span>(</span><span>&amp;</span><span>cmd</span><span>);</span>

        <span>if</span><span>(</span><span>cmd</span> <span>==</span> <span>'A'</span><span>)</span> <span>{</span>                                    <span>// 1
</span><span></span>            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff4808c</span><span>)</span> <span>=</span> <span>0x4001f880</span><span>;</span>
            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff48090</span><span>)</span> <span>=</span> <span>0x00003a98</span><span>;</span>
            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff4808c</span><span>)</span> <span>=</span> <span>0xc001f880</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>asm</span> <span>volatile</span> <span>(</span> <span>d</span> <span>);</span>                                     <span>// 2
</span><span></span>
    <span>"movi a6, 0x40; slli a6, a6, 24;"</span>                       <span>// 3
</span><span></span>    <span>"movi a7, 0x00; slli a7, a7, 16;"</span>
    <span>"xor a6, a6, a7;"</span>
    <span>"movi a7, 0x7c; slli a7, a7, 8;"</span>
    <span>"xor a6, a6, a7;"</span>
    <span>"movi a7, 0xf8;"</span>
    <span>"xor a6, a6, a7;"</span>

    <span>"movi a10, 0x52; callx8  a6;"</span> <span>// R
</span><span></span>    <span>"movi a10, 0x61; callx8  a6;"</span> <span>// a            
</span><span></span>    <span>"movi a10, 0x65; callx8  a6;"</span> <span>// e               
</span><span></span>    <span>"movi a10, 0x6C; callx8  a6;"</span> <span>// l               
</span><span></span>    <span>"movi a10, 0x69; callx8  a6;"</span> <span>// i               
</span><span></span>    <span>"movi a10, 0x7A; callx8  a6;"</span> <span>// z               
</span><span></span>    <span>"movi a10, 0x65; callx8  a6;"</span> <span>// e               
</span><span></span>    <span>"movi a10, 0x21; callx8  a6;"</span> <span>// !               
</span><span></span>    <span>"movi a10, 0x0a; callx8  a6;"</span> <span>// \n               
</span><span></span>
    <span>while</span><span>(</span><span>1</span><span>);</span>
<span>}</span>
</code></pre></div><p>To summarize, the above code implements the following:</p>
<ol>
<li>Command handler with a single command to perform a <strong>watchdog</strong> reset</li>
<li>NOP-like padding using <code>addi</code> instructions</li>
<li>Assembly for printing <code>Raelize!</code> on the serial interface</li>
</ol>
<p>Please note, the listing's numbers match the numbers in the code.</p>
<h4 id="timing">Timing</h4>
<p>We target a reasonably small attack window at the start of <strong>F</strong> which is shown in the picture below. We know from previous experiments that during this moment the <strong>flash bootloader</strong> is copied.</p>
<p>
    <a href="https://raelize.com/img/esp32/esp32-spi-pin1-during-boot.png">
        <img src="https://raelize.com/img/esp32/esp32-spi-pin1-during-boot.png" width="600px">
    </a>
</p>
<p>The glitch must be injected before our code in <strong>SRAM</strong> is entirely overwritten by the valid <strong>flash bootloader</strong>.</p>
<h4 id="attack-cycle">Attack cycle</h4>
<p>We took the following steps for each experiment to determine if the attack idea actually works. A successful glitch will print <code>Raelize!</code> on the serial interface.</p>
<ol>
<li>Set pin <strong>G0</strong> to low and perform a <strong>cold reset</strong> to enter <strong>UART bootloader</strong> boot mode</li>
<li>Use the <code>load_ram</code> command to execute our <strong>attack code</strong> from <strong>SRAM</strong></li>
<li>Send an <code>A</code> to the program to issue a <strong>warm reset</strong> into <strong>normal</strong> boot mode</li>
<li>Inject a glitch while the <strong>flash bootloader</strong> is being copied by the <strong>ROM code</strong></li>
</ol>
<h4 id="results">Results</h4>
<p>After running these experiments for more than a day, resulting in more than 1 million experiments, we did not observe any successful glitch…</p>
<h4 id="an-unexpected-result">An unexpected result</h4>
<p>Nonetheless, while analyzing the results, we noticed something unexpected.</p>
<p>The <strong>serial interface</strong> output for one of the experiments, which is shown below, indicated that the glitch caused an <strong>illegal instruction</strong> exception.</p>
<pre><code>ets Jun  8 2016 00:22:57
rst:0x10 (RTCWDT_RTC_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0008,len:4
load:0x3fff000c,len:3220
load:0x40078000,len:4816
load:0x40080400,len:18640
entry 0x40080740
Fatal exception (0): IllegalInstruction
epc1=0x661b661b, epc2=0x00000000, epc3=0x00000000, 
excvaddr=0x00000000, depc=0x00000000
</code></pre><p>These type of exceptions happened quite often when glitches are injected in a chip. This was not different for the <strong>ESP32</strong>. For most the exceptions the <code>PC</code> register is set to a value that's expected (i.e. a valid address). It does not happen often the <code>PC</code> register is set to such an interesting value.</p>
<p>The <code>Illegal Instruction</code> exception is caused as there is no valid instruction stored at the <code>0x661b661b</code> address. We conclude this value must come from somewhere and that is cannot magically end up in the <code>PC</code> register.</p>
<p>We analyzed the code that we load into the <strong>SRAM</strong> in order to find an explanation. The …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/">https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/</a></em></p>]]>
            </description>
            <link>https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552482</guid>
            <pubDate>Tue, 22 Sep 2020 09:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolutionary Design of Up Banking]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24552043">thread link</a>) | @merricksb
<br/>
September 22, 2020 | https://up.com.au/blog/the-evolutionary-design-of-up/ | <a href="https://web.archive.org/web/*/https://up.com.au/blog/the-evolutionary-design-of-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>When we launched nearly 2 years ago, we declared our first principles approach to banking:</p>
<blockquote>
<p>“Challenge the assumptions and limitations in banking and re-evaluate them from a more current point of view."</p>
</blockquote>
<p>This statement did not come out of a contrived workshop, or committee, or a board of investors. It was the resonating sentiment of a team that had spent years in the weeds of banking software and its bureaucracy. Existing banks have too much baggage to be able to see the future of banking for what it could be. They lacked the courage to really re-invent themselves. Some questions that emerged from that period:</p>
<ul>
<li><em>Why doesn’t every transaction have a timestamp, a merchant logo?</em></li>
<li><em>Why are all my payments to a particular person not grouped?</em></li>
<li><em>Why isn’t it easier to pay someone I’ve paid before?</em></li>
<li><em>Why am I sitting on hold on my phone to resolve an issue?</em></li>
<li><em>How can saving money be fun and engaging?</em></li>
</ul>
<p>We knew that if we followed our noses and solved these user-centric problems, and many others of course, that winning customers would take care of itself. We now have over 280,000 Upsiders and counting.</p>
<h2>Making Feedback Easy</h2>
<p>Up does not do traditional user testing. There, I said it. That’s our dirty secret.</p>
<p>We think there are other techniques that are faster and better indicators of real-world behaviour. We also believe we have two advantages:</p>
<ul>
<li><strong>An innovation mindset</strong></li>
<li><strong>A deeper relationship with our customers than any financial institution in Australia</strong></li>
</ul>
<p>Much of banking is a known problem space. We feel like we're taking a more creative approach to the problem, but that's not to say we don't rely on user feedback. Our <em>Talk to Us</em> section encourages Upsiders to give us feedback or suggest ideas. To date, we have received over 6,000 ideas via this channel, making it one of the most crucial conduits into the minds of our customers. We also have other highly-engaged channels such as our socials and the newsletter where we hear, almost instantly, what customers think of what we’ve delivered.</p>
<figure>
  <img loading="lazy" src="https://up.com.au/449d9fa0873011802b194d6b669ffe9e/feedback-categories.gif" alt="Initiating a 'Talk to Us' chat with our team">
  <figcaption>
    Our <em>Talk to Us</em> trinity; ask for help, give feedback and report a bug
  </figcaption>
</figure>
<h2>Engagement Is the Name of the Game</h2>
<p>So where do we get our inspiration? It's rarely in the banking or fintech space. These are the apps that exist on billions of devices and set the bar for mobile digital experiences:</p>
<figure>
  <span>
      <a href="https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/c6b2e/inspire_apps.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="World leaders for designing mobile experiences" title="World leaders for designing mobile experiences" src="https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/40619/inspire_apps.jpg" srcset="https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/b0fd2/inspire_apps.jpg 175w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/aaaf9/inspire_apps.jpg 350w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/40619/inspire_apps.jpg 700w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/e8c9e/inspire_apps.jpg 1050w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/5814a/inspire_apps.jpg 1400w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/c6b2e/inspire_apps.jpg 2175w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  <figcaption>
    The leaders in mobile experience design
  </figcaption>
</figure>
<p>While they vary in purpose, their collective dominance in the landscape means they teach and familiarise patterns to expect when using our phones.</p>
<ul>
<li><em>How does TikTok allow you to react to content quickly and effortlessly?</em></li>
<li><em>What similarities are there between Whatsapp, Messenger and Instagram when conversing with friends?</em></li>
<li><em>When explaining new features what language do these platforms use? When do they use visualisations? When do they use words?</em></li>
<li><em>When is Snapchat playful and when is it serious?</em></li>
<li><em>Do I identify with my real name or username for Instagram? What about Facebook?</em></li>
</ul>
<p>As users we immerse ourselves in the apps that have nailed engagement. While acknowledging the patterns they establish, we also appreciate the balance between knowing when to follow them and when to do our own thing. Up has a handful of atypical patterns, but as long as they are usable and intuitive they can become distinct moments used to engage and delight.</p>
<p>Why is it so important that Upsiders engage with the Up app? Aside from the opportunity to nurture a relationship through frequent interactions, we also think that being more engaged with your money encourages better financial literacy. It’s common that people fall into credit trouble by continuing to use their plastic cards without checking their balance regularly. By making Up an engaging experience, we’re making Upsiders more confident and connected to their finances.</p>
<h2>Becoming an Upsider</h2>
<p>We’ve previously deep-dived on our <a href="https://up.com.au/blog/designing-a-super-powered-welcome-pack-experience/">card delivery experience</a>. Before we could even get that far, we had to solve the huge problem of enabling people to sign up for a bank account without leaving the comfort of a mobile app — something that had not been done before in Australia.</p>
<p>We knew that the sheer amount of information we needed from the user was going to be a challenge. Banking is highly regulated in Australia, so we had to cater for many types of identity data (passport, license etc). Most apps can get away with just asking for a username, email and password.</p>
<p>Mobile flows tend to be atomic with a single input per screen, so with identity verification we were anticipating quite a long flow. Our focus was to trim the fat wherever possible, not just by reducing the total number of screens but also by making it easy for people to understand what was being asked of them as they progressed.</p>
<figure>
  <span>
      <a href="https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/c6b2e/signup-flow.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Large and complicated data capture flow" title="Large and complicated data capture flow" src="https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/40619/signup-flow.jpg" srcset="https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/b0fd2/signup-flow.jpg 175w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/aaaf9/signup-flow.jpg 350w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/40619/signup-flow.jpg 700w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/e8c9e/signup-flow.jpg 1050w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/5814a/signup-flow.jpg 1400w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/c6b2e/signup-flow.jpg 2175w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  <figcaption>
    A portion of the Sign-up flow
  </figcaption>
</figure>
<p>We fought to reduce the amount of data we needed to collect. Why does banking need to know your gender? We cut it. Do you need your card sent to a PO Box? We’ll give you a contextual experience based on answers you’ve already provided rather than a scrolling form full of fields. As we tested the new flow amongst ourselves and with beta users from our waitlist, we made a few changes:</p>
<ul>
<li>Anchoring buttons to the bottom of the viewport, and making them full-width. Close to your thumb and easy to hit.</li>
<li>Removing anything extra like images, so you could move faster without distractions.</li>
<li>Using conversational instructions (eg “What is your mobile number?” Instead of “Enter mobile number”). And only using secondary body text when it was really necessary.</li>
<li>Using example text for the input placeholder, so you'd know what the right info looks like.</li>
</ul>
<figure>
  <video autoplay="true" loop="true" muted="true" playsinline="true" alt="Signup flow, before and after">  
    <source type="video/mp4" src="https://up.com.au/85d89ef5fc1450db9c15cb25ceed64d1/signup-flow-tweaks.mp4">
  </video>
  <figcaption>    
    Tweaks made to the signup flow
  </figcaption>
</figure>
<p>All of these small iterations reduced the cognitive load for users and made it feel easy and fast, despite the number of screens. This granularity was important as there isn’t actually a single sign up flow, but several which vary depending on your circumstances and the information we are required to collect.</p>
<h2>Up Yeah!</h2>
<p>Once we became more confident in our onboarding flow and how streamlined it was becoming, you could feel the team were ready to ship it and move onto the next bit of work.</p>
<p>It’s easy to have the blinkers on when you have such a measurable and objective goal — get users into the app in under x time — but stepping back, we made the observation that although we’d nailed sign up speed, something was missing the first time you landed on your activity feed. A moment that should feel significant and celebratory — you’ve literally just opened a bank account in under 3 minutes through your phone — feels clinical and unimpressive. We appreciate great brand moments in digital experiences, most notably MailChimp’s use of emotive design throughout their email software.</p>
<figure>
  <img loading="lazy" src="https://up.com.au/b5b11a8931d184e937662bc553657582/mailchimp.gif" alt="Mailchimp animations">
  <figcaption>  
    Great emotive design through animations by MailChimp
  </figcaption>
</figure>
<p>Email campaigns are stressful exercises — you can’t unsend them once they go out. It’s the nature of the beast. Interestingly, it was the arm of their mascot beast Freddie that was used in these cute but situationally-aware animations. The red button before launch, the high five once your campaign is live, and the rock fist for scheduled campaigns.</p>
<p>Our creative director Pete was eager to create a moment post-signup that made you go “f*ck yeah” in celebration.</p>
<figure>
  <img loading="lazy" src="https://up.com.au/1c642ec78c4396636c3b1bc150d48a29/upyeahmoment-signup.gif" alt="Up Yeah! account created">
  <figcaption>  
    The first of many ‘Up Yeah!’ moments
  </figcaption>
</figure>
<p>Almost immediately after this launched it was being shared by new Upsiders and acknowledged through our feedback channels. Of course you only give yourself an opportunity for these moments if you are nailing the fundamentals. But this reinforcement encouraged us to lean into these seemingly frivolous treatments as a way to delight Upsiders while building a stronger brand.</p>
<h2>Logging in Sucks</h2>
<p>Sometimes the design process involves considering what you don’t see as much as what you do see. For Up, removing the login screen is a great example of this. Banking apps tend to have heavy authentication flows before you see your feed or landing screen. It’s easy to see how this came to be; mobile apps came after desktop banking sites, and so inherited their secure lockdown context. And perhaps it goes back even further back to the mindset of “money belongs in a vault, behind a locked door”.</p>
<p>With all the technological advances in mobile device security, from the humble PIN code to sophisticated biometric recognition, it’s worth questioning some of the assumptions and trade-offs made in the name of security.</p>
<blockquote>
<p>Logging in is a big friction point. Especially if we’re trying to help inform you about your finances.</p>
</blockquote>
<p>There’s an interesting distinction that’s prominent in tech — the difference between security and privacy. If we break out of the world of banking apps and look at some of the apps we use each and every day – imagine if you had to enter a passcode every time you opened your email, or your messages? Yet if someone had access to either, they could reset every password you have and really cause you some headaches. We found a helpful albeit simplified distinction when approaching this aspect of the user-experience:</p>
<br>
<table>
    <tbody><tr>
        <td><img loading="lazy" src="https://up.com.au/251bbe56c807fe4657239958a04f14e6/zap-coat.gif" alt="Mailchimp animations">
        </td>
        <td>
          <h3>Privacy</h3>
          Protecting information that is sensitive
          <em> "Read Only"</em>
        </td>
    </tr>
</tbody></table>
<table>
    <tbody><tr>
        <td><img loading="lazy" src="https://up.com.au/6e9f440aae0b397bd198cc1182838ed9/zap-lock.gif" alt="Mailchimp animations">
        </td>
        <td>
          <h3>Security</h3>
          Protecting against being compromised financially
          <em>"Write Access"</em>
        </td>
    </tr>
</tbody></table>

<p>A design decision we’ve made with this framework is removing the need to enter a passcode by default (which can be re-enabled in settings), and also when moving money where there isn’t any risk. Transfering between Savers doesn’t require you to use your phone’s authentication flow (e.g. passcode, Apple’s FaceID or Android’s BioAuth), but moving money into your spending account or sending money outside of your account (e.g. to another bank or via BPay) does.</p>
<p>Our philosophy is to ask for authentication where appropriate to maximise security, while also letting Upsiders enjoy the benefits of being more informed and connected with their money in a low-friction way.  Our push …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://up.com.au/blog/the-evolutionary-design-of-up/">https://up.com.au/blog/the-evolutionary-design-of-up/</a></em></p>]]>
            </description>
            <link>https://up.com.au/blog/the-evolutionary-design-of-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552043</guid>
            <pubDate>Tue, 22 Sep 2020 07:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mainline Linux on the MikroTik RB3011]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24550846">thread link</a>) | @pabs3
<br/>
September 21, 2020 | https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html | <a href="https://web.archive.org/web/*/https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I upgraded my home internet connection to fibre (FTTP) <a href="https://www.earth.li/~noodles/blog/2019/10/native-ipv6-fttp.html">last October</a>. I’m still on an 80M/20M service, so it’s no faster than my old VDSL FTTC connection was, and as a result for a long time I continued to use my HomeHub 5A running <a href="https://openwrt.org/">OpenWRT</a>. However the FTTP ONT meant I was using up an additional ethernet port on the router, and I was already short, so I ended up with a GigE switch in use as well. Also my wifi is handled by a <a href="https://unifi-network.ui.com/">UniFi</a>, which takes its power via Power-over-Ethernet. That mean I had a router, a switch and a PoE injector all in close proximity. I wanted to reduce the number of devices, and ideally upgrade to something that could scale once I decide to upgrade my FTTP service speed.</p>

<p>Looking around I found the <a href="https://mikrotik.com/product/RB3011UiAS-RM">MikroTik RB3011UiAS-RM</a>, which is a rack mountable device with 10 GigE ports (plus an SFP slot) and a dual core <a href="https://www.qualcomm.com/products/ipq8064">Qualcomm IPQ8064</a> ARM powering it. There’s 1G RAM and 128MB NAND flash, as well as a USB3 port. It also has PoE support. On paper it seemed like an ideal device. I wasn’t particularly interested in running RouterOS on it (the provided software), but that’s based on Linux and there was some work going on within OpenWRT to add support, so it seemed like a worthwhile platform to experiment with (what, you expected this to be about me buying an off the shelf device and using it with only the supplied software?). As an added bonus a friend said he had one he wasn’t using, and was happy to sell it to me for a bargain price.</p>

<p><img alt="RB3011 router in use" src="https://www.earth.li/~noodles/blog/images/2020/rb3011.jpg"></p>

<p>I did try out RouterOS to start with, but I didn’t find it particularly compelling. I’m comfortable configuring firewalling and routing at a Linux command line, and I run some additional services on the router like my <a href="https://www.earth.li/~noodles/blog/2018/05/mqtt-broker.html">MQTT</a> broker, and <a href="https://www.earth.li/~noodles/blog/2018/09/netlink-arp-presence.html">mqtt-arp</a>, my wifi device presence monitor. I could move things around such that they ran on the <a href="https://www.earth.li/~noodles/blog/2019/07/upgrading-the-house-server.html">house server</a>, but I consider them core services and as a result am happier with them on the router.</p>

<p>The first step was to get something booting on the router. Luckily it has an RJ45 serial console port on the back, and a reasonably featured bootloader that can manage to boot via tftp over the network. It wants an ELF binary rather than a plain kernel, but Sergey Sergeev had done the hard work of getting <a href="https://github.com/adron-s/uboot-ipq806x">u-boot working for the IPQ8064</a>, which mean I could just build normal u-boot images to try out.</p>

<p>Linux upstream already had basic support for a lot of the pieces I was interested in. There’s a slight fudge around <code>AUTO_ZRELADDR</code> because the network coprocessors want a chunk of memory at the start of RAM, but there’s ongoing discussions about how to handle this cleanly that I’m hopeful will eventually mean I can drop that hack. Serial, ethernet, the QCA8337 switches (2 sets of 5 ports, tied to different GigE devices on the processor) and the internal NOR all had drivers, so it was a matter of crafting an appropriate DTB to get them working. That left niggles.</p>

<p>First, the second switch is hooked up via SGMII. It turned out the IPQ806x <code>stmmac</code> driver didn’t initialise the clocks in this mode correctly, and neither did the <code>qca8k</code> switch driver. So I need to fix up both of those (Sergey had handled the stmmac driver, so I just had to clean up and submit his patch). Next it turned out the driver for talking to the Qualcomm firmware (SCM) had been updated in a way that broke the old method needed on the IPQ8064. Some git archaeology figured that one out and provided a solution. Ansuel Smith helpfully provided the DWC3 PHY driver for the USB port. That got me to the point I could put a Debian armhf image onto a USB stick and mount that as root, which made debugging much easier.</p>

<p>At this point I started to play with configuring up the device to actually act as a router. I make use of a number of VLANs on my home network, so I wanted to make sure I could support those. Turned out the stmmac driver wasn’t happy reconfiguring its MTU because the IPQ8064 driver doesn’t configure the FIFO sizes. I found what seem to be the correct values and plumbed them in. Then the <code>qca8k</code> driver only supported port bridging. I wanted the ability to have a trunk port to connect to the upstairs switch, while also having ports that only had a single VLAN for local devices. And I wanted the switch to handle this rather than requiring the CPU to bridge the traffic. Thankfully it’s easy to find a copy of the QCA8337 datasheet and the kernel <a href="https://www.kernel.org/doc/html/latest/networking/dsa/index.html">Distributed Switch Architecture</a> is pretty flexible, so I was able to implement the necessary support.</p>

<p>I stuck with Debian on the USB stick for actually putting the device into production. It makes it easier to fix things up if necessary, and the USB stick allows for a full Debian install which would be tricky on the 128M of internal NAND. That means I can use things like <a href="https://wiki.nftables.org/">nftables</a> for my firewalling, and use the standard Debian packages for things like <a href="https://collectd.org/">collectd</a> and <a href="https://mosquitto.org/">mosquitto</a>. Plus for debug I can fire up things like tcpdump or tshark. Which ended up being useful because when I put the device into production I started having weird IPv6 issues that turned out to be a lack of proper Ethernet multicast filter support in the IPQ806x ethernet device. The driver would try and setup the multicast filter for the IPv6 NDP related packets, but it wouldn’t actually work. The fix was to fall back to just receiving all multicast packets - this is what the vendor driver does.</p>

<p>Most of this work will be present once the 5.9 kernel is released - the basics are already in 5.8. Currently not queued up that I can think of are the following:</p>

<ul>
  <li>stmmac IPQ806x FIFO sizes. I sent out an RFC patch for these, but didn’t get any replies. I probably just need to submit this.</li>
  <li>NAND. This is missing support for the QCOM ADM DMA engine. I’ve sent out the patch I found to enable this, and have had some feedback, so I’m hopeful it will get in at some point.</li>
  <li>LCD. AFAICT LCD is an ST7735 device, which has kernel support, but I haven’t spent serious effort getting the SPI configuration to work.</li>
  <li>Touchscreen. Again, this seems to be a zt2046q or similar, which has a kernel driver, but the basic attempts I’ve tried don’t get any response.</li>
  <li>Proper SFP functionality. The IPQ806x has a PCS module, but the stmmac driver doesn’t have an easy way to plumb this in. I have ideas about how to get it working properly (and it can be hacked up with a fixed link config) but it’s not been a high priority.</li>
  <li>Device tree additions. Some of the later bits I’ve enabled aren’t yet in the mainline RB3011 DTB. I’ll submit a patch for that at some point.</li>
</ul>

<p>Overall I consider the device a success, and it’s been entertaining getting it working properly. I’m running a mostly mainline kernel, it’s handling my house traffic without breaking a sweat, and the fact it’s running Debian makes it nice and easy to throw more things on it as I desire. However it turned out the RB3011 isn’t as perfect device as I’d hoped. The PoE support is passive, and the UniFi wants 802.1af. So I was going to end up with 2 devices. As it happened I picked up a cheap <a href="https://eu.dlink.com/uk/en/products/dgs-1210-series-gigabit-smart-plus-switches">D-Link DGS-1210-10P</a> switch, which provides the PoE support as well as some additional switch ports. Plus it runs Linux, so more on that later…</p>

  </article></div>]]>
            </description>
            <link>https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550846</guid>
            <pubDate>Tue, 22 Sep 2020 04:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RIP iCloud, Self-Hosting Part 5: Finale]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24550197">thread link</a>) | @walterbell
<br/>
September 21, 2020 | https://www.naut.ca/blog/2020/05/05/self-hosting-series-part-5-finale/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/05/05/self-hosting-series-part-5-finale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://www.naut.ca/blog/content/images/2020/05/Screen-Shot-2020-05-05-at-3.30.56-PM.jpeg" width="400px/"></p><p>Just yesterday, I turned off iCloud on <strong>all</strong> my Apple devices. I then took a moment to savour my liberation from Apple's walled garden.</p>
<p>It has been over two years since I first dabbled in hosting my own blog server to finally disabling my iCloud account. There is a good reason as to why it took so long. Apple has cultivated a beautiful hardware+software ecosystem over the years, resulting in an ecosystem filled with magical features such as Apple Pay, Home Sharing, Handoff, and Instant Hotspot. An iCloud account is apparently a requirement for all of those features, which is a shame. I didn't find out until after I logged out and lost those features, but maybe it was for the better. Anyway, here's the proof:<br>
<img src="https://www.naut.ca/blog/content/images/2020/05/Screen-Shot-2020-05-05-at-3.38.39-PM.jpeg" alt="Screen-Shot-2020-05-05-at-3.38.39-PM"><br>
Now this may sound odd, but I feel that the fallbacks and replacements to iCloud features are sometimes easier to understand and give more of a feeling of groundedness, albeit at the cost of convenience. For example, I no longer debate about whether to use Apple Pay or not, and I feel grounded knowing that the physical card is all I need to protect, and that my credit card won't run out of battery. I now plug in a cable to backup my iPhone, and I hear the hard disks on my server grinding away as the files are transferred. I'm confident that something, if anything, is happening. By physically self-hosting emails in the house, I feel secure that a company can't tell me that my account has vanished, a concept that is becoming <a href="https://news.ycombinator.com/item?id=23057365">increasingly common</a>.</p>
<p>As we switched from using physical devices such as floppy disks, CDs, and servers to storing data and logic online, we lost a sense of physicality and tangibility, replaced by an abstract notion of the <a href="https://www.youtube.com/watch?v=8GRPArTor7w">cloud</a>. Most programmers realize that the cloud is not a magical place and are comfortable with the notion, but I've noticed that the cloud instills fear, uncertainty, and doubt in others.</p>
<p>Given that I've been to hell and back setting up a self-hosted cloud (even my programmer friends stare at me quizzically), I sound crazy to mention that this has made things "easier". I'm definitely <strong>not</strong> saying that self-hosting is easier than using iCloud, but it has made me aware of what we are missing. In any interactive system, the true complexity must hide somewhere, and in this case, Apple is offering to manage it for you. In an attempt for trust, security, and ease of use, these services create a greater disconnect between you and your "interactee". To give an example, take transactions between you and a merchant. First there was bartering. Then there was cash. These are both easy to understand, and almost nobody has trouble understanding the end-to-end concepts. However, take Apple Pay. Here's a high-level example of what it actually does:</p>
<blockquote>
<p><em>NFC Coil in POS Terminal energizes iPhone antenna ⟶ sends data to NFC Chip ⟶ activates iPhone CPU ⟶ requests Face ID unlock ⟶ beams tiny Infrared dots at your face ⟶ Infrared Camera constructs 3D model using Machine Learning model ⟶ decrypts credit card details in Secure Enclave ⟶ creates credit card token ⟶ sends back to iPhone NFC chip ⟶ transmits to POS Terminal ⟶ encrypts with TLS ⟶ sends through internet to the credit card network ⟶ network replies back</em></p>
</blockquote>
<p>To reiterate, this is a <em>high-level</em> overview. So yeah, try feeling grounded with that. It's a miracle that it even works.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Overall, my self-hosting series has reduced the FUD surrounding these services for <em>me</em> (and hopefully at least another reader), since I now understand how the software works. I feel it is an accomplishment to be disconnected from Apple, knowing that I'm free to switch hardware whenever I please. Although increased privacy was one of the main reasons I started this series, I haven't really noticed anything different day-to-day. This series has been a very interesting journey, and it will be something that I will continue to explore with future blog posts. As somebody who is now examining iCloud from an outsider perspective for the first time, it is mind-boggling the amount of complexity that Apple manages and exerts power over, such as their COVID-19 Contact Tracing technology. I wonder what the future holds for Apple, and how its values will change over time.</p>
<h3 id="alternativestoicloud">Alternatives to iCloud:</h3>
<p><em>Note: E2EE software with easily exportable data is acceptable, e.g. Firefox Sync</em></p>
<p><strong>Rationale</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2019/06/19/self-hosting-series-part-1-saying-bye-bye-to-icloud/">Self-Hosting Part 1: Why I'm Ditching iCloud</a></li>
<li><a href="https://medium.com/bugbountywriteup/how-apple-stored-all-your-email-metadata-for-years-on-their-servers-2a61b1a3232d">How Apple store all your email metadata for years on their servers</a></li>
</ul>
<p><strong>iCloud Mail, Notes</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2019/10/06/self-hosting-series-part-2-mail-server/">Self-Hosting Part 2: Mail Server</a></li>
</ul>
<p><strong>iCloud Contacts, Calendar, Reminders</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2019/11/16/self-hosting-series-part-3-radicale-server/">Self-Hosting Part 3: WebDAV Server</a></li>
</ul>
<p><strong>iCloud Safari</strong></p>
<ul>
<li><a href="https://hacks.mozilla.org/2018/11/firefox-sync-privacy/">Firefox Sync</a></li>
</ul>
<p><strong>iCloud Backup</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2020/03/20/self-hosting-series-part-4-backup/">Self-Hosting Part 4: iOS + macOS Backup</a></li>
<li><a href="https://support.apple.com/en-ca/HT203977#computer">iTunes Local Backup</a></li>
</ul>
<p><strong>iCloud Drive</strong></p>
<ul>
<li><a href="https://9to5mac.com/2019/06/17/ios-13-beta-2-enables-smb-server-connectivity-in-the-files-app/">Samba Server</a></li>
<li><a href="https://nextcloud.com/">NextCloud</a></li>
</ul>
<p><strong>iCloud Photos</strong></p>
<ul>
<li><a href="https://nextcloud.com/">NextCloud</a></li>
<li><a href="https://support.apple.com/en-us/HT201313">iTunes Photo Sync</a></li>
</ul>
<p><strong>iCloud Keychain</strong></p>
<ul>
<li><a href="https://bitwarden.com/">Bitwarden (Self-hosted)</a></li>
<li><a href="https://www.enpass.io/">Enpass (Self-hosted)</a></li>
</ul>
<p><strong>iCloud Home</strong><br>
TBD. Currently, HomeKit requires iCloud Keychain to sync with your iOS devices. I am trying to develop a hub that rebroadcasts all HomeKit accessories allowing for multiple devices to connect to the same HomeKit device.</p>
<p><strong>Further Resources</strong></p>
<ul>
<li><a href="https://roll.urown.net/index.html">Roll Your Own Network</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/05/05/self-hosting-series-part-5-finale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550197</guid>
            <pubDate>Tue, 22 Sep 2020 02:07:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When feature flags do and don’t make sense (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24549917">thread link</a>) | @nomdep
<br/>
September 21, 2020 | https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.redbubble.com/i/canvas-print/If-Else-Software-Developer-Joke-Beer-Lover-by-VaSkoy/33140544.5Y5V7" target="_blank"><img data-attachment-id="282" data-permalink="https://software.rajivprab.com/flag/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png" data-orig-size="896,1480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flag" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=620" src="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" alt="" srcset="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182 182w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=364 364w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=91 91w" sizes="(max-width: 182px) 100vw, 182px"></a></figure></div>



<p>Over the past years, I’ve worked in multiple teams adopting very different strategies when it comes to feature flags. I’ve seen the pros and cons of both, and over time, I found myself disagreeing with any fundamentalist position on their use. There is a lot of nuance to this topic, and I think it is worth considering more carefully the various scenarios where feature flags do and do not make sense.</p>



<h2>The Reasons For</h2>



<p>There are a few major scenarios where feature flags make a lot of sense. The first is when it’s used for <a rel="noreferrer noopener" aria-label="A/B testing (opens in a new tab)" href="https://en.wikipedia.org/wiki/A/B_testing" target="_blank">A/B testing</a>, where you absolutely do want different behaviors for different users, based on their randomly assigned treatment. I’ve seen this strategy employed extremely well at Amazon where new features are gated by a “feature flag” that is actually controlled by an internal A/B testing framework. The framework randomly exposes some Amazon customers to the new feature, and then monitors their subsequent behavior in order to estimate the business impact of launching the feature.&nbsp;</p>



<p>I was initially skeptical, but was soon won over by how easy the framework was to use, and the valuable insights it provided on the benefits (or drawbacks) of certain features. “Flavor of the month” decisions were replaced with real data. And none of this is possible without the use of “feature flags” to dynamically toggle new features.</p>



<hr>



<p>Another great use case for feature flags, is when you’re working on a very complex epic that require many different sub-tasks to be completed in different parts of the system. Sub-tasks that are too numerous and invasive to be done in a single pull-request. </p>



<p>In such cases, trying to keep all these disparate changes in side-branches and coordinating a simultaneous merge and deployment, is a recipe for disaster. It’s far more manageable to gate any disruptive changes behind a master flag, merge and deploy all the sub-commits incrementally, and do a flag-flip once all the pieces are in place.</p>



<hr>



<p>One last use case for feature flags, is when you do not have control over your deployments. For example, consider the Facebook Android app, which contains code contributed by hundreds of different teams, all combined and deployed as a single binary. In such scenarios, performing rollbacks can be infeasible. For practical, political, bureaucratic or even marketing reasons. In such cases, feature flags allow your team to toggle new functionality or mitigate risky changes, without having to rollback or deploy any new binaries.</p>



<p><em>Someone on Reddit pointed out a similar use-case for feature flags: targeting a very specific launch date for marketing reasons, while still deploying your code much earlier, in order to ensure stability. You can then have a “dynamic” feature flag that automatically enables itself at a specific time. This is also a great use-case for similar reasons – changing functionality in situations where deploying a new binary is impractical.</em></p>



<h2>Risk Aversion</h2>



<p>The above are all fantastic use cases for feature flags, but I’ve also seen teams get bogged down by policies that overreach in their use. For example, mandating that every single code change should be behind a feature flag, <em>“just in case we made a mistake”</em>.</p>



<p>Risk management should indeed be a priority for all teams. But there are better ways of doing this than relying on feature flags, especially if your team has control over its own deployments. The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/" target="_blank">vast majority of your bugs should be caught by your automated test suite</a> and/or QA process. And the last few stragglers should be handled using <a rel="noreferrer noopener" aria-label="incremental deployments, production alarms and rollbacks (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">incremental deployments, production alarms and rollbacks</a>.</p>



<p>Besides, as soon as any problem is detected, the recommendation at places like Google is to <a rel="noreferrer noopener" aria-label="rollback first and ask questions later (opens in a new tab)" href="https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons" target="_blank">rollback first and investigate the problem later</a>:</p>



<blockquote><p><em>We have seen this at Google any number of times, where a hastily deployed roll-forward fix either fails to fix the original problem, or indeed makes things worse. Even if it fixes the problem it may then uncover other latent bugs in the system; you’re taking yourself further from a known-good state, into the wilds of a release that hasn’t been subject to the regular strenuous QA testing. At Google, our philosophy is that “rollbacks are normal.” When an error is found or reasonably suspected in a new release, the releasing team rolls back first and investigates the problem second</em></p></blockquote>



<p> When things are on fire, the last thing you want to do is root-cause the bug and figure out which flag-flip will safely fix the problem. And that may not even fix things – there’s no guarantee that even if your teammate tried to put his changes behind a feature flag, he didn’t inadvertently introduce a bug that cannot be solved by a flag-flip.</p>



<p>Feature flags are a poor man’s alternative to binary rollbacks, and they definitely aren’t a substitute for having a great automated test suite and a robust QA process. If you’re relying on feature flags to remedy production bugs, you should stop and evaluate your team’s practices. Risk aversion is often a smell of your team <a rel="noreferrer noopener" aria-label="entering into a doom loop which will only get worse and worse with time (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">entering into a doom loop which will only get worse and worse with time</a>.</p>



<h2>Death By Feature Flags</h2>



<p>You may be wondering at this point why we shouldn’t use feature flags anyway. After all, <em>“defense in depth” …</em> and it never hurts to have more fine-grain flexibility right?</p>



<p>While feature flags are great in some cases, we should also keep in mind their costs. Software engineering is primarily an exercise in managing complexity. And each feature flag immediately doubles the universe of corner cases that your programmers have to understand, and your code is required to handle. <em>“But what would happen if Foo is enabled, Bar is disabled, and we do independent A/B tests on Baz and Kaz on the same day?”</em> In my experience, this combinatorial explosion in complexity can and <strong>will</strong> lead to bugs. Not to mention slowing down the speed at which your team can make any changes.</p>



<p><em>“But these feature flags are only temporary. You should be removing them as soon as possible!”</em></p>



<p>Sure, and we should also not allow our tech debt to accumulate and we should follow every single best-practice religiously. Unfortunately, this never happens in any corporate environment. Even in great teams, tech debt often gets de-prioritized in the face of new requests. Newcomers to the team or those on their way out, aren’t always disciplined enough to clean up their flags after a successful rollout. And sometimes, these tasks simply slip through the cracks and get forgotten.</p>



<p>There is no better illustration of this than the KCG debacle where a financial firm lost half a billion dollars and almost went bankrupt in 30 minutes, partly due to dead code that was behind a feature flag.</p>



<blockquote><p><a href="https://www.bugsnag.com/blog/bug-day-460m-loss"><em>The cause of the failure</em></a><em> was due to multiple factors. However, one of the most important was that a flag which had previously been used to enable Power Peg… Power Peg had been obsolete since 2003, yet still remained in the codebase some eight years later.</em></p><p><em>In 2005, an alteration was made to the Power Peg code which inadvertently disabled safety-checks which would have prevented such a scenario. However, this update was deployed to a production system at the time, despite no effort having been made to verify that the Power Peg functionality still worked</em></p></blockquote>



<hr>



<p>Feature flags are a powerful tool that can help you experiment with new features, manage the rollout of complex epics, and mitigate the problems associated with not controlling your team’s deployments. </p>



<p>But they come at a significant cost, in the form of code complexity, tech debt, slower development speeds, and inevitably, bugs. </p>



<p>As tempting as it may be, there is no silver bullet here. Weigh the pros against the cons, and use this tool judiciously when it makes sense to do so.</p>



<hr>



<p><a href="https://www.reddit.com/r/programming/comments/i5zbvk/when_feature_flags_do_and_dont_make_sense/" target="_blank" rel="noreferrer noopener"><em>Discussion thread on /r/programming</em></a></p>
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24549917</guid>
            <pubDate>Tue, 22 Sep 2020 01:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mike Speiser Incubation Playbook]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24549767">thread link</a>) | @sethbannon
<br/>
September 21, 2020 | https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/ | <a href="https://web.archive.org/web/*/https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>In Formula 1 racing, you can win a world championship as a driver with one team but then not even make the top 10 without that team’s car and infrastructure. Venture can often feel like this, too. Many top performing VCs would struggle if they weren’t on their firm’s platform. And similarly, a far greater number of VCs might be able to do well if they were just at a firm with a strong enough brand. Most special are those that are the source of their own success.</p>



<p>In <a href="https://kwokchain.com/2019/04/09/making-uncommon-knowledge-common/">Making Uncommon Knowledge Common</a>, I wrote about Rich Barton because he’s one of the rare founders (or investors) with the demonstrated ability to create multiple billion dollar companies. Unpacking and learning from the few who have shown repeatable and internally compounding approaches to building companies is important.</p>



<p>Unlike consumer, traditional enterprise markets lend themselves more naturally to deterministic and repeatable success. There’s a small handful of VCs who have clearly shown they can succeed repeatedly and whose approaches and playbooks are legible enough to imply it’s not a fluke. Speiser is one of them.</p>



<p>Speiser’s portfolio includes companies like Pure Storage and Snowflake Computing. It’s worth noting that Snowflake not only IPO’d and is now at a market cap of over $60B but Speiser and Sutter Hill Ventures owned more than 20% of the company leading up to the IPO. When Pure Storage went public, Sutter Hill held more than 25%. Speiser may have the highest percentage of portfolio companies that have become multi-billion dollar companies—and that trend looks to continue with his newer companies.</p>



<p>But impressive returns are not solely what matters for the industry. It’s tempting to evaluate firms by their returns, and from the LP perspective that may be the correct metric. But another, and more important way to judge VC firms is by the <a href="https://en.wikipedia.org/wiki/Value_over_replacement_player">value they add above replacement</a> to their portfolio companies. How much do they help their portfolio companies increase their likelihood and magnitude of success? Firms do this most notably by providing capital, but also by other methods like lending their brand or directly helping with operations.</p>



<p>For founders, this value added is what matters. The returns of a VC firm only matter to a startup insofar as they translate into improved brand, network, or access to capital for the startup. A firm’s financial performance is a reasonable signal that they may add real value and be worth partnering with, especially since some aspects like brand strength for recruiting, future financing, and customer development are a function of perceived firm success. But to prospective portfolio companies, a fund’s returns are important only as a means, not an end.</p>



<p>What makes Speiser intriguing is how distinct his approach is from other VCs. The tantalizing clues suggest that he has figured something out that nobody else has: the formula for creating successful companies from scratch.</p>



<figure><img loading="lazy" width="800" height="559" src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=800%2C559&amp;ssl=1" alt="" srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=768%2C537&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=768%2C537&amp;ssl=1 768w" data-lazy-src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=800%2C559&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>you didn’t really think there wasn’t going to be a drawing of a loop did you?</figcaption></figure>



<h2>The Speiser playbook</h2>



<p>At the core of Speiser’s approach is incubating companies, or “originating companies” in <a href="https://www.strictlyvc.com/2014/11/10/sam-pullara-entrepreneur-vc-firm/">Sutter Hill nomenclature</a>. Instead of investing in existing companies, Speiser stays solely focused on one thing: starting and building companies. Even among others who have been very successful at incubations, he is the most singularly focused on this.</p>



<figure><img loading="lazy" width="800" height="560" src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=800%2C560&amp;ssl=1" alt="" srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=768%2C538&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=768%2C538&amp;ssl=1 768w" data-lazy-src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=800%2C560&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>bespoke artisanal charts as a service</figcaption></figure>



<p>Every year Speiser incubates around one company. The core of his model is to find 2-3 co-founders and be the founding investor. Often he takes on the interim CEO role himself for the first year or two. This has many advantages. The biggest is that it reshapes the ideal founding team profile. He can focus on getting the right top technical co-founders that will have strong views on what to build and the ability to build it—even if they are people who don’t generally view themselves as having a natural inclination to be founders. This is a significant talent arbitrage.</p>



<h3>A better package for founders</h3>



<p>There has been a dearth of coverage of Snowflake’s three cofounders, Benoit Dageville, Thierry Cruanes, and Marcin Zukowski in both the news and social media. Partially this is because they have not sought the spotlight. But partially, it is due to the veneration of a certain type of founder we have, those who seek the limelight of public presence and being in control of every aspect of the company.</p>



<p>Snowflake’s founders are cut from a different cloth. As Benoit Dageville put it “We never thought of it as building a company. We just wanted to build a cloud product. The company was an afterthought.” Yet, their product and technical decisions have been prescient in threading the narrow path to taking on Amazon and Google in the most important core markets of cloud computing.</p>



<p>There are people who often don’t <em>want</em> to be CEO, or even to start a company. They are driven by their conviction of what the future should look like, as well as their frustration with the internal dynamics they confront at legacy incumbents that prevent them from creating that reality. But they are still unlikely to start a company due to all the inertial cruft that comes with founding a company—and especially with being CEO. They want to build what matters, not set up a new corporate structure, manage fundraising, or build a sales team.</p>



<p>Eric Yuan, the founder and CEO of Zoom, <a href="https://www.cnbc.com/2019/08/21/zoom-founder-left-job-because-he-wasnt-happy-became-billionaire.html">has explained</a> this feeling of being held back at Webex. He knew what should be built and that the Webex team could do it, but given the dynamics of Webex as a subsidiary of Cisco he was unable to get the political capital to do it. And he’s proven himself right by leaving with his Webex teammates and building Zoom. Considering he was VP Engineering at Webex and still unable to build what he thought was important should be a very discomfiting reality shock to large companies about the very real economic harm the malaise of their internal processes have caused. However, for every Eric Yuan, there are countless others that never leave and start a company. The inertial barriers are too high. They can stay at their company and struggle to work on what they know should be built. Or leave and take on more uncertainty and risk than they want.</p>



<p>Speiser introduces a third model that breaks through this <a href="https://en.wikipedia.org/wiki/Between_Scylla_and_Charybdis">Scylla and Charybdis</a> dilemma. Start a company with Speiser and stay focused on what you want: deciding what to build, hiring the team you need, and building it. Speiser will handle fundraising, handling the operations generally, and setting up the sales motion and machine. Founders get much of the autonomy and upside of starting a new company while also getting support and guardrails so they can stay focused while having confidence the business is being built well.</p>



<p>Speiser doesn’t just take on these roles because founders don’t want to do it. There are actually aspects of company building where he should be better than the founders. Sutter Hill Ventures has the capital already, so it’s easy for them to take on responsibility for fundraising and remove that as a blocker. Instead of having to burn a lot of cycles fundraising, Sutter Hill can provide the capital. And they often do, leading multiple rounds into their companies. Or they can bring in outside investors, with the confidence that Sutter Hill can lead the entire round as a backstop if the process becomes too much of a hassle. Also, like any VC firm, Sutter Hill builds a brand that compounds their companies’ ability to raise follow on funding. At this point there are multiple firms that have made their bread and butter following on after Sutter Hill, to great success.</p>



<p>Similarly, Speiser is likely to have more experience in setting up companies and the initial customer development process than the founders will. Perhaps most importantly, he has relationships with customers and an established reputation that can be used to bootstrap the initial pilot conversations, which may be the point of highest leverage for these new startups.</p>



<p>These advantages all <em>compound</em> with every incremental company Speiser originates, and not just because of the typical brand network effects that venture has broadly. In many tangible ways, the spread between Speiser’s process knowledge relative to a new founder should widen with every new company.</p>



<p>As an industry we seem to often want to see machismo and martyrdom in founders. A decade ago it was wanting founders to be willing to mortgage their house and their kids’ college fund. Now it is founders wanting to be in charge of every aspect of companies. If founders aren’t willing to put everything on the line for the company their companies will be worse is the thought. As an ecosystem it doesn’t appear the data bears this out. Everything we do that has expanded opportunity and decreased the friction to more people becoming founders has led to huge benefits for the industry.</p>



<p>Just as Eric Yuan should be a massive shot across the bow for all large tech incumbents, Snowflake’s founders should be a wakeup call to venture that we have much further to go to enable and support even more brilliant people who don’t think of themselves as CEOs to bring their vision of the world into existence.</p>



<h3>A better package for CEOs</h3>



<p>But this isn’t the only talent arbitrage Speiser’s playbook benefits from. The interim CEO model allows another one too. As the startup does well and figures out its product market fit, Speiser eventually rolls off as CEO and finds a full-time replacement to take on the role as he takes a step back into being solely a board member.</p>



<p>His companies are <em>very</em> advantaged in finding great CEOs to take the mantle. To understand why, look at it from the perspective of an executive looking to become the CEO of a company. Like the potential founders, these executives have their own Scylla and Charybdis dilemma. They want to be CEO of a company, but they also want to join a company that has already …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/">https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/</a></em></p>]]>
            </description>
            <link>https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24549767</guid>
            <pubDate>Tue, 22 Sep 2020 00:29:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Syncing Oracle to Dolt Using Python]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24548870">thread link</a>) | @oscar-batori
<br/>
September 21, 2020 | https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p><a href="https://github.com/liquidata-inc/dolt">Dolt</a> is a relational database with Git-like version control features. In particular the underlying data storage format is a commit graph, and each commit represents the complete state (schema and data) of the database at a point in time. <a href="https://github.com/liquidata-inc/doltpy">Doltpy</a>, our Python API, provides users with tools to easily move data between their existing databases and Dolt. This post covers adding support for Oracle. We wanted to support Oracle because several customers asked for it. Given how widely adopted it is as a database solution, this is not surprising. Supporting Oracle proved more complicated than the other databases. Most of that complexity comes from Oracle having a model that differs substantially from Postgres and MySQL, as well as how long the database takes to actually startup. We cover how to abstract away this complexity in a clean test fixture in the final section using Docker.</p>
<h3>Overview</h3>
<p>Let's start with the goal: we want to provide a simple API for moving data from Dolt to Oracle, or from Oracle to Dolt. Let's say we want to get data from the <code>revenue_estimates</code> table in Oracle into Dolt for versioning, we want to write code like this:</p>
<div data-language="python"><pre><code><span>from</span> doltpy<span>.</span>etl<span>.</span>sql_sync <span>import</span> sync_from_dolt<span>,</span> get_dolt_target_writer<span>,</span> get_oracle_source_reader

sync_to_dolt<span>(</span>get_oracle_source_reader<span>(</span>oracle_engine<span>)</span><span>,</span>
             get_dolt_target_writer<span>(</span>dolt_repo<span>)</span><span>,</span>
             <span>{</span><span>'revenue_estimates'</span><span>:</span> <span>'revenue_estimates'</span><span>}</span></code></pre></div>
<p>We need some objects for managing database connections, which are defined as follows:</p>
<div data-language="python"><pre><code><span>from</span> doltpy<span>.</span>core <span>import</span> Dolt
<span>import</span> sqlalchemy <span>as</span> sa
<span>import</span> cx_Oracle


dolt <span>=</span> Dolt<span>.</span>init<span>(</span><span>'my-org/estiamtes'</span><span>)</span>
dolt<span>.</span>sql_server<span>(</span><span>)</span>

engine <span>=</span> create_engine<span>(</span><span>'oracle+cx_oracle://'</span><span>,</span> creator<span>=</span>_oracle_connection_helper<span>)</span>
<span>def</span> _oracle_connection_helper<span>:</span>
    <span>return</span> cx_Oracle<span>.</span>connect<span>(</span><span>'oracle_user'</span><span>,</span> <span>'oracle_pwd'</span><span>,</span> <span>'{}:{}/{}'</span><span>.</span><span>format</span><span>(</span><span>'oracle_host'</span><span>,</span> <span>1521</span><span>,</span> <span>'oracle_db'</span><span>)</span><span>)</span></code></pre></div>
<p>In order to incorporate Oracle into our SQL Sync tooling we need to verify that we can "round trip" data from Dolt to Oracle, and from Oracle to Dolt. We do the same for Postgres and MySQL. In practice this means we need instances of each of these databases running, and available to our test harness. The most repeatable and portable way we have found is to use <code>pytest-docker</code> to run a containerized instance of each database implementation. The architecture looks something like this:
<span>
      <a href="https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/ef9e5/sql_sync_test_architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="SQL Sync test architecture" title="SQL Sync test architecture" src="https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/ef9e5/sql_sync_test_architecture.png" srcset="https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/a48b3/sql_sync_test_architecture.png 214w,
https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/47730/sql_sync_test_architecture.png 428w,
https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/ef9e5/sql_sync_test_architecture.png 607w" sizes="(max-width: 607px) 100vw, 607px" loading="lazy">
  </a>
    </span></p>
<p>To achieve this we need three things:</p>
<ol>
<li>a Docker image available that stands up an Oracle instance</li>
<li>augment our test harness to run that image, and populate it with a test table</li>
<li>code to execute and test the sync</li>
</ol>
<p>We will examine them in reverse order, starting with the implementation, as that's closest to the user value the feature delivers.</p>
<h2>Implementation</h2>
<p>Once Oracle was incorporated into our test harness, actually reading and writing from it was straightforward, and done via SQL Alchemy. We focus on the issues caused by how SQL Alchemy maps between higher level types and Oracle types. One main benefit of SQL Alchemy is the <a href="https://docs.sqlalchemy.org/en/13/core/tutorial.html">SQL Expression Language</a> that abstracts over multiple database implementations, something we <a href="https://www.dolthub.com/blog/2020-08-24-schema-support-in-sql-sync/">blogged</a> about. In most cases this takes care of translating between database implementation specific types by providing a higher level set of types. A concrete example is how this higher level expression language allows us to use a single definition of a test table, making our code cleaner and more readable, as well as reducing database implementation specific boilerplate:</p>
<div data-language="python"><pre><code><span>from</span> sqlalchemy<span>.</span>types <span>import</span> Integer<span>,</span> DateTime<span>,</span> String<span>,</span> Text<span>,</span> Float<span>,</span> Date

TEST_TABLE_METADATA <span>=</span> Table<span>(</span>TABLE_NAME<span>,</span>
                            MetaData<span>(</span><span>)</span><span>,</span>
                            Column<span>(</span><span>'first_name'</span><span>,</span> String<span>(</span><span>256</span><span>)</span><span>,</span> primary_key<span>=</span><span>True</span><span>)</span><span>,</span>
                            Column<span>(</span><span>'last_name'</span><span>,</span> String<span>(</span><span>256</span><span>)</span><span>,</span> primary_key<span>=</span><span>True</span><span>)</span><span>,</span>
                            Column<span>(</span><span>'playing_style_desc'</span><span>,</span> Text<span>)</span><span>,</span>
                            Column<span>(</span><span>'win_percentage'</span><span>,</span> Float<span>)</span><span>,</span>
                            Column<span>(</span><span>'high_rank'</span><span>,</span> Integer<span>)</span><span>,</span>
                            Column<span>(</span><span>'turned_pro'</span><span>,</span> DateTime<span>)</span><span>,</span>
                            Column<span>(</span><span>'date_of_birth'</span><span>,</span> Date<span>)</span><span>)</span></code></pre></div>
<p>In the snippet above <code>engine</code> is a SQL Alchemy object that manages a database connection pool. Passing that engine to a call to create the table we just defined will execute the generated query against the corresponding database instance. This is exactly what we do to create a test table in our containerized Oracle instance:</p>
<div data-language="text"><pre><code>TEST_TABLE_METADATA.metadata.create_all(engine)</code></pre></div>
<p>The type mapping issue arises because SQL Alchemy translates both <code>sqlalchemy.types.Date</code> and <code>sqlalchemy.types.DateTime</code> to Oracle's <code>DATE</code> type. This is clearly a bug, as this amounts to "destructive" type coercion, and in fact the library should not permit writes of <code>datetime.datetime</code> Python objects to <code>DATE</code> without at least warning the user of information loss. We plan to implement fixes to SQL Alchemy, and push them back to that project as a wider benefit to the community.</p>
<p>For the purposes of using the data sync, however, this is not an issue. This code is purely for creating a test table, and we do not yet support schema sync in Oracle. We work around this in our test suite.</p>
<h3>Test Harness</h3>
<p>In order for us to execute the SQL Alchemy expressions above, we need to incorporate a running Docker image that exposes an Oracle instance to our test harness. We launch our containers via <code>pytest-docker</code>, a <code>pytest</code> plugin that wraps <code>docker-compose</code>. This allows us to define Docker services using dictionaries which are in turn translated into YAML:</p>
<div data-language="python"><pre><code><span>@pytest<span>.</span>fixture</span><span>(</span>scope<span>=</span><span>'session'</span><span>)</span>
<span>def</span> <span>docker_compose_file</span><span>(</span>tmpdir_factory<span>,</span> mysql_service_def<span>,</span> postgres_service_def<span>,</span> oracle_service_def<span>)</span><span>:</span>
    compose_file <span>=</span> tmpdir_factory<span>.</span>mktemp<span>(</span><span>'docker_files'</span><span>)</span><span>.</span>join<span>(</span><span>'docker-compose.yml'</span><span>)</span>

    compose_conf <span>=</span> <span>{</span>
        <span>'version'</span><span>:</span> <span>'2'</span><span>,</span>
        <span>'services'</span><span>:</span> <span>{</span>
            <span>'mysql'</span><span>:</span> mysql_service_def<span>,</span>
            <span>'postgres'</span><span>:</span> postgres_service_def<span>,</span>
            <span>'oracle'</span><span>:</span> oracle_service_def
        <span>}</span>
    <span>}</span>

    <span>with</span> compose_file<span>.</span><span>open</span><span>(</span><span>'w'</span><span>)</span> <span>as</span> f<span>:</span>
        yaml<span>.</span>dump<span>(</span>compose_conf<span>,</span> stream<span>=</span>f<span>)</span>

    <span>return</span> compose_file<span>.</span>strpath</code></pre></div>
<p>Note that this fixture itself depends on a test fixture called <code>oracle_service_def</code> which specifies how to launch the Oracle service definition. Again, this fixture returns a dictionary, which is incorporated into <code>docker_compose_file</code> as follows:</p>
<div data-language="python"><pre><code><span>@pytest<span>.</span>fixture</span><span>(</span>scope<span>=</span><span>'session'</span><span>)</span>
<span>def</span> <span>oracle_service_def</span><span>(</span><span>)</span><span>:</span>
    <span>return</span> <span>{</span>
        <span>'image'</span><span>:</span> <span>'oscarbatori/oracle-database:18.4.0-xe-quick'</span><span>,</span>
        <span>'container_name'</span><span>:</span> ORACLE_CONTAINER_NAME<span>,</span>
        <span>'ports'</span><span>:</span> <span>[</span><span>'{port}:{port}'</span><span>.</span><span>format</span><span>(</span>port<span>=</span>ORACLE_LISTENER_PORT<span>)</span><span>,</span>
                  <span>'{port}:{port}'</span><span>.</span><span>format</span><span>(</span>port<span>=</span>ORACLE_OEM_EXPRESS_PORT<span>)</span><span>]</span>
    <span>}</span></code></pre></div>
<p>In the following section we detail how to get an Oracle image that takes a reasonable amount of time to start (around a minute). That is still too slow for <code>pytest</code> which will throw errors when our fixtures for fetching a SQL Alchemy engine object run. We can put some retry logic around those calls to make the fixture swallow errors for some reasonable period of time until it obtains a connection:</p>
<div data-language="python"><pre><code><span>@pytest<span>.</span>fixture</span>
<span>def</span> <span>oracle_engine</span><span>(</span>docker_ip<span>,</span> docker_services<span>)</span> <span>-</span><span>&gt;</span> Engine<span>:</span>
    engine <span>=</span> create_engine<span>(</span><span>'oracle+cx_oracle://'</span><span>,</span> creator<span>=</span><span>lambda</span><span>:</span> _oracle_connection_helper<span>(</span>docker_ip<span>)</span><span>)</span>

    <span>@retry</span><span>(</span>delay<span>=</span><span>10</span><span>,</span> tries<span>=</span><span>12</span><span>,</span> exceptions<span>=</span><span>(</span>sqlalchemy<span>.</span>exc<span>.</span>DatabaseError<span>)</span><span>)</span>
    <span>def</span> <span>verify_connection</span><span>(</span><span>)</span><span>:</span>
        conn <span>=</span> engine<span>.</span>connect<span>(</span><span>)</span>
        conn<span>.</span>close<span>(</span><span>)</span>
        <span>return</span> engine

    <span>return</span> verify_connection<span>(</span><span>)</span>


<span>def</span> <span>_oracle_connection_helper</span><span>(</span>host<span>)</span><span>:</span>
    <span>return</span> cx_Oracle<span>.</span>connect<span>(</span>ORACLE_USER<span>,</span> ORACLE_PWD<span>,</span> <span>'{}:{}/{}'</span><span>.</span><span>format</span><span>(</span>host<span>,</span> ORACLE_LISTENER_PORT<span>,</span> ORACLE_DB<span>)</span><span>)</span></code></pre></div>
<p>Our test harness is now augmented to fire up a service running an instance of Oracle XE. In order to get this container running we needed to create the actual image, as unlike Postgres and MySQL, there was not a freely available on one on Docker Hub.</p>
<h2>Building an Image</h2>
<p>Up until this point we have assumed the instance of an Oracle image. This proved a little tricky in practice. We found a GitHub repository containing some tools for building images <a href="https://github.com/oracle/docker-images/tree/master/OracleDatabase/SingleInstance">here</a>. We cloned the repo, and ran the following from the appropriate subdirectory:</p>
<div data-language="text"><pre><code>$ /buildDockerImage.sh -v 18.4.0 -x</code></pre></div>
<p>After about twenty minutes, this produced an image that we could then use to run a container in our development in environment, in this case locally on OSX:</p>
<div data-language="text"><pre><code>$ docker run --name test_oracle \
-p 1521:1521 -p 5500:5500 \
-e ORACLE_PWD=oracle_password \
oracle/database:18.4.0-xe</code></pre></div>
<p>Unfortunately, it takes about 15 minutes for the Oracle database to get into a state were it is accepting connections. This is far too slow for a test suite, as it would make a single test run take more than fifteen minutes. Slow tests discourage developers from using them, increasing the the likelihood of error. Fortunately, Docker provides functionality for creating an image from a running container (credit to <a href="https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/(https://medium.com/@ggajos/drop-db-startup-time-from-45-to-3-minutes-in-dockerized-oracle-19-3-0-552068593deb)%20for%20inspiration">this blog post</a>. The following command creates a snapshot of the container we fired up in our dev environment in the previous step:</p>
<div data-language="text"><pre><code>$ docker commit --author "Oscar Batori me@my-email.com" --message "Fast Oracle XE snapshot" oscarbatori/oracle-database:18.4.0-xe-quick</code></pre></div>
<p>The image could then be started as follows:</p>
<div data-language="text"><pre><code>docker run --name test_oracle \
-p 1521:1521 -p 5500:5500 \
-e ORACLE_PWD=oracle_password \
oscarbatori/oracle-database:18.4.0-xe-quick</code></pre></div>
<p>We now had an image that could present stand up a running Oracle instance in under a minute, allowing us to build the test harness and tests detailed above on top of it.</p>
<h2>Conclusion</h2>
<p>In this post we covered how we incorporated Oracle into our <code>doltpy.etl.sql_sync</code>, a module of the Dolt's Python API, Doltpy, that provides utilities to users who would like to use Dolt alongside existing relational database solutions. We hope that by supporting Oracle we will vastly increase the number of users who are able to capture the benefits for a version controlled SQL database while not having to abandon their existing tools. We have a full SQL Sync guide in our <a href="https://www.dolthub.com/docs/guides/sql-sync/">documentation</a>.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24548870</guid>
            <pubDate>Mon, 21 Sep 2020 21:53:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mainline Linux on the MikroTik RB3011]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547067">thread link</a>) | @edward
<br/>
September 21, 2020 | https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html | <a href="https://web.archive.org/web/*/https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I upgraded my home internet connection to fibre (FTTP) <a href="https://www.earth.li/~noodles/blog/2019/10/native-ipv6-fttp.html">last October</a>. I’m still on an 80M/20M service, so it’s no faster than my old VDSL FTTC connection was, and as a result for a long time I continued to use my HomeHub 5A running <a href="https://openwrt.org/">OpenWRT</a>. However the FTTP ONT meant I was using up an additional ethernet port on the router, and I was already short, so I ended up with a GigE switch in use as well. Also my wifi is handled by a <a href="https://unifi-network.ui.com/">UniFi</a>, which takes its power via Power-over-Ethernet. That mean I had a router, a switch and a PoE injector all in close proximity. I wanted to reduce the number of devices, and ideally upgrade to something that could scale once I decide to upgrade my FTTP service speed.</p>

<p>Looking around I found the <a href="https://mikrotik.com/product/RB3011UiAS-RM">MikroTik RB3011UiAS-RM</a>, which is a rack mountable device with 10 GigE ports (plus an SFP slot) and a dual core <a href="https://www.qualcomm.com/products/ipq8064">Qualcomm IPQ8064</a> ARM powering it. There’s 1G RAM and 128MB NAND flash, as well as a USB3 port. It also has PoE support. On paper it seemed like an ideal device. I wasn’t particularly interested in running RouterOS on it (the provided software), but that’s based on Linux and there was some work going on within OpenWRT to add support, so it seemed like a worthwhile platform to experiment with (what, you expected this to be about me buying an off the shelf device and using it with only the supplied software?). As an added bonus a friend said he had one he wasn’t using, and was happy to sell it to me for a bargain price.</p>

<p><img alt="RB3011 router in use" src="https://www.earth.li/~noodles/blog/images/2020/rb3011.jpg"></p>

<p>I did try out RouterOS to start with, but I didn’t find it particularly compelling. I’m comfortable configuring firewalling and routing at a Linux command line, and I run some additional services on the router like my <a href="https://www.earth.li/~noodles/blog/2018/05/mqtt-broker.html">MQTT</a> broker, and <a href="https://www.earth.li/~noodles/blog/2018/09/netlink-arp-presence.html">mqtt-arp</a>, my wifi device presence monitor. I could move things around such that they ran on the <a href="https://www.earth.li/~noodles/blog/2019/07/upgrading-the-house-server.html">house server</a>, but I consider them core services and as a result am happier with them on the router.</p>

<p>The first step was to get something booting on the router. Luckily it has an RJ45 serial console port on the back, and a reasonably featured bootloader that can manage to boot via tftp over the network. It wants an ELF binary rather than a plain kernel, but Sergey Sergeev had done the hard work of getting <a href="https://github.com/adron-s/uboot-ipq806x">u-boot working for the IPQ8064</a>, which mean I could just build normal u-boot images to try out.</p>

<p>Linux upstream already had basic support for a lot of the pieces I was interested in. There’s a slight fudge around <code>AUTO_ZRELADDR</code> because the network coprocessors want a chunk of memory at the start of RAM, but there’s ongoing discussions about how to handle this cleanly that I’m hopeful will eventually mean I can drop that hack. Serial, ethernet, the QCA8337 switches (2 sets of 5 ports, tied to different GigE devices on the processor) and the internal NOR all had drivers, so it was a matter of crafting an appropriate DTB to get them working. That left niggles.</p>

<p>First, the second switch is hooked up via SGMII. It turned out the IPQ806x <code>stmmac</code> driver didn’t initialise the clocks in this mode correctly, and neither did the <code>qca8k</code> switch driver. So I need to fix up both of those (Sergey had handled the stmmac driver, so I just had to clean up and submit his patch). Next it turned out the driver for talking to the Qualcomm firmware (SCM) had been updated in a way that broke the old method needed on the IPQ8064. Some git archaeology figured that one out and provided a solution. Ansuel Smith helpfully provided the DWC3 PHY driver for the USB port. That got me to the point I could put a Debian armhf image onto a USB stick and mount that as root, which made debugging much easier.</p>

<p>At this point I started to play with configuring up the device to actually act as a router. I make use of a number of VLANs on my home network, so I wanted to make sure I could support those. Turned out the stmmac driver wasn’t happy reconfiguring its MTU because the IPQ8064 driver doesn’t configure the FIFO sizes. I found what seem to be the correct values and plumbed them in. Then the <code>qca8k</code> driver only supported port bridging. I wanted the ability to have a trunk port to connect to the upstairs switch, while also having ports that only had a single VLAN for local devices. And I wanted the switch to handle this rather than requiring the CPU to bridge the traffic. Thankfully it’s easy to find a copy of the QCA8337 datasheet and the kernel <a href="https://www.kernel.org/doc/html/latest/networking/dsa/index.html">Distributed Switch Architecture</a> is pretty flexible, so I was able to implement the necessary support.</p>

<p>I stuck with Debian on the USB stick for actually putting the device into production. It makes it easier to fix things up if necessary, and the USB stick allows for a full Debian install which would be tricky on the 128M of internal NAND. That means I can use things like <a href="https://wiki.nftables.org/">nftables</a> for my firewalling, and use the standard Debian packages for things like <a href="https://collectd.org/">collectd</a> and <a href="https://mosquitto.org/">mosquitto</a>. Plus for debug I can fire up things like tcpdump or tshark. Which ended up being useful because when I put the device into production I started having weird IPv6 issues that turned out to be a lack of proper Ethernet multicast filter support in the IPQ806x ethernet device. The driver would try and setup the multicast filter for the IPv6 NDP related packets, but it wouldn’t actually work. The fix was to fall back to just receiving all multicast packets - this is what the vendor driver does.</p>

<p>Most of this work will be present once the 5.9 kernel is released - the basics are already in 5.8. Currently not queued up that I can think of are the following:</p>

<ul>
  <li>stmmac IPQ806x FIFO sizes. I sent out an RFC patch for these, but didn’t get any replies. I probably just need to submit this.</li>
  <li>NAND. This is missing support for the QCOM ADM DMA engine. I’ve sent out the patch I found to enable this, and have had some feedback, so I’m hopeful it will get in at some point.</li>
  <li>LCD. AFAICT LCD is an ST7735 device, which has kernel support, but I haven’t spent serious effort getting the SPI configuration to work.</li>
  <li>Touchscreen. Again, this seems to be a zt2046q or similar, which has a kernel driver, but the basic attempts I’ve tried don’t get any response.</li>
  <li>Proper SFP functionality. The IPQ806x has a PCS module, but the stmmac driver doesn’t have an easy way to plumb this in. I have ideas about how to get it working properly (and it can be hacked up with a fixed link config) but it’s not been a high priority.</li>
  <li>Device tree additions. Some of the later bits I’ve enabled aren’t yet in the mainline RB3011 DTB. I’ll submit a patch for that at some point.</li>
</ul>

<p>Overall I consider the device a success, and it’s been entertaining getting it working properly. I’m running a mostly mainline kernel, it’s handling my house traffic without breaking a sweat, and the fact it’s running Debian makes it nice and easy to throw more things on it as I desire. However it turned out the RB3011 isn’t as perfect device as I’d hoped. The PoE support is passive, and the UniFi wants 802.1af. So I was going to end up with 2 devices. As it happened I picked up a cheap <a href="https://eu.dlink.com/uk/en/products/dgs-1210-series-gigabit-smart-plus-switches">D-Link DGS-1210-10P</a> switch, which provides the PoE support as well as some additional switch ports. Plus it runs Linux, so more on that later…</p>

  </article></div>]]>
            </description>
            <link>https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547067</guid>
            <pubDate>Mon, 21 Sep 2020 18:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signposts for “when to hire more QA testers”]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24546260">thread link</a>) | @ohjeez
<br/>
September 21, 2020 | https://www.functionize.com/blog/8-ways-to-know-that-its-time-to-hire-a-new-qa-tester/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/8-ways-to-know-that-its-time-to-hire-a-new-qa-tester/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester.jpg" alt="8 ways to know that it’s time to hire a new QA tester" srcset="https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>You want top-quality software, sure. But when is it time to increase the size of the testing team, so that you can deliver said top-quality software? Glad you asked.</p></blockquote>
<p>QA testers are part investigative reporter, part janitor—and all important to the user experience. That’s because the testers’ role is to hunt for untidy coding and to ensure that any user interaction with your software is free from error. As a result, every company worth its engineering chops knows it needs QA testers to do this crucial, sometimes dirty, work. The issue is: When do you bring on new people? How do you know it’s time to hire another QA professional?</p>
<p>In a perfect world, there would be a formula, like “hire one software tester for every five developers,” that is, runs <code>numQATesters = (numDevs+numFeatures)/(5+weWroteTests)</code>. But as life (and code) is imperfect, I came up with a few simple guidelines to justify your budget request.</p>
<p>Don’t thank me. A streamlined user experience is thanks enough.&nbsp;Particularly when it’s <em>your</em> software that I’m using.</p>
<h3>When your software is buggy</h3>
<p>Bugs are annoying yet inevitable errors that range from low priority (font change, alignment issues in text) to “Call the crisis PR team, stat!” (such as loss or exposure of data). And as we all know, a single critical flaw can result in customer dissatisfaction and a high bill from your crisis PR team. Or from the lawyers.</p>
<p>Jennifer Willy, editor of <a href="https://etia.com/" target="_blank" rel="noopener noreferrer">Etia.com</a>, considers bug complaints and customer issues a call to action, where the action is hiring a new QA tester. “User experience is vital. When you are faced with a situation like this, it is important to rely on good testers.” Hiring excellent testing staff both helps you <a href="https://www.functionize.com/blog/6-ways-to-improve-your-debugging-skills/">unravel the buggy situation</a> and also brings about a positive change in the software development process, Willy says.</p>
<p>(Of course, the lack of testers is one possible reason the software got into that sorry state. But that’s another discussion.)</p>
<p><em>Recommended hire</em>: A careful QA tester who can find bugs and other errors that the development team has overlooked. A QA with the patience of a saint, specifically Saint Monica, the saint most associated with patience.</p>
<h3>When your QA team is backlogged</h3>
<p>Christian Lavender, chief product officer of vehicle refinancing platform <a href="https://www.rategenius.com/" target="_blank" rel="noopener noreferrer">RateGenius</a>, says that it’s time to take on a new team member when QA can’t keep up with developer output. “You can hire more engineers to get projects built faster, but if your team doesn’t have the bandwidth to test releases, they’ll just sit in the QA backlog.”</p>
<p>If your developers produce more code than you can thoroughly test in a reasonable amount of time before your QA team drowns in <a href="https://www.functionize.com/blog/the-icky-sticky-tale-of-test-case-management/">a sea of test cases</a>, it’s time to consider pinging HR. Do so sooner rather than later, because as Lavender says, “When there’s a bottleneck in QA, it ripples across the company.”</p>
<p><em>Recommended hire</em>: An octopus. During crunch time, eight hands are better than two.</p>
<h3>When your QA staff is overworked</h3>
<p>If your QA department is working overtime, on weekends, and are called in during holidays, it means they’re handling an unusually heavy load. And if you overwork your QA staff, there’s no telling if your application’s name fields will accept <a href="https://www.cnet.com/news/how-elon-musk-pronounces-x-ae-a-12-his-new-sons-name/" target="_blank" rel="noopener noreferrer">user names like “X Æ A-12.”</a></p>
<p>“If you find that you’re spending more and more time testing than necessary, then you know it might be worth considering hiring a new QA tester,” says <a href="https://www.linkedin.com/in/colinlma/">Colin Ma</a>, founder of Makujin Media and a former director of engineering.</p>
<p><em>Recommended hire</em>: A QA tester who knows how to tap out when pinned to a wrestling mat.&nbsp;A QA who would never name their child X AE A-12.</p>
<h3>When you expand your application platforms</h3>
<p>Your QA team excels at what it does, and what it does is testing desktop software. But what happens <a href="https://www.functionize.com/blog/the-mobile-testing-gotchas-you-need-to-know-about/">when your users access your site on their cell phones</a>?</p>
<p>Your customer base should drive your next hire, says Lavender. “What devices do they use? What browser versions are they on? Are they on tablet, mobile, or desktop? Looking at all those breakdowns would drive you to the methods your QA team would use and what the specialties they would need.”</p>
<p><em>Recommended hire</em>: Someone who specializes in banking apps on iOS devices from versions 10 to 13 using Firefox versions 78 through 82, but only on Tuesdays during a full moon. Someone who <a href="https://www.functionize.com/blog/what-testers-should-know-about-domain-knowledge/">specializes in every other testing scenario</a>, too.</p>
<h3>When your QA team asks you to</h3>
<p>You’re in the software planning phase, and the project manager is laying out the scope of work. Joining you in the room is your QA team lead. Looking at the project, they say it straight up: “We need to hire more testers.”</p>
<p>Egor Bulyhin, project manager and team lead at consulting firm <a href="https://smart-it.com/" target="_blank" rel="noopener noreferrer">Smart IT</a>, says a good QA professional lets you know when work is beyond even their leet skillz. Part of a professional’s skill set is knowing their own limitations, including when they need more people to maintain a steady flow of approved features. It’s up to you to see that they get what they need (unless they need an early retirement).</p>
<p><em>Recommended hire</em>: A QA tester who isn’t afraid to tell you that you need a new hire. A QA tester who isn’t afraid to tell you that your fly is unzipped.</p>
<h3>When you need to keep your customer’s data secure</h3>
<p>Some testing specialties are less about platforms than reliability – including software security. Do you have someone qualified to find application vulnerabilities during testing?</p>
<p>When it comes to sensitive information, you need a higher level of either data or application integrity, Ma says. “One issue could be costly.” Issues include breach of trust or regulatory infractions that result in fines. If your product requires rock-solid data integrity, such as banking applications, you need a tester with relevant experience.</p>
<p>Even if you’re outside a regulatory regime, like the EU’s GDPR, you may still need to comply with it if you support EU customers. Also, have you ever read the term “data breach” in a feel-good piece? No, I didn’t think so.</p>
<p><em>Recommended hire</em>: Someone who knows what the acronym <a href="https://gdpr-info.eu/" target="_blank" rel="noopener noreferrer">GDPR</a> stands for. Someone who winces when you say “<a href="https://www.scmagazine.com/home/security-news/whats-really-changed-three-years-after-equifax-breach/" target="_blank" rel="noopener noreferrer">Equifax</a>.”</p>
<h3>When you need someone in a leadership position</h3>
<p>Let’s say your QA team has been working together for months, and each member excels at the job they’ve always done. But the work is piecemeal, with no cohesion or strategy. It’s time to hire someone with leadership abilities.</p>
<p>Jessica Salter, people operations manager of <a href="https://www.bestresponsemedia.co.uk/" target="_blank" rel="noopener noreferrer">Best Response Media</a>, needed someone who could create guidelines for future best practices. In making the hire, the key attribute was finding someone in a leadership position “to help us establish a strategy and implement new ways of working.” This particular hire should have management experience, to mentor the current QA team and set them up for future success.</p>
<p><em>Recommended hire</em>: Someone who has a plan for future strategies. And might know future lottery numbers.</p>
<h3>When your business is growing</h3>
<p>Maybe your application is getting new functionality. Or perhaps you’re developing an entire new product line. Or your business is among those <a href="https://www.nytimes.com/2020/09/08/style/guitar-sales-fender-gibson.html?fbclid=IwAR39kZlhJCKPqaUmzO9Ix18hFklDs-dnN1M7-yytGPT7EPD6Z4e4drgUY7E" target="_blank" rel="noopener noreferrer">getting a sales boost due to the pandemic</a>, which means it’s time to take on long-delayed projects.</p>
<p>Whatever the reason: On your to-hire list are several new developers. Make sure you add to this list a new QA professional, or you may experience that deadline-slaying backlog mentioned above.</p>
<p>Bulyhin likes to hire QA staff members before a new project begins, so he can onboard them before work ramps up in earnest. More importantly, he works with them to <a href="https://www.functionize.com/blog/the-best-qa-job-interview-questions-for-managers-to-ask/">make sure the new QA hire</a> has the skills they need for this particular job. This way, they both can achieve their work goals.</p>
<p>Recommended hire: Someone who has been there, done that, and <a href="https://duckduckgo.com/?q=%2522quality+assurance%2522+t-shirts&amp;atb=v63-1&amp;iar=images&amp;iax=images&amp;ia=images" target="_blank" rel="noopener noreferrer">has the t-shirts</a>. Very likely, the t-shirt reads, “A QA tester walks into a bar. Orders a beer. Orders 3.33 beers. Orders null beers. Orders &amp;@% beers.”</p>
<blockquote><p>Whomever you hire, surely you want someone with a steady grasp on <a href="https://www.functionize.com/project/getting-started-with-test-automation/">test automation essentials</a>? Our white paper gives you the basics.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/01/author-Carol-Pinchefsky.jpg"></p>
<div>
<p>by Carol Pinchefsky</p>
<p>Carol Pinchefsky is a freelance writer who writes about technology, science, and geek culture. She lives in New York City with her husband and their books. She can also be found on <a href="https://twitter.com/CarolPinchefsky"> Twitter</a>, <a href="https://www.facebook.com/CarolPinchefsky/">Facebook</a> and <a href="http://carolpinchefsky.com/">carol pinchefsky.com</a></p>
</div>

</div>
</div>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/8-ways-to-know-that-its-time-to-hire-a-new-qa-tester/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546260</guid>
            <pubDate>Mon, 21 Sep 2020 17:43:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yoga instructor is fighting the rise of QAnon in the wellness community]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24546235">thread link</a>) | @colinprince
<br/>
September 21, 2020 | https://www.cbc.ca/radio/asithappens/this-yoga-instructor-is-fighting-the-rise-of-qanon-in-the-wellness-community-1.5728153 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/this-yoga-instructor-is-fighting-the-rise-of-qanon-in-the-wellness-community-1.5728153">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Seane Corn never thought her duties as yoga instructor would one day include warning&nbsp;people about the dangers of international right-wing conspiracy theories.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5728482.1600375194!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/seane-corn.jpg"></p></div><figcaption>Seane Corn is an L.A. yoga teacher and Instagram influencer who is part of pushback against proliferation of QAnon conspiracy theories in the wellness space. <!-- --> <!-- -->(Norman Seeff)</figcaption></figure><p><span></span><span>Listen</span><span>7:02</span></p><p><span><p><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5728151/september-17-2020-episode-transcript-1.5730632">Read Story Transcript</a></p>  <p>Seane Corn never thought her duties as yoga instructor would one day include warning&nbsp;people about the dangers of an international right-wing conspiracy theory.</p>  <p>The Los Angeles&nbsp;yoga teacher is one of several high-profile&nbsp;Instagram influencers using their platforms to combat the rise of the QAnon conspiracy theory in wellness spaces.&nbsp;</p>  <p>"I just didn't think that I would be having to talk about things like a cabal of people in the U.S. that are kidnapping children and drinking their blood to gain power," Corn told <em>As It Happens </em>host Carol Off.</p>  <p>"I never thought that this would be a conversation I would have to have with my community to say, like, 'This isn't true. This isn't happening. Please use more discernment.'"</p>    <p>QAnon&nbsp;is a conspiracy theory that&nbsp;posits that&nbsp;U.S. President Donald Trump is secretly fighting an international&nbsp;cabal of Satan-worshipping, leftist elites&nbsp;who are&nbsp;running a global child sex trafficking&nbsp;ring.</p>  <p>It tends to overlap with conspiracy theories that involve anti-vaccination and anti-mask beliefs, and has roots in anti-Semitism and white supremacy.&nbsp;</p>  <p>Once relegated to the fringes of the internet, QAnon has&nbsp;recently made its way into more mainstream spaces. QAnon supporter&nbsp;Marjorie Taylor Greene recently<a href="https://www.cbc.ca/news/world/us-primaries-greene-omar-1.5683022a"> won the Republican nomination in Georgia's primary race</a>, and the president himself has referred to the conspiracy theory's followers <a href="https://www.nytimes.com/2020/08/19/us/politics/trump-qanon-conspiracy-theories.html">as people who "love our country."</a></p>    <p>But it's also started gaining&nbsp;significant traction among people who are into wellness,&nbsp;yoga, spirituality&nbsp;and alternative medicine.</p>  <p><em>Conspirituality,</em> a podcast that examines the links between wellness and conspiracy, has curated a list&nbsp;<a href="https://conspirituality.net/redpilled/">of more than two dozen wellness influencers</a> who have alluded to QAnon in their posts.&nbsp;</p>  <p>Corn says she started to notice it creeping into her social media feed at the start of the pandemic, with its followers&nbsp;using "yoga speak" and wellness branding to radicalize people online.&nbsp;</p>  <p>"The colours might be pastel. The fonts are very specific. There's maybe one post of someone doing yoga. Then the next day it's their food. The next day, it's a lifestyle shot," she said.</p>  <p>"But on maybe the fourth day, there's going to be a post that says, you know, very prettily "COVID is a hoax" and then a bunch of slides that keep giving misinformation and invite you to another link that then gives you more misinformation."</p>  <h2>'Magical thinking'&nbsp;</h2>  <p>For Corn, the conspiracy theory's proliferation in her community is not all that surprising.&nbsp;</p>  <p>"In the wellness community, there's often a lot of magical thinking," she said.</p>  <p>For example, she says people may turn to&nbsp;crystals or prayer as a Band-Aid solution for their life's problems, without engaging with those problems on a deeper level.&nbsp;</p>  <p>"I think that some of the messaging in QAnon&nbsp;is appealing to magical thinking. People are afraid. Their instincts are telling them that there's something else going on, but 'I just don't know what it is. I think I'm being lied to,'" she said.</p>  <p>"Someone is coming in and saying, 'Actually, you are,' and taking them down this rabbit hole."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/qanon-in-quebec.jpg 300w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/qanon-in-quebec.jpg 460w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/qanon-in-quebec.jpg 620w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/qanon-in-quebec.jpg 780w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/qanon-in-quebec.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/qanon-in-quebec.jpg"></p></div><figcaption>Protesters hold a sign with a QAnon slogan at an anti-mask protest in Montreal. <!-- --> <!-- -->(Jonathan Montpetit/CBC)</figcaption></figure></span></p>  <p>Ali Breland,&nbsp;a reporter for Mother Jones who has been covering the overlap between QAnon and wellness, agrees.</p>  <p>He <a href="https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585">told&nbsp;CBC Radio's<em> Day 6 </em>earlier this month</a>&nbsp;that wellness communities were already rife with anti-vaccination sentiment.</p>  <p>"[It's the idea that] these big powerful interests — these external interests that are beyond us, like Big Pharma, that we can't conceptualize, are trying to hurt our children ... and we need to protect them because no one else will," she said.&nbsp;</p>  <p>"That's the prevailing belief of QAnon."</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>There's a lot of women in this community who are sensitive and empathic. And so you bring in, you know, victimized children and you're going to appeal to that part of them that wants to do something, that wants to engage.'<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Seane Corn</cite></span></blockquote>    <p>Annie Kelly, a researcher who studies digital extremism,&nbsp;<a href="https://www.nytimes.com/2020/09/10/opinion/qanon-women-conspiracy.html">recently wrote in the New York Times</a> that QAnon's "ranks are populated by a noticeably high percentage of women."</p>  <p>While suburban moms with yoga mats might not be the first image that pops into most people's minds&nbsp;when they think about online&nbsp;conspiracy theorists, Corn says it actually makes a lot of sense — especially as QAnon followers&nbsp;flood hashtags like #SaveTheChildren.&nbsp;</p>  <p>"There's a lot of women in this community who are sensitive and empathic. And so you bring in, you know, victimized children and you're going to appeal to that part of them that wants to do something, that wants to engage," Corn said.</p>  <h2>Risks of speaking out&nbsp;</h2>  <p>Corn, with her 100,000 Instagram followers, is trying to stem the tide by sharing posts that attempt to neutralize the disinformation.</p>  <p>Others are also heeding the call. Shannon Algeo, a&nbsp;L.A. yoga and meditation teacher with 25,000 followers, is one of several influencers who shared an Instagram post&nbsp;taking&nbsp;stand against the QAnon movement.</p>  <p>"I have a community that stands behind me, or rather stands with me," Corn said.&nbsp;"I'm not alone in this effort."</p>    <p>It's the kind of stance that could, at best, cost them some of their followers and income, and at worst, invite harassment and even violence.</p>  <p>Last week, a Texas&nbsp;woman was charged with&nbsp;aggravated assault with a deadly weapon after she&nbsp;<a href="https://wacotrib.com/news/local/crime-and-courts/affidavit-drunk-driver-who-rammed-car-claimed-to-be-chasing-pedophile/article_5989fa98-49fb-5db1-a5f2-2cef7a42e009.html">struck two strangers with her car</a>. According to the arrest affidavits, she believed they were pedophiles. Two people who knew her <a href="https://www.rightwingwatch.org/post/texas-qanon-car-attack-cecilia-fulbright/">told the website Right Wing Watch</a> she followed&nbsp;QAnon&nbsp;content&nbsp;online and sent them pro-QAnon&nbsp;messages.</p>  <p>Still, Corn says she has to speak out. She's already done interviews <a href="https://www.nytimes.com/2020/09/15/technology/yoga-teachers-take-on-qanon.html">with the New York Times</a>, <a href="https://www.rollingstone.com/culture/culture-news/qanon-wellness-influencers-seane-corn-yoga-1059856/">Rolling Stone </a>and more.&nbsp;</p>  <p>"I would feel worse being silent. That would make me complicit, and I just can't live with myself in that way,"&nbsp;she said. "So, hopefully, I'll remain safe and we'll see what happens."</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Chloe Shantz-Hilkes.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/this-yoga-instructor-is-fighting-the-rise-of-qanon-in-the-wellness-community-1.5728153</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546235</guid>
            <pubDate>Mon, 21 Sep 2020 17:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things we learned running Postgres 13]]>
            </title>
            <description>
<![CDATA[
Score 351 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24544881">thread link</a>) | @lfittl
<br/>
September 21, 2020 | https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>
      <a href="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/aa440/postgres_13.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="postgres 13" title="Astronaut writing Postgres 13" src="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/8c557/postgres_13.png" srcset="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/4edbd/postgres_13.png 175w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/13ae7/postgres_13.png 350w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/8c557/postgres_13.png 700w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/e996b/postgres_13.png 1050w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/2cefc/postgres_13.png 1400w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/aa440/postgres_13.png 1500w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
</p>
<p>Postgres 13 is almost here. It's been in beta since May, and the general availability release is
coming any day. We've been following Postgres 13 closely here at pganalyze, and have been running
the beta in one of our staging environments for several months now.</p>
<p>There are no big new features in Postgres 13, but there are a lot of small but important incremental
improvements. Let's take a look.</p>

<h2 id="performance"><a href="#performance" aria-label="performance permalink"></a>Performance</h2>
<p>Postgres 13 performance improvements include both built-in optimizations and heuristics that will make
your database run better out of the box, as well as additional features to give you more flexibility
in optimizing your schema and queries.</p>
<h3 id="smaller-indexes-with-b-tree-deduplication"><a href="#smaller-indexes-with-b-tree-deduplication" aria-label="smaller indexes with b tree deduplication permalink"></a>Smaller Indexes with B-Tree Deduplication</h3>
<!-- -->

<svg xmlns:xl="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" xmlns:dc="http://purl.org/dc/elements/1.1/" version="1.1" viewBox="222 230.5 630.072 116" width="630.072" height="116">
  <defs>
    <font-face font-family="Avenir Next" font-size="16" panose1="2 11 5 3 2 2 2 2 2 4" units-per-em="1000" underline-position="-75" underline-thickness="50" slope="0" x-height="468" cap-height="708" ascent="1000" descent="-365.9973" font-weight="400">
      <font-face-src>
        <font-face-name name="AvenirNext-Regular"></font-face-name>
      </font-face-src>
    </font-face>
    <font-face font-family="Avenir Next" font-size="16" panose1="2 11 8 3 2 2 2 2 2 4" units-per-em="1000" underline-position="-75" underline-thickness="50" slope="0" x-height="498" cap-height="708" ascent="1000" descent="-365.9973" font-weight="700">
      <font-face-src>
        <font-face-name name="AvenirNext-Bold"></font-face-name>
      </font-face-src>
    </font-face>
  </defs>
  <metadata> Produced by OmniGraffle 7.17.2\n2020-09-20 19:29:10 +0000</metadata>
  <g id="Canvas_1" strokedasharray="none" stroke-opacity="1" stroke="none" fill="none" fill-opacity="1">
    <title>Canvas 1</title>
    <g id="Canvas_1_Layer_1">
      <title>Layer 1</title>
      <g id="Graphic_2">
        <rect x="232" y="240.5" width="250.5" height="39.5" fill="#d8d5df"></rect>
      </g>
      <g id="Graphic_3">
        <rect x="232" y="297" width="89.5" height="39.5" fill="#d8eef0"></rect>
      </g>
      <g id="Graphic_9">
        <text transform="translate(244.128 251.026)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16"></tspan>
        </text>
      </g>
      <g id="Graphic_10">
        <text transform="translate(244.128 309.013)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16"></tspan>
        </text>
      </g>
      <g id="Graphic_13">
        <text transform="translate(502 251.026)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16">deduplicate_items=off</tspan>
        </text>
      </g>
      <g id="Graphic_14">
        <text transform="translate(502 307.526)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16">deduplicate_items=on   </tspan>
          <tspan font-family="Avenir Next" font-size="16" font-weight="700" fill="black" y="16">(new in Postgres 13)</tspan>
        </text>
      </g>
    </g>
  </g>
</svg>
<p>Postgres 13 introduces a way for B-Tree indexes to <a href="https://www.postgresql.org/docs/13/btree-implementation.html#BTREE-DEDUPLICATION">avoid storing duplicate entries in some situations</a>.
In general, a B-Tree index consists of a tree of indexed values, with each leaf node pointing to a
particular row version. Because each leaf points to one row version, if you are indexing non-unique
values, those values need to be repeated.</p>
<p>The de-duplication mechanism avoids that by having a leaf node point to several row versions if possible,
which leads to smaller indexes.</p>
<p>Here is an example from our own pganalyze application schema: We have a <code>queries</code> table to
track all the queries we monitor, and a <code>database_id</code> field to track which database they belong to. We
index <code>database_id</code> (so we can quickly fetch queries for a specific database), and because each database
typically has more than one query, there is a lot of duplication in this index.</p>
<p>New B-Tree indexes in Postgres 13 use the deduplication feature by default, but if for some reason,
you need to turn it off, you can control it with the <code>deduplicate_items</code> storage parameter. Here we
create the same index in two different ways, with deduplication explicitly on and off (though again,
you don't need to specify <code>on</code>—this is the default):</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>INDEX</span> CONCURRENTLY queries_db_id_idx_no_dedup <span>ON</span> queries<span>(</span>database_id<span>)</span>
<span>WITH</span> <span>(</span>deduplicate_items<span>=</span><span>off</span><span>)</span><span>;</span>

<span>CREATE</span> <span>INDEX</span> CONCURRENTLY queries_db_id_idx_yes_dedup <span>ON</span> queries<span>(</span>database_id<span>)</span>
<span>WITH</span> <span>(</span>deduplicate_items<span>=</span><span>on</span><span>)</span><span>;</span>

<span>SELECT</span> relname<span>,</span> pg_size_pretty<span>(</span>pg_relation_size<span>(</span>oid<span>)</span><span>)</span> <span>FROM</span> pg_class
<span>WHERE</span> relname <span>IN</span> <span>(</span><span>'queries_db_id_idx_no_dedup'</span><span>,</span> <span>'queries_db_id_idx_yes_dedup'</span><span>)</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>           relname           | pg_size_pretty 
-----------------------------+----------------
 queries_db_id_idx_no_dedup  | 218 MB
 queries_db_id_idx_yes_dedup | 67 MB
(2 rows)</code></pre></div>
<p>With deduplication, the new index is more than <strong>three times smaller</strong>! Smaller indexes are faster to load
from disk, and take up less space in memory, meaning there's more room for your data.</p>
<p>One interesting note here is that the index entries point to row <em>versions</em> (as in, a row the way it
exists in one specific <a href="https://www.postgresql.org/docs/13/mvcc.html">MVCC</a> state), not rows themselves,
so this feature <strong>can improve index size even for unique indexes</strong>, where one would not expect any duplication
to occur.</p>
<p>Note that deduplication is not possible in all cases (see above link for details), and that you
will need to reindex before you can take advantage of it if upgrading via <code>pg_upgrade</code>.</p>
<h3 id="extended-statistics-improvements-in-postgres-13"><a href="#extended-statistics-improvements-in-postgres-13" aria-label="extended statistics improvements in postgres 13 permalink"></a>Extended Statistics Improvements in Postgres 13</h3>
<p>Postgres 10 introduced the concept of <a href="https://www.postgresql.org/docs/13/planner-stats.html#PLANNER-STATS-EXTENDED">extended statistics</a>. Postgres keeps some statistics about the "shape" of your data to ensure it can plan queries efficiently,
but the statistics kept by default cannot track things like inter-column dependencies. Extended statistics
were introduced to address that: These are database objects (like indexes) that you create manually with
<code>CREATE STATISTICS</code> to give the query planner more information for more specific situations. These would be
expensive for Postgres to determine automatically, but armed with an understanding of the semantics of your
schema, you can provide that additional info. Used carefully, this can lead to
<a href="https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61">massive performance improvements</a>.</p>
<p>Postgres 13 brings a number of small but important improvements to extended statistics, including
support for using them with <code>OR</code> clauses and in <code>IN</code>/<code>ANY</code> constant lists, allowing consideration
of multiple extended statistics objects in planning a query, and support for
<a href="https://www.postgresql.org/docs/13/sql-alterstatistics.html">setting a statistics target</a> for
extended statistics:</p>
<div data-language="sql"><pre><code><span>ALTER</span> <span>STATISTICS</span> table_stx <span>SET</span> <span>STATISTICS</span> <span>1000</span><span>;</span></code></pre></div>
<p>Like with the regular statistics target, this is a trade-off between additional planning time (and longer <code>ANALYZE</code> runs), versus having more precise plans. We recommend using this in a targeted manner using EXPLAIN plans to confirm plan changes.</p>
<h3 id="parallel-vacuum--better-support-for-append-only-workloads"><a href="#parallel-vacuum--better-support-for-append-only-workloads" aria-label="parallel vacuum  better support for append only workloads permalink"></a>Parallel VACUUM &amp; Better Support for Append-only Workloads</h3>
<p>Postgres multi-version concurrency control means you need to run <code>VACUUM</code> regularly (usually you can rely
on the autovacuum process, though it may need some tuning). In Postgres 13, one notable improvement is
that multiple indexes for a single table can be vacuumed in parallel. This can lead to big performance
improvements in <code>VACUUM</code> work. Parallel <code>VACUUM</code> is the default and can be controlled with the <code>PARALLEL</code> option:</p>
<div data-language="sql"><pre><code>VACUUM <span>(</span>PARALLEL <span>2</span><span>,</span> VERBOSE<span>)</span> queries<span>;</span></code></pre></div>
<div data-language="text"><pre><code>INFO:  vacuuming "public.queries"
INFO:  launched 2 parallel vacuum workers for index vacuuming (planned: 2)
INFO:  scanned index "index_queries_on_database_id" to remove 1403418 row versions by parallel vacuum worker
DETAIL:  CPU: user: 0.98 s, system: 0.15 s, elapsed: 2.37 s
INFO:  scanned index "index_queries_on_last_occurred_at" to remove 1403418 row versions by parallel vacuum worker
DETAIL:  CPU: user: 0.88 s, system: 0.27 s, elapsed: 2.60 s
...</code></pre></div>
<p>Parallel VACUUM occurs when the following is true:</p>
<ul>
<li>Sufficient parallel workers are available, based on the system-wide limit set by <a href="https://www.postgresql.org/docs/13/runtime-config-resource.html#GUC-MAX-PARALLEL-WORKERS-MAINTENANCE"><code>max_parallel_maintenance_workers</code></a> (defaults to 2)</li>
<li>There are multiple indexes on the table (one index can be processed by one worker at a time)</li>
<li>Index types support it (all built-in index types support parallelism to some extent)</li>
<li>The indexes are large enough to exceed <a href="https://www.postgresql.org/docs/13/runtime-config-query.html#GUC-MIN-PARALLEL-INDEX-SCAN-SIZE"><code>min_parallel_index_scan_size</code></a> (defaults to 512 kB)</li>
</ul>
<p>Be aware that <strong>parallel VACUUM is currently not supported for autovacuum.</strong> This new feature is intended for use in manual VACUUM runs that need to complete quickly, such as when insufficient autovacuum tuning has lead to an imminent TXID wraparound, and you need to intervene to fix it.</p>
<p>On that note, an important <code>autovacuum</code> improvement in Postgres 13 is that the autovacuum background process can now be triggered by <code>INSERT</code> statements for append-only tables. The main purpose of VACUUM is to clean up old versions of updated and deleted rows, but it is also essential to set pages as all-visible for MVCC bookkeeping. All-visible pages allow index-only scans to avoid checking visibility status row-by-row, making them faster.</p>
<p>We make extensive use of append-only tables at pganalyze for our timeseries data, and this improvement will make our lives considerably easier, avoiding the occasional manual VACUUM run on these tables. This new behavior can be controlled by the <code>autovacuum_vacuum_insert_threshold</code> and <code>autovacuum_vacuum_insert_scale_factor</code> variables.</p>
<h3 id="incremental-sorting"><a href="#incremental-sorting" aria-label="incremental sorting permalink"></a>Incremental Sorting</h3>
<p>Sorting data is a common database task, and Postgres has a number of features to avoid unnecessary work
here. For example, if you have a B-Tree index on a column, and you query your table ordered by that column,
it can just scan that index in order to get sorted data.</p>
<p>In Postgres 13, this is improved to handle partially sorted data. If you have an index on <code>(a, b)</code> (or
the data is already sorted by <code>(a, b)</code> for another reason), and you issue a query to order by <code>(a, b, c)</code>,
Postgres understands that the input data is already partially sorted, and can avoid re-sorting the whole
dataset. This is especially useful if you have a <code>LIMIT</code> in your query, since this can avoid even more
work.</p>
<h2 id="monitoring"><a href="#monitoring" aria-label="monitoring permalink"></a>Monitoring</h2>
<p>Monitoring improvements in Postgres 13 include more details on <code>WAL</code> usage, more options for logging your
queries, and more information on query planning.</p>
<h3 id="wal-usage-stats"><a href="#wal-usage-stats" aria-label="wal usage stats permalink"></a>WAL Usage Stats</h3>
<p>The write-ahead log (<code>WAL</code>) ensures your data stays consistent in the event of a crash, even mid-write. Consistency
is a fundamental property of databases—it ensures your transaction either committed or did not commit; you don't
have to worry about in-between states. But on a busy system, <code>WAL</code> writes can often be a bottleneck. To help
diagnose this, Postgres 13 includes more information on <code>WAL</code> usage from your queries.</p>
<p><code>EXPLAIN</code> now supports information about <code>WAL</code> records generated during execution:</p>
<div data-language="sql"><pre><code><span>EXPLAIN</span> <span>(</span><span>ANALYZE</span><span>,</span> WAL<span>)</span> <span>DELETE</span> <span>FROM</span> users<span>;</span></code></pre></div>
<div data-language="text"><pre><code>                                                    QUERY PLAN                                                     
-------------------------------------------------------------------------------------------------------------------
 Delete on users  (cost=0.00..5409.00 rows=100000 width=6) (actual time=108.910..108.911 rows=0 loops=1)
   WAL: records=100000 fpi=741 bytes=11425721
   -&gt;  Seq Scan on users  (cost=0.00..5409.00 rows=100000 width=6) (actual time=8.519..51.850 rows=100000 loops=1)
 Planning Time: 6.083 ms
 Execution Time: 108.955 ms
(5 rows)</code></pre></div>
<p>You can see that the <code>WAL</code> line includes the number of records generated, the number of full page images (fpi), and
the number of <code>WAL</code> bytes generated. Only non-zero values are printed in the default text format.</p>
<p>This is also available in <code>pg_stat_statements</code>. For example, on our staging environment, here is what we ran to get
the statement that produced the most <code>WAL</code> records:</p>
<div data-language="sql"><pre><code><span>SELECT</span> query<span>,</span> calls<span>,</span> wal_records<span>,</span> wal_fpi<span>,</span> wal_bytes <span>FROM</span> pg_stat_statements
  <span>ORDER</span> <span>BY</span> wal_records <span>DESC</span> <span>LIMIT</span> <span>1</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>-[ RECORD 1 ]---------------------------------------------------------------------------------------------
query       | CREATE TEMPORARY TABLE upsert_data (server_id uuid NOT NULL, backend_id uuid NOT NULL,
            | query_start timestamp NOT NULL, query_fingerprint bytea NOT NULL, query_text text NOT NULL)
calls       | 7974948
wal_records | 966960816
wal_fpi     | 1018412
wal_bytes   | 100086092097</code></pre></div>
<p>Like many other values in <code>pg_stat_statements</code>, the <code>wal_records</code>, <code>wal_fpi</code>, and <code>wal_bytes</code> values here are
cumulative since the last <code>pg_stat_statements_reset</code> call.</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability">https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544881</guid>
            <pubDate>Mon, 21 Sep 2020 15:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Scoping in C++]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24544716">thread link</a>) | @stettberger
<br/>
September 21, 2020 | https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP.html | <a href="https://web.archive.org/web/*/https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-post-dynamic-scope-cpp">
            <ol>
                      <li><a href="https://blog.dokucode.de/index.html">Home</a></li>

    <li><a href="https://blog.dokucode.de/posts.html">Posts</a></li>

    <li><strong>Dynamic Scoping in C++</strong> </li>

    </ol>

           
  <p><i>Date: 2020-07-10</i></p><p>I always had a faible for dynamic scoping as it is implemented in
Common Lisp, Emacs Lisp, or LaTeX. To me, it seems that dynamic
scoping is an almost forgotten technique and dismissed technique in
modern programming. While it is more complex to understand and more
magically than lexical scoping, there are some applications that
benefit from dynamic scoping.</p>
<p>In lexical scoping, if you access a variable, your compiler will start
searching the declaration from the point of reference outwards in
lexical order. This means it searches first in the most inner scope,
and continoues to widen its search scope by the "closed-nested-scope
rule". For example, in the following code snippet, the call to <code>foo()</code>
would return 23, as the lexcially-closest declaration is the global variable.</p>
<div><pre><span></span><span>int</span> <span>config</span> <span>=</span> <span>23</span><span>;</span>

<span>return</span> <span>foo</span><span>()</span> <span>{</span>
    <span>return</span> <span>config</span><span>;</span>
<span>}</span>

<span>void</span> <span>bar</span><span>()</span> <span>{</span>
    <span>int</span> <span>config</span> <span>=</span> <span>42</span><span>;</span>
    <span>printf</span><span>(</span><span>"%d</span><span>\"</span><span>, foo());</span>
<span>}</span>
</pre></div>


<p>With dynamic scoping, the world would look different as the closest
(time-wise) dynamic binding for a given name is found instead of
lexically closest. In the example, <code>foo()</code> would return 42, as the
binding in <code>bar()</code> happened more recently that the global binding.</p>
<p>You can think of a dynamically-scoped global variable as shadowable
global binding. By creating a new binding for the variable, we shadow
the old binding, and all references in child functions will now refer
to the new binding, although they have not received the value via an
argument transfer. Ergo, dynamically-scoped variables are shadowable
side-channels that can influence the behavior of a function.</p>
<p>For example, in Common Lisp, the variable <code>*standard-output*</code> is
dynamically scoped and functions <code>(print)</code> simply send there
characters to that variable. As it is dynamically scoped, we can just
redirect all output to a file by creating a new binding for
<code>*standard-output*</code>.</p>
<div><pre><span></span><span>(</span><span>with-open-file</span> <span>(</span><span>*standard-output*</span> <span>"somefile.dat"</span> <span>:direction</span> <span>:output</span>
                                   <span>:if-exists</span> <span>:supersede</span><span>)</span>
   <span>(</span><span>print</span> <span>"this goes into file"</span><span>))</span>
</pre></div>


<p>Wouldn't it be neat to do the same in, let's say, C++? Luckily, with
templates, the RAII pattern, and some template magic, we can write
code like this:</p>
<div><pre><span></span><span>DynamicScope</span><span>&lt;</span><span>int</span><span>&gt;</span> <span>G</span><span>(</span><span>0</span><span>);</span>

<span>void</span> <span>bar</span><span>()</span> <span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"bar "</span> <span>&lt;&lt;</span> <span>*</span><span>G</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
<span>}</span>

<span>void</span> <span>foo</span><span>()</span> <span>{</span>
    <span>DynamicScope</span><span>&lt;</span><span>int</span><span>&gt;::</span><span>BindInstance</span> <span>_</span><span>(</span><span>G</span><span>,</span> <span>3</span><span>);</span>
    <span>bar</span><span>();</span>
<span>}</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"main1 "</span> <span>&lt;&lt;</span> <span>*</span><span>G</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>foo</span><span>();</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"main2 "</span> <span>&lt;&lt;</span> <span>*</span><span>G</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>

<span>}</span>
</pre></div>


<p>and end up with the output:</p>



<p>The source for the <code>DynamicScope&lt;T&gt;</code> can be found here:    <a href="https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP/dynamic_scope.cc">dynamic_scope.cc</a>
</p>
<h2 id="update-23092020-multi-threaded-programs">[UPDATE 23.09.2020] Multi-Threaded Programs</h2>
<p>After some discussion on
<a href="https://news.ycombinator.com/item?id=24544716">HackerNews</a> (which I
highly recommend to read), I was made aware that the previous
implementation has a problem with multi-threaded programs. As all
threads share the same global objects as a root to their dynamic-scope
value stack, bindings in one thread had an influence on the bindings
in another thread. Of coure, this would be a broken version of dynamic
scoping.</p>
<p>The problem can be circumvented by making the global variable thread local:</p>
<div><pre><span></span><span>thread_local</span> <span>DynamicScope</span><span>&lt;</span><span>int</span><span>&gt;</span> <span>G</span><span>(</span><span>0</span><span>);</span>
</pre></div>


<p>With this, every thread has its own version of the G object, which
internally is the head of a linked list of the shadowed values.
However, someone could forget the add the required thread_local attribute.</p>
<p>Unluckily, checking whether the storage class of a given variable is
thread_local is not that trivial. However, I came up with a rather
low-cost sanity check that ensures that a variable must be declared
<code>thread_local</code>. The updated version of <code>DynamicScope&lt;T&gt;</code>, as well as
some benchmarking code, can be found here:    <a href="https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP/thread_dynamic_scope.cc">thread_dynamic_scope.cc</a>
</p>
      </div></div>]]>
            </description>
            <link>https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544716</guid>
            <pubDate>Mon, 21 Sep 2020 15:45:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dating is better than ever with social distancing]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24544686">thread link</a>) | @colinprince
<br/>
September 21, 2020 | https://www.cbc.ca/radio/thedebaters/dating-is-actually-better-than-ever-with-social-distancing-1.5629793 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/thedebaters/dating-is-actually-better-than-ever-with-social-distancing-1.5629793">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>DeAnne Smith and Arthur Simeon have each other’s number when they discuss if social distancing improves dating.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5629807.1593220440!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/social-distance-dating.jpg"></p></div><figcaption> <!-- -->(CCO/Pexels)</figcaption></figure><p><span></span><span>Listen</span><span>17:15</span></p><p><span><p><a href="http://www.deannesmith.com/" target="_blank">DeAnne Smith</a> and <a href="https://www.arthursimeon.com/" target="_blank">Arthur Simeon</a> have each other's number when they discuss if social distancing improves dating.</p>  <p>DeAnne Smith makes it clear why dating in isolation is their fascination.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Being in a new relationship during a global pandemic puts things in perspective. We're not evaluating each other on whether or not we want to grow old together&nbsp;but on whether or not we want to grow vegetables together.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- DeAnne Smith</cite></span></blockquote>    <p>But Arthur Simeon says he's not willing to go the distance with social distance dating.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Every first date is happening via video call so while you don't have to be bothered by showering or wearing anything below the waist, you still have to find the most 'interesting' corner of your house to make the call.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Arthur Simeon</cite></span></blockquote>    <p>For a debate that will make you feel like a lovesick quaran-teen-ager, click play now!</p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/thedebaters/dating-is-actually-better-than-ever-with-social-distancing-1.5629793</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544686</guid>
            <pubDate>Mon, 21 Sep 2020 15:42:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 Basic Rules of Productivity]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24544084">thread link</a>) | @iuliangulea
<br/>
September 21, 2020 | https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p><img src="https://iuliangulea.com/images/how-people-learn/working-memory/3-basic-rules-of-productivity-cover.png" alt="3 Basic Rules Of Productivity Cover"></p>
<p>Have you ever wondered what happens inside our brain whenever we are thinking about something? How some people have great ideas, are able to learn fast, and are incredibly productive, while others are struggling with finalizing even a simple task? There are many components to this process, and in this article, you will learn about one of them.</p>
<p>Working Memory is one of the <a href="https://iuliangulea.com/blog/how-people-learn-memory-storage-types/">several memory types</a> where information is processed and manipulated before it is either discarded or committed to the long-term storage. Understanding its nuances can allow us to be more efficient in using it and be a bit more productive at what we do.</p>
<p>And since it is at the core of information processing by our brain, the things you are about to learn are independent of the domain you are working in.</p>
<h2 id="an-strikeirstrikerelevant-example-first">An <strike>Ir</strike>relevant Example First</h2>
<p>I don’t know how many articles online make you do exercises, but let’s do one right now. Moreover, I count on your integrity to follow the exercise’s directions since I cannot check you play by the rules.</p>
<h3 id="exercise-description">Exercise Description</h3>
<p>You will see below two blank boxes. Upon clicking on “Show Letters,” you will see two sequences (one after another) of random characters for 7 seconds each.</p>
<p><em>Rule # 1:</em> after you click on the button, you have 7 seconds to read and memorize the first sequence, and 7 seconds for the second one (the sequences will display automatically, you only have to click on the button once).
<em>Rule #2:</em> do not use any note-taking software (doc, excel, text editor, etc.) or hardware (pen and paper, pen and table, pen and walls; a pencil if fine though!). Well, you can, but you will miss the whole point of it.</p>

<p>abcdlmnowxyz</p>
<p>gdluwcemjroc</p>   
<p>Great! How it went? Sorry if you tried to click on a box the second time, and it didn’t show up. I put some sophisticated locking mechanisms in place to prevent that.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Now, there are two more boxes below. Click on each of them, input the characters you memorized, and see how good you have performed on the task.</p>
<div id="boxAnswer1">
    
    <div id="comparisonData1">
        <p>abcdlmnowxyz</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>
<div id="boxAnswer2">
    
    <div id="comparisonData2">
        <p>gdluwcemjroc</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>   
<p>If you got neither of them correctly, do not worry. 7 seconds is quite fast, and, as you will see next, the capacity of Working Memory is limited.</p>
<p>If you did remember only the first one, though, how did you do it? Most people usually memorize it as three distinct subsets: <code>abcd</code> <code>lmno</code> <code>wxyz</code>. It is relatively easy to remember it because of several reasons:</p>
<ul>
<li>instead of 12 units of information (characters, in this case), you had to memorize much less (3 letters and the length of the groups–4);</li>
<li>you have inherent knowledge about the alphabet (if you, dear reader, are older than 6 years);</li>
<li>you have advanced <a href="https://en.wikipedia.org/wiki/Pattern_recognition_(psychology)">pattern recognition</a> abilities that help you discern and group units of information into collections;</li>
</ul>
<p>But what about the second sequence?</p>
<p>How did you attempt to memorize it? Maybe you have split the characters into chunks of 3 or 4 letters and tried to remember the groups, or perhaps you made words out of different adjacent letters and memorized those, or even you came up with a totally different strategy. Anyway, it is usually harder to remember the second sequence. And that is because the amount of information exceeded the capacity of our Working Memory. You had to memorize 12 units of information (or had to search anxiously for some associations to find a way to group those letters), while you have much less space to process at once in such a short period of time.</p>
<p>Let’s do one more similar exercise, but this time with numbers.</p>

<p>193919451969</p>
<p>826492104350</p>   
<p>How did it go? You can verify your answers below.</p>
<div id="boxAnswer3">
    
    <div id="comparisonData3">
        <p>193919451969</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>
<div id="boxAnswer4">
    
    <div id="comparisonData4">
        <p>826492104350</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>   

   
<p>There are two main approaches to store the first sequence of digits. The first is to combine them by 2, getting 19, 39, 19, 45, 19, and 69. You have 19 repeating three times, a 39 and 69 that are divisible by three, and a 45 that you just have to remember. But this approach is suboptimal. A more efficient one is to group them by four and use some knowledge of history. You can represent that sequence as three numbers: <code>1939</code>, <code>1945</code>, and <code>1969</code>. The first two are the start and end of the Second World War, and the third is the year of the <a href="https://en.wikipedia.org/wiki/Apollo_11">Apollo 11 moon landing</a>. So you just need to remember three chunks of information rather than 12. It is another demonstrative example that shows how our brain not only seeks to encode and compress information (as in the previous example with the first character sequence), but also it heavily relies on existing knowledge (as in the case with the WWII and moon landing years). The approaches you take may also vary in their efficiency.</p>
<p>The second one does not have any specific pattern to follow. Maybe you divided the sequence into groups of two or three or even four digits, or perhaps you tried to find a rule to group them. For instance, 82 add up to 10, then 64 add up to 10, but it’s not consistent. You’ll arrive at 92, and it doesn’t add up to 10. The approaches can be very different here, but the conclusion is the same - the second sequence is harder to remember because there is no exact rule or compression algorithm that would facilitate the remembering.</p>
<h2 id="the-working-memory-capacity">The Working Memory Capacity</h2>
<p>We saw that it is hard to memorize a sequence of 12 items, which implies that its capacity should be smaller than that, as otherwise, you would effortlessly remember those 12 pieces of information. But how <strike>big</strike> small is it?</p>
<p>The first quantification of the working memory capacity was provided in 1956 in a paper by George A. Miller titled: <em>“The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information."</em> It is one of the most highly cited papers in psychology<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> with over 33400 papers that cited it (at the time of writing), according to <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=The+magical+number+seven%2C+plus+or+minus+two%3A+Some+limits+on+our+capacity+for+processing+information.&amp;btnG=">Google Scholar</a>. In his paper, Miller claims the working memory capacity to be 7±2 “chunks,” to which I’ll get shortly.</p>
<p>But since 1956, the Working Memory was actively researched and studied, and other theories of its capacity emerged. One such prominent hypothesis is that of Nelson Cowan, who in 2001 published the paper titled <em>“The magical number 4 in short-term memory: A reconsideration of mental storage capacity,"</em> in which, you guessed, he suggests a smaller capacity of <em>four chunks.</em></p>
<h2 id="what-is-a-chunk-anyway">What Is A Chunk Anyway?</h2>
<p>Since we can store a very limited amount of chunks in the Working Memory for processing, how does one define a <em>chunk?</em></p>
<p>Unfortunately, there is no concrete answer to this question because it is a relative measure that depends on the type of information and the pre-existing knowledge of the person who operates with it.</p>
<p>It can vary greatly:</p>
<ul>
<li>If you are not familiar with the Russian language, the sequence <code>плюшечка</code> would result in a chunk being the size of an individual letter (or even less), since you don’t have implicit knowledge about it. However, it would represent a single chunk for a Russian speaking person since it is a real word (in a diminutive form).</li>
<li>Distinct words such as <em>job, emotion, productivity</em> may represent single chunks.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></li>
<li>Combinations of words like <em>“The Fellowship Of The Ring,” “The Two Towers,” “The Return Of The King”</em> can also be considered individual chunks.</li>
<li>Entire sentences can also represent chunks: “Today, I went to the seaside.” or “I am a responsible citizen, and I will vote.”</li>
<li>When thinking about them holistically, even entire chapters and books may represent single chunks, as in the Lord Of The Rings trilogy mentioned above.</li>
</ul>
<p>As you can see, there is no exact size for a chunk, as it depends on different factors, such as:</p>
<ul>
<li>familiarity with the topic;</li>
<li>complexity of the concept;</li>
<li>one’s mental agility;</li>
</ul>
<p>But chunks are not represented only by words on paper or screen:</p>
<ul>
<li>Chess players store groups of pieces together when they are asked to reproduce a chess arrangement from memory onto an empty chessboard.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Therefore, a chunk represents the position of several figures at once.</li>
<li>Solving a simple math equation like <code>8 * 3 - 42 / 2 = ?</code> requires an iterative approach to load the operands with the highest priority (8 and 3) and the operation to perform (multiplication), then solve that simple equation and store the result in the WM (24), repeat with next pair of operands (42 / 2), hold the result (21), and finally, repeat one more time, by accessing the results of the two simple operations in the WM and doing the subtraction (24 - 21) to get 3.</li>
<li>Attending a meeting requires keeping different presented ideas in mind to reason about them, make connections with one’s own thoughts, or doing tons of other stuff with them.</li>
</ul>
<h2 id="navigating-the-hierarchical-structure-of-information-within-a-complex-network-of-associations">Navigating The Hierarchical Structure Of Information Within A Complex Network Of Associations</h2>
<p>You might wonder how a chunk may be represented by a single word as well as a whole book? After all, the amount of information differs immensely.</p>
<p>The idea here is how data is represented in our long-term memory and the agility of our Working Memory to combine information. The processes I have described run seamlessly and fast. When we read a sentence (not a random list of words), we expect a specific structure that we are very good at understanding. We know there is usually an action, an object, and a subject in a sentence.</p>
<p>So, when we read words, our Working Memory combines parts of the sentence into chunks and stores them in one of the four available memory slots. Then, once you are done reading a sentence, WM extracts all the relevant pieces that belong to the sentence you just read, combines them into a <em>superchunk,</em> and stores it in a single memory slot or even enter it into the long-term memory. Once you have read a paragraph, you combine several sentence superchunks into one, store it, and repeat the entire process. You thus create a hierarchy of information.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/working-memory/hierarchical-information.png" alt="Image of information hierarchy"></p>
<p>You can navigate it up and down. Say, you discuss the events described in the “Lord Of The Rings: The Fellowship Of The Ring” book with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/">https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/</a></em></p>]]>
            </description>
            <link>https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544084</guid>
            <pubDate>Mon, 21 Sep 2020 14:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I visualised the co-occurrence of origin and variety in coffee beans]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24543871">thread link</a>) | @DataCrayon
<br/>
September 21, 2020 | https://datacrayon.com/posts/statistics/data-is-beautiful/arabica-coffee-beans-origin-and-variety/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/statistics/data-is-beautiful/arabica-coffee-beans-origin-and-variety/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Data is Beautiful</h2>
                    <p>
                    A practical book on data visualisation that shows you how to
                    create static and interactive visualisations that are engaging and
                    beautiful.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the book</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertop_dib.jpg">
</p>
                </div>
            </div>
            </div>
        </div><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        
            

            
<div id="support-this-work-top">
                                <p>Made with Chord Pro</p>
                                <p>
                        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.</p>
                            </div>

            

    


                    <div id="support-this-work-bottom">
                                    <p>Made with Chord Pro</p>
                                    <p>
        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.
        </p>
                                </div>
                            </div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/statistics/data-is-beautiful/arabica-coffee-beans-origin-and-variety/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543871</guid>
            <pubDate>Mon, 21 Sep 2020 14:27:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google and data brokers accused of illegally collecting people’s data: report]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543614">thread link</a>) | @chris_f
<br/>
September 21, 2020 | https://www.politico.eu/article/google-and-data-brokers-accused-of-illegally-collecting-data-report/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/google-and-data-brokers-accused-of-illegally-collecting-data-report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<div>
            <figure><div><div><p><img src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/GettyImages-1200825328-714x476.jpg"></p></div></div><figcaption><p>Google faces allegations of illegal user-data collection | Kenzo Tribouillard/AFP via Getty Images</p></figcaption></figure>        <div>
        <header>
                        
                        <p>A campaigner says much of the world’s online advertising industry doesn’t comply with Europe’s privacy rules.</p>
                    </header>
                
<!--/.meta-->
    </div><!--/.summary-->
</div><!--/.story-intro-->

							
							
							<p>Google and several data brokers are violating the EU's privacy rules by harvesting people's personal information to build highly detailed online profiles, including some firms' collection of information on sexual orientation, health status and religious beliefs, <a href="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/JohnnyRyanDocumnet.pdf">according to a report</a> published on Monday.</p>
<p>The accusations — from Johnny Ryan, a senior fellow at the Irish Council for Civil Liberties, an NGO — come 18 months after Ireland's privacy regulator began a probe into how Google collects and shares people's online information for its advertising business.</p>
<p>Several other European data protection authorities subsequently received separate complaints into so-called real-time bidding (RTB), a system by which advertisers use data to target people with paid-for messages when they surf the web.</p>
<p>The online advertising industry, including Google, says it has bolstered privacy protections since the European Union started enforcing its updated rules, known as the General Data Protection Regulation, or GDPR, more than two years ago.</p>
<p>But Ryan, who filed a complaint with the Irish privacy regulator about these data practices in September 2018, said that little has changed since the new rules came online two years ago.</p>
<p>He called on Ireland's Data Protection Commission (DPC) to act swiftly to clamp down on what he believes were wide-scale breaches of people's online privacy, including the use of online profiles to target individuals around sensitive topics like whether they have AIDS, and to influence voters during elections.</p>
<p>Ryan said the real-time bidding system, which broadcasted web users' online behavior and habits to multiple advertising companies and data brokers, infringed on the region's privacy rules that required data to be kept secure and used proportionately.</p>
<p>"The [Irish Data Protection] Commission has failed to stop that ongoing biggest data breach in history and as a consequence people across Europe and in Ireland are exposed to intimate profiling including of health conditions and political views and location over time, because the RTB system leaks that data into the data broker market," he told POLITICO in reference to Ireland's privacy regulator.</p>
<h3>Spotlight on Dublin</h3>
<p>Because Dublin is home to many of the world's largest tech companies like Google and Facebook, it has the responsibility to oversee how they comply with Europe's privacy standards.</p>
<p>Under the region's data protection rules, sensitive data, including information about a person's health status, sexual orientation or religious beliefs, must be handled more carefully than other information, and companies have to explicitly ask individuals if such information can be collected about them.</p>
<p>"The question for Ireland and the Irish government that must be answered is whether DPC is capable of advancing critical urgent investigations of this nature," he added. "Does it have adequate resources, including technical and procedural competence to discharge its tasks?"</p>
<p>In response, Ireland's privacy agency said that it had met with Ryan to discuss his concerns and that work on its Google investigation continues. The watchdog also has a separate ongoing probe into the data practices of Quantcast, a major online advertising firm, though it has yet to bring an enforcement action or fine against any non-Irish company or organization under Europe's privacy rules.</p>
<p>"The investigation has progressed and a full update on the next steps [was] provided to the concerned party," said Graham Doyle, deputy commissioner at Ireland's privacy agency, in reference to Ryan's complaint about how Google and others collect and use people's data. He declined to comment on what the next steps would be or when a decision would be taken in the investigation into the search giant.</p>
<p>Google said that it also has safeguards in place to protect people's personal data, including in its real-time bidding network.</p>
<p>"We do not allow advertisers to select ads based on sensitive personal data and we do not share people’s sensitive personal data, browsing histories or profiles with advertisers," Alex McPhillips, a Google spokesman, said in a statement.</p>
<p>In his report, Ryan outlines what he says are ongoing privacy failures by many of the world's largest online advertising firms and data brokers linked to the global real-time bidding industry.</p>
<p>That includes OnAudience, a data broker, that holds data on people in almost every country on the planet, according to its website.</p>
<p>It used that information,&nbsp;for instance, to target 1.4 million people who supported gay rights during last year's Polish parliamentary election, <a href="https://www.dropbox.com/sh/7xo77grl2mnb6b6/AAAlszXoQ_zM2kUSsSRqKJSqa?dl=0&amp;preview=4.+Evidence+of+election+interference+in+Poland+(Appendix+A).pdf" target="_blank">based on&nbsp;a company presentation</a>. To do that, OnAudience created online profiles of people based on whether they had read, watched or searched for content associated with LGBTQ rights ahead of the vote, and used that data for a get-out-the-vote campaign for a local group.</p>
<p>The company also uses its database to allow clients to target people who have displayed an interest in other sensitive data topics such as AIDS and HIV, diabetes, incest and abuse support. Such information is considered sensitive and must be handled with additional care under Europe's privacy rules.</p>
<p>An OnAudience representative said the company does not process any personal data, or information about sexual orientation. “Our data is only based on online behavior and visited content. The campaign mentioned [in Ryan’s research] was not conducted by a political party, but by a social organization that promotes equality.”</p>
<p>"The most intimate thing about anyone that you can buy is their health data because this dictates their life expectancy, their ability to pay their mortgage, the risk of giving them health insurance and potentially influences decisions about whether to employ them," Ryan said.</p>
<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="mailto:pro@politico.eu" target="_blank">pro@politico.eu</a> to request a complimentary trial.</em></p>

														<!--/.story-supplement-->
							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/google-and-data-brokers-accused-of-illegally-collecting-data-report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543614</guid>
            <pubDate>Mon, 21 Sep 2020 14:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is revenue model more important than culture?]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24543510">thread link</a>) | @Ozzie_osman
<br/>
September 21, 2020 | https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-101">

	

	
	<div>
		
<p>I always loved getting problems of the type “What is the limit as x approaches infinity” type in high-school/college. You’re given an equation (of the classic y=x format), and asked to derive what the value of y will be as x grows to infinity.</p>



<p>One thing you learn pretty quickly about these types of problems is that often it doesn’t matter where the function “starts” (or where it is at small values of x). It could start at zero, or at negative infinity, but its limit might be infinity, and vice versa (it could start large but have a limit of zero or negative infinity).</p>



<p>In fact, for many equations, there’s usually one <strong>dominant term</strong>. This is the term that dominates the limit. There might be countless other factors or parts of the equation that matter initially, but eventually it’s that dominant term that wins. This is sometimes known as the <strong>dominant term rule</strong>. We’ll get back to this in a second.</p>



<h3>Ads vs. Search</h3>



<p>Google had a little press kerfuffle a few months ago. You can read a summary in the New York Times <a href="https://www.nytimes.com/2020/01/31/technology/google-search-results.html">here</a>, but the short of it is that the company launched a design change that made search results and ads look very similar. Presumably, this increased revenue for Google, since many people ignore ads when they can easily identify them, the same way you’d ignore stepping in dog crap if you can identify it in the mud (and yes, given the state of online ads and content I pick this analogy deliberately). But there was a pretty strong backlash against this as a “dark pattern” designed to trick users. After the negative press, Google walked back the change.</p>



<p>If you’ve been following the news around big tech companies these past couple of years, this type of behavior is not surprising at all. These companies have grown really large, are arguably monopolistic, and hyper-focused on growth and revenue. Over and over, they have made decisions that have resulted in backlash from the press and from their users.</p>



<p>On the other hand, if I ignore the past ten years, and jump back to when I worked at Google as an entry-level Software Engineer, it is a <em>little</em> surprising to me. I worked at Google from 2006-2009. At the time, it was already a rapidly-growing public company (I think I joined when there were around 8,000 employees, and left when there were 20,000). I initially worked on the team responsible for AdWords, so I had some exposure to the culture and decisions that were made at the time (of course it wasn’t <em>deep</em> exposure, since I was an entry-level Software Engineer on the lowest rung of the ladder… but it was exposure nonetheless).</p>



<p><em>Note: I’m going to pick on Google a little bit here, but I do love that company. I think there’s a lot it can improve on, but it’s still one of my favorite and least “evil” large tech company. I chose them simply because I’m more familiar with them.</em></p>



<p>At the time, Google employees might have argued against making a change because it was “evil”. The “don’t be evil” motto was still around, and as engineers who were building parts of the product and making decisions, we were pretty ideological about it. One of the company’s values was also to put users first, employees second, and shareholders third. By any of these lenses, the type of design change that Google got flak for recently would have been highly unlikely at the time.</p>



<h3>Revenue is the Dominant Term</h3>



<p>Let’s take a dominant term view of this problem. When a company is first built, several variables dictate its decisions:</p>



<ul><li>The <em>implicit </em>values/culture of the early team. As Ben Horowitz would say, “what you do is who you are.”&nbsp;</li><li>The <em>explicit </em>values/culture of the early team. Are we user-centric? Data-driven? …</li><li>The revenue model.</li></ul>



<p>I think that over time, the revenue model is the dominant term. The limit of a product towards infinity, so to speak, is based on its revenue model. If your revenue model is ads, it doesn’t matter if your stated mission is “to organize the world’s knowledge and make it universally accessible and useful”, “to give people the power to build community and bring the world closer together”, or anything else. If your revenue model is ads, you are an ads company.</p>



<p>I’m not diminishing the role of culture and values. I think those are critical. Part of me would love to believe the hundreds of books written on how culture determines everything. But I don’t. At least not for companies that can hire some of the smartest people in the world, gather massive amounts of data, and build technology more sophisticated than ever. And be trying to “maximize shareholder value”.</p>



<p>I’ve actually agonized over whether culture or revenue are the dominant term. In fact, I agonized so much that I’ve had this article in my head for years, and in a Google Doc for months, but I couldn’t get myself to write it / publish it. Because part of me believes culture always wins. Actually, <em>all</em> of me <em>wants </em>to believe culture <em>always</em> wins. But I’ve had my idealism crushed enough times by hard realities.&nbsp;</p>



<p>Yes, having and espousing a positive culture and set of values are important. And they may shape how and how quickly the revenue model dominates (for example, companies like Enron or pre-IPO Uber show how bad things can get if you have a terrible culture). But regardless of your mission statement, your culture, your values, and so on, if you choose the wrong revenue model, it will dominate them in a shareholder-value-driven, capitalistic society. Culture can only dominate if it’s negative. A positive culture <em>is </em>necessary, but it’s not sufficient.</p>



<p><em>In other words, over the long term, a company (and its product) will morph to take the shape of its revenue streams.</em></p>



<h3>Charlie Munger Knew It</h3>



<p>Charlie Munger, Warren Buffet’s business partner, has a pretty famous speech where he talks about the power of incentives.</p>



<blockquote><p>“Well I think I’ve been in the top 5% of my age cohort all my life in understanding the power of incentives, and all my life I’ve underestimated it. And never a year passes, but I get some surprise that pushes my limit a little farther.” —<a href="https://fs.blog/2013/02/the-psychology-of-human-misjudgement/">Charlie Munger</a></p></blockquote>



<p>Charlie gives several examples: for instance, FedEx needed to move/sort their packages more quickly, so instead of paying employees per hour, they paid them per shift: productivity increased dramatically (employees now had less incentive to take longer hours to do the same amount of work). Charlie’s model of human behavior is pretty simple: we follow incentives. He makes people sound almost coin-operated.</p>



<p>Now, this isn’t entirely true—there are plenty of examples and research showing that our behavior is more complicated than simple incentives would predict. But Charlie is arguably one of the best investors in the world, and he’s onto something. Even though there might be other variables that influence our behavior, you can still simplify things down to incentives. Incentives are his dominant term.</p>



<p>That incentives are dominant is actually pretty obvious to a lot of people. Somehow in the tech industry, we seem to have just clouded our own judgement through some sense of moral superiority. We care about the impact we’re having on the world. We have noble missions that we rally around and try to hire people who are excited by them. So far, so good. But then we shoot ourselves in the foot by setting up business models with misaligned incentives.</p>



<h3>Look for Aligned Business Models</h3>



<p>So what does this mean in practice? Well, if you only care about making money, it doesn’t mean much. But if you do care about more than money, if you care about the impact your work has and you want to be proud of what you do, it’s worth thinking through this a little more deeply.</p>



<p>Whether you’re starting a company or joining one, look for a business model <em>without</em> perverse incentives. A business model that sets things up so that the better a product is, the better off the company is and its users are.</p>



<p>Sometimes, counterintuitively, a business model may seem aligned at first glance, but end up being quite harmful. The classic example that we’re all now aware of is free products. Free seems great at first glance. But companies have to make money somehow. So they sell ads, or data, or some mix of the two that their users don’t quite understand. And so now, success for the company means more time spent on the product (which may or may not be a good thing for users), less privacy (definitely not a good thing for users), and ultimately more ads.*</p>



<p>So often, paid is better than free*.  At <a href="https://www.monarchmoney.com/">Monarch Money</a>, my current startup, we’ve chosen to go with a paid model, with a hope that we’ll be more aligned in creating value for our users (who we can now call customers… notice how there’s a word for “customer service”, but no “user service”?). There will still be plenty of forks in the road where we can decide whether we help our customers, or take advantage of them, and I hope our values will help us navigate those forks, but at least the revenue model is in our favor.</p>



<p>Another layer to consider is whether your product and revenue model help people with just short-term goals, or a mix of both short and long-term goals. Products that are great and helpful, help their users with both. Good products might help with one or the other. The products with the most potential for damage provide some short-term benefit at the <em>expense</em> of longer-term goals.</p>



<p>So when you consider starting or joining a company, look at the business model, and do the “limit math”. Think about what things might look like if you become massively successful, because you might be.</p>



<hr>



<p><em>*This is an opinion piece. I had to draw a lot of simplifications to keep this article short. A lot of statements are definitely not universally true, but are true enough that they’re worth using as examples.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543510</guid>
            <pubDate>Mon, 21 Sep 2020 13:58:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Shows the Germans How to Move Quickly]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24543038">thread link</a>) | @Tomte
<br/>
September 21, 2020 | https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;4f34f3e1-6c6f-4065-9ec6-3301690ac70f&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;549e05c1-3a21-428c-b151-f4af37011e3d&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg" srcset="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w520_r1.77_fpx76_fpy24.jpg 520w, https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg 948w" width="948" height="536" sizes="948px" title="Tesla founder Elon Musk: &quot;A ton of fun!&quot;" alt="Tesla founder Elon Musk: &quot;A ton of fun!&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Tesla founder Elon Musk:</strong> "A ton of fun!"</p>
<span>
Foto: <p>Julian Stähle / dpa</p>
</span>
</figcaption>
</figure>
</div><div>
<p>A large property map hangs in the mayor's office, right next to a display cabinet full of memorabilia accumulated over a long term in office. The coat of arms of the town of Grünheide on the map has faded, as has the writing: "Net settlement area of 300 hectares," it reads, if you look hard enough.</p>


<div>
<p>Arne Christiani's predecessor hung up the poster 20 years ago, back when BMW wanted to build a car manufacturing plant on the site, but then chose the city of Leipzig instead. "When I was first elected mayor in 2003, I left the map up," says Christiani. The pine forest on the edge of the town has remained his field of dreams for almost 17 years.</p><p>During that time, Grünheide has grown steadily, but its population has also aged. It's a place that's beautiful for people who appreciate peace and quiet, but not one that’s particularly tempting for the younger generation. Each year, Christiani has apologized to locals on International Volunteer Day for the fact that it had once again not been possible to attract high-quality industrial jobs to the area.</p>
</div>

<div>
<p>For some time now, though, two new maps have been hanging above the old one, with the parcel of land colored red. Christiani's dream could finally be coming true, with Tesla hoping to build electric cars on the site.</p><h3><strong>Dreams Threatened, Dreams Come True</strong></h3><p>If you leave Town Hall and walk a good 800 meters through a pine forest to the edge of the village, you reach a lake called Peetzsee. Christiani had been in office for two years when Johannes Curth and his family came to fulfil their dream here, swapping a rental apartment in Berlin’s Prenzlauer Berg neighborhood for a home of their own, surrounded by forests and lakes.</p>
</div>

<p>The Curths bought a plot of land just a few meters from the shore of the lake back when prices were still reasonable. They built a house with large windows and surrounded by a good-sized yard, in which stand two magnificent old trees in it.</p>

<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;f04b3214-3e9f-45a6-8d53-631458487ee1&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>But now that Mayor Christiani's dream is coming true, Curth sees his own dream threatened. "We moved here because of the peace and quiet and the nature," he says. "What will happen if Tesla starts building cars here?" He fears for the quality of the water and air. And he worries about the extra traffic and what will happen to this sleepy community of 8,755 people when Tesla moves in.</p>

<div>
<p>Elon Musk, the entrepreneur behind the carmaker, is an uncompromising man whose ideas jump back and forth between California, Mars and Grünheide. The head of the world's largest electric car manufacturer builds rockets that ferry people into space and dreams of building a hyperloop tunnel for passenger transport. He is adored by his followers because, as an entrepreneur, he refuses to accept any limits.</p><h3><strong>Breathtaking Speed</strong></h3><p>Almost as a byproduct, Musk is now also changing not only the provincial state of Brandenburg, where he’s setting up his factory, but also Germany. The project just outside of Berlin is becoming symbolic for industrial policy in times of climate change. Whereas German companies tend to moan and dig in their heels when the government sets overly ambitious climate targets, as they did last week when the new European Union climate goals were announced, Tesla brings both together: sustainable manufacturing and speed. Breathtaking speed.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;7bfd7c90-7763-4bb3-ad45-ab17ec97c569&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;f3f27691-eb97-44b4-92f0-baa8cdd1eca1&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" width="718" height="479" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" title="Tesla Gigafactory in Grünheide: Are the Germans fast enough?" alt="Tesla Gigafactory in Grünheide: Are the Germans fast enough?">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Tesla Gigafactory in Grünheide:</strong> Are the Germans fast enough?</p>
<span>
Foto: Robert Grahn&nbsp;/ euroluftbild.de / ullstein bild
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>Musk's Gigafactory will be built in a region where most structures tend to be single-family homes, if there are any at all. In the first stage of development, 12,000 people will work around the clock in three shifts. Once the factory is complete, more than 40,000 people could produce a good 2 million Tesla vehicles here. "Please work at Tesla Giga Berlin! It's going to be a ton of fun," Musk recently tweeted in German.</p><p>For quite some time, German car executives and politicians tended to make fun of Musk, notorious as he was for his outrageous personality on Twitter. When he outlined his visions at a 2014 lunch with Peter Altmaier - who was chief of staff of Angela Merkel's Chancellery at the time but is now economics minister – and raved about the advantages of electric propulsion, saying it could be used in all means of transportation except for rockets flying into space, Altmaier still thought he sounded a bit unhinged. "At the time," says Altmaier, "nobody thought this technology would be so successful." At least the German competition didn't.</p><p>As recently as 2018, when the California-based company was having troubles with the serial production of its Model 3, Volkswagen considered becoming a strategic investor in Tesla to teach Musk how to do mass production. But reality has long since overtaken that idea: Tesla is now worth five times as much as Volkswagen on the stock exchange.</p><p>The days when the billionaire had to ask politicians for an appointment are over. When he came to Germany in early September to visit his construction site, the reception he received was that of a pop star. Fans shared the latest movement data of his private jet and puzzled where he might pop up next. Leading politicians cleared their calendars at short notice.</p><p>This week, the Musk party is set to continue, and his name will once again appear in newspapers around the world. He has slated this Tuesday as "Battery Day,” when he plans to announce the progress Tesla has made in battery technology in addition to identifying the site of at least one new battery plant. There are many indications, including interviews with Musk, that Grünheide may be chosen as the site. If it is, giant tree-felling machines would again show up to wait for authorization to clear another 60 hectares (nearly 150 acres) of forest.</p><p>It would send an unmistakable message. Because one day later, on Wednesday, hearings are set to begin in the nearby town of Erkner on the 406 complaints against the factory that have been filed by environmental associations and residents. Construction, though, has already been underway for months, with Tesla deciding to move ahead at its own risk with preliminary permits.</p><h3><strong>Faster and Better</strong></h3><p>A recent visit to the construction site in Grünheide provided a glimpse of the degree to which Tesla's mantra has been internalized at Tesla, a mantra by which speed counts most. Evan Horetsky, who heads the roughly 100-member Tesla team in Grünheide, showed a number of interested journalists around the construction site.</p><p>The slim man in his mid-30s with a shaved head and carefully trimmed beard is one of the troubleshooters on Musk's team. He helped out with the Tesla factory in California before going to Reno, Nevada, to lead the creation of the company's first Gigafactory. That had hardly been finished by the time construction in Shanghai began. He says that he and his people have gotten "faster and better" each time. Now, Horetsky is moving things along in Brandenburg.</p><p>Just last fall, the site was covered with tall pine trees. Now, though, they have been replaced by dozens of white concrete pillars protruding from the levelled ground. In the rear section, the shell of the paint shop has been erected. "We gained experience during the construction of the first buildings that we could directly apply in the further development of the design," the American says. "It enabled us to save a couple of days."</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;557ddc99-4b15-46b4-871e-c4391a0edffd&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;cb31e673-7b8c-4dd2-8059-5034e2f8727f&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg" srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" width="718" height="480" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" title="Mayor Arne Christiani: A field of dreams." alt="Mayor Arne Christiani: A field of dreams.">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Mayor Arne Christiani: </strong>A field of dreams.</p>
<span>
Foto: HC Plambeck / DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>The fact that final permission to build the factory has not yet been granted and that skeptical citizens must first be heard doesn't bother Horetsky. He says he takes their fears seriously. He notes that similarly complicated requirements had to be fulfilled when building the factory in Shanghai. "The difference to Germany is that here, the people who are directly affected can have their say," says Horetsky. "And who has more of a right to air their views than they do?"</p><p>It is, essentially, the concrete realization of what had been an abstract discussion. What price is society prepared to pay for the future? And are Germans capable of keeping up with the necessary pace?</p><p>The Gigafactory is set to be built in record time, with the first Y model electric SUVs slated for shipping as early as summer 2021. Plans call for 500,000 electric cars to be produced annually by the end of the first construction stage, a pace the <em>Wall Street Journal</em> has described as "breakneck."</p><p>And all this is taking place in Germany, a country where the length of approval procedures has almost doubled in the last 10 years. And in the state of Brandenburg, where construction of the Berlin-Brandenburg Airport (BER) has been marred by endless construction problems and is finally set to open its doors, fully nine years behind schedule.</p><h3><strong>Not Even Corona Has Slowed the Project</strong></h3><p>It sounded almost like a joke initially: An American high-tech car company with a volatile boss meets German environmental law, citizen participation and German bureaucracy. Now, though, it looks as though electric cars could start rolling off the assembly line in Grünheide even faster than they did in centrally steered China. And not even the coronavirus has thus far managed to slow down the project.</p><p>Somehow, the clichés didn't hold true. Tesla may be a tenacious, demanding company, but it also takes criticism seriously and tries to address it. In contrast to German companies, Musk uses every possibility that planning law avails him to accelerate construction, but he does so at his own risk. At the same time, the Brandenburg government has shown itself to be a skilful negotiator in the fight for the project. Since the contract was awarded, a task force of employees from the participating authorities has met weekly with Tesla representatives to discuss progress on the project.</p><p>Axel Vogel was one of the founding members of the Green Party in 1980. He worked in the party's …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543038</guid>
            <pubDate>Mon, 21 Sep 2020 13:23:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed in Minecraft, Built IRL]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24542830">thread link</a>) | @donohoe
<br/>
September 21, 2020 | https://restofworld.org/2020/rebuilding-gaza-with-minecraft/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/rebuilding-gaza-with-minecraft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most Sundays, Somia Hamdan visits her local park with her two friends, Amal and Laima. They sit on a picnic bench opposite one another and chat neurotically about Twitter and local gossip. Hamdan is there to socialize but also to supervise. “Since I created the space,” Hamdan said, “I like to take care of it.”</p>



<p>At 23, living in Gaza, Hamdan has been blighted by three brutal conflicts with Israel, decades of protests, a cycle of rocket fire between Israel and Gaza’s rulers, Hamas, and infighting between Palestinian factions. She faces one of the <a href="https://www.unrwa.org/where-we-work/gaza-strip">worst employment rates</a> in the world, <a href="https://www.unrwa.org/activity/education-gaza-strip">oversubscribed schools</a>, and a territory in which movement is tightly controlled and more than half the population <a href="https://www.theyworkforyou.com/wrans/?id=2020-01-23.7154.h&amp;p=11132">lives on less than $5.50 per day.</a> Live concerts and movie theaters are rare, imports and exports restricted, and <a href="https://www.un.org/unispal/humanitarian-situation-in-the-gaza-strip-fast-facts-ocha-factsheet/">children often used, and killed, for smuggling.</a></p>



<p>Though Hamdan and most of her peers have mobile phones — a lifeline for connecting with the outside world — power cuts are relentless: Az-Zawayda, her home in Deir al-Balah of some 25,000, often has barely <a href="https://www.hrw.org/news/2017/08/20/gaza-we-get-four-hours-electricity-day-if-were-lucky">four hours of electricity a day</a>. “There’s little to do here,” Hamdan said.</p>



<p>Before 2018, Hamdan had certainly never played a video game. That year, she learned to play Minecraft, the wildly popular computer game<strong> </strong>in which players make things out of blocks — but not purely for fun. In 2012, U.N.-Habitat, Microsoft, and Mojang, the company that made Minecraft, teamed up on <a href="https://www.blockbyblock.org/about">Block by Block</a>, a venture that aims to improve marginalized areas by actively engaging community members in public projects. According to the U.N., more than 17,000 people have participated in Block by Block initiatives in around 100 different countries — including three<strong> </strong>projects in Gaza — improving hundreds of thousands of lives in the process.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/2017-08-23_12.58.05-600x429.jpg 600w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Using Minecraft’s building blocks, community groups design a virtual public space, later made into concrete reality. From parks to beaches and even streets themselves, these spaces are a key indicator of the health and sustainability of cities.<strong> </strong>“If made safe, accessible, and welcoming, they can be drivers of civic cohesion, biodiversity, livelihood, and economic growth,” Christelle Lahoud, 30, a program management officer for U.N.-Habitat, told <em>Rest of World</em>. “If not, we tend to see more crime and pollution, reduced productivity, and general social disparities.”&nbsp;</p>



<p>Participants in the Gaza experiment were selected by the Aisha Association for Women and Child Protection, an independent organization and project partner working to achieve gender integration in Gaza. Promising candidates were motivated, interested, and hungry for change.&nbsp;</p>



<p>Hamdan was one of 42 others — young women, mostly — given the chance to imagine a virtually designed town center through the game.<strong> </strong>The project aimed to design and build a community garden for Az-Zawayda — a modest goal.</p>



<p>Fatma Zoqlam, 18, and her sister, Ghada, 17, also made the cut, much to the approval of their mother. “She was all, like, ‘You have to do it! It will improve your confidence! And communication!’” Fatma, wearing a floral hijab and bright-purple dress, told <em>Rest of World</em> over Skype. “Not that I needed persuading.”&nbsp;</p>



<p>But Ghada, a tad more shy, wasn’t quite as up for it. “It made me feel nervous, working in a team with strangers,” she said. The first day, the group visited the space, which was only sand, ruins, and unlit roads. “I stood there and thought, This isn’t going to work,” Fatma said.&nbsp;</p>



<p>The architects introduced the world of Minecraft. “Most of us had never played a video game before,” Hamdan said, “but it was surprisingly user-friendly.” They were split into groups of four. “We took turns figuring out the keys, playing around,” Ghada said. “Once I got going, I didn’t want to stop.”&nbsp;</p>



<p>On the second day, things got heated. Keen to impress teammates, the decision-making adults in the room, and their family and friends, things got competitive. “I wanted to have the optimal design. … Because then my work could be reflected in the actual space!” Fatma said. She leaned forward, “I wanted to be able to say to everyone I knew, I made that!”</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/1-41-600x429.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/1-41-1000x714.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/1-41-1600x1143.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/1-41-2800x2000.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/2-21-600x429.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/2-21-1000x714.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/2-21-1600x1143.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/2-21-2800x2000.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Az-Zawayda Community Garden officially opened on December 31, 2018. Photos courtesy of Project Team.</figcaption>
    </figure>


<p>“I wanted technical approval,” Ghada said. “My group was, er, leader-heavy, though. A boy took charge. He was like, ‘We need to do this, this, and this.’”</p>



<p>What the group concluded was that protective measures were a priority. “We discussed safety a lot,” Hamdan said. “Me and my friends feel scared to leave the house alone. The threat of sexual assault is too much.” (Around 51% of women in Gaza are victims of gender-based violence.) They needed lighting, fencing, security (including a guard), and a separate area for women and families. “The fence was my input,” Ghada said.&nbsp;</p>



<p>For Fatma, aesthetics mattered — plants, trees, a proud fountain. Her team also made a cafeteria and installed<strong> </strong>municipal Wi-Fi to keep residents connected, along with solar panels.&nbsp;</p>



<p>Three female Palestinian architects brought the park to fruition. One of them, Tasneem Omar, 29, described the process as “genuinely eye-opening.” Despite Minecraft’s limitations — the game allows players to use only blocks, no curved shapes — the women’s 3D efforts made her job far simpler.&nbsp;</p>



<p>As the workshop came to a close, Omar drew up a schematic<strong> </strong>for a park based on the team’s work and handed it over to a group of selected contractors. Save for the Wi-Fi — which was costly and might detract from the community experience of the park — they used almost everything in the team’s design.</p>



<p>On December 31, 2018, Az-Zawayda Community Garden opened. Representatives from civil society organizations in the Gaza Strip, local and international NGOs, local universities, and workshop participants attended the launch. “It was a great feeling,” said Hamdan. “I gave a speech, something I wouldn’t have had the confidence to do before.”&nbsp;</p>



<p>Since then, additional projects have begun in Kosovo, Nepal, Lebanon, and Guinea; initiatives in Mozambique, South Africa, Ethiopia, Vietnam, Bangladesh, and Kyrgyzstan are currently underway. The Block by Block Foundation is also supporting coronavirus relief projects in ten affected countries.&nbsp;</p>



<p>For participants, the work is transformative. “We saw our work on the ground,” Fatma said, her eyes wide. “Nothing like this had been done before,” she added. “The municipality had never put us — the public — in charge.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/rebuilding-gaza-with-minecraft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542830</guid>
            <pubDate>Mon, 21 Sep 2020 13:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aligning Span Annotations to Hugginface Tokenizers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541780">thread link</a>) | @talolard
<br/>
September 21, 2020 | https://www.lighttag.io/blog/sequence-labeling-with-transformers/example | <a href="https://web.archive.org/web/*/https://www.lighttag.io/blog/sequence-labeling-with-transformers/example">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p><em>This post <a href="https://github.com/LightTag/sequence-labeling-with-transformers">comes with a repo</a></em></p>
</blockquote>
<p>Our previous post on
<a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/">aligning span annotations to Hugginface's tokenizer outputs</a>
discussed the various tradeoffs one needs to consider, and concluded that a windowing strategy over the tokenized text
and labels is optimal for our use cases. </p>
<p>This post demonstrates an end to end implementation of token alignment and windowing. We'll start by implementing
utility classes that make programming a little easier, then implement the alignment functionality which aligns offset
annotations to the out of a tokenizer. Finnaly we'll implement a PyTorch Dataset that stores our aligned tokens and
labels as windows, a Collator to implement batching and a simple DataLoader to be used in training. </p>
<p>We'll show and end to end flow on the DDI Corpus, recognizing pharmacological entities with BERT.</p>
<h2>Utility Classes For Convenient APIs</h2>
<p>We'll start by defining some types and utility classes that will make our work more convenient</p>
<div data-language="python"><pre><code><span>from</span> typing_extensions <span>import</span> TypedDict
<span>from</span> typing <span>import</span> List<span>,</span>Any
IntList <span>=</span> List<span>[</span><span>int</span><span>]</span> 
IntListList <span>=</span> List<span>[</span>IntList<span>]</span> </code></pre></div>

<h2>The Alignment Algorithm</h2>
<h3>FastTokenizers Simplify Alignment</h3>
<p>Recent versions of Hugginface's tokenizers library include variants of Tokenizers that end with Fast and inherit
from <a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a><br>
such as <a href="https://huggingface.co/transformers/model_doc/bert.html#berttokenizerfast">BertTokenizerFast</a>
and <a href="https://huggingface.co/transformers/model_doc/gpt2.html#gpt2tokenizerfast">GPT2TokenizerFast</a>. </p>
<p>Per the tokenizer's documentation</p>
<blockquote>
<p>When the tokenizer is a “Fast” tokenizer (i.e., backed by HuggingFace tokenizers library), [the output] provides in addition several advanced alignment methods which can be used to map between the original string (character and words) and the token space (e.g., getting the index of the token comprising a given character or the span of characters corresponding to a given token).</p>
</blockquote>
<p>Notably, the output provides the methods
<a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.token_to_chars">token<em>to</em>chars</a>
and <a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.char_to_token">char<em>to</em>token</a>
which do exactly what their name implies, provide mappings between tokens and character offsets in the original text.
That's exactly what we need to align annotations in offset format with tokens.</p>
<h2>A warmup implementation</h2>
<p>Our final implementation will use the BIOUL scheme we mentioned before. But before we do that, let's try a simple
alignment to see what it feels like</p>
<div data-language="python"><pre><code>text <span>=</span> <span>"I am Tal Perry, founder of LightTag"</span>
annotations <span>=</span> <span>[</span>
    <span>dict</span><span>(</span>start<span>=</span><span>5</span><span>,</span>end<span>=</span><span>14</span><span>,</span>text<span>=</span><span>"Tal Perry"</span><span>,</span>label<span>=</span><span>"Person"</span><span>)</span><span>,</span>
    <span>dict</span><span>(</span>start<span>=</span><span>16</span><span>,</span>end<span>=</span><span>23</span><span>,</span>text<span>=</span><span>"founder"</span><span>,</span>label<span>=</span><span>"Title"</span><span>)</span><span>,</span>
    <span>dict</span><span>(</span>start<span>=</span><span>27</span><span>,</span>end<span>=</span><span>35</span><span>,</span>text<span>=</span><span>"LightTag"</span><span>,</span>label<span>=</span><span>"Org"</span><span>)</span><span>,</span>
    
              <span>]</span>
<span>for</span> anno <span>in</span> annotations<span>:</span>
    
    <span>print</span> <span>(</span>text<span>[</span>anno<span>[</span><span>'start'</span><span>]</span><span>:</span>anno<span>[</span><span>'end'</span><span>]</span><span>]</span><span>,</span>anno<span>[</span><span>'label'</span><span>]</span><span>)</span>
    </code></pre></div>
<div data-language="text"><pre><code>Tal Perry Person
founder Title
LightTag Org</code></pre></div>
<div data-language="python"><pre><code><span>from</span> transformers <span>import</span> BertTokenizerFast<span>,</span>  BatchEncoding
<span>from</span> tokenizers <span>import</span> Encoding
tokenizer <span>=</span> BertTokenizerFast<span>.</span>from_pretrained<span>(</span><span>'bert-base-cased'</span><span>)</span> 
tokenized_batch <span>:</span> BatchEncoding <span>=</span> tokenizer<span>(</span>text<span>)</span>
tokenized_text <span>:</span>Encoding  <span>=</span>tokenized_batch<span>[</span><span>0</span><span>]</span></code></pre></div>
<div data-language="python"><pre><code>tokens <span>=</span> tokenized_text<span>.</span>tokens
aligned_labels <span>=</span> <span>[</span><span>"O"</span><span>]</span><span>*</span><span>len</span><span>(</span>tokens<span>)</span> 
<span>for</span> anno <span>in</span> <span>(</span>annotations<span>)</span><span>:</span>
    <span>for</span> char_ix <span>in</span> <span>range</span><span>(</span>anno<span>[</span><span>'start'</span><span>]</span><span>,</span>anno<span>[</span><span>'end'</span><span>]</span><span>)</span><span>:</span>
        token_ix <span>=</span> tokenized_text<span>.</span>char_to_token<span>(</span>char_ix<span>)</span>
        <span>if</span> token_ix <span>is</span> <span>not</span> <span>None</span><span>:</span> 
            aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> anno<span>[</span><span>'label'</span><span>]</span>
<span>for</span> token<span>,</span>label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span>aligned_labels<span>)</span><span>:</span>
    <span>print</span> <span>(</span>token<span>,</span><span>"-"</span><span>,</span>label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
I - O
am - O
Ta - Person
##l - Person
Perry - Person
, - O
founder - Title
of - O
Light - Org
##T - Org
##ag - Org
[SEP] - O</code></pre></div>
<h3>Accounting For Multi Token Annotations</h3>
<p>In the above example, some of our annotations spanned multiple tokens.
For instance "Tal Perry" spanned "Ta", "##l" and "Perry". Clearly by themselves none of those tokens are a Person, and
so our current alignment scheme isn't as useful as it could be.
To overcome that, we'll use the previously mentioned BIOLU scheme, which will indicate if a token is the beginning,
inside, last token in an annotation or if it is not part of an annotation or if it is perfectly aligned with an annotation.</p>
<div data-language="python"><pre><code><span>def</span> <span>align_tokens_and_annotations_bilou</span><span>(</span>tokenized<span>:</span> Encoding<span>,</span> annotations<span>)</span><span>:</span>
    tokens <span>=</span> tokenized<span>.</span>tokens
    aligned_labels <span>=</span> <span>[</span><span>"O"</span><span>]</span> <span>*</span> <span>len</span><span>(</span>
        tokens
    <span>)</span>  
    <span>for</span> anno <span>in</span> annotations<span>:</span>
        annotation_token_ix_set <span>=</span> <span>(</span>
            <span>set</span><span>(</span><span>)</span>
        <span>)</span>  
        <span>for</span> char_ix <span>in</span> <span>range</span><span>(</span>anno<span>[</span><span>"start"</span><span>]</span><span>,</span> anno<span>[</span><span>"end"</span><span>]</span><span>)</span><span>:</span>

            token_ix <span>=</span> tokenized<span>.</span>char_to_token<span>(</span>char_ix<span>)</span>
            <span>if</span> token_ix <span>is</span> <span>not</span> <span>None</span><span>:</span>
                annotation_token_ix_set<span>.</span>add<span>(</span>token_ix<span>)</span>
        <span>if</span> <span>len</span><span>(</span>annotation_token_ix_set<span>)</span> <span>==</span> <span>1</span><span>:</span>
            
            token_ix <span>=</span> annotation_token_ix_set<span>.</span>pop<span>(</span><span>)</span>
            prefix <span>=</span> <span>(</span>
                <span>"U"</span>  
            <span>)</span>
            aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> <span><span>f"</span><span><span>{</span>prefix<span>}</span></span><span>-</span><span><span>{</span>anno<span>[</span><span>'label'</span><span>]</span><span>}</span></span><span>"</span></span>

        <span>else</span><span>:</span>

            last_token_in_anno_ix <span>=</span> <span>len</span><span>(</span>annotation_token_ix_set<span>)</span> <span>-</span> <span>1</span>
            <span>for</span> num<span>,</span> token_ix <span>in</span> <span>enumerate</span><span>(</span><span>sorted</span><span>(</span>annotation_token_ix_set<span>)</span><span>)</span><span>:</span>
                <span>if</span> num <span>==</span> <span>0</span><span>:</span>
                    prefix <span>=</span> <span>"B"</span>
                <span>elif</span> num <span>==</span> last_token_in_anno_ix<span>:</span>
                    prefix <span>=</span> <span>"L"</span>  
                <span>else</span><span>:</span>
                    prefix <span>=</span> <span>"I"</span>  
                aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> <span><span>f"</span><span><span>{</span>prefix<span>}</span></span><span>-</span><span><span>{</span>anno<span>[</span><span>'label'</span><span>]</span><span>}</span></span><span>"</span></span>
    <span>return</span> aligned_labels


labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> annotations<span>)</span>
<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span> labels<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
I - O
am - O
Ta - B-Person
##l - I-Person
Perry - L-Person
, - O
founder - U-Title
of - O
Light - B-Org
##T - I-Org
##ag - L-Org
[SEP] - O</code></pre></div>
<p>Notice how <strong>founder</strong> above has a <strong>U</strong> prefix and the other annotations now follow a BIL scheme.</p>
<h3>Mapping Labels To Ids</h3>
<p>It's great that we have our annotations aligned, but we need the labels as integer ids for training.
During inference, we'll also need a way to map predicted ids back to labels.
I'm going to make a custom class that handles that, called a LabelSet. </p>
<div data-language="python"><pre><code><span>import</span> itertools


<span>class</span> <span>LabelSet</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> labels<span>:</span> List<span>[</span><span>str</span><span>]</span><span>)</span><span>:</span>
        self<span>.</span>labels_to_id <span>=</span> <span>{</span><span>}</span>
        self<span>.</span>ids_to_label <span>=</span> <span>{</span><span>}</span>
        self<span>.</span>labels_to_id<span>[</span><span>"O"</span><span>]</span> <span>=</span> <span>0</span>
        self<span>.</span>ids_to_label<span>[</span><span>0</span><span>]</span> <span>=</span> <span>"O"</span>
        num <span>=</span> <span>0</span>  
        
        <span>for</span> _num<span>,</span> <span>(</span>label<span>,</span> s<span>)</span> <span>in</span> <span>enumerate</span><span>(</span>itertools<span>.</span>product<span>(</span>labels<span>,</span> <span>"BILU"</span><span>)</span><span>)</span><span>:</span>
            num <span>=</span> _num <span>+</span> <span>1</span>  
            l <span>=</span> <span><span>f"</span><span><span>{</span>s<span>}</span></span><span>-</span><span><span>{</span>label<span>}</span></span><span>"</span></span>
            self<span>.</span>labels_to_id<span>[</span>l<span>]</span> <span>=</span> num
            self<span>.</span>ids_to_label<span>[</span>num<span>]</span> <span>=</span> l
        

    <span>def</span> <span>get_aligned_label_ids_from_annotations</span><span>(</span>self<span>,</span> tokenized_text<span>,</span> annotations<span>)</span><span>:</span>
        raw_labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> annotations<span>)</span>    
        <span>return</span> <span>list</span><span>(</span><span>map</span><span>(</span>self<span>.</span>labels_to_id<span>.</span>get<span>,</span> raw_labels<span>)</span><span>)</span>


example_label_set <span>=</span> LabelSet<span>(</span>labels<span>=</span><span>[</span><span>"Person"</span><span>,</span> <span>"Org"</span><span>,</span> <span>"Title"</span><span>]</span><span>)</span>
aligned_label_ids <span>=</span> example_label_set<span>.</span>get_aligned_label_ids_from_annotations<span>(</span>
    tokenized_text<span>,</span> annotations
<span>)</span>

<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span> aligned_label_ids<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - 0
I - 0
am - 0
Ta - 1
##l - 2
Perry - 3
, - 0
founder - 12
of - 0
Light - 5
##T - 6
##ag - 7
[SEP] - 0</code></pre></div>

<p>Now that we have alignment logic in place, we need to figure out how to load, batch and pad the data. We also need
to handle the case where our text is longer than we can feed our model. Below we show an implementation of a
particular strategy, windowing over uniform length segments of the text. This isn't the only strategy, or even
necessarily the best, but it fits our use case well. You can read more about
why <a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/">we use windowing when training ner models with BERT here</a>.
Below we'll just show how to do that.</p>
<h2>The Raw Dataset</h2>
<p>We'll be using the <a href="https://www.sciencedirect.com/science/article/pii/S1532046413001123">DDI Corpus</a>. You can download
a JSON verion of it  <a href="https://github.com/LightTag/DDICorpus">here</a>.
Let's take a quick look at the data</p>
<div data-language="python"><pre><code><span>import</span> json
<span>from</span> pprint <span>import</span> pprint

raw <span>=</span> json<span>.</span>load<span>(</span><span>open</span><span>(</span><span>"./ddi_train.json"</span><span>)</span><span>)</span>
<span>for</span> example <span>in</span> raw<span>:</span>
    
    <span>for</span> anno <span>in</span> example<span>[</span><span>"annotations"</span><span>]</span><span>:</span>
        anno<span>[</span><span>"label"</span><span>]</span> <span>=</span> anno<span>[</span><span>"tag"</span><span>]</span>
pprint<span>(</span>raw<span>[</span><span>2</span><span>]</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>{'annotations': [{'end': 58, 'label': 'drug', 'start': 47, 'tag': 'drug'},
                 {'end': 75, 'label': 'drug', 'start': 62, 'tag': 'drug'},
                 {'end': 135, 'label': 'drug', 'start': 124, 'tag': 'drug'},
                 {'end': 164, 'label': 'drug', 'start': 152, 'tag': 'drug'}],
 'content': 'Pharmacokinetic studies have demonstrated that omeprazole and '
            'erythromycin significantly increased the systemic exposure of '
            'cilostazol and/or its major metabolites.',
 'metadata': {'original_id': 'DrugDDI.d452.s1'}}</code></pre></div>
<p>Lets take a look at that tokenized and aligned</p>
<div data-language="python"><pre><code>example <span>=</span> raw<span>[</span><span>2</span><span>]</span>
tokenized_batch <span>=</span> tokenizer<span>(</span>example<span>[</span><span>"content"</span><span>]</span><span>)</span>
tokenized_text <span>=</span> tokenized_batch<span>[</span><span>0</span><span>]</span>
labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> example<span>[</span><span>"annotations"</span><span>]</span><span>)</span>
<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokenized_text<span>.</span>tokens<span>,</span> labels<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
Ph - O
##arma - O
##co - O
##kin - O
##etic - O
studies - O
have - O
demonstrated - O
that - O
o - B-drug
##me - I-drug
##pra - I-drug
##zo - I-drug
##le - L-drug
and - O
er - B-drug
##yt - I-drug
##hr - I-drug
##omy - I-drug
##cin - L-drug
significantly - O
increased - O
the - O
systemic - O
exposure - O
of - O
c - B-drug
##ilo - I-drug
##sta - I-drug
##zo - I-drug
##l - L-drug
and - O
/ - O
or - O
its - O
major - O
meta - B-drug
##bol - I-drug
##ites - I-drug
. - L-drug
[SEP] - O</code></pre></div>
<h2>Padding and Windowing in a Dataset</h2>
<p>Our dataset is conveniently split into sentences. We still need to batch it and pad the examples.
More commonly, data is not split into sentences, and so we will window over fixed sized parts of it.
The windowing, padding and alignment logic will be done in a pytorch Dataset and we'll get to batching in a moment.</p>
<div data-language="python"><pre><code><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> torch<span>.</span>utils<span>.</span>data <span>import</span> Dataset
<span>from</span> transformers <span>import</span> PreTrainedTokenizerFast</code></pre></div>
<div data-language="python"><pre><code><span>@dataclass</span>
<span>class</span> <span>TrainingExample</span><span>:</span>
    input_ids<span>:</span> IntList
    attention_masks<span>:</span> IntList
    labels<span>:</span> IntList


<span>class</span> <span>TraingDataset</span><span>(</span>Dataset<span>)</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        self<span>,</span>
        data<span>:</span> Any<span>,</span>
        label_set<span>:</span> LabelSet<span>,</span>
        tokenizer<span>:</span> PreTrainedTokenizerFast<span>,</span>
        tokens_per_batch<span>=</span><span>32</span><span>,</span>
        window_stride<span>=</span><span>None</span><span>,</span>
    <span>)</span><span>:</span>
        self<span>.</span>label_set <span>=</span> label_set
        <span>if</span> window_stride <span>is</span> <span>None</span><span>:</span>
            self<span>.</span>window_stride <span>=</span> tokens_per_batch
        self<span>.</span>tokenizer <span>=</span> tokenizer
        <span>for</span> example <span>in</span> data<span>:</span>
            
            <span>for</span> a <span>in</span> example<span>[</span><span>"annotations"</span><span>]</span><span>:</span>
        …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/example">https://www.lighttag.io/blog/sequence-labeling-with-transformers/example</a></em></p>]]>
            </description>
            <link>https://www.lighttag.io/blog/sequence-labeling-with-transformers/example</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541780</guid>
            <pubDate>Mon, 21 Sep 2020 10:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to catch a spy that is using a numbers station – The KGB Experience]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24541163">thread link</a>) | @Shaddox
<br/>
September 21, 2020 | https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/ | <a href="https://web.archive.org/web/*/https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div id="attachment_166048"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166048" src="https://i2.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547.jpg?resize=183%2C300&amp;ssl=1" alt="" width="183" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=183%2C300&amp;ssl=1 183w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=624%2C1024&amp;ssl=1 624w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=768%2C1261&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=935%2C1536&amp;ssl=1 935w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=1247%2C2048&amp;ssl=1 1247w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1559&amp;ssl=1 1559w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1500&amp;ssl=1 1500w" sizes="(max-width: 183px) 100vw, 183px" data-recalc-dims="1"></a></p><p id="caption-attachment-166048">Cover of the KGB manual. Mobile screen grab from Latvian national archive</p></div>


<p>From 2019 onwards the Latvian National Archive offers access to various KGB documents. The author had already previously shown the very detailed efforts of the Latvian KGB counterintelligence to monitor and study the CIA and BND numbers stations broadcasts, or what they called – “one directional communications”.<a href="#_ftn1" name="_ftnref1"><sup>[1]</sup></a> These are one of the most definitive archival sources which prove that foreign intelligence actively used shortwave in the USSR and that the KGB was aware of it. The documents showed that the KGB had monitored these broadcasts from at least 1978, but the files spoke very vaguely if the monitoring effort led to any apprehension and capture of a foreign agent. We, however, know that there were such cases like Alexander Ogorodnik<a href="#_ftn2" name="_ftnref2"><sup>[2]</sup></a>, and others where the use of shortwave signals was determined.</p>
<p>The Latvian National Archive digitized operational cases and also special KGB training manuals. These manuals were published for inner agency use and were never issued in public because they contained secret information. One such manual called “<em>Некоторые вопросы организаций работы по сигналам и делам оперативного учета лиц причастий в шпионажу”</em> published in 1985 by KGB of F. E Dzherzhinsky in Moscow.<a href="#_ftn3" name="_ftnref3"><sup>[3]</sup></a> (A few issues on organizing work on signals and cases recognizing persons taking part in espionage”). The manual was credited to major general A. A Fabrichinikov and colonel V.V Holopov The word “signal” in the title does not mean just a radio signal. In the KGB terminology “signal” meant a sign or report of a foreign intelligence or anti Soviet activity. If this “signal” indicated that the person is taking part in espionage he had to be investigated and evidence to be collected. The manual showed various historical cases as examples on how to apprehend and capture a foreign agent.</p>



<p>One such case was called” Case on Filatov”. Starting from page 41 the manual examples this case as one of the cases where radio communication was used between the agency and agent and how it was uncovered by counter intelligence. <strong>Anatoly N. Filatov</strong> was according to a 1981 Washington Post report sentenced in 1978 to be shot by a firing squad, though the sentence was commuted later to 15 years in prison.<a href="#_ftn4" name="_ftnref4"><sup>[4]</sup></a> A New York Times article in 1980 had rumored that A. Filatov was the same “Trigon” who is now commonly known as Alexandr Ogorodnik. The article states that A. Filatov was suspected of being discovered by the KGB counterintelligence and forced to send the CIA false information. The reasoning behind this hypothesis was that in 1977 “Trigon” went dark at the same time as A. Filatov sent a very questionable cable about Secretary of State Henry Kissinger, where he questioned the “bargaining position of president Carter” during the 1977 missile control talks.<a href="#_ftn5" name="_ftnref5"><sup>[5]</sup></a> Alexander Ogorodnik aka “Trigon” died on June 22 1977 after swallowing cyanide pills during a KGB break in.<a href="#_ftn6" name="_ftnref6"><sup>[6]</sup></a></p>
<p>David E. Hoffman, author of the book “The Million Dollar Spy” states that Filatov was arrested during a “car toss”, where a package is quickly swapped between two passing cars.<a href="#_ftn7" name="_ftnref7"><sup>[7]</sup></a> Russian author Aleksandr Kolpakidi in his book “The GRU Empire” writes that Filatov was born in 1940 in the Saratov district, joined the GRU in 1973. (GRU – the Main Intelligence Directorate – Soviet military intelligence agency) and served in Algiers where in 1974 he established contact with the CIA. Filatov had stated that his involvement with the adversary CIA happened as a result of being lured into a honey trap with a woman called Nadia, as similar happened to&nbsp; A. Ogorodnik. Either so or A. Filatov himself decided to become a double agent and started meeting CIA agent Edward Kane. In 1976 A. Filatov was called back to Moscow and the CIA had instructed him to receive shortwave coded broadcasts in German numbers from Frankfurt near Main, the broadcasts were to be carried out twice a week. Operative broadcast would be started with uneven numbers and training with even numbers. The broadcasts on precaution were carried out before A. Filatov returned to Moscow. The return message was to be carried out in a dead drop in an area near Dinamo sports stadium.</p>
<p>As the author states the coded messages contained such instructions: “Do not contain yourself with gathering information within your service only. Gain trust of friends and relatives. Visit them at their workplaces, their homes, invite them to restaurants, and with careful, clever talking gain information you could not get yourself”<a href="#_ftn8" name="_ftnref8"><sup>[8]</sup></a>. The instructions also stated that the agency is not just interested in documents with “Top Secret” on it but also common information about his department and situation in it. Filatov was arrested on the 2nd of September 1977. As A. Kolpakidi states he was first sentenced to death in 1978 but instead was sent to labor camp 389/35 near Perm. In 1989 Filatov was visited by French journalists to whom he stated that he took very high stakes risks in his life which he lost and now naturally pays for it.</p>
<p>After release he demanded compensation from the US embassy, but was denied as a non citizen. The Russian TV company TV Center in 2014 made the documentary series “Завербуй меня, если сможешь” (Contract me if you can) and featured the A. Filatov case showing various pictures of him and accounts from his colleagues, such as Anatoly Tereshchenko, colonel of the military counter intel. Tereshchenko stated that if A. Filatov had come to the GRU and reported that he was lured into cooperation with the CIA, they could outplay the CIA, and Filatov would be a hero.<a href="#_ftn9" name="_ftnref9"><sup>[9]</sup></a> What became of Filatov after his release, is not known, the TV documentary showed his picture after his release. Possibly A. Filatov is dead now.</p>
<div id="attachment_166050"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?ssl=1"><img aria-describedby="caption-attachment-166050" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1" alt="" width="300" height="177" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=768%2C453&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?w=873&amp;ssl=1 873w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166050">Anatoly Filatov</p></div>
<div id="attachment_166051"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?ssl=1"><img aria-describedby="caption-attachment-166051" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1" alt="" width="300" height="173" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=768%2C442&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?w=871&amp;ssl=1 871w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166051">Anatoly Filatov years after the arrest</p></div>
<p>What will follow is a translation from Russian to English from the mentioned KGB manual, where the case about Filatov is described as an example of apprehending and capturing foreign spies who use radio signals and codes. With photo scans of included photo evidence.</p>

<p><em>Start of the original translation</em></p>
<div id="attachment_166052"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166052" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640.jpg?resize=225%2C300&amp;ssl=1" alt="" width="225" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1"></a></p><p id="caption-attachment-166052">First page in the manual about A.FIlatov case</p></div>
<p>The case regarding American agent Filatov is particularly useful for agency and operative workers. Two agents who worked on this case had limited, but clear objectives: one controlled his work shifts, the other one lured him to a position within a GRU object (facility), where he was arrested. Secondary events were mostly carried out by the workers of the operational staff.</p>
<p>In the case materials the use of operational technical and criminal resources is very clearly displayed. The workers of the operational services had a clear objective: gain information about practical espionage activity.</p>
<p>A lot of support for apprehending the spy was provided by the GRU radio counterintelligence. During the first phase of the operation the counter radio intelligence played a helpful, but mostly backseat role, in terms of gaining radio information. However, after Filatov was discovered in possession of multiple ciphers the RCI<a href="#_ftn11" name="_ftnref11"><sup>[11]</sup></a> played the most active role in gaining information about the adversary’s plans for their agent. It must be asserted that the RCI data about the new communication line only gained importance after comprehensive analysis about known agents and data gained from agency postal communication lines.</p>
<p>It is useful to take note of the surveillance tactics used to monitor&nbsp; FIlatov, during all phases of the operation. Here the artistic use of surveillance, determination of the personality of the object, working out on his work conditions and living place (such an approach is essential for any future attempts for apprehending an adversary agent).</p>
<p>Finally it’s important to point out the very high level of secrecy is required to successfully&nbsp; carry out the operation, with minimal numbers&nbsp; of agents and operative staff workers as reglamented by the authority of KGB, and adjusted fully to the set parameters.</p>
<p>All this taken to an account assured that the case was carried out in highest quality the tasks were carried out decisively.</p>
<p>“””</p>
<p>The investigation into the incoming signals, and the timeline for the search for the CIA agent Filatov took place in the following order.</p>
<p>At the start of 1977 the second chief directorate of the KGB had received data that led to the belief that a new agent from American intelligence had become active within Soviet Union.</p>
<p>On January 21 and February 6 1977 the RCI had detected the transmission of operational (combat)<a href="#_ftn12" name="_ftnref12"><sup>[12]</sup></a> radiograms on the communication line sent from Frankfurt CIA radio center, that had appeared already in the first half of 1976.<a href="#_ftn13" name="_ftnref13"><sup>[13]</sup></a> With that the general reception of the radiograms was possible within the central part of European side of the USSR. <a href="#_ftn14" name="_ftnref14"><sup>[14]</sup></a></p>
<p>In this same timeframe espionage activity within CIA station inside the US embassy in Moscow, was observed to have increased, showing signs of preparing for creating operational dead drop communications, it was determined that these activities could not be part of the ongoing cases and operational games.</p>
<p>It was expected that the agent, after receiving operational radiograms, will likely make contact with the Frankfurt radio center using postal telegraph, telephone, dead drop, radio transmission or make a meeting with his handler, usually from US diplomatic service.</p>
<p>Taking this into account together with Operative-technical and Seventh authority of the KGB, extra measures were made to control the agency channels within Moscow and eavesdrop on CIA actions.</p>
<p>On February 9 1977 a postal parcel coming from Moscow to the US, a suspicious letter was identified which had signs which made its purpose likely being for espionage uses. This letter had a date indicating it was sent on February 7 and was written in the in English language “from English tourist”<a href="#_ftn15" name="_ftnref15"><sup>[15]</sup></a>. By using a physical-chemical method on the blank side of the letter, a cipher of 353 five number …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</a></em></p>]]>
            </description>
            <link>https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541163</guid>
            <pubDate>Mon, 21 Sep 2020 08:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook fears ruling may force it to pull social media platforms from EU]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 106 (<a href="https://news.ycombinator.com/item?id=24540991">thread link</a>) | @rusk
<br/>
September 21, 2020 | https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4 | <a href="https://web.archive.org/web/*/https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app">

        





<div>
    <div>
        <p>
            Wednesday September 23, 2020
        </p>
        
    </div>
</div>





        

        
    <div>
        
        
        <div>

            
            
                            <div>
                    
            
                            <p>Court filings show tech giant doesn’t believe it can convince Data Protection Commission to overturn preliminary ruling that bans transfer of data from EU to US</p>
                    
        
        

        
        
    </div>
            
                            
                <div id="img-article">
                    <figure>
                        
                        <figcaption>Under fire: Data Protection Commissioner Helen Dixon</figcaption>
                    </figure>
                </div>
                    </div>

        
        <div>
            <div>
                
                                    <div>
                                                    <div>
                                
                                <p>Facebook fears that a ruling by the Data Protection Commission (DPC) could force it to pull its social media platforms from Europe, High Court filings show.</p> <p>The social media giant said it does not believe it can convince the watchdog to overturn a preliminary ruling banning the transfer of personal data from EU citizens to servers in the US which relates to concerns about American intelligence agencies.</p> <p>In the filings which detail the gravity of...</p>
                            </div>
                        
                        
                                                    <div>
                                <div>
    <div>
        <h2>Subscribe from just €1 for the first month!</h2>
        <p>Exclusive offers:</p>
        <p>All Digital Access + eReader</p>
    </div>

            
        <div>
            <div>

                
                <div>
                    <h2>Trial</h2>
                                        <p>
                        €1
                                            </p>
                    <p>Unlimited Access for 1 Month</p>
                                            <p>Then €19.99 a month after the offer period.</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                
                <div>
                    <h2>Annual</h2>
                                            <p>€200</p>
                                        <p>
                        €149
                                                    <span>For the 1st Year</span>
                                            </p>
                    <p>Unlimited Access for 1 Year</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                
                <div>
                    <h2>Quarterly</h2>
                                            <p>€55</p>
                                        <p>
                        €42
                                            </p>
                    <p>90 Day Pass</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                                    
                    <svg version="1.1" fill="#FFF" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 49.94 49.94" xml:space="preserve">
                        <path d="M48.856,22.73c0.983-0.958,1.33-2.364,0.906-3.671c-0.425-1.307-1.532-2.24-2.892-2.438l-12.092-1.757
                            c-0.515-0.075-0.96-0.398-1.19-0.865L28.182,3.043c-0.607-1.231-1.839-1.996-3.212-1.996c-1.372,0-2.604,0.765-3.211,1.996
                            L16.352,14c-0.23,0.467-0.676,0.79-1.191,0.865L3.069,16.622c-1.359,0.197-2.467,1.131-2.892,2.438
                            c-0.424,1.307-0.077,2.713,0.906,3.671l8.749,8.528c0.373,0.364,0.544,0.888,0.456,1.4L8.224,44.701
                            c-0.183,1.06,0.095,2.091,0.781,2.904c1.066,1.267,2.927,1.653,4.415,0.871l10.814-5.686c0.452-0.237,1.021-0.235,1.472,0
                            l10.815,5.686c0.526,0.277,1.087,0.417,1.666,0.417c1.057,0,2.059-0.47,2.748-1.288c0.687-0.813,0.964-1.846,0.781-2.904
                            l-2.065-12.042c-0.088-0.513,0.083-1.036,0.456-1.4L48.856,22.73z"></path>
                    </svg>
                
                <div>
                    <h2>2 Yearly</h2>
                                            <p>€315</p>
                                        <p>
                        €248
                                            </p>
                    <p>Unlimited Access for 2 Years</p>
                                    </div>
                

                <div>
                    <svg version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="442.533px" height="442.533px" viewBox="0 0 442.533 442.533" style="enable-background:new 0 0 442.533 442.533;" xml:space="preserve">
                        <path d="M434.539,98.499l-38.828-38.828c-5.324-5.328-11.799-7.993-19.41-7.993c-7.618,0-14.093,2.665-19.417,7.993L169.59,247.248
                            l-83.939-84.225c-5.33-5.33-11.801-7.992-19.412-7.992c-7.616,0-14.087,2.662-19.417,7.992L7.994,201.852
                            C2.664,207.181,0,213.654,0,221.269c0,7.609,2.664,14.088,7.994,19.416l103.351,103.349l38.831,38.828
                            c5.327,5.332,11.8,7.994,19.414,7.994c7.611,0,14.084-2.669,19.414-7.994l38.83-38.828L434.539,137.33
                            c5.325-5.33,7.994-11.802,7.994-19.417C442.537,110.302,439.864,103.829,434.539,98.499z"></path>
                    </svg><p>
                    This product does not auto-renew
                </p></div>
            </div>
        </div>
    
    
    <div>
        <div>
            <h2>Team Pass</h2>
            <p>Get a Business Account for you and your team</p>
        </div>
        
    </div>
    
    
</div>

                            </div>
                                            </div>
                            </div>
        </div>

        

        
                    
            </div>

        

    </div></div>]]>
            </description>
            <link>https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540991</guid>
            <pubDate>Mon, 21 Sep 2020 08:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need young programmers; We need old programmers]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 244 (<a href="https://news.ycombinator.com/item?id=24540919">thread link</a>) | @mrcsharp
<br/>
September 21, 2020 | https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The software industry loves young people, but old-timers serve an important purpose, too.</em>
	</p>
	<p>
		Our culture idolises youth. There's several reasons for this, I believe. Youth seems synonymous with vigour, strength, beauty, and many other desirable qualities. The cynical perspective is that young people, while rebellious, also tend to be easy to manipulate, if you know which buttons to push. A middle-aged man like me isn't susceptible to the argument that I should buy a particular pair of Nike shoes because they're named after Michael Jordan, but for a while, one pair wasn't enough for my teenage daughter.
	</p>
	<p>
		In intellectual pursuits (like software development), youth is often extolled as the source of innovation. You're often confronted with examples like that of <a href="https://en.wikipedia.org/wiki/%C3%89variste_Galois">Évariste Galois</a>, who made all his discoveries before turning 21. <a href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada Lovelace</a> was around 28 years when she produced what is considered the 'first computer program'. <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a> was 24 when he wrote <a href="https://en.wikipedia.org/wiki/Turing%27s_proof">On Computable Numbers, with an Application to the Entscheidungsproblem</a>.
	</p>
	<p>
		Clearly, young age is no detriment to making ground-breaking contributions. It has even become folklore that everyone past the age of 35 is a has-been whose only chance at academic influence is to write a textbook.
	</p>
	<h3 id="800321a74c054ea0b75815c86f4ce18d">
		The story of the five monkeys <a href="#800321a74c054ea0b75815c86f4ce18d" title="permalink">#</a>
	</h3>
	<p>
		You may have seen a story called <em>the five monkeys experiment</em>. It's most likely a fabrication, but it goes like this:
	</p>
	<p>
		A group of scientists placed five monkeys in a cage, and in the middle, a ladder with bananas on the top. Every time a monkey went up the ladder, the scientists soaked the rest of the monkeys with cold water. After a while, every time a monkey went up the ladder, the others would beat it up.
	</p>
	<p>
		After some time, none of the monkeys dared go up the ladder regardless of the temptation. The scientists then substituted one of the monkeys with a new one, who'd immediately  go for the bananas, only to be beaten up by the others. After several beatings, the new member learned not to climb the ladder even though it never knew why.
	</p>
	<p>
		A second monkey was substituted and the same occurred. The first monkey participated in beating the second. A third monkey was exchanged and the story repeated. The fourth was substituted and the beating was repeated. Finally the fifth monkey was replaced.
	</p>
	<p>
		Left was a group of five monkeys who, even though they never received a cold shower, continued to beat up any monkey who attempted to climb the ladder. If it was possible to ask the monkeys why they would beat up all who attempted to go up the ladder, the answer would probably be:
	</p>
	<p>
		"That's how we do things here."
	</p>
	<p>
		While the story is probably just that: a story, it tells us something about the drag induced by age and experience. If you've been in the business for decades, you've seen numerous failed attempts at something you yourself tried when you were young. You know that it can't be done.
	</p>
	<p>
		Young people don't know that a thing can't be done. If they can avoid the monkey-beating, they'll attempt the impossible.
	</p>
	<h3 id="4add8a9af0424d7e889d3125837ed611">
		Changing circumstances <a href="#4add8a9af0424d7e889d3125837ed611" title="permalink">#</a>
	</h3>
	<p>
		Is attempting the impossible a good idea?
	</p>
	<p>
		In general, no, because it's... impossible. There's a reason older people tell young people that a thing can't be done. It's not just because they're stodgy conservatives who abhor change. It's because they see the effort as wasteful. Perhaps they're even trying to be kind, guiding young people off a path where only toil and disappointment is to be found.
	</p>
	<p>
		What old people don't realise is that sometimes, circumstances change.
	</p>
	<p>
		What was impossible twenty years ago may not be impossible today. We see this happening in many fields. Producing a commercially viable electric car was impossible for decades, until, with the advances made in battery technology, it became possible.
	</p>
	<p>
		Technology changes rapidly in software development. People trying something previously impossible may find that it's possible today. Once, if you had lots of data, you had to store it in fully normalised form, because storage was expensive. For a decade, relational databases were the only game in town. Then circumstances changed. Storage became cheaper, and a new movement of NoSQL storage emerged. What was before impossible became possible.
	</p>
	<p>
		Older people often don't see the new opportunities, because they 'know' that some things are impossible. Young people push the envelope driven by a combination of zest and ignorance. Most fail, but a few succeed.
	</p>
	<h3 id="4272a069588e47f796646bd282b9de02">
		Lottery of the impossible <a href="#4272a069588e47f796646bd282b9de02" title="permalink">#</a>
	</h3>
	<p>
		I think of this process as a lottery. Imagine that every impossible thing is a red ball in an urn. Every young person who tries the impossible draws a random ball from the urn.
	</p>
	<p>
		The urn contains millions of red balls, but every now and then, one of them turns green. You don't know which one, but if you draw it, it represents something that was previously impossible which has now become possible.
	</p>
	<p>
		This process produces growth, because once discovered, the new and better way of doing things can improve society in general. Occasionally, the young discoverer may even gain some fame and fortune.
	</p>
	<p>
		It seems wasteful, though. Most people who attempt the impossible will reach the predictable conclusion. What was deemed impossible was, indeed, impossible.
	</p>
	<p>
		When I'm in a cynical mood, I don't think that it's youth in itself that is the source of progress. It's just the <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">law of large numbers</a> applied. If there's a one in million chance that something will succeed, but ten million people attempt it, it's only a matter of time before one succeeds.
	</p>
	<p>
		Society at large can benefit from the success of the few, but ten million people still wasted their efforts.
	</p>
	<h3 id="016744f0ea77495c958a7914f08187db">
		We need the old, too <a href="#016744f0ea77495c958a7914f08187db" title="permalink">#</a>
	</h3>
	<p>
		If you accept the argument that young people are more likely to try the impossible, we need the young people. Do we need the old people?
	</p>
	<p>
		I'm turning fifty in 2020. You may consider that old, but I expect to work for many more years. I don't know if the software industry needs fifty-year-olds, but that's not the kind of old I have in mind. I'm thinking of people who have retired, or are close to retirement.
	</p>
	<p>
		In our youth-glorifying culture, we tend to dismiss the opinion and experiences of old people. <em>Oh, well, it's just a codgy old man</em> (or woman), we'll say.
	</p>
	<p>
		We ignore the experience of the old, because we believe that they haven't been keeping up with times. Their experiences don't apply to us, because we live under new circumstance. Well, see above.
	</p>
	<p>
		I'm not advocating that we turn into a gerontocracy that venerates our elders solely because of their age. Again, according to the law of large numbers, some people live to old age. There need not be any correlation between survivors and wisdom.
	</p>
	<p>
		We need the old to tell us the truth, because they have little to lose.
	</p>
	<h3 id="8b5c613ba6c44bb4b4e6dbba7ae7d19a">
		Nothing to lose <a href="#8b5c613ba6c44bb4b4e6dbba7ae7d19a" title="permalink">#</a>
	</h3>
	<p>
		In the last couple of years, I've noticed a trend. A book comes out, exposing the sad state of affairs in some organisation. This has happened regularly in Denmark, where I live. One book may expose the deplorable conditions of the Danish tax authorities, one may describe the situation in the ministry of defence, one criticises the groupthink associated with the climate crisis, and so on.
	</p>
	<p>
		Invariably, it turns out that the book is written by a professor emeritus or a retired department head.
	</p>
	<p>
		I don't think that these people, all of a sudden, had an epiphany after they retired. They knew all about the rot in the system they were part of, while they were part of it, but they've had too much to lose. You could argue that they should have said something before they retired, but that requires a moral backbone we can't expect most people to have.
	</p>
	<p>
		When people retire, the threat of getting fired disappears. Old people can speak freely to a degree most other people can't.
	</p>
	<p>
		Granted, many may simply use that freedom to spew bile or shout <em>Get off my lawn!</em>, but many are in the unique position to reveal truths no-one else dare speak. Many are, perhaps, just bitter, but some may possess knowledge that they are in a unique position to reveal.
	</p>
	<p>
		When that grumpy old guy on Twitter writes something that makes you uncomfortable, consider this: he may still be right.
	</p>
	<h3 id="2d64bd2c7ccb4b7ca2418802ed82689e">
		Being unreasonable <a href="#2d64bd2c7ccb4b7ca2418802ed82689e" title="permalink">#</a>
	</h3>
	<p>
		In a way, you could say that we need young and old people for the same fundamental reason. Not all of them, but enough of them, are in a position to be unreasonable.
		</p><blockquote>
			<p>
				"The reasonable man adapts himself to the world: the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man."
			</p>
			
		</blockquote><p>
		Young people and old people are unreasonable in each their own way, and we need both.
	</p>
	<h3 id="df88f595ec814e2bafcbd018ff5f5ad2">
		Conclusion <a href="#df88f595ec814e2bafcbd018ff5f5ad2" title="permalink">#</a>
	</h3>
	<p>
		We need young people in the software development industry. Because of their vigour and inexperience, they'll push the envelope. Most will fail to do the impossible, but a few succeed.
	</p>
	<p>
		This may seem like a cynical view, but we've all been young, and most of us have been through such a phase. It's like a rite of passage, and even if you fail to make your mark on the world, you're still likely to have learned a lot.
	</p>
	<p>
		We need old people because they're in a position to speak truth to the world. Notice that I didn't make my argument about the <em>experience</em> of old-timers. Actually, I find that valuable as well, but that's the ordinary argument: <em>Listen to old people, because they have experience and wisdom.</em>
	</p>
	<p>
		Some of them do, at least.
	</p>
	<p>
		I didn't make much out of that argument, because you already know it. There'd be no reason to write this essay if that was all I had to say. Old people have less on the line, so they can speak more freely. If someone you used to admire retires and all of a sudden starts saying or writing unpleasant and surprising things, there might be a good explanation, and it might be a good idea to pay attention.
	</p>
	<p>
		Or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</a></em></p>]]>
            </description>
            <link>https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540919</guid>
            <pubDate>Mon, 21 Sep 2020 08:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Teams as a Platform]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24540799">thread link</a>) | @homarp
<br/>
September 21, 2020 | https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/ | <a href="https://web.archive.org/web/*/https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Microsoft Teams as a platform" itemref="hero-page-title"><div>
<p>2020 became the year of #WFH (work from home) and for many organizations also the turning point when Microsoft Teams became the primary place where being “at work” happens. This is accelerating the evolution of Teams from being merely a communication tool that connects human beings into a foundational service layer for many types of business applications.</p>



<p>How the concept of Teams as a platform contrasts with Microsoft’s Power Platform suite of technology is something I’ve been thinking about a lot lately. In this post I’ll first reflect on the relatively short history of where Teams came from. I’ll then examine how the recent feature announcements are brining apps front &amp; center in Teams. Finally, a few words on the possible future for Teams as part of Microsoft’s broader strategy.</p>



<h2>The road that lead to Teams</h2>



<p>Looking back ~10 years, the real-time communication &amp; instant messaging tools from MS seemed to be going through an endless renaming cycle: from OCS to Lync to Skype for Business. The core feature set presented to the end user didn’t seem to evolve nearly as much as product branding did. On a broader level, the communication activities of information workers within an organization still typically took place within Outlook’s inbox, and different servers like SharePoint and Dynamics CRM all packed their own features for posting short messages to other users.</p>



<figure></figure>



<p>4 years ago, when the first images of what was then called “Skype Teams” started to leak out, we were already waiting for MS to create something a bit more ambitious than just another online meeting tool. Office Groups had began to emerge in various different places inside the MS Cloud, but they were primarily a technical construct with no sensible UX for everyday people to approach them. Even Dynamics CRM had it’s own solution that attempted to bring together the dicussion, calendars, notes, documents and team memberships from under an Office 365 Group associated with a record like account or opportunity:</p>



<div><figure><a href="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/collaborate-with-colleagues-using-office-365-groups" target="_blank" rel="noopener noreferrer"><img src="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/media/office-groups-dashboard.png" alt=""></a></figure></div>



<p>I remember having many discussions with our CRM customers where I attempted to steer people away from deploying this Groups solution. Instead I wanted to encourage them to wait for something a bit more polished that I knew had to be on it’s way sooner or later.</p>



<p>At one point there was a clear &amp; present danger of another “Yammer moment” taking place, as Microsoft was reportedly quite serious about their plans to acquire Slack. In retrospect it was a blessing for both parties that MS decided to keep investing in building their own product, instead of trying to retrofit an established service like Slack into their existing software offering.</p>



<p>I would argue that this “build over buy” strategy which Microsoft has since then followed across their business software stack has been a key success factor for BizApps in particular.  It has enabled MS to move from merely chasing CRM competitors like Salesforce into redefining the business apps playing field with Power Platform. There’s a stark difference between acquiring companies and bundling them as “X Cloud” versus engineering your own software stack to act as a true platform.</p>



<h2>Teams: the collaboration chapter</h2>



<p>Initially the first version of the Microsoft Teams product that became generally available in Spring 2017 was pretty much focused on being three things: </p>



<ol><li>Replacement for Skype for Business</li><li>Alternative to Slack</li><li>UI layer for Office 365 Groups</li></ol>



<p>From a business applications perspective there wasn’t all that much you could do to hook Teams up with Dynamics 365, until Fall 2018 when the previews for the first integrated features were launched. In particular the integrated file sharing experience that Teams offered seemed almost like the Holy Grail for many CRM professionals, offering to fix the glaring hole in the SharePoint integration story that lacked any security model synchronization. The roadmap image below presents the plans from 2 years ago on how Teams and Dynamics 365 were going to be integrated:</p>



<figure></figure>







<p>The last item on the roadmap has still not been delivered, which is the visibility of Teams conversations inside the Dynamics 365 record form. Why this hasn’t been a higher priority for MS to implement seems to me like a sign of how Microsoft Teams is nowadays positioned as the primary UI for all information work. MS probably would prefer if everything always started from inside Teams. You pin record tabs into channels, you show previews of records inside teams discussions, you interact with records via bot interfaces and so on. As long as Teams is that big umbrella under which all work takes place.</p>



<p>The lack of a deep 2-way integration does not therefore mean that investments aren’t being made into the products involved. It can simply be a reflection of the new vision that is being built, by aligning many existing services to form a whole that aims to be greater than the sum of its parts.</p>



<p>As an example, if you look at Microsoft’s task management story, you’ll see that features and data from across various apps like To Do, Planner and Outlook tasks / flagged emails are currently being collapsed into a central location that is the <a href="https://docs.microsoft.com/en-us/microsoftteams/manage-tasks-app" target="_blank" rel="noreferrer noopener">Tasks app for Teams</a>. Tasks as a generic construct don’t necessarily need to be fully controlled by a single database, yet they very much need to be logically represented within “the hub for teamwork” that Teams is positioned as.</p>



<p>Going forward, when new apps appear into the MS cloud product portfolio and they need to offer task management features to users, the logical integration point to focus on would be Teams. For activity feed type of functionality the choice is even more clear for product development: choose to piggyback on Teams instead of inventing yet another stream of short messages.</p>



<h2>Teams: the platform chapter</h2>



<p>Moving beyond simply integrating Teams with products X, Y and Z, we’re now seeing the rise of a model where apps are built specifically to be used in Teams. This has of course been possible for a long time already, by developing custom web services and using the SDKs. Now there are many features coming up that will amplify the platform story around Teams on the no-code/low-code front specifically.</p>



<figure><img src="https://techcommunity.microsoft.com/t5/image/serverpage/image-id/215495iAC8095B3BF8D5E46/image-size/large?v=1.0&amp;px=999" alt="lists in teams1.png"></figure>



<p>Microsoft Lists app has been the  first to <a href="https://techcommunity.microsoft.com/t5/microsoft-teams-blog/microsoft-lists-in-microsoft-teams-is-now-generally-available/ba-p/1621979" target="_blank" rel="noreferrer noopener">reach GA</a> and offers an ultra low barrier for users to process data in a single table through a configurable, readymade UI. When accessed via Teams, the list data gains one more special dimension: discussions to be had regarding a list item. This is pretty much the same as the usage pattern offered for a Dynamics 365 record with the integration mentioned earlier.</p>



<p>Underneath the new covers of MS Lists is the technology familiar from SharePoint lists. If we were to only examine the UI layer, there is actually a remarkable similarity to a popular no-code service called Airtable. So much that the <a rel="noreferrer noopener" href="https://mspoweruser.com/airtable-accuses-microsoft-of-copying-its-service/" target="_blank">accusations</a> of MS simply copying the visuals and core features from this competitor don’t seem entirely unjustified. </p>



<figure><img loading="lazy" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png" alt="" width="583" height="729" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png 777w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-240x300.png 240w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-768x961.png 768w" sizes="(max-width: 583px) 100vw, 583px"></figure>



<p>Comparing these two offerings gives us some perspective on what exactly is the market position these tools are aiming to conquer. Simple lists themselves are not a particularly unique feature, rather it’s the team collaboration capabilities and ease of data sharing that turns these tables into what you’d call an actual app. Incidentally, just this week Airtable <a href="https://blog.airtable.com/airtable-platform-launch-automations-sync-apps/" target="_blank" rel="noreferrer noopener">announced</a> they were building a full platform with apps offering JavaScript based extensibility, a marketplace for sharing apps, automations for executing business logic, and finally a sync service to transfer data across environments (“bases”).</p>



<p>Collaboration scenarios around semi-structured data like lists and Excel style tables can be seen as a  gateway drug. They allow turning email or paper based manual processes into a quick first draft of what the digital process could be like. If there are indeed clear business benefits in automating the said process, the requirements for more complex app features will soon begin to emerge from the user base. Hence the collaboration platform should offer an obvious path to grow these pre-built app experiences into more advanced no-code/low-code apps.</p>



<h2>Project Oakdale a.k.a bringing CDS to Teams</h2>



<p>If Microsoft Lists is the equivalent of an Excel table within the Teams context, then <a href="https://jukkaniiranen.com/2020/07/dataflex-is-more-and-less-than-cds/">Project Oakdale</a> / “CDS Lite” could be though of as bringing SQL Server inside Teams. Now, obviously Microsoft has zero intent on actually replacing Excel nor SQL with features built into Teams. They only need to introduce those parts that make sense from a team collabocation perspective.</p>



<p>Microsoft Lists is a far cry from what a real Excel workbook can do, yet it can offer much more value in a collaboration scenarios that those lone .xlsx files ever could. Similarly, the version of CDS that will very soon be available for building Power Apps within Teams is nowhere near as powerful as the services powering enterprise CRM systems like Dynamics 365 (or the raw power offered by SQL). Still, the fact that it can be found from within every team and used by a much larger audience than what Power Apps citizen developer tools could hope to capture – those are the factors that can truly make CDS a mainstream service that most information workers in the Microsoft 365 cloud interact it.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg" alt="" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg 1024w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-300x169.jpg 300w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-768x432.jpg 768w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The experience of defining the CDS data model in Project Oakdale will be very different from the path that Power Apps makers have gone through – let alone the XRM veterans. In fact, you could easily mistake the table design and row entry UX to be that of Microsoft Lists rather than CDS. This highlights a key aspect that not all Power Platform experts may yet have grasped: for MS this “CDS Lite” is not so much about deciding what premium features of the full Power Platform to give away for free to Teams subscibers – rather it’s about how to best simplify the enterprise CRM features of CDS into a new product that Teams users could adopt on their own.</p>



<p>This doesn’t mean that …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</a></em></p>]]>
            </description>
            <link>https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540799</guid>
            <pubDate>Mon, 21 Sep 2020 07:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Monitor your internet speed with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24540344">thread link</a>) | @perryizgr8
<br/>
September 20, 2020 | https://perryizgr8.github.io/raspberry-pi/2020/09/20/monitoring-speed-rpi.html | <a href="https://web.archive.org/web/*/https://perryizgr8.github.io/raspberry-pi/2020/09/20/monitoring-speed-rpi.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>While cleaning out some old cartons last weekend, I found my old Raspberry Pi Model B+. It is the first iteration of the Pi. It has a 700MHz ARM CPU and 512MB of RAM. It uses a micro-SD card for non-volatile storage. So as you can see, it is quite a capable little computer, and you can power it off a standard 5V USB charger, which means you can run it all the time without worrying about power consumption.</p>

<p>I decided to track my home internet speed to see if my ISP is ripping me off 😉. Here’s how I did it.</p>

<h2 id="measuring-speed-on-raspberry-pi">Measuring speed on Raspberry Pi</h2>
<p><a href="https://www.speedtest.net/">Speedtest.net</a> has an <a href="https://www.speedtest.net/apps/cli">official CLI client</a> that you can install directly using <code>apt</code>. It selects the best server automatically and reports the download and upload speed, along with the latency of your connection.</p>

<figure><pre><code data-lang="shell"><span>$ </span>speedtest-cli
Retrieving speedtest.net configuration...
Testing from ACT Fibernet <span>(</span>X.X.X.X<span>)</span>...
Retrieving speedtest.net server list...
Selecting best server based on ping...
Hosted by North East Dataa Network Pvt Ltd <span>(</span>Bangalore<span>)</span> <span>[</span>0.10 km]: 9.601 ms
Testing download speed................................................................................
Download: 83.85 Mbit/s
Testing upload speed................................................................................................
Upload: 60.37 Mbit/s</code></pre></figure>

<p>There is an option to get this info in json format, which is easier to parse.</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"download"</span><span>:</span><span> </span><span>30421342.381950885</span><span>,</span><span>
  </span><span>"upload"</span><span>:</span><span> </span><span>19739920.106307168</span><span>,</span><span>
  </span><span>"ping"</span><span>:</span><span> </span><span>30.315</span><span>,</span><span>
  </span><span>"server"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"url"</span><span>:</span><span> </span><span>"http://speed.telexair.in:8080/speedtest/upload.php"</span><span>,</span><span>
    </span><span>"lat"</span><span>:</span><span> </span><span>"12.9716"</span><span>,</span><span>
    </span><span>"lon"</span><span>:</span><span> </span><span>"77.5946"</span><span>,</span><span>
    </span><span>"name"</span><span>:</span><span> </span><span>"Bangalore"</span><span>,</span><span>
    </span><span>"country"</span><span>:</span><span> </span><span>"India"</span><span>,</span><span>
    </span><span>"cc"</span><span>:</span><span> </span><span>"IN"</span><span>,</span><span>
    </span><span>"sponsor"</span><span>:</span><span> </span><span>"TelexAir Telecom Pvt Ltd"</span><span>,</span><span>
    </span><span>"id"</span><span>:</span><span> </span><span>"14493"</span><span>,</span><span>
    </span><span>"host"</span><span>:</span><span> </span><span>"speed.telexair.in:8080"</span><span>,</span><span>
    </span><span>"d"</span><span>:</span><span> </span><span>0.10306914928173351</span><span>,</span><span>
    </span><span>"latency"</span><span>:</span><span> </span><span>30.315</span><span>
  </span><span>},</span><span>
  </span><span>"timestamp"</span><span>:</span><span> </span><span>"2020-09-18T16:47:59.425361Z"</span><span>,</span><span>
  </span><span>"bytes_sent"</span><span>:</span><span> </span><span>24870912</span><span>,</span><span>
  </span><span>"bytes_received"</span><span>:</span><span> </span><span>38423553</span><span>,</span><span>
  </span><span>"share"</span><span>:</span><span> </span><span>null</span><span>,</span><span>
  </span><span>"client"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"ip"</span><span>:</span><span> </span><span>"X.X.X.X"</span><span>,</span><span>
    </span><span>"lat"</span><span>:</span><span> </span><span>"12.9719"</span><span>,</span><span>
    </span><span>"lon"</span><span>:</span><span> </span><span>"77.5937"</span><span>,</span><span>
    </span><span>"isp"</span><span>:</span><span> </span><span>"ACT Fibernet"</span><span>,</span><span>
    </span><span>"isprating"</span><span>:</span><span> </span><span>"3.7"</span><span>,</span><span>
    </span><span>"rating"</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>""</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>"ispulavg"</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>"loggedin"</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>"country"</span><span>:</span><span> </span><span>"IN"</span><span>
  </span><span>}</span><span>
</span><span>}</span></code></pre></figure>

<p>So I wrote a simple python script to capture this output.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>subprocess</span>
<span>import</span> <span>json</span>

<span>speed_test</span> <span>=</span> <span>subprocess</span><span>.</span><span>Popen</span><span>([</span><span>'speedtest-cli'</span><span>,</span> <span>'--json'</span><span>],</span> 
    <span>stdout</span><span>=</span><span>subprocess</span><span>.</span><span>PIPE</span><span>,</span> <span>stderr</span><span>=</span><span>subprocess</span><span>.</span><span>STDOUT</span><span>)</span>
<span>out</span><span>,</span> <span>err</span> <span>=</span> <span>speed_test</span><span>.</span><span>communicate</span><span>()</span>
<span>speed_dict</span> <span>=</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>out</span><span>)</span>

<span>print</span><span>(</span><span>'download='</span> <span>+</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'download'</span><span>])))</span>
<span>print</span><span>(</span><span>'upload='</span> <span>+</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'upload'</span><span>])))</span>
<span>print</span><span>(</span><span>'time='</span> <span>+</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>now</span><span>)))</span></code></pre></figure>

<h2 id="store-measurments-in-a-firestore-db">Store measurments in a Firestore DB</h2>
<p>A bit of code will push this to a Firestore DB. Google lets you use a Firestore DB for free if you stay within a reasonable number of operations per day.</p>

<figure><pre><code data-lang="python"><span>from</span> <span>google.cloud</span> <span>import</span> <span>firestore</span>

<span>now</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
<span>db</span> <span>=</span> <span>firestore</span><span>.</span><span>Client</span><span>()</span>
<span>doc_ref</span> <span>=</span> <span>db</span><span>.</span><span>collection</span><span>(</span><span>'speedtests'</span><span>).</span><span>document</span><span>(</span><span>str</span><span>(</span><span>int</span><span>(</span><span>now</span><span>)))</span>
<span>doc_ref</span><span>.</span><span>set</span><span>({</span>
    <span>'download'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'download'</span><span>])),</span>
    <span>'upload'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'upload'</span><span>])),</span>
    <span>'ping'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'ping'</span><span>])),</span>
    <span>'server_url'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'url'</span><span>]),</span>
    <span>'server_lat'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'lat'</span><span>]),</span>
    <span>'server_lon'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'lon'</span><span>]),</span>
    <span>'server_name'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'name'</span><span>]),</span>
    <span>'server_country'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'country'</span><span>]),</span>
    <span>'server_cc'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'cc'</span><span>]),</span>
    <span>'server_sponsor'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'sponsor'</span><span>]),</span>
    <span>'server_id'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'id'</span><span>]),</span>
    <span>'server_host'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'host'</span><span>]),</span>
    <span>'server_distance'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'d'</span><span>]),</span>
    <span>'server_latency'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'latency'</span><span>]),</span>
    <span>'bytes_sent'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'bytes_sent'</span><span>])),</span>
    <span>'bytes_received'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'bytes_received'</span><span>])),</span>
    <span>'client_ip'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'ip'</span><span>]),</span>
    <span>'client_lat'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'lat'</span><span>]),</span>
    <span>'client_lon'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'lon'</span><span>]),</span>
    <span>'client_isp'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'isp'</span><span>]),</span>
    <span>'client_isp_rating'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'isprating'</span><span>]),</span>
    <span>'client_rating'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'rating'</span><span>]),</span>
    <span>'client_ispdlavg'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'ispdlavg'</span><span>]),</span>
    <span>'client_ispulavg'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'ispulavg'</span><span>]),</span>
    <span>'client_loggedin'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'loggedin'</span><span>]),</span>
    <span>'client_country'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'country'</span><span>]),</span>
<span>})</span></code></pre></figure>

<h2 id="take-measurements-every-30-minutes">Take measurements every 30 minutes</h2>
<p>Then I added this to <code>crontab</code> so it runs every 30 minutes.</p>

<figure><pre><code data-lang="shell"><span>GOOGLE_APPLICATION_CREDENTIALS</span><span>=</span><span>"/home/pi/speed-monitor/speed-db-key.json"</span>
<span>*</span>/30 <span>*</span> <span>*</span> <span>*</span> <span>*</span> python3 speed-monitor.py</code></pre></figure>

<h2 id="pulling-records-from-firestore-to-google-sheets">Pulling records from Firestore to Google Sheets</h2>
<p>I let this run for a bit over 24 hours, and got 52 readings. Next step was to write a small Google Apps Script to pull these records from Firestore and put them in rows in a Google Sheets worksheet.</p>

<figure><pre><code data-lang="javascript"><span>function</span> <span>copyFromFirestore</span><span>()</span> <span>{</span>
  <span>const</span> <span>firestore</span> <span>=</span> <span>FirestoreApp</span><span>.</span><span>getFirestore</span><span>(</span><span>email</span><span>,</span> <span>key</span><span>,</span> <span>projectId</span><span>);</span>
  <span>const</span> <span>allDocuments</span> <span>=</span> <span>firestore</span><span>.</span><span>getDocuments</span><span>(</span><span>"</span><span>speedtests</span><span>"</span><span>);</span>
  <span>Logger</span><span>.</span><span>log</span><span>(</span><span>'</span><span>num=</span><span>'</span> <span>+</span> <span>allDocuments</span><span>.</span><span>length</span><span>);</span>
  <span>for</span><span>(</span><span>i</span><span>=</span><span>0</span><span>;</span><span>i</span><span>&lt;</span><span>allDocuments</span><span>.</span><span>length</span><span>;</span><span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>var</span> <span>sheet</span> <span>=</span> <span>SpreadsheetApp</span><span>.</span><span>getActiveSheet</span><span>();</span>
    <span>sheet</span><span>.</span><span>appendRow</span><span>([</span><span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>createTime</span><span>,</span> <span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>fields</span><span>.</span><span>download</span><span>.</span><span>stringValue</span><span>,</span> <span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>fields</span><span>.</span><span>upload</span><span>.</span><span>stringValue</span><span>,</span> <span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>fields</span><span>.</span><span>ping</span><span>.</span><span>stringValue</span><span>]);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<p>Then it’s simple to chart the speeds and latency over the roughly 24-hour period.</p>

<p><img src="https://perryizgr8.github.io/images/speedtest.png" alt="Speed test chart"></p>

<h2 id="problem-in-the-setup">Problem in the setup</h2>
<p>This chart shows that my download speed varies between 20 to 35Mbps, and the upload varies between 15 to 20Mbps. This is significantly lower than the 100Mbps symmetric I pay for. If you go back to the first test result I showed in this post, which I ran from my laptop, it shows 83Mbps download and 60Mbps upload. So why this discrepancy?</p>

<p>I suspect this is where my old Pi is showing its age. Even though it is connected to my router using a 100Mbps ethernet cable, the hardware is simply not powerful enough to fully saturate the connection. So I will not be running this setup anymore. Maybe one day I’ll get a newer model and run this for a longer duration. That would hopefully reveal some interesting patterns.</p>

<p>Another concern of mine is the amount of data transfered. Each run of the test consumes around 60MB of data. Running it every half hour for a month would use up ~85GB. That is close to 17% of my plan’s monthly quota. That would probably push me over the limit and cause the connection to slow down to something unusable like 1Mbps.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://perryizgr8.github.io/raspberry-pi/2020/09/20/monitoring-speed-rpi.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540344</guid>
            <pubDate>Mon, 21 Sep 2020 06:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BridgeCom Systems SkyBridge Hotspot Review]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24537600">thread link</a>) | @RFTinker
<br/>
September 20, 2020 | http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/ | <a href="https://web.archive.org/web/*/http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-248">
	<!-- .entry-header -->

	<div>
		
<p>Are you a ham radio operator interested in DMR? Getting started can be intimidating, but not with the <a href="https://www.bridgecomsystems.com/pages/plug-and-play-878-plus-skybridge">SkyBridge Hotspot DMR Plug N’ Play package</a> from BridgeCom Systems. </p>



<p>BridgeCom’s SkyBridge dual band hotspot is the latest hotspot on the market for amateur radio operators. What makes it such a compelling buy is the ease at which you can get on the air. BridgeCom will take care of programming the radio <em>and</em> the hotspot before it ships. Once it arrives, simply plug in the hotspot, turn on the radio and you’re on the air rag chewing. </p>



<h2>BridgeCom SkyBridge Hotspot features</h2>



<p>The SkyBridges uses a Pi-Zero board with a custom MMDVM hat putting out 10mW of output power. More than enough power to blanket your entire house and property (unless you live on acres of property) with seamless digital coverage. </p>



<ul><li>Wired and wireless Internet capability</li><li>High-performance 32-bit ARM processor</li><li>SkyBridge&nbsp;Board Fully Assembled And Tested</li><li><a href="https://www.pistar.uk/">Pi-Star Operating System</a></li><li>Compatible with DMR, D-Star, Yaesu System Fuzion (YSF),&nbsp; NXDN, P25 and POCSAG radios</li><li>Supports the following Cross-Mode Capabilities: DMR to NXDN, DMR to YSF, YSF to DMR and YSF to NXDN</li><li>Supports operation in both 2m (144Mhz) and 70cm (440Mhz) bands</li><li>Onboard LEDs to show status (Tx, Rx, PTT, Mode)</li><li>Up to 10mW RF power</li><li>SMA antenna connector, dual-band VHF/UHF antenna included</li><li>MMDVM open-source firmware is pre-loaded and is easily upgraded via software</li><li>Built-in 1.3″ OLED display</li><li>Connection for Nextion LCD display</li><li><strong>1 Year Warranty</strong></li><li><strong>FCC Part 15 Certified</strong></li></ul>



<p>The most important thing you get, in my opinion, is fantastic support form BridgeCom. You’re paying for the piece of mind you’ll have someone to call if you have troubles, or something malfunctions. You will also get access to BridgeCom University, and online portal that provides a long list of videos that will help you learn everything you need to know about DMR. </p>







<h2>How far does the BridgeCom SkyBridge reach?</h2>



<p>Many hams wonder just how far a little 10mW transmitter will work. The answer is— surprisingly far. I set my SkyBridge near the window in my basement and was able to walk about 600 feet in my suburban neighborhood before losing the signal from my hotspot. Don’t worry about having coverage around your home or property. This hotspot has you covered! I <a href="http://k0lwc.com/what-is-the-range-of-a-dmr-hotspot/">tested the coverage from my PiSpot</a> with a high gain antenna at 40 feet HAAT, it’s worth checking out. </p>



<h2>Is the SkyBridge hotspot reliable?</h2>



<p>I was able to use the SkyBridge for a week and I found it to be incredibly reliable. It handled my day-to-day just as well as my PiSpot hotspot running a Raspberry PiB3 board and a DVMega hat. In fact, it ran cooler in temperature than my custom built PiB3. </p>



<h2>Can I talk to friends who use D-Star or YSF?</h2>



<p>Yes! The hotspot supports cross-mode capability thanks to the Pi-Star firmware. You can use your DMR radio to talk to your ham radio friends who may be using D-Star, YSF, P25 or NXDN. This is huge. It sucks we have a fragmented digital protocol system. With this hotspot that becomes less of an issue.</p>



<h2>Is the SkyBridge hotspot worth the money?</h2>



<p>If you’re a ham looking to make the jump into DMR, I think it’s absolutely worth it. The real value of the SkyBridge Plug N’ Play package is the ease of getting on the air. BridgeCom makes it incredibly easy. Pair that with access to BridgeCom University you can watch hours and hours worth of tutorials on DMR — that’s a lot of value in a single package. </p>



<p>You can buy the BridgeCom SkyBridge hotspot <a href="https://www.bridgecomsystems.com/pages/skybridge">here</a>, or get their SkyBridge Plug N’ Play package <a href="https://www.bridgecomsystems.com/pages/plug-and-play-878-plus-skybridge">here</a>. </p>



<h2>Take a look at what you get in this YouTube video</h2>



<figure><p>
<iframe id="_ytid_32838" width="640" height="360" data-origwidth="640" data-origheight="360" src="https://www.youtube.com/embed/bghFnES-KI4?enablejsapi=1&amp;rel=0&amp;modestbranding=0&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;fs=1&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe>
</p></figure>
<br>
			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537600</guid>
            <pubDate>Sun, 20 Sep 2020 21:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Little Things: Speeding up C++ compilation]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24537231">thread link</a>) | @ingve
<br/>
September 20, 2020 | https://codingnest.com/the-little-things-speeding-up-c-compilation/ | <a href="https://web.archive.org/web/*/https://codingnest.com/the-little-things-speeding-up-c-compilation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>
            <p><em>The Little Things</em> is a new series of posts based on Locksley's internal training sessions. Often the contents are either proprietary (e.g. the inner workings of specific master key platforms) or not generally interesting (e.g. our internal libraries and tooling), but sometimes the contents are suitable for a wider audience, in which case I want to share them.</p>
<hr>
<p>This post will be about some source-level techniques for speeding up C++ compilation, and their (dis)advantages. It will <strong>not</strong> talk about things external to C++, such as buying better hardware, using a better build system, or using smarter linker<sup><a href="#fn1" id="fnref1">[1]</a></sup>. It will also not talk about the tooling that can find compilation bottlenecks, as that will be a subject of a later post.</p>
<h2 id="overviewofccompilationmodel">Overview of C++ compilation model</h2>
<p>I will start with a quick overview of the C++ compilation model, to provide context for some of the tricks I will show later. Note that this overview will be very coarse, if you want a detailed look at the subtleties of the <em>9</em> phase compilation model defined in the C++ standard, look elsewhere.</p>
<p>We will consider the compilation of C++ binary to happen in 3 steps:</p>
<ol>
<li>Preprocessing</li>
<li>Compilation</li>
<li>Linking</li>
</ol>
<h3 id="preprocessing">Preprocessing</h3>
<p>The first step is preprocessing. During it, the preprocessor takes a .cpp file and parses it, looking for <em>preprocessor directives</em>, such as <code>#include</code>, <code>#define</code>, <code>#ifdef</code>, etc.</p>
<p>Let's take this super simple file as an example</p>
<pre><code>// tiny.cpp
#define KONSTANTA 123

int main() {
    return KONSTANTA;
}
</code></pre>
<p>It contains one preprocessor directive, <code>#define</code>. It says that any following occurence of <code>KONSTANTA</code> should be replaced with <code>123</code>. Running the file through a preprocessor leads to output like this one:</p>
<pre><code>$ clang++ -E tiny.cpp
# 1 "tiny.cpp"
# 1 "&lt;built-in&gt;" 1
# 1 "&lt;built-in&gt;" 3
# 383 "&lt;built-in&gt;" 3
# 1 "&lt;command line&gt;" 1
# 1 "&lt;built-in&gt;" 2
# 1 "tiny.cpp" 2


int main() {
    return 123;
}
</code></pre>
<p>We can see that in <code>return KONSTANTA</code> the <code>KONSTANTA</code> part was replaced with <code>123</code>, as it should be. We also see that the compiler left itself a bunch of other notes, that we do not care about that much<sup><a href="#fn2" id="fnref2">[2]</a></sup>.</p>
<p>The big problem with the preprocessor model is that the <code>#include</code> directive literally means "copy-paste all of this file's contents here". Of course, if that file's contents contain further <code>#include</code> directives, then more files will be opened, their contents copied out, and in turn, the compiler will have more code to deal with. In other words, preprocessing increases the size of the input, usually significantly so.</p>
<p>The following is a simple "Hello World" in C++, using streams.</p>
<pre><code>// hello-world.cpp
#include &lt;iostream&gt;

int main() {
    std::cout &lt;&lt; "Hello World\n";
}
</code></pre>
<p>After preprocessing, the file will have <strong>28115</strong><sup><a href="#fn3" id="fnref3">[3]</a></sup> lines for the next step, compilation, to deal with.</p>
<pre><code>$ clang++ -E hello-world.cpp | wc -l
28115
</code></pre>
<h3 id="compilation">Compilation</h3>
<p>After a file is preprocessed, it is compiled into an <em>object file</em>. Object files contain the actual code to run, but cannot be run without linking. One of the reasons for this is that object files can refer to symbols (usually functions) that they do not have the definition (code) for. This happens, e.g. if a .cpp file uses a function that has been declared, but not defined, like so:</p>
<pre><code>// unlinked.cpp
void bar(); // defined elsewhere (hopefully)

void foo() {
    bar();
}
</code></pre>
<p>You can look inside a compiled object file to see what symbols it provides and what symbols it needs, using <code>nm</code> (Linux) or <code>dumpbin</code> (Windows). If we look at the output for the <code>unlinked.cpp</code> file, we get this:</p>
<pre><code>$ clang++ -c unlinked.cpp &amp;&amp; nm -C unlinked.o
                 U bar()
0000000000000000 T foo()
</code></pre>
<p><code>U</code> means that the symbol is not defined in this object file. <code>T</code> means that the symbol is in the text/code section and that it is exported, which means that other object files can get <code>foo</code> from this <code>unlinked.o</code>. It is important to know that symbols might also be present in an object file, but not be available to other object files. Such symbols are marked with <code>t</code>.</p>
<h3 id="linking">Linking</h3>
<p>After all the files have been compiled into object files, they have to be <em>linked</em> into the final binary artefact. During linking, all the various object files are smashed together in a specific format, e.g. ELF, and the various references to undefined symbols in object files are resolved with the address of the symbol, as provided by a different object file (or library).</p>
<p>With this overview done, we can start tackling the different ways to speed up the compilation of your code. Let's start simple.</p>
<h2 id="includeless"><code>#include</code> less</h2>
<p>Including a file usually brings in a <em>lot</em> of extra code, which the compiler then needs to parse and check. Thus the simplest, and usually also the biggest, way to speed up the compilation of your code, is to just <code>#include</code> fewer files. Reducing the include set is especially beneficial in header files, as they are likely to be included from other files, thus amplifying the impact of your improvements.</p>
<p>The easiest way to do this is to remove any unused includes. Unused includes shouldn't happen often, but sometimes they are left behind during refactoring, and using a tool like <a href="https://include-what-you-use.org/">IWYU</a> <em>can</em><sup><a href="#fn4" id="fnref4">[4]</a></sup> make it simple to do. However, just cleaning up unused includes is unlikely to provide many benefits, and so you will have to reach for bigger guns, forward declarations and manual outlining.</p>
<p>But before explaining forward declarations and manual outlining, I want to go over the costs of header inclusion quickly, so we can build up intuition on what sort of speed-ups we can expect from pruning down include graphs.</p>

<p>The table below shows the time required by Clang<sup><a href="#fn5" id="fnref5">[5]</a></sup> to compile a file that <em>only</em> includes some stdlib headers.</p>

<table>
<thead>
<tr>
<th>header(s) included</th>
<th>time to compile (ms)</th>
<th>difference from baseline (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>none</td>
<td>11.3  ± 0.2</td>
<td>-</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code></td>
<td>68.8  ± 0.3</td>
<td>57.5 ±  0.36</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code></td>
<td>136.3  ± 0.8</td>
<td>125.0 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;stdexcept&gt;</code></td>
<td>137.0  ± 0.8</td>
<td>125.7 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code></td>
<td>155.3  ± 0.9</td>
<td>144.0 ±  0.92</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>136.7  ± 0.7</td>
<td>125.4 ±  0.73</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>156.1  ± 0.8</td>
<td>144.8 ±  0.82</td>
</tr>
</tbody>
</table>
<p>The first row shows the time needed to compile a completely empty file, to provide a baseline time required by the compiler to start, read the file, and do nothing. The other lines are more interesting. As the second line says, just including <code>&lt;vector&gt;</code> adds 57 ms to compilation times, even though there will be no actual line emitted. As we can see, the cost to include <code>&lt;string&gt;</code> is more than double of <code>&lt;vector&gt;</code>, and the cost to include <code>&lt;stdexcept&gt;</code> is about the same as for <code>&lt;string&gt;</code>.</p>
<p>More interesting are the rows for combinations of headers, because no combination of headers is as expensive as compiling each of them on its own. The reason is quite simple: their internal include overlap. The most extreme case is <code>&lt;string&gt;</code> + <code>&lt;stdexcept&gt;</code>, because <code>&lt;stdexcept&gt;</code> is basically <code>&lt;string&gt;</code> + couple of types deriving from <code>std::exception</code>.</p>
<p>What you should take away from this are two things:</p>
<ul>
<li>Even if you do not use anything from a header, you still have to pay for it.</li>
<li>Include costs do not neatly sum, nor subtract.</li>
</ul>
<p>Now let's go through techniques we can use to include fewer files.</p>
<h3 id="forwarddeclarations">Forward declarations</h3>
<p>Quite often, when we mention a type, we only need to know that it exists but do not need to know its definition. The common case is creating a pointer or a reference to a type, in which case you need a knowledge that the type exists (a <em>forward declaration</em>), but not what it looks like (a <em>definition</em>).</p>
<p>As an example, this header is valid:</p>
<pre><code>class KeyShape; // forward declaration

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs);
</code></pre>
<p>as long as the implementation file includes the appropriate headers:</p>
<pre><code>#include "key-shape.hpp" // provides the full definition of KeyShape

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs) {
    assert(lhs.positions() == rhs.positions());
    ...
}
</code></pre>
<p>You can also use forward declaration together with some templated classes, whose size does not change depending on the template argument, e.g. <code>std::unique_ptr</code> and <code>std::vector</code><sup><a href="#fn6" id="fnref6">[6]</a></sup>. However, doing so can force you to outline your constructors, destructors and other special member functions (<em>SMFs</em>), as those usually need to see the full definition of the type. Your code then ends up looking like this:</p>
<pre><code>// foo.hpp
#include &lt;memory&gt;

class Bar;

class Foo {
    std::unique_ptr&lt;Bar&gt; m_ptr;
public:
    Foo(); // = default;
    ~Foo(); // = default;
};
</code></pre>
<pre><code>// foo.cpp
#include "bar.hpp"

Foo::Foo() = default;
Foo::~Foo() = default;
</code></pre>
<p>Notice that we still use the compiler-generated default constructor and destructor, but do so in the <code>.cpp</code> file, where we see the full definition of <code>Bar</code>. I also like to use the <code>// = default;</code> comment to signal to other programmers reading the code that the SMF is explicitly declared but will be defaulted, and thus there won't be any special logic in it.</p>
<p>When using this technique, please remember that the outlined functions cannot be inlined without LTO. In other words, you probably do not want to outline <em>every</em> function just because you can, because calling trivial functions can be much more expensive than inlining their code directly.</p>
<h3 id="explicitoutlining">Explicit outlining</h3>
<p>The idea underlying explicit outlining is quite simple: sometimes we get better results if a piece of code is explicitly split away from a function. One of the most common reasons is, perhaps ironically, improving inlining by making the common path of a function small. However, in our case, the reason for doing this is to improve the compilation times.</p>
<p>If a piece of code is expensive to compile, and inlining it is not crucial for performance, only one TU has to pay for compiling it. The canonical example of this is throwing an exception in general, and exceptions from <code>&lt;stdexcept&gt;</code> in particular. Throwing an exception generates quite a lot of code, and throwing more complex standard exception types, such as <code>std::runtime_error</code>, also requires an expensive<sup><a href="#fn7" id="fnref7">[7]</a></sup> header, <code>&lt;stdexcept&gt;</code> to be included.</p>
<p>By instead replacing all <code>throw foo;</code> statements with calls to a helper function along the lines of <code>[[noreturn]] void throw_foo(char const* msg)</code>, the call sites become …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codingnest.com/the-little-things-speeding-up-c-compilation/">https://codingnest.com/the-little-things-speeding-up-c-compilation/</a></em></p>]]>
            </description>
            <link>https://codingnest.com/the-little-things-speeding-up-c-compilation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537231</guid>
            <pubDate>Sun, 20 Sep 2020 20:41:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why aren’t you more serious?]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24537147">thread link</a>) | @luu
<br/>
September 20, 2020 | https://rubenerd.com/why-arent-you-more-serious/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/why-arent-you-more-serious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>I get more hits to my site and RSS feed in a typical month now than I used to get in a given year. For a fifteen year old blog that started life as a Perl CGI script in high school, it’s been wild to see. Whether you’re coming here from Hacker News, Reddit, Twitter, Discord, newsgroups, or the BSD Now podcast, hi! Sometimes I talk about tech here.</p>
<p>This marked increase in traffic corresponds with more feedback email, a not altogether insignificant number of which are negative. I’ll address some recurring themes here, because they’re Jason Bourne of the same misunderstanding of the kind of site people have come across.</p>
<p>Once you filter out the obvious trolls saying BSD is dead, Apple computers are for posers who value form over function, and that we’re all sheep for wearing a mask, most of the remainder concern the tone of my posts, and what they consider the ancillary topics I cover. They claim that my writing is too jovial, my site <a href="https://rubenerd.com/about/#mascot">mascot</a> drawn by Clara is inappropriate, and inclusion of posts about <a href="https://rubenerd.com/josh-on-how-to-peel-garlic/" title="Josh on how to peel garlic">cooking garlic</a> are a waste of time and somehow detract from my serious technical and political posts.</p>
<p><em>(One gentleman spent an inordinate amount of time criticising Rubi’s skirt in such lurid detail I felt but the tiniest twinge of what women must feel as creepy men ogle them walking past).</em></p>
<p>I appreciate—most of—the feedback, but respectfully disagree. There may not be many of us doing this anymore, but this is specifically a personal blog. This site has always been a labour of love for me since I started it in high school in 2004, and will necessarily be about stuff that’s on my mind and that I’m interested in. There are drier technical blogs by people I respect out there, but that’s not my style.</p>
<p>I’m also unsure how one can quantify detraction in this context. I remember having a similar debate with a WikiProject Albums contributor, who claimed compilation album articles similarly detracted from the quality of Wikipedia. In a finite space like a newspaper or book that might make sense, but in an electronic medium it seems to me the easiest solution is to ignore things in which you have no interest. Your also free to find an anime mascot drawn by my girlfriend offensive, just as I’m free to include her to make the world a slightly nicer place.</p>
<p>Which dovetails to the third comment which I take more seriously. I haven’t received permission to quote their email, but in summary they said my serious posts about COVID, social security, and attitudes in open source software communities are valuable, but sporadic. The implication is it’s incumbent upon me to only discuss important topics, and that by including what amounts to sidebars I’m trivialising them.</p>
<p>This one, selfishly, comes down to self-preservation. I need to write about the intricacies of BSD text editors and fun engineering or cooking videos to afford me sufficient mental fortitude to discuss serious topics. Sometimes we all need a break, and this is how I do it.</p>
<p>As I wrote on my <a href="https://rubenerd.com/the-first-post/">first post</a> fifteen years ago:</p>
<blockquote>
<p>… it’s a blog site with random stuff on it that I think is groovy, weird etc … maybe one percent of it, or maybe two, might be useful to someone, especially with respect to some of the tech problems I’ve had and solved over the years. So here it is.</p>
</blockquote>
<p>Thanks for reading.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/why-arent-you-more-serious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537147</guid>
            <pubDate>Sun, 20 Sep 2020 20:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to the Turbulent Twenties]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24536933">thread link</a>) | @dforrestwilson
<br/>
September 20, 2020 | https://www.noemamag.com/welcome-to-the-turbulent-twenties/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/welcome-to-the-turbulent-twenties/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				


<p>Almost three decades ago, one of us, Jack Goldstone, published a <a href="https://www.amazon.com/Revolution-Rebellion-Early-Modern-World/dp/1138222127/ref=pd_lpo_14_img_0/140-4438334-0411838?_encoding=UTF8&amp;pd_rd_i=1138222127&amp;pd_rd_r=48abcf2c-170c-43f1-ac2b-6aceb88ec983&amp;pd_rd_w=ROnfs&amp;pd_rd_wg=qroCO&amp;pf_rd_p=7b36d496-f366-">simple model</a> to determine a country’s vulnerability to political crisis. The model was based on how population changes shifted state, elite and popular behavior. Goldstone argued that, according to this Demographic-Structural Theory, in the 21st century, America was likely to get a populist, America-first leader who would sow a whirlwind of conflict.</p>



<p>Then ten years ago, the other of us, Peter Turchin, <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0237458">applied</a> Goldstone’s model to U.S. history, using current data. What emerged was alarming: The U.S. was heading toward the highest level of vulnerability to political crisis seen in this country in over a hundred years. Even before Trump was elected, Turchin <a href="https://www.nature.com/articles/463608a">published</a> his prediction that the U.S. was headed for the “Turbulent Twenties,” forecasting a period of growing instability in the United States and western Europe.</p>



<p>Given the Black Lives Matter protests and cascading clashes between competing armed factions in cities across the United States, from Portland, Oregon to Kenosha, Wisconsin, we are already well on our way there. But worse likely lies ahead.</p>



<p>Our model is based on the fact that across history, what creates the risk of political instability is the behavior of elites, who all too often react to long-term increases in population by committing three cardinal sins. First, faced with a surge of labor that dampens growth in wages and productivity, elites<strong> </strong><em>seek to take a larger portion of economic gains for themselves</em>, driving up inequality. Second, facing greater competition for elite wealth and status, <em>they tighten up the path to mobility to favor themselves and their progeny</em>. For example, in an increasingly meritocratic society, elites could keep places at top universities limited and raise the entry requirements and costs in ways that favor the children of those who had already succeeded. </p>



<p>Third, anxious to hold on to their rising fortunes, they <em>do all they can to resist taxation of their wealth and profits</em>, even if that means starving the government of needed revenues, leading to decaying infrastructure, declining public services and fast-rising government debts.</p>



<p>Such selfish elites lead the way to revolutions. They create simmering conditions of greater inequality and declining effectiveness of, and respect for, government. But their actions alone are not sufficient. Urbanization and greater education are needed to create concentrations of aware and organized groups in the populace who can mobilize and act for change.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Such selfish elites lead the way to revolutions.”    </p>

    
    
  </div>
</div>




<p>Top leadership matters. Leaders who aim to be inclusive and solve national problems can manage conflicts and defer a crisis. However, leaders who seek to benefit from and fan political divisions bring the final crisis closer. Typically, tensions build between elites who back a leader seeking to preserve their privileges and reforming elites who seek to rally popular support for major changes to bring a more open and inclusive social order. Each side works to paint the other as a fatal threat to society, creating such deep polarization that little of value can be accomplished, and problems grow worse until a crisis comes along that explodes the fragile social order.</p>



<p>These were the conditions that prevailed in the lead-up to the great upheavals in political history, from the French Revolution in the eighteenth century, to the revolutions of 1848 and the U.S. Civil War in the nineteenth century, the Russian and Chinese revolutions of the twentieth century and the many “color revolutions” that opened the twenty-first century. So, it is eye-opening that the data show very similar conditions now building up in the United States.</p>



<p>In applying our model to the U.S., we tracked a number of indicators of popular well-being, inequality and political polarization, all the way from 1800 to the present. These included the ratio of median workers’ wages to GDP per capita, life expectancy, the number of new millionaires and their influence on politics, the degree of strict party-line voting in Congress, and the incidence of deadly riots, terrorism and political assassinations. We found that all of these indicators pointed to two broad cycles in U.S. history.</p>



<p>In the decades following independence, despite growing party competition, elites in office often compromised and voted together, and rising national prosperity was broadly shared. But that wave of positive conditions peaked around 1820; from there, political polarization and economic inequality rose sharply in the years leading up to the Civil War. The crisis indicators peaked in the 1860s but did not fall sharply after the war; instead, they remained high until 1920 (the years of Reconstruction, Jim Crow, Gilded Age and violent labor unrest, and the anarchists).</p>



<p>Then, the tide shifted, and a second wave of greater unity and prosperity began to gather strength. Contrary to expectations, World War I and the Great Depression did <em>not </em>produce a rise in political instability indicators. Instead, the country pulled together. The reforms introduced during the Progressive Era and clinched in the New Deal reduced inequality and strengthened the economic share of workers; during and after World War II, the country agreed on new tax policies and increased spending on roads and schools.</p>



<p>The 1950s were a golden age of worker progress and party cooperation; even in the 1960s and 1970s, despite serious racial conflicts, the country’s leaders were able to agree on remarkably far-reaching reforms to improve civil rights and environmental protection. However, the 1960s were a high point in our indicators of political resilience; in the 1970s and 1980s, things began to turn, and by the 1990s, a new wave of rising inequality and political divisions was well underway, exemplified by Newt Gingrich’s policies as speaker of the House. In the next two decades, the crisis indicators rose just as sharply as they had in the decades before the Civil War. It was not just that by the late 2010s, overall inequality was rising to the levels not seen since the Gilded Age; median wages in relation to GDP per capita also were falling to historically low levels.</p>



<p>Writing in the journal <a href="https://www.nature.com/articles/463608a">Nature in 2010</a>, we pointed out that such trends were a reliable indicator of looming political instability and that they “look set to peak in the years around 2020.” In <a href="https://www.amazon.com/Ages-Discord-Peter-Turchin/dp/0996139540/ref=pd_lpo_14_img_1/140-4438334-0411838?_encoding=UTF8&amp;pd_rd_i=0996139540&amp;pd_rd_r=e31aa110-1e97-41b5-b8b9-59732b68e1b1&amp;pd_rd_w=NKvjs&amp;pd_rd_wg=QoYuR&amp;pf_rd_p=7b36d496-f366-4631-94d3-61b87b52511b&amp;pf_rd_r=53CDBB3DFVBED71T3PKV&amp;psc=1&amp;refRID=53CDBB3DFVBED71T3PKV">Ages of Discord</a>, published early in 2016, we showed that America’s “political stress indicator” had turned up sharply in recent years and was on track to send us into the “Turbulent Twenties.”</p>


<!-- Content Image Block Template -->
<div>

  <div>

    <!-- Main Image -->
    <div>

            <div>
              <p><img width="1024" height="730" src="https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord.png" alt="" srcset="https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord.png 1024w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-300x214.png 300w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-768x548.png 768w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-540x385.png 540w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-701x500.png 701w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-898x640.png 898w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-600x428.png 600w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
      </div>

              <div>
              
      <figcaption>
        <p>The Political Stress Index (PSI) combines the three crisis indicators in the Goldstone-Turchin theory: declining living standards, increasing intra-elite competition/conflict and a weakening state. Growing PSI indicates increased likelihood of political violence. The Well-Being Index indicates greater equality, greater elite consensus and a more legitimate state.</p>
      </figcaption>

            </div>
      
    </div>


      </div>

</div>



<hr>



<p>This year, the COVID-19 pandemic and the death of George Floyd at the hands of the Minneapolis police have delivered a double-barreled crisis to U.S. politics. America has reacted with a nationwide, months-long series of urban protests. But this explosion of protest is not just the result of this year’s events. The U.S. has weathered epidemics and racial protests before and produced legislation that made the country better as a result. What is different this decade is that these events are occurring at a time of extreme political polarization, after decades of falling worker’s share in national income, and with entrenched elite opposition to increased spending on public services. These trends have crippled the U.S. government’s ability to mount an effective response to the pandemic, hampered our ability to deliver an inclusive economic relief policy and exacerbated the tensions over racial injustice that boiled over in response to the video of Floyd’s death.</p>



<p>Is the U.S. likely headed for still greater protests and violence? In a word, yes. Inequality and polarization have not been this high since the nineteenth century. Democrats are certain that if Donald Trump is re-elected, American democracy will not survive. Republicans are equally certain that if Trump loses, radical socialists will seize the wealth of elites and distribute it to underserving poor and minorities, forever destroying the economy of the United States. Both sides are also convinced that the other side intends to change the democratic “rules of the game” in ways that will make it impossible for them to compete effectively in future elections. In such conditions, elections are not merely contests over policy preferences; they become existential battles for the future of the nation. Whichever party loses is likely to view the results as rigged and the outcome as intolerable.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Almost any election scenario this fall is likely to lead to popular protests on a scale we have not seen this century.”    </p>

    
    
  </div>
</div>




<p>The upcoming election therefore offers <a href="https://www.bostonglobe.com/2020/07/25/nation/bipartisan-group-secretly-gathered-game-out-contested-trump-biden-election-it-wasnt-pretty/">several outcomes</a> that could trigger mass violence. If Trump wins narrowly in the electoral college but loses the popular vote by a large margin, there will surely be massive demonstrations protesting the outcome, calling it illegitimate and demanding allegiance to the will of the majority of Americans. Trump may then be tempted to call in federal forces to put down these protests (as in Portland), which may in turn, as in Portland, provoke even larger uprisings.</p>



<p>If Trump loses, he is likely to contest the outcome as a “<a href="https://nymag.com/intelligencer/2020/05/trump-is-preparing-to-contest-any-election-loss.html">rigged</a>” election. But that action will again lead to massive popular protests, this time to insist that the election results be honored. If Trump again puts federal security forces in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/welcome-to-the-turbulent-twenties/">https://www.noemamag.com/welcome-to-the-turbulent-twenties/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/welcome-to-the-turbulent-twenties/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536933</guid>
            <pubDate>Sun, 20 Sep 2020 20:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets I use to becoming a better remote developer]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24536775">thread link</a>) | @mateusfreira
<br/>
September 20, 2020 | https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/ | <a href="https://web.archive.org/web/*/https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I have been working as a remote developer fulltime, for the last five years. Part-time/freelancing for at least ten years, over this time, I have collected several tips and tricks on how to become better at it and how to succeed and deliver results under this environment. I am writing this post to share some of these tricks, while this is a brief list. I am always testing these things. I thought it would be useful to do this one and periodically create a new one to share some updates.</p>

<p>If you are a TLDR reader, I am sharing here the list of the subtitles:</p>

<ul id="markdown-toc">
  <li><a href="#secrets" id="markdown-toc-secrets">Secrets</a>    <ul>
      <li><a href="#be-positive-and-open-minded" id="markdown-toc-be-positive-and-open-minded">Be Positive and Open-minded</a></li>
      <li><a href="#create-a-clean-setup-and-neat-workspace" id="markdown-toc-create-a-clean-setup-and-neat-workspace">Create a clean setup and neat workspace</a></li>
      <li><a href="#create-a-before-commit-secret-message" id="markdown-toc-create-a-before-commit-secret-message">Create a “before commit” secret message</a></li>
      <li><a href="#create-a-pull-request-checklist" id="markdown-toc-create-a-pull-request-checklist">Create a Pull request checklist</a></li>
      <li><a href="#address-daily-meetings-like-a-diary" id="markdown-toc-address-daily-meetings-like-a-diary">Address daily meetings like a diary</a></li>
      <li><a href="#tools-you-should-use" id="markdown-toc-tools-you-should-use">Tools you should use</a>        <ul>
          <li><a href="#1-grammarly" id="markdown-toc-1-grammarly">1. Grammarly</a></li>
          <li><a href="#2-time-tracker" id="markdown-toc-2-time-tracker">2. Time tracker</a></li>
          <li><a href="#3-skitch" id="markdown-toc-3-skitch">3. Skitch</a></li>
          <li><a href="#4-obs-screen-recording" id="markdown-toc-4-obs-screen-recording">4. OBS (screen recording)</a></li>
        </ul>
      </li>
      <li><a href="#take-notes-notes-and-notes" id="markdown-toc-take-notes-notes-and-notes">Take Notes, notes, and notes</a></li>
      <li><a href="#work-in-the-morning" id="markdown-toc-work-in-the-morning">Work in the morning</a></li>
      <li><a href="#create-a-routine" id="markdown-toc-create-a-routine">Create a routine</a>        <ul>
          <li><a href="#1-wake-up-early" id="markdown-toc-1-wake-up-early">1. Wake up early</a></li>
          <li><a href="#2-prepare-coffee" id="markdown-toc-2-prepare-coffee">2. Prepare coffee</a></li>
          <li><a href="#3-workout-3-times-a-week" id="markdown-toc-3-workout-3-times-a-week">3. Workout 3 times a week</a></li>
          <li><a href="#4-read" id="markdown-toc-4-read">4. Read</a></li>
          <li><a href="#5-write" id="markdown-toc-5-write">5. Write</a></li>
          <li><a href="#6-sleep-regularly" id="markdown-toc-6-sleep-regularly">6. Sleep regularly</a></li>
        </ul>
      </li>
      <li><a href="#use-vim-and-tmux-or-at-least-master-your-env-and-editor" id="markdown-toc-use-vim-and-tmux-or-at-least-master-your-env-and-editor">Use Vim and Tmux (or at least master your Env and editor)</a></li>
      <li><a href="#create-a-dotproject" id="markdown-toc-create-a-dotproject">Create a Dotproject</a></li>
      <li><a href="#read-these-books" id="markdown-toc-read-these-books">Read these books</a>        <ul>
          <li><a href="#1-the-culture-map" id="markdown-toc-1-the-culture-map">1. The Culture map</a></li>
          <li><a href="#2-the-pragmatic-programmer" id="markdown-toc-2-the-pragmatic-programmer">2. The Pragmatic Programmer</a></li>
          <li><a href="#3-getting-thins-done" id="markdown-toc-3-getting-thins-done">3. Getting Thins done</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#reviewers" id="markdown-toc-reviewers">Reviewers</a></li>
</ul>

<p>Now, if you find something interesting, stay with me and let’s learn something.</p>

<h2 id="secrets">Secrets</h2>

<p>From the easiest to the hardest.</p>

<h3 id="be-positive-and-open-minded">Be Positive and Open-minded</h3>

<p>This may be cliche, and not everyone is a positive person (and does not need to be). Still, is cool to have a positive attitude upfront a challenge or request; I am not saying you should be a yes man, I am saying that when you get a request, try to think about it as if is a challenge rather than a boring request,  or someone wanting to steal some of your time.</p>

<p>Be energetic and show what happens when you overcome some hard challenges, push the time to be more positive (for example). Being positive and expressing the success will increase yours and your team morale, and high team morale increases the chance of success.</p>

<h3 id="create-a-clean-setup-and-neat-workspace">Create a clean setup and neat workspace</h3>

<p>My workspace has a significant impact on my state of mind and even my productivity; back when I started working remotely, my office was a mess. I had a lot of objects on my table, and lots of them I had never used or even touched. That all ended-up on a day that I got a massive allergy that lasted for over two weeks. I noticed that was because of the dust in my office. It was out of control, and it would have been easier to clean it up weren’t for all the objects I had on my table.</p>

<p><img src="https://user-images.githubusercontent.com/234049/92327865-0b314c80-f033-11ea-9727-baa8721d65a7.png" alt="Old office"></p>

<p>At that time, I also noticed I would work anywhere but in the office. After that day, I cleaned my office and removed everything from my table. In one week, I noticed a productivity-boosting and a much better sense of peace while working in my office. Then I started reading about all of that “clean-setup” movement, which immediately made sense. So I started the journey on how I could de more productive without working more hours, and I decided to go all-in. I stopped buying electronics that I rarely used and instead, I used the money to make my office simpler, cleaner, and more set to productivity.
I bought two ergonomic chairs, started using a single and bigger monitor instead of two. I got a mechanical arm that suspends it and therefore I do not occupy my table with supports. I switched my wired mouse and keyboard for wireless, added a plant, and even a fancy lamp to my office table.</p>

<p>Here is how it looks now.</p>

<p><img src="https://user-images.githubusercontent.com/234049/93273814-36ccd900-f78f-11ea-844e-bad54f0d8dab.png" alt="New office"></p>

<p>Since these changes, I’ve noticed an even more significant increase in my productivity and well-being while working. I am still working out of the office sometimes, like from the garden of my house, from coffee shops or libraries, but now I feel there is no more productive place than my office in the quiet hours of the day. And I have tested myself to see how to return to the old mess environment. I placed a single page of paper on my table next to my keyboard, and at the end of that day, I felt exhausted. That day didn’t feel productive at all. It amazes me how much impact can a little mess do to my well-being nowadays, and how could I possibly work on such a chaotic environment in a close past.</p>

<p><img src="https://user-images.githubusercontent.com/234049/92327958-bcd07d80-f033-11ea-86d5-4c8205b63a1f.jpg" alt="Garden"></p>

<h3 id="create-a-before-commit-secret-message">Create a “before commit” secret message</h3>

<p>Before doing any commit, my secret is that I will have my editor asking me, <code>Is it easy to change?</code>. This advice comes from several coding or software design books. The most important factory of a useful feature, project, software, method, and commit is that it needs to be changed easily. The idea for that message came from the book <a href="https://amzn.to/2AVGWiZ">Pragmatic programmer</a> (This is an outstanding book I recommend for any programmer at any level). As soon as I read it, I knew it would be a good idea to ask my self that question from time to time, once every commit seems to be the best I have for the moment.</p>

<p><img src="https://mateusfreira.github.io/images/commit-message.png" alt="Secret commit question"></p>

<h3 id="create-a-pull-request-checklist">Create a Pull request checklist</h3>

<p>In my daily notes, I have one checklist for each PR I will open for any project. This will help me making sure that PR will be good and will pass easily on review. I am also giving a grammar checking on Grammarly (I will talk about it in detail later in the Grammarly chapter). Check the variable names I have added in (You know how hard naming is), check the docs of the methods (So I make sure I’ve documented any critical information), check API docs (Changes in public APIs are usually rare, but when they happen you better remember to also update their docs). Smoke testing (of course, running the tests locally and seeing how they go). And finally, improve something I see that is bad (I try as much as I can not to rush on PR opening and to have this last step to improve something work for me like and “It won’t be possible to rush at this point”. The thing is, I usually find other small problem on the code in this step and consider it to be one of the most important)</p>

<div><div><pre><code><span># PR self review check list</span>
- <span>[</span> <span>]</span> Pass grammarly <span>in </span>the PR body
- <span>[</span> <span>]</span> Pass grammarly <span>in </span>the <span>test </span>spec
- <span>[</span> <span>]</span> Revisit variables and methods names
- <span>[</span> <span>]</span> Check every public method doc
- <span>[</span> <span>]</span> Check API docs
- <span>[</span> <span>]</span> Smoke <span>test </span>everyting
- <span>[</span> <span>]</span> Improvement
</code></pre></div></div>

<h3 id="address-daily-meetings-like-a-diary">Address daily meetings like a diary</h3>

<p>Some people think that daily meetings are boring, but I think they can and should be fun and productive. I write my daily meeting notes every day as if I were keeping a diary, telling a short story about yesterday and this morning, as well as what I plan to do today and whether the plan for the week needs to change. I usually start working 4 hours before the next member of my team wakes up (I work from Brazil with a team located in the USA), so I write the notes of the daily meetings between 2 and 3 hours after starting work, which helps me to clarify how my day was yesterday, what should I keep doing, what should I avoid and what is blocking.</p>

<p>Also, the notes will give you a direct message to say at daily meetings, and I avoid starting the meeting by saying, “Let me remember what I did yesterday !!!” you will look professional, having the updates you need to provide at your fingertips. It also gives you a sense of how things are going over the days; you can look back at your daily notes and see if you’re making progress or not.</p>

<p>The time tracker is your ally when taking notes; this will help you not to forget any details, even if you take notes 3 days later, on a Monday. After a while, it will be natural, and you will not need to remember to do them, to start this habit, I recommend adding a task in your agenda 1 hour before the daily meeting to make notes this way once in the daily meeting begins you will be ready.</p>

<h3 id="tools-you-should-use">Tools you should use</h3>

<h4 id="1-grammarly">1. <a href="https://www.grammarly.com/">Grammarly</a></h4>

<p>Grammarly, for me, is one of the most essential tools for my day-to-day, whether as my text editor or email corrector. Writing for me is a superpower for remote workers and we have to make sure our text is reasonable; you do not need to proofread every single document you produce but it helps you not having any typos or structural problems. I do overuse Grammarly, and it has paid dividends for the last three years. Since I started my master’s degree, I had it verifying every single article and master thesis. Since then, I use to say it is the best investment I do every year.</p>

<h4 id="2-time-tracker">2. Time tracker</h4>

<p>Time tracking is a superpower that will enable you to see where you are putting your time on, even if your employer does not require it, I would recommend you to have one for many reasons.</p>
<ul>
  <li>You will where you are spending most of your time in.</li>
  <li>You can avoid overworking by knowing how many hours you worked on that day and not trusting your sense of “have I worked too much or too few?”</li>
</ul>

<p>Today I use <a href="https://www.getharvest.com/">Harvest</a> but in the past, while working as independet contractor I have used <a href="http://toggl.com/">Toggl</a>, and I track my activities in real time, without caring about all about details (Like I will not stop the clock if I go out to grap coffee or to read email), but I would recommend using any if them that you like using.</p>

<h4 id="3-skitch">3. <a href="https://evernote.com/products/skitch">Skitch</a></h4>

<p>One picture worths a thousand words, but it needs to be good, because sometimes you need to explain complex subjects to people that will not have the same context you have about the topic you are talking about. In that matter, Skitch is a great tool to take prints and show critical points and do short explanations. Check out the next image, where I was explaining a chart just as an example.</p>

<p><img width="1849" alt="Grafana_-_Nun-Db_Monitoring" src="https://user-images.githubusercontent.com/234049/93271844-9d032d00-f78a-11ea-9e1c-922578623c36.png"></p>

<h4 id="4-obs-screen-recording">4. <a href="https://obsproject.com/">OBS</a> (screen recording)</h4>

<p>As well as writing, showing information as video can be a superpower. Some subjects are much easier to demonstrate as a video than as a text. For example, simulating a bug or showing a problem needs to touch several services and multiple monitoring charts and sources.
Recording a good video showing how you find the bug, how you made sure it was fixed, or even explaining the process you have implemented can save you several paragraphs of text, and save you from having a PR rejected. Any complex new feature or bug fix, I would advise you to come with an excellent text in the PR, great code comments, great self-review showing the critical areas, and a good video explaining …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/">https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/</a></em></p>]]>
            </description>
            <link>https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536775</guid>
            <pubDate>Sun, 20 Sep 2020 19:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust?]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 317 (<a href="https://news.ycombinator.com/item?id=24536645">thread link</a>) | @dochtman
<br/>
September 20, 2020 | https://matklad.github.io/2020/09/20/why-not-rust.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/09/20/why-not-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Sep 20, 2020</p>
  <p>I’ve recently read an article criticizing Rust, and, while it made a bunch of good points, I didn’t enjoy it — it was an easy to argue with piece.
In general, I feel that I can’t recommend an article criticizing Rust.
This is a shame — confronting drawbacks is important, and debunking low effort/miss informed attempts at critique sadly inoculates against actually good arguments.</p>
<p>So, here’s my attempt to argue <em>against</em> Rust:</p>
<div>
<dl>
<dt>Not All Programming is Systems Programming</dt>
<dd>
<div>
<div>
<p>Rust is a systems programming language.
It offers precise control over data layout and runtime behavior of the code, granting  you maximal performance and flexibility.
Unlike other systems programming languages, it also provides memory safety — buggy programs terminate in a well-defined manner, instead of unleashing (potentially security-sensitive) undefined behavior.</p>
<p>However, in many (most) cases, one doesn’t need ultimate performance or control over hardware resources.
For these situations, modern managed languages like Kotlin or Go offer decent speed, enviable
<a href="https://qconlondon.com/london-2017/system/files/presentation-slides/highperformancemanagedlanguages.pdf">time to performance</a>, and are memory safe by virtue of using a garbage collector for dynamic memory management.</p>
</div>
</div>
</dd>
<dt>Complexity</dt>
<dd>
<div>
<div>
<p>Programmer’s time is valuable, and, if you pick Rust, expect to spend some of it on learning the ropes.
Rust community poured a lot of time into creating high-quality teaching materials, but the Rust language <em>is</em> big.
Even if a Rust implementation would provide value for you, you might not have resources to invest into growing the language expertise.</p>
<p>Rust’s price for improved control is the curse of choice:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Bar</span>         <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>Bar</span>     <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> <span>Bar</span> <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Box</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Rc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>     <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In Kotlin, you write <code>class Foo(val bar: Bar)</code>, and proceed with solving your business problem.
In Rust, there are choices to be made, some important enough to have dedicated syntax.</p>
<p>All this complexity is there for a reason — we don’t know how to create a simpler memory safe low-level language.
But not every task requires a low-level language to solve it.</p>

</div>
</div>
</dd>
<dt>Compile Times</dt>
<dd>
<div>
<div>
<p>Compile times are a multiplier for everything.
A program written in a slower to run but faster to compile programming language can be <em>faster</em> to run because the programmer will have more time to optimize!</p>
<p>Rust intentionally picked slow compilers in the <a href="https://research.swtch.com/generic">generics dilemma</a>.
This is not necessary the end of the world (the resulting runtime performance improvements are real), but it does mean that you’ll have to fight tooth and nail for reasonable build times in larger projects.</p>
<p><code>rustc</code> implements what is probably the most advanced <a href="https://rustc-dev-guide.rust-lang.org/queries/incremental-compilation.html">incremental compilation</a> algorithm in production compilers, but this feels a bit like fighting with language compilation model.</p>
<p>Unlike C++, Rust build is not embarrassingly parallel; the amount of parallelism is limited by length of the critical path in the dependency graph.
If you have 40+ cores to compile, this shows.</p>
<p>Rust also lacks an analog for the <a href="https://en.cppreference.com/w/cpp/language/pimpl">pimpl</a> idiom, which means that changing a crate requires recompiling (and not just relinking) all of its reverse dependencies.</p>
</div>
</div>
</dd>
<dt>Maturity</dt>
<dd>
<div>
<div>
<p>Five years old, Rust is definitely a young language.
Even though its future looks bright, I will bet more money on “C will be around in ten years” than on “Rust will be around in ten years”
(See <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a>).
If you are writing software to last decades, you should seriously consider risks associated with picking new technologies.
(But keep in mind that picking Java over Cobol for banking software in 90s retrospectively turned out to be the right choice).</p>
<p>There’s only one complete implementation of Rust — the <a href="https://github.com/rust-lang/rust/"><code>rustc</code></a> compiler.
The most advanced alternative implementation, <a href="https://github.com/thepowersgang/mrustc"><code>mrustc</code></a>, purposefully omits many static safety checks.
<code>rustc</code> at the moment supports only a single production-ready backend — LLVM.
Hence, its support for CPU architectures is narrower than that of C, which has GCC implementation as well as a number of vendor specific proprietary compilers.</p>
<p>Finally, Rust lacks an official specification.
<a href="https://doc.rust-lang.org/reference/">The reference</a> is a work in progress, and does not yet document all the fine implementation details.</p>
</div>
</div>
</dd>
<dt>Alternatives</dt>
<dd>
<div>
<div>
<p>There are other languages besides Rust in systems programming space, notably, C, C++, and Ada.</p>
<p>Modern C++ provides <a href="https://www.viva64.com/en/pvs-studio/">tools</a> and <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">guidelines</a> for improving safety.
There’s even a proposal for a Rust-like <a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf">lifetimes</a> mechanism!
Unlike Rust, using these tools does not <em>guarantee</em> the absence of memory safety issues.
However, if you already maintain a large body of C++ code, it makes sense to check if following best practices and using <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">sanitizers</a> helps with security issues.
This is hard, but clearly is easier than rewriting in another language!</p>
<p>If you use C, you can use formal methods to <a href="https://sel4.systems/Info/FAQ/proof.pml">prove</a> the absence of undefined behaviors, or just <a href="https://sqlite.org/testing.html">exhaustively test</a> everything.</p>
<p>Ada is memory safe if you don’t use dynamic memory (never call <code>free</code>).</p>
<p>Rust is an interesting point on the cost/safety curve, but is far from the only one!</p>
</div>
</div>
</dd>
<dt>Tooling</dt>
<dd>
<div>
<div>
<p>Rust tooling is a bit of a hit and miss.
The baseline tooling, the compiler and the build system
(<a href="https://doc.rust-lang.org/cargo/index.html">cargo</a>), are often cited as best in class.</p>
<p>But, for example, some runtime-related tools (most notably, heap profiling) are just absent — it’s hard to reflect on the runtime of the program if there’s no runtime!
Additionally, while IDE support is decent, it is nowhere near the Java-level of reliability.
Automated complex refactors of multi-million line programs are not possible in Rust today.</p>
</div>
</div>
</dd>
<dt>Integration</dt>
<dd>
<div>
<div>
<p>Whatever the Rust promise is, it’s a fact of life that today’s systems programming world speaks C, and is inhabited by C and C++.
Rust intentionally doesn’t try to mimic these languages — it doesn’t use C++-style classes or C ABI.</p>
<p>That means that integration between the worlds needs explicit bridges.
These are not seamless.
They are <code>unsafe</code>, not always completely zero-cost and need to be synchronized between the languages.
While the general promise of <a href="http://adventures.michaelfbryan.com/posts/how-to-riir/">piece-wise integration</a> holds up and the <a href="https://github.com/dtolnay/cxx">tooling</a> catches up, there is accidental complexity along the way.</p>
<p>One specific gotcha is that Cargo’s opinionated world view (which <em>is</em> a blessing for pure Rust projects) might make it harder to integrate with a bigger build system.</p>
</div>
</div>
</dd>
<dt>Performance</dt>
<dd>
<div>
<div>
<p>“Using LLVM” is not a universal solution to all performance problems.
While I am not aware of benchmarks comparing performance of C++ and Rust at scale, it’s not to hard to come up with a list of cases where Rust leaves some performance on the table relative to C++.</p>
<p>The biggest one is probably the fact that Rust’s move semantics is based on values (<code>memcpy</code> at the machine code level).
In contrast, C++ semantics uses special references you can steal data from (pointers at the machine code level).
In theory, compiler should be able to see through chain of copies; in practice it often doesn’t: <a href="https://github.com/rust-lang/rust/issues/57077">#57077</a>.
A related problem is the absence of placement new — Rust sometimes need to copy bytes to/from the stack, while C++ can construct the thing in place.</p>
<p>Somewhat amusingly, Rust’s default ABI (which is not stable, to make it as efficient as possible) is sometimes worse than that of C: <a href="https://github.com/rust-lang/rust/issues/26494#issuecomment-619506345">#26494</a>.</p>
<p>Finally, while in theory Rust code should be more efficient due to the significantly richer aliasing information, enabling aliasing-related optimizations triggers LLVM bugs and miscompilations: <a href="https://github.com/rust-lang/rust/issues/54878">#54878</a>.</p>
<p>But, to reiterate, these are cherry-picked examples, sometimes the field is tilted the other way.
For example, <code>std::unique_ptr</code> <a href="https://www.youtube.com/watch?v=rHIkrotSwcc&amp;feature=youtu.be&amp;t=1261">has a performance problem</a> which Rust’s <code>Box</code> lacks.</p>
<p>A potentially bigger issue is that Rust, with its definition time checked generics, is less expressive than C++.
So, some C++ <a href="http://eigen.tuxfamily.org/index.php?title=Expression_templates">template tricks</a> for high performance are not expressible in Rust using a nice syntax.</p>
</div>
</div>
</dd>
<dt>Meaning of Unsafe</dt>
<dd>
<div>
<div>
<p>An idea which is even more core to Rust than ownership &amp; borrowing is perhaps that of <code>unsafe</code> boundary.
That, by delineating all dangerous operations behind <code>unsafe</code> blocks and functions and insisting on providing a safe higher-level interface to them, it is possible to create a system which is both</p>
<div>
<ol>
<li>
<p>sound (non-<code>unsafe</code> code can’t cause undefined behavior),</p>
</li>
<li>
<p>and modular (different <code>unsafe</code> blocks can be checked separately).</p>
</li>
</ol>
</div>
<p>It’s pretty clear that the promise works out in practice: <a href="https://github.com/rust-fuzz/trophy-case">fuzzing Rust code</a> unearths panics, not buffer overruns.</p>
<p>But the theoretical outlook is not as rosy.</p>
<p><em>First</em>, there’s no definition of Rust memory model, so it is impossible to formally check if a given unsafe block is valid or not.
There’s informal definition of “things rustc does or might rely on” and in in-progress <a href="https://github.com/rust-lang/miri">runtime verifier</a>, but the actual model is in flux.
So there might be some <code>unsafe</code> code somewhere which works OK in practice today, might be declared invalid tomorrow, and broken by a new compiler optimization next year.</p>
<p><em>Second</em>, there’s also an observation that <code>unsafe</code> blocks are not, in fact, modular.
Sufficiently powerful <code>unsafe</code> blocks can, in effect, extend the language.
Two such extensions might be fine in isolation, but lead to undefined behavior if used simultaneously:
<a href="https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/">Observational equivalence and unsafe code</a>.</p>

</div>
</div>
</dd>
</dl>
</div>
<p>Here are some thing I’ve deliberately omitted from the list:</p>
<div>
<ul>
<li>
<p>Economics (“it’s harder to hire Rust programmers”) — I feel that the “maturity” section captures the essence of it which is not reducible to chicken and egg problem.</p>
</li>
<li>
<p>Dependencies (“stdlib is too small / everything has too many deps”) — given how good Cargo and the relevant parts of the language are, I personally don’t see this as a problem.</p>
</li>
<li>
<p>Dynamic linking (“Rust should have stable ABI”) — I don’t think this is a strong argument. Monomorphization is pretty fundamentally incompatible with dynamic linking and there’s C ABI if you really need to. I do think that the situation here can be improved, <a href="https://internals.rust-lang.org/t/a-stable-modular-abi-for-rust/12347/10?u=matklad">but I don’t think that improvement needs to be Rust-specific</a>.</p>
</li>
</ul>
</div>

</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/09/20/why-not-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536645</guid>
            <pubDate>Sun, 20 Sep 2020 19:27:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing the NYC Trip in “The Warriors” (2006)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24536427">thread link</a>) | @keiferski
<br/>
September 20, 2020 | http://www.stonegreasers.com/greaser/conclay.html | <a href="https://web.archive.org/web/*/http://www.stonegreasers.com/greaser/conclay.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="centernote"> 	
		<h3>Coney Island to The Bronx</h3>  
  		<p>"The Warriors" Movie: In 1979, the Street Gang the Coney Island Warriors made their Famous Trip - From Coney Island to Dyre Avenue/Eastchester in the Bronx - which would Change Their Lives Forever!. March 27, 2006, I Documented their Legendary Trip. "<em>It's still on, and we're going. Cyrus sent an emissary this afternoon to make sure. Cyrus don't want anybody packed or anybody flexing any muscle. So I gave him my word that the Warriors would uphold the truce. Everybody says that Cyrus is the one and only. I think we'd better go have a look for ourself</em>."</p>
		
<div><p><img src="http://www.stonegreasers.com/greaser/coney_station.jpg" alt="Its still and were going! Stillwells and Ocean Avenue Subway Station"> From Stillwells and Ocean Avenue, you take the Q Train to Union Square, that is where you catch the Number 5 Bronx train to Eastchester. 
		</p><p><span>"We ain't been to the Bronx before!"</span></p><p> <span>"No sweat! This Conclave is going to be a big item, every gang in the city is going to be there!"</span></p></div>

		<h2>The Big CI Coney Island</h2>
		<p><img src="http://www.stonegreasers.com/greaser/coney1.jpg" alt="Coney Island freak show building"><br>
      		<img src="http://www.stonegreasers.com/greaser/coney2.jpg" alt="Coney Island Neighborhood to the west from station">	
                <img src="http://www.stonegreasers.com/greaser/coney3.jpg" alt="Coney Island neighborhood to the North from the station">
      		<span>"We Fought All Night to Get Back to this?"</span></p>     	
  
    		<h2>Wonderwheel, The Cyclone, and the Observation Tower</h2>
		<div><p><img src="http://www.stonegreasers.com/greaser/q_train1.jpg" alt="From the Q Train, Coney Island and the Ocean">Q Train leaving Stillwells Station, you can see the world famous Cyclone Roller Coaster, the observation tower, the Wonderwheel, and the Ocean in the background. </p><p><span>"Were goin in there with nothing! Were goin in their like everybody else - nine guys, no weapons!"</span></p></div>
    
		<h4>At the Q line curve (East 16th Street) - Taggings on Buildings</h4>

         	<div><p><img src="http://www.stonegreasers.com/greaser/q_train2.jpg" alt="Around the curve, gang taggings on the buildings.">      The Q Train runs along Ocean Parkway, curves and heads up East 16th Street until it hits Prospect Park and runs along Flatbush Avenue.</p><p><span>"What do you know about Cyrus? He's the One and Only!" </span></p></div>
    
    		<h4>Union Square - 14th Street Station - Little Break in the Action</h4>
		<div><p><img src="http://www.stonegreasers.com/greaser/Union_sq.jpg" alt="Break in the action - the Gray Mime at Union Square">On my way down the ramp to pick up the Number 5 Bronx bound Lexington, I did not get delayed by the Punks or the Baseball Furies, but I did run into the Gray Lady Mime.</p><p><span>"You never what you're gonna run into. In our colours, we can't hide."<p>"Who wants to hide?"</p></span></p></div>

          	<h4>42nd Street - Grand Central Station</h4>
        	<div><p><img src="http://www.stonegreasers.com/greaser/lexington1.jpg" alt="The Lexington Number 5 Train"><span>"42nd Street - Next Stop!" </span></p><p>Made it to Grand Central. Now pick up the number 5 Bronx bound train.</p><p><span>"That's our train!" </span></p></div>
      
    		<h4>Lexington Number 5 Sights and Scenes</h4>    
      		<p><img src="http://www.stonegreasers.com/greaser/morris.jpg" alt="Bronx Morris Station">Morris Park Station - we are in the Bronx.  </p>
		<p><img src="http://www.stonegreasers.com/greaser/prospect.jpg" alt="Prospect Park Subway Station">Passing Prospect Avenue</p>
		<p><img src="http://www.stonegreasers.com/greaser/gunhill.jpg" alt="Gun Hill Subway station">Passing Gun Hill Road </p>
     
   		<h4>Dyre Avenue - Eastchester Final Stop</h4>
		<div><p><img src="http://www.stonegreasers.com/greaser/dyre.jpg" alt="Dyre Road Subway station">We made it! Dyre Avenue Station, the last stop on the Number 5. Now to make it to the Conclave to meet Cyrus.</p><p>Standing on the station platform, you can imagine the various gangs coming into the station and heading down the steps on their way to the Conclave.</p></div>
     
    		<h4>Scenes of the Dyre Avenue Hood</h4>
   		<p><img src="http://www.stonegreasers.com/greaser/dyre_station_3.jpg" alt="Dyre Road/Eastchester Subway Station">Eastchester Station </p>
          	<p><img src="http://www.stonegreasers.com/greaser/dyre_station_2.jpg" alt="Dyre Road Station - different angle photo">Not much in the way of a cemetery in the area, as I walked around looking for the Conclave. Today, the area seems to be desserted, or just a commuter stop. </p>
		<div><p><img src="http://www.stonegreasers.com/greaser/dyre_station_4.jpg" alt="Syre Road Subway station from a different angle">Picture taken from the Dyre Avenue Station platform.</p><p>Reminds me of the neighborhood the Orphans were from.</p></div>
     
    		<h4>Number 4 (Muggers' Express) Woodlawn Station</h4>
  		<p><img src="http://www.stonegreasers.com/greaser/woodlawn1.jpg" alt="Woodlawn Subway Station and Cementary">You have to wonder if the producer of the Warriors wanted us to imagine where the location of the Conclave was really at, because it seems like the Woodlawn line (aka. Muggers' Express), Route 4, would have been a better choice since across the street from the Woodlawn Station is the famous Civil War era Woodlawn Cemetery? </p>
  
		<h3>Retracing The Warriors By Subway Lines</h3> 
<ul>
<li>Looking at the MTA Subway Map, and considering that the map in the movie showed them taking the Number 5 Train to Eastchester, I would have to assume after the Warriors were chased by the Turnbull A.C's, they rode the Number 5 down as far as Morris Park before they were detoured by the subway line fire. That way they could walk to the Pelham Parkway Station and pick up the Number 2 line. If they were able to make it down as far as the 149th Street and Grand Concourse Station, they would be able to run between the B, D, 2, 4, 5, and 6 Lines. I assume that is what the Director wanted us to think. </li>

<li>After watching the Directors-cut DVD, you find that the producer wanted you to come to your own conclusion to the various questions that you have about the famous trip. He gave you the map on where the Warriors arrived, and I think the rest is up to
  	 your imagination on where the following events took place.</li>


<li>The subway map in "The Warriors" movie, showed that the "D", "M", "Q", and "B" trains made the Brighton Beach Coney Island loop. Today, the "B" train stops at Brighton Beach and the "M" train travels on the Fourth Avenue/New Utrecht line. The "Q" Train is the only train that still travels to Coney Island via the Brighton line. The trains that travel to and from Coney Island are the D, F, N, and Q lines. The N and D Trains connect to the number 4, 5, and 6 Bronx bound trains at the Broadway-Lafayette Street Station. The F Train connects to those lines at the Canal Street Station. The Q and the N Trains are the only two trains making the Union Square - 14th Street connection, but the Q train is the only one that swings out towards Brighton Beach from the Stillwell's station like the 1970 Subway map in the movie. The N train also runs through Bay Ridge instead of running either the Culver or Brighton Lines. Like the Fox said to Rembrant, "Nobody can read these maps anyways!"</li>
<li>I could not find Cyrus, the Turnbull A.C's, the Rogues, or the rest of the gangs at either location, but I wanted everyone to know - The Gaylords were there! <a href="http://www.stonegreasers.com/greaser/lords_of_kilbourn.html">"Lords of Kilbourn"</a></li>
<li><a href="http://www.scoutingny.com/the-new-york-city-filming-locations-of-the-warriors-ny-youve-changed/">New York City Filming Location for The Warriors</a> - Great website that takes you through the filming loacations in the movie.</li>
</ul>



        </div></div>]]>
            </description>
            <link>http://www.stonegreasers.com/greaser/conclay.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536427</guid>
            <pubDate>Sun, 20 Sep 2020 19:03:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sixty second stories of exceptional founders every 10 days]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24536331">thread link</a>) | @evla
<br/>
September 20, 2020 | http://tareksway.com/visionaries | <a href="https://web.archive.org/web/*/http://tareksway.com/visionaries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://tareksway.com/visionaries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536331</guid>
            <pubDate>Sun, 20 Sep 2020 18:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In the computer]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24535977">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | https://chris-martin.org/2020/in-the-computer | <a href="https://web.archive.org/web/*/https://chris-martin.org/2020/in-the-computer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When people talk about "algebraic reasoning", explanations fall flat because we neglect to first figure out kind of reasoning we're contrasting it against. When we write computer code using an operational model, we do <i>think about</i> what we write — so what manner of reasoning are we using? Can we give it a name? And can we explain why it seems so incompatible with the sort of reasoning that Lambda Man is always going on about?</p><p>I propose that the culture of programming at present may be divided into two approaches, explained by the following competing conceptions of the act of programming:</p><ol><li>An operational programmer <i>goes into</i> the computer;</li><li>An algebraic programmer remains <i>outside</i> the computer.</li></ol><p>We all have some need to shift between the two perspectives, but many of us become more entrenched in one or the other.</p><h2>Who calls the calls</h2><p>To start piecing together the orientation of each kind of programmer with respect to the computer, I'd like to look at a curious question of agency regarding function calls.</p><ul><li>When I write the expression "f x", I may describe my act of programming by saying that "we <b>apply</b> the function <i>f</i> to an argument <i>x</i>".</li><li>When the machine executes the program, I expect that "it will <b>evaluate</b> the function <i>f</i> at the argument <i>x</i>".</li></ul><p>But this separation between my action as an author and the machine's action as an automaton is only so distinct in the parlance of an algebraic programmer. If I were a Python programmer:</p><ul><li>When I write the expression "f(x)", I am "calling the function <i>f</i>".</li><li>When the machine executes my program, I expect that the Python interpreter will "call the function <i>f</i>".</li></ul><p>So who calls the function: me or Python? The answer is both; I <i>am</i> Python, and its actions are my actions, regardless of whether I am present and typing into a REPL or whether I have scripted them out ahead of time in a program that may run in my absence.</p><h2>One with the machine</h2><p>In either variety of programming, we sometimes put ourselves in the shoes of the machine to reason about the anticipated outcome of what we write. But how this imagination works depends on a great deal on whether we are outside or in. When we trace an operational program flow, the text of the program forms a space we can move within, and each variable is a statue that comes alive and begins to talk. Algebraic expression evaluation is a much more sterile and dull affair, and we remain seated in our desk chair. <i>Evaluating</i> is rewriting an expression in another form; it does not take us into different headspace from the one in which we wrote the code in the first place.</p><h2>Removing the lime from the coconut</h2><p>When an experienced inside-the-computer author begins in a programming language that forces us to approach programs from the outside, we can expect the question: If "I have an <code>IO String</code>", then "how do I get to the <code>String</code>"?</p><p>While others have already addressed this question in detail, what I want to draw attention to here is that the misunderstanding originates from trying to apply the <i>inside</i> conceptual mapping to a programming model that is strongly <i>outside</i>. An <code>IO String</code> is a process that produces a <code>String</code> result. So if I <i>were</i> standing inside a Haskell program, holding such a thing in my hands, it stands to reason that I could run the process and get the string. But we do not <i>have</i> such values because we do not <i>go</i> inside to <i>get</i> anything. We remain at the text editor, writing definitions. One such definition might be for a process which consists of the machine 1. first running some <code>IO String</code> process; and then 2. doing some other action with the resulting string.</p><p>This is not an unfamiliar task for a JavaScript programmer, who knows that one cannot get the value from a Promise — all we can do is set up plans for what to do once the Promise is fulfilled. A JavaScript programmer, although inside of the computer, is outside of the event loop. When my callbacks are roused, I do my work, then I fall back sleep to await another gig.</p><h2>What you got in that room</h2><p>The term "global variable" reveals something interesting about our mental picture. Such a variable does not span the globe, nor even a local network. To what scope does a word so grand as "global" refer? Humbly, the scope of a process. Or perhaps an entire machine, if I am a kernel developer. When I code operationally, I reside in a tiny world — the landmasses on my little blue marble are the memory segments to which I have access.</p><p>When I switched from operational to algebraic programming, first I learned that there are no global variables, then that terminology began to fade from consciousness altogether. As a Haskell programmer, I'm not in a little globe on the desk; I live on the Earth and I type definitions. Among those definitions may be a datatype that represents the state of a process, true. But this datatype is not my world, and the vast majority definitions I write in service of the program will not be functions of it.</p><p>Private "member variables" in a Java class can only be accessed <i>from within</i> the class. Perhaps the preposition can be taken to refer somewhat literally to the lexical scope of the class definition — that is, the code that is written between the opening and closing braces. But do we employ a deeper container metaphor here? Maybe this one is just me, but I see the <i>instance</i> as a <i>room</i>, and the members as the stuff I have at my disposal when I'm working inside that room.</p><p>In Haskell we also have lexical scoping, as well as a notion of modules with definitions that are either exported or not exported, which for many purposes mirrors the public/private field distinction. But I do not have the experience of mentally going inside a module in the same sense as reasoning inside of a Java instance. I believe it is Java's coupling of modules with mutable state that encourages this spacial reasoning.</p><h2>Getting your steps in</h2><p>When you use a step debugger, you actually <i>step into</i> the program! This is true regardless of whether you are using the debugging facilities of Python or Haskell. Though the code may be algebraic, when we use a step debugger we are always looking at it from an operational perspective.</p><h2>Working on documents</h2><p>Lately I like to refer to my role as "author" more than "programmer" — regardless of whether the file extension is ".md" or ".hs". It's because I don't feel like I work inside a computer anymore. I work sitting <i>at</i> a computer, I write <i>about</i> programs, and — although much of what I write can be executed by a machine — I do not often become lost within, because I remain safely on the outside.</p></div></div></div>]]>
            </description>
            <link>https://chris-martin.org/2020/in-the-computer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535977</guid>
            <pubDate>Sun, 20 Sep 2020 18:18:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need physical audio kill switches]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 430 (<a href="https://news.ycombinator.com/item?id=24535408">thread link</a>) | @stargrave
<br/>
September 20, 2020 | https://rubenerd.com/we-need-physical-audio-kill-switches/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/we-need-physical-audio-kill-switches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>(Update: I didn’t mention this concerned <strong>wired</strong> headphones).</p>
<p>I aggressively disagree with any computer design decisions that detract from ergonomics or health, and nowhere does this continue to remain bafflingly true than audio output. Strap in, I’m about to get a bit ranty!</p>
<p>If we encounter an unwanted audio signal emanating from our computers, especially an uncomfortably-loud one over headphones, we should <em>immediately</em> be able to terminate it. No exceptions. If there is any latency <em>whatsoever</em> between us hitting a mute button and the audio not cutting out, the hardware or software has failed. Crypton Future Media’s Hatsune Miku wouldn’t tolerate latency with her headphones, and neither should we.</p>
<p><img src="https://rubenerd.com/files/2020/miku-headphones@1x.jpg" srcset="https://rubenerd.com/files/2020/miku-headphones@1x.jpg 1x, https://rubenerd.com/files/2020/miku-headphones@2x.jpg 2x" alt=""></p>
<p>I was in a conference call last Friday where I’d adjusted the volume up to compensate for the client’s quiet microphone, only to be audibly shot in the ears by an auto-playing video on a website. There is a <em>lot</em> of problematic stuff to unpack there, much of which is not the fault of the audio hardware or OS. But shocked in the moment, I hit the mute button on my MacBook Pro Touchbar, and it took a solid two seconds for it to register. My ears were ringing throughout the whole call. <em>This is unacceptable.</em></p>
<p>Well-engineered mute buttons on keyboards shouldn’t need to go to software, they should immediately send a signal to the motherboard’s DAC—ideally on a separate wire or connection—to say <em>terminate this signal</em>. Then it’s less of a concern if it takes the OS a few seconds to react to the change, because our ears have been spared.</p>
<p id="just-ackchyually">The <em>just ackchyually</em> crowd would don their Captain Obvious capes and brightly-coloured underwear to proclaim that people could <em>just</em> unplug their headphones, or rip them off ones head when suddenly inundated with loud audio. Sure, and if you start getting electric shocks from your keyboard you could <em>just</em> use an external one, bro. Or if you get your hand caught in a mixer, <em>just</em> use your other hand, that’s why you have two of them. There are so many reasons why this dismissive attitude is specious, but even if it weren’t, it would still take more physical effort <em>than a button</em>. And if a mute button doesn’t fulfill the function for which it’s labelled and designed, what’s the point of it? But then, these people know all that, they’re just being obtuse.</p>
<p>We have valid privacy arguments advocating for physical Wi-Fi, camera, and microphone buttons; I’d say audio should be voiced in these discussions too. They should be heard. Sound ideas should be reverberated. Miku.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/we-need-physical-audio-kill-switches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535408</guid>
            <pubDate>Sun, 20 Sep 2020 17:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Printing on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24535357">thread link</a>) | @paedubucher
<br/>
September 20, 2020 | https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I have a roughly ten year old Brother HL-5370DW printer on the shelf next to me.
This printer is mostly used by my wife to print sewing patterns. When I was
studying computer science, I sometimes printed documents I've written for
proofreading. I often was able to find typos that I didn't see on the screen
even after proofreading the document two or three times. However, I didn't
bother to print out my bachelor thesis. Printing 120 pages just for proofreading
just seemed a waste to me. I did my proofreading on the screen extra carefully,
and nobody complained about typos. (Which doesn't mean that there were none.)</p>
<p>Having finished my studies, I hardly ever print out documents. However, I still
prefer to read long texts on paper rather than on the screen. Therefore I often
buy technical books as paperbacks or hardcovers rather than ebooks. And if I buy
an ebook with demanding content, I print out those sections for offline reading.</p>
<p>Having switched to OpenBSD for my private computing shifted my reading habits
more towards manpages. When I need to figure out how something works on
OpenBSD, <code>apropos(1)</code> beats Google as a starting point in many cases. Some
manpages are really long, for example <code>ksh(1)</code>. I have a book on the Korn Shell
in my basement, which covers <code>ksh93</code>.  However, there are some differences
between <code>ksh93</code> and OpenBSD's <code>pdksh</code>. So reading the manpage not only gives me
more accurate information, but also <em>less</em> to read.</p>
<p>So why not printing out the manpage <code>ksh(1)</code>? I can do so even nicely formatted
using PostScript:</p>
<pre><code>$ man -T ps -O paper=a4 ksh &gt;ksh.1.ps
</code></pre>
<p>Now <code>ksh.1.ps</code> can be read with <code>zathura(1)</code>, given that the package
<code>zathura-ps</code> is installed:</p>
<pre><code># pkg_add zathura zathura-ps
$ zathura ksh.1.ps
</code></pre>
<p>But why using PostScript and not PDF like anybody else for the last twenty five
years? Because PostScript is the least common denominator and, thus, supported
out of the box by OpenBSD. (For fancier printing options, check out <code>cups</code>, but
I'd like to keep it minimalistic for the moment.)</p>

<p>I figured out how to configure my printer by reading the section <em>The lpd
Printing Daemon</em> in the 16th chapter of <a href="https://nostarch.com/obenbsd2e">Absolute OpenBSD (2nd
Edition)</a> (p. 306-307) by <a href="https://mwl.io/">Michael W
Lucas</a>. This is how I applied the configuration to my local
setup.</p>
<p>First, I created the file <code>/etc/printcap</code> with the following content:</p>
<pre><code>lp|brother:\
    :sh=:\
    :rm=192.168.178.52:\
    :sd=/var/spool/output/brother:\
    :lf=/var/log/lpd-errs:\
    :rp=brother
</code></pre>
<p>There must be a newline at the end of the file. The line breaks are escaped
using backslashes, except for the last line. The options are defined as follows:</p>
<ul>
<li>The first line defines two names for my printer: <code>lp</code>, which should always be
  there, and <code>brother</code>, which is my arbitrary name for the printer.</li>
<li>The second line (<code>sh</code>) defines that no <em>burst page</em> (summarizing the last
  print job on a special page) should be printed.</li>
<li>The third line (<code>rm</code>) refers to the printer on the network. My FritzBox always
  gives the same IP to my printer. It's also possible to use the printer's
  hostname.</li>
<li>The fourth line (<code>sd</code>) defines the spooler directory for this printer. Print
  jobs are written into that directory.</li>
<li>The fifth line (<code>lf</code>) defines a log file for error messages, which you hopefully
  never need to check.</li>
<li>The sixth line (<code>rp</code>) defines the remote printer name.</li>
</ul>
<p>Next, the spooler directory needs to be created. It must be owned by the user
<code>root</code> and the group <code>daemon</code>. Regular users need write access to this directory
in order to print documents:</p>
<pre><code># mkdir /var/spool/output/brother
# chown -R root:daemon /var/spool/output/brother
# chmod 770 /var/spool/output/brother
</code></pre>
<p>Now the printer daemon <code>lpd</code> needs to be activated. To do so on system startup,
add the following line to <code>/etc/rc.conf/local</code>:</p>
<pre><code>lpd_flags=""
</code></pre>
<p>Then start the service:</p>
<pre><code># /etc/rc.d/lpd restart
</code></pre>
<p><strong>Update (2020-09-21)</strong>: As one reader on
<a href="https://news.ycombinator.com/item?id=24535357#24538879">Hacker News</a> pointed
out, the last two steps can be performed using <code>rcctl(8)</code>:</p>
<pre><code># rcctl enable lpd
# rcctl restart lpd
</code></pre>
<p>The manpage says that <code>rcctl(8)</code> was introduced in OpenBSD 5.7 back in 2015.
<em>Absolute OpenBSD (2nd Edition)</em> is from 2013 and, thus, older than that. (At
the time of this writing, I'm using Version 6.7.)</p>
<p>Another reader pointed out that setting the access rights to <code>777</code> is a bad
practice. That's true, and I actually got the reasoning behind this wrong: I
thought any user must be able to write to the spooler, because any user is
supposed to print. However, it's <code>lpd</code> that is writing to the spooler, which of
course runs under the <code>daemon</code> group. Therefore, the access rights for
<code>/var/spool/output/brother</code> should be set to <code>770</code>, not to <code>777</code> (as corrected
above).</p>

<p>Now the printer is ready to accept jobs. In order to print the PostScript file
generated before, just run <code>lpr</code> on the file:</p>
<pre><code>$ lpr ksh.1.ps
</code></pre>
<p>It's also possible to send the PostScript output directly to the printer (this
is Unix, after all), if no preview is needed:</p>
<pre><code>$ man -T ps -O paper=a4 ksh | lpr
</code></pre>
<p>Printing plain text files behaved strange on my setup, but could to using the
<code>pr</code> formatter with <code>lpr</code> as follows:</p>
<pre><code>$ lpr -p plain.txt
</code></pre>
<p>Instead, I also convert plain text files to PostScript, which looks quite nice
on paper. I use <code>enscript(1)</code> for this task:</p>
<pre><code># pkg_add enscript
$ enscript plain.txt -o plain.ps
$ lpr plain.ps
</code></pre>
<p>PDFs can also be converted to PostScript using <code>pdf2ps(1)</code>, which comes with
GhostScript, i.e. the <code>ghostscript</code> package:</p>
<pre><code>$ pdf2ps document.pdf document.ps
</code></pre>
<p>Unfortunately, this doesn't work with all PDFs. But for the time being, I have
enough manpages to read. Printing PostScript works extremely fast, by the way.
When I press return at the end of a <code>lpr</code> command, I can see the status LED on
my printer start blinking almost immediately.</p></div></div>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535357</guid>
            <pubDate>Sun, 20 Sep 2020 17:15:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tarsnap – cleaning up old backups]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24535046">thread link</a>) | @tosh
<br/>
September 20, 2020 | https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/ | <a href="https://web.archive.org/web/*/https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
<p>I use <a href="https://www.tarsnap.com/">Tarsnap</a> for my critical data. Case in point, I use it to backup my Bacula database dump. I use Bacula to backup my hosts. The database in question keeps track of what was backed up, from what host, the file size, checksum, where that backup is now, and many other items. Losing this data is annoying but not a disaster. It can be recreated from the backup volumes, but that is time consuming. As it is, the file is dumped daily, and rsynced to multiple locations.</p>
<p>I also backup that database daily via <span>tarsnap</span>. I’ve been doing this since at least 2015-10-09.</p>
<p>The uncompressed dump of this PostgreSQL database is now about 117G. </p>
<pre># ls -l bacula.dump 
-rw-r-----  1 10839  10839  125497737071 Sep  8 03:29 bacula.dump
</pre>
<p>Let’s look at recent usage by that host:</p>
<div id="attachment_6180"><p><a href="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png"><img aria-describedby="caption-attachment-6180" loading="lazy" src="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png" alt="tarsnap recent usaage" width="634" height="1024" srcset="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png 634w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-186x300.png 186w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png 747w" sizes="(max-width: 634px) 100vw, 634px"></a></p><p id="caption-attachment-6180">tarsnap recent usaage</p></div>
<p>The latest <span>Daily storage</span> value is 96G.</p>
<p>Using this command, I obtained a list of the archives stored:</p>
<pre>tarsnap --list-archives -vv &gt; ~/tarsnap-knew-archive-list
</pre>
<p>See <a href="https://www.tarsnap.com/man-tarsnap.1.html">man 1 tarsnap</a></p>
<p>I found 1751 archives, the oldest one was created on 2015-10-08 19:01:17.</p>
<p>This is a great example of <a href="https://www.tarsnap.com/deduplication-examples.html">Tarsnap deduplication and compression</a>.  I have 5 years of backups taking up only 96G and the latest backup is 113G.</p>
<p>By comparison, my other <span>tarsnap</span> backups take up this amount of space:</p>
<hr>
<table>
<tbody><tr>
<th>backup</th>
<th>size</th>
</tr>
<tr>
<td>bacula dump</td>
<td>96G</td>
</tr>
<tr>
<td>bacula configuration</td>
<td>13.7G</td>
</tr>
<tr>
<td>subversion</td>
<td>8G</td>
</tr>
<tr>
<td>supernews</td>
<td>32.5G</td>
</tr>
<tr>
<td>zuul-postgresql</td>
<td>0.18G</td>
</tr>
<tr>
<td>zuul-mysql</td>
<td>0.57G</td>
</tr>
<tr>
<td>zuul-pg02</td>
<td>5.7G</td>
</tr>
</tbody></table>
<hr>
<p>I’m going to trim down the dump archives, for sure.</p>
<p>I’m curious about that bacula configuration archive.  The Bacula configuration is only about 600K:</p>
<pre>$ cd /usr/local/etc/bacula
$ sudo du -ch .
608K	.
608K	total
$ </pre>
<p>Checking the archive list for that machine, I find 6 database backups from early October 2015.</p>
<p>Let’s delete those backups first. The names of those archives are:</p>
<pre title="">bacula.int.BaculaDatabase.2015-10-02
bacula.int.BaculaDatabase.2015-10-03
bacula.int.BaculaDatabase.2015-10-05
bacula.int.BaculaDatabase.2015-10-06
bacula.int.BaculaDatabase.2015-10-07
bacula.int.BaculaDatabase.2015-10-08
</pre>
<p>Let’s delete one:</p>
<pre># tarsnap -d -f bacula.int.BaculaDatabase.2015-10-02
                                       Total size  Compressed size
All archives                         196056412740      57482749453
  (unique data)                       50147278933      14694175940
This archive                          48831544077      14324291125
Deleted data                              2073099          1672760
# 
</pre>
<p>Let’s delete the rest (based on <a href="https://www.tarsnap.com/improve-speed.html">Delete multiple archives faster</a>:</p>
<pre>[dan@bacula:~] $ sudo tarsnap -d \
&gt; -f bacula.int.BaculaDatabase.2015-10-03 \
&gt; -f bacula.int.BaculaDatabase.2015-10-05 \
&gt; -f bacula.int.BaculaDatabase.2015-10-06 \
&gt; -f bacula.int.BaculaDatabase.2015-10-07 \
&gt; -f bacula.int.BaculaDatabase.2015-10-08
                                       Total size  Compressed size
All archives                         147224869967      43158468600
  (unique data)                       50147260360      14694156775
bacula.int.BaculaDatabase.2015-10-03      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          98393327194      28834187747
  (unique data)                       50147241787      14694137610
bacula.int.BaculaDatabase.2015-10-05      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          49561784421      14509906894
  (unique data)                       49265856159      14448990041
bacula.int.BaculaDatabase.2015-10-06      48831542773      14324280853
Deleted data                            881385628        245147569
                                       Total size  Compressed size
All archives                            314745728         65670242
  (unique data)                          19214507          4841679
bacula.int.BaculaDatabase.2015-10-07      49247038693      14444236652
Deleted data                          49246641652      14444148362
                                       Total size  Compressed size
All archives                            314744195         65668842
  (unique data)                          19212974          4840279
bacula.int.BaculaDatabase.2015-10-08             1533             1400
Deleted data                                 1533             1400
[dan@bacula:~] $ [dan@bacula:~] $ sudo tarsnap -d \
</pre>
<p>I won’t see the change in the ‘Recent account usage by machine’ page because that ‘updates shortly after midnight UTC’.  I’ll come back tomorrow.</p>
<p>In the meantime, I think I can delete all my old Bacula database backups from before 2020.  For fun, I will keep each backup from 01-01, and the oldest backup.</p>
<p>Here is how I can get that list from the existing file:</p>
<pre>[dan@knew:~] $ head /root/tarsnap-knew-archive-list 
bacula.int.BaculaDatabase.2020-08-13	2020-08-13 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-08-13 bacula.dump
bacula.int.BaculaDatabase.2018-08-17	2018-08-17 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-17 bacula.dump
bacula.int.BaculaDatabase.2018-11-08	2018-11-08 13:25:01	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-11-08 bacula.dump
bacula.int.BaculaDatabase.2020-07-08	2020-07-08 13:25:00	/usr/local/bin/tarsnap -c -f ˜tarbacula.int.BaculaDatabase.2020-07-08 bacula.dump
bacula.int.BaculaDatabase.2016-05-25	2016-05-25 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-05-25 bacula.dump
bacula.int.BaculaDatabase.2018-08-09	2018-08-09 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-09 bacula.dump
bacula.int.BaculaDatabase.2016-10-12	2016-10-12 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-10-12 bacula.dump
bacula.int.BaculaDatabase.2016-01-20	2016-01-20 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-01-20 bacula.dump
bacula.int.BaculaDatabase.2019-02-06	2019-02-06 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2019-02-06 bacula.dump
bacula.int.BaculaDatabase.2016-03-18	2016-03-18 13:25:04	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-03-18 bacula.dump
[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | head
bacula.int.BaculaDatabase.2020-08-13
bacula.int.BaculaDatabase.2018-08-17
bacula.int.BaculaDatabase.2018-11-08
bacula.int.BaculaDatabase.2020-07-08
bacula.int.BaculaDatabase.2016-05-25
bacula.int.BaculaDatabase.2018-08-09
bacula.int.BaculaDatabase.2016-10-12
bacula.int.BaculaDatabase.2016-01-20
bacula.int.BaculaDatabase.2019-02-06
bacula.int.BaculaDatabase.2016-03-18
[dan@knew:~] $ 
</pre>
<p>Oh wait, let’s sort that to get a proper range:</p>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | tail -2
bacula.int.BaculaDatabase.2020-09-05	2020-09-05 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-05 bacula.dump
bacula.int.BaculaDatabase.2020-09-07	2020-09-07 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-07 bacula.dump
[dan@knew:/root] $ 
</pre>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | head -2
bacula.int.BaculaDatabase.2015-10-08	2015-10-08 19:01:17	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-08 bacula.dump
bacula.int.BaculaDatabase.2015-10-09	2015-10-09 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-09 bacula.dump
</pre>
<p>Backups going back 5 years. Yeah, that might be a bit excessive, even for me. I usually keep them for three years at home.</p>
<p>Knowing that, let’s select the entries I want to keep:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -e '-01-01|2015-10-08' | sort
bacula.int.BaculaDatabase.2015-10-08
bacula.int.BaculaDatabase.2016-01-01
bacula.int.BaculaDatabase.2017-01-01
bacula.int.BaculaDatabase.2019-01-01
bacula.int.BaculaDatabase.2020-01-01
[dan@knew:~] $ 
</pre>
<p>I sorted the output just to make it easier.</p>
<p>Now, dump everything else, by using <span>-v</span>, into a file:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1746 tarsnap-volumes-to-delete
</pre>
<p>Oh wait, I forgot to exclude 2020</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08|bacula.int.BaculaDatabase.2020' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1503 tarsnap-volumes-to-delete
[dan@knew:~] $ 
</pre>
<p>I used an editor to quickly modify that file to look like this:</p>
<pre>[dan@knew:~] $ head tarsnap-volumes-to-delete 
#!/bin/sh
-f bacula.int.BaculaDatabase.2018-08-17 \
-f bacula.int.BaculaDatabase.2018-11-08 \
-f bacula.int.BaculaDatabase.2016-05-25 \
-f bacula.int.BaculaDatabase.2018-08-09 \
-f bacula.int.BaculaDatabase.2016-10-12 \
-f bacula.int.BaculaDatabase.2016-01-20 \
-f bacula.int.BaculaDatabase.2019-02-06 \
-f bacula.int.BaculaDatabase.2016-03-18 \
-f bacula.int.BaculaDatabase.2018-01-15 \
[dan@knew:~] $ 
</pre>
<p>This delete will take a while so I started a <span>tmux</span> session.  I did a <span>chmod +x</span> on the file.</p>
<p>I started the command and went on to do other lines.  It is deleting 1500 archives. It will be a few hours at least I think.</p>
<pre>[dan@knew:~] $ time sudo ./tarsnap-volumes-to-delete
</pre>
<p>I wish I sorted that list. I’d know easily where we were.</p>
<p>I know we are on <span>bacula.int.BaculaDatabase.2018-08-19</span> which is line 836 of 1505.</p>
<pre> $ ps auwwx | grep tmux
dan        78234   0.0  0.0   14344    5872  -  Is   13:15       0:00.36 tmux: server (/tmp//tmux-1001/default) (tmux)
</pre>
<p><span>tmux</span> was started at 13:15 and it is now 20:49 – so that’s 7.5 hours to get about half-way through. This should finish overnight.</p>
<p>Night passes….</p>
<p>The next morning I found:</p>
<pre>real    819m10.118s
user    372m34.315s
sys     3m23.045s
</pre>
<p>That is 13 hours and 40 minutes, or about 18 every 10 minutes.</p>
<p>I want to compare before and after disk usage, but I may have to wait until 0000 UTC when the statistics are updated.</p>
<p>The next day (2020-09-10), I found these …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</a></em></p>]]>
            </description>
            <link>https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535046</guid>
            <pubDate>Sun, 20 Sep 2020 16:43:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laid Off, Now What?]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 355 (<a href="https://news.ycombinator.com/item?id=24534685">thread link</a>) | @bbhat
<br/>
September 20, 2020 | https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html | <a href="https://web.archive.org/web/*/https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>As an immigrant on an H1B, you have exactly 60 days to find a new job when you are laid-off. This is a very short window of time to explore and land any job, let alone a job that matches your skills and interests. I found myself in this situation along with many others when Uber announced <a href="https://www.theverge.com/2020/5/18/21262337/uber-layoff-3000-employees-covid-19-coronavirus">layoffs</a> earlier this year. The following is a recollection of some things that worked well for me during my eventually successful job hunt.</p>
<ul>
<li><a href="#always-be-prepping">Always be Prepping</a></li>
<li><a href="#reach-out-to-everyone">Reaching Out</a></li>
<li><a href="#interview-preparation">Interview Preparation</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<h3 id="always-be-prepping">Always be prepping</h3>
<p>Coding interviews are hard to crack if you haven't been prepping, so I was lucky that I had been spending roughly 3-4 hours every week on <a href="http://leetcode.com/">leetcode</a>, from about 2 months before the layoff rumours broke. I was lucky that</p>
<ul>
<li>I knew that I wanted to change jobs in any case and</li>
<li>Rumours of layoffs broke approximately a month before the actual layoffs happened, giving me more lead time to prepare and send out emails to recruiters and friends.</li>
</ul>
<p>Whenever there's an economic downturn, I think it's critical to be acutely aware of what's happening at the company and start preparing for job interviews right away.</p>
<h3 id="reach-out-to-everyone">Reach out to everyone</h3>
<p>One of the hardest things to do when you are laid off is to write to your friends and family seeking help. But if there's ever a time to swallow your pride, then this is it. I reached out to everyone I knew, and told them plainly about my situation, and asked to be recommended to specific roles at their companies, or to tell their friends who may be hiring. I am extremely grateful to the help I got from my network, and the kind messages that I received. So many friends wrote to make sure I was okay, and kept checking in throughout the interview process, and they all have my immense gratitude.</p>
<p>It is tempting to just apply on the careers page when you find relevant roles at a company instead of spending time on finding connections and reaching out to them, but in my experience, it was very much worth it. Response times from recruiters was roughly 1-2 days when I was referred by an employee, whereas applying on the careers page was a hit or miss. One BigCo. took 40 days to respond, while some smaller companies were much quicker (3-4 days).</p>
<h4 id="the-process">The Process</h4>
<p>In terms of companies, cast a wide net because you absolutely need <em>a</em> job before a deadline. The steps are the obvious ones:</p>
<ol>
<li>Make a list of companies</li>
<li>For each company, compile a list of open job profiles that are relevant.</li>
<li>Email/Text a connection at the company, or apply on the careers page if all else fails.</li>
</ol>
<p>I think I reached out to an initial list of 10 companies or so on the day news of the layoffs broke. This worked well because there's at least a week's time before you speak to a hiring manager or interviewer from when you reach out, so there's ample time to prepare.</p>
<p>What companies to reach out to? In my case, it was the usual suspects (FAANG), and then some domain specific ones such as autonomous vehicle companies. The two most common roles that I applied to were:</p>
<ul>
<li><strong>Machine Learning Engineer</strong> - This is a hybrid role with ML + Software Engineering skills needed, and job roles usually talk about some specific domain such as recommendation systems, or in the case of autonomous vehicles, things such as perception or object detection. I typically looked for some mention of Computer Vision, NLP and deep learning.</li>
<li><strong>Machine Learning Infra Engineer</strong> - This role tends to be more on the software systems side, and deals with the infra for training and serving ML models for production workloads.</li>
</ul>
<h3 id="interview-preparation">Interview Preparation</h3>
<ul>
<li><a href="#an-initial-screen-with-the-hiring-manager">Hiring Manager Screen</a></li>
<li><a href="#coding-interviews-phone--onsite">Coding Interviews</a></li>
<li><a href="#machine-learning-interviews">Machine Learning Interviews</a></li>
<li><a href="#behavioral-interviews">Behavioral Interviews</a></li>
</ul>
<p>Interviewing for ML specific roles typically involves a few different kinds of interviews, each of which needs specific preparation. I'm outlining the most common ones I saw below:</p>
<h3 id="an-initial-screen-with-the-hiring-manager">An initial screen with the hiring manager</h3>
<p>Companies that do general interviews (Google / Facebook) don't have this step, but most others do. I personally like this, because it means that you are interviewing for a specific position in a specific team, and there's a high level of engagement from the beginning. Most of these calls were about getting to know me, and making sure I have relevant work experience, while some of them also were rapid fire technical questions. The latter ones were rare, and I encountered them when the manager wasn't certain that I was the right person for the job. In my experience, the introduction is the most important part of this interview (<strong>Tell me about yourself</strong>), and it helps to have prepared intros for each type of role that you are applying to. The idea is to tailor your story to highlight aspects of your work experience that are relevant to the job role. The next most important question is "<strong>What would you like to do in your next role?</strong>". Again, it helps immensely to be prepared to answer this question, and ideally, in a way so that there's reasonable overlap between your answer and what the role offers. Being able to answer this question also provides clarity to the job search process. For example, a consistent theme for me was to be (a) in an impactful / critical role for the company and (b) continue to work with the latest in ML.</p>
<p>Writing and rehearsing your stories often seems unimportant when compared to more tangible preparation steps such as spending time on leetcode, but I believe that it was critical, because it sets the tone and gives you confidence that you have done this in the past, and done it well, and there's no reason for the interviewer to doubt your abilities.</p>
<h3 id="coding-interviews-phone--onsite">Coding Interviews (Phone / Onsite)</h3>
<p>These are the standard leetcode style coding interviews, done using coderpad, or some similar service. The template for these is consistent across all companies, and involves 1 or 2 coding questions (or 1 question with follow-ups) that you are expected to implement and test. Some tips that were helpful for me preparation:</p>
<ol>
<li><strong>Get a premium subscription with leetcode</strong> - It is nice to be able to filter by companies and have access to the entire question bank, and it is good karma. The service is valuable and the creators should be compensated.</li>
<li><strong>Simulate the interview setting as much as possible</strong> - For example, I would set aside a 3 hour block of time for leetcode, shut myself in a room, and do 4 questions, 45 minutes each. If you are unable to solve a question in 45 minutes, you still move on to the next one. No extensions or looking at the solution. Think of it like moving on to the next interviewer. After the 3 hour session is done, go back to the questions as needed, either to look at solutions or to understand them better. A question is <code>Done</code> when your solution passes all the tests on leetcode and is <code>Accepted</code>.</li>
<li><strong>Talk out loud</strong> - This is big. Again, assuming that you are in an actual interview, talk out loud about the process you are using during these practice sessions. Talking out loud helps massively because you are forced to put your current train of thought into words, and it is often evident when a solution isn't justifiable.</li>
<li><strong>How to pick questions?</strong> - I filtered for questions that were tagged <code>Hard</code>, and then picked at random. No filter for company, or problem type. I went from doing all Mediums to a mix of Mediums and Hard to all Hards over a span of 4-5 weeks.</li>
<li><strong>How many questions to do?</strong> - In the first 2-3 weeks of my prep, I was doing 4 questions on one of the weekend days, and once I had more time post the lay-off news, it was 4 questions every 3 days or so. Overall, my stats look so:</li>
</ol>
<p><img src="https://bharathpbhat.github.io/assets/images/leetcode_xp.png" alt="Leetcode stats"></p>
<h3 id="machine-learning-interviews">Machine Learning Interviews</h3>
<p>These typically come in two flavors:</p>
<h4 id="concepts--basics">Concepts / Basics</h4>
<p>These are kind of like rapid fire questions where the interviewer will quiz you about ML basics. Some questions that I recall right now, to give a flavor of things:</p>
<pre><code>- What are some unsupervised learning methods?
- What is underfitting / overfitting?
- What is batch normalization? What's the motivation behind it?
- What is dropout? 
- What optimizers have you used? And typically some follow-up like, why does momentum make sense?
- What are some object detection techniques / papers that you are familiar with? (Computer Vision specific)
- What are decision trees? 
- How does logistic regression work?
- How do you train a linear regression model?
- What are some loss functions that you are familiar with?
- Why does Cross Entropy loss make sense?
- What are residual networks?
</code></pre>
<p>These are usually follow up questions where the interviewer will try to dig deeper into these concepts, often picking on some portion of the initial answer.</p>
<p>I did a lot of reading, and then some writing with a pen and paper for this part of the interview. If I am already somewhat/fairly familiar with a topic, like say, object detection, then my process was:</p>
<ol>
<li><strong>Write</strong> from memory a summary of what I remember about the topic</li>
<li>Note down <strong>questions</strong> for the parts that I am not clear about</li>
<li><strong>Read</strong> about the topic, and fill in whatever I missed on first go.</li>
</ol>
<p>If I don't remember much about a topic at all, like say, multi-armed bandits, then I would do step (3) first, and then do steps (1) and (2) a few days later, and eventually repeating step (3) as needed.</p>
<p>It helps to start with a list of topics that you want do this for. This list will grow as you remember more topics or expand the list of companies you are interviewing at. For reference, the list of topics I looked at is <a href="https://bharathpbhat.github.io/assets/files/index_card.pdf">here</a>, and a sample of the handwritten notes I made is here, for <a href="https://bharathpbhat.github.io/assets/files/rec_sys.pdf">recommendation systems</a>.</p>
<h4 id="ml-system-design">ML System Design</h4>
<p>This is my favorite interview, and corresponds neatly to skills used day to day as a ML practitioner. These are typically open ended interviews where the candidate is expected to design a product with some ML at its core. For example, things like:</p>
<pre><code>- Let's build a model that ranks photos in your photo library based on quality.
- How would you build a model that identifies pedestrians from drone imagery?
- Let's build a model that can does face detection for a user's photo library.
- How do you build a model that automatically picks out …</code></pre></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</a></em></p>]]>
            </description>
            <link>https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534685</guid>
            <pubDate>Sun, 20 Sep 2020 15:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is unauthenticated encryption insecure?]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24534619">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/ | <a href="https://web.archive.org/web/*/https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Cryptography is a complex subject. There are many subtle issues that can be introduced if you don’t know what you are doing.</p>



<p>There is a common mantra: “don’t roll your own crypto”. This is because both inexperienced and experienced developers frequently build cryptographic systems that are insecure.</p>



<p>However, there has to be a line – when does it start becoming “rolling your own”? Particularly in embedded systems, there are times when custom protocols need to be used, and developers stray into the dangerous area of cryptography.</p>



<p>One of the most common mistakes we have seen is the use of unauthenticated encryption.</p>



<h3>What is encryption?</h3>



<p>Encryption is encoding a plaintext into a ciphertext using a key, with the goal of keeping the plaintext confidential.</p>



<p>Only someone with the correct key should be able to decrypt the ciphertext and turn it back into plaintext.</p>



<p>Encryption provides confidentiality. It stops someone working out what the message is.</p>



<h3>So what’s the issue?</h3>



<p>An attacker can modify the ciphertext and cause the plaintext to change. There is no inherent means in encryption to detect this change.</p>



<p>Encryption does not provide authenticity. You cannot check that the message is genuine and has not been tampered with.</p>



<h3>What can an attacker do with this?</h3>



<p>I’m going to describe one attack against unauthenticated encryption.</p>



<p>Many encryption algorithms only operate on fixed-size blocks of data – they are called <a href="https://en.wikipedia.org/wiki/Block_cipher">block ciphers</a>. To encrypt longer lengths of data, a <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">mode of operation</a> is used to apply the block cipher repeatedly.</p>



<p>One mode of operation is called <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)">CBC</a> (Cipher Block Chaining). When encrypting the data, the previous ciphertext block is mixed into the current plaintext block using an operation called “<a href="https://en.wikipedia.org/wiki/Exclusive_or">exclusive OR</a>“. This is denoted with the + in a circle in diagrams.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/CBC_encryption.svg" alt=""></figure>



<p>There is also an input called the initialisation vector, or IV. This is a random input to the algorithm, and is intended to ensure that the ciphertext is different, even if the same plaintext is encrypted. This prevents leaking information about the content.</p>



<p>The initialisation vector is transmitted alongside the ciphertext.</p>



<p>Decryption is similar. The previous ciphertext block is exclusive ORed with the output of the block cipher to obtain the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/1200px-CBC_decryption.svg.png" alt=""></figure>



<p>Exclusive OR is a deterministic operation. If we look at a single bit, then it operates as follows:</p>



<figure><table><tbody><tr><td>A</td><td>B</td><td>Output</td></tr><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td></tr></tbody></table></figure>



<p>I always think of this as “if one input is high, invert the other input, otherwise leave it alone”.</p>



<p>The operation is carried out for each bit in a byte.</p>



<pre><code>A: 0 1 0 1 1 0 0 1 (0x59)
B: 1 1 1 1 0 0 0 0 (0xF0)
O: 1 0 1 0 1 0 0 1 (0xA9)</code></pre>



<p>What this means is that modifying one of the inputs to exclusive OR results in a predictable change to the output. And the operation can be easily reversed.</p>



<pre><code>A: 0123456789ABCDEF
B: FFFF00FFF00F0FF0
O: FEDC459879A4C21F</code></pre>



<p>If we now exclusive OR the output with one of the inputs:</p>



<pre><code>A: FEDC459879A4C21F
B: FFFF00FFF00F0FF0
O: 0123456789ABCDEF</code></pre>



<p>Hopefully that explains exclusive OR.</p>



<p>Let’s look back to how CBC uses this in decryption. In the first block, the IV is exclusive ORed with the output of the block cipher. The IV is transmitted alongside the ciphertext and an attacker can modify both at at will.</p>



<figure><img loading="lazy" width="922" height="786" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png 922w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-300x256.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-768x655.png 768w" sizes="(max-width: 922px) 100vw, 922px"></figure>



<p>We can encrypt the string “A dog’s breakfast” using a key and the initialisation vector of all 0x00 (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=QSBkb2cncyBicmVha2Zhc3Q">here</a> on CyberChef).</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Plaintext: A dog's breakfast
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50</code></pre>



<p>Of course, this can be decrypted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef).</p>



<p>If I change just one byte in the ciphertext, the entire message is corrupted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMmQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on Cyberchef). There’s no way for me to predictably modify this plaintext by changing the ciphertext.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Ciphertext: c7b2d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: .L...Q½êU...ì7Ò.t</code></pre>



<p>But the attacker also has control over the IV. Let’s set the first byte of the IV to 0xFF (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'FF00000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef). Only the first byte of the plaintext has changed!</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  FF00000000000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: ¾ dog's breakfast</code></pre>



<p>And it has changed predictably. The capital A (ASCII 0x41) has been exclusive ORed with 0xFF to become 0xBE (which decodes as ¾ although it’s above the normal ASCII range).</p>



<pre><code>A: 0 1 0 0 0 0 0 1 (0x41)
B: 1 1 1 1 1 1 1 1 (0xFF)
O: 1 0 1 1 1 1 1 0 (0xBE)</code></pre>



<p>This is a very high level of control! The attacker can now modify the plaintext without detection. Let’s try and significantly change the meaning of it.</p>



<p>The original message contained “A dog’s breakfast”. Can we change this canine feast into a feline one?</p>



<p>We exclusive OR the original plaintext with the desired one (<a href="https://gchq.github.io/CyberChef/#recipe=XOR(%7B'option':'UTF8','string':'The%20cat%5C's%20breakfast'%7D,'Standard',false)To_Hex('Space',0)&amp;input=VGhlIGRvZydzIGJyZWFrZmFzdA">here</a> on CyberChef). Notice how the output only has value for the characters we have changed.</p>



<pre><code>Original: A. .d.o.g.'.s. .b.r.e.a.k.f.a.s.t.
Original: 4120646f67277320627265616b66617374
Desired:  A. .c.a.t.'.s. .b.r.e.a.k.f.a.s.t.
Desired:  4120636174277320627265616b66617374
Output:   0000070e13000000000000000000000000</code></pre>



<p>Pop that output in as the IV to the decryption, and we’ve successfully changed the message (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000070e13000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">CyberChef</a>). All of this without even knowing the key.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000070e130000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: A cat's breakfast</code></pre>



<p>Of course, the attacker needs to have knowledge of the plaintext to make use of this attack. However, it’s extremely common for some or all of the message to be known. For example, when we visit most websites, the first part of the response will be “HTTP/1.1 200 OK”. If this was only protected by CBC encryption, we could change that to “HTTP/1.1 404 No”, changing the behaviour of the browser (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'00000000000000000006000000012400'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=ZGJkY2FkYWZjYjQ5NTJiNDE0OTBhODM4NDFhYzgxZGE">CyberChef</a>).</p>



<p>This doesn’t just impact the first block of data either. After the first block, instead of the IV, the previous ciphertext block is used in the exclusive OR operation. The attacker can modify the ciphertext and end up controlling the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/2880px-CBC_decryption.svg.png" alt=""></figure>



<p>This comes at a cost though – the previous plaintext block will be totally corrupted as a result.</p>



<p>To illustrate this, we can encrypt a longer block of text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=VGhpcyBpcyBvdXIgd29ybGQgbm93Li4uIHRoZSB3b3JsZCBvZiB0aGUgZWxlY3Ryb24gYW5kIHRoZSBzd2l0Y2gsIHRoZQpiZWF1dHkgb2YgdGhlIGJhdWQuICBXZSBtYWtlIHVzZSBvZiBhIHNlcnZpY2UgYWxyZWFkeSBleGlzdGluZyB3aXRob3V0IHBheWluZwpmb3Igd2hhdCBjb3VsZCBiZSBkaXJ0LWNoZWFwIGlmIGl0IHdhc24ndCBydW4gYnkgcHJvZml0ZWVyaW5nIGdsdXR0b25zLCBhbmQKeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2UgZXhwbG9yZS4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2Ugc2VlawphZnRlciBrbm93bGVkZ2UuLi4gYW5kIHlvdSBjYWxsIHVzIGNyaW1pbmFscy4gIFdlIGV4aXN0IHdpdGhvdXQgc2tpbiBjb2xvciwKd2l0aG91dCBuYXRpb25hbGl0eSwgd2l0aG91dCByZWxpZ2lvdXMgYmlhcy4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLgpZb3UgYnVpbGQgYXRvbWljIGJvbWJzLCB5b3Ugd2FnZSB3YXJzLCB5b3UgbXVyZGVyLCBjaGVhdCwgYW5kIGxpZSB0byB1cwphbmQgdHJ5IHRvIG1ha2UgdXMgYmVsaWV2ZSBpdCdzIGZvciBvdXIgb3duIGdvb2QsIHlldCB3ZSdyZSB0aGUgY3JpbWluYWxzLg">here</a> on CyberChef).</p>



<p>Let’s change “baud” to “cats”. We need to locate the correct place in the ciphertext. AES (the encryption algorithm we are using) works in 16 byte blocks. The word “baud” is 85 characters in, so in the 6th block. We therefore want to modify the 5th block of ciphertext.</p>



<p>The exclusive OR is a bit more complex than last time – we now need to exclusive OR the ciphertext, the original text, and the desired text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=MTkxNWRkOGU4ODBhN2JlZjgzN2Y1NDRlMzBlZGI5YmQxMjA3ZjMwMmRjM2NlZGQwY2I2NGJkY2JiOTk3YjVkYmM4M2RhNjU3MmZkNmMyMDVmOGQ4ZDI2NjQ5MmQyMDY3M2U0NGZhNzUwNGU2YzY0ZTI4M2E2NzI2MmIyYzMwNjM4OGI4ZjQyZTBmYjMxNzdmNmFmMTNlMWE0OGUxNDBmYTFhNDhmMThmZGYyNTc3MzgwMTUwYzM5ZDIwZTYyY2QzMzQ1ZDVmNTFiYzU4NDU2NGUwMzc5MTFkYTM1MTc3YjVkY2ZmOTkxZTRmYzg3NDFlYmJjMmRmM2I2YTc3OGViOTU3MTI1MmQxYTY0Yjk5NmRhOWFkMzFmNGE5MTI3NjM0M2FhMmU1ODQ1NjEyOTM1MDg0Zjc3Y2FhMmRiNDRiYTM5OTA5NzFkOTcwZWVlMjFlZDc3MjRiOWU3MDMwODEyZWI4N2U1ZDVmYmI3Y2M1MGE1NzYxNDBiN2I0NzhiYmZiNzU1MGU1MWU3ZmM0ZTg5ODExY2Y4MTg1OTJjNGY4ZWU3NGIyNTQ0Y2VhMGE4ZDdkZjM0OTE2YjIzYmMwOWIxYWJhN2IwN2ZlNDM0YWRjNjY5MzhhNzczMDU4MjNhYzdkMWJjZmEwOGNlOTRhYzc0MjUzNjdiODQwMGE5NGFlMDc0ZTFhY2NmZDkwYThjNDllYmYzNDNkMmU4YWQ5MmI2NDZlZDM0OTM4Yzg3NTI2MDUyYjA4ZjQ1MzgxMWQ4YTYyZjE2MzczMzkxZmE4YTBlZGIwZDJlZDBhYWQyNDViY2RlZmI1YTk0ZmRmZTBkNzA4YTMwYTVjZDVlZmI5ZjExNTk3MDU2NWFiMjg1ZGUyY2FlYWNkMTI3YzBhNzhkZDRjNmE4Y2U2NjRjYTFiOWI0YjI1ODk0MTYxMmUzMjgwOWEwNGRhYzIxODlkNGVkN2Q2ZDU4ZDcwMGNlODM5NTIzYzlmNTZiOGU2YWY1NGIzYjMxYjAxM2E4ODM4MjljM2Y0YTJhZmI3Mzc3OTFjNjBiN2E1N2I4NGNhOTgxYjFiM2E3N2M2YmI5ZWNiMzIwNzk3YmVhNzAyMDk5NGUwNzRmYmQ1NzM0MWQwMmVjYTY3ZWM1NWU5YzA1MmFkODA3NjUzMmUxZTI4MDJjMzc2YmRhMzg1NWIxYzYzY2FhNzRhZmI0YTRjNTFkMDNlNGZiMjEzY2ZiMTM4YjcxMTc1NzFhNTIzOTQzZGU1MWJiNzZiYTgwMzY2MDNkNDI2NmFmMzI3MGMyYjBhOTNjZDdlYzkyZmVjMjA0MTAyYjJkYWZlNDliMzUwZDFhNDk2NjVhYjE0MTFiMjhkZWQ1MmE5ZWE5NTA3ZWU5ZDljM2M0NzI4ZDBlNTk0YjEzM2VkMmRiOGUwYWQxZjBjZWM0NWRhYjJlN2Y1ODE5YTQyNWQ4NTY2ZWQ5MGQwYzI4MTMzZjlkZTM4ODQ4OTE3NjJhYTcxMzc2MjZmNmM2MTEzMDY4M2NkNWEzYmFjN2EzNTFkZDY0MjZjYzI2NzdjOGRjYWI0ZDMwZjg0OGNiZjYwOTBmMjM4MDM2ZTFlMzczMGZmODc4MTk2YWYyMjg4YWY5MTU5ZThkZA">here</a> on CyberChef). But change those 4 bytes, and we change the word “baud” to “cats”.</p>



<figure><img loading="lazy" width="1024" height="272" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png 1024w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-300x80.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-768x204.png 768w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1536x407.png 1536w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54.png 1682w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The only issue is, as expected, the previous block has been entirely corrupted. Whilst in this case, it’s made part of the message nonsensical, it frequently has no impact when carrying out attacks.</p>



<h3>But there are worse problems?</h3>



<p>The above issue allows an attacker to modify the plaintext without detection. This would be an issue in certain situations, such as lock/unlock messages to a door.</p>



<p>But not authenticating your encryption can lead to worse issues. A type of attack called <a href="https://en.wikipedia.org/wiki/Padding_oracle_attack">padding oracle attacks</a> can let an attacker obtain the plaintext by sending a large number of specially crafted packets.</p>



<p>Block ciphers only operated on fixed blocks. If the data is shorter than a block, it must be padded. There are a number of ways of doing this, such as appending the number of padding bytes (e.g. 0x02 0x02 or 0x05 0x05 0x05 0x05 0x05). The process of decryption may check this padding is correct or not, and respond differently in each case. </p>



<p>An attacker can exploit these differential responses to leak the plaintext. This can break the confidentiality of messages.</p>



<h3>What’s the solution to this?</h3>



<p>Encryption should always be authenticated. There are two common solutions to this:</p>



<ul><li>Add a <a href="https://en.wikipedia.org/wiki/Message_authentication_code">Message Authentication Code</a> (MAC). This is a keyed cryptographic checksum that provides authenticity and integrity.</li><li>Use an authenticated mode of operation such as <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Galois/Counter_(GCM)">GCM</a>.  </li></ul>



<p>Even with this advice, there are many pitfalls. Applying the authentication and encryption in the wrong order can lead to weaknesses; this is so common that it has been deemed the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>.</p>



<p>Generally, developers shouldn’t be working with cryptography at this level unless they are suitably skilled. That’s easy to say, harder to put into action. There is a big movement to make use of secure-by-default cryptographic libraries and APIs that provide developers with useful functions without giving them so much rope they can hang themselves.</p>



<p>There are scant few reasons for not authenticating encryption.</p>
			</div></div>]]>
            </description>
            <link>https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534619</guid>
            <pubDate>Sun, 20 Sep 2020 15:42:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Backblaze tracking me?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24534572">thread link</a>) | @gingerlime
<br/>
September 20, 2020 | https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-2612">
		<!-- .entry-header -->

	
	<div>
		
<p>This is a follow-up to my previous post: <a href="https://blog.gingerlime.com/2020/hey-com-is-onto-something-with-its-tracking-pixel-blocker/">hey.com is onto something with its tracking-pixel blocker</a>. I mentioned contacting Backblaze about their email tracking there. </p>



<div><figure><img loading="lazy" width="630" height="396" src="https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12.png" alt="" srcset="https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12.png 630w, https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12-300x189.png 300w" sizes="(max-width: 630px) 100vw, 630px"></figure></div>



<p>I didn’t think too much of it at the time, and honestly (or naively?) was expecting some kind of a “Oh, yes, you’re right, there’s no need to track those emails”… But it didn’t unfold in quite the same way.</p>



<h2>TL;DR</h2>



<p>This is my own interpretation, obviously. Backblaze seems to think that tracking emails is totally fine, even under the GDPR. They’re not going to stop doing it until further notice.</p>



<h2>Blow by blow details</h2>



<p>Rather than describing the conversation, I think for the sake of transparency it’s easier to just quote the entire thread. So here goes, in chronological order… I removed names and identifying details to protect the privacy of the people involved, but the text was otherwise left exactly as-is. Some of the interaction is fairly mundane, but you can skip to the end to see how it was resolved (or rather, not resolved).</p>



<h2>Initial conversations with Backblaze support</h2>



<figure><div>Jun 20, 2020<p>Hi Backblaze,</p><p>I started forwarding my emails to hey.com and they spotted the use of tracking pixels on your emails. I (and I believe many other customers, especially in Europe) would appreciate not being tracked without explicit consent (and I didn’t give such consent).</p><p>Respectfully,<br>Yoav</p></div></figure>



<figure><div>Jun 21, 2020<p>Hello,&nbsp;</p><p>Thank you for writing in. We do use Sendgrid to send system emails, and only collect if an email was delivered, opened, and how many times it was opened. We do not gather other information beyond that.&nbsp;</p><p>Please note that the terms can be found when you click on the link below and by using the service agree to our terms:<br>–&nbsp;<a href="http://www.backblaze.com/terms.html" rel="noreferrer noopener" target="_blank">http://www.backblaze.com/terms.html</a></p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<figure><div>Jun 21, 2020<p>Hi A.,</p><p>Thanks for getting back to me. Your terms page doesn’t actually say anything about tracking my email opens etc. Or at least I couldn’t find anything.</p><p>Regardless, I don’t believe this is permissible without explicit consent under the GDPR. I also don’t quite understand why you would even want to track those alert emails?</p><p>Sincerely,<br>Yoav</p></div></figure>



<figure></figure>



<figure><div>Jun 22, 2020<p>Hi A.,</p><p>Perhaps the timestamps on their own aren’t considered personal data, but combined with my email address, IP, browser info etc, I’m pretty sure falls under personal data as defined by the GDPR. According to two articles I was able to find, this kind of tracking isn’t permissible by GDPR and the e-Privacy directive without explicit consent, which was not requested, nor given by me.</p><p><a href="https://www.lexology.com/library/detail.aspx?g=ac233fd4-cd49-45a7-9494-6085512c0312" rel="noreferrer noopener" target="_blank">https://www.lexology.com/library/detail.aspx?g=ac233fd4-cd49-45a7-9494-6085512c0312</a><br><a href="https://www.pipedrive.com/en/blog/gdpr-email-tracking" rel="noreferrer noopener" target="_blank">https://www.pipedrive.com/en/blog/gdpr-email-tracking</a></p><p>The links you provided so far do not appear to address this issue. Would appreciate if you could look into this more seriously.</p><p>Sincerely,<br>Yoav</p></div></figure>



<figure><div>Jun 23, 2020<p>Hello Yoav,</p><p>I asked my Compliance organization to review your concerns. They noted that much of the literature around this topic deals with Marketing Emails, which you can opt-out of at any time.&nbsp;&nbsp;</p><p>For Service Emails, which the message in question is, the rules are less clear and they will contact our GDPR attorney in the EU for clarification. That said, I believe you have four choices:<br>1) You may alter the settings on your email system to receive such emails as text, this will remove all tracking,<br>2) You can discontinue using the Backblaze service and delete your Backblaze account if you remain an active customer we will continue to send you Service emails per our Terms,<br>3) You can wait to see what our GDPR attorney says, or<br>4) You may file a complaint with the GDPR authorities in your jurisdiction.</p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<figure><div>Jun 23, 2020<p>Hi A.,</p><p>Happy to wait and hear from your GDPR attorneys.</p><p>I agree that most resources talk about marketing emails, because those are the most prevalent and most common use-case of B2C and B2B emails these days. Transactional emails are generally considered legitimate use, and in this case, I explicitly asked for those emails. So there’s no question there about *sending* these emails. As far as *tracking* how I interacted with the email, as well as further personal data like IP address, device/browser info etc (that this type of tracking typically involves), and storing this info on Sendgrid’s servers, I’m pretty confident that this isn’t considered legitimate without informed and explicit consent under the GDPR and the ePrivacy directives. hey.com seem also quite confident that this is illegal (although I don’t take legal advice from them).</p><p>But besides that, I’m just curious to understand why Backblaze even cares to track those emails? what insights do you gain from knowing that X% of those emails were opened? (especially given that those stats are hugely inaccurate and some email clients block them anyway?). Wouldn’t it be easier to do the right thing here, respect your customers privacy, and stop tracking those emails? (or if you do gain important insights, explicitly and clearly ask for consent?)</p><p>Sincerely,<br>Yoav</p><p>p.s. I also believe the same rules apply to tracking of marketing emails, even if someone explicitly gives consent to *receive* those, it does not automatically mean that they give consent to being tracked, and the privacy implications of such tracking.</p></div></figure>



<figure><div>Jun 24, 2020<p>Hello,&nbsp;</p><p>I have referred the matter to the legal department and will need to close this ticket. Any further communication will come from <a href="mailto:legal@backblaze.com" rel="noreferrer noopener" target="_blank">legal@backblaze.com</a>.</p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<h2>A month passes…</h2>



<p>I was losing my patience, so sent another message to Backblaze.</p>



<figure><div>Jul 25, 2020<p>This is a follow-up to your previous request #ZZZZZZZ “email tracking”</p><p>Hi A.,It’s been a month now, and I still haven’t heard back. Would appreciate if someone can get back to me on this.</p><p>Sincerely,<br>Yoav</p></div></figure>



<div><div>
<figure><div>Jul 25, 2020<p>Hi Yoav,</p><p>Thank you for reaching out regarding this issue. Apologies for any delay. I’m sorry to say but further communication will need to go through <a href="mailto:legal@backblaze.com" rel="noreferrer noopener" target="_blank">legal@backblaze.com</a>.</p><p>Please reach out to that email for additional information.<br>M.<br>Support Technician</p></div></figure>



<figure><div>Jul 26, 2020<p>Hi M.,</p><p>Yes, but it’s been a month, and I believe that under GDPR I can typically expect an answer within a month? see https://ico.org.uk/your-data-matters/time-limits-for-responding-to-data-protection-rights-requests/</p><p>Looking forward to hearing back from whichever team/person that can handle my enquiry.</p><p>Sincerely,<br>Yoav</p></div></figure>



<h2>Legal department steps in</h2>



<figure><div>Jul 31, 2020<p>Hi Yoav,</p><p>Thank you for following up on this matter. We take data privacy matters very seriously at Backblaze, Inc. We have reviewed your concerns and understand your sensitivity regarding the use of tracking technology on emails. In this particular case, we believe there is an exception allowed for doing so for a valid business purpose. There are two reasons we believe this is necessary.</p><p>The first reason is to accurately measure the reach and usefulness of our service email messages to our customers. Service emails communicate important information to the customer and if they are not being received or opened, valuable information is being missed. For example, the customer’s data we are storing could be at risk of being deleted, or their account could be in peril of being compromised. We use the tracking technology to provide an aggregated measure of this information versus using more invasive technologies such as user surveys or onscreen popups. Over the years we have sent many service emails and we have a full understanding as to the delivery and open rates of our service emails. As such, any anomalies are easily detected and can be acted upon to improve how well we communicate with our customers.</p><p>The second reason is for forensic purposes to respond to questions from customers and defend ourselves as needed. For example, we send multiple service emails to a customer whose subscription is expiring, as once it does expire, we will close their account and delete the data we are storing for them. From time-to-time an ex-customer will want their data and claim we did not notify them that their account was expiring. The tracking technology allows us to show what messages we have sent and what messages the customer received and opened. While not perfect, it has helped us defend ourselves in the past. There is no reasonable replacement for using the tracking technology in such cases. By the way, the same technology also allows us to prove the customer right in many cases, so it delivers value and protects both us and the customer at the same time.</p><p>Thank you for being a valued customer.</p><p>Best regards,<br>T.<br>Legal Department</p></div></figure>



<figure><div>Aug 1, 2020<p>Hi T.,</p><p>Thanks for getting back to me and explaining your reasoning in detail.</p><p>I have to admit, it sounds a bit like a husband spying on their wife “because they love her” to some extent. I don’t feel like these are valid reasons for blanket tracking of ALL emails across all customers, which seems to be the case at Backblaze. As far as I can tell, all Backblaze emails are tracking me and all other customers, from newsletters, across minor service notifications all the way to billing and other messages. Not all messages are the same, but they are all tracked in the same way as far as I can tell. Furthermore, not only there is no informed consent for this tracking, there’s actually no opt-out mechanism either. As a customer, I cannot tell you that I want your service emails, but I don’t want them tracking me. I don’t believe this meets the spirit nor the letter of the GDPR.</p><p>The first example does not at all sound like a legitimate reason to me, and I doubt the data protection authorities will accept it as legitimate either. Especially when it applies to all emails, including minor notifications, newsletters and other marketing materials. What you’re describing is that you’re compromising the privacy of your customers for your own internal reasons for marketing purposes. And as I mentioned before, with no informed consent, nor opt-out options. But besides that, given …</p></div></figure></div></div></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/">https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/</a></em></p>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534572</guid>
            <pubDate>Sun, 20 Sep 2020 15:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Arrow and MinIO]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24534274">thread link</a>) | @jtsymonds
<br/>
September 20, 2020 | https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/ | <a href="https://web.archive.org/web/*/https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>More and more enterprises have begun or have already implemented a data lake strategy based on some of the work we did a couple of years ago. If you want to take a moment to review - you can find those posts below <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">here</a> and <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">here</a>. </p><h2 id="objective">Objective</h2><p>In this article, I am going to explain a mechanism to turbocharge the use of MinIO. Nothing changes as far as MinIO is concerned, the optimization will be on the underlying storage of our data. We are going to choose one of the latest formats to improve agility manifoldly. We are going to show the ways by which your data lake data can travel across systems without experiencing any "conversion" time. </p><h2 id="apache-arrow">Apache Arrow</h2><p>I believe understanding this article needs some basic concepts of<a href="https://arrow.apache.org/"> </a>how applications like Spark works. Let me explain it in simple terms.</p><p>Imagine you got a nice job at a location different from where you live currently and you want to relocate, as the new company demands it and pays for it. You have got the most modern televisions, refrigerators, super soft leather sofas, bed and so on. You engage a moving company, who comes, disassembles everything, packs it conveniently. They also make sure to pack as much possible in containers to fill the truck such that they can do it in a single trip. Once they reach the destination, they unpack, assembles and restore everything as it was.</p><p>The same applies to data. When I store some data in MinIO , and I need to feed it to, say, another application, say Spark, the consuming application needs to disassemble the data from MinIO data lake, pack it and transport it through the wire (or wireless), receive, unpack and re-assemble. </p><p>Let's use more technical terms for this disassembly and assembly - serialization and de-serialization of data. The unfortunate part is, both these processes are complex and time consuming. Here is a brief diagram illustrating what happens in Apache Spark when it reads data</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1944w" sizes="(min-width: 720px) 720px"><figcaption>Experimental setup. Courtesy: <a href="https://databricks.com/session/running-apache-spark-on-a-high-performance-cluster-using-rdma-and-nvme-flash">Spark Summit</a></figcaption></figure><p>You may not have noticed this problem before. Assume that MinIO is on a machine(s) on the network. We write a Spark Map-Reduce application. Eventhough the network limit is 100 GbE, we are almost getting less that 10 GbE speed. What's the use of this high speed network then? What is the potential problem which is not allowing us to utilize the full potential of the network, or at least 70-80% of it?</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1948w" sizes="(min-width: 720px) 720px"><figcaption>Additional layers, buffers and serializers</figcaption></figure><p>The issues are with the way in which Spark is retrieving the data. Look at the number of layers the data has to pass though. This creates a limit on the throughput that we can achieve. There are projects like <a href="https://crail.apache.org/">Apache Crail,</a> which are designed to address these issues.</p><h2 id="optimization-columnar-data-format">Optimization : Columnar Data Format </h2><div><p>If we think about the relocation example mentioned above, we see that the logistic company will never take the sofa as it is, they will break it down to make it easy to transport. Note that this is for transportation purposes only - if that objective is different, then disassembling the sofa might not be the right approach. </p><p>Given that the objective for a data lake is analytics - rather than transactional needs we must take that under consideration. For transactions, we often use OLTP systems like Oracle or PostGres - given that they are particularly well suited for the job. A quick review of OLAP's analytics requirements is probably in order. </p></div><figure><img src="https://blog.min.io/content/images/2020/09/Picture1.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Picture1.png 600w, https://blog.min.io/content/images/2020/09/Picture1.png 966w" sizes="(min-width: 720px) 720px"><figcaption>Introducing columnar format</figcaption></figure><p>Let's start with one of the most famous RDMBS table - the "emp" table of Oracle. The top part shows how the data is stored in RDBMS as a "relation" or "tuple". We call it a table. I am providing you two queries</p><!--kg-card-begin: markdown--><ol>
<li>select ename from emp where job = 'CLERK'</li>
<li>select sum(sal) from emp</li>
</ol>
<!--kg-card-end: markdown--><p>The first is a transactional query. It has to scan every row on the table and find out the name of the employee wherever the job is clerk. The second is an analytical query - rather than an atomic result, the goal is a general result. Unfortunately, the first and second query has to scan through all the rows, if we use RDBMS way of representation of data. If the size of data is 20 GB, all the 20 GB more or less will be scanned. This is the top part of above figure.</p><p>Let's make some changes - taking all of our columns and make them into rows. Like a transpose of a matrix - and see the bottom part of above figure, how your data will look like. Following this transposition, an entire block is just representing one column. How many blocks need to be scanned for the second analytical query? Just one block, probably around 2 GB of size. </p><p>The difference is significant? Columnar representation is what is being used in ORC (Optimized Row Columnar) and Parquet files - with the goal of making the analytics faster.</p><p>Columnar formats are easier to read, however, they pose another problem - they are usually stored in compressed format. As a result, the consuming application will need to uncompress it while reading and compress it back while writing. </p><p>Note this, as we will revisit the point later.</p><h2 id="the-science-of-reading-writing-data">The Science of Reading/Writing Data</h2><p>Let me explain briefly how reading/writing happens in a software system and what role is played by the hardware.</p><p>Microprocessors normally use two methods to connect external devices: <strong>memory mapped</strong> or <strong>port mapped</strong> I/O. </p><p>Memory mapped I/O is mapped into the same address space as program memory and/or user memory, and is accessed in the same way.</p><p>Port mapped I/O uses a separate, dedicated address space and is accessed via a dedicated set of microprocessor instructions.</p><p>In memory mapped approach, I/O devices are mapped into the system memory map along with RAM and ROM. To access a hardware device, simply read or write to those 'special' addresses using the normal memory access instructions.The advantage to this method is that every instruction which can access memory can be used to manipulate an I/O device.</p><p>Usually applications use Port mapped I/O. If we are using memory mapped I/O for a particular format, it will be faster, especially for analytical needs. When combined with our columnar data format, then it becomes even more advantageous.</p><p>Welcome to <a href="https://arrow.apache.org/">Apache Arrow</a>. </p><p>Arrow uses memory mapped I/O and avoids serialization/deserialization overheads when you convert between most of the formats while leveraging the columnar data format. </p><p>Thanks to <a href="https://wesmckinney.com/">Wes McKinney</a> for this brilliant innovation, its not a surprise that such an idea came from him and team, as he is well known as the creator of Pandas in Python. He calls Arrow as the future of data transfer.</p><h2 id="store-data-in-minio-in-arrow-format">Store Data in MinIO in Arrow Format</h2><p>This is how we are going to make MinIO even more powerful. </p><p>We are going to store that data in Arrow and then let the consuming applications read it - resulting in dramatically increased speeds. Step one has us putting the data into MinIO in Arrow format. I was using my own approach until I saw a much better implementation from <a href="https://github.com/BryanCutler">Bryan Cutler</a>, whose contributions include integrating Arrow formats to Spark as well.</p><p>We will start with a a .csv file, in this case movie ratings downloaded from the <a href="https://movielens.org/">movielens</a> site. For illustration purposes, I took about 100K rows. First, let's write a Spark program to read this CSV file and write it into Arrow format using Arrow RDD. You can get the full code from the link given towards the bottom of this article.</p><p>Step 1: build.sbt , please note the arrow dependencies</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1990w" sizes="(min-width: 720px) 720px"><figcaption>See lines 18 and 19, we have Arrow related dependencies with Spark</figcaption></figure><p>We will use Spark 3.0, with Apache Arrow 0.17.1</p><p>The ArrowRDD class has an iterator and RDD itself. For creating a custom RDD, essentially you must override mapPartitions method. You can browse the code for details. </p><p>Next, start MinIO and create a bucket named "arrowbucket". </p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Create a bucket named "arrowbucket" in MinIO</figcaption></figure><p>Let's use ArrowRDD and create an ArrowFile in local. Here is the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 2372w" sizes="(min-width: 720px) 720px"><figcaption>Writing Arrow file with ArrowRDD</figcaption></figure><p>Lines 22 to 34 do the main part. Compile and execute the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Execute the code</figcaption></figure><p>As you see from code, the Arrow format file is is generated in data directory. Let's copy it to the MinIO bucket we created earlier (bucket name is arrowbucket)</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Copy the arrow file we generated to MinIO bucket</figcaption></figure><p>Let's have some fun now. </p><p>Use your favorite Python editor, and write some code. First, let us start with Spark reading the file and converting it to a dataframe, with and without Arrow enabled options.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1698w" sizes="(min-width: 720px) 720px"><figcaption>Initializing Spark context and connection parameters to Minio</figcaption></figure><p>Start your Spark cluster. Complete the code with all settings and check whether we created the Spark context successfully. To ensure that our app (named Minio-Arrow-Spark at line 8) is connected, just check the Spark UI. You should see something like this:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Spark UI (default localhost:8080) is showing our app is connected</figcaption></figure><p>Run the below code now:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1708w" sizes="(min-width: 720px) 720px"><figcaption>Reading from MinIO with Arrow format "not enabled" (top) and "enabled"(bottom)</figcaption></figure><p>The output which displays the time, shows the power of this approach. The performance boost is tremendous, almost 50%.</p><p>Recall that we created an ArrowRDD earlier and used it to write to MinIO. Let us test the memory consumption in reading it. We will use different methods.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1882w" sizes="(min-width: 720px) 720px"><figcaption>See the results - Arrow is zero copy memory format</figcaption></figure><p>We are reading different file formats and seeing the memory consumption for each. As it is evident, Arrow format based files are zero copy - almost no memory consumed at all.</p><p>By combining MinIO with the Arrow Format, you can enhance your analytics ecosystem and virtually eliminating the friction associated with converting between different formats. This is primarily due to the reduction of serialization overhead.</p><h2 id="code">Code </h2><p>You can see the<a href="https://github.com/passionbytes/ArrowRDD"> Jupyter notebook and ArrowRDD code here</a>.</p><p>Ravishankar Nair is a technology evangelist, a consultant and an inspiring speaker. He is the CTO of PassionBytes, based in Florida. With his vast expertise in data engineering, Ravi provides consultancy in machine learning, modern data lakes and distributed computing technology. You can refer to his other articles related to MinIO here:</p><p>1) <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">Modern Data Lakes with Minio - Part 1</a></p><p>2) <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">Modern Data Lakes with MinIO - Part 2</a></p><p>3) <a href="https://blog.min.io/building-an-on-premise-ml-ecosystem-with-minio-powered-by-presto-r-and-s3select-feature/">Building an …</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534274</guid>
            <pubDate>Sun, 20 Sep 2020 14:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yelp: Local Economic Impact Report]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 172 (<a href="https://news.ycombinator.com/item?id=24534186">thread link</a>) | @bookofjoe
<br/>
September 20, 2020 | https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html | <a href="https://web.archive.org/web/*/https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
    
    <section>
      <!--<p class='prose flag'><i>If you'd like additional detail on how the economy is shifting, please contact us at <a href='mailto:press@yelp.com'>press@yelp.com</a> or <a class=underline href=http://eepurl.com/cMFvGL target=_blank>join our mailing list</a> to receive an email when new reports are released.</i></p>-->
    
      
        <p>Since the first fears of the pandemic emerged in the U.S. in early March, businesses across the nation have endured six months of uncertainty. Yet, businesses are adapting and proving their resilience through lockdowns, reopenings, a <a href="https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html?name=styln-coronavirus-markets&amp;region=TOP_BANNER&amp;variant=1_Show&amp;block=storyline_menu_recirc&amp;action=click&amp;pgtype=Article&amp;impression_id=76e345d2-e946-11ea-8ee3-5b12c6c78bc9" target="_blank">summer surge in virus cases</a>, new ways of doing business such as <a href="https://www.nytimes.com/2020/08/23/nyregion/outdoor-dining-new-york.html" target="_blank">outdoor dining</a>, new mask wearing rules and backlash from <a href="https://www.washingtonpost.com/nation/2020/07/18/covid-pandemic-store-clerk-north-carolina/?arc404=true" target="_blank">anti-mask patrons</a>, as well as milestones such as the <a href="https://www.yelpeconomicaverage.com/back-to-school-2020.html" target="_blank">return to school</a>. Even in the wake of increased closures we’re seeing businesses effectively transition to new operating models while keeping their employees and consumers safe.</p>
        <p>Yelp closure data shows that businesses providing home, local and professional services have been able to withstand the effects of the pandemic particularly well. But despite bright spots in some sectors, restaurants and retail continue to struggle and total closures nationwide have started to increase.</p>
        <p>The <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">last Yelp Economic Average</a> showed a decreasing number of overall closures, 132,580 in total. As of August 31, 163,735 total U.S. businesses on Yelp have closed since the beginning of the pandemic (observed as March 1), a 23% increase since July 10. In the wake of COVID-19 cases increasing and local restrictions continuing to change in many states we’re seeing both permanent and temporary closures rise across the nation, with 60% of those closed businesses not reopening (97,966 permanently closed).</p>
    </section>
    
    <section>
      <h3>Business Closures Continue to Increase Nationally</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
      <p><i></i>Hover over a circle to see closures</p>
    	
    </section>
    
    <!--
    <section class='report-wrapper'>
    	<h3 class='centered-title'>Business Closures Continue to Increase Nationally</h3>
      <h4 class='centered-title'>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<div class='static-image-container'>
    		<img class='static-image-desktop' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-tablet' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-mobile' src='./assets/img/closures092020/Closures_Rate_Mobile-f0f8a42c99.png'/>
    	</div>
    </section>
    -->    <section>
    	<h2>Resilient Businesses Operating in an Unpredictable Economy</h2>
        <p>Some business sectors have been able to weather the COVID-19 storm particularly well. In general, professional services and solo proprietors as a whole have been able to maintain a relatively low fraction of closures since March 1. This group includes lawyers, real estate agents, architects, and accountants – all with only two to three out of every thousand businesses closed, as of August 31. Health related businesses in particular have been able to maintain a low rate of closures – orthopedists, internal medicine, hospitals, physicians, family doctors and OB/GYNs all have less than three closures out of every thousand businesses.</p>
        <p>Yelp’s closure data also shows that demand for <a href="https://blog.yelp.com/2020/08/yelp-reinvents-the-hiring-experience-for-home-and-local-services" target="_blank">home, local</a> and automotive services has remained robust with a far lower rate of closures compared to restaurants and retail. Towing companies, plumbers and contractors in particular have maintained a low rate of closures, with only six to seven out of every thousand businesses closed. In fact, the share of consumer interest in home and local services is up 24% between March 1 and August 31, relative to all categories on Yelp, compared to the same time last year.</p>
    </section>
    
    <section>
    	<h3>Home, Local, Professional, and Auto Services Prove Their Strength Amid the Pandemic</h3>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Mobile-069e01b319.png">
    	</p>
    </section>    <section>
      <h2>Restaurants Remain Hardest Hit, Permanent and Temporary Closures Increase</h2>
        <p>The restaurant industry continues to be among the most impacted with an increasing number of closures – totalling 32,109 closures as of August 31, with 19,590 of these business closures indicated to be permanent (61%). Breakfast and brunch restaurants, burger joints, sandwich shops, dessert places and Mexican restaurants are among the types of restaurants with the highest rate of business closures. Foods that work well for delivery and takeout have been able to keep their closure rates lower than others, including pizza places, delis, food trucks, bakeries and coffee shops.</p>
        <p>Meanwhile, bars and nightlife, an industry 6X smaller than restaurants, has endured an especially high closure rate, with an increasing percentage of closures being permanent. As of the end of August there were 6,451 total business closures, of which 3,499 were permanently closed (54%). The share of permanent closures within bars and nightlife have increased by 10% since our <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">Economic Average Report</a> in July.</p>
        <p>Retail and shopping follows closely behind restaurants with 30,374 total business closures, 17,503 of which are permanent (58%). Similar to bars and nightlife, the share of permanent closures increased by 10% since July. Both men and women’s clothing, as well as home decor, have the highest rate of business closures.</p>
        <p>The beauty industry has seen a 22% increase in closures since July, totalling 16,585 closures. Of all closed businesses in the beauty industry 7,002 won’t reopen (42%), a significant 43% increase since July when we reported that 4,897 of all closures in the beauty industry were permanent. Similarly the fitness industry has endured a 23% increase in closures since July, with 6,024 total closures, 2,616 of which are permanently closed.</p>
    </section>
    
    <section>
    	<h3>Restaurants and Retail Continue to Struggle</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Mobile-529b856e87.png">
    	</p>
    </section>    <section>
      <h2>Larger States and Metros See a Greater COVID-19 Impact on Local Businesses</h2>
        <p>Even as the pandemic spreads nationally, geographically Yelp data shows business closure rates vary across the country. Bigger states and metros with higher rents and more stringent local operations for small businesses throughout the last six months have felt a greater toll. So have businesses more closely linked to physical locations that require crowds of consumers to attain profitability. Meanwhile, smaller cities and solo operations that can do their work one-on-one or virtually have proven better positioned to stay in business.</p>
        <p>For the states with widespread business closures, the economic struggle appears to be closely coupled with unemployment rates. Hawaii, California, and Nevada have the highest rate of total closures and permanent closures – they’re also the three states with the <a href="https://finance.yahoo.com/news/these-states-are-suffering-from-the-worst-unemployment-rates-144451899.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAABND8yZDak2Xg6GnNC9LukDHqDayj3GYnFbfZn_9NctEnowVC1JMpg9oZFKixnWrRLGLPortUEEaymyEAYmZ0jMN8vOuriLR1N7S0Roqv9OT99H-WdN5XH_sd_I_r0-EgEJSDExY9yTtI7Xduv3Q-Agxb55dUepi3-k8T1fGZ153" target="_blank">highest unemployment rates</a>, and among the <a href="https://www.worldatlas.com/articles/the-most-visited-states-in-the-us.html" target="_blank">biggest states for tourism</a>. Meanwhile, West Virginia and the Dakotas have the lowest closure rates.</p>
        <p>The states with the most closures are home to the hardest-hit metros: Las Vegas in Nevada, Honolulu in Hawaii, and several of the largest California urban areas all are among the metro areas with the highest total closure and permanent closure rates (San Diego, San Francisco, San Jose, Los Angeles and others), with roughly 20 businesses per thousand temporarily or permanently closing their doors since March 1. Larger metros with far fewer closures tend to be in the East, including Pittsburgh, Philadelphia, and Baltimore, all with closure rates below 10 per thousand.</p>
    </section>
    
    <section>
    	<h3>Where are the Most Businesses Closed?</h3>
      <h4>Geographic areas with the largest number of business closures since March 1</h4>
    	<div>
    		<p>Total Closures</p>
    		<p>Closures per 1,000</p>
    	</div>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Mobile-98f53c8115.png">
    	</p>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Mobile-1878bbd645.png">
    	</p>
    </section>
    <section>
        <p>Keep an eye out for our next update in our Q3 <a href="https://www.yelpeconomicaverage.com/index.html" target="_blank">Yelp Economic Average</a>.</p>
        <p>—Carl Bialik and Daniel Gole contributed to this report</p>
    </section>
    
    <section>
        <p><em>If you'd like additional detail on how the economy is shifting, please contact us at <a href="https://www.yelpeconomicaverage.com/cdn-cgi/l/email-protection#90e0e2f5e3e3d0e9f5fce0bef3fffd"><span data-cfemail="9eeeecfbededdee7fbf2eeb0fdf1f3">[email&nbsp;protected]</span></a> or <a href="http://eepurl.com/cMFvGL" target="_blank">join our mailing list</a> to receive an email when new reports are released.</em></p>
        <p><em>Interested in learning how Yelp data can assist you in developing market insights for your business? Yelp Knowledge can help, learn more <a href="https://www.yelp.com/knowledge" target="_blank">here</a>.</em></p>
    </section>
    
    
    <!--
    <section class='report-wrapper'>
    </section>
    -->
    
    <section>
    	
    	<h2>Methodology</h2>
    
    		<p><em>Business Closures</em></p>
    		<p>On each date, starting with March 1, we count U.S. businesses that were open on March 1 and were closed on that day. Closure can be permanent or temporary, and is signaled by a business owner marking the business as closed, including by changing its hours or through a COVID-19 banner on its Yelp page. Closure counts are likely an estimate of the businesses most impacted, with many others not counted because they remain open with curtailed hours and staffing, or because they have not yet updated their Yelp business pages to reflect closures. Additionally, we only count closures that have been vetted by our User Ops team or have been updated directly by a business owner. Closures are counted by state, metro area, and category; some businesses are in more than one category. Businesses can also set automatic reopening dates on Yelp, which are counted as reopenings unless the business updates their information.</p>
    		<p><em>Downloadable static graphics can be found <a href="https://drive.google.com/drive/folders/1kSIOmVz_06NEP37NRfkODkzrpE0lAl3X?usp=sharing" target="_blank">here</a>.</em></p>
    		<p><em>See Yelp's previous Local Economic Impact Reports at our Data Science Medium, <a href="https://medium.com/tag/yelp-coronavirus-report/archive" target="_blank">Locally Optimal</a>.</em></p>
    </section>
    <section>
      <!-- <p class='prose'><strong>Interested in the numbers behind YEA? Check out the <a class='underline' href='./methodology.html'>methodology</a>.</strong></p> -->
      
    </section>    
  </div></div>]]>
            </description>
            <link>https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534186</guid>
            <pubDate>Sun, 20 Sep 2020 14:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using QEMU to Create a Ubuntu 20.04 Desktop VM on macOS]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24533742">thread link</a>) | @arthurk
<br/>
September 20, 2020 | https://www.arthurkoziel.com/qemu-ubuntu-20-04/ | <a href="https://web.archive.org/web/*/https://www.arthurkoziel.com/qemu-ubuntu-20-04/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <time datetime="2020-09-20">September 20, 2020</time>
<p>In this blog post we’re going to create a Ubuntu 20.04 VM using <a href="https://www.qemu.org/">QEMU</a> on MacOS.</p>
<p><img src="https://www.arthurkoziel.com/qemu-ubuntu-20-04/ubuntu-20-04-with-qemu.png" alt="A picture of the Ubuntu 20.04 Desktop"></p>
<p>QEMU is a hardware emulator which can make use of different accelerators when running VMs. The most popular accelerator is <a href="https://www.linux-kvm.org/page/Main_Page">KVM</a> which is built into the Linux kernel and allows Linux hosts to run VMs with native performance.</p>
<p>Using QEMU on macOS used to be very slow as no accelerator was available. This changed 2 years ago when the project <a href="https://wiki.qemu.org/ChangeLog/2.12">added support</a> for the macOS native hypervisor with Hypervisor.framework (HVF) as an accelerator.</p>
<p>Before we begin with the setup I assume that the <a href="https://releases.ubuntu.com/20.04/">Ubuntu 20.04 Desktop ISO</a> has been downloaded in the current working directory.</p>
<h2 id="qemu-installation">QEMU Installation</h2>
<p>We can use Homebrew to install QEMU. The version we’re using in this tutorial is 5.1.0:</p>
<pre><code>$ brew install qemu

qemu-system-x86_64 --version
QEMU emulator version 5.1.0
Copyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers</code></pre>
<p>It will pull in a few dependencies (the package depends on 14 other packages) and the installation can take a few minutes.</p>
<h2 id="create-the-disk-image">Create the disk image</h2>
<p>Once the installation is done, we can create the disk image that we’re going to install Ubuntu on.</p>
<p>We’re using the QCOW2 format to create a 20GB image. This can be resized later on if needed. The Ubuntu installation took around 5GB of space when I installed it.</p>
<pre><code>qemu-img create -f qcow2 ubuntu-20.04.1-desktop-amd64.qcow2 20G</code></pre>
<h2 id="boot-machine-with-ubuntu-iso-mounted">Boot machine with Ubuntu ISO mounted</h2>
<p>We can now boot up the machine with the Ubuntu ISO attached as a</p>
<p>In this step we boot up the machine with the Ubuntu ISO mounted in the CD drive:</p>
<pre><code>qemu-system-x86_64 \
    -machine type=q35,accel=hvf \
    -cpu host \
    -smp 2 \
    -hda ubuntu-20.04.1-desktop-amd64.qcow2 \
    -cdrom ./ubuntu-20.04.1-desktop-amd64.iso \
    -m 4G \
    -vga virtio \
    -usb \
    -device usb-tablet \
    -display default,show-cursor=on</code></pre>
<p>The options are:</p>
<ul>
<li><code>-machine</code>: The emulated machine and the accelerator. q35 is the newest machine type and HVF is the macOS native hypervisor.</li>
<li><code>-cpu</code>: The CPU architecture. The value <code>host</code> will use the HVF processor with all supported host features</li>
<li><code>-smp</code>: Number of CPUs to use</li>
<li><code>-m</code>: Amount of memory to use</li>
<li><code>-hda</code>: Disk drive (the one we created earlier)</li>
<li><code>-cdrom</code>: The ISO image to put into the CD drive</li>
<li><code>-vga</code>: The graphic card to use. I found <code>virtio</code> (based on <a href="https://virgil3d.github.io/">Virgil</a> to have the best performance</li>
<li><code>-usb</code>: Enable USB host controller</li>
<li><code>-device</code> Adding a “usb-tablet” as an input device. I’m running this on a laptop and without this setting the mouse did not work.</li>
<li><code>-display</code>: To show the mouse cursor (disabled by default)</li>
</ul>
<p>During testing I had problems with the Linux kernel as it would panic during the boot process. The issue was the <code>-cpu host</code> parameter. I fixed it by specifying the CPU architecture manually (see <code>qemu-system-x86_64 -cpu help</code> for a list of all available architectures).</p>
<p>My machine has an IvyBridge processor (Core i7):</p>
<pre><code>$ sysctl -n machdep.cpu.brand_string

Intel(R) Core(TM) i7-3740QM CPU @ 2.70GHz</code></pre>
<p>And using <code>-cpu IvyBridge</code> would fail. However when using <code>-cpu Nehalem</code> (<a href="https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures">also an i7 CPU</a>) everything worked well.</p>
<p>Now after the machine is booted up the Ubuntu installer will run. Follow the installation steps and don’t restart the VM at the end of the installation, instead shut it down by stopping the qemu process with CTRL-C on the host.</p>
<h2 id="boot-without-iso-mounted">Boot without ISO mounted</h2>
<p>When running the VM we don’t need the Ubuntu ISO mounted and can remove it by leaving out the <code>-cdrom</code> option:</p>
<pre><code>qemu-system-x86_64 \
    -machine type=q35,accel=hvf \
    -cpu host \
    -smp 2 \
    -hda ubuntu-20.04.1-desktop-amd64.qcow2 \
    -m 4G \
    -vga virtio \
    -usb \
    -device usb-tablet \
    -display default,show-cursor=on</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>In my experience QEMU is faster, more responsive and uses less CPU/RAM than VirtualBox. I didn’t have to configure any display scaling for HiDPI screens as it worked out of the box. The only thing I’m missing are shared clipboards and drag-and-drop of files (which are available when installing the VirtualBox Guest Additions).</p>
    </article></div>]]>
            </description>
            <link>https://www.arthurkoziel.com/qemu-ubuntu-20-04/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533742</guid>
            <pubDate>Sun, 20 Sep 2020 12:58:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Interactive tutorial for learning Git's internals]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533602">thread link</a>) | @chrisparnin
<br/>
September 20, 2020 | https://docable.cloud/chrisparnin/examples/tutorials/Git.md | <a href="https://web.archive.org/web/*/https://docable.cloud/chrisparnin/examples/tutorials/Git.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" id="main">

        <!-- Display major errors here -->
        


        

        <!-- style="flex: 1;" -->
        <div>
            <!-- Rendered notebook content -->
            <!--
setup: 
  docker:
    image: git_workshop
-->
<p><img src="https://cloud.githubusercontent.com/assets/742934/15635543/d1044ff6-25ae-11e6-9680-077830cff8f5.png" alt="image"></p>
<p>Have you ever wondered how git worked <em>inside</em>? Here’s a chance to interactively play around with a few git commands that will help reveal the inner workings of git, itself!</p>
<p>Just click on the “Run” button in each cell, and see the result of the command, below. Some command results can be clicked on to reveal a few more details.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/docable-click.gif" alt="docable-click"></p>
<blockquote>
<p>See how this tutorial was built from simple markdown with <a href="https://github.com/ottomatica/docable-notebooks">docable notebooks</a>!</p>
</blockquote>
<h2 id="understanding-git-internals">Understanding Git Internals</h2>
<blockquote>
<p>By <a href="https://stolee.dev/">Derrick Stolee</a>, git core contributor, adapted into interactive notebook by <a href="http://chrisparnin.me/">Chris Parnin</a>.</p>
</blockquote>
<p>What better way to understand git, then check out git itself. </p>
<p><em>Note:</em> We have already run this step for you! Otherwise, this might take a while!</p>
<pre><code>git <span>clone</span> https://github.com/git/git</code></pre><p>We’ll be working inside the git/ directory set our working state to v2.23.0.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-failed_when="exitCode!=0" id="e6dfd181-c817-4ca9-9dc9-c0e9c716d4f3"><code><span>cd</span> git
git reset --hard v2.23.0</code></pre></div></div><h3 id="gits-object-model-content-addressable-data-store">Git’s Object Model: Content-Addressable Data Store.</h3>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-object-model.png" alt="git object model"></p>
<ul>
<li>Every object has a SHA-1 hash: 40 hex characters.</li>
<li>Given 40 hex characters, we can find the unique object with that hash.</li>
</ul>
<p>Let’s examine a single commit.</p>
<h3 id="object-types-blobs-trees-commits">Object Types: Blobs, Trees, Commits</h3>
<p>We will use the <code>git cat-file</code> command to help us search for objects inside the store.
If we provide git with a partial hash, it will attempt to find a unique match, and if it is unable to, it will provide a list of those that did match.</p>
<h4 id="blobs">Blobs</h4>
<p>Let’s examine a <strong>blob</strong> object. A blob contains <em>file contents</em>. 
<img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-blob.png" alt="img"></p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-highlight="{&quot;word&quot;:&quot;Here are the topics that have been cooking&quot;,&quot;title&quot;:&quot;Note: the file name is not part of the object! It is just the text or binary contents.&quot;}" id="f7b06331-3f24-44ec-9773-bfd2696d3d6c"><code>git cat-file -p 5fa073a885</code></pre></div></div><h4 id="trees">Trees</h4>
<p>Let’s examine a <strong>tree</strong> object. A tree contains <em>folder contents</em>. 
<img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-tree.png" alt="img"></p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-block="{&quot;word&quot;:&quot;CodingGuidelines&quot;,&quot;rows&quot;:8,&quot;title&quot;:&quot;A tree can contain blobs and other trees. Notice that RelNotes is another tree with additional folder content.&quot;}" id="730fc4f1-8350-4b62-b520-a25d589b5bbe"><code>git cat-file -p 5fa02bff4e</code></pre></div></div><p>Example representation of folder contents contained by a tree: </p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-tree-folder.png" alt="img"></p>
<h4 id="commits">Commits</h4>
<p>Perhaps one of the most important type of object inside the object model is a commit. A <strong>commit</strong> contains many things:</p>
<ul>
<li>A root <strong>tree</strong></li>
<li>A list of <strong>parent commits</strong></li>
<li>A commit message</li>
<li>An author name, email, time.</li>
<li>A committer name, email, time.</li>
</ul>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-commit.png" alt="git commit"></p>
<p>Let’s examine an example commit.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-highlight="{&quot;word&quot;:&quot;committer&quot;,&quot;title&quot;:&quot;A committer can differ from an author, for example, a committer may be merging a pull request from another author.&quot;}" id="861fa445-0b18-4609-b2bc-12e556f6d9d0"><code>git cat-file -p 5fa00a4dcf</code></pre></div></div><p>We can examine the commit graph (but only the first part!).</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-tty="true" id="55a37c79-4ccc-4c50-a6a5-69801bc92dc0"><code>PAGER=<span>'head -n 80'</span> git <span>log</span> --graph --oneline</code></pre></div></div><h4 id="diffs">Diffs</h4>
<p>Diffs are not part of the object model!</p>
<blockquote>
<p><strong>Commits are NOT diffs</strong></p>
</blockquote>
<p>Instead, diffs are dynamically calculated from the commit graph inside the object store. For example, even object attributes, such as <em>file renames</em> are not represented inside the datastore and must be calculated dynamically.</p>
<p>Let’s examine a diff.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" id="2718b8b7-1fcd-4308-a6ac-5ded680e9d20"><code>git diff --raw v2.22.0 v2.23.0</code></pre></div></div><h4 id="merkle-trees">Merkle Trees</h4>
<p>To enable efficient representation and fast computations of git operations, <em>merkle trees</em> provide forward references within the graph to blobs.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-merkle-tree.png" alt="merkle-tree"></p>
<h3 id="branches">Branches</h3>
<p><em>Branches</em> are simply pointers to commits. <em>Tags</em> are pointers to anything (commits, trees, blobs).</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-branches.png" alt="git-branches"></p>
<h4 id="move-between-branches-with-git-switch">Move between branches with git switch</h4>
<p><code>git switch</code> is a new feature in v2.23.0 of git. It essentially replaces and does less work than <code>git checkout</code>. Primarily, <code>git switch</code> will:</p>
<ul>
<li>Change <code>HEAD</code> to point to a new branch.</li>
<li>Updates the working directory to match the commit’s tree.</li>
</ul>
<p>We can switch our branch to the maintenance branch.</p>
<p>Let’s confirm.</p>
<p>We can return to the main branch.</p>
<h2 id="practice-creating-a-repo">Practice: Creating a Repo</h2>
<p>Let’s try the basics. Let’s create a new local git repository.</p>
<p>Create a new directory (Basics) and file (README.md).</p>
<p>We are going to create a new git repository, but maybe not the way you’ve done it before. 
In the next set of commands, we will be working inside the <code>Basics/</code> directory.</p>
<p>This will create a new .git directory to store commits and other objects.</p>
<p>We can quickly inspect the contents of the git’s directory and object store.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="cbd996a7-f556-432b-8af0-f3029dce2ca8"><code>ls -l .git
<span>echo</span> <span>"objects:"</span>
ls -l .git/objects</code></pre></div></div><p>Before adding a file to the repository, it must first be staged.</p>
<p>We will commit our staged changes into the repository.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="0300faa6-159d-4ab0-abe2-22f3cae55bdc"><code>git commit -m <span>"initial commit"</span></code></pre></div></div><p>Nice work!</p>
<h3 id="stage-unstage-and-discard-changes">Stage, unstage, and discard changes</h3>
<p>Changes flow from our working tree, to staging index, and into repository.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-staging.png" alt="git-staging"></p>
<p><strong>Exercise</strong>: Use the following sets of steps and execute them in any order you wish. Observe what happens to the <em>working tree</em> and <em>index</em>, by running the <code>git status</code> step.</p>
<p>Update the README.md and stage our change.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" data-shell="bash" id="01ab5e23-2c23-4e06-b04c-9a3cf16105ab"><code><span>echo</span> <span>" Update: <span>$(date)</span>"</span> &gt;&gt; README.md
cat README.md
git add README.md</code></pre></div></div><p>View the current state of our <strong>working tree</strong> and <strong>index</strong>.</p>
<p>Unstage file (remove from index), but keep changes in working tree.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="2af2fca4-c97e-45df-aa5f-e94a1c788c04"><code>git restore --staged README.md</code></pre></div></div><p>Discard changes in worktree (we will lose our work!). This will restore changes to both the index and the working tree based on the latest version in the repo.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="a4f8e61d-8920-491a-afa0-34a41e9d15fb"><code>git restore --<span>source</span>=HEAD --staged --worktree README.md</code></pre></div></div><h3 id="remotes">Remotes</h3>
<p>While having a local git repository is cool, we should connect it to another remote repository. In other words, we have no place to <code>git push</code> to…</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-remote.png" alt="git-remote"></p>
<h4 id="remote-operations">Remote operations</h4>
<ul>
<li>Get new data: <code>git fetch &lt;remote&gt; [branch]</code></li>
<li>Upload your data: <code>git push &lt;remote&gt; &lt;branch&gt;</code></li>
<li>Get new data and merge into working tree: <code>git pull &lt;remote&gt; &lt;refspec&gt;</code></li>
</ul>
<p><em>Hot Take</em>: Avoid <code>git pull</code> on large repositories! You may want to handle merges yourself into your target branch instead of having git mess with your working tree.</p>
<p><strong>Exercise</strong>: Let’s open a terminal and perform the following steps.</p>
<p><em>Note</em>: You must be running local docable server to run these steps.</p>
<p>Windows:</p>
<p>Mac/Linux:</p>
<ol>
<li><p>Create a repo on GitHub (If you are a NCSU student, use GitHub Enterprise: <a href="https://github.ncsu.edu/">https://github.ncsu.edu</a>). </p>
</li>
<li><p>Follow the instructions on GitHub to add a remote url to an <em>existing git repository</em>. Basically, you need to run something like: <code>git remote add origin https://github.com/&lt;user&gt;/&lt;repo&gt;.git</code></p>
</li>
<li><p>Push your changes to GitHub. Verify you can see your updated README.md!</p>
</li>
<li><p>On GitHub, edit the README.md, to say “Hello GitHub!”. Commit the changes on GitHub. Now you have changes in your remote (origin), that are missing on your local copy.</p>
</li>
<li><p>Run <code>git pull</code> and verify you now have the updated changes.</p>
</li>
</ol>
<h2 id="git-branching-playground">Git Branching Playground</h2>
<p>Manipulating the commit graph can get quite complicated! This interactive visualization is very useful for getting a deeper understanding of how operations such as branches, merges, cherry-picking, and more work!</p>
<p>We will solve the “Introduction Sequence” levels in:<br><a href="http://pcottle.github.io/learnGitBranching/">http://pcottle.github.io/learnGitBranching/</a>   </p>
<p><img src="https://cloud.githubusercontent.com/assets/742934/9494425/c4dd4b66-4bd3-11e5-9aac-04bfc8fed771.png" alt="example"></p>
<h2 id="git-configuration-and-security">Git Configuration and Security</h2>
<p>If you want to make sure your commits are properly linked to your GitHub account, make sure you have configured your computer to have your name and email filled out.</p>
<pre><code>$ git config --global user.name "FirstName LastName"
$ git config --global user.email email@example.com</code></pre><p>You might also consider an authenication strategy. If you’re being asked to login everytime your pull/push to your remote repository, you might want to enable caching of your credentials. For example, you could use: </p>
<pre><code>git config --global credential.helper store</code></pre><p>However, this may store your credentials in plain text on your computer. There are other platform-specific credential.helpers that you can use to more securely store your credentials. It is also possible to generate <a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">personal access tokens</a> that you can use authenicate instead of a passcode.</p>
<p>An alternative approach is to use sshkeys. In this case, you have a public/private keypair, with the public key stored on GitHub. You then use a <a href="https://help.github.com/articles/which-remote-url-should-i-use/">different url pattern</a> for your commands such as <code>git clone</code>. Instead of the <code>https://</code> prefix, you instead use <code>git@github.com:user/repo.git</code>.</p>
<p>If you are interested in exploring this option: See these guides on GitHub:</p>
<ul>
<li><a href="https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/">Generating SSH Key</a></li>
<li><a href="https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/">Adding SSH Key to GitHub</a></li>
<li><a href="https://help.github.com/articles/testing-your-ssh-connection/">Testing SSH Connection</a></li>
</ul>

        </div>

        <!--- init and style customization not supported by css -->
        

    </div></div>]]>
            </description>
            <link>https://docable.cloud/chrisparnin/examples/tutorials/Git.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533602</guid>
            <pubDate>Sun, 20 Sep 2020 12:25:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Quality DOSBox Video Capture]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24533484">thread link</a>) | @susam
<br/>
September 20, 2020 | https://susam.in/blog/good-quality-dosbox-video-capture/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/good-quality-dosbox-video-capture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 01 Sep 2020</p>
<h2 id="vintage-dos-programs"><a href="#vintage-dos-programs">Vintage DOS Programs</a></h2>

<p>
Once in a while, I fire up one of the vintage DOS games or language
interpreters in DOSBox for nostalgia's sake. I have archived these
vintage programs at <a href="https://github.com/susam/dosage">github.com/susam/dosage</a>.
DOSBox is an emulator program that emulates IBM PC compatible computers
running DOS. Trying my hands on these antiquated DOS programs now evokes
old memories from my childhood days days when I first came across
computers as part of our primary school curriculum.
</p>

<p>
Computers were much simpler in those days. The ones in our school were
IBM PC compatible computers with mostly monochrome displays. A couple of
them had support for a very limited number of colours provided by CGA or
EGA graphics cards. The ability to boot a computer using a
5¼-inch floppy disk containing MS-DOS, load a Logo or BASIC
interpreter, or a computer game from another floppy disk, and then write
some programs or play a few games without any distraction had its own
charm that I find missing from modern day computing.
</p>

<p>
Often while using old DOS programs with DOSBox in this day and age, I
want to take screenshot captures or video captures of the DOSBox
sessions and share them with my friends. In this article, I will explain
how I create good quality screenshot captures and video captures of
DOSBox sessions in formats that I can share with others.
</p>


<h2 id="contents"><a href="#contents">Contents</a></h2>
<ul>
  <li><a href="#vintage-dos-programs">Vintage DOS Programs</a></li>
  <li><a href="#software-versions">Software Versions</a></li>
  <li><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></li>
  <li><a href="#digger-in-dosbox">Digger in DOSBox</a></li>
  <li><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></li>
  <li><a href="#dosbox-video-capture">DOSBox Video Capture</a></li>
  <li><a href="#dosbox-audio-video-capture">DOSBox Audio/Video Capture</a></li>
  <li><a href="#dosbox-gif-animation">DOSBox GIF Animation</a></li>
  <li><a href="#references">References</a></li>
</ul>


<h2 id="software-versions"><a href="#software-versions">Software Versions</a></h2>

<p>
Since this article involves several pieces of software, some of what is
written here may not hold good in future if the behaviour of any of
these software tools change in future. The list below contains the
versions of all software tools that were used to test the commands
provided in this article:
</p>

<ol>
  <li>macOS High Sierra 10.13.6</li>
  <li>DOSBox 0.74-3</li>
  <li>FFmpeg 4.3.1</li>
  <li>ImageMagick 7.0.10-28
  </li><li>IBM Personal Computer Logo Version 1.00</li>
  <li>Digger (Original PC booter version by Windmill Software)</li>
</ol>

<p>
Note that both Logo and Digger programs in the list above are DOS
programs that were released in 1983. They cannot be run directly on
modern computers but they can be run with DOSBox since it emulates old
IBM PC compatible computers.
</p>


<h2 id="ibm-pc-logo-in-dosbox"><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></h2>

<p>
IBM Personal Computer Logo developed by Logo Computer Systems Inc.
(LCSI) in 1983 was the first piece of software I got introduced to while
learning computers as a kid. I came across it at the age of 8 when I was
in Class 4 and our school had a 5¼-inch floppy disk with IBM PC
Logo on it. As a result, Logo was the first programming language I
learnt in my life. About 20 years later, I would realize that the first
programming language I learnt is a dialect of Lisp. How wonderful!
</p>

<figure id="logo-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-0.png"><img src="https://susam.in/files/blog/dosbox-logo-0.png" alt="A screenshot of IBM Personal Computer Logo with copyright notices of IBM and LCSI, welcome message, and question mark prompt"></a>
  <figcaption>
    Welcome screen of IBM Personal Computer Logo
  </figcaption>
</figure>

<!--
Class Age Year
   KG   4   88
    1   5   89
    2   6   90
    3   7   91
    4   8   92
    5   9   93
    6  10   94
    7  11   95
    8  12   96
    9  13   97
   10  14   98
-->

<p>
If the Logo interpreter program <code>LOGO.COM</code> exists in the
current directory, it can be run with DOSBox using the following
command:
</p>

<pre><code>dosbox LOGO.COM</code></pre>

<p>
One of the things I enjoyed drawing with Logo was a grid of overlapping
circles like this:
</p>

<figure id="logo-program-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-1.png"><img src="https://susam.in/files/blog/dosbox-logo-1.png" alt="A grid made with 20 circles along with Logo source code for it"></a>
  <figcaption>
    Grid of circles drawn with IBM Personal Computer Logo
  </figcaption>
</figure>

<p>
Here is the Logo source code for the above output:
</p>

<pre><code>REPEAT 20 [REPEAT 180 [FD 1 RT 2] RT 18]</code>
</pre>


<h2 id="digger-in-dosbox"><a href="#digger-in-dosbox">Digger in DOSBox</a></h2>

<p>
At around the same time I learnt Logo, I also came across Digger, a
computer game for IBM PC developed by Windmill Software in 1983.
</p>

<figure id="digger-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-0.png"><img src="https://susam.in/files/blog/dosbox-digger-0.png" alt="A screenshot of Digger welcome screen with the names and pictures of various game characters with a copyright notice of Windmill Software"></a>
  <figcaption>
    Welcome screen of Digger
  </figcaption>
</figure>

<p>
If the Digger program <code>DIGGER.COM</code> exists in the directory,
it can be run using DOSBox with the following command:
</p>

<pre><code>dosbox DIGGER.COM -c "config -set cpu cycles=500" -machine cga</code>
</pre>

<p>
The <code>-machine cga</code> option emulates a machine with Color
Graphics Adapter (CGA) because Digger requires a machine of this type to
run correctly. The <code>cycles=500</code> configuration option slows
down the speed at which DOSBox emulates instructions in order to emulate
the slow machines of olden days. Without this option, Digger runs too
fast to be able to be conveniently playable.
</p>

<figure id="digger-game-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-1.png"><img src="https://susam.in/files/blog/dosbox-digger-1.png" alt="A screenshot of underground maze in the game of Digger"></a>
  <figcaption>
    A game of Digger that has just begun
  </figcaption>
</figure>

<p>
Digger has an excellent gameplay where the player digs through
underground tunnels to pick up emeralds, drop gold bags to release the
gold or squash nobbins and hobbins, collect the released gold to earn
more points, and so on. It uses bright and attractive colours. The music
is great. When Digger was released in 1983, it was quite advanced for
its time.
</p>



<h2 id="dosbox-screenshot-capture"><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></h2>

<p>
The screenshots above were obtained by running IBM PC Logo and the
original 1983 PC booter version of Digger on DOSBox and then resizing
the screenshots such that their aspect ratio matches the aspect ratio of
old CRT computer monitors.
</p>

<p>
To obtain the screenshots, we first press <kbd>Ctrl</kbd> +
<kbd>F5</kbd> while DOSBox is running. The paths of the screenshots
appear in the console output at the terminal where DOSBox was launched.
For example:
</p>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_001.png</samp>
</pre>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_001.png</samp>
</pre>

<p>
The screenshots obtained in this manner have an aspect ratio of 8:5
which makes the output look stretched horizontally. The old CRT computer
monitors for which these old DOS programs were written had an aspect
ratio of 4:3 instead. This stretched look can be fixed by resizing the
images to an aspect ratio of 4:3. Here are the commands used to fix the
aspect ratio and produce the images:
</p>

<pre><code>convert logo_000.png -sample '1920x1440!' dosbox-logo-0.png
convert logo_001.png -sample '1920x1440!' dosbox-logo-1.png</code>
</pre>
<pre><code>convert digger_000.png -sample '1920x1440!' dosbox-digger-0.png
convert digger_001.png -sample '1920x1440!' dosbox-digger-1.png</code>
</pre>

<!--
According to Screen Resolution Statistics for January 2020 by
w3schools.com, here are the statistics of browser resolutions:

Resolution   %age  Cumulative

Lower         9.0    9.0
1280 x  720   3.9   12.9
1024 x  768   1.4   14.3
1360 x  768   1.0   15.3
1366 x  768  27.6   42.9
1280 x  800   1.8   44.7
1536 x  864   9.8   54.5
1440 x  900   5.6   60.1
1600 x  900   4.1   64.2
1280 x 1024   2.4   66.6
1680 x 1050   2.6   69.2
1920 x 1080  20.3   89.5
1920 x 1200   1.5   91.0
2560 x 1440   1.7   92.7
Other High    7.3  100.0

1440 x 1080 is strictly larger than 55.3% displays.
1600 x 1200 is strictly larger than 66.6% displays.
1920 x 1440 is strictly larger than 91.0% displays.
x 1080 >= 89.5% displays
x 1200 >= 91.0% displays.
x 1440 >= 92.7% displays
-->

<p>
The <code>convert</code> program comes with ImageMagick. There are a few
things worth noting here:
</p>

<ul>
  <li>
    We use the <code>-sample</code> option here to resize the image as
    opposed to using <code>-resize</code> or <code>-scale</code>. The
    <code>-resize</code> or <code>-scale</code> option would smooth the
    jagged edges in the text and graphics by introducing additional
    colours. The <code>-resize</code> option is great for real world
    images where we do want the edges to be smooth while scaling up or
    down but in these screenshots we want to retain the crisp and jagged
    edges that is typical of DOSBox and the old CRT monitors. Therefore
    we use the <code>-sample</code> option that does not introduce any
    new colours. Instead it uses nearest-neighbour interpolation (point
    sampling) to decide the colours of the scaled image.
  </li>
  <li>
    The <code>!</code> flag is used to ignore the aspect ratio of the
    original image. Without this flag, the output files would be
    1920x1200 in size, that is, the largest size with an aspect ratio of
    8:5 that fits in a 1920x1440 box. With this flag, the original
    aspect ratio of 8:5 is ignored and the output is exactly 1920x1440
    in size.
  </li>
</ul>

<p>
By the way, I have donated these images above to Wikimedia Commons under
the Creative Commons Attribution 4.0 International (CC BY 4.0) license:
</p>

<ul>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Welcome_Screen.png">File:IBM_LCSI_Logo_Welcome_Screen.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Circles.png">File:IBM_LCSI_Logo_Circles.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Welcome_Screen.png">File:Digger_Original_PC_Booter_Version_Welcome_Screen.png</a>
  </li><li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Game.png">File:Digger_Original_PC_Booter_Version_Game.png</a></li>
</ul>

<p>
Having the images on Wikimedia Commons helps to include these
screenshots in the Wikipedia articles on <a href="https://en.wikipedia.org/wiki/Logo_(programming_language)#Implementations">Logo</a>
and <a href="https://en.wikipedia.org/wiki/Digger_(video_game)">Digger</a>.
</p>


<h2 id="dosbox-video-capture"><a href="#dosbox-video-capture">DOSBox Video Capture</a></h2>

<p>
To start capturing video of DOSBox, we press <kbd>Ctrl</kbd> +
<kbd>Alt</kbd> + <kbd>F5</kbd>. The same key combination stops capturing
video. The following output appears in the console output to show where
the video file is saved:
</p>

<pre><samp>Capturing Video to /Users/susam/Library/Preferences/capture/logo_000.avi
Stopped capturing video.</samp>
</pre>

<p>
Say, I want to share a video capture of DOSBox with Logo running on it
with my friends who might be on devices that do not support playing AVI
files. The following FFmpeg command converts the video to a format that
can be distributed widely and played on a wide range of devices and
players:
</p>

<pre><code>ffmpeg -i logo_000.avi -an -c:v libx264 -preset veryslow \
       -crf 17 -vf format=yuv420p,scale=1920:1440:flags=neighbor,fps=30 \
       dosbox-logo.mp4</code>
</pre>

<p>
Here is what the output looks like:
</p>

<figure id="logo-video">
  <video controls="">
    <source src="https://susam.in/files/blog/dosbox-logo.mp4" type="video/mp4">
  </video>
  <figcaption>
    Video capture of IBM Personal Computer Logo
    [<a href="https://susam.in/files/blog/dosbox-logo.mp4">MP4</a>]
  </figcaption>
</figure>

<p>
Let us briefly discuss the various FFmpeg options used here:
</p>

<ul>
  <li>
    <p>
      <code>-i logo_000.avi</code>
    </p>
    <p>
      This, of course, specifies the input file.
    </p>
  </li>
  <li>
    <p>
      <code>-an</code>
    </p>
    <p>
      The audio is silent in this video, so we reduce the file size a
      little by disabling the audio stream with this option. For
      example, without this option the output file size was 317 KB but
      with this option it turned out to be 282 KB.
    </p>
    <p>
      This option should not be specified if the audio stream needs to
      preserved, for example, with DOS games that have audio. We will
      see an example of this in the next section.
    </p>
  </li>
  <li>
    <p>
      <code>-c:v libx264</code>
    </p>
    <p>
      This option selects the x264 encoder to encode the video stream
      into H.264 format. H.264 is also known as MPEG-4 Part 10, Advanced
      Video Coding (MPEG-4 AVC). Currently, it is the most popular
      format for recording, compression, and distribution of video
      content.
    </p>
  </li>
  <li>
    <p>
      <code>-crf 17</code>
    </p>
    <p>
      This option provides visually lossless output, that is, high
      quality output without any loss in quality that can be perceived
      by human eyes. For completely lossless output, we need to use the
      <code>-crf 0</code> option. However, this option sets the video
      profile to <code>High 4:4:4 Predictive</code> which prevents the
      video from playing in some video players. This issue is discussed
      in more detail in the point about <code>yuv420p</code> pixel
      format that comes later in this list. Since <code>-crf 0</code>
      cannot be used due to this issue, the next best option is
      <code>-crf 1</code> which while not completely lossless is much
      better than …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://susam.in/blog/good-quality-dosbox-video-capture/">https://susam.in/blog/good-quality-dosbox-video-capture/</a></em></p>]]>
            </description>
            <link>https://susam.in/blog/good-quality-dosbox-video-capture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533484</guid>
            <pubDate>Sun, 20 Sep 2020 12:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting Apple Notes (6): The Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24533249">thread link</a>) | @LaSombra
<br/>
September 20, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve’s</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger’s Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won’t look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn’t plaintext and discover that you’re actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language’s include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don’t even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn’t needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can’t find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn’t do a great job of telling you you what might be in there. I made heavy use of mildsunrise’s <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533249</guid>
            <pubDate>Sun, 20 Sep 2020 11:02:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Skeletonised Leaves]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24532709">thread link</a>) | @arbol
<br/>
September 20, 2020 | https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/ | <a href="https://web.archive.org/web/*/https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1332">

	

	
			<figure>
				<img width="992" height="1331" src="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=992" alt="" loading="lazy" srcset="https://adq454703481.files.wordpress.com/2020/09/dried.jpg 992w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=768 768w" sizes="(max-width: 992px) 100vw, 992px" data-attachment-id="1333" data-permalink="https://blog.lidskialf.net/dried/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=763">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>I decided I wanted to try making some skeletonised leaves. So I did some Googling and decided to try <a href="https://penguinbaybiology.org/make-clear-leaf-view-vein-structure/">this</a> approach.</p>



<p>We went out in the evening and gathered some leaves from the local  Shrubbery. Totally not suspicious 🙂</p>



<figure><img data-attachment-id="1343" data-permalink="https://blog.lidskialf.net/leaves/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203574&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;909&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="leaves" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>I bought some Sodium Hydroxide and a cheap steel pot from ebay. Note: it must <strong>not</strong> be Aluminium as the Sodium Hydroxide will react with Aluminium!</p>



<figure><img data-attachment-id="1336" data-permalink="https://blog.lidskialf.net/ingredients/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381793&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;543&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ingredients" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Although Sodium Hydroxide isn’t a deadly poison, you really don’t want it on your skin or in your eyes, so gloves/goggles are a necessity for safety. Hmm, I should really look into some sort of cheap lab coat as well to protect my clothes for this sorta stuff:</p>



<figure><img data-attachment-id="1339" data-permalink="https://blog.lidskialf.net/safety/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381856&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;634&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="safety" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I scaled up the proportions to 1L of (Edinburgh) tap water and 30G of Sodium Hydroxide powder. I put them in the pot, brought it to the boil and added the leaves. </p>



<p>For fun I also tested the pH of the solution with my new pH paper (also from Ebay/China). Its about a 14, so pretty alkaline!</p>



<figure><img data-attachment-id="1340" data-permalink="https://blog.lidskialf.net/phpaper/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203853&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;108&quot;,&quot;shutter_speed&quot;:&quot;0.04001&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="phpaper" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>The instructions suggested boiling for about two hours, but it appears to depend on the leaves you choose. I checked on it every 20 minutes or so, and pulled leaves out as they became ready. </p>



<p>To process them, I had the following set up next to the pot:</p>



<ul><li>Tray 1: Plain tap water to wash off the Sodium Hydroxide.</li><li>Tray 2: Some “Ordinary Household Bleach” (aka Sodium Hypochlorite) to bleach any remaining colour out.</li><li>Tray 3: More plain tap water to wash off the bleach.</li><li>A sheet of alumunium foil to put the leaves on to dry out.</li></ul>



<p>After all of them were processed, I ended up with this:</p>



<figure><img data-attachment-id="1345" data-permalink="https://blog.lidskialf.net/drying/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600212131&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;104&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="drying" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The next morning I was able to unpeel the more robust leaves, yielding me these:</p>



<figure><img data-attachment-id="1346" data-permalink="https://blog.lidskialf.net/dried-1/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried-1" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>Observations</p>



<ul><li>You need to use <em>robust</em> leaves from trees. I tried some nettle leaves, but they quickly turned to mush. Some of the tree leaves appeared to process fine, but turned out to be way too delicate to remove from the foil after drying: definitely depends on the species. There may be a better way to dry them, will think on it.</li><li>Only process one species of leaf at a time, otherwise you constantly have to check each one in the pot, which means you’re disturbing them more to check.</li><li>Make sure to check on the water level! I <em>almost</em> boiled it dry.</li><li>Its fiddly! During processing, you have to <em>carefully</em> unroll the leaves by hand while wearing gloves to get them flat prior to drying.</li><li>I tried processing a dried up Oak leaf since theoretically it should be closer to being skeletonised: it didn’t seem to work very well (you can see the unsuccessful result on the aluminium foil photo).</li></ul>



<p>What Next?</p>



<p>They’re definitely more robust than I expected, but they’re still quite delicate. I fancy trying dying them and embedding them into some transparent resin next.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532709</guid>
            <pubDate>Sun, 20 Sep 2020 08:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generative Bad Handwriting]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24532352">thread link</a>) | @atulvi
<br/>
September 19, 2020 | https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>So.. I made a popular tweet last week in the <a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hashtag_click">#つぶやきProcessing</a> circles.</p>

<blockquote><p lang="cy" dir="ltr">j=24,m=0,draw=(a=&gt;{for(v=(i=&gt;w/3*(n=noise)(i)-k),createCanvas(w=1e3,w),noFill(),background('<a href="https://twitter.com/hashtag/fd7?src=hash&amp;ref_src=twsrc%5Etfw">#fd7</a>'),translate(0,m--),i=0,y=0;y&lt;w-m;y+=j)for(x=k=90;x&lt;w-k;x+=9)if(y+k&gt;-m?curve(v(i++)+x,v(i++)+y,x,j+y,x+9,j+y,v(i++)+x,v(i++)+y):i+=4,x+=v(i++)%9,n(x*y)&lt;.13)y+=j});//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/WNIwAAAXjQ">pic.twitter.com/WNIwAAAXjQ</a></p>— atulvinayak (@atulvinayak) <a href="https://twitter.com/atulvinayak/status/1305116417419653120?ref_src=twsrc%5Etfw">September 13, 2020</a></blockquote>


<p>I’ll try to explain how this script worked and how I was able to fit the whole thing into 280 characters. If you’re new to p5.js, just try pasting the tweet text to <a href="https://editor.p5js.org/" title="https://editor.p5js.org/">https://editor.p5js.org/</a> to get a similar output.</p>



<p>All of this started when last week when I was experimenting with the p5js <code>curve()</code> function. Internally this is an implementation of the <a href="https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline" title="Centripetal Catmull–Rom spline">Centripetal Catmull–Rom spline</a>. I tried generating a bunch of 8 legged water spiders for fun :)</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1303620577589039104/pu/vid/720x720/8iYWjReFxe-9kWVl.mp4?tag=10">
</video>

<p>I admit this looks pretty stupid. The aim was to generate an animation a whole bunch of water spiders with the camera panning around. But then, for me to understand how exactly the Catmull-Rom spline worked, I decided to randomly plot a bunch of curves on a 2D canvas and it somehow resembled handwriting from my native language (<a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>).</p>

<p><img src="https://avinayak.github.io/uploads/download-12.png" alt=""></p>

<p>Actual Malayalam handwriting sample.<br>
<img src="https://avinayak.github.io/uploads/4f31bc2ce9a02537444fc6eeea276dc5.jpg" alt=""></p>

<p>Reducing character spacing.. Do you see the similarity now?<br>
<img src="https://avinayak.github.io/uploads/download-10.png" alt=""></p>

<p>Also, at this time I was playing the PC remaster of <a href="https://en.wikipedia.org/wiki/Journey_(2012_video_game)">Journey (2012)</a>. Journey has a very beautiful blocky scriptures all over the temples in the game.</p>

<p><img src="https://avinayak.github.io/uploads/eayhyxhueaagmqu.jpg" alt=""></p>

<p>I guessed this is pretty easy generate. I made a few attempts to reproduce the approximate style using p5.js</p>

<p><img src="https://avinayak.github.io/uploads/download-8.png" alt=""></p>

<p>and even an infinite scrolling version</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1304311867284664323/pu/vid/720x720/zNWZ-LQrIl0KrnCU.mp4?tag=10">
</video>

<p>This script had some serious performance issues(you can see it slowing down towards the end). Later I learned that this style of meaningless writing is a thing in the art community known as Generative <a href="https://en.wikipedia.org/wiki/Asemic_writing">Asemic Writing</a>. According to Wikipedia:</p>

<blockquote>
  <p><strong>Asemic writing</strong> is a wordless open semantic form of writing. The word asemic means “having no specific semantic content”. With the nonspecificity of asemic writing there comes a vacuum of meaning which is left for the reader to fill in and interpret.</p>
</blockquote>

<p>I decided to combine the two and make an infinite generator of malayalam-esque asemic writing. I’ve seen curve generated asemic <a href="https://www.reddit.com/r/asemic/comments/dw5ze3/generative_script/?ref=share&amp;ref_source=link">before</a>. So, What I did is not something new.. however, maybe the way I made it infinite scrolling was something new(?). I’ll try to explain how the code works.</p>



<p>I lost the original script in the minifying process, but I managed to unminify the tweet somehow.</p>

<div><div><pre><code>var yOffset = 24;
var scrollPosition = 0;
var canvasWidth = 800;
var margin = 90

function setup() {
    createCanvas(canvasWidth, canvasWidth)
    noFill();
}

function deterministicRandom(index) {
  return 1000 / 3 * noise(index) - 90
}

function draw() {
    background('#fd7');
    translate(0, scrollPosition--);

    for (i = 0, y = 0; y &lt; canvasWidth - scrollPosition; y += yOffset)
        for (x = 90; x &lt; canvasWidth - margin;) {
            if (y + margin &gt; -scrollPosition) {
                curve(
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y, 
                  x, 
                  y + yOffset, 
                  x + 9, 
                  y + yOffset, 
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y
                )
            } else {
                i += 4
            }
            x += (9 + deterministicRandom(i++) % 9)
            if (noise(x * y) &lt; .13)
            {
              y += 2*yOffset
              x = margin
            }
        }

}
</code></pre></div></div>

<p>The most important part of the code is the function <code>deterministicRandom()</code> which is used a lot of times in the sketch. It’s basically <code>noise()</code> but mapped to range <code>[243, -90]</code>. p5 js <code>curve()</code> takes in 2 control point and 2 physical point coordinate to determine the location and shape of the curve. Each character is is thus a set of 4 deterministically random numbers for control points + 4 constants for physical points. All of these points are offset by a base <code>&lt;x,y&gt;</code> coordinate to place the curve in a line. <em>Because it’s deterministically random, the shapes and location of the curves are preserved in every frame</em>.. making the infinite scroll effect work.</p>

<p>The 2 loops iterate over x and y, at a constant rate. x by 9 pixels and y by 24 pixels. But, inside the loop, based on deterministic random, x is randomly incremented by up to 9 pixels to simulate the randomness in spaces between characters. Also, if for a random condition with somewhat low probability (<code>noise(x * y) &lt; .13</code>), a line-break is added. Which means, y is incremented thrice in that loop and x is reset to a margin value (90).</p>





<p>The infinite scroll effect is basically done using <code>translate(0, scrollPosition--)</code>. The loop termination clause is adjusted such that only lines within the frame are rendered (between <code>y = scrollPosition to scrollPosition+canvasHeight</code>). The condition <code>y + margin &gt; -scrollPosition</code> directly inside the loop checks for this. This also offsets the random number index to the one needed by the lines being rendered in the else case. Here’s a version of the script that shows lines being rendered as the script runs:</p>



<p>And that’s basically it. The initial version I designed rendered every line from the first scroll position to the last in every frame, even if those lines were not visible. This is terrible for performance and the if condition inside the loop fixed this.</p>



<p>Step one of minifying was converting all the functions to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions">arrow functions</a>. This took up way less space. Then I moved all the <code>setup()</code> stuff to <code>draw()</code>. p5 does not re-execute <code>createCanvas</code> even if you place it in <code>draw()</code>. Then I had to cut down number of variables as much as I can. 2 of them were reused: <code>canvasWidth(w)</code> and <code>margin(k)</code> were also used as a coefficient in <code>deterministicRandom()</code>. Finally spaces were removed and long names were truncated to single characters.</p>



<p>This script was written in about 2-3 hours. Looking back, I can see a lot of places where I’d try to reduce repeated code and make it smoother. I never thought this would go so popular, so I never really cared to optimize so much. But there you go.. a simple way to generate bad handwriting :)</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532352</guid>
            <pubDate>Sun, 20 Sep 2020 06:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Internet, Social Media and the Individual]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24532213">thread link</a>) | @nktsg
<br/>
September 19, 2020 | https://techimadions.com/internet-social-media-individual/ | <a href="https://web.archive.org/web/*/https://techimadions.com/internet-social-media-individual/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As the COVID-19 pandemic has proliferated and as we have come to terms with it, the Internet became the heartbeat of our world. It has already become ubiquitous in our lives but the pandemic has forced people and businesses to realize how our socioeconomic lives have become dependent on it. This is only going to accelerate in the coming years considering the new ways of work and interaction people have adopted over the previous few months.</p>
<p>On the other hand, this has left people with increased psychological disquiet since we're already overwhelmed by the influence of the Internet and social media in our day to day lives. It's ever more important to reflect on our relationship with the Internet on the individual front and ask hard questions about our future with it.</p>
<p>The following are some of my reflections on the current state of the influence of the Internet in our individual lives and what can be done.</p>
<h3>Connected But Dejected</h3>
<p>We are living in the most connected times, yet we've never felt more isolated collectively. Our phones ring with so many notifications in a day that no single notification has more value. The asynchronicity of our communication patterns has no definite coherent start and end. Text is not suitable for hourly long conversations over food and drinks; so now we talk in bits and pieces. Instant messaging has made communication so cheap and effortless that talking on the phone for more than a few minutes feels like dread. Social media, online news, and videos on anything take so much of our time that later we end up deciding whether to work or check for what's up with a friend/family member.</p>
<p>I think it's not the time that we end up sacrificing, it's the fear of missing out of things. Information moves so fast on the Internet that we trade-off attention for aggregation. We've started to live in two realities. One is physical and the other is digital and unfortunately, the digital one is taking the lead. Even when we are in the physical one, we left some part of ourselves in the digital one. It's like we're sailing two boats at the same time. We're in constant flux. It's not so difficult to map both the realities with the characteristics of the modern world that humans cherish. The digital one is fast, productive, opportunistic, economic, scalable, reliable, and mostly non-discriminatory. But all this comes at the cost of our psychological health. While we marvel at the disruptive innovations of digital connection that the Internet has sown seeds for, it's no substitute for our fundamental biological and physical need for connection. We still long to sense fellow humans by engaging with them in a physical medium. And that's when our psychological instincts find refuge.</p>
<h3>The Desire For Feedback</h3>
<p>We are a creature that loves attention. This starts from the day we are born. Babies demand attention to care. Teens demand attention to self-esteem. Adults require attention to form new connections that help in job prospects. Attention is a natural and necessary part of our biological behavior. The problem occurs when instead of getting attention as a result of our personalities, we tend to <strong>seek</strong> attention. What popular culture does is divide people into two categories: the influencer and the follower. Class-based societies are everywhere in the world. But popular culture creates another category.</p>
<p>Before the internet, there were fixed avenues for a person to become popular. Internet followed by social media turned the table upside down. And after the smartphone revolution, anyone having a phone got the tools to broadcast to possibly every other person on the planet. Social media started with networks of friends and family and platforms like Instagram and YouTube eventually turned it into a worldwide virtual stage.</p>
<p>Now, everybody has got everybody's attention. The playing field has been leveled. Everyone wants a piece of it. This behavior is not permanent though. In the end, everybody can't win. Since social media is far less daunting than the physical space, we tend to delegate the feedback mechanism of society to it. The effort required to represent oneself is frugal and the consequences are far less intimidating. And since the said rules and codes of society are not applicable here, the expectation for feedback increases.</p>
<h3>The Perfect Life Diet</h3>
<p>Social media was started as a way to connect with friends and family. At least, it was projected like that. It's not that we didn't have mediums for that before. I think it provided a great escape from physical reality especially for teens and young adults. We know that these years are an intimidating phase of our lives. Connecting with other people to know a little more something about their life and creating your persona was way much easier.</p>
<p>Once all the young people onboarded, the network effects made the older generation to join it. Text was still a banal way of sharing your life. Soon after, the social media companies realized that photos are more stimulating to us than text and activate more parts of our brain. Then came platforms like Instagram and Snapchat. Photos became the dominant media crossing through our minds. <a href="https://marshallmcluhan.com/">Marshall McLuhan</a> in his book quotes that in the long run, content matters less than the medium itself in influencing how we think and act. Soon after, the advertisers got hold of this fact and since more people were shifting to these platforms leaving TV and newspapers behind, advertising gave way for people to make some extra cash. Eventually, the ship started sailing and marketing picked up speed.</p>
<p>Advertising has always worked on exaggerated product characteristics and contrived human behaviors. As a result, people started sharing their ideal lives. The perfect couple, the perfect job, the perfect clothing, the perfect diet, the perfect fitness regime, the perfect accessories, the perfect home, the perfect vacation became mainstream outlook.  Some people post multiple photos in a single day. Young people have even started to start their professional journey on social media. Dissatisfaction start to seep in when we start to compare our persona with other people's personas. Comparison is a natural trait of us. That's how we perceive the world around us and separate one thing from another.</p>
<p>But it doesn't work the same way in the physical and digital space. In the physical space, there can only be a handful of objects or people in our line of vision. Hence, our brains get an ample amount of time to process our emotions.  This changes completely in the digital space. We go through so much media in so little time that the brain is not able to register all of them at the moment. Instead, it registers hooks to all the information which resurface later in our daily lives</p>
<h3>Mimetic Paralysis</h3>
<p><a href="https://iep.utm.edu/girard/">René Girard's</a> Mimetic theory’s key insight is that human desire is not an autonomous process, but a collective one. We want things because other people want them. This is ever more visible today as we spend more of our time watching what's going on with other people and the world. The increased consumption of digital media might be rewiring our brain structures in ways that we don't understand yet. While we are mapping our social behaviors in the physical world onto the digital world, our digital persona is creating a space of its own. This novel persona is being shaped by the values and norms of the digital atmosphere.</p>
<p>We can already see the effect on how people have started curating their digital persona according to these rules and how the nature of every social profile has started to look the same. Someone creates a new style of content and soon after you can see mushrooms of other people creating the same content. It's not a special trait of social media. Just that it has aggravated this trend. We don't realize when our digital worlds start to influence our physical world. The places we go, the things we buy, the food we eat. Some people have started even doing things in their physical worlds just to enhance their digital curation. The mostly independent nature of social media also attracts many of the young people. Bringing up connected is also a huge reason for the current generation of teens trying to find a stable work opportunity out of it.</p>
<h3>The Information Rabbit Hole</h3>
<p>How many times have you opened a bunch of links in different browser tabs; all seeming interesting just to realize that you can't possibly read all of it? How many times have you started watching something on YouTube just to realize that it's been hours? Every new second, someone is publishing content somewhere in the world. And it's all available instantly. There are no distribution costs. There is simply too much information now. There are news sites, wiki sites, videos, blog posts, independent publishers, newsletters, twitter threads, documentaries, etc.</p>
<p>But information is not a substitute for knowledge. This is a great misunderstanding of the post-internet era. Cramming our minds with disparate information doesn't make us knowledgeable. The brain is a very efficient machine. It doesn't retain information which it doesn't find useful regularly. That's why however a great article you've read days ago, you don't remember much of it.  We've delegated memorization to search engines. Memorization is a key element in forming a solid understanding of the world.  Since there is so much content, every different person is reading, watching, and listening to different things.</p>
<p>That's why it's getting harder to talk or chat about a common topic of interest. Consequences are FOMO and despair. You're now subject to know every social, political, national, geopolitical news. Every second something bad is happening in some part of the world and it's all visible in plain sight. But we can't do much about any single incident. This ends up in a lot of mental despair. In the end, we've to pick our battles. There is limited fuel in our brains and it's in our control what we choose to put it at work.</p>
<h3>Where's the …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techimadions.com/internet-social-media-individual/">https://techimadions.com/internet-social-media-individual/</a></em></p>]]>
            </description>
            <link>https://techimadions.com/internet-social-media-individual/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532213</guid>
            <pubDate>Sun, 20 Sep 2020 06:09:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prodigal Techbro]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24531490">thread link</a>) | @cyunker
<br/>
September 19, 2020 | https://conversationalist.org/2020/03/05/the-prodigal-techbro/ | <a href="https://web.archive.org/web/*/https://conversationalist.org/2020/03/05/the-prodigal-techbro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://conversationalist.org/2020/03/05/the-prodigal-techbro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531490</guid>
            <pubDate>Sun, 20 Sep 2020 02:06:14 GMT</pubDate>
        </item>
    </channel>
</rss>
