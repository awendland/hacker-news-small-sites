<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 05 Sep 2020 08:43:53 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 05 Sep 2020 08:43:53 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Top Tools to Make Debugging APIs Easier]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24362466">thread link</a>) | @todsacerdoti
<br/>
September 3, 2020 | https://blog.bearer.sh/api-debugging-tools/ | <a href="https://web.archive.org/web/*/https://blog.bearer.sh/api-debugging-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			<!--kg-card-begin: markdown--><p>Integrating with APIs can be challenging. Each with its own <a href="https://blog.bearer.sh/best-practices-for-navigating-api-documentation/">documentation format</a>, SDK patterns, and authentication quirks. Once you get the integration up and running, the harder step is testing and debugging any problems. This part can be exploratory‚Äîbefore you finish building‚Äîor as part of problem resolution.</p>
<p>While you can certainly debug within your codebase, by testing methods and reviewing logs, it can be beneficial to isolate the API calls by using one of the many API testing tools available.</p>
<p>Rather than list the pros and cons of each, let's focus on what makes each tool unique and worth trying.</p>
<h2 id="postman">Postman</h2>
<p>Cost: Free + Paid Plans</p>
<p><img src="https://blog.bearer.sh/content/images/2020/09/postman.png" alt="postman"></p>
<p><a href="https://postman.com/">Postman</a> is an institution in this space. It's been around for years, and went from a small app that made API calls into the full ecosystem that it is today. While Postman's primary use case is building and managing your own APIs, their emphasis on encouraging third-parties to publish collections has made it a great tool for exploring and debugging web services. These collections are what make Postman a fantastic tool for debugging external API calls.</p>
<p>Some providers, like Zendesk, <a href="https://developer.zendesk.com/rest_api/docs/sunshine/custom_objects_api">link directly to their Postman collections</a> in their documentation. Others can be found on Postman's <a href="https://explore.postman.com/">Explore</a> page, and then opened within the Postman app. Once installed, you can explore endpoints and resources with minimal setup.</p>
<p><a href="https://postman.com/">Learn more about Postman</a>.</p>
<h2 id="hoppscotch">Hoppscotch</h2>
<p>Cost: Free</p>
<p><img src="https://blog.bearer.sh/content/images/2020/09/hoppscotch.png" alt="hoppscotch"></p>
<p><a href="https://hoppscotch.io/">Hoppscotch</a> started as a faster, browser-first alternative to Postman, called Postwoman. It has since been rebranded and continues to add features. Its main benefits are speed and availability. It is also <a href="https://github.com/hoppscotch/hoppscotch">open source</a>, and can even run as a browser extension or progressive web app (PWA).</p>
<p><a href="https://hoppscotch.io/">Learn more about Hoppscotch</a>.</p>
<h2 id="paw">Paw</h2>
<p>Cost: Free Trial, then $49.99</p>
<p><img src="https://blog.bearer.sh/content/images/2020/09/paw.png" alt="paw"></p>
<p>Moving on to platform-specific applications, <a href="https://paw.cloud/">Paw</a> is a paid Mac application for interacting with APIs. Like many of the others, it's core focus is on providing a tool to build, test, and document your own APIs. Perhaps Paw's greatest selling point is the UI. Compared to many of the other application's on this list, it really feels like quality Mac-first software. It also offers Team functionality, and an interesting feature called Pawprint that lets you share request/response pairs via a URL, even if the receiver doesn't use Paw.</p>
<p><a href="https://paw.cloud/">Learn more about Paw</a>.</p>
<h2 id="insomnia">Insomnia</h2>
<p>Cost: Free + Paid plans.</p>
<p><img src="https://blog.bearer.sh/content/images/2020/09/insomnia.png" alt="insomnia"></p>
<p><a href="https://insomnia.rest/">Insomnia</a> is another API client that lets you design, debug, and test APIs. Unlike some of the other "all-inclusive" applications, Insomnia splits the API designer functionality into a seperate app. This makes the UI much more approachable, and makes it easier to quickly try out a new request without excess setup and configuration.</p>
<p>One additional tool that you can find in their documentation is a CLI version called Inso. It allows you to use the functionality from both their core Insomnia client as well as the designer app, right from the command line, and even from within CI/CD environments.</p>
<p><a href="https://insomnia.rest/">Learn more about Insomnia</a>.</p>
<h2 id="fiddler">Fiddler</h2>
<p>Cost: Free + Paid plans</p>
<p><img src="https://blog.bearer.sh/content/images/2020/09/fiddler.png" alt="fiddler"></p>
<p>While the rest of the applications in this list are centered around allowing you to directly interface with APIs, <a href="https://www.telerik.com/fiddler">Fiddler</a> takes a different approach. It is more of a general purpose web debugging tool. It acts as a proxy to capture local requests between your device and the internet. This means you can run your application locally, and inspect any outgoing requests and incoming responses from the Fiddler application.</p>
<p>This approach can be useful for live-debugging, but it also allows you to mock requests and responses that match specific rules. Combined with features around creating collections of requests and responses, and the ability to collaborate with a team, this approach could really help debugging more complex API problems.</p>
<p><a href="https://www.telerik.com/fiddler">Learn more about Fiddler</a></p>

<p>Cost: Free + Paid plans</p>
<p><img src="https://blog.bearer.sh/content/images/2020/09/http-toolkit.png" alt="http-toolkit"></p>
<p><a href="https://httptoolkit.tech/">HTTP Toolkit</a> is another proxy-style tool like Fiddler, but it is much easier to use and allows you to target specific apps and devices. Where I had trouble getting Fiddler to recognize calls made from my terminal, HTTP Toolkit just worked immediately. The Pro plans offer some really interesting features, such as modifying calls as they are sent, simulating timeouts, and simulating connection failures. In a lot of ways, it feels like the browser's "Network" panel, but for any application.</p>
<p>There's clearly a goal of developer productivity, shown through small touches like inline documentation for status codes and headers, as well as the ability to export code for the API call itself in a variety of languages. It's also open source, which is always a nice bonus.</p>
<p><a href="https://httptoolkit.tech/">Learn more about HTTP Toolkit</a></p>
<h2 id="bearer">Bearer</h2>
<p>Cost: Free + Paid plans</p>
<p><a href="https://www.bearer.sh/">Bearer</a> takes a different approach, in that it monitors APIs from within your application with minimal code changes. Any common issues are detected and collected in the dashboard, but you can also set up custom rules for edge case problems. This is a great way to actively debug, but also passively keep watch for unexpected problems that may arise with web services.</p>
<p><img src="https://blog.bearer.sh/content/images/2020/09/bearer.png" alt="bearer"></p>
<p><a href="https://www.bearer.sh/">Learn more about Bearer</a></p>

<p>Choosing the right tool, not just for the task, but also for your workflow can be a challenge. Fortunately, all of the options we've looked at here are free or offer free trials to get you started. Whether you're doing some exploratory testing, debugging a rare problem, or looking for a way to make your integrations more reliable, there's an existing API debugging and testing tool that can help.</p>
<!--kg-card-end: markdown-->
		</section></div>]]>
            </description>
            <link>https://blog.bearer.sh/api-debugging-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24362466</guid>
            <pubDate>Thu, 03 Sep 2020 10:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic SSL Certificates for internal IP's for home k8 setup using LetsEncrypt]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24361930">thread link</a>) | @gcds
<br/>
September 3, 2020 | https://www.techprowd.com/automatic-ssl-certificates-for-home-microk8s-setup-using-letsencrypt/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/automatic-ssl-certificates-for-home-microk8s-setup-using-letsencrypt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>One of the issues I discovered while playing with microk8s Kubernetes setup locally was that many services and tools like <code>Kubernetes Dashboard</code> uses HTTPS for access and I don't want to use Self-Signed SSL certificates as it would require me installing these certificates in every device I use which would be a pain in the butt. So I was on the journey finding a way to have an SSL Certificate for my internal IP addresses. This article will document my journey of getting automatic SSL certificates for my internal microk8s Kubernetes setup.</p><h2 id="ssl-certificate-for-internal-ip-address">SSL Certificate for internal IP address?</h2><p>My first question was is there a way to get an SSL certificate from Public trusted Certificate Authority after looking at many free services like Let's Encrypt and similar services don't provide certificates to IP addresses, but only to domain names.</p><p>After discovering the issue with no way to get an SSL certificate for internal IP I was looking into other options for my problem. After racking my brains for a few minutes I had a question: Could I create a DNS A record for internal IP and would it work? A quick visit to my DNS control panel adding A record to the local IP address and visiting the domain name and seeing my local IP address served website I was amazed that it worked.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image.png 1000w, https://www.techprowd.com/content/images/2020/09/image.png 1212w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-1.png" alt=""></figure><p>Discovering that I can have a domain name for internal IP working I was surprised now I had curiosity if I will be able to use service like Let's Encrypt to generate an SSL Certificate for this domain name but if I remember correctly the Let's Encrypt requires external access to verify domain name ownership. Hmm, maybe there is a way to verify domain name ownership without external access? After some digging around Let's Encrypt documentation, I found that there many ways to verify domain ownership one of them is DNS plugins which have many DNS providers to automatically verify domains by modifying DNS records using API from those providers. In my case it is DigitalOcean.</p><p>Following <code>certbot-dns-digitalocean</code> <a href="https://certbot-dns-digitalocean.readthedocs.io/en/stable/">documentation</a>I tried to generate a certificate for internal IP but I ran into the issue that default macOS <code>certbot</code> installation from <code>brew install certbot</code> had no <code>certbot-dns-digitalocean</code> plugin available.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>After a quick search online I found that DNS Plugins are not installed by default with <code>certbot</code>. I needed to install <code>certbox-dns-digitalocean</code> plugin using PIP</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Afterward, I was able to generate a certificate without many issues:</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Applying SSL certificate to local HTTPS server I was able to get HTTPS valid response from the internal IP address using a domain name</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-5.png" alt=""></figure><p>Now that I know that I can generate &amp; use an SSL certificate for internal IP address just by using a domain name. Now I can try to migrate this knowledge to integrate this to microk8s local setup.</p><h2 id="integrating-let-s-encrypt-with-dns-challenge-into-microk8s-setup-using-cert-manager">Integrating Let's Encrypt with DNS challenge into microk8s setup using <code>cert-manager</code></h2><p>I am not going to describe microk8s Kubernetes setup as it is pretty straightforward compared to the plain Kubernetes setup.</p><p>The first step is to install <code>cert-manager</code> I will be using Helm to install it.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now let's configure Certificate Issuer. I will be using the configuration for DigitalOcean but it should be pretty easy to follow instructions from <a href="https://cert-manager.io/docs/configuration/acme/dns01/">documentation</a>.</p><p>First, we need DigitalOcean API token Base64 encoded to be saved in secrets</p><p>You can encode token to base64 using <code>echo -n "Token" | base64</code></p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now we need to configure Certificate Issuer. (I had to change kind from <code>Issuer</code> to <code>ClusterIssuer</code> because of namespace issues)</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now that we configured everything we should use the SSL certificate somewhere for this article I will configure microk8s ingress to allow access to <code>kubernetes-dashboard</code> via <code>https://server.techprowd.com/dashboard</code></p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now after applying the resources we can check if our certificate resource was created and check if our Let's Encrypt Certificate was created too</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now that everything created we should be able to access <code>https://server.techprowd.com/dashboard</code></p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-6.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-6.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-6.png 1000w, https://www.techprowd.com/content/images/2020/09/image-6.png 1135w" sizes="(min-width: 720px) 720px"></figure><p>If I understood correctly the Certificate will be automatically renewed when expiration time comes up.</p><p>So that's all for this article. I hope this helped other people who had similar ideas like me when started working with Kubernetes.</p><p>P.S. I am not a professional Kubernetes engineer and everything mentioned in this article is just my assumptions and trying out practices in the local environment.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://www.techprowd.com/automatic-ssl-certificates-for-home-microk8s-setup-using-letsencrypt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24361930</guid>
            <pubDate>Thu, 03 Sep 2020 08:27:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Be Indistractable]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24360966">thread link</a>) | @nireyal
<br/>
September 2, 2020 | https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you | <a href="https://web.archive.org/web/*/https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>√¢‚Ç¨ÀúJust a second. I just need to respond to this one thing,√¢‚Ç¨‚Ñ¢ I said to my daughter, as I attended to my iPhone.</p>
<p>Only much later could I count the mistakes in that statement. No, it wouldn√¢‚Ç¨‚Ñ¢t take √¢‚Ç¨Àújust a second√¢‚Ç¨‚Ñ¢; no, I didn√¢‚Ç¨‚Ñ¢t √¢‚Ç¨Àúneed√¢‚Ç¨‚Ñ¢ to respond to the email √¢‚Ç¨‚Äú I√¢‚Ç¨‚Ñ¢m an author and researcher, and thus rarely receive messages that have a drop-everything-and-answer urgency to them. And no, it wouldn√¢‚Ç¨‚Ñ¢t be √¢‚Ç¨Àúone thing√¢‚Ç¨‚Ñ¢. My brain would be too tempted, I√¢‚Ç¨‚Ñ¢d feast on it all.</p>
<p>After I finished, I looked up and my daughter was gone. The worst part: before I became distracted, we had been playing a lovely game, telling each other what superpower we most wished for. It could have brought us closer together, but I√¢‚Ç¨‚Ñ¢d just blown the spirit and substance of it big-time.</p>
<p>If you√¢‚Ç¨‚Ñ¢re a parent in the 21st century, I bet you√¢‚Ç¨‚Ñ¢ve experienced your own version of this. But it√¢‚Ç¨‚Ñ¢s not just parents, it√¢‚Ç¨‚Ñ¢s all of us in our interactions with each other. Distraction has become the norm. We√¢‚Ç¨‚Ñ¢re blessed with pocket-sized supercomputers that connect us to anyone and everyone, and a buffet of information. But there√¢‚Ç¨‚Ñ¢s a dark side: those same gadgets distract us, often at the moments that matter most.</p>
<p>Of course, smartphones didn√¢‚Ç¨‚Ñ¢t invent distraction √¢‚Ç¨‚Äú they√¢‚Ç¨‚Ñ¢re just the latest culprit. Before that, we blamed television. And before that, it was the telephone, or comic books, or the radio. Go back more than 2,000 years, and Socrates was even criticising the written word, for causing √¢‚Ç¨Àúforgetfulness in the learners√¢‚Ç¨‚Ñ¢ souls√¢‚Ç¨‚Ñ¢.</p>
<p>Still, our present feels different, with the sources of distraction seeming greater in number and more ubiquitous. One <a href="https://journals.sagepub.com/doi/full/10.1177/0013916514539755">study</a> in 2014 showed that when two people are talking, the mere presence of a smartphone resting on a table is enough to change the character of their conversation. That√¢‚Ç¨‚Ñ¢s a tame example. To see the seriousness of the problem, look at the sobering <a href="https://www.nhtsa.gov/risky-driving/distracted-driving">statistics</a> on √¢‚Ç¨Àúdistracted driving√¢‚Ç¨‚Ñ¢ in the United States.</p>
<p>After I abandoned my daughter and our game for an utterly inconsequential email, I realised I needed to deal with my distraction problem. First, I tried a popular approach: I blamed technology and made a serious attempt at a √¢‚Ç¨Àúdigital detox√¢‚Ç¨‚Ñ¢. I bought a flip phone, subscribed to a print newspaper, and even purchased a 1990s-era word processor without an internet connection. I convinced myself that, once I banished all the technology from my life, I√¢‚Ç¨‚Ñ¢d become the disciplined writer and focused father I√¢‚Ç¨‚Ñ¢d always strived to be.</p>
<p>Talk about a rude awakening. Sitting at my ancient word processor, my eyes began to peer over to my now-tantalising bookshelf. √¢‚Ç¨ÀúHmmm,√¢‚Ç¨‚Ñ¢ I said to myself, √¢‚Ç¨ÀúI really should take a glance at this book√¢‚Ç¨‚Ñ¢. I√¢‚Ç¨‚Ñ¢d justify the distraction as necessary for √¢‚Ç¨Àúresearch√¢‚Ç¨‚Ñ¢. And if it wasn√¢‚Ç¨‚Ñ¢t reading, then I√¢‚Ç¨‚Ñ¢d find something else √¢‚Ç¨‚Äú the laundry that <em>needed</em> to be folded right now, my desk that <em>needed</em> to be tidied-up this minute. The technology wasn√¢‚Ç¨‚Ñ¢t distracting me. <em>I</em> was distracting me.</p>
<p>That√¢‚Ç¨‚Ñ¢s when I started a five-year journey to understand <a href="https://www.nirandfar.com/distractions/">distraction</a>, its causes and its cures. I discovered a great deal that I found surprising and counterintuitive, and I developed methods to deal with my distraction that actually worked √¢‚Ç¨‚Äú and didn√¢‚Ç¨‚Ñ¢t involve me trying to turn back time and operate a flip phone. I realised that distraction often begins from within, not without, and found that the fix came from identifying and managing the psychological discomfort that leads us off track.</p>
<p>As often as not, distraction is your brain ducking challenging feelings such as boredom, loneliness, insecurity, fatigue and uncertainty. These are the internal triggers √¢‚Ç¨‚Äú the <a href="https://www.nirandfar.com/kids-video-game-obsession/">root causes</a> √¢‚Ç¨‚Äú that prompt you to find the comfort of distraction and open a browser tab, Twitter or email, instead of focusing on the matter at hand. Once you identify these internal triggers, you can decide to respond in a more advantageous manner. You won√¢‚Ç¨‚Ñ¢t always be able to control how you feel √¢‚Ç¨‚Äú but you can learn to control how you react to the way you feel. A trigger that once sent you to Twitter can perhaps lead instead to 10 deep breaths.</p>
<p>Distraction, in other words, is a symptom of a problem √¢‚Ç¨‚Äú not the problem itself. Those deeper and systemic reasons √¢‚Ç¨‚Äú such as an inability to cope with fear, anxiety or stress √¢‚Ç¨‚Äú deserve our concern, because it√¢‚Ç¨‚Ñ¢s only when we start to address them that we can make real progress. When we begin to understand what we√¢‚Ç¨‚Ñ¢re trying to avoid by clicking over to Twitter or checking the news for the 10th time today, we can begin to address the issue itself, and not medicate it through more distraction. We also begin to appreciate how habitual the act of avoiding discomfort via distraction can be, and how much it√¢‚Ç¨‚Ñ¢s become a part of how we work and live.</p>
<p>The good news is that there√¢‚Ç¨‚Ñ¢s something paradoxical about discomfort: it√¢‚Ç¨‚Ñ¢s actually the best tool we have for evolving and developing as a species. Feeling bad isn√¢‚Ç¨‚Ñ¢t actually bad; it√¢‚Ç¨‚Ñ¢s what helped us survive. Writing in 2001, the American psychologist Roy Baumeister and his colleagues <a href="https://psycnet.apa.org/record/2018-70020-001">observed</a>: √¢‚Ç¨ÀúIf satisfaction and pleasure were permanent, there might be little incentive to continue seeking further benefits or advances.√¢‚Ç¨‚Ñ¢ If we didn√¢‚Ç¨‚Ñ¢t feel bad, in other words, we√¢‚Ç¨‚Ñ¢d never achieve good.</p>
<p>Once you understand the depth of distraction, you can start to manage it and improve. After years of experiments, I found myself less distracted √¢‚Ç¨‚Äú a quality that improved nearly every aspect of my life. It turns out that being able to focus on the subjects and people in my life who matter improved everything from my health to my happiness to my productivity. That can seem obvious, but I couldn√¢‚Ç¨‚Ñ¢t have fully appreciated the joys of living an indistractable life if I hadn√¢‚Ç¨‚Ñ¢t gotten there on my own after a five-year journey. Being indistractable can lead you to not just change your life for the better, but also experience life fully.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>Self-explore</strong></p>
<p>Identifying the triggers that made you feel bad in the first place requires self-exploration. When you notice yourself feeling distracted, pause and ask yourself what you√¢‚Ç¨‚Ñ¢re feeling. Are you worried? Are you afraid? Then go one step deeper. What caused the sensation? How does it feel in your body?</p>
<p>In exploring my own internal triggers, I began to appreciate that my anxiety about a project, which might lead me to find a tempting Wikipedia rabbit hole, was actually adaptive: the fact that I was anxious was good because it meant I was trying to become better. It was sometimes even as easy as saying to myself: √¢‚Ç¨ÀúYou√¢‚Ç¨‚Ñ¢re getting distracted right now because you√¢‚Ç¨‚Ñ¢re worried this won√¢‚Ç¨‚Ñ¢t be up to snuff. That√¢‚Ç¨‚Ñ¢s okay. It means you√¢‚Ç¨‚Ñ¢re trying to do your best work, and that√¢‚Ç¨‚Ñ¢s something to feel good about.√¢‚Ç¨‚Ñ¢ It seems like a simple mental trick, but even that thought can have a profound influence in keeping you on track.</p>
<p>There√¢‚Ç¨‚Ñ¢s an interesting paradox about internal triggers: they can be big, imposing, powerful issues, and yet the fixes can sometimes be easy and quick. Here√¢‚Ç¨‚Ñ¢s an example: let√¢‚Ç¨‚Ñ¢s say that an internal trigger when you√¢‚Ç¨‚Ñ¢re about to get started on a looming project is boredom. You just can√¢‚Ç¨‚Ñ¢t bring yourself to get excited about doing your taxes. And because you get bored, you get distracted. But if you know you√¢‚Ç¨‚Ñ¢re going to get bored, you can find ways to avoid the distraction that will soothe the boredom. For instance, if you set a time limit to work on the otherwise mind-numbing task that is so short, you won√¢‚Ç¨‚Ñ¢t have a chance to get bored. Anyone can work on their taxes for just 10 minutes. This is called the <a href="https://www.nirandfar.com/strange-sex-habits-of-silicon-valley/">10-minute rule</a>, and it√¢‚Ç¨‚Ñ¢s an effective way to avoid distractions of all sorts. The point is to anticipate the internal trigger and then intercept it with a new routine rather than allowing yourself to slink away into doing something you didn√¢‚Ç¨‚Ñ¢t intend to do.</p>
<p>In the case of my interaction with my daughter, the internal trigger might have been anxiety about work or <a href="https://www.nirandfar.com/fomo/">fear of missing out</a> (on an email). But I can address both of those proactively, so that they don√¢‚Ç¨‚Ñ¢t interfere with precious daddy-daughter time. In the case of my work anxiety, I could make sure that someone on my team is monitoring incoming messages. I could put up an √¢‚Ç¨Àúout of office√¢‚Ç¨‚Ñ¢ email that encourages people to call me if there√¢‚Ç¨‚Ñ¢s really an emergency. Or in reality, I could get comfortable with the discomfort that I might indeed be missing out on something, but that√¢‚Ç¨‚Ñ¢s all right too. Any one of those is a better and more constructive response to the internal trigger than being distracted.</p>
<p>Whatever approach you take to address your inner triggers, it√¢‚Ç¨‚Ñ¢s encouraging to note that merely recognising uncomfortable feelings and identifying them could be beneficial. For instance, in a smoking-cessation <a href="https://www.sciencedirect.com/science/article/abs/pii/S0376871611002535?via%3Dihub">study</a>, researchers found that participants who learned to acknowledge and explore their cravings managed to quit smoking at double the rates of those in the American Lung Association√¢‚Ç¨‚Ñ¢s best-performing cessation programme. Just identifying and investigating a craving had a tremendous impact.</p>
<p><strong>Reframe</strong></p>
<p>Once you√¢‚Ç¨‚Ñ¢ve identified the triggers, you can reframe the task at hand. Sure, you might be √¢‚Ç¨Àúforced to do your taxes√¢‚Ç¨‚Ñ¢. But another way of thinking about that is that you √¢‚Ç¨Àúget to review last year√¢‚Ç¨‚Ñ¢s business successes√¢‚Ç¨‚Ñ¢. It sounds laughable, but it works. When I hit rough patches mid-book writing, I would say: √¢‚Ç¨ÀúI get to share this with my audience,√¢‚Ç¨‚Ñ¢ as opposed to: √¢‚Ç¨ÀúI really have to work on the book today.√¢‚Ç¨‚Ñ¢</p>
<p>Here√¢‚Ç¨‚Ñ¢s one strategy: I found the fun in whatever I was doing. Yes, I know, this is where you roll your eyes, but hear me out. I learned to stay focused on the tedious work of writing books by looking for and finding the mystery embedded in my work. I wasn√¢‚Ç¨‚Ñ¢t √¢‚Ç¨Àúwriting√¢‚Ç¨‚Ñ¢, I was √¢‚Ç¨Àúexploring√¢‚Ç¨‚Ñ¢. I wasn√¢‚Ç¨‚Ñ¢t Ernest Hemingway; I was Scooby-Doo. Research indicates that even the simple act of thinking of something that you don√¢‚Ç¨‚Ñ¢t enjoy as ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you">https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-24360966</guid>
            <pubDate>Thu, 03 Sep 2020 05:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even in Go, concurrency is still not easy]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24359650">thread link</a>) | @benhoyt
<br/>
September 2, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Even in Go, concurrency is still not easy (with an example)</h2>

	<p><small>September  1, 2020</small></p>
</div><div><p>Go is famous for making concurrency easy, through good language
support for <a href="https://golangbot.com/goroutines/">goroutines</a>. Except
what Go makes easy is only one level of concurrency, the nuts and
bolts level of making your code do things concurrently and communicating
back and forth through channels. Making it do the right things
concurrently is still up to you, and unfortunately Go doesn't
currently provide a lot of standard library support for correctly
implemented standard concurrency patterns.</p>

<p>For example, one common need is for a limited amount of concurrency;
you want to do several things at once, but only so many of them.
At the moment this is up to you to implement on top of goroutines,
channels, and things like the <a href="https://golang.org/pkg/sync/"><code>sync</code></a>
package. This is not as easy as it looks, and quite competent people
can make mistakes here. As it happens, I have an example ready to
hand today.</p>

<p><a href="https://github.com/google/gops">Gops</a> is a convenient command to
list (and diagnose) Go processes that are currently running on your
system. Among other things, it'll tell you which version of Go they
were compiled with, which is handy if you want to see if you have out
of date binaries that should be rebuilt and redeployed. One of the
things <code>gops</code> needs to do is look at all of the Go processes on your
system, which it does concurrently. However, it doesn't want to look
at too many processes at once, because <a href="https://github.com/google/gops/pull/118">that can cause problems with
file descriptor limits</a>. This
is a classic case of <em>limited concurrency</em>.</p>

<p>Gops implements this at the moment with code in <a href="https://github.com/google/gops/blob/6fb0d860e5fa50629405d9e77e255cd32795967e/goprocess/gp.go#L29">goprocess.FindAll()</a>
that looks like this, in somewhat sketched and reduced form:</p>

<blockquote><pre>func FindAll() []P {
   pss, err := ps.Processes()
   [...]
   found := make(chan P)
   limitCh := make(chan struct{}, concurrencyProcesses)

   for _, pr := range pss {
      limitCh &lt;- struct{}{}
      pr := pr
      go func() {
         defer func() { &lt;-limitCh }()
         [... get a P with some error checking ...]
         found &lt;- P
      }()
   }
   [...]

   var results []P
   for p := range found {
      results = append(results, p)
   }
   return results
}
</pre>
</blockquote>

<p>(In the real code there's a WaitGroup for coordination, and the
<code>found</code> channel gets closed appropriately.)</p>

<p>How this works is clear, and is a standard pattern (covered in eg
Go 101's <a href="https://go101.org/article/channel-use-cases.html">Channel Use Cases</a>). We use a
buffered channel to provide a limited number of tokens; sending a
value into the channel implicitly takes a token (and blocks if the
token supply is exhausted), while receiving a value from it puts a
token back in. We take a token before we start a new goroutine, and
the goroutine releases the token when it's done.</p>

<p>Except that <a href="https://github.com/google/gops/issues/123">this code has a bug if there are too many processes
to examine</a>. Even knowing
that there is a bug in this code, it may not be obvious.</p>

<p>The bug is that the goroutines only receive from <code>limitCh</code> to release
their token after sending their result to the unbuffered <code>found</code>
channel, while the main code only starts receiving from <code>found</code>
after running through the entire loop, and <strong>the main code takes
the token in the loop and blocks if no tokens are available</strong>. So
if you have too many processes to go through, you start N goroutines,
they all block trying to write to <code>found</code> and don't receive from
<code>limitCh</code>, and the main <code>for</code> loop blocks trying to send to <code>limitCh</code>
and never reaches the point where it starts receiving from <code>found</code>.</p>

<p>At one level, this bug is a very fragile bug; it only exists because
of multiple circumstances. If the goroutines took the token by
sending to <code>limitCh</code> instead of the main <code>for</code> loop doing it, the
bug would not exist; the main <code>for</code> loop would start them all, many
would stop, and then it would go on to receive from <code>found</code> so that
they could receive from <code>limitCh</code> and release their token so other
goroutines would run. If the goroutines received from <code>limitCh</code> to
release their token before sending to <code>found</code>, it wouldn't exist
(but because of error handling, it's simpler and more reliable to
do the receive in a <code>defer</code>). And if the entire <code>for</code> loop was in
an additional goroutine, the main code would go on to receive from
<code>found</code> and unblock completed goroutines to release their tokens,
so the fact that the <code>for</code> loop was blocked waiting to send to
<code>limitCh</code> wouldn't matter.</p>

<p>At another level, this shows how concurrency is not easy as easy
as it looks in Go. All you need is one mistake and things skid to
a halt, and all of the code involved can look good to a casual
examination. Getting concurrency correct is simply hard for people
(we can debate about why, but I think that it is is very clear).</p>

<p>(I'm sure that the people who wrote and approved the change that
added this concurrency limiting code to gops were good programmers.
A tricky case still tripped them up, passing all of their scrutiny.
Even when I knew that there was a concurrency problem in the code
and where it was (because my <code>gops</code> was hanging all of a sudden,
and <a href="https://github.com/go-delve/delve">Delve</a> told me where
everything was stuck), it still took me some time to see what the
exact problem was.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24359650</guid>
            <pubDate>Thu, 03 Sep 2020 00:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Flight Simulator in Web Assembly]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24359640">thread link</a>) | @richardanaya
<br/>
September 2, 2020 | https://s-macke.github.io/FSHistory/ | <a href="https://web.archive.org/web/*/https://s-macke.github.io/FSHistory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://s-macke.github.io/FSHistory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24359640</guid>
            <pubDate>Thu, 03 Sep 2020 00:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I built a keyboard/video/mouse switch for my two 4k monitors]]>
            </title>
            <description>
<![CDATA[
Score 398 | Comments 188 (<a href="https://news.ycombinator.com/item?id=24357308">thread link</a>) | @car
<br/>
September 2, 2020 | https://haim.dev/posts/2020-07-28-dual-monitor-kvm/ | <a href="https://web.archive.org/web/*/https://haim.dev/posts/2020-07-28-dual-monitor-kvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I like my two big hi-res monitors. I love my keyboard and my mouse. And I connect them to my stationary
‚Äúmain‚Äù PC and to several other Windows and Mac laptops, alternatively. I‚Äôd like to easily switch where these peripheral
devices are connected to, and that‚Äôs the traditional role of a <a href="https://en.wikipedia.org/wiki/KVM_switch">KVM switch</a>.</p><p>Unfortunately for me, KVM switches that support 4K/60hz resolutions cost hundreds of dollars, there are
no KVM switches that support USB-C, and I couldn‚Äôt find KVM switches that support multiple high-res monitors
either.</p><p>So I decided to implement a mixed hardware/software solution: my monitors (all monitors today really) have more
than one input, so I can connect all my computers simultaneously. The idea is:</p><ul><li>Switch USB devices in hardware.</li><li>Detect this switch in software, and switch monitors inputs as needed.</li></ul><p>To switch USB devices, I ordered <a href="https://www.amazon.ca/gp/product/B01N6GD9JO">this USB 3.0 two-computer switch</a> from Amazon,
that‚Äôs $38 Canadian, under $30 USD.</p><p>To automatically switch monitor inputs, I <a href="https://github.com/haimgel/display-switch">wrote some software</a>.</p><p>My plan was:</p><ul><li>Watch for USB device connections/disconnections.</li><li>When a configured device is connected, use <a href="https://en.wikipedia.org/wiki/Display_Data_Channel#DDC/CI">DDC/CI</a> to
send a command to all connected monitors to switch inputs.</li><li>In case the power management turned the video output off, turn it on again (otherwise the monitors will auto-switch
back to the input that actually supplies video output).</li></ul><p>I needed this to happen on Windows and on a Mac, and mature cross-platform support for USB low-level
control and hot plug, DDC/CI and monitor power management is non-existent. I ended up implementing this two
times: <a href="https://github.com/haimgel/display-switch/tree/master/MacOS">once in Swift</a>, for MacOS, and the
<a href="https://github.com/haimgel/display-switch/tree/master/Windows">second time in Rust</a>, for Windows.</p><p>Amazingly enough, this works really well: when I press the button on the USB switch, monitor input is changed
instantaneously, it feels like a ‚Äúreal‚Äù KVM switch! üéâ</p></div></div>]]>
            </description>
            <link>https://haim.dev/posts/2020-07-28-dual-monitor-kvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24357308</guid>
            <pubDate>Wed, 02 Sep 2020 19:56:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critical Wormable RCE Vulnerability Discovered in Cisco Jabber]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24355742">thread link</a>) | @watchcom
<br/>
September 2, 2020 | https://watchcom.no/nyheter/nyhetsarkiv/uncovers-cisco-jabber-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://watchcom.no/nyheter/nyhetsarkiv/uncovers-cisco-jabber-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TL;DR Four vulnerabilities in Cisco Jabber have been discovered by security consultants at Watchcom. One of the vulnerabilities allows Remote Code Execution (RCE) by sending specially crafted chat messages, either in group chats or directly to targeted users. No user interaction is required, and the vulnerability can be exploited even when Cisco Jabber is running in the background.</p><div data-module="editorial-page">
            <p><em>All vulnerabilities have been responsibly disclosed to Cisco and patches are available. If you or your organization are using Cisco Jabber, <strong>update now!</strong></em></p>
<p><img alt="" src="https://watchcom.no/siteassets/jabber-calc.gif" height="720" width="1280"></p>
<p><em>Figure 1: The Jabber RCE vulnerability in action.</em></p>
<p>Security consultants from Watchcom discovered the four high severity vulnerabilities while pen-testing for a client. The vulnerabilities affect all currently supported versions of the Cisco Jabber client (12.1 ‚Äì 12.9). The four vulnerabilities and their corresponding CVE numbers are listed below:</p>
<ul>
<li>CVE-2020-3495: Cisco Jabber Message Handling Arbitrary Code Execution (CVSS 9.9)</li>
<li>CVE-2020-3430: Cisco Jabber Protocol Handler Command Injection (CVSS 8.0)</li>
<li>CVE-2020-3498: Cisco Jabber Information Disclosure (CVSS 6.5)</li>
<li>CVE-2020-3537: Cisco Jabber Universal Naming Convention Link Handling (CVSS 5.7)</li>
</ul>
<p>This article describes the technical details of the vulnerabilities and gives useful advice for detection and mitigation.</p>
<h3>Introduction</h3>
<p>Cisco Jabber is a video conferencing and instant messaging application. It is mainly used for internal communication, but can also be used to chat, call or conduct meetings with people outside of the organization. These days a lot of people are working from home and applications like Cisco Jabber are essential to stay connected, communicate efficiently and keep businesses running smoothly.</p>
<p>Given their newfound prevalence in organizations of all sizes, these applications are becoming an increasingly attractive target for attackers. A lot of sensitive information is shared through video calls or instant messages and the applications are used by the majority of employees, including those with privileged access to other IT-systems.</p>
<p>The security of these applications is therefore paramount, and it is important to ensure that both the applications themselves, and the infrastructure they are using, are regularly audited for security gaps.</p>
<p>During a recent penetration test for an unrelated client, security consultants Olav Sortland Thoresen and Torjus Bryne Retterst√∏l from Watchcom discovered four serious vulnerabilities in Cisco Jabber. The vulnerabilities range from medium to critical severity and two of the vulnerabilities can be used to gain remote code execution. The most severe vulnerability is also wormable, meaning that it can be used to automatically spread malware without any user interaction.</p>
<p>Watchcom immediately reported these vulnerabilities to Cisco and coordinated a responsible disclosure. Patches have been issued and all Cisco Jabber users are strongly encouraged to update to the latest version.</p>
<h3>Background</h3>
<p>All four vulnerabilities affect the Cisco Jabber client application and were tested on Windows. The Cisco Jabber client is based on the Chromium Embedded Framework (CEF) and uses the Extensible Messaging and Presence Protocol (XMPP) for instant messages and presence updates. These two technologies are important for understanding the vulnerabilities and their implications. A brief overview of each of them is therefore provided below.</p>
<h3>Chromium Embedded Framework (CEF)</h3>
<p>CEF is a framework that allows developers to embed Chromium-based web browsers in their applications. It is used to create desktop applications based on web technologies like HTML, CSS and JavaScript. Normally, the code running in the embedded web browser is sandboxed and cannot access files or perform system calls. While this is a good security measure, application developers often want such functionality in their application and therefore find or create ways to bypass the sandbox.</p>
<p><em><strong>This leaves applications vulnerable in scenarios where the sandbox normally would‚Äôve provided protection.</strong></em></p>
<p>Additionally, many applications that use CEF choose to pass through command line flags to the embedded web browser. This means that many CEF applications accept <a href="https://www.chromium.org/developers/how-tos/run-chromium-with-flags" target="_blank">Chromium command line flags</a>. Some of these flags can be used to execute arbitrary commands or load arbitrary DLLs and should therefore be treated with caution.</p>
<h3>Extensible Messaging and Presence Protocol (XMPP)</h3>
<p>XMPP is an XML-based protocol for instant messaging and presence. It is based on an open standard and is widely used in both open-source and proprietary software. XMPP is an extensible protocol and several extensions that provide additional functionality to the protocol exist.</p>
<p><img alt="" src="https://watchcom.no/siteassets/figure2.png" height="209" width="1137"> <em>Figure 2: An XMPP message containing both a plaintext and an HTML version of a message.</em></p>
<p>One of these extensions is XEP-0071: XHTML-IM. This extension defines how instant messages containing HTML formatted content can be exchanged over XMPP. Since HTML content can contain malicious elements, the specification states that applications must assume that messages containing HTML are malicious and sanitize them accordingly.</p>
<p>It also states that it must be possible for users to prevent automatic loading of images. Not all applications take such precautions and we will later see how this is the root cause of two of the vulnerabilities that we discovered.</p>
<h3>Cross Site Scripting Leading to RCE Vulnerability</h3>
<p>Cisco Jabber is vulnerable to Cross Site Scripting (XSS) through XHTML-IM messages. The application does not properly sanitize incoming HTML messages and instead passes them through a flawed XSS filter.</p>
<p>The filter is based on a blacklist of known-bad tags and attributes, but it is not comprehensive. Since the application is based on CEF, its embedded web browser will execute any scripts that can pass through the filter.</p>
<p>We discovered that the filter could be bypassed using the lesser-known onanimationstart attribute. Tags that had this attribute were not caught by the filter and were directly inserted into the embedded web browser‚Äôs DOM. This attribute is used to specify a JavaScript function that will be called when an element‚Äôs CSS animation starts playing. To achieve XSS using this attribute the element must have an animation assigned to it. It was not possible to inject custom CSS animations since &lt;style&gt; tags were caught by the filter, but we discovered a built-in animation called spinner-grow by grepping through the files in the installation directory. By combining these two, it was possible to create malicious HTML tags that bypassed the filter and were executed.</p>
<p><img alt="" src="https://watchcom.no/siteassets/figure3.png" height="387" width="1003"> <em>Figure 3: An XHTML-IM message that has been intercepted and modified. A malicious &lt;img&gt; tag has been added.</em></p>
<p>Cisco Jabber uses XHTML-IM by default for all messages. A malicious message can therefore easily be created by intercepting an XMPP message sent by the application and modifying it. Attackers can do this manually on their own machine or it can be automated to create a worm that spreads automatically.</p>
<p><img alt="" src="https://watchcom.no/siteassets/figure4.png" height="783" width="1123"> <em>Figure 4: When the victim receives the message, the JavaScript code is executed. In this case the code opens an alert box as a proof of concept.</em></p>
<p>After achieving XSS, we started looking for ways to escape the CEF sandbox. A vulnerable function (named window.CallCppFunction) was identified. This function is used to invoke native C++ code and the application uses it to, among other things, open files received from other Cisco Jabber users.</p>
<p>We discovered that this function can be abused by an attacker to run arbitrary executable files on the victim‚Äôs machine. The function takes a file:// URL as its second parameter and by manipulating this parameter an attacker can execute arbitrary .exe files.</p>
<p><em><strong>Since Cisco Jabber supports file transfers, an attacker can initiate a file transfer containing a malicious .exe file and force the victim to accept it using an XSS attack. </strong></em></p>
<p>The attacker can then trigger a call to window.CallCppFunction, causing the malicious file to be executed on the victim¬¥s machine.</p>
<p><img alt="" src="https://watchcom.no/siteassets/figure5.png" height="464" width="794"> <em>Figure 5: An XHTML-IM message containing exploit code that escapes the CEF sandbox and launches calc.exe on the victim‚Äôs machine.</em></p>
<p>This vulnerability has been assigned CVE-2020-3495 with a CVSS score of 9.9 (Critical) / CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:H/I:H/A:H</p>
<h3>Protocol Handler Vulnerability</h3>
<p>While researching the XSS vulnerability, we discovered another high severity vulnerability concerning the handling of URLs with custom protocols.</p>
<p>Upon installation, Cisco Jabber registers protocol handlers for a number of different protocols. These are used to tell the operating system that whenever a user clicks on a URL containing one of the custom protocols (e.g. ciscoim:test@example.com) the URL should be passed to Cisco Jabber. In this case, the protocol handlers specify that the URL should be passed as a command line flag.</p>
<p><img alt="" src="https://watchcom.no/siteassets/figure6.png" height="255" width="1032"> <em>Figure 6: One of Cisco Jabber‚Äôs protocol handlers. The protocol handler specifies that URLs should be passed to the application as a command line flag.</em></p>
<p>These protocol handlers are vulnerable to command injection because they fail to consider URLs that contain spaces. By including a space in the URL, an attacker can inject arbitrary command line flags that will be passed to the application. Since the application uses CEF and accepts Chromium command line flags, several flags that can be used to execute arbitrary commands or load arbitrary DLLs exist. An example of such a flag is --GPU-launcher. This flag specifies a command that will be executed when CEFs GPU process is started.</p>
<p>This vulnerability can be combined with the XSS vulnerability to achieve code execution without transferring any files to the victim. This makes it possible to deliver malware without writing any files to disk, thus bypassing most antivirus software.</p>
<p>The video below shows the vulnerability being exploited. The attacker sends a malicious message, containing an XSS payload that escapes the CEF sandbox and uses the protocol handler vulnerability to execute commands on the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://watchcom.no/nyheter/nyhetsarkiv/uncovers-cisco-jabber-vulnerabilities/">https://watchcom.no/nyheter/nyhetsarkiv/uncovers-cisco-jabber-vulnerabilities/</a></em></p>]]>
            </description>
            <link>https://watchcom.no/nyheter/nyhetsarkiv/uncovers-cisco-jabber-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24355742</guid>
            <pubDate>Wed, 02 Sep 2020 17:45:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: New platform reveals the Jamstack to non-developers]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24355138">thread link</a>) | @ohadpr
<br/>
September 2, 2020 | https://www.stackbit.com/blog/announcing-stackbit-studio/ | <a href="https://web.archive.org/web/*/https://www.stackbit.com/blog/announcing-stackbit-studio/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When we started building what would eventually become the Stackbit platform, the Jamstack was still the JAMStack and the coolest parts about it were the technology that enabled it. It wasn√¢‚Ç¨‚Ñ¢t very fun to use, and it certainly wasn√¢‚Ç¨‚Ñ¢t for everybody.</p><p>Today, after tons of hard work and feedback, we√¢‚Ç¨‚Ñ¢re thrilled to announce the general availability of <strong>Stackbit Studio</strong>, the first complete platform for the Jamstack. Stackbit Studio fulfils the promise of the Jamstack by unlocking its potential for anyone.</p><ul><li><strong>Marketers</strong> can edit content inline and see live previews of their changes without bugging developers</li><li><strong>Agency and Freelance Web Developers</strong> can easily hand off projects to clients without having to worry about being on the hook for small changes and security issues</li><li><strong>Teams</strong> can collaborate and quickly share updates with stakeholders, designers, writers and dev</li></ul><p>and most importantly,</p><ul><li><strong>Anyone</strong> who wants to build websites can start their journey with the cutting edge, secure, and fast technological wonder that the Jamstack has matured into</li></ul><h2>Stackbit Studio - The live editing experience at the heart of our complete Jamstack platform</h2><p><video width="640" height="444" autoplay="" muted="" loop=""><source src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-editing.mp4" type="video/mp4"><img src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-editing.gif" alt="Example of the inline editing experience in Stackbit Studio"></video></p><p>You can pick a theme and deploy a test site to <a href="https://app.stackbit.com/create">play with the Studio,</a> or <a href="https://youtu.be/zd9lGRLVDm4">watch a quick video walkthrough on YouTube</a>. Here√¢‚Ç¨‚Ñ¢s a quick tour of what is available in the Stackbit Studio, today:</p><h3>Connected Tools</h3><p>Stackbit is the first complete platform for the Jamstack. We work with your tools, and make the ecosystem accessible to everyone. When editing a site in the Studio, your headless CMS updates automatically with all the changes you made to text, images, and other on-page elements. Stackbit Studio works with Next.js, Gatsby, Hugo or Jekyll for your static site generators, and Contentful, Sanity, and even plain ol√¢‚Ç¨‚Ñ¢ git for your headless CMS, with more SSGs, headless CMS and other integrations coming soon.</p><h3>Advanced Control</h3><p>We want to enable everyone to build creative and powerful Jamstack sites. We√¢‚Ç¨‚Ñ¢re releasing several advanced features that make Stackbit Studio the ultimate environment to build in, whether you√¢‚Ç¨‚Ñ¢re just starting out or have an existing site ready to grow.</p><p><strong>Live previews:</strong> Any changes you make will be instantly previewed right then and there.</p><p><strong>Inline editing:</strong> Now everyone can <a href="https://www.stackbit.com/docs/using-stackbit/editing-content/#video_editing_content">update content with a click</a>.</p><p><img src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-text-editing.png" alt="Example of inline editing, with heading selected in a live preview and a text area on the left to edit it"></p><p><strong>Markdown editor:</strong> Markdown text goes on the left, and previews on the right. Easy.</p><p><img src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-content-editing.png" alt="Example of long form content editing in Markdown, with preview on the right"></p><h3>Powerful Collaboration &amp; Management</h3><p>The Jamstack isn√¢‚Ç¨‚Ñ¢t just for developers! Stackbit Studio enables stakeholders to collaborate freely on projects so they can edit with confidence while developers maintain peace of mind.</p><p><img src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-share.png" alt="Share dropdown option to invite others to collaborate within Stackbit Studio"></p><p><strong>Integrated asset management:</strong> <a href="https://www.stackbit.com/docs/using-stackbit/editing-content/#image_editing">Upload and manage images</a> quickly and easily.</p><p><img src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-image-picker.png" alt="Image selection within Stackbit Studio"></p><p><strong>Granular publishing controls:</strong> <a href="https://www.stackbit.com/docs/using-stackbit/publishing/">Publish at will, or schedule pages</a> to ship right on time, anytime.</p><p><img src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-publish.png" alt="Stackbit Studio publishing controls, with the options to publish the entire site or the current page"></p><p><strong>Build logs:</strong> Catch errors quickly with <a href="https://www.stackbit.com/docs/using-stackbit/logs/">integrated build logs</a>.</p><p><img src="https://www.stackbit.com/images/blog/stackbit-studio-announcement/stackbit-studio-logs.png" alt="Example build logs, showing events, within Stackbit Studio"></p><p><strong>Portable content</strong> allows you to store your CMS content in git version control without committing to a <a href="https://www.stackbit.com/docs/best-practices/api-versus-git-based-cms/">particular CMS API</a>.</p><p>The web is re-platforming. We see as much as a 12% Jamstack adoption rate in VC-backed startups, and a staggering 20% of Indie Hackers sites. It is now time to make it all usable for real people, in the real world of the web.</p><p>And it√¢‚Ç¨‚Ñ¢s just getting started √¢‚Ç¨‚Äú we really ain√¢‚Ç¨‚Ñ¢t seen nothin√¢‚Ç¨‚Ñ¢ yet. New Jamstack tech is mushrooming constantly, each with its own merit and charm. We√¢‚Ç¨‚Ñ¢re proud to offer a truly open platform that helps these amazing tools play together nicely and make the web better.</p><p><strong>Stackbit. Make the web, better.</strong></p></div></div>]]>
            </description>
            <link>https://www.stackbit.com/blog/announcing-stackbit-studio/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24355138</guid>
            <pubDate>Wed, 02 Sep 2020 16:56:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on user growth and product]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24354842">thread link</a>) | @jonluca
<br/>
September 2, 2020 | https://blog.jonlu.ca/posts/thoughts-on-product | <a href="https://web.archive.org/web/*/https://blog.jonlu.ca/posts/thoughts-on-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My day job is, officially, as a Growth Engineer working primarily on Unauth Product at Pinterest. It‚Äôs slightly different from my previous software engineering roles - typically, in other roles, I would be handed a spec sheet or design and had to implement it. Sometimes I‚Äôd design it myself, but the challenges were uniquely <em>technical</em> - I had to build something, and there was creativity in so far as what technologies and design patterns I‚Äôd use, but the features and product itself were usually dictated to you. They would either be so obvious that they were trivial, or they‚Äôd be handed down by some PM some point above the line.</p><p>Working on growth engineering is different - you‚Äôre responsible for the ideation and product, and focus around a north star metric, and can gauge the success of your ideas <em>objectively</em>. You own the entirety of the process, and have a quantifiable number at the end (for unauth and SEO, it‚Äôs usually traffic, time on site, and, most importantly, user acquisition).</p><p>This lends itself to an interesting focus at work every day. You want to build a product that is actually enjoyed and valuable to users, while still trying to ‚Äúgame‚Äù their attention and behavior.</p><p>The following are some thoughts I‚Äôve had from working and consulting in growth at startups and companies of various sizes, mostly in the consumer tech space:</p><h2 id="thoughts-on-users-and-product">Thoughts on users and product</h2><ul><li><p>Trying to get users to do something is less like being an omnipotent god that tells people what to do than it is reshaping rivers of user intent. You can‚Äôt control what a user does, merely guide the flow of their actions. Adding a huge button doesn‚Äôt mean they‚Äôll click on it.</p></li><li><p>Removing the ability to do something won‚Äôt prevent them from doing it (and will most likely just increase distaste for your product).</p></li><li><p>Users are simultaneously smarter and dumber than you think. Dumber in the sense that, when you take the average level of product comprehension for a user of any site that is used by a significant portion of the world population every day, it‚Äôs fairly low. Especially when you‚Äôre focused on new user acquisition, they don‚Äôt know what to expect, or how to use what you‚Äôre providing them. At the same time, though, they‚Äôre <strong>on your site for a reason</strong>, and usually know what they want.</p></li><li><p>You need to make sure to put yourself in the same headspace as your users. As someone building a product, you have to remember that you have a significantly higher familiarity with it than the people using it. You‚Äôll have specific names for each product feature and know the user flows and reasoning behind each action, but for a lot of the people that visit your site, it‚Äôs their first time there.</p></li><li><p>It‚Äôs easy for me, as an early 20s San Francisco based software engineer, to have a fairly skewed perception of the world. Remember the user can have every possible demographic and characteristic.</p></li><li><p>Make sure you track what your users do when they come to your site, and experiment often with major shifts to your platform. It‚Äôs incredibly easy to <em>think</em> that users are doing something for a certain reason, when in reality it‚Äôs baseless.</p></li><li><p>Everything comes at a trade-off. Sometimes this is strictly better, metrics wise, but other times the trade-offs aren‚Äôt as clear - it doesn‚Äôt mean they don‚Äôt exist, though. The choices in button ordering, what you put above the fold, the font size, it all pulls and pushes the user experience in different directions.</p></li><li><p>Build for everyone, not just the professional. It‚Äôs easy when building products at work to be in a professional mindset - you‚Äôre not really thinking about <strong>every</strong> possible aspect that someone could be using your product for. Users get value in ways you never could predict - it‚Äôs better to build a platform that is flexible and ambiguous than imagine a single purpose use for what you‚Äôre building.</p></li><li><p>You do not and can not control users, and should view yourself more as at their mercy than them at yours. Working on a product is a lot more like swinging your arms around blindly in a room hoping you hit the light switch than it is knowing exactly what people want and how to deliver it to them.</p></li><li><p>Question all of your previous learnings. Something might‚Äôve been true in the past, but is no longer. The same experiment or feature can lead to differences in results based on some slight change in the product or flow.</p></li></ul><h2 id="thoughts-on-growth">Thoughts on growth</h2><ul><li><p>Your user metrics are almost always proxies for what you‚Äôre trying to measure. You‚Äôll pick some north star metric and say that this is what you‚Äôre building around, but this is just a shadow of what you‚Äôre trying to measure - the nebulous cloud of ‚Äúuser enjoyment‚Äù</p></li><li><p>Sometimes building a more aggressive user experience is worth it in the long run. For example: By default, your site could have a 2% conversion rate and a 20% bounce rate. A new feature is introduced behind an experiment that increases the conversion rate to 3%, but increases the bounce rate to 80%. This is clearly a subpar experience - it increases your bounce rate by 400%. However, it also increases your conversion rate by <strong>50%</strong>. Depending on your product this can make sense (for example, anything with an LTV for each user that is really high, or that has a really high CAC). It might not be ideal in the long term, but having a short term lever like this can be instrumental to a product‚Äôs success.</p></li><li><p>User growth is often cyclical. Some products will have the same traffic every day of the year, whereas others will have time of day, day of week, week of month, or seasonal patterns.</p></li><li><p>Monitor everything. As a product grows, you‚Äôll build out one-off features that are significant wins at the time, but which aren‚Äôt actively monitored. It‚Äôs cheap to add a log to something and just page a team when it drops to 0. This is significantly eased by TDD, but TDD is rarely the right answer when your main concern is growth (you should move quickly).</p></li><li><p>You should move as quickly as possible. Don‚Äôt work on an idea for a long time - build out the smallest possible version that gives you directionality (positive or negative for the user metrics you‚Äôre looking at) and iterate from there. Especially in the early stages of a company, moving slowly and not adapting to shifting market conditions can kill you.</p></li><li><p>Growth is product + a direction + fuel. Each of these is a multiplier on the others - any combination of these can make a successful company. The dream is to have a great product that knows exactly where it wants to go, with all the resources it needs, but this is very rarely the case. More often than not you‚Äôll have a mediocre product that‚Äôs floated along for a bit while being severely understaffed. If any of them is 0, you‚Äôre DOA. There‚Äôs no pithy truism here - a company can succeed <em>because</em> it has great direction and resources, or it can fail <em>in spite of it</em>.</p></li></ul><h2 id="success">Success</h2><p>One of the most important parts of the above is that they‚Äôre not static. These aren‚Äôt commandments that are written in stone - they‚Äôre learnings that are based on trial and error, off of experiments and conversations with users. You‚Äôll run an experiment one day that contradicts nearly everything you‚Äôve learned about growth and product, and you just have to re-baseline yourself and take those learnings forward.</p><p>You have a lot of control in so far as what the user sees and has access to - you can never control what they do with it, though. Building something that keeps the experience in mind, and that is focused on long term, sustainable growth is all you can hope to achieve.</p></div></div>]]>
            </description>
            <link>https://blog.jonlu.ca/posts/thoughts-on-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-24354842</guid>
            <pubDate>Wed, 02 Sep 2020 16:29:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: DNS-based alternative to the web for structured data]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24354559">thread link</a>) | @elliottinvent
<br/>
September 2, 2020 | https://www.num.uk/blog/announcing-num | <a href="https://web.archive.org/web/*/https://www.num.uk/blog/announcing-num">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-holder">
      <div id="content">
        
<p>1st September 2020, by Elliott Brown</p>
<h4>Today we're announcing NUM, a new DNS-based protocol to store and retrieve structured data</h4>
<p>
  The Namespace Utility Modules (NUM) protocol can be used to store structured data for any domain name or email address. NUM&nbsp;records can be stored in the DNS of the independent NUM zone (e.g. <code>_num.example.com</code>) or in the hosted NUM zone (a DNS-based store of NUM records below the domain <code>num.net</code>) using a simple web interface: <a href="https://www.numserver.com/" target="_blank">NUM Server</a> <img src="https://www.num.uk/images/link-external.png" title="Content on another site." alt="Content on another site.">.
</p>
<p>
  We're announcing this experimental protocol to the technical community today and are very interested in feedback and input.
</p>
<h5>Custom and standardised records</h5>
<p>
  Custom NUM records can store structured data for any purpose, particular use cases are standardised with <a href="https://www.num.uk/modules">modules</a> <img src="https://www.num.uk/images/link-internal.png" title="Content elsewhere on this site." alt="Content elsewhere on this site.">. One of our leading use cases for NUM is contact information. Enabling organisations and individuals to store contact data in the DNS opens up lots of new possibilities like dialling a domain name or email address.
</p>
<h5>Automatically populating the DNS with millions of pieces of structured data</h5>
<p>
  As well as offering a simple, user-friendly way to adopt NUM, the NUM Server also helps overcome the chicken-and-egg problem. We&nbsp;intend to populate NUM records for millions of domain names based on website information hosted on those domain names. We&nbsp;expect to publish this data in early 2021.
</p>
<h5>Free, unrestricted and unlimited access to data</h5>
<p>
  Since NUM data is stored and served using DNS it's ultra-fast, reliable and massively scalable. Access to records on the NUM Server is free, unrestricted and unlimited forever. NUM enables organisations and individuals to take back control of their data and provides a valuable resource to developers building devices, apps and services.
</p>
<h5>Find out more</h5>

<h5>Experimenting with NUM</h5>
 


      </div>
    </div></div>]]>
            </description>
            <link>https://www.num.uk/blog/announcing-num</link>
            <guid isPermaLink="false">hacker-news-small-sites-24354559</guid>
            <pubDate>Wed, 02 Sep 2020 16:06:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XLS: Accelerated HW Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24354083">thread link</a>) | @victor82
<br/>
September 2, 2020 | https://google.github.io/xls/ | <a href="https://web.archive.org/web/*/https://google.github.io/xls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
        
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/google/xls/tree/main/docs_src/README.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                <p><img src="https://google.github.io/xls/images/xls_logo_623_250.png" alt="XLS Logo">
</p>


<!-- nav -->

<h2 id="what-is-xls">What is XLS?</h2>
<p>The XLS (Accelerated HW Synthesis) project aims to enable the rapid development
of <em>hardware IP</em> that also runs as efficient <em>host software</em> via "software
style" methodology.</p>
<p>XLS implements a High Level Synthesis (HLS) toolchain which produces
synthesizable designs from flexible, high-level descriptions of functionality.
It is fully Open Source: Apache 2 licensed and developed via GitHub.</p>
<p>XLS is used inside of Google for generating feed-forward pipelines from
"building block" routines / libraries that can be easily retargeted, reused, and
composed in a latency-insensitive manner.</p>
<p><em>Not yet available</em>, but active work in progress is the implementation of XLS
<em>concurrent processes</em>, in Communicating Sequential Processes (CSP) style, that
allow pipelines to communicate with each other and induct over time.</p>
<p>XLS is still experimental, undergoing rapid development, and not an officially
supported Google product. Expect bugs and sharp edges. Please help by trying it
out, <a href="https://github.com/google/xls/issues">reporting bugs</a>, and letting us know
what you think!</p>
<h2 id="building-from-source">Building From Source</h2>
<p>Currently, XLS must be built from source using the Bazel build system.</p>
<p><em>Note:</em> Binary distributions of the XLS library are not currently available, but
we hope to enable them via continuous integration, <a href="https://github.com/google/xls/issues/108">see this issue</a>.</p>
<p>The following instructions are for the Ubuntu 20.04 (Focal) Linux distribution.
Note that we start by assuming <a href="https://docs.bazel.build/versions/master/install-ubuntu.html">Bazel has been
installed</a>.</p>
<pre><code># Follow the bazel install instructions:
# https://docs.bazel.build/versions/master/install-ubuntu.html
#
# Afterwards we observe:

$ bazel --version
bazel 3.2.0

$ sudo apt install python3-dev python3-distutils python3-dev libtinfo5

# py_binary currently assume they can refer to /usr/bin/env python
# even though Ubuntu 20.04 has no `python`, only `python3`.
# See https://github.com/bazelbuild/bazel/issues/8685

$ mkdir -p $HOME/opt/bin/
$ ln -s $(which python3) $HOME/opt/bin/python
$ echo 'export PATH=$HOME/opt/bin:$PATH' &gt;&gt; ~/.bashrc
$ source ~/.bashrc

$ bazel test -c opt ...
</code></pre>

<p>A reference build/test environment setup is also provided via <code>Dockerfile</code>:</p>
<pre><code>~$ git clone https://github.com/google/xls.git
~$ cd xls
~/xls$ docker build .  # Performs optimized build and test.
</code></pre>

<h2 id="stack-diagram-and-project-layout">Stack Diagram and Project Layout</h2>
<p>Navigating a new code base can be daunting; the following description provides a
high-level view of the important directories and their intended organization /
purpose, and correspond to the components in this XLS stack diagram:</p>
<p><img src="https://google.github.io/xls/images/xls_stack_diagram.png" alt="XLS Stack Diagram">
</p>

<ul>
<li><a href="https://github.com/google/xls/tree/main/dependency_support"><code>dependency_support</code></a>:
  Configuration files that load, build, and expose Bazel targets for <em>external</em>
  dependencies of XLS.</li>
<li><a href="https://github.com/google/xls/tree/main/docs"><code>docs</code></a>: Generated documentation
  served via GitHub pages:
  <a href="https://google.github.io/xls/">https://google.github.io/xls/</a></li>
<li><a href="https://github.com/google/xls/tree/main/docs_src"><code>docs_src</code></a>: Markdown file
  sources, rendered to <code>docs</code> via
  <a href="https://google.github.io/xls/contributing/#rendering-documentation">mkdocs</a>.</li>
<li>
<p><a href="https://github.com/google/xls/tree/main/xls"><code>xls</code></a>: Project-named
  subdirectory within the repository, in common Bazel-project style.</p>
<ul>
<li><a href="https://github.com/google/xls/tree/main/xls/build"><code>build</code></a>: Build macros
  that create XLS artifacts; e.g. convert DSL to IR, create test targets for
  DSL code, etc.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/codegen"><code>codegen</code></a>: Verilog
  AST (VAST) support to generate Verilog/SystemVerilog operations and FSMs.
  VAST is built up by components we call <em>generators</em> (e.g.
  PipelineGenerator, SequentialGenerator for FSMs) in the translation from XLS
  IR.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/common"><code>common</code></a>: "base"
  functionality that layers on top of standard library usage. Generally we use
  <a href="https://abseil.io/">Abseil</a> versions of base constructs wherever possible.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/contrib/xlscc"><code>contrib/xlscc</code></a>:
  Experimental C++ syntax support that targets XLS IR (alternative path to
  DSLX) developed by a sister team at Google, sharing the same open source /
  testing flow as the rest of the XLS project. May be of particular interest
  for teams with existing C++ HLS code bases.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/data_structures"><code>data_structures</code></a>:
  Generic data structures used in XLS that augment standard libraries; e.g.
  BDDs, union find, min cut, etc.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/delay_model"><code>delay_model</code></a>:
  Functionality to characterize, describe, and interpolate data delay for
  XLS IR operations on a target backend process. Already-characterized
  descriptions are placed in <code>xls/delay_model/models</code> and can be referred to via
  command line flags.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/dslx"><code>dslx</code></a>: A DSL (called
  "DSLX") that mimics Rust, while being an immutable expression-language
  dataflow DSL with hardware-oriented features; e.g.  arbitrary bitwidths,
  entirely fixed size objects, fully analyzeable call graph. XLS team has found
  dataflow DSLs are a good fit to describe hardware as compared to languages
  designed assume von Neumann style computation.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/dslx/fuzzer"><code>dslx/fuzzer</code></a>: A
  whole-stack multiprocess fuzzer that generates programs at the DSL level and
  cross-compares different execution engines (DSL interpreter, IR interpreter,
  IR JIT, code-generated-Verilog simulator). Designed so that it can easily be
  run on different nodes in a cluster simultaneously and accumulate shared
  findings.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/examples"><code>examples</code></a>: Example
  computations that are tested and executable through the XLS stack.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/experimental"><code>experimental</code></a>:
  Artifacts captured from experimental explorations.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/ir"><code>ir</code></a>:
  XLS IR definition, text parser/formatter, and facilities for abstract
  evaluation and execution engines (<a href="https://google.github.io/xls/interpreters/">IR interpreter</a>,
  <a href="https://google.github.io/xls/ir_jit/">JIT</a>).</li>
<li><a href="https://github.com/google/xls/tree/main/xls/modules"><code>modules</code></a>:
  Hardware building block DSLX "libraries" (outside the DSLX standard library)
  that may be easily reused or instantiated in a broader design.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/netlist"><code>netlist</code></a>: Libraries
  that parse/analyze/interpret netlist-level descriptions, as are
  generally given in simple structural Verilog with an associated cell library.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/passes"><code>passes</code></a>: Passes that
  run on the XLS IR as part of optimization, before scheduling / code
  generation.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/scheduling"><code>scheduling</code></a>:
  Scheduling algorithms, determine when operations execute (e.g. which
  pipeline stage) in a clocked design.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/simulation"><code>simulation</code></a>:
  Code that wraps Verilog simulators and generates Verilog testbenches for XLS
  computations.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/solvers"><code>solvers</code></a>:
  Converters from XLS IR into SMT solver input, such that formal proofs can be
  run on XLS computations; e.g. Logical Equalence Checks between XLS IR and a
  netlist description.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/synthesis"><code>synthesis</code></a>:
  Interface that wraps backend synthesis flows, such that tools can be
  retargeted e.g. between ASIC and FPGA flows.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/tests"><code>tests</code></a>:
  Integration tests that span various top-level components of the XLS project.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/tools"><code>tools</code></a>:
  <a href="https://google.github.io/xls/tools/">Many tools</a> that work with the XLS system and its libraries in a
  decomposed way via command line interfaces.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/uncore_rtl"><code>uncore_rtl</code></a>:
  Helper RTL that interfaces XLS-generated blocks with device top-level for e.g.
  FPGA experiments.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/visualzation"><code>visualization</code></a>:
  Visualization tools to inspect the XLS compiler/system interactively. See
  <a href="https://google.github.io/xls/ir_visualization/">IR visualization</a>.</li>
</ul>
</li>
</ul>

<p>Discussions about XLS - development, debugging, usage, and anything else -
should go to the <a href="https://groups.google.com/g/xls-dev">xls-dev mailing list</a>.</p>
<h2 id="contributors">Contributors</h2>
<p>The following are
<a href="https://github.com/google/xls/graphs/contributors">contributors</a> to the XLS
project, see our
<a href="https://google.github.io/xls/contributing/">contributing documentation</a> and
<a href="https://github.com/google/xls/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">good first issues</a>!</p>
<ul>
<li><a href="https://github.com/brajiang">Brandon Jiang</a></li>
<li><a href="https://github.com/cdleary">Chris Leary</a></li>
<li><a href="https://github.com/dmlockhart">Derek Lockhart</a></li>
<li><a href="https://github.com/felixzhuologist">Felix Zhu</a></li>
<li><a href="https://github.com/hmontero1205">Hans Montero</a></li>
<li><a href="https://github.com/jbaileyhandle">Jonathan Bailey</a></li>
<li><a href="https://github.com/julianviera99">Julian Viera</a></li>
<li><a href="https://github.com/kevineharlley">Kevin Harlley</a></li>
<li><a href="https://github.com/meheffernan">Mark Heffernan</a></li>
<li><a href="https://github.com/per-gron">Per Gr√∂n</a></li>
<li><a href="https://github.com/rchen152">Rebecca Chen (Pytype)</a></li>
<li><a href="https://github.com/rhundt">Robert Hundt</a></li>
<li><a href="https://github.com/RobSpringer">Rob Springer</a></li>
<li><a href="https://github.com/spurserh">Sean Purser-Haskell</a></li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://google.github.io/xls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24354083</guid>
            <pubDate>Wed, 02 Sep 2020 15:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Delegated Types in Rails, handling models with overlapping attributes]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24353984">thread link</a>) | @rvlee
<br/>
September 2, 2020 | https://www.blackboxengineering.work/delegated-types-in-rails-handling-models-with-overlapping-attributes | <a href="https://web.archive.org/web/*/https://www.blackboxengineering.work/delegated-types-in-rails-handling-models-with-overlapping-attributes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="1471232539"> <div id="1292474755"> <div id="1668470589"> <div id="1829584526" data-uialign="center" data-version="5"><p><span work="" sans";"=""><span>Let‚Äôs say we have a blog application that manages different types of posts, ex:</span> 
</span><span>Videos</span><span work="" sans";"=""> <span>and</span> 
</span><span>Texts</span><span work="" sans";"=""><span>. The posts are similar enough that they will share certain attributes (like a title), but also different enough that they will require unique columns (a url column for video). In addition, we want to have a newsfeed feature where we display all posts by most recently created. This means we need to have a way to query across the entire</span> 
</span><span>Posts</span><span work="" sans";"=""> <span>architecture.</span></span></p><p><span work="" sans";"=""><span>This problem is generally solved in one of two ways in Rails:</span> 
</span><span>single table inheritance</span><span work="" sans";"=""> <span>(STI) or</span> 
</span><span>abstract classes</span><span>. Since ActiveRecord models do not have to be backed by a database table, these solutions leverage Plain Old Ruby Objects in order to represent this inheritance hierarchy. Polymorphic associations also often get thrown into the mix but don't quite fit our use case (we‚Äôll briefly touch on this). We‚Äôll discuss the pros and cons of each of these approaches and shed light on a new Rails feature that combines the best of both worlds.</span></p>  
  
 <h4><span>Single Table Inheritance (STI)</span></h4> 
  
<p><span work="" sans";"=""><span>In an STI implementation, attributes are stored in a single parent class table and a</span> 
</span><span>type</span><span work="" sans";"=""> <span>column holds the name of the subclass for the given row. Subclasses inherit from the parent class which allows us to write Text specific methods on the Text class without polluting the Video class.&nbsp; Generating a newsfeed is also very straightforward since all the data is in a single table, i.e. we can do things like</span> 
</span><span>Posts.order(created_at: :desc)</span><span>.<br></span><span><br></span></p></div> <p><a id="1268435434" data-caption="STI example"><img src="https://lirp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/opt/Screen+Shot+2020-08-02+at+11.00.04+AM-1920w.png" alt="" id="1798209722" data-dm-image-path="https://irp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/Screen+Shot+2020-08-02+at+11.00.04+AM.png" onerror="handleImageLoadError(this)"></a> 
</p> 
 <div data-dmtmpl="true" data-element-type="paragraph" data-version="5" id="1828567217" data-uialign="center"><p><span>STI is simple to implement but can quickly get unwieldy as slight differences in models introduce new fields.&nbsp; This leads to wide tables that are full of null values storing information for a collection of now distinct models that are forced to share the same table.</span></p>  
 <h4><span>Abstract Classes</span></h4> 
  
<p><span>Abstract Classes solve the problem of wide tables by giving each model its own table and connecting them via an Abstract Base Model - the parent class cannot be instantiated and must be subclassed to be utilized. Where the entire hierarchy was represented in a single table in STI, the opposite is true using abstract classes.&nbsp;</span></p><p><span work="" sans";"=""><span>This gives us the ability to separate unique attributes to distinct tables, but now we have the opposite problem - repetitive columns. The</span> 
</span><span>author</span><span work="" sans";"=""> <span>and</span> 
</span><span>title</span><span work="" sans";"=""> <span>columns will have to be included in all subclasses. We have also lost the ability to query across the entire hierarchy (i.e.</span> 
</span><span>Posts.all</span><span work="" sans";"=""><span>), making our newsfeed unnecessarily cumbersome.</span> 
</span></p></div> 
 <p><a id="1980528968"><img src="https://lirp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/opt/Screen%2BShot%2B2020-08-02%2Bat%2B11.06.37%2BAM-1920w.png" alt="" id="1509483609" data-dm-image-path="https://irp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/Screen%2BShot%2B2020-08-02%2Bat%2B11.06.37%2BAM.png" onerror="handleImageLoadError(this)"></a> 
</p> 
  
 <p><span>We've established that both methods have their strengths but are not without significant drawbacks. So what's the solution?</span></p> 
  
 <div data-dmtmpl="true" data-element-type="paragraph" data-version="5" id="1670289024" data-uialign="center"> <h4><span>Delegated Types</span></h4> 
  
<p><span><span>*At the time of writing, this feature is only included in edge Rails and is expected to be included in the next minor release (6.1.0). However,</span> 
</span><a href="https://github.com/rails/rails/pull/39341" target="_blank" runtime_url="https://github.com/rails/rails/pull/39341" type="url">the code</a><span> <span>can be pulled from the Rails codebase and included in ApplicationRecord to be used right away*</span></span></p><p><span>Delegated types take the best of STI and abstract classes and merge them into a single solution. Both the superclass and subclasses are backed by database tables, allowing for common attributes to live in the parent class table and unique attributes to live in the subclass tables.</span><span><br></span></p></div> 
 <p><a id="1774745395"><img src="https://lirp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/opt/Screen+Shot+2020-08-02+at+11.06.59+AM-1920w.png" alt="" id="1346878900" data-dm-image-path="https://irp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/Screen+Shot+2020-08-02+at+11.06.59+AM.png" onerror="handleImageLoadError(this)"></a> 
</p> 
 <div data-dmtmpl="true" data-element-type="paragraph" data-version="5" id="1860625639" data-uialign="center"><p><span work="" sans";"=""><span>So what's happening here? By including</span> 
</span><span>delegated_type :postable</span><span work="" sans";"=""> <span>on the</span> 
</span><span>Post</span><span work="" sans";"=""> <span>model, it adds a polymorphic belongs_to relationship to</span> 
</span><span>postable</span><span work="" sans";"=""> <span>under the hood. So far, this is the same as setting up a regular polymorphic association minus the syntactical difference. However, where polymorphic relationships define an interface for a ‚Äúhas_many‚Äù relationship, delegated types define an interface for ‚Äúhas_one‚Äù. That distinction is what allows us to isolate shared attributes in a separate table, but still be able to retrieve values specific to a delegated type row.&nbsp;</span></span></p></div> 
 <p><a id="1363070377" data-caption="* √¢‚Ç¨≈ìPostable√¢‚Ç¨ÔøΩ is an interface and not an actual table"><img src="https://lirp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/opt/Screen+Shot+2020-09-01+at+7.40.10+PM-1920w.png" alt="" id="1121678949" data-dm-image-path="https://irp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/Screen+Shot+2020-09-01+at+7.40.10+PM.png" onerror="handleImageLoadError(this)"></a> 
</p> 
 <div data-dmtmpl="true" data-element-type="paragraph" data-version="5" id="1486664709" data-uialign="center"><p><span><span>Polymorphism has its role in the opposite use case - ex: ‚ÄúX and Y models</span> 
</span><span>can</span><span single-space="true"> <span></span> 
</span><span>be</span><span> <span>commented on‚Äù vs ‚ÄúX and Y models are</span> 
</span><span>types</span><span> <span>of comments‚Äù.</span></span></p><p><span><br>Going back to delegated types, creating a new Video record looks something like this:</span></p></div> 
 <p><a id="1892891013"><img src="https://lirp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/opt/carbon-1920w.png" alt="" id="1893159695" data-dm-image-path="https://irp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/carbon.png" onerror="handleImageLoadError(this)"></a> 
</p> 
 <div data-dmtmpl="true" data-element-type="paragraph" data-version="5" id="1498830295" data-uialign="center"><p><span><span>There is some fantastic Rails magic up there as the title and author attributes will be stored in the parent Post table! Videos and Texts are always created in the context of Posts so that they always retain common post attributes. Now, if we need to ask questions to the subclass models, the</span> 
</span><span>:postable</span><span> <span>role will delegate to the class defined in the</span> 
</span><span>postable_type</span><span> <span>column.&nbsp;</span></span></p><p><span><span>As for our newsfeed feature, we can still call</span> 
</span><span>Posts.all</span><span> <span>to retrieve all the blog posts that a user has written. To get the specific post type, we call</span> 
</span><span>.postable</span><span> <span>on the record. To get the common post attribute, we call</span> 
</span><span>.post</span><span> <span>on the subclass model.<br></span></span></p></div> 
 <p><a id="1284824131"><img src="https://lirp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/opt/Screen+Shot+2020-09-01+at+7.44.17+PM-1920w.png" alt="" id="1725864807" data-dm-image-path="https://irp-cdn.multiscreensite.com/8a8eebaa/dms3rep/multi/Screen+Shot+2020-09-01+at+7.44.17+PM.png" onerror="handleImageLoadError(this)"></a> 
</p> 
 <p><span>We don't have any repeated or nil values, we can still query across records, and can confidently scale the parent and subclasses‚Äô attributes and behavior √∞≈∏≈Ω‚Ä∞<br></span></p> 
</div> 
</div> 
</div></div>]]>
            </description>
            <link>https://www.blackboxengineering.work/delegated-types-in-rails-handling-models-with-overlapping-attributes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353984</guid>
            <pubDate>Wed, 02 Sep 2020 15:09:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with Categories]]>
            </title>
            <description>
<![CDATA[
Score 313 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24353976">thread link</a>) | @kercker
<br/>
September 2, 2020 | http://brendanfong.com/programmingcats.html | <a href="https://web.archive.org/web/*/http://brendanfong.com/programmingcats.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<img src="http://brendanfong.com/programmingcats_files/seal.gif" width="150">
<h2>
<a href="http://brendanfong.com/">Brendan Fong</a>,
<a href="https://bartoszmilewski.com/">Bartosz Milewski</a>,
and
<a href="http://math.mit.edu/~dspivak/">David Spivak</a>
</h2>
Department of Mathematics<br>
Massachusetts Institute of Technology<br>
<b>Office:</b> 2-180<br>
<b>Email:</b> {bfo,dspivak} -- mit/edu  <center>

<h2> IAP 2020</h2>
<img src="http://brendanfong.com/programmingcats_files/pigskell.jpeg" width="300">
</center>

<h3> General information</h3>

<table>
<colgroup><col width="105"> <col width="300">
</colgroup><tbody><tr><td>Room:</td><td>4-163</td></tr>
<tr><td>Dates:</td><td> Jan 7‚Äî31 (MTWRF)</td></tr>
<tr><td>Time:</td><td> 2‚Äî3pm</td></tr>
<tr><td>Prerequisites:</td><td> None</td></tr>
<tr><td>Credit:</td><td> 3 units (1-0-2) (P/D/F)</td></tr>
</tbody></table>
<p>

<b>Summary</b>: In this course we explain how category theory‚Äîa branch of mathematics known for its ability to organize the key abstractions that structure much of the mathematical universe‚Äîhas become useful for writing elegant and maintainable code. In particular, we'll use examples from the Haskell programming language to motivate category-theoretic constructs, and then explain these constructs from a more abstract and inclusive viewpoint. Hands-on programming exercises will be used to demonstrate categorical ideas like "the universal property of products" in working Haskell code. A rough list of topics includes: 
</p><ol>
<li>Sets, types, categories, functors, natural transformations</li>
<li>Universal constructions and associated data types</li>
<li>Adjunctions and cartesian closed categories</li>
<li>Algebras, catamorphisms, anamorphisms</li>
<li>Monads, comonads, Kleisli arrows</li>
<li>Monoids, monoidal categories, lax monoidal functors, applicatives</li>
<li>Profunctors, (co)ends, optics</li>
</ol>
<b>We will assume no background knowledge on behalf of the student</b>, starting from scratch on both the programming and mathematics.

(<a href="http://brendanfong.com/programmingcats_files/flyer.pdf">Flyer</a>)
<p>
Students are very welcome to audit.
</p><hr>

<h3>Course details</h3>
<p>
Course notes and videos will be published here following each class. Feedback about the notes is welcome <a href="https://docs.google.com/document/d/1CQF1k01Ik_ehEpvE0KzYhLZbfMQY-kPW8QAm48xTe7k/edit">
here</a> or via email to the instructors.
</p>
<p>
Students taking the course for credit will be required to complete three problem
sets. There will be no exam. See the <a href="http://brendanfong.com/programmingcats_files/C4P-syllabus.pdf">syllabus</a> for more details.
</p>

<p>The instructors will lead problem discussion and be available for questions each
day from 3 to 4pm, in the course classroom, 4-163.
</p>

<p>
There will be no class on Monday 1/20 (MLK Day).
</p>

<hr>

<h3>Course resources</h3>
    
<ul>
    <li>
        <a href="http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf">Course notes: Programming with Categories</a>
    </li>
    <li>
        <a href="https://www.youtube.com/playlist?list=PLhgq-BqyZ7i7MTGhUROZy3BOICnVixETS">Class videos</a>
    </li>
    <li>
        <a href="https://roamresearch.com/#/app/programming-with-categories/page/4PUHYRX13">David Dalrymple's summaries of each class</a>
    </li>
    <li>
        <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">Discussion forum</a>
    </li>
</ul>
    
<hr>

<h3>Problem sets</h3>
<ul>
<li>
  <a href="http://brendanfong.com/programmingcats_files/ps1.pdf">PS1</a> (<a href="http://brendanfong.com/programmingcats_files/pset1-solutions.pdf">Solutions</a>)
</li>

<li>
  <a href="http://brendanfong.com/programmingcats_files/ps2.pdf">PS2</a> (Due 1/24)
</li>

<li>
  <a href="http://brendanfong.com/programmingcats_files/ps3.pdf">PS3</a> (Due 1/31)
</li>
</ul>

<hr>

<h3>Open access and remote participation</h3>

<p>
  All are welcome to attend the lectures in person. We encourage those participating remotely to post questions and discuss course content on the <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">Azimuth Forum</a>.
</p>
<hr>

<h3>Additional resources</h3>
<ul>
  <li>
    <a href="https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/">Bartosz' blog and book on Category Theory for Programmers</a>
  </li>
  <li>
    <a href="https://www.youtube.com/user/DrBartosz/playlists">Bartosz' lectures on Category Theory</a>
  </li>
  <li>
    <a href="https://ocw.mit.edu/courses/mathematics/18-s097-applied-category-theory-january-iap-2019/">Brendan and David's previous MIT course on Applied Category Theory</a>
  </li>
  <li>
    <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">An online forum dedicated to discussing this course, and applied category theory in general</a>
  </li>
</ul>

<hr>

<h3> Mailing list </h3>
Join the <a href="https://docs.google.com/forms/d/e/1FAIpQLSdnuk-lIrjBJPLAO17ZkxeSgV7f6oCp3VUmuAJd138daYDQXA/viewform">mailing list</a> to get updates.
<hr>


<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/"><img alt="Creative
Commons License" width="50" src="http://brendanfong.com/programmingcats_files/88x31.png"></a>
<span size="-2">This
<span xmlns:dc="http://purl.org/dc/elements/1.1/" href="http://purl.org/dc/dcmitype/Text" rel="dc:type">work</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Brendan Fong, Bartosz Milewski, and David Spivak</span> is licensed 
under a
<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons
Attribution-Share Alike 3.0 Unported License</a>.
</span>


</div>]]>
            </description>
            <link>http://brendanfong.com/programmingcats.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353976</guid>
            <pubDate>Wed, 02 Sep 2020 15:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CubeSat interplanetary exploration is heating up]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24353966">thread link</a>) | @tectonic
<br/>
September 2, 2020 | http://orbitalindex.com/archive/2020-09-02-Issue-80 | <a href="https://web.archive.org/web/*/http://orbitalindex.com/archive/2020-09-02-Issue-80">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div replace-ids="_main" link-selector="a[href]:not([href*='/assets/']):not(.external):not(.no-push-state)" duration="250" script-selector="script:not([type^='math/tex'])" prefetch=""><main id="_main" role="main" data-color="#4fb1ba" data-theme-color="black" data-image="/assets/img/sidebar-bg.jpg" data-overlay=""><article class="page" role="article"><header></header><div id="mc-archive"> <center> <!--[if (gte mso 9)|(IE)]><table align="center" border="0" cellspacing="0" cellpadding="0" width="600" style="width:600px;"><tr><td align="center" valign="top" width="600" style="width:600px;"> <![endif]--><table><tbody><tr><td id="templatePreheader"></td></tr><tr><td id="templateHeader"><div> <!--[if mso]><table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;"><tr> <![endif]--> <!--[if mso]><td valign="top" width="600" style="width:600px;"> <![endif]--><div><div><p>Issue No. 80&nbsp;|&nbsp;Sep 2, 2020</p><p>   <span>üöÄ üåç üõ∞</span></p></div></div><!--[if mso]> <![endif]--> <!--[if mso]></table><![endif]--></div></td></tr><tr><td id="templateBody"><div> <!--[if mso]><table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;"><tr> <![endif]--> <!--[if mso]><td valign="top" width="600" style="width:600px;"> <![endif]--><div><p><a href="#cubesat-interplanetary-exploration-is-heating-up">¬∂</a><strong id="cubesat-interplanetary-exploration-is-heating-up">CubeSat interplanetary exploration is heating up.</strong> The twin <a href="https://www.jpl.nasa.gov/cubesat/missions/marco.php" target="_blank">MarCO 6U cubesats</a> (<a href="https://solarsystem.nasa.gov/resources/2373/marco-3d-model/" target="_blank">3D model</a>) made history when they <a href="https://www.jpl.nasa.gov/spaceimages/details.php?id=PIA22833" target="_blank">flew past Mars</a> and successfully relayed Mars InSight‚Äôs landing in real time (+ speed-of-light delay, natch). Now, many more lunar and interplanetary CubeSats are under development. From NASA comes <a href="https://www.jpl.nasa.gov/cubesat/missions/lunar_flashlight.php" target="_blank">Lunar Flashlight</a>, <a href="https://www.nasa.gov/feature/goddard/2019/lunar-icecube-mission-to-locate-study-resources-needed-for-sustained-presence-on-moon" target="_blank">Lunar IceCube</a>, and <a href="https://www.nasa.gov/content/nea-scout/" target="_blank">NEAScout</a> (a <em>solar sailing</em> small near-Earth asteroid explorer). ESA is working on <a href="http://www.esa.int/ESA_Multimedia/Images/2017/06/M_Argo" target="_blank">M-ARGO</a>, to explore small, rapidly spinning asteroids, and <a href="https://www.esa.int/Safety_Security/Hera/CubeSats_joining_Hera_mission_to_asteroid_system" target="_blank">2 cubesats that will tag along with their Hera mission</a> to the Didymos/Didymoon system (which will have already been attacked by NASA‚Äôs <a href="https://www.nasa.gov/planetarydefense/dart" target="_blank">DART kinetic impactor</a> along with its <a href="https://www.argotec.it/online/liciacube-nasa-choose-italian-excellence-to-monitor-a-space-impact-between-a-satellite-and-an-asteroid/" target="_blank">LICIACube</a> companion CubeSat). Caltech is working on <a href="https://trailblazer.caltech.edu/" target="_blank">Lunar Trailblazer</a> to map the lunar water cycle, while University of Arizona‚Äôs <a href="https://lunahmap.asu.edu/" target="_blank">LunaH-Map</a> will perform a high resolution search for water in permanently shadowed regions on the Moon‚Äôs poles. CubeSats can also enable less resourced countries and private entities to do deep space exploration. Poland and Virgin Orbit <a href="https://virginorbit.com/satrevolution-virgin-orbit-and-polish-universities-establish-mars-consortium/" target="_blank">are collaborating on a Mars cubesat</a>. <a href="https://www.theverge.com/21292753/rocket-lab-nasa-capstone-moon-mission-photon-hypercurie-engine" target="_blank">Rocket Lab is planning a mission to the Moon next year</a> (check out <a href="https://www.rocketlabusa.com/lunar/" target="_blank">Rocket Lab‚Äôs lunar site</a>), and Rocket Lab CEO Peter Beck is even <a href="https://www.space.com/rocket-lab-private-venus-mission-2023.html" target="_blank">investigating a private mission to Venus</a>‚Äîthe upgraded Electron should be able to deliver around 25 kg to Mars or Venus (Venus requires an additional ‚àÜv of ~1,000 m/s according to the handy chart at the end of this issue, ignoring aerobraking). Slightly larger upcoming vehicles like Firefly's Alpha and Relativity Space‚Äôs Terran 1 ‚Äú<a href="https://arstechnica.com/science/2020/07/how-small-satellites-are-radically-remaking-space-exploration/2/" target="_blank"><em>probably could put CubeSats beyond the asteroid belt, toward Jupiter or beyond.</em></a>‚Äù Related: JPL‚Äôs "Honey, I Shrunk the NASA Payload" challenge <a href="https://www.herox.com/NASApayload/131-meet-the-winners" target="_blank">recently ended with awards for miniaturized lunar payloads</a>. Also Related: Astrobotic‚Äôs <a href="https://www.astrobotic.com/2019/10/2/astrobotic-s-cuberover-program-awarded-2-million-contract-by-nasa" target="_blank">CubeRover</a> is pretty cute.</p></div><!--[if mso]> <![endif]--> <!--[if mso]></table><![endif]--></div><div> <!--[if mso]><table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;"><tr> <![endif]--> <!--[if mso]><td valign="top" width="600" style="width:600px;"> <![endif]--><div><p><a href="#a-busy-weekend-in-launch">¬∂</a><strong id="a-busy-weekend-in-launch">A Busy Weekend in Launch. </strong>ULA, Rocket Lab, and SpaceX all had scheduled launches over the weekend. ULA kicked the weekend off with a Delta IV Heavy launch of an NRO spy satellite. The aging heavy lifter, which will be phased out and replaced by <a href="https://www.ulalaunch.com/rockets/vulcan-centaur" target="_blank">Vulcan</a> over the next few years, had a <a href="https://twitter.com/torybruno/status/1299623698090135552" target="_blank">T-3 sec hotfire abort</a> complete with a dramatic fireball (<a href="https://youtu.be/1jkjgo0Cs_8" target="_blank">video</a>). The rocket and payload are undamaged, but launch is delayed a week or more while expendable ground systems are replaced. Next up was SpaceX, launching <a href="https://space.skyrocket.de/doc_sdat/saocom-1.htm" target="_blank">SAOCOM-1B</a> into a polar orbit, the <a href="https://www.nasaspaceflight.com/2020/08/spacex-polar-cape-50-years/" target="_blank">first such southward flight path from Florida since 1969</a> when <a href="http://www.digitaljournal.com/tech-and-science/science/herd-shot-around-the-world-the-last-east-coast-polar-launch/article/567614" target="_blank">booster debris landed on Cuba</a> and <a href="https://www.mapfreglobalrisks.com/risks/images/Seguros_de_satelites_ENU_tcm1366-435032.pdf" target="_blank">killed a cow named Rufina</a> üêÆ. Returning to this flight path was only possible due to the Falcon 9‚Äôs automated self-destruct systems‚Äîrocket exhaust in this flight path can block manually radioed abort messages. This launch was also temporarily halted due to its overflight of ULA‚Äôs aborted NROL-44 payload (expensive!) and required last minute approval from the NRO. To cap the weekend off,&nbsp;<a href="https://www.rocketlabusa.com/missions/completed-missions/i-cant-believe-its-not-optical/" target="_blank">Rocket Lab returned to flight with their 14th mission</a> (and announced that they will be conducting a first soft ocean splashdown of the booster for their 17th mission). Their&nbsp;<em>I Can‚Äôt Believe It‚Äôs Not Optical</em> mission was a dedicated launch for <a href="https://www.capellaspace.com/technology" target="_blank">Capella Space</a>, a startup focused on capturing 0.5 m resolution <a href="https://en.wikipedia.org/wiki/Synthetic-aperture_radar" target="_blank">synthetic aperture radar</a> (SAR) data as a service, the first of an eight satellite constellation. (<em>Ed., amusingly, this satellite was originally supposed to launch as a rideshare with SAOCOM-1B, but when that mission was delayed, Capella switched to Rocket Lab, which was then delayed by a July 4th failure, eventually launching just a few hours after the original mission. You just can‚Äôt get ahead. </em>ü§∑‚Äç‚ôÇÔ∏è)</p></div><!--[if mso]> <![endif]--> <!--[if mso]></table><![endif]--></div><div> <!--[if mso]><table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;"><tr> <![endif]--> <!--[if mso]><td valign="top" width="600" style="width:600px;"> <![endif]--><div><p><a href="#etc">¬∂</a><strong id="etc">Etc.</strong></p><ul><li>Explore Mars has <a href="https://www.exploremars.org/wp-content/uploads/2020/08/H2MR_2020_Web_v1.pdf" target="_blank">released their annual Humans to Mars report</a> detailing progress towards human exploration of the planet in the 2030s.</li><li>The US Department of Education has&nbsp;<a href="https://www.ctemissioncubesat.com/" target="_blank">announced a CubeSat mission design and prototyping challenge for High School students</a>. Project submission is October 16th, with a Phase 2 scheduled for January.</li><li>Chris Cassidy shared <a href="https://twitter.com/Astro_SEAL/status/1298703689960443904" target="_blank">dramatic views of Hurricane Laura from the ISS</a>.</li><li> <a href="https://www.tylermw.com/a-step-by-step-guide-to-making-3d-maps-with-satellite-imagery-in-r/" target="_blank">A Step-by-Step Guide to Making 3D Maps with Satellite Imagery in R</a>.</li><li><a href="https://ideas.esa.int/servlet/hype/IMT?documentTableId=45087622658433786&amp;userAction=Browse&amp;templateName=&amp;documentId=3817af91809ba52ab7cd2323267d5582" target="_blank">Submit new space mission ideas and concepts to ESA.</a></li><li>Cave of the Winds (<a href="https://www.nasa.gov/sites/default/files/files/Cave_of_the_Winds.pdf" target="_blank">pdf</a>) is a book about the history of NASA Langley‚Äôs <a href="https://www.nasa.gov/centers/langley/news/factsheets/30X60.html" target="_blank">Full-Scale Wind Tunnel</a>, which was in operation for 64 years until it closed in 1995. It was ‚Äú<em>used to test everything from World War II fighters, to submarines, to the Mercury capsule to concepts for a supersonic transport.</em>‚Äù</li><li> <a href="https://satnogs.org/2020/08/introducing-the-brand-new-satnogs-db/" target="_blank">SatNOGS DB launched with a new UI</a>, you can use it to learn about all the satellites they track.</li><li> <a href="https://history.nasa.gov/afj/ap11fj/cm-107_graffiti.html" target="_blank">Analysis of Handwritten Notes Inside the Cabin of Apollo 11 Spacecraft CM-107 "Columbia"</a>. The level of detail is wonderful.</li><li> <a href="http://beza1e1.tuxen.de/lore/moon_phases.html" target="_blank">Software that failed based on the phase of the Moon</a> at CERN: ‚Äú<em>A few desperate engineers discovered the truth; the error turned out to be the result of a tiny change in the geometry of the 27km circumference ring, physically caused by the deformation of the Earth by the passage of the Moon!</em>‚Äù</li></ul></div><!--[if mso]> <![endif]--> <!--[if mso]></table><![endif]--></div><div> <!--[if mso]><table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;"><tr> <![endif]--> <!--[if mso]><td valign="top" width="600" style="width:600px;"> <![endif]--><div><p><a href="#jobs">¬∂</a><strong id="jobs">Jobs</strong>.</p><ul><li>The newly launched <a href="https://spacetalent.org/" target="_blank">SpaceTalent.org</a> is a clearing house for finding a job in the industry, including resources for making the switch into aerospace.</li><li> <a href="https://www.pldspace.com/es/" target="_blank">PLD Space</a>, a European NewSpace startup working on reusable liquid fueled micro launchers, is <a href="https://twitter.com/pld_space/status/1300478458888290310?s=21" target="_blank">hiring a Senior Propulsion Engineer</a>.</li><li>NASA is seeking their <a href="https://twitter.com/Interplanetypod/status/1300816238873137153" target="_blank">next class of Flight Directors for Human Spaceflight missions</a>.</li></ul></div><!--[if mso]> <![endif]--> <!--[if mso]></table><![endif]--></div></td></tr><tr></tr></tbody></table><!--[if (gte mso 9)|(IE)]></table><![endif]--> </center></div></article></main><hy-drawer threshold="10" touch-events="" prevent-default=""></hy-drawer> </div></div>]]>
            </description>
            <link>http://orbitalindex.com/archive/2020-09-02-Issue-80</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353966</guid>
            <pubDate>Wed, 02 Sep 2020 15:06:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Clojure in the command line with Babashka]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24353476">thread link</a>) | @Borkdude
<br/>
September 2, 2020 | https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html | <a href="https://web.archive.org/web/*/https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://www.karimarttila.fi/img/2020-09-01-using-clojure-in-command-line-with-babashka_img_1.png" alt="Ordinary Clojure code"></p>

<p><em>Ordinary Clojure code - can be run in REPL or in command line with Babashka (the whole file can be found <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/bb_postgres.clj">here</a> )</em></p>

<h3 id="introduction">Introduction</h3>

<p>I never bothered to learn <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a> so that I could be really fluent with it. If I needed anything beyond basic Bash stuff I immediately used <a href="https://www.python.org/">Python</a> in command-line scripting.</p>

<p>I‚Äôm currently implementing my Clojure simple server again, this time using the <a href="https://github.com/weavejester/integrant">Integrant</a> library. In this new version, I implemented three data stores: CSV, AWS DynamoDB, and Postgres. I had already implemented importing development data into DynamoDB (using Python), this time I used <a href="https://github.com/borkdude/Babashka">Babashka</a> to import development data into Postgres - mainly just to have an excuse to try if I could replace Python with Clojure when scripting something with Bash.</p>

<p>The scripts can be found in my <a href="https://github.com/karimarttila/clojure">Clojure git</a> repo in directory <a href="https://github.com/karimarttila/clojure/tree/master/webstore-demo/integrant-simple-server/postgres">postgres</a>.</p>

<h3 id="developing-with-babashka">Developing with Babashka</h3>

<p>The really neat thing with Babashka is that you can develop your Babashka scripts as part of your Clojure project, or independently but using your favorite Clojure IDE. The picture above shows Clojure code in my favorite Clojure IDE, <a href="https://cursive-ide.com/">Cursive</a>. I have the Clojure code that imports data into the Postgres database in directory <a href="https://github.com/karimarttila/clojure/tree/master/webstore-demo/integrant-simple-server/postgres">postgres</a>, so I have the following extra path in my <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/deps.edn">deps.edn</a>:</p>

<div><div><pre><code><span> </span><span>:postgres</span><span> </span><span>{</span><span>:extra-paths</span><span> </span><span>[</span><span>"postgres"</span><span>]}</span><span>
</span></code></pre></div></div>

<p>Then the nice thing is that I can develop the Clojure code as part of project‚Äôs other Clojure code. Let‚Äôs first create a short bash script that tells Babashka to run your Clojure code with a flag so that we know in the Clojure code when we are running the code using Babashka or using Clojure IDE REPL (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-bb-load-data.sh">run-bb-load-data.sh</a>):</p>

<div><div><pre><code><span>#/bin/bash</span>

<span>export </span><span>POSTGRES_PASSWORD</span><span>=</span>simpleserver
<span>export </span><span>RUNNING_BB</span><span>=</span>TRUE
bb bb_postgres.clj
</code></pre></div></div>

<p>The flag is the <code>RUNNING_BB</code> export above.</p>

<p>Then in the Clojure code we have a top level form <code>(run-me)</code> in the namespace (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/bb_postgres.clj">bb_postgres.clj</a>):</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>run-me</span><span> </span><span>[]</span><span>
  </span><span>"Loads data only if running from Babashka script which sets the environment variable.
  We don't want the repl to load the data when reloading the namespace.
  In repl experimentation use the rich comment below."</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>running-bb?</span><span> </span><span>(</span><span>System/getenv</span><span> </span><span>"RUNNING_BB"</span><span>)]</span><span>
    </span><span>(</span><span>if</span><span> </span><span>(</span><span>=</span><span> </span><span>running-bb?</span><span> </span><span>"TRUE"</span><span>)</span><span>
      </span><span>(</span><span>import-data</span><span>))))</span><span>

</span><span>(</span><span>run-me</span><span>)</span><span>
</span></code></pre></div></div>

<p>I.e. when reloading the namespace REPL runs the code but if the flag is not set it doesn‚Äôt actually do anything - it imports the code only if we are running the code using Babashka. The reason for this is that when I reload the namespace as part of my Clojure workflow I don‚Äôt want the data import to happen. For development purposes to test importing data, or any other function, I have a <code>rich comment</code> at the end of the file:</p>

<div><div><pre><code><span>(</span><span>comment</span><span>
  </span><span>(</span><span>def</span><span> </span><span>data-dir</span><span> </span><span>"dev-resources/data"</span><span>)</span><span>
  </span><span>(</span><span>get-raw-products</span><span> </span><span>data-dir</span><span> </span><span>2</span><span>)</span><span>
  </span><span>(</span><span>get-product-groups</span><span> </span><span>data-dir</span><span>)</span><span>
  </span><span>(</span><span>do</span><span>
    </span><span>(</span><span>delete-products!</span><span>)</span><span>
    </span><span>(</span><span>delete-product-groups!</span><span>))</span><span>
  </span><span>(</span><span>vals</span><span> </span><span>(</span><span>get-users</span><span> </span><span>data-dir</span><span>))</span><span>
  </span><span>(</span><span>load-users</span><span> </span><span>(</span><span>vals</span><span> </span><span>(</span><span>get-users</span><span> </span><span>data-dir</span><span>)))</span><span>
  </span><span>(</span><span>import-data</span><span>)</span><span>
  </span><span>(</span><span>db-get-all-product-groups</span><span>)</span><span>
  </span><span>(</span><span>db-get-all-products</span><span>)</span><span>
  </span><span>)</span><span>
</span></code></pre></div></div>

<p>The <code>comment</code> block is here so that REPL does not run this code when reloading, of course. The function calls you see inside the comment block are just experiments added in no particular order. I can send any of these forms individually to be evaluated in the REPL - a typical Clojure trick when developing with REPL.</p>

<h3 id="babashka-use-cases">Babashka Use Cases</h3>

<p>I really like the idea that I can now use Clojure in shell scripting. Of course I could use Clojure in shell scripting also without Babashka but JVM boot takes quite a long time which makes testing of the script in command line a bit painful. Not so with Babashka - Babashka boots lightning fast:</p>

<div><div><pre><code>Œª&gt; <span>time </span>bb <span>'(println "Hello world!")'</span>
Hello world!

real	0m0.006s
user	0m0.003s
sys	0m0.003s
</code></pre></div></div>

<p>The use cases using Babashka in my personal scripting probably is a bit like I used Babashka to import data into the Postgres database in this exercise:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>run-sql</span><span> </span><span>[</span><span>command</span><span>]</span><span>
  </span><span>(</span><span>sh/sh</span><span> </span><span>"psql"</span><span> </span><span>"--host"</span><span> </span><span>"localhost"</span><span> </span><span>"--port"</span><span> </span><span>"5532"</span><span> </span><span>"--username=simpleserver"</span><span> </span><span>"--dbname=simpleserver"</span><span> </span><span>"-c"</span><span> </span><span>command</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>insert-product-group!</span><span> </span><span>[</span><span>product-group</span><span>]</span><span>
  </span><span>(</span><span>println</span><span> </span><span>"Inserting product-group: "</span><span> </span><span>product-group</span><span>)</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[[</span><span>id</span><span> </span><span>name</span><span>]</span><span> </span><span>product-group</span><span>
        </span><span>command</span><span> </span><span>(</span><span>str</span><span> </span><span>"INSERT INTO product_group VALUES ('"</span><span> </span><span>id</span><span> </span><span>"', '"</span><span> </span><span>name</span><span> </span><span>"');"</span><span>)]</span><span>
    </span><span>(</span><span>run-sql</span><span> </span><span>command</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>load-product-groups</span><span> </span><span>[</span><span>product-groups</span><span>]</span><span>
  </span><span>(</span><span>doseq</span><span> </span><span>[</span><span>pg</span><span> </span><span>product-groups</span><span>]</span><span>
    </span><span>(</span><span>insert-product-group!</span><span> </span><span>pg</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>get-product-groups</span><span> </span><span>[</span><span>data-dir</span><span>]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>raw</span><span> </span><span>(</span><span>with-open</span><span> </span><span>[</span><span>reader</span><span> </span><span>(</span><span>io/reader</span><span> </span><span>(</span><span>str</span><span> </span><span>data-dir</span><span> </span><span>"/product-groups.csv"</span><span>))]</span><span>
              </span><span>(</span><span>doall</span><span>
                </span><span>(</span><span>csv/read-csv</span><span> </span><span>reader</span><span>)))</span><span>
        </span><span>product-groups</span><span> </span><span>(</span><span>into</span><span> </span><span>{}</span><span>
                             </span><span>(</span><span>map</span><span>
                               </span><span>(</span><span>fn</span><span> </span><span>[[</span><span>item</span><span>]]</span><span>
                                 </span><span>(</span><span>str/split</span><span> </span><span>item</span><span> </span><span>#</span><span>"\t"</span><span>))</span><span>
                               </span><span>raw</span><span>))]</span><span>
    </span><span>product-groups</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>import-data</span><span> </span><span>[]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>data-dir</span><span> </span><span>"dev-resources/data"</span><span>
        </span><span>product-groups</span><span> </span><span>(</span><span>get-product-groups</span><span> </span><span>data-dir</span><span>)]</span><span>
</span><span>;...</span><span>
    </span><span>(</span><span>load-product-groups</span><span> </span><span>product-groups</span><span>)</span><span>
</span><span>;...</span><span>
</span></code></pre></div></div>

<p>I.e. parsing CSV, transforming data, and then call some program with the transformed data, possibly read what was returned and do other stuff. You could possibly do all this using plain old Bash but I never bothered to learn Bash in that level that I can do more than test some flags and call other programs using Bash.</p>

<h3 id="how-do-i-use-the-babashka-script-in-this-exercise">How Do I Use the Babashka Script in This Exercise?</h3>

<p>I used Babashka to load development data into the Postgres data store. During development I built a custom Postgres image and provided a <a href="https://github.com/casey/just">Just</a> recipe to start the data store (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/Justfile">Justfile</a>):</p>

<div><div><pre><code><span># Start local postgres</span>
@postgres:
    <span>cd </span>postgres <span>&amp;&amp;</span> ./run-docker-compose.sh
</code></pre></div></div>

<p>The <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-docker-compose.sh">run-docker-compose.sh</a> starts the Postgres docker container, creates the schema and finally calls <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-bb-load-data.sh">./run-bb-load-data.sh</a> which loads the data into the development Postgres data store:</p>

<div><div><pre><code><span>#!/usr/bin/env bash</span>

<span>echo</span> <span>"NOTE: Remember to destroy the container if running again!"</span>
<span>echo</span> <span>"Starting docker compose..."</span>
docker-compose <span>-p</span> ss-postgres <span>-f</span> docker-compose-setup-local-postgres.yml up <span>-d</span>
<span>sleep </span>5
<span>echo</span> <span>"Creating Simple Server schemas..."</span>
./create-schema.sh
<span>sleep </span>1
<span>echo</span> <span>"Loading data..."</span>
./run-bb-load-data.sh
<span>sleep </span>1
docker logs <span>-f</span> ss-postgres_postgres_1
</code></pre></div></div>

<h3 id="clojure-babashka-vs-python-in-shell-scripting">Clojure (Babashka) vs Python in Shell Scripting</h3>

<p>Let‚Äôs finally compare Python and Clojure (Babashka) when doing some Linux shell scripting.</p>

<p><strong>Easiness</strong>. Both languages are pretty easy and fast to work if you have used them. Developing Python scripts is pretty fast - you just run the script in command line. Working with Clojure has one additional plus: you can use the Clojure REPL.</p>

<p><strong>Library support</strong>: Python wins. When you are scripting in Python and you realize that it would be nice e.g. to use some AWS library - just use it (e.g. <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/dynamodb/pysrc/table_importer.py">table_importer.py</a> - the AWS <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">boto3</a> library). The library support for Babashka is not as extensive, of course - but Babashka supports quite many namespaces outside <code>clojure.core</code> and also some additional libraries: <a href="https://github.com/borkdude/babashka#built-in-namespaces">Babashka built-in namespaces</a> - keep eye on that page, maybe Babashka library support is growing in the future!</p>

<p>So, the library support might not be as good as with Python. But I really do love Clojure and if I‚Äôm implementing apps using Clojure it is really nice to do some ad hoc scripting using Babashka.</p>

<h3 id="conclusions">Conclusions</h3>

<p>It‚Äôs nice to have another scripting tool in my toolbox: <a href="https://github.com/borkdude/babashka">Babashka</a>. Time will tell if I start using Clojure instead of Python as my preferred scripting language, thanks to Babashka. At least in this exercise Babashka did really well.</p>

<p><em>The writer is working at Metosin using Clojure in cloud projects. If you are interested to start a Clojure project in Finland or you are interested to get Clojure training in Finland you can contact me by sending email to my Metosin email address or contact me via LinkedIn.</em></p>

<p>Kari Marttila</p>

<ul>
  <li>Kari Marttila‚Äôs Home Page in LinkedIn: <a href="https://www.linkedin.com/in/karimarttila/">https://www.linkedin.com/in/karimarttila/</a></li>
</ul>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353476</guid>
            <pubDate>Wed, 02 Sep 2020 14:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Tagging Best Practices: Using Terraform and CloudFormation to Enforce Tags]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24353412">thread link</a>) | @toeknee123
<br/>
September 2, 2020 | https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/ | <a href="https://web.archive.org/web/*/https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->            
                
                <!-- End Toc -->
				

<p>Once <a href="https://www.cloudforecast.io/blog/aws-tagging-best-practices/" target="_blank">you have adopted an AWS tagging strategy</a>, you‚Äôll need to make sure that all your existing AWS resources and any new ones you create abide by it. Consistency is the key - if you don‚Äôt proactively enforce your AWS tagging strategy, you‚Äôll always be playing catch up and chasing down team members to make sure they add the right tags to their resources.</p>

<p>While you can apply AWS tags to your resources manually using the <a href="https://docs.aws.amazon.com/cli/latest/reference/resourcegroupstaggingapi/tag-resources.html" target="_blank">AWS CLI</a> or <a href="https://docs.aws.amazon.com/ARG/latest/userguide/tag-editor.html" target="_blank">AWS Tag Editor</a>, you‚Äôll probably find this cumbersome and error-prone at scale. A better approach is to automatically apply AWS tags to your resources and use rules to enforce their consistent usage.</p>

<p>Depending on the tool you use to maintain your infrastructure on AWS, your method of proactively enforcing AWS tags on new resources may vary. In this guide, I‚Äôll highlight two tools: Terraform and AWS CloudFormation. You‚Äôll see how to use each to create and update AWS cost allocation tags on your resources and then enforce the proper use of specific tags for new resources. By proactively enforcing your AWS tagging strategy, you‚Äôll minimize your time spent auditing and correcting improper AWS tags and force developers to learn best AWS tagging best practices for your environment.</p>



<p>The first infrastructure management tool I‚Äôll cover is <a href="https://www.terraform.io/" target="_blank">Terraform</a>. Terraform works across a variety of cloud hosting providers to help you provision and maintain your AWS resources. With Terraform, you can define your servers, databases, and networks in code and apply your changes programmatically to your AWS account.</p>

<p>If you‚Äôre new to Terraform, they have a well-documented <a href="https://learn.hashicorp.com/terraform/getting-started/intro" target="_blank">Getting Started guide</a> and several <a href="https://github.com/terraform-providers/terraform-provider-aws/tree/master/examples" target="_blank">AWS template examples on GitHub</a>. In this section, I‚Äôll show you some snippets from a demo Terraform project and module that <a href="https://github.com/CloudForecast/cf-terraform-demo" target="_blank">is available on GitHub</a>. You‚Äôll learn the following in this Terraform AWS tags:</p>

<ol>
  <li>Tag a New AWS EC2 Instance with Terraform</li>
  <li>Using Terraform to Update Existing AWS Tags</li>
  <li>Enforce AWS Tags with Terraform</li>
</ol>

<h3 id="tag-a-new-aws-ec2-instance-with-terraform">Tag a New AWS EC2 Instance with Terraform</h3>

<p>If you want to deploy an EC2 instance with AWS Tags using Terraform, your configuration might include something like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td><pre>resource "aws_instance" "cart" {
  connection {
    type = "ssh"
    user = "ubuntu"
    host = self.public_ip
    private_key = file(var.private_key_path)
  }

  instance_type = "t2.micro"

  ami = var.aws_amis[var.aws_region]

  key_name = aws_key_pair.auth.key_name

  vpc_security_group_ids = [aws_security_group.default.id]

  subnet_id = aws_subnet.default.id

  provisioner "remote-exec" {
    inline = [
      "sudo apt-get -y update",
      "sudo apt-get -y install nginx",
      "sudo service nginx start",
    ]
  }
  tags = {
    contact = "j-mark"
    env = "dev"
    service = "cart"
  }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The above example includes three AWS cost allocation tags: <code>contact</code>, <code>env</code>, and <code>service</code> with values described as strings. When you <a href="https://www.terraform.io/docs/commands/apply.html" target="_blank">apply this configuration</a>, Terraform will connect to AWS and deploy an EC2 instance having the AWS tags you specified.</p>

<p><img src="https://paper-attachments.dropbox.com/s_11675783F6270CC3362B9903B770D88B278C2B2D779D11551760688B8EA1DFC4_1596383259429_cf-2020-08-02-a.png" alt=""></p>

<h3 id="using-terraform-to-update-existing-aws-tags">Using Terraform to Update Existing AWS Tags</h3>

<p>Terraform makes it easy to update already existing resources with AWS tags in reversible and consistent ways. If you‚Äôre using AWS tags to keep track of a resource‚Äôs contact (e.g.: <code>j-mark</code> in the above example), you‚Äôre likely to need to update the AWS tag when the team member leaves or changes roles.</p>

<p>To update the AWS tags on your resource, simply update the corresponding tags in your Terraform configuration. The new tags will overwrite any previous tags assigned to the resource, including tags added outside of Terraform.</p>

<p>For example, to change the <code>contact</code> cost allocation tag on the EC2 instance above, you might update the <code>tags</code> block above with the following:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>tags = {
  contact = "l-duke"
  env = "dev"
  service = "cart"
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>When you apply this configuration, the AWS tags will be automatically updated in the AWS console:</p>

<p><img src="https://paper-attachments.dropbox.com/s_11675783F6270CC3362B9903B770D88B278C2B2D779D11551760688B8EA1DFC4_1596383277121_cf-2020-08-02-b.png" alt=""></p>

<p>If you keep your Terraform configuration files in version control - which is probably a good idea - you will be able to see how tags have changed over time. You can also review changes using the same code review process that your application code goes through to help you catch mistakes in the execution of your tagging strategy.</p>

<h3 id="enforce-aws-tags-with-terraform">Enforce AWS Tags with Terraform</h3>

<p>As your infrastructure grows, a code review process likely won‚Äôt be enough to prevent improper AWS tagging. Fortunately, you can enforce AWS tag names and values using <a href="https://www.terraform.io/docs/configuration/variables.html" target="_blank">variables</a> and custom validation rules in Terraform.</p>

<p>In the examples above, the <code>tags</code> list was hard-coded into the EC2 instance definition. A more scalable pattern would be to break your EC2 instance template into its own <a href="https://www.terraform.io/docs/configuration/modules.html" target="_blank">module</a> and use a <code>tags</code> variable. You can then write a <a href="https://www.terraform.io/docs/configuration/variables.html#custom-validation-rules" target="_blank">custom validation rule</a> to check that the tags comply with your strategy.</p>

<p>For example, if you want to check that:</p>

<ol>
  <li>The user specifies at least one tag</li>
  <li>The <code>contact</code> tag is either <code>j-mark</code> or <code>l-duke</code></li>
  <li>The <code>env</code> tag is set</li>
  <li>The <code>service</code> tag is either <code>cart</code> or <code>search</code></li>
</ol>

<p>You might create a module with a variable specified like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre>variable "tags" {
  description = "The tags for this resource."
  validation {
    condition = length(var.tags) &gt; 0 &amp;&amp; contains(["j-mark", "l-duke"], var.tags.contact) &amp;&amp; var.tags.env != null &amp;&amp; contains(["cart", "search", "cart:search"], var.tags.service)
    error_message = "Invalid resource tags applied."

  }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now when you run <code>terraform plan</code> with a missing or invalid tag, you‚Äôll get an error:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>Error: Invalid value for variable
...
Invalid resource tags applied.
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Your rules can be as complex as <a href="https://www.terraform.io/docs/configuration/index.html" target="_blank">Terraform‚Äôs Configuration Language</a> allows, so functions like <code>regex()</code>, <code>substr()</code>, and <code>distinct()</code> are all available. That said, there are some caveats to this approach.</p>

<p>First, custom variable validation is an experimental feature in Terraform. <a href="https://www.terraform.io/docs/configuration/terraform.html#experimental-language-features" target="_blank">Experimental features</a> are subject to change, meaning that you might need to pay attention to Terraform update mores closely. To enable <code>variable_validation</code>, add the following to your <code>terraform</code> block:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>terraform {
  experiments = [variable_validation]
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Second, Terraform‚Äôs variable validation only happens during the <code>terraform plan</code> phase of your infrastructure‚Äôs lifecycle. It can‚Äôt prevent users from accidentally changing your tags directly in the AWS console, and it‚Äôs only as good as the validation rules you write. If you start using a new resource but forget to add validation rules, you might end up with lots of resources that don‚Äôt adhere to your tagging strategy.</p>

<p>Another option for paid Terraform Cloud customers is <a href="https://www.terraform.io/docs/cloud/sentinel/index.html" target="_blank">Sentinel</a>, which allows you to create custom policies for your resources. I won‚Äôt cover this method here, but Terraform has created an <a href="https://www.terraform.io/docs/cloud/sentinel/examples.html" target="_blank">example policy</a> to show you how to enforce mandatory AWS tags.</p>



<p>Similar to Terraform, AWS <a href="https://aws.amazon.com/cloudformation/" target="_blank">CloudFormation</a> lets you provision AWS resources based on configuration files. Unlike Terraform, CloudFormation is part of Amazon‚Äôs offerings, so it won‚Äôt necessarily help you if you want to use another infrastructure provider. The approach to tagging your resources in CloudFormation is similar to that used by Terraform, but as you‚Äôll see, the configuration format is different.</p>

<p>If you‚Äôre new to AWS CloudFormation, <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/GettingStarted.Walkthrough.html" target="_blank">Amazon‚Äôs official walkthrough</a> will help you get started deploying some basic templates. In this section, I‚Äôll show you some snippets from a demo AWS CloudFormation template which is <a href="https://github.com/CloudForecast/cf-cloudformation-demo" target="_blank">also available on GitHub</a>. You‚Äôll learn the following in this Terraform AWS tags section:</p>

<ol>
  <li>AWS CloudFormation Template to Deploy Tags</li>
  <li>Using CloudFormation to Update AWS Tags</li>
  <li>CloudFormation Template to Enforce AWS Tags</li>
</ol>

<h3 id="aws-cloudformation-template-to-deploy-tags">AWS CloudFormation Template to Deploy Tags</h3>

<p>AWS CloudFormation is designed to make it easy to create AWS resources with a single template file. Using a CloudFormation template, every resource that can be deployed with an AWS tag.</p>

<p>For example, to create a new EC2 instance with the same three AWS tags used in the Terraform example above, add an array of <code>Tags</code> to the resource‚Äôs <code>Properties</code> block:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td><pre>"Resources" : {
  "WebServerInstance": {  
    "Type": "AWS::EC2::Instance",
    "Metadata" : {...},
    "Properties": {
      "Tags" : [
       {
          "Key" : "contact",
          "Value" : "j-mark"
       },
       {
          "Key" : "env",
          "Value" : "dev"
       },
       {
          "Key" : "service",
          "Value" : "cart"
       }
      ],
      ...       
    }
  },
  ...         
},
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Using <a href="https://aws.amazon.com/cli/" target="_blank">AWS CLI</a>, you can <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/create-stack.html" target="_blank">deploy this CloudFormation template as a new stack</a>. This will ensure your template is valid and create the specified resources with their tags on AWS:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>aws cloudformation create-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>If you have lots of similar resources in your template, you can deploy AWS tags to all the resources in the stack at once using the <code>--tags</code>  flag with the <code>create-stack</code> or <code>update-stack</code> commands:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre># Creating a stack with tags
aws cloudformation create-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt; --tags="Key=env,Value=dev"

# Updating a stack with tags
aws cloudformation update-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt; --tags="Key=env,Value=dev"
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="using-cloudformation-to-update-aws-tags">Using CloudFormation to Update AWS Tags</h3>

<p>If you want to change the contact on your EC2 instance created above, simply change the <code>Tags</code> section of your template file and use the <code>[update-stack](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/update-stack.html)</code> <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/update-stack.html" target="_blank">command</a> to deploy your changes.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre>"Tags" : [
 {
    "Key" : "contact",
    "Value" : "l-duke"
 },
  ...
],
</pre></td></tr></tbody></table></code></pre></div></div>

<p>AWS CloudFormation behaves the same way that Terraform does when you update tags outside your template file. Any tags set manually will be overridden by the <code>update-stack</code> ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/">https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/</a></em></p>]]>
            </description>
            <link>https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353412</guid>
            <pubDate>Wed, 02 Sep 2020 14:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To be creative, Chinese philosophy teaches us to abandon ‚Äòoriginality‚Äô]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24353137">thread link</a>) | @canada_random1
<br/>
September 2, 2020 | https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>When I was 15</strong>, one of my closest friends died unexpectedly. Our physics teacher broke the news to me after I√¢‚Ç¨‚Ñ¢d sat an exam, having wondered all the way through why my friend wasn√¢‚Ç¨‚Ñ¢t there doing the same. I still don√¢‚Ç¨‚Ñ¢t have the words to describe how I felt: it was something approaching shock, distress, disorientation. I didn√¢‚Ç¨‚Ñ¢t know what to think, much less what to do. I spent many nights awake and many days in a daze.</p>
<p>Fifteen years later, when I was in graduate school, another friend died suddenly, a man I loved very much. I remember checking my phone and finding out, to my dismay, via text message. But while my initial response was much the same as before, there was a palpable difference in how I felt later on. While I was again surprised and saddened, I was much less disoriented than I√¢‚Ç¨‚Ñ¢d been as a teenager. I could still think, and I could still get things done. It seemed to me that I√¢‚Ç¨‚Ñ¢d become better at living with loss.</p>
<p>You might think that the reason for this difference is obvious √¢‚Ç¨‚Äú I was older, and I√¢‚Ç¨‚Ñ¢d had more experience in coping with death. But raw experience alone isn√¢‚Ç¨‚Ñ¢t enough: what matters more is whether we learn from experience. And learning from experience, especially an experience as difficult as the death of a loved one, can involve quite a lot. Among other things, it can involve creativity.</p>
<p>This claim might seem surprising. After all, creativity is often associated with the idea of a lone creative genius, an individual who not only excels at what they do, but also transforms the world in the process. Further, even if we don√¢‚Ç¨‚Ñ¢t limit ourselves to romantic or heroic perspectives on the nature and value of creativity, it√¢‚Ç¨‚Ñ¢s commonly thought that creativity at least aims at novelty or originality.</p>
<p>This way of thinking about creativity isn√¢‚Ç¨‚Ñ¢t universal. The <a href="http://cup.columbia.edu/book/the-complete-works-of-zhuangzi/9780231164740"><em>Zhuangzi</em></a> (√®≈Ω≈†√•¬≠ÔøΩ), a classical Chinese philosophical and literary text, provides a different perspective. On one interpretation, creativity isn√¢‚Ç¨‚Ñ¢t conceived as aiming at novelty or originality, but rather <em>integration</em>. Instead of aiming at something new, it aims at something that combines well with the situation of which it√¢‚Ç¨‚Ñ¢s a part.</p>
<p>The story of Wheelwright Pian, from a chapter of the Zhuangzi known as the <em>Tian Dao</em> (√•¬§¬©√©ÔøΩ‚Äú), meaning √¢‚Ç¨ÀúHeaven√¢‚Ç¨‚Ñ¢s Way√¢‚Ç¨‚Ñ¢ or √¢‚Ç¨ÀúThe Way of Heaven√¢‚Ç¨‚Ñ¢, effectively illustrates this perspective on creativity as it pertains to artists or artisans. In this short vignette, a wheelwright known as Pian (√¶‚Ä∞ÔøΩ) tells a duke that the book of sages√¢‚Ç¨‚Ñ¢ advice he√¢‚Ç¨‚Ñ¢s reading is nothing but √¢‚Ç¨Àúchaff and dregs√¢‚Ç¨‚Ñ¢. Angered, the duke demands an explanation. The wheelwright responds that, at least concerning his craft, he can create what he does only because he√¢‚Ç¨‚Ñ¢s developed a √¢‚Ç¨Àúknack√¢‚Ç¨‚Ñ¢ for it that can√¢‚Ç¨‚Ñ¢t be wholly conveyed in words. If the blows of his mallet are too gentle, his chisel slides and won√¢‚Ç¨‚Ñ¢t take hold. If they√¢‚Ç¨‚Ñ¢re too hard, it bites in and won√¢‚Ç¨‚Ñ¢t budge. √¢‚Ç¨ÀúNot too gentle, not too hard √¢‚Ç¨‚Äú you can get it in your hand and feel it in your mind,√¢‚Ç¨‚Ñ¢ he says. √¢‚Ç¨ÀúSo, I√¢‚Ç¨‚Ñ¢ve gone along for 70 years and at my age I√¢‚Ç¨‚Ñ¢m still chiselling wheels. When the men of old died, they took with them the things that couldn√¢‚Ç¨‚Ñ¢t be handed down. So, what you are reading there must be nothing but the chaff and dregs of the men of old.√¢‚Ç¨‚Ñ¢</p>
<p>Although he√¢‚Ç¨‚Ñ¢s a √¢‚Ç¨Àúlowly√¢‚Ç¨‚Ñ¢ craftsperson, the wheelwright has something important to teach the duke. He√¢‚Ç¨‚Ñ¢s been creating wheels by hand for many years and has developed an ability to act and to execute his craft in an integrated manner that can√¢‚Ç¨‚Ñ¢t be fully captured through an algorithmic list of instructions. He responds to precise particularities in the wood, his tools and his body to create what he wants √¢‚Ç¨‚Äú something he doesn√¢‚Ç¨‚Ñ¢t accomplish by imposing a plan.</p>
<p>Striving for originality can be counterproductive when it comes to achieving genuinely fresh results</p>
<p>The sages√¢‚Ç¨‚Ñ¢ advice for living well is therefore mere √¢‚Ç¨Àúdregs√¢‚Ç¨‚Ñ¢ if it√¢‚Ç¨‚Ñ¢s interpreted as instructions that one can simply read and then complete. Living well in general involves much more than this; namely, a spontaneous integration between contrasting types such as the hard and the soft, as well as the learned and the spontaneous, the active and the passive, and even the unproductive and the productive √¢‚Ç¨‚Äú all of which apply in the case of carving wheels, as well as elsewhere. In other words, living well involves creativity.</p>
<p>This kind of creativity isn√¢‚Ç¨‚Ñ¢t taken to aim at novelty or originality as such. The wheelwright is presented as creative not because of anything to do with his, or his projects√¢‚Ç¨‚Ñ¢, novelty or originality, but instead because of his ability to create wheels in a sensitive, responsive and √¢‚Ç¨‚Äú crucially √¢‚Ç¨‚Äú well-integrated manner: one not learned by rote, but rather via engaging in sustained, spontaneous activity.</p>
<p>We can use the story of Wheelwright Pian to better understand why learning to live with loss is a creative pursuit. Although there√¢‚Ç¨‚Ñ¢s an abundance of books dispensing advice on how to do so, ultimately learning to live with death is a deeply personal endeavour that √¢‚Ç¨‚Äú like carving wheels √¢‚Ç¨‚Äú can√¢‚Ç¨‚Ñ¢t be fully captured through a programmatic set of directions. We must respond to precise particularities of our situation (concerning our thoughts, feelings and overall circumstances) to create what we want to create (such as a sense of peace or closure). This isn√¢‚Ç¨‚Ñ¢t something that can be accomplished by imposing a plan, even if we make various provisional and highly malleable √¢‚Ç¨Àúplans√¢‚Ç¨‚Ñ¢ on the fly as we go along.</p>
<p>Moreover, in working through our thoughts, feelings and circumstances in all their particularities, it√¢‚Ç¨‚Ñ¢s not that we√¢‚Ç¨‚Ñ¢re doing anything all that different from what countless others have had to do as they√¢‚Ç¨‚Ñ¢ve learned to cope with loss. Nonetheless √¢‚Ç¨‚Äú again, like carving wheels √¢‚Ç¨‚Äú it√¢‚Ç¨‚Ñ¢s plausibly a creative activity, in that it involves a spontaneous integration between contrasting types such as the grieving and the celebratory, the resentful and the grateful, the distressed and the joyous. The ability to live with death, too, in a sensitive, responsive, and well-integrated manner isn√¢‚Ç¨‚Ñ¢t learned by rote, but rather via engaging in sustained, spontaneous activity. Indeed, even the philosopher Zhuangzi himself can be understood as engaging in such a creative process after the death of his own wife in chapter 18 of the text, the <em>Zhi Le</em> (√®‚Ä°¬≥√¶¬®‚Äö), meaning √¢‚Ç¨ÀúPerfect Happiness√¢‚Ç¨‚Ñ¢ or √¢‚Ç¨ÀúPerfect Joy√¢‚Ç¨‚Ñ¢.</p>
<p><strong>This way of thinking</strong> about creativity has a variety of other potential benefits. First, even if creativity were taken to aim at originality, de-emphasising originality might ironically result in greater creativity. This is because striving for originality can actually be counterproductive when it comes to achieving genuinely fresh results: if we focus on the task of achieving something original, we√¢‚Ç¨‚Ñ¢ll explore only the range of possibilities deemed sufficiently likely to yield that result, leaving out a lot that could have contributed to achieving something original.</p>
<p>But imagine instead that we worked with idea that creativity wasn√¢‚Ç¨‚Ñ¢t about novelty. That doesn√¢‚Ç¨‚Ñ¢t mean we√¢‚Ç¨‚Ñ¢d have to give up the value of originality entirely, but rather see it as one of a range of possible outcomes. Casting a wider net in this way might hence make creativity (whatever it involves) easier to achieve.</p>
<p>Second, focusing on integration could encourage us to better understand creative agents as being intimately connected with, and products of, their environments. This would broaden our notion of creativity in a way that might allow us to see creativity demanded in a greater range of activities. After all, many of life√¢‚Ç¨‚Ñ¢s activities, from the mundane to the meaningful, aren√¢‚Ç¨‚Ñ¢t learned by rote, but rather via spontaneous action that integrates contrasting aspects. Just for starters, additional examples might include getting along with one√¢‚Ç¨‚Ñ¢s family, building relationships with colleagues and organising one√¢‚Ç¨‚Ñ¢s finances.</p>
<p>This alternative perspective on creativity might help us to see it as an everyday phenomenon in which we all participate √¢‚Ç¨‚Äú rather than an extraordinary talent or gift that only a few enjoy. And it might also allow us to make sense of the idea of <a href="https://link.springer.com/chapter/10.1007/978-3-319-43893-1_19#:~:text=As%20an%20art%20practice%2C%20calligraphy,Daoist%20aesthetic%20concerns%20discussed%20here.&amp;text=The%20aesthetic%20of%20the%20everyday,and%20the%20need%20for%20imagination">living creatively</a>: of an integrated life, lived spontaneously, in which all of life√¢‚Ç¨‚Ñ¢s contrasting aspects can be arranged to form a rich and variegated whole.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353137</guid>
            <pubDate>Wed, 02 Sep 2020 13:44:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serverless Functions with Vercel]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24352879">thread link</a>) | @andreascreten
<br/>
September 2, 2020 | https://andr.as/32SiY27 | <a href="https://web.archive.org/web/*/https://andr.as/32SiY27">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group" id="gatsby-focus-wrapper"><main><section width="auto"><section width="auto"><a href="#footer">Menu</a><a href="https://andr.as/"></a><section width="1024px"><div><div><p>Published on <strong>September 02, 2020</strong> <span>and filed under<!-- --> <a href="https://andr.as/blog/software-engineering/#categories"><strong>Software engineering</strong></a><br>Written<!-- --> </span>by</p><!-- --> <p><a href="https://andr.as/team/geoffrey-dhuyvetters/"><strong>Geoffrey Dhuyvetters</strong></a> <span>and will take <p><strong>5<!-- --> <!-- -->minutes</strong></p> of your time.</span></p></div></div><p><span>In short</span>In this article I'll walk you through the steps to create serverless functions with Vercel. These functions will provide you with a place to add server side logic like verifying captcha's, sending emails or liking posts that you can use in your static sites.</p></section></section></section><section width="auto"><div><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAB00lEQVQozx2SS2sTYRiFZ+9KsZkkc8vMJDOZ3C+Tm4nNJKYJXtI2BiJYhOAFxRJpKIrNQgkFDUJX3qALEcXiVvT/PX7J4sB3Xr5zFu/zSiEtSlhoS4ug6ioR8XYMA01TCakRcqaFbejUbIekbiArYYqWTUP4YsxCjsibvCaya0lt08W3EjRjCfoxl9eZFgcJn6njc1IK+NMY87l+h3+tCUdOlale4EdlyIdMwO/mXT4GY07zwaY4qilIi0ybL5XbLLMBU6/KYa5J23A4Ff5TY5eOl2XuNZgl6wztNC8Mn4vyLntWiu/NEatgxKFX4+zWfRKmifQ+1eO42mWxM+br4ICL9oRjp85RrMI7t8NABJ8LPxMamVn6lsd+KM5ZpsuTdJUgYlGQdU78HiU7jjRPtgisJI+cCkvvOq/STf6Wxywz2zy1y5y7A1apG7wp9fiWHfBAz/HMrbLwtvnlD/lZ2mMWrzHWPWSxSykkYKyX2Qlb1BWTy1qYh8kKE69ITovR113OCzeZlprcc/K8LXSY+wGmqvLSvcZjp8Yq36VluxuIki7KFF3BVlQMVdmUX1XDXBE0I2Iu61F2EilMQf2SskVDAMwasQ0AR1Bf/11fwbpHFbP/l6PoVSuwR8sAAAAASUVORK5CYII=" alt=""></p></div></section><section width="auto"><div><p><a href="" target="_blank" rel="noopener noreferrer"><img src="data:image/svg+xml;base64,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" alt="Twitter logo"></a></p></div></section><section type="condensed" step="email"><div><p><img src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAeABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBA//EABgBAAIDAAAAAAAAAAAAAAAAAAECAAQF/9oADAMBAAIQAxAAAAHijrW1pQhndtlgB//EABoQAAEFAQAAAAAAAAAAAAAAAAEAAhAREiD/2gAIAQEAAQUCFVkrMF3TY//EABURAQEAAAAAAAAAAAAAAAAAABAR/9oACAEDAQE/ASQ//8QAFhEBAQEAAAAAAAAAAAAAAAAAARAR/9oACAECAQE/AXYs/8QAFxAAAwEAAAAAAAAAAAAAAAAAASAhEP/aAAgBAQAGPwKpGOf/xAAbEAEAAwEAAwAAAAAAAAAAAAABABEhEFFhcf/aAAgBAQABPyHVq/U+Uv5INMyLRbd4dQCSOs//2gAMAwEAAgADAAAAEHvhzv/EABoRAAICAwAAAAAAAAAAAAAAAAABEBEhQVH/2gAIAQMBAT8Qdp4KfTdH/8QAGREBAAIDAAAAAAAAAAAAAAAAAQAhEBFR/9oACAECAQE/EFQJp7Kcf//EAB0QAQACAQUBAAAAAAAAAAAAAAEAETEQIUFRYYH/2gAIAQEAAT8Qxl0atl4+QYLR5EMnAB6bm+HvmJcrdMnSjqWYKriKxxbP/9k=" alt=""></p></div><section width="auto"><p type="condensed">Want to see more articles like this in your inbox? You know what to do.</p><section width="auto"></section></section></section><section height="condensed"><div><div><p><img src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='500'%3e%3cpath%20d='M0%20250v250h401V0H0v250m194-145l-1%202-1%201-3%203c-1%203-2%205-3%204l-2%201c0%201-1%201-1-1l-1-3v2l-2%206-2%205c0%203%200%203-1%201s-3-3-3-1l1%201c3%200-4%2014-8%2015-2%200-5%206-6%2013l1%204%202-2v-5l2-6c1-1%201-1%201%201%200%203%201%203%2010%202%203-1%204-1%206%201l6%203c5%201%206%203%203%204l-2%201c-1%202-11%201-12%200-1-2-5%201-5%203v1c-2%200-5-2-5-3%200-2%207-4%2012-4l6-1h-14l-5%202-1%202-2%202c-2%200-2%200-2%209%201%2017%205%2033%209%2034l1%202%201%202%202%202%205%204%204%203%202%201%202%201c3%203%2016%206%2018%203l4-1%206-3%204-3c2%200%206-5%208-8l3-3c1%201%201%200%201-2l1-1c1%201%202-2%203-8l2-12c2-8%202-14-1-26-2-6-2-8-1-10s0-9-1-10l-1%201c0%204-3-6-3-10%200-7-7-13-13-11-7%202-18%200-19-3v-2l-2%202c-3%203-6%203-4%200l3-4c2-2%201-3-2-1m51%2054l-1%208-1%205-1%203v8c-1%205-1%205%201%205%203%200%205-3%205-9l3-7%201-7c0-6%200-6-1-1l-1%205v-4l-1-5-1-1%202-1h1c-1-3-5-2-6%201m-51%207l-3%203-2%201%202%201c3%201%204%203%200%204h-3l-2-1-1%201v3c2%200%201%202-2%203-4%202-5%208-2%2010l4%202%203%202c1%202%202%203%203%202h1l1%201c4-2%2013-2%2013-1v1l2-1h2l4-2c1-2%202-2%202-1%200%203%203-2%203-5s-3-7-4-5v2c-2%201-2%201-1%202%203%201%202%202%200%201h-12l-9-1h-4l-3-1c1-2%205-2%2011-1%203%201%205%201%207-1%203-2%200-4-3-2-3%201-8-1-9-4%200-1%202-1%205%201h5l4-2%204-1c0-2-4-2-7-1-4%202-8%201-8-2l-1-4%201-2c1%201%201%200%201-1%200-3-2-3-2-1m39%2049l-6%206-3%204c0%201-8%205-11%205l-12%203c-1%201-4%200-8-1-3-1-7-2-8-1l-1-1h-1c-2%201-4%200-4-3-1-3-10-13-11-11l1%208c3%2013%204%2017%201%2017-2-1-2-1%200%204s10%2011%2016%2013c7%203%2026%202%2034-1%2016-5%2026-23%2018-32-2-2-3-4-3-8v-5l-2%203'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e" alt=""></p></div><div><h3>Geoffrey Dhuyvetters</h3><p>This former teacher likes all things front end (the more complex web applications get, the happier Geoffrey becomes). His weak spot? JavaScript and all its quirks</p><p><a href="https://andr.as/team/geoffrey-dhuyvetters">Learn more about <!-- -->Geoffrey Dhuyvetters</a></p></div></div></section><section><h2>Related articles</h2></section></main></div></div></div>]]>
            </description>
            <link>https://andr.as/32SiY27</link>
            <guid isPermaLink="false">hacker-news-small-sites-24352879</guid>
            <pubDate>Wed, 02 Sep 2020 13:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Actively Discourage Online Tooling like jwt.io and Online JSON Validators]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 162 (<a href="https://news.ycombinator.com/item?id=24352360">thread link</a>) | @pcr910303
<br/>
September 2, 2020 | https://www.jvt.me/posts/2020/09/01/against-online-tooling/ | <a href="https://web.archive.org/web/*/https://www.jvt.me/posts/2020/09/01/against-online-tooling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Something my colleagues know well is how little I trust online tools like <a href="https://jwt.io/">jwt.io</a>, online JSON validators or online tooling in general, but it also bleeds into <a href="https://www.jvt.me/mf2/2020/08/zebqf/">comments I make online</a> and in my blog posts, too, and I thought I'd share a little bit of a reason as to why.</p><p>Instead of using an online service, I will reach for a way to run it locally, using whichever programming language toolchain I have available. But why? Why wouldn't I recommend something like jwt.io? Or an online JSON validator, especially if they boast client-side functionality, and mean I don't need things installed?</p><p>Let's start with a bit of background. Firstly, I'd just like to caveat this all with the note that <strong>I have no access to Production data, customer or otherwise</strong>. All of these examples are referencing Non-Production examples.</p><p>I also want to caveat this with the fact that this is <strong>not a personal attack</strong> on jwt.io. I am using them as an example as they're a well-known and well-used service, and I've seen issues with it before. Auth0 run it, and are probably one of the few companies we'd want to be running it. It's also <a href="https://github.com/jsonwebtoken/jsonwebtoken.github.io">Open Source</a> <em>but</em> one of the great difficulties of Web-hosted services are that we have no idea if the source code that we're told is being used is actually being used!</p><p>I'm currently working on the Open Banking platform for Capital One. We're fortunate to have very restricted access to Production, which makes things safer for everyone. One thing we strive to do is to treat Non-Production secrets like Production ones where possible - where we shouldn't have access to them at all, and shouldn't be sharing them with external services. Some of these Non-Production secrets may be usable outside of Capital One, for instance Open Banking Sandbox signing certificates.</p><p>We perform a fair bit of testing in our Non-Production environments and sometimes need to debug things, such as what's inside a JWT (as Open Banking introduces several places they're used). I've been burned a number of times by folks putting a Non-Production JWT or an Open Banking Sandbox certificate into jwt.io. Although Non-Production, these are sensitive in of themselves, as they have implementation details for our services, and as mentioned, certain things could be used outside of Capital One.</p><p>The biggest reason I hear from folks using online tooling is that it's easier, and that they'd rather do that than find out how to run it locally. I disagree with this, but am quite biased, as I often have a blog post for many of these common issues. I love sharing my blog with others and having a handy solution, or if I don't have an answer to a problem, I'll find out how and <a href="https://www.jvt.me/tags/blogumentation/">blogument it for later</a>. So I see that reaching for online tooling is more just because we've got folks who aren't aware of how they could do otherwise.</p><p>One great thing about removing the need for an online tool is that you can self-serve it once you have the tools locally. You can run it locally when you've got no internet (which isn't as much of an issue in these Coronavirus times) but also regardless of whether the upstream service is broken. You can use it with other i.e. command-line tooling, for instance how I've set up <a href="https://gitlab.com/jamietanna/dotfiles-arch/-/blob/master/terminal/home/bin/unpack">this command-line script</a> to handle a lot of common data formats I deal with and unpack them to a human-readable format.</p><p>But most importantly, by telling people to put sensitive data (such as credentials, configuration files, etc) it's a really dangerous lesson for our teams. We're teaching people to blindly trust arbitrary websites that they don't have any relationship with, nor have fully audited the source code, when posting potentially sensitive data.</p><p>I realise this may not be something you do when running it locally, but it's less likely for a well-known library running locally to need to reach outbound.</p><p>jwt.io is an interesting example, because although it boasts that it runs as a client-side solution, you may not have been aware that <a href="https://github.com/jsonwebtoken/jsonwebtoken.github.io/commit/b362ab19a9f37e337b5f8ea38987aa680aa6e0a9">until last September</a>, there were metrics being determined which although may have seemed innocent, show that it's easy for other functionality to be hidden in a seemingly client-side-only website. Unless you audit everything, every time, you're in a risky position where you may be leaking data you're not expecting to.</p><p>I feel that we can do something to help services that handle potentially sensitive data with helping educate the user that they should be more careful, because jwt.io's warning definitely doesn't help with folks who don't fully appreciate what the risk is if jwt.io isn't actually as trustworthy as the user thinks:</p><blockquote><p>Warning: JWTs are credentials, which can grant access to resources. Be careful where you paste them! We do not record tokens, all validation and debugging is done on the client side.</p></blockquote><p>What do you think? Am I maybe being a little too sensitive? Am I not being sensitive enough?</p><p>Edit: Based on some conversations being had in response to the post, I thought it'd mention I've written about how to <a href="https://www.jvt.me/posts/2019/06/13/pretty-printing-jwt-openssl/">pretty-print a JWT locally with OpenSSL</a> and <a href="https://www.jvt.me/posts/2018/08/31/pretty-printing-jwt-ruby/">a Ruby alternative</a>.</p></div></div>]]>
            </description>
            <link>https://www.jvt.me/posts/2020/09/01/against-online-tooling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24352360</guid>
            <pubDate>Wed, 02 Sep 2020 12:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The problem with C compatibility in C++]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24352258">thread link</a>) | @fanf2
<br/>
September 2, 2020 | https://cor3ntin.github.io/posts/c/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://cor3ntin.github.io/posts/c/fight.jpeg" alt="Fish"></p>
<p>In the early 70s, C was created at Bell Labs as a byproduct of the development of UNIX.
It quickly became one of the most popular programming languages.
But it was not expressive enough for Bjarne Stroustrup.
And so, in 1983, as a byproduct of his Ph.D. thesis, he extended C.</p>
<p>C with classes was born.</p>
<p>At the time, Bjarne Stroustrup understood that a programming language has many components,
not only the language, its compiler, but also a linker and libraries.
Offering a familiar tool also makes adoption easier.
In this historical context, it makes sense that C++ would be based on C.</p>
<p>Fast-forward 40 years later.</p>
<p>Both C and C++ are widely used in the industry.
But go 5 minutes on the Internet and C developers will tell you that C++ is the most horrific man-made creation,
while many C++ developers wait for the day when C finally burns in the hot flames of hell.</p>
<h2 id="so-what-happened">So what happened?</h2>
<p>On the surface, C and C++ cater to the same use cases: high performance, deterministic, native but portable code for the widest range of hardware and applications.</p>
<p>But C is proudly a low-level language. A nicer assembly.</p>
<p>From day one, C++ had magic. Dark witchcraft: destructors. Suddenly the compiler was doing things on its own.
It also had type inference very early on, but the developers of the mid-80s were not quite ready for that and Bjarne Stroustrup
was pressured into removing <code>auto</code>, until it was added back to C++11.</p>
<p>From then, C++ got more and more tools to build abstractions.
I don‚Äôt think it would be fair to say that C++ is a low-level or high-level language. It‚Äôs both, by design.
But building high-level abstractions while not sacrificing performance is hard.
C++ then needed tools to achieve that: <code>constexpr</code>, move semantics, templates, and an ever-growing standard library.</p>
<p>Fundamentally I think C trusts developers while C++ trusts compilers.
This is a massive difference that sharing the same native types or syntax for while loop cannot hide.</p>
<p>C++ developers blame C for all their lost limbs, while C developers probably think C++ is batshit crazy.
I imagine that is a fair perspective if you look at C++ through a C lense. C++ is pretty wild <em>as a superset of C</em>.
A seasoned C person looking at C++ expecting familiarity in C++ will not find it. C++ is not C.
This is enough to feed flamewars for generations.</p>
<p>But as much as I dislike C, I don‚Äôt have any legitimacy to make fun of it. See, I have some experience with C++ but I
wrote very little C. It was probably bad C.
A language is also its good practices, patterns, idioms, and these take years to learn. If you try to write C code like it‚Äôs C++ or C++ like it is C, you will have a bad time.
Knowing <a href="https://www.youtube.com/watch?v=YnWhqhNdYyk">C doesn‚Äôt teach you C++</a>. Knowing C++ does not teach you C.</p>
<p>So can we all stop saying C/C++, regret the unfortunate naming, and sing kumbaya in harmony?
Not so fast.</p>
<p>See, despite being philosophically different from C, C++ is still somewhat a superset of C.
That is to say, you can include a C header in a C++ translation unit and that should compile.
And this is where it gets messy.</p>
<p>C++ is not an extension of C.
It is designed as a separate standard, by a different committee, different people.
Logically, people who like C++'s philosophy will get involved in the C++ community and the C++ standardization process
while other people might try to get involved with C.
Committees, whether its C‚Äôs or C++'s, only manifest intent and direction through their respective end-product: the standards; standards which are the fruits of numerous voting.</p>
<p>At the same time, it is difficult for a compiler to know that it is dealing with a C header or a C++ header.</p>
<p><code>extern "C"</code> is not used consistently and only affects mangling, but neither grammar nor semantics.
And headers only exists in the eyes of the preprocessor, for a C++ compiler, everything is a C++ translation unit, and therefore C++.
And yet, people include C headers in C++ and expect it to ‚Äújust work‚Äù ‚Ñ¢Ô∏è.
Which it mostly does.</p>
<p>We can wonder then,</p>
<h2 id="how-c-maintains-c-compatibility-while-being-developed-by-different-people-in-different-places">How C++ maintains C compatibility while being developed by different people in different places?</h2>
<p>Badly, I‚Äôm afraid.</p>
<p>A coworker recently reminded me of Conway‚Äôs law:</p>
<blockquote>
<p>Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization‚Äôs communication structure</p>
</blockquote>
<p>By that logic, it would stand to reason that if the two committees don‚Äôt interoperate,
neither would the languages they produce.</p>
<p>C++ maintains a list of <a href="http://eel.is/c++draft/diff.iso">incompatibilities with C</a> and <a href="http://eel.is/c++draft/diff.library">its standard library</a>.
This list does not seem to reflect the many features that were added to C11 and C18 but are not valid C++ constructs. <a href="https://en.wikipedia.org/wiki/Compatibility_of_C_and_C%2B%2B">Wikipedia</a> draws a clearer picture.</p>
<p>Listing incompatibilities isn‚Äôt sufficient to get a measure of incompatibilities between both languages.</p>
<p>Functions that exist in the C++ standard library but whose primary declaration is expected to come from C are difficult to make <code>constexpr</code>, and more difficult still to make <code>noexcept</code>.
C compatibility translates to performance costs and C functions are optimization barriers.</p>
<p>Many C constructs are valid C++ but should never pass a code review (<code>NULL</code>, <code>longjmp</code>, <code>malloc</code>, create/destroy functions, <code>free</code>, C  casts), etc.</p>
<p>These might not be bad C idioms, but they are bad C++. C++ has a stronger type system,
and unfortunately using C idioms punch a giant hole in that type system, and so C compatibility has a cost in terms of safety.</p>
<p>Don‚Äôt get me wrong, C++ still care about C compatibility. Somewhat.
And interestingly C cares about C++. Somewhat.
Truth be told, C might care about C++ more than C++ cares about C.
So each committee cares somewhat about what the other does.
We care reluctantly.</p>
<p>See, C++ is aware of the many foundational libraries written in C, not only the <code>libc</code> but also <code>zip</code>, <code>png</code>, <code>curl</code>, <code>openssl</code> (!), and countless others, which are used in many, many C++ projects.
We can‚Äôt break that.</p>
<p>But recently, especially over the past decade, C++ has become much bigger than C.
C++ has more users - and a much more active community: <a href="https://nullprogram.com/blog/2018/11/21/">There Are No C Conferences</a>.
Maybe that‚Äôs why the C++ committee is now over 10 times the size of the C committee.</p>
<p>C++ then is a force to be reckoned with and the C committee has to consider not breaking C++.
To the point that if a standard would track another, these days, C++ leads and C follow.</p>
<p>C++ is now on a steady three years cycle come rain or shine, or deadly pandemics.
Meanwhile, C has a major release every decade or so.
This makes sense. As a lower-level language, C doesn‚Äôt need to evolve as fast.</p>
<p>The C landscape is also rather different from the C++ landscape.
C caters to more platforms and a lot more compilers.
Everybody and their dog is writing C compilers because the language has a surface area small enough to make that possible, whereas the C++ committee will only really consider 4 implementations, all of which are represented at every meeting.
As a result, many features in C are implementation-defined or optionally supported so that the variety of compilers that exist can claim conformance without doing much work, which I‚Äôm told pleases regulatory bodies.</p>
<p>C++ these days is more interested in portability than implementation freedom. Yet another difference of philosophy.</p>
<h2 id="so-your-proposal-breaks-c-compatibility">So, your proposal breaks C compatibility</h2>
<p>Parts of my <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2178r1.pdf">P2178</a> paper theoretically affects C compatibility.
In such cases, none of the options seems satisfactory.</p>
<p>You could be told that you have to first get your feature into C. Which means more meetings.
Meetings you might not be able to attend because C has strict <a href="https://thephd.github.io/follow-the-river-wg14-ithaca-2019">attendance rules</a> - Excluding individuals not willing to put down thousands of dollars to become ISO members.
This is because the C committee is forced to adhere strictly to ISO rules.</p>
<p>It might also take a decade if the standard just shipped.
And most importantly, it might go nowhere if the C committee doesn‚Äôt understand or doesn‚Äôt care about the particular problem you are trying to solve.
And they probably don‚Äôt have the bandwidth to deal with it.
And you may not have the bandwidth to deal with C. After all, you joined C++ to improve C++.
In fact, if the room invites you to ‚Äútalk to the C committee‚Äù, it is likely your proposal is dead, even in the unlikely event that no one in the room was against it.</p>
<p>Another likely scenario is that the C committee accepts a version of a proposal that is slightly different from what exists in C++.
<code>true</code>? Let‚Äôs make that a macro. <code>char16_t</code> ? Let‚Äôs make that a typedef. <code>char32_t</code>? Not necessarily UTF-32. <code>static_assert</code> ? <code>_Static_assert</code>.</p>
<p>The list goes on. Should we blame C? Probably not. Their committee does what they think is best for their language.
The opposite is true too. In C++20 designated initializers were inspired by C‚Äôs but are slightly different because they would otherwise not fit with the C++ initialization rules.</p>
<p>I am part of the problem. C has VLAs. I would vote against a proposal to adopt that in standard C++, <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kills-The-VLA">too many security issues</a>. A proposal to add <code>_Generic</code> to C++ would be over-my-dead-body. I am not sure if <code>_Generic</code> attempts to palliate to the lack of template or the lack of overloads, but C++ has both these features - from my point of view <code>_Generic</code> doesn‚Äôt fit into the big picture of what I imagine C++ to be.</p>
<p>Both committees seem also inconsistent in how much they care about the other language.
Sometimes we go to great lenghts (<a href="https://en.cppreference.com/w/cpp/numeric/complex">std::complex</a>), sometimes we don‚Äôt care at all (<a href="https://en.cppreference.com/w/c/language/array">static array parameters</a>).</p>
<p>There is no way around this. Don‚Äôt forget that each committee is a bunch of people
voting at different times in different rooms and trying to control the outcome would defeat the purpose
of having a vote.
Putting people in the same room is not realistic either. ISO might object and the participation inbalance
would put C people at an enormous disadvantage.</p>
<h2 id="c-compatibility-doesnt-matter-kinda">C compatibility doesn‚Äôt matter, kinda</h2>
<p>If you are a C developer, I imagine you see C as a neat programming language.
But for the rest of us, C is something else.</p>
<p>C is the universal, cross-language glue that ties it all together.</p>
<p>For C++ users, C is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/c/">https://cor3ntin.github.io/posts/c/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24352258</guid>
            <pubDate>Wed, 02 Sep 2020 11:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CAC is not S&M]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24352053">thread link</a>) | @Lukas1994
<br/>
September 2, 2020 | https://www.causal.app/blog/cac-is-not-sales-marketing-expense | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/cac-is-not-sales-marketing-expense">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a></p><p>Generally accepted accounting principles were designed to create a single standard for comparing any and all businesses using the same terms and metrics. This is a very powerful tool, but it is a clear exchange for breadth over specificity. As a result, the economic reality of a business will likely differ from what the accounting metrics represent. By looking at a subset of business models, we can improve specificity - terms like <em>ARR </em>and <em>GMV</em> are both examples of this. While these terms have their own challenges with definitions, I think most agree what they represent: ARR is annualized recurring revenue for SaaS companies, and GMV is gross merchandise/marketplace value for marketplace companies.</p><p>One of my favorite examples of this is CAC - customer acquisition cost. It‚Äôs relevant for both SaaS businesses and marketplaces. Average CAC is the cost to acquire a single customer and Total CAC is the full spend for a cohort of customers. So what is the difference between <strong>CAC</strong> and <strong>Sales &amp; Marketing</strong> expense? The truth is that Total CAC and S&amp;M over a given period of time <em>might </em>be the same. That being said, the usually differ by a <em>time offset </em>that depends on <strong><em>sales cycle length</em></strong>.</p><p>The critical distinction is <strong>sales cycle length</strong>. <em>Sales cycle is how long it takes for a customer to go from first contact to closing a deal</em>. We measure sales cycle by segment and can use simple reports in Salesforce or another CRM tool to figure out how long it takes on average for customers to move through the sales funnel. Generally sales opportunities begin as leads, some of those convert to <em>qualified for sales</em> and then some of those convert to <em>closed-won</em>. The Sales Funnel shows the volume and conversion at each step in the process and is usually in the hands of the CRO or sales operations team. The two lengths of time that we care about in finance are: top of funnel to sales qualification (i.e. marketing cycle length) and then sales qualification to closed-won (i.e. sales cycle length).</p><p>There is a large variance in sales cycle lengths from business to business. For example, consumer software might have a &lt;1 month sales cycle that runs entirely on marketing. On the other end of the spectrum, a complex sale to a large institution may take over a year and involve a number of different people and teams.</p><p>For the in-month sales cycle, New ARR in Month X will be attributed to the Marketing expense in Month X. Pretty straightforward.</p><p>As soon as you have a separate marketing funnel and sales funnel and things take longer than a few weeks, it becomes more complicated to measure, track and predict.</p><p>I often see operating stats that look like this:</p><figure id="w-node-be6f6b2d374d-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f4e9f755f630ab3e0e98ebd_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F79d18d99-150c-4eae-b10a-cc00916f9da3_1168x196.png" alt=""></p></figure><p>‚Äç</p><p>The high level sales efficiency metric is New ARR / S&amp;M: the idea being that we are investing in S&amp;M in order to generate new ARR. The missing piece of information here is <strong>how long are the customers in the marketing funnel and how long are they in the sales funnel</strong>. Without that info, people often assume that it is in the same time period - whether that is a month, a quarter or a year. Switching over to a CAC calculation based on sales cycle length gives a more accurate picture of the sales efficiency.<br></p><p>For example: let‚Äôs say the marketing funnel takes <strong>1 month</strong> and the sales funnel takes <strong>3 months</strong>.<br></p><p>As a result, CAC would be the Marketing expense from 3 months prior and the average of the Sales expense over the last 3 months. So in the above example, new ARR acquired in April would be associated with the Marketing spend in January and the average of the Sales spend in Feb, March and April. Because this is a growing business, CAC will be lower than the S&amp;M in the same month, meaning that efficiency numbers are actually higher when based on CAC. Quick note to operating executives: don‚Äôt use a basic formula and sell yourself short.<br></p><p>Now looking at it through the lens of sales cycle-dependent CAC:<br></p><figure id="w-node-5b3f68252472-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f4e9f8ca3a860067d1d36b8_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Fce0d6249-9d70-4cff-87bb-36004dfe03c8_1168x278.png" alt=""></p></figure><p>‚Äç</p><p>Once you have the CAC line in the model, you can use it for SaaS Magic number, CAC payback, and a number of other metrics. (Of course, as the sales cycle changes, the CAC calculation must also change.) These metrics are important because they usually stay constant for a given product and business operation and allow you to project into the future.</p><p>The CAC calculation gets you one level deeper towards operating metrics from the high level financial metrics and is often a good bridge between the two. It represents the detailed funnels at a high level, and will ultimately drive projections with a higher degree of accuracy. For example, we now know that leads acquired through marketing spend in December will not yield sales until 3 months later in March. Based on historical metrics, we know roughly how many leads this spend will get us and therefore what kind of sales capacity we need to close on those leads and can plan sales hiring accordingly.<br></p><p>Coming from the financial perspective down into the operating perspective is a bit of a rabbit hole, so there‚Äôs an art in knowing where to stop, and it‚Äôs usually the point where precision starts to overtake accuracy in the model and digging deeper stops yielding better results. One step down from this, for example, would be to look into the sales expense - sales people are generally paid 50%+ of their total salary in commissions. If those commissions are paid in the month of sale, half of the sales expense should be weighted from that month and the other half weighted across the earlier months. If sales people are paid later on, then looking at it from a purely economic perspective as it pertains to commission rates will yield a much better result than looking at the accounting outputs for sales expense.<br></p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/cac-is-not-sales-marketing-expense</link>
            <guid isPermaLink="false">hacker-news-small-sites-24352053</guid>
            <pubDate>Wed, 02 Sep 2020 11:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of a Switch]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24351706">thread link</a>) | @pkolaczk
<br/>
September 2, 2020 | https://pkolaczk.github.io/in-defense-of-switch/ | <a href="https://web.archive.org/web/*/https://pkolaczk.github.io/in-defense-of-switch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-09-02T00:00:00+00:00">September 02, 2020</time>
</header>

  <p>Recently I came across a <a href="https://levelup.gitconnected.com/if-else-is-a-poor-mans-polymorphism-ab0b333b7265">blog post</a>
whose author claims, from the perspective of good coding practices, polymorphism is strictly superior to branching. 
In the post they make general statements about how branching statements lead to unreadable, unmaintainable, inflexible code and
how they are a sign of immaturity. However, in my opinion, the topic is much deeper and in this post 
I try to objectively discuss the reasons for and against branching.</p>

<!--more-->



<p>Before I dive into polymorphism vs branching dilemma, let‚Äôs first define what we mean when we say some code is
flexible and easy to extend. In my career I reviewed thousands of lines of code, and I had thousands of lines of my code
reviewed by others, and during these reviews it often occured that the terms <em>code extensibility</em> or <em>flexibility</em> 
mean different things to different people. Familiarity with the code-base or particular programming style plays a huge role.</p>

<p>For example, someone used to writing code in a Java/C# OOP style would generally consider dynamic polymorphism through 
interfaces a standard way of providing extensibility to the code, 
while a C programmer may find a switch or if/else much more 
approachable than OOP. There are also many other factors related 
to maintainability as quality of documentation, good naming, separation of concerns, etc. These factors are orthogonal 
to the ‚Äúpolymorphism vs branching‚Äù dimension and also far too broad for a single blog post, so I won‚Äôt discuss them.</p>

<p>For the sake of this post, let‚Äôs define <em>extensibility</em> as the inverse of number of distinct units in the codebase
that need to be changed in order to implement a new feature. The more places you have to touch to implement the feature, 
the harder the code is to change. Obviously, it is much better when you have to touch only
one unit of code (one function, one class, one module, one package) rather than change 10 distinct unrelated units.</p>


<p>Imagine you‚Äôre writing a calculator. Your program gets an expression as an input and outputs the computed value.
For example the user inputs <code>1 + 2 * 3</code> and the output is <code>7</code> 
(or <code>9</code> if you‚Äôve messed up the operator precedence like one of my former CS students).</p>

<p>Why such a silly example? Who is writing calculators these days? Probably no-one, but this looks like a classic example given
in many programming classes. And it is easy enough to illustrate the concept.</p>

<p>How can we model a structure to represent an expression?
You‚Äôd probably use classes or structures. Here is the code in Scala:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
<span>}</span>

<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>value</span>
<span>}</span>

<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>left</span><span>.</span><span>eval</span> <span>+</span> <span>right</span><span>.</span><span>eval</span>
<span>}</span>
</code></pre></div></div>

<p>Then it is quite easy to build an expression and evaluate it:</p>
<div><div><pre><code><span>Add</span><span>(</span><span>Const</span><span>(</span><span>2</span><span>),</span> <span>Const</span><span>(</span><span>3</span><span>)).</span><span>eval</span> <span>// evaluates to 5 </span>
</code></pre></div></div>


<p>This OOP-based solution is indeed very extensible when it comes to add a new operator.
The example above is missing subtraction operation. We can add one by defining a new class:</p>

<div><div><pre><code><span>case</span> <span>class</span> <span>Sub</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>left</span><span>.</span><span>eval</span> <span>-</span> <span>right</span><span>.</span><span>eval</span>
<span>}</span>
</code></pre></div></div>

<p>That‚Äôs really awesome ‚Äì we didn‚Äôt have to touch any old code at all! 
OOP definitely rocks here.</p>


<p>Imagine you continued to extend our calculation engine with more operation classes over the next few years.
You‚Äôve added multiplication, division, modulo, variables, logarithms, trigonometric functions, etc.</p>

<p>Then suddenly a new requirement comes ‚Äì users want to not only evaluate the value of an expression,
but also do symbolic manipulation ‚Äì e.g. simplify expressions. For example, given an expression
<code>a + a</code> they want to get an expression <code>2 * a</code> as a result.</p>

<p>This requirement can‚Äôt be captured by the <code>eval</code> method on the <code>Expression</code> interface. We need a new method:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
    <span>def</span> <span>simplify</span><span>:</span> <span>Expression</span>
<span>}</span>
</code></pre></div></div>

<p>And as the next step, they would likely want to be able to display the expression as a String:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
    <span>def</span> <span>simplify</span><span>:</span> <span>Expression</span>
    <span>def</span> <span>toString</span><span>:</span> <span>String</span>
<span>}</span>
</code></pre></div></div>

<p>How many units of code do you have to change now to implement these features?
<strong>All the implementations of <code>Expression</code></strong>. Before touching all the classes, the code wouldn‚Äôt even compile.
It looks like in the context of this kind of feature, our polymorphic solution is terribly non-extensible.</p>


<p>Let‚Äôs take a step back and let‚Äôs see how we could implement this differently.
Scala and many other modern languages have a feature called <em>pattern matching</em>
which can be considered a very flexible, powerful switch.</p>

<p>Instead of defining the operations like <code>eval</code> or <code>simplify</code> on the case classes,
let‚Äôs pull them up:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span>


<span>def</span> <span>eval</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Double</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>a</span> <span>+</span> <span>b</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Now adding a new operation like <code>Sub</code> would require two changes to the code ‚Äì adding a new class
<em>and</em> adding a new case in the match (switch) statement.</p>

<p>Some may say this much worse not only because of more places to update, but because of a possibility of
forgetting to update the switches which could lead to runtime errors due to unhandled cases.
Fortunately, Scala designers thought about this by providing the <code>sealed</code> keyword, which instructs the compiler
that all case classes can be defined in the same module only. This unlocks pattern exhaustiveness analysis and the
compiler would warn about missing cases:</p>

<div><div><pre><code><span>sealed</span> <span>trait</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span>

<span>def</span> <span>eval</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Double</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>a</span> <span>+</span> <span>b</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>What about adding new functions like <code>simplify</code> or <code>toString</code>? 
It requires to changle only <strong>one place</strong> ‚Äì by adding the required methods. 
No changes to the existing code are needed!</p>

<div><div><pre><code><span>def</span> <span>simplify</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Expression</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Add</span><span>(</span><span>Const</span><span>(</span><span>0</span><span>),</span> <span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>x</span><span>,</span> <span>Const</span><span>(</span><span>0</span><span>))</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>other</span> <span>=&gt;</span> <span>other</span>
  <span>}</span>
<span>}</span>

<span>def</span> <span>toString</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>String</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span><span>.</span><span>toString</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>"("</span> <span>+</span> <span>toString</span><span>(</span><span>a</span><span>)</span> <span>+</span> <span>" + "</span> <span>+</span> <span>toString</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>"</span><span>)</span> 
  <span>}</span>
<span>}</span>
</code></pre></div></div>


<p>The blog post I mentioned in the introduction stated that using polymorphism instead of
branching leads to more readable code. I find this statement far too general and actually very debatable.</p>

<p>First, even in their own example given by the author of that blog, the solution using branching was a lot
shorter and less complex than the solution using OOP. While brief code is not always more readable than a longer version of it,
in that case, I found branching to be very explicit and easy to follow. 
It is much easier to understand the control flow
in such a program because all targets are explicitly given in a single place. In the OOP solution, 
the actual implementations are hidden behind the interface and it is much harder to find them all without additional 
help of a good IDE with a ‚Äújump to implementations‚Äù feature 
(which fortunately often works well for statically typed languages, but I‚Äôve seen IDEs sometimes 
struggle with dynamic languages like Python).</p>

<p>Second, in general case, branching has an advantage that the function logic may depend on more than
one object type or even the actual data. For example, in the example from this post, 
the transformation <code>a * (b + c)</code> =&gt; <code>a * b + a * c</code> would depend on 
both addition and multiplication. In the classic OOP solution, would you place it in the <code>Add</code> or in the <code>Mul</code> class? 
Neither seems right. Also, putting it into one of them creates a dependency on the other one. 
An expression simplifier with code scattered accross multiple classes heavily depending on each other 
would be hard to understand.</p>


<p>This is a blog on high performance programming, so the post would be incomplete without a 
section on performance. In theory, a sufficiently good compiler should produce the same
code regardless of the choice between branching or dynamic polymorphism, but is this the case in reality?
Compilers have limitations and often don‚Äôt generate the best result code possible.</p>

<p>Let‚Äôs consider a more realistic example this time.
Some time ago I was working on serializing/deserializing code in a database system.
I stumbled upon a set of classes that described data types. They all implemented 
a common interface defining methods for serializing and deserializing values of given data type
and also computing serialized data lenghts. The following Rust snippet is a huge simplification 
of that code, but it illustrates the concept:</p>

<div><div><pre><code><span>pub</span> <span>trait</span> <span>DataType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span><span>;</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>BoolType</span><span>;</span>
<span>pub</span> <span>struct</span> <span>IntType</span><span>;</span>
<span>pub</span> <span>struct</span> <span>LongType</span><span>;</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>BoolType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>1</span> <span>}</span>
<span>}</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>IntType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>4</span> <span>}</span>
<span>}</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>LongType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>8</span> <span>}</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>data_len</span><span>(</span><span>data_type</span><span>:</span> <span>&amp;</span><span>dyn</span> <span>DataType</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
    <span>data_type</span><span>.len</span><span>()</span>
<span>}</span>
</code></pre></div></div>

<p>Given a reference to a <code>DataType</code> object, it is trivial to compute the data size associated with it, 
without knowing the exact static type:</p>

<div><div><pre><code><span>let</span> <span>t1</span> <span>=</span> <span>IntType</span><span>;</span>
<span>let</span> <span>t2</span> <span>=</span> <span>LongType</span><span>;</span>
<span>let</span> <span>v</span><span>:</span> <span>Vec</span><span>&lt;&amp;</span><span>dyn</span> <span>DataType</span><span>&gt;</span> <span>=</span> <span>vec!</span><span>[</span><span>&amp;</span><span>t1</span><span>,</span> <span>&amp;</span><span>t2</span><span>];</span>
<span>println!</span><span>(</span><span>"{}"</span><span>,</span> <span>data_len</span><span>(</span><span>v</span><span>[</span><span>0</span><span>]));</span>  <span>// prints 4</span>
<span>println!</span><span>(</span><span>"{}"</span><span>,</span> <span>data_len</span><span>(</span><span>v</span><span>[</span><span>1</span><span>]));</span>  <span>// prints 8</span>
</code></pre></div></div>

<h2 id="performance-of-dynamic-dispatch">Performance of Dynamic Dispatch</h2>

<p>The implementation of the <code>data_len</code> function is actually very simple:</p>


<p>Wow! A single assembly instruction! 
It jumps to the address stored in the the vtable of the object pointed by the <code>rsi</code> register.
The target of the jump depends on the actual type of the object. Here is the code generated for <code>IntType.len</code>:</p>



<p>The codes for the other types differ only in the constant value.</p>

<p>These are only 3 instructions to return the result. Shouldn‚Äôt it be fast? 
Let‚Äôs measure this. Let‚Äôs put more random <code>DataType</code> objects ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pkolaczk.github.io/in-defense-of-switch/">https://pkolaczk.github.io/in-defense-of-switch/</a></em></p>]]>
            </description>
            <link>https://pkolaczk.github.io/in-defense-of-switch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351706</guid>
            <pubDate>Wed, 02 Sep 2020 10:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes: Make your services faster by removing CPU limits]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24351566">thread link</a>) | @iansinnott
<br/>
September 2, 2020 | https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/ | <a href="https://web.archive.org/web/*/https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>At Buffer, we‚Äôve been using <a href="https://kubernetes.io/case-studies/buffer/">Kubernetes since 2016</a>.  We‚Äôve been managing our k8s (kubernetes) cluster with <a href="https://kops.sigs.k8s.io/">kops</a>, it has about 60 nodes (on AWS), and runs about 1500 containers. Our transition to a micro-service architecture has been full of trial and errors. Even after a few years running k8s, we are still learning its secrets. This post will talk about how something we thought was a good thing, but ended up to be not as great as we thought: <strong>CPU limits</strong>.</p>
<h2 id="cpu-limits-and-throttling">CPU limits and Throttling</h2>
<p>It is s general recommendation to set CPU limits. <a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-resource-requests-and-limits">Google, among others, highly recommends it</a>. The danger of not setting a CPU limit is that containers running in the node could exhaust all CPU available. This can trigger a cascade of unwanted events such as having key Kubernetes processes (such as <code>kubelet</code>) to become unresponsive. So it is in theory a great thing to set CPU limit in order to protect your nodes.</p>
<p>CPU limits is the maximum CPU time a container can uses at a given period (100ms by default). The CPU usage for a container will never go above that limit you specified. Kubernetes use a mechanism called <a href="https://en.wikipedia.org/wiki/Completely_Fair_Scheduler">CFS Quota</a> to <strong>throttle</strong> the container to prevent the CPU usage from going above the limit. That means CPU will be artificially restricted, making the performance of your containers lower (and slower when it comes to latency).</p>
<h2 id="what-can-happen-if-we-dont-set-cpu-limits">What can happen if we don‚Äôt set CPU limits?</h2>
<p>We unfortunately experienced the issue. The <code>kubelet</code> , a process running on every node, and in charge of managing the containers (pods)  in the nodes became unresponsive. The node will turn into a <code>NotReady</code> state, and containers (pods) that were present will be rescheduled somewhere else, and create the issue in the new nodes. Definitely not ideal isn‚Äôt it?</p>
<h2 id="discovering-the-throttling-and-latency-issue">Discovering the throttling and latency issue</h2>
<p>A key metric to check when you are running container is the <code>throttling</code> . This indicate the number of time your container has been throttled. Interestingly, we‚Äôve discovered a lot of containers having throttling no matter if the CPU usage was near the limits or not. Here the example of one of our main API:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/cpu-usage-limits.png" alt="Kubernetes pods CPU usage and limits"></p>
<p>You can see in the animation that the CPU limits is set at <code>800m</code> (0.8 core, 80% of a core), and the peak usage is at most <code>200m</code> (20% of a core). After seeing, we might think we have plenty of CPU to let the service running before it throttle right? . Now check this one out:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/cpu-throttling-low-usage.gif" alt="Kubernetes pods Low CPU usage, High limit, lot of throttling"></p>
<p>You can notice the CPU throttling occurs, even though the CPU usage is below the CPU Limits. The maximum CPU usage isn‚Äôt even near the CPU limits.</p>
<p>We‚Äôve then found a few resources(<a href="https://github.com/kubernetes/kubernetes/issues/67577">github issue</a>, <a href="https://www.youtube.com/watch?v=LpFApeaGv7A&amp;feature=youtu.be&amp;t=1204">zanado talk</a>,  <a href="https://medium.com/omio-engineering/cpu-limits-and-aggressive-throttling-in-kubernetes-c5b20bd8a718">omio post</a>) talking about how throttling lead to poorer performances and latency for your services.</p>
<p><strong>Why do we see CPU throttling while CPU usage is low?</strong>
The tldr is basically a bug in the Linux kernel throttling unecessarly containers with CPU limit. If you‚Äôre curious about the nature of it, I invite you to check Dave Chiluk‚Äôs <a href="https://www.youtube.com/watch?v=UE7QX98-kO0">great talk</a>, a <a href="https://engineering.indeedblog.com/blog/2019/12/unthrottled-fixing-cpu-limits-in-the-cloud/">written version</a> also exists with more details.</p>

<p>After many long discussions, we‚Äôve decided to remove the CPU limits for all services that were directly or indirectly on the critical path of our users.</p>
<p>This wasn‚Äôt an easy decision since we value the stability of our cluster. We‚Äôve experimented in the past some instability in our cluster with services using too much resources and disrupting all other services present in the same node.  That time was a bit different, we understood more about how our services needed to be and had a good strategy to roll this out.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/unleash-k8s.jpg" alt="Buffer-remove-cpu-limits-announcement"></p>
<h2 id="how-to-keep-your-nodes-safe-when-removing-limits-">How to keep your nodes safe when removing limits ?</h2>
<p><strong>Isolating ‚ÄúNo CPU Limits‚Äù services:</strong></p>
<p>In the past we‚Äôve seen some nodes going to a <code>notReady</code> state, mainly because some services were using too much resources in a node.</p>
<p>We‚Äôve decided to put those services on some specific nodes (tainted nodes), so those services will not disrupt all the ‚Äúbounded‚Äù ones.  We have better control and could identify easier if any issue occurs with a node. We did this by tainting some nodes and adding toleration to services that were ‚Äúunbounded‚Äù. Check <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/">the documentation</a> on how you can do that.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/buffer-k8s-infrastructure-nodes.jpg" alt="Buffer k8s nodes infrastructure"></p>
<p><strong>Assigning the correct CPU and memory request:</strong></p>
<p>The main worry we had was service using too much resources and leading to nodes becoming unresponsive. Because we now had great observability of all services running in our cluster (with Datadog), I‚Äôve analyzed a few months of usage of each service we wanted to ‚Äúunbound‚Äù. I‚Äôve assigned the maximum CPU usage as the CPU request with a &gt; 20% margin. This will make sure to have allocated space in a node. If k8s won‚Äôt try to schedule any other service in that node.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/choose-cpu-request-based-on-max.png" alt="Chose CPU request based on max"></p>
<p>You can see in the graph that the peak CPU usage was <code>242m</code> CPU core (0.242 CPU core). Simply take this number and make it a bit higher to become the CPU request. You can notice that since the service is user facing, the peak CPU usage matches peak traffic time.</p>
<p>Do the same with your memory usage and requests, and you will be all set!
To add more safety, you can use the horizontal pod autoscaler to create new pods if the resource usage is high, so kubernetes will schedule it in nodes that have room for it. Set an alert if your cluster do not have any room, or use the node austoscaler to add it automatically.</p>
<p>The downsides are that we lose in ‚Äú<a href="https://wiki.openvz.org/WP/Containers_density">container density</a>‚Äù, the number of containers that can run in a single node. We could also end up with a lot of ‚Äúslack‚Äù during a low traffic time.
You could also hit some high CPU usage, but nodes autoscaling should help you with it.</p>
<h2 id="results">Results</h2>
<p>I‚Äôm happy to publish really great results after few weeks of experimentation, we‚Äôve already seen really great latency improvements across all the services we‚Äôve modified:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/speedup-no-cpu-limits2.png" alt="faster-kubernetes-containers"></p>
<p>The best result happened on our main landing page (<a href="https://buffer.com/">buffer.com</a>) where we speed the service up to <strong>22x</strong> faster!</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/no-cpu-limit-speedup-buffer-com.jpg" alt="buffer.com speedup without cpu limits"></p>
<h2 id="is-the-linux-kernel-bug-fixed">Is the Linux kernel bug fixed?</h2>
<p>The bug <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=763a9ec06c4">has been fixed and merged into the kernel</a> for Linux distribution running 4.19 or higher (kudo again to <a href="https://twitter.com/dchiluk">Dave Chiluk</a> for finding and fixing that).</p>
<p>However, as for <em>September 2nd 2020</em>, when reading <a href="https://github.com/kubernetes/kubernetes/issues/67577">the kubernetes issue</a>, we can see various Linux projects that keep referencing the issue, so I guess some Linux distribution still have the bug and working into integrating the fix.</p>
<p>If you are below a Linux distribution that has a kernel version below 4.19, I‚Äôd recommend you to upgrade to the latest Linux distribution for your nodes, but in any case, you should try removing the CPU limits and see if you have any throttling.  Here a non exhausting list of various managed Kubernetes services or Linux distribution:</p>
<ul>
<li>Debian: The latest version <a href="https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/%5Bhttps://www.debian.org/releases/buster/">buster</a> has the fix,  it looks <a href="https://tracker.debian.org/news/1167353/accepted-linux-latest-419-105deb10u5deb9u1-source-amd64-into-oldstable-oldstable/">quite recent (august 2020)</a>. Some previous version might have get patched</li>
<li>Ubuntu: The latest version <a href="https://releases.ubuntu.com/20.04/">Ubuntu Focal Fosa 20.04</a> has the fix.</li>
<li>EKS has the fix since <a href="https://github.com/aws/containers-roadmap/issues/175">December 2019</a>. Upgrade your AMI if you have a version below than that</li>
<li>kops: Since <a href="https://github.com/kubernetes/kops/pull/9283">June 2020</a>,  <code>kops 1.18+</code> will start using <code>Ubuntu 20.04</code> as the default host image. If you‚Äôre using a lower version of kops, you‚Äôll have to probably to wait the fix. We are currently in this situation.</li>
<li>GKE (Goggle Cloud) : The kernel fix was merged in <a href="https://cloud.google.com/container-optimized-os/docs/release-notes#cos-stable-77-12371-141-0">January 2020</a>. But it does looks like throttling are <a href="https://news.ycombinator.com/item?id=24356903">still hapenning</a></li>
</ul>
<p>ps: Feel free to <a href="https://news.ycombinator.com/item?id=24351566">comment</a> if you have more precise information, I‚Äôll update the post accordingly</p>
<p><strong>If the fix solved the throttling issue?</strong></p>
<p>I‚Äôm unsure if totally solved the issue. I will give it a try once we hit a kernel version where the fix has been implemented and will update this post accordingly. If anyone have upgrade I‚Äôm keen to hear their results.</p>
<h2 id="takeaways">Takeaways</h2>
<ul>
<li>If you run Docker containers under Linux (no matter Kubernetes/Mesos/Swarm) you might have your containers underperforming because of throttling</li>
<li>Upgrade to the latest version of your distribution hoping the bug is fixed</li>
<li>Removing CPU limit is a solution to solve this issue, but this is dangerous and should be made with extra-care (prefer upgrading your kernel first and monitor throttling first)</li>
<li>If you remove CPU limits, carefully monitor CPU and  memory usage in your nodes, and make sure your CPU requests are</li>
<li>A safe way to is to use the Horizontal pod autoscaler to create new pods if the resource usage is high, so kubernetes will schedule it in nodes that have space.</li>
</ul>
<p>üëâ<strong>Hacker news update: lot of insighful <a href="https://news.ycombinator.com/item?id=24351566">comments</a>. I‚Äôve updated the post to have better recommendations. You should prefer upgrading your kernel version over removing the CPU limits. Be really mindful, set the proper CPU requests, add the necessary monitoring when you do this</strong></p>
<p>I hope this post helps you get performance gains on the containers you are running. If so, don‚Äôt hesitate to share or <a href="https://news.ycombinator.com/item?id=24351566">comment</a> with always some insighful comments</p>
<p>Special thanks to <a href="https://www.linkedin.com/in/dilyevsky/">Dmitry</a>, <a href="https://coderanger.net/">Noah</a> and <a href="https://mydev.org/">Andre</a> that adviced me on this.</p>
<h4 id="next-reads">Next reads:</h4>
<p>üëâ <a href="https://erickhun.com/posts/why-you-should-have-a-side-project/">Why you should have a side project</a></p>
<p>üëâ <a href="https://erickhun.com/posts/sharing-knowledge-in-a-remote-team/">How we share technical knowledge in a remote team, across timezones</a></p>




        <center>

            
            <a href="https://twitter.com/eric_khun" data-size="large" data-show-count="true">Follow @eric_khun</a>
            <br>
            <a href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=fb" target="_blank" rel="noopener" aria-label="Facebook">
              
            </a>
  
            
            <a href="https://twitter.com/intent/tweet/?text=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits%20by%20@eric_khun%20&amp;url=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=tw" target="_blank" rel="noopener" aria-label="Twitter">
              
            </a>
  
            
            <a href="https://erickhun.com/cdn-cgi/l/email-protection#82bdf1f7e0e8e7e1f6bfc9f7e0e7f0ece7f6e7f1a7b1e3a7b0b2cfe3e9e7a7b0b2fbedf7f0a7b0b2f1e7f0f4ebe1e7f1a7b0b2e4e3f1f6e7f0a7b0b2e0fba7b0b2f0e7efedf4ebece5a7b0b2c1d2d7a7b0b2eeebefebf6f1a2a4e3eff2b9e0ede6fbbfc9f7e0e7f0ece7f6e7f1a7b1e3a7b0b2cfe3e9e7a7b0b2fbedf7f0a7b0b2f1e7f0f4ebe1e7f1a7b0b2e4e3f1f6e7f0a7b0b2e0fba7b0b2f0e7efedf4ebece5a7b0b2c1d2d7a7b0b2eeebefebf6f1a2afa2eaf6f6f2f1a7b1e3a7b0e4a7b0e4e7f0ebe1e9eaf7ecace1edefa7b0e4f2edf1f6f1a7b0e4e9f7e0e7f0ece7f6e7f1afe4e3f1f6e7f0aff1e7f0f4ebe1e7f1afecedafe1f2f7afeeebefebf6f1a7b0e4a4f1bfe7efe3ebee" target="_self" rel="noopener" aria-label="E-Mail">
              
            </a>
  
            
            <a href="https://reddit.com/submit/?url=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;resubmit=true&amp;title=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits&amp;s=red" target="_blank" rel="noopener" aria-label="Reddit">
              
            </a>
  
            
            <a href="whatsapp://send?text=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits%20-%20https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=whatsapp" target="_blank" rel="noopener" aria-label="WhatsApp">
              
            </a>
    
          </center>
      </div></div>]]>
            </description>
            <link>https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351566</guid>
            <pubDate>Wed, 02 Sep 2020 09:47:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Moneyed ‚Äì be your own financial adviser ‚Äì built with Quart and React]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24351472">thread link</a>) | @pgjones
<br/>
September 2, 2020 | https://moneyed.co.uk/app/ | <a href="https://web.archive.org/web/*/https://moneyed.co.uk/app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="sapper">   <section><div><h3>Transparency, privacy and security </h3> <p>All data is encrypted and securely stored in the UK. We don't share or sell data. We are regulated by the FCA and are completely independent. We make money from subscriptions alone. </p> <p><a href="https://moneyed.co.uk/signup/">Try for 1 month for free </a></p></div></section> <section><div><div><div><h4>Get a clear financial overview</h4> <div><p>Securely link all current accounts, credit cards, savings, pensions, investments, and debt for a clear picture of your finances. Moneyed breaks down and categorises spending to make budgeting easy. </p> <p>Moneyed has the same level of security as banks, in addition to two factor authentication and remote session termination, all data is encrypted and securely stored. Moneyed is regulated by the UK Financial Conduct Authority and account linking is ‚Äúread-only‚Äù. </p></div> <div><p><img alt="" src="https://moneyed.co.uk/static/images/user-3.jpg"></p> <div><blockquote><p>"I had no idea how much money I was actually spending each month until I used Moneyed. Now I have a clear picture of where my money is going." </p></blockquote></div></div></div> </div></div></section> <section><div><div><div><h4>Make a plan to meet important life goals</h4> <div><p>Set financial goals that matter to you. Whether it's buying a house, raising a family, or retiring. Moneyed combines advanced optimisation techniques, machine learning algorithms, and financial analytics to generate a personalised financial plan. </p> <p>Financial projections help to identify future shortfalls and strategies suggest changes to your savings to ensure you meet your goals. </p></div> <div><p><img alt="" src="https://moneyed.co.uk/static/images/user-1.jpg"></p> <div><blockquote><p>"I always just made the default pension contribution and put whatever I had left at the end of the month into savings for a house deposit. The app definitely gave me a wakeup call. Now, I save a set amount each month and I'm on track to buying a house in two years. I've also increased my pension contributions." </p></blockquote></div></div></div> </div></div></section> <section><div><p><img alt="Sifted's logo" src="https://moneyed.co.uk/static/images/sifted_logo.png" height="40"></p> <p><b>Pioneer of the New World</b> <br> One of 80 European founders and companies at the forefront of seismic change, shaping the post-pandemic world </p></div></section> <section><div><div><div><h4>Track progress to success</h4> <p>Moneyed enables you to track progress to achieving important life goals and quickly respond to any changes life throws at you, whether it‚Äôs due to a change in personal circumstances, like a pay cut, or changes implemented by the government, like yearly tax rules. </p> <div><p><img alt="" src="https://moneyed.co.uk/static/images/user-6.jpg"></p> <div><blockquote><p>"Seeing the progress bar filling up for all my goals really helps to motivate me to keep saving!" </p></blockquote></div></div></div> </div></div></section> <section><div><div><div><h4>Get personalised insights and guidance</h4> <div><p>Moneyed helps you understand the costs and tax implications of your plan. </p> <p>The app provides a clear overview of all costs likely to be involved in buying a house, like stamp duty and fees, not just the deposit. In addition to information about potential tax credits for childcare, or tax implications associated with pension contributions, and much much more. </p></div> <div><p><img alt="" src="https://moneyed.co.uk/static/images/user-7.jpg"></p> <div><blockquote><p>"The in-app insights helped me see the advantages of opening a Lifetime ISA - free money from the government to help buy my flat." </p></blockquote></div></div></div> </div></div></section> <div><div><div><h4>Unlimited access for ¬£5 per month</h4> <p>Moneyed provides access to the types of financial planning tools used by professional financial advisors that would normally cost in excess of ¬£150 per month </p> </div></div></div>  <section><div><h3>Transparency, privacy and security </h3> <p>All data is encrypted and securely stored in the UK. We don't share or sell data. We are regulated by the UK Financial Conduct Authority and are completely independent. We make no money from product and service recommendations. We make money from subscriptions alone. </p> <p><a href="https://moneyed.co.uk/signup/">Try 1 month for free </a></p></div></section> </div></div>]]>
            </description>
            <link>https://moneyed.co.uk/app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351472</guid>
            <pubDate>Wed, 02 Sep 2020 09:33:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IHP: Live Reloading Haskell Code, How It Works]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24351369">thread link</a>) | @_query
<br/>
September 2, 2020 | https://ihp.digitallyinduced.com/blog/2020-08-10-ihp-live-reloading.html | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/blog/2020-08-10-ihp-live-reloading.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <ul>
                <li>
                    <strong>Starting an IHP app</strong>

                    <p>
                        Let's first take a look at what happens when you start your IHP app by running <code>./start</code>.
                    </p>

                    <p>
                        The <a href="https://github.com/digitallyinduced/ihp-boilerplate/blob/master/start" target="_blank"><code>./start</code></a> script in your project is basically just a small wrapper that makes sure that all dependencies that are managed by nix are available and then calls the <code>RunDevServer</code> binary. <a href="https://github.com/digitallyinduced/ihp/blob/master/IHP/IDE/DevServer.hs" target="_blank">This binary is part of IHP</a> and does the actual application startup as well as managing the postgres server.
                    </p>

                    <p>
                        You can think of <code>RunDevServer</code> as a small process manager. When <code>RunDevServer</code> is started, it will directly start all processes required for your application to run:
                        </p><ul>
                            <li>the web-based IDE</li>
                            <li>a status server on port 8000 showing the compiler status and possible type errors</li>
                            <li>a websocket server used for communicating file changes for live reloading</li>
                            <li>a ghci (the standard haskell REPL) where it directly loads your app</li>
                            <li>a postgres server bound to unix socket</li>
                            <li>a file watcher to track haskell and css file changes</li>
                        </ul>
                    

                    <p>
                        All these processes are started in parallel for fast performance and synchronised in the main event loop of the dev server. Made possible thanks to haskells great concurrency capabilities.
                    </p>

                    <p>
                        The most important process is the ghci process with your app. Instead of fully recompiling your app on every file change, IHP loads your app in the repl and then refreshes only the changed files. 
                    </p>

                    <p>
                        At first ghci needs a couple of seconds to load all haskell files of your application. While loading your application the status server is serving all http requests on localhost:8000. The status server will also show all type errors in case ghci failed to load your app. When the ghci finished loading, the status server is stopped and your application is started on localhost:8000.
                    </p>

                </li>

                <li>
                    <strong>Haskell File Changes</strong>

                    <p>
                        <iframe width="100%" height="500" src="https://www.youtube.com/embed/nTjjDo57B8g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                    </p>

                    <p>
                        Once your application is started, the dev server mainly deals with file changes. Using a file watcher the dev server is notified about any changes to your haskell files in your project. When a haskell file is changed the app process running in the ghci process is stopped and a refresh (<code>:r</code>) is triggered. The refresh is usually very fast. Once completed the app server will be started again.
                    </p>

                    <p>
                        Once the haskell app has started, open browser pages will be notified using a websocket connection. The open pages will fetch the current page via ajax and will then update the dom using <a href="https://github.com/patrick-steele-idem/morphdom" target="_blank">a diff and patch approach</a>. So only dom nodes that have actually changed will be touched during the live reloading. This approach will keep existing page state like scroll position or text typed into a form field. It allows for a very fast and productive feedback cycle.
                    </p>
                </li>

                <li>
                    <strong>CSS File Changes</strong>

                    <blockquote><p lang="en" dir="ltr">Did you know: <a href="https://twitter.com/hashtag/ihp?src=hash&amp;ref_src=twsrc%5Etfw">#ihp</a> also supports live reloading of CSS. <a href="https://t.co/uRCCr3gkHz">pic.twitter.com/uRCCr3gkHz</a></p>‚Äî digitally induced (@digitallyinduce) <a href="https://twitter.com/digitallyinduce/status/1277583045919375363?ref_src=twsrc%5Etfw">June 29, 2020</a></blockquote> 
                    

                    <p>
                        IHP also supports live reloading of CSS files. Once IHP sees a file change to your CSS files in the <code>static</code> directory it will notify all open browser tabs using its websocket connection. Once notified in the browser IHP will look for any <code>&lt;link rel="stylesheet"&gt;</code> and <a href="https://github.com/digitallyinduced/ihp/blob/master/lib/IHP/static/livereload.js#L68" target="_blank">will reload the css file using a cache buster</a>.
                    </p>

                    <p>
                        This is only possible because nix allows us to pin down the set of package definitions to a specific git commit of the nix package registry.
                    </p>
                </li>

                <li>
                    <strong>Type Errors</strong>

                    <p>
                        Sometimes you make a change which will stop your application from compiling. In these error cases the status server jumps in and starts listening on localhost:8000. The status server will then display the error message so you can quickly fix it:
                    </p>

                    <img src="https://ihp.digitallyinduced.com/releases/v07082020.png" alt="Example of a status server error message">

                    <p>
                        Additionally open browser tabs will be notified about this and will refresh. This way the error is instantly visible to you.
                    </p>
                </li>

                <li>
                    <strong>Batteries-included</strong>

                    <p>
                        While the above steps are technically complicated, when doing actual development you will not see much of this complexity.  Lots of time have been spent to find the best approach and smoothing out all the edge cases. The whole process is very much inspired by PHP where you just make file changes and it works. The live reloading really <q>just works</q>.
                    </p>

                    <p>
                        The dev server is the heart of IHP and makes the dev process extremely productive. You get all the benefits of type-safety with the development speed you previously only got with scripting languages. If you haven't already it's time to try it out! üöÄ
                    </p>
                </li>
            </ul>


        </div><p>Feel free to share this post on Twitter, Reddit, Hacker News or anywhere else on the internet :)</p></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/blog/2020-08-10-ihp-live-reloading.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351369</guid>
            <pubDate>Wed, 02 Sep 2020 09:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two musings on the design of compiler warnings]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24351306">thread link</a>) | @ingve
<br/>
September 2, 2020 | https://quuxplusone.github.io/blog/2020/09/02/wparentheses/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2020/09/02/wparentheses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Today I finally write down some musings on two peripheral aspects of
compiler diagnostic design that I think are very important for certain kinds of warnings.
My first musing relates to <em>fixits</em>, and my second to <em>suppression mechanisms</em>.</p>

<h2 id="what-is-a-fixit">What is a fixit?</h2>

<p>Most C++ compilers these days don‚Äôt just tell you <em>that</em> a problem occurred
(like <a href="https://www.gnu.org/fun/jokes/ed-msg.txt"><code>ed</code>‚Äôs famous <code>?</code> prompt</a>),
and <em>what</em> the problem is (‚Äúexpected identifier,‚Äù for example).
They‚Äôll try to tell you <em>how to fix</em> the problem.</p>

<p>Compare GCC 4.1‚Äôs error messages with GCC 4.6‚Äôs. (<a href="https://godbolt.org/z/KM8P9E">Godbolt.</a>)
For this input:</p>



<p>GCC 4.1 complains merely that you have put <code>multiple types in one declaration</code>.
GCC 4.6 more helpfully complains that it <code>expected ';' after struct definition</code>,
and points to the exact position where it believes a semicolon should be inserted.</p>

<p>GCC 7 goes even further, and suggests a <em>fixit</em> ‚Äî a machine-readable ‚Äúspellcheck suggestion‚Äù
that some IDEs are able to apply with a single click.</p>

<div><div><pre><code>test.cc:1:12: error: expected ';' after struct definition
 struct S {}
            ^
            ;
</code></pre></div></div>

<p>In medical terms, the compiler has gone from simply detecting the <em>symptom</em>
(‚Äúthis declaration seems to contain two types, which isn‚Äôt valid C++‚Äù)
to producing a <em>diagnosis</em> of the disease (‚ÄúI bet you forgot a semicolon somewhere‚Äù);
and a compiler that supports fixits is actually <em>prescribing a treatment plan</em>.
Each of these steps is a quantum leap beyond the previous one in terms of both user-friendliness
and implementation complexity.</p>

<h2 id="what-is-a-suppression-mechanism">What is a suppression mechanism?</h2>

<p>Suppression mechanisms relate to compiler <em>warnings</em>, not compiler errors.
Consider the following snippet (<a href="https://godbolt.org/z/fTnao9">Godbolt</a>):</p>

<div><div><pre><code>if (argc = 1)
    puts("hello");
</code></pre></div></div>

<p>Every mainstream compiler warns on this suspicious-looking code (GCC and Clang with <code>-Wall</code>; MSVC with <code>-W4</code>).
Here‚Äôs GCC‚Äôs diagnostic:</p>

<div><div><pre><code>warning: suggest parentheses around assignment used as truth value [-Wparentheses]
    4 |     if (argc = 1)
      |         ~~~~~^~~
</code></pre></div></div>

<p>Notice that GCC doesn‚Äôt even bother to explain really what its diagnosis is;
it emits a passive-aggressive warning message that does nothing more than suggest how to
shut itself up!</p>

<p>The diagnosis, of course, is that frequently people mean to write <code>if (argc == 1)</code>
but their finger slips and they write <code>if (argc = 1)</code> instead, which unfortunately
is also valid C++ code. Every mainstream compiler has evolved the same way to deal with this:
if you really mean <code>=</code>, then you write an extra pair of parentheses around the expression, like so:</p>



<p>The extra pair of parentheses is what I‚Äôm calling a ‚Äúsuppression mechanism.‚Äù
It‚Äôs just an arbitrary way of silencing a warning diagnostic ‚Äî telling the compiler
‚Äúno, I really <em>meant</em> to write this legal but unusual construct.‚Äù</p>

<p>Another well-known suppression mechanism is writing <code>(void)</code> in front of unused results
to silence <code>-Wunused-value</code> and <code>-Wunused-result</code> warnings (<a href="https://godbolt.org/z/WdrhrE">Godbolt</a>):</p>

<div><div><pre><code>[[nodiscard]] int foo();
void test(int x) {
    (void)x;
    (void)foo();
}
</code></pre></div></div>

<p>And a trivial suppression mechanism is implied by the name of the <code>-Wparentheses</code> warning:</p>

<div><div><pre><code>warning: '&amp;&amp;' within '||' [-Wlogical-op-parentheses]
    return (a &amp;&amp; b || c);
            ~~^~~~ ~~
</code></pre></div></div>

<p>Here the compiler just wants you to add a pair of parentheses to clarify the precedence for the reader.</p>

<h2 id="musing-a-single-fixit-must-preserve-actual-behavior-or-likely-intent-but-cant-do-both">Musing: A single fixit must preserve (actual) behavior or (likely) intent, but can‚Äôt do both</h2>

<p>It‚Äôs easy for the programmer to ‚Äúfix‚Äù diagnostics like <code>-Wunused-result</code> and <code>-Wlogical-op-parentheses</code>,
because they‚Äôre just asking the programmer to clarify intent that is already pretty clear:
<em>Yes</em>, I mean to discard this result. <em>Yes</em>, I mean to evaluate <code>(a &amp;&amp; b) || c</code>.</p>

<p>The more interesting diagnostics are the ones where the compiler believes it has identified a mismatch
between the code‚Äôs actual <em>behavior</em> and the programmer‚Äôs <em>intent</em>. Our <code>if (argc = 1)</code> example
above was like that. A more realistic example might be something like</p>



<p>Here it is almost certain that the programmer intended to write</p>



<p>However, the literal behavior of the code as written is equivalent to</p>



<p>When the compiler suggests a fixit for this warning, it has to choose: Should we suggest the fix
that changes the behavior of the code to what you probably meant to type ‚Äî the ‚Äúspellcheck‚Äù option?
Or should we show how to silence the warning while preserving the existing code‚Äôs behavior ‚Äî the
‚ÄúAdd To Dictionary‚Äù option, if you will? (Or, continuing our medical analogy, there‚Äôs the ‚Äútreatment‚Äù
option and the ‚Äú<a href="https://en.wikipedia.org/wiki/Do_not_resuscitate">DNR</a>‚Äù option.)</p>

<p>Showing just the ‚Äútreatment‚Äù option puts the compiler in the awkward position of ‚Äúrecommending‚Äù that you change
the behavior of code that is, after all, perfectly legal C++ already; blindly applying the fixit to
working code might break that code. But showing just the ‚Äúsuppression‚Äù option might encourage a programmer to
blindly apply the fixit to <em>broken</em> code, thus leaving the bug in place but making it harder to detect
in the future.</p>

<p>For certain kinds of warnings, Clang shows <em>both</em> fixits. Two examples of this in Clang 10
are (<a href="https://godbolt.org/z/aWf9s6">Godbolt</a>):</p>

<div><div><pre><code>warning: using the result of an assignment as a condition without parentheses [-Wparentheses]
    if (x = foo())
        ~~^~~~~~~
note: place parentheses around the assignment to silence this warning
    if (x = foo())
          ^
        (        )
note: use '==' to turn this assignment into an equality comparison
     if (x = foo())
          ^
          ==
</code></pre></div></div>

<p>and</p>

<div><div><pre><code>warning: &amp; has lower precedence than !=; != will be evaluated first [-Wparentheses]
    return (foo() &amp; mask != 0);
                  ^~~~~~~~~~~
note: place parentheses around the '!=' expression to silence this warning
    return (foo() &amp; mask != 0);
                  ^
                    (        )
note: place parentheses around the &amp; expression to evaluate it first
    return (foo() &amp; mask != 0);
                  ^
            (           )
</code></pre></div></div>

<p>Notice that in both cases, Clang decides to print the ‚Äúsuppression‚Äù option first
and the ‚Äútreatment‚Äù option second.
But sometimes Clang prints the ‚Äútreatment‚Äù option first and the ‚Äúsuppression‚Äù option second:</p>

<div><div><pre><code>warning: size argument in 'strncmp' call is a comparison [-Wmemsize-comparison]
    return strncmp(a, b, len &lt; 0);
                         ~~~~^~~
note: did you mean to compare the result of 'strncmp' instead?
    return strncmp(a, b, len &lt; 0);
           ^                    ~
                            )
note: explicitly cast the argument to size_t to silence this warning
    return strncmp(a, b, len &lt; 0);
                         ^
                         (size_t)( )
</code></pre></div></div>

<p>and</p>

<div><div><pre><code>warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]
    return x == y &amp;&amp; !x == z;
                     ^  ~~
note: add parentheses after the '!' to evaluate the comparison first
    return x == y &amp;&amp; !x == z;
                     ^
                      (     )
note: add parentheses around left hand side expression to silence this warning
    return x == y &amp;&amp; !x == z;
                     ^
                     ( )
</code></pre></div></div>

<p>Of course, there are many more cases where Clang emits <em>only</em> the ‚Äúsuppression‚Äù option
as a fixit, leaving the programmer to figure out the ‚Äútreatment‚Äù on their own. (GCC 10.2
emits a fixit for only the last of these four examples; and it‚Äôs the ‚Äúsuppression‚Äù option.)</p>

<p>Even in the absence of any machine-readable fixits, the phrasing of the warning message
itself can induce the human reader to think in terms of suppression or in
terms of treatment. A warning message can be phrased as ‚ÄúPlease confirm that you meant X‚Äù;
or ‚ÄúYou did X; did you mean Y?‚Äù; or even as ‚ÄúYour attempt to do Y failed.‚Äù</p>

<h2 id="musing-suppression-mechanisms-are-about-edit-distance-and-about-signaling">Musing: Suppression mechanisms are about edit distance, and about signaling</h2>

<p>Compiler warnings of the kind we‚Äôre discussing here are basically of the form
‚ÄúYou wrote X, but I think you meant Y.‚Äù This happens only when X and Y are
in some sense <em>close together</em>. Sometimes the ‚Äúcloseness‚Äù is semantic, not syntactic
(as when the programmer means to invoke copy elision but writes <code>return std::move(x)</code> instead).
But for our purposes today, let‚Äôs just think about <em>syntactic</em> closeness. You meant
to write Y, but a minor typographical slip caused you to write X. In the examples above,
the slips are things like ‚Äúomit one <code>=</code>,‚Äù or ‚Äúomit a pair of parens‚Äù or
‚Äúput <code>&lt; 0</code> inside the parens instead of outside.‚Äù</p>

<p>Take X=‚Äùequality-compare <code>!a</code> to <code>b</code>‚Äù and Y=‚Äùnegate the sense of <code>a == b</code>.‚Äù
There are some pieces of code that clearly intend to express X, such as <code>(!a)==(b)</code>.
There are some that clearly intend to express Y, such as <code>a != b</code>.
But you wrote <code>(!a==b)</code>, which falls into a gray area: it‚Äôs not clear which of
X and Y you really intended to express.</p>

<p>The job of the compiler-diagnostic-developer is to create some separation between
the space of inputs that the compiler considers ‚Äúclearly X‚Äù
and the space of inputs that the compiler considers ‚Äúclearly Y.‚Äù
Essentially, we create an error-correcting code by deliberately increasing the
<a href="https://en.wikipedia.org/wiki/Hamming_distance">edit distance</a>
between pairs of inequivalent C++ programs ‚Äî deliberately increasing the number of keystrokes
the programmer would have to screw up in order to transform a working (and warning-free)
C++ program into an inequivalent broken (yet warning-free) C++ program.</p>

<p>Furthermore, in cases where Y is more commonly intended than X, it should be relatively <em>easier</em>
to write Y than X. In our example that‚Äôs true even at the core-language level: <code>a != b</code> is
already easier to write than <code>!a == b</code>. But when we increase the distance between X-space and Y-space,
we shrink X-space by more than we shrink Y-space. If you really intend to express <code>!a == b</code>, we‚Äôll force you
to retreat all the way to <code>(!a) == b</code>. This is kind of analogous to the
<a href="https://en.wikipedia.org/wiki/Signalling_(economics)">signaling principle</a>
in economics or evolutionary biology: Basically, if you want the compiler to accept your intent,
your code must adopt some cumbersome and frankly maladaptive ornamentation in order to <em>prove</em>
its worthiness to the compiler.</p>

<p>According to the prevailing theory of
<a href="https://en.wikipedia.org/wiki/Handicap_principle">sexual selection in the animal kingdom</a>,
when a peahen is deciding whether to accept
a particular peacock, she uses ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quuxplusone.github.io/blog/2020/09/02/wparentheses/">https://quuxplusone.github.io/blog/2020/09/02/wparentheses/</a></em></p>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2020/09/02/wparentheses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351306</guid>
            <pubDate>Wed, 02 Sep 2020 08:57:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hash Monster: ESP-32 Tamagotchi for WiFi Cracking]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24351269">thread link</a>) | @wolframio
<br/>
September 2, 2020 | https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking | <a href="https://web.archive.org/web/*/https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Would you like to have a portable WiFi capture tool that fits in your pocket? A device that saves PCAP captures into micro sd card to later review them on Wireshark or crack those WPA / WPA2 passphrases. Sounds like something out of the <a href="https://nsa.gov1.info/dni/nsa-ant-catalog/wireless-lan/index.html" target="_blank" rel="nofollow noopener">NSA spy WiFi toolset</a> but It's very easy to setup with the ESP32 WiFi Hash Monster and the <a href="https://bit.ly/3jFAnl8" target="_blank" rel="nofollow noopener">M5 Stack Development Kit</a>.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/5658dfbd47952c4395bccb7da3699c7ff86527064f6b43771f3da3456ec43fa9.png"></p><p><strong>The Hash Monster</strong></p><p>If you are now thinking it seems similar to the <a href="https://www.vice.com/en_us/article/xwekw4/pwnagotchi-is-the-open-source-handheld-that-eats-wi-fi-handshakes" target="_blank" rel="nofollow noopener">Pwnagotchi project</a> and is not causal, G4lile0 the author of Hash Monster was inspired by it to make an alternative that runs on the M5 Stack Development Kit, an ESP32 powered portable platform. ESP32 is a series of dual-core up to 240Mhz, low-cost, low-power system on a chip microcontroller with integrated Wi-Fi and dual-mode Bluetooth/BLE.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/ac7ba2d12ae49bb808d323edae91463b7f97656872f7d24c91dab86d4ba1653d.jpeg"></p><p>Pwnagotchi is a tamagochi like device powered by bettercap and running on a Raspberry Pi Zero W that learns from its surrounding WiFi environment in order to maximize the crackable WPA key material it captures (either through passive sniffing or by performing deauthentication and association attacks). This material is collected on disk as PCAP files containing any form of handshake supported by hashcat, including full and half WPA handshakes as well as PMKIDs. Or put quickly, it's a tamagochi who eats WiFi handshakes to be happy.</p><p>Hash Monster runs in a smaller size and cheaper platform superior to the Pwnagotchi in several aspects. While Pwnagotchi is based on the Raspberry Pi Zero and requires assembling a DIY kit with various components such as an eInk screen and an external powerbank, the Hash Monster works on directly on the tiny M5Stack device. M5 Stack couples an ESP32 with a small LCD display, buttons and internal battery. It‚Äôs a modular, stackable, scalable, and portable device which is powered with an ESP-32 core, which makes it open source, low cost, full-function, and easy for developers to handle ESP32 IoT product development. You can program M5Stack through Arduino, C++, Blockly or MicroPython to name a few. The complete development kit for M5 Stack just under $45 provides a friendly price and full-featured resources which makes it a good starter kit for you to explore ESP32. While the M5 Stack includes a built-in battery 110mAh, it can be upgraded with a stackable 700 mAh lipo battery extension module.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/615059260bcadb5085e71de543154bec6c52222f5d1efda91cdcafdbe403cce2.png"></p><p>The similarity between Pwnagotchi and Hash Monster is that they capture both PSK handshakes from WPA / WPA2 networks and PSK hashes contained in beacon frames with PMKID. A great advantage of PMKID cracking is that everything you need is available over the air even if there are no stations connected and only a single packet capture is required. Later we can crack these hashes with standard tools such as aircrack or hashcat, and thus obtain the credentials. Of course, we should only do this in networks that we manage ourselves or that we have permission to audit.</p><p><strong>The process.</strong></p><p>Hardware requirements:</p><ul><li><a href="https://bit.ly/3jFAnl8" target="_blank" rel="nofollow noopener">M5Stack CORE Development Kit</a> with built-in 110mAh Battery ($45)</li></ul><p>Optionally:</p><ul><li><a href="https://bit.ly/3gYtI48" target="_blank" rel="nofollow noopener">Extended Battery M5Stack Core Development Kit Capacity 700mAh Stackable Module</a> (USD$12)</li><li><a href="https://www.banggood.com/M5Stack-Multi-function-Digital-Watch-with-700mAh-Battery-for-M5Stack-ESP32-Core-p-1551727.html?rmmds=search&amp;cur_warehouse=CN" target="_blank" rel="nofollow noopener">Smart Watch Module with 700mAh Battery for M5Stack ESP32 Core</a> ($15)</li></ul><p>The software installation is pretty straight forward:</p><p>1.Setup Arduino IDE environment.</p><p><em>M5Stack Arduino IDE Setup in 5 minutes <a href="https://www.youtube.com/watch?v=U2es-l4z2Zg" target="_blank" rel="nofollow noopener">https://www.youtube.com/watch?v=U2es-l4z2Zg</a></em></p><p>2. Add M5 stack / ESP32 library. (read the <a href="https://docs.m5stack.com/" target="_blank" rel="nofollow noopener">M5 Stack documentation</a> , its pretty solid. As far as ‚Äúinstallation‚Äù goes)</p><p>3. Git clone G4lile0 code.</p><p><a href="https://github.com/G4lile0/ESP32-WiFi-Hash-Monster" target="_blank" rel="nofollow noopener">https://github.com/G4lile0/ESP32-WiFi-Hash-Monster</a></p><p>4. Compile &amp; upload the file to the M5Stack.</p><p>5. Go handshake/PMKID fishing.</p><p>6. Review captures.</p><p>The monster hash saves the files in the micro sd card in pcap format so they can be used by most network analysis tools directly. The files are saved sequentially with the pattern 1.pcap, 2.pcap, etc.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/3dfd72fd0d7415f58f7320b77d722a313f4568f49c863c9bbb502f18d8f454f9.png"></p><p><strong>Cracking notes: Aircrack &amp; hashcat.</strong></p><p>In order to complete this tutorial, we will try doing dictionary attacks against a handshake file from Hash Monster. We will do this with two known tools ‚Äì Aircrack-ng and Hashcat, which relies respectively on CPU and GPU power. We will be running these tools from linux, even though they are both found in a Windows version as well. Remember to use recent versions to benefit from the PMKID attack in addition to the traditional cracking of handshakes.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/adb3724e47a02d9fe14b83454cae422f882a9c99ccc78f0f2db6ef6e7a7f6f9b.png"></p><p>Aircrack-ng can be used for very basic dictionary attacks running on your CPU. Before you run the attack you need a wordlist. I recommend using the infamous rockyou dictionary file:</p><p># download the 134MB rockyou dictionary file</p><pre><code><code>curl -L -o rockyou.txt https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt</code></code></pre><p>Note, that if the network password is not in the wordlist you will not crack the password.</p><p># -a2 specifies WPA2, -b is the BSSID, -w is the wordfile</p><pre><code><code>aircrack-ng -a2 -b AC:FC:E3:C9:AB:C0 -w rockyou.txt 3.cap</code></code></pre><p>If the password is cracked you will see a KEY FOUND! message in the terminal followed by the plain text version of the network password.</p><p>Cracking an WiFi password using brute force attack for a long WiFi password without GPUs or Cloud help, will be a nightmare but if the password is short or you know the key pattern it will be "easily" cracked.</p><p>Here you have a small guide for linux (Ubuntu) to crack the WiFi password using the files stored on the SD_Card of the Purple Hash Monster using your computer.</p><p>First we need to install <strong>hashcat</strong></p><pre><code><code>sudo apt-get update</code><br>
<code> sudo apt install hashcat</code></code></pre><p>EAPOL/PMKID stored on the SD-Card are <em>pcap</em> files, we have to convert to <em>hccapx</em> format to work with hashcat. In terminal from the directory were we have the <em>pcap</em> file from the SD-CARD:</p><pre><code><code>wget https://raw.githubusercontent.com/hashcat/hashcat-utils/master/src/cap2hccapx.c</code><br>
<code> gcc -o cap2hccapx cap2hccapx.c</code><br>
<code> ./cap2hccapx 1.pcap 1.hccapx</code></code></pre><p>For example if we know that the wifi password has a lenght of 8 digits we can run the following command, and in few seconds we will have the WiFi Password :)</p><pre><code><code>hashcat --force -m 2500 -a 3 -1 ?d -o cracked 1.hccapx ?1?1?1?1?1?1?1?1</code></code></pre><p><strong>Final notes</strong></p><p>Although in my case I exclusively use the M5 Stack for the pocket monster hash, there are undoubtedly several projects that run on the M5 Stack and you will certainly want to take a look if you are interested in wifi and bluetooth security attack tools for this platform.</p><p>M5 Stack WiFi SSID Scanner by Elkentaro</p><p><a href="https://github.com/elkentaro/M5_SSID_scanner_collector" target="_blank" rel="nofollow noopener">https://github.com/elkentaro/M5_SSID_scanner_collector</a></p><p>Covid Sniffer: BLE COVID exposure app sniffer using M5 Stack</p><p><a href="https://gitlab.com/mschmidl/covidsniffer" target="_blank" rel="nofollow noopener">https://gitlab.com/mschmidl/covidsniffer</a></p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/02ee78aa44062073eb950642e19a44a548daf55d3217643f1a98cc84d37bc7d6.jpeg"></p></article></div>]]>
            </description>
            <link>https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351269</guid>
            <pubDate>Wed, 02 Sep 2020 08:51:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economics of Skyscraper Height]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 73 (<a href="https://news.ycombinator.com/item?id=24351069">thread link</a>) | @keiferski
<br/>
September 2, 2020 | https://buildingtheskyline.org/economics-of-skyscraper-height-series/ | <a href="https://web.archive.org/web/*/https://buildingtheskyline.org/economics-of-skyscraper-height-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article class="page"><div><p><img src="https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1.jpg" alt="" width="978" height="652" srcset="https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1.jpg 978w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-300x200.jpg 300w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-768x512.jpg 768w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-640x427.jpg 640w" sizes="(max-width: 978px) 100vw, 978px"></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-i" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part I)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018</p>
<p>Many people look at skyscrapers around the world and conclude they are unnecessarily tall. This blog post discusses the economics of skyscraper height. Contrary to popular belief, most skyscrapers have a strong economic rational. <a href="http://buildingtheskyline.org/skyscraper-height-i" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-ii/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part II)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; January 3, 2019</p>
<p>What drives the heights of the world‚Äôs tallest buildings? This post reviews some of the theories that may causes skyscrapers to be economically ‚Äútoo tall.‚Äù Some theories are ‚Äúnefarious,‚Äù some are benign, while others are productive. <a href="http://buildingtheskyline.org/skyscraper-height-ii/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-iii/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part III)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; January 21, 2019</p>
<p>Supertall skyscrapers are assumed to be driven by greed and ego. This blog post reviews the evidence for eight world-record-breaking buildings completed since 1930. The case studies demonstrate, however, that the reality is a bit more complex. <a href="http://buildingtheskyline.org/skyscraper-height-iii/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-iv/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part IV): Construction Costs Around the World</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noopener noreferrer">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; June 4, 2019</p>
<p>What does it cost to build a skyscraper? The blog post reviews the economics of skyscraper supply. One of the reasons why we increasingly see supertalls in Asia is the because of cost of construction is so low there.&nbsp; So, what are the ‚Äúcostnomics‚Äù that generate building height? <a href="http://buildingtheskyline.org/skyscraper-height-iv/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>

<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --></div></article></main></div></div></div>]]>
            </description>
            <link>https://buildingtheskyline.org/economics-of-skyscraper-height-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351069</guid>
            <pubDate>Wed, 02 Sep 2020 08:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lesser-known Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 377 | Comments 126 (<a href="https://news.ycombinator.com/item?id=24350647">thread link</a>) | @Sandeepg33k
<br/>
September 1, 2020 | https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn | <a href="https://web.archive.org/web/*/https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><code>API</code> is the acronym for Application Programming Interface which defines interactions between multiple software architecture layers. Programmers carry out complex tasks easily using APIs in software development. Without APIs, a programmer's life would have been miserable with no proper(security, for example) access to data,  knowing unnecessary low level details etc.</p>
<p>When it comes to Web APIs, there are extremely useful  objects, properties and functions available to perform tasks as minor as accessing DOM to as complex as managing audios, videos, graphics, etc. </p>

<p>If you are from the web development background, you are using many of them already. Here is the list of very well known web APIs.</p>
<ul>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">Canvas</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API">Fetch</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/History_API">History</a> </li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Geolocation_API">Geolocation</a> </li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model">DOM</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Console_API">Console</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API">Drag &amp; Drop API</a></li>
</ul>
<p>In this article, I am going to talk about 10 more web APIs that are not so popular. Lesser popular doesn't mean, they are not useful. You can use them in various use-cases of your project. Please have a look.</p>

<p>If you would like to jump into the source code or see the demonstration immediately, here are the quick links to them:</p>
<blockquote>
<ul>
<li><a target="_blank" href="https://github.com/atapas/demolab/tree/master/code/src/demos/web-apis">Link to the Source Code @GitHub</a></li>
<li><a target="_blank" href="https://demo.greenroots.info/categories/web-apis/">Link to the Web API DemoLab</a></li>
</ul>
</blockquote>
<p>Note: Web APIs are nothing but the interfaces, functions, objects, properties written and exposed using vanilla JavaScript. However the usage of the web APIs is not limited to the vanilla JavaScript based application alone. It is very straightforward to use them with an Angular, React or Vue based applications as well.</p>
<p>All the examples I have used to demonstrate the web apis in this article are written using reactjs. You can find them in the github link mentioned above. Please feel free to fork, change and use!</p>

<p>A big (pain) point about  using a web API is, most of them are not standardized yet. It means, the support for a web API  may differ from one browser vendor to another. For example, You may find an API working with the Chrome browser but, not supported by Firefox or Edge browsers yet.</p>
<p>I would suggest a couple of ways to have a check on this,</p>


<p>Alright, time to get started knowing them. Hope you also find these useful.</p>
<h2 id="1-fullscreen-api">1. üì∫ Fullscreen API</h2>
<p>Do you have the need to show any of the DOM elements in full-screen mode? The full-screen use-case is very demanding for gaming applications, online video platforms(like, youtube) etc. </p>
<p>The <code>Fullscreen API</code> provides methods to present a specific Element (and its children) in a full-screen mode. There is a method available to exit full-screen mode once it is no longer needed. Not only that, this API can also help to perform any actions when a DOM element transition into a full-screen mode or comes out of it.</p>
<p>In the example below, my favorite Santa Claus can get into the full-screen mode and come out of it with ease.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598715764074/fR7trCfsA.gif?auto=format,compress&amp;gif-q=60" alt="full_screen.gif"></p>
<p>In the code below, the <code>manageFullScreen()</code> function uses  the <code>requestFullscreen()</code> API on an element which is having an id called, <code>fs_id</code>. </p>
<pre><code><span>const</span> manageFullscreen = () =&gt; {
   <span>document</span>.getElementById(<span>'fs_id'</span>).requestFullscreen();
}
</code></pre>
<p>This element with id, <code>fs_id</code> is a <code>DIV</code> with a child element, i.e, the Santa Clause image.</p>
<pre><code>&lt;div className=<span>"column"</span>&gt;
  <span><span>&lt;<span>div</span> <span>id</span>=<span>"fs_id"</span>&gt;</span>
    <span>&lt;<span>Img</span> <span>fixed</span>=<span>{imageData.image.childImageSharp.fixed}</span> <span>alt</span>=<span>"santa"</span> /&gt;</span>
   <span>&lt;/<span>div</span>&gt;</span>

    <span>&lt;<span>StyledButton</span> 
         <span>onClick</span>=<span>{manageFullscreen}</span>&gt;</span>
            Enter Fullscreen with Santa
    <span>&lt;/<span>StyledButton</span>&gt;</span>
 <span>&lt;/<span>div</span>&gt;</span></span>
</code></pre>
<p>You can check if the <code>Fullscreen API</code> is supported by the browser,</p>
<pre><code><span>if</span> (<span>document</span>.fullscreenEnabled) {
   setSupported(<span>true</span>);
} <span>else</span> {
   setSupported(<span>false</span>);
}
</code></pre>
<p>Also watch out for the useful handlers like,</p>
<ul>
<li><code>onfullscreenchange</code>: An event handler for the fullscreenchange event.</li>
<li><code>onfullscreenerror</code>: An event handler for the fullscreenerror event.</li>
</ul>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-fullscreen/">https://demo.greenroots.info/web-apis/web-apis-fullscreen/</a></p>
<h2 id="2-clipboard-async-api">2. üìã Clipboard Async API</h2>
<p>What is a clipboard in comuping?</p>
<blockquote>
<p>The clipboard is a buffer that some operating systems provide for short-term storage and transfer within and between application programs.</p>
</blockquote>
<p>There are mainly three operations you can perform with the clipboard. They are, <code>copy</code>, <code>cut</code> and <code>paste</code>. The Clipboard API provides the ability to respond to these three operations. </p>
<p>Interestingly, copying content to the clipboard is open as in, there is no need of a user permission. However, for pasting the content from the clipboard to the user application, the user needs to grant permission for it. It is achieved using another web API called, <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Permissions_API">Permission API</a></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598716493747/PwPwDDK8Y.png?auto=format&amp;q=60" alt="image.png"></p>
<p>Here is a simple example of the copy-paste operation,</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598716547383/PoXUNZmnr.gif?auto=format,compress&amp;gif-q=60" alt="clip_board.gif"></p>
<p>This is how to check if the feature is supported by the browser,</p>
<pre><code><span>if</span> (navigator.clipboard 
     &amp;&amp; navigator.clipboard.read 
     &amp;&amp; navigator.clipboard.write) {
   setSupported(<span>true</span>);
} <span>else</span> {
   setSupported(<span>false</span>);
}
</code></pre>
<p>Here is the async API function for writing the content to the clipboard,</p>
<pre><code><span>async</span> <span><span>function</span> <span>performCopy</span>(<span>event</span>) </span>{
   event.preventDefault();
   <span>try</span> {
      <span>await</span> navigator.clipboard.writeText(copyText);
      <span>console</span>.log(<span>`<span>${copyText}</span> copied to clipboard`</span>);
   } <span>catch</span> (err) {
      <span>console</span>.error(<span>'Failed to copy: '</span>, err);
   }
}
</code></pre>
<p>The Async API function to read the content from the clipboard and do something with it,</p>
<pre><code><span>async</span> <span><span>function</span> <span>performPaste</span>(<span>event</span>) </span>{
   event.preventDefault();
   <span>try</span> {
       <span>const</span> text = <span>await</span> navigator.clipboard.readText();
       setPastetext(text);
       <span>console</span>.log(<span>'Pasted content: '</span>, text);
   } <span>catch</span> (err) {
      <span>console</span>.error(<span>'Failed to read clipboard contents: '</span>, err);
   }
}
</code></pre>
<p>Note: With the inclusion of the <code>Clipboard Async API</code>, you can get rid of the usage of <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Document/execCommand">document.execCommad()</a> function as it is obsolete now.</p>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-clipboard-apis/">https://demo.greenroots.info/web-apis/web-apis-clipboard-apis/</a></p>
<h2 id="3-resize-observer-api">3. üßê Resize Observer API</h2>
<p>Do you want to take some actions based on the changes to the content or border box of a DOM element? Are you thinking of writing a handler by yourself? What if I tell you, there is already one provided by the web API implementation?</p>
<p>Here is a story about a dumb button. We use a range slider to resize the button. While the button gets resized, we also want to control the text color, without letting the button know much about it. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717277220/dITL6Nog2.gif?auto=format,compress&amp;gif-q=60" alt="resizer.gif"></p>
<p>First, create a button and specify an id so that, we can access the button later using the id.</p>
<pre><code>&lt;StyledButton id=<span>"dumbBtnId"</span>&gt;
   I am a Dumb Button
&lt;<span>/StyledButton&gt;</span>
</code></pre>
<p>Now we create a slider using the <code>range</code> input type from HTML5. A <code>resize()</code> function is invoked when the slider value changes.</p>
<pre><code>&lt;div&gt;
   <span><span>&lt;<span>input</span> 
         <span>onChange</span>=<span>{(event)</span> =&gt;</span> resize(event)} 
         type="range" 
         min={minRange} 
         max={maxRange} 
         defaultValue={rangeValue} /&gt;
<span>&lt;/<span>div</span>&gt;</span></span>
</code></pre>
<p>The <code>resize()</code> function simply sets the width of the button as the slider range value so that, it can be resized dynamically.</p>
<pre><code><span>const</span> resize = event =&gt; {
   <span>const</span> value = event.target.valueAsNumber;
   setRangeValue(value);
   <span>let</span> dumbBtn = <span>document</span>.getElementById(<span>'dumbBtnId'</span>);
   dumbBtn.style.width = <span>`<span>${value}</span>px`</span>;
 }
</code></pre>
<p>So far, so good? Now for every range value change, the button gets resized. We have a <code>ResizeObserver</code> observing this change and change the color of the button text.</p>
<pre><code>useEffect(() =&gt; {
   <span>try</span> {
            <span>let</span> dumbBtn = <span>document</span>.getElementById(<span>'dumbBtnId'</span>);
            <span>var</span> resizeObserver = <span>new</span> ResizeObserver(entries =&gt; {
                <span>for</span>(<span>const</span> entry <span>of</span> entries) {
                    
                    
                   entry.target.style.color = <span>'green`;
                }
      });
      resizeObserver.observe(dumbBtn);
   } catch(e) {
            setSupported(false);
            console.log(e);      
   }
}, [rangeValue]);</span>
</code></pre>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-api-resize-observer/">https://demo.greenroots.info/web-apis/web-api-resize-observer/</a></p>
<h2 id="4-image-capture-api">4. üì∑ Image Capture API</h2>
<p>There are some cool and useful APIs around user media like, audio, video etc. I love the <code>Image Capture API</code> which helps us to capture an image or grab a frame from the video devices(like webcam). Not only that, you can also perform actions on capturing an image or grabbing a frame.</p>
<p>First, get the user media access. In this case we are getting the webcam access.</p>
<pre><code>navigator.mediaDevices.getUserMedia({video: <span>true</span>})
  .then(mediaStream =&gt; {
     <span>document</span>.querySelector(<span>'video'</span>).srcObject = mediaStream;
     <span>const</span> track = mediaStream.getVideoTracks()[<span>0</span>];
     setTrack(track);
  }).catch(error =&gt; {
     <span>console</span>.error(<span>` <span>${error}</span> is not yet supported`</span>);
     setError(error);
});
</code></pre>
<p>Just like the clipboard paste operation, a webcam media access permission has to be granted by the user.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717565379/MCRNY49Tl.png?auto=format&amp;q=60" alt="image.png"></p>
<p>Now Grab a frame and do something. In this example, I am just drawing the frame on a Canvas.</p>
<pre><code><span>const</span> imageCapture = <span>new</span> ImageCapture(track);
    imageCapture.grabFrame()
      .then(imageBitmap =&gt; {
          <span>const</span> canvas = <span>document</span>.querySelector(<span>'#grabFrameCanvas'</span>);
          drawCanvas(canvas, imageBitmap);
    }).catch(error =&gt; {
          <span>console</span>.log(error);
          setError(error);
});
</code></pre>
<p>I can also take a picture and do the similar thing.</p>
<pre><code><span>const</span> imageCapture = <span>new</span> ImageCapture(track);
    imageCapture.takePhoto().then(blob =&gt; createImageBitmap(blob))
      .then(imageBitmap =&gt; {
          <span>const</span> canvas = <span>document</span>.querySelector(<span>'#takePhotoCanvas'</span>);
          drawCanvas(canvas, imageBitmap);
    }).catch(error =&gt; {
          <span>console</span>.log(error);
          setError(error);
});
</code></pre>
<p>To stop the video streaming from the webcam, just call he method <code>stop()</code> on the running video track.</p>
<pre><code><span>const</span> videoOff = () =&gt; {
   track.stop();
 }
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717833234/MPOxVZ92M.png?auto=format&amp;q=60" alt="chrome_Umvi16wUlu.png"></p>
<p>Also watch out for the methods,</p>
<ul>
<li><code>getPhotoCapabilities()</code>: To get the ranges of available configuration options.</li>
<li><code>getPhotoSettings()</code>: To get the current photo configuration settings.</li>
</ul>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-image-capture/">https://demo.greenroots.info/web-apis/web-apis-image-capture/</a></p>
<h2 id="5-broadcast-channel-api">5. üì° Broadcast Channel API</h2>
<p>The <code>Broadcast Channel API</code> allows communication between browsing contexts (windows, tabs, iframes) and workers on the <strong>same origin</strong>. Think of a use-case like, once you logout from an app running in a browser tab, you want to broadcast it to the app instances opened in other tabs of the same browser.</p>
<p>Here is an example where a sender is sending a message to the receiver and the same is being ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn">https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn</a></em></p>]]>
            </description>
            <link>https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24350647</guid>
            <pubDate>Wed, 02 Sep 2020 06:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A round-up of topology-based papers at ICML 2020]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24350436">thread link</a>) | @Topolomancer
<br/>
September 1, 2020 | https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>With this year‚Äôs <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning&nbsp;(ICML)</a>
being over, it is time to have another instalment of this series.
Similar to <a href="http://bastian.rieck.me/blog/posts/2019/icml_tda_roundup/">last year‚Äôs post</a>, I shall cover
several papers that caught my attention because of their use of
topological concepts‚Äîhowever, <em>unlike</em> last year, I shall not
restrict the selection to papers using <a href="https://en.wikipedia.org/wiki/Topological_data_analysis">topological data analysis&nbsp;(TDA)</a>.</p>
<p><strong>Caveat lector:</strong> I might have missed some promising papers. Any
suggestions for additions are more than welcome! Please reach out
to me via <a href="https://twitter.com/Pseudomanifold">Twitter</a> or
<a href="mailto:bastian@rieck.me">e-mail</a>.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_chen.png" alt="Learning Flat Latent Manifolds with VAEs" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.04881">Learning Flat Latent Manifolds with VAEs</a>
by <a href="https://argmax.ai/team/nutan-chen">Nutan Chen</a>, <a href="https://www.argmax.ai/team/alexej-klushyn">Alexej Klushyn</a>,
Francesco Ferroni, <a href="http://bayerj.github.io/">Justin Bayer</a>, and
<a href="https://argmax.ai/team/patrick-van-der-smagt">Patrick van der Smagt</a>
discusses an interesting modification of variational autoencoders, viz.
an extended loss term that regularises the latent space to be
<em>flat</em>&nbsp;(i.e. having no <a href="https://en.wikipedia.org/wiki/Curvature">curvature</a>).
The main idea is to ensure that the <a href="https://en.wikipedia.org/wiki/Metric_tensor">Riemannian metric tensor</a>
is the identity matrix.</p>
<p>The ingenious implication of such a latent space is that the Euclidean
distance is a good proxy for the similarity between data points, whereas
this is <em>not</em> a priori the case for other latent spaces. It is interesting
to note that there is a ‚Äòsibling‚Äô paper to this one, which was published
at ICLR 2020, namely <a href="https://openreview.net/pdf?id=S1g6xeSKDS">Mixed-curvature Variational Autoencoders</a>.
This paper presents an autoencoder whose latent space is a product of
Riemannian manifolds, whose curvature is either fixed or learnable.</p>
<p>I am glad to see that curvature is starting to attract more attention
from the machine learning community. It is such a fundamental property
of a manifold but can influence the validity of many calculations in
latent spaces. It also has some beneficial properties for <a href="https://openreview.net/pdf?id=BylEqnVFDB">graph
classification</a>, but this is
maybe a better topic for a subsequent post!</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_hoferb.png" alt="Graph Filtration Learning" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/1905.10996">Graph Filtration Learning</a> by
<a href="https://www.researchgate.net/profile/Christoph_Hofer8">Christoph Hofer</a>,
<a href="https://www.uni-salzburg.at/index.php?id=213185&amp;L=1">Florian Graf</a>,
<a href="https://bastian.rieck.me/">Bastian Rieck</a>,
<a href="http://wwwx.cs.unc.edu/~mn/?q=content/overview">Marc Niethammer</a>, and
<a href="https://rkwitt.github.io/">Roland Kwitt</a> is arguably<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> the first step
towards properly integrating topological features into neural networks
for graph classification! Briefly put, we developed a homological
<code>READOUT</code> function&nbsp;(to use the parlance of graph neural networks)
that gives rise to a learnable filter function‚Äîa <em>filtration</em>.</p>
<p>This concept might be unknown to some readers, but a filtration in this
context is a scalar-valued function on the vertices of a graph that
permits <em>sorting</em> it. Filtrations serve as the backbone for many
topology-based algorithms, primarily for the aforementioned <a href="https://christian.bock.ml/posts/persistent_homology/">persistent homology</a>,
which permits us to study multi-scale topological
features&nbsp;(connected components, cycles, etc.) of an object.
Prior to this paper, filtrations were pre-defined or chosen based on
some target function, such as the vertex degree function of a graph. Our
approach changes this‚Äîleading to a filtration that is learnable in an
end-to-end fashion and thus specifically designed for a classification
problem.</p>
<p>We manage to achieve this by first initialising our filter function
based on a regular graph neural network; essentially, one level of
message passing between nodes is sufficient. This provides us with
a non-trivial filter function whose performance we can subsequently
adjust by calculating the topological features induced by said filter,
and vectorising the resulting representations. Since each of these steps
is differentiable<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, the resulting function is also differentiable,
making it possible to adjust the filter for the best classification
results.</p>
<p>I would recommend this paper to anyone who is interested in learning
more about the benefits that a topology-based perspective brings to
certain application problems. Being able to learn the <em>right</em> topological features
to classify a set of graphs opens up exciting opportunities.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_hofera.png" alt="Topologically Densified Distribution" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.04805">Topologically Densified Distributions</a>
by <a href="https://www.researchgate.net/profile/Christoph_Hofer8">Christoph Hofer</a>,
<a href="https://www.uni-salzburg.at/index.php?id=213185&amp;L=1">Florian Graf</a>,
<a href="http://wwwx.cs.unc.edu/~mn/?q=content/overview">Marc Niethammer</a>, and
<a href="https://rkwitt.github.io/">Roland Kwitt</a> studies regularisation properties of
over-parametrised neural networks in the context of small sample-size learning.
This is achieved by studying the properties of latent
representations&nbsp;(the paper uses the term <em>internal representation</em>,
but this is equivalent). More precisely, generalisation properties are
analysed via the <a href="https://en.wikipedia.org/wiki/Pushforward_measure">push-forward probability measure</a>
induced by the latent representation&nbsp;(or <em>encoding</em>).</p>
<p>The authors show that probability mass concentration around training
samples in the latent space is linked to the generalisation capabilities
of a model, but, even more exciting, such a concentration can be achieved by applying
topological constraints on samples from that space! In the context of
this paper, such constraints pertain to measuring the <em>connectivity</em> of
samples. This is achieved using <a href="https://christian.bock.ml/posts/persistent_homology/">persistent homology</a>, specifically,
by calculating a zero-dimensional Vietoris‚ÄìRips complex‚Äîif you are
not familiar with this term, just think of a minimum spanning tree.</p>
<p>What I particularly enjoyed about this paper is that it starts providing
solid answers to fundamental concepts in machine learning. All too often,
we remain in the realm of the empirical and just <em>observe</em> whether our
network generalises. This paper ventures into hitherto-unknown territories
and gives us a theoretical justification!</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_moor.png" alt="Topological Autoencoders" width="250"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/1906.00722">Topological Autoencoders</a> by
<a href="https://michaelmoor.ml/">Michael Moor</a>,
<a href="https://expectationmax.github.io/">Max Horn</a>,
<a href="https://bastian.rieck.me/">Bastian Rieck</a>, and
<a href="https://bsse.ethz.ch/mlcb/karsten.html">Karsten Borgwardt</a> deals with
regularising the latent space in terms of its topology. More precisely,
we preserve the topological features of the input data in the respective
latent space&nbsp;(on the batch level, respectively). While we restrict
our experiments to connected components for now&nbsp;(so no cycles
yet, even though our method generalises to higher dimensions),
our approach makes it possible to create latent representations
that ‚Äòmimic‚Äô the topological features of the input.</p>
<p>This leads to a nice plug-and-play loss term that can be easily
integrated into most architectures, and we can demonstrate that, among
others, it considerably improves the quality of a ‚Äòvanilla‚Äô autoencoder
architecture. To achieve this goal, we had to solve all kinds of
interesting adventures, one of them being how to make everything
differentiable. Interestingly, we end up with a similar necessary
condition for differentiability than for the graph filtration learning
paper, viz. the pairwise distances between different samples of the
input batch need to be <em>unique</em>.</p>
<p>The coolest feature of our method is that it technically <em>only</em> requires
a distance metric between input samples<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, nothing more‚Äîno feature
vector representation or anything. It can thus conceivably be used to
represent the topology of any object you fancy&nbsp;(including
documents, images, and graphs).</p>
<p>If you are interested in a beautifully-animated high-level introduction
to this publication, you should take the time to read Michael‚Äôs <a href="https://michaelmoor.ml/blog/topoae/main/">blog post on our paper</a>.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_rezende.png" alt="Normalizing Flows on Tori and Spheres" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.02428">Normalizing Flows on Tori and Spheres</a> by
<a href="https://danilorezende.com/">Danilo Jimenez Rezende</a>,
<a href="https://gpapamak.github.io/">George Papamakarios</a>,
<a href="https://scholar.google.com/citations?user=o-h0vrQAAAAJ">S√©bastien Racani√®re</a>,
<a href="http://malbergo.me/">Michael S. Albergo</a>,
<a href="https://scholar.google.com/citations?user=zK77P6MAAAAJ">Gurtej Kanwar</a>,
<a href="https://web.mit.edu/physics/people/faculty/shanahan_phiala.html">Phiala E.  Shanahan</a>,
and <a href="http://theoryandpractice.org/">Kyle Cranmer</a>
present a novel method for calculating normalising flows on more complex
spaces than the usual Euclidean ones. Specifically, as the title
implies, they develop methods for calculating such flows on tori and
spheres.</p>
<p>What I enjoyed about this paper is the smart way of constructing flows
iteratively: first, flows on the circle are being constructed&nbsp;(using
different concepts for defining a <a href="https://en.wikipedia.org/wiki/Diffeomorphism">diffeomorphism</a>, the most favourite of
mine being a <a href="https://en.wikipedia.org/wiki/M%C3%B6bius_transformation">M√∂bius transformation</a>).
Since a torus can be described as the Cartesian product of circles, this
is sufficient to describe flows on tori of arbitrary dimensions! Next,
the flows are generalised to higher-dimensional spheres.</p>
<p>While I am by no means and expert in normalising flows, I liked
reading this paper a lot. The theory is well-developed and it is another
one of those publications that shows you how to go beyond the boundaries
of what is currently possible. Moreover, I enjoyed the discussion of the
implementation details‚Äîit turns out that achieving numerical stability
here is another feat that deserves some mention!</p>

<p>This year‚Äôs ICML also featured an interesting array of topology-based
papers. Not all of them fit neatly into the field of topological data
analysis&nbsp;(TDA), but I am happy to see that the community is
starting to pick up this fundamental topic. I remain convinced that
a topology-driven perspective is needed to answer certain foundational
questions in machine learning. Here‚Äôs to the future of topology!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Even if say so myself. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Under mild assumptions, viz. provided that the filter function
values are unique for each vertex. This can always be achieved by
a small symbolic perturbation. <a href="#fnref:2" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Practically, it might not even require the properties of a metric,
although the mathematician in me is screaming at the horrors of this
thought. <a href="#fnref:3" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24350436</guid>
            <pubDate>Wed, 02 Sep 2020 06:03:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The problem with C according to a C++ developer]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24349256">thread link</a>) | @eatonphil
<br/>
September 1, 2020 | https://cor3ntin.github.io/posts/c/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://cor3ntin.github.io/posts/c/fight.jpeg" alt="Fish"></p>
<p>In the early 70s, C was created at Bell Labs as a byproduct of the development of UNIX.
It quickly became one of the most popular programming languages.
But it was not expressive enough for Bjarne Stroustrup.
And so, in 1983, as a byproduct of his Ph.D. thesis, he extended C.</p>
<p>C with classes was born.</p>
<p>At the time, Bjarne Stroustrup understood that a programming language has many components,
not only the language, its compiler, but also a linker and libraries.
Offering a familiar tool also makes adoption easier.
In this historical context, it makes sense that C++ would be based on C.</p>
<p>Fast-forward 40 years later.</p>
<p>Both C and C++ are widely used in the industry.
But go 5 minutes on the Internet and C developers will tell you that C++ is the most horrific man-made creation,
while many C++ developers wait for the day when C finally burns in the hot flames of hell.</p>
<h2 id="so-what-happened">So what happened?</h2>
<p>On the surface, C and C++ cater to the same use cases: high performance, deterministic, native but portable code for the widest range of hardware and applications.</p>
<p>But C is proudly a low-level language. A nicer assembly.</p>
<p>From day one, C++ had magic. Dark witchcraft: destructors. Suddenly the compiler was doing things on its own.
It also had type inference very early on, but the developers of the mid-80s were not quite ready for that and Bjarne Stroustrup
was pressured into removing <code>auto</code>, until it was added back to C++11.</p>
<p>From then, C++ got more and more tools to build abstractions.
I don‚Äôt think it would be fair to say that C++ is a low-level or high-level language. It‚Äôs both, by design.
But building high-level abstractions while not sacrificing performance is hard.
C++ then needed tools to achieve that: <code>constexpr</code>, move semantics, templates, and an ever-growing standard library.</p>
<p>Fundamentally I think C trusts developers while C++ trusts compilers.
This is a massive difference that sharing the same native types or syntax for while loop cannot hide.</p>
<p>C++ developers blame C for all their lost limbs, while C developers probably think C++ is batshit crazy.
I imagine that is a fair perspective if you look at C++ through a C lense. C++ is pretty wild <em>as a superset of C</em>.
A seasoned C person looking at C++ expecting familiarity in C++ will not find it. C++ is not C.
This is enough to feed flamewars for generations.</p>
<p>But as much as I dislike C, I don‚Äôt have any legitimacy to make fun of it. See, I have some experience with C++ but I
wrote very little C. It was probably bad C.
A language is also its good practices, patterns, idioms, and these take years to learn. If you try to write C code like it‚Äôs C++ or C++ like it is C, you will have a bad time.
Knowing <a href="https://www.youtube.com/watch?v=YnWhqhNdYyk">C doesn‚Äôt teach you C++</a>. Knowing C++ does not teach you C.</p>
<p>So can we all stop saying C/C++, regret the unfortunate naming, and sing kumbaya in harmony?
Not so fast.</p>
<p>See, despite being philosophically different from C, C++ is still somewhat a superset of C.
That is to say, you can include a C header in a C++ translation unit and that should compile.
And this is where it gets messy.</p>
<p>C++ is not an extension of C.
It is designed as a separate standard, by a different committee, different people.
Logically, people who like C++'s philosophy will get involved in the C++ community and the C++ standardization process
while other people might try to get involved with C.
Committees, whether its C‚Äôs or C++'s, only manifest intent and direction through their respective end-product: the standards; standards which are the fruits of numerous voting.</p>
<p>At the same time, it is difficult for a compiler to know that it is dealing with a C header or a C++ header.</p>
<p><code>extern "C"</code> is not used consistently and only affects mangling, but neither grammar nor semantics.
And headers only exists in the eyes of the preprocessor, for a C++ compiler, everything is a C++ translation unit, and therefore C++.
And yet, people include C headers in C++ and expect it to ‚Äújust work‚Äù ‚Ñ¢Ô∏è.
Which it mostly does.</p>
<p>We can wonder then,</p>
<h2 id="how-c-maintains-c-compatibility-while-being-developed-by-different-people-in-different-places">How C++ maintains C compatibility while being developed by different people in different places?</h2>
<p>Badly, I‚Äôm afraid.</p>
<p>A coworker recently reminded me of Conway‚Äôs law:</p>
<blockquote>
<p>Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization‚Äôs communication structure</p>
</blockquote>
<p>By that logic, it would stand to reason that if the two committees don‚Äôt interoperate,
neither would the languages they produce.</p>
<p>C++ maintains a list of <a href="http://eel.is/c++draft/diff.iso">incompatibilities with C</a> and <a href="http://eel.is/c++draft/diff.library">its standard library</a>.
This list does not seem to reflect the many features that were added to C11 and C18 but are not valid C++ constructs. <a href="https://en.wikipedia.org/wiki/Compatibility_of_C_and_C%2B%2B">Wikipedia</a> draws a clearer picture.</p>
<p>Listing incompatibilities isn‚Äôt sufficient to get a measure of incompatibilities between both languages.</p>
<p>Functions that exist in the C++ standard library but whose primary declaration is expected to come from C are difficult to make <code>constexpr</code>, and more difficult still to make <code>noexcept</code>.
C compatibility translates to performance costs and C functions are optimization barriers.</p>
<p>Many C constructs are valid C++ but should never pass a code review (<code>NULL</code>, <code>longjmp</code>, <code>malloc</code>, create/destroy functions, <code>free</code>, C  casts), etc.</p>
<p>These might not be bad C idioms, but they are bad C++. C++ has a stronger type system,
and unfortunately using C idioms punch a giant hole in that type system, and so C compatibility has a cost in terms of safety.</p>
<p>Don‚Äôt get me wrong, C++ still care about C compatibility. Somewhat.
And interestingly C cares about C++. Somewhat.
Truth be told, C might care about C++ more than C++ cares about C.
So each committee cares somewhat about what the other does.
We care reluctantly.</p>
<p>See, C++ is aware of the many foundational libraries written in C, not only the <code>libc</code> but also <code>zip</code>, <code>png</code>, <code>curl</code>, <code>openssl</code> (!), and countless others, which are used in many, many C++ projects.
We can‚Äôt break that.</p>
<p>But recently, especially over the past decade, C++ has become much bigger than C.
C++ has more users - and a much more active community: <a href="https://nullprogram.com/blog/2018/11/21/">There Are No C Conferences</a>.
Maybe that‚Äôs why the C++ committee is now over 10 times the size of the C committee.</p>
<p>C++ then is a force to be reckoned with and the C committee has to consider not breaking C++.
To the point that if a standard would track another, these days, C++ leads and C follow.</p>
<p>C++ is now on a steady three years cycle come rain or shine, or deadly pandemics.
Meanwhile, C has a major release every decade or so.
This makes sense. As a lower-level language, C doesn‚Äôt need to evolve as fast.</p>
<p>The C landscape is also rather different from the C++ landscape.
C caters to more platforms and a lot more compilers.
Everybody and their dog is writing C compilers because the language has a surface area small enough to make that possible, whereas the C++ committee will only really consider 4 implementations, all of which are represented at every meeting.
As a result, many features in C are implementation-defined or optionally supported so that the variety of compilers that exist can claim conformance without doing much work, which I‚Äôm told pleases regulatory bodies.</p>
<p>C++ these days is more interested in portability than implementation freedom. Yet another difference of philosophy.</p>
<h2 id="so-your-proposal-breaks-c-compatibility">So, your proposal breaks C compatibility</h2>
<p>Parts of my <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2178r1.pdf">P2178</a> paper theoretically affects C compatibility.
In such cases, none of the options seems satisfactory.</p>
<p>You could be told that you have to first get your feature into C. Which means more meetings.
Meetings you might not be able to attend because C has strict <a href="https://thephd.github.io/follow-the-river-wg14-ithaca-2019">attendance rules</a> - Excluding individuals not willing to put down thousands of dollars to become ISO members.
This is because the C committee is forced to adhere strictly to ISO rules.</p>
<p>It might also take a decade if the standard just shipped.
And most importantly, it might go nowhere if the C committee doesn‚Äôt understand or doesn‚Äôt care about the particular problem you are trying to solve.
And they probably don‚Äôt have the bandwidth to deal with it.
And you may not have the bandwidth to deal with C. After all, you joined C++ to improve C++.
In fact, if the room invites you to ‚Äútalk to the C committee‚Äù, it is likely your proposal is dead, even in the unlikely event that no one in the room was against it.</p>
<p>Another likely scenario is that the C committee accepts a version of a proposal that is slightly different from what exists in C++.
<code>true</code>? Let‚Äôs make that a macro. <code>char16_t</code> ? Let‚Äôs make that a typedef. <code>char32_t</code>? Not necessarily UTF-32. <code>static_assert</code> ? <code>_Static_assert</code>.</p>
<p>The list goes on. Should we blame C? Probably not. Their committee does what they think is best for their language.
The opposite is true too. In C++20 designated initializers were inspired by C‚Äôs but are slightly different because they would otherwise not fit with the C++ initialization rules.</p>
<p>I am part of the problem. C has VLAs. I would vote against a proposal to adopt that in standard C++, <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kills-The-VLA">too many security issues</a>. A proposal to add <code>_Generic</code> to C++ would be over-my-dead-body. I am not sure if <code>_Generic</code> attempts to palliate to the lack of template or the lack of overloads, but C++ has both these features - from my point of view <code>_Generic</code> doesn‚Äôt fit into the big picture of what I imagine C++ to be.</p>
<p>Both committees seem also inconsistent in how much they care about the other language.
Sometimes we go to great lenghts (<a href="https://en.cppreference.com/w/cpp/numeric/complex">std::complex</a>), sometimes we don‚Äôt care at all (<a href="https://en.cppreference.com/w/c/language/array">static array parameters</a>).</p>
<p>There is no way around this. Don‚Äôt forget that each committee is a bunch of people
voting at different times in different rooms and trying to control the outcome would defeat the purpose
of having a vote.
Putting people in the same room is not realistic either. ISO might object and the participation inbalance
would put C people at an enormous disadvantage.</p>
<h2 id="c-compatibility-doesnt-matter-kinda">C compatibility doesn‚Äôt matter, kinda</h2>
<p>If you are a C developer, I imagine you see C as a neat programming language.
But for the rest of us, C is something else.</p>
<p>C is the universal, cross-language glue that ties it all together.</p>
<p>For C++ users, C is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/c/">https://cor3ntin.github.io/posts/c/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24349256</guid>
            <pubDate>Wed, 02 Sep 2020 01:53:46 GMT</pubDate>
        </item>
    </channel>
</rss>
