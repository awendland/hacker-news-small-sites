<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 01 Mar 2021 08:36:11 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 01 Mar 2021 08:36:11 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Bupstash Garbage Collector]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26282771">thread link</a>) | @andrewchambers
<br/>
February 26, 2021 | https://acha.ninja/blog/the_bupstash_garbage_collector/ | <a href="https://web.archive.org/web/*/https://acha.ninja/blog/the_bupstash_garbage_collector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<h2 id="overview">Overview</h2>
<p>My backup tool <a href="https://github.com/andrewchambers/bupstash">bupstash</a> stores backups in a repository as an evergrowing set of
encrypted data trees which use content addressing and structural sharing
to deduplicate data. In order to delete unused backups we need to do something very similar to how
many programming languages free unreferenced memory - garbage collection. This post will
explain the evolution and implementation of the garbage collector in bupstash for the curious.</p>
<h2 id="stop-mark-and-sweep">Stop, mark and sweep.</h2>
<p>The initial version of the bupstash garbage collector was a naive stop-the-world
garbage collector. It walks all backup data trees creating a set of reachable data chunks
by address and then deletes unreachable data.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Stop the world.</li>
<li>Mark.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>lock_repository()
reachable_addresses = empty_set()

for data_tree in all_backups():
  
  work_list = new_work_list_from_backup(data_tree.root_address)
  
  until work_list.is_empty():
    
    node_height, node_address = work_list.pop()
    reachable_addresses.add(node_address)
    
    if node_height != 0:
      add_child_nodes_to_worklist(work_list, node_address)

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><p>This algorithm is short and sweet, but if the repository is very large our repository becomes unavailable
for a potentially long time. The next version shortens the downtime of the repository significantly.</p>
<h2 id="mark-stop-mark-and-sweep">Mark, stop, mark and sweep.</h2>
<p>The bupstash v0.6.4 garbage collector takes advantage of two facts:</p>
<ul>
<li>Because many backups share data with each other, we can memoize the walk phase to skip work.</li>
<li>Because backups are immutable while the repository is unlocked, we can walk most of them without
stopping the world.</li>
</ul>
<p>This time we walk the repository without the repository locked, then lock it and walk
the repository again using our memoization to quickly complete the job. If any new backups
appeared during our first walk, we are guaranteed to mark them now that the repository lock is held. Doing the majority of the slow mark phase without locking the repository greatly increases
the repository availability for other operations.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Memoized mark repository.</li>
<li>Stop the world.</li>
<li>Memoized mark repository.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>walked_trees = empty_set()
reachable_addresses = empty_set()

func walk_repository():

  for data_tree in all_backups():

    if walked_trees.has(data_tree):
      continue

    walked_trees.add(data_tree)
    
    work_list = new_work_list_from_backup(data_tree.root_address)
    
    until work_list.is_empty():
      
      node_height, node_address = work_list.pop()
      already_walked = reachable_addresses.has(node_address)
      reachable_addresses.add(node_address)
      
      if node_height != 0 and not already_walked:
        add_child_nodes_to_worklist(work_list, node_address)

walk_repository()
lock_repository()
walk_repository()

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><h2 id="mark-stop-mark-bloom-adjust-and-sweep">Mark, stop, mark, bloom adjust, and sweep</h2>
<p>The next version of the garbage collector is a WIP unreleased version.</p>
<p>In bupstash each data chunk address is 32 bytes, which means we need at least 32 bytes of RAM per chunk in the repository to successfully perform a garbage collection. For a repository containing a 100 million chunks or
more this could easily exhaust memory on a busy or small system.</p>
<p>If we are willing to accept a very low probability of retaining some extra data, we can reduce this down
to a few <em>bits</em> per chunk reducing memory usage by 64x or more.
To do this we use a probabilistic data structure called a <a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter</a> to track reachable addresses.</p>
<p>Bloom filters have two downsides:</p>
<ul>
<li>They can have false positives. For us this means we might keep a data chunk by accident we could have actually freed.</li>
<li>We must presize them. They cannot grow if we got the size wrong.</li>
</ul>
<p>Luckily for us these downsides are not bad:</p>
<ul>
<li>Because memory use is so low per address, we can generously size our bloom filter reducing false positives to less than one percent, even for large repositories.</li>
<li>We can easily detect when a bloom filter gets overly full and produces many false positives, and thus adjust it’s size for future garbage collections.</li>
</ul>
<p>As a bonus, the bupstash implementation of a bloom filter is actually simpler than a hash table, with the implemenation
weighing in at around 30 lines of code plus tests and helpers.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Memoized mark repository.</li>
<li>Stop the world.</li>
<li>Memoized mark the repository.</li>
<li>Adjust bloom filter size.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>walked_trees = empty_set()
walked_addresses = empty_cache()
reachable_addresses = empty_bloom_filter(repository_bloom_size())

func walk_repository():

  for data_tree in all_backups():

    if walked_trees.has(data_tree):
      continue

    walked_trees.add(data_tree)
    work_list = new_work_list_from_backup(data_tree.root_address)
    
    until work_list.is_empty():
      
      node_height, node_address = work_list.pop()
      already_walked = walked_addresses.has(node_address)
      reachable_addresses.add(node_address)
      walked_addresses.add(node_address)
      
      if node_height != 0 and not already_walked:
        add_child_nodes_to_worklist(work_list, node_address)

walk_repository()
lock_repository()
walk_repository()

if bloom_filter_overutilized(reachable_addresses):
  increase_bloom_filter_size_for_next_gc()
else if bloom_filter_underutilized(reachable_addresses):
  decrease_bloom_filter_size_for_next_gc()

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><p>One thing to note about this implementation is that because the bloom filter has false positives we can not use it to skip processing addresses, instead
we must introduce a new cache for this purpose. A cache also lets us put a fixed upper bound on memory usage for large repositories.</p>
<p>Overall for large repositories, the addition of a bloom filter reduces ram requirements from the gigabyte range down to tens of megabytes while increasing the repository size by only a fraction of a percent.</p>

<p>The bupstash garbage collector tries hard to keep the repository avaliable as long
as possible while also providing excellent performance with a small memory profile. If you are implementing
a content addressed storage system, this post will hopefully provide you with some new ideas.</p>
<p>In the future bupstash could follow the same path as programming language garbage collectors to find more improvements:</p>
<ul>
<li>Parallelism in the mark phase.</li>
<li>Parallelism in the sweep phase.</li>
<li>Incremental collection.</li>
<li>Object generations.</li>
<li>Write barriers</li>
<li>Yet to be invented techniques…</li>
</ul>
<p>As always, thanks for reading and please feel free to give <a href="https://github.com/andrewchambers/bupstash">bupstash</a> a try.</p>

			</div></div>]]>
            </description>
            <link>https://acha.ninja/blog/the_bupstash_garbage_collector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282771</guid>
            <pubDate>Sat, 27 Feb 2021 04:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do farmers have the right to repair their own equipment?]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26282642">thread link</a>) | @curmudgeon22
<br/>
February 26, 2021 | https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/ | <a href="https://web.archive.org/web/*/https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><span><span>Reading Time: </span> <span>5</span> <span>minutes</span></span></p><p>It’s a story that’s becoming more and more common.</p>
<p>You’re smack dab in the middle of harvest and an error code appears on your combine’s monitor. A call to the dealership results in a long wait for a technician to come out, with anxiety rising with every passing hour because priceless harvesting time is being lost or, worse, nasty weather is moving in.</p>
<p>Then when the technician gets to your farm, he determines what is needed is to reset (or ‘flash’) the onboard computer.</p>
<p>That happened to Cole Siegle last fall when he was harvesting canola, leaving the Fairview-area producer to wonder why he can’t have access to the same diagnostic tools.</p>
<div id="attachment_133445"><p><img loading="lazy" src="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied-150x150.jpg" alt="" width="150" height="150" srcset="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied-150x150.jpg 150w, https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied.jpg 300w" sizes="(max-width: 150px) 100vw, 150px"></p><p>Cole Siegle.<br><small><i>photo:</i><span> Supplied </span></small></p></div>
<p>“If I could have done that myself or been able to use a mechanic or a technician who’s closer to me, our downtime could have gone from six hours to two hours,” he said. “That four hours could have been the difference between getting&nbsp;a crop off before the snow or not.”</p>
<p>But these days it’s dealerships — via sales and service agreements with manufacturers — that have legal access to these diagnostic tools. So when an error message pops up, farmers and independent mechanics are out in the cold, sometimes literally.</p>

<ul>
<li><strong>Read more: <a href="https://www.albertafarmexpress.ca/news/connectivity-grey-under-new-trade-agreement/">Connectivity ‘grey’ under new trade agreement</a></strong></li>
<li><strong>Read more: <a href="https://www.albertafarmexpress.ca/news/remote-diagnostics-blocked-by-poor-internet-on-farms/">Remote diagnostics blocked by poor internet on farms</a></strong></li>

</ul>
<p>“As a producer I think we need access to these diagnostic tools,” said Siegle. “If (manufacturers) want to continue to build equipment like this that’s fine, but we need access to the laptops with the programs that we can plug into our equipment so we can buy whatever part we need.”</p>
<p>Equipment manufacturers make a lot of repair information public, including what codes mean, but giving access to proprietary tools raises several issues, said John Schmeiser, CEO of the Western Equipment Dealers Association.</p>
<p>The hardware and software Siegle and other farmers wish to acquire for repair purposes can also be used to modify equipment to the detriment of machinery, warranties, the lawfulness of their operations and even their own safety, he said.</p>
<p>“I applaud the manufacturers that put a lot of stuff online&nbsp;like parts, service manuals and operational guides. But it’s a slippery slope,” said Schmeiser.</p>
<p>“When you provide special tools to somebody outside a controlled environment like the manufacturer/dealer&nbsp;relationship, that opens the door for illegal modification. They lose that control when they provide&nbsp;diagnostic or special tools to a third-party retailer with whom they don’t have the same sales and services agreement.”</p>
<h2>Repair versus modify</h2>
<p>‘Right to repair’ is a term being thrown around a lot in ag circles today, but it means different things to different people.</p>
<p>For Siegle and other like-minded producers, it means the right to either repair equipment themselves or hire an unaffiliated local mechanic — just as farmers have done throughout the history of mechanized agriculture.</p>
<div id="attachment_133446"><p><img loading="lazy" src="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn-150x150.jpg" alt="" width="150" height="150" srcset="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn-150x150.jpg 150w, https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn.jpg 300w" sizes="(max-width: 150px) 100vw, 150px"></p><p>John Schmeiser.<br><small><i>photo:</i><span> Supplied </span></small></p></div>
<p>But Schmeiser argues that farmers’ right to repair is already entrenched in law in many jurisdictions (including Alberta) as long as the owner is using the equipment for its intended purpose and doesn’t violate manufacturer standards.</p>
<p>The right to repair (R2R) movement (which started in the tech sphere but expanded to other areas, such as ag equipment) is actually a front for promoting the ‘right to modify,’ he said.</p>
<p>Often that means making modifications to bypass environmental controls in order to boost vehicle horsepower.</p>

<p>“There are over 25 states that had R2R bills introduced — every one impacting farm equipment has been defeated,” said Schmeiser. “They haven’t passed&nbsp;because as the state representatives were hearing the rationale coming from R2R advocates, they were finding out that what they were really looking for is to modify the equipment in a manner where&nbsp;it can get around emission standards and violate U.S. Environmental Protection Agency laws and regulations.”</p>
<h2>DEF delete and chipping</h2>
<p>There are two specific actions that concern Schmeiser’s association (a Missouri-based advocacy group for equipment dealerships with a Canadian headquarters in Calgary).</p>
<p>One is circumventing Diesel Exhaust Fluid (or DEF) emissions systems using grey-market ‘DEF delete’ kits to boost horsepower on tractors and combines. Another is ‘chipping’ or ‘tuning,’ which usually refers to adding a specific chip to increase horsepower.</p>
<p>Bypassing emissions control systems contravenes the Canadian Environmental Protection Act, leaving producers open to fines, said Schmeiser, adding he was unsure of the Canadian penalties but breaches of similar U.S. laws have produced fines in excess of $300,000.</p>
<p>Part of the problem is that not everyone knows this practice is illegal. Another is it comes with a host of potential risks including damaged equipment, voided warranties, reduced trade-in value, insurance cancellation and even safety, he said.</p>
<p>“We have seen an unusual number of combine fires this (past) year,” said Schmeiser.</p>
<p>“Now, we have had some dry conditions but in some of those cases the combines were running hotter (due to alterations).</p>

<p>“The insurance company will look at it from the standpoint that you have altered your combine away from the manufacturer’s original standards and you are going to be denied insurance coverage in a situation like that.”</p>
<p>But Siegle isn’t convinced.</p>
<p>He said he has no interest in making such modifications to his equipment and suggested it’s a straw man argument from manufacturing and dealership interests seeking exclusive control over the diagnostic tools.</p>
<p>The kind of modification Siegle is concerned about losing is the legal ability to place, for example, a third-party manufacturer’s custom header on a John Deere combine. Specifically, he worries about big manufacturers denying third-party companies the codes required for an implement to interact with a tractor or combine.</p>
<p>Schmeiser said this isn’t considered modification but rather interoperability or connectivity: A third party designing an implement to attach to another manufacturer’s product. This is a long-standing tradition in the manufacturing and dealership industries that few if anyone has any interest in ceasing, he said (see accompanying story).</p>
<h2>The business aspect</h2>
<p>All of this still does not answer Siegle’s fundamental question: Why can’t I — or mechanics unaffiliated with specific manufacturers — have all the tools required to diagnose and fix a mechanical problem?</p>
<p>In the past it was relatively easy for mechanically minded producers and unaffiliated mechanics to repair machinery because it ran on tried-and-traditional engineering principles. This is still by and large the case, said Schmeiser, adding 95 per cent of equipment issues can still be fixed mechanically.</p>
<p>He said he understands the frustration farmers feel by not having diagnostic tools at their fingertips. But at the same time dealerships have rights as well, especially when one considers the considerable training and expense needed to obtain service contracts with manufacturers.</p>
<p>“What the farmer is speaking to is the frustration of being down. He wants to get up and running as quickly as possible. We get that,” said Schmeiser.</p>
<p>“But the moment the manufacturers start providing special tools or diagnostics&nbsp;equipment to businesses that are outside of their dealer contracts, doesn’t that diminish the value of the contract in the dealer’s eyes as well?… So what’s the incentive for the manufacturer&nbsp;to provide special tools or even service manuals to a third party that would be competing with somebody they have a contractual relationship with&nbsp;(and) who is also making a substantial financial investment to be the representative for the manufacturer?”</p> </div>
</div></div>]]>
            </description>
            <link>https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282642</guid>
            <pubDate>Sat, 27 Feb 2021 04:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mining Ethereum on M1 Mac GPU]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 81 (<a href="https://news.ycombinator.com/item?id=26281864">thread link</a>) | @gyf304
<br/>
February 26, 2021 | https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/ | <a href="https://web.archive.org/web/*/https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-444">

	

	
	<div>
		
<p>TL;DR: It’s possible to mine Ethereum on a M1 Mac GPU. Hashrate is about 2Mh/s.</p>



<figure><img data-attachment-id="452" data-permalink="https://blog.yifangu.com/image-1-5/" data-orig-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png" data-orig-size="1338,754" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=300" data-large-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=750" src="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=1024" alt="" srcset="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=1024 1024w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=150 150w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=300 300w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=768 768w, https://yifangucom.files.wordpress.com/2021/02/image-1.png 1338w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Mining on a M1 Mac</figcaption></figure>



<p>I’ve had my M1 MacBook Air for a bit of time now, and I also recently started mining Ethereum. I can’t help asking myself: What’s Ethereum mining performance like on a M1 Mac?</p>



<p>The obvious thing to do first is to run the off-the-shelf <code>ethminer</code>, which gives the following error:</p>



<pre><code>ethminer 0.19.0-alpha.0
Build: darwin/release/appleclang

Unrecognized platform Apple
Error: No usable mining devices found</code></pre>



<p>Not good. Apparently Apple GPUs are not whitelisted in ethminer. That should be easy to fix. Relevant lines are in <code>libethash-cl/CLMiner.cpp</code>, and I added Apple GPUs to the whitelist, pretending it’s an Intel GPU.</p>



<p>Then <code>boost</code> won’t compile since it’s trying to compile with a <code>-fcoalesce-templates</code> argument, which doesn’t exist in recent clang versions. So I have to update <code>boost</code> to the latest version, and fix relevant <code>asio</code> code since <code>ethminer</code> was using deprecated <code>asio</code> APIs.</p>



<p>I also need to upgrade OpenSSL to the latest version to have it support darwin + arm64.</p>



<p>After getting everything to compile. Here’s the result:</p>



<pre><code>ethminer 0.19.0-17+commit.ce52c740.dirty
Build: darwin/release/appleclang

 i 19:51:36          Configured pool eth-us-east1.nanopool.org:9999
 i 19:51:36          Selected pool eth-us-east1.nanopool.org:9999
 i 19:51:36          Connection remotely closed by eth-us-east1.nanopool.org
 i 19:51:36          Stratum mode : EthereumStratum/1.0.0 (NiceHash)
 i 19:51:36          Established connection to eth-us-east1.nanopool.org [144.217.14.139:9999]
 i 19:51:36          Spinning up miners...
cl 19:51:36 cl-0     Using Device : Intel GPU 0.0 Apple M1 OpenCL 1.2  Memory : 10.67 GB (11453251584 B)
 i 19:51:36          Extranonce set to 778d
 i 19:51:36          Extranonce set to 778d
 i 19:51:36          Authorized worker [REDACTED]
 i 19:51:36          Epoch : 397 Difficulty : 10.00 Gh
 i 19:51:36          Job: c7fc5311… eth-us-east1.nanopool.org [144.217.14.139:9999]
cl 19:51:38 cl-0     Generating split DAG + Light (total): 4.10 GB
 i 19:51:38          Job: 40a57756… eth-us-east1.nanopool.org [144.217.14.139:9999]
cl 19:51:38 cl-0     OpenCL kernel
cl 19:51:38 cl-0     Creating DAG buffer, size: 4.10 GB, free: 6.57 GB
cl 19:51:38 cl-0     Creating light cache buffer, size: 65.62 MB
cl 19:51:38 cl-0     Loading kernels
cl 19:51:38 cl-0     Creating buffer for header.
cl 19:51:38 cl-0     Creating mining buffer
 m 19:51:41          0:00 A0 0.00 h - cl0 0.00
 i 19:51:42          Job: 077b62f6… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:51:46          0:00 A0 0.00 h - cl0 0.00
 i 19:51:46          Job: 2835839e… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:51:51          0:00 A0 0.00 h - cl0 0.00
 m 19:51:56          0:00 A0 0.00 h - cl0 0.00
 i 19:51:57          Job: 97f724e7… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:01          0:00 A0 0.00 h - cl0 0.00
 m 19:52:06          0:00 A0 0.00 h - cl0 0.00
 m 19:52:11          0:00 A0 0.00 h - cl0 0.00
 m 19:52:16          0:00 A0 0.00 h - cl0 0.00
 i 19:52:16          Job: 54df0504… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:21          0:00 A0 0.00 h - cl0 0.00
cl 19:52:22 cl-0     4.10 GB of DAG data generated in 44,060 ms.
 m 19:52:26          0:00 A0 184.16 Kh - cl0 184.16
 m 19:52:31          0:00 A0 1.96 Mh - cl0 1.96
 m 19:52:36          0:01 A0 1.98 Mh - cl0 1.98
 i 19:52:39          Job: d3b1da5e… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:41          0:01 A0 1.99 Mh - cl0 1.99
cl 19:52:43 cl-0     Job: 54df0504… Sol: 0x778d000001d14c71
 i 19:52:43          **Accepted 150 ms. eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:46          0:01 A1 1.95 Mh - cl0 1.95
 m 19:52:51          0:01 A1 2.07 Mh - cl0 2.07
 m 19:52:56          0:01 A1 2.00 Mh - cl0 2.00
 m 19:53:01          0:01 A1 1.98 Mh - cl0 1.98
 i 19:53:01          Job: ccc2b97f… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:53:06          0:01 A1 1.97 Mh - cl0 1.97
 i 19:53:07          Job: 23919d82… eth-us-east1.nanopool.org [144.217.14.139:9999]
^C i 19:53:10 main     Got interrupt ...
 i 19:53:10 main     Disconnected from eth-us-east1.nanopool.org [144.217.14.139:9999]
 i 19:53:10 main     Shutting down miners...
 i 19:53:16 main     Terminated!</code></pre>



<p>Code is available at <a rel="noreferrer noopener" href="https://github.com/gyf304/ethminer-m1" target="_blank">https://github.com/gyf304/ethminer-m1</a></p>



<h2>Is it worth it?</h2>



<p>Um. Not really. At current Ethereum prices (2021-02-26), it generates $0.14 of profit per day. It’s still a profit, but very miniscule.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281864</guid>
            <pubDate>Sat, 27 Feb 2021 01:32:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Every thought about personal finance I've ever had, as concisely as possible]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 81 (<a href="https://news.ycombinator.com/item?id=26281108">thread link</a>) | @aadillpickle
<br/>
February 26, 2021 | https://blog.aadilali.com/posts/personal-finance.html | <a href="https://web.archive.org/web/*/https://blog.aadilali.com/posts/personal-finance.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><nav id="63540a58-887b-43a8-802f-008032cf227a"></nav><p id="96dbe6a8-0b25-43a2-88b6-ca4688f23134"><em>NOTE: LITERALLY ZERO OF THIS IS FINANCIAL ADVICE!!! DO YOUR OWN RESEARCH!!!</em></p><h3 id="f7ffa1c1-d40e-4aac-9101-563cb5c43efd">1. Before you even think about investing, start with the personal finance fundamentals</h3><ol id="636ca7eb-6ddd-4d2a-96ee-02cfda1b58ac" start="1"><li>Pay down any debts greater than 7% per year (7% is the average yearly return for the stock market)<ul id="a08592f8-ef0a-4b25-ae93-4cb5bd4f0e54"><li>Don't even think about investing until you do this, not being charged 15% a year in interest and penalties on credit card debt gives you a 2x higher return than the average investor</li></ul></li></ol><ol id="338f55be-2d71-474c-9360-54ee494b18e1" start="2"><li>If you have the space, buy products you're guaranteed to use in bulk on sale<ul id="3b530a5d-4653-4853-983a-ccb62d628437"><li>Buying years supply of toilet paper on sale at $100 instead of $200 means a 100% rate of return - 14x the average investor</li></ul></li></ol><ol id="d22a6401-3bc3-4754-be17-d40a2fba6213" start="3"><li>Reconsider your spending habits (i.e. cut up your credit cards, return things you don't need, uninstall the amazon app and <a href="https://getcoldturkey.com/">block all the online shopping websites</a>)<ul id="e74e9c24-39de-43cf-878a-e8fb7716f238"><li>The reason you don't have money might not be because you're losing it to inflation, it's because you're losing it to $4 cups of coffee <ul id="844e56f6-5a8c-40a2-b980-b06ece4f69c4"><li>In fact, you're probably losing ~$1000 a year - if you invested that, you could have ~$650K in 40 years:<figure id="4f73cb39-38e2-423e-9c4e-714ef03e4350"><a href="https://blog.aadilali.com/posts/Every%20thought%20about%20finance%20I've%20ever%20had,%20as%20conc%204f73cb3938e2423e9c4e714ef03e4350/pfin.png"><img src="https://blog.aadilali.com/posts/Every%20thought%20about%20finance%20I've%20ever%20had,%20as%20conc%204f73cb3938e2423e9c4e714ef03e4350/pfin.png"></a></figure></li></ul></li></ul></li></ol><h3 id="7c5be926-1109-48eb-8caf-7d8768f42a8e">2. When you should (and shouldn't) buy things</h3><p id="0c7ad9de-777a-444b-a703-e2fd64c6a748">Buy things if they:</p><ol id="fb66b42a-e007-4f54-92ee-0125704a9790" start="1"><li>Spark joy, especially when buying for someone else — the emotional ROI of gift-giving is off the charts.</li></ol><ol id="61953c5a-f373-460a-8c86-a1df20760a17" start="2"><li>Get used everyday (Ex. Nice pants, laptop and phone).</li></ol><ol id="38edd8a2-4d00-455e-90c4-351dfb0e2b8b" start="3"><li>Come in between you and the ground (Ex. Mattresses, chairs, winter tires).</li></ol><ol id="dce98e87-6a65-4304-994a-fbaf12c1e596" start="4"><li>Make your life &gt;1% easier (Ex. Good cookware/knives, tools, software).</li></ol><ol id="d6357926-602c-4450-aad9-c53bee4d4845" start="5"><li>Make you better (Ex. Education, gym memberships, travel).</li></ol><p id="dccfbf19-9ddc-4278-b1e6-b8dfa92d77b8">Don't buy things if:</p><ol id="2bb2a4df-bd52-4d81-bb3d-4f34d2a515fd" start="1"><li>You pretty much already own them (Ex. The newest iPhone if you have the last gen already, anything limited edition that won't appreciate in value, cars unless somethings wrong with them).</li></ol><ol id="e14026b6-6d57-439c-baef-b19bf5115bc9" start="2"><li>They're "on sale" — by all means try to get a good deal but sometimes products "on sale" were the same price last month and you just didn't see it, use a price tracker like <a href="https://camelcamelcamel.com/">camelcamelcamel.com</a> to avoid this and make sure you're actually getting a good deal for something you will actually use. Marketing people get paid millions to make you buy things you don't need with money you don't have - outsmart them.</li></ol><ol id="2a9c7b05-6a47-4be0-a8ff-e642252f11d6" start="3"><li>They're cheap — inexpensive and cheap mean 2 different things here but generally look for quality items with lifetime warranties, 1 coat that costs $1000 but lasts 30 years has better ROI than buying a $100 coat every other year. Plus it's less mental strain since you don't have to think about replacing it and you'll get to use something you actually like.</li></ol><ol id="37763a48-4232-460c-86f0-87dcb651fea1" start="4"><li>They're heavily advertised to you — more money spent on marketing means a higher price for you since you're not just paying for the product but the salaries of the people hired to sell/advertise it to you.</li></ol><ol id="f7b4a249-f8bd-4ae4-8fb2-2329bd1b01b6" start="5"><li>You can't afford it! Treat your credit card like a debit card and even then make sure it doesn't dip below an uncomfortable balance.</li></ol><h3 id="2e2f2deb-32bc-4e8d-be04-8a43469e6060">3. Legal tax evasion strategies</h3><p id="31a30907-dbb4-4d92-a98f-4adcdc753115">There are a few ways to legally pay less taxes that the average joe usually isn't aware of. </p><p id="0dff2cad-cfef-4b44-9f44-8577b867fd68">If you have a company, incorporated or not, you can write off lots of things as business expenses like transportation, buying new equipment or rent for co-working spaces. It's also not that hard to start a company — if you're a freelancer, call yourself a consultant and start a "consulting firm" or start an e-commerce store and call yourself a sole-proprieter. Then you can hire a family member, deduct home office expenses and even if you lose money operating the business, you'll save money on taxes. </p><p id="3b719889-6616-4458-94ca-655d168fe3d5">Investing in your government's version of a retirement savings plan is tax deductible against your personal income. So are losses from the stock market. So is charitable giving!</p><p id="62423246-e396-4a48-a5de-a2435a7b19e6">Always try to max out tax free investment accounts/retirement accounts — even if you think it's not worth it the taxes breaks alone mean you come out ahead, even better if your employer matches your contributions. And at the very least, not being able to withdraw for a few decades means you'll be in it for the long run and the market always goes up in the long run.</p><h3 id="93a74cf1-8c77-4182-9946-e91424039ed0">4. <strong>Investing the 80/20 way</strong></h3><p id="05897fe9-4a0e-47d4-8df2-cd910fe40f75">For traditional investing, I try to maximize output and minimize effort. I only use 1 app: Wealthsimple Trade. </p><p id="919727c6-9844-4e45-9aaf-173cb2c3689c">Wealthsimple Trade is like a broker — they let you buy stocks, ETFs, mutual funds, etc., all with $0 fees. They make money from charging a 1.5% currency conversion fee — you can only hold CAD in your account but have to buy US equities with USD and when you sell holdings in USD your balance is credited with CAD. $0 fees are not typical for a brokerage but the currency exchange fees are a killer so I try to only buy Canadian equities. Sometimes I can't resist and I'll run a YOLO on GME - this is more common than I'd like to admit.</p><p id="6dc5cb83-3b1e-410c-b972-d95b9797fc56">Since I'm young, have a job, live at home and can take lots of financial risk, my net worth is divided up roughly as follows (in order of volatility):</p><ul id="467c8446-9ec7-43ad-8b1f-1791cdd43b52"><li>35.5% virtual NBA trading cards</li></ul><ul id="bf81caae-aa42-4c95-a52c-5b3ddf5d07f8"><li>1% Cryptocurrency</li></ul><ul id="8b770356-e3fd-4fb1-ad38-bc3c816dc0d9"><li>33.3% individual stocks I picked (mostly tech companies, this is basically gambling)</li></ul><ul id="5cdbf0f9-7f1d-472a-92ce-9b2b01f7f923"><li>7.1% tech ETFS (ZQQ, ARKK)</li></ul><ul id="4ce7e8fa-3420-4f06-be9d-3418a842c2fd"><li>21.6% whole market ETFs (VSP.TO, VTI, EEMV)</li></ul><ul id="12e4ffe2-10d1-409e-b40a-cf0726ac9eb5"><li>1.5% cash</li></ul><p id="b48787d4-7850-4d49-9104-2819465bd622">This portfolio was made when I was young and stupid. I do not recommend this for anyone and am slowly selling off my more risky positions and buying more into whole market ETFs. It also makes no sense that I'm so heavily invested in the tech sector while working in tech - if that industry goes to shit I'll be doubly ruined. I'm just sharing this for full disclosure since you should know who you're in business with while reading this. Do as I say, not as I do. </p><p id="ddde7cc2-1ab0-4ced-8353-1fe79f450c38">For most investors under 30 who have a similar financial and risk profile as me but aren't as insane, I'd recommend the following steps:</p><ul id="ecc17c23-5127-4155-99d6-30a736287057"><li>Open up a $0 fee trading account - likely Wealthsimple Trade or QuestTrade in Canada, Robinhood in the States</li></ul><ul id="05d79173-10cf-4145-9713-6bb38ced3c08"><li>Deposit a certain % of your paycheque every time you get it and try to maintain a certain ratio of risky investments to safe ones - consistently depositing $500 every month is way better than $10 000 at one time, <a href="https://www.investopedia.com/terms/d/dollarcostaveraging.asp#:~:text=Dollar%2Dcost%20averaging%20(DCA)%20is%20an%20investment%20strategy%20in,volatility%20on%20the%20overall%20purchase.&amp;text=Dollar%2Dcost%20averaging%20is%20also%20known%20as%20the%20constant%20dollar%20plan.">trust me</a></li></ul><ul id="4df5cac9-c4f4-42ae-8c3e-711a751152fd"><li>I believe inflation is worse than market volatility and the market has always gone up and likely will continue to. For that reason, I recommend the following allocation for your investing money:<ul id="4d3ce485-0523-4605-afe5-c97bacc99497"><li>40% in a whole market fund - something that tracks a lot of high quality stocks and moves in the direction of the entire stock market every day (ex. VRGO, SPY)</li></ul><p id="36533864-3c86-44f4-8bbe-144d15b97ab3">The rest is based on your risk tolerance:</p><ul id="2599b8be-90db-47ad-8ea9-151e9b7b538d"><li><details open=""><summary>Risky (in order of ascending risk): </summary><ul id="6a974d7a-0e47-4fa1-ad6f-226fd0949462"><li>20-30% in a tech sector ETF (I like QQQ/ZQQ, ARKK and ARKW)</li></ul><ul id="24e9d83b-a18d-489a-a7dd-9a8450856b2f"><li>15-20% in individual stocks (this is basically blackjack)</li></ul><ul id="5f3b11bd-9b9f-4ebb-9293-724fea03a1a7"><li>5-10% in cryptocurrency (this is basically roulette)</li></ul><ul id="d8860df2-13af-47d9-816c-dcbe43ecb54e"><li>10-20% in cash</li></ul></details></li></ul><ul id="b9d7004e-e41f-4eda-a330-dbc5d5d13da4"><li><details open=""><summary>Conservative:</summary><ul id="6338a2a9-ded0-4731-ac23-9de34ba326ba"><li>Another 20-40% in in a whole market fund</li></ul><ul id="3d919383-87af-4291-86b0-1e4a6cb790ba"><li> 10-20% in a tech ETF (or pick a more stable industry like banking/energy)</li></ul><ul id="6db6640c-7c77-446b-bd0a-a67883caa04f"><li>10-20% in an ETF tracking bonds</li></ul><ul id="8dc7967e-2184-4ccb-a303-f9f0bf0be1c7"><li>10-20% cash</li></ul><ul id="2e285b82-ee2e-40d1-a547-46ae9a3c3dad"><li>0-5% gold</li></ul></details></li></ul></li></ul><p id="7ca5d98c-014c-4654-8ccc-6e333334b9b8">Some other things to remember:</p><ul id="9225f5e9-eb42-4d81-945f-39e312b14045"><li>Wherever you're investing, keep it consistent and comfortable — it's better to invest 20% of your salary every month and never withdraw than depositing $10000 sporadically when "you see an opportunity"<ul id="ab8e384c-f4a5-4b48-8075-9041ce3ed137"><li>You'll have cash when you need it — if something happens and all your money is tied up in investments, you have to withdraw no matter what → the stock market may always go up in the long run but it fluctuates in the short run, if you need money immediately you may need to sell while you're at a loss.</li></ul></li></ul><ul id="1321b660-f49d-4127-9920-56410f7d3fa5"><li>Keep your personal wellbeing above all<ul id="6e47ce6d-42d0-4836-8a06-ab17b09af564"><li>I have a low appetite for risk when it comes to things I don't understand — that's why I'll never trade on margin, trade options or invest more than 40% of my portfolio in one equity, the possibility of losing all my money would keep me up at night and wouldn't be worth the potential financial upside.</li></ul><ul id="32700e60-6458-4a6a-a801-8318377ba405"><li>I keep less cash on hand because I don't need to buy things very often - you may the opposite in that case your asset allocation will look different from mine - the most important thing is just beating inflation by getting at least 2-4% return (ideally more).</li></ul></li></ul><ul id="6f4d5ce0-26bb-480e-b466-30deb7b0ff0d"><li>Don't over-optimize<ul id="29ad34f1-b279-4417-971b-b2c6e3be98e8"><li>The average person doesn't need to spend hours researching trading strategies or comparing fees for different investment platforms. Spend that time making more money to invest.</li></ul><ul id="56117fd6-92da-4ee1-91ee-228fd20c3118"><li>Just get your money into an investment account. It's literally losing value to inflation by sitting in your 0.00001% annual return savings account or in your mattress.</li></ul></li></ul><ul id="07c2820c-b3c4-4316-b808-4b5f64405b35"><li>Investing is actually 90% saving and 10% all of the sexy things people normally associate with "investing". Always make more than you spend.</li></ul><h3 id="bb0a9476-8011-49e8-9941-25daf83f7d51">5. <strong>My tech stack (aka the section with my referral codes)</strong></h3><ol id="368ae0b9-15f6-488c-92ae-093d7beda66e" start="1"><li>Wealthsimple Trade: I use this everyday and it powers most of my investments — <a href="https://my.wealthsimple.com/app/public/trade-referral-signup?code=OJCS_A">my referral gives you $10 to invest</a> (after investing $100).</li></ol><ol id="add28728-e360-4118-8ac7-bc60741f1f61" start="2"><li>Newton: This is where I buy crypto, best app in Canada - <a href="https://web.newton.co/r/66UJ16">my referral gives you $25</a> (after investing $100).</li></ol><p id="a7125418-57fa-4791-8e37-29dd0fbbb3dc">-AA</p><hr id="c2406a8a-6a85-4d4f-85c5-9e057b0c749b"><p id="ce82f288-c85b-4d43-a343-a6065ffdd874"><em>Thanks for reading! Let me know if you have any questions via twitter </em><em><a href="https://twitter.com/aadillpickle">@aadillpickle</a></em><em> - I'd be happy to help!</em></p><p id="3a2e7255-b50a-4bb6-a39e-e2de8b1da195"><em>And if you found this tutorial particularly useful, consider </em><em><a href="https://www.buymeacoffee.com/aadillpickle">buying me a coffee</a></em><em> ☕️.</em></p></div></div>]]>
            </description>
            <link>https://blog.aadilali.com/posts/personal-finance.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281108</guid>
            <pubDate>Fri, 26 Feb 2021 23:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Land – Living Off Grid With No Money]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26281103">thread link</a>) | @SQL2219
<br/>
February 26, 2021 | https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html | <a href="https://web.archive.org/web/*/https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>If you are like me, the biggest obstacle to the dream of living off grid is money. Today, I thought I would help out wannabe homesteaders by gathering together tips for living off grid without money, some you probably haven’t seen before.</p><p>How to live off grid with no money:</p><ul><li><strong>Get yourself a piece of free or low-cost land (4 methods below)</strong></li><li><strong>Build a free home</strong></li><li><strong>Gather and grow naturally abundant foods</strong></li><li><strong>Purify available water for free — no wells to dig</strong></li><li><strong>Set up dirt cheap (free) waste disposal</strong></li><li><strong>Bonus: Find a free living community</strong></li></ul><p>Despite what advertisers, builders, and real estate agents might want you to believe, there are actually many ways to get off grid with out much cost. It all depends on how much work you are willing to put in, and being able to think outside the box.</p><h2 id="getting-land-for-no-money">Getting Land for No Money</h2><p>Free land is still out there and still available. Right now there are many out of the way towns and villages offering plots free or basically free if you are willing to live there. Out in the country, there also opportunities for farm caretakers or land contract deals that will not be advertised online. You have to know where to look. Lastly, there are many tracks of land sitting, unused, that could be yours for <strong>free</strong>, using the unknown law called “adverse possession” that exists in some form in all 50 states!</p><div><div><h5>Free Off Grid Guide</h5><p>Thinking about going off grid? Receive the 30+ page PDF that helps you get there! My gift to you.</p><p><small>You will receive your free guide, exclusive discounts, and occasional announcements</small></p></div></div><h3 id="free-land-in-the-us">Free Land in the US</h3><p>While the original homesteading act is no longer on the books, there are many remote cities in the US that are offering free and, usually in exchange for building a home and living in that city for a set period of time. Here is a list of all the towns in the US offering free land for living there:</p><ul><li><a href="http://www.beatrice.ne.gov/dept/city/attorney/homestead.php">Beatrice, Nebraska</a></li><li><a href="https://www.buffalony.gov/306/Urban-Homestead-Program">Buffalo, New York</a></li><li><a href="https://www.curtisnebraska.com/copy-of-medicine-valley-economic-de">Curtis, Nebraska</a></li><li><a href="http://www.elwoodnebraska.com/Wheatfield1.pdf">Elwood, Nebraska</a></li><li><a href="http://www.lincolnks.org/Housing.html">Lincoln, Kansas</a></li><li><a href="http://www.loupcity.com/business/housing/john-subdivision/">Loup City, Nebraska</a></li><li><a href="https://www.mankatoks.com/free-land">Mankato, Kansas</a></li><li><a href="https://www.manillaia.com/">Manilla, Iowa</a></li><li><a href="https://www.marneiowa.com/marne-free-lots/">Marne, Iowa</a></li><li><a href="http://www.marquettekansas.com/land.html">Marquette, Kansas</a></li><li><a href="https://www.cityofnewrichlandmn.com/index.asp?SEC=E4182CA2-FBE7-4271-89BD-2907B9067956&amp;Type=B_BASIC">New Richland, Minnesota</a></li><li><a href="http://www.discoverosborne.com/ECONOMICDEVELOPMENT/BusinessIncentives.aspx">Osborne, Kansas</a></li><li><a href="http://rookscounty.net/free_homesites">Plainnville, Kansas</a></li></ul><h3 id="free-land-in-canada">Free Land in Canada</h3><p>Being the world’s second largest country yet with only 37 million people (just over 1/10th the United State’s population), Canada is interested in getting more people to live in their many underpopulated rural regions. Right now, there are countless small towns looking for people to move in, in exchange for free or practically free (eg $10/acre) land.</p><p>Many of these deals stipulate that you build a home within a set amount of time, in order to get the free land. But read the section on low cost housing below to see how you might be able to get that done on your own for free.</p><p>Here are some towns and regions in Canada offering free land:</p><ul><li><a href="https://www.cbc.ca/news/canada/new-brunswick/new-brunswick-straw-house-community-offers-free-land-1.2765195">New Brunswick Strawhouse Community</a></li><li><a href="https://www.albertafarmexpress.ca/2016/12/05/the-lure-of-free-land-is-drawing-in-a-new-type-of-homesteader/">St-Louis-de-Blandford, Quebec</a></li><li><a href="http://rmofpipestone.com/main.aspx?CategoryCode=BE0B3259-5572-4DEA-9D08-6072C1F49D90&amp;pageCode=2DB56BC7-F94C-4DE9-A71C-C7E5E9EE352A&amp;subPageCode=6EC9A94F-F258-4746-8369-FECB852B7AEA">Pipestone, Manitoba</a></li><li><a href="https://www.cbc.ca/news/canada/manitoba/manitoba-rm-looks-to-sell-ghost-town-lots-for-10-1.2086700">Scarth, Manitoba</a></li><li><a href="http://www.back2land.ca/">South Knowlesville Community Land Trust, New Brunswick</a></li><li><a href="https://www.mundare.ca/Business-Opportunity">Mundare, Alberta</a></li><li><a href="https://www.thefarmersdaughtercountrymarket.ca/employment">Free Land for Working in Wycocomagh, Cape Breton</a></li><li><a href="https://yukon.ca/en/apply-agriculture-land#getting-public-land-for-agriculture">Free Land in the Yukon</a></li><li><a href="http://www.greenenergyfutures.ca/episode/craik-eco-village">Craik Eco-Village , Saskatchewan</a> (ecovillage website not up at time of writing, but community may still be in operation)</li></ul><p>Also, crown land in Canada (land owned by the government) allows people to live there free for 6 weeks at a time, after which time you would have to move on. This could be a perfect free way for a yurt, RV, or portable tiny home dweller to live free of rent.</p><h3 id="cheap-land-and-free-money-in-alaska"><span data-ez-name="offgridpermaculture_com-large-leaderboard-2"></span>Cheap Land and Free Money in Alaska</h3><p>Long one of the last bastions of truly untouched wilderness, Alaska is still one of the freest states in the Union and one of the most beautiful places in the world. While not free up front, <a href="https://dnr.alaska.gov/mlw/landsales">the Alaskan government routinely sells cheap land</a> over the counter as well as through periodic auctions.</p><h4 id="free-money-for-living-in-alaska">Free Money for Living in Alaska</h4><p>While not initially free, establishing residency in Alaska makes you eligible to receive the annual <a href="https://pfd.alaska.gov/">Permanent Fund Dividend</a>. Last year’s dividend was <a href="https://www.adn.com/alaska-news/2019/09/27/this-years-alaska-permanent-fund-dividend-1606/">$1,606 per person</a> including dependents and children. <strong>So a household of five would have seen a $8030 payment this year.</strong> The amount paid depends on how much money Alaska is making, and thus the economy, but the dividend payout has been between about $1,000 – $2,000 per person in recent memory.</p><p>For a family who lives frugally and attempts to produce most of their food off grid through hunting would be able to pay of their off grid land purchase in only a few years.</p><figure><img alt="Subsistence Fishing in Alaska" height="393" src="https://offgridpermaculture.com/img/subsistence_fishing_alaska_salmon.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/subsistence_fishing_alaska_salmon.jpg"></figure><h4 id="subsistence-hunting-and-fishing-licenses">Subsistence Hunting and Fishing Licenses</h4><p>Residents of Alaska also get <a href="https://www.adfg.alaska.gov/index.cfm?adfg=residentfishing.main">special privileges concerning hunting and fishing rights</a>. This includes practices such as net fishing for Salmon and subsistence hunting that are not possible in other states. When I lived in Alaska, it was rare to find a home without a chest freezer packed with salmon and moose meat caught for free.</p><p><span data-ez-name="offgridpermaculture_com-leader-1"></span>For those of you haven’t spent time in Alaska the remoteness of the land and ferocity of the cold weather may astonish you. Likewise, the cost of necessities such as gas and food is well above most regions of United States. So be careful if you decide to go up there. However, for many of my readers, Alaska might just be the perfect spot.</p><h3 id="usda-farm-grant-and-loan-program">USDA Farm Grant and Loan Program</h3><p>No money, but interested in opening a functioning off grid farm? <a href="https://www.usda.gov/topics/farming/grants-and-loans">USDA Grants &amp; Loans</a> has programs to provide money for family size farms as well as a program specifically for new farms.</p><p>In exchange for accepting these funds you will be obligated to attempt to start a farm that conforms to the USDA’s standards of farming. But, for looking to get started with their own off grid agriculture business, these programs could be perfect for you.</p><h3 id="farm-caretaker">Farm Caretaker</h3><p>One way to get started off grid for no money is to become a <a href="https://www.motherearthnews.com/homesteading-and-livestock/farm-caretaker-zmaz76mjztak">Farm Caretaker</a>. Farm care taking is a free rent situation where you work in exchange for free rent. And, can often be a longer term arrangement, lasting years if you choose.</p><p>With labor in rural farm lands at an all time low, and children of farming families moving to the city, there are many farms out there that are looking for people to watch over them. Depending on the situation, some owners may ask you to work part time on the farm — tending livestock and the like — while others may just want someone around to keep an eye on the place and do occasional maintenance work.</p><p>You will not find offers for farm care taker advertised online or on job sites. and will have to search for your own opportunities. Try posting an add on Craigslist, Facebook local forums, or in regional newspapers with good rural distribution. Explain clearly and quickly what you are looking for and what you plan to offer in return.</p><h3 id="land-contract">Land Contract</h3><p>Undeveloped land is not easily financed or mortgaged by banks, which makes land contracts, also known as owner carry, very common practice for purchasing off grid land. A land contract is an agreement between the buyer and seller that you will pay off the purchase over time at a set rate, and at the end of the contract you become the full owner of the land.</p><p>Essentially, the seller becomes the bank.</p><h4 id="finding-no-down-land-contracts">Finding No Down Land Contracts</h4><p>While land contracts typically require a 10% – 20% down payment, finding a motivated owner through direct contact gives you the opportunity to negotiate for a zero down or work exchange situation. See my article <a href="https://offgridpermaculture.com/Finding_Land/How_to_Find_Off_Grid_Land_Ways_You_Havent_Heard_Of.html">“How to Find Off Grid Land - Ways You Haven’t Heard Of”</a> for details on how to find and contact motivated sellers not yet on the market.</p><h4 id="local-businesses-that-sell-land">Local Businesses that Sell Land</h4><p>Another no down option would be to contact <a href="https://www.classiccountryland.com/blog/become-a-land-owner-with-no-down-payment-or-fees">small companies that specialize in off grid properties</a>. Some have special deals for no down payment parcels, while others might be amenable to negotiating special terms. Also, if you are in a lumber producing area, search for local timber investment firms. I have found firms that sell off grid “timber land” with land contracts, and may be willing to provide good terms on parcels of land that they consider unproductive.</p><p>Land contracts are well established legally, generally safe for both parties. However, be wary if you sign one, because failure to pay timely payments or follow through with the contract usually results in the buyer losing the property and anything they paid up to that point.</p><figure><img alt="Map of Adverse Possession Laws in the US" height="450" src="https://offgridpermaculture.com/img/adverse_possession_free_land_laws_in_the_us_by_state.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/adverse_possession_free_land_laws_in_the_us_by_state.jpg"></figure><h3 id="adverse-possession">Adverse Possession</h3><p>One legal concept for acquiring land that you probably haven’t heard of before is <a href="https://en.wikipedia.org/wiki/Adverse_possession#United_States">adverse possession</a> or “squatter’s rights”. What they are is the right to claim ownership of a piece of land that you have been openly living on it for a certain amount of time (see above map), between 5 – 30 years depending on your state.</p><p>The idea of these laws are that vacant pieces of land where, the owner is completely absent, should go to someone who is putting it to good use. What that means in practice varies form state to state. Every state in the US has some form of adverse possession.</p><p>Adverse possession does not mean you have the right to live on a piece of property if you have been asked to leave. The legal owner can ask you to leave at any time. Ultimately, it can be a gamble, since you <strong>must live on the land without the owner’s permission in order to claim adverse possession.</strong></p><p>EDIT: More info on adverse possession and squatters rights, including a state by state breakdown of the laws, can be found here —</p><ul><li><a href="https://offgridpermaculture.com/Finding_Land/How_to_Homestead_on_Abandoned_Property_Is_It_Legal.html">How to Homestead on Abandoned Property | Is It Legal?</a></li></ul><h2 id="low-cost-or-no-cost-off-grid-housing">Low Cost or No Cost Off Grid Housing</h2><p>The next big hurdle to get started living off grid is housing. While some of the options provided above may come with a living arrangement, there are may free or low cost ways to live comfortably off the grid.</p><p>Homes are usually the mainstream family’s biggest expense, but if you are willing to work and to live conservatively, a dept free or even plain free home is within your grasp. Building a tiny home is well within the skills of most people with minimal training. And, they can be built quickly and cheap or free depending on your building material foraging skills. There are also may natural building styles like cob building, light straw clay, earth bag, and straw bale that can be build largely from earth already on site, and can last for generations.</p><figure><img alt="Tiny Home Living for Free" height="400" src="https://offgridpermaculture.com/img/tiny_home_living_off_grid.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/tiny_home_living_off_grid.jpg"></figure><h3 id="tiny-home-from-recycled-materials">Tiny Home from Recycled Materials</h3><p>With the tiny home craze growing every year, there are many places to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html">https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html</a></em></p>]]>
            </description>
            <link>https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281103</guid>
            <pubDate>Fri, 26 Feb 2021 23:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PicoCAD: A tiny modeller made in PICO-8]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26280141">thread link</a>) | @leafo
<br/>
February 26, 2021 | https://johanpeitz.itch.io/picocad | <a href="https://web.archive.org/web/*/https://johanpeitz.itch.io/picocad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>A tiny modeller for tiny models</h3>
<p>picoCAD is a program to build and texture lowpoly 3D models. Where many programs for modelling and texturing are&nbsp;bloated and overly complicated, picoCAD aims to make it fun, easy, and accessible by focusing on the&nbsp;bare essentials.&nbsp;It is built on the PICO-8 platform and comes rich with constraints.&nbsp;Experiment to find your own workflow and anything is possible!</p>
<h3>Features</h3>
<ul><li>Streamlined and easy to use editor</li><li>Place and modify&nbsp;meshes to create amazing things</li><li>Live manipulation of textures and UV coordinates&nbsp;</li><li>A unique look with picoCAD's dithered shading</li><li>Render in wireframe, solid fill, or textured</li><li>All save files in easy to read text format</li><li>Exports&nbsp;Twitter friendly GIFs</li><li>Ships with a manual that is worth reading</li></ul>
<h3>Get involved</h3>
<p>Check out our&nbsp;<a href="https://discord.gg/hjXMammbPB" rel="nofollow noopener">discord</a> for help, as well as&nbsp;cool stuff built by the community.</p>
<p>The&nbsp;<a href="https://twitter.com/search?q=%23picoCAD" rel="nofollow noopener">#picoCAD</a>&nbsp;on Twitter is also a good place to browse the latest and greatest.</p>
<h3>Have fun</h3>
<p>I&nbsp;hope you'll have a good time using picoCAD! If you find it useful, please consider donating - thanks! &lt;3&nbsp;</p></div></div>]]>
            </description>
            <link>https://johanpeitz.itch.io/picocad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280141</guid>
            <pubDate>Fri, 26 Feb 2021 21:39:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Road to Common Lisp (2018)]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279468">thread link</a>) | @Tomte
<br/>
February 26, 2021 | https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/ | <a href="https://web.archive.org/web/*/https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-blog-entry"><article><p>Posted on August 27th, 2018.</p><p>I've gotten a bunch of emails asking for advice on how to learn Common Lisp in
the present day.  I decided to write down all the advice I've been giving
through email and social media posts in the hopes that someone might find it
useful.</p>

<p>One disclaimer up front: this is <em>a</em> road to Common Lisp, not <em>the</em> road to
Common Lisp.  It's what I followed (without some of the dead ends) and has
a <em>lot</em> of my personal opinions baked in, but it is by no means the only way to
learn the language.</p>

<p>This post has been translated into
<a href="https://gist.github.com/y2q-actionman/49d7587912b2786eb68643afde6ca192">Japanese</a>.
I can't vouch for the accuracy of any translations.</p>

<ol><li><a href="#s1-context">Context</a><ol><li><a href="#s2-history">History</a></li><li><a href="#s3-consequences">Consequences</a><ol><li><a href="#s4-escaping-the-hamster-wheel-of-backwards-incompatibility">Escaping the Hamster Wheel of Backwards Incompatibility</a></li><li><a href="#s5-practicality-begets-purity">Practicality Begets Purity</a></li><li><a href="#s6-extensibility">Extensibility</a></li><li><a href="#s7-power">Power</a></li><li><a href="#s8-ugliness">Ugliness</a></li></ol></li></ol></li><li><a href="#s9-a-road-to-learning-common-lisp">A Road to Learning Common Lisp</a><ol><li><a href="#s10-get-a-lisp">Get a Lisp</a></li><li><a href="#s11-pick-an-editor">Pick an Editor</a></li><li><a href="#s12-hello-lisp">Hello, Lisp</a></li><li><a href="#s13-a-gentle-introduction">A Gentle Introduction</a></li><li><a href="#s14-getting-practical">Getting Practical</a></li><li><a href="#s15-make-something">Make Something</a></li><li><a href="#s16-lisp-as-a-system">Lisp as a System</a></li><li><a href="#s17-learning-paradigms">Learning Paradigms</a></li><li><a href="#s18-switch-things-up">Switch Things Up</a></li><li><a href="#s19-recipes-for-success">Recipes for Success</a></li><li><a href="#s20-final-patterns">Final Patterns</a></li></ol></li><li><a href="#s21-where-to-go-from-here">Where to Go From Here</a><ol><li><a href="#s22-macros">Macros</a></li><li><a href="#s23-object-oriented-programming-with-clos">Object-Oriented Programming with CLOS</a></li><li><a href="#s24-low-level-programming">Low-Level Programming</a></li><li><a href="#s25-web-development">Web Development</a></li><li><a href="#s26-game-development">Game Development</a></li><li><a href="#s27-window-management">Window Management</a></li><li><a href="#s28-unit-testing">Unit Testing</a></li><li><a href="#s29-more-implementations">More Implementations</a></li></ol></li><li><a href="#s30-modern-common-lisp">Modern Common Lisp</a><ol><li><a href="#s31-structure">Structure</a><ol><li><a href="#s32-packages">Packages</a></li><li><a href="#s33-systems">Systems</a></li><li><a href="#s34-projects">Projects</a></li><li><a href="#s35-recap">Recap</a></li></ol></li><li><a href="#s36-common-libraries">Common Libraries</a><ol><li><a href="#s37-alexandria">Alexandria</a></li><li><a href="#s38-bordeaux-threads">Bordeaux Threads</a></li><li><a href="#s39-cffi">CFFI</a></li><li><a href="#s40-cl-ppcre">CL-PPCRE</a></li><li><a href="#s41-drakma">Drakma</a></li><li><a href="#s42-iterate">Iterate</a></li><li><a href="#s43-local-time">local-time</a></li><li><a href="#s44-lparallel">lparallel</a></li><li><a href="#s45-named-readtables">Named Readtables</a></li><li><a href="#s46-roswell">Roswell</a></li><li><a href="#s47-series">SERIES</a></li><li><a href="#s48-st-json">st-json</a></li><li><a href="#s49-usocket">usocket</a></li></ol></li></ol></li><li><a href="#s50-good-luck">Good Luck!</a></li></ol>

<h2 id="s1-context"><a href="#s1-context">Context</a></h2>

<p>I think it's important to have a sense of where Common Lisp came from and what
kind of a language it is before you start learning it.  There are some things
that will seem very strange if you're coming straight from modern languages,
but will make more sense if you've got a bit of background context.</p>

<h3 id="s2-history"><a href="#s2-history">History</a></h3>

<p>Common Lisp has a long, deep history.  I'm not going to try to cover it all here
— if you're interested you should check out some of the following (in roughly
increasing order of detail):</p>

<ul>
<li>Wikipedia's <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)#History">History of Lisp</a> and <a href="https://en.wikipedia.org/wiki/Common_Lisp#History">History of Common Lisp</a>.</li>
<li>The <a href="http://www.gigamonkeys.com/book/introduction-why-lisp.html#where-it-began">Where it Began section in Practical Common Lisp</a>.</li>
<li>The <a href="https://www.cs.cmu.edu/Groups//AI/lang/lisp/faq/lisp_2.faq">History: Where did Lisp come from?</a> section of the comp.lang.lisp FAQ.</li>
<li><a href="http://www.nhplace.com/kent/Papers/cl-untold-story.html">Common Lisp: the Untold Story</a> by Kent Pitman.</li>
<li><a href="https://www.dreamsongs.com/Files/HOPL2-Uncut.pdf">The Evolution of Lisp</a> by Guy Steele and Richard Gabriel.</li>
</ul>

<p>I realize you probably won't want to read all of the links above immediately, so
here's a whirlwind tour of sixty years of Lisp.</p>

<p>Lisp began in the late 1950's.  It was invented by John McCarthy at MIT.</p>

<p>Over the next twenty or so years various versions and dialects of Lisp grew and
flourished.  Some of the more notable dialects were Maclisp, BBN Lisp/Interlisp,
Franz Lisp, Spice Lisp, and Lisp Machine Lisp.  There were others too.  The
point is that there were a <em>lot</em> of different implementations, all growing,
changing, and trying out different things.</p>

<p>(Scheme also originated in this time frame, but took a very different route and
diverged from the path we're looking at.  I won't cover Scheme in this post.)</p>

<p>In the early 1980s people decided that having a whole slew of
mutually-incompatible dialects of Lisp might be not be ideal.  An effort was
made to take these different languages that had grown organically and produce
one common language that would satisfy the needs of everyone (or at least
a reasonable subset of "everyone").  In 1984 the first edition of Guy Steele's
<a href="https://www.cs.cmu.edu/Groups/AI/html/cltl/cltl2.html">Common Lisp: the Language</a> was published.</p>

<p>If you do some math you'll see that at the time the book was published Lisp had
around twenty-five years of real-world use, experimentation, experience, and
history to draw upon.  Even so, the book alone didn't quite satisfy everyone and
in 1986 a committee (X3J13) was formed to produce an ANSI specification for
Common Lisp.</p>

<p>While the committee worked on the standardization process, in 1990 the second
edition of Common Lisp: the Language was published.  This was more
comprehensive and contained some of the things the committee was working on
(see the comp.lang.lisp FAQ linked above for more on this).  At this point the
Lisp family of languages had over thirty years of experience and history to
draw upon.  For comparison: Python (a "modern" language many people think of as
also being "kind of old") <a href="https://en.wikipedia.org/wiki/History_of_Python#Early_history">was released</a> for the first time the
following year.</p>

<p>In 1992 the X3J13 committee published the first draft of the new Common Lisp
ANSI standard for public review (see Pitman's paper).  The draft was approved in
1994 and the approved specification was finally published in 1995.  At this
point Lisp was over thirty-five years old.  The first version of Ruby <a href="https://en.wikipedia.org/wiki/Ruby_(programming_language)#First_publication">was
released</a> in December of that year.</p>

<p>That's the end of the history lesson.  There has not been another revision of
the ANSI specification of Common Lisp.  The version published in 1995 is the one
that is still used today — if you see something calling itself "an
implementation of Common Lisp" today, that is the specification it's referring
to.</p>

<h3 id="s3-consequences"><a href="#s3-consequences">Consequences</a></h3>

<p>I wanted to give you a quick overview of the history of Common Lisp because I
want you to know what you're getting yourself into.  I want you to realize that
Common Lisp is a stable, large, practical, extensible, ugly language.
Understanding these characteristics will make a lot of things make more sense
as you learn the language, and I want to talk a little bit more about each of
them before I start offering recommendations.</p>

<h4 id="s4-escaping-the-hamster-wheel-of-backwards-incompatibility"><a href="#s4-escaping-the-hamster-wheel-of-backwards-incompatibility">Escaping the Hamster Wheel of Backwards Incompatibility</a></h4>

<p>If you're coming from other languages, you're probably used to things breaking
when you "upgrade" your language implementation and/or libraries.  If you want
to run Ruby code you wrote ten years ago on the latest version of Ruby, it's
probably going to take some effort to update it.  My current day job is in Scala,
and if a library's last activity is more than 2 or 3 years old on Github I just
assume it won't work without a significant amount of screwing around on my part.
The Hamster Wheel of Backwards Incompatibility we deal with every day is a fact
of life in most modern languages, though some are certainly better than others.</p>

<p>If you learn Common Lisp, this is usually not the case.  In the next section of
this post I'll be recommending a book written in 1990.  You can run its code,
unchanged, in a Common Lisp implementation released last month.  After years of
jogging on the Hamster Wheel of Backwards Incompatibility I cannot tell you how
much of a <em>relief</em> it is to be able to write code and reasonably expect it to
still work in twenty years.</p>

<p>Of course, this is only the case for the language itself — if you depend on any
libraries there's always the chance they might break when you update them.  But
I've found the stability of the core language is contagious, and overall the
Common Lisp community seems fairly good about maintaining backwards
compatibility.</p>

<p>I'll be honest though: there are exceptions.  As you learn the language and
start using libraries you'll start noticing some library authors who don't
bother to document and preserve stable APIs for their libraries, and if
staying off the Hamster Wheel is important to you you'll learn to avoid relying
on code written by those people as much as possible.</p>

<h4 id="s5-practicality-begets-purity"><a href="#s5-practicality-begets-purity">Practicality Begets Purity</a></h4>

<p>Another thing to understand about Common Lisp is that it's a large, practical
language.  The second edition of Common Lisp: the Language (usually abbreviated
as "CLtL2" by Common Lisp programmers) is 971 pages long, not including the
preface, references, or index.  You can get a surprising amount done by writing
pure Common Lisp without much extra support.</p>

<p>When programming applications in Common Lisp people will often depend on
a small(ish) number of stable libraries, and library writers often try to
minimize dependencies by utilizing as much of the core language as possible.
I try to stick to fewer than ten or so dependencies for my applications and no
more than two or three for my libraries (preferably zero, if possible), but I'm
probably a bit more conservative than most folks.  I <em>really</em> don't like the
Hamster Wheel.</p>

<p>It's also worth noting that since Common Lisp has been around and stable for so
long, it has <em>libraries</em> older and more stable than many programming languages.
For example: Bordeaux Threads (the de-facto threading library for Common Lisp)
was first proposed in 2004 and released soon after (2006 at the latest but
possibly earlier, it's hard to tell because so many links are dead now), which
makes it about fourteen years old.  So yes, threading is handled by a library,
but I'm not worried about it breaking my code in the next decade or two.</p>

<p>My advice is this: as you learn Common Lisp and look for libraries, try to
suppress the voice in the back of your head that says "This project was last
updated six years ago?  That's probably abandoned and broken."  The stability of
Common Lisp means that sometimes libraries can just be <em>done</em>, not <em>abandoned</em>,
so don't dismiss them out of hand.</p>

<h4 id="s6-extensibility"><a href="#s6-extensibility">Extensibility</a></h4>

<p>Part of Common Lisp's practicality comes from its extensibility.  No one has
been clamoring for a new version of the specification that adds features
because Common Lisp's extensibility allows users to add new features to the
language as plain old libraries, without having to alter the core language.
Macros are what might come to mind when you hear "Lisp extensibility", and of
course that's part of it.  Macros allow users to write libraries that would
need to be core language features in other languages.</p>

<p>Common Lisp doesn't include string interpolation.  You want it?  No problem, you
don't have to wait for <a href="https://docs.scala-lang.org/overviews/core/string-interpolation.html">Scala
2.10</a> or
<a href="https://www.python.org/dev/peps/pep-0498/">Python 3.6</a>, just <a href="https://edicl.github.io/cl-interpol/">use
a library</a>.</p>

<p>Want to try some nondeterministic programming without any boilerplate?  <a href="https://nikodemus.github.io/screamer/">Grab
a library</a>.</p>

<p>Pattern matching syntax can make for some really beautiful, readable code.
Common Lisp doesn't include it, but of course <a href="https://github.com/guicho271828/trivia/wiki/What-is-pattern-matching%3F-Benefits%3F">there's a library</a>.</p>

<p>Enjoying algebraic data types in Haskell or Scala?  Here's your
<a href="https://github.com/tarballs-are-good/cl-algebraic-data-type">library</a>.</p>

<p>All of these libraries rely on macros to make using them feel seamless.  Of
course you could <em>do</em> all of that without macros, but you've have to add a layer
of boilerplate to manage evaluation.  This:</p>

<pre><code>(match foo
  '(list x y z) (lambda (x y z) (+ x y z))
  '(vector x y) (lambda …</code></pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/">https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/</a></em></p>]]>
            </description>
            <link>https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279468</guid>
            <pubDate>Fri, 26 Feb 2021 20:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hummingbard – decentralized communities built on Matrix]]>
            </title>
            <description>
<![CDATA[
Score 308 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26277602">thread link</a>) | @SubGenius
<br/>
February 26, 2021 | https://hummingbard.com/hummingbard/introducing-hummingbard | <a href="https://web.archive.org/web/*/https://hummingbard.com/hummingbard/introducing-hummingbard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>Hummingbard is an experiment in building communities on top of <a href="https://matrix.org/" rel="nofollow">Matrix</a>. Hummingbard has social elements like user profiles, posts, communities, sharing and so on. It is intended to be more than just a decentralized link aggregator or a microblogging platform.</p>

<h3>Spaces</h3>

<p>The main centre of interest in Hummingbard is a space, which is an ordinary <a href="https://github.com/matrix-org/matrix-doc/blob/kegan/spaces-summary/proposals/2946-spaces-summary.md" rel="nofollow">Matrix space</a>. A space is similar to a forum board, subreddit or an FB group. The posts in a space are ordinary Matrix events, with additional metadata for rendering social-like posts. Posts can include images, attachments and links. This should be extendable to add polls, reviews etc. in the future. Hummingbard posts can be blog posts too, like <em>this one youâ€™re reading right now</em>.</p>

<p>Spaces can be rendered in various ways, which makes it possible to use them as user profiles like <a href="https://hummingbard.com/@david" rel="nofollow">@david</a>, or communities like <a href="https://hummingbard.com/art" rel="nofollow">art</a>. Spaces can be arbitrarily nested, allowing sub-spaces like <a href="https://hummingbard.com/music/classical" rel="nofollow">music/classical</a> or <a href="https://hummingbard.com/music/jazz/fusion" rel="nofollow">music/jazz/fusion</a>. Spaces can also have sub-spaces that render as wiki pages like <a href="https://hummingbard.com/hummingbard/about" rel="nofollow">hummingbard/about</a>.</p>

<p>It is possible to have different types of spaces. A gallery type renders a space in Instagram-like fashion, like the <a href="https://hummingbard.com/pics" rel="nofollow">pics</a> space. Any type of space can be nested under any other type of space. This allows normal boards to have sub-spaces which are galleries, or vice versa. In the future, a space could be rendered to be a business page, and e-commerce page etc.</p>

<p>Hummingbard spaces are very limited in options right now, but basic info like title, description, header-image can be changed. Spaces support custom CSS too.</p>

<h3>Social</h3>

<p>Hummingbard has very basic social-like features. Users can follow other users and join spaces. A user feed shows posts chronologically. Posts can be shared from one user/community to another user/community. Posts can be replied to. Replies can be nested like in this <a href="https://hummingbard.com/test/$kXWe3pG7N53PIWl33KnW_zA0GYGTRDWy2d5jj6rE0G8" rel="nofollow">thread</a>.</p>

<h3>Federation</h3>

<p>Hummingbard works with federated Matrix servers too. Users can create Matrix accounts on remote servers, or log in with an existing account. Logging in with an existing account creates a user profile automatically, unless one already exists. Hummingbard spaces on federated servers work just the same as local spaces. Here are a few examples:</p>

<ul>
<li><p><a href="https://hummingbard.com/rhythm:matrix.org" rel="nofollow">rhythm:matrix.org</a></p></li>

<li><p><a href="https://hummingbard.com/food:tchncs.de" rel="nofollow">food:tchncs.de</a></p></li>

<li><p><a href="https://hummingbard.com/ask:matrix.org" rel="nofollow">ask:matrix.org</a></p></li>

<li><p><a href="https://hummingbard.com/@ahq:matrix.org" rel="nofollow">ahq:matrix.org</a></p></li>
</ul>

<p>Federated spaces can also have nested spaces like <a href="https://hummingbard.com/ebooks:matrix.org/fantasy" rel="nofollow">ebooks:matrix.org/fantasy</a> or pages <a href="https://hummingbard.com/rhythm:matrix.org/about" rel="nofollow">rhythm:matrix.org/about</a>.</p>

<p>In an ideal world, owners of Matrix servers would be hosting their own instance of Hummingbard, instead of going through one popular instance.</p>

<h3>Dendrite</h3>

<p>Hummingbard is dependent on <a href="https://github.com/hummingbard/dendrite/tree/thread_pagination" rel="nofollow">Dendrite</a>, the second-generation Matrix homeserver written in Go. Features like spaces and threading have only been implemented on Dendrite. Note that it is a forked repo with a temporary patch for paginating threads.</p>

<h3>Code</h3>

<p>Hummingbardâ€™s code will be available as soon as I am able to decide which license works best for us.</p>

<h3>Whatâ€™s Coming</h3>

<p>Hummingbard is very bare-bones at the moment. Iâ€™m actively working on the following:</p>

<ul>
<li><p>Private spaces</p></li>

<li><p>Power levels for admins/mods</p></li>

<li><p>Dark mode and various UI changes</p></li>
</ul>

<p>Aside from that, Hummingbard has a lot of bugs, and will likely crash randomly. If you do want to check out the site, either create a local Hummingbard account, or use an existing throwaway Matrix account. Iâ€™d advice against using your main Matrix account, as the authentication code may have bugs. Please try to avoid any rooms that are too large. My tiny VPS running dendrite will not be able to handle it.</p>

<h3>Contact/Feedback</h3>

<p>Weâ€™re using <a href="https://matrix.to/#/%23hummingbard:matrix.org" rel="nofollow">#hummingbard:matrix.org</a> as a meeting place to discuss Hummingbard development. You can also leave bug reports on a Hummingbard space itself - <a href="https://hummingbard.com/hummingbard/bugs" rel="nofollow">hummingbard/bugs</a></p>

<p>Lastly, if youâ€™d like to leave a reply on this blog post itself, you can log into Hummingbard with an existing Matrix account, join the <a href="https://hummingbard.com/hummingbard" rel="nofollow">hummingbard</a> space, and come back here to write your reply.</p>

<p>Many thanks.</p>

<p><strong>PS</strong>: If this post has a typo, I wonâ€™t be able to fix it because Hummingbard has not implemented editing posts yet.</p>

<p><strong>PPS</strong>: Thanks to <a href="https://hummingbard.com/@david" rel="nofollow">@david</a> for reviewing this post.</p>

                </div></div>]]>
            </description>
            <link>https://hummingbard.com/hummingbard/introducing-hummingbard</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277602</guid>
            <pubDate>Fri, 26 Feb 2021 17:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: your build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26277521">thread link</a>) | @moonlighter
<br/>
February 26, 2021 | https://justine.lol/cosmopolitan/ | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>your build-once run-anywhere c library</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/tutorials.html">Tutorials</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» justine's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
printf %s <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -O -static -fno-pie -no-pie -mno-red-zone -nostdlib -nostdinc \
  -o hello.com.dbg hello.c -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>
objcopy -SO binary hello.com.dbg hello.com

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, OpenBSD, and NetBSD too. For details on how this works,
  please read the <a title="Actually Portable Executable" aria-label="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly
  pδrταblε εxεcµταblε</a> blog post. This novel binary format is also
  optional, since <code>hello.com.dbg</code> is executable too, only on
  your local system since it's an ELF binary.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277521</guid>
            <pubDate>Fri, 26 Feb 2021 17:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Judge in Google case disturbed that 'incognito' users are tracked]]>
            </title>
            <description>
<![CDATA[
Score 864 | Comments 337 (<a href="https://news.ycombinator.com/item?id=26277396">thread link</a>) | @johncena33
<br/>
February 26, 2021 | https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When Google users browse in â€œIncognitoâ€� mode, just how hidden is their activity? The Alphabet Inc. unit says activating the stealth mode in Chrome, or â€œprivate browsingâ€� in other browsers, means the company wonâ€™t â€œremember your activity.â€� But a judge with a history of taking Silicon Valley giants to task about their data collection raised doubts Thursday about whether Google is being as forthright as it needs to be about the personal information itâ€™s collecting from users.</p>

<p>At a hearing Thursday in San Jose, California, U.S. District Judge Lucy Koh said sheâ€™s â€œdisturbedâ€� by Googleâ€™s data collection practices in a class-action lawsuit that describes the companyâ€™s private browsing promises as a â€œruseâ€� and seeks US$5,000 in damages for each of the millions of people whose privacy has been compromised since June of 2016.</p>

<p>Weighing Googleâ€™s attempt to get the suit dismissed, Koh said she finds it â€œunusualâ€� that the company would make the â€œextra effortâ€� of data collection if it doesnâ€™t use the information to build user profiles or targeted advertising. Google has become a target of antitrust complaints in the last year filed by state and federal officials -- as well as businesses -- accusing it of abusing its dominance in digital advertising and online search. Koh has a deeper history with the company as a vocal critic of its privacy policies. She forced Google in one notable case to disclose its scanning of emails to build profiles and target advertising.</p>

<p>In this case, Google is accused of relying on pieces of its code within websites that use its analytics and advertising services to scrape usersâ€™ supposedly private browsing history and send copies of it to Googleâ€™s servers. Google makes it seem like private browsing mode gives users more control of their data, Amanda Bonn, a lawyer representing users, told Koh. In reality, â€œGoogle is saying thereâ€™s basically very little you can do to prevent us from collecting your data, and thatâ€™s what you should assume weâ€™re doing,â€� Bonn said.</p>

<p>Andrew Schapiro, a lawyer for Google, argued the companyâ€™s privacy policy â€œexpressly disclosesâ€� its practices. â€œThe data collection at issue is disclosed,â€� he said.Another lawyer for Google, Stephen Broome, said website owners who contract with the company to use its analytics or other services are well aware of the data collection described in the suit.</p>

<p>Broomeâ€™s attempt to downplay the privacy concerns by pointing out that the federal court systemâ€™s own website uses Google services ended up backfiring.</p>

<p>The judge demanded an explanation â€œabout what exactly Google does,â€� while voicing concern that visitors to the courtâ€™s website are unwittingly disclosing information to the company. â€œI want a declaration from Google on what information theyâ€™re collecting on users to the courtâ€™s website, and what thatâ€™s used for,â€� Koh told the companyâ€™s lawyers. The case is Brown v. Google, 20-cv-03664, U.S. District Court, Northern District of California (San Jose).</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277396</guid>
            <pubDate>Fri, 26 Feb 2021 17:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grouparoo: Declarative Data Sync]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26276917">thread link</a>) | @bleonard
<br/>
February 26, 2021 | https://www.grouparoo.com/blog/declarative-data-sync | <a href="https://web.archive.org/web/*/https://www.grouparoo.com/blog/declarative-data-sync">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent"><div><p>Developers have been using the <a href="https://www.grouparoo.com/" target="_blank" rel="nofollow noopener noreferrer">Grouparoo</a> UI to set up automated data movement from their databases to Mailchimp, Marketo, Salesforce, and <a href="https://www.grouparoo.com/integrations" target="_blank" rel="nofollow noopener noreferrer">more</a>. While having these integrations already written for them saved plenty of time, there was something they missed: their normal developer workflow.</p><p>Grouparoo now supports declarative data models and integrations to continuously sync your data to all of your cloud-based tools. You manage data sync just like you would any other part of your stack. You test the configuration, check it into git, run it on CI, review, merge, and deploy.</p><p>Using the declarative configuration, Grouparoo does the heavy lifting of building profiles from your customer data sources, segmenting them into groups, and syncing the results to destination tools. Everyone wins when engineers can move faster and with more confidence.</p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/kQ789gMXJB8?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>Here is the <a href="https://github.com/grouparoo/app-example-config" target="_blank" rel="nofollow noopener noreferrer">example app</a> from the video.</p><h2 id="data-sync-framework"><a href="#data-sync-framework">Data Sync Framework</a></h2><p>If you have developed Node apps before, you will have a pipeline up and running in minutes. The whole app is just a <code>package.json</code> file and the declarative configuration. If you are new to Node, we have lots of helpers to get you going.</p><p>Here is how you declare your pipeline:</p><ul><li><a href="https://www.grouparoo.com/docs/installation#step-2-pick-an-installation-method" target="_blank" rel="nofollow noopener noreferrer">Get</a> our <code>grouparoo</code> command line tool via npm and <code>init</code> a new Grouparoo project</li><li><a href="https://www.grouparoo.com/docs/installation/plugins#installing-a-plugin" target="_blank" rel="nofollow noopener noreferrer">Install</a> plugins for the connections you need (Postgres, Mailchimp, Salesforce, etc.).</li><li>Generate an <a href="https://www.grouparoo.com/docs/config/apps/community" target="_blank" rel="nofollow noopener noreferrer">App</a> with connection information (Postgres database, etc).</li><li>Generate a <a href="https://www.grouparoo.com/docs/config/sources/community" target="_blank" rel="nofollow noopener noreferrer">Source</a> with <a href="https://www.grouparoo.com/docs/config/properties/community" target="_blank" rel="nofollow noopener noreferrer">Properties</a> (id, email, first_name from users table) to create Profiles.</li><li>Generate calculated <a href="https://www.grouparoo.com/docs/config/groups/community" target="_blank" rel="nofollow noopener noreferrer">Groups</a> of Profiles (High Value Users) based on Profile Property values.</li><li>Generate a <a href="https://www.grouparoo.com/docs/config/destinations/community" target="_blank" rel="nofollow noopener noreferrer">Destination</a> and map the data to it (sync email, first_name, and group membership to Mailchimp)</li></ul><p>Now, you can call <code>grouparoo run</code> to test the data <a href="https://www.grouparoo.com/docs/running" target="_blank" rel="nofollow noopener noreferrer">sync</a>, make expectation or snapshot <a href="https://www.grouparoo.com/docs/running/testing" target="_blank" rel="nofollow noopener noreferrer">tests</a>, and <a href="https://www.grouparoo.com/docs/deployment" target="_blank" rel="nofollow noopener noreferrer">deploy</a> your application so it’s always running and looking for new data to sync.</p><h2 id="zooming-out"><a href="#zooming-out">Zooming Out</a></h2><p>Businesses need data in their tools to be effective because success in marketing, sales, and support is data-driven with personalization, segmentation, and timeliness. We want these teams to be empowered to create great customer experiences.</p><p>Unfortunately, integrations are not fun to build and are tricky to get right. There are edge cases around rate limiting and data formatting. Engineers don’t tend to use the tools being integrated, so it’s hard to know what “right” even looks like. There are no clear patterns to follow. Consequently, data sync infrastructure is often brittle and unloved.</p><p>Open source is great because it tends to take hard problems and solve them for everyone. Grouparoo solves the data sync problem by making it 10x easier to build and maintain by allowing developers to stop worrying about the data pipes and focus on declaring the right definition of what is valuable.</p><div><p><img alt="Declaratively sync data to Mailchimp" src="https://www.grouparoo.com/posts/declarative-data-sync/declarative-sync.png" width="600" height="315"></p></div></div></div></div>]]>
            </description>
            <link>https://www.grouparoo.com/blog/declarative-data-sync</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276917</guid>
            <pubDate>Fri, 26 Feb 2021 17:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid career change – from cruise ship cleaner to developer]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26276390">thread link</a>) | @Pete-Codes
<br/>
February 26, 2021 | https://www.nocsdegree.com/cleaner-developer-covid-career-change/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/cleaner-developer-covid-career-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Aldhair made a career change due to Covid. He became a web developer by learning to code with <a href="https://scrimba.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=nocsdegree_email#join">Scrimba</a>, an online learning platform. Before, Aldhair was working as a cleaner on cruise ships. This interview tells you how Aldhair learned to code, his tips for self-taught web developers and how he got his first job. Enjoy!</p><h2 id="hey-so-can-you-introduce-yourself">Hey, so can you introduce yourself?</h2><p>Hi, I’m Aldhair Escobar, I’m from Mexico and currently living in Veracruz, MX. Currently, I’m working as a Developer for Client Solutions at Scalero, My main duty is building HTML Email Templates for clients, apart from that there are some “inside” projects where I’m using Node JS and even Electron JS to try things out. The company is based on San Francisco so it’s a remote position and I’m loving it a lot. Previously, I have worked as a Tax advisor for almost 4 years, and as a cleaner at a cruise ship.</p><h2 id="why-did-you-learn-to-code">Why did you learn to code?</h2><p>Well, as I said before, I was working as a Tax advisor and spending a lot of time and energy without getting paid enough so I decided to start learning English (You can see that I am still learning it), this language opened some doors so I submitted an application to Royal Caribbean International as a cleaner on a cruise ship (which got me a better salary than my last job).</p><p>The idea to work as a cleaner was to have some experience in that industry and improve my English skills, at the same time I was saving some money.</p><p>When I was on the ship, I applied to some jobs but they didn’t allow me to have an interview (you need a second contract in the company so you can apply to another position), and I was thinking on return to the ship and apply to a better position with a better salary and then COVID happened…</p><p>Fortunately while on the ship I thought about learning some new skills after finishing my contract (e.g English for business, code, or maybe to buy a franchise).</p><p>I decided to start learning to code because I was curious about it and had some business ideas that required it.</p><h2 id="how-did-you-start-learning-to-code">How did you start learning to code?</h2><p>I started with some courses in my native language for around 1 month but I did not like them. I realized I was able to understand English resources so I began with FreeCodeCamp and did the first web development certification module, along with that I found an Udemy course called “The Complete Web Development Bootcamp” by Angela Yu ($10) and things started to make sense.</p><p>So if I can make a timeline could be like this:</p><p>April – FreeCodeCamp (Free), “The Complete Web Development Bootcamp” by Angela Yu ($10).</p><p>May – Full Academy Intro (Free), Full Academy prep (It was Free)</p><p>June – Continued with the courses above, building some projects. (I also tried some new courses that did not like)</p><p>July – Building projects in Frontendmentor, youtube video courses (JS, CSS), Started in Scrimba with a <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">React Course</a> (Free).</p><p>August – “<a href="https://scrimba.com/learn/frontend?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Frontend Developer Career Path</a> Scrimba ($19 Monthly), “21 Days Challenge “Conquering Responsive Layouts” by Kevin Powell (Free), Frontendmentor projects.</p><p>September – <a href="https://scrimba.com/learn/responsive?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Responsive Web Design Bootcamp</a> (Scrimba), Building projects for my portfolio.</p><p>October – <a href="https://scrimba.com/learn/designbootcamp?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">UI Design Bootcamp</a> (Scrimba), Building Projects and continuing with the Frontend Career Path (Scrimba).</p><p>November – FullStackOpen Part 0 and Part 1 (Free), (Finished Frontend Career Path), Started Practicing about Interviews (Scrimba has <a href="https://scrimba.com/learn/reactinterview?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">a module about it</a>), Applied for jobs, I got an interview.</p><h2 id="what-made-you-decide-to-learn-to-code-with-scrimba">What made you decide to learn to code with Scrimba?</h2><p>I was curious about the platform because of this option to modify the code directly on the screen and the mini browser so I decided to take the <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Learn React For Free course</a> and I just loved it.</p><p>It is so interactive! They have amazing teachers! , you are writing code the whole course and that is something that I like about their courses, there are many challenges and repetition is the key! (And I love the “spaced repetition” system).</p><p>Apart from that, I like to hear someone explaining a concept and I like when they use images or diagrams to show something, so I realized that Scrimba was created for me 😀</p><h2 id="what-courses-did-you-do-with-scrimba">What courses did you do with Scrimba?</h2><p>I started with the <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Learn React For Free course</a>, and then I decided to get the subscription because I wanted to take some Bootcamps and the Frontend Developer Career Path, so I paid $19 per month until finishing the Path.</p><p>The advantage is that you have access to everything with the subscription and maybe in the FrontendCareerPath there’s a module that is also part of a Bootcamp so then you can finish the Bootcamp and get the individual certificate while you continue with the “main” (FrontendCareerPath) course.</p><p>I loved the Path because they are putting together all the things that are going to help you to get hired.</p><p>With Scrimba I learned a lot of JavaScript and CSS and also improved my &nbsp;ReactJS knowledge, the challenges and projects helped me to build my projects that I was going to use in my portfolio.</p><h2 id="how-did-you-get-your-first-entry-level-developer-job">How did you get your first entry level developer job?</h2><p>I always had this idea to have my GitHub profile with everything I was building, together with a “nice” CV because you know… without any experience or degree, you need to show something…</p><p>For that reason, I had my GitHub profile with almost every project I was building, a CV, and a simple portfolio website and started applying for jobs that I was interested in; I sent four applications and then got the opportunity to have an interview from one of those submissions.</p><p>Scrimba has a module dedicated to interviews and some challenges about it so it helped me with my confidence.</p><p>I was nervous because I was so interested to get the job in that company and I got some questions like “What did you learn in that course (Frontend Developer Career Path - Scrimba)?” “Why did you change careers?” Why did you go to the ship (my last job)? “The best characteristic a leader can have...” The best attitude of an employee”, Am I willing to relocate?”.</p><p>After that interview, I had three more interviews (same company), did a test (Wonscore), and built a small project with HTML, CSS and Jinja Template Engine (I learned a little bit of python to get this done).</p><p>So after 812 hours of learning and this interview process I got an offer!!</p><h2 id="what-does-a-typical-day-as-a-software-developer-look-like-for-you">What does a typical day as a software developer look like for you? </h2><p>My main duty is building Email Templates, so I get my ticket with its handoff and I start building the template with old HTML and CSS, apart from that, for instance, last week I was testing some stuff with Selenium WebDriver and Selenium IDE, and this week I am building a small desktop app with ElectronJS.</p><p>So it depends on the day, if there are a lot of templates or not then I do something else. I love what I am doing and everything is better than I was expecting.</p><h2 id="do-you-have-tips-for-people-who-want-to-learn-to-code-without-doing-a-degree">Do you have tips for people who want to learn to code without doing a degree?</h2><p>If I needed to start again, I would do things slightly different, for instance, I would start with 2 weeks of watching a lot of YouTube videos about web development, frontend, backend, stacks, languages, and also some videos that gave you the “roadmap” and all that kind of things.</p><p>After that, you will know what you don’t know and what you want to do, maybe you want to build websites or desktop apps, so you will see exactly the language that you need to learn.</p><p>Then, the most important thing, in my opinion, is to learn how you like to acquire information. Do you prefer books, video or audio? Or just the exercises without video or audio like FreeCodeCamp? It’s really important to know this because you need to search for resources that will work for you (because you prefer it).</p><p>I realized I was spending time on some resources that I didn’t like a lot so that was the main reason I decided to test Scrimba (and it worked!!)</p><p>Only with those first steps, you are going to save you a lot of time so now you can focus on the resources that you chose.</p><p>Always build stuff, it’s going to be a disaster, It won’t look good and that’s great! You can always return and fix it 😉.</p><p>I encourage you to use a “Pomodoro app” (I used “forest”) so you can keep track of your journey and see how much time you are spending, this is going to help you to push yourself and gives you extra motivation.</p><h2 id="what-are-your-career-goals-for-the-future">What are your career goals for the future?</h2><p>The idea is to get familiar with my new job, this is my first time working remotely, in tech, in a startup so it is taking time, and after a few months I want to return to build personal projects, I have some ideas and maybe I will try to build a SaaS product. In short, I want to get used to working in this field and keep pushing myself.</p>
            </div></div>]]>
            </description>
            <link>https://www.nocsdegree.com/cleaner-developer-covid-career-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276390</guid>
            <pubDate>Fri, 26 Feb 2021 16:20:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI/ML needs a key-value store, and Redis is not up to it]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276177">thread link</a>) | @LexSiga
<br/>
February 26, 2021 | https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div id="ron_db"><h2>‍<strong>The rise of key-value stores as online feature stores.&nbsp;</strong></h2><p>Online feature stores are the data layer for operational machine learning models - the models that make online shopping recommendations for you and help identify financial fraud. When you train a machine learning model, you feed it with high signal-to-noise data called features. When the model is used in operation, it needs the same types of features that it was trained on (e.g., how many times you used your credit card during the previous week), but the online feature store should have low latency to keep the end-to-end latency of using a model low. Using a model requires both retrieving the features from the online feature store and then sending them to the model for prediction.&nbsp;</p><p>Hopsworks has been using NDB Cluster as our online feature store from its first release. It has the unique combination of low latency, high availability, high throughput, and scalable storage that we call LATS. However, we knew we could make it even better as an online feature store in the cloud, so we asked one of the world’s leading database developers to do it - the person who invented NDB, Mikael Ronström. Together we have made RonDB, a key-value store with SQL capabilities, that is the world’s most advanced and performant online feature store. Although NDB Cluster is open-source, its adoption has been hampered by an undeserved reputation of being challenging to configure and operate. With <a href="https://www.rondb.com/?utm_source=rondb" target="_blank">RonDB</a>, we overcome this limitation by providing it as a managed service in the cloud on AWS and Azure.<strong>‍</strong></p><h3><strong>Requirements for an Online Feature Store</strong>‍</h3><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/60364af8c8f5d47b1f1f70ce_graph_white.png" loading="lazy" alt=""></p></figure><p>The main requirements from a database used as an online feature store are: low latency, high throughput for mixed read/write operations, high availability and the ability to store large data sets (larger than fit on a single host). We unified these properties in a single muscular term <strong>LATS</strong>:</p><p><a href="https://www.rondb.com/?utm_source=rondb" target="_blank">‍<strong>LATS</strong>: low <strong>L</strong>atency, high <strong>A</strong>vailability, high <strong>T</strong>hroughput, scalable <strong>S</strong>torage.&nbsp;</a></p><p>RonDB is not without competition as the premier choice as an online feature store. To quote Khan and Hassan from DoorDash, it should be a low latency database:&nbsp;</p><p><a href="https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/?utm_source=rondb" target="_blank">“latency on feature stores is a part of model serving, and model serving latencies tend to be in the low milliseconds range. Thus, read latency has to be proportionately lower.”&nbsp;</a></p><p>To that end, Redis fits this requirement as it is an in-memory key-value store (without SQL capabilities). Redis is open source (BSD Licence), and it enjoys popularity as an online feature store. Doordash even invested significant resources in increasing Redis’ storage capacity as an online feature store, by adding custom serialization and compression schemes. Significantly, similar to RonDB, it provides sub-millisecond latency for single key-value store operations. There are other databases that have been proposed as online feature stores, but they were not considered in this post as they have significantly higher latency (over one order-of-magnitude!), such as DynamoDB, BigTable, and SpliceMachine.</p><p>As such, we thought it would be informative to compare the performance of RonDB and Redis as an online feature store. <strong>The comparison was between Redis open-source and RonDB open-source</strong> (the commercial version of Redis does not allow any benchmarks). In addition to our benchmark, we compare the innards of RonDB’s multithreading architecture to the commercial Redis products (since our benchmark identifies CPU scalability bottlenecks in Redis that commercial products claim to overcome).<br></p><h2>Benchmark: RonDB vs Redis</h2><p>In this simple benchmark, I wanted to compare apples with apples, so I compared open-source RonDB to the open-source version of Redis, since the commercial versions disallow reporting any benchmarks. In the benchmark, I deliberately hobble the performance of RonDB by configuring it with only a single database thread, as Redis is <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">“a single-threaded server from the POV of command execution”</a>. I then proceed to describe the historical evolution of RonDB’s multithreaded architecture, consisting of three different generations, and how open-source Redis is still at the first generation, while commercial Redis products are now at generation two.</p><p>Firstly, for our single-threaded database benchmark, we performed our experiments on a 32-core Lenovo P620 workstation with 64 GB of RAM. We performed key-value lookups. Our experiments show that a single-threaded RonDB instance reached around 1.1M reads per second, while Redis reached more than 800k reads per second - both with a mean latency of around 25 microseconds. The throughput benchmark performed batch reads with 50 reads per batch and had 16 threads issuing batch requests in parallel. Batching reads/writes improves throughput at the cost of increased latency.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6037dae7ff678a83e8eaf1a8_performance.jpg" loading="lazy" alt=""></p></figure><p>On the same 32-core server, both RonDB and Redis reached around 600k writes per second when performing SET for Redis and INSERT, UPDATE or DELETE operations for RonDB. For high availability, both of those tests were done with a setup using two replicas in both RonDB and in Redis.<br></p><h3><strong>Low latency</strong></h3><p>We expected that the read latency and throughput of RonDB and Redis would be similar since both require two network jumps to read data. In case of updates (and writes/deletes), Redis should have lower latency since an update is only performed on the main replica before returning. That is, Redis only supports asynchronous replication from the main replica to a backup replica, which can result in data loss on failure of the main node. In contrast, RonDB performs an update using a synchronous replication protocol that requires 6 messages (<a href="https://www.amazon.com/MySQL-Cluster-7-5-Inside-Out/dp/9176998142/utm_source=rondb" target="_blank">a non-blocking version of two-phase commit</a>). Thus, the expected latency is 3 times higher for RonDB for writes.&nbsp;<br></p><h3><strong>High Throughput</strong></h3><p>A comparison of latency and throughput shows that RonDB already has a slight advantage in a single-threaded architecture, but with its third-generation multithreaded architecture, described below, RonDB has an even bigger performance advantage compared to Redis commercial or open-source. RonDB can be scaled up by adding more CPUs and memory or scaled out, by automatically sharding the database.&nbsp; As early as 2013, we developed a benchmark with NDB Cluster (RonDB’s predecessor) that showed how <a href="http://mikaelronstrom.blogspot.com/2015/03/200m-reads-per-second-in-mysql-cluster.html?utm_source=rondb" target="_blank">NDB could handle 200M Reads per second</a> in a large cluster of 30 data nodes with 28 cores each.&nbsp;<br></p><h3><strong>High Availability</strong></h3><p>The story on high availability is different. A write in Redis is only written to one replica. The replication to other replicas is then done asynchronously, thus consistency can be seriously affected by failures and data can be lost. An online feature store must accept writes that change the online features constantly in parallel with all the batched key reads. Thus handling node failures in an online feature store must be very smooth.<br></p><p>Given that an online feature store may need to scale to millions of writes per second as part of a normal operation, this means that a failed node can cause millions of writes to be lost, affecting the correctness and quality of any models that it is feeding with data. RonDB has transactional capabilities that ensure that transactions can be retried in the event of such partial failures. Thus, as long as the database cluster is not fully down, no transactions will be lost.<br></p><p>In many cases the data comes from external data sources into the online Feature Store, so a replay of the data is possible, but an inconsistent state of the database can easily lead to extra unavailability in failure situations. Since an online feature store is often used in mission-critical services, this is clearly not desirable.<br></p><p>RonDB updates all replicas synchronously as part of writes. Thus, if a node running the transaction coordinator or a participant fails, the cluster will automatically fail over to the surviving nodes, a new transaction coordinator will be elected (non-blocking), and no committed transactions will be lost. This is a key feature of RonDB and has been tested in the most demanding applications for more than 15 years and tested thousands of times on a daily basis.<br></p><p>Additionally it can be mentioned that in a highly available setup, in a cloud environment RonDB can read any replica and still see the latest changes whereas Redis will have to read the main replica to get a consistent view of the data and this will, in this case, require communicating across availability zones which can easily add milliseconds to latency for reads. RonDB will automatically setup the cluster such that applications using the <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud?utm_source=rondb" target="_blank">APIs will read replicas that are located in the same availability zone</a>. Thus in those setups RonDB will always be able to read the latest version of the data and still deliver data at the lowest possible latency. <strong>Redis setups will have to choose between delivering consistent data with higher latency or inconsistent data with low latency in this setup.</strong><br></p><h3><strong>Scalable Storage</strong></h3><p>Redis only supports in-memory data - this means that Redis will not be able to support online Feature Stores that store lots of data. In contrast, RonDB can store data both in-memory and on-disk, and with support for up to 144 database nodes in a cluster, it can scale to clusters of up to 1PB in size.<br></p><h3><strong>Analysis: Three Generations of Multithread Architectures</strong></h3><p>For our single-threaded benchmark, we did not expect there to be, nor were there, any major differences in throughput or latency for either read or write operations. The purpose of the benchmark was to show that both databases are similar in how efficiently they use a single CPU. RonDB and Redis are both in-memory databases, but the implementation details of their multithreaded architectures matters for scalability (how efficiently they handle increased resources), as we will see.&nbsp;<br></p><p>Firstly, <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">“Redis is not designed to benefit from multiple CPU cores. People are supposed to launch several Redis instances to scale out on several cores if needed.”</a> For our use-case of online feature stores, it is decidedly non-trivial to partition a feature store across multiple redis instances. Therefore, commercial …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276177</guid>
            <pubDate>Fri, 26 Feb 2021 16:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Catalog of resources related with Oberon programming language]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26275553">thread link</a>) | @lproven
<br/>
February 26, 2021 | https://oberon.org/en | <a href="https://web.archive.org/web/*/https://oberon.org/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><a href="https://oberon.org/ru"><img src="https://oberon.org/ru.png" alt="ru"></a>
<a href="https://oberon.org/uk"><img src="https://oberon.org/uk.png" alt="uk"></a>
<a href="https://oberon.org/en"><img src="https://oberon.org/en.png" alt="en"></a>
<a href="https://oberon.org/de"><img src="https://oberon.org/de.png" alt="de"></a>
</p>

<div><p><img src="https://oberon.org/oberon.png" alt="OBERON.ORG"></p><p><img src="https://oberon.org/title.png"></p></div>



<p>
OBERON.ORG project unites projects related to programming languages Oberon, Oberon-2, Active Oberon, Modula-2/3, Oberon-07 and Component Pascal (Blackbox Oberon).


</p>





<p><h2 id="history">
Historical materials
</h2></p>

<div>
<h3>
Niklaus Wirth website
</h3>
<p><a href="https://inf.ethz.ch/personal/wirth">inf.ethz.ch/personal/wirth</a></p><p>
Niklaus Wirth is the author of the Oberon programming language. Together with Jürg Gutknecht, he developed the Oberon operating system, giving rise to the technological direction of Oberon languages and tools.
</p>
</div>

<div>
<h3>
One of the first pages about Oberon in Russian
</h3>
<p><a href="http://www.uni-vologda.ac.ru/oberon">www.uni-vologda.ac.ru/oberon</a></p><p>
Sergey Zalmanovich Sverdlov about the main features of Oberon and its application for education.
</p>
</div>

<div>
<h3>
Educational portal about N. Wirth's visit to Russia
</h3>
<p><a href="http://oberon2005.oberoncore.ru/">oberon2005.oberoncore.ru</a></p><p>
The site was created after Niklaus Wirth's visit to Russia in 2005. The core of the site is work on the history and development of programming languages of its authorship.
</p>
</div>

<div>
<h3>
Project Оberon 2013
</h3>
<p><a href="http://www.projectoberon.com/">www.projectoberon.com</a></p><p>
Repeating by Niklaus Wirth, Jürg Gutknecht and Paul Reed of the Oberon project for FPGA
</p>
</div>

<div>
<h3>
Oberon Day in Russia
</h3>
<p><a href="https://oberoncore.ru/oberonday">oberoncore.ru/oberonday</a></p><p>
The event brings together developers who use Oberon-family systems in their practice, and interested listeners. Every year, experts representing fundamental science (high energy physics, biophysics), strategic industries (Rosatom), the industry of control systems (APCS, unmanned aerial vehicles), small innovative business (development of software systems for various purposes) make reports. Also in the center of attention are the problems of IT education, from grade 5 to specialized higher, and the key to their solution, developed by the Informatics-21 project. The mission of the seminar, besides the exchange of experience between the participants, is the broadcast of IT education in the industry and in the field of education.
</p>
</div>

<p><h2 id="education">
Educational materials
</h2></p>

<div>
<h3>
Educational project "Informatics-21"
</h3>
<p><a href="http://www.inr.ac.ru/~info21">www.inr.ac.ru/~info21</a></p><p>
Under the leadership of Fyodor Tkachev, the project coordinates the efforts of specialists in science, education, the aerospace industry and the IT industry to streamline the teaching of programming and computer science based on the achievements of Science.
</p>
</div>

<div>
<h3>
Component Pascal in School Computer Science Course
</h3>
<p><a href="https://inf.1sept.ru/article.php?ID=200800100">inf.1sept.ru/article.php?ID=200800100</a></p><p>
Article by A.S. Ilyina and A.I. Popokov in the magazine "September First". “Teaching programming based on Component Pascal / Blackbox started experimentally in Russia in 2002. The most positive experience accumulated to date, both personal and colleagues, allows us to recommend this environment for mass use in schools and universities."
</p>
</div>

<div>
<h3>
Open wikipedia on languages and projects in the Oberon language
</h3>
<p><a href="http://wiki.oberon.org/">wiki.oberon.org</a></p>
</div>





<div>
<h3>
The site is dedicated to the Oberon family of programming languages
</h3>
<p><a href="https://way.oberon.org/">way.oberon.org</a></p>
</div>





<div>
<h3>
BlackBox Component Builder for Windows
</h3>
<p><a href="http://blackboxframework.org/">blackboxframework.org</a></p><p>
Blackbox is a free and open source programming environment for the Component Pascal language, developed by the Swiss company Oberon Microsystems. The environment supports dynamic loading of modules (compiled into machine code) and garbage collection, i.e. provides its own component object model. Writing, compiling, executing, testing can be done inside an integrated environment, which greatly increases the productivity of the programmer. Blackbox is an operating environment (a kind of micro-OS) that runs on top of a regular OS. This operating environment can be included in whole or in part in the final application (along with the compiler), allowing this application to be easily extended and rebuilt on the fly.
</p>
</div>

<div>
<h3>
Cross Platform Blackbox
</h3>
<p><a href="https://blackbox.oberon.org/download">blackbox.oberon.org/download</a></p><p>
A cross-platform version of Blackbox for Windows, GNU / Linux, OpenBSD and FreeBSD is published on the site. A system of open publishing of extensions is also being developed.
</p>
</div>

<div>
<h3>
O7 compiler for microcontrollers with ARMv{6,7E}-M architecture
</h3>
<p><a href="https://github.com/aixp/O7">github.com/aixp/O7</a></p><p>
The compiler is distributed in open source, along with a set of useful modules, which are combined into a Micro subsystem. These modules store register addresses, controller initialization procedures, templates for transferring data via the UART protocol, and much more. The Mobx subsystem contains sample programs for several microcontrollers.
</p>
</div>





<div>
<h3>
MultiOberon
</h3>
<p><a href="https://github.com/dvdagaev/Mob">github.com/dvdagaev/Mob</a></p><p>
Oberon compiler with syntax constraint support. Supports three backends: BlackBox x86, Ofront for C translation, and LLVM. Can be used from Blackbox or command line.
</p>
</div>



<div>
<h3>
"Visual" or Online Oberon
</h3>
<p><a href="https://online.oberon.org/">online.oberon.org</a></p><p>
Visual is a tool for creating interactive educational and scientific models. The project aims to disseminate knowledge and teach programming.
</p>
</div>

<div>
<h3>Free Oberon</h3>
<p><a href="https://free.oberon.org/">free.oberon.org</a></p><p>
Turpo Pascal style IDE for Windows and GNU/Linux.
</p>
</div>









<div>
<h3>Astrobe</h3>
<p><a href="http://astrobe.com/">astrobe.com</a></p><p>
Oberon-07 compiler for microcontrollers
</p>
</div>





<div>
<h3>
Herschel
</h3>
<p><a href="https://herschel.oberon.org/">herschel.oberon.org</a></p><p>
Direct Component Pascal compiler for x86-64 architecture and Blackbox framework.
</p>
</div>


<div>
<h3>
YaOS — Russian translation of the A2 operating system (in development)
</h3>
<p><a href="https://gitlab.com/budden/ja-o-s">https://gitlab.com/budden/ja-o-s</a></p><p>
The YaOS project is a copy (fork) of the A2 operating system, written in the "ETH Oberon" language. The project started in 2019 and managed to make progress in the following areas: translation of source texts into Russian, expanding Unicode support, expanding documentation, improving developer tools, changing the language to improve reliability.
</p>
</div>










<p><h2 id="communities">
Communities
</h2></p>

<div>
<h3>
OberonCore Project
</h3>
<p><a href="https://oberoncore.ru/">oberoncore.ru</a></p><p>
The project brings together users and developers of oberon systems and languages.
</p>
</div>

<div>
<h3>
BlackBox Framework Center
</h3>
<p><a href="http://blackboxframework.org/">blackboxframework.org</a></p><p>
The international volunteer organization "Blackbox Component Frame Development Center" was created after the official announcement of Oberon microsystems inc. about publishing Blackbox under BSD 2-clause license and ending official support for Blackbox environment. The center took over the correction of known and newly discovered defects, the addition of innovations, the release and publication of new versions of Blackbox for OS Windows.
</p>
</div>






<p><h2 id="boards">
Forums
</h2></p>







<div>
<h3>
Chat with thematic channels
</h3>
<p><a href="https://chat.oberon.org/">chat.oberon.org</a></p><p>
Thematic communication on the RocketChat software platform.
</p>
</div>






<!--
<div class='item'>
<h3>

</h3>
<a href=http://oberspace.org>oberspace.org</a>
<p>

</p>
</div>
-->

<p><h2 id="video">
Video about Oberon
</h2></p>











<p><h2 id="repos">
Repositories
</h2></p>

<div>
<h3>
Component Pascal Collection
</h3>
<p><a href="http://www.zinnamturm.eu/">www.zinnamturm.eu</a></p><p>
A collection of different subsystems for Blackbox that contains source code examples, tools, utilities, math and graphics libraries, and many other applications. There are also helpful simple examples for tutorials. Here you will find algorithms and solutions for common computer programming problems.
</p>
</div>






<p>
end of catalog
</p><p>

For information on updating and supplementing the information in the directory, as well as if you need a third-level domain for the project, — <a href="mailto:iadenisov %D0%90%D0%A2 oberon.org" onmouseover="this.href = 'mailto:Иван Денисов '+base64_decode('PGlhZGVuaXNvdkBvYmVyb24ub3JnPj9zdWJqZWN0PQ==')+'About oberon.org'">write a letter</a>.

</p><p>
The site runs on an http server developed by Blackbox.
</p>

</div></div>]]>
            </description>
            <link>https://oberon.org/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275553</guid>
            <pubDate>Fri, 26 Feb 2021 15:15:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steampipe v0.2.0 New AWS Multi-Region Queries and Query Caching]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26275128">thread link</a>) | @51stpage
<br/>
February 26, 2021 | https://steampipe.io/blog/release-0-2-0 | <a href="https://web.archive.org/web/*/https://steampipe.io/blog/release-0-2-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>What is Steampipe?</h2><p>SQL is an expressive and powerful language for asking questions of structured data. Steampipe, an open-source project from <a href="https://turbot.com/">Turbot</a>, enables cloud pros (e.g. software developers, operations engineers and security teams) to query their favorite cloud services with SQL.</p><p>The heart of Steampipe is an intuitive command line interface (CLI) that solves the challenges encountered when asking questions of cloud resources and services. Traditional tools and custom scripts that provide visibility into these services are cumbersome, inconsistent across providers and painful to maintain. Steampipe provides a consistent, explorable and interactive approach across IaaS, PaaS and SaaS services.</p></div><div><div><div><div><div><p>&gt;</p><div><pre><code><p><span>select</span><span> </span></p><p><span>  region</span><span>,</span><span> </span></p><p><span>  instance_state </span><span>as</span><span> state</span><span>,</span><span> </span></p><p><span>  instance_type </span><span>as</span><span> </span><span>type</span><span></span></p><p><span></span><span>from</span><span> </span></p><p><span>  aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------+-----------+
| region    | state   | type      |
+-----------+---------+-----------+
| eu-west-1 | running | t3.medium |
| eu-west-2 | running | m5a.large |
| us-east-1 | running | t3.large  |
+-----------+---------+-----------+
    </pre></div></div></div></div></div><p>From the moment you have a question about your cloud, Steampipe is already at work giving you structured tables to formulate that question as SQL and execute it against your live cloud APIs. Steampipe v0.2.0 delivers an even faster response to those questions with our preview of <a href="https://steampipe.io/#blazing-fast-query-response-with-new-query-caching">query caching</a>, and enables you to do more work in each query with our new <a href="https://steampipe.io/#aws-multi-region-queries-with-steampipe">multi-region</a> and <a href="https://steampipe.io/#connection-configuration-management-in-steampipe">connection configuration</a> features.</p><h2 id="aws-multi-region-queries-with-steampipe">AWS multi-region queries with Steampipe</h2><p>Starting with version <code>0.2.0</code> of the Steampipe CLI and version <code>0.5.0</code> of the <a href="https://hub.steampipe.io/plugins/turbot/aws">Steampipe AWS Plugin</a> you can perform multi-region queries that execute in parallel against all AWS regions within your account (see below for multi-account too).</p><br><div><div><div><div><p>&gt;</p><div><pre><code><p><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>select</span><span></span></p><p><span>  region</span><span>,</span><span></span></p><p><span>  instance_id</span><span>,</span><span></span></p><p><span>  instance_state</span><span>,</span><span></span></p><p><span>  instance_type</span><span>,</span><span></span></p><p><span>  title</span></p><p><span></span><span>from</span><span> </span></p><p><span>  aws_ec2_instance</span><span>;</span></p></code><span></span></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 244.685827ms
    </pre></div></div></div><h3 id="how-can-it-be-so-fast">How can it be so fast?</h3><p>Steampipe is smart! When you execute a query it fans out concurrent connections to the configured regions, aggregates the results and then presents them to you as one result set. The speed of the query is just limited to the speed of the slowest regional response.</p><h2 id="blazing-fast-query-response-with-new-query-caching">Blazing fast query response with new query caching</h2><p>Believe it or not, we can go even faster. Once you enable the new query caching feature, subsequent queries to the same data source will operate out of the in-memory cache, and return result sets in the blink of an eye.</p><h3 id="fast-1-second">Fast (1 Second)</h3><p>The first time you query a connection, Steampipe needs to create and authenticate API connections, in this case it took a little over 1 second to establish connections across 16 AWS regions and return results.</p><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 1.045864439s
    </pre></div></div></div><h3 id="real-fast-Â¼-second">Real Fast (Â¼ Second)</h3><p>With the connections now cached, the same query returns in less than Â¼ second.</p><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 243.693268ms
    </pre></div></div></div><h3 id="blazing-fast---1-microsecond">Blazing Fast ( &lt; 1 Microsecond)</h3><p>With query caching enabled, subsequent queries to the same table are more than 1000x faster!</p><div><div><div><div><div><pre><code><p><span>$ export STEAMPIPE_CACHE</span><span>=</span><span>true</span><span></span></p><p><span>$ steampipe query</span></p><p><span></span><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 653.39Âµs
    </pre></div></div></div><h2 id="connection-configuration-management-in-steampipe">Connection configuration management in Steampipe</h2><p>Regardless of what cloud you are working with, you are likely to need connections to more than one environment.  Everyone has multiple Slack channels and Github repositories that we work with and most cloud pros have multiple AWS accounts that they work with on a daily basis.</p><p>The latest Steampipe release now makes it even easier to work with (and across multiple api connections). This example shows how to configure multiple AWS accounts in a single Steampipe configuration:</p><div><div><div><div><div><div><div><pre><code><p><span>connection </span><span>"dmi_scranton"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"scranton"</span><span></span></p><p><span>  regions     = </span><span>[</span><span>"us-east-2"</span><span>]</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span>connection </span><span>"dmi_albany"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"albany"</span><span></span></p><p><span>  regions     = </span><span>[</span><span>"us-east-1"</span><span>]</span><span></span></p><p><span></span><span>}</span><span> </span></p><p><span>connection </span><span>"dmi_global"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"dmi_corp"</span><span></span></p><p><span>  regions     = </span><span>[</span><span></span></p><p><span>    </span><span>"eu-west-1"</span><span>,</span><span> </span></p><p><span>    </span><span>"eu-west-2"</span><span>,</span><span> </span></p><p><span>    </span><span>"us-east-1"</span><span>,</span><span> </span></p><p><span>    </span><span>"us-east-2"</span><span></span></p><p><span>  </span><span>]</span><span></span></p><p><span></span><span>}</span></p></code></pre></div></div></div></div></div></div></div><p>In the example above, I chose different <code>[profiles]</code> from my <code>~/.aws/config</code> configuration for the connection credentials. You can optionally configure Steampipe to use <code>access key/secret key</code> pairs instead of your AWS profile if desired. After changing any .spc configuration, restart Steampipe. </p><p>Each account configuration creates a separate <code>namespace</code> in the Steampipe embedded Postgres DB; this allows us to query different accounts using standard <code>schema.table_name</code> syntax:</p><div><div><div><div><div><div><p>&gt;</p><div><pre><code><p><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_albany</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>2</span><span>     </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_scranton</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>34</span><span>    </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_global</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>15</span><span>    </span><span>|</span><span></span></p><p><span></span><span>+</span></p></code></pre></div></div></div></div></div></div></div><p>Aggregating results across accounts can be as simple as an SQL <code>union</code> statement:</p><div><div><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_scranton</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span></p><p><span>  </span><span>union</span><span></span></p><p><span>  </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_albany</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span></p><p><span>  </span><span>union</span><span></span></p><p><span>  </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_global</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span><span>;</span></p></code></pre></div></div></div><div><pre>
   +--------------+-------+
   | account_id   | count |
   +--------------+-------+
   | 111222333444 | 2     |
   | 444555666777 | 15    |
   | 888899990000 | 34    |
   +--------------+-------+
    </pre></div></div></div></div></div><h2 id="yes-we-think-that-is-super-cool-too--get-started-today">Yes, we think that is super cool too!  Get started today.</h2><p>Seeing Steampipeâ€™s multi-region and multi-account queries definitely put a smile on our product teamâ€™s face, we hope it is both delightful and a huge time saver for you in your day-to-day cloud work.  For even more good stuff, checkout the <a href="https://github.com/turbot/steampipe/blob/main/CHANGELOG.md">full release notes on Steampipe v0.2.0</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://steampipe.io/blog/release-0-2-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275128</guid>
            <pubDate>Fri, 26 Feb 2021 14:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose the Browser Carefully]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26275103">thread link</a>) | @axiomdata316
<br/>
February 26, 2021 | https://unixsheikh.com/articles/choose-your-browser-carefully.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/choose-your-browser-carefully.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Published on <span id="pubdate">2020-10-20</span>. Updated on <span id="moddate">2020-10-26</span></p>
<p><a href="https://en.wikipedia.org/wiki/Internet_privacy">Privacy on the Internet</a> is important because privacy risks range from the gathering of statistics on users to more malicious acts such as the spreading of spyware and the exploitation of various forms of bugs (software faults). Many companies, such as Google, track which websites people visit and then use the information, for instance by sending advertising based on one's web browsing history. Sometimes prices on products are changed on the same website, depending on tracking information, and two people may view the exact same product on the exact same website yet be presented with very different prices.</p>

<h3>Table of contents</h3>
<ul>
<li><a href="#privacy-compromising">Introduction</a></li>
<li><a href="#third-party-clones">Third party clones</a></li>
<li><a href="#privacy-compromising">Privacy compromising browsers</a>
    <ul>
    <li><a href="#firefox">Mozilla Firefox</a></li>
    <li><a href="#chrome">Google Chrome and Chromium</a></li>
    <li><a href="#brave">Brave</a></li>
    <li><a href="#palemoon">Palemoon</a></li>
    <li><a href="#waterfox">Waterfox</a></li>
    <li><a href="#librewolf">Librewolf</a></li>
    <li><a href="#epiphany">GNOME Web (Epiphany) and Eolie</a></li>
    <li><a href="#midori">Midori</a></li>
    <li><a href="#other-problematic-browsers">Other problematic browsers</a></li>
    </ul>
</li>
<li><a href="#alternatives">Privacy respecting browsers</a></li>
<ul>
<li><a href="#tweaking-firefox">Tweaking Firefox - the best solution</a>
    <ul>
    <li><a href="#control">Controlling Firefox's DNS over HTTPS</a></li>
    <li><a href="#blocking">Blocking DoH via a firewall</a></li>
    </ul>
</li>
<li><a href="#falkon">Falkon</a></li>
<li><a href="#qutebrowser">qutebrowser</a></li>
<li><a href="#icecat">GNU IceCat</a></li>
<li><a href="#ungoogled-chromium">ungoogled-chromium</a></li>
<li><a href="#tor">Tor browser</a></li>
<li><a href="#other-okay-browsers">Other okay browsers</a></li>
</ul>
<li><a href="#recommended-extensions">Recommended extensions</a></li>
    <ul>
    <li><a href="#noscript">NoScript</a></li>
    <li><a href="#ublock-origin">uBlock Origin</a></li>
    <li><a href="#https-everywhere">HTTPS Everywhere</a></li>
    </ul>
<li><a href="#conclusions">Conclusions</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>This article isn't specifically about privacy issues only, it's about promises that are being broken, which might be about privacy. It is also about the lack of user freedom, as in the choice to enable or disable features, such as automatic updates, or forced usage of third party services, or software that the user generally is unaware of or don't have a say about.</p>

<p>Privacy as a subject regarding the usage of services on the Internet is a very difficult subject to deal with. Not only can it be difficult to actually define privacy, but it also requires a balance between freedom of choice by the users, security and usability. Naturally you need to be able to use the browser on the Internet and as such you will always leave some kind of trail behind, and this article is not about how you can hide your tracks. What I am addressing in this article are browsers that are either promoted as "privacy-respecting" by the developers, or in general are considered to be so (mostly due to misunderstanding or misinformation), while it is very clear they are not.</p>

<p>Some browsers either directly violate users by collecting telemetric data without consent, or you have to opt-out rather than opt-in, or they bounce around the Internet visiting places in the background without you knowing (using dns-prefetch or automatic updates etc.), using third party services that operates with a privacy policy you either cannot trust, or that are directly violating your privacy, or they have integrated third party software that do some of these things.</p>

<p>I will try to keep this article updated with relevant information as much as possible. I know several other browsers exist, but if they are not mentioned on this list I have either not had a change to investigate them, they are closed source and completely irrelevant (such as Microsoft Edge or Opera), or they are not actively maintained, or they cannot perhaps be trusted for some reason or another.</p>

<p>I will also <b>not</b> be looking at browsers that only work on Microsoft Windows or macOS, even if they are Open Source. Both Microsoft Windows and macOS are highly controversial and completely untrustworthy operating systems.</p>

<p>Also please note that just because the developers of a browser are promising that their browser is privacy-respecting doesn't mean that you can trust the information. As you will see with the examples of some of the browsers below even developers some times compromise user privacy perhaps without even thinking about it.</p>

<p>I also want to make a strong advice to people recommending browsers to other people without investigation or knowledge. The <a href="https://old.reddit.com/r/privacy/">privacy related channel on Reddit</a> is filled with wrong recommendations regarding privacy-respecting browsers and many people are merely guessing or blindly trusting the information the browser producers are publishing. Neither Mozilla Firefox, Google Chrome or Chromium, Brave, Waterfox, or several of the other recommended browsers truly respect privacy. They all do some form of telemetry and/or privacy-compromising actions without the user consenting to it or even knowing about it.</p>

<p>Also, privacy doesn't mean that you simply pull out telemetry from Firefox, rebrand it, and then ship it. Privacy is more than that. Unless the browser is automatically checking for an updated version, and the website isn't logging that request, it cannot be considered truly private if the browser starts bouncing around on the Internet visiting all kinds of places without the user has done anything more than open the browser up! Every time the browser makes a DNS request, that DNS request is in most cases logged unless the user actively does something to mitigate that - such as using a trusted VPN or non-logging DNS service etc. Furthermore, the Mozilla add-on CDN is logging user activity, as is <a href="https://en.wikipedia.org/wiki/Amazon_CloudFront">Amazon Cloudfront</a>, so if the browser visits these places without the user explicitly pushes a "check for updates" option, the browser is compromising user privacy. The point I'm trying to make is that the user needs to have the choice and that nothing happens until the user actively do something.</p>

<p>Last, but not least, if you discover any mistakes on my part, feel free to email me about it so that I can correct the information.</p>

<h2 id="privacy-compromising">Privacy compromising browsers</h2>

<h3 id="firefox">Mozilla Firefox</h3>
<p>In the past I have always supported Mozilla and promoted <a href="https://en.wikipedia.org/wiki/Firefox">Firefox</a>, but Mozilla has made some pretty controversial decisions as of late and I no longer feel that Mozilla is an organization that deserves any support. Not unless they change the way they conduct their business.</p>
<p>Firefox is promoted by Mozilla as a privacy-respecting browser, but this is highly misleading. Firefox "phones home" every time you start it up even when you have disabled telemetry and automatic updates of extensions. Domains such as mozilla.org, cloudfront.net, firefox.settings.services.mozilla.com (see: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12">https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12</a>), autopush.prod.mozaws.net, detectportal.firefox.com and location.services.mozilla.com are visited each time you start Firefox.</p>
<p>In 2017 Mozilla made a <a href="https://en.wikipedia.org/wiki/Cliqz#Integration_with_Firefox">deal with Cliqz</a> where approximately 1% of users downloading Firefox in Germany would receive a version with Cliqz software included. And in 2018 Mozilla revealed that they had no data on the number of Firefox installations with disabled Telemetry.</p>
<p>Mozilla then developed the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1487578">Telemetry Coverage</a> system and distributed it to 1% of the Firefox installations. The system is automatically installed and designed to inform Mozilla whether telemetry is enabled in the browser.</p>
<p>Mozilla also <a href="https://support.mozilla.org/en-US/kb/telemetry-collection-windows-default-browser-trend">developed a Windows-only scheduled task</a> which runs in the background once a day for each installation of Firefox installed on a computer running Microsoft Windows. The task collects information related to the system's current and previous default browser setting and the operating system locale and version.</p>
<p>This is a list of some of the things that Mozilla collects: <a href="https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content">https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content</a>.</p>
<p>On the <a href="https://www.mozilla.org/en-US/about/">Mozilla website</a> we can read (when I originally started writing this article) that <q>We put people over profit</q>, and <q>a product to support user privacy</q>. We can also read in the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla manifesto</a>, in the fourth principle, that <q>Individuals' security and privacy on the internet are fundamental and must not be treated as optional.</q> However, with their decision to make Cloudflare the default DNS provider for DNS over HTTPS, they are definitely not supporting user privacy or putting people over profit!</p>
<p>DNS over HTTPS is by itself <a href="https://www.youtube.com/watch?v=ZxTdEEuyxHU">bad enough</a>, and <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Criticism">highly criticized</a> with <a href="https://www.zdnet.com/article/dns-over-https-causes-more-problems-than-it-solves-experts-say/">very good reason</a>, but combining it with a US based company like Cloudflare makes it even worse. Cloudflare <a href="https://old.reddit.com/r/privacy/comments/d52kop/eli5_why_cloudflare_is_depicted_as_evil_and_whats/f0jrxox/">cannot be trusted</a> with DNS requests.</p>
<p>Cloudflare has made an <a href="https://developers.cloudflare.com/1.1.1.1/commitment-to-privacy/privacy-policy/firefox/">agreement</a> with Mozilla that when it acts as a DNS resolver for Firefox, that:</p>
<ul>
<li>DNS requests will be stored as part of Cloudflare's "temporary" logs which are permanently deleted within 24 hours.</li>
<li>Cloudflare will also collect and store the following information as part of its permanent logs:
<ul>
<li>Total number of requests processed by each Cloudflare co-location facility.</li>
<li>Aggregate list of all domain names requested.</li>
<li>Samples of domain names queried along with the times of such queries.</li>
</ul>
</li>
<li>Information stored in Cloudflare's permanent logs will be anonymized and may be held indefinitely by Cloudflare for its own internal research and development purposes.</li>
</ul>
<p>Anyone who has worked with DNS servers knows what goes into such logs and in order for Cloudflare to keep their promise they need to: Delete the DNS requests information, but at the same time somehow still keep "anonymized" logs of the total number of requests, a list of all domain names requested, a so-called "sample" of complete DNS queries along with date and time.</p>
<p>This means that even if Cloudflare could be trusted and they have the best of intentions, they will still log everything the first 24 hours. If Cloudflare is ever compromised all these logs could be copied and distributed over a period of time.</p>
<p>Furthermore, the actual wording of the agreement is such that the technical procedure for how they actually do this can only be guessed at. How do they plan to anonymize the data? Is the "sample" 99.9% of all the queries, or is it 1%?</p>
<p>Last, but not least, Cloudflare is an American company subject to American law, a law that pretty much undermines the foundation of any kind of privacy.</p>
<blockquote>
<p>Cloudflare will not retain or sell or transfer to any third party (except as may be required by law) any personal information, IP addresses or other user identifiers from the DNS queries sent from the Firefox browser to the Cloudflare Resolver for Firefox;</p>
</blockquote>
<p>Real privacy means:</p>
<ul>
<li><b>No logging</b></li>
<li><b>No data retention</b></li>
<li><b>No phoning home without consent before doing so</b></li>
<li><b>No user opt-out telemetry, it has to be opt-in</b></li>
<li><b>Real and 100% transparency regarding …</b></li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unixsheikh.com/articles/choose-your-browser-carefully.html">https://unixsheikh.com/articles/choose-your-browser-carefully.html</a></em></p>]]>
            </description>
            <link>https://unixsheikh.com/articles/choose-your-browser-carefully.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275103</guid>
            <pubDate>Fri, 26 Feb 2021 14:30:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cuboid: A DIY air purifier that's better than a box fan]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 121 (<a href="https://news.ycombinator.com/item?id=26275091">thread link</a>) | @dynm
<br/>
February 26, 2021 | https://dynomight.net/better-DIY-air-purifier.html | <a href="https://web.archive.org/web/*/https://dynomight.net/better-DIY-air-purifier.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Feb 26, 2021  / Last updated: Feb 7, 2021  </strong></p>
            
            <p>I love box-fan based air purifiers. They are cheap, trivial to build, and people around the world have done experiments to show they <a href="https://dynomight.net/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">actually work</a>.</p>

<p>Still, box-fan purifiers have two downsides: They create a lot of noise, and they consume a fair amount of electricity.</p>

<p>I wanted a new design that preserves the best aspects of using a box-fan:</p>

<ol>
  <li>Cheap.</li>
  <li>Easily built with no tools.</li>
  <li>No proprietary parts.</li>
  <li>Good at purifying the air.</li>
</ol>

<p>The design should also fix the worst parts of using a box fan:</p>

<ol>
  <li>Make less noise.</li>
  <li>Use less electricity.</li>
</ol>

<p>I think I’ve found such a design. Behold, the Cuboid:</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/cuboid.jpg" alt="Cuboid DIY purifier">
</p>

<h2 id="performance-summary">Performance summary</h2>

<p>I’ve done some experiments comparing this to a <a href="https://dynomight.net/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">box-fan based purifier</a>, using the same filters.  Here’s a summary.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>Cost to build</td>
    <td colspan="3">$71.50</td>
    <td colspan="3">$100</td>
</tr>
<tr>
    <td>Time to build</td>
    <td colspan="3">30 s</td>
    <td colspan="3">5 min</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>18.4</td>
    <td>13.2</td>
    <td>9.6</td>
    <td>15.1</td>
    <td>10.3</td>
    <td>6.9</td>
</tr>
<tr>
    <td>PM 2.5 CADR (m³/min)</td>
    <td>1.15</td>
    <td>1.58</td>
    <td>2.17</td>
    <td>1.40</td>
    <td>2.02</td>
    <td>2.95</td>
</tr>
<tr>
    <td>Sound level (dB)</td>
    <td>43</td>
    <td>48</td>
    <td>55</td>
    <td>16</td>
    <td>39</td>
    <td>51</td>
</tr>
<tr>
    <td>Power usage (W)</td>
    <td>65.4</td>
    <td>76.4</td>
    <td>96.0</td>
    <td>22.6</td>
    <td>40.3</td>
    <td>51.3</td>
</tr>
<tr>
    <td>Power cost/year ($)</td>
    <td>74.4</td>
    <td>87.0</td>
    <td>109.3</td>
    <td>25.73</td>
    <td>45.9</td>
    <td>58.4</td>
</tr>
<tr>
    <td>Resembles IED</td>
    <td colspan="3">★☆☆☆</td>
    <td colspan="3">★★★☆</td>
</tr>
</tbody>
</table>
</div>

<p>Less is better for everything except the clean air delivery rate (CADR). The half-life is calculated in a 31 m³ room. Electricity costs assume operation 24 hours/day at 1 kWh = $0.13.</p>

<p>As you can see, the cuboid gives major improvements in noise and electricity consumption, with small regressions in cost, difficulty of construction, and IED resemblance. Particularly on low, the cuboid is very quiet and energy-efficient. Somewhat accidentally, it’s also better at removing particles.</p>

<h2 id="contents">Contents</h2>

<ul id="markdown-toc">
  <li><a href="#performance-summary" id="markdown-toc-performance-summary">Performance summary</a></li>
  <li><a href="#contents" id="markdown-toc-contents">Contents</a></li>
  <li><a href="#the-fanfilter-tradeoff" id="markdown-toc-the-fanfilter-tradeoff">The fan/filter tradeoff</a></li>
  <li><a href="#how-to-build-it" id="markdown-toc-how-to-build-it">How to build it</a>    <ul>
      <li><a href="#materials-used" id="markdown-toc-materials-used">Materials used</a></li>
      <li><a href="#step-1-form-a-column-out-of-the-filters" id="markdown-toc-step-1-form-a-column-out-of-the-filters">Step 1: Form a column out of the filters</a></li>
      <li><a href="#step-2-cut-out-a-base-for-the-column" id="markdown-toc-step-2-cut-out-a-base-for-the-column">Step 2: Cut out a base for the column</a></li>
      <li><a href="#step-3-cut-out-a-base-for-the-fan" id="markdown-toc-step-3-cut-out-a-base-for-the-fan">Step 3: Cut out a base for the fan</a></li>
      <li><a href="#step-4-set-the-fan-on-the-filter-column" id="markdown-toc-step-4-set-the-fan-on-the-filter-column">Step 4: Set the fan on the filter column</a></li>
    </ul>
  </li>
  <li><a href="#cost" id="markdown-toc-cost">Cost</a></li>
  <li><a href="#measuring-filtering-performance" id="markdown-toc-measuring-filtering-performance">Measuring filtering performance</a>    <ul>
      <li><a href="#experimental-setup" id="markdown-toc-experimental-setup">Experimental setup</a></li>
      <li><a href="#results" id="markdown-toc-results">Results</a></li>
      <li><a href="#fitting-exponential-curves" id="markdown-toc-fitting-exponential-curves">Fitting exponential curves</a></li>
      <li><a href="#clean-air-delivery-rate-calculations" id="markdown-toc-clean-air-delivery-rate-calculations">Clean air delivery rate calculations</a></li>
    </ul>
  </li>
  <li><a href="#measuring-noise" id="markdown-toc-measuring-noise">Measuring noise</a></li>
  <li><a href="#measuring-energy-usage" id="markdown-toc-measuring-energy-usage">Measuring energy usage</a></li>
  <li><a href="#discussion" id="markdown-toc-discussion">Discussion</a>    <ul>
      <li><a href="#the-upper-limit" id="markdown-toc-the-upper-limit">The upper limit</a></li>
      <li><a href="#should-you-bother-building-a-cuboid" id="markdown-toc-should-you-bother-building-a-cuboid">Should you bother building a Cuboid?</a></li>
      <li><a href="#when-is-airflow-helpful" id="markdown-toc-when-is-airflow-helpful">When is airflow helpful?</a></li>
      <li><a href="#the-competition" id="markdown-toc-the-competition">The competition</a></li>
      <li><a href="#advice" id="markdown-toc-advice">Advice</a></li>
      <li><a href="#you-might-ask" id="markdown-toc-you-might-ask">You might ask</a></li>
    </ul>
  </li>
</ul>

<h2 id="the-fanfilter-tradeoff">The fan/filter tradeoff</h2>

<p>Air purifiers push air through filters. If you’ve ever built a box-fan-based air purifier, you noticed that once you attach HEPA filters, throughput decreases dramatically. If you use a weak fan, it will barely push any air at all.</p>

<p>Fundamentally, if you want to increase purification, you have two options:</p>
<ul>
  <li><strong>Big fan</strong>: Keep the same amount of filter, but run a bigger/faster motor to push air through it faster.</li>
  <li><strong>Big filter</strong>: Keep the same fan, but install more filters in parallel. This will decrease the pressure on each of them, meaning more total airflow.</li>
</ul>

<p>If we want to be quiet and energy-efficient, the choice is clear: Use a relatively weak fan, but with a large a filter surface area.</p>

<p>Using more filters has a higher upfront cost — filters aren’t free. However, that extra cost disappears over time. If each filter can remove a fixed amount of particulates before it needs to be replaced, then doubling the number of filters means also doubling the replacement interval.</p>

<h2 id="how-to-build-it">How to build it</h2>

<p>(Contact me if you want the exact products I used.)</p>

<h3 id="materials-used">Materials used</h3>

<ul>
  <li>An 8inch (20.32cm) diameter inline duct booster fan ($30).</li>
  <li>Four HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick ($70 for all).</li>
  <li>Two bungee cords (free).</li>
  <li>Tape (free).</li>
  <li>Two pieces of packaging foam (free).</li>
</ul>

<p>Inline duct <em>booster</em> fans are fairly weak fans often used to help with grow rooms or range hoods. An <em>inline duct fan</em> would probably perform even better (see the <a href="#discussion">discussion</a>) but at a higher cost. The one I bought is rated to push around 12 m³ of air per minute.</p>

<p>You can use filters and fans of different sizes if you want. All that matters is that the fan has a smaller diameter than the filters (20.32 cm &lt; 22 cm). The pieces of foam also need to be at least as large as the matching dimension of the filter. I just used the foam that my fan was shipped in.</p>

<h3 id="step-1-form-a-column-out-of-the-filters">Step 1: Form a column out of the filters</h3>

<p>Take the four filters, and assemble them into a vertical structure. Be careful to align the edges as you see in the middle, with two sides slightly “inside” of the other sides.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step1.jpg" alt="Step 1 of construction" loading="lazy">
</p>

<p>This column is somewhat unstable, but we’ll deal with that.</p>

<h3 id="step-2-cut-out-a-base-for-the-column">Step 2: Cut out a base for the column</h3>

<p>Cut one piece of foam to the size of the square at the bottom of the filter column (I taped over a hole in the foam I used.) Place it at the bottom.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step2.jpg" alt="Step 2 of construction" loading="lazy">
</p>

<p>I did this by setting the filters on top of the foam, tracing out the shape with a pencil, and then cutting the foam with scissors. You probably want to err on the side of making it larger and trim if necessary. It should fit firmly so that it’s held in place by the filters.</p>

<p>Strictly speaking, you could also probably skip this step. I did that in an early version and it was OK. However, this adds a lot of stability allows the purifier to work even if it isn’t on top of a flat surface. You could also substitute some other material for the foam.</p>

<h3 id="step-3-cut-out-a-base-for-the-fan">Step 3: Cut out a base for the fan</h3>

<p>Cut another piece of foam so that it supports the fan from below while holding the fan in place. This should be large enough so that that the piece will sit on top of the filters.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step3.jpg" alt="Step 3 of construction" loading="lazy">
</p>

<p>As you can see, the foam was missing a corner, which I solved inelegantly by gluing on a piece of cardboard.</p>

<h3 id="step-4-set-the-fan-on-the-filter-column">Step 4: Set the fan on the filter column</h3>

<p>Set the fan+foam on top of the filters, oriented so it will blow air <em>upward</em>, and pull air through the filters.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step4.jpg" alt="Step 4 of construction" loading="lazy">
</p>

<p>That’s it, you’re done. The top is only held on by gravity, plus pressure if it’s on. You could obviously make this more stable or beautiful, but I wanted to focus on a design that’s <em>really</em> easy to build.</p>

<h2 id="cost">Cost</h2>

<p>The only significant cost is the fan ($30) and the filters ($70 for 4). This is more expensive than a box fan design, where the fan costs $19 and you only need 2 or 3 filters. However, as mentioned <a href="#the-fanfilter-tradeoff">above</a>, the cost of extra filters evens out in the long run since they need to be replaced half as often.</p>

<h2 id="measuring-filtering-performance">Measuring filtering performance</h2>

<h3 id="experimental-setup">Experimental setup</h3>

<p>I did experiments in a room with a volume of around 31 m³. To generate smoke, I cut 5 credit-card length sticks of incense and placed them on one end of a table. On the other end of the table, I placed a tablet that took a time-lapse video of a particle counter and a stopwatch. I then manually transcribed the measurements from this video.</p>

<p>The purifier (box fan or cuboid) was on the ground around a meter from the particle counter.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/setup.jpg" alt="setup for measuring air purification performance" loading="lazy">
</p>

<h3 id="results">Results</h3>

<p>As a comparison, I attached three of the same filters to a box fan (Literally the <em>same</em> filters).</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/boxfan.jpg" alt="DIY box fan compared to">
</p>


<p>Here are the results with the cuboid. Note that the y-axis is logarithmic. The straight lines indicate that particulates are decreasing at an exponential rate.</p>

<p><a href="https://dynomight.net/img/cuboid_purifier/cuboid_performance_cropped.svg">
<img src="https://dynomight.net/img/cuboid_purifier/cuboid_performance_cropped.svg" alt="performance of the cuboid on different fan speeds">
</a>
</p>

<p><br>
Here are the results of the box fan.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/boxfan_performance_cropped.svg" alt="performance of the box fan on different fan speeds" loading="lazy">
</p>



<p>You’ll notice two things. First and most importantly, the slopes for the cuboid graphs are steeper. This indicates better performance.</p>

<p>Second, the particles peak at higher values with the cuboid. I believe this is because the incense was near the particle counter on a table, while the purifiers were sitting on the floor 2m away. If the air isn’t disturbed, it takes a while before smoke drifts over the purifier and it actually starts doing anything. However, the box fan creates so much wind that the smoke immediately diffuses around the room and the box-fan purifier essentially gets a “head start”.</p>

<p>While wind seems to help here, it could be harmful in other cases. I discuss this more <a href="#when-is-airflow-helpful">below</a>.</p>

<h3 id="fitting-exponential-curves">Fitting exponential curves</h3>

<p>The y-axes in the plots above are logarithmic. As you can see from the dotted lines, these are well-fit by straight lines. This is what we’d expect if a fixed fraction of the air were being cleaned per minute.</p>

<p>The dotted lines for each curve show a fit of the form <strong>y=a×bᵐ</strong>, where <strong>y</strong> is the level of particulates, <strong>m</strong> is the number of minutes, and <strong>a</strong> and <strong>b</strong> are constants.</p>

<p>We can convert a fit of this type to a half-life: The number of minutes the purifier needs to eliminate half the particles from the air when running in a 31 m³ room.  That would be the number of minutes <strong>m</strong> such that <strong>bᵐ = .5</strong>. We can solve this equation as <strong>b = log(.5) / log(b)</strong>.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 fit</td>
    <td>90×.963ᵐ</td>
    <td>90×.949ᵐ</td>
    <td>65×.93ᵐ</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>18.4</td>
    <td>13.2</td>
    <td>9.6</td>
</tr>
</tbody>
</table>
</div>



<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 fit</td>
    <td>300×.955ᵐ</td>
    <td>280×.935ᵐ</td>
    <td>180×.905ᵐ</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>15.1</td>
    <td>10.3</td>
    <td>6.9</td>
</tr>
</tbody>
</table>
</div>

<h3 id="clean-air-delivery-rate-calculations">Clean air delivery rate calculations</h3>

<p>One common way of estimating the performance of purifiers is the clean air delivery rate (CADR). If the air that came out of the purifier had zero particulates, this would just be the volume of air per unit of time.</p>

<p>The fits above were of the form <strong>y=a×bᵐ</strong>. This means that the number of particulates drops by a factor of <strong>b</strong> each minute.</p>

<p>Here’s how I calculated the CADR. Note that that if the purifier delivered <strong>(cleaned air) m³</strong> of clean air in a single minute in a room with a total volume of <strong>(all air) m³</strong>, then the particulates in a room would drop by a factor of</p>

<p><b>b=(uncleaned air)/(all air)= 1 - (cleaned air) / (all air)</b>
</p>
<p><br>
per minute. We can solve this to find that equation to get that</p>

<p><b>(cleaned air) = (all air)×(1-b).</b>
</p>


<p>I measured the dimensions of the room where I did these measurements. I estimated it was 31m³. From this, I computed the CADR for each purifier and speed as <strong>CADR = 31×(1-b)</strong>. This gives the following table of CADR rates.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 CADR (m³/min)</td>
    <td>1.15</td>
    <td>1.58</td>
    <td>2.17</td>
    <td>1.40</td>
    <td>2.02</td>
    <td>2.95</td>
</tr>
<tr>
    <td>PM 2.5 CADR (ft³/min)</td>
    <td>40.5</td>
    <td>55.8</td>
    <td>76.6</td>
    <td>49.2</td>
    <td>71.1</td>
    <td>104</td>
</tr>
</tbody>
</table>
</div>


<p>A recent <a href="https://www.cbc.ca/1.5900782">study</a> from the University of Toronto also measured the CADR of a similar box-fan purifier. They measure around 92 ft³/min. (They don’t give numbers, but there’s a <a href="https://i.cbc.ca/1.5902727.1612545406!/fileImage/httpImage/image.png_gen/derivatives/original_1180/air-purifiers-graph.png">graph</a> CADR=100 is 130 pixels high and the box fan is 100 pixels high.) This is reassuringly close to my estimate of 76.6. I’d put a confidence band of around 20% on my numbers due to the crude …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dynomight.net/better-DIY-air-purifier.html">https://dynomight.net/better-DIY-air-purifier.html</a></em></p>]]>
            </description>
            <link>https://dynomight.net/better-DIY-air-purifier.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275091</guid>
            <pubDate>Fri, 26 Feb 2021 14:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Text Summarization in PDF Documents with Faster R-CNN and PEGASUS]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26275071">thread link</a>) | @konfuzio
<br/>
February 26, 2021 | https://konfuzio.com/de/automatic-text-summarization-in-pdf-files | <a href="https://web.archive.org/web/*/https://konfuzio.com/de/automatic-text-summarization-in-pdf-files">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Today, rising amounts of documents and the contained information have to be processed by enterprises to be able to use the hidden content. This is either done by time-expensive manual text summarization or by using an automatization solution. Automatic text summarization helps humans to efficiently process the growing volume of information.&nbsp;</p><h4>What exactly is automatic text summarization?</h4><p>The Oxford English dictionary defines automatic text summarization as “the creation of a shortened version of a text by a computer program. The product of this procedure still contains the most important points of the original text.” [1]</p><p>A good example where summarization can be useful is the annual reports of companies. Those documents contain a lot of facts that can be crucial for investors since they include information on many factors such as sustainability or environmental policies which can help for the investors‘ decision. However, the annual reports are normally very long documents with hundreds of pages, which makes their analysis a time consuming process that could be facilitated by an automatic workflow.&nbsp;</p><h2>How can we summarize text in PDF files?</h2><p>We divide the process in three main parts. For each of those steps we go more into detail in the following sections of this article. Feel free to jump right into the details or let us first walk you through the main outcomes of each step.</p><h3>1. Use Object Detection for Page Segmentation</h3><p>In the first step, we need to select those parts of the document that have to be focused on. While we can get a lot of already summarized information from images, graphs, and headlines, it is the text that is the most complete source of information. A possible way to split the document in different components is to use a computer vision approach. A model for multiclass object detection can automatically differentiate between different elements in the annual report. All content can be split into five categories: title, text, table, list, and figure. Only the found locations of the category text are used for the following steps of the summarization process.</p><h3>2. Use OCR to convert the image to text</h3><p>The next step is to convert the selected bounding boxes of the document into text. This part can be defined as an optical character recognition (OCR) problem, which was resolved using estabilished tools.&nbsp;</p><h3>3. Text Summarization of any paragraph</h3><p>The final step is the summarization of the selected content. So-called Transformers, which lately have proven to be powerful models, come to play. We used the tailored BERT model PEGASUS which is especially designed for automatic summarization. The outcome shows us a summarized version of the paragraph which we detected and extracted from the report in the first steps. The original length of 910 characters was reduced to 193 characters, leading to a time saving of almost 80%. Still, all the relevant information to understand the paragraph is included.</p><h4>This approach shrinks paragraphs in a PDF by 80 %</h4><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/summarize_annual_report.gif" alt=""><figcaption>The result of the automatic text summarization with the PEGASUS model of one paragraph extracted from the annual report shows us a good result. Let’s step through it to check what kind of aspects are included: name of company, likelyhood of an event, amount of the fine, name of the comission.</figcaption></figure><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-650x431.png" alt="" srcset="https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-650x431.png 650w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-300x199.png 300w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-150x100.png 150w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-768x510.png 768w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-1536x1019.png 1536w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-16x12.png 16w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924.png 1611w" sizes="(max-width: 650px) 100vw, 650px"></figure><h4>Join our Meetup talk on the 3rd of March 2021 from 5:00 pm to 6:00 pm GMT+1.</h4><h2>Do you want to learn more right now?</h2><h3>How to use object detection for page segmentation?</h3><p>Object detection is a task where objects of a known class are identified in the image and information about its location is provided. A very known architecture for this task is the Faster R-CNN. This architecture has two outputs for each object: a class label and a bounding-box. It consists of two modules: one deep fully convolutional network to propose regions and a Fast R-CNN that detects objects in those regions.</p><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-600x650.jpg" alt="Faster R-CNN has two outputs for each object: a class label and a bounding-box. " srcset="https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-600x650.jpg 600w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-277x300.jpg 277w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-139x150.jpg 139w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-768x832.jpg 768w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-11x12.jpg 11w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection.jpg 1229w" sizes="(max-width: 600px) 100vw, 600px"></figure><p>The way that works is that an input image is fed to a convolutional network that provides a feature map of that image. Then, a separated network (the region proposal network) takes that feature map and predicts possible regions for the objects (region proposals). Those region proposals are fed to a ROI pooling layer that reshapes them into a predefined size. Finally, the output vector from the pooling layer is used to classify the proposed regions and to refine the bounding boxes.&nbsp;</p><p>More recently, Mask R-CNN, which is an extension of the Faster R-CNN, added a third output that allows to have the mask of the object. This results in having the classification, bounding box and the mask of the object.The mask prediction is done in parallel with predicting the class and the bounding box [2].</p><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-542x650.jpg" alt=" By fine tuning a mask R-CNN model trained in the PubLayNet, we can have a model that allows us to detect those parts of the documents that correspond to text. " srcset="https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-542x650.jpg 542w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-250x300.jpg 250w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-125x150.jpg 125w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-768x920.jpg 768w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-10x12.jpg 10w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs.jpg 1049w" sizes="(max-width: 542px) 100vw, 542px"></figure><p>The goal is to select only the relevant parts of the report, in our case the text paragraphs. Other parts that already include summaries, like headlines or tables, are not relevant. So the first thing we need is an annotated dataset with the different document elements. PubLayNet is a dataset with annotations of text, figures, titles, lists and tables on more than 360 k pages of scientific papers [3]. By fine tuning a mask R-CNN model trained in the PubLayNet, we can have a model that allows us to detect those parts of the documents that correspond to text. The model that we used is available in the Detectron2 platform, which is a platform from Facebook AI Research that allows fast tests of state of art algorithms [4]. In the figure we can see the bounding boxes and the classification shown with a different color for each class, which was the result without any finetuning. For our problem we are not interested in the mask of the text, just the bounding box highlighted in blue.&nbsp;</p><p>Register for free and try out the page segmentation API with your own documents. <a href="https://app.konfuzio.com/v2/swagger/">Register to access our API documentation.</a> Using our document labeling tool you can create a dataset and fine-tune the PubLayNet model on your own documents.</p><figure><img src="https://lh4.googleusercontent.com/VqjsXgNjS9Na36xmpvqcFjgMbYWtyC4g_Xg0T0lDkggpol3mu1akQpHNWjj6P2T6oNBAPSpKpldVep3liFeX_egvwh2AuaZkbUBHM9wHEZcj_NnuBJ3so110A8g9Ynp45_rCTq9a" alt="Konfuzio API to segment pages via Faster R-CNN."></figure><h3>Wich is the best OCR engine?</h3><p>After having found the portion of the images that we are interested in, the next step is to extract the text from them with the use of optical character recognition (OCR). OCR can be done by computer vision approaches that can include detection, segmentation and recognition of characters but most recent approaches include a combination of CNNs and Recurrent Neural Networks.</p><p>An example of a OCR pipeline can be:</p><ul><li>Text detection – detects where the characters are located</li><li>Pre-processing – the text is normalized</li><li>Feature extraction – the output is the feature map of the image</li><li>Post processing – errors can be corrected by comparing with more common sequences of words, for example.&nbsp;</li></ul><p><a href="https://github.com/kba/awesome-ocr">Several OCR tools can be used.</a> We found the best approach to select the OCR per project. So at <a href="https://konfuzio.com/en/">Konfuzio </a>we integrate different OCR engines. In this video you can see how our API detects handwriting.</p><figure><p> <iframe title="Versteht Konfuzio Handschrift?" width="1170" height="878" src="https://www.youtube.com/embed/zbZgTYflpWk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></figure><h3>How does text summarization work?</h3><p>Summarization is now commonly performed using Transformer models. Transformers are a type of neural network architecture introduced in 2017. They were initially designed for machine translation, but are now used for almost all modern NLP applications, such as: entity recognition, natural language inference, question answering and summarization. Transformers are able to process all incoming data in parallel, in comparison to the previous state-of-the-art models, LSTMs, which processed data sequentially. This ability for parallelization makes them easier to scale up with an exponentially growing amount of compute and data.</p><p>The main novel concept introduced in the Transformer architecture is the use of “multi-head attention”. In the Transformer each element in the input sequence is split into three vectors: Q, K, and V. Attention calculated as a weighted sum of these vectors, where the weights are both learned and are context dependent. In other words, the data input into the model decides where the model should focus its attention. Multi-headed attention implies that we split each vector into multiple “heads” and calculate attention across each head in parallel. Therefore, we perform multiple attention calculations at once, all in parallel, before combining the results together at the output. [5]</p><p>The most commonly used Transformer variant is called BERT. BERT only uses the encoder from the original Transformer with very small architecture changes. The main novelty of BERT is that it was trained as a “masked language model” on a large amount of unlabelled text. Masked language models are tasked with “filling in the blanks” of a given sentence, i.e. given a sentence replace a few of the words with a [MASK] token and then try and predict what the actual word was. It turns out that this task teaches the model a lot about natural language, so much so that it is now common to take a pre-trained BERT model and then fine-tune it your desired task. This is usually a good starting point when trying out neural networks for NLP and most NLP research is now focused on how to improve Transformer models and their variants by either tweaking the architecture or inventing a new pre-training objective.&nbsp;</p><p>PEGASUS is a model designed for automatic summarization. The architecture is similar to the original Transformer, with the decoder, but it is pre-trained on two tasks simultaneously. The first task is the masked language modeling task introduced by BERT. The second task involves predicting an entire sentence that has been masked out in the input. PEGASUS is first pre-trained trained on a huge amount of text, consisting of 1.5 billion news articles and then fine-tuned on the target dataset. It achieved state-of-the-art performance across twelve commonly used summarization datasets. [6].</p><h4>Sources:</h4><p>[1] <a href="https://research.fb.com/publications/mask-r-cnn/" target="_blank" rel="noreferrer noopener">He, K. et al. (2017). Mask R-CNN. Facebook AI Research (FAIR).</a></p><p>[2] <a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" rel="noreferrer noopener">Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks.&nbsp;</a></p><p>[3] <a href="https://github.com/ibm-aur-nlp/PubLayNet" target="_blank" rel="noreferrer noopener">Zhong, X., Tang, J., &amp; Yepes, A. (2019). PubLayNet: largest dataset ever for document layout analysis. In 2019 International Conference on Document …</a></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://konfuzio.com/de/automatic-text-summarization-in-pdf-files">https://konfuzio.com/de/automatic-text-summarization-in-pdf-files</a></em></p>]]>
            </description>
            <link>https://konfuzio.com/de/automatic-text-summarization-in-pdf-files</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275071</guid>
            <pubDate>Fri, 26 Feb 2021 14:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Allowing Big Tech to Form “Techno-Governments” to Be Announced Today]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 89 (<a href="https://news.ycombinator.com/item?id=26274611">thread link</a>) | @TheWellerman
<br/>
February 26, 2021 | https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span data-preserver-spaces="true">Nevada Governor Steve Sisolak will be announcing legislation today that will allow major technology companies to effectively form techno-governments.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Gov. Sisolak first mentioned the proposal of creating “Innovation Zones” in Nevada during his&nbsp;</span><a href="https://thenevadaindependent.com/article/full-transcript-annotations-of-sisolaks-2021-state-of-the-state-address" target="_blank" rel="noopener"><span data-preserver-spaces="true">State-of-the-State address</span></a><span data-preserver-spaces="true">&nbsp;on January 19. “New companies creating groundbreaking technologies can come to Nevada to develop their industries. This will be done without tax abatements or public financing.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">While the legislation wouldn’t provide subsidiaries or public funding, according to a draft of the Bill obtained by the&nbsp;</span><a href="https://www.reviewjournal.com/news/politics-and-government/2021-legislature/bill-would-allow-tech-companies-to-create-local-governments-2272887/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Las Vegas Review-Journal</span></a><span data-preserver-spaces="true">, major technology firms would be granted authority to form their independent techno-governments within Nevada. “[They] would carry the same authority as a county, including the ability to impose taxes, form school districts and justice courts and provide government services, to name a few duties,” Las Vegas Review-Journal reports.&nbsp;</span></p>
<figure id="attachment_3641" aria-describedby="caption-attachment-3641"><img src="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png" alt="techno-governments " width="653" height="440" srcset="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png 653w,https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min-300x202.png 300w" sizes="(max-width: 653px) 100vw, 653px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png 653w, https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min-300x202.png 300w" data-src="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3641">Illustration shows Blockchains, LLC’s proposed “smart city” in rural northern Nevada. (Image Source: EYRC Architects/Blockchains LLC via AP)</figcaption></figure>

<p><span data-preserver-spaces="true">During his remarks in January, Gov. Sisolak specifically mentioned the company Blockchains, LLC as already being committed to creating a techno-government in the state that would “fully run on blockchain technology.” Gov. Sisolak said the move would make Nevada “the epicenter of this emerging industry and creating the high paying jobs and revenue that go with it.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">In the simplest terms, blockchain is a type of database system that stores computational information in groups, known as “blocks.” Though not entirely unalterable, blockchain technology is considered secure by design because data transactions between parties are recorded efficiently and in an open, verifiable, and permanent manner. Financial services, particularly cryptocurrencies, widely use blockchain technology.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The company mentioned explicitly by Gov. Sisolak, Blockchains, LLC, was founded in 2014 by consumer protection attorney and cryptocurrency millionaire <a href="https://www.blockchains.com/our-people/jeffrey-berns/" target="_blank" rel="noopener">Jeffrey Berns</a>.&nbsp;</span></p>
<p><span data-preserver-spaces="true">According to their&nbsp;</span><a href="https://www.blockchains.com/real-life-sandbox/" target="_blank" rel="noopener"><span data-preserver-spaces="true">website</span></a><span data-preserver-spaces="true">, Blockchains, LLC currently owns over 67,000 acres in Storey County, Nevada. The company says they aim to convert this land into “the most advanced ‘high-tech’ community and society for business and residents in the country.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Calling it “a new way to live,” Blockchains says they “believe the integration of our product suite is where the full potential of a smart community, digital economy, and connected society can be realized.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">“Blockchains aims to showcase how business development, residential living, and commerce can flourish alongside world-changing technologies. To do that, we have to start with a blank slate – otherwise, we’d merely be trying to insert smart technologies into devices that aren’t, well, ‘smart,'” reads the company’s “</span><a href="https://www.blockchains.com/real-life-sandbox/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Road to Development</span></a><span data-preserver-spaces="true">” plan.</span></p>
<p><span data-preserver-spaces="true">According to state records, in 2018, Blockchains purchased 67,125 acres of uninhabited land at the Tahoe Reno Industrial Center for $170 million. At the time, the company’s website did not list any executive, a phone number, or a clear explanation of what it’s software did, leading some local media outlets to label the company as “mysterious.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Since the land grab, Blockchains has been lobbying hard to get legislation passed that would allow the company to form its own techno-government.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Las Vegas Review-Journal reports Blockchains, LLC gave $50,000 to a political action committee, Home Means Nevada, which managed Sisolak’s transition into office in January 2019. Campaign&nbsp;</span><a href="https://www.followthemoney.org/entity-details?eid=48060485" target="_blank" rel="noopener"><span data-preserver-spaces="true">finance records</span></a><span data-preserver-spaces="true">&nbsp;also show the company donated $10,000 to Sisolak and his Republican opponent Adam Laxalt’s campaign in 2018.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Records also show the company’s owner, Jeffrey Berns, personally gave $50,000 to the Nevada Democratic Party in 2019 and various donations ranging from $1,000 to $5,000 to various state lawmakers from both parties.&nbsp;</span></p>
<p>Over a week ago,<em><span data-preserver-spaces="true"> The Debrief&nbsp;</span></em><span data-preserver-spaces="true">reached out to Blockchains, LLC for comment; however, the company did not respond to this request.&nbsp;</span></p>

<figure id="attachment_3640" aria-describedby="caption-attachment-3640"><img src="https://thedebrief.org/wp-content/uploads/2021/02/nevadasmartcty-min-e1614341465363.jpg" alt="techno-governments" width="760" height="428" data-src="https://thedebrief.org/wp-content/uploads/2021/02/nevadasmartcty-min-e1614341465363.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3640">Illustration shows Blockchains, LLC’s proposed “smart city” in rural northern Nevada. (Image Source: EYRC Architects/Blockchains LLC via AP)</figcaption></figure>

<p><span data-preserver-spaces="true">In an email to&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">, Communications Director for the Governor’s office, Meghin Delaney, said Gov. Sisolack will formally unveil the proposed “Innovation Zones” legislation during a virtual press conference today, Friday, February 26, at 4:30 pm (EST).&nbsp;</span></p>
<p><span data-preserver-spaces="true">Joining Gov. Sisolack at today’s conference will be Michael Brown, Executive Director of the Governor’s Office of Economic Development, and Jeremy Aguero, principal analyst at Applied Analysis.&nbsp;</span></p>
<p><span data-preserver-spaces="true">According to the&nbsp;</span><a href="https://www.reviewjournal.com/news/politics-and-government/2021-legislature/bill-would-allow-tech-companies-to-create-local-governments-2272887/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Las Vegas Review-Journal</span></a><span data-preserver-spaces="true">, the draft language in the proposal said the traditional local government model was “inadequate alone to provide the flexibility and resources conducive to making the State a leader in attracting and retaining new forms and types of businesses and fostering economic development in emerging technologies and innovative industries.”</span></p>
<p><span data-preserver-spaces="true">The draft proposal also reportedly said the creation of techno-governments or “alternative forms of local government” were needed to aid economic development within the state.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The Governor’s Office of Economic Development is slated to handle applications for the Innovation Zones, which would be limited to specific “innovative technologies,” including “blockchain, autonomous technology, the internet of things, artificial intelligence, wireless technology, biometrics, and renewable resource technology.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">The Governor’s Office of Economic Development redirected <em>The Debrief’s</em> questions on the legislation backing techno-governments to the Governor’s communications staff; since the Bill had not been formally proposed, much less passed.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The draft proposal laid out the requirements for companies to create their own techno-government, including an applicant owning at least 50,000 acres of undeveloped and uninhabited land, all within a single county but separate from any city, town or tax increment area.</span></p>
<p><span data-preserver-spaces="true">Big Tech companies would also have to pledge at least $250 million toward initial development, with a plan to invest an additional $1 billion over ten years in the zone.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Major technology companies would function as their own independent governmental body, with a three-member board of supervisors that would carry the same authority as a board of county commissioners. The Bill’s proposed draft suggests technology companies would have a significant say over who would sit on techno-government’s board.&nbsp;</span></p>
<p><span data-preserver-spaces="true">While the draft proposal provides insight into some of the details behind the concept, some aspects could be changed when the Bill is formally introduced.&nbsp;</span></p>
<figure id="attachment_3639" aria-describedby="caption-attachment-3639"><img src="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg" alt="techno-governments" width="640" height="441" srcset="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg 640w,https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min-300x207.jpg 300w" sizes="(max-width: 640px) 100vw, 640px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg 640w, https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min-300x207.jpg 300w" data-src="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3639">Las Vegas, Nevada (Image Source: Pixabay)</figcaption></figure>
<div><div id="block-wrap-74747" data-id="74747"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/capitol-hill-rioters-scrub-their-social-media-in-race-against-archivists/">
				<img width="120" height="120" src="https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-120x120.jpg" alt="capitol hill rioters" srcset="https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-120x120.jpg 120w,https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-150x150.jpg 150w,https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-70x70.jpg 70w,https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-240x240.jpg 240w,https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-360x360.jpg 360w,https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-540x540.jpg 540w,https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-720x720.jpg 720w,https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-125x125.jpg 125w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-120x120.jpg 120w, https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-150x150.jpg 150w, https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-70x70.jpg 70w, https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-240x240.jpg 240w, https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-360x360.jpg 360w, https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-540x540.jpg 540w, https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-720x720.jpg 720w, https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-125x125.jpg 125w" data-src="https://thedebrief.org/wp-content/uploads/2021/01/podiumguy-e1610045118871-120x120.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p><span data-preserver-spaces="true">Aside from lobbying by companies such as Blockchains, the primary motivation for proposing the allowance of techno-governments would be the hope that the move would significantly boost Nevada’s beleaguered economy.&nbsp;</span></p>
<p><span data-preserver-spaces="true">With tourism indirectly or directly accounting for&nbsp;</span><a href="https://www.travelnevada.biz/wp-content/uploads/Nevada-Visitor-Economic-Impact-2018.pdf" target="_blank" rel="noopener"><span data-preserver-spaces="true">almost 25%</span></a><span data-preserver-spaces="true">&nbsp;of the state’s economy, Nevada has been devastated by the COVID-19 pandemic. Las Vegas, the United States’ second-largest municipal tourism industry, accounted for over $19 billion of Nevada’s GDP before the pandemic. According to the&nbsp;</span><a href="http://nevadaresorts.org/cv19/Nevada%20NRA%20Corona%20Virus%20Assessment%20Fact%20Sheet%20%20FINAL.pdf" target="_blank" rel="noopener"><span data-preserver-spaces="true">Nevada Resort Association</span></a><span data-preserver-spaces="true">, tourism and leisure services account for one out of every three jobs in Nevada.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The&nbsp;</span><a href="https://www.brookings.edu/research/explaining-the-economic-impact-of-covid-19-core-industries-and-the-hispanic-workforce/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Brookings Institute</span></a><span data-preserver-spaces="true">&nbsp;found two Nevada cities, Las Vegas and Reno, were among the top three metro economies hardest-hit by the pandemic. In December 2020, the U.S. Bureau of Labor Statistics reported Nevada’s unemployment rate of 9.2% was the second-highest in the United States. Hawaii, which came in dead last, was only a tenth of a percentage point below Nevada at 9.3%.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Conversely, metropolitan hubs specializing in technology, such as Seattle and San Francisco, have thrived and benefited from COVID-19. Sales at non-store retailers (i.e., online shopping) increased by 15% from November 2019 to November 2020. Online retail giant Amazon, headquartered in Seattle,&nbsp;</span><a href="https://www.washingtonpost.com/technology/2020/10/29/amazon-hiring-pandemic-holidays/" target="_blank" rel="noopener"><span data-preserver-spaces="true">nearly doubled its workforce</span></a><span data-preserver-spaces="true">, adding 400,000 jobs in 2020. Social media monolith Facebook&nbsp;</span><a href="https://variety.com/2020/digital/news/facebook-hiring-10000-workers-small-business-grants-1234570018/" target="_blank" rel="noopener"><span data-preserver-spaces="true">announced</span></a><span data-preserver-spaces="true">&nbsp;plans to hire an additional 10,000 workers in April 2020.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The adage that “the most secure job is a federal government job” has held during the COVID-19 pandemic, and the U.S. Government grew by over 50,000 jobs in 2020. The metropolitan seat of America’s power, Washington D.C., saw a government employment rate increase over 2% last year.&nbsp;</span></p>
<p><span data-preserver-spaces="true">By allowing major technology corporations to form their techno-governments, Nevada will be trying to capture lightning in a bottle by enticing a mix of the most benefited industries during these economically downtrodden times.&nbsp;</span></p>
<p><span data-preserver-spaces="true">While economic benefits seem enticing, almost assuredly, there will be some public concerns over the idea of Big Tech being allowed to form its own sovereign governance.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In a&nbsp;</span><a href="https://ideas.ted.com/heres-the-real-danger-that-facebook-google-and-the-other-tech-monopolies-pose-to-our-society/" target="_blank" rel="noopener"><span data-preserver-spaces="true">2018 essay</span></a><span data-preserver-spaces="true">, technology analyst Jamie Bartlett warned technology monopolies posed a real threat to democracies. “Tech is just the latest vehicle for very rich people to use well-tested techniques of buying political influence, monopolistic behavior and avoiding regulation,” wrote Bartlett.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Fear over the power Big Tech companies wield has only increased in the past two years. The public and politicians alike have expressed concerns over Big Tech companies’ potential to be a cultural hegemony, dominating public ideas and beliefs.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The jury is still out as to the ultimate impact of allowing Big Tech to form techno-governments, provided that the proposed legislation passes.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In the area Blockchains plans to build their “better way to live,” Storey County Commissioner Lance Gilman was a little hesitant toward the proposed legislation during an interview with the Las Vegas Journal Review. “[It’s] going to have an impact on Storey County, and the jury is still out on whether that will be positive or negative.”</span></p>
<p><b>Join us on</b><a href="https://twitter.com/Debriefmedia"> <b>Twitter</b></a><b> or</b><a href="https://www.facebook.com/thedebriefnews"> <b>Facebook</b></a><b> to weigh in and share your thoughts on Big Tech …</b></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/">https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/</a></em></p>]]>
            </description>
            <link>https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274611</guid>
            <pubDate>Fri, 26 Feb 2021 13:37:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU poke 1.0]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26274466">thread link</a>) | @todsacerdoti
<br/>
February 26, 2021 | http://www.jemarch.net/poke-1.0-relnotes.html | <a href="https://web.archive.org/web/*/http://www.jemarch.net/poke-1.0-relnotes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jemarch.net/poke-1.0-relnotes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274466</guid>
            <pubDate>Fri, 26 Feb 2021 13:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Actually Portable Executable]]>
            </title>
            <description>
<![CDATA[
Score 613 | Comments 151 (<a href="https://news.ycombinator.com/item?id=26273960">thread link</a>) | @NilsIRL
<br/>
February 26, 2021 | https://justine.lol/ape.html | <a href="https://web.archive.org/web/*/https://justine.lol/ape.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
24 aug 2020 @ <a href="https://justine.lol/index.html"> justine's web page</a>

</p>

<p>
One day, while studying old code, I found out that it's possible to
encode Windows Portable Executable files as a UNIX Sixth Edition shell
script, due to the fact that the Thompson Shell didn't use a shebang
line. Once I realized it's possible to create a synthesis of the binary
formats being used by Unix, Windows, and MacOS, I couldn't resist the
temptation of making it a reality, since it means that high-performance
native code can be almost as pain-free as web apps. Here's how it works:

</p><pre>MZqFpD='
BIOS BOOT SECTOR'
exec 7&lt;&gt; $(command -v $0)
printf '\177ELF...LINKER-ENCODED-FREEBSD-HEADER' &gt;&amp;7
exec "$0" "$@"
exec qemu-x86_64 "$0" "$@"
exit 1
REAL MODE...
ELF SEGMENTS...
OPENBSD NOTE...
NETBSD NOTE...
MACHO HEADERS...
CODE AND DATA...
ZIP DIRECTORY...
</pre>

<p>
I started a project called
<a href="https://github.com/jart/cosmopolitan">Cosmopolitan</a> which
implements
the <a aria-label="Actually Portable Executable" href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/ape/ape.S">αcτµαlly
pδrταblε εxεcµταblε</a> format. I chose the name because I like the idea
of having the freedom to write software without restrictions that
transcends traditional boundaries. My goal has been helping C become a
build-once run-anywhere language, suitable for greenfield development,
while avoiding any assumptions that would prevent software from being
shared between tech communities. Here's how simple it is to get started:

</p><pre>gcc -g -O -static -fno-pie -no-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>
</pre>

<p>
In the above one-liner, we've basically reconfigured the stock compiler
on Linux so it outputs binaries that'll run on MacOS, Windows, FreeBSD,
OpenBSD, and NetBSD too. They also boot from the BIOS. Please note this
is intended for people who don't care about desktop GUIs, and just want
stdio and sockets without devops toil.

</p><h3>Platform Agnostic C / C++ / FORTRAN Tooling</h3>

<p>
Who could have predicted that cross-platform native builds would be this
easy? As it turns out, they're surprisingly cheap too. Even with all the
magic numbers, win32 utf-8 polyfills, and bios bootloader code, exes
still end up being roughly 100x smaller than Go Hello World:

</p><p>
  <a href="https://justine.lol/life.com">life.com</a> is 12kb (<a href="https://justine.lol/life.com.dbg">symbols</a>,
  <a href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/examples/life.c">source</a>)
  <br>
  <a href="https://justine.lol/hello.com">hello.com</a> is 16kb (<a href="https://justine.lol/hello.com.dbg">symbols</a>,
  <a href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hello.c">source</a>)
  <br>

</p><p>
Please note that zsh has a minor backwards compatibility glitch with
Thompson Shell [update
2021-02-15: <a href="https://github.com/zsh-users/zsh/commit/326d9c203b3980c0f841bc62b06e37134c6e51ea">zsh
has now been patched</a>] so try <code>sh hello.com</code> rather
than <code>./hello.com</code>. That one thing aside, if it's this easy,
why has no one done this before? The best answer I can tell is it
requires an minor ABI change, where C preprocessor macros relating to
system interfaces need to be symbolic. This is barely an issue, except
in cases like <code>switch(errno){case EINVAL:...}</code>. If we feel
comfortable bending the rules, then the GNU Linker can easily be
configured to generate at linktime all the PE/Darwin data structures we
need, without any special toolchains.

</p><h3>PKZIP Executables Make Pretty Good Containers</h3>

<p>
Single-file executables are nice to have. There are a few cases where
static executables depending on system files makes sense, e.g. zoneinfo.
However we can't make that assumption if we're building binaries
intended to run on multiple distros with Windows support too.

</p><p>
As it turns out, PKZIP was designed to place its magic marker at the end
of file, rather than the beginning, so we can synthesize ELF/PE/MachO
binaries with ZIP too! I was able to implement this efficiently in the
Cosmopolitan codebase using a few lines of linker script, along with a
program for incrementally compressing sections.

</p><p>
It's possible to run <code>unzip -vl executable.com</code> to view its
contents. It's also possible on Windows 10 to change the file extension
to .zip and then open it in Microsoft's bundled ZIP GUI. Having that
flexibility of being able to easily edit assets post-compilation means
we can also do things like create an easily distributable JavaScript
interpreter that reflectively loads interpreted sources via zip.

</p><p>
  <a href="https://justine.lol/hellojs.com">hellojs.com</a> is 300kb (<a href="https://justine.lol/hellojs.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hellojs.c">source</a>)

</p><p>
Cosmopolitan also uses the ZIP format to automate compliance with the
GPLv2 [update 2020-12-28: APE is now licensed ISC]. The non-commercial
libre build is configured, by default, to embed any source file linked
from within the hermetic make mono-repo. That makes binaries roughly 10x
larger. For example:

</p><p>
  <a href="https://justine.lol/life2.com">life2.com</a> is 216kb (<a href="https://justine.lol/life2.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/life.c">source</a>)
  <br>
  <a href="https://justine.lol/hello2.com">hello2.com</a> is 256kb (<a href="https://justine.lol/hello2.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hello.c">source</a>)
  <br>

</p><p>
Rock musicians have a love-hate relationship with dynamic range
compression, since it removes a dimension of complexity from their
music, but is necessary in order to sound professional. Bloat might work
by the same principles, in which case, zip source file embedding could
be a more socially conscious way of wasting resources in order to gain
appeal with the non-classical software consumer.

</p><h3>x86-64 Linux ABI Makes a Pretty Good Lingua Franca</h3>

<p>
It wasn't until very recently in computing history that a clear shakeout
occurred with hardware architectures, which is best evidenced by the
<a rel="nofollow" href="https://en.wikipedia.org/w/index.php?title=TOP500&amp;oldid=966847096#Architecture_and_operating_systems">TOP
500 list</a>. Outside phones routers mainframes and cars, the consensus
surrounding x86 is so strong, that I'd compare it to the Tower of Babel.
Thanks to Linus Torvalds, we not only have a consensus on architecture,
but we've come pretty close to having a consensus on the input output
mechanism by which programs communicate with their host machines, via
the SYSCALL instruction. He accomplished that by sitting at home in a
bathrobe sending emails to huge corporations, getting them to agree to
devote their resources to creating something beautifully opposite to
tragedy of the commons.

</p><p>
So I think it's really the best of times to be optimistic about systems
engineering. We agree more on sharing things in common than we ever
have. There are still outliers like the plans coming out of Apple and
Microsoft we hear about in the news, where they've sought to pivot PCs
towards ARM. I'm not sure why we need a C-Class Macintosh, since the
x86_64 patents should expire this year. Apple could have probably made
their own x86 chip without paying royalties. The free/open architecture
that we've always dreamed of, might turn out to be the one we're already
using.

</p><p>
If a microprocessor architecture consensus finally exists, then I
believe we should be focusing on building better tools that help
software developers benefit from it. One of the ways I've been focusing
on making a contribution in that area, is by building a friendlier way
to visualize the impact that x86-64 execution has on memory. It should
should hopefully clarify how <span aria-label="Actually Portable
Executable">αcτµαlly pδrταblε εxεcµταblε</span> works.

</p><center>
    <video id="video" width="960" height="540" controls="" autoplay="" muted="" loop="">
      <source src="https://storage.googleapis.com/justine/emulator2.mp4" type="video/mp4">
    </video>
    
  </center>

<p>
You'll notice that execution starts off by treating the Windows PE
header as though it were code. For example, the ASCII string <code>"MZqFpD"</code>
decodes as <code>pop %r10 ; jno 0x4a ; jo 0x4a</code> and the string
<code>"\177ELF"</code> decodes as <code>jg 0x47</code>. It then hops
through a mov statement which tells us the program is being run from
userspace rather than being booted, and then hops to the entrypoint.

</p><p>
Magic numbers are then 
<a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/sysv/systemfive.S">easily
unpacked</a> for the host operating system using decentralized sections
and the GNU Assembler <code>.sleb128</code> directive. Low entropy data
like UNICODE bit lookup tables will generally be decoded using either
a <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/str/lz4cpy.c">103
byte LZ4 decompressor</a> or
a <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/nexgen32e/rldecode.S">17
byte run-length decoder</a>, and runtime code morphing can easily be
done using
Intel's <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/third_party/xed/x86ild.greg.c">3kb
x86 decoder</a>.

</p><p>
Please note that this emulator isn't a
requirement. <span aria-label="Actually Portable Executables">αcτµαlly
pδrταblε εxεcµταblεs</span> work fine if you just run them on the shell,
the NT command prompt, or boot them from the BIOS. This isn't a JVM. You
only use the emulator if you need it. For example, it's helpful to be
able to have cool visualizations of how program execution impacts
memory.

</p><p>
It'll be nice to know that any normal PC program we write will "just
work" on Raspberry Pi and Apple ARM. All we have to do embed an ARM
build of the emulator above within our x86 executables, and have them
morph and re-exec appropriately, similar to how Cosmopolitan is already
doing doing with qemu-x86_64, except that this wouldn't need to be
installed beforehand. The tradeoff is that, if we do this, binaries will
only be 10x smaller than Go's Hello World, instead of 100x smaller. The
other tradeoff is the GCC Runtime Exception forbids code morphing, but I
already took care of that for you, by rewriting the GNU runtimes.

</p><p>
The most compelling use case for making x86-64-linux-gnu as tiny as
possible, with the availability of full emulation, is that it enables
normal simple native programs to run everywhere including web browsers
by default. Many of the solutions built in this area tend to focus too
much on the interfaces that haven't achieved consensus, like GUIs and
threads, otherwise they'll just emulate the entire operating system,
like Docker or Fabrice Bellard running Windows in browsers. I think we
need compatibility glue that just runs programs, ignores the systems,
and treats x86_64-linux-gnu as a canonical software encoding.

</p><h3>Long Lifetime Without Maintenance</h3>

<p>
One of the reasons why I love working with a lot of these old unsexy
technologies, is that I want any software work I'm involved in to stand
the test of time with minimal toil. Similar to how the Super Mario Bros
ROM has managed to survive all these years without needing a GitHub
issue tracker.

</p><p>
I believe the best chance we have of doing that, is by gluing together
the binary interfaces that've already achieved a decades-long consensus,
and ignoring the APIs. For example, here are the
<a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/sysv/consts.sh">magic
numbers</a> used by Mac, Linux, BSD, and Windows distros. They're worth
seeing at least once in your life, since these numbers underpin the
internals of nearly all the computers, servers, and phones you've used.

</p><p>
If we focus on the subset of numbers all systems share in common, and
compare it to their common ancestor, Bell System Five, we can see that
few things about systems engineering have changed in the last 40 years
at the binary level. Magnums are boring. Platforms can't …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justine.lol/ape.html">https://justine.lol/ape.html</a></em></p>]]>
            </description>
            <link>https://justine.lol/ape.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273960</guid>
            <pubDate>Fri, 26 Feb 2021 12:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Reading More Effectively and Efficiently]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 162 (<a href="https://news.ycombinator.com/item?id=26273735">thread link</a>) | @ingve
<br/>
February 26, 2021 | https://aliabdaal.com/read-more-effectively/ | <a href="https://web.archive.org/web/*/https://aliabdaal.com/read-more-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>It might seem odd to have a blog post devoted entirely to reading. After all, if you’re reading this, chances are you can read. But reading effectively and efficiently is its own skill - one that we’re never really taught how to do.</p><p>Throughout our academic life, we’re programmed to believe that effective reading is measured by speed and breadth. The more we can read, the smarter we look. And the more broadly we can read, the more intelligent we seem.</p><p>In fact, I’ve fallen prey to this myself, making a clickbait video called <em><a href="https://www.youtube.com/watch?v=8tKuviI68Ss">How I Read 100 Books a Year</a></em>. Full disclosure: I don’t actually. It’s closer to 50. But that makes for a less clickable video (sorry, not sorry).</p><p>Because of this obsession we have with reading more, we miss out on a lot of valuable insights. Wisdom from across the ages, the lessons mastered by people who've overcome extraordinary challenges, and the chance to gain knowledge that challenges our beliefs. All because we're never taught the ultimate meta-skill: the art of reading.</p><p>Reading more effectively and efficiently means developing a watertight process to <strong>capture ideas</strong>, <strong>analyse arguments</strong>, and <strong>ask the right questions</strong>. It means identifying the <strong>right books to read</strong>, understanding the <strong>different reading goals</strong>, and using evidence-based techniques to <strong>increase reading productivity</strong>.</p><p>In many ways, improving the way we read is the number one skill that can change our lives for the better.</p><h2 id="the-importance-of-effective-efficient-reading">The Importance of Effective &amp; Efficient Reading</h2><blockquote>“A person who won’t read has no advantage over one who can’t read" - Mark Twain</blockquote><p>Books have had an enormous impact on my own life. They’ve acted as a personal mentor, and as a vehicle for compounding knowledge.</p><h3 id="-books-have-been-my-personal-mentors">🤓 Books have been my Personal Mentors</h3><p>If someone asked me to name the most influential people in shaping my life (outside of my immediate family), I wouldn't find it too hard to identify a group of people who've transformed my thinking through their incredible actions, ideas, and journeys. But the number one influence in my life wouldn't be people at all. It would be books.</p><p>By reading lots of books (and by trying to read effectively), I've managed to accumulate decades worth of knowledge and experience from the world's most incredible minds, with minimal personal effort. I've learned from mistakes without having to fail, I've learned from successes without having to take huge risks, and I've travelled thousands of miles without leaving the comfort of my bed in Cambridge.</p><p>Reading is the mentor without the cost, the pain, and the discomfort. I honestly wouldn't have started <a href="https://6med.co.uk/">6med</a>, my <a href="https://www.youtube.com/channel/UCoOae5nYA7VqaXzerajD0lg">YouTube channel</a>, or decided to <a href="https://book.aliabdaal.com/">write a book</a> without the encouragement, motivation, inspiration, and boundless insights offered by my paper friends. Seriously. My only regret is that I didn't learn to read properly sooner.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/hv1gOEY3cs4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>3 Books That Changed My Life</figcaption></figure><h3 id="-books-help-us-compound-knowledge">🧠 Books help us Compound Knowledge</h3><blockquote>"Compound interest is the 8th Wonder of the World" - Albert Einstein</blockquote><p>Just as money accumulates exponentially, so too does personal knowledge as it snowballs and branches out over time. In other words, the more we read and the better our reading processes are, the more our ideas, beliefs, and opinions begin to develop at an ever-increasing rate.</p><p>Not only does our brain begin effortlessly creating connections between seemingly disparate pieces of information, but cohesive and creative solutions to some of our most puzzling and perplexing problems gradually emerge. It's a personal superpower that all of us have the opportunity to discover.</p><blockquote>“To develop a complete mind: Study the science of art; Study the art of science. Learn how to see. Realise that everything connects to everything else” - Da Vinci</blockquote><h2 id="the-reading-objective">The Reading Objective</h2><p>Increasing our ability to read more effectively, as a means to unlock our own personal potential, begins by deciding on a reading goal. After all, we’re probably going to have a different objective and experience reading <em>Paradise Lost</em> compared to our favourite <em>Harry Potter</em> book.</p><p>Many brilliant authors talk about books as having a rather loose objective of success, happiness, and personal fulfilment. Roald Dahl, for instance, said that "if you are going to get anywhere in life, you have to read a lot of books". And J. K. Rowling once said that "something very magical can happen when you read a good book".</p><p>But I’d agree, these opinions are abstract, subjective, and largely unhelpful in guiding the way in which we should read. Instead, it's easier and more useful for our purposes to segment reading objectives into three distinct categories, as identified by Mortimer Adler in <em><a href="https://geni.us/HkStXXO">How to Read a Book</a></em>.</p><h3 id="-category-1-reading-to-entertain">🤪 Category 1: Reading to Entertain</h3><p>In this category, we read books purely for enjoyment. It’s how we spend the majority of our time as readers. There are no rules and there's no need to think too deeply or critically about what we’re reading. The goal is simple: we can relax and immerse ourselves in the story.</p><p>There’s nothing inherently wrong with reading to entertain ourselves.</p><p>It's a healthy way to escape from everyday stress and, if you're anything like me, a perfect way to finish <a href="https://www.youtube.com/watch?v=KMskdqtR1yA">a productive day of work</a>. In particular, I enjoy reading (or listening to) fantasy novels (with the <a href="https://brandonsanderson.com/">Brandon Sanderson</a> books being a personal favourite). I even created a video on <em><a href="https://www.youtube.com/watch?v=i7awefFU_Hg">My Favourite Fantasy Books</a></em>, which you can check out if you're interested.</p><h3 id="-category-2-reading-to-inform">🗞 Category 2: Reading to Inform</h3><p>In this second category, we read books to learn specific facts or information about something. These books are typically easy to navigate and simple in their layout and structure. This lets us consume them effortlessly and jump around to relevant sections without losing the gist of what's being said. The goal is to <strong>learn without judgement</strong>.</p><p>For example, we'd read the newspaper, a tourist guide, or the <em>Guinness World Records, </em>all to inform. Although we may find aspects of each of them entertaining, we primarily read these things to develop a factual picture of current affairs, a particular location, or some other snippet of knowledge.</p><p>Again, for most of us, reading to inform isn't too problematic.</p><h3 id="-category-3-reading-to-understand">📖 Category 3: Reading to Understand</h3><p>It's the final category of reading - reading to understand - that most of us (including me) tend to struggle with. It therefore deserves most of our attention when it comes to improving the efficiency and effectiveness of our reading.</p><p>The problem is that out of the three reading categories, reading to understand requires the greatest cognitive effort. It forces us to challenge our preconceptions, critically analyse the status quo, and directly confront ideas that we may not be immediately comfortable with. This is hard. It can be uncomfortable. But it’s the only way for us to level-up our thinking and personal growth.</p><p>Ultimately, this is a skill that few of us have mastered. But it's at the very heart of meaningful productivity and improving the way we read. Therefore, we need a method that takes us from reading at an elementary level (like when we’re reading to entertain and inform) to reading at an analytical or syntopical level.</p><p>Let's dive into how we can do this.</p><h2 id="the-four-levels-of-reading">The Four Levels of Reading</h2><figure><img src="https://aliabdaal.com/content/images/2021/02/GW-Article.png" alt="" srcset="https://aliabdaal.com/content/images/size/w600/2021/02/GW-Article.png 600w, https://aliabdaal.com/content/images/size/w1000/2021/02/GW-Article.png 1000w, https://aliabdaal.com/content/images/size/w1600/2021/02/GW-Article.png 1600w, https://aliabdaal.com/content/images/2021/02/GW-Article.png 2000w" sizes="(min-width: 720px) 720px"></figure><p>While the three categories of reading help guide our reading goal, the four cumulative levels of reading help guide our reading style. These levels were again devised by Mortimer Adler and operate to help us understand a book at a far deeper level than what most of us are used to. As we move up the levels we'll not only find ourselves more capable of grasping the author's perspectives and forge deeper insights, but we'll have a process that works with every single book we decide to read.</p><p>This is great stuff.</p><h3 id="-level-1-elementary-reading">👶 Level 1: Elementary Reading</h3><p>The first level of reading is the style of reading that everyone knows how to do, as it's what we're taught in school. As an elementary reader we can easily understand the words on the page, follow the plot, and have a solid grasp of what the book is trying to say.</p><p>However, even at this elementary level, it's easy to screw it up by trying to read too quickly.</p><p>As you know, I'm all about <a href="https://aliabdaal.com/productivity/">increasing productivity</a>, but trying to improve reading speed before understanding the fundamentals of effective reading is only going to hinder our capacity to learn new information.</p><p>My advice - we should try and first improve our reading level. Then, once we've mastered the art of reading analytically, we can worry about reading faster (and we'll talk more about this later).</p><blockquote>"Every book should be read no more slowly than it deserves, and no more quickly than you can read it with satisfaction and comprehension” - Adler</blockquote><h3 id="-level-2-inspectional-reading">🔎 Level 2: Inspectional Reading</h3><p>This second level of reading requires marginally more skill than at the elementary reading level. As an inspectional reader we're tasked with unearthing the overall framework of the book and mapping out the general picture the author is trying to paint. The idea is that we're making some preliminary calculations about the book's content and worth before delving into it properly.</p><p>There are two aspects to inspectional reading: systematic skimming and superficial reading.</p><p><strong>Systematic Skimming</strong></p><p>With systematic skimming our aim is to decide whether or not this is a book we actually want to spend the time reading. I like to ask myself "is this one of the greats that I'd happily spend the next few hours of my life looking at?". If the answer is anything less than "hell yes!" then I won't bother reading it.</p><p>To help me answer this question, I first look at the title, the blurb, and the contents page to determine what the book is about and understand its high-level structure. I then flip through the book concentrating on each chapter's introduction, conclusion, and any sub-headings that interest me. In other words, I do a surface level examination of the book before writing a couple of sentences that neatly summarises everything.</p><p>Another way to systematically skim a book is by reading a book summary. My favourite way of doing this is with the service <a href="https://go.aliabdaal.com/shortform">Shortform</a>. If a book’s available on <a href="https://go.aliabdaal.com/shortform">Shortform</a> (they’re always adding …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aliabdaal.com/read-more-effectively/">https://aliabdaal.com/read-more-effectively/</a></em></p>]]>
            </description>
            <link>https://aliabdaal.com/read-more-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273735</guid>
            <pubDate>Fri, 26 Feb 2021 11:36:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp and most alternatives share the same problem]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 179 (<a href="https://news.ycombinator.com/item?id=26273594">thread link</a>) | @sysoleg
<br/>
February 26, 2021 | https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/ | <a href="https://web.archive.org/web/*/https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
            
            
<p>Shall I migrate to Signal, Threema or Telegram? No, because they all have — WhatsApp included — the same problem: They are walled gardens. Imagine a world where for each mail recipient using a separate domain, I would need separate mail client? Or in other words: Gmail users can only communicate with Gmail users.</p>



<h5>Let’s start with mail first.</h5>



<p>The origin of mail were a couple of geeks who wanted to exchange messages on ARPANET (the internets great grandmother). At the time they solved two challenges. Invent a packet-switching network with distributed control that was intended to survive a nuclear attack. And hook up different types of computers types that were not interoperable at the time: A DEC PDP-10, a SDS Sigma 7, an IBM 360/75 and SDS 940. The second topic is our primary issue here.</p>



<figure><img loading="lazy" width="622" height="749" src="https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969.jpg" alt="" srcset="https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969.jpg 622w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-249x300.jpg 249w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-580x698.jpg 580w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-320x385.jpg 320w" sizes="(max-width: 622px) 100vw, 622px"></figure>



<p>To achieve this they agreed on a common terminology and on common standards to exchange messages in a collaborative way. Layering on existing definitions (such as TCP/IP) they created:</p>



<ul><li>RFC 524: <a href="https://tools.ietf.org/html/rfc524">A Proposed Mail Protocol</a></li><li>RFC 561: <a href="https://tools.ietf.org/html/rfc561">Standardizing Network Mail Headers</a></li><li>RFC 680: <a href="https://tools.ietf.org/html/rfc680">Message Transmission Protocol</a></li><li>RFC 724: <a href="https://tools.ietf.org/html/rfc724">Proposed Official Standard for the Format of ARPA Network Messages</a></li></ul>



<p>That summed up later in the document RFC 733: <a href="https://tools.ietf.org/html/rfc733">STANDARD FOR THE FORMAT OF ARPA NETWORK TEXT MESSAGES</a> . And many of the aspects solved back then still live in today’s mail infrastructure. Including an address scheme using “@”.</p>



<figure><img loading="lazy" width="1024" height="655" src="https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1024x655.jpg" alt="" srcset="https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1024x655.jpg 1024w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-300x192.jpg 300w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-768x492.jpg 768w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1536x983.jpg 1536w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-720x461.jpg 720w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-580x371.jpg 580w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-320x205.jpg 320w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson.jpg 1656w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raymond&nbsp;Tomlinson who implemented the first&nbsp;email&nbsp;program on the&nbsp;ARPANET</figcaption></figure>



<p>Later the transport of the messages (originally they used multiple protocols such as CPYNET, UUCP or FTP) transitioned in 1981 to SMTP which is still todays way to transport mail. All of this allows that any mail client (MUA = Mail User Agent) can talk via any mail server (MTA = Mail Transfer Agent). An open, collaborative process defining an interoperable system.</p>



<h5>And now come the instant messengers.</h5>



<p>As I already said Signal, Threema, Telegram AND WhatsApp are broken. Why does everybody wanting to exchange messages need the same client? Before digging into more technical detail or rant about companies earning money with closed gardens let come to a possible solution: <a href="https://matrix.org/">The Matrix-Protocol</a>. In short it’s about the same deal as mail (building on HTTP and WebRTC) but for chat-messaging (including IP-telephony and video-telephony) initiated by a non-profit foundation based in the UK. After XMPP or IRC it’s not the only approach to solve the issue, but so far the most successful.</p>



<p>Their reference implementation of the client is called <a href="https://matrix.org/docs/projects/client/element">Element (former Riot)</a> and a server called <a href="https://github.com/matrix-org/synapse/">Synapse</a>. So in theory there could be any chat client communicating over any chat server to any chat client. Sadly it’s not really used yet. Although the <a href="https://www.heise.de/security/meldung/Tchap-Frankreichs-nicht-so-exklusiver-Regierungschat-4403961.html">French Government</a> is supporting it with a client implementation named Tchap and <a href="https://www.golem.de/news/messenger-bundeswehr-will-komplett-auf-matrix-chat-wechseln-2005-148407.html">German Bundeswehr</a> plans to do alike.</p>



<h5>So what?</h5>



<p>Well no real cheering news and in case don’t want to be alone on Matrix you can write to @juerg:matrix.org.</p>



<p>And will it work? No, because there is already too much money in the game (and telcos try to <a href="https://stuker.com/2018/die-sms-nachfolge-heisst-rcs-rich-communication-services/">reanimate the SMS Eldorado</a> too, without success).</p>



<p>But it would be the right thing. And me? I don’t’ switch, I use them all!</p>



<p>PS: The post was inspired by the very nice article <a href="https://www.republik.ch/2021/02/24/kill-the-messenger">“Kill the Messenger”</a>.</p>

                        
            
        </div></div>]]>
            </description>
            <link>https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273594</guid>
            <pubDate>Fri, 26 Feb 2021 11:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Interactive real-time chemistry and fluids: water electrolysis]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26272642">thread link</a>) | @pkarnakov
<br/>
February 26, 2021 | https://cselab.github.io/aphros/wasm/electrochem.html | <a href="https://web.archive.org/web/*/https://cselab.github.io/aphros/wasm/electrochem.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cselab.github.io/aphros/wasm/electrochem.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272642</guid>
            <pubDate>Fri, 26 Feb 2021 08:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being on Call]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 124 (<a href="https://news.ycombinator.com/item?id=26272170">thread link</a>) | @colluder
<br/>
February 25, 2021 | https://tyler.kim/being-on-call | <a href="https://web.archive.org/web/*/https://tyler.kim/being-on-call">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        

        <p>
          April 21, 2020

            ☼ <a href="https://tyler.kim/tagged/life">life</a>
            ☼ <a href="https://tyler.kim/tagged/roka">roka</a>
        </p>

        
<p>I’m an occasional on-call operator for my battalion, assisting the on-call commander and staffing the control room from 16:00 in the afternoon until 08:30 the next morning on weekdays. Most of the work is answering and making calls, updating documents, and making sure that nothing is out of the ordinary. It’s not that difficult, just tiring as there is a lot of stuff to follow and pay attention to through the night.&nbsp;</p>
<p>I was on-call on Friday, the 10th, and for 24 hours last Wednesday (not the usual shift), starting from 08:30 to the next 08:30 since it was the legislative election day in Korea. I wrote most of this post over those two shifts to share how I personally am being on-call.</p>

<hr>

<p>A little past 2300 is when I try to find some peace. I usually make myself a cup of coffee, and it doesn’t take long to feel the caffeine flowing through my bloodstream. I’m exhausted. It’s been many hours since I started my shift, and I have nine hours to go. No shift goes without a hectic evening with lots of random situations to handle, and they are usually followed by a series of paperwork.</p>
<p>I sit in front of a bunch of monitors and tactical comms equipment in bad posture, and the chair predates the concept of ergonomics. Meanwhile my feet are trapped in my airtight combat boots and they are begging to take a breath. In addition, no matter how much water I drink, my mouth is dry the whole time. It’s probably from all the sugar-intakes from snacking. It’s a similar feeling to a tiring second day at a college hackathon - constant snack intakes and sleep deprivation.</p>
<p>Around midnight, after I’m finished with all the paperwork that needs to be done by the morning, is a good time to seek solace in a cup ramen. It’s hard to convey the exact late-night-cup-ramen sentiment, but the hot soup warms you up in a way no others can console you in this late time.&nbsp;</p>
<p>I also have books with me so that I can read whenever I can. Late in the night especially after a ramen session is usually a good time to read. Every time I try to read in the evening or during the day, I either get a disruptive phone call or a situation, and they make me re-read the same page multiple times. It gets annoying after a couple of tries.</p>
<p>When I tried to read on the past few shifts, I faced some sad ironies. I brought <em>Why We Sleep</em> to my first shift. Reading about the importance of sleep while not being able to sleep was quite saddening, so I stopped after a few pages in. At least I learned why I feel wide awake towards the end of my shift (in the morning), and why I have difficulties sleeping after my shift despite being tired as hell. Now I’m reading <em>the Utopia of Rules</em>, a book filled with social commentaries on bureaucracy and filling out paper forms. Reading that in between the processing and filling out a ton of paperwork was yet another sad irony I encountered. Inevitably and unfortunately, as the night passes, my ability to focus gets decimated. I wish I could accomplish more reading on the job.&nbsp;</p>
<p>Around 0300~0400, a little after 12 hours (or 20) into the shift, I’m usually passed out on my desk. In a zombie-like state, I get half-woken up by periodic phone calls but I occasionally sleep through the ringings. Sometimes I answer the phone and pretend to handle whatever they tell me, and then go right back to sleep, forgetting everything I heard. I also get woken up when I have to unlock a small safe with ammunition for those going to a guard shift at night. Even then, my body isn’t fully awake sometimes.&nbsp;</p>
<p>By dawn, I can feel my internal organs are rotting. With that, my body starts to produce an uncomfortable amount of gas. A little past 0600, with my internal rhythm resetting, my body spontaneously wakes me up. It’s when I start to get busy again. Meanwhile my body goes through this illusion of feeling refreshed, but soon enough it feels like it has aged about six months over the past six hours. It’s obviously not a great feeling and it takes me about two full days to recover. Five more on-call shifts will age me by two years.&nbsp;</p>
<p>Despite such horribleness, the one positive aspect about doing the on-call shifts is that I get to sleep in and rest for the entirety of the next day, getting exempt from pretty much everything. Then, after one shift, two days have gone by just like that. Time flies and a week passes by only after a few days. And I get to rest over the weekend. That’s a good feeling to have in here, the sense of getting closer to the discharge date quicker than how I would feel it otherwise. Just gotta rinse and repeat till I’m out. It’s like Stockholm syndrome - despite how shitty I feel during and after the shift, I’m a bit disappointed that I don’t have a shift this week.</p>

        <br>

  

</div></div>]]>
            </description>
            <link>https://tyler.kim/being-on-call</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272170</guid>
            <pubDate>Fri, 26 Feb 2021 07:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ISO 8601: a better date format]]>
            </title>
            <description>
<![CDATA[
Score 331 | Comments 394 (<a href="https://news.ycombinator.com/item?id=26272084">thread link</a>) | @kirbykevinson
<br/>
February 25, 2021 | https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/ | <a href="https://web.archive.org/web/*/https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

				
				
	<p>If you haven’t been living under a rock, you’ve probably heard that
there are different date formats in the world such as the American one
(mm/dd/yyyy) and the European one (dd.mm.yyyy). If you’re smart
enough, you’ve probably also noticed that the American one makes no
sense and is just awful. A simple conclusion that many people draw out
of this is that the European format is the best one, however I don’t
think this is true. If you’re one of these people who think so, I’m
here to (hopefully) change your mind by introducing you to a
lesser-known date format called ISO 8601.</p>
<h2 id="basics">Basics</h2>
<p>As you can see by the “ISO” part in the format’s name, it’s an actual
standard written by the International Organization for
Standardization. It defines many cool things like a way to write time
intervals, which can be useful for writing portable software, and a
calendar where the year is separated not by months but by weeks, which
is used in finances, but here we’re only interested in the basics.
Simplified, the core date format looks like this:</p>
<pre><code>yyyy-mm-dd hh:mm:ss
</code></pre><p>Yup, that’s about it. You write the year, the month, the day, and then
the time exactly like it’s done in other date formats. There’s nothing
extraordinary, so you can learn it in 2 minutes.</p>
<h2 id="why-its-better">Why it’s better</h2>
<h3 id="its-unambigous">It’s unambigous</h3>
<p>This is the main reason the standard was written and why people still
use it. Other date formats can be diffucult to tell apart. For
example, consider this date:</p>
<pre><code>02-03-04
</code></pre><p>When you read it out of context, you have absolutely no idea what’s
going on there. Is <code>02</code> here the day or the month? You just can’t know
unless the day in the date is greater than 12, in which case it just
can’t be a month:</p>
<pre><code>30-03-04
</code></pre><p>This day-month ambiguity is a really common problem, which often
occurs online. People just write down their dates in whatever date
format they know without even thinking that other people can interpret
it in different ways.</p>
<p>ISO 8601 doesn’t have this problem as it’s always obvious which part
is the day and which is the month because of the uniqueness of the
format:</p>
<pre><code>2004-03-02
</code></pre><h3 id="its-more-strict">It’s more strict</h3>
<p>While other date formats usually don’t provide strict requirements on
how to write something, ISO 8601 is an exception. Here there’s only
one correct way to write a date, which is not only useful for
computers to parse, but also helpful for humans to avoid confusion
with other formats and improve readability. Here are some of the
restrictions:</p>
<ul>
<li>The elements in the date are always separated by a hyphen. Not many
date formats use this delimiter, and this also can be useful when
using dates inside filenames as slashes are usually not accepted in
them.</li>
<li>The elements are always padded to the maximum number of digits. This
not only makes all of the dates look equally nice, but also, coupled
with other quirks of this format, allows the files with the date in
the name to be sorted just by the filename.</li>
<li>The year is always written in the full form. This makes the format
unique when written down and  eliminates <a href="https://en.wikipedia.org/wiki/Year_2000_problem">the year 2000 problem</a> in
any forms that it can take. For example, when writing down
birthdays, it always makes it obvious which century we’re talking
about.</li>
<li>The time is always written in the 24 hour format, so there can be no
confusion about what half of the day something happened in.</li>
</ul>
<h3 id="it-makes-more-sense">It makes more sense</h3>
<p>On the first glance, it seems like the European format is about as
logical as it can get - days go into months and months go into years:</p>
<pre><code>18.12.2002
---------&gt; Elements
</code></pre><p>However, this ignores a very important characteristic of numbers -
endianness. Consider a regular number, for example:</p>
<pre><code>69420
&lt;---- Digits
</code></pre><p>As you can see the digits here do the opposite of what elements do in
the European format. When the leftmost element of something is the
most valuable, we call it big endian.</p>
<p>Thus, the European format is little endian while the numbers in it are
big endian:</p>
<pre><code>18.12.2002
&lt;- &lt;- &lt;--- Digits
---------&gt; Elements
</code></pre><p>And the American format just makes no sense:</p>
<pre><code>12/18/2002
&lt;- &lt;- &lt;--- Digits
?????????? Elements
</code></pre><p>And, as you can see, ISO 8601 is completely consistent in this regard
as everything is big endian:</p>
<pre><code>2002-12-18
&lt;--- &lt;- &lt;- Digits
&lt;--------- Elements
</code></pre><p>The situation becomes even worse if you consider time because it is
big endian, like ISO 8601, thus doesn’t work with any other date
format:</p>
<pre><code>18.12.2002 23:03:59
&lt;- &lt;- &lt;--- &lt;- &lt;- &lt;- Digits
---------&gt; &lt;------- Elements

12/18/2002 23:03:59
&lt;- &lt;- &lt;--- &lt;- &lt;- &lt;- Digits
?????????? &lt;------- Elements

2002-12-18 23:03:59
&lt;--- &lt;- &lt;- &lt;- &lt;- &lt;- Digits
&lt;--------- &lt;------- Elements
</code></pre><p>If you’re still having trouble visualizing all of this in your head,
look at <a href="https://www.reddit.com/r/ISO8601/comments/ln33j2/datetime_format_by_region_visualised_v3_thanks/">this Reddit post</a>.</p>
<h3 id="its-standardized-and-actively-used">It’s standardized and actively used</h3>
<p>If you think that ISO 8601 is a silly thing that someone in their
basement made up and no one actually uses, think again because that
can’t be further from the truth:</p>
<ul>
<li>The fact that it’s standardized says at least something. Does your
favorite format has a neat several hundred page document where it’s
described in extreme detail and that is internationally recognized?
Also the standard is quite far from being dead - after being
published in 1988 it was updated in 1991, 2000, 2004, and 2019.</li>
<li>As I already mentioned, the standard is actively used in IT.
Almost everything that is used by software and somehow involves a
written numerical date format already speaks ISO 8601.</li>
<li>yyyy-mm-dd has been adapted or used since the beginning as a
national date format by many countries such as Canada, Sweden, and
Japan. See <a href="https://en.wikipedia.org/wiki/Date_format_by_country">this article</a> for more details.</li>
</ul>
<h2 id="frequently-asked-questions">Frequently asked questions</h2>
<h3 id="why-not-use-a-format-like-01-jan-2020">Why not use a format like 01-Jan-2020?</h3>
<p>It doesn’t have any of the nice features ISO 8601 has and doesn’t work
well internationally (i.e. assumes the person you’re communicating
with knows knows English). If you think the latter is not a problem,
imagine how you would feel feel if you had to read a date someone
wrote in their native language that you don’t understand:</p>
<pre><code>01-Янв-2020
</code></pre><h3 id="yyyy-mm-dd-looks-weird">yyyy-mm-dd looks weird</h3>
<p>The only reason why it does to you is because you’re not used to it.
After a little bit of practice, it’ll be even less weird than your
favorite date format.</p>
<h3 id="maybe-the-european-date-format-is-better-because-the-elements-are-in-the--order-of-relevance">Maybe the European date format is better because the elements are in the  order of relevance?</h3>
<p>First of all, the claim that the order of relevance is little endian
is quite questionable. The only situation when you can say that for
certain is when we’re talking about events occuring on a day-to-day
basis, however I can think of numerous cases when the year and the
month are more relevant:</p>
<ul>
<li>Article publication date</li>
<li>Historical event</li>
<li>Personal event that happened a long time ago</li>
<li>Someone’s birthday</li>
<li>Random database entry</li>
</ul>
<p>Second, the order of relevance is actually irrelevant. Even if the
order of relevance was this way, you’re not reading the dates out
loud, so there’s no need for them to be ordered a certain way. If
you’re not interested in the year, you just skip it and read the end
of the date just like you would do when reading time while not being
interested in the hour.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In my opinion, ISO 8601 seems clearly superior to other date formats
when it comes to international communication (such as posting things
online), and as you can see, I have enough reasons to say so. While
the format certainly has an audience, it’s unfortunate that it’s not
as big as it could be. By writing this article, I hope I made you at
least think about different date formats and be more careful when it
comes to making people understand what date you’re talking about.</p>


			</div></div>]]>
            </description>
            <link>https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272084</guid>
            <pubDate>Fri, 26 Feb 2021 07:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PureScript and Haskell]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26271851">thread link</a>) | @allenleein
<br/>
February 25, 2021 | https://blog.drewolson.org/purescript-and-haskell | <a href="https://web.archive.org/web/*/https://blog.drewolson.org/purescript-and-haskell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><time datetime="2021-02-24 00:00:00 -0600">February 24, 2021</time>
  </p>

  
  

  <p>Two years ago, I starting learning <a href="https://www.purescript.org/">PureScript</a>.  I
had been intrigued by purely functional programming for some time but had failed
to learn <a href="https://www.haskell.org/">Haskell</a> once or twice. PureScript seemed to
be a kinder, gentler introduction to this world while retaining the fundamental
properties of pureness that made Haskell intriguing to me. As part of my
learning process, I rebuilt a slack bot<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> I had previously written in go.</p>

<p>Once I had learned PureScript and become more comfortable with purely functional
idioms, the next logical step seemed to be learning Haskell. I was surprised to
discover how much Haskell I already knew from learning PureScript, but core
features like laziness (PureScript is a strict language) took some getting used
to.</p>

<p>I decided to finish my Haskell learning experience by rewriting my slack bot<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>
once again, this time in Haskell. In this post I’ll compare and contrast my
experiences writing the same program in Haskell and PureScript. The application
I built was “real” enough to have some interesting design challenges. They
included:</p>

<ul>
  <li>Exposing an HTTP endpoint</li>
  <li>Parsing and generating JSON</li>
  <li>Full-text search</li>
</ul>

<p>On to the comparison!</p>



<p>Haskell is a lazy language while PureScript is a strict one. I expected this
core difference to manifest itself constantly when writing these applications,
but in reality it rarely came up. I had predicted a lot of banging my head
against the wall dealing with laziness bugs but it just didn’t happen.</p>

<p>I will say that I generally prefer PureScript being a strict-by-default
language. When laziness is required, there are plenty of ways to <a href="https://blog.drewolson.org/laziness-in-purescript">get
it</a>, but it is always explicit.</p>

<p>While not directly related to strictness, a pain point on the PureScript side
that I didn’t experience in Haskell was stack safety<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. In PureScript, it can
often be confusing to determine if the operation you’re using is stack safe.
When these operations <em>aren’t</em> stack safe, the errors that are produced can be
confusing and hard to track down. I found myself struggling with stack safety in
PureScript far more than I struggled with laziness in Haskell.</p>



<p>A year or two ago, I would have simply said that PureScript has incredible
tooling and Haskell does not. Thanks to the amazing work on the <a href="https://github.com/haskell/haskell-language-server">Haskell
Language Server</a> project,
this gap is starting to close.</p>

<p>Regardless, PureScript still has far better tooling.
<a href="https://github.com/purescript/spago">Spago</a> is an incredible build tool that
offers many of the same features as
<a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> while remaining far
more user friendly and PureScript’s <a href="https://github.com/nwolverson/purescript-language-server">language
server</a> is excellent
and easy to install.</p>

<p>However, PureScript is currently struggling on a few fronts. First, the package
ecosystem is moving from bower to a
<a href="https://github.com/purescript/registry">registry</a> hosted on Github. The
resulting registry seems to be moving along nicely and I believe the result will
be incredible for the language, but the current in-between state is unfortunate.
I am glad the core maintainers are taking their time to design this registry
well and I firmly believe that this will be a strong positive for the PureScript
community in 6-12 months.</p>

<p>Second, PureScript doesn’t have a great option for a formatter. While
<a href="https://gitlab.com/joneshf/purty">purty</a> does exist, it seems to be mostly in
maintenance mode and many of the formatting choices are frustrating for me.
Specifically, the automatic removal of blank lines within functions and the
addition of newlines for <code>let</code> assignments in <code>do</code> blocks both hamper
readability and author intent. On the Haskell side,
<a href="https://hackage.haskell.org/package/ormolu">ormolu</a> was easy to install and
“just worked”.</p>



<p>It’s not a controversial statement to say that Haskell has far more language
features than PureScript. It’s also not a new observation to say that it is
challenging to determine which of these features one should be using and what
extensions one should enable to use them. Here’s the list of default extensions
I have enabled for my project:</p>

<ul>
  <li>DataKinds</li>
  <li>DeriveGeneric</li>
  <li>FlexibleContexts</li>
  <li>FlexibleInstances</li>
  <li>GeneralizedNewtypeDeriving</li>
  <li>InstanceSigs</li>
  <li>LambdaCase</li>
  <li>MultiParamTypeClasses</li>
  <li>NamedFieldPuns</li>
  <li>OverloadedStrings</li>
  <li>ScopedTypeVariables</li>
  <li>TypeApplications</li>
  <li>TypeOperators</li>
</ul>

<p>I found Haskell’s deriving capabilities to be more powerful than PureScript and
led to reduced boilerplate, especially when creating my application monad. I
also like that Haskell’s type class instances do not require names. The names
required by PureScript add very little in terms of readability or author intent.</p>

<p>By far the biggest difference I felt between the two languages is the way they
deal with records. Again, this isn’t a new observation, but it can not be
overstated how much better PureScript’s records are than Haskell’s. Records
based on row polymorphism are a joy to work with, as is having a dedicated
syntax for creating, updating, and accessing records. GHC does have an <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0282-record-dot-syntax.rst">accepted
proposal</a>
for adding record dot syntax which will solve many of these problems, but I
think the underlying implementation based on row polymorphism will continue to
give PureScript the edge here.</p>



<p>When I first learned PureScript I compared its compile times to other statically
typed languages like Rust, Go, and Java. I found it much slower than these other
languages, though incremental rebuilds were generally quite fast. I assumed upon
moving to Haskell that the situation would be comparable or better. I was very
wrong.</p>

<p>Compilation times in Haskell are significantly worse than PureScript, often by
an order or two of magnitude when compiling a project’s dependencies. I say this
less to rag on Haskell (this seems like a challenging problem to tackle), but
more to applaud the PureScript community for the work they’ve already done on
this front.</p>



<p>Haskell has a far larger ecosystem of packages than PureScript – kind of. In
terms of Haskell and PureScript in isolation, Haskell has a vastly superior
collection of packages and the quality of these packages is generally very high.
However, PureScript has done a great job of porting over many of the best
Haskell packages.</p>

<p>Additionally, PureScript gives you access to the entire ecosystem of JavaScript
packages via FFI. While many in the community find this to be something of a
disadvantage, from a practical perspective it is fantastic. As an example, when
building full-text search for Haskell, I ended up using the full-text-search
package. It was fully featured and comprehensive, but required <a href="https://github.com/drewolson/epicbot-hs/blob/736e4a47a29f8935ecb489d3cdbeb48b738c34ca/src/Epicbot/Data/Index/SearchEngine.hs">quite a
bit</a>
of code to get working.</p>

<p>On the PureScript side, I built a <a href="https://github.com/drewolson/epicbot/blob/e7e93d2e2642ae135c92c6ff5b73b733685b550e/src/Epicbot/Index.js">simple FFI
wrapper</a>
around elasticlunr. While I understand that the JavaScript ecosystem has
packages of variable quality, it does have <em>lots</em> of package solving <em>many</em>
problems and PureScript’s FFI makes it extremely easy to leverage this giant
ecosystem in a safe way.</p>



<p>For my PureScript application I chose the
<a href="https://github.com/cprussin/purescript-httpure">HTTPure</a>. It was light-weight
and easy to use while feeling idiomatic. This was a relatively simple choice
because there are few options for server-side frameworks within the PureScript
ecosystem that included the features I needed (specifically middleware).</p>

<p>On the Haskell side, the choice of web framework was more complicated. I wanted
something small and light-weight, but with the ability work within my custom
monad stack for my application. I ended up using <a href="">scotty</a>, but the default
middleware solution doesn’t operate within your application’s monad stack, so I
needed to explicitly provide middleware-like-functions for <a href="https://github.com/drewolson/epicbot-hs/blob/736e4a47a29f8935ecb489d3cdbeb48b738c34ca/src/Epicbot/Web/Router.hs#L33-L34">each
endpoint</a>
in my router.</p>

<p>At the end of the day, this was mostly a wash between languages, but I expected
the Haskell ecosystem to be far more mature in the backend HTTP service space.</p>



<p>To deploy my PureScript application, I used
<a href="https://github.com/vercel/ncc">ncc</a>. While this required that I had <code>node</code>
available in my deployment environment, it made everything else easy. The <code>ncc</code>
tool produced a single, self-contained JavaScript file that included all of the
application code along with required dependencies. I then simply <code>scp</code>‘d this to
my deployment environment and ran it with <code>node</code>.</p>

<p>On the Haskell side, I used stack’s docker support to build my application’s
executable within a container that matches my deployment environment (debian),
and then shipped the resulting executable via <code>scp</code> as well. The executable was
completely self-contained.</p>

<p>Overall, both approaches felt equivalent in terms of ease. On the PureScript
side, it is a bit frustrating to need <code>node</code> within the deployment environment.
On the Haskell side, there was the added complication of having to use docker
for cross-compilation. Overall, though, both experiences were reasonably nice.</p>



<p>In reading over this post, I worry that it feels like I’m picking on Haskell –
I’m absolutely not. I’m very aware that PureScript is <em>heavily</em> influenced by
Haskell and is standing the shoulders of giants. PureScript was able to learn
from some of the mistakes of Haskell and make choices about intentional
departures from the Haskell ecosystem that better fit the intended use cases of
PureScript.</p>

<p>I found the experiences of learning and using both Haskell and PureScript very
rewarding. I will admit to being surprised at how well PureScript compared to
Haskell in the server-side HTTP space, given that its primary focus is currently
on the front end. I think both languages have a bright future and I’m excited to
follow their continued development.</p>



</div>



    </div></div>]]>
            </description>
            <link>https://blog.drewolson.org/purescript-and-haskell</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271851</guid>
            <pubDate>Fri, 26 Feb 2021 06:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercal, YAML, and Other Horrible Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 164 (<a href="https://news.ycombinator.com/item?id=26271582">thread link</a>) | @sidcool
<br/>
February 25, 2021 | https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/ | <a href="https://web.archive.org/web/*/https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><h2 id="programrejectedformentalhealthreasons">PROGRAM REJECTED FOR MENTAL HEALTH REASONS</h2>
<p>In 1972, two students learning FORTRAN came up with a fantastic new programming language called INTERCAL.  INTERCAL is a bit unusual. For example, single quotes are called <em>sparks</em>, and double quotes are called <em>rabbit ears</em>, less than (&lt;) is an <em>angle</em>, and a dash (-) is a <em>worm</em>.  This makes the manual read like a word puzzle combined with an extended in-joke:</p>
<blockquote>
<p>One final comment about sparks and rabbit-ears; if the next character in the program is a spot, as often happens because onespot variables are common choices for operands, a spark and the following spot can be combined into a wow (!). - <a href="http://www.catb.org/~esr/intercal/ick.htm">INTERCAL Manual</a>.</p>
</blockquote>
<p>The compiler errors are where the authors got genuinely creative. Errors include <code>VARIABLES MAY NOT BE STORED IN WEST HYPERSPACE</code> for accessing an array incorrectly, <code>IT CAME FROM BEYOND SPACE</code> for invalid control flow, <code>PROGRAM REJECTED FOR MENTAL HEALTH REASONS</code> for threading issues, <code>I HAVE NO FILE AND I MUST SCREAM</code> for file not found, and <a href="http://www.catb.org/~esr/intercal/ick.htm#Errors">many many more</a>.</p>
<p>Yes, this is a parody language, and reading the manual, you get the sense that no one has yet had as much fun writing technical documentation as Lyon and Woods did writing this.</p>
<p>The language itself looks less fun.  Here is <a href="http://www.rosettacode.org/wiki/Category:Intercal">Hello World</a>:</p>
<pre><code>       NOTE THIS IS INTERCAL
       PLEASE ,1 &lt;- #5
       DO ,1 SUB #1 &lt;- #54
       DO ,1 SUB #2 &lt;- #192
       DO ,1 SUB #3 &lt;- #136
       PLEASE ,1 SUB #4 &lt;- #208
       DO ,1 SUB #5 &lt;- #98
       DO COME FROM (1)
       DO READ OUT ,1
(2)    DO ,1 SUB #1 &lt;- #134
(1)    PLEASE ABSTAIN FROM (2)
</code></pre>
<p>One of the exciting innovations of INTERCAL is the <code>COMEFROM</code> <a href="https://en.wikipedia.org/wiki/COMEFROM#Examples">instruction</a>, seen here in a variant of BASIC.<sup><a href="#fn1" id="fnref1">[1]</a></sup></p>
<pre><code>10 COMEFROM 40
20 INPUT "WHAT IS YOUR NAME? "; A$
30 PRINT "HELLO, "; A$
40 REM
</code></pre>
<p>A <code>COMEFROM</code> anywhere in a program can grab control flow from the line you are reading. And in some implementations, if many <code>COMEFROM</code>'s reference the same line, execution splits off in each direction.</p>
<p>A <code>COMEFROM</code> is the inverse of a <code>GOTO</code> statement with multi-threading thrown in. It breaks the mental model of imperative execution where each line's evaluation leads to the next line. The idea that you can simulate its execution in your head, line by line, is fundamental to imperative programming and <code>COMEFROM</code> attempts to break that model.</p>
<h2 id="variablesmaynotbestoredinwesthyperspace">VARIABLES MAY NOT BE STORED IN WEST HYPERSPACE</h2>
<p>At Twitter, they have a giant monorepo with lots of services in it.  And somebody at Twitter wanted to know which language was most prevalent.  Which language does Twitter use the most?</p>
<p>Java came in 3rd, and Scala came in 2nd. But 1st was a surprise.  The number one programming language used at Twitter was YAML.<sup><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>YAML usually doesn't feel like a programming language to me.  The file I'm currently writing in is in markdown with some YAML at the top to set the title and associated fields:</p>
<pre><code>title: INTERCAL, YAML, And Other Horrible Programming Languages
author: Adam
</code></pre>
<p>Nothing executes this YAML. It only offers some information to the blogging platform. But I don't think that is the type of YAML that made up the bulk of config at Twitter.</p>
<p>I suspect a lot of it was build and deployment scripts in the form of YAML. It was the type of configuration that encoded the control flow of some external system.  YAML like that lives in this grey zone between declarative configuration and a full-blown programming language.</p>
<p>I'll show you what I mean. Let's look at an example from <a href="https://github.com/koalaman/shellcheck/blob/master/.travis.yml">shellcheck</a>'s build script:</p>
<pre><code>language: shell
os: linux

services:
  - docker
</code></pre>
<p>That seems like straight-forward config.</p>
<pre><code>jobs:
  include:
    - stage: Build
      env: BUILD=linux
      workspaces:
        create:
          name: ws-linux
          paths: deploy
</code></pre>
<p><code>create</code>, in the above, is starting to seem a bit more like execution. Let's continue.</p>
<pre><code>      script:
        - ls -la ${CASHER_DIR}/ || true
        - tar -xvf ${CASHER_DIR}/ws-osx-fetch.tgz --strip-components=5
        - ls -la deploy
        - ./.github_deploy
</code></pre>
<p>Now the YAML has just devolved into specifying how to execute a grab bag of commands.  We haven't seen control-flow yet, but it's coming.</p>
<pre><code>      if: type = push
      script:
        - source ./.multi_arch_docker
        - set -ex; multi_arch_docker::main; set +x
</code></pre>
<p>There we go, branching. It's an if statement in a YAML file!</p>
<p>That was for TravisCI but this isn't TravisCI, or CI specific.  Here is a simple example from Ansible:</p>
<pre><code>- hosts: all
  tasks:
    - include: foo.yml
      when: something == "foo"
    
    - include: bar.yml
      when: something == "bar"
</code></pre>
<p>Here is GitHub Actions:</p>
<pre><code>steps:
 - name: Step 7
   if: ${{ github.event_name == 'pull_request' &amp;&amp; github.event.action == 'unassigned' }}
   run: echo This event is a pull request that had an assignee removed.
</code></pre>
<p>Here is part of a Grafana <a href="https://github.com/grafana/helm-charts/blob/main/charts/grafana/templates/deployment.yaml">Helm Chart</a>:</p>
<pre><code>
{{ if (or (not .Values.persistence.enabled) (eq .Values.persistence.type "pvc")) }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ template "grafana.fullname" . }}
  namespace: {{ template "grafana.namespace" . }}
  labels:
    {{- include "grafana.labels" . | nindent 4 }}
{{- if .Values.labels }}
{{ toYaml .Values.labels | indent 4 }}
{{- end }}
{{- with .Values.annotations }}
  annotations:
{{ toYaml . | indent 4 }}
{{- end }}
</code></pre>
<p>I think this is a problem. Writing control flow in a config file is like hammering in a screw. It's a useful tool being used for the wrong job<sup><a href="#fn3" id="fnref3">[3]</a></sup>.</p>
<p>How did we get to this world of little programming languages embedded into YAML? Is calling something configuration just less scary? And if so, is a c++ program just config you give to gcc?</p>
<p>Did things ever get this complicated in XML times?</p>
<p>It turns out they did:</p>
<pre><code>&lt;xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;
  &lt;xsl:output method="text" omit-xml-declaration="yes" /&gt;

  &lt;xsl:template match="/"&gt;
    &lt;xsl:call-template name="FizzBuzz"&gt;
      &lt;xsl:with-param name="i" select="1" /&gt;
    &lt;/xsl:call-template&gt;
  &lt;/xsl:template&gt;

  &lt;xsl:template name="FizzBuzz"&gt;
    &lt;xsl:param name="i" /&gt;
    &lt;xsl:choose&gt;
      &lt;xsl:when test="($i mod 3) = 0 and ($i mod 5) = 0"&gt;FizzBuzz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:when test="$i mod 3 = 0"&gt;Fizz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:when test="$i mod 5 = 0"&gt;Buzz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:otherwise&gt;&lt;xsl:value-of select="$i" /&gt;&lt;xsl:text&gt;&amp;#xa;&lt;/xsl:text&gt;&lt;/xsl:otherwise&gt;
    &lt;/xsl:choose&gt;
    &lt;xsl:if test="$i &amp;lt; 100"&gt;
      &lt;xsl:call-template name="FizzBuzz"&gt;
        &lt;xsl:with-param name="i" select="$i + 1" /&gt;
      &lt;/xsl:call-template&gt;
    &lt;/xsl:if&gt;
  &lt;/xsl:template&gt;
&lt;/xsl:stylesheet&gt;
</code></pre>
<p>That is <code>FizzBuzz</code> in <a href="https://gist.github.com/JustinPealing/6f619a23729720a9c14d9917201028c8">XSLT</a>. I assume it was written in jest, but in many ways, XML and XSLT are better than an ad-hoc YAML based scripting language. XSLT is a documented and standardized thing, not just some ad-hoc format for specifying execution.</p>
<p>It burns my eyes to look at it, but at least XSLT was intended to be used as a programming language. That is something we can't say about YAML or INTERCAL.</p>
<p>The problem with these languages embedded into YAML is they are all one-off implementations.  TravisCI conditionals have a TravisCI specific syntax, usage, and features. You can't use Travis's <code>concat</code> function or conditional regex in the YAML configuration for your ansible playbooks.</p>
<p>In a vague way, this YAML problem is like the <code>COMEFROM</code> problem. If you know yaml, you can't just open a .yml file and start reading file line by line.  You need to understand how the configuration controls the execution of the specific system it's for.  And that is hard.</p>
<h2 id="ihavenofileandimustscream">I HAVE NO FILE AND I MUST SCREAM</h2>
<p>The line between configuration and programming languages is not some bright dividing line. It's easy to slowly drift into adding programming language constructs to a config file. Before you know it, you have a full unspecified programming language embedded in the interpretation of your config file.</p>
<p>That is the worst of both worlds, and so much YAML seems to drift into this area.</p>
<p>I like YAML more than XML, but for control flow, you know what would be better than YAML? Anything else!  Maybe even INTERCAL? I mean, how bad could a joke programming language be?</p>
<pre><code>(100)  PLEASE NOTE THIS IS THE FIZZBUZZ FUNCTION	

	PLEASE NOTE: IS THE INPUT DIVISIBLE BY #15?
	DO .1 &lt;- .100	
	DO .2 &lt;- #15
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (130) NEXT
	
	PLEASE NOTE NUMBER IS NOT DIVISIBLE BY #15 =&gt; CHECK IF DIVISIBLE BY #3
	DO .2 &lt;- #3
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (110) NEXT

	PLEASE NOTE NUMBER IS NOT DIVISIBLE BY #3 =&gt; CHECK IF DIVISIBLE BY #5
	DO .2 &lt;- #5
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (120) NEXT
	
	PLEASE NOTE NUMBER IS REGULAR =&gt; RETURN THE INPUT
	DO .101 &lt;- .100
	DO (199) NEXT

(110)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #3 =&gt; RETURN FIZZ
	DO .101 &lt;- #61440
	DO (199) NEXT


(120)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #5 =&gt; RETURN BUZZ
	DO .101 &lt;- #45056
	DO (199) NEXT

(130)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #15 =&gt; RETURN FIZZ-BUZZ
	DO .101 &lt;- #64256
	DO (199) NEXT

(111)	DO RESUME .4
	
(199)	DO FORGET #1
	DO RESUME #1
</code></pre>
<p>Oh God.</p>
<p>Well, ok, maybe not INTERCAL but anything else. <sup><a href="#fn4" id="fnref4">[4]</a></sup><sup><a href="#fn5" id="fnref5">[5]</a></sup></p>
<hr>
<section>
<ol>
<li id="fn1"><p><code>COME FROM</code> was introduced in INTERCAL-90 and not part of the orginal implementation (INTERCAL-72). <code>I HAVE NO FILE AND I MUST SCREAM</code> was also introduced in INTERCAL-90. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>See my interview with <a href="https://www.se-radio.net/2019/08/episode-375-gabriel-gonzalez-on-configuration/">Gabriel Gonzalez on Configuration</a> at Software Engineering Radio. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>Ansible and Helm use templating languages built on top of YAML, which is better than embedded control flow, but I think the point still stands. <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p>Practically, you may have to use tools that encode a DSL into config, but you can use them while recognizing that we can do better.  I think something like <a href="https://dhall-lang.org/#">Dhall</a> for complicated config and something like <a href="https://www.pulumi.com/">pulumi</a> for complex configuration as code should be where we aim for as an industry. <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p>The …</p></li></ol></section></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/">https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/</a></em></p>]]>
            </description>
            <link>https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271582</guid>
            <pubDate>Fri, 26 Feb 2021 05:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Redbean – Single-file distributable web server]]>
            </title>
            <description>
<![CDATA[
Score 1624 | Comments 207 (<a href="https://news.ycombinator.com/item?id=26271117">thread link</a>) | @jart
<br/>
February 25, 2021 | https://justine.lol/redbean/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/redbean/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://storage.googleapis.com/justine/redbean/redbean.png" width="84" height="84">
<h2>
  <big>redbean</big><br>
  <small>single-file distributable web server</small>
</h2>

<p>
  redbean makes it possible to share web applications that run offline
  as a
  single-file <a aria-label="Actually Portable Executable" href="https://storage.googleapis.com/justine/ape.html">αcτµαlly
  pδrταblε εxεcµταblε</a> zip archive which contains your assets. All
  you need to do is download the <code>redbean.com</code> program below,
  change the filename to .zip, add your content in a zip tool like
  Windows 10 or InfoZIP, and change the extension back to .com.

</p><p>
  redbean can serve 1 million+ gzip encoded responses per second on a
  cheap personal computer. That performance is thanks to zip and gzip
  using the same compression format, which enables kernelspace copies.
  Another reason redbean goes fast is that it's a tiny static binary,
  which makes fork memory paging nearly free.

</p><p>
  redbean is also easy to modify to suit your own needs. The program
  itself is written as a single .c file.

</p><p>
  <strong>
    download
    &nbsp;
    <img src="https://storage.googleapis.com/justine/redbean/linux.png" title="Linux" width="28" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/windows10.png" title="Windows" width="32" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/macos.png" title="MacOS" width="26" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/freebsd.png" title="FreeBSD" width="28" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/openbsd.png" title="OpenBSD" width="34" height="32">
    <img src="https://justine.lol/redbean/NetBSD.png" title="NetBSD" width="30" height="30">
  </strong>
  <br>

</p><p>
  <a href="https://justine.lol/redbean/redbean-2021-02-27.com">redbean-2021-02-27.com</a><br>
  <small>200kb - PE+ELF+MachO+ZIP+SH</small>

</p><p>
  <a href="https://justine.lol/redbean/redbean-2021-02-27.com.dbg">redbean-2021-02-27.com.dbg</a><br>
  <small>2.2m - ELF debugger data (optional)</small>

</p><p>
  <a href="https://github.com/jart/cosmopolitan/blob/master/tool/net/redbean.c">redbean.c</a><br>
  <small>source code</small>

</p><p>
  <strong>
    features
  </strong>
  </p><ul>
    <li>HTTP v1.1
    </li><li>Content-Encoding
    </li><li>Range / Content-Range
    </li><li>Last-Modified / If-Modified-Since
  </li></ul>

<p>
  <strong>
    installation
  </strong>
  </p><pre>curl https://justine.lol/redbean/redbean-latest.com &gt;redbean.com
chmod +x redbean.com
bash -c './redbean.com -vv'
</pre>

<p>
  <strong>
    usage
  </strong>
  </p><pre>echo '&lt;b&gt;hello&lt;/b&gt;' &gt;index.html
zip redbean.com index.html
./redbean.com -vv
curl -v http://127.0.0.1:8080/index.html
</pre>

<p>
  <strong>
    details
  </strong>

</p><p>
  Assets can be listed by running the following command:

</p><pre>unzip -vl redbean.com        # lists files
</pre>

<p>
  Assets can be added to the zip archive as follows:

</p><pre>zip redbean.com index.html   # adds file
</pre>

<p>
  By default, anything you add to the archive gets compressed. Sometimes
  you don't want that to happen. A good example is video files. The web
  browser will want to send HTTP range requests to seek in the video, in
  which case redbean requires that the asset be uncompressed.

</p><pre>zip -0 redbean.com video.mp4  # adds file without compression
</pre>

<p>
  Each connection uses a point in time snapshot of your ZIP file.
  If your ZIP is deleted then serving continues. If it's replaced
  then issuing SIGUSR1 (or SIGHUP if daemon) will reindex the zip
  for subsequent connections without interrupting active ones. If
  SIGINT or SIGTERM is issued then a graceful shutdown is started
  but if it's issued a second time, active connections are reset.

</p><p>
  <strong>
    flags
  </strong>

</p><table>
  <tbody><tr><th>  -h        </th><td>help
  </td></tr><tr><th>  -v        </th><td>verbosity
  </td></tr><tr><th>  -d        </th><td>daemonize
  </td></tr><tr><th>  -s        </th><td>uniprocess
  </td></tr><tr><th>  -m        </th><td>log messages
  </td></tr><tr><th>  -c INT    </th><td>cache seconds
  </td></tr><tr><th>  -r /X=/Y  </th><td>redirect X to Y
  </td></tr><tr><th>  -l ADDR   </th><td>listen ip [default 0.0.0.0]
  </td></tr><tr><th>  -p PORT   </th><td>listen port [default 8080]
  </td></tr><tr><th>  -L PATH   </th><td>log file location
  </td></tr><tr><th>  -P PATH   </th><td>pid file location
  </td></tr><tr><th>  -U INT    </th><td>daemon set user id
  </td></tr><tr><th>  -G INT    </th><td>daemon set group id
  </td></tr><tr><th>  -B STR    </th><td>changes server header
</td></tr></tbody></table>

<p>
  <strong>benchmark</strong>

</p><pre>$ <a href="https://github.com/wg/wrk">wrk</a> -H 'Accept-Encoding: gzip' -t 12 -c 120 \
  http://127.0.0.1:8080/tool/net/redbean.html
Running 10s test @ http://127.0.0.1:8080/tool/net/redbean.html
  12 threads and 120 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   745.49us    8.79ms 406.77ms   99.54%
    Req/Sec    96.60k     6.10k  123.66k    77.36%
  11631210 requests in 10.10s, 7.96GB read
Requests/sec: 1151621.71
Transfer/sec:    807.23MB
</pre>

<p>
  <strong>
    see also
  </strong>

</p><p>
  <a href="https://justine.lol/index.html">justine's web page</a><br>
  <a aria-label="Actually Portable Executable" href="https://storage.googleapis.com/justine/ape.html">αcτµαlly pδrταblε εxεcµταblε</a>

</p>
</div>]]>
            </description>
            <link>https://justine.lol/redbean/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271117</guid>
            <pubDate>Fri, 26 Feb 2021 03:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dasung Paperlike HD-FT Teardown]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26270995">thread link</a>) | @alex-a-soto
<br/>
February 25, 2021 | https://alexsoto.dev/dasung-paperlike-hdft-teardown.html | <a href="https://web.archive.org/web/*/https://alexsoto.dev/dasung-paperlike-hdft-teardown.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A series where I’m documenting my process of designing and building an eink laptop.</p><ul><li><span><span title="2021-02-17T22:13"><a href="https://alexsoto.dev/building-an-e-ink-laptop.html">Building an E-Ink Laptop</a><span data-nosnippet="" title="Folgezettel">#</span></span></span></li></ul><p>In my first post, <a href="https://alexsoto.dev/building-an-e-ink-laptop.html">Building an E-Ink Laptop</a>, I went over some history about e-ink technology, the e-ink modding community, recent advancements, and the hardware I’ve selected to create an e-ink laptop.</p><p>This post in the series will be a teardown of the Dasung HD-FT, inspired from Kev Zettler’s work on the, <a href="https://kevzettler.com/2018/02/11/dasung-paperlike-pro-teardown/">Dasung Paperlike Pro Teardown</a>. Thank you, <a href="https://kevzettler.com/">Kev Zettler</a>, for showing your work on the Dasung Paperlike Pro and making all of this possible. I will later create an accompanying video to go over the Dasung HD-FT teardown process.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_203519.jpg"></p><h2 id="overview-of-the-dasung-hd-ft">Overview of the Dasung HD-FT</h2><p>The Dasung HD-FT is a third-generation e-ink monitor with a display of 13.3“, a screen resolution of 2200x1650, a touchscreen, and an adjustable backlight. The monitor connects via a proprietary Y cable, with connections for USB and HDMI; additionally, the Dasung HD-FT can be powered by the micro-usb connection on the left side.</p><p>Once connected to a computer, it acts as a second monitor or, for our purposes, a primary monitor for our e-ink laptop. The monitor’s physical buttons allow you to adjust the contrast, brightness, clear the screen, and change modes.</p><p>The modes (M1, M2, M3, Fast, Fast++, Black, Black+, Black++) correspond to how the monitor displays what’s rendered in the screen using different shades of grey or black/white.</p><p>Let’s take a closer look and dismantle the Dasung HD-FT and look at its components.</p><h2 id="opening-the-dasung-paperlike-hd-ft">Opening the Dasung Paperlike HD-FT</h2><p>Similar to Zettler’s observations and approach, the Dasung HD-FT is made of one piece of construction. I first began with a knife, carefully prying the outer edges of the Dasung Monitor where it’s all glued and making my way slowly through all of the sides.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_194558.jpg"></p><p>Once I finished prying through all of the sides, what became visible were the screws that were holding everything together.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_194714.jpg"></p><p>After removing all of the screws, I was able to gain access to the panel!</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_203519.jpg"></p><h2 id="the-e-ink-display-module-and-control-board">The E-ink display module and control board</h2><p>Like Zettler discovered, the Dasung HD-FT chip components upon closer inspection were also chemically peeled off to prevent reverse engineering of the e-ink display and control board.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201821.jpg"></p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201158.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201211.jpg"></p><h2 id="es133tt3-display-module">ES133TT3 Display Module</h2><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201921.jpg"></p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202037.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202009.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202020.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202024.jpg"></p><p>The e-ink display module model number for the Dasung HD-FT is the: <span><strong>ES133TT3</strong></span></p><p>beck-elektronik<span data-nosnippet=""><sup><a href="#fn1" id="fnref1">1</a></sup></span> describes it as “<em>reflective electrophoretic E Ink technology display module based on active matrix TFT and plastic substrate. The plastic substrate is protected by an outer covering.</em>”</p><p>Specification:</p><ul><li>Size: 13.3 inch</li><li>Resolution (HxV): 2200 * 1650</li><li>Active Area: 270.60 * 202.95 mm</li><li>Outline Dimensions: 287.00 * 215.50 mm</li><li>Dpi: 206</li><li>E Ink Film: Carta 1.2</li><li>Refresh Time: 450 ms</li><li>Backplane: Flexible</li><li>Total Thickness: 0.65 mm</li><li>Total Weight: 68 g</li><li>Grey Level: 16</li><li>Surface Treatment: Anti-Glare</li><li>Partial Update: yes</li></ul><p>Their website also lists an EPD driver kit that’s compatible with it, the ES133TT3.<span data-nosnippet=""><sup><a href="#fn2" id="fnref2">2</a></sup></span></p><h2 id="next-steps">Next Steps</h2><p>This second post provided an overview of the Dasung HD-FT, a teardown of the Dasung HD-FT and its internal components, and identifying the display module used, the ES133TT3.</p><p>The following post in the series will be a teardown of the Thinkpad T480 that we will be using to build our e-ink laptop.</p><p><img id="avatar" src="https://alexsoto.dev/static/profile.jpeg"></p><p>Hi, I’m Alexander Soto.</p><p>I’m a community organizer, educator, software engineer, hacktivist, and agent of social change. My interests are in exploring community-building, social justice, education, and leveraging technology to address social problems.</p><p>In the past, I’ve worked as a labor rights organizer, a teacher, and I’m currently an Expert In Residence at <a href="https://www.resilientcoders.org/">Resilient Coders.</a></p><p>I enjoy tinkering/playing/breaking things, 3D printing, painting, playing piano, swimming, and writing in my spare time.</p><p>This site is the <a href="https://alexsoto.dev/impulse.html">scattered and unfinished version of my thoughts</a> while documenting what I’m currently learning and exploring.</p><p>If a post resonated positively or negatively, send me a <a href="https://twitter.com/messages/compose?recipient_id=4648173315">direct message</a> on <a href="https://twitter.com/alexsotodev">Twitter</a>, an <a href="mailto:contact@alexsoto.dev">email</a>, or subscribe to the <a href="https://buttondown.email/alexsotodev">mailing list</a> and we can talk. Also, ping if you’d like to know the updates of a post or if you have suggestions, comments, questions, or would like to collaborate.</p>



</div></div>]]>
            </description>
            <link>https://alexsoto.dev/dasung-paperlike-hdft-teardown.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270995</guid>
            <pubDate>Fri, 26 Feb 2021 03:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Craziest Drinks Sold in Japan]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26270957">thread link</a>) | @rmason
<br/>
February 25, 2021 | https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/ | <a href="https://web.archive.org/web/*/https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>Oh come on!  Don’t play it safe and only go just go for a Coke or Pepsi.  You’re in Japan now.  It’s time to try something more adventurous.</p>



<p>Vending machines mainly for carbonated drinks started appearing across the country in 1960.&nbsp; Now there are an estimated 2,470,000 of them throughout Japan or 1 for approximately every 50 people.&nbsp; Thus, it is easy to grab either a cold or hot drink virtually anywhere in the country on a 24/7 basis.</p>



<p>While the same global players such as Coca-Cola and national powerhouses in the beverage industry like Suntory do, in fact, dominate distribution via vending machines and other channels, relatively obscure minor entrants have still managed to carve out a niche with several unique offerings.&nbsp; Even the big boys have become used to granting a creative license to their marketers to go well beyond normal colas.</p>



<div><figure><img loading="lazy" src="https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-1024x640.jpg" alt="" width="512" height="320" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-1024x640.jpg 1024w, https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-300x188.jpg 300w, https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea.jpg 1280w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Some of the more unusual selections from Ryoko Shimizu’s Top 50, Image sourced from Crea</figcaption></figure></div>



<p>The sheer variety of beverages—<em>both non-alcoholic and alcoholic</em>—available in Japan is staggering. &nbsp;To make sense of it all is soft drink critic Ryoko Shimizu (aside–<em>now that’s a cool job!</em>).&nbsp; She has been reviewing the world of non-alcoholic Japanese beverages since the 1980s.&nbsp; Shimizu recently published a <a href="https://news.nifty.com/article/entame/etc/12113-930661/">Top 50 list of her all-time favorites</a> (the original article in Japanese only).</p>



<p>…but wait!  First you need to know this.</p>



<h3><strong>What’s a <em>supodo</em>?</strong></h3>



<p><em>Supodo</em> (スポド) is an abbreviation for the made-up English term “sports drink” in Japanese.&nbsp; This category is a type of soft drink that replenishes the water and minerals lost from the body due to perspiration, especially during exercise. &nbsp;It supposedly helps to prevent dehydration and the potential for heatstroke while playing sports under the scorching sun.</p>



<h3><strong>Top Fifty</strong></h3>



<p>Okay, now that this term has been defined, let’s get to Shimizu’s extensive list which includes plenty of <em>supodo</em> as well as other types of drinks!</p>



<p>Not all of her favorites are still around, but, despite humble beginnings in some cases, a surprising number have since gone mainstream.&nbsp; Scroll down to see how Shimizu ranked them by counting backward from 50 down to 1:</p>



<h4>#50 Sports Mugicha</h4>



<p><strong>Sports Mugicha</strong> sold in the 1990s by Kanebo:&nbsp; Shimizu wrote, “When I first heard the name of this drink, my first impression was that it must be a blend of traditional barley tea and a ‘sports drink.’&nbsp; It consists, in fact, of a combination of an appropriate amount of salt mixed with regular barley tea to enhance its absorption into the body. &nbsp;The can was decorated with a theme from the professional baseball team Yokohama BayStars.”</p>



<div><figure><img loading="lazy" width="223" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea.jpg 223w, https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea-209x300.jpg 209w" sizes="(max-width: 223px) 100vw, 223px"><figcaption>Sports Mugicha (barley tea), Image sourced from Crea</figcaption></figure></div>



<h4>#49 Mountain Dew</h4>



<p><strong>Mountain Dew</strong> launched in 1981 by Pepsi Co:&nbsp; This long-seller, which is still popular today, is marketed in Japan with the tag line “new citrus beverage.”&nbsp; The package has changed little over the years.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Mountain Dew (written in Japanese), Image sourced from Crea</figcaption></figure></div>



<h4>#48 Tab Clear</h4>



<p><strong>Tab Clear</strong> launched in 1993 by Coca-Cola:&nbsp; Shimizu commented, “It became a hot topic because it was a transparent cola, but I remember that it was subtle in terms of taste. Kotaro Tawara, a popular newscaster at the time, appeared in a commercial.”</p>



<div><figure><img loading="lazy" width="245" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea.jpg 245w, https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea-230x300.jpg 230w" sizes="(max-width: 245px) 100vw, 245px"><figcaption>Tab Clear, Image sourced from Crea</figcaption></figure></div>



<h4>#47 Tsubu-Tsubu Orange</h4>



<p><strong>Tsubu-Tsubu Orange</strong> was sold in the 1990s by Yamato:&nbsp; This orange drink was conceived based upon the trend of mashed fruit drinks in the 1980s.&nbsp; “Tsubu” means “bead” or “drop” in Japanese.&nbsp; When it was launched, Tsubu-Tsubu Orange lacked national distribution.&nbsp; It was only marketed locally in Nagoya, near where it was made.</p>



<div><figure><img loading="lazy" width="208" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea.jpg 208w, https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea-195x300.jpg 195w" sizes="(max-width: 208px) 100vw, 208px"><figcaption>Tsubu Tsubu Orange, Image sourced from Crea</figcaption></figure></div>



<h4>#46 Post Water</h4>



<p><strong>Post Water</strong> launched in 1990 by Kirin:&nbsp; Made from lychees, this <em>supodo</em>  or “sports drink” made quite a scene when it debuted in an unusually-shaped flask.</p>



<div><figure><img loading="lazy" width="554" height="554" src="https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter.jpg 554w, https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter-300x300.jpg 300w, https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter-150x150.jpg 150w" sizes="(max-width: 554px) 100vw, 554px"><figcaption>Post Water, Image sourced from Twitter</figcaption></figure></div>



<h4>#45 Cheerio Grape</h4>



<p><strong>Cheerio Grape</strong> launched in 1965 by Cheerio:&nbsp; Shimizu fondly recalls Cheerio’s Grape drink as being for sale at the candy store near her childhood home.</p>



<div><figure><img loading="lazy" width="204" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea.jpg 204w, https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea-191x300.jpg 191w" sizes="(max-width: 204px) 100vw, 204px"><figcaption>Cheerio Grape, Image sourced from Crea</figcaption></figure></div>



<h4>#44 J Water</h4>



<p><strong>J Water</strong> launched in 1993 by Suntory:&nbsp; This drink made its debut as an officially licensed beverage of the J League or Japan Professional Football (soccer) League back when J League was new.&nbsp; This “sports drink” did not have a particularly distinctive taste, but the taste was secondary to packaging in any case.&nbsp; There are also team-specific variants.</p>



<div><figure><img loading="lazy" width="195" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online.jpg 195w, https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online-183x300.jpg 183w" sizes="(max-width: 195px) 100vw, 195px"><figcaption>J. Water, Image sourced from Bunshun Online</figcaption></figure></div>



<h4>#43 Ambasa</h4>



<p><strong>Ambasa</strong> launched in 1982 by Coca-Cola:&nbsp; Shimizu commented, “I felt a little &nbsp;uncomfortable with the unfamiliar word ‘Ambasa’ at first, but I quickly got used to it because it was put into virtually every Coca-Cola vending machine.” &nbsp;This carbonated beverage looks milky and tastes lighter than Calpis Soda. &nbsp;There were also melon and pine flavors for a while.</p>



<div><figure><img loading="lazy" width="240" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea.jpg 240w, https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea-225x300.jpg 225w" sizes="(max-width: 240px) 100vw, 240px"><figcaption>Ambasa, Image sourced from Crea</figcaption></figure></div>



<h4>#42 Apple Oolong Soda</h4>



<p><strong>Apple Oolong Soda</strong> launched in 1988 by Kirin:&nbsp; This is another drink that relies primarily upon packaging to drum up sales.&nbsp; It features characters from the anime Modern Children (いまどきのこども), which attracted a lot of attention when launched.  It is still fairly popular.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Apple Oolong Soda, Image sourced from Bunshun Online</figcaption></figure></div>



<h4>#41 Sweet Kiss</h4>



<p><strong>Sweet Kiss</strong> launched in 1982 by Cheerio:&nbsp; Sweet Kiss is sort of a variant of Mountain Dew (#49) and features a distinctive graphic design.&nbsp; It is, however, still relatively difficult to find this drink even in Tokyo.</p>



<div><figure><img loading="lazy" width="590" height="442" src="https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net.jpg 590w, https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net-300x225.jpg 300w" sizes="(max-width: 590px) 100vw, 590px"><figcaption>Sweet  Kiss, Image sourced from J Town Net</figcaption></figure></div>



<h4>#40 Saruo Monkey King</h4>



<p><strong>Saruo Monkey King</strong> launched in 1994 by Lotte:&nbsp; The name Saruo literally means “monkey king” in Japanese.&nbsp; It was originally marketed as an exclusive type of oolong tea made from tea leaves grown on cliffs where monkeys like to forage food.&nbsp; There is, naturally, some question about whether monkeys actually harvest tea leaves.&nbsp; One of the respondents reportedly remarked in a taste test, “It sort of smells like a monkey.”&nbsp; Luckily for the brand, there are, however, plenty of other people who disagree!</p>



<div><figure><img loading="lazy" width="216" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea.jpg 216w, https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea-203x300.jpg 203w" sizes="(max-width: 216px) 100vw, 216px"><figcaption>Saruo or “monkey king” in Japanese, Image sourced from Crea</figcaption></figure></div>



<h4>#39 Afternoon Tea</h4>



<p><strong>Afternoon Tea</strong> launched in sold in 1986 by Kirin:&nbsp; This drink is a best selling long-runner.&nbsp; It is fairly sweet and was the first black tea sold in a 1.5 liter PET bottle.</p>



<div><figure><img loading="lazy" width="194" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea.jpg 194w, https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea-182x300.jpg 182w" sizes="(max-width: 194px) 100vw, 194px"><figcaption>Afternoon Tea, Image sourced from Crea</figcaption></figure></div>



<h4>#38 Bireley’s Orange</h4>



<p><strong>Bireley’s Orange</strong> launched in 1951 by Asahi:&nbsp; The name of this ultra-long-runner, “Birely’s,” used to be synonymous orange juice. Since the 1970s, when restrictions were introduced that limited marketers’ ability to label a drink as juice unless it was 100% juice, Birely’s had to drop the reference to juice.&nbsp; This minor setback did, however,  not make a major dent in its market share.  The brand is still sold today.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Bireley’s Orange, Image sourced from Crea</figcaption></figure></div>



<h4>#37 Hokuriku Soda Godzilla Matsui Can</h4>



<p><strong>Hokuriku Soda Godzilla Matsui Can</strong> launched in 1997 by Soka Komatsuen:&nbsp; This is a locally produced drink made to help immortalize the famous baseball player Hideki Matsui who was also a “favorite son” of Ishikawa Prefecture.&nbsp; Matsui, whose nickname was “Godzilla,” was a home run king who went on to play for the New York Yankees.</p>



<div><figure><img loading="lazy" width="214" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea.jpg 214w, https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea-201x300.jpg 201w" sizes="(max-width: 214px) 100vw, 214px"><figcaption>Hokuriku Soda Godzilla Matsui Can, Image sourced from Crea</figcaption></figure></div>



<h4>#36 Honey Lemon</h4>



<p><strong>Honey Lemon</strong> launched in 1986 by Suntory:&nbsp; This fruit drink experienced explosive sales upon its release.&nbsp; Suntory had a problem, though.&nbsp; As they could not register a trademark for “honey lemon” or even its nickname in Japanese <em>hachi-lemo</em>, this particular name essentially became its own category because several other manufacturers flooded the market with similar drinks by the same name.&nbsp; It is a classic example of just how cut-throat the non-alcoholic drink industry can be in Japan.</p>



<div><figure><img loading="lazy" width="225" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea.jpg 225w, https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea-211x300.jpg 211w" sizes="(max-width: 225px) 100vw, 225px"><figcaption>Honey Lemon, Image sourced from Crea</figcaption></figure></div>



<h4>#35 McCOL</h4>



<p><strong>McCOL</strong> launched in 1982 by MMC:&nbsp; This collector’s item has long since been taken off the market.&nbsp; It was, apparently, relatively hard to find even when it was available through the mid-1990s.&nbsp; McCOL was marketed as “barley cola,” but it looked just like any other cola.&nbsp; The taste was a combination of barley tea and cider.</p>



<div><figure><img loading="lazy" width="197" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea.jpg 197w, https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea-185x300.jpg 185w" sizes="(max-width: 197px) 100vw, 197px"><figcaption>McCOL, Image sourced from Crea</figcaption></figure></div>



<h4>#34 TESS Milk Tea</h4>



<p><strong>TESS Milk Tea</strong> sold in the late 1980s by Suntory:&nbsp; TESS had a relatively short lifetime as a semi-sweet type of milk tea.</p>



<div><figure><img loading="lazy" width="238" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea.jpg 238w, https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea-223x300.jpg 223w" sizes="(max-width: 238px) 100vw, 238px"><figcaption>TESS Milk Tea, Image sourced from Crea</figcaption></figure></div>



<h4>#33 NCAA</h4>



<p><strong>NCAA</strong> launched in 1981 by Suntory:&nbsp; Named for the National College Athletic Association (NCAA), this classic sports drink was introduced as “the brand new thirst quencher for those who love sports.”</p>



<div><figure><img loading="lazy" width="193" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea.jpg 193w, https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea-181x300.jpg 181w" sizes="(max-width: 193px) 100vw, 193px"><figcaption>NCAA, Image sourced from Crea</figcaption></figure></div>



<h4>#32 Atamaruko</h4>



<p><strong>Atamaruko</strong> launched in 1990 by Suntory:&nbsp; This citrus mixture of kumquats and calamansi (aka “Philippine lime”) was actually sold hot in the heated section of vending machines. Its name means, in fact, “A Child to Warm You Up.”&nbsp; The cute package design proved effective at attracting customers. &nbsp;It actually led to a second-generation character called “Nacchan” that became even more famous than Atamaruko, who was relegated to the status of “the unknown older sister.”</p>



<div><figure><img loading="lazy" width="223" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory.jpg 223w, https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory-209x300.jpg 209w" sizes="(max-width: 223px) 100vw, 223px"><figcaption>Atamaruko, Image sourced from Suntory</figcaption></figure></div>



<h4>#31 Gatorade</h4>



<p><strong>Gatorade</strong> sold in the 1980s by Yukijirushi:&nbsp; Having been replaced by homegrown rival Pocari Sweat, American uber-brand Gatorade is no longer sold in cans in Japan. It was, though, the first “sports drink” to appear in Japan.&nbsp; At that point, Gatorade was only available as a powder.</p>



<div><figure><img loading="lazy" width="198" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea.jpg 198w, https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea-186x300.jpg 186w" sizes="(max-width: 198px) 100vw, 198px"><figcaption>Gatorade, Image sourced from Crea</figcaption></figure></div>



<h4>#30 Dr. Nakamatsu’s Head Tea</h4>



<p><strong>Dr. Nakamatsu’s Head Tea</strong> launched in 1994 by Cheerio:&nbsp; Now we’re entering the realm of the truly odd.&nbsp; Named for Dr. Yoshiro Nakamatsu, a leading researcher of “smart foods” at the time of launch, this strong blended tea was somehow supposed to enhance cognitive capability.&nbsp; Years later, the same Dr. Nakamatsu gained additional notoriety outside Japan by winning the “Ig Noble …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/">https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/</a></em></p>]]>
            </description>
            <link>https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270957</guid>
            <pubDate>Fri, 26 Feb 2021 02:58:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EdgeDB in Beta]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270576">thread link</a>) | @avador
<br/>
February 25, 2021 | https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/ | <a href="https://web.archive.org/web/*/https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="---post-root---"><section><div><p><img src="https://www.edgedb.com/static/beta1-937a02b3aacf5f4c5a6f10540333cf02.jpg" width="100%" height="100%"></p></div></section>
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<section id="edgedb-1-0-beta-1-sirius">
<!-- -->
<p>Nearly two years after releasing 1.0 Alpha 1, and after seven alpha releases,
            we are ready to bring EdgeDB to the public beta phase!</p>
<p>This means that as of now, we will make every effort to keep the public-facing
            APIs backwards compatible.  This includes EdgeQL, our standard library,
            schema definition language, official database clients’ APIs, even CLI
            commands and their options.  Most importantly, EdgeDB’s dumps made today
            will be restorable in future versions of the database.</p>
<p>This release completes a set of features we feel are crucial for
            a well-rounded 1.0 product, and we invite early adopters to try it out.
            On our end, we’re spending the next few months on getting EdgeDB ready
            for the first stable release.  Entering Beta means we won’t be adding
            new features until the release of 1.0 final.</p>
<p>You can <a href="https://www.edgedb.com/download">download</a> 1.0b1 in a number of ways or try it out
            in our <a href="https://tutorial.edgedb.com/">interactive tutorial</a> without the need to install
            anything.</p>

<h4>What’s EdgeDB</h4>
<p>EdgeDB is an advanced <a href="https://github.com/edgedb/edgedb">open source</a> relational database built
            on top of PostgreSQL which aims to <a href="https://www.edgedb.com/blog/a-path-to-a-10x-database">change the game</a> in terms
            of data layer usability and performance.</p>
<p>It combines an expressive object-oriented data model with a composable
            query language based on set logic, making complex data schemas easy to
            express, populate, and query.  The query system’s explicit goal is to
            address <a href="https://www.edgedb.com/blog/we-can-do-better-than-sql">shortcomings of SQL</a>.</p>
<p>As a database designed for the long haul, EdgeDB allows for your data
            to evolve along with changing business needs, by providing built-in
            support for schema migrations.  It’s also developed in the open and
            under the permissive Apache license.</p>
<p>EdgeDB’s performance focus is embodied in its carefully designed
            first-party database clients (currently available for JavaScript, Go,
            and Python.)  The database server itself compiles EdgeQL queries to
            efficient SQL in ways that outperform many manually written queries.</p>
<p>As a modern database, EdgeDB also provides interoperability with your
            other services via built-in support for GraphQL, REST, and easy <a href="https://www.edgedb.com/docs/clients/01_js/api/connection#Connection.queryJSON">casting
                from and to JSON</a> while keeping your data strictly typed.</p>
<div id="built-in-database-migrations-in-use">

<p>We believe that managing the evolution of your data models is a crucial
                feature in a modern database product.  The alternatives would be either
                weakly typed schemas or a third-party product.  We’re not satisfied with
                either.  The former unnecessarily moves some of the responsibilities of
                the database into your application code, making data consistency harder
                and development more error-prone.  The latter on the other hand usually
                ties you to a particular database connection framework in a particular
                programming language, putting that language in a privileged position.
                This is suboptimal in today’s environment where very often mobile
                applications are written in multiple programming languages, a Web
                front-end can be another, and back-end processing using yet another.</p>
<p>With Beta 1, the migrations functionality we envisioned for EdgeDB
                is fully realized.  While you could <a href="https://www.edgedb.com/docs/edgeql/ddl/migrations">start, populate, and commit
                    migrations</a> from EdgeQL directly for a few releases
                already, now you can fully manage migrations from the CLI, making the
                workflow even more high-level.</p>
<p>The idea here is to be able to version your schema alongside your
                source code, possibly as a separate repository that you can link
                as a submodule in multiple applications that your system consists of.
                That repository would hold schema files describing migrations between
                different states of your data model.</p>
<p>As an example, let’s say we start with the following schema for a simple
                chat app:</p>
<pre><span><span><span>module</span> <span>default</span> {
    <span>type</span> User {
        <span>required</span> <span>property</span> name <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> email <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> password_hash <span>-&gt;</span> <span>str</span>;
    }

    <span>type</span> Message {
        <span>required</span> <span>link</span> author <span>-&gt;</span> User;
        <span>required</span> <span>property</span> body <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> timestamp <span>-&gt;</span> <span>datetime</span> {
            <span>default</span> <span>:=</span> <span>datetime_current</span>()
        }
    }
};</span></span></pre>
<p>The migration CLI looks for <code>.esdl</code> files in the <code>dbschema</code> directory
                by default, so let’s create one and write the above into a
                <code>dbschema/default.esdl</code> file inside it.  Let’s
                <a href="https://www.edgedb.com/docs/tutorial/install/">install</a> EdgeDB server and then create a new
                database instance for our chat app:</p>
<pre><span><span>$ edgedb server init chatapp</span></span></pre>
<p>Now, we can create the initial migration to the schema we’ve written above:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you create object type 'default::User'? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>This is new, what do all those possible actions mean?  Let’s find out:</p>
<pre><span><span>?

y - confirm the prompt, use the DDL statements
n - reject the prompt
l - list the DDL statements associated with prompt
c - list already confirmed EdgeQL statements
b - revert back to previous save point, perhaps previous question
s - stop and save changes (splits migration into multiple)
q - quit without saving changes
h or ? - print help
did you create object type 'default::User'? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>That’s clear, we did in fact create <code>User</code>. Let’s confirm:</p>
<pre><span><span>y
did you create object type 'default::Message'? [y,n,l,c,b,s,q,?]
y
Created dbschema/migrations/00001.edgeql, id:
m1ufwaxcqiwcq3ttcujnxv6f3jewhfrywc442z6gjk3sm3e5fgyr4q</span></span></pre>
<p>This creates the first migration file
                <code>dbschema/migrations/00001.edgeql</code>. After reviewing it to make
                sure everything is in order, we can apply the migration with the
                following command:</p>
<pre><span><span>$ edgedb -I chatapp migrate
Applied m1ufwaxcqiwcq3ttcujnxv6f3jewhfrywc442z6gjk3sm3e5fgyr4q
(00001.edgeql)</span></span></pre>
<p>In the course of implementing our app we decide to add more features,
                such as a friends list and multiple chat channels, so we alter our
                schema to be:</p>
<pre><span><span><span>module</span> <span>default</span> {
    <span>type</span> User {
        <span>required</span> <span>property</span> name <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> email <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> password_hash <span>-&gt;</span> <span>str</span>;

        <span>multi</span> <span>link</span> friends <span>-&gt;</span> User;
    }

    <span>type</span> Message {
        <span>required</span> <span>link</span> author <span>-&gt;</span> User;
        <span>required</span> <span>property</span> body <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> timestamp <span>-&gt;</span> <span>datetime</span> {
            <span>default</span> <span>:=</span> <span>datetime_current</span>()
        }

        <span>link</span> channel <span>-&gt;</span> Channel;
    }

    <span>type</span> Channel {
        <span>required</span> <span>property</span> title <span>-&gt;</span> <span>str</span> {
            <span>constraint</span> <span>exclusive</span>;
        };
        <span>property</span> description <span>-&gt;</span> <span>str</span>;
    }
};</span></span></pre>
<p>And we apply the changes by using <code>create-migration</code> and <code>migrate</code>
                commands again:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you create object type 'default::Channel'? [y,n,l,c,b,s,q,?]
y
did you create link 'channel' of object type 'default::Message'?
[y,n,l,c,b,s,q,?]
y
did you create link 'friends' of object type 'default::User'?
[y,n,l,c,b,s,q,?]
y
Created dbschema/migrations/00002.edgeql, id:
m1kebitqygj3o75wvrnicnpwthinqsofb6hnpbnr7vrtjfynqelmzq
$ edgedb -I chatapp migrate
Applied m1kebitqygj3o75wvrnicnpwthinqsofb6hnpbnr7vrtjfynqelmzq
(00002.edgeql)</span></span></pre>
<p>At this point we may want to actually create a default channel “Main”
                and make the <code>channel</code> link required. So we alter the schema to make
                the link required and run <code>create-migration</code> again:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you make link 'channel' of object type 'default::Message'
required? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>Indeed we did but for the sake of curiosity let’s list the DDL that
                the tool is producing for us here:</p>
<pre><span><span>l

Following DDL statements will be applied:
ALTER TYPE default::Message {
    ALTER LINK channel {
        SET REQUIRED USING (\(fill_expr));
    };
};</span></span></pre>
<p>Interestingly the DDL statement specifies that some expression will
                have to be provided to backfill data in the database.  Let’s see how
                it deals with this:</p>
<pre><span><span>did you make link 'channel' of object type 'default::Message'
required? [y,n,l,c,b,s,q,?]
y
Please specify an expression to populate existing objects in
order to make link 'channel' required:
fill_expr&gt; SELECT Channel FILTER .title = 'Main'
Created dbschema/migrations/00003.edgeql, id:
m1wk64aoerkmvbdlurcxjxgbgv6c3xmuo3uz7pxc3gauyx4muysg6q</span></span></pre>
<p>However, before applying this migration we also add the line <code>INSERT
default::Channel {title := 'Main'};</code> at the beginning of the
                migration block in the <code>dbschema/migrations/00003.edgeql</code> file
                to ensure the <code>SELECT</code> above finds the default channel.
                Now we can actually apply the changes:</p>
<pre><span><span>$ edgedb -I chatapp migrate
edgedb error: could not read migrations in dbschema/migrations:
could not read migration file dbschema/migrations/00003.edgeql:
migration name should be
`m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba` but
`m1wk64aoerkmvbdlurcxjxgbgv6c3xmuo3uz7pxc3gauyx4muysg6q` is used
instead.
Migration names are computed from the hash of the migration
contents. To proceed you must fix the statement to read as:
  CREATE MIGRATION
  m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba ONTO ...
if this migration is not applied to any database. Alternatively,
revert the changes to the file.</span></span></pre>
<p>Uh-oh! The migration failed, but the error message actually explains
                what happened: the tool discovered we made manual changes to the file.
                Since this is deliberate, we just need to adjust the migration hash in
                order to proceed.  The tool even supplies us with the new hash. After
                adjusting the migration file, we can now apply it:</p>
<pre><span><span>$ edgedb -I chatapp migrate
Applied m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba</span></span></pre></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/">https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/</a></em></p>]]>
            </description>
            <link>https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270576</guid>
            <pubDate>Fri, 26 Feb 2021 01:35:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zine machine: a compact 3D-printed block printing press]]>
            </title>
            <description>
<![CDATA[
Score 245 | Comments 63 (<a href="https://news.ycombinator.com/item?id=26270251">thread link</a>) | @hownottowrite
<br/>
February 25, 2021 | https://hibred.pmvabf.org/zine-machine | <a href="https://web.archive.org/web/*/https://hibred.pmvabf.org/zine-machine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div><p>
            Zine Machine is a compact 3D-printed block printing press. Convert images into blocks, try friends' blocks, or use the supplied type to set a page.
    </p><p>
    All files and instructions necessary to print and use a zine machine are open to the public and available on this website. Designed and released by <a href="https://gestalte.design/" target="_blank">Gestalte Design</a>, 
    Zine Machine is an experiment in guerilla digital fabrication. 
        </p></div>
    </div></div>]]>
            </description>
            <link>https://hibred.pmvabf.org/zine-machine</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270251</guid>
            <pubDate>Fri, 26 Feb 2021 00:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IsometricBlocks]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26270042">thread link</a>) | @autoditype
<br/>
February 25, 2021 | http://shaunlebron.github.io/IsometricBlocks/ | <a href="https://web.archive.org/web/*/http://shaunlebron.github.io/IsometricBlocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="https://github.com/shaunew/IsometricBlocks"><img src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>


	

	<p>
In an <a href="http://en.wikipedia.org/wiki/Isometric_projection">isometric</a>
display, it can be tricky to draw boxes of various sizes in the correct order
to keep them appropriately in front of or behind one another.  The figure below
shows an example.  The blue box should be drawn first, then green, then red.
	</p>

	<figure>
		<canvas id="figure1a" width="350" height="200"></canvas>
		<canvas id="figure1b" width="350" height="200"></canvas>
		<figcaption>
Figure 1: The boxes on the left are <u>not</u> drawn in the correct order, whereas the
boxes on the right are drawn correctly.
		</figcaption>
		
	</figure>

	<p>
We will explore a simple solution for determining the correct order to draw a
given set of boxes.  But first, we must define what we mean by <em>boxes</em>.
	</p>

	<h3>What do we mean by <em>boxes</em>?</h3>

	<p>
We define boxes as <em>axis-aligned</em> and <em>non-intersecting</em>
rectangular prisms. Take a look at the above Figure 1 again.  Each box is
parallel to the <em>x</em>, <em>y</em>, and <em>z</em> axis (i.e.
axis-aligned).  Also, note that the boxes are next to each other but do not
intersect.
	</p>

	<h3>Determine if boxes overlap on screen.</h3>

	<p>
First of all, if two boxes do not overlap on the screen, then we do not have to
worry about which one is drawn first.  This is the first test we must perform,
which we explore in this section.
	</p>

	<figure>
		<canvas id="figure2a" width="350" height="200"></canvas>
		<canvas id="figure2b" width="350" height="200"></canvas>
		<figcaption>
Figure 2: No overlap on the left; overlap on the right.  (Note: we are talking
about overlap on screen, not intersection in space.)
		</figcaption>
		
	</figure>

	<p>
The silhouettes of the 3D boxes become 2D hexagons in the isometric view, as seen below.  We use the
outline of these silhouettes to test for overlap.
	</p>

	<figure>
		<canvas id="figure3a" width="350" height="200"></canvas>
		<canvas id="figure3b" width="350" height="200"></canvas>
		<figcaption>
Figure 3: The box silhouettes in an isometric view are simple hexagons.  Note
that their sides are always parallel to the vertical and two diagonal axes.
		</figcaption>
		
	</figure>

	<p>
We take advantage of the fact that the hexagon sides are always parallel to
some axis.  This allows us to easily determine if the hexagons overlap by
checking for intersection of their regions on each axis.  We add an <em>h</em>
(horizontal) axis to help.
	</p>

	<figure>
		<canvas id="figure4a" width="350" height="200"></canvas>
		<canvas id="figure4b" width="350" height="200"></canvas>
		<figcaption>
The red and blue boxes do not overlap on the h axis, therefore they do not overlap.
The green and blue boxes do overlap since their region on every axis overlap.
		</figcaption>
		
	</figure>

	<p>
Now that we have outlined our concept for <em>determining if two boxes overlap
on the screen</em>, we will fill in the details necessary for implementing it.
	</p>

	<p>
The act of flattening the 3D box into a 2D hexagon involves getting rid of the
Z coordinate.  Notice that increasing a point's Z coordinate by 1 is the same
as incrementing both X and Y coordinates by 1.  Thus, we can add Z to both X
and Y and drop Z completely.  Shown below is the source code for a function
that performs this conversion.
	</p>

<code>
<span>function</span> spaceToIso(spacePos) <span>{</span>

    
    <span>var</span> isoX = spacePos.x + spacePos.z;
    <span>var</span> isoY = spacePos.y + spacePos.z;

    <span>return</span> <span>{</span>
        x: isoX,
        y: isoY,

        
        h: (isoX - isoY) * Math.cos(Math.PI/6),

        
        v: (isoX + isoY) / 2;
    <span>}</span>;
<span>}</span></code>

	<p>
And finally, after determining the bounds of each hexagon, we can determine if
they overlap by using the source code below.
	</p>

<code><span>function</span> doHexagonsOverlap(hex1, hex2) <span>{</span>
    
    <span>return</span> (

        
        !(hex1.xmin &gt;= hex2.xmax || hex2.xmin &gt;= hex1.xmax) &amp;&amp;

        
        !(hex1.ymin &gt;= hex2.ymax || hex2.ymin &gt;= hex1.ymax) &amp;&amp;

        
        !(hex1.hmin &gt;= hex2.hmax || hex2.hmin &gt;= hex1.hmax));
<span>}</span></code>

	<p>
Now that we have determined if two boxes overlap on the screen, we can begin exploring how to determine which box is in front of the other.
	</p>

	<h3>Determine which box is in front.</h3>

	<p>
Recall that our boxes do not intersect each other. we can visualize their separation
as a thin plane between them (see Figure 5 below).  After identifying this
plane, we can determine which box is in front by selecting the one on the
correct side of this plane.
	</p>

	<figure>
		<canvas id="figure5a" width="230" height="200"></canvas>
		<canvas id="figure5b" width="230" height="200"></canvas>
		<canvas id="figure5c" width="230" height="200"></canvas>
		<figcaption>
Figure 5: A pair of blocks can be separated in one of three ways shown here.
The dark glass illustrates this separation.
		</figcaption>
		
	</figure>

	<p>
We can find this plane of separation by looking at each axis individually.  In
particular, we look for an axis which has non-intersecting box ranges (see
Figure 6 below).
	</p>

	<figure>
		<canvas id="figure6a" width="350" height="200"></canvas>
		<canvas id="figure6b" width="350" height="200"></canvas>
		<figcaption>
Figure 6: On the left, the blocks are separated on the y-axis.  On the right,
the blocks are separated on the x-axis. (The z-axis is omitted for simplicity.)
		</figcaption>
		
	</figure>

	<p>
In Figure 6 above, we have chosen a coordinate system which make lesser values
of <em>x</em> and <em>y</em> to be closer to the camera.  Though not shown, the
<em>z</em> axis is positive in the up direction, so a greater value makes it
closer to the camera.
	</p>

	<p>
The following is a javascript function for determining if the first block is in
front of the second:
	</p>

	<code><span>function</span> isBoxInFront(box1, box2) <span>{</span>

    
    
    <span>if</span> (box1.xmin &gt;= box2.xmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.xmin &gt;= box1.xmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.ymin &gt;= box2.ymax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.ymin &gt;= box1.ymax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.zmin &gt;= box2.zmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.zmin &gt;= box1.zmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>

<span>}</span></code>

	<h3>Draw boxes in the correct order.</h3>

	<p>
In general, <u>a box should not be drawn until all the ones behind it are
drawn</u>.  Thus, we begin by drawing the boxes that have nothing behind them.
Then, we can draw the boxes that are only in front of those that are already
drawn. This process continues until all boxes are drawn. (See Figure 4 below
for an example.)
	</p>

	<figure>
		<canvas id="figure7" width="650" height="200"></canvas>
		<figcaption>
Figure 4: (1) Nothing is behind blue, so draw it first. (2) Draw green next
since blue was the only one behind it and is already drawn.  (3) Then draw red,
since both blocks that were behind it have been drawn.
		</figcaption>
		
	</figure>

	<p>
To implement this algorithm, each box must know exactly which boxes are behind
it.  We have already determined how to do this in the last section.  A search
must be implemented so that each box has a list of boxes behind it.
	</p>

	<p>
You are now armed with everything you need to know to render isometric boxes in
the correct order.
	</p>

	<h3>A conundrum</h3>

	<p>
It is possible to have a situation seen in the figure below.  The aforementioned drawing
methods dictate that we first draw the box with nothing behind it, but this example illustrates
a case where this cannot be done.
	</p>

	<figure>
		<canvas id="figure8" width="650" height="200"></canvas>
		<figcaption>
Here are three boxes intertwined in a way such that one is always behind
another.  This prevents us from drawing a first box.
		</figcaption>
		
	</figure>

	<p>
The figure above cheats by segmenting the orange box into two.
This is one method of breaking this type of cycle.
	</p>

	<p>
There are formal methods used for detecting
such cycles mentioned in the appendix.  After detection of a cycle, the blocks in that cycle
could be drawn with special clipping regions to respect front boxes or to segment a block or blocks
that will break the cycle.  These are solutions that I will be exploring and updating this article as
my experiments progress.
	</p>

	<hr>
	<h2>Appendix</h2>

	<h4>A formal description of the solution</h4>

	<p>
This is a special case of the <a href="https://en.wikipedia.org/wiki/Painter%27s_algorithm">Painter's Algorithm</a>,
which handles occlusion by drawing back-to-front.
	</p>

	<p>
For those who are interested, our method for determining if hexagons and boxes
are overlapping is a result of the <a href="http://en.wikipedia.org/wiki/Hyperplane_separation_theorem">hyperplane separation theorem</a>.
	</p>

	<p>
Also, the way in which we determined the drawing order of the boxes is known in graph theory as a <a href="http://en.wikipedia.org/wiki/Topological_sorting">topological sort</a>,
which is essentially a depth-first search of a directed graph.
	</p>

	<p>
You can build a directed graph of the <em>boxes</em>, with directed edges to
the boxes that are behind it.  Topologically sorting this graph will produce an
ordered list of boxes that can be drawn in that exact order.
	</p>

	<p>
Mathematicians will recognize this directed graph as a <a href="http://en.wikipedia.org/wiki/Partially_ordered_set">partially ordered
set</a>.
	</p>

	<p>
Finally, to prevent the aforementioned cycle conundrum, we can use <a href="">Tarjan's
strongly connection components</a> algorithm.  After computing these cycles,
one could either split a block to prevent a cycle, or to use a clipping region
to prevent drawing over any blocks that are supposed to be in front of it.
	</p>

	<h4>Alternative Solutions</h4>

	<p>
You may be able to just use <a href="https://en.wikipedia.org/wiki/Z-buffering">Z-buffering</a>,
though drawing order is still important for transparent sprites.  Also, if all
bounding boxes are unit cubes, sorting is much simpler.
	</p>

	<h4>Full example of working code</h4>

	<p>
All the diagrams above were created using a simple isometric box renderer
written in Javascript, which applies all the techniques described in this
article.  You can study the fully annotated source code on <a href="https://github.com/shaunew/IsometricBlocks">IsometricBlocks project on
GitHub</a>.
	</p>

	<h4>Real game examples</h4>

	<ul>
		<li><a href="http://andrewrussell.net/2016/06/how-2-5d-sorting-works-in-river-city-ransom-underground/">How 2.5D Sorting works in River City Ransom: Underground</a> - allowing bounding boxes to intersect by specifying heightmaps within them (<a href="https://news.ycombinator.com/item?id=12313271">summary</a>)</li>
		<li><a href="http://bannalia.blogspot.co.uk/2008/02/filmation-math.html">Filmation engine on the ZX Spectrum</a></li>
	</ul>
	

	<h4>Thanks</h4>

	<p>
Thanks to Ted Suzman at <a href="http://playbuildy.com/">buildy</a> for
introducing this problem and solution to me.  And thanks to adamhayek for <a href="http://www.reddit.com/r/gamedev/comments/18222r/how_to_determine_the_draw_order_for_an_isometric/c8ayzby">further
insight</a> on a general solution. And thanks to <a href="http://www.reddit.com/r/gamedev/comments/18bg95/tutorial_how_to_render_isometric_blocks_correctly/c8dfx51">Slime0 at reddit</a> for pointing out errors in this article by illustrating the cycle example shown in this article, and for illustrating why we cannot deduce relative drawing order between two non-overlapping boxes.
Thanks to <a href="https://lobste.rs/s/bengjo/drawing_isometric_boxes_correct_order/comments/rzgvnc#c_rzgvnc">Mark Nelson</a> for extra context on painter's algorithm and z-buffering.
	</p>

	<hr>

	<figure>
		<canvas id="figure5" width="700" height="200"></canvas>
		
	</figure>



</div>]]>
            </description>
            <link>http://shaunlebron.github.io/IsometricBlocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270042</guid>
            <pubDate>Fri, 26 Feb 2021 00:08:02 GMT</pubDate>
        </item>
    </channel>
</rss>
