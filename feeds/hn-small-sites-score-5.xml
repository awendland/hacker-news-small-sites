<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 24 Oct 2020 12:36:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 24 Oct 2020 12:36:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The programming architecture of Babbage's Analytical Engine]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24856235">thread link</a>) | @doener
<br/>
October 22, 2020 | https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Prof.+Dr.+Raul+Rojas">Prof. Dr. Raul Rojas</a>

</p>
<p>
Playlists:
<a href="https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas/playlist">'vcfb20' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas/audio">audio</a></p>
<!-- %h3 About -->
<p>The mathematician and inventor Charles Babbage wrote 26 programs between 1836 and 1841 for the unfinished "Analytical Engine" (AE). The code is embedded implicitly in tables summarizing program traces. In this talk, I present the programming architecture of Babbage’s mechanical computer based on the first code written for the machine. The AE had a processor separate from memory, and worked using a kind of dataflow approach. The stream of arithmetical operations was independent from the stream of memory addresses. Special "combinatorial" cards allowed the processor to execute FOR and WHILE loops. Combinatorial cards also allowed independent looping through the stream of memory addresses. Quite sophisticated computations were possible and illustrate why Babbage talked about the possibility of doing "algebra" with his machine. The programs I will discuss predate by several years the account published by Menabrea in 1842 and translated later by Lady Lovelace with notes of her own.</p>

<h3>Download</h3>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24856235</guid>
            <pubDate>Thu, 22 Oct 2020 09:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Google obliterated my 4 year old Chrome extension with 24k+ users (2016)]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24855582">thread link</a>) | @Fiveplus
<br/>
October 22, 2020 | https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18 | <a href="https://web.archive.org/web/*/https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><div><p>
              After 3 months of trying everything I could think of, I give up.
              I don’t think I will ever develop anything for the Google
              ecosystem again. I’m not angry, I’m not doing this out of spite.
              I just don’t think it is worth it to invest any amount of effort
              to build something on a platform that turned out to be so
              unreliable.
            </p>  <h2>Please scroll down to read the latest update.</h2>  <p>
              I started developing my first extension back in 2010, when Apple
              finally decided to implement proper extension support in Safari.
              Exciting times. I spent a weekend writing my first Safari
              Extension, an ad blocker called “Cleaner Facebook”. I must
              confess it was ugly, and by today’s standards, very poorly
              written, but it did the job.
            </p> <p>
              After a few weeks while browsing Facebook using Chrome, the
              annoying ads popped up and I figured that it’ll be worthwhile to
              port it over, so I did. I also made it available to everyone via
              <a href="http://apps.graffino.com/" target="_blank" title="App Development">Graffino’s apps playground.</a></p> <p>
              Months later the due to some policy changes in Chrome, I moved
              to the Chrome Web Store where I made it available for free under
              the name “Cleaner Facebook”.
            </p> <p>
              What happened next was beyond my wildest expectations. It
              quickly gathered around 4.000 users and over the last year it
              surged to 24.000+ users. Whenever I pushed an update, the
              numbers would spike.
            </p> <p>
              I got quite a few offers to sell it, so others could push
              advertising through it. Thing is, I never wanted to make any
              money off it and I felt like I was betraying my users. So, I
              kept it and improved it constantly. It worked so well because I
              needed it to work well, I was using it daily and my users loved
              it. It got a 5 stars rating and over 85 reviews.
            </p> <blockquote>
              Google has been notified that some of your materials allegedly
              infringe upon the trademarks of others.
            </blockquote> <p>
              At the end of May this year, I received an email from Google
              telling me that my extension violated Facebook’s trademark and
              got taken down. There was no information how to solve the issue,
              no way to appeal. Google washed its hands clean and directed all
              inquiries to an automatically generated email address. This
              email address was a black hole that never responded to any of my
              emails.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/bcfd01f.png" alt="Google's notification that they removed Graffino's Ads removal app from the store."> <figcaption>
                The original infringement and taken down notice (shortened).
              </figcaption></figure> <p>
              I figured out that the name might be an issue although there
              were
              <a href="https://chrome.google.com/webstore/search/facebook?hl=en-US" target="_blank">a lot of other extensions</a>
              with the same name in the store. Even so, I changed the name of
              my extension to “Cleaner — for Facebook” and resubmitted it to
              the store where it got placed “In review”.
            </p> <p>
              Over the next weeks I never received any email from the Chrome
              Store other than the initial take down notice. When I logged in
              again, I found my extension was still “Taken down” and the “In
              review” flag gone.
            </p> <p>
              I went on to search for a Developer Support page, but after half
              an hour of searching I found out that there is none. There is no
              support whatsoever for the developer besides Google’s own
              documentation. If you encounter an issue that you can’t solve
              yourself, you’re stranded. There’s no contact info. No one to
              write to.
            </p> <p>
              After getting really frustrated that day, I vented out sending
              out a nasty email to removals@google.com. Not sure it helped.
            </p> <p>
              The next day I poked around and found a support form intended
              for Chrome Web Store users. In my desperation I figured this was
              my only option left.
            </p> <p>
              About a week later, I got my first reply from <em>Google</em>.
              Although it sounded nice, it wasn’t really helpful. Most
              probably due to the fact it was a canned response, totally
              unrelated to my issue.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/a38f41d.png" alt="Google's first email response to Graffino's complaint."> <figcaption>First canned response</figcaption></figure> <p>
              Later that day, I fired a few other emails, telling them that my
              extension was not under review and the cause for the take down
              was not flagging. I also submitted another message via the
              support form I used before. My requests got closed with a
              <em>“Thanks for your feedback.”</em> canned response.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/c1a157e.png" alt="Google's first email response to Graffino's complaint."> <figcaption>“Thank you for your feedback” response</figcaption></figure> <p>
              Meanwhile my extension’s user base was dwindling, and I could do
              absolutely nothing about it.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/ee3fd6a.png" alt="Google's first email response to Graffino's complaint."> <figcaption>
                Screenshot from the Developer Dashboard made on the 18th of
                July.
              </figcaption></figure> <p>
              After another two weeks I finally gave up and sent this final
              email. I got a reply that my case was “Reopened”. It’s been a
              month and I didn’t hear back since, so I don’t think I will ever
              get my extension back on the store.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/3e2eaf4.png" alt="Google's first email response to Graffino's complaint."> <figcaption>Final email from my side.</figcaption></figure> <p>
              I’m not playing the victim here, and I don’t expect this post to
              solve anything for my extension. I just want you to think twice
              before creating a revenue stream based on the Chrome Web Store.
            </p> <p>
              Google has great automated tools and services, to help
              developers ramp up and deliver their apps to users quickly and
              painless. Most of the time these tools work perfectly. The
              problems arise when they don’t.
            </p> <p>
              I have never experienced such frustration, and such feelings of
              helplessness from any other major player out there. A similar
              issue with the
              <a href="https://safari-extensions.apple.com/details/?id=com.graffino.cleaner-for-facebook-86755BRK69" target="_blank">“Cleaner Facebook” Safari extension”</a>, got promptly solved by Apple in under three days.
            </p> <p>
              Google has a record of very bad user support. Basically, if your
              issue is not listed in the “Support Forums” you’re screwed. If I
              would have based my business on the Chrome Web store, I would be
              out of business by now.
            </p>  <h2>Update 8.09.2016</h2> <p>
              I never imagined this would generate this amount of attention:
              featured by
              <strong>Medium, 100k+</strong> views, heated discussions on
              <a href="https://www.reddit.com/r/programming/comments/51mgix/how_google_obliterated_my_4_year_old_chrome/" target="_blank">Reddit</a>
              or
              <a href="https://news.ycombinator.com/item?id=12442048" target="_blank">Hackernews</a>. I don’t really expect this to change anything for me, but I’m
              glad people are speaking up. If Google would implement a paid
              support option like Apple does for its developers, I’m sure a
              lot of pain would be avoided.
            </p> <p>
              I try to read everything, but I don’t respond on Medium (hate
              the commenting system), but you can ping me on Twitter.
            </p> <h2>To answer the most common questions:</h2> <p>1.<em> “Why don’t you change the name completely?”</em></p> <p>
              Well, because using “for Facebook” in the name is considered
              <a href="http://www.inta.org/TrademarkBasics/FactSheets/Pages/FairUse.aspx" target="_blank">fair use</a>. Also, when managing an app or extension with that many users,
              you don’t really want to confuse the users by renaming it to a
              completely different thing over night. It’s also an extension
              that only works on Facebook. I might also be infringing with the
              icon.
            </p> <p>
              So, you see, I really need guidelines to do this. Again, my
              problem is with the way this was handled, not the takedown
              itself.
            </p> <p>
              2.
              <em>“The extension was taken down because it was blocking ads.”
              </em></p> <p>
              This is simply untrue. I don't believe I was intentionally
              targeted. I was simply unlucky enough to be targeted by
              automated tools. Even the way my requests were handled weren’t
              done with malicious intent by Google. I think I’m just an edge
              case for which their support tools aren’t equipped to deal with.
            </p> <h2>Update: 9.09.2016</h2> <p>
              I received an email from Google today in which they’re
              expressing their apologies about the incident. It seems that
              they cannot do anything for the current store entry until the
              original complainant retracts his complain.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/3e2eaf4.png" alt="Google's first email response to Graffino's complaint."> <figcaption>Final email from my side.</figcaption></figure> <p>
              They offered me clear options though. We’re currently assessing
              what the best option might be. As I said in the article, this
              wasn’t an intentional targeting but a slip-up of their support
              which they’re trying to fix.
            </p> <p>
              Hopefully I will have the time to write a follow-up once all
              this is over. I didn’t expect or wanted this kind of attention,
              these have been 2 stressful days for me, trying to keep up with
              all the requests and messages, as I do have a job and my own
              company to run.
            </p> <p>
              It also happens that today is my birthday. I guess receiving a
              response from Google was my birthday present :).
            </p>  <h2>Update: 10.09.2016</h2> <p>
              You can still find the
              <a href="http://apps.graffino.com/" target="_blank">ad blocker extension</a>
              here. However, you will not be able to run it. Chrome made
              changes so that extensions cannot be side-loaded without an
              enterprise profile.
            </p> <h2>Final Update: 12.09.2016</h2> <p>
         …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18">https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18</a></em></p>]]>
            </description>
            <link>https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18</link>
            <guid isPermaLink="false">hacker-news-small-sites-24855582</guid>
            <pubDate>Thu, 22 Oct 2020 07:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The virtual device farm for rendering websites on multiple devices]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24855342">thread link</a>) | @seleniumbase
<br/>
October 21, 2020 | https://seleniumbase.io/devices/?url=news.ycombinator.com | <a href="https://web.archive.org/web/*/https://seleniumbase.io/devices/?url=news.ycombinator.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://seleniumbase.io/devices/?url=news.ycombinator.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-24855342</guid>
            <pubDate>Thu, 22 Oct 2020 06:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Early Adopters: Be Picky About Who You Serve]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24854108">thread link</a>) | @johnkoht
<br/>
October 21, 2020 | https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve | <a href="https://web.archive.org/web/*/https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>October 08, 2020</p></header><section itemprop="articleBody"><p>Any successful founder will tell you that team, product, and market are the most critical factors to building a successful business. And you’ll probably hear many of them talk about being “customer-obsessed” or “customer first.” But one of the most underrated factors in their success is not just the customers but also the quality of their early adopters.</p>
<p>While we can all agree that early adopters are good, they are not all created equal. The wrong users can derail entrepreneurs, causing them to lose focus and solve the wrong problems. Like a bad team or poor product, the wrong early adopters can push a company towards failure.</p>
<p>You should be picky about who you serve, especially during the initial phase of your product development process. Finding early adopters should be an investment similar to hiring a team. Entrepreneurs should recruit, interview, qualify, and partner with early adopters that will help them become most successful. It’s not a simple process and shouldn’t be taken for granted.</p>
<p>So how do you find the right early adopters? That’s a difficult question to answer. It’s all going to come down to your market, product, and judgment. But here are some characteristics that you should look for.</p>
<h2>They are in real pain.</h2>
<p>The right early users are deeply affected by the problem that you’re solving. They know the problem exists and are hungry for a better solution. They’ve probably tried other solutions and yearn for something better.</p>
<p>Early adopters will be keenly aware of the problem. They will explain the problem in various ways and how it affects their ability to work, live, or perform some activity. They’ve probably even tried to solve it somehow, maybe using Excel, some no-code app, a third-party tool, or a manual process.</p>
<h2>Their problem is very specific.</h2>
<p>Users have all kinds of problems. Most of which you’ll never solve. Others might be in your roadmap but are not core today. It’s essential to focus on users with the specific problem that you are solving for. Problems can emerge from various systems, workflows, and integrations that have nothing to do with the core problem or your potential solution. Eliminate the users who are looking to solve all of their problems. Eliminate the users who want a different, possibly related, problem solved.</p>
<p>The best early adopters need to solve a specific problem. It’s vital to ensure that it matches your vision and product solution.</p>
<h2>They are excited to help you.</h2>
<p>The solution you’re offering them is going to alleviate a pain point, and the best early adopters are more than excited to help you help them. The more excited they are, the more pain they experience from the problem.</p>
<p>Early adopters are partners. They should be excited about working with you, helping you solve their problem, and providing feedback. They should also be excited that they will be using your solution before others and developing a competitive edge as well.</p>
<p>When you acquire great early adopters, they will be the ones sending you feedback often and with excitement. They’ll be proud to help you craft your solution and feel like their part of the team.</p>
<h2>They are empowered</h2>
<p>Early adopters must be empowered to make decisions quickly. Working with your dream enterprise customer sounds great, but if they can’t get approval, move quickly, or activate your solution, you’ll be at the mercy of their bureaucracy.</p>
<p>Working with early adopters is a partnership, not a transaction. It’s important that early adopters can take your prototype, beta, or product and implement it within their team or organization.</p>
<p>The person is as vital as the company. Are they authorized to make the right decisions? Can they dedicate the time and resources to the problem and solution? Are they empowered to help you create the right solution? If they can’t meet these criteria, you should find another early adopter who can.</p>
<h2>They have a high-risk tolerance.</h2>
<p>The best products are built with customers, through an iterative process of trial and error. Early adopters who experience the pain are not enough; you need a partner who can tolerate the risks involved in the product development process. Not only do they have a high-risk tolerance, but they should also be willing and able to engage in ongoing experiments throughout the process.</p>
<p>Experimentation is critical to the process. You need to ensure that you partner with a customer that recognizes the process is about learning and improvement, not a finished product.</p>
<p>When interviewing customers, you should be upfront about this process and ensure they are comfortable with it. It’s okay if a potential customer can’t commit to the process, you can keep in touch and invite them to the product when it’s a bit more developed.</p>
<h2>Hire early adopters, don’t settle.</h2>
<p>Don’t just settle for the first few customers that show interest in your product. Spend time doing market mapping to better understand the market, sectors, and potential customers. Learn more about the companies and find who the best possible contacts would be. Reach out and conduct interviews to learn more about their organization, how the problem affects them, and their goals regarding the problem and solution. Make sure to dig in and ask tough questions to assess their risk-tolerance, current solutions, and whether they are authorized to make the necessary decisions.</p>
<p>If a potential customer seems like the problem isn’t that big of a deal, you should move on. If they can’t focus on just the one problem, move on. If they aren’t authorized to make decisions, ask about their manager and see if you can work your way up.</p>
<p>You should spend a good amount of time learning about each of these customers and selecting the best candidates. Don’t hesitate to reach out multiple times and have conversations with them to build confidence in your decisions. These will be partners as you experiment and craft your solution, so ensure you find the best possible partners.</p>
<h2>They’re all leads, too.</h2>
<p>Choosing the best early adopters doesn’t mean that the others will not be good future customers. All of these customers are now leads. Some might be great customers once you hit a particular milestone and finish more features; others might be customers down the road. Keep in touch and share updates on the product and feature set.</p>
<p>Recruiting high-quality early adopters is difficult but vital to the success of a company. Spend the time upfront to say no to customers that don’t fit your current vision and mission. While the process is difficult and costly, it’ll be worth the investment as the product matures.</p></section></article></div>]]>
            </description>
            <link>https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve</link>
            <guid isPermaLink="false">hacker-news-small-sites-24854108</guid>
            <pubDate>Thu, 22 Oct 2020 01:37:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a startup financial model from scratch]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24853787">thread link</a>) | @aaronbski
<br/>
October 21, 2020 | https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model | <a href="https://web.archive.org/web/*/https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
  <article id="article-57daf9aad2b857a2108683be" data-item-id="57daf9aad2b857a2108683be">

    

    <div>
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1473969767493" id="item-57daf9aad2b857a2108683be"><div><div><div data-block-type="2" id="block-7c825fcce3d916c3aa66"><div><p><em>This article was originally published over on Startup Rocket&nbsp;</em><a href="https://www.startuprocket.com/articles/startup-financial-modeling-part-1-what-is-a-financial-model" target="_blank"><em>here</em></a><em>, and written by Will Little and Troy Henikoff.</em></p><p><em>This series is the result of a friendly debate I had recently with&nbsp;</em><a href="https://www.mathventurepartners.com/troy-henikoff" target="_blank">Troy Henikoff</a><em>&nbsp;(former Techstars Chicago Accelerator Managing Director)&nbsp;regarding the best approach for founders to take when building a financial model. More accurately, the “debate” was a strong adverse reaction from Troy after I shared a template I built for Prota Ventures’ portfolio companies. His feedback was, essentially, to never use a template and instead build each model from scratch.</em></p><p><em>He invited me to a 90-minute lecture he gave where he overwhelmingly convinced me and the room that, indeed, founders need to take the time necessary to build their models from scratch. After I asked him where I could find his lecture material online, he suggested we co-author this article series since there weren’t many solid resources available. We sincerely hope you find this series helpful.&nbsp;</em></p><p>Our plan is to break this out into a four-part series and guide you through the components necessary for building your own financial model from scratch:</p><ul data-rte-list="default"><li><p><a href="https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model" target="_blank">Part 1: The Why and What of Financial Modeling</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/2/startup-financial-modeling-part-2-start-with-your-assumptions" target="_blank">Part 2: Assumptions</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/2/startup-financial-modeling-part-3-the-income-statement-and-custom-detail-tabs" target="_blank">Part 3: Income Statement and Custom Detail Tabs</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/7/startup-financial-modeling-part-4-the-balance-sheet-cash-flow-and-unit-economics" target="_blank">Part 4: Cash Flow, Balance Sheet and Keeping the Model Updated</a></p></li></ul><p>In short, a financial model is an abstract mathematical representation of how a company works (and more importantly, how it will work going forward). The model has inputs and outputs. The inputs are the assumptions that drive the model, things like what drives your customer acquisition cost, what your churn rates are, how much you pay people, etc. The outputs are a set of projections that show how the company will perform if the assumptions are true. One model can produce multiple sets of projections given different assumptions.</p><p>Based on a set of assumptions, a financial model is used to make smart decisions (e.g. how many sales people to hire and what to pay them). The model includes financial projections that are tied mathematically to the assumptions, which allows operators to “play with the variables” in order to understand how certain decisions might affect the future health of their company.</p><p><strong>Troy has an important story to share on this topic:</strong></p><p>“When fundraising for SurePayroll, we had some very high level financials in the pitch deck. Inevitably, VC’s would ask where the numbers came from. I would tell them that we had a very detailed financial model that drove it, I was setting the bait…</p><p>They would ask to be sent a copy of the model and I would refuse. I would only share it by first sitting down with them and an associate and reviewing the model in person and after that 90 minute session, I would leave them a copy of the model to play with further.</p><blockquote><p>They would insist that they could figure it out without the meeting, but I ALWAYS held my ground. I wanted the meeting not just to save them time and frustration learning a new model, but more importantly to get more face time with them in a situation where I was going to shine.</p></blockquote><p>I knew the model inside and out since I built it; I could answer any question about any cell and look like a genius. In the end, I did eight&nbsp;of these meetings and EVERY ONE of the firms that did the 90 minute meeting with me on the financial model either made an investment in the company or made an offer to invest in the company.&nbsp;<strong>Every single one</strong>.”</p><p>While it’s easy to search around and find a template to use, those templates were built by someone with a particular business in mind. Since every business is unique, this will lead you into trouble.</p><p>While it’s often helpful to&nbsp;<em>learn&nbsp;</em>from other people’s models to ensure, for example, that you aren’t missing anything important, you should never build your model using their template. You’ll end up banging your head against a wall when you need to change things, and you’ll inevitably be confused about some nuance that will come back to haunt you since you don’t understand it.</p><blockquote><p>In other words, while you may think that a template will help you save time, what you are actually doing is acquiring “technical debt” that will end up costing you more time in the long run.</p></blockquote><p>Plus, it’s critical to understand every column, row, cell and tab in your spreadsheet for two key reasons; it will help you better manage your business, and when the time comes to explain it to an investor, you’ll be able to explain exactly how it works and increase your odds of landing funding.</p><p>Since most people are using the financial model to communicate projections to investors, it is critical that you speak the investors’ language. They are used to having financials in Excel, so you should build your model in Excel.</p><blockquote><p>Google sheets is convenient for making changes and having multiple people editing, but sending an investor a model in Google sheets signals that you are not financially savvy.</p></blockquote><p>Investors are also used to seeing three standard statements; an income statement, a balance sheet, and a statement of cash flow. &nbsp;Each of these is more credible if it has BOTH the past performance and the future projections in the same spreadsheet.</p><p>Your spreadsheet should contain a tab for each of these outputs along with an “assumptions” tab and custom detail tabs needed to help calculate the main outputs. We’ll walk through a specific example later in this series so you have a better understanding of what this should look like.</p><p>Because of various accounting nuances – such as fixed asset depreciation and deferring revenue – if you assign ten accountants to finish your books at the end of the year, you’ll get ten different answers for how much profit (or loss) you had in the year. While hopefully not far off from the others, each will have a slightly different report of your “profit” based on their accounting opinions.</p><blockquote><p>However, the balance of your bank account is a specific number to point at; it’s a fact that your ten accountants should agree on.</p></blockquote><p>Therefore, it’s important to remember that your financial model will have your own opinions baked in regarding your profit. This means that examining your cash flow carefully as you fine-tune your business assumptions is critical.</p><p>Having a solid financial model is a significant step in communicating to investors that you are a logical thinker with a defensible plan and clearly understand your business and the levers that drive it. &nbsp;&nbsp;</p><p>Nobody expects your model to be perfect, as a matter of fact, when we present a model, we always open with the same line:</p><blockquote><p><em>“The only thing we know for sure about this model is that it is wrong. But, if we look critically at it we can better understand the drivers of the business and what we need to be focused on to reduce our risk.” &nbsp;</em></p></blockquote><p>Keep in mind, investors are looking for the big home runs, but they are also looking at reducing their risk. The model can help them get comfortable with the risk.</p><p>– – –</p><p><em>In our next post in this series, we’ll dive in a step-by-step guide of how to build a financial model, starting with the assumptions tab.&nbsp;</em><a href="https://satchel.works/@wclittle/subscribe" target="_blank">Subscribe</a><em>&nbsp;to Will’s newsletter to get notified when the next articles are up. As we mentioned above, feel free to ping us on Twitter (</em><a href="https://twitter.com/wclittle" target="_blank"><em>@wclittle</em></a><em>,&nbsp;</em><a href="https://twitter.com/troyhenikoff" target="_blank"><em>@troyhenikoff</em></a><em>) with any questions.</em></p></div></div></div></div></div>
      
    </div>


    

    
      
    

    

  </article>

  

  

  
  
  

</div></div>]]>
            </description>
            <link>https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853787</guid>
            <pubDate>Thu, 22 Oct 2020 00:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI reveals hundreds of millions of trees in the Sahara]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24853679">thread link</a>) | @hhs
<br/>
October 21, 2020 | https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara | <a href="https://web.archive.org/web/*/https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-area">
        <div>
          <!-- Content with right menu -->

<div>
  
    





  

	<p>
		20 October 2020
	</p>

	


	<div>
		<p><span>TREES</span></p><p>There are far more trees in the West African Sahara and Sahel than most would expect. A combination of artificial intelligence and detailed satellite imagery allowed a team from the University of Copenhagen and international collaborators to count all trees across a 1.3 million km2 area of West Africa. 
</p>
	</div> 
		<figure>
			<img alt="Dryland landscape in Africa" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/Sahara_1100x600.jpg" title="Dryland landscape in Africa">
			<figcaption>Photo: Martin Brandt</figcaption>
		</figure>

	<p>If you think that the Sahara is covered only by golden dunes and scorched rocks, you aren’t alone. Perhaps it's time to shelve that notion. In an area of West Africa 30 times larger than Denmark, an international team, led by University of Copenhagen and NASA researchers, has counted over 1.8 billion trees and shrubs. The 1.3 million km<sup>2</sup> area covers the western-most portion of the Sahara Desert, the Sahel and what are known as sub-humid zones of West Africa.</p>
<p>"We were very surprised to see that quite a few trees actually grow in the Sahara Desert, because up until now, most people thought that virtually none existed. We counted hundreds of millions of trees in the desert alone. Doing so wouldn't have been possible without this technology. Indeed, I think it marks the beginning of a new scientific era," asserts Assistant Professor Martin Brandt of the University of Copenhagen’s Department of Geosciences and Natural Resource Management, lead author of <a href="https://www.nature.com/articles/s41586-020-2824-5">the study’s scientific article, now published in <em>Nature</em></a>.</p>
<p>The work was achieved through a combination of detailed satellite imagery provided by NASA, and deep learning — an advanced artificial intelligence method. Normal satellite imagery is unable to identify individual trees, they remain literally invisible. Moreover, &nbsp;a limited interest in counting trees outside of forested areas led to the prevailing view that there were almost no trees in this particular region. This is the first time that trees across a large dryland region have been counted.</p>
<h2>The role of trees in the global carbon budget</h2>
<p>New knowledge about trees in dryland areas like this is important for several reasons, according to Martin Brandt. For example, they represent an unknown factor when it comes to the global carbon budget:</p>
<p>"Trees outside of forested areas are usually not included in climate models, and we know very little about their carbon stocks. They are basically a white spot on maps and an unknown component in the global carbon cycle," explains Martin Brandt.</p>
<p>Furthermore, the new study can contribute to better understanding the importance of trees for biodiversity and ecosystems and for the people living in these areas. In particular, enhanced knowledge about trees is also important for developing programmes that promote agroforestry, which plays a major environmental and socio-economic role in arid regions.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>"Thus, we are also interested in using satellites to determine tree species, as tree types are significant in relation to their value to local populations who use wood resources as part of their livelihoods. Trees and their fruit are consumed by both livestock and humans, and when preserved in the fields, trees have a positive effect on crop yields because they improve the balance of water and nutrients," explains Professor Rasmus Fensholt of the Department of Geosciences and Natural Resource Management.</p>

<figure><img alt="The area where the trees were mapped" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/West_Africa_study_area_1100x600.jpg" title="The red rectangle marks the area where the trees were mapped">
<figcaption>The red rectangle marks the area where the trees were mapped.</figcaption>
</figure>

<h2>Technology with a high potential</h2>
<p>The research was conducted in collaboration with the University of Copenhagen’s Department of Computer Science, where researchers developed the deep learning algorithm that made the counting of trees over such a large area possible.</p>
<p>The researchers show the deep learning model what a tree looks like: They do so by feeding it thousands of images of various trees. Based upon the recognition of tree shapes, the model can then automatically identify and map trees over large areas and thousands of images. The model needs only hours what would take thousands of humans several years to achieve.</p>
<p>"This technology has enormous potential when it comes to documenting changes on a global scale and ultimately, in contributing towards global climate goals. It is a motivation for us to develop this type of beneficial artificial intelligence," says professor and co-author Christian Igel of the Department of Computer Science.</p>
<p>The next step is to expand the count to a much larger area in Africa. And in the longer term, the aim is to create a global database of all trees growing outside forest areas.</p>





  

</div>
<div>

  
    
    
        	

	


        <div>
    <p>
        <h2>Fakta</h2>
    </p>
    <div>
        <ul>
<li>The researchers counted 1.8 billion trees and shrubs with crowns larger than 3 m<sup>2</sup>. Thus, the actual number of trees in the area is even higher.</li>
<li>Deep learning can be characterized as an advanced artificial intelligence method where an algorithm is trained to recognize specific patterns in large amounts of data. The algorithm used in this research was trained using nearly 90,000 images of different trees across a variety of landscapes. </li>
<li><a href="https://www.nature.com/articles/s41586-020-2824-5">The scientific article for this study is published in the renowned journal Nature.</a> </li>
<li>The research was carried out by researchers from the University of Copenhagen; NASA Goddard Space Flight Center, USA; HCI Group, University of Bremen, Germany; Université Paul Sabatier, France; Pastoralisme Conseil, France; Centre de Suivi Ecologique, Senegal; Geosciences Environnement Toulouse (GET), France; Ecole Normale Supérieure, France; Université Catholique de Louvain, Belgium.</li>
<li>The research is supported, among others, The AXA Research Fund (postdoctoral programme); Independent Research Fund Denmark - Sapere Aude; Villum Foundation and the European Research Council (ERC) under the EU's Horizon 2020 Programme.</li>
</ul>

    </div>
</div>


        






  
</div>

        </div>
        
      </div></div>]]>
            </description>
            <link>https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853679</guid>
            <pubDate>Thu, 22 Oct 2020 00:07:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on My Colon Cancer]]>
            </title>
            <description>
<![CDATA[
Score 336 | Comments 182 (<a href="https://news.ycombinator.com/item?id=24853503">thread link</a>) | @whatrocks
<br/>
October 21, 2020 | https://www.charlieharrington.com/colon-cancer | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/colon-cancer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The giant robot looks like a WED Treadwell, <a href="https://www.charlieharrington.com/robots-i-love">my favorite robot</a> of all the Star Wars droids. I admit, I was worried that it would look organic, like a Sentinel from The Matrix, with wriggling Dr. Octopus arms and pinchy pincers that pinch. But I'm calmed by the robot's EVE-like exterior.</p>
<p>The room is sterile. A dozen masked, gloved attendants in blue buzz. I imagine I'm an astronaut about to step into the rocketship capsule.</p>
<p>Except I won't be going anywhere on this particular journey, unless something goes very, very wrong. In fact, I've already been asked repeatedly by various staffers to describe what I'm expecting to happen in this room over the next few hours:</p>
<blockquote>
<p>"I'm here to remove my sigmoid colon via robotic surgery because of the cancerous tumor inside."</p>
</blockquote>
<p>I'm 34 years old. It's October 12th, 2020. Five weeks ago I was diagnosed with colon cancer.</p>
<h2>Stool, bloody stool</h2>
<p>I've always been a standing wiper. Not sure entirely why. I must have once, accidentally, touched a load of poo during a seated wipe. That sort of thing can change a person.</p>
<p>This charming anecdote does factor into our story, because it means I've always had a pretty good sense for my poo. Consistency, quality, and color, both in the bowl and on the TP. Did you know, there's even a seven-stage scientific classification system for your poo, called the <a href="https://en.wikipedia.org/wiki/Bristol_stool_scale">Bristol stool scale</a>?!</p>
<p><span>
      <span></span>
  <img alt="Bristol stool scale" title="Bristol stool scale" src="https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/a6d36/bristol.png" srcset="https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/222b7/bristol.png 163w,
https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/ff46a/bristol.png 325w,
https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/a6d36/bristol.png 650w,
https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/be86f/bristol.png 662w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<p>I first noticed blood two or three years ago. On a monthly or so cadence, I'd wipe and notice a reddish tinge. Not bright red, more like muddy-red. Poopy-red. Initially, I thought little of it. Just a minor curiousity. It certainly didn't happen every time. Still, I decided to check off the <code>Blood in stool</code> box on the forms at my annual physical with my primary care doctor that year.</p>
<p>A brief aside on the phrase "your primary care doctor." Like in <em>Forgetting Sarah Marshall</em>, the last doctor I really thought of as "my doctor" was my pediatrician. Since "becoming an adult", I've lived in three cities in two countries, which means that I've generally had no idea who my primary care doctor is or was, only that I'd need to find one to give me a referral to get this wart on my foot removed.</p>
<p><span>
      <span></span>
  <img alt="Firetruck" title="Firetruck" src="https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/a6d36/firetruck.png" srcset="https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/222b7/firetruck.png 163w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/ff46a/firetruck.png 325w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/a6d36/firetruck.png 650w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/e548f/firetruck.png 975w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/3c492/firetruck.png 1300w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/6c2de/firetruck.png 1334w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<p>Anyway, this season's Dr. Who told me not to worry about the blood. "It's probably hemorrhoids."</p>
<p><em>WTF is a hemorrhoid?</em> I wondered to myself as I said to him, "Sounds good." Googled it after, and I learned that it's a vein that pokes out a little in your butt and doesn't really want to be poking out a little, so it bleeds. Seems like a thing that can happen, so I more or less returned to regularly scheduled programming and just dealt with the occasional poopy-red wipe. This doc also said I probably don't need to come for a physical for a few years, that annual physicals are a myth, dry land in a water world.</p>
<p>Fast-forward to 2020. Everything sucks. And the bloody wipes are making a resurgence. Because, of course, they are. About four months ago I noticed that my first poop of the day (I usually go 2x) would have this purple-red streak embedded in it, like a racing stripe from hell. And it would happen almost without fail every single morning. That just didn't seem right, no matter what Doctors of Physicals Past told me. And then one morning I felt like I had actual blood dripping from my butt.</p>
<p>Now I consider myself to be a mostly healthy person. I eat fairly well (even though I enjoy the occasional sourdough loaf and hazy IPA), I run and bike and hike regularly, I ran an IRONMAN in 2016 and a few ultramarathons since. I also don't like being sick (who does?). But, like with most things in my life, I want to be "good" at health. An ideal dental appointment for me would go something like this, "Wow, Charlie, these are the straightest, whitest teeth we've ever seen. We'd like you to come in and be the model for our Instagram ads and also be our 3D teeth model for dentures. Congratulations. Here's <em>two</em> free toothbrushes. You also never need to floss again."</p>
<p>Anything that deviates from that ideal makes me squirm and I do think I can fix anything. For what it's worth I still believe that, if I ever encounter a blue flower on a mountain-top, I'm only a few months of mystical training away from becoming Batman. I already have the cape (it's actually a Harry Potter robe, but, hey, I'm scrappy).</p>
<p>At the same time, I counterweight this with a mild touch of hypochondria. I'll see the poison oak in the mistletoe, so to speak. In this case it was a gift.  I googled again for <em>stool, bloody stool</em> and the dreaded <em>colon cancer</em> came back. Last time, I averted my eyes from these search results. But the bloody racing stripes weren't going away. I needed to get myself checked out.</p>
<p>Then I remembered an email from work: I was eligible for a <a href="http://members.onemedical.com/membership_referrals?code=cha0014&amp;source=sa">OneMedical</a> membership. I knew there was hype about OneMedical, certainly I've seen the billboards, but I still wasn't exactly sure what they were all about. It had been a few years since my last physical, as you know, so I was primary-care-less, with a bloody problem on my hands. I downloaded the OneMedical app, uploaded a photo of my insurance card, beep-boop, and I've got an appointment with a new doc in a few days in one of their nearby clinics. Already, I loved the experience - I could text my questions any time (see <em>foot wart</em> above). I'd describe OneMedical as a network of clinics with an app for scheduling appointments and texting with a doc. Sure, ZocDoc kinda does the scheduling thing, but Zocdoc feels like you're sifting through the classifieds. Gimme some non-user-generated-ratings-based curation, please. </p>
<p>So, I met with the doc, liked him a lot, discussed my bloody poops, and sheepishly asked if he'd be my new primary care. He agreed, and he also referred me to UCSF for a colonoscopy. Sure, I'm young, and it's probably hemorrhoids, we agreed, but it's the only way to be sure.</p>
<p>After some jiggling about with the referral documentation, we finally get the colonoscopy scheduled for a few weeks later on Sept 9th.</p>
<p>Then, on August 28th, <a href="https://en.wikipedia.org/wiki/Chadwick_Boseman">Chadwick Boseman</a> died of complications from colon cancer.</p>
<p>I wasn't freaked out. Okay, yes, I was very freaked out.</p>
<h2>Colonoscopies are not bad</h2>
<p>What's a colonoscopy? It's a surgical procedure where the doctor goes all the way up your butt to see what's going on in there. You are completely knocked out, so you feel nothing. The only thing you need to do is what we in the business like to call "bowel prep."</p>
<p>Allow me to describe bowel prep: the day before the procedure, you will poop your ever-living guts out for a few hours until you are clean-as-a-whistle, stem to stern. They'll give you a prescription for a gigantic jug of clear laxatives that you'll drink every 15 minutes or so for a few hours. In today's toilet-paper hoarding economy, I'd make sure that you are stocked up, because this gets messy.</p>
<p>Other then the laxatives, you're allowed to drink clear liquids - which is confusing because you can enjoy such clear liquids as black coffee, Gatorade, broth, even green jello.</p>
<p>But that's it. Easy. I watched Stranger Things season 3 again during my bowel prep day. Might not have been the best choice, as I intermittently had to pause Netflix to contribute my own liquified form of the Mind-Flayer, but it got the job done, and I cried my way thru Dustin and Suzie's hymn to childhood, again, as expected.</p>
<p>Okay, next, I woke up on September 9th. My appointment is around 2 PM. Normal day, right?</p>
<p><span>
      <span></span>
  <img alt="sf" title="sf" src="https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/6aca1/sf.jpg" srcset="https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/d2f63/sf.jpg 163w,
https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/c989d/sf.jpg 325w,
https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/6aca1/sf.jpg 650w,
https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/8e1fc/sf.jpg 900w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<blockquote><p lang="en" dir="ltr">A strange, apocalyptic orange-red sky looms over the Bay Area. Here's what you need to know.<br>Read more: <a href="https://t.co/JxpYSnUPG9">https://t.co/JxpYSnUPG9</a> <a href="https://t.co/ZPOj4X3jRg">pic.twitter.com/ZPOj4X3jRg</a></p>— San Francisco Chronicle (@sfchronicle) <a href="https://twitter.com/sfchronicle/status/1303799596515172352?ref_src=twsrc%5Etfw">September 9, 2020</a></blockquote> 
<p>Nope.</p>
<p>I decide to walk over to the UCSF Parnassus building in the creepy Mars firelight, imagining I'm the last man on Earth (and hoping I don't step on my reading glasses). Carly makes a plan to pick me up in a few hours in our car.</p>
<p>As expected, the procedure was painless. My only bit of further colonoscopy advice here is to ALWAYS bring a book with you, to every single medical appointment you have, because there's always going to be some sort of delay or waiting room.</p>
<p>An hour or so later, I woke up feeling the feels of that post-anesthesia giddiness. Except no one else was happy. Carly was in the room, a surprise to me. And my doctor looked quite serious.</p>
<p>In addition to two small polyps (which she removed), my colonoscopy surgeon found a tumor in my sigmoid colon. At this point, I don't know a sigmoid colon from a semi-colon, but I knew it wasn't good news. Go 2020!</p>
<p>Despite the odds (my youth, my health), I now had cancer. Well, I probably had it for awhile, but we just found out I had it.</p>
<p>My doc said I'd need to meet with <a href="https://www.ucsfhealth.org/clinics/center-for-colorectal-surgery">UCSF's colorectal surgery team</a>, and I'd also need to get CT scans ("cat scans") to see if the cancer had spread anywhere else in my body.</p>
<p>And so began one of the worst weeks of our lives.</p>
<h2>A brief family history</h2>
<p>Let's talk about the odds for a moment.</p>
<p><img src="https://www.charlieharrington.com/899a4e01fcef3d2113e4588727bc0834/odds.gif" alt="odds"></p>
<p>We've already discussed my vigorous, proto-Batman level of health. And how I'm a fresh-faced, occasionally-bearded, 34 year old with the heart of a child and the strength of a chimpanzee (no, that's a <a href="https://en.wikipedia.org/wiki/Humanzee">humanzee</a>).</p>
<p>Speaking of unfortunate genetics, it turns out that I have some family history of colon cancer. </p>
<p>Here's the scoop: my pops (that's cool talk for Dad) has had benign (non-cancerous) polyps in his previous colonoscopies. What's a poylp? It's a little growth thingy in your colon that may evolve into a tumor. Just like how a Charmander becomes a Charmeleon, polyps can grow bigger and more serious with more destructive power. Polyps are usually just snipped out during your colonoscopy and sent off for pathology (aka to see if they have cancer in them). Most do not. This is the case with my dad's polyp experience. Even though none of his have been cancerous, he still needs to go in for colonoscopies more regularly than those who don't have polyps.</p>
<p>My own tumor began as a lowly polyp, perhaps some ten years ago. We don't know exactly. But if I'd …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.charlieharrington.com/colon-cancer">https://www.charlieharrington.com/colon-cancer</a></em></p>]]>
            </description>
            <link>https://www.charlieharrington.com/colon-cancer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853503</guid>
            <pubDate>Wed, 21 Oct 2020 23:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy Erlang and PSQL in Seconds with Zeet]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24852802">thread link</a>) | @theonlyjohnny
<br/>
October 21, 2020 | https://blog.zeet.co/phoenix-psql/ | <a href="https://web.archive.org/web/*/https://blog.zeet.co/phoenix-psql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.zeet.co/content/images/size/w300/2020/10/phoenix_framework.png 300w,
                            https://blog.zeet.co/content/images/size/w600/2020/10/phoenix_framework.png 600w,
                            https://blog.zeet.co/content/images/size/w1000/2020/10/phoenix_framework.png 1000w,
                            https://blog.zeet.co/content/images/size/w2000/2020/10/phoenix_framework.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.zeet.co/content/images/size/w2000/2020/10/phoenix_framework.png" alt="Deploying a Phoenix app">
            </figure>

            <section>
                <div>
                    <p>This guide will walk you through deploying a <a href="https://www.phoenixframework.org/">Phoenix</a> project (with a database!) to production on <a href="https://zeet.co/">Zeet</a>.</p><p>Finished code from this demo is available <a href="https://github.com/theonlyjohnny/zeet_hello">here</a>!</p><!--kg-card-begin: markdown-->
<blockquote>
<p>If you already have a Phoenix app, feel free to skip this section!</p>
</blockquote>
<h3 id="prerequisites">Pre-requisites</h3>
<!--kg-card-end: markdown--><p>First things first, you're gonna need to install some tooling. If you haven't already, <a href="https://elixir-lang.org/install.html">install Elixir</a> and <a href="https://nodejs.org/en/download/">NodeJS</a>.</p><p>We'll also need to grab the Hex package manager, and install the Phoenix application generator:</p><figure><pre><code>mix local.hex
mix archive.install hex phx_new 1.5.6 # version is optional
</code></pre><figcaption>Install hex and Phoenix</figcaption></figure><!--kg-card-begin: markdown--><h3 id="creatingourapp">Creating our app</h3>
<!--kg-card-end: markdown--><p>Now that we have everything installed, let's setup a Github repo for it, and psuh some code!</p><p>Make a <a href="https://github.com/new">new Github repository</a></p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-3.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-3.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-3.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-3.png 1600w, https://blog.zeet.co/content/images/2020/10/image-3.png 1618w" sizes="(min-width: 720px) 720px"></figure><p>Now all we have to do is generate our app and push it to Github!</p><figure><pre><code>mix phx.new zeet_hello # When prompted, press Y to fetch and install dependencies
cd zeet_hello
git init
git remote add origin git@github.com:username/repo.git # NOTE: change username to your github username, and repo to your newly created repo name!
git checkout -b main
git commit -m "Initial commit"
git push -u origin main</code></pre><figcaption>Generate and push your code</figcaption></figure><p>Nicely done! We've setup a demo project, now let's get it deployed</p><hr><!--kg-card-begin: markdown-->
<p>Now that we have our project generated, let's deploy it to <a href="https://zeet.co/">Zeet</a> and setup a database alongside it!</p>
<h2 id="setupaprivatedatabase">Setup a private database</h2>
<!--kg-card-end: markdown--><blockquote>Phoenix projects usually come with a database, so you can store information about your users / app. Zeet makes it super easy to deploy a PostgreSQL database alongside your Phoenix application!</blockquote><p><strong>All you have to do is click <a href="https://zeet.co/new/docker?image=postgres">this link</a>!</strong></p><p>You should see a page like this:</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-2.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-2.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-2.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-2.png 1600w, https://blog.zeet.co/content/images/size/w2400/2020/10/image-2.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Project name can be whatever you'd like, but can't be changed later!</figcaption></figure><p>Zeet will automatically generate a database user and password for you, and dedicate you 1GB of storage.</p><p>You<strong> don't need to change</strong> <strong>any</strong> of these values, so go on and hit Deploy 😎</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-4.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-4.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-4.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-4.png 1600w, https://blog.zeet.co/content/images/2020/10/image-4.png 2170w" sizes="(min-width: 720px) 720px"><figcaption>Great! We have a database now</figcaption></figure><blockquote>By default, this database will <strong>not be accessible to the public internet</strong>. The only way to your database is from another Zeet project. Very secure, much wow</blockquote><!--kg-card-begin: markdown--><h2 id="deployingtheapp">Deploying the app!</h2>
<!--kg-card-end: markdown--><p>Last but not least, let's deploy this app 😤</p><p>Let's <a href="https://zeet.co/new/github">link our new Github repo to Zeet</a>. Click New Project -&gt; Github on <a href="https://zeet.co/">zeet.co</a> and look for your new Github repository.</p><blockquote>If you don't see your repo, click Manage Repositories and make sure Zeet has access to your Github repository. We recommend checking the "All Repositories" option to make this easy in the future!</blockquote><figure><img src="https://blog.zeet.co/content/images/2020/10/image-5.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-5.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-5.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-5.png 1600w, https://blog.zeet.co/content/images/size/w2400/2020/10/image-5.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Click that beautiful "Deploy Now" button and we're off to the races! Right away, Zeet will start building and deploying our project.</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-6.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-6.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-6.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-6.png 1600w, https://blog.zeet.co/content/images/2020/10/image-6.png 2234w" sizes="(min-width: 720px) 720px"></figure><p>If you click on the Settings tab, you'll see Zeet configured almost everything for our project!</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-7.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-7.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-7.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-7.png 1600w, https://blog.zeet.co/content/images/2020/10/image-7.png 2138w" sizes="(min-width: 720px) 720px"><figcaption>So configured, so little work 🤩</figcaption></figure><!--kg-card-begin: markdown--><h2 id="connectingtothedatabase">Connecting to the database</h2>
<!--kg-card-end: markdown--><p>There's one more step before we're all done: we need to connect this new project to our database!</p><p>Scroll down to the Environment Variables section – the <code>DATABASE_URL</code> is empty 😢</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-8.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-8.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-8.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-8.png 1600w, https://blog.zeet.co/content/images/2020/10/image-8.png 2054w" sizes="(min-width: 720px) 720px"><figcaption>Database-senpai... where are you? 🥺</figcaption></figure><p>Phoenix uses Ecto as a database driver. Ecto needs a special URL in the form of <code>ecto://USER:PASS@HOST/DATABASE</code></p><p>We're going to need 4 things from our database project:</p><ol><li>Private Endpoint</li><li>Username</li><li>Password</li><li>Database name</li></ol><p>Luckily, Zeet makes this super easy! Go back to your database project, and the Private Endpoint is right there! This tells your app how to communicate with the database.</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-4.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-4.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-4.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-4.png 1600w, https://blog.zeet.co/content/images/2020/10/image-4.png 2170w" sizes="(min-width: 720px) 720px"><figcaption>On your postgres Overview tab, look for Private Endpoint</figcaption></figure><p>The Username, Password, and Database name are in the Settings tab</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-9.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-9.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-9.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-9.png 1600w, https://blog.zeet.co/content/images/2020/10/image-9.png 2078w" sizes="(min-width: 720px) 720px"><figcaption>The values are hidden by default for security, hover to reveal</figcaption></figure><p>Great, we have everything we need. Let's put it all together into a <code>DATABASE_URL</code>. Remember, the format is <code>ecto://USER:PASS@HOST/DATABASE</code>.</p><p>For this example, my <code>DATABASE_URL</code> is <code>ecto://postgres:u2D2dp6XwQ@zeet-hello-postgres-production/postgres</code></p><p>Paste your URL into your <strong>Phoenix project's Settings tab</strong> and <strong>click Save</strong></p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-11.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-11.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-11.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-11.png 1600w, https://blog.zeet.co/content/images/2020/10/image-11.png 2236w" sizes="(min-width: 720px) 720px"><figcaption>Don't worry! Since this database is private, even with the password being published I'm secure</figcaption></figure><!--kg-card-begin: markdown--><h3 id="alldone">All done!</h3>
<p>Click the Visit button in the top right corner, and see your app in action!</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.zeet.co/content/images/2020/10/image-12.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-12.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-12.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-12.png 1600w, https://blog.zeet.co/content/images/size/w2400/2020/10/image-12.png 2400w" sizes="(min-width: 720px) 720px"></figure>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.zeet.co/phoenix-psql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24852802</guid>
            <pubDate>Wed, 21 Oct 2020 22:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking, Typing, Thinking: Software Is Not a Desk Job]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24851861">thread link</a>) | @danielfone
<br/>
October 21, 2020 | https://daniel.fone.net.nz/blog/2020/10/21/talking-typing-thinking-software-is-not-a-desk-job/ | <a href="https://web.archive.org/web/*/https://daniel.fone.net.nz/blog/2020/10/21/talking-typing-thinking-software-is-not-a-desk-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <h2>
      Talking, Typing, Thinking: Software Is Not a Desk Job
    </h2>
    <p>
      October 2020
      ·
      about 7  minutes to read
    </p>

      <summary>
        <p><strong>tl;dr</strong> Developers over-optimise for the ergonomics of typing and not enough for the ergonomics of thinking.</p>
      </summary>

    <p>I had a wonderful shower the other day.</p>

<p>It was late morning (as the best showers often are) and I was reflecting on how I spend my time during the day. As a work-from-home consultant, I constantly need to justify my billing and my time, and in this case I was justifying spending more of it in the shower.</p>

<p>Like most of us, I started my career with the impression that a productive day was spent ergonomically poised over a keyboard typing hundreds of lines of code into Microsoft Visual Basic 6.0 Professional Edition, and <em>not</em> standing in a perfectly hot stream of high pressure fresh water. However, the longer I spend as a developer, the less I’m convinced I need to be at my desk to deliver the truly astounding spreadsheet-to-web-application business value us senior engineering consultants deliver.</p>

<p>So that you too can justify spending the good part of a morning enveloped in a cocoon of cleansing warmth, let’s break this down and look at 5 physical activities of effective software development. Like all good listicles, this is ordered roughly in order of increasing time and importance.</p>

<h2 id="talking">5. Talking</h2>

<p>Some software development probably doesn’t need any talking to be effective. I understand for example that it is universally considered bad manners to talk about linux kernel development out loud. The contents of ~/bin too, we do not speak of.</p>

<p>But every commercial project I’ve worked on has needed at least some talking. When people are too busy or just too shy to talk, the lack of high-bandwidth communication can make it hard to tease out requirements and unpack poorly explained business problems.</p>

<p>But more importantly, a lack of talking makes it hard to build trust and rapport — critical&nbsp;in early stages of any new relationship. As social animals, we are particularly good at doing this verbally, and not particularly good at doing this with emails and spicy subtweets.</p>

<p>On the other hand I’ve worked on projects where talking is a prop to disguise that no-one knows what to do. Where a dozen people sit in a room and talk for an hour without saying anything and we all walk out dumber than when we walked in.</p>

<p>So for most cases: talking is critical, but in the right amount.</p>

<h2 id="listening">4. Listening</h2>

<p>Honestly I just included this for symmetry. The only thing I’ll add is that we have two ears and one mouth so either binaural hearing offers an evolutionary advantage against some selection pressure or we’re supposed to listen twice as much as we talk.</p>

<p>Take your pithy wisdom however you like it.</p>

<p><em>(quickly googles why do we have two ears)</em></p>

<h2 id="writing">3. Writing</h2>

<p>Writing code of course! But also… READMEs, comments, inline documentation, PR descriptions, code reviews, git commits; this is all part of the <em>core work</em>. It’s tempting to see this meta-writing as overhead on top of the real ‘code’ writing. But effective writing in these other places is a force multiplier for your code.</p>

<p>Much more importantly though, in my experience the best communication is written.</p>

<ul>
  <li>It’s async, meaning it can be consumed whenever convenient for each reader (i.e. after a late morning shower).</li>
  <li>It can be easily distributed and has no fidelity loss when shared (compared to talking to John about what Sarah told you Steve said in meeting that none of you were at).</li>
  <li>It creates a record, as opposed to “wait, why did we…?”</li>
  <li><a href="https://alistapart.com/article/writing-is-thinking/">Writing is thinking</a>! Writing forces you to structure your ideas coherently (at least, it seems to for some people). It reveals shortcomings or gaps in your understanding or plan.</li>
</ul>

<p>Because of this I encourage team comms to be mostly written. Jira, slack, emails, trello, blog posts, whatever. Even a hi-res photo of a wall of post-it notes has been an indispensable architectural road-map at times. However it’s published, detailed, well-thought out writing is 💯.</p>

<p>Perhaps even more important than writing though is…</p>

<h2 id="reading">2. Reading</h2>

<p>Having just extolled the virtues of writing READMEs, commit messages, PR descriptions, etc, I should obviously encourage you to read them. It’s called README IN CAPITALS for a reason, and it’s not just because it’s an acronym. Yet if I had a dollar for every time someone asked me a question that was already answered in the README I would have three dollars. 💰</p>

<p>This is because of what I succinctly call the vicious-reading-writing-cycle-feedback-loop. When people don’t update the commentary, people become trained to ignore it, so people don’t update it, etc. Truthfully, if you know someone’s reading your git commits, their quality will rapidly improve. Even if you’ve never read a coherent git commit from your colleagues before, it’s never too late to ask them to elaborate on what <code>finally fix it</code> means.</p>

<p>But like writing, the value of reading extends well beyond the code repository.</p>

<p>I recently started a project involving a completely unfamiliar field of medical technology (ps you’re <a href="https://twitter.com/danielfone/status/1318026784454045703">still my favourite</a> patient <code>01-004</code> 📊❤️). The most valuable activity I find at this stage of a project is to read.</p>

<p>We have to parse a <a href="https://en.wikipedia.org/wiki/European_Data_Format">specialised file format</a>, for which there is <a href="https://github.com/nsrr/edfize">a gem</a>. But why leave all that useful context buried inside the gem? The <a href="https://www.edfplus.info/specs/edf.html">file specification</a> is not that long, even if it takes many attempts to understand it. Reading the file format spec makes it much easier to understand why the gem needs to <a href="https://github.com/nsrr/edfize/blob/93566cdc82b160ef319c51908c1c4a19666e2625/lib/edfize/edf.rb#L243">load_digital_signals_by_epoch</a>, which in turn suggests alternative solutions to the problem you have in hand.</p>

<p>None of the <em>adjacent possible</em><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> is discoverable without the insights gained from reading these sources, so whatever you’re dealing with, go to the source and read read read…</p>

<ul>
  <li>documentation (<em>reading the very well-written <a href="https://www.postgresql.org/docs/current/index.html">postgres manual</a> or <a href="https://redis.io/documentation">redis docs</a> is the closet experience I’ve had to Neo downloading kung-fu into his brain</em>)</li>
  <li>code (<em>vastly underrated - there’s not a gem in my Gemfiles I haven’t <code>bundle open</code>d at least once</em>)</li>
  <li>log files, error messages, that tutorial on how to read flame graphs</li>
  <li>the specification, legislation, policy document, NIST guideline, the original paper in the open access journal</li>
</ul>

<p>… you get the idea, just find the authoritative document and slurp it into your brain. Even if it seems like nothing sticks, a brief encounter with the text will leave a long-lasting impression. It’s like homeopathy but real.</p>

<p>So talking/listening… writing/reading… and finally… <em>drumroll noises</em></p>

<h2 id="thinking">1. Thinking</h2>

<p>When you boil it down, <em>this</em> is the main effort for me, and yet it’s kind of the hidden one.</p>

<p>How much of my programming/coding/dev time is actually just spent <em>thinking</em> about the problems?
Modelling the domain,
thinking through the edge cases,
mentally playing with abstractions.</p>

<p>And it’s obvious when you think about what makes good developers. The people I value working with most aren’t accurate typists, they’re <em>clear thinkists</em>.</p>

<p>Yet the image persists that typing is working and working is typing and a productive day is in your chair at your desk.
So we have dual 4k monitors, mechanical keyboards, aeron chairs, touchbar, vim shortcuts, whatever optimises for us tapping away at our computers.</p>

<p>But how much attention do we pay to the <strong>ergonomics of thinking</strong>?</p>

<p>When we elevate ‘thinking’ to core work, we naturally start to optimise for it specifically. In general, we don’t need to be in front of anything to think effectively, and often I find it better not to be. My times of greatest clarity are invariably when I’m moving, often when I’m exercising. Further, I can read on my phone practically anywhere, and the best conversations are often had while strolling.</p>

<p>So while I’m glad for all the ergonomics of my workspace, increasingly I find that writing code is the brief part where I’m simply harvesting all the mental crop that I’ve sown from the talking and listening and reading and thinking.</p>

<p>To distill this into something a little more alliterative, I have sometimes described this as the 3 Ts of software development…</p>

<h2>Talking · Typing · Thinking</h2>

<p><strong>Talking</strong> and listening; the verbal discussions. Most of the time we need a small but critical amount of high bandwidth synchronous comms.</p>

<p><strong>Typing</strong> code commentary: READMEs, code reviews, PR descriptions; and all asynchronous communication: project updates, technical overviews, emails with next steps; These are all an essential part of the job and not just ancillary or busywork. Also typing actual code at some point. But I find the more time you spend typing the other stuff, the less time you need to spend (re)typing code.</p>

<p><strong>Thinking</strong>: (including, for the purposes of alliteration, reading)</p>

<p>Talking, typing, thinking: this is the work we do. And I for one want to give myself the space to do all parts of it really well.</p>

<p>Anyway, I gotta go take a shower. 🚿</p>



  </article></div>]]>
            </description>
            <link>https://daniel.fone.net.nz/blog/2020/10/21/talking-typing-thinking-software-is-not-a-desk-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24851861</guid>
            <pubDate>Wed, 21 Oct 2020 20:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stable 1.2 Gigabit/s Internet achieved in moving train in Switzerland]]>
            </title>
            <description>
<![CDATA[
Score 366 | Comments 303 (<a href="https://news.ycombinator.com/item?id=24851365">thread link</a>) | @richx
<br/>
October 21, 2020 | https://www.swisscom.ch/en/about/news/2020/10/21-mehr-bandbreite-im-zug.html | <a href="https://web.archive.org/web/*/https://www.swisscom.ch/en/about/news/2020/10/21-mehr-bandbreite-im-zug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

		
		
		

		
		

		
	
	<section>
		

<div>
	
	<div>
		<div>
			<div>







	<p>Mobile phone reception</p>


	


	<p>Uninterrupted, good quality mobile phone reception is extremely important to rail passengers. In technical terms, it’s the pièce de résistance for every network provider because the demands on bandwidth increase with data-intensive applications. Swisscom has now successfully achieved a transmission speed of over 1 Gigabit per second on a moving train under test conditions. This result sets a new benchmark for the mobile phone industry.</p>



	
	
		<div>
			
			<p><img src="https://rcp.scsstatic.ch/content/dam/swisscom/de/about/news/authors/armin-schaedeli-260x260-2x.png.scsimg.89x89.ts1543323485216.png/armin-schaedeli-260x260-2x.png" width="89" height="89" alt="Armin Schädeli" loading="lazy">
			</p>
			
			<p>
				Armin
				Schädeli,
				Deputy Head of Media Relations<br>
				21 October 2020
			</p>
		</div>
	
	


</div>

		</div>
		<div>
			<div><div>

	

	
	
	
		
		
			<div data-column-count="3">
				
					
				
					<div>
						



	
		
		
			


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<p>How do most people use their phones when on a train? Besides checking their mail and reading the paper, they also stream videos, play online games or work in virtual offices. This requires a great deal of bandwidth, meaning that capacity issues can prove particularly annoying. A Swisscom team has been researching and working on continuously improving mobile coverage for rail travellers and commuters for more than ten years.</p>

<p>The invention of a special type of glass for the train windows, which lets mobile telephone signals through, has made it possible to bring mobile coverage directly onto the train without intermediate components. However, coverage along train routes remains challenging as much more data is transmitted under the same conditions with each mobile phone generation. One possible solution is a specially designed antenna corridor along railway lines.</p>

			
		</div>
		
	</div>
</div>


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<p>Swisscom has now made a major breakthrough on a test route between Biberlikopf and Kerenzerberg at Lake Walen with a newly designed four-kilometre antenna corridor: Swisscom engineers achieved a connection with 1.2 Gbit/s on a moving train. Christoph Aeschlimann, Head of IT, Network &amp; Infrastructure at Swisscom says: “This concept sets a new benchmark for the mobile phone industry. Just one year ago, we had no idea whether this would be possible. We now have a solution that provides stable and reliable coverage for passengers as well as important insights for safety-relevant applications in rail transport.”</p>
<p>Another positive side effect is the lower transmitting power required due to the shorter distances between antennas and devices.</p>

			
		</div>
		
	</div>
</div>


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<p>After evaluating the results, the test corridor will be further optimised and validated with measurements in the first quarter of 2021. The long-term goal is to achieve uninterrupted mobile phone coverage along the main routes for all mobile phone users and providers in Switzerland In terms of the antenna corridor, Swisscom has developed a feasible solution that is also available to other providers.</p>
		
	</div>
</div>


	<div>

	


























	



	
	
	<div>
		


	<div>

	
	

	
	

	

	
	
	



	
	
	
		
	



	
	
		
	
	




















	












	<div data-interactive-name="" data-interactive-value="">
		<div>
			
				
			
			
				
					
						
						
							


	<div>

	


























	



	
	
	<div>
		


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<p>A four-kilometre antenna corridor was constructed along the railway line at Lake Walen for the test, in conjunction with network equipment supplier Ericsson. The proximity of the antenna to devices means the transmitting power is lower and the coverage along the railway corridor is more targeted.</p>

<p>In a step-by-step procedure, numerous combinations (4G and 5G mobile phone generations, seating position, type of train car, transmitting power, train windows, mast antennas, smartphone models, etc.) were measured and analysed over more than 200 train journeys. The project has shown that the antenna corridor is possible and offers good performance. Download speeds of over 1.2 Gbit/s were possible on a moving train with a combination of 4G and 5G. The 5G response time was four times shorter than 4G – an impressive 8 milliseconds.</p>

<p>In addition to network coverage, safety-critical applications on rail transport are another consideration. The existing GSM-R railway communication network standard will be replaced in the coming years by the new Future Railway Mobile Communication System (FRMCS). Good mobile phone coverage is also therefore crucial for rail companies as well as passengers.</p>

			
		</div>
		
	</div>
</div>



	</div>
</div>



						
					
				
			
		</div>
		
	</div>

</div>



	</div>
</div>


	


	

	


	


	<div>





	
	
	
		
		
			
			
				<div>
					
						
						
							<div>






	










	

















	



	
	<div>
		
			
				
				
					

				
			
		
			
				
				
					<div>

	










	





	
	
	















	
	
	<div>
		


	


	<div>

	

	
	
	
		
			<div data-column-count="3">
				
					<div>
						



	
		
		
			


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<div><p>Swisscom<br> Media Relations<br> Alte Tiefenaustrasse 6<br> 3048 Worblaufen</p><p>  Postal address:<br> Postfach, CH-3050 Bern<br> Switzerland</p></div>
			
		</div>
		
	</div>
</div>



		
	


					</div>
				
					
				
					<div>
						



	
		
		
			


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<p>Tel. +41 58 221 98 04<br> Fax +41 58 221 81 53<br> media@swisscom.com</p>
		
	</div>
</div>


	


	



		
	


					</div>
				
			</div>
		
		
	

</div>



	</div>
</div>

				
			
		
		
	</div>

</div>

						
					
				</div>
			
		
	
	

</div>



		
	


					</div>
				
					
				
			</div>
		
	

</div>

</div>

		</div>
	</div>
</div>

	</section>
</div></div>]]>
            </description>
            <link>https://www.swisscom.ch/en/about/news/2020/10/21-mehr-bandbreite-im-zug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24851365</guid>
            <pubDate>Wed, 21 Oct 2020 19:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping Science's Paradox]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24851141">thread link</a>) | @stuart_buck
<br/>
October 21, 2020 | https://worksinprogress.co/issue/escaping-sciences-paradox/ | <a href="https://web.archive.org/web/*/https://worksinprogress.co/issue/escaping-sciences-paradox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p>Science has two stark problems: replication and innovation. Many scientific findings aren’t reproducible. That is to say, you can’t be sure that another study or experiment on the same question would get similar results. At the same time, the pace of scientific innovation could be slowing down.</p>
<p>Does attempting to solve one problem make the other worse? Many have argued that policies seeking to avoid reproducibility issues will create a constrictive atmosphere that inhibits innovation and discovery.</p>
<p>Indeed, top policymakers are worried about just this. Along with other prominent philanthropists and academics, I attended a White House meeting on scientific reproducibility early in 2020 (just before COVID-19 really hit). One of the key questions on a sheet of paper that the White House Office of Science and Technology Policy circulated for discussion was whether a tradeoff existed: Would efforts to improve reproducibility risk harming the creativity and innovation of federally-funded research?</p>
<p>I do <i>not</i> think there’s a contradiction between reproducibility and innovation. Contrary to common belief, we can improve <i>both</i> at once – by incentivizing failed results, and by funding “Red Teams” that would aim to refute existing dogma or would be entirely outside it.</p>
<p>First, though, let’s take a step back, and briefly review the evidence that significant areas of science could be more reproducible and innovative.</p>
<h2><b>Is science reproducible?<br>
</b></h2>
<p>Many people have written about scientific irreproducibility over the past several decades. But the issue became more prominent in the mid-2000s with the publication of what soon became one of the most downloaded research papers of all time: The 2005 piece “<a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Why Most Published Research Findings Are False</a>,” by Stanford’s John Ioannidis. (Disclaimer: he is a long-time grantee of Arnold Ventures, where I work.)</p>
<p>To be sure, Ioannidis’s finding was mostly theoretical; it’s not as if he actually redid “most” published research (i.e., tens of millions of studies). Instead, he showed that given the way most studies are carried out, if journals have even a slight bias towards positive results (and they most definitely do), then most of the results that end up getting published would inevitably be statistical flukes or the results of p-hacking.</p>
<p>His theoretical case has been confirmed by many empirical studies in fields from drug development to psychology. Pharmaceutical companies such as <a href="https://www.nature.com/articles/483531a">Amgen</a> and <a href="https://www.nature.com/articles/nrd3439-c1">Bayer</a> have reported that they are unable to reproduce 80+% of experiments from prestigious journals. To quote Bayer’s scientists, “projects that were started in our company based on exciting published data have often resulted in disillusionment when key data could not be reproduced.”</p>
<p>Then there was the <a href="https://osf.io/ezcuj/">Reproducibility Project in Psychology</a>, which we funded, and which was carried out by our grantee Center for Open Science. That project organized well over 200 psychology labs around the world to systematically redo 100 experiments published in top psychology journals. It found that only about 40% could be reliably replicated (another 40% were inconclusive, and around 20% were decisively <i>not</i> replicated). Since <a href="http://science.sciencemag.org/content/349/6251/aac4716">those results were published</a> in 2015, the study has already been cited <a href="https://scholar.google.com/scholar?cites=10200793109432081889&amp;as_sdt=5,44&amp;sciodt=0,44&amp;hl=en">over 4,400 times</a> according to Google Scholar. Many of the most famous results in psychology have turned out to be <a href="https://www.theguardian.com/science/2018/apr/16/a-real-life-lord-of-the-flies-the-troubling-legacy-of-the-robbers-cave-experiment">unreliable</a> and possibly fraudulent (such as Zimbardo’s <a href="https://www.vox.com/2018/6/13/17449118/stanford-prison-experiment-fraud-psychology-replication">Stanford prison experiment</a>), and the best recent treatment of this issue is Stuart Ritchie’s 2020 book “Science Fictions.”</p>
<p>To be sure, the problem seems much less acute in harder sciences – e.g., physics, chemistry, cosmology – that have an established tradition of skepticism, replication, or even <a href="https://www.law.berkeley.edu/wp-content/uploads/2018/01/Paper-MacCounPerlmutter2017ch15.pdf">blinding researchers</a> to their own conclusions. The bulk of the reproducibility and publication bias problem seems to be in social science and biomedicine. In many of those fields and subfields – such as <a href="https://pubmed.ncbi.nlm.nih.gov/19160345/">clinical trials in medicine</a>, <a href="https://arxiv.org/pdf/1010.1092.pdf">high-throughput bioinformatics</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2213158213000090">neuroimaging</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S1364661314000540">cognitive science</a>, <a href="https://www.niss.org/publications/deming-data-and-observational-studies-process-out-control-and-needing-fixing">public health and epidemiological research</a>, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12032">economics</a>, <a href="https://www.semanticscholar.org/paper/The-fault-in-our-stars-%3A-Measuring-and-correcting-Esarey-Wu/48403d5dce1f2972c7a91af3bb2d41635221cb3f">political science</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/23696308/">psychiatry</a>, <a href="https://eric.ed.gov/?id=EJ1019294">education</a>, <a href="https://journals.sagepub.com/doi/10.1177/0049124108318973">sociology</a>, <a href="http://cs.brown.edu/~sk/Memos/Examining-Reproducibility/">computer science</a>, and <a href="https://dennybritz.com/blog/ai-replication-incentives/">machine learning and AI</a> – the published literature features too many false positives as well as conclusions that may well be p-hacked. It’s enough to make folks at the White House, NIH, and NSF worried about the quality of federally-funded science.</p>
<h2><b>Is science innovative enough?<br>
</b></h2>
<p>At the same time, numerous observers have pointed to an entirely different problem: science has grown less innovative these days. (And even if it hasn’t, we could always benefit from faster innovation.)</p>
<p>In a recent piece, Patrick Collison, the founder of Stripe, and Michael Nielsen, a theoretical physicist, <a href="https://www.theatlantic.com/science/archive/2018/11/diminishing-returns-science/575665/">made the case</a> that the rate of scientific advancement is slowing down in recent years per dollar spent. Based on surveys of noted leaders in physics, chemistry, and medicine, they concluded, “Over the past century, we’ve vastly increased the time and money invested in science, but in scientists’ own judgement, we’re producing the most important breakthroughs at a near-constant rate. On a per-dollar or per-person basis, this suggests that science is becoming far less efficient.”</p>
<p>Collison and Nielsen are <a href="https://www.nber.org/papers/w26752.pdf">far from alone</a>. Cowen and Southwood <a href="https://www.brown.edu/academics/political-theory-project/sites/brown.edu.academics.political-theory-project/files/uploads/Innovation%20%26%20scientific%20progress.pdf">argue</a> that “there is good and also wide-ranging evidence that the rate of scientific progress has indeed slowed down.” The 2019 <a href="https://web.stanford.edu/~chadj/IdeaPF.pdf">paper</a>, “Are Good Ideas Getting Harder to Find?” argues that in semiconductors, agriculture, and medical innovations, “research effort is rising substantially while research productivity is declining sharply.”	<sup data-close="x" data-content="[1]">[1]</sup>
	<span>They attempted to replicate this analysis for “the internal combustion engine, the speed of air travel, the efficiency of solar panels, the Nordhaus (1997) ‘price of light’ evidence, and the sequencing of the human genome.” But they couldn’t do so because there was no accurate measure of the amount of R&amp;D on those issues.</span>
	 That paper concludes by predicting that “just to sustain constant growth in GDP per person, the U.S. must double the amount of research effort searching for new ideas every 13 years to offset the increased difficulty of finding new ideas.”</p>
<p>Of course, some of these assessments might be too <a href="https://guzey.com/how-life-sciences-actually-work/">pessimistic</a>. But it is depressingly common to hear the world’s most innovative scientists lament that they would never have succeeded in today’s academic or funding system because their work was too outside the box:</p>
<ul>
<li>Roger Kornberg (a Nobel-winning biochemist) <a href="http://www.washingtonpost.com/wp-dyn/content/article/2007/05/27/AR2007052700794.html">told the Washington Post in 2007</a> that his 1970s research on DNA “would never have gotten the necessary funding” if he had come along in the 2000s: “In the present climate especially, the funding decisions are ultraconservative. If the work that you propose to do isn’t virtually certain of success, then it won’t be funded.”</li>
<li>As <a href="https://www.kqed.org/forum/201310090930/cuts-in-federal-funding-hurt-scientific-research">reported</a> in 2013, “UC Berkeley molecular biologist Randy Schekman won the Nobel Prize for Medicine with two other scientists this week. But he says the kind of basic science research that led to his prize might have never gotten funded if he were applying for grants today.”</li>
<li>David Deutsch, who pioneered quantum computing, <a href="https://twitter.com/DavidDeutschOxf/status/982233180081029128">says</a> that he would never have gotten his “first research grant on quantum computers . . . under today’s criteria.”</li>
<li>Peter Higgs, the Nobel Laureate for whom the Higgs Boson is named, “<a href="https://www.theguardian.com/science/2013/dec/06/peter-higgs-boson-academic-system">believes</a> no university would employ him in today’s academic system because he would not be considered ‘productive’ enough. . . . ‘Today I wouldn’t get an academic job. It’s as simple as that. I don’t think I would be regarded as productive enough.’”</li>
</ul>
<p>When so many top scientists say that their own work would never have passed muster in the current system, we must take stock of the current system. As prominent scientists <a href="https://science.sciencemag.org/content/364/6441/613">have asked</a>, “How successful would Silicon Valley be if nearly 99% of all investments were awarded to scientists and engineers aged 36 years or older, along with a strong bias toward funding only safe, non-risky projects?” Moreover, a <a href="https://www.telegraph.co.uk/business/2018/06/07/science-holds-key-unlocking-economic-success/">common complaint</a> is that “scientists are forced to specify years in advance what they intend to do, and spend their time continually applying for very short, small grants” – hardly a system that would encourage innovation.</p>
<p>In short, we have evidence that US science funding is often fairly tame and incremental, that some of the most innovative science of the past would <a href="https://www.npr.org/2019/05/19/723326933/billion-dollar-gamble-how-a-singular-hero-helped-start-a-new-field-in-physics?fbclid=IwAR28fazRNhzzT5ijMINwzZkNqlP6fEfBlI4OLyY-eesrUyOfbZfF7-P4qUc">never have been funded</a> by today’s bureaucracy, and that scientific review panels are <a href="https://www.nature.com/articles/492034a">dominated by insiders</a>.</p>
<p>Thus, innovation in science is imperiled. If Einstein had to navigate such a system, we might <a href="https://www.wsj.com/articles/could-einstein-get-published-today-11600974323">never have heard of relativity</a>. And even if innovation weren’t slowing down <em>per se</em>, we could still do better.</p>
<h2><b>What next?</b></h2>
<p>There are lots of ideas about how to improve scientific reproducibility in how federal research is funded. After all, quality control and assurance are hardly new ideas.</p>
<p>For example, we could require that data and computer code be shared openly so that others can scrutinize and rerun it. In too many cases to list, this sort of reanalysis has led to revisions, retractions, and even the discovery of <a href="https://www.newyorker.com/science/maria-konnikova/how-a-gay-marriage-study-went-wrong">outright fraud</a>.</p>
<p>Next, we could require that experiments and other empirical studies be pre-registered, so that the analysis and results are less likely to be cherry-picked later. We already do this for clinical trials in medicine, and a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132382">review</a> of federally-sponsored clinical trials found that the rate of positive results went down dramatically as soon as researchers were required to pre-register their studies. We could do the same for much else in science. We could even move towards more widespread use of the Registered Reports format, in which journals accept an article for publication before the final results are even available.</p>
<p>It’s less obvious how to reform government funding so as to improve scientific <i>innovation</i>. Let’s try a thought experiment:</p>
<p>Imagine that you were the President 100 years ago, instead of Woodrow Wilson. Imagine that a time-traveling genie from the future tells you that over the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worksinprogress.co/issue/escaping-sciences-paradox/">https://worksinprogress.co/issue/escaping-sciences-paradox/</a></em></p>]]>
            </description>
            <link>https://worksinprogress.co/issue/escaping-sciences-paradox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24851141</guid>
            <pubDate>Wed, 21 Oct 2020 19:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 10 year journey – from the creator of Durable Task Framework]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24850309">thread link</a>) | @rylandgold
<br/>
October 21, 2020 | https://docs.temporal.io/blog/samars-journey | <a href="https://web.archive.org/web/*/https://docs.temporal.io/blog/samars-journey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Back in 2010 I was contemplating my next move after working on Microsoft's Project Oslo. Oslo was an effort to deliver 10X productivity to developers which inspired me to set the following criteria for my next job:</p><ol><li><strong>Iterate with Developers:</strong> I want to work in a place where we can start small, get something in the hands of developers and then iterate over the product to solve real problems.</li><li><strong>Cloud:</strong> So far I had been focussed on building platforms using bare-metal products.  But I was starting to see the kind of requirements modern applications have around scale and resiliency.  I knew Cloud had to be huge part of the experience to deliver on those requirements.</li></ol><h2>Start of Journey</h2><p><img src="https://dev-to-uploads.s3.amazonaws.com/i/jv8et2b448mjtifrh1wy.png" alt="Alt Text"></p><p>The Oslo framework led me to join the <a href="https://aws.amazon.com/swf/" target="_blank" rel="noopener noreferrer">AWS Simple Workflow (SWF)</a> team.  The team was led by Maxim Fateev, who came from a strong messaging background. Maxim was one of the most brilliant software engineers I had ever worked with, especially when it came to designing large scale distributed systems.  Little did I know that I was about to embark on a long journey which is still being written to this day.</p><p>When I joined, the team was wrapping up a second version of the service which was already seeing decent usage within AWS.  Even at the time, we could clearly see a pattern emerging. Developers were spending significant amounts of time building resiliency into applications, using low level primitives like queues, databases, retry mechanisms, durable timers, etc. Those same developers were able to produce higher quality systems with far less effort when using SWF instead of implementing resiliency themselves.  Considering how useful the service was within AWS, the next natural step was to offer SWF publicly. I was part of the core team which worked on the public version of SWF which was launched in early 2012.</p><h2>Durable Task Framework (DTFx)</h2><p><img src="https://docs.microsoft.com/en-us/azure/azure-functions/durable/media/durable-functions-concepts/monitor.png"></p><p>After shipping the public SWF service, I took an opportunity at Microsoft Azure and ended up joining the <a href="https://azure.microsoft.com/en-us/services/service-bus/" target="_blank" rel="noopener noreferrer">Azure Service Bus</a> team that owns the messaging stack for Azure.  Cloud was steadily gaining momentum and as more and more workloads started to get migrated, teams like Azure Service Bus became a focal point.  As application developers increasingly started adopting microservices architecture to keep up with scale and availability requirements for modern applications, services like Azure Service Bus became the backbone to orchestrate calls across microservices.  To keep up with the explosive growth, I worked as part of the team focused on large scale ingestion through <a href="https://azure.microsoft.com/en-us/services/event-hubs/" target="_blank" rel="noopener noreferrer">Azure EventHubs</a>.  This solved the scalability and reliability issues at a messaging layer but developers still had to work with very low level primitives whenever they need to reliably orchestrate calls across microservices.  The result was complex architectures which were expensive to build, hard to operate, and still came with reliability challenges. Reliability challenges stemming from all sorts of failure cases which needed to be handled due to the distributed nature of the application.</p><p>I could clearly see that the developers building applications on Microsoft Azure were facing eerily similar challenges to what I had seen back at AWS. The same challenges we had tried to address with SWF.  So I used one of the internal team hackathons as an opportunity to pair up with Affan Dar and take another stab at solving the problem. Affan had a very deep understanding of Azure ServiceBus so he was the perfect person to build the backend for the stateful C# experience I had in mind.  Microsoft had recently added async/await capabilities into C# and it turned out to be an amazing fit for writing stateful applications which need to orchestrate calls among microservices.  Since Java lacked an async/await like primitive, we had to rely on Promise-based async approach when building SWF.  But with C#, we were able to deliver a much cleaner and synchronous programming model using async/await.  This hackathon project resulted in Azure <a href="https://github.com/Azure/durabletask" target="_blank" rel="noopener noreferrer">Durable Task Framework</a> as an OSS client SDK which uses Azure ServiceBus as the backend to provide a stateful workflow-as-code experience for applications. I'm so glad to see Microsoft has continued investing in the experience with <a href="https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview" target="_blank" rel="noopener noreferrer">Azure Durable Functions</a> as the latest reincarnation of the original effort. An effort which started with that hackathon project.</p><h2>Transportation as Reliable as Running Water</h2><p><img src="https://d3i4yxtzktqr9n.cloudfront.net/uber-sites/f452c7aefd72a6f52b36705c8015464e.jpg"></p><p>In 2015, Uber opened a development center in Seattle and I decided to take the leap and join the engineering team.  Coincidently enough, Maxim Fateev ended up joining the Uber team in Seattle only a month after I did. At the time, Uber was running on Kafka 7 as the messaging backbone. Based on the scale they were running, they were encountering some serious operational issues. Considering Maxim and I had more than a decade worth of experience building messaging systems similar to Kafka, we decided to create the OSS project <a href="https://github.com/uber-archive/cherami-server" target="_blank" rel="noopener noreferrer">Cherami</a> to address this Uber sized problem. After a year of working on the project, we were observing a very similar pattern to the one that we tried to solve with SWF and Durable Task Framework. When engineers needed to build with raw infrastructure primitives like queues and databases they were spending 80% of their time building resiliency into the application.  This was clearly not sustainable for Uber, which was growing at an amazing pace and building a brand of "Transportation as Reliable as Running Water".  This need to increase developer productivity without compromising on reliability of the system was the motivation for Maxim and I to create the OSS project <a href="https://github.com/uber/cadence" target="_blank" rel="noopener noreferrer">Cadence</a>.  Within a very short period of time, we built a multi-tenant service hosted by our team. Cadence provided a great developer experience by enabling developers to use Golang to build and run stateful applications with very little operational overhead.  Cadence grew organically within Uber and quickly became popular among developers. It slowly but surely began to emerge as the standard way to build stateful applications when reliability cannot be compromised.</p><h2>Magic of Open Source</h2><p><img src="https://dev-to-uploads.s3.amazonaws.com/i/8llekr4lqjmaok138su4.png" alt="Alt Text"></p><p>Today, more businesses are turning to software for running mission critical parts of the system and software is becoming key part of the end-user experience. The problems faced by engineers at places like AWS, Microsoft Azure and Uber have become more and more common across the industry.  This belief was validated in early 2019. Developers from companies like Hashicorp, Box, Doordash, Checkr and dozens of other places organically discovered the Temporal technology and immediately started using it for their mission critical workloads.</p><p>We have a strong belief that an infrastructure technology of this magnitude needs to built as an Open-source project.  This led both Maxim and I to quit our jobs at Uber and launch <a href="https://temporal.io/" target="_blank" rel="noopener noreferrer">Temporal Technologies</a> in October 2019.  Over the last year we made huge advances with our developer experience and released <a href="https://github.com/temporalio/temporal/" target="_blank" rel="noopener noreferrer">Temporal</a> as an Open Source Software under <a href="https://github.com/temporalio/temporal/blob/master/LICENSE" target="_blank" rel="noopener noreferrer">MIT license</a>.  We recently launched our first production release of <a href="https://docs.temporal.io/blog/temporal-v1-announcement/" target="_blank" rel="noopener noreferrer">Temporal v1.0.0</a> which is already being used by numerous companies for critical workloads.</p><p><a href="https://temporal.io/" target="_blank" rel="noopener noreferrer">https://temporal.io</a></p><p><a href="https://github.com/temporalio/temporal" target="_blank" rel="noopener noreferrer">https://github.com/temporalio/temporal</a></p></section></div>]]>
            </description>
            <link>https://docs.temporal.io/blog/samars-journey</link>
            <guid isPermaLink="false">hacker-news-small-sites-24850309</guid>
            <pubDate>Wed, 21 Oct 2020 17:52:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[File Exfiltration via LibreOffice in BigBlueButton and JODConverter]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24849878">thread link</a>) | @hannob
<br/>
October 21, 2020 | https://blog.hboeck.de/archives/902-File-Exfiltration-via-Libreoffice-in-BigBlueButton-and-JODConverter.html | <a href="https://web.archive.org/web/*/https://blog.hboeck.de/archives/902-File-Exfiltration-via-Libreoffice-in-BigBlueButton-and-JODConverter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- s9ymdb:496 --><p><img width="300" height="303" src="https://blog.hboeck.de/uploads/bluebutton.jpg" alt="Blue Button">BigBlueButton is a free web-based video conferencing software that lately got quite popular, largely due to Covid-19. Earlier this year I did a brief check on its security which led to an <a href="https://www.golem.de/news/big-blue-button-das-grosse-blaue-sicherheitsrisiko-2010-151610.html">article on Golem.de (German)</a>. I want to share the most significant findings here.</p><p>

BigBlueButton has a feature that lets a presenter upload a presentation in a wide variety of file formats that gets then displayed in the web application. This looked like a huge attack surface. The conversion for many file formats is done with Libreoffice on the server. Looking for ways to exploit server-side Libreoffice rendering I found a <a href="https://buer.haus/2019/10/18/a-tale-of-exploitation-in-spreadsheet-file-conversions/">blog post by Bret Buerhaus</a> that discussed a number of ways of exploiting such setups.</p><p>

One of the methods described there is a feature in Opendocument Text (ODT) files that allows embedding a file from an external URL in a text section. This can be a web URL like https or a file url and include a local file.</p><p>

This directly worked in BigBlueButton. An ODT file that referenced a local file would display that local file. This allows displaying any file that the user running the BigBlueButton service could access on the server. A possible way to exploit this is to exfiltrate the configuration file that contains the API secret key, which then allows basically controlling the BigBlueButton instance. I have a <a href="https://www.youtube.com/watch?v=op2hc2Z56a8">video showing the exploit here</a>. (I will publish the exploit later.)</p><p>

I reported this to the developers of BigBlueButton in May. Unfortunately my experience with their security process was not very good. At first I did not get an answer at all. After another mail they told me they plan to sandbox the Libreoffice process either via a chroot or a docker container. However that still has not happened yet. It is planned for the upcoming version 2.3 and independent of this bug this is a good idea, as Libreoffice just creates a lot of attack surface.</p><p>

Recently I looked a bit more into this.  The functionality to include external files only happens after a manual user confirmation and if one uses Libreoffice on the command line it does not work at all by default. So in theory this exploit should not have worked, but it did.</p><p>

It turned out the reason for this was another piece of software that BigBlueButton uses called <a herf="https://github.com/sbraconnier/jodconverter">JODConverter</a>. It provides a wrapper around the conversion functionality of Libreoffice. After contacting both the Libreoffice security team and the developer of JODConverter we figured out that it enables including external URLs by default.</p><p>

I forwarded this information to the BigBlueButton developers and it finally let to a fix, they now change the default settings of JODConverter manually. The JODConverter developer considers changing the default as well, but this has not happened yet. Other software or web pages using JODConverter for serverside file conversion may thus still be vulnerable.</p><p>

The fix was included in version 2.2.27. Today I learned that the company RedTeam Pentesting <a href="https://www.redteam-pentesting.de/en/advisories/rt-sa-2020-005/-arbitrary-file-disclosure-and-server-side-request-forgery-in-bigbluebutton">has later independently found the same vulnerability</a>. They also requested a CVE: It is now filed as CVE-2020-25820.</p><p>

While this issue is fixed, the handling of security issues by BigBlueButton was not exactly stellar. It took around five months from my initial report to a fix. The <a href="https://github.com/bigbluebutton/bigbluebutton/releases/tag/v2.2.27">release notes</a> do not mention that this is an important security update (the change has the note “speed up the conversion”).</p><p>

I found a bunch of other security issues in BigBlueButton and proposed some hardening changes. This took a lot of back and forth, but all significant issues are resolved now.</p><p>

Another issue with the presentation upload was that it allowed cross site scripting, because it did not set a proper content type for downloads. This was independently discovered by another person and was fixed a while ago. (If you are interested in details about this class of vulnerabilities: I have given <a href="https://www.youtube.com/watch?v=8t8JYpt0egE">a talk about it at last year’s Security Fest</a>.)</p><p>

The session Cookies both from BigBlueButton itself and from its default web frontend Greenlight were not set with a secure flag, so the cookies could be transmitted in clear text over the network. This has also been changed now.</p><p>

By default the BigBlueButton installation script starts several services that open ports that do not need to be publicly accessible. This is now also changed. A freeswitch service run locally was installed with a default password (“ClueCon”), this is now also changed to a random password by the installation script.</p><p>

What also looks quite problematic is the use of outdated software. BigBlueButton only works on Ubuntu 16.04, which is a long term support version, so it still receives updates. But it also uses several external repositories, including one that installs NodeJS version 8 and shows a warning that this repository no longer receives security updates. There is an <a href="https://github.com/bigbluebutton/bbb-install/issues/109">open bug in the bug tracker</a>.</p><p>

If you are using BigBlueButton I strongly recommend you update to at least version 2.2.27. This should fix all the issues I found. I would wish that the BigBlueButton developers improve their security process, react more timely to external reports and more transparent when issues are fixed.</p><p>

<a href="https://commons.wikimedia.org/wiki/File:Porpita_porpita.jpg">Image Source: Wikimedia Commons / NOAA / Public Domain</a></p></div></div>]]>
            </description>
            <link>https://blog.hboeck.de/archives/902-File-Exfiltration-via-Libreoffice-in-BigBlueButton-and-JODConverter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849878</guid>
            <pubDate>Wed, 21 Oct 2020 17:12:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To write better, develop a habit of writing]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24849485">thread link</a>) | @pavelegorkin
<br/>
October 21, 2020 | https://bookpub.club/post/to-write-better-you-need-to-develop-a-habit-of-writing--1603298302647x354487348376371200 | <a href="https://web.archive.org/web/*/https://bookpub.club/post/to-write-better-you-need-to-develop-a-habit-of-writing--1603298302647x354487348376371200">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookpub.club/post/to-write-better-you-need-to-develop-a-habit-of-writing--1603298302647x354487348376371200</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849485</guid>
            <pubDate>Wed, 21 Oct 2020 16:39:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LinkedIn will scan the browser to identify extensions]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24849282">thread link</a>) | @youeseh
<br/>
October 21, 2020 | https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-your-browser | <a href="https://web.archive.org/web/*/https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-your-browser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <a href="https://prophitt.me/">Corey Prophitt's Website</a>
  <hr>
  <ul>
    <li><a href="mailto:corey@prophitt.me">Email</a></li>
    <li><a href="https://code.prophitt.me/corey" target="_blank" rel="noreferrer noopener">Code</a></li>
  </ul>
</header><section>
      <p>June 22, 2019</p>
      
      <hr>
      <p>A look at how LinkedIn exfiltrates browser extension data from your browser.</p>
    </section>

    <section>
      
      <hr>
      <p>How would you feel if you opened a program and the program started to check your file system to see what other programs you
      had installed? You would probably feel the software was overstepping. This is essentially what LinkedIn does when you visit their
      website. LinkedIn will scan your local browser files in an attempt to identify a number of different browser extensions you may
      have installed. The data collected by LinkedIn is then exfiltrated from the browser.</p>
      <p>
        This whole adventure started when I was browsing LinkedIn and happened to have my browser console open. While on my LinkedIn
        profile I noticed a large number of 404 errors and as a developer it piqued my interest.
        <a href="https://prophitt.me/assets/images/spying-xs.gif" target="blank" rel="nopener noreferrer">
          <img src="https://prophitt.me/assets/images/spying-xs.gif" alt="LinkedIn's website making local host web requests.">
        </a>
      </p>
      <p>What really piqued my curiosity was the fact all of these failed web requests were for <strong>chrome-extension://</strong>
      resources. After inspecting a few of the extension IDs in the resources I began to suspect LinkedIn was attempting to determine
      if I had certain extensions installed by executing local web requests to the browser itself.</p>
      <p>I spent some time toying around with my browser and LinkedIn's assets. Note, reverse engineering LinkedIn's source code is
      apparently <a href="https://www.linkedin.com/legal/user-agreement#dos" target="_blank" rel="noopener noreferrer">against their terms of service</a>. If I was
      LinkedIn I would probably not want people figuring out how I spy on them either.</p>
      <p>After poking around and doing some investigation I found an interesting object in one of LinkedIn's local storage values.</p>
    </section>

    <section>
      
      <hr>

      <p>One of LinkedIn's local storage keys is <strong>C_C_M</strong>. The value itself is a base64 encoded string (which isn't too
      abnormal). However, if you decode the string you will see a large JSON blob that seems to be encoded with unicode code points (not
      human readable).</p>
      <a href="https://prophitt.me/assets/images/unicode-resized.png" target="blank" rel="nopener noreferrer">
        <img src="https://prophitt.me/assets/images/unicode-resized.png" alt="LinkedIn's local storage printed to a browser console encoded with unicode.">
      </a>
      <p>I am not too sure how or why they encoded it that way, but it seems to me like it was in an attempt to obfuscate the data. The
      encoding is easy enough to reverse, simply parse the JSON. You can do it yourself with the following snippet:</p>
      <p><code>JSON.parse(atob(localStorage.getItem("C_C_M")));</code></p>
      <p>Doing so will display a large JavaScript object with some interesting data in it. Note, it appears the data held in this JSON
      blob is personalized to some degree. In other words, my JSON blob may be larger or smaller than yours. I am unsure which heuristic
      LinkedIn uses to determine which extensions to scan for but they must be using some. Curious what the complete JSON object looks
      like? <a href="https://prophitt.me/assets/files/linkedin-extension.json" target="_blank">Here's mine</a>.</p>
      <a href="https://prophitt.me/assets/images/localstorage.png" target="blank" rel="nopener noreferrer">
        <img src="https://prophitt.me/assets/images/localstorage.png" alt="LinkedIn's local storage printed to the console as a javascript object.">
      </a>
    </section>

    <section>
      
      <hr>
      <p>After examing the JSON file it became pretty clear what was going on. LinkedIn is using two different methods to determine if
      you have an extension installed.</p>
      <ol>
        <li>Content Changed</li>
        <li>Web Accessible Resources</li>
      </ol>
      <p>The first method is the simplest. LinkedIn simply looks for certain content on the page they know doesn't belong there. For
      instance, if they find a div with the ID <strong>email-hunter</strong>, they know you have the Email Hunter extension installed
      (and now your account is probably restricted, or at least on a blacklist).</p>
      <p>The second method is a lot more interesting to me. When building an extension you can specify web accessible resources. These
      resources are typically used via a content script to build a custom interface. However, there's a bit of a gotcha. If the content
      script can make a request for the web accessible resource, so can the underlying website. LinkedIn abuses this fact and sprays
      web requests to your local browser in attempt to find extensions.</p>
      <p>I built a simple extension to automatically parse the extension file and display extensions LinkedIn is looking for.
        <a href="https://code.prophitt.me/corey/nefarious-linkedin" target="_blank" rel="noopener noreferrer">Check it out here</a>.
      </p>
    </section>

    <section>
      
      <hr>
      <p>So, as a developer of an extension what can you do about this? I recommend not using
      <a href="https://developer.chrome.com/extensions/manifest/web_accessible_resources" target="_blank" rel="noopener noreferrer">web accessible resources</a>. Out
      of all extensions LinkedIn finds, a majority of them are due to web accessible resources.</p>
      <p>I would recommend not modifying or injecting user interface features into the underlying page. Alternatively, I would use a
      browser action and communicate with the content page through messaging passing.</p>
    </section>
  


</div>]]>
            </description>
            <link>https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-your-browser</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849282</guid>
            <pubDate>Wed, 21 Oct 2020 16:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using machine learning to tune your Kubernetes HPA]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24849098">thread link</a>) | @digi59404
<br/>
October 21, 2020 | https://www.carbonrelay.com/blog/using-machine-learning-to-tune-your-hpa-for-optimal-performance/ | <a href="https://web.archive.org/web/*/https://www.carbonrelay.com/blog/using-machine-learning-to-tune-your-hpa-for-optimal-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>




<p>Kubernetes users often rely on the Horizontal Pod Autoscaler (HPA) and cluster autoscaling to scale applications. We show how using Red Sky Ops to optimize the whole application alongside the HPA improves cost and performance using the example of a web-application.</p>





<h2><strong>What is the Kubernetes Horizontal Pod Autoscaler?</strong></h2>





<p>The<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noreferrer noopener"> Horizontal Pod Autoscaler</a> (HPA) in Kubernetes scales up and down the number of replicas in a deployment or a stateful set based on metrics prescribed by the user. The most common metrics are CPU and memory utilization of the target pods.&nbsp;</p>





<p>To deploy the HPA, the user sets target metrics for all replicas in a deployment as well as the minimum and maximum number of replicas. The HPA is responsible for adding or deleting replicas to keep the observed metrics lower than the target values while keeping the number of replicas within the prescribed bounds.</p>





<p>When scaling based on CPU and memory utilization, HPA uses the metrics.k8s.io API implemented by the <a href="https://github.com/kubernetes-sigs/metrics-server" target="_blank" rel="noreferrer noopener">metrics-server</a>. The HPA can also use<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/custom-metrics-api.md" target="_blank" rel="noreferrer noopener"> custom metrics</a> or external metrics (e.g. number of requests per second on the ingress) implemented by a third-party or the user.</p>





<h2><strong>HPA tuning challenges</strong></h2>





<p>Optimizing the target metrics of the HPA for all applications and their specific workloads can be frustrating. While newer versions of kubernetes support more in depth configuration of the HPA through policies<a href="#note">*</a>, many users are left with a minimal set of configuration options: namely a cpu/memory utilization target and the maximum number of replicas.</p>





<p>If the application is a web server for example, the speed at which the HPA adds replicas is critical to accommodate bursts in traffic. A simple fix would be to reduce the CPU utilization target to a small value (say 15%) so that the HPA adds replicas early on when the traffic increases. However, this increases your cloud cost because many replicas are underutilized. To limit the cost, one could use replicas with a high CPU utilization target. If the traffic increases, while the HPA is creating replicas waiting to be available, the current replicas experience CPU throttling and the HTTP request latency increases, impacting the clients experience.</p>





<p>A ML-powered experimentation engine such as <a href="https://github.com/redskyops" target="_blank" rel="noreferrer noopener">Red Sky Ops</a> can be used to design a highly available, scalable and cost-efficient application. Let’s demonstrate this using an example web application.</p>





<h2><strong>Example web application</strong></h2>





<p>In the following example, we will optimize the <a href="https://github.com/dockersamples/example-voting-app" target="_blank" rel="noreferrer noopener">Docker example voting app</a> using Red Sky Ops. This app is a simple distributed application that allows the user to vote between two options – cats or dogs.</p>





<figure><img src="https://lh6.googleusercontent.com/FbR98IC_2s4U7qpocG4wyH_iAWd8k9aAwai5OTLYvDezvic2HrNZLbqfI-9ABGgoR6RPJxESclSW5oYGyF3m-s6tfS3ByaensHUNlUIMLaIJ69-znggPRpL2WAYxHX4fkGYAlUQ" alt=""></figure>





<p>A Redis queue collects the votes. Workers consume the votes and insert them in a postgres database. Finally there is a node.js webapp that shows the results of the voting in real time. You can deploy this application in a dedicated namespace with:</p>





<pre>kustomize build github.com/redskyops/redskyops-recipes/voting-webapp/application | kubectl apply -f -</pre>





<h2><strong>Red Sky Ops experiments</strong></h2>





<p>An “experiment” is made of multiple trials whereby the Red Sky Ops server patches the whole application to find the optimal configuration. For each trial, the application is tested using a scalability test. At the end of each test, the Red Sky Ops controller measures metrics to optimize for. In this experiment, we will optimize for two metrics of opposite goals: cost of running the application (in $/month) and p95 latency (in ms). While the performance increases with resources, cost becomes problematic. On the other hand, starving an application reduces user experience. Machine learning helps finding the best tradeoff. You can find detailed instructions to run the experiment yourself <a href="https://github.com/redskyops/redskyops-recipes/tree/master/hpa" target="_blank" rel="noreferrer noopener">here</a> with Locust.</p>





<p>We are using the HPA to scale up and down the number of replicas of the front-end deployment responsible for the user experience. For simplicity, we will tune HPA using a target utilization available via the metrics server. The parameters that we are optimizing are the minimum and maximum number of replicas, target utilization used by the HPA and CPU requests for the voting-service pod. Note that every pod runs with a guaranteed QoS (limits=requests).</p>





<p>We run the experiment for 400 trials, and consider a trial as failed if the response latency is greater than one second.</p>





<h2><strong>Scalability test</strong></h2>





<p>During each trial we load test the application with increasing requests per second (RPS): 100 RPS for one minute, 500 RPS for one minute, 1000 RPS for one minute, 2000 for one minute. This allows us to test the scalability of the application and make sure that the HPA is configured correctly. The application should be able to minimize the cost for a low level of traffic (100 RPS) but still able to scale up fast enough to 2000 RPS.</p>





<h2><strong>Experiment results</strong></h2>





<p>We first set a baseline configuration with:</p>





<pre>Minimum replicas=3<br>Maximum replicas=7<br>CPU utilization target=65%<br>CPU per replica=2&nbsp;</pre>





<p>In this case the cost is $481/month to run this application for a p95 latency of 579 milliseconds.</p>





<p>Each dot represents the metric values measured at the end of each trial (<a href="#figure-1">see Figure 1</a>). The red dots are the best trials found during the experiment, i.e. there is no better configuration for one metric without increasing the value of the other metric. After some exploration of the parameter space, the algorithm converges towards optimal configurations. We find a sharp transition in latency around a cost of $330 per month, where the most satisfying performance is achieved. We find that the best application is obtained for:</p>





<pre>Minimum replicas=10<br>Maximum replicas=15<br>CPU utilization target=80%<br>CPU per replica=0.855</pre>





<p>The cost of running this application is $365/month (24% savings) while the latency is 27.8 milliseconds (95% increase in performance). The advantage of providing multiple best configurations is the ability for the user to pick based on experience. For example, if an experienced devops engineer wants a more scalable application in case of larger spikes of traffic than the ones created for the load test, the following configuration can be chosen:</p>





<pre>Minimum replicas=3<br>Maximum replicas=9<br>CPU utilization target=10%<br>CPU per replica=0.849</pre>





<p>The cost is $344/month (28% savings) while the latency is 60 milliseconds (89% increase in performance). Because the CPU utilization target per replica is lower in this case, a sudden burst in traffic triggers a scale up from the HPA early allowing for the newly added replicas to be available.</p>
<p><img loading="lazy" src="https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1024x568.png" alt="hpa blog figure 1" width="1024" height="568" srcset="https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1024x568.png 1024w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-300x166.png 300w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-768x426.png 768w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1536x852.png 1536w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-2048x1136.png 2048w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1160x644.png 1160w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-90x50.png 90w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-650x361.png 650w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1000x555.png 1000w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-50x28.png 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p>















<p>Figure 1. Red Sky Ops experiment results</p>
<h2><strong>Summary</strong></h2>





<p>Using Red Sky Ops, we can deploy a web application using the HPA that efficiently scales and avoids over provisioning for spikes in traffic.</p>





<p>We decided to tune the CPU target utilization of the HPA. This is more of an infrastructure monitoring approach that is made available quite easily by the metrics server. A different approach would have been to tune the HPA based on the number of requests-per-second on the ingress. Check out this great<a href="https://medium.com/uptime-99/kubernetes-hpa-autoscaling-with-custom-and-external-metrics-da7f41ff7846" target="_blank" rel="noreferrer noopener"> blog post</a> on how to set up the external metrics server to work with the HPA.</p>





<p>Like the<a href="http://www.brendangregg.com/usemethod.html" target="_blank" rel="noreferrer noopener"> USE</a> and <a href="https://www.weave.works/blog/the-red-method-key-metrics-for-microservices-architecture/" target="_blank" rel="noreferrer noopener">RED</a> methods for monitoring your infrastructure and user experience, the Red Sky Ops experiments can be written to optimize both of your infrastructure cost and usage and/or user experience on your deployed application.</p>





<p>Finally, Red Sky Ops allows you to efficiently find the optimal configurations when the correlations are<a href="https://www.carbonrelay.com/blog/the-new-basics-of-configuration-management-in-kubernetes/"> too complicated for a human to understand</a>. For this example, we have oversimplified the application to easily interpret the results, but in production one would tune the resources of all the deployments.</p>





<p>To try it for yourself, create a free Red Sky Ops account.</p>
</div></div><div><div>





<hr>





<p id="note"><strong>*Note:</strong> For v1.18+ the HPA API will allow the scaling behavior to be configurable, allowing the user to design the scale up and scale down policies.</p>





<p><code><code>scaleDown: &nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;stabilizationWindowSeconds: 300 &nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;policies:<br>&nbsp;&nbsp;&nbsp;&nbsp;- type: Percent<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value: 100<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;periodSeconds: 15<br>&nbsp;&nbsp;scaleUp:<br>&nbsp;&nbsp;&nbsp;&nbsp;stabilizationWindowSeconds: 0<br>&nbsp;&nbsp;&nbsp;&nbsp;policies:<br>&nbsp;&nbsp;&nbsp;&nbsp;- type: Percent<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value: 100<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;periodSeconds: 15<br>&nbsp;&nbsp;&nbsp;&nbsp;- type: Pods<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value: 4<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;periodSeconds: 15<br>&nbsp;&nbsp;&nbsp;&nbsp;selectPolicy: Max</code></code></p>








<p>In order to check if your kubernetes cluster has the behavior field available run:</p>









<pre>kubectl explain --api-version=autoscaling/v2beta2 hpa.spec.metrics</pre>






</div></div></div>]]>
            </description>
            <link>https://www.carbonrelay.com/blog/using-machine-learning-to-tune-your-hpa-for-optimal-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849098</guid>
            <pubDate>Wed, 21 Oct 2020 16:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LUMI to become the world's fastest supercomputer]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24848921">thread link</a>) | @clon
<br/>
October 21, 2020 | https://www.lumi-supercomputer.eu/lumi-one-of-the-worlds-mightiest-supercomputers | <a href="https://web.archive.org/web/*/https://www.lumi-supercomputer.eu/lumi-one-of-the-worlds-mightiest-supercomputers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>One of the most powerful supercomputers in the world, LUMI, will start its operations in CSC’s data center in Kajaani, Finland, next year. The peak performance of LUMI is an astonishing 552 petaflop/s. To date, the world’s fastest computer, Fugaku in Japan, reaches peak performance of 513 petaflop/s. When LUMI’s operations start next year, it will be one of the world’s fastest supercomputers.</p>
<p>LUMI is a unique European endeavor, with ten European countries and the EuroHPC Joint Undertaking (EuroHPC JU) investing in one joint system. It is set to boost research, employment, and competitiveness throughout Europe. The procurement process of LUMI is now complete, and the system supplier is Hewlett Packard Enterprise (HPE), providing an HPE Cray EX supercomputer with next generation AMD EPYC™ CPUs and AMD Instinct™ GPUs. In addition to the remarkable computing power, LUMI is also one of the world’s most advanced platforms for artificial intelligence and it will be one of the world’s best known scientific instruments throughout its lifetime.</p>
<p>– Today we mark an important step forward in the realisation of the European High-Performance Computing strategy. The pre-exascale supercomputer hosted by the LUMI consortium will be among the top 5 in the world. Together with the other EuroHPC pre-exascale and petascale supercomputers that will be deployed in 2021, the LUMI supercomputer will help Europe’s public and private users address many daunting research and innovation problems across different areas from weather and climate change through cybersecurity to drug discovery and personalised medicine. LUMI supercomputer aligns the Digital and Green Deal policies of the European Commission, using 100% renewable carbon neutral energy. Moreover, the heat generated will provide 20 percent of the district heat of the area, being one of the most efficient supercomputers in the world, says <strong>Khalil Rouhana</strong>, Deputy Director-General of the Directorate‑General for Communications Networks, Content and Technology (DG Connect) of the European Commission.</p>
<p>– Once operational in mid-2021, the LUMI supercomputer will be one of the most competitive and green supercomputers in the world! Such a leadership-class system will support European researchers, industry, and public sector, in better understanding and responding to complex challenges and transforming them into innovation opportunities in sectors like health, weather forecasting, or urban and rural planning, says the Executive Director of EuroHPC Joint Undertaking, <strong>Anders Dam Jensen</strong>.</p>
<p>– We are committed to supporting the European High Performance Computing Joint Undertaking (EuroHPC JU) to seize opportunities in next-generation supercomputing and bolster R&amp;D in science, advance innovation, and unlock economic growth. We are honored to continue collaborating with EuroHPC JU, and through our partnership with AMD, build one of the world’s fastest pre-exascale supercomputers for Europe.”, says <strong>Peter Ungaro</strong>, senior vice president, and general manager, high-performance computing (HPC) and mission critical solutions (MCS), HPE.</p>
<p>– The reliability of CSC and Finland made the European Commission and ten partner countries to invest in one pan-European high-performance computing and data management infrastructure in Finland. We have to keep up the excellent collaboration in order to maximize this investment to benefit society on a larger scale, says Permanent Secretary <strong>Anita Lehikoinen</strong> from Ministry of Education and Culture, Finland</p>
<p>LUMI is an investment of over 200 million euros, covering the whole lifecycle of the system. It will lift Europe to the forefront of high performance computing (HPC) and research. Exploiting the potential of the data economy is crucial for Europe’s competitiveness.</p>
<p>– The investment will make CSC data center one of the world’s largest players in the field of HPC. The joint procurement process with the EuroHPC Joint Undertaking and ten European countries has proceeded on schedule despite the global pandemic, thanks to the vast know-how of the LUMI consortium and the excellent collaboration. LUMI’s astonishing computing power combined with a highly modern artificial intelligence platform and data management infrastructure will help European researchers tackle unforeseen research challenges, says CSC’s Managing Director <strong>Kimmo Koski</strong>.</p>
<p>The uptake of HPC will remarkably increase the competitiveness of small and medium-sized enterprises (SMEs) in Europe remarkably. Up to one-fifth of LUMI’s resources will be available for industry and SMEs.</p>
<p>– The technology we are using is strongly based on mathematical modelling: analyses, artificial intelligence, simulations, and optimization. Therefore, powerful computing capacity and data management infrastructure are of the utmost importance for us. The LUMI infrastructure will open up entirely new possibilities for us, which we may exploit, says Anna-Maria Henell, CEO of Disior Ltd. Disior is a Finnish company developing software for analysing medical images in 3D.</p>
<p><img loading="lazy" src="https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-300x149.jpg" alt="" width="300" height="149" srcset="https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-300x149.jpg 300w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-1024x507.jpg 1024w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-768x380.jpg 768w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small.jpg 1512w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p><span>Caption: A sketch image of LUMI, an HPC Cray EX supercomputer. Copyright: Hewlett Packard Enterprise</span></p>
<p><img loading="lazy" src="https://www.lumi-supercomputer.eu/content/uploads/2020/10/lumi_havainnekuva3-300x199.png" alt="" width="300" height="199" srcset="https://www.lumi-supercomputer.eu/content/uploads/2020/10/lumi_havainnekuva3-300x200.png 300w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/lumi_havainnekuva3.png 548w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p><img loading="lazy" src="https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-300x212.jpg" alt="" width="300" height="212" srcset="https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-300x212.jpg 300w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-1024x724.jpg 1024w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-768x543.jpg 768w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-283x200.jpg 283w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small.jpg 1489w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p><span>Caption: This is how the LUMI data center will look like. Copyright: Synopsis Architects Ltd. and Geometria Architecture Ltd.</span></p>
<p><strong>Supercomputers enable the fight against pandemics and help resolve unforeseen research questions<br>
</strong>LUMI’s top-notch computing resources are needed in leading-edge research in a wide range of data- and computing-intensive fields. Examples include climate, pharmaceutical, and artificial intelligence.<br>
LUMI will also have a fast-track for urgent computing in time- and mission-critical simulations. This kind of simulation might be, for example, related to a large epidemic or pandemic disease. The current COVID-19 pandemic has largely benefitted from supercomputers: supercomputers have been used for example to simulate studies related to vaccine research and defeat the spread of the virus. With its vast computing resources, LUMI can address different research challenges even faster than before. In addition, it will enable addressing totally new types of scientific challenges combining multidisciplinary research and artificial intelligence.</p>
<p><strong>World-class environmental sustainability and energy-efficiency</strong><br>
As a carbon-neutral data center, LUMI helps the European ICT sector in becoming greener and more cost-efficient, which is a necessity for reaching EU’s ambitious climate targets and paving the way for the green transition. CSC’s data center in Kajaani is among the world’s most eco-efficient: it uses 100% renewable energy produced with hydropower. LUMI’s waste heat will be used in Kajaani’s district heating network: 20% of the area’s yearly district heating needs will be covered with LUMI’s waste heat.</p>
<p><strong>LUMI system architecture explained:</strong></p>
<ul>
<li>The LUMI system will be supplied by Hewlett Packard Enterprise (HPE), based on an HPE Cray EX supercomputer.</li>
<li>The peak performance of LUMI is an astonishing 552 petaflop/s meaning 552 *10<sup>15</sup> floating point operations per second. This figure makes LUMI one of the world’s fastest supercomputers. For comparison, the world’s fastest computer today (Fugaku in Japan) reaches 513 petaflop/s and the second fastest (Summit in the US) 200 petaflop/s (more information: <a href="http://www.top500.org/">www.top500.org</a>). If LUMI’s computing power was compared to normal laptops, it would require 1.5 million laptops together to reach the performance of LUMI. If these laptops were piled up, they would form a tower of over 23 kilometers high!</li>
<li>LUMI will also be one of the most advanced platforms in the world for artificial intelligence (AI). With LUMI, it will be possible to combine AI, especially deep learning, and traditional large scale simulations combined with massive scale data analytics in solving one research problem.</li>
<li>The number crunching capability of LUMI is accelerated by the GPU (Graphics Processing Unit) partition. It is based on the future generation AMD Instinct™ GPU.</li>
<li>LUMI will be complemented by a CPU (Central Processing Unit) partition, featuring 64-core next-generation AMD EPYC™ CPUs.</li>
<li>LUMI’s data analytics partition has 32 aggregated terabytes of memory and 64 visualization GPUs. This partition is used e.g. for visualization, heavy data analysis, meshing, and pre/post-processing.</li>
<li>LUMI’s storage system will consist of three components. First, there will be a 7-petabyte partition of ultra-fast flash storage, combined with a more traditional 80-petabyte capacity storage, both based on the Lustre parallel filesystem, as well as a data management service, based on Ceph and being 30 petabytes in volume.</li>
<li>In total, LUMI will have astounding storage of 117 petabytes and an impressive aggregated I/O bandwidth of 2 terabytes per second</li>
<li>LUMI will also have an OpenShift/Kubernetes container cloud platform for running microservices.</li>
<li>All the different compute and storage partitions are connected to the very fast Cray Slingshot interconnect of 200 Gbit/s. The global bandwidth of the LUMI-GPU partition is 160 TB/s. The global Internet traffic would fit therein, in fact, two times!</li>
<li>LUMI takes over 150m2 of space, which is about the size of a tennis court. The weight of the system is nearly 150 000 kilograms (150 metric tons).</li>
</ul>
<p><strong>More information:</strong><br>
Images, videos and contact information for media: <a href="http://www.lumi-supercomputer.eu/media">www.lumi-supercomputer.eu/media</a></p>
<p><strong>Read also</strong></p>
<p>EuroHPC JU <a href="https://eurohpc-ju.europa.eu/news/lumi-new-eurohpc-world-class-supercomputer-finland">press release</a></p>
<p>Hewlett Packard Enterprise (HPE) <a href="https://www.hpe.com/us/en/newsroom/press-release/2020/10/hewlett-packard-enterprise-wins-160m-contract-to-power-one-of-the-worlds-fastest-supercomputers-based-in-finland-to-bolster-europes-research-in-science-and-unlock-economic-growth.html">press release.</a></p>

            </div></div>]]>
            </description>
            <link>https://www.lumi-supercomputer.eu/lumi-one-of-the-worlds-mightiest-supercomputers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848921</guid>
            <pubDate>Wed, 21 Oct 2020 15:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GraphQL and REST APIs in seconds with Hypi's low-code back end as a service]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24848809">thread link</a>) | @hypi_universe
<br/>
October 21, 2020 | https://hypi.io/2020/10/20/announcing-hypis-public-beta2/ | <a href="https://web.archive.org/web/*/https://hypi.io/2020/10/20/announcing-hypis-public-beta2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="62d125cc" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<section data-id="76f2e445" data-element_type="section">
<div>
<div>
<div data-id="4036ff2a" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>


 
<div data-id="74b51eb2" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>The Hypi team is incredibly proud to announce today that we’re making our second <a href="https://hypi.app/auth/register" target="_blank" rel="noreferrer noopener">public beta available today</a>.</p>
<p>This has been in the making for a few months after receiving very valuable feedback from our community. Not only have we listened to the original feedback, some members of our community have directly contributed to the improvements in this release.</p>
<div data-tilt-max="15"><div><p><img data-attachment-id="3786" data-permalink="https://hypi.io/2020/10/20/announcing-hypis-public-beta2/attachment/2/" data-orig-file="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?fit=3200%2C1600&amp;ssl=1" data-orig-size="3200,1600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2" data-image-description="" data-medium-file="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?fit=300%2C150&amp;ssl=1" data-large-file="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?fit=960%2C480&amp;ssl=1" loading="lazy" width="960" height="480" src="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=960%2C480&amp;ssl=1" srcset="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=3200&amp;ssl=1 3200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1536%2C768&amp;ssl=1 1536w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=2048%2C1024&amp;ssl=1 2048w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1200%2C600&amp;ssl=1 1200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=2880&amp;ssl=1 2880w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=3200&amp;ssl=1 3200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1536%2C768&amp;ssl=1 1536w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=2048%2C1024&amp;ssl=1 2048w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1200%2C600&amp;ssl=1 1200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=2880&amp;ssl=1 2880w" data-lazy-src="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=960%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p></div></div>
<p>Three years ago our team set out to make it easier for developers to build applications but we had no idea of the amazing journey this would take us on. In our first 18 months we built 3 different versions and threw them all away because they just weren’t quite right. We spoke to developers at conferences and meetups including WebSummit, Collision and Apache Ignite London and France. It was 18 months researching and speaking to developers 6 countries face to face and 4 more virtually all of this has culminated into what Hypi is today.</p>

<figure><img data-attachment-id="3792" data-permalink="https://hypi.io/2020/10/20/announcing-hypis-public-beta2/app-to-api/" data-orig-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?fit=640%2C328&amp;ssl=1" data-orig-size="640,328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="App-to-API" data-image-description="" data-medium-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?fit=300%2C154&amp;ssl=1" data-large-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?fit=640%2C328&amp;ssl=1" loading="lazy" width="640" height="328" src="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?resize=640%2C328&amp;ssl=1" alt="" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Several months ago we offered limited access and got feedback from the wider community. That feedback was reassuring, almost everyone felt it was a good product with great potential but were missing a few things or could be improved here and there and now we’re again announcing Hypi, a comprehensive low-code backend as a service platform.</p>
<figure><img data-attachment-id="3777" data-permalink="https://hypi.io/2020/10/20/announcing-hypis-public-beta2/screenshot-2020-10-19-at-21-57-13/" data-orig-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?fit=1824%2C1042&amp;ssl=1" data-orig-size="1824,1042" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-2020-10-19-at-21.57.13" data-image-description="" data-medium-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?fit=960%2C548&amp;ssl=1" loading="lazy" width="960" height="548" src="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=960%2C548&amp;ssl=1" alt="" srcset="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1024%2C585&amp;ssl=1 1024w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=300%2C171&amp;ssl=1 300w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=768%2C439&amp;ssl=1 768w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1536%2C877&amp;ssl=1 1536w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1200%2C686&amp;ssl=1 1200w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?w=1824&amp;ssl=1 1824w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1024%2C585&amp;ssl=1 1024w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=300%2C171&amp;ssl=1 300w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=768%2C439&amp;ssl=1 768w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1536%2C877&amp;ssl=1 1536w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1200%2C686&amp;ssl=1 1200w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?w=1824&amp;ssl=1 1824w" data-lazy-src="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=960%2C548&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Hypi’s founding purpose is to make development simple and hair-loss free. We’ve spent a lot of time thinking about how to do that best and we summised a few things from our own experience as well as from our research and speaking to developers.</p>
<ol><li>We spend too much time repeating ourselves from project to project, sometimes even within the same project. The things that almost everyone we spoke to say they repeat a lot are:<ol><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/crud" target="_blank">CRUD APIs</a> – the bare bones of all data driven applications</li><li>Authentication – Registration and login in</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/authorisation" target="_blank">Authorisation</a> – Access control, even more than that, <strong>flexible</strong> access control. Role based access control is great but simply doesn’t fit the bill in many cases.</li><li>Caching and scaling – even today, this remains a challenge for most developers</li></ol></li><li>We spend so much time integrating and <a href="https://docs.hypi.app/references/api-gateway" target="_blank" rel="noreferrer noopener">staying in sync with external services</a>.</li><li>We still have to build what are now commonplace features into our apps every time.</li></ol>
<p>The team’s very proud to say that Hypi takes care of all of these and so much more.</p>
<p>Available today are features such as:</p>
<ol><li>Instantly generating CRUD APIs from a data model</li><li>Automatically available login and registration APIs</li><li>A simple, yet flexible authorisation API allowing you to model anything from simple role based access control to complex corporate authorisation models</li><li>Hypi is built on <a rel="noreferrer noopener" href="https://ignite.apache.org/" target="_blank">Apache Ignite</a> allowing us to automatically scale your APIs, no effort required. Taking advantage of its massively scalable in-memory technology we’re also able to achieve incredible performance, thinking nothing of it!</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/serverless-functions" target="_blank">Serverless functions</a> so you can add custom APIs and extend the built in ones.</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/user-defined-functions" target="_blank">Inline functions</a> for when Docker containers are too heavy handed</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/webhooks" target="_blank">Webhooks</a> to accept incoming, unauthenticated events from external systems</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/workflow" target="_blank">Workflows</a> for scheduling and orchestrating function executions</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/math-api" target="_blank">Math APIs</a> for performing atomic mathematical operations server side</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/aggregations-api" target="_blank">Aggregations API</a> for getting analytics and other insights from your data</li><li>A powerful <a rel="noreferrer noopener" href="https://docs.hypi.app/tutorials/arcql" target="_blank">query/filtering language</a> to find data</li><li>…and <a rel="noreferrer noopener" href="https://docs.hypi.app/" target="_blank">so much more</a> </li></ol>
<p>When we say it’s a comprehensive platform, we mean it. For our existing users who have been working closely with us to get to this stage we thank you! This announcement signals our push towards general availability in the coming months. </p>
<p><a href="https://hypi.app/auth/register" target="_blank" rel="noreferrer noopener">Sign up and let Hypi</a> take the stress and repetition out of back end development. Simple is best!</p>
</div>
</div>

</div>
</div>
</div>
</div>
</div>
</section>

<section data-id="5e429d25" data-element_type="section">

</section>

<section data-id="3ed2ebec" data-element_type="section">

</section>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://hypi.io/2020/10/20/announcing-hypis-public-beta2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848809</guid>
            <pubDate>Wed, 21 Oct 2020 15:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gardening Your Twitter]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24848782">thread link</a>) | @tosh
<br/>
October 21, 2020 | https://steipete.com/posts/growing-your-twitter-followers/ | <a href="https://web.archive.org/web/*/https://steipete.com/posts/growing-your-twitter-followers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://d33wubrfki0l68.cloudfront.net/f99dfb0a1f04e2577108899ca48dca03f49f0d67/039b8/assets/img/2020/make-twitter-work/gardening-growing.jpg"></p><p>I’ve been using Twitter for almost 12 years now. It can be challenging to navigate your timeline, so today I’m sharing some tips to keep it fun.</p><p>This is the first part of my Twitter series about Gardening Your Twitter. Don’t miss out on the second part, where you can learn how to best <a href="https://steipete.com/posts/curating-your-twitter-timeline/">curate your timeline</a> and manage who to follow and unfollow.</p><h2 id="your-online-persona">Your Online Persona</h2><p>There are many strategies for online personas, but I can only share what works well for me. I follow people to cover specific areas/topics and also for their commentary/personality. In a way, Twitter is a newsfeed where the comments are presented before the content, and you pick people for both content and comments.</p><p>I’m known for talking about iOS and bootstrapping a company, and I have a pretty sharp tongue on tech news. I used to keep politics out of my feed, but since 2016, I do sprinkle in topics that are important to me — from US politics to climate change and LGBTQIA rights.</p><p>There will always be people who complain that XY topic shouldn’t be on Twitter, but in the end, it’s <em>your choice</em> what you talk about and it’s their choice to follow you.</p><p>I’m openly gay on Twitter, but only in the last few years have I also started talking about that. Being open does allow me to add a unique perspective to some content, and it adds more complexity to my persona. I almost never share pictures or private content though; <a href="https://www.instagram.com/sportg33k/">that stuff is for Instagram</a>.</p><p>Whatever you go with, be authentic. I don’t share everything on Twitter, but what I do share is honest and is usually done with passion. Additionally, it can be interesting or funny. I do not share content for money or for favors, rather I only share things if I find them interesting.</p><h3 id="your-avatar">Your Avatar</h3><p>Pick an avatar you like and stick with it. I recommend a real face and not a sketch or something more abstract, as it’ll help folks identify you at conferences or events. Make sure you use the same picture and use it everywhere (GitHub, Gravatar, email, etc.) so that you have one universal online identity. People will scan the picture much faster than your name — changing it is usually something folks dislike, and it’ll result in a temporary loss of engagement. You can change it, but I recommend not doing that, or at least doing so only every few years.</p><p>Or, you can be really sneaky and just <a href="https://krausefx.com/blog/continuous-delivery-for-your-profile-picture">remake your picture so it changes slightly every year</a>.</p><h3 id="direct-messages">Direct Messages</h3><p>I highly recommend going into Settings and privacy &gt; Privacy and safety &gt; Direct Messages and enabling “Receive messages from anyone.” There’s a lot of great commentary from people that I received via DM since they’re not comfortable replying publicly. There are the occasional odd messages (and inappropriate offers), but if you’re a cis white male, you likely are good. Minority groups might want to reconsider this setting or at least enable the Quality filter.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/863f9afff497ec9faee70ce7485680fbc999fde1/a1446/assets/img/2020/make-twitter-work/settings.png" alt="Twitter Settings"></p><p>If in doubt, I suggest you experiment with this — the settings are easy to change if it turns out to be a bad idea.</p><h3 id="multiple-profiles">Multiple Profiles</h3><p>Quite a few of my friends have “alt” accounts for the hot takes or for talking with friends. If you work at a Big Corp, you might be required to filter what you say, and having an alt can be a solution. In general, I don’t recommend making an alt account, as it’s simply too much work to maintain multiple accounts. Just tweet out your hot takes and attract the right followers on your main account.</p><h2 id="extending-reach">Extending Reach</h2><p>The more active followers you have on Twitter, the more fun it becomes. There’s no hack or shortcut for gaining followers, but there are various things you can do that can help you steadily grow your audience.</p><h3 id="blog-posts">Blog Posts</h3><p>Twitter is a great indicator for topics that people find interesting — <a href="https://twitter.com/steipete/status/1297956386836566016">I often get my best ideas for blog posts out of Twitter conversations</a>, and I also already have half the content there. Twitter is great for inspiration and to learn, but it’s often hard to read and follow conversations. Go the extra mile and convert some of these interactions to blog posts. This will greatly extend your reach, and in turn, it’ll attract new followers who find your content interesting.</p><h3 id="conference-talks">Conference Talks</h3><p><a href="https://steipete.tv/">Speaking at conferences</a> is a great way to meet new people and extend your social circle. I often meet folks at conferences, and either we connect on Twitter or we find out that we already know each other on there! Either way — this will increase the bond and will make it more likely that people reach out to you. <strong>Conferences are work, but they are so worth it.</strong></p><p>Bonus: <a href="https://pspdfkit.com/blog/2018/binary-frameworks-swift/">Convert your conference talk to a blog post</a>. Very few people will actually watch a recording, so via recycling and reshaping content you already have, you can extend your reach again.</p><p>If you plan on starting to speak, create a website where you list what topics you can talk about and your bio. I’m using <a href="https://github.com/steipete/speaking">a simple GitHub repo</a> that has been proven extremely useful for me to track past events, attract new speaking gigs, and help conference organizers with getting the information they need to announce me.</p><h3 id="engage-with-your-audience">Engage with Your Audience</h3><p>I try to reply to almost everyone who interacts with me on Twitter. This doesn’t take much time, and sometimes I just reply with an emoji, but taking time to engage shows your audience you care, and they’re much more likely to interact with your content again if they know that it’s not a one-way street. Same goes for your feed — don’t just read, reply. This can range from helping others with questions/problems to just posting a “me too” retweet. Sometimes I get content in my feed via a retweet, and by interacting with that, I get a new follower.</p><h3 id="tracking-statistics">Tracking Statistics</h3><p>Be consistent. You won’t grow an audience overnight. Make Twitter a daily thing. Share content. Be present — and you’ll grow your audience every day.</p><p><a href="https://analytics.twitter.com/">Twitter Analytics</a> is great to understand which tweets work. To track long-term performance, I’m using <a href="http://birdbrainapp.com/">Birdbrain</a>. It’s one of the oldest apps on my phone, so I have data since 2014. Interestingly, my follower count has been growing pretty much linearly:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/b753fb6d7ed16ff2e572edcc90d8143bf73653eb/38f85/assets/img/2020/make-twitter-work/follower.png" alt="Birdbrain Follower Count of @steipete" width="50%"></p><h2 id="tweets-that-work">Tweets that Work</h2><p>I do share a lot of news articles. I often just quote something interesting from the news if it doesn’t need strong commentary, but the inclusion of a pull quote helps show that it’s worth reading.</p><p>The tweets that are the most engaging, however, usually are original content, particularly in context with your audience and topics of interest. Here are some of my top performing tweets from the last few months, with about 80K–450K impressions each. Sometimes it’s the <a href="https://twitter.com/steipete/status/1310331623729229827">ridiculous tweets that explode</a>, and sometimes you <a href="https://twitter.com/steipete/status/1306884214252613632?s=20">don’t need words</a>. It also can be news commentary if the comment <a href="https://twitter.com/steipete/status/1288151223028322304">really nails it</a> or just <a href="https://twitter.com/steipete/status/1281547449660825601">really fits</a>.</p><h3 id="using-threads">Using Threads</h3><p>Lately I’ve been using more and more threads to connect tweets over time — this has been proven to be really great, as it immediately gives people context, they can read more, and the official Twitter client also usually shows 2–3 tweets in a thread, giving you more “space” in the timeline. Here’s an example:</p><div><blockquote><div lang="en" dir="ltr"><p>Been clicking around for a minute with Apple's new Fruta SwiftUI sample. </p><p>Things jump around wildly, fav' doesn't work, and it crashes once you open a second window. I understand it's b1, but looking at how SwiftUI went last year I doubt this will all be fixed. <a href="https://t.co/zGRRYswRde">pic.twitter.com/zGRRYswRde</a></p></div>— Peter Steinberger (@steipete) <a href="https://twitter.com/steipete/status/1277623561604214784?ref_src=twsrc%5Etfw">June 29, 2020</a></blockquote></div><h2 id="curating-your-timeline">Curating Your Timeline</h2><p>Who you follow defines your Twitter experience. Learn how you can curate your Twitter timeline to keep it fun and interesting by reading <a href="https://steipete.com/posts/curating-your-twitter-timeline/">the second part of this series</a>.</p><h2 id="addendum-building-personal-brands-for-introverts">Addendum: Building Personal Brands for Introverts</h2><p>I gave a talk at UIKonf in Berlin in 2018 about Building Personal Brands for Introverts. This talk is still highly relevant and goes even deeper into defining your online identity. Check it out if you want to know more.</p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/0c6izSzP-KQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div>]]>
            </description>
            <link>https://steipete.com/posts/growing-your-twitter-followers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848782</guid>
            <pubDate>Wed, 21 Oct 2020 15:28:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Kubernetes native SaaS applications by deploying in-cluster data planes]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24848618">thread link</a>) | @htroisi
<br/>
October 21, 2020 | https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>At Pixie, we are working on a Kubernetes native monitoring system which stores and processes the resulting data entirely within a user’s cluster. This is the first in a series of posts discussing techniques and best practices for effectively building Kubernetes native applications. In this post, we explore the trade-offs between using an air-gapped deployment that lives completely within a cluster and a system which splits the control and data planes between the cloud and cluster, respectively.  </p><p>One benefit of building for the Kubernetes platform is that it simplifies the process of deploying applications to a user’s environment, often requiring only a few simple steps such as applying a set of YAMLs or installing a Helm Chart. Within minutes, users can easily have a running version of the application on their cluster. However, now that these applications are running entirely on prem, it becomes difficult for the developer to manage. In many cases, rolling out major updates or bug fixes relies on having the user manually update their deployment. This is unreliable for the developer and burdensome for the user.</p><div><figure><img src="https://blog.pixielabs.ai/static/e4ba6d3f5793c83a25a64e4fba9e2981/connected-on-prem.svg"><figcaption>Diagram of a connected on-prem architecture.</figcaption></figure></div><p>To address this problem, we propose a connected on-prem architecture which delegates the responsibility of managing the data and control planes of the application to the deployment running in the cluster and a developer-managed cloud environment, respectively. More concretely, the application deployed in the user’s cluster is solely responsible for collecting data and making that data accessible. Once the foundation of this data layer is established, the logic remains mostly stable and is infrequently updated. Meanwhile, a cloud-hosted system manages the core functionality and orchestration of the application. As the cloud is managed by the developer themselves, they are freely able to perform updates without any dependency on the users. This allows the developer to iterate quickly on the functionality of their system, all while maintaining data locality on prem.</p><p>This split-responsibility architecture is common in many hardware products, since external factors may make it challenging to deploy updates to software running on physical devices. For instance, despite these physical limitations, <a href="https://www.ui.com/" target="_blank" rel="noopener noreferrer">Ubiqiti</a>’s UI is able to offer a rich feature-set by delegating functionality to their cloud and keeping their physical routers within the data plane. Similarly, <a href="https://webrtc.org/" target="_blank" rel="noopener noreferrer">WebRTC</a> is a standard built into most modern browsers for handling voice and video data. Although browser updates are infrequent, having the separated data and control layers allows developers to freely build a diverse set of applications on top of WebRTC. This architecture is still relatively uncommon in enterprise software, but has been adopted by popular products such as <a href="https://harness.io/wp-content/uploads/2018/03/arch_2.png" target="_blank" rel="noopener noreferrer">Harness</a>, <a href="https://streamsets.com/" target="_blank" rel="noopener noreferrer">Streamsets</a>, and <a href="https://cloud.google.com/anthos" target="_blank" rel="noopener noreferrer">Anthos</a>.</p><p>However, designing a connected on-prem architecture is easier said than done. When building such a system, one challenge you may encounter is how to query data from an application running on the user’s cluster via a UI hosted in the cloud. We explore two approaches for doing so:</p><ol><li>Making requests directly to the application in the cluster</li><li>Proxying requests through the cloud</li></ol><p>For brevity, we will refer to the application running on the user’s cluster as a satellite.</p><h2>Approach 1: Making Requests Directly to the Application in the Cluster</h2><p>The simplest approach for executing the query on a satellite is to have the UI make the request directly to the satellite itself. To do this, the UI must be able to get the (1) status and (2) address of the satellite from the cloud, so that it knows whether the satellite is available for querying and where it should make requests to. </p><div><figure><img src="https://blog.pixielabs.ai/static/eb62b05f17165493ca6c988177555267/non-passthrough.svg"><figcaption>Diagram of Non-Passthrough Mode where the UI makes requests directly to the satellite agent itself.</figcaption></figure></div><h3>Step 1: Heartbeating</h3><p>A common technique to track the status of a program is to establish a heartbeat sequence between the program (the satellite) and the monitoring system (the cloud). This is typically done by having the satellite first send a registration message to the cloud. During registration, the satellite either provides an identifier or is assigned an identifier via the cloud, which is used to identify the satellite in subsequent heartbeat messages.</p><p>Following registration, the satellite begins sending periodic heartbeats to the cloud to indicate it is alive and healthy. Additional information can be sent in these heartbeats. In our case, we also attach the satellite’s IP address. Alternatively, the IP address could have been sent during registration, if it is not subject to change. The cloud records the satellite’s status and address so that it can be queried by the UI.</p><p>Now, when the UI wants to make a request to a satellite, it first queries the cloud for the address, then directly makes the request to that address. </p><p>Great! That wasn’t too bad. In many cases, many cloud/distributed satellite architectures already communicate via heartbeats to track satellite state, so sending an additional address is no problem. However... If your UI is running on a browser and your satellite is responding over HTTPS (likely with self-signed certs), you are not done yet...</p><div><figure><img src="https://blog.pixielabs.ai/static/f178e72484d5e1de0dcc20d539cd25d6/cert-authority-invalid-1.png"><figcaption></figcaption></figure></div><h3>Step 2: Assigning Satellites a Domain Name</h3><p>The browser is blocking our requests because of the satellite’s SSL certs! A user could go ahead and navigate directly to the satellite’s address, where the browser prompts the user with whether or not they want to bypass the invalid cert.</p><div><figure><img src="https://blog.pixielabs.ai/static/2473c1e3bd36f293ccf4938cd7d1b4f4/cert-authority-invalid-2.png"><figcaption></figcaption></figure></div><p>However, this would need to be done per satellite and is disruptive to the user’s overall experience. It is possible to generate SSL certs for IP addresses, but this is uncommon and isn’t available with most free Certificate Authorities. This approach is also complicated if the satellite’s IP address is subject to change. </p><div><figure><img src="https://blog.pixielabs.ai/static/16755003b378767879ee5d066ff07608/SSL-cert-flow.svg"><figcaption>Diagram of SSL certification flow for Non-Passthrough Mode.</figcaption></figure></div><p>To solve this problem, we used the following solution:</p><ol><li>Pre-generate SSL certs under a subdomain that you control, for instance: <code>&lt;uuid&gt;.satellites.yourdomain.com</code>. This step is easy to do with any free Certificate Authority <em>and can be safely done if the subdomain has a well-known DNS address</em>. You should make sure to generate more SSL certs than the number of expected satellites. </li><li>When an satellite registers with the cloud, it should be assigned an unused SSL cert and associated subdomain. The SSL cert should be securely sent to the satellite and the satellite’s proxy should be updated to use the new cert.</li><li>When the cloud receives the satellite’s IP address from its heartbeats, it updates the DNS record for the satellite’s subdomain to point to the IP address. </li><li>When executing queries, the UI can now safely make requests to the satellite’s assigned subdomain rather than directly to its IP address, all with valid certs!</li></ol><p>In the end, making requests directly to the satellites turned out to be more complicated (and hacky) than we’d originally thought. The solution also doesn’t scale well, since the SSL certs need to be pre-generated. Without having a fixed number of satellites, or an upperbound on the number of satellites, it isn’t long before all the certs have been assigned and someone needs to step in and manually generate more. It is possible to generate the certs and their DNS records on the fly, but we’ve found these operations can take too long to propagate to all networks. <em>It is also important to note that this approach may violate the terms of service for automated SSL generation and is susceptible to usual security risks of wildcard certificates.</em></p><p>When a satellite is behind a firewall, it will only be queryable by users within the network. This further ensures that no sensitive data leaves the network.</p><h2>Approach 2: Proxying Queries through the Server</h2><div><figure><img src="https://blog.pixielabs.ai/static/2aea205714b53dd0286e660bec0c9370/passthrough-general.svg"><figcaption>Diagram of Passthrough Mode where UI requests are proxied through the cloud.</figcaption></figure></div><p>As seen in the previous approach, it is easiest to have the UI make requests to the cloud to avoid any certificate errors. However, we still want the actual query execution to be handled by the satellites themselves. To solve this, we architected another approach which follows these general steps:</p><ol><li>User initiates query via the UI.</li><li>The cloud forwards the query to the appropriate satellite.</li><li>Satellite send its responses back to the cloud.</li><li>Cloud forwards responses back to the UI.</li></ol><p>The cloud must be able to handle multiple queries to many different satellites at once. A satellite will stream batches of data in response, which the server needs to send to the correct requestor. With so many messages flying back and forth, all of which need to be contained within their own request/reply channels, we thought this would be the perfect job for a message bus. </p><p>The next question was: which message bus should we use? </p><h3>Choosing a Message Bus</h3><p>We built up a list of criteria that we wanted our message bus to fulfill: </p><ul><li>It should receive and send messages quickly, especially since there is a user waiting at the receiving end.</li><li>It should be able to handle relatively large messages. An satellite’s query response can be batched into many smaller messages, but the size of a single datapoint can still be non-trivial.</li><li>Similarly, since an satellite’s response may be batched into many messages, the message bus should be able to handle a large influx of messages at any given time.</li><li>It should be easy to start new channels at any time. We may want to create a new channel per request or per satellite, all of which we have no fixed number.</li></ul><p>We briefly considered Google Pub/Sub, which had strict quota requirements (only 10,000 topics per Google project), and other projects such as Apache Pulsar. However, we primarily considered two messaging systems: Apache Kafka and NATS. General comparisons between Kafka and NATS have been discussed at length in other blogs. In this blog post, we aim to compare these two systems based on our requirements above.</p><p>We relied heavily on benchmarks that <a href="https://bravenewgeek.com/category/benchmarking/" target="_blank" rel="noopener noreferrer">others have performed</a> to judge latency based on message size and message volume. These results lean in …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/">https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/</a></em></p>]]>
            </description>
            <link>https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848618</guid>
            <pubDate>Wed, 21 Oct 2020 15:14:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fear and Loathing in YAML]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24848511">thread link</a>) | @mooreds
<br/>
October 21, 2020 | https://chrisshort.net/fear-and-loathing-in-yaml/ | <a href="https://web.archive.org/web/*/https://chrisshort.net/fear-and-loathing-in-yaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><blockquote><p>This post was originally written as the introduction to <a href="https://devopsish.com/188/">DevOps’ish 188</a>, has been modified based on feedback, and deemed worthy to share as its own blog post.</p><p>Photo by <a href="https://twitter.com/wocintechchat">Christina Morillo</a> from <a href="https://www.pexels.com/photo/adult-computer-eyewear-female-1181325/">Pexels</a></p></blockquote><p><a href="https://twitter.com/brunoborges/status/1315230767207784450">We kinda went down a rabbit hole</a> the other day when I suggested folks check out <a href="https://dev.to/vikcodes/yq-a-command-line-tool-that-will-help-you-handle-your-yaml-resources-better-8j9"><em>yq</em></a>, “The aim of the project is to be the jq or sed of yaml files.” First, there’s nothing wrong with this project. I like it, I find the tool useful, and that’s that. But the great debate started over our lord and savior, <a href="https://yaml.org/">YAML</a>. Yeah, I know, XML vs. JSON vs. YAML vs. TOML vs. the next thing is a tired and old debate.</p><p>Let me level set here. I routinely joke about how I’m a “Calendar Driven YAML Engineer” and have been for years on <a href="https://openshift.tv/">openshift.tv</a>. But I’m not too fond of YAML. Let me tell you a story…</p><p>In 2012, I worked at McClatchy Interactive (before the really dark times) and enjoyed the systems and security work I was doing. We had our machine creation down to a finite science. Bare metal spun up, you punched the MAC address into a database file, and off the machine went to get all the needed packaging and code to run as its defined purpose in our infrastructure.</p><p><a href="https://en.wikipedia.org/wiki/CFEngine">CFEngine</a> provisioned the machine accordingly based on purpose and positioned it in the network ready for code deployment. DevOps was something the company was embracing at the time. So instead of using the existing CFEngine infrastructure, the DevOps tandem at the time was using <a href="https://en.wikipedia.org/wiki/Puppet_(company)">Puppet</a> for code deploys. This system worked fine until it didn’t. There were clear lines between infrastructure (typical IT in the datacenter) and software deployment and configuration (developers). In our case, DevOps represented the development team more so than the Operations team. Sound familiar?</p><p>But, as you can imagine, even with all the automation in place, it was still a throw over the wall kind of scenario. When Puppet needed system packages installed because of modifications to the codebase (requiring a newer version of Perl, for example) or new services coming online using different OS packages, Puppet now had to do the task CFEngine was doing; systems management. The idea was to build an overarching WebOps team that was cross-functional, spirited, and deeply technical. The first edict laid down to the team by the DevOps lead was, “read the <a href="https://yaml.org/spec/1.2/spec.html">YAML spec</a>.” We were all jumping into the Puppet pool to help integrate our processes and procedures better.</p><p>“Ugh…” I thought to myself. “I have to read this horribly written spec.” It was not an RFC, which I am fond of reading, but something about the YAML spec made me sad and frustrated. Syntax <em>really</em> mattered. Whitespace <em>really</em> mattered. My experiences have taught me that rote memorization and getting humans to see the absence of something were incredibly difficult tasks. These are things that most hackers take advantage of when infiltrating systems. Humans aren’t as good as computers at finding the absence of something or memorizing things. I was not too fond of this non-markup language for these reasons.</p><p>It irked me that the YAML creators laid out goal #1 as “YAML is easily readable by humans.” It is human-readable because you see the human-readable words in the scalars and structures, but there was something off-putting about YAML. It was a markup language claiming not to be a markup language. I held the firm belief that markup languages are supposed to make things simpler for humans, not harder (XML is the antithesis of markup languages, in my opinion).</p><p>Here I was, relatively fresh to the DevOps game, learning some core developer concepts to understand a markup language, the crux of which was two Achilles heels. I also didn’t like how big, bulky, and cumbersome Puppet was to work with. But, here I was thrust headfirst into this world. Might as well make the best of it. I’ve since embraced YAML, but it doesn’t mean I’m writing my notes in YAML format.</p><div><div id="sib-form-container"><div id="error-message"><div><svg viewBox="0 0 512 512"><path d="M256 40c118.621.0 216 96.075 216 216 0 119.291-96.61 216-216 216-119.244.0-216-96.562-216-216 0-119.203 96.602-216 216-216m0-32C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm-11.49 120h22.979c6.823.0 12.274 5.682 11.99 12.5l-7 168c-.268 6.428-5.556 11.5-11.99 11.5h-8.979c-6.433.0-11.722-5.073-11.99-11.5l-7-168c-.283-6.818 5.167-12.5 11.99-12.5zM256 340c-15.464.0-28 12.536-28 28s12.536 28 28 28 28-12.536 28-28-12.536-28-28-28z"></path></svg><p><span>Your subscription could not be saved. Please try again.</span></p></div></div><div id="success-message"><div><svg viewBox="0 0 512 512"><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 464c-118.664.0-216-96.055-216-216 0-118.663 96.055-216 216-216 118.664.0 216 96.055 216 216 0 118.663-96.055 216-216 216zm141.63-274.961L217.15 376.071c-4.705 4.667-12.303 4.637-16.97-.068l-85.878-86.572c-4.667-4.705-4.637-12.303.068-16.97l8.52-8.451c4.705-4.667 12.303-4.637 16.97.068l68.976 69.533 163.441-162.13c4.705-4.667 12.303-4.637 16.97.068l8.451 8.52c4.668 4.705 4.637 12.303-.068 16.97z"></path></svg><p><span>Your subscription has been successful.</span></p></div></div></div></div><p>Close to ten years later, I see YAML in the same somewhat offputting light. It’s not friendly to new people in the same sense <a href="https://git-scm.com/">git</a> isn’t. <a href="https://www.kubernetes.dev/">Kubernetes</a> has almost abused YAML to the point that it has become a punchline. And we’ve stuck ourselves with it for a long time to come too. If Kubernetes is the platform of the future, that means we’ll be using a spec written in 2009 well into the 2030s (and likely beyond).</p><p>I hope that a drop in replacement is possible. The fact that we need tools like <a href="https://github.com/mikefarah/yq/">yq</a> does show that there is some work to be done when it comes to wrangling the YAML beast at scale. In 2009, when the latest version of the YAML spec was written, no one thought of applying pod security policies to massive Kubernetes deployments spread out across data centers the world over. Something better will come along and I hope adopting it isn’t as painful as adopting YAML is.</p><p>Remember, comparing things relatively to like something (YAML vs. XML or YAML vs. JSON) completely throws out the beginner’s journey. Start from the newb and go forward from there. YAML doesn’t. Git doesn’t. Incrementally, YAML is better than XML but, it sucks compared to something like HTML or Markdown (which I can teach to execs and children alike). Yes, balancing machine and human readability is hard. The compromises suck, but, at some point, there’s enough compute to run a process to take in something 100% human-readable and make it 100% machine-readable. In the same sense that compute has become so readily available that we gzip and encrypt almost all HTTP traffic today, I hope we can do the same with systems configuration languages. Move the complexity from the human to code. Computers are better at remembering things and syntax-semantics than humans could ever hope to be.</p><p>There’s always a happy medium between human and machine readability. However, I’d much rather see a human first, <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">80-20</a> approach here where entry-level skills can solve 80% of the markup language’s use cases. That’s the true nirvana, in my opinion. There will always be complexity and a need to understand the tool you’re using. But, YAML gives us an example that there can and should be better things.</p><hr><h4>See also</h4><ul><li><a href="https://chrisshort.net/2019-learnings-2020-expectations/">2019 Learnings, 2020 Expectations</a></li><li><a href="https://chrisshort.net/docker-inc-is-dead/">Docker, Inc is Dead</a></li><li><a href="https://chrisshort.net/live-streaming-on-openshift.tv-and-some-lessons-learned/">Live streaming on openshift.tv and some lessons learned</a></li></ul></article></div></div></div></div>]]>
            </description>
            <link>https://chrisshort.net/fear-and-loathing-in-yaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848511</guid>
            <pubDate>Wed, 21 Oct 2020 15:01:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generative Figures]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24848421">thread link</a>) | @parisianka
<br/>
October 21, 2020 | https://polyfig.app/index.html | <a href="https://web.archive.org/web/*/https://polyfig.app/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p>Each character here is unique! The body shape, colour palette, texture, and paint effect is generated fresh each time. Check out the animation to see how the figures are moulded by merging and smoothing simple polygons <span>👉</span> <span>☝️</span></p><p>Follow me on Twitter <a href="https://twitter.com/georgedoescode" target="_blank">@georgedoescode</a></p><p><strong>Note:</strong> I have no official connection to Studio Arhoj. They have been extremely cool and allowed me to publish this project. Please do not use the images generated for any commercial / physical production purpose.</p></div></header></div></div>]]>
            </description>
            <link>https://polyfig.app/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848421</guid>
            <pubDate>Wed, 21 Oct 2020 14:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attempts to make Python fast]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 145 (<a href="https://news.ycombinator.com/item?id=24848318">thread link</a>) | @Queue29
<br/>
October 21, 2020 | https://sethops1.net/post/attempts-to-make-python-fast/ | <a href="https://web.archive.org/web/*/https://sethops1.net/post/attempts-to-make-python-fast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody" id="content">
        <p>Posted on Hacker News there was an <a href="https://github.com/markshannon/faster-cpython/blob/master/plan.md">Implementation Plan</a>
for making CPython (the official Python implementation) faster. The author claims a 5x speedup
is possible for the low cost of <a href="https://github.com/markshannon/faster-cpython/blob/master/funding.md">$2 million</a> USD.</p>
<p>The four step plan includes</p>
<ul>
<li>creating an adaptive interpreter</li>
<li>improvements to internal types</li>
<li>creating a JIT compiler</li>
<li>extending the JIT compiler</li>
</ul>
<p>We have witnessed other attempts at making Python fast, each achieving their own degree
of success in terms of performance and compatibility. For posterity I started keeping a
list of them here, in no particular order.</p>
<p>(update: added more projects from HN comments - ones that make at least some claim about
performance, thanks!)</p>
<h3 id="pyston">Pyston</h3>
<blockquote>
<p><em>Pyston is a performance-oriented Python implementation built using LLVM and modern JIT techniques.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/pyston/pyston">https://github.com/pyston/pyston</a></li>
</ul>
<h3 id="unladen-swallow">Unladen Swallow</h3>
<blockquote>
<p><em>An optimization branch of CPython, intended to be fully compatible and significantly faster.</em></p>
</blockquote>
<ul>
<li><a href="https://code.google.com/archive/p/unladen-swallow/">https://code.google.com/archive/p/unladen-swallow/</a></li>
</ul>
<h3 id="stackless-python">Stackless Python</h3>
<blockquote>
<p><em>Stackless Python is an enhanced version of the Python programming language. It allows programmers to reap the benefits of thread-based programming without the performance and complexity problems associated with conventional threads.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/stackless-dev/stackless">https://github.com/stackless-dev/stackless</a></li>
</ul>
<h3 id="pypy">PyPy</h3>
<blockquote>
<p><em>A fast, compliant alternative implementation of Python.</em></p>
</blockquote>
<ul>
<li><a href="https://www.pypy.org/">https://www.pypy.org/</a></li>
</ul>
<h3 id="jython">Jython</h3>
<blockquote>
<p><em>Jython is approximately as fast as CPython–sometimes faster, sometimes slower. Because most JVMs–certainly the fastest ones–do long running, hot code will run faster over time.</em></p>
</blockquote>
<ul>
<li><a href="https://www.jython.org/">https://www.jython.org/</a></li>
</ul>
<h3 id="hotpy">HotPy</h3>
<blockquote>
<p><em>The HotPy virtual machine is a high-performance virtual machine for Python.</em></p>
</blockquote>
<ul>
<li><a href="https://code.google.com/archive/p/hotpy/">https://code.google.com/archive/p/hotpy/</a></li>
</ul>
<h3 id="iron-python">Iron Python</h3>
<blockquote>
<p><em>Performance is comparable to CPython - much faster for some things … but slower for other things.</em></p>
</blockquote>
<ul>
<li><a href="https://wiki.python.org/moin/IronPython">https://wiki.python.org/moin/IronPython</a></li>
</ul>
<h3 id="psyco">Psyco</h3>
<blockquote>
<p><em>Psyco is a Python extension module which can greatly speed up the execution of any Python code.</em></p>
</blockquote>
<ul>
<li><a href="http://psyco.sourceforge.net/">http://psyco.sourceforge.net/</a></li>
</ul>
<h3 id="2c-python">2c-python</h3>
<blockquote>
<p><em>Using the generated binary code gives a speed boost from 2 to 4.5 times.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/DarrenRainey/2c-python">https://github.com/DarrenRainey/2c-python</a></li>
</ul>
<h3 id="cython">Cython</h3>
<blockquote>
<p><em>Easily tune readable Python code into plain C performance by adding static type declarations.</em></p>
</blockquote>
<ul>
<li><a href="https://cython.org/">https://cython.org/</a></li>
</ul>
<h3 id="nuitka">Nuitka</h3>
<blockquote>
<p><em>Nuitka is more than 2 times faster than CPython …</em></p>
</blockquote>
<ul>
<li><a href="http://nuitka.net/pages/overview.html">http://nuitka.net/pages/overview.html</a></li>
</ul>
<h3 id="pyc">Pyc</h3>
<blockquote>
<p><em>Pyc is a python compiler intended for high performance computing and programming-in-the-large</em></p>
</blockquote>
<ul>
<li><a href="https://sourceforge.net/projects/pyc/">https://sourceforge.net/projects/pyc/</a></li>
</ul>
<h3 id="shedskin">Shedskin</h3>
<blockquote>
<p><em>For a set of 75 non-trivial programs …, measurements show a typical speedup of 2-200 times over CPython.</em></p>
</blockquote>
<ul>
<li><a href="https://code.google.com/archive/p/shedskin/">https://code.google.com/archive/p/shedskin/</a></li>
</ul>
<h3 id="numba">Numba</h3>
<blockquote>
<p><em>Numba makes Python code fast</em></p>
</blockquote>
<ul>
<li><a href="http://numba.pydata.org/">http://numba.pydata.org/</a></li>
</ul>
<h3 id="parakeet">Parakeet</h3>
<blockquote>
<p><em>Parakeet was a runtime accelerator for an array-oriented subset of Python.</em></p>
</blockquote>
<ul>
<li><a href="https://pypi.org/project/parakeet/">https://pypi.org/project/parakeet/</a></li>
</ul>
<h3 id="cannoli">Cannoli</h3>
<blockquote>
<p><em>Cannoli is a compiler for a subset of Python 3.6.5 and is designed to evaluate the language features of Python that negatively impact performance.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/joncatanio/cannoli">https://github.com/joncatanio/cannoli</a></li>
</ul>
<p>Happy hacking!</p>

      </article></div>]]>
            </description>
            <link>https://sethops1.net/post/attempts-to-make-python-fast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848318</guid>
            <pubDate>Wed, 21 Oct 2020 14:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is a Feature Store?]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24847994">thread link</a>) | @willempienaar
<br/>
October 21, 2020 | https://www.tecton.ai/blog/what-is-a-feature-store/ | <a href="https://web.archive.org/web/*/https://www.tecton.ai/blog/what-is-a-feature-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="5dd09226" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<h5>About the authors: <br>Mike Del Balso, CEO &amp; Co-Founder of <a href="http://tecton.ai/">Tecton</a><br>Willem Pienaar, Creator of <a href="http://feast.dev/">Feast</a></h5>



<hr>











<p>Data teams are starting to realize that operational machine learning requires solving data problems that extend far beyond the creation of data pipelines.</p>



<p>In Tecton’s previous post, <a href="https://www.tecton.ai/blog/devops-ml-data/">Why We Need DevOps for ML Data</a>, we highlighted some of the key data challenges that teams face when productionizing ML systems.</p>



<ul><li>Accessing the right raw data</li><li>Building features from raw data</li><li>Combining features into training data</li><li>Calculating and serving features in production</li><li>Monitoring features in production</li></ul>



<p>Production data systems, whether for large scale analytics or real-time streaming, aren’t new. However, <em>operational machine learning</em> — ML-driven intelligence built into customer-facing applications — is new for most teams. The challenge of deploying machine learning to production for operational purposes (e.g. recommender systems, fraud detection, personalization, etc.) introduces new requirements for our data tools.</p>



<p>A new kind of ML-specific data infrastructure is emerging to make that possible.</p>



<p>Increasingly Data Science and Data Engineering teams are turning towards feature stores to manage the data sets and data pipelines needed to productionize their ML applications. This post describes the key components of a modern feature store and how the sum of these parts act as a force multiplier on organizations, by reducing duplication of data engineering efforts, speeding up the machine learning lifecycle, and unlocking a new kind of collaboration across data science teams.</p>



<figure><table><tbody><tr><td>Quick refresher: in ML, a <strong>feature</strong> is data used as an input signal to a predictive model.</td></tr><tr><td>For example, if a credit card company is trying to predict whether a transaction is fraudulent, a useful feature might be <em>whether the transaction is happening in a foreign country</em>, or <em>how the size of this transaction compares to the customer’s typical transaction</em>. When we refer to a feature, we’re usually referring to the concept of that signal (e.g. “transaction_in_foreign_country”), not a specific value of the feature (e.g. not “transaction #1364 was in a foreign country”).</td></tr><tr><td><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore1.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr></tbody></table></figure>











<p><strong><em>“The interface between models and data”</em></strong></p>



<p>We first introduced feature stores in our blog post describing Uber’s <a href="https://eng.uber.com/michelangelo-machine-learning-platform/">Michelangelo</a> platform. Feature stores have since emerged as a necessary component of the operational machine learning stack.&nbsp;</p>



<p>Feature stores make it easy to:</p>



<ol><li>Productionize new features without extensive engineering support</li><li>Automate feature computation, backfills, and logging</li><li>Share and reuse feature pipelines across teams</li><li>Track feature versions, lineage, and metadata</li><li>Achieve consistency between training and serving data</li><li>Monitor the health of feature pipelines in production</li></ol>



<p>Feature stores aim to solve the full set of data management problems encountered when building and operating operational ML applications.&nbsp;</p>



<p>A feature store is an ML-specific data system that:</p>



<ul><li>Runs data pipelines that <strong>transform</strong> raw data into feature values</li><li><strong>Stores</strong> and manages the feature data itself, and</li><li><strong>Serves</strong> feature data consistently for training and inference purposes</li></ul>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisafeaturestore10.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>To support simple feature management, feature stores provide data abstractions that make it easy to build, deploy, and reason about feature pipelines across environments. For example, they make it easy to define a feature transformation once, then calculate and serve its values consistently across both the development environment (for training on historical values) and the production environment (for inference with fresh feature values).</p>



<p>Feature stores act as a central hub for feature data and metadata across an ML project’s lifecycle. Data in a feature store is used for:</p>



<ul><li>feature exploration and engineering</li><li>model iteration, training, and debugging</li><li>feature discovery and sharing</li><li>production serving to a model for inference</li><li>operational health monitoring</li></ul>



<p>Feature stores bring economies of scale to ML organizations by enabling collaboration. When a feature is registered in a feature store, it becomes available for immediate reuse by other models across the organization. This reduces duplication of data engineering efforts and allows new ML projects to bootstrap with a library of curated production-ready features.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore9.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Effective feature stores are designed to be modular systems that can be adapted to the environment in which they’re deployed. There are five primary components that typically make up a feature store. In the rest of this post, we will walk through those components and describe their role in powering operational ML applications.</p>







<p>There are 5 main components of a modern feature store: Transformation, Storage, Serving, Monitoring, and feature Registry.</p>



<figure><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore3.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>In the following sections we’ll give an overview of the purpose and typical capabilities of each of these sections.</p>



<h2>Serving</h2>



<p>Feature stores serve feature data to models. Those models require a <strong>consistent view of features across training and serving</strong>. The definitions of features used to train a model must exactly match the features provided in online serving. When they don’t match, <a href="https://developers.google.com/machine-learning/guides/rules-of-ml#:~:text=Training%2Dserving%20skew%20is%20a,train%20and%20when%20you%20serve.">training-serving skew</a> is introduced which can cause catastrophic and hard-to-debug model performance problems.</p>



<p><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore5.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>







<p>Feature stores abstract away the logic and processing used to generate a feature, providing users an easy and canonical way to access all features in a company consistently across all environments in which they’re needed.</p>



<p>When retrieving data offline (i.e. for training), feature values are commonly accessed through notebook-friendly feature store SDKs. They provide point-in-time correct views of the state of the world for each example used to train a model (a.k.a. “<a href="https://www.tecton.ai/blog/time-travel-in-ml/"><strong>time-travel</strong></a>”).</p>



<p>For online serving, a feature store delivers a single vector of features at a time made up of the freshest feature values. Responses are served through a high-performance API backed by a low-latency database.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisafeaturestore11.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<h2>Storage</h2>



<p>Feature stores persist feature data to support retrieval through feature serving layers. They typically contain both an online and offline storage layer to support the requirements of different feature serving systems.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore8.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Offline storage layers are typically used to store months’ or years’ worth of feature data for training purposes. Offline feature store data is often stored in data warehouses or data lakes like S3, BigQuery, Snowflake, Redshift. Extending an existing data lake or data warehouse for offline feature storage is typically preferred to prevent data silos.</p>



<p>Online storage layers are used to persist feature values for low-latency lookup during inference. They typically only store the latest feature values for each entity, essentially modeling the current state of the world. Online stores are usually eventually consistent, and do not have strict consistency requirements for most ML use cases. They are usually implemented with key-value stores like DynamoDB, Redis, or Cassandra.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore6.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Feature stores use an entity-based data model where each feature value is associated with an entity (e.g. a user) and a timestamp. An entity-based data model provides minimal structure to support standardized feature management, fits naturally with common feature engineering workflows, and allows for simple retrieval queries in production.</p>



<h2>Transformation</h2>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore2.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Operational ML applications require regular processing of new data into feature values so models can make predictions using an up-to-date view of the world. Feature stores both manage and orchestrate data transformations that produce these values, as well as ingest values produced by external systems. Transformations managed by feature stores are configured by definitions in a common feature registry (described below).</p>



<figure><p>Most teams getting started with feature stores already have existing data pipelines producing feature values. This makes it very important for feature stores to be gradually adoptable and have first class integrations with existing data platforms, allowing teams to immediately operationalize existing ETL pipelines for their ML use cases.</p></figure>



<p>Feature stores commonly interact with three main types of data transformations:</p>







<figure><table><tbody><tr><td data-align="left">Feature Type</td><td>Definition</td><td>Common input data source</td><td data-align="left">Example</td></tr><tr><td data-align="left">Batch Transform</td><td>Transformations that are applied only to data at rest</td><td>Data warehouse, data lake, database</td><td data-align="left">User country, product category</td></tr><tr><td data-align="left">Streaming Transform</td><td>Transformations that are applied to streaming sources</td><td>Kafka, Kinesis, PubSub</td><td data-align="left"># of clicks per vertical per user in last 30 minutes, # of views per listing in past hour</td></tr><tr><td data-align="left">On-demand transform</td><td>Transformations that are used to produce features&nbsp; based on data that is only available at the time of the prediction. These features cannot be pre-computed.</td><td>User-facing application</td><td data-align="left">Is the user currently in a supported location?<br>Similarity score between listing and search query</td></tr></tbody></table></figure>



<p>A key benefit is to make it easy to use different types of features together in the same models.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisafeaturestore12.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Models need access to fresh feature values for inference. Feature stores accomplish this by regularly recomputing features on an ongoing basis. Transformation jobs are orchestrated to ensure new data is processed and turned into fresh new feature values. These jobs are executed on data processing engines (e.g. Spark or Pandas) to which the feature store is connected.&nbsp;</p>



<p>Model development introduces different transformation requirements. When iterating on a model, new features are often engineered to be used in training datasets that correspond to historical events (e.g. all purchases in the past 6 months). To support these use cases, feature stores make it easy to run “backfill jobs” that generate and persist historical values of a feature for training. Some feature stores automatically backfill newly registered features for preconfigured time ranges for registered training datasets.</p>



<p>Transformation code is reused across environments preventing …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tecton.ai/blog/what-is-a-feature-store/">https://www.tecton.ai/blog/what-is-a-feature-store/</a></em></p>]]>
            </description>
            <link>https://www.tecton.ai/blog/what-is-a-feature-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847994</guid>
            <pubDate>Wed, 21 Oct 2020 14:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to Avoid When Contributing to Open-Source Projects]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24847824">thread link</a>) | @lanecwagner
<br/>
October 21, 2020 | https://qvault.io/2020/10/21/6-things-to-avoid-when-contributing-to-open-source-projects/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/10/21/6-things-to-avoid-when-contributing-to-open-source-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>With <a aria-label="#HacktoberFest (opens in a new tab)" href="https://hacktoberfest.digitalocean.com/" target="_blank" rel="noreferrer noopener nofollow">#HacktoberFest</a> being a thing, there has been an influx of devs desperately trying to contribute to their favorite Open-Source projects. Unfortunately, many of these pull requests have been a waste of time, with the maintainers ultimately unable to use the contributions. Maintainers don’t want to waste their time reviewing bad PRs, and contributors don’t want to waste their time writing code that will never make it into production.</p>



<p>Let’s take a look at some common pitfalls that developers fall prey to when working on an open-source project. As a side note, we recently open-sourced the <a href="https://app.qvault.io/">Qvault</a> front-end, so take a look<a href="https://github.com/qvault/webapp" rel="noopener"> at that</a> if you want to help out.</p>



<h2>1. Pull Requests Should Handle ONE Thing</h2>



<p>Don’t open a PR like this:</p>



<ul><li>Fixes bug #543</li><li>Adds new linting rules</li><li>Includes feature #456</li></ul>



<p>Your PR should do <em>one thing</em>. Small diffs decrease the cognitive load of the reviewer and make it easier to get your code into the main branch. If you have beef with multiple issues in a project then open multiple PRs.</p>



<h2>2. Don’t Break Consistency</h2>



<p>This one happens the most often to me in my own projects. Well-intentioned developers open pull requests with any of the following annoyances:</p>



<ul><li>Omitting semicolons in a project that prefers them</li><li>Using spaces in a project that has clearly been using tabs</li><li>Introducing snake_case in a camelCase repo</li></ul>



<p>When you contribute to an existing project, use the existing styling. No one gives two hoots about your preference on the “<a href="https://www.youtube.com/watch?v=SsoOG6ZeyUI" target="_blank" aria-label="tabs vs spaces (opens in a new tab)" rel="noreferrer noopener nofollow">tabs vs spaces</a>” debate in the context of this pull request.</p>



<p>If you think styling needs to change, see points #1 and #3.</p>



<h2>3. Don’t Start Work Without Approval</h2>



<p>If you hop into a Github repo and find something you don’t like, don’t immediately open a pull request. Follow these steps instead:</p>



<ul><li>Is there already an issue logged? If not, make one.</li><li>If there is an issue, reach out to the maintainers (just comment on the issue) and let them know you want to work on it, and give a quick overview of how you will address it.</li><li>Assuming you have their blessing, start work on your PR.</li></ul>



<p>This will help mitigate the creation of pointless PRs that will never be accepted on the basis of a flawed premise.</p>



<h2>4. Don’t Re-open Known Problems/Solutions</h2>



<p>Some codebases have thousands of open issues, take the <a aria-label="Go language (opens in a new tab)" href="https://github.com/golang/go" target="_blank" rel="noreferrer noopener nofollow">Go language</a> project, or the <a aria-label="nocode repository (opens in a new tab)" href="https://github.com/kelseyhightower/nocode" target="_blank" rel="noreferrer noopener nofollow">nocode repository</a> as an example. No one wants to read your duplicate issue or review your duplicate pull request. Make sure there isn’t an existing open <em>or closed</em> issue for what you are trying to address.</p>



<h2>5. Squash Those Commits</h2>



<p>Not every project will require (or care) about <a aria-label="commit squashing (opens in a new tab)" href="https://github.com/wprig/wprig/wiki/How-to-squash-commits" target="_blank" rel="noreferrer noopener nofollow">commit squashing</a>. That said, there are no projects that require <em>not</em> squashing commits. To be on the safe side just give ’em a squash.</p>



<h2>6. Be Meaningful</h2>



<p>Rewording documentation and other frivolous changes make you look like <a href="https://github.com/whatwg/html/pulls?q=is%3Apr+is%3Aclosed+label%3Aspam" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">these assholes</a>. This particularly <a href="https://github.com/whatwg/html/pull/6075" target="_blank" aria-label="atrocious example (opens in a new tab)" rel="noreferrer noopener nofollow">atrocious example</a> is not only scoped to pointless documentation changes but actually makes the documentation <em>worse</em>.</p>
		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/10/21/6-things-to-avoid-when-contributing-to-open-source-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847824</guid>
            <pubDate>Wed, 21 Oct 2020 13:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning to Decapsulate Integrated Circuits Using Acid Deposition]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24847500">thread link</a>) | @garaetjjte
<br/>
October 21, 2020 | https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/ | <a href="https://web.archive.org/web/*/https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>20 Oct 2020
  </span></p><p>In this post:</p>

<ul>
  <li><a href="#existing-methodologies">Known decapping methodologies</a></li>
  <li><a href="#personal-safety">Personal safety</a></li>
  <li><a href="#my-own-experiments">My experiments</a>
    <ul>
      <li><a href="#tools-and-materials">Tools and materials</a></li>
      <li><a href="#attempt-1-sand-down-the-epoxy-packaging">Failure: Sand down the packaging</a></li>
      <li><a href="#attempt-2-dremel--69-nitric-acid--gentle-acetone-bath">Limited success: Nitric acid + acetone bath</a></li>
      <li><a href="#attempt-3-dremel--69-nitric-acid--acetone-syringe">Failure: Nitric acid + acetone syringe</a></li>
      <li><a href="#attempt-4-dremel--69-nitric-acid--acetone-syringe-epoxy-removal--ultrasonic-methanol-cleanup">Failure: Nitric acid + acetone syringe + ultrasonic methanol bath</a></li>
      <li><a href="#attempt-5-dremel--69-nitric-acid--acetone-syringe--ultrasonic-acetone-cleanup">Success: Nitric acid + acetone syringe + ultrasonic acetone bath</a></li>
      <li><a href="#attempt-6-dremel--69-nitric-acid--room-temp-nitric-acid--acetone-syringe--ultrasonic-acetone-cleanup">Pointless: Bath the IC in room-temp nitric acid before cleanup</a></li>
      <li><a href="#attempt-7-dremel--98-sulfuric-acid--69-nitric-acid--ultrasonic-acetone-bath">Success: Using a mix of Sulfuric and Nitric acids</a></li>
    </ul>
  </li>
  <li><a href="#taking-pictures-under-the-microscope">How I took the silicon die pictures</a></li>
  <li><a href="#successful-imaging">Pretty pictures of silicon dies</a></li>
  <li><a href="#resources">Resources</a></li>
</ul>

<p>I’ve been looking to try my hand at IC decapsulation for years, and finally got
the time to do it. The process took plenty of trial and error, so this post will
document most of my failures and successes, and detail the methodologies used for
each attempt. These are most of the ICs I worked on throughout the process:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/macro-all-manipulated-ics.jpg" alt="Most ICs I experimented on"></p>

<p>A typical chip is built as a silicon die, connected to its leads/contacts through
bonding wires, and encapsulated in resin for protection.</p>

<p>Of course, there are other ICs that use different designs and encapsulation
materials: mostly metal and plastics. But the epoxy-based design is extremely
common, so we’ll be focusing on it.</p>

<p>This picture of a DIP package -<a href="https://en.wikipedia.org/wiki/File:DIP_package_sideview.PNG">courtesy of Wikipedia</a>-
explains it very well:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/3rd-party/DIP_package_sideview.png" alt="Generic IC diagram"></p>

<p>The decapsulation/decapping of Integrated Circuits, also known as “delidding”, is
nothing new.</p>

<p>It’s used in the industry to debug hardware issues, reverse engineer chips, verify
the authenticity of parts, and other tasks that require access to the underlying
circuitry.</p>

<p>That’s why there’s plenty of commercial services that will decapsulate your ICs
using expensive and dedicated equipment.
I’ve linked a couple of them in <a href="#resources">the bibliography</a>.
But, without having any idea how much they cost or how long they take, I can’t
imagine them being an option for the average hacker.</p>

<p>Hackers and smaller companies generally decap Integrated Circuits to identify
counterfeits, gain a very rudimentary understanding of the parts comprising them,
or just to share the pretty pictures of the silicon die.
For those cases, a DIY process is generally good enough.</p>

<p>Decapping/delidding has also been used by hackers for more fun purposes, such as
<a href="https://www.bunniestudios.com/blog/?page_id=40">unsetting efuses from production hardware to extract and/or override their firmware</a>,
private keys, etc.
So there are cases where a commercial-level result can be worth it.</p>

<p>I’ve been wanting to try my hand at decapping ICs for years, for no other purpose
than to satiate my curiosity. I’ve finally had the time to get to it, so this
post will describe the methods I tried and the hurdles I encountered.</p>



<p>The biggest factor to decide which method is best for your project is whether
or not you need the chip to still work after it’s been decapsulated. That means
not destroying or disconnecting the die, bonding wires, external contact points,
etc. so you can still use the chip after the process is complete.</p>

<p>Here’s a list of the most common options.</p>

<p>Destructive methods:</p>

<ul>
  <li><a href="https://www.experimental-engineering.co.uk/2016/02/20/ic-decapping-the-process/">Burn the encapsulation to hell</a> using a blowtorch</li>
  <li><a href="http://jg.sn.sg/decap/">Full wet chemical decapsulation</a>: Bath the entire chip in acid to remove all encapsulation, leads, bonds, etc.</li>
</ul>

<p>Non-destructive methods:</p>

<ul>
  <li>Selective wet chemical decapsulation:
    <ul>
      <li><a href="https://ieeexplore.ieee.org/document/1707865">Rubber gaskets + acid yet for targetted decapping</a></li>
      <li><a href="https://www.youtube.com/watch?v=mT1FStxAVz4">Manual acid deposition</a>:
Repeatedly apply drops of acid on the IC’s target area, and rinse the acid
residue and weakened encapsulation</li>
    </ul>
  </li>
  <li><a href="https://bseteq.com/decapsulation/plasma-decap/plaser-plasma-decapsulation-system/">Plasma etching</a>
uses expensive equipment to create plasma, make it react with the encapsulation,
and drain it away</li>
</ul>

<p>In this post we’re gonna focus on the manual acid deposition method, to achieve
non-destructive decapsulation at a reasonable cost.</p>



<p>First of all, let me preface this safety talk with an important disclaimer:
I HAVE NO IDEA WHAT I’M DOING. My thing is firmware and electronics, not chemistry.</p>

<p>PLEASE, do not assume the safety measures discussed here are valid or enough to
protect yourself. Do your own research, follow any and all measures you deem
appropriate, and remain paranoid all along the process.</p>

<p>We’re dealing with very dangerous chemicals. If you decide to replicate the
experiments it’s at your own peril.</p>

<p>Here are more authoritative sources of safety information for a project like this.
Review as much of this info as you can, and take it with the seriousness it requires:</p>

<ul>
  <li><a href="https://safetyservices.ucdavis.edu/safetynet/safe-use-of-nitric-acid">UCDavis docs on the safe use of nitric acid</a></li>
  <li><a href="https://www.3m.com/3M/en_US/safety-centers-of-expertise-us/respiratory-protection/respirator-selection/">3M respiratory protection selection guide</a></li>
  <li><a href="https://www.cdc.gov/niosh/topics/nitric-acid/default.html">CDC resources on the use of nitric acid</a></li>
  <li><a href="https://www.youtube.com/watch?v=ftACSEJ6DZA">NileRed’s “Chemistry is Dangerous” introduction to personal protection when working with chemicals</a></li>
</ul>

<p>After doing enough research to feel comfortable with the risks involved, I settled
for following these measures:</p>

<ul>
  <li>Run all experiments outside, with all nearby windows closed, and never accessing
the area without using PPE. I might invest in a fume hood in the future, either
commercial or DIY</li>
  <li>Wear chemical splash goggles. They should protect your eyes from droplets
coming from any direction. If they become uncomfortable or fog up, do not remove
them or pull them off your face in the working area</li>
  <li>Wear a respirator mask with filters that are appropriate for chemical fumes.
Preferably a full face mask, to avoid acid splashes</li>
  <li>Wear gloves that are appropriate for the acids you’re dealing with. Nitrile gloves
should NOT be used to work with nitric acid; especially fuming (98%+) nitric acid.
Long, thick neoprene-based gloves are best for Nitric, but make delicate tasks
difficult. I settled for wearing a thick neoprene glove on my non-dominant hand,
and a vinyl glove on my dominant hand for the more delicate work. When touching
any surface that’s hot or has been in touch with acid, I use the neoprene glove</li>
  <li>Expose as little of your skin as possible: Wear shoes, trousers (not shorts),
long sleeves… Preferably use a lab coat, so you can remove the acid-splashed
clothing without dragging it over your face</li>
  <li>Never mix chemicals without fully understanding the outcome to expect. Keep
different chemicals as far apart from each other as possible. Keep the smallest
possible amount of dangerous chemicals in the working area</li>
  <li>Be prepared for the worst:
    <ul>
      <li>Keep enough sodium bicarbonate at hand to neutralize acid spills and leftover acid.
Keep in mind that neutralizing acid with bicarb will give off heat, and the bubbling
could be dangerously vigorous for significant amounts. Expect the possibility of
a spill during the neutralization process</li>
      <li>Keep enough water at hand to dilute chemicals in case of spills, splashes, etc.</li>
      <li>Understand what are the recommended procedures in case of any given chemical
contacting your skin, eyes, etc. Eyes are generally the most sensitive to chemical
splashes, as they can be permanently damaged in seconds; they’re also the most
difficult to clean up, so be particularly careful with them and have a plan of
action in case the worst happens</li>
    </ul>
  </li>
</ul>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/ppe.jpg" alt="Picture of my PPE"></p>



<p>These describe failures and successes, and what I learned along the way.
Keep in mind that most resources I’ve found recommend using fuming nitric acid
(86%+).</p>

<p>I was not able to source fuming nitric acid, so I used concentrated nitric
(69%) instead. That could account for some of the problems I’m about to describe,
but worked fine once I found the most fitting methodology.</p>



<p>Chemicals I used during my experiments:</p>

<ol>
  <li>Concentrated (69%) Nitric Acid</li>
  <li>100% Sodium bicarbonate - Bought on Amazon</li>
  <li>98% methanol - From a hardware store</li>
  <li>Acetone - From a hardware store</li>
  <li>Water - Either tap water or regular distilled water from a grocery store</li>
</ol>

<p>I also ran a couple of tests using Sulfuric Acid, both standalone and mixed with
the Nitric, but the results were not very promising. Probably because of the
encapsulation material used in my ICs. These are the acids I used:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/all-chemicals.jpg" alt="Both bottles of acid used during my experiments"></p>

<p>Necessary equipment:</p>

<ol>
  <li>Dremel
    <ul>
      <li>I’ve found <a href="https://jcjc-dev.com/assets/ic-decapping/jc/dremel-diamond-pointy-bit.jpg">this off-brand pointy diamond bit</a>
to work great</li>
    </ul>
  </li>
  <li>Hot plate</li>
  <li>High-temperature and acid safe recipient
    <ul>
      <li>Tried using ceramic recipients and they worked well enough, but it was hard
to maintain a stable temperature outside using my hot plate</li>
      <li>Graphite ingot molds ended up being better at conducting heat (hence
maintaining a reasonably stable temperature outside) and providing easy access
to the IC inside</li>
    </ul>
  </li>
  <li>Plastic tweezers</li>
  <li>A syringe, or preferably an assortment of them</li>
</ol>

<p>Other very useful equipment:</p>

<ol>
  <li>An Erlenmeyer flask to keep a small amount of acid in a stable container</li>
  <li>Pipettes:
    <ul>
      <li>10ml pipette to transfer acid from its primary container to the flask</li>
      <li>1ml pipette to drop acid on the ICs</li>
    </ul>
  </li>
  <li>Beakers:
    <ul>
      <li>A small one for acetone</li>
      <li>A large one for water, to rinse tools</li>
    </ul>
  </li>
  <li>Thermocouple to monitor the temperature of the hot plate and IC container</li>
  <li>Tongs to move the hot ceramic/graphite container</li>
  <li>Ultrasonic cleaner. Explained later</li>
</ol>

<p>This picture shows most of the equipment used for the most successful method:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/ultrasonic-acetone-all-equipment.jpg" alt="All the equipment used for the most successful method"></p>

<h2 id="attempt-1-sand-down-the-epoxy-packaging">Attempt 1: Sand down the epoxy packaging</h2>

<p>This is how the project started. I just got a new microscope, met with a couple
of good friends, and we started looking at some random samples. Blood, dust, etc.</p>

<p>Then we decided to take a look at some random IC. We were not looking to
see anything useful or complete; just an overall image of the silicon die in
an IC, so I sanded down a microcontroller and we took a look. The result, as
expected, was absolute garbage:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/macro-sanded-pic.jpg" alt="Macro: Sanded down IC"></p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/micro-sanded-pic.jpg" alt="Micro: Sanded down silicon die"></p>

<p>Well, that went exactly as terribly as expected… Time to go down the rabbit hole.</p>

<h2 id="attempt-2-dremel--69-nitric-acid--gentle-acetone-bath">Attempt 2: Dremel + 69% Nitric Acid + Gentle acetone bath</h2>

<p>Steps:</p>

<ol>
  <li>Drill a pocket on the top of the epoxy package so the acid does not spill over
to the leads.</li>
  <li>Place IC on a ceramic or graphite recipient, on top of the hot plate. Attach
a thermocouple to the recipient to monitor its temperature</li>
  <li>When the temperature is appropriate (around 100 degrees C), drop one or 2 drops
of acid in the epoxy pocket we just drilled. Wait until there is no more acid,
and continue to apply acid when that happens</li>
  <li>Every once in a while, grab the IC with plastic tweezers, dip it in acetone
and move it around to remove the reacted epoxy</li>
</ol>

<p>Results: <strong>Terrible</strong></p>

<p>A simple acetone bath and some stirring are not enough to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/">https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/</a></em></p>]]>
            </description>
            <link>https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847500</guid>
            <pubDate>Wed, 21 Oct 2020 13:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Millennials are not getting married]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24847433">thread link</a>) | @koolhead17
<br/>
October 21, 2020 | https://www.allendowney.com/blog/2020/10/21/millennials-are-not-getting-married/ | <a href="https://web.archive.org/web/*/https://www.allendowney.com/blog/2020/10/21/millennials-are-not-getting-married/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

									
<article id="post-498">

	
	
	<!-- .entry-header -->

			<div>
				
<p>In 2015 I wrote a paper called “<a href="http://conference.scipy.org/proceedings/scipy2015/allen_downey.html" target="_blank" rel="noreferrer noopener">Will Millennials Ever Get Married?</a>” where I used data from the National Survey of Family Growth (NSFG) to estimate the age at first marriage for women in the U.S, broken down by decade of birth. &nbsp;</p>



<p>I found that women born in the 1980s and 90s were getting married later than previous cohorts, and I generated projections that suggest they are on track to stay unmarried at substantially higher rates.</p>



<p>Here are the results from that paper, based on 58 488 women surveyed between 1983 to 2015:</p>



<figure><img loading="lazy" width="1024" height="683" src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png" alt="" srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3.png 1800w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3.png 1800w" data-lazy-src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Percentage of women ever married, based on data up to 2015.</figcaption></figure>



<p>Each line represents a cohort grouped by decade of birth.  For example, the top line represents women born in the 1940s.</p>



<p>The colored segments show the fraction of women who had ever been married as a function of age.  For example, among women born in the 1940s, 82% had been married by age 25.  Among women born in the 1980s, only 41% had been married by the same age.</p>



<p>The gray lines show projections I generated by assuming that going forward each cohort would be subject to the <a href="https://en.wikipedia.org/wiki/Survival_analysis#Hazard_function_and_cumulative_hazard_function">hazard function</a> of the previous cohort. This method is likely to overestimate marriage rates.</p>



<p>These results show two trends:</p>



<ul><li>Each cohort is getting married later than the previous cohort.</li><li>The fraction of women who never marry is increasing from one cohort to the next.  </li></ul>



<h3>New data</h3>



<p>Yesterday the National Center for Health Statistics (NCHS) released a&nbsp;<a rel="noreferrer noopener" href="https://www.cdc.gov/nchs/nsfg/nsfg_2017_2019_puf.htm" target="_blank">new batch of data from surveys conducted in 2017-2019</a>. &nbsp;So we can compare the predictions from 2015 with the new data, and generate updated predictions.</p>



<p>The following figure shows the predictions from the previous figure, which are based on data up to 2015, compared to the new curves based on data up to 2019, which includes 70 183 respondents.</p>



<figure><img loading="lazy" width="1024" height="683" src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png" alt="" srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4.png 1800w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4.png 1800w" data-lazy-src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Percentage of women ever married, based on data up to 2019, <br>compared to predictions based on data up to 2015.</figcaption></figure>



<p>For women born in the 1980s, the fraction who have married is almost exactly as predicted.  For women born in the 1990s, it is substantially lower.  </p>



<h3>New projections</h3>



<p>The following figure shows projections based on data up to 2019.</p>



<figure><img loading="lazy" width="1024" height="683" src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png" alt="" srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4.png 1800w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4.png 1800w" data-lazy-src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Percentage of women ever married, based on data up to 2019,<br>with predictions based on data up to 2019.</figcaption></figure>



<p>The vertical dashed lines show the ages where we have the last reliable estimate for each cohort.  The following table summarizes the results at age 28:</p>



<figure><table><thead><tr><th>Decade of birth</th><th>1940s</th><th>1950s</th><th>1960s</th><th>1970s</th><th>1980s</th><th>1990s</th></tr></thead><tbody><tr><td>% married <br>before age 28</td><td>87%</td><td>80%</td><td>70%</td><td>63%</td><td>55%</td><td>31%</td></tr></tbody></table><figcaption>Percentage of women married by age 28, grouped by decade of birth.</figcaption></figure>



<p>The percentage of women married by age 28 has dropped quickly from each cohort to the next, by about 11 percentage points per decade.  </p>



<p>The following table shows the same percentage at age 38; the last value, for women born in the 1990s, is a projection based on the data we have so far.</p>



<figure><table><thead><tr><th>Decade of birth</th><th>1940s</th><th>1950s</th><th>1960s</th><th>1970s</th><th>1980s</th><th>1990s</th></tr></thead><tbody><tr><td>% married <br>before age 38</td><td>92%</td><td>88%</td><td>85%</td><td>80%</td><td>68%</td><td><em>51%</em></td></tr></tbody></table><figcaption>Percentage of women married by age 38, grouped by decade of birth.</figcaption></figure>



<p>Based on current trends, we expect barely half of women born in the 1990s to be married before age 38.</p>



<p>Finally, here are the percentages of women married by age 48; the last two values are projections.</p>



<figure><table><thead><tr><th>Decade of birth</th><th>1940s</th><th>1950s</th><th>1960s</th><th>1970s</th><th>1980s</th><th>1990s</th></tr></thead><tbody><tr><td>% married <br>before age 48</td><td>&gt;93%</td><td>&gt;90%</td><td>88%</td><td>83%</td><td><em>72%</em></td><td><em>58%</em></td></tr></tbody></table><figcaption>Percentage of women married by age 48, grouped by decade of birth.</figcaption></figure>



<p>Based on current trends, we expect women born in the 1980s and 1990s to remain unmarried at rates substantially higher than previous generations.</p>



<p>Projections like these are based on the assumption that the future will be like the past, but of course, things change.  In particular:</p>



<ul><li>These data were collected before the COVID-19 pandemic. Marriage rates in 2020 will probably be lower than predicted, and the effect could continue into 2021 or beyond.</li><li>However, as economic conditions improve in the future, marriage rates might increase.</li></ul>



<p>We’ll find out when we get the next batch of data in October 2022.</p>



<p><a href="https://github.com/AllenDowney/MarriageNSFG" target="_blank" rel="noreferrer noopener">The code I used for this analysis is in this GitHub repository</a>.</p>


							</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
				</div></div>]]>
            </description>
            <link>https://www.allendowney.com/blog/2020/10/21/millennials-are-not-getting-married/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847433</guid>
            <pubDate>Wed, 21 Oct 2020 13:05:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RuboCop v1.0 Released]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24846902">thread link</a>) | @kpsnow
<br/>
October 21, 2020 | https://metaredux.com/posts/2020/10/21/rubocop-1-0.html | <a href="https://web.archive.org/web/*/https://metaredux.com/posts/2020/10/21/rubocop-1-0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
  <p>If at first you don’t succeed, call it version 1.0.</p>
</blockquote>

<p>RuboCop’s development started exactly 7 and half years ago. I made
<a href="https://github.com/rubocop-hq/rubocop/commit/afbead34db54506c12a21dbd4ce04fada0f8b9a4#diff-bc37d034bad564583790a46f19d807abfe519c5671395fd494d8cce506c42947">the first
commit</a>
on April 21, 2012. That’s a lot of time in general, but even more in
the fast moving world of IT. During this long period we’ve racked up some
impressive numbers:</p>

<ul>
  <li><strong>9905</strong> commits</li>
  <li><strong>152</strong> releases</li>
  <li>around <strong>3500</strong> closed issues</li>
  <li>almost <strong>5000</strong> merged pull requests</li>
  <li>over <strong>120 million</strong> downloads</li>
  <li>over <strong>200</strong> publicly available related gems (extensions, custom configurations, etc)</li>
  <li>over <strong>700</strong> contributors</li>
</ul>

<p>I never expected any of this on April 21, 2012. If there’s a person truly
surprised by the success of RuboCop that’d be me. But wait, there’s more!
We also reached some important milestones in the last couple of years:</p>

<ul>
  <li>Created the <a href="https://github.com/rubocop-hq">RuboCop HQ organization</a> that became the home for RuboCop, the community style guides, and many popular RuboCop extensions</li>
  <li>Extracted the Rails cops to a separate gem (<code>rubocop-rails</code>)</li>
  <li>Extracted the performance cops to a separate gem (<code>rubocop-performance</code>)</li>
  <li>Extracted the AST-related functionality to a separate gem (<code>rubocop-ast</code>)</li>
  <li>Created new extensions focused on Rake (<code>rubocop-rake</code>) and Minitest (<code>rubocop-minitest</code>)</li>
  <li>Made significant improvements to RuboCop’s code formatting capabilities</li>
  <li>Reworked the cop API</li>
  <li>Switched to safe-only cops by default</li>
  <li>Introduced the notion of “pending” cops</li>
  <li>Created a brand new <a href="https://docs.rubocop.org/">documentation site</a></li>
  <li>Provided more polished versions of the community style guides over at <a href="https://rubystyle.guide/">https://rubystyle.guide</a></li>
</ul>

<p>One thing eluded us, though - a “stable” RuboCop release. Today this finally changes with
RuboCop 1.0!<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>There’s nothing ground-breaking about the new RuboCop release - it’s almost the same as RuboCop 0.93.1 that
preceded it. I believe the only change, that most of you are going to notice, is that all cops that used to be
“pending” are now enabled by default, which is in line with our release policy. No new cops will be enabled
by default until RuboCop 2.0.</p>

<p>The big news for end users and maintainers of extensions is that we’re finally embracing fully Semantic Versioning, which
should make the upgrade process simpler (painless?) for everyone. Going forward the following things will happen only on major releases:</p>

<ul>
  <li>enabling of new cops</li>
  <li>changes to the default cop configuration</li>
  <li>breaking API changes</li>
</ul>

<p>It’s really funny that I felt for at least a couple of years that we were very close to the 1.0
release, only to come up with more and more things I wanted to include in it. I believe <a href="https://rubykaigi.org/2018/presentations/bbatsov.html">I first spoke</a>
about my intentions to ship RuboCop 1.0 at RubyKaigi 2018 and back then I truly believed this was bound to happen in the next
6 months. Classic example of planning in the software development world, right?</p>

<p>Many people urged me for years to label a random release as 1.0 with
the argument that if some software is useful and widely used than it
probably deserves that magic moniker. It’s not a bad argument and I
totally understood the perspective of those people. I, however, was
not convinced as for me version 1.0 also stands for “we got to a place
we consider feature complete and aligned with our vision”.  Needless
to say - the vision we (RuboCop’s team) had was quite ambitious and it took us
a while to make it a reality.</p>

<p>I cannot begin to explain how happy I am that we got here, and I can
assure you that it wasn’t easy.  Over the years RuboCop had its ups
and downs, it got a lot of praise, but also a lot of flak.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Some
days I was super pumped and motivated to work on it, on other days I
couldn’t stand to think about it.  Working on popular OSS projects is
one of the most rewarding and most frustrating experiences that one
can have.  I was (un)fortunate enough to be involved in a few of those
(RuboCop, CIDER, nREPL, Projectile, Emacs Prelude, etc) and each one
was a crazy roller-coaster ride.</p>

<p>I find it funny how my role in RuboCop evolved with time. Originally I
used to write mostly code, these days I write mostly tickets,
issue/code review comments and documentation. Often I feel more like a
project manager rather than a programmer. There was a time when I was
super happy to see a PR and I’d immediately respond to it, now I can’t
keep up with all the PRs. In fact, our entire team can’t keep up with
them, so consider this my apology that it sometimes takes a while to
get feedback on your suggestions. I’ll even admit that I rarely read
issue tickets these days as there are so many of them and it’s
impossible for me to respond to all of them. I’ve just learned that
important tickets always get noticed, if not by me than by someone else from our
fantastic team.</p>

<p>I want to extend special thanks to RuboCop’s core team, as we would have never gotten so far without all those amazing people
working tirelessly on the project:</p>

<ul>
  <li><a href="https://github.com/jonas054">Jonas Arvidsson</a></li>
  <li><a href="https://github.com/yujinakayama">Yuji Nakayama</a> (retired)</li>
  <li><a href="https://github.com/edzhelyov">Evgeni Dzhelyov</a> (retired)</li>
  <li><a href="https://github.com/drenmi">Ted Johansson</a></li>
  <li><a href="https://github.com/pocke">Masataka Kuwabara</a></li>
  <li><a href="https://github.com/koic">Koichi Ito</a></li>
  <li><a href="https://github.com/darhazer">Maxim Krizhanovski</a></li>
  <li><a href="https://github.com/bquorning">Benjamin Quorning</a></li>
  <li><a href="https://github.com/marcandre">Marc-André Lafortune</a></li>
</ul>

<p>You rock, guys!</p>

<p>Jonas, in particular, deserves just as much credit for RuboCop existing today as me. He was the first contributor to RuboCop and he
pushed me to get RuboCop to the state where it got critical mass, mindshare and some traction. It’s a long story for another day and another article.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>Koichi also deserves a special mention for his tireless work and incredible dedication to RuboCop and its users over the years! And for his great karaoke skills!
He has also been a fantastic head maintainer for key RuboCop extensions like <code>rubocop-rails</code>, <code>rubocop-performance</code> and <code>rubocop-minitest</code>.</p>

<p>Last, but not least - another round of big thanks for all the people who contributed to RuboCop in any capacity over the years! RuboCop is all of you!
Keep those contributions coming!</p>

<p>Some closing notes:</p>

<ul>
  <li>As mentioned above, recently we’ve extracted RuboCop’s AST-related logic to the <a href="https://github.com/rubocop-hq/rubocop-ast">rubocop-ast</a> gem, that’s going to be very handy for everything looking to supercharge
<a href="https://github.com/whitequark/parser">parser</a>’s API. I’d love to see more tools using it, as I think we really managed to simplify the interaction with an AST. Work on the new gem is led by the awesome Marc-André Lafortune. By the way, he released <code>rubocop-ast</code> 1.0 today! We have some cause for double celebration!</li>
  <li>The cop API was completely reworked recently by Marc-André. He did some truly fantastic work there! Check out the <a href="https://docs.rubocop.org/rubocop/v1_upgrade_notes.html">upgrade notes</a> if you maintain any RuboCop extensions, as the legacy API will be removed
in RuboCop 2.0.</li>
  <li>We’ve made some changes to how department names are calculated that might affect some extensions. Read more about them <a href="https://github.com/rubocop-hq/rubocop/pull/8490">here</a>.</li>
  <li>Check out the <a href="https://github.com/rubocop-hq/rubocop/releases/tag/v1.0.0">release notes</a> for all the details.</li>
  <li><code>rubocop-rspec</code> is currently not compatible with RuboCop 1.0, but we’re working on this. You can follow the progress on that front <a href="https://github.com/rubocop-hq/rubocop-rspec/issues/1051">here</a>.</li>
</ul>

<p>And that’s a wrap!</p>

<p>I feel a bit sorry for disappointing everyone who hoped we’d make it
to RuboCop 0.99, before cutting RuboCop 1.0. We did our best and we
had a great 0.x run, but we ran out of things to do.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> :-) On the bright side - now
I can finally say that I’ve got 99 problems (and 200 open issues), but cutting RuboCop 1.0 ain’t one.</p>

<p>Enjoy RuboCop 1.0 and share with us your feedback about it! Our focus now shifts to RuboCop 1.1, and I hope that we’ll be dropping
new major releases rather infrequently going forward (although RuboCop 2.0 will probably arrive in less than 7 years). Thanks for your help, love, feedback and
support! Keep hacking!</p>

<p><strong>P.S.</strong> Koichi recently covered in great details our long journey to RuboCop 1.0 in his presentation <a href="https://speakerdeck.com/koic/road-to-rubocop-1-dot-0">Road to RuboCop 1.0</a> at RubyKaigi 2020. I cannot recommend it highly enough to those of you who’d like to learn more about the technical aspects of RuboCop 1.0 and all the challenges we had to solve along the way!</p>


  </div></div>]]>
            </description>
            <link>https://metaredux.com/posts/2020/10/21/rubocop-1-0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24846902</guid>
            <pubDate>Wed, 21 Oct 2020 11:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aim for Operability, Not SRE as a Cult]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24846132">thread link</a>) | @slyall
<br/>
October 21, 2020 | https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/ | <a href="https://web.archive.org/web/*/https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		
<blockquote><p><strong>Site Reliability Engineering (SRE) offers a philosophy for operating reliable distributed systems, with admirable principles and practices. However, in only a few years SRE cargo culting has emerged at a level to rival DevOps cargo culting in the 2010s.&nbsp;<p>What is SRE as a Cult, and how does it intersect with DevOps as a Cult? Why is SRE so difficult to apply to enterprise organisations with IT as a A Cost Centre? Why is an emphasis on operability more important to IT performance than SRE?</p></strong></p></blockquote>



<h3>Introduction&nbsp;</h3>



<p>A successful Digital transformation is predicated on a transition from <a href="https://www.stevesmith.tech/blog/it-as-a-cost-centre/">IT as a Cost Centre</a> to <a href="https://www.stevesmith.tech/blog/it-as-a-business-differentiator/">IT as a Business Differentiator</a>. An IT cost centre creates segregated Delivery and Operations teams, trapped in an endless conflict between speed and reliability. Delivery wants to maximise deployments, to increase speed. Operations wants to minimise deployments, to increase reliability. This results in low performance IT, and has negative consequences for profitability, market share, and productivity.&nbsp;</p>



<p>In <a href="https://www.amazon.com/dp/B07B9F83WM" target="_blank" rel="noreferrer noopener"><em>Accelerate</em></a>, Dr Nicole Forsgren <em>et al</em> demonstrates speed and reliability are not a zero sum game. Investing in both Continuous Delivery and Operability will produce a high performance IT capability that can uncover new product revenue streams. For instance, transforming production support from <a href="https://www.stevesmith.tech/blog/you-build-it-ops-runs-it/">You Build It Ops Run It</a> to <a href="https://www.stevesmith.tech/blog/you-build-it-you-run-it/">You Build It You Run It</a> will unlock daily deployments, and have a positive impact on service reliability. User satisfaction, revenue protection, and brand reputation will all be improved.&nbsp;</p>



<h3>SRE as a Philosophy</h3>



<p>In 2004, Ben Treynor Sloss started an initiative called SRE within Google. He later described SRE as a software engineering approach to IT operations, with developers automating work historically owned outside Google by sysadmins. SRE key concepts include:</p>



<ul><li>Availability levels.</li><li>Service Level Objectives.</li><li>Error budgets.&nbsp;</li><li><a href="https://www.stevesmith.tech/blog/you-build-it-sre-run-it">You Build It SRE Run It</a>.</li></ul>



<p>Availability levels are known by the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/High_availability" target="_blank">nines of availability</a>. 99.0% is two nines, 99.999% is five nines. 100% availability is unachievable, as less reliable user devices will limit the user experience. 100% is also undesirable, as maximising availability limits speed of feature delivery and increases operational costs. In the seminal book <a rel="noreferrer noopener" href="https://landing.google.com/sre/sre-book/chapters/introduction/" target="_blank"><em>Site Reliability Engineering</em></a>, Betsey Byers <em>et al</em> observe that ‘an additional nine of reliability requires an order of magnitude more engineering effort’. At any availability level, an amount of unplanned downtime needs to be tolerated, in order to invest in feature delivery.</p>



<figure><img loading="lazy" width="960" height="540" src="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels.png" alt="" srcset="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels.png 960w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels-300x169.png 300w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels-768x432.png 768w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels-676x380.png 676w" sizes="(max-width: 960px) 100vw, 960px"></figure>



<p>A Service Level Objective (SLO) is a published target range of measurements, which sets user expectations on an aspect of service performance. A product manager chooses SLOs, based on their own risk tolerance. They have to balance the engineering cost of meeting an SLO with user needs, the revenue potential of the service, and competitor offerings. An availability SLO could be a median request success rate of 99.9% in 24 hours, with measurements collected every minute for 24 hours as a Service Level Indicator (SLI).&nbsp;</p>



<p>An error budget is a quarterly amount of tolerable, unplanned downtime for a service. It is used to mitigate any inter-team conflicts between product teams and SRE teams, as found in You Build It Ops Run It. It is calculated as 100% minus the chosen nines of availability. For example, an availability level of 99.9% equates to an error budget of 0.01% unsuccessful requests. 0.002% of failing requests in a week would consume 20% of the error budget, and leave 80% for the quarter.&nbsp;</p>



<p>You Build It SRE Run It is a conditional production support method, where a team of SREs support a service for a product team. All product teams do You Build It You Run It by default, and there are strict entry and exit criteria for an SRE team. A service must have a critical level of user traffic, some elevated SLOs, and pass a readiness review. The SREs will take over on-call, and ensure SLOs are consistently met. The product team can launch new features if the service is within its error budget. If not, they cannot deploy until any errors are resolved. If the error budget is repeatedly blown, the SRE team can hand on-call back to the product team, who revert to You Build It You Run It.</p>



<p>This is <strong>SRE as a Philosophy</strong>. The biggest gift from SRE is a framework for quantifying availability targets and engineering effort, based on product revenue. SRE has also promoted ideas such as measuring partial availability, monitoring the golden signals of a service, building SLO alerts and SLI dashboards from the same telemetry data, and reducing operational toil where possible.&nbsp;&nbsp;</p>



<h3>SRE as a Cult</h3>



<p>In the 2010s, the DevOps philosophy of collaboration was bastardised by <a href="https://www.stevesmith.tech/blog/aim-for-operability-not-devops-as-a-cult/">DevOps as a Cult</a>. The DevOps cargo cult is ubiquitous, and wrong. Its beliefs are:</p>



<ol><li>The divide between Delivery and Operations teams is <em>always</em> the constraint in IT performance.&nbsp;</li><li>DevOps automation tools, DevOps engineers, DevOps teams, and/or DevOps certifications are <em>always</em> solutions to that problem.</li></ol>



<p>In a similar vein, the SRE philosophy has been corrupted by <strong>SRE as a Cult</strong>. The SRE cargo cult is based on the same flawed premise, and espouses SRE error budgets, SRE engineers, SRE teams, and SRE certifications as a panacea. Examples include Patrick Hill stating in <a rel="noreferrer noopener" href="https://www.atlassian.com/incident-management/devops/sre" target="_blank">Love DevOps? Wait until you meet SRE</a> that ‘SRE removes the conjecture and debate over what can be launched and when’, and the DevOps Institute offering <a rel="noreferrer noopener" href="https://devopsinstitute.com/certifications/sre-foundation/" target="_blank">SRE certification</a>.&nbsp;</p>



<p>SRE as a Cult ignores the central question facing the SRE philosophy – its applicability to IT as a Cost Centre. SRE originated from talented, opinionated software engineers in a single, unique organisation. Google has IT as a Business Differentiator as a core tenet. Using <a rel="noreferrer noopener" href="https://qualitysafety.bmj.com/content/13/suppl_2/ii22" target="_blank"><em>A Typology of Organisational Cultures</em></a> by Ron Westrum, its organisational culture can be described as generative. <em>Accelerate</em> found a generative culture is predictive of high performance IT, and less employee burnout.</p>



<figure><img loading="lazy" width="960" height="540" src="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum.png" alt="" srcset="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum.png 960w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum-300x169.png 300w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum-768x432.png 768w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum-676x380.png 676w" sizes="(max-width: 960px) 100vw, 960px"></figure>



<p>There are fundamental challenges with applying SRE to an IT as a Cost Centre organisation with a bureaucratic or pathological culture. Product, Delivery, and Operations teams will be hindered by orthogonal incentives, funding pressures, and silo rivalries.&nbsp;</p>



<p>Availability levels are a leading indicator of cross-organisation support for SRE. When failure leads to scapegoating or justice:</p>



<ul><li>Heads of Product/Delivery/Operations might not agree 100% reliability is unachievable.</li><li>Heads of Product/Delivery/Operations might not accept an additional nine of reliability means an order of magnitude more engineering effort.&nbsp;</li><li>Heads of Delivery/Operations might not consent to availability levels being owned by product managers.</li></ul>



<p>Service Level Objectives are based on the risk tolerances of product managers. When responsibilities are shirked or discouraged:</p>



<ul><li>Product managers might decline to take on responsibility for service availability.</li><li>Product managers will need help from Delivery teams to uncover user expectations, calculate service revenue potential, and check competitor availability levels.</li><li>Sysadmins might object to developers wiring automated, fine-grained measurements into their own production alerts.&nbsp;</li></ul>



<p>Error budgets depend on shared agreements between different teams, without resorting to the inter-team battles of You Build It Ops Run It. When cooperation is modest or low:</p>



<ul><li>Product manager/developers/sysadmins might disagree on availability levels and the maths behind &nbsp;&nbsp;&nbsp; error budgets.</li><li>Heads of Product/Development might not accept a block on deployments when an error budget is 0%.</li><li>A Head of Operations might not accept deployments at all hours when an error budget is above 0%.</li><li>Product managers/developers might accuse sysadmins of blocking deployments unnecessarily</li><li>Sysadmins might accuse product managers/developers of jeopardising reliability</li><li>A Head of Operations might arbitrarily block production deployments</li><li>A Head of Development might escalate a block on production deployments</li><li>A Head of Product might override a block on production deployments</li></ul>



<p>You Build It SRE Run It means a central developer team supporting services with high availability levels and critical user traffic, while other developer teams support their own services under You Build It You Run It. It is worlds apart from You Build It Ops Run It. When bridging is merely tolerated or discouraged:</p>



<ul><li>A Head of Operations might not consent to on-call Delivery teams on their opex budget</li><li>A Head of Development might not consent to on-call Delivery teams on their capex budget</li><li>A Head of Operations might be unable to afford months of software engineering training for their sysadmins on an opex budget</li><li>Sysadmins might not want to undergo training, or be rebadged as SREs</li><li>Developers might not want to do on-call for their services, or be rebadged as SREs</li><li>Delivery teams will find it hard to collaborate with an Operations SRE team on errors and incident management</li><li>A Head of Operations might be unable to transfer an unreliable service back to the original Delivery team, if it was disbanded when its capex funding ended&nbsp;</li></ul>



<p>In <em>Site Reliability Engineering</em>, Ben Treynor Sloss identifies SRE recruitment as a significant challenge for Google. Developers are needed that excel in both software engineering and systems administration, which is rare. He counters this with the argument that an SRE team is cheaper than an Operations team, as the headcount is reduced by task automation. Recruitment challenges will be exacerbated in IT as a Cost Centre organisations, due to much smaller recruitment budgets. The touted headcount benefit is absurd, as salary rates are invariably higher for developers than sysadmins.&nbsp;</p>



<h3>Aim for Operability, not SRE as a Cult</h3>



<p>Continuous Delivery requires operational excellence. Reliable production services will minimise operational rework, and increase the throughput of feature delivery. There are many pathways to Operability, and SRE is only one of those pathways. SRE as a Cult will promote the world …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/">https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/</a></em></p>]]>
            </description>
            <link>https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24846132</guid>
            <pubDate>Wed, 21 Oct 2020 09:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Does Julia Work So Well?]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24846033">thread link</a>) | @Tomte
<br/>
October 21, 2020 | https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia | <a href="https://web.archive.org/web/*/https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="-1" id="notebook">
    <div id="notebook-container">

<div>
<div>
<div>
<p>There is an obvious reason to choose Julia:</p>
<blockquote><p>it's faster than other scripting languages, allowing you to have the rapid development of Python/MATLAB/R while producing code that is as fast as C/Fortran</p>
</blockquote>
<p>Newcomers to Julia might be a little wary of that statement.</p>
<ol>
<li>Why not just make other scripting languages faster? If Julia can do it, why can't others? </li>
<li>How do you interpert Julia benchmarks to confirm this? (This is surprisingly difficult for many!)</li>
<li>That sounds like it violates the No-Free-Lunch heuristic. Is there really nothing lost?</li>
</ol>
<p>Many people believe Julia is fast <strong>because it is Just-In-Time (JIT) compiled</strong> (i.e. every statement is run using compiled functions which are either compiled right before they are used, or cached compilations from before). This leads to questions about what Julia gives over JIT'd implementations of Python/R (and MATLAB by default uses a JIT). These JIT compilers have been optimized for far longer than Julia, so why should we be crazy and believe that somehow Julia quickly out-optimized all of them? However, that is a complete misunderstanding of Julia. What I want show, in a very visual way, is that Julia is fast because of its design decisions. The core design decision, <strong>type-stability through specialization via multiple-dispatch</strong> is what allows Julia to be very easy for a compiler to make into efficient code, but also allow the code to be very concise and "look like a scripting language". This will lead to some very clear performance gains.</p>
<p>But what we will see in this example is that Julia does not always act like other scripting languages. There are some "lunches lost" that we will have to understand. Understanding how this design decision effects the way you must code is crucial to producing efficient Julia code.</p>
<p>To see the difference, we only need to go as far as basic math.</p>

</div>
</div>
</div>
<div>
<div>
<div>
<h2 id="Arithmetic-in-Julia">Arithmetic in Julia<a href="#Arithmetic-in-Julia">¶</a></h2><p>In general, math in Julia looks the same as in other scripting languages. One detail to note is that the numbers are "true numbers", as in a <code>Float64</code> is truly the same thing as a 64-bit floating point number or a "double" in C. A <code>Vector{Float64}</code> is the same memory layout as an array of doubles in C, both making interop with C easy (indeed, in some sense "Julia is a layer on top of C") and it leads to high performance (the same is true for NumPy arrays).</p>
<p>Some math in Julia:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[1]:</p>
<div>
    <div>
<div><pre><span></span><span>a</span> <span>=</span> <span>2</span><span>+</span><span>2</span>
<span>b</span> <span>=</span> <span>a</span><span>/</span><span>3</span>
<span>c</span> <span>=</span> <span>a÷3</span> <span>#\div tab completion, means integer division</span>
<span>d</span> <span>=</span> <span>4</span><span>*</span><span>5</span>
<span>println</span><span>([</span><span>a</span><span>;</span><span>b</span><span>;</span><span>c</span><span>;</span><span>d</span><span>])</span>
</pre></div>

</div>
</div>
</div>

<div>
<div>


<div>




<div>
<pre>[4.0, 1.33333, 1.0, 20.0]
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>Note here that I showed off Julia's unicode tab completion. Julia allows for unicode characters, and these can be used by tab completing Latex-like statements. Also, multiplication by a number is allowed without the * if followed by a variable. For example, the following is allowed Julia code:</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[2]:</p>
<div>
    <div>
<div><pre><span></span><span>α</span> <span>=</span> <span>0.5</span>
<span>∇f</span><span>(</span><span>u</span><span>)</span> <span>=</span> <span>α</span><span>*</span><span>u</span><span>;</span> <span>∇f</span><span>(</span><span>2</span><span>)</span>
<span>sin</span><span>(</span><span>2</span><span>π</span><span>)</span>
</pre></div>

</div>
</div>
</div>



</div>
<div>
<div>
<div>
<h2 id="Type-stability-and-Code-Introspection">Type-stability and Code Introspection<a href="#Type-stability-and-Code-Introspection">¶</a></h2><p>Type stability is the idea that there is only 1 possible type which can be outputtted from a method. For example, the reasonable type to output from <code>*(::Float64,::Float64)</code> is a <code>Float64</code>. No matter what you give it, it will spit out a <code>Float64</code>. This right here is multiple-dispatch: the <code>*</code> operator calls a different method depending on the types that it sees. When it sees floats, it will spit out floats. Julia provides code introspection macros so that way you can see what your code actually compiles to. Thus Julia is not just a scripting language, it's a scripting language which lets you deal with assembly! Julia, like many languages, compiles to LLVM (LLVM is a type of portable assembly language).</p>

</div>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>; Function *
; Location: int.jl:54
define i64 @"julia_*_33751"(i64, i64) {
top:
  %2 = mul i64 %1, %0
  ret i64 %2
}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>This output is saying that a floating point multiplication operation is performed and the answer is returned. We can even look at the assembly</p>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>	.text
; Function * {
; Location: int.jl:54
	imulq	%rsi, %rdi
	movq	%rdi, %rax
	retq
	nopl	(%rax,%rax)
;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<div>
<p>This shows us that the <code>*</code> function has compiled down to exactly the same operation as what happens in C/Fortran, meaning it achieves the same performance (even though it's defined in Julia). Thus it is possible to not just get "close" to C, but actually get the same C code out. In what cases does this happen?</p>
<p>The interesting thing about Julia is that, asking which cases this happens is not the right question. the right question is, in what cases does the code not compile to something as efficient as C/Fortran? The key here is type-stability. If a function is type-stable, then the compiler can know what the type will be at all points in the function and smartly optimize it to the same assembly as C/Fortran. If it is not type-stable, Julia has to add expensive "boxing" to ensure types are found/known before operations.</p>
<h4 id="This-is-the-key-difference-between-Julia-and-other-scripting-languages">This is the key difference between Julia and other scripting languages<a href="#This-is-the-key-difference-between-Julia-and-other-scripting-languages">¶</a></h4><p>The upside is that Julia's functions, when type stable, are essentially C/Fortran functions. Thus <code>^</code> (exponentiation) is fast. However, <code>^(::Int64,::Int64)</code> is type-stable, so what type should it output?</p>

</div>
</div>
</div>


<div>
<div>
<p>Here we get an error. In order to guarantee to the compiler that <code>^</code> will give an Int64 back, it has to throw an error. If you do this in MATLAB, Python, or R, it will not throw an error. That is because those languages do not have their entire language built around type stability.</p>
</div>
</div>
<div>
<div>
<p>What happens when we don't have type stability? Let's inspect this code:</p>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>	.text
; Function ^ {
; Location: intfuncs.jl:220
	pushq	%rax
	movabsq	$power_by_squaring, %rax
	callq	*%rax
	popq	%rcx
	retq
	nop
;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>Now let's define our own exponentiation on integers. Let's make it "safe" like the form seen in other scripting languages:</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[8]:</p>
<div>
    <div>
<div><pre><span></span><span>function</span> <span>expo</span><span>(</span><span>x</span><span>,</span><span>y</span><span>)</span>
    <span>if</span> <span>y</span><span>&gt;</span><span>0</span>
        <span>return</span> <span>x</span><span>^</span><span>y</span>
    <span>else</span>
        <span>x</span> <span>=</span> <span>convert</span><span>(</span><span>Float64</span><span>,</span><span>x</span><span>)</span>
        <span>return</span> <span>x</span><span>^</span><span>y</span>
    <span>end</span>
<span>end</span>
</pre></div>

</div>
</div>
</div>

<div>
<div>


<div>

<p>Out[8]:</p>




<div>
<pre>expo (generic function with 1 method)</pre>
</div>

</div>

</div>
</div>

</div>
<div>
<div>
<p>Let's make sure it works:</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[9]:</p>
<div>
    <div>
<div><pre><span></span><span>println</span><span>(</span><span>expo</span><span>(</span><span>2</span><span>,</span><span>5</span><span>))</span>
<span>expo</span><span>(</span><span>2</span><span>,</span><span>-</span><span>5</span><span>)</span>
</pre></div>

</div>
</div>
</div>



</div>
<div>
<div>
<p>What happens if we inspect this code?</p>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>	.text
; Function expo {
; Location: In[8]:2
	pushq	%rbx
	movq	%rdi, %rbx
; Function &gt;; {
; Location: operators.jl:286
; Function &lt;; {
; Location: int.jl:49
	testq	%rdx, %rdx
;}}
	jle	L36
; Location: In[8]:3
; Function ^; {
; Location: intfuncs.jl:220
	movabsq	$power_by_squaring, %rax
	movq	%rsi, %rdi
	movq	%rdx, %rsi
	callq	*%rax
;}
	movq	%rax, (%rbx)
	movb	$2, %dl
	xorl	%eax, %eax
	popq	%rbx
	retq
; Location: In[8]:5
; Function convert; {
; Location: number.jl:7
; Function Type; {
; Location: float.jl:60
L36:
	vcvtsi2sdq	%rsi, %xmm0, %xmm0
;}}
; Location: In[8]:6
; Function ^; {
; Location: math.jl:780
; Function Type; {
; Location: float.jl:60
	vcvtsi2sdq	%rdx, %xmm1, %xmm1
	movabsq	$__pow, %rax
;}
	callq	*%rax
;}
	vmovsd	%xmm0, (%rbx)
	movb	$1, %dl
	xorl	%eax, %eax
; Location: In[8]:3
	popq	%rbx
	retq
	nopw	%cs:(%rax,%rax)
;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>That's a very visual demonstration on why Julia achieves such higher performance than other scripting languages by how it uses type inference.</p>
</div>
</div>
<div>
<div>
<div>
<p>Type stability is one crucial feature which separates Julia apart from other scripting languages.  In fact, the core idea of Julia is the following statement:</p>
<h4 id="Multiple-dispatch-allows-for-a-language-to-dispatch-function-calls-onto-type-stable-functions.">Multiple dispatch allows for a language to dispatch function calls onto type-stable functions.<a href="#Multiple-dispatch-allows-for-a-language-to-dispatch-function-calls-onto-type-stable-functions.">¶</a></h4><p>This is what Julia is all about, so let's take some time to dig into it.If you have type stability inside of a function (meaning, any function call within the function is also type-stable), then the compiler can know the types of the variables at every step. Therefore it can compile the function with the full amount of optimizations since at this point the code is essentially the same as C/Fortran code.  Multiple-dispatch works into this story because it means that <code>*</code> can be a type-stable function: it just means different things for different inputs. But if the compiler can know the types of <code>a</code> and <code>b</code> before calling <code>*</code>, then it knows which <code>*</code> method to use, and therefore it knows the output type of <code>c=a*b</code>. Thus it can propogate the type information all the way down, knowing all of the types along the way, allowing for full optimiziations. Multiple dispatch allows <code>*</code> to mean the "right thing" every time you use it, almost magically allowing this optimization.</p>
<p>There are a few things we learn from this. For one, in order to achieve this level of optimization, you must have type-stability. This is not featured in the standard libraries of most languages, and was choice that was made to make the experience a little easier for users. Secondly, multiple dispatch was required to be able to specialize the functions for types which allows for the scripting language syntax to be "more explicit than meets the eye". Lastly, a robust type system is required. In order to build the type-unstable exponentiation (which may be needed) we needed functionalities like convert. Thus the language must be designed to be type-stable with multiple dispatch and centered around a robust type system in order to achieve this raw performance while maintaining the syntax/ease-of-use of a scripting language. You can put a JIT on Python, but to really make it Julia, you would have to design it to be Julia.</p>

</div>
</div>
</div>
<div>
<div>
<div>
<h2 id="The-Julia-Benchmarks">The Julia Benchmarks<a href="#The-Julia-Benchmarks">¶</a></h2><p>The Julia benchmarks, featured on <a href="http://julialang.org/">the Julia website</a>, test components of the programming language for speed. <strong>This doesn't mean it's testing the fastest implemention</strong>. That is where a major misconception occurs. You'll have an R programmer look at the R code for the Fibonacci calculator and say "wow, that's terrible R code. You're not supposed to use recursion in R. Of course it's slow". However, the Fibonacci problem is designed to test recursion, not the fastest implementation to the the ith Fibonacci number. The other problems are the same way: testing basic components of the langauge to see how fast they are.</p>
<p>Julia is built up using multiple-dispatch on type-stable …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia">https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia</a></em></p>]]>
            </description>
            <link>https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia</link>
            <guid isPermaLink="false">hacker-news-small-sites-24846033</guid>
            <pubDate>Wed, 21 Oct 2020 09:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Flat SVG Designs – Free Vector(SVG) Icons and Illustrations]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24845908">thread link</a>) | @seuyu_bin
<br/>
October 21, 2020 | https://flat-svg-designs.net/en/ | <a href="https://web.archive.org/web/*/https://flat-svg-designs.net/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to FLAT SVG DESIGNS!</p><p>Free vector(SVG) icons and illustrations with flat design.</p></div></div>]]>
            </description>
            <link>https://flat-svg-designs.net/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845908</guid>
            <pubDate>Wed, 21 Oct 2020 08:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS and their Billions in IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24845464">thread link</a>) | @tomklein
<br/>
October 21, 2020 | https://toonk.io/aws-and-their-billions-in-ipv4-addresses/ | <a href="https://web.archive.org/web/*/https://toonk.io/aws-and-their-billions-in-ipv4-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>Earlier this week, I was doing some work on AWS and wanted to know what IP addresses were being used. Luckily for me, AWS publishes this all here <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="nofollow noopener">https://ip-ranges.amazonaws.com/ip-ranges.json</a>. When you go through this list, you’ll quickly see that AWS has a massive asset of IPv4 allocations. Just counting quickly I noticed a lot of big prefixes.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Ever wondered what all of the AWS network ranges are? You can find them all here:<a href="https://t.co/NBaBF6w0la">https://t.co/NBaBF6w0la</a><br>That's *a lot* of big prefixes!<br>4x /11, 14x /12, 30x /13, 78x /14, 184x /15, 278x /16</p>— Andree Toonk, Adelante! (@atoonk) <a href="https://twitter.com/atoonk/status/1316098702260359168?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

</figure><p>However, the IPv4 ranges on that list are just the ranges that are in use and allocated today by AWS. Time to dig a bit deeper.</p><h3 id="ipv4-address-acquisitions-by-aws">IPv4 address acquisitions by AWS</h3><p>Over the years, AWS has acquired a lot of IPv4 address space. Most of this happens without gaining too much attention, but there were a few notable acquisitions that I’ll quickly summarize below.</p><h4 id="2017-mit-selling-8-million-ipv4-addresses-to-aws">2017: MIT selling 8 million IPv4 addresses to AWS</h4><p>In 2017 <a href="https://www.internetsociety.org/blog/2017/05/mit-goes-on-ipv4-selling-spree/" rel="noopener">MIT sold half of its 18.0.0.0/8</a> allocation to AWS. This 18.128.0.0/9 range holds about 8 million IPv4 addresses.</p><h4 id="2018-ge-sells-3-0-0-0-8-to-aws">2018: GE sells 3.0.0.0/8 to AWS</h4><p>In 2018 the IPv4 prefix 3.0.0.0/8 was transferred from GE to AWS. With this, AWS became the proud owner of its first /8! That’s sixteen million new IPv4 addresses to feed us hungry AWS customers. <a href="https://news.ycombinator.com/item?id=18407173" rel="nofollow noopener">https://news.ycombinator.com/item?id=18407173</a></p><h4 id="2019-aws-buys-amprnet-44-192-0-0-10">2019: AWS buys AMPRnet 44.192.0.0/10</h4><p>In 2019 AWS bought a /10 from AMPR.org, the Amateur Radio Digital Communications (ARDC). The IPv4 range 44.0.0.0/8 was an allocation made to the Amateur Radio organization in 1981 and known as the AMPRNet. This sell caused a fair bit of discussion, check out the <a href="https://mailman.nanog.org/pipermail/nanog/2019-July/thread.html#102103" rel="noopener">nanog discussion here.</a></p><p>Just this month, it <a href="http://www.southgatearc.org/news/2020/october/sale-of-amateur-radio-amprnet-tcp-ip-addresses.htm" rel="noopener">became public knowledge</a> AWS paid $108 million for this /10. That’s $25.74 per IP address.</p><p>These are just a few examples. Obviously, AWS has way more IP addresses than the three examples I listed here. The IPv4 transfer market is very active. Check out this website to get a sense of all transfers: <a href="https://account.arin.net/public/transfer-log#NRPM-8.3IPv4" rel="noopener">https://account.arin.net/public/transfer-log</a></p><h3 id="all-aws-ipv4-addresses">All AWS IPv4 addresses</h3><p>Armed with the information above it was clear that not all of the AWS owned ranges were in the <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">JSON</a> that AWS published. For example, parts of the 3.0.0.0/8 range are missing. Likely because some of it is reserved for future use.</p><p>Combining all those IPv4 prefixes, removing duplicates and overlaps by aggregating them results in the following list of unique IPv4 address owned by AWS: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes</a></p><p>The total number of IPv4 addresses in that list is just over 100 Million (100,750,168). That’s <strong>the equivalent of just over six /8’s,</strong> not bad!</p><p>If we break this down by allocation size, we see the following:</p><pre><code>1x /8     =&gt; 16,777,216 IPv4 addresses
1x /9     =&gt; 8,388,608 IPv4 addresses
4x /10    =&gt; 16,777,216 IPv4 addresses
5x /11    =&gt; 10,485,760 IPv4 addresses
11x /12   =&gt; 11,534,336 IPv4 addresses
13x /13   =&gt; 6,815,744 IPv4 addresses
34x /14   =&gt; 8,912,896 IPv4 addresses
53x /15   =&gt; 6,946,816 IPv4 addresses
182x /16  =&gt; 11,927,552 IPv4 addresses
&lt;and more&gt;</code></pre><p>A complete breakdown can be found here: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size</a></p><h3 id="putting-a-valuation-on-aws-ipv4-assets">Putting a valuation on AWS’ IPv4 assets</h3><blockquote>Alright.. this is just for fun…</blockquote><p>Since AWS is (one of) the largest buyers of IPv4 addresses, they have spent a significant amount on stacking up their IPv4 resources. It’s impossible, as an outsider, to know how much AWS paid for each deal. However, we can for fun, try to put a dollar number on AWS’ current IPv4 assets.</p><p>The average price for IPv4 addresses has gone up over the years. From ~$10 per IP a few years back to ~$25 per IP <a href="https://auctions.ipv4.global/" rel="noopener">nowadays</a>. <br>Note that these are market prices, so if AWS would suddenly decide to sell its IPv4 addresses and overwhelm the market with supply, prices would drop. But that won’t happen since we’re all still addicted to IPv4 ;)</p><p>Anyway, let’s stick with $25 and do the math just for fun.</p><pre><code>100,750,168 ipv4 addresses x $25 per IP = $2,518,754,200</code></pre><p>Just<strong> over $2.5 billion worth of IPv4 addresses,</strong> not bad! </p><h3 id="peeking-into-the-future">Peeking into the future</h3><p>It’s clear AWS is working hard behind the scenes to make sure we can all continue to build more on AWS. One final question we could look at is: <em>how much buffer does AWS have?</em> ie. how healthy is their IPv4 reserve?</p><p>According to their <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="noopener">published data</a>, they have allocated roughly 53 Million IPv4 addresses to existing AWS services. We found that all their IPv4 addresses combined equates to approximately 100 Million IPv4 addresses. That means they still have ~47 Million IPv4 addresses, or 47% available for future allocations. That’s pretty healthy! And on top of that, I’m sure they’ll continue to source more IPv4 addresses. The IPv4 market is still hot!</p></div>
    </div></div>]]>
            </description>
            <link>https://toonk.io/aws-and-their-billions-in-ipv4-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845464</guid>
            <pubDate>Wed, 21 Oct 2020 07:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What ORMs Have Taught Me: Just Learn SQL (2014)]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 282 (<a href="https://news.ycombinator.com/item?id=24845300">thread link</a>) | @IA21
<br/>
October 20, 2020 | https://wozniak.ca/blog/2014/08/03/1/ | <a href="https://web.archive.org/web/*/https://wozniak.ca/blog/2014/08/03/1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>
I’ve come to the conclusion that, for me, ORMs are more detriment than
benefit. In short, they can be used to nicely augment working with SQL
in a program, but they should not replace it.
</p>

<p>
Some background: For the past 30 months I’ve been working with code
that has to interface with Postgres and to some extent, SQLite. Most
of that has been with <a href="http://sqlalchemy.org/">SQLAlchemy</a> (which I quite like) and <a href="http://hibernate.org/">Hibernate</a>
(which I don’t). I’ve worked with existing code and data models, as
well as designing my own. Most of the data is event-based storage
(“timelines”) with a heavy emphasis on creating reports.
</p>

<p>
Much has been written about the Object/Relational Impedance
Mismatch. It’s hard to appreciate it until you live it. Neward, in his
<a href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">well known essay</a>, lays out many cogent reasons why ORMs turn into
quagmires. In my experience, I’ve had to deal directly with a fair
number of them: <i>entity identity issues</i>, <i>dual-schema problem</i>, <i>data
retrieval mechanism concern</i>, and the <i>partial-object problem</i>. I want to
talk briefly about my experiences with these issues and add one of my
own.
</p>

<div id="outline-container-orge4f50a6">
<h2 id="orge4f50a6">Partial objects, attribute creep, and foreign keys</h2>
<div id="text-orge4f50a6">
<p>
Perhaps the most subversive issue I’ve had with ORMs is “attribute
creep” or “wide tables”, that is, tables that just keep accruing
attributes. As much as I’d like to avoid it, sometimes it becomes
necessary (although things like <a href="http://www.postgresql.org/docs/9.3/interactive/hstore.html">Postgres’ hstore</a> can help). For
example, a client may be providing you with lots of data that they
want attached to reports based on various business logic. Furthermore,
you don’t have much insight into this data; you’re just schlepping it
around.
</p>

<p>
This in and of itself isn’t a terrible thing in a database. It becomes
a real pain point with an ORM. Specifically, the problem starts to
show up in any query that uses the entity directly to create the
query. You may have a Hibernate query like so early on in the project.
</p>

<pre>query(Foo.class).add(Restriction.eq("x", value))
</pre>

<p>
This may be fine when Foo has five attributes, but becomes a data fire
hose when it has a hundred. This is the equivalent of using <code>SELECT
*</code>, which is usually saying more than what is intended. ORMs, however,
encourage this use and often make writing precise projections as
tedious as they are in SQL. (I have optimized such queries by adding
the appropriate projection and reduced the run time from minutes to
seconds; all the time was spent translating the database row into a
Java object.)
</p>

<p>
Which leads to another bad experience: the pernicious use of foreign
keys. In the ORMs I’ve used, links between classes are represented in
the data model as foreign keys which, if not configured carefully,
result in a large number of joins when retrieving the object. (A
recent count of one such table in my work resulted in over 600
attributes and 14 joins to access a single object, using the preferred
query methodology.)
</p>

<p>
Attribute creep and excessive use of foreign keys shows me is that in
order to use ORMs effectively, you still need to know SQL. My
contention with ORMs is that, if you need to know SQL, just use SQL
since it prevents the need to know how non-SQL gets translated to SQL.
</p>
</div>
</div>

<div id="outline-container-org2d7e33d">
<h2 id="org2d7e33d">Data retrieval</h2>
<div id="text-org2d7e33d">
<p>
Knowing how to write SQL becomes even more important when you attempt
to actually write queries using an ORM. This is especially important
when efficiency is a concern.
</p>

<p>
From what I’ve seen, unless you have a really simple data model (that
is, you never do joins), you will be bending over backwards to figure
out how to get an ORM to generate SQL that runs efficiently. Most of
the time, it’s more obfuscated than actual SQL.
</p>

<p>
And if you elect to keep the query simple, you end up doing a lot of
work in the code that could be done in the database faster. <a href="https://en.wikipedia.org/wiki/Window_function_%28SQL%29#Window_function">Window
functions</a> are relatively advanced SQL that is painful to write with
ORMs. Not writing them into the query likely means you will be
transferring a lot of extra data from the database to your
application.
</p>

<p>
In these cases, I’ve elected to write queries using a templating
system and describe the tables using the ORM. I get the convenience of
an application level description of the table with direct use of
SQL. It’s a lot less trouble than anything else I’ve used so far.
</p>
</div>
</div>

<div id="outline-container-org05d550b">
<h2 id="org05d550b">Dual schema dangers</h2>
<div id="text-org05d550b">
<p>
This one seems to be one of those unavoidable redundancies.  If you
try to get rid of it, you only make more problems or add excessive
complexity.
</p>

<p>
The problem is that you end up having a data definition in two places:
the database and your application.  If you keep the definition
entirely in the application, you end up having to write the SQL Data
Definition Language (DDL) with the ORM code, which is the same
complication as writing advanced queries in the ORM.  If you keep it
in the database, you will probably want a representation in the
application for convenience and to prevent too much “string typing”.
</p>

<p>
I much prefer to keep the data definition in the database and read it
into the application.  It doesn’t solve the problem, but it makes it
more manageable.  I’ve found that reflection techniques to get the
data definition are not worth it and I succumb to managing the
redundancy of data definitons in two places.
</p>

<p>
But the damn migration issue is a real kick in the teeth: changing the
model is no big deal in the application, but a real pain in the
database.  After all, databases are persistent whereas application
data is not.  ORMs simply get in the way here because they don’t help
manage data migration at all.  I work on the principle that the
database’s data definitions aren’t things you should manipulate in the
application.  Instead, manipulate the results of queries.  That is,
the queries are your API to the database.  So instead of thinking
about objects, I think about functions with return types.
</p>

<p>
Thus, one is forced to ask, should you use an ORM for anything but
convenience in making queries?
</p>
</div>
</div>

<div id="outline-container-org7033826">
<h2 id="org7033826">Identities</h2>
<div id="text-org7033826">
<p>
Dealing with entity identities is one of those things that you have to
keep in mind at all times when working with ORMs, forcing you to write
for two systems while only have the expressivity of one.
</p>

<p>
When you have foreign keys, you refer to related identities with an
identifier. In your application, “identifier” takes on various
meanings, but usually it’s the memory location (a pointer). In the
database, it’s the state of the object itself. These two things don’t
really get along because you can really only use database identifiers
in the database (the ultimate destination of the data you’re working
with).
</p>

<p>
What this results in is having to manipulate the ORM to get a database
identifier by manually flushing the cache or doing a partial commit to
get the actual database identifier.
</p>

<p>
I can’t even call this a leaky abstraction because the work “leak”
implies small amounts of the contents escaping relative to the source.
</p>
</div>
</div>

<div id="outline-container-orgddbdda4">
<h2 id="orgddbdda4">Transactions</h2>
<div id="text-orgddbdda4">
<p>
Something that Neward alludes to is the need for developers to handle
transactions. Transactions are dynamically scoped, which is a powerful
but mostly neglected concept in programming languages due to the
confusion they cause if overused.  This leads to a lot of boilerplate
code with exception handlers and a careful consideration of where
transaction boundaries should occur.  It also makes you pass session
objects around to any function/method that might have to communicate
with the database.
</p>

<p>
The concept of a transaction translates poorly to applications due to
their reliance on context based on time. As mentioned, dynamic scoping
is one way to use this in a program, but it is at odds with lexical
scoping, the dominant paradigm. Thus, you must take great care to know
about the “when” of a transaction when writing code that works with
databases and can make modularity tricky (“Here’s a useful function
that will only work in certain contexts”).
</p>

<p>
Where do I see myself going?
</p>

<p>
At this point, I’m starting to question the wisdom behind the outright
rejection of <a href="http://c2.com/cgi/wiki?StoredProcedures">stored procedures</a>.  It sounds <a href="http://c2.com/cgi/wiki?StoredProceduresAreEvil">heretical</a>, but it may work
for my use cases.  (And hey, with the advent of “devops”, the divide
between the developer and the database administrator is basically
non-existent.)
</p>

<p>
I’ve found myself thinking about the database as just another data
type that has an API: the queries.  The queries return values of some
type, which are represented as some object in the program. By moving
away from thinking of the objects in my application as something to be
stored in a database (the raison d’être for ORMs) and instead thinking
of the database as a (large and complex) data type, I’ve found working
with a database from an application to be much simpler. And wondering
why I didn’t see it earlier.
</p>

<p>
(It should be made clear that I am not claiming this is how all
applications should deal with a database.  All I am saying is that
this fits my use case based on the data I am working with.)
</p>

<p>
Regardless of whether I find that stored procedures aren’t actually
that evil or whether I keep using templated SQL, I do know one thing:
I won’t fall into the “ORMs make it easy” trap. They are an acceptable
way to represent a data definition, but a poor way to write queries
and a bad way to store object state. If you’re using an RDBMS, bite
the bullet and learn SQL.
</p>

<p>
August 03, 2014
</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://wozniak.ca/blog/2014/08/03/1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845300</guid>
            <pubDate>Wed, 21 Oct 2020 06:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GitHub for Learning]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24844734">thread link</a>) | @IvanVLiu
<br/>
October 20, 2020 | https://astrasum.com/subject/1 | <a href="https://web.archive.org/web/*/https://astrasum.com/subject/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://astrasum.com/subject/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844734</guid>
            <pubDate>Wed, 21 Oct 2020 04:26:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Diablo (Pitch from 1994) (2016) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24844666">thread link</a>) | @tosh
<br/>
October 20, 2020 | http://www.graybeardgames.com/download/diablo_pitch.pdf | <a href="https://web.archive.org/web/*/http://www.graybeardgames.com/download/diablo_pitch.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div �oe="">€öŒA]øýçÏ‰9_ÝŒGƒÀà«ÛOlF•t|ífl5µÞæ"8²36%vLFÔn¸’ÖÞY‰Ò-ßËÖ¢§¼ù€‘2ož™›;^0YÐnÙ°ž@3GnÖ?ñ$†S;\«ÊÚ€éŸ¾˜ø"#¸ù©ƒ &lt;†¸‰´(ØF‘F%}EBì™C‘ÆäS P|î}0&nbsp;‘¬š£]*Cgqg"}ºaÃpË•2™g!ÖFò¥Ûæ$ôjHä‹T�oôÓöM2Ñ¥k»o-WÎ
Šïû´&amp;9|ÄýÞ$a°¨õ±5¬Úáû¼öIa$köƒŒÞ:ü�Á;“(2N3¶€Óë.š“¥ÅƒØ´Ž¶¸9¹*7�œFÛß
ƒd€©©j¬gŠTþ×ûºFPØù@e÷•ÿT“þµ„¢Pû�0H%’;uM@	ô«‘µ´òÃyE�2%Ï•TWRÈÇ~âÜgc|ÊGˆBMÅOìá�Yw”ÜU&gt;XÜ% ÂpË»8¡–s¥“®H²\I¨* ±láòOÌYSË;”¤n“€"K¨Ê·Sj�:AqnÇd HÜð’±îÆÀy"ª$håÄšäƒ‹ÂIòÔåÊyì&lt;àL!”mC�à×–vÒY•§gV™™¶"ÙŒJÃ/…o1ª*1Ž1¤À‡Bß±É2:ê@Á\ôÜ7dÝç}ÖÁÀÎ/'�zË¥Zo«BÒ}¢ïÍ(eT'*$_ßK¿åb¬¿.Ìã‚W'Q·#O�ìÿd¶ctâl5Ç#qeÈó`Íƒœ†ÇÈ¦ÇŸ¡Z!hbKy$e½�íYB™
ŒCoîí’R@9»¢Õ"¾ÍhÖ–ùà¦w`#`‘Ábs€FJ/J‹t’ê°ùV0ÉŸl'oœîô§;CJ–fLüÁ@!oÚm9®X-ŸÚ€þY*A+¸¨
FÆRažxo˜êJ––Íoäf×$yÄ0$¬{@*Ã†¢}ïï3ƒÄ�ýªØIö‚‚ÄÇ•
cûûsœ$�”(p ü�GözEq{¸´ž)…¼~y_ÌWÚFy
Å·‘½qDð½‚˜ï£K™®mã6ò´äˆPä+\¸ÉU]˜©5Å§bô%­ÊÝ$Á­ðO“óeydÇð¥7rwÓ—¥ÄÑ/ÙnÅÜL˜.Öå²;«ŒüÃ²ž›XJHŸM™êRÍÛÃ;³#a07lÝŽ&nbsp;œîËt%™»M"éÖÈ‘ß$“	.ÅÃ�7ïî\à}à@îN9sUyDV…´ÝÖ²Å#Æ~Ø±³Ôì$+ç`r£w%ÔœŸ•¬±Ë·N&amp;Ý$ÿJÚÃÌœ³
Û”ðÿÏR@1äA--ZÞÝÌìnùûv†ã,O!ÚsŒáW3K‘%åº$ÖþG�jnt&nbsp;0|&nbsp;�zpA'fæâ«y‹~‹†&gt;ÍáÄeZR1€Ä™Ïð’˜‘“ƒ$’Ç¨o¹?e·6éÛp¤yø8ùGÌX°áðyw`ô3,$ÿiù1?;gØþÐá·yx$ƒŒüÄõþlæ«É°ªÜ¨ò¡¹2ˆÕ$ß±wdÆÄsÂ•0€É«KržiÔØZ¤‹(_±yL^Ýû;`ò‡$ƒòš%bL\«DÍ9—t
¬¢/˜àq�”nÌxl¼Rn9‚§Ó£
úb¾gœíŒôíƒœ`ä`ó×ùúb„ ¢Š)€QEQEQEQERc&gt;Ô´PIKF)QŠJZJ)i(¤—¥ÐÒf–Š(¢’˜Eb�QLŠ(&nbsp;Š(&nbsp;Š(&nbsp;Š(#4QEQEQEQES§ãO¦IÓñ¤¨¤Pm+S(z(¢˜Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@yïÄ0�on²¨gä¨Éâ7ÁÁ ÄƒŒã½zy¿ÄV";QŽ&lt;×ç¾vp3èrr;àzPžÉp/"X/¦e†Ú	¸)Ãav¦UAù¶€]ò^H'5zâyîåûN£$ÑêQ,&amp;É&gt;Î?zw–N~|õÀÉà1IhÕÎÔÆÞXF
Ÿ”œƒ•Ê0OPEk\A-´­m¨¤òj²ù?c“íü²\…ËoùNüã%ùäl; Îºk¿µ™$ÚËµmÍ¿XÌXÎØÂsœ&nbsp;¶:=2Ê[ËyÍÎžòKªMö�µEägË`$Ÿ—nK<p­„!~ëh-nÇØöÌuÁ6~ÑçŸõbÛwù˜ÎÎ:go‰ùj+k{»©m¶ž²Åªb'7r‹‚ ˜�="" Ý·!±œ¬~bn2°x-Ÿûydi`s¨³f¸‹!ºn]ß*™rp±À,öžx‚ÄñiòÈú#Éº�ã]ÊÛ“pæ5‘¶�="" ©Œœ‚iŽÞÛí¶ît¥{dµ„h="¿Ò08" v·="" 'urtuµ,="" yêr´zd‚âÑ¥‘="" Ì¥c´3¡Ê²="" –s…€tÚ¬©o,³="" \1Žs�É![!–-¹3´ƒÉ*0pvÛçÅ:”²Åd‘ÌÖŒ!Îã¸=""  ÉÏ,ß(�¡ÃuÇ€$1êŒ„èï+*Ù-ÄÄ£m‘71à.\$6pázukhâ¸¿ŠiìçiþÉÚî¾u#6s="" ²–—2is“u’xî#·ŒÙ¯•þ±k1°€môc‚sœ’¥zyä¸3<÷2lºÊmŽ1="" à�£i!s±Œ="" ;²£km•®m›o="" j6¸ž[x¾Èþ{~åim ="" •*�‡="" �‡="" ¾¦žÖx.Îu’]u¥‹dÿ�hÎ¨ùˆÉ<a™�_—Ã="" o,þrÏló�eæ›Ì�Ê@…mÇ="" ¡wc="" ©)mrªyömp›[eye¾–)zõz(ðŸ2�ª6à�Ý8�);dÁq="ÂÚÛ¬‘ê‹,¾d¿h" ±ÃÉ…*7e•Žñœî$�¶pËª•�kÒæ+wk™mË�;”ÝŸîå²h8\·Î~phÁ·ysc–i´³âu¨bêûd‘¡Èˆ˜ÔãfÀ­¹qd‚Ýî†÷ù²yj[vØ‹dì`¸à»ò³¹ˆ¿mi®4ÈžÖÎÞ8þÕÚ\�fÎn~l¡`à�p2ÁjÄ±="üQlÒÒáZ}¥¹rŠ�Üœ‚[ï(8_‘" v!¾{¼qÛnÓ�%&�Â|•'þz!‚¨g;Îåß…Üh(É¦i"rk…hm×ì;#eùz&æÂ³gÂàòÇæ!³ÃÎ#6ðgq›¦m4¾]¯Ú\l?8\ñÕvœ8Ë="">|nŠtû _Eö“ul�jÞ{�³¡Ý´`Œ­·îü¸î| -Üý§í÷¦í¡$gUHv�T¶ÐP‘ÈÇ;s¸o
¡®–ì4fíã3]�y{|²		Ùƒ»…Á$tV1ÜÛËkpÖ)æêo,,—Ÿi“)‘Ñ’Ê€Fâr»�
¹žÚÎi®×L@`Õäi/~Ñ#3�¬Jü£‚T¨ÎsòœŒ±Àm‡Úä—þ$ípÚ‹¤¦óÌª‚Î¹Ú_�óçœï8ÈÊ…´Œ¬r
!§6&gt;Z
H¸„0P~Íß7™8AœŽ­š[µ2ltÐ–7VŠëq0žOß�Á_”BJï]ÛI*«ÈúºIy§D–vvhêÙet
¡�”ùqímÈ¬Ÿ0ã&lt;äò¬öc3ø{zùøòD‚C³¦à%Ç™åŽ1�8¨eÇ•\Ÿì!#ý˜¢Å¼°Ô•Ë&gt;ð#¦á+Ý‰ã:¬QFšdr*I`&amp;(®ø;F±ˆú”nA'fH#8Î\(º„ÑG5ŒÒÊ#²[—&amp;9ä€¼/P ®@E&gt;}þTcV7&gt;@€ý„*Ä88Û»žr9|mÁ·6î
×ž§T?Ú„DÖ!|‚¡·/xû£÷€eH©`Iªªiñ¤·IÒ\ÂÞB†-oÎ@a�áÝ÷s‚Crjšæb~Åv‘\Ý\¬^M×ÚXˆTáW’8×‚å—†j†¹70›þ5?+~ãË(Ppy0àCžÁ·‘ß¤ÑÉtÎF–’.¶3ö×&gt;NÆù†ŒYßåíò”erMe•xä:Aû:ß™·ý¼ÌrÐÛ|Ížg lûÝNÝ»ŽjŠ=E…‚ý–Þâ×Ìóoà�9æÚî'pÉc�ØzÜË)oìU¸“þ&amp;!Ì[[ûÅ7·Þ?½åJœcn&gt;j»É$m&amp;�‘h+‘w)½œ¾ÒîÒà¡‰NÇ^Ç9Ï/s$7È¢aµE‰16
Æ
ç®ÝÄã!Fæ9'qÀÅóuÃ›Øc‚ÞÖÜÅ¾ÃÎÇÚ
Ÿ½´¦×&lt;�Ä§AÎNIC5ä‘DBfŽgðàû‘nMûó´c÷‚m¾nHøöÆQ›*¾¨·gL}ÆÅÄ]zl$È
‡$Ž�GZÂ{x%þ×h¬Þb£OóAdÊ•ÜP¡P27}Ìr6�ÁG-¾–~Ù,v—ive¸�±·Ür7
§n3�Üàá”ŒÐëÉ7™Ö–yoåÇØ
”G’63lt‹ãvõn&gt;×¤IÄëÒ´šû)kyÕ”D¨7c 2ÆQ  ÄI'¾Es1­¶Ž¦ÚU´»kÐ»fû6xË
ŒÊW;‰R¹Ç$â¬`�±åkI¥—‘¨ù�„j~m»Ê’·E8ëÉÛT¸–v‚Ù]5äP×ëå”ùs�½“ÀÆ:M�æG�EIa¼‰±~Ï*âSóÛ™$‹†ÚÊ.zŒŒgF-®q¥y–¶�n2ÚˆeÌÞÈØL“¸S�¾Ø«ñ,:Ã#û=‰±92ÇŒ]ã#‚&lt;¿‘°Ke¤ÎáÁ�C­Ö)Õ¦Ò’H4ØËèžOšL`¶ÜÉ!¯‡MÃ�ïb7„Û}±Wn‚¨GÙzÊ_¦î§ø½fíŸz‚!o«bùbŽÉm¡m]·8³Ò0sÓý[ò*ô
dÿ‰ÊÂCyEL	“ÁÀqÇB0Ùús@Éw$Q¥ÍçïtÉÚ!en«ûÈ�ˆÚX|¸
3ŸÞ7\œ
’X¤µ‘`ÔÚ/§wûÊ…–ÇŽ‚9&lt;&lt;ú
Ñ�'±c©,w=ç–�lÿG
Ôãîº1ÉlH°�I§fŸi¹K¶�ÉpdÉƒ#�Ð…Çnƒ&lt;ŸJ?¯ÀJâÅÌ‹`ìï­²–[µy:ãz�x_—2Ô�Xïkpóý†ÝY5(�3Üý­Çš:¼Aàãƒ�Èôëî­&lt;˜¿±¿~m¤Vw¿vÊ©$¶°Œà¸úW#ws…ÒÝía·€—¦2¢b£ß»i$œÎ	Ç âV¹4ô{S
ÿ¥¶&amp;LŒç
Ðcœê�áòÖŸ{sxxG$à¶~`@y/ âºy˜Ä�ghlÐmÂm7ÜnÃ·Ê9ÆIn:\ýÝØ:„Ÿd·¸ƒý]—Ùð&amp;œ”.îÉÂõ�
±&nbsp;½xIÒØñmö³�ßw8CsÓ8ÆxæŒCfâö´ZÏŸ³Ãö¦ÌY$ŒàñÀÁ÷íž�#_íHþÊ÷lv�?ìç
1´�‚BãçÎÐ:óÆ(FKö»Sow5ÇúØ&gt;ÌÄ[†ä�7m#o*
G*ý�lè.æ�ÑœÝ¾ &nbsp;ô3�—Ðæ–KsŸaœ	u'å.þØÛTƒŸ@^y˜«
‘i¿èÐImwçúéÌ;¾ÍŸ£�¸Î~bÇ b�äEl?²kw³�e¯„¶±çfñ!NÝw9är(¡’I&gt;Åj‚F&gt;^íoo�Û‘�Á=	Àæ�-o÷%Š­³@3títøœŒÌAA?Ž20*7µ‚SýŸ$–ñZÅÊ_b§Û¼&gt;'{Ÿ|T¾";£ob¶Ã0È-Y~ÓŽw0Ýœg§Rxæ�ëòa½îÖ(à³ƒý}¹ºpfõÇ~s�ÀöÉ4·Xÿ´LQ&lt;ü¿aRoÝýãòúóŽ£§NiK­èûtíomsoÄV¢Ø�0‚Wv[wû¤œa&gt;Ðÿiƒ	¾?)±û+mÔ.ìþ=sÎhøQ¥(»¹Ž«Kœ-¾Ðïänî!ät%FAAÅO,
¦ºA¨,wrÝôiMÌ¸·R&gt;Qó.UTò
à•Ÿë¦1¼µx.î.0&amp;·6ÍˆAå°ñŽAèìGIà‘4ÀÐYËÌ7Œ~Ñ'ÙÜ›px=¸n‡Š?¯ÀbÔÂãOŸlº¤&nbsp;˜ïEÃáGUËŸÞÏg­*Â÷-ý™oåÅªD3%à�Á“{«æÝÁé�zŠ¶ð�.)c}6@KÞý�ŽÖ&lt;í,fsÀ'$
q�.a\òG�;Ñ/˜Ã¶öo,’:‘’p;Óþ¿�ub²X¬äµ#ígeóÇR2Šg%�|v¨À†û7ö±C­©"k8ƒ6:œÚrÁnN=zK;QU/dK8íRÖìã‚0�TëœŠ•¤’þU¾»+o{m‘omä²yÀt*®ÅØÿq�J@UdˆD5_)?³Xô/9ÁÝÓvÀ&lt;¼çæÆ;�­+ìÓ”^Ý$W—-šwo#w?uÐ¨Ú8$c�JÐy—ûTm±L}ˆ¯;znÙ¸H8ç'¿½2#5”�yf÷÷›/q‡'žî\{’Ò�ëñGÉK3%½Ü×›Œwc7ÙÁáFâ…”.AJûç�S-&nbsp;ñ(	¹ØíáÛë·~Àùí�0Žzw§©6[¬¬œ½­Ácyp±ä±á—rü£=sŒc®iTÄ4å•†�´tb&lt;·]»ø^ÝvšŒ[Gª3X[¬³Y�^ä9Äþ£z¨by,Ì@ì*`ÕOœ‰if,˜‰É�´mÎzF„‚GäœŒòjü¡/Ù/]¡ÓíÊýšo(©™»�Aç&lt;Æ3žŽ�½ó,º‘6Ó[1qùD	±÷IX¶ì�·q�Gõø•æÛ\ãWX¬âŽ A²-Ì˜Ç;D`döýÞÎsÎ^²[ÛgWò­fŽPª,QòPž3´£÷?»c«þmÄÎ5ƒåêè¤EiåpËÛåÉsŸ]À�å0ÂÆö×çÖeQæÛ2¨U^„…ùHÇ\ù‡4ÿ¯Ä"�4vó¼¸oõÀT�æ6ÙyV ò&gt;NxÈÅ[òM�þÏV7†ì·úWµ„‚øÇûéêjH?Ðw6˜EÕÌÌ&gt;ÚþY)ûûTmol–ú�#[/ÙtìË§M¸ÝË‚Þ[w
ØP£ì¿Ðš_×à!žNGö(p@RÇP=û=O?öÔtüDÀG¨gNÜmE¦Ò.�QöŒvåëÓ‡9'‘ÅUC—ö/œh{sö�¬¿LoÚÎ~Cõ«3¹_#PÌ:l;&gt;Ë.Nd#î‚ø9ÏùW�^¡ÿ_ˆ&lt;ƒTýüÛ¬É¾ãp.¶Ž?¹÷ÏøÆ	Ï³\ÃzãUT´‰¢”‡/'mÛB)$ýá…aŽ§ƒZW[†ê­%¼°¿ú
ÄŠÂL}Ì¨Y‰÷ÛøU6»�˜]\µÊk*A
Ûü¥:gi��ùrNh9çHê~]‹4ªìd1hóüF=£c®1Éü FƒNbéö;¿µpWk7‘Ÿb&gt;R3�^1Ò´ÕÈsql×Û14gR¡;ágÃ‚}{P·3[îþÌ’êF”ÿ¦³.SƒžL/Véé×¦Ê‘´6‹ýž­e<säµÉb|�ÜcqnÞ£ÐžÙâÀ··u[µª@´c“ÉÛ»!noÊrãÓ‘Š•%òsË°’ñ´Ç'í-ä©*oßÃyy.3�¡ÈÅù‹ÈfºþÄê²”1lñól�ü0~¼rgm}‹i¾Ëi¹]Ï”wísÀ!‡'’iÏõhšÞý–æo³ÙËho•„âç é×="" Ö§–s6#Õzé,��±¸…'.nÃ»åìzŽýèk‹‰ävÔzí="" c'ìaa@Ð‘åòoçëœb�ëð�ûr™µœeò®Ñ``l·8="" ÉÝž§;{uél?cvÔmšÞâîãkcnçÊÅ�­¸`u$="" ŒŽje–êwhnf½·¯—¦Ì÷{qœŸÏ½="" ’ê9¬~Òuƒ�µ‚‘ßiltÛŽÿ�…o:é»ÖÐÃv·lmÁx$Å¶zä~piÆvœ��1Ë¢ò£µ:lwöÒ^y.6-‘w„ù±Á-€2z¡óp7ök]²3·åb8ù¶îqƒ×…ç;Ñ±g="" Žtt="" Ï%"Ý¼ž�ŠÆìg�q‘@nÑßb,.dŽÚÒßi‚èÀÁfÆ2,qŒáŽzsg“ûm–k÷ŠÍ­}œwÿ�hq÷hÞÃ="" ž�×‘k30‹v¨.Ž•ò›m¦-ùþáh|ã7tíÅi#o”¸¹3–Í†Ï'Ž="">MÅ0wúï&gt;÷4	¹’iSP”Ç£á˜´“2Šp[q%NF2@èGQs<sj-“ê’®Ù,¾ÊùŒw8ÜÀËÎy'œÈæàj¢ì\m�Þac�b1ÆvþïîýíÃúÒbîf)l.·6æs¾1ÌóÎáÜíÚ�úgƒlbÛk6œ\éŽ.Þèÿ�¥ �‡Ùò9<0#nÁâŸŽÒØéÖlg±›qº»toÝg¨ À÷n="ê5ŽW,4…ºI�ÿ�§î‘Fx9Æö" ¶wcf:sá="" §ý£ûw}­Ð6‹hs»¦2="" ž”„="">W‚[a§tÑ�öÏ-Ég!r(¸ÉS“R]OîØu
öÖvÅM”¢9œ€ç*Ùr…88ÍDá"ˆM*\&gt;€TmŒÈ7n'å$ÛætÀ¯\Se‹ìØ“WŽyld X¨œ#)œH¤½³Ð¯&nbsp;©îdº’;­I^Úúßb…coßw”†9Îù“Î9Å)¹4_HŒuæM©jªÛgÈàl$�ÒãÛ š©,SÛ:Å©¤òêR“öYÁòú	¡Hb2X8on¦o*e²âOøH3çù¿(�9ÆíÛ~à ™¾)�f)g¶�çÓ—ÏÕ¦ÛöËvæ8†	;Xlî
Îø'·CnÌ­¹dÒ¸‚iœêHÄ³÷‚çË8
\‚ªý9,jŒ6ïs#ZiÎmõXvÉØ¶ÙqÃí ±?9�ˆéš–ÙcÔ36’~Íko#äpÊgÄ"—Èe±B	è
 /AöX­¼›t�ô†y™äó‚rÈ|–
Tç¨ à™íŒ&gt;Uüq.„«µ”&lt;…ÙˆAÚÞgwÎUv�É YÐ›y-þÝäÐ‘e´ ùŒù# `rå7š6ãøFjGžH¿´/›F™#Kk@�š7à‚Q°ŠT,€°‘³ž§�@�I¼·•[ŽV9‚i¥L¿&lt;ØíòñYÂ¨'�23šÏ*I¨G
ëª’ý’%gØÊl-†hÁ-æmÞã<r­ÊÄÓ.›"¾ªÂì^ÌÀù{Ì�€7p¢0eò&na ’+:ËfÉ§^:Ë¬n­®öo+µk°9y0u•¿��@ƒÈ…žâo4+æ f*r="" üÌ="" å„$+’jåo3Å)y\è‰="" ½i£þÑrÏµÏ»ir€þ`cæÏð“ÓÊ’ij…Êëh‹æÞüÊasÌpdá="" k¼ Þwiê3£n_s•í´É="">Éwg2}¶o-í,»‘Ÿ	�ß:»ß
Ûòy'v‚ÔG·HX”Æo·3´™@
ç lèW(zü£’n´6»Ãÿð‡%‹K¿ÌóIÀçÌ&gt;8#vzü¡m.¡Ô“ûCOskclÒýª!q&gt;3¶Õ?1eÀç,:ã&lt;1µ¯ö¨$éV&gt;Â-ã=©8ÎÑ‡ó÷vää(€GvÖo5XáM%?aeiw6c8ÈO›s�Á@Ç;Æ†bÒ«jIÖA›ì*›J€vn*Jãví¢B	k–ª·“Å¦¡ÔµöÍ&gt;ìÃökS‘cÜ¤#·—HÃ/ÉË“’G8�ä–Æd°ºcqxdkkÍ¤˜PQ@È¸!™•HXƒñ�(CÌrÇjÁÿ	�22åBdzþèIå‘Æz÷1pmDû¦‘tƒoý¡¾/·îóB�¹
³+·ïn¨È–ùÈ5�&lt;×'E³W�×¡NYAÄÃ÷¤lÚ¥Î2TŒnàÛˆ¶«3ØÙÊÖ—vO¹¸XÂ›’ŠQ‹*HÝ’Ë+1•èjÝ­™7é&amp;ìÓ$çP,_¼cqòvíçäÂýÜ»©Y5˜(`ÿ„|BÁÁóD‚A/^Fÿ½Œr±$gåÌ·‘ë)öû&amp;{KkIfk›q?hC1eR3¯0bç¨¤†ê-†¯tÒÖ�¬*Ø‘ƒ6Àvc&lt;“ŽÌ°/šÐÁ�H@4‚ ›|ÝÄìÊîÛÐ``³ïÍ6ñG�öÏÙ�É˜ÿg3}âWh“h„y$ÉíÀ§\ÝÃeö”þmÍ�×Ù„‚ÞI”!KmžrüÛTÂÓ¥K•b¼‘îæ¼��«˜}™˜c‚ÌÀ*ä)BÜh.Pìè.D#ÄF'6äoÛ³2`ž;Âù›wÑwPboœX˜ÿá"òÓíG-þ¯÷{¶ïfßþ¨0\7íä
¶ðySE’Y%Ô&amp;‰Þ-@ÆÆ¥˜”_Ìj¸È~7(@V½»^JúDÉ
ý¼q´·þP20…ÕÄ€|Ñœ—;¶0ÁÆH[á¥Æ„b'S©ŸŸ[!|àG–H”~èä|»x$†[‹vAý�å�$Æó&gt;fâû&gt;aóƒ0!vòñß¾Ð_ÿkJñØ1³k	×íl"	ö¼g,â&lt;’²f6Ü8-‚p+Áqô?Ú¶ƒìÚm¨˜Md"f`¼–TýÛ‡F@K‚#+×`+›gˆ™ü¯øGH!ÿXÌßŒŒ´nß¸6p
`óóš”¬;ƒk&gt;Q´3F4Å]ù�“!â¥|½Þn@läT­v‘Bu‰—ÌÒe…;€¬r;¬Dœ¼¿w3Mpšc}§QÝym,mh†=ßfÇ#u
¨	m„ã962�­«¿¶·Iö“·lË&gt;^7îÙæœž7‚j¤�&amp;ñ°)ñ)ŒU¯'ìþaƒnq‘×g™ž94ùL¾cs}vÒy›w=º¶U
³|à†Š£/—»åcÁ§Ám3»h®ï¦!6&nbsp;€—eÞa“å”&nbsp;c_®Ò�ªËænÑ|³ª†A¨ç;s�Þ&gt;#Øe\Ã‡ãåê*õ’[ª)ÐÌ#MY$â]ä»¹”3#Î0vFx-‰ÒMA¤²µy,®lÞ=Ð‹k]�Œ6
’e°ìêÀƒ‚EëP·çÏ²ó,aµž_´Aöp&gt;Òv¨$¨ÃË‘Ê³ÇÊT�ìZU1ù?ðŽ˜›ÌÝçyžg›Án|Í¡yÏþ™Ó®V×ÉÎ¦aþÅ"ßìC÷»�ØvçIÊd°bp:ào©ã’'¶¤BDÓ’	´ñá¿xÁ˜&nbsp;%y8'ŽXqRÏ"ÙDÚ�ÈšæÒà[ùVbo³ð
�¥Š‚3�¸l±Ú@Kå‹ˆÿ¶V•ni¡ž«·vÜŽ¢&gt;X`1û£åHÆÉ£fÝµÓ‚&lt;ß,®\®p\ð�ûxÍKå�.U­%ó]\Ÿ!¼•?f.á‰mªq�€HLn§Á¶ªº|’K5ãÅ.Ëï#!1!Y‰`8ùK@Q�JdªÄÌâØZÿl*Eö’D»6»‘�£9ÆÍü«„g#LÂßÎ•oC\`0PÒÜ�Ûø#àÕµó\}‘d•&amp;„DZá¡e€%vÃ!¶ò…� ŠºÌC#:,lÁÔÆFüq½A+žC&amp;Cc‚EsQÇj-6Ä-Æ‡ä¾óº_0�Ç8öÏ\“!nœàº[SnVü[
#ý›i�6p
îÆUØ~æwä­/µ4‹ý¢|ô�bpÖ­$,ïm#~ì÷H!²sÓµ¸kùŒÓÛL!òíDxÏ‘÷³œHÀÉÚó*JƒTÁÚr,v†cÓå$²ü¯Ó,0¹ÀíÉä:Cyöoíc†=ŠåäãÃxSÆá¸!¶ð8”I5ƒpÓ]ý¢cå´p[©öä…^…Ødç‘�Æˆ„ðF¶I4³È’µˆ€U9;wu@ÀîÛ“Œ�@¡�YÌ@ÆnÑÊ#¯ïm';rN;ÕÄ•$ÎÂiÚØ9ÁAô#=+/386HóG,H„Ü˜”«ž‡�BÇpåÍ[viÏîÙâòœoýßßr&nbsp;ºò÷“ð4^{˜Äf\Äl•_Î''€9@*G]ÀóØšåï¦µh¼ËŸ$è/yjŠêÂMÙTPã¡àcñÍlItó¨ÔŸ¼(–ÕàùåàŒàœãºõuÇ5ÊêWA#]fE3é²"¢XÈUn�ŠÑŒNìãŠCy‚AÕƒ"Ëýœ Û¸d|ƒ ‡ÎÀ¿ë\õ=ª´¦íd�uqý®w}�”Ûùj?‡vÆr~þðsÆ*µÍÔv'íIo¨Gxq}&nbsp;Ÿ²©…
Q‚��7 R
ã#5XtýºtŸfº¸ºÎËÑ9&gt;Fx_˜©eÛ×åuÜ1š])x&amp;Û�ý¿´b`ò¼³Û1ãoL.ìöÍFëÍì‘8¿S‹òÍ	ûÅ…³œm¶*	ÑÿdfØ]…u˜‚{í-´¾qò•ÞGµW’ÞßS?d‰m,å´#ÌœÎvÜ`sƒ±r©$¶&gt;ƒ�„Hé'öRÝ&amp;Ÿÿ/»ÚÜ99ù¶&lt;uÛŒô#S#r‹¿ìryƒÍß�AÎÝß�õÝŠ„G&nbsp;
Ì)kk·À×MÁ^¤|£ïcŒóÈÁ&amp;«ïµsý¤!€Zƒ�±“¸�1»AÆy)±Š¿&gt;ãh›Á¥sö@¢!þîütÂç³è¼f²o&amp;¹”¯Û}è£ÈÜ&nbsp;|¹ù»ù€r{â¦h¢·Åì±Ãqo6v[%Ón‹&lt;€vüÃëŠÏ’ÔÛá[Ê&amp;Q•Ù*¸\öb¤í&gt;¡¹îhHŒï01™�Ùo”©;ºv9ÝœtöéZ6ÒÜA&amp;ëµiüâ|¢8ÛŸ›·6ìã%—9èFi-ºö6Hšvl¬ÿhTc;N	ŒŽÙÈ9àò$L«kqÅq&gt;eÇÚ2²ž$F½°TœàzÑýtÖ�`lä¸Ré‹€ÁPÜ¬w)ÉÈl~¦ª«`mO$‘¸R2ŸNiBy«ò×Ë7ï-î7·'Ž‹ž¸Ç"£8o˜.íœÿ&gt;i­Êñ¤zƒ\}Ž5o F©�Äÿµ�Ž¹äôÀ#¨Ùiv‰u_´ý°�ýœWÉUnì¹Ý³vþqÃs\œ2E’1*�FÒì˜'£duÇ¡à×C®˜Øà»{ÕL­qŸ³‚9d;
’FÑÆ#8_¶”\yÃ_Æa Ûù[p0Ë]ÙÈÎOzÍ•.|òagX›’»6÷&lt;¬ö áä�J¿åq¥ÊÖó^Ê7.&nbsp;n˜Àè¹*\0€»ÔŽ:g2Hcwû»„æKÁvÊ²Œ�›' IÈôÍ02yÿ–&amp;Làù¹sžGr¿P9íN·™Àòäi…«02¬dr=B±[Ó5.îUÚ0H|ç±çé×­1H8²yöÈÁþµ#:o1�²¥×Úÿ±ˆ‡jÛù›�;Cw`ÙÉ ‘€8ánÌÛ#þÖûOÙÕÐ6ˆÎß3nIà.AÉïÎsYVþ]¹SÅð�³™ðA=öngÇR¤Ä™V;%\ÅÂ\. _µô|÷Û†#:ç¥Õ¸kÇ™N¥öŸíS·ì{ÝSnr»Êàgqlät=À‰…çÚ³þ“ýº,@‡ÊÙ³`íÎÌsŒc#æ«5ªY¿Ø.R	în1]}©ŠÂ8H'¨ëÐŽ¨m@ì¿ôsy�ßnûS*Fí™Ú	 |¿^ï@%½Ì²fn$¼ùÍÈ
iÏÍó+’Ùn¹'©­–O-ÅŸÚM‘	öÏ’-ÀçoÌrÜG ÿxb›öE½ÿD·X-î-”‰¦ûQ9ŒŒœž0{
rˆµÜZÅ
¬6ê&lt;è~ÔAŸ“Œ¨'�ŽýxÉâ�Ë(H„€n¿°‹‚ß,&gt;a~8È!¶î‘Ç|nâ§�ÜÂ¿Új&gt;Ñ&lt;ÌŒíßüCv7g?Nj€X]N¦ ‰,…6Ÿj9fànåI&lt;�p8¸n-íGÛg†‹Y‰[-ÙÝzdc=ÉÛÆrpqL	å39VÕMÐ›hûUˆƒ�¹»Œw'ŽrOJšf½®
ÏöÐ+å òöcŽŸ/®p6õÜN(›x¬Ë˜á¹{¡û‡[’|Œô¶Fs�ÇSÍ)·[SýŸ*D÷®AKÁtÀF0	Û�”dœóÓ�@�8&gt;Øfo±}¤ë}n7›qÞ„Ä¡wo@8«6M;n/ÚÞ?´žFÒyÜT±,ßû˜ãä
ÍŠ#pßÙöÞE­ìC/z.Ü	GFPUrÛ²22z�ÍhÙ‡Õr¶Ãbl¿ãäÇ3fåGÞ
±õl³–ë‚hVÍ!òÇØ6a•µùœ6ì|Ä’&lt;ÜýÜm8ëŒ|¦µÏÙ×lŸg”»2foÜ1œà�œÿ·œwÍfi³ý¾1¨Úÿ¢Ø[YF€¬¸'€ªÛ¸ä©éƒŽMmÛ\ù�®&nbsp;�BÙefVÈÁ2xþî09àR+É*51iöRñ‹-¡Ù³�—qeÀ8Æ
ñŒƒï$›Ã©ºû!Ô3/Øþøvñ’FìãïíÇJ²�5›4Ó&lt;—ÎéåF°äÂ©\œg’X
¸úÓKMú#K#Ïpd1L!bÈÝ�“ŽÙå�­þ¿­æ_.V’²¶¸Ñ(‘KÈfW8\ç¦N:‰ŠG}[›·™&gt;ÜGl}íØù¸!‰Æïòä`&lt;¯šíeÂ-Q#C-×ÙW.€�Q°ƒÇˆ8,2Ù$‹N”[Om*ý­¾Ì¹˜€AÎq÷°~aóc¡V´KtO/JXM-(¼,òno;I'ŒuÆAÛ�óT%-&gt;Ëå…·•’Ûåó7ïÈï»;ð0rÄÿ~J±Ñ^/Úì˜ÛÙÛ&lt;ßh·ã÷äœàsÎ8$“Èb&nbsp;ûU¹µþÓgÆ“åíûµ@3»õÁ;¹=2hÑ³h¶jb¤/”,Š´…˜íÀ9R[dã®FM$²‰%�ûb8’î9_û4+I‰1´¡mŒÀe¶cÌ
z|¹Îe¹ºK7—çí:}ÃD-ààù$�”•`6àvêOÝÀªó§J±ê,nî/&amp;o±Ëå‚-ÉÀBcaÉRUAÛŒóŒÐ2ž%óc¸ºÿ	ÆÞLýÛ¨-‚ÞYØfò˜&nbsp;÷Æ&gt;Tß"ÌóééëÎ‹ö¨w’‘¦Fò»˜G»"0ÃÌm¿Â;˜. tÓ&amp;`úÔˆÞUæX„Œîm¾aOºd!Û¸ãÝª’Ï#é–¤C¬Fªg»ÀJ£†ð¥ùÜ�Td¨Ï¥1Ç–î4`’É$Ÿñ3Üøw*îØ6dÊwF†08À¨¢Kd‡ËÓŽý™</r­êäó.›"¾ªâì^ìàù{ì�€7p¢0eò&na></sj-“ê’®ù,¾êùœw8üàëîy'œèæàj¢ì\m�þac�b1ævþïîýíãúòbîf)l.·6æs¾1ìóîáüíú�úgƒlbûk6œ\éž.þèÿ�¥></säµéb|�ücqnþ£ðžùâà··u[µª@´c“éû»!noêrãó‘š•%òsë°’ñ´ç'í-ä©*oßãyy.3�¡èåù‹èfºþäê²”1lñól�ü0~¼rgm}‹i¾ëi¹]ï”wísà!‡'’iïõhšþý–æo³ùëho•„âç></p­„!~ëh-nçøöìuá6~ñçÿõbûwù˜îî:go‰ùj+k{»©m¶ž²åªb'7r‹‚></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.graybeardgames.com/download/diablo_pitch.pdf">http://www.graybeardgames.com/download/diablo_pitch.pdf</a></em></p>]]>
            </description>
            <link>http://www.graybeardgames.com/download/diablo_pitch.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844666</guid>
            <pubDate>Wed, 21 Oct 2020 04:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AOC plays Among Us live on Twitch and has 330k viewers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24844474">thread link</a>) | @tomashertus
<br/>
October 20, 2020 | https://www.twitch.tv/aoc | <a href="https://web.archive.org/web/*/https://www.twitch.tv/aoc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.twitch.tv/aoc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844474</guid>
            <pubDate>Wed, 21 Oct 2020 03:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Jamstack is failing at comments]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24844172">thread link</a>) | @leoloso
<br/>
October 20, 2020 | https://leoloso.com/posts/jamstack-failing-at-comments/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/jamstack-failing-at-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few weeks ago I added <a href="https://wptavern.com/matt-mullenweg-clarifies-jamstack-remarks#comment-344626">this comment in WPTavern</a>, on an article where WordPress founder's Matt Mullenweg clarifies his earlier remarks that the Jamstack is "a regression for the vast majority of the people adopting it".</p><p>Since I like owing my own content, I reproduce it here in my own blog.</p><hr><p>I think Matt’s brutal honesty is welcome, because most information out there about the Jamstack praises it. However, it also comes from developers using these modern new tools, evaluating their own convenience and satisfaction. As Matt points out, that doesn’t mean it makes it easier for the end user to use the software, which is what WordPress is good at.</p><p>I actually like the Jamstack, but because of how complex it is, it’s rather limiting, even to support some otherwise basic functionality.</p><p>The definitive example is comments, which should be at the core websites building communities. WordPress is extremely good at supporting comments in the site. The Jamstack is sooooo bad at it. In all these many years, nobody has been able to solve comments for the Jamstack, which for me evidences that it is inherently unsuitable to support this feature.</p><p>All attempts so far have been workarounds, not solutions. Eg:</p><ul><li>Netlify forms: no hierarchy, so can post a comment but not a response (unless adding some meta to the comment body? how ugly is that?)</li><li>Storing comments in a GitHub repo: it takes a long time to merge the PR with the comment</li></ul><p>Also, all these solutions are overtly complicated. Do I need to set-up a webhook to trigger a new build just to add a comment? And then, maybe cache the new comment in the client’s LocalStorage for if the user refreshes the page immediately, before the new build is finished? Seriously?</p><p>And then, they don’t provide the killer feature: to send notifications of the new comment to all parties involved in the discussion. That’s how communities get built, and websites become successful. Speed is a factor. But more important than speed, it is dynamic functionality to support communities. The website may look fancy, but it may well become a ghost town.</p><p>(Btw, as an exercise, you can research which websites started as WordPress and then migrated to the Jamstack, and check how many comments they had then vs now… the numbers will, most likely, be waaaaaaay down)</p><p>Another way is to not pre-render the comments, but render them dynamically after fetching it with an API. Yes, this solution works, but then you still have WordPress (or some other CMS) in the back-end to store the comments :P</p><p>The final option is to use 3rd parties such as Disqus to handle this functionality for you. Then, I will be sharing my users’ data with the 3rd party, and they may use it who knows how, and for the benefit of who (most likely, not my users’). Since I care about privacy, that’s a big no for me.</p><p>As a result, my own blog, which is a Jamstack site, doesn’t support comments! What do I do if I want feedback on a blog post? I add a link to a corresponding tweet, asking to add a comment there. I myself feel ashamed at this compromise, but given my site’s stack, I don’t see how I can solve it.</p><p>I still like my blog as a Jamstack, though, because it’s fast, it’s free, and I create all the blog posts in Markdown using VSCode. But I can’t create a community! So, as Matt says, there are things the Jamstack can handle. But certainly not everything. And possibly, not the one(s) that enable your your website to become successful.</p></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/jamstack-failing-at-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844172</guid>
            <pubDate>Wed, 21 Oct 2020 02:01:49 GMT</pubDate>
        </item>
    </channel>
</rss>
