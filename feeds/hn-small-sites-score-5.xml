<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 11 Oct 2020 01:11:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 11 Oct 2020 01:11:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It, Part IVa: Steel Yourself]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24726793">thread link</a>) | @parsecs
<br/>
October 8, 2020 | https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, we continue our four(and a half)-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">II</a>, <a href="https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">III</a>, IVa, IVb) look at pre-modern iron and steel production.  Last week, we looked at how a blacksmith reshapes our iron from a spongy mass called a bloom first into a more workable shape and then finally into some final useful object like a tool.  But as we noted last week, the blacksmith doesn’t just need to manage the shape of the iron, but also its hardness and ductility.</p>



<p>As we’ll see this week, those factors – hardness and ductility (and a bunch of other more complex characteristics of metals which we’re going to leave out for simplicity’s sake) – can be manipulated by changing the chemical composition of the metal itself by <em>alloying</em> the iron with another element, carbon.  And because writing this post has run long and time has run short, <em>next</em> week, we’ll finish up by looking at how those same factors also respond to mechanical effects (work hardening) and heat treatment.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<h2>What Is Steel?</h2>



<p>Let’s start with the absolute basics: <em>what is steel</em>?  Fundamentally, <strong>steel is an alloy of iron and carbon</strong>.  We can, for the most part, dispense with many modern varieties of steel that involve more complex alloys; things like stainless steel (which add chromium to the mix) were unknown to pre-modern smiths and produced only by accident.  Natural alloys of this sort (particularly with manganese) might have been produced by accident where local ores had trace amounts of other metals.  This may have led to the common belief among ancient and medieval writers that iron from certain areas was superior to others (steel from <a href="https://en.wikipedia.org/wiki/Noricum">Noricum </a>in the Roman period, for instance, had this reputation, note Buchwald, <em>op. cit.</em> for the evidence of this), though I have not seen this proved with chemical studies.</p>



<p>So we are going to limit ourselves here to just carbon and iron.  Now in video-game logic, that means you take one ‘unit’ of carbon and one ‘unit’ of iron and bash them together in a fire to make steel.  As we’ll see, the process is at least moderately more complicated than that.  But more to the point: <strong>those proportions are totally wrong</strong>.  Steel is a combination of iron and carbon, <em>but not equal parts or anything close to it</em>.  Instead, the general division goes this way (there are several classification systems but they all have the same general grades):</p>



<p>Below 0.05% carbon or so, we just refer to that as iron.  There is going to be some small amount of carbon in most iron objects, picked up in the smelting or forging process.<br>From 0.05% carbon to 0.25% carbon is mild or low carbon steel.<br>From about 0.3% to about 0.6%, we might call medium carbon steel, although I see this classification only infrequently.<br>From <strong>0.6% to around 1.25%</strong> carbon is <em>high-carbon steel</em>, also known as <strong>spring steel</strong>.  For most armor, weapons and tools, this is the ‘good stuff’ (but see below on pattern welding).<br>From <strong>1.25% to 2%</strong> are ‘ultra-high-carbon steels’ which, as far as I can tell didn’t see much use in the ancient or medieval world.<br><strong>Above 2%</strong>, you have <strong>cast iron</strong> or <strong>pig iron</strong>; excessive carbon makes the steel much too hard and brittle, making it unsuitable for most purposes.</p>



<figure><img data-attachment-id="4764" data-permalink="https://acoup.blog/360074001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg" data-orig-size="2200,2431" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="360074001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=271" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=927" src="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=927" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=927 927w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=1854 1854w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=136 136w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=271 271w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=768 768w" sizes="(max-width: 927px) 100vw, 927px"><figcaption>This is a difficult topic to illustrate so, since the internet is for cat pictures,<a href="https://www.britishmuseum.org/collection/object/A_1993-0714-2"> via the British Museum</a>, here is a Ming Dynasty cast-iron statuette of a cat, 15th or 16th century.  Cast iron production was discovered much earlier in China than in most of the rest of the world, but cast iron products were brittle and not generally suitable for demanding use.</figcaption></figure>



<p>I don’t want to get too bogged down in the exact chemistry of how the introduction of carbon changes the metallic matrix of the iron; <a href="https://en.wikipedia.org/wiki/Steel#Properties">you are welcome to read about it</a>.  <strong>As the carbon content of the iron increases, the iron’s basic characteristics – it’s ductility and hardness (among others) – changes</strong>.  Pure iron, when it takes a heavy impact, tends to deform (bend) to absorb that impact (it is ductile and soft).  Increasing the carbon-content makes the iron harder, causing it to both resist bending more and also to hold an edge better (hardness is the key characteristic for holding an edge through use).  In the right amount, the steel is springy, bending to absorb impacts but rapidly returning to its original shape.  But <em>too much</em> carbon and the steel becomes <em>too</em> hard and not ductile enough, causing it to become brittle.</p>



<p>Compared to the other materials available for tools and weapons, high carbon ‘spring steel’ was essentially the super-material of the pre-modern world.  High carbon steel is <em>dramatically</em> harder than iron, such that a good steel blade will bite – often surprisingly deeply – into an iron blade without much damage to itself.  Moreover, good steel can take fairly high energy impacts and simply bend to absorb the energy before springing back into its original shape (rather than, as with iron, having <em>plastic</em> deformation, where it bends, but doesn’t bend back – which is still better than <em>breaking</em>, but not much).  And for armor, <a href="https://acoup.blog/2019/07/04/collections-archery-distance-and-kiting/">you may recall from our previous</a> look at arrow penetration, a steel plate’s ability to resist puncture is <em>much</em> higher than the same plate made of iron (bronze, by the by, performs about as well as iron, assuming both are work hardened).  of course, different applications still prefer different carbon contents; armor, for instance, tended to benefit from somewhat lower carbon content than a sword blade.</p>



<p>It is sometimes contended that the ancients did not know the difference between iron and steel.  This is mostly a philological argument based on the infrequency of a technical distinction between the two in ancient languages.  Latin authors will frequently use <em>ferrum</em> (iron) to mean both iron and steel; Greek will use <a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.04.0057%3Aentry%3Dsi%2Fdhros&amp;highlight=iron">σίδηρος </a>(sideros, “iron”) much the same way.  The problem here is that high literature in the ancient world – which is almost all of the literature we have – has a strong aversion to technical terms <em>in general</em>; it would do no good for an elite writer to display knowledge more becoming to a tradesman than a senator.  That said in a handful of spots, Latin authors use <a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.04.0059%3Aentry%3Dchalybs1&amp;highlight=steel"><em>chalybs</em> </a>(from the Greek χάλυψ) to mean steel, as distinct from iron.</p>



<p>More to the point, while our elite authors – who are, at most dilettantish observers of metallurgy, never active participants – may or may not know the difference,<strong> ancient artisans clearly did</strong>.  As Tylecote (<em>op. cit.</em>) notes, we see surface carburization on tools as clearly as 1000 B.C. in the Levant and Egypt, although the extent of its use and intentionality is hard to gauge to due rust and damage. There is no such problem with Gallic metallurgy from at least the La Tène period (450 BCE – 50 B.C.) or Roman metallurgy from c. 200 B.C., because we see evidence of smiths quite deliberately varying carbon content over the different parts of sword-blades (more carbon in the edges, less in the core) through pattern welding, which itself can leave a tell-tale ‘streaky’ appearance to the blade (these streaks can be faked, but there’s little point in faking them if they are not already understood to signify a better weapon).  There can be little doubt that the smith who welds a steel edge to an iron core to make a sword blade understands that there is something <em>different</em> about that edge (especially since he cannot, as we can, precisely test the hardness of the two every time – he must know a method that <em>generally</em> produces harder metal and be working from that assumption; high carbon steel, properly produced, can be much harder than iron, as we’ll see).</p>



<figure><img data-attachment-id="4760" data-permalink="https://acoup.blog/34632001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg" data-orig-size="2500,1692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="34632001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/G_1866-0806-1">Via the British Museum</a>, the so-called ‘Sword of Tiberius,’ a Mainz-type Roman gladius from the early imperial period (c. 15 AD).  The sword itself has a mild steel core with high carbon steel edges and a thin coating of high-carbon steel along the flat.  Almost certainly the higher carbon edge was welded on to the mild steel core during manufacture, an example of a blacksmith quite intentionally using different grades of steel.</figcaption></figure>



<p>That said, our ancient – or even medieval – smiths do not understand the chemistry of all of this, of course.  Understanding the effects of carbuzation and how to harness that to make better tools must have been something learned through experience and experimentation, not from theoretical knowledge – a thing passed from master to apprentice, with only slight modification in each generation (though it is equally clear that techniques could move quite quickly over cultural boundaries, since smiths with an inferior technique need only imitate a superior one).</p>



<h2>Making Steel</h2>



<p>Now, in modern steel-making, the main problem is an excess of carbon.  Steel, when smelted in a blast furnace, tends to have far too much carbon.  Consequently a lot of modern iron-working is about walking the steel down to a usefully low amount of carbon <a href="https://en.wikipedia.org/wiki/Steelmaking#Modern_processes">by getting excess carbon out of it</a>.  But ancient iron-working approaches the steeling problem from exactly the opposite direction, likely beginning with something close to a pure mass of iron and having to find ways to get more carbon into that iron to produce steel.</p>



<p><strong>So how do we take our carbon and get it into our iron?</strong>  Well, the good news is that the basic principle is actually very simple: <strong>when hot, iron will absorb carbon from the environment around it, although the process is quite slow</strong> if the iron is not molten (which it never is in these processes).  There are a few stages where that can happen and thus a few different ways of making steel out of our iron.</p>



<p>The popular assumption – in part because it was the working scholarly assumption for quite some time – is that iron can be at least partially …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/">https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24726793</guid>
            <pubDate>Fri, 09 Oct 2020 04:20:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bye-Bye, Apple]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24726241">thread link</a>) | @rauhl
<br/>
October 8, 2020 | http://blog.cretaria.com/posts/bye-bye-apple.html | <a href="https://web.archive.org/web/*/http://blog.cretaria.com/posts/bye-bye-apple.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                
                <p>Sync’ up! … without getting drained</p>
            </header>
	    <section>
<article>
<p><abbr>oct 8</abbr></p>
<h2>Bye-bye, Apple</h2>
<p>The days of Apple products are behind me.
I had been developing on a Macbook for over
twelve years, but now, I’ve switched to an
ever trending setup: OpenBSD on a Thinkpad.</p>

<p>The new platform is a winner. Everything is
clean, quick, and configurable. When I 
<code>ps uaxww</code>, I’m not hogging ‘gigs’ of <abbr>RAM</abbr>
just to have things up and running. There’s
no black magic that derails me at every turn.
In short, my sanity has been long restored.</p>

<h3>What I miss</h3>


<p>Nothing is better than a fast web browser.
In Mac, this ‘<abbr>OS</abbr> within the <abbr>OS</abbr>’ was 
a mean beast. It certainly ran fast, but
the Chromium package for OpenBSD isn’t all
that bad.</p>

<p>That magnet power interface was a real win
with the Apple laptops. I miss that, in 
addition to speakers that could be maxed
out to their potential.</p>

<h3>On the other hand…</h3>


<p>There’s a healthy list of things I will
forever be glad to never have to deal 
with again:</p>

<ul>
<li>Xcode</li>
<li>the omnipresent ‘Dock’ (never used it once)</li>
<li>the omnipresent ‘Finder’</li>
<li>‘.DS_Store’ files</li>
<li>black magic in the ‘Terminal.app’</li>
<li>Notifications (and its omnipresent menu hamburger icon)</li>
<li>App store</li>
<li>start-up chord</li>
</ul>
<p>I’ve noticed that with every passing year, the
peripheral interface ports are dwindling. On
an older Macbook, I still had <em>some</em> options (<abbr>SD</abbr>
card reader, <abbr>USB2</abbr>, etc.). But lately, it’s out of
control.</p>

<p>On this middle-of-the-road Thinkpad, I have
an <abbr>SD</abbr> card reader,
<abbr>HDMI</abbr>, scads of <abbr>USB</abbr> ports, <abbr>RJ-45</abbr> —
I’m never going to need a dongle, or say the
word dongle, ever again now that Apple is 
out of my life.</p>

<h3>Home again</h3>


<p>My memory is pretty good. And I recall when
I got my first Mac product: it was because
there was no other decent option for
having a development laptop, but one
where Microsoft Windows wasn’t a requirement.</p>

<p>Many times I tried duct-taping a Linux
install on my various Macs, but things 
were ‘just not there.’ There was always
an issue with this or that, and it was
truly painful.</p>

<p>I think I lost the scent of the trail. 
OpenBSD works so well, I wonder how many
years I could have been using this great
<abbr>OS</abbr> outside of just the server world.</p>

<p>Of course, this setup isn’t for all. If
you’re green on the <abbr>UNIX</abbr> front, or
can’t read a manual, you’d be foolish 
to do it. For the others, it certainly
is a viable solution, to say the least.</p>

<p>I can honestly predict that I can see 
myself using this setup for twenty-five
more years. It’s like coming home to a
quiet, orderly house.</p>

<p>Open your heart to OpenBSD on Thinkpad
at your first opportunity.</p><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" viewBox="200 0 400 800" width="400" height="800"><rect width="400" height="800" fill="#b33a3a"></rect><polygon points="299.5 150 254.5 247 351.5 247 "></polygon><path d="m321.9 548.9l-243.8 0"></path><path d="m303 247.1l0 243.8"></path><polygon points="94.5 150 49.5 247 146.5 247 "></polygon><path d="m98 247.1l0 243.8"></path><text font-family="Helvetica, Arial, sans-serif" font-size="60" y="112" x="10" style="fill-opacity:null">THIS END UP</text><a xlink:href="//cretaria.com"><text id="link-cretaria" font-family="Helvetica, Arial, sans-serif" font-size="50" y="680" x="10" fill-opacity="null">What’s Cretaria?</text></a><path d="m175 700l200 0" style="fill-opacity:null;fill:none;stroke-linejoin:null;stroke-opacity:null;stroke-width:4;stroke:#000"></path></svg></p></article>
            </section>
            
        </div></div>]]>
            </description>
            <link>http://blog.cretaria.com/posts/bye-bye-apple.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24726241</guid>
            <pubDate>Fri, 09 Oct 2020 02:49:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Report may suggest that login requirement for Oculus Quest 2 is anticompetitive]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 144 (<a href="https://news.ycombinator.com/item?id=24725515">thread link</a>) | @vrfinal
<br/>
October 8, 2020 | https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <main>
            <article>
                            <p><time datetime="2020-10-08">
                  Oct 08, 2020
                </time>
                <span>2 min read</span>
              </p>
                <div>
    <p><a href="https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/">
        <img data-srcset="/content/images/size/w400/2020/10/Oculus.png 400w, /content/images/size/w750/2020/10/Oculus.png 750w, /content/images/size/w960/2020/10/Oculus.png 960w" data-sizes="auto" alt="Report from the House of Representatives may suggest that the Facebook login requirement for the Oculus Quest 2 is anticompetitive." srcset="https://www.vrfinal.com/content/images/size/w400/2020/10/Oculus.png 400w, https://www.vrfinal.com/content/images/size/w750/2020/10/Oculus.png 750w, https://www.vrfinal.com/content/images/size/w960/2020/10/Oculus.png 960w">
      </a>
    </p>
  </div>
              <div>
                <div>
                  <p><a href="https://www.documentcloud.org/documents/7222836-Investigation-of-Competition-in-Digital-Markets.html">A recent report</a> from the US House of Representatives subcommittee on antitrust laws suggests that the requirement for all Quest 2 users to login via a Facebook account may be anticompetitive.</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/ts_oculus-quest-2.png" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/ts_oculus-quest-2.png 600w, https://www.vrfinal.com/content/images/2020/10/ts_oculus-quest-2.png 960w" sizes="(min-width: 720px) 720px"></figure><p>The Oculus Quest 2 is the first headset produced by Facebook that requires users to create an account on their social media site in order to set it up. The report states that, <em>“conditioning access to a product or service in which a firm has market power to the use of a separate product or service is anticompetitive.”</em></p><p>The report, which clocks in at a terrify 449 pages, investigates the issues of competition in the digital market. The report looks at companies like Amazon, Google, Apple, and yes, Facebook. The report only mentions VR a small number of times, but it does go into detail about the large acquisitions of that each company has made. This includes Facebook’s purchase of Oculus in 2014.</p><p>The report states,</p><p><em>“Facebook has also maintained and expanded its dominance through a series of acquisitions of companies it viewed as competitive threats, and selectively excluded competitors from using its platform to insulate itself from competitive pressure.</em></p><p><em>Facebook has also maintained its monopoly through a series of anticompetitive business practices. The company used its data advantage to create superior market intelligence to identify nascent competitive threats and then acquire, copy, or kill these firms. Once dominant, Facebook selectively enforced its platform policies based on whether it perceived other companies as competitive threats. In doing so, it advantaged its own services while weakening other firms.”</em></p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Sidequest-New-Logo-1.jpg" alt=""></figure><p>This has major implications for the future of the Oculus and developers, we have seen Facebook flex their considerable power over smaller developers. We have previously reported on the issues that the <a href="https://www.vrfinal.com/unofficial-oculus-quest-appstore-receives-650-000-in-funding/">developer focused app store, Sidequest</a>, has had in gaining purchase in the Oculus ecosystem, not to mention the <a href="https://www.vrfinal.com/vr-developers-are-concerned-about-facebooks-walled-garden/">side-lining of the VR steaming service, Bigscreen</a>, by giving favourable terms to large companies like Fandango. With Facebook offering the most affordable headset on the market, we may see even more developers become disillusioned with the Oculus ecosystem and move on to greener pastures.</p>
                </div>
                  
                              </div>
            </article>
              <section>
    <p><img data-src="/content/images/size/w150/2020/09/IMG_20200812_155324.jpg" alt="Andrew Boggs" src="https://www.vrfinal.com/content/images/size/w150/2020/09/IMG_20200812_155324.jpg">
    </p>
    <div>
      
      <p>Andrew is a Northern Ireland based journalist with a passion for video games. His latest hobby is watching people speedrun Super Mario 64 and realising how bad he is at platformers.</p>
    </div>
  </section>
            <div>
      <div>
        <p><img data-srcset="/content/images/size/w400/2020/10/jump-vr-headset-1021x580.jpg 400w, /content/images/size/w750/2020/10/jump-vr-headset-1021x580.jpg 750w, /content/images/size/w960/2020/10/jump-vr-headset-1021x580.jpg 960w" data-sizes="auto" alt="Co-Founder of The Void announces his new VR attraction: Skydiving" srcset="https://www.vrfinal.com/content/images/size/w400/2020/10/jump-vr-headset-1021x580.jpg 400w, https://www.vrfinal.com/content/images/size/w750/2020/10/jump-vr-headset-1021x580.jpg 750w, https://www.vrfinal.com/content/images/size/w960/2020/10/jump-vr-headset-1021x580.jpg 960w">
        <span>Previous Post</span></p><h4>Co-Founder of The Void announces his new VR attraction: Skydiving</h4>
        </div>

    <div>
      <p><img data-srcset="/content/images/size/w400/2020/10/all-new-zapbox-1.png 400w, /content/images/size/w750/2020/10/all-new-zapbox-1.png 750w, /content/images/size/w960/2020/10/all-new-zapbox-1.png 960w" data-sizes="auto" alt="The All-New ZapBox revealed on Kickstarter, MR headset for only $40" srcset="https://www.vrfinal.com/content/images/size/w400/2020/10/all-new-zapbox-1.png 400w, https://www.vrfinal.com/content/images/size/w750/2020/10/all-new-zapbox-1.png 750w, https://www.vrfinal.com/content/images/size/w960/2020/10/all-new-zapbox-1.png 960w">
      <span>Next Post</span></p><h4>The All-New ZapBox revealed on Kickstarter, MR headset for only $40</h4>
      </div>
</div>            


        </main>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24725515</guid>
            <pubDate>Fri, 09 Oct 2020 00:35:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never Again: We Need Science Based Government]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 35 (<a href="https://news.ycombinator.com/item?id=24725512">thread link</a>) | @pbw
<br/>
October 8, 2020 | https://www.kmeme.com/2020/10/never-again.html | <a href="https://web.archive.org/web/*/https://www.kmeme.com/2020/10/never-again.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4155188876056568307" itemprop="description articleBody">
<p>This year Americans have been whipsawed between feelings of fear and helplessness. More than 200,000 of us died from COVID-19, the streets raged in conflict, and wildfires destroyed more than seven million acres of wilderness.</p>

<p>The media and the general public turned to scientists to help understand all three crises, but President Trump did not. Instead, he steadfastly and repeatedly denounced scientific consensus. He vociferously denigrated scientists and their beliefs. He invented pet theories during press events and routinely ignored even his own advisors.</p>

<p>Today we are focused on the general election, but even if Mr. Trump loses, Pandora's box sits wide open. We now know an administration can wreak havoc by wantonly flouting scientific consensus. We cannot let this happen again, we cannot allow <i>either</i> party to do this again. The United States cannot function effectively as a country if our leaders invent their own scientific reality and force us to live within it.</p>

<p><a href="https://lh3.googleusercontent.com/-zLGOoGGvFag/X3-HeQXuz2I/AAAAAAAFGxw/NldY4MGcvvU-Wbc-5BTas2g5M0mGQEY9gCLcBGAsYHQ/image.png"><img data-original-height="1013" data-original-width="1520" height="426" src="https://lh3.googleusercontent.com/-zLGOoGGvFag/X3-HeQXuz2I/AAAAAAAFGxw/NldY4MGcvvU-Wbc-5BTas2g5M0mGQEY9gCLcBGAsYHQ/w640-h426/image.png" width="640"></a></p>

<p>Ruth Bader Ginsburg passed away on September 18th. She served 27 years as a beloved member of the nine-person Supreme Court, an institution that strives to ensure the American promise of equal justice under law.</p>

<p>However, the Supreme Court is two-hundred and thirty years old, founded seventy years before <i>On The Origin of Species</i> was published, one-hundred twenty years before Albert Einstein’s famous equation, and nearly two-hundred years before the internet crackled to life.</p>

<p>In the 2020s we need to set up a new institution. An institution that can absorb the scientific consensus, communicate that understanding to the rest of the government, and shape our laws and policies in light of the best-known science. The Science Council will not run things, it will serve only as a check and balance against the three existing branches of government, including the Supreme Court.</p>

<p>We need to make sure no future administration can dismantle the scientific footing of the nation as if discarding the previous administration's choice of drapes in the West Wing.</p>

<p>President Ronald Reagan formed the twelve-person Rogers Commission after the Challenger exploded shortly after lift-off in 1986. The commission featured the esteemed physicist Richard Feynman. We desperately need a standing council of similar stature with permanent members and the mandate to foster science within the government.</p>

<p>Since the internet now exists, the council will cultivate and leverage an online community of millions of scientists throughout the world to augment their own personal expertise.</p>

<p>The Science Council needs real power in the government, we do not need another National Academy of Sciences. In normal times the council can focus on education, verifying facts, and serving as a resource for other branches.</p>

<p>However, if a future president once again claims climate change or a pandemic is a hoax, the council would respond with full force using whatever political mechanisms we grant it.</p>

<p>We also desperately need scientific thinking on issues that might not seem overtly science-based. This year civil unrest and sickening violence was a nightly presence in the news. Mr. Trump responded to the unrest by pronouncing himself the law and order president. This approach more subtly but equally flouts conventional scientific thinking.</p>

<p><a href="https://1.bp.blogspot.com/-7lsy9L0nzBg/X3-I9x6XJzI/AAAAAAAFGyA/xcz_JiE33BMUfWrteIEuFKAgT1DgAsvTACLcBGAsYHQ/s1166/pathways.png"><img data-original-height="733" data-original-width="1166" height="402" src="https://1.bp.blogspot.com/-7lsy9L0nzBg/X3-I9x6XJzI/AAAAAAAFGyA/xcz_JiE33BMUfWrteIEuFKAgT1DgAsvTACLcBGAsYHQ/w640-h402/pathways.png" width="640"></a></p>
<p>The country is a large physical system that obeys scientific laws whether you believe it does or not, whether you personally know the laws or not. The violent acts of 2020 are kernels of corn popping in hot oil. Our law and order president wants to sweep away this inconvenient problem by forcefully crushing the popcorn back into its kernel form.</p>

<p>Instead, we need science to guide us towards turning down the heat, to guide us towards carefully lowering the temperature. We need to use the best science in sociology, psychology, anthropology, economics, and every other scientific field. We face hard problems, but millions of our citizens trained their entire lives to solve exactly these problems. We need to put them to work.</p>

<p>Mr. Trump walked us down the dark path. We need to create a new institution that will light the way for future generations, so that they do not go down that same path, so that the great American experiment can continue, so that our country is around for the next two hundred years and beyond.</p>

</div></div>]]>
            </description>
            <link>https://www.kmeme.com/2020/10/never-again.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24725512</guid>
            <pubDate>Fri, 09 Oct 2020 00:35:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Police violence: Your ratios don't prove what you think they prove]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24724115">thread link</a>) | @dyno-might
<br/>
October 8, 2020 | https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        







<div>
    <div>
        <div>
            
            <p><strong>Oct 8, 2020</strong></p>
            
            

<p>Watching people discuss police bias statistics, I despair. Some claim simple calculations prove police bias, some claim the opposite. Who is right?</p>

<p>No one. Frankly, nobody has any clue what they are talking about. It’s not that the statistics are <em>wrong</em> exactly. They just don’t prove what they’re being used to prove. In this post, I want to explain why, and give you the tools to dissect these kinds of claims.</p>

<p>I’ve made every effort to avoid politics, due to my <a href="https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/">naive dream</a> where well-meaning people can agree on facts even if they don’t agree on policy.</p>



<p>The obvious place to start is to look at the number of people killed by police. This is easy to find.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># in US (million)</td>
      <td>41.3</td>
      <td>185.5</td>
      <td>57.1</td>
    </tr>
    <tr>
      <td># killed by police per year</td>
      <td>219</td>
      <td>440</td>
      <td>169</td>
    </tr>
    <tr>
      <td># killed by police per million people</td>
      <td>5.3</td>
      <td>2.3</td>
      <td>2.9</td>
    </tr>
  </tbody>
</table>

<p>Does this prove the police are racist? Before you answer, consider a different division of the population.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Male</th>
      <th>Female</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># in US (million)</td>
      <td>151.9</td>
      <td>156.9</td>
    </tr>
    <tr>
      <td># killed by police per year</td>
      <td>944</td>
      <td>46</td>
    </tr>
    <tr>
      <td># killed by police per million people</td>
      <td>6.2</td>
      <td>0.29</td>
    </tr>
  </tbody>
</table>

<p>And here’s a third one.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&lt;18 y/o</th>
      <th>18-29</th>
      <th>30-44</th>
      <th>45+</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># in US (million)</td>
      <td>72.9</td>
      <td>53.6</td>
      <td>63.2</td>
      <td>137.3</td>
    </tr>
    <tr>
      <td># killed by police per year</td>
      <td>19</td>
      <td>283</td>
      <td>273</td>
      <td>263</td>
    </tr>
    <tr>
      <td># killed by police per million people</td>
      <td>0.26</td>
      <td>5.2</td>
      <td>4.3</td>
      <td>1.9</td>
    </tr>
  </tbody>
</table>

<p>The first table above is often presented as an obvious “smoking gun” that proves police racism with no further discussion needed. But if that were true, then the second would be a smoking gun for police <em>sexism</em> and the third for police <em>ageism</em>. So let’s keep discussing.</p>

<p>Of course, the second and third tables have obvious explanations: Men are different from women. The young are different from the old. Because of this, they interact with the police in different ways. Very true! But the following is also true:</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>average height (men)</td>
      <td>175.5cm (5’9”)</td>
      <td>177.4cm (5’10)</td>
      <td>169.5cm (5’7”)</td>
    </tr>
    <tr>
      <td>life expectancy</td>
      <td>74.9 yrs</td>
      <td>78.5 yrs</td>
      <td>81.8 yrs</td>
    </tr>
    <tr>
      <td>mean annual income</td>
      <td>$41.5k</td>
      <td>$65.9k</td>
      <td>$51.4k</td>
    </tr>
    <tr>
      <td>median age</td>
      <td>33 yrs</td>
      <td>43 yrs</td>
      <td>28 yrs</td>
    </tr>
    <tr>
      <td>go to church regularly</td>
      <td>65%</td>
      <td>53%</td>
      <td>45%</td>
    </tr>
    <tr>
      <td>children in single-parent homes</td>
      <td>65%</td>
      <td>24%</td>
      <td>41%</td>
    </tr>
    <tr>
      <td>identify as LGBT</td>
      <td>4.6%</td>
      <td>3.6%</td>
      <td>5.4%</td>
    </tr>
    <tr>
      <td>live in a large urban area</td>
      <td>82%</td>
      <td>61%</td>
      <td>82%</td>
    </tr>
    <tr>
      <td>poverty</td>
      <td>21%</td>
      <td>8.1%</td>
      <td>17%</td>
    </tr>
    <tr>
      <td>men obese</td>
      <td>41%</td>
      <td>44%</td>
      <td>45%</td>
    </tr>
    <tr>
      <td>women obese</td>
      <td>56%</td>
      <td>39%</td>
      <td>43%</td>
    </tr>
    <tr>
      <td>completed high school</td>
      <td>87%</td>
      <td>93%</td>
      <td>66%</td>
    </tr>
    <tr>
      <td>completed bachelor’s</td>
      <td>22%</td>
      <td>36%</td>
      <td>15%</td>
    </tr>
    <tr>
      <td>heavy drinkers</td>
      <td>4.5%</td>
      <td>7.1%</td>
      <td>5.1%</td>
    </tr>
  </tbody>
</table>

<p>Maybe it’s uncomfortable, but it’s a fact: In the US today, there are few traits where there <em>aren’t</em> major statistical differences between races.</p>



<p>Suppose police were required wear augmented reality goggles. On those goggles, real-time image processing changes faces so that race is invisible. Would doing this cause police statistics to equalize with respect to race?</p>

<p>No. Even if race is <em>literally invisible</em>, young urban alcoholics will have different experiences with police than old teetotalers on farms. The fraction of these kinds of people varies between races. Thus, racial averages will still look different because of things that are <em>associated with race</em> but aren’t <em>race as such</em>.</p>

<p>So despite the thousands of claims to the contrary, just looking at killings as a function of population size doesn’t prove bias. Not does it prove a lack of bias. It really doesn’t prove anything.</p>



<p>Why do police kill more men than women? We can’t rule out police bias. But surely it’s relevant that men and women behave differently? So, it might seem like we should normalize not by population size, but by <em>behavior</em>.</p>

<p>One popular suggestion is to consider the number of arrests:</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># killed by police per year</td>
      <td>219</td>
      <td>440</td>
      <td>169</td>
    </tr>
    <tr>
      <td># arrests for violent crimes per year (thousands)</td>
      <td>146</td>
      <td>230</td>
      <td>83</td>
    </tr>
    <tr>
      <td># killed by police per thousand violent crime arrests</td>
      <td>1.4</td>
      <td>1.9</td>
      <td>1.9</td>
    </tr>
  </tbody>
</table>

<p>Some claim this proves the police <em>aren’t</em> biased, or even that there is bias in favor of blacks. But that’s nearly circular logic: If police are biased, that would manifest in arrests as much as killings. So what we are really calculating above is</p><p>

\[\frac{\text{“Normal” killings + killings due to bias}}{\text{“Normal” arrests + arrests due to bias}}.\]

</p><p>The ratio doesn’t tell you much about how large the bias terms are. So, unfortunately this also doesn’t prove anything.</p>

<p>Incidentally: There are some <a href="https://twitter.com/leonydusjohnson/status/1267466345844740098">popular but different</a> numbers out there for this same ratio. These have tens of thousands of re-tweets with no one questioning the math. But I’ve checked the source data carefully, and I’m pretty sure my numbers are right. (They reach the same basic conclusion anyway.)</p>



<p>The police have discretion when deciding to make an arrest. But a dead body either exists or doesn’t. So why not normalize by the number of murders committed?</p>

<p>This turns out to be basically impossible:</p>
<ul>
  <li>Something like 40% of murders go unsolved, so the race of the murderer is unknown.</li>
  <li>The only real source of murder statistics is the <a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/expanded-homicide-data-table-6.xls">FBI</a>. They treat hispanic/non-hispanic ethnicity as <em>independent</em> of race. Why not just ignore hispanics then? Well, you can’t. Hispanics are still counted as white or black in an unknown way. It’s impossible to compare to police shooting statistics where hispanic is an alternative race.</li>
  <li>In around 31% of cases, the FBI has <a href="https://ucr.fbi.gov/crime-in-the-u.s/2017/crime-in-the-u.s.-2017/tables/expanded-homicide-data-table-3.xls">no information</a> about race, and in 40% of cases, no information about ethnicity.</li>
</ul>

<p>I’ve seen tons of articles use <a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/expanded-homicide-data-table-6.xls">this version</a> of the FBI’s murder data that simply drops all the cases where data are unknown. None of these articles even acknowledge the issue of missing data or different treatment of hispanics.</p>

<p>Instead, let’s look at murder <em>victims</em>. This is counterintuitive, but it’s <a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/expanded-homicide-data-table-6.xls">relatively rare</a> for murders to cross racial boundaries (&lt;20%). So this is a non-terrible proxy for the number of murders committed. Data from the CDC separates out black, white, and hispanics in a similar way as police shooting statistics.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># killed by police per year</td>
      <td>219</td>
      <td>440</td>
      <td>169</td>
    </tr>
    <tr>
      <td># murder victims per year</td>
      <td>9,908</td>
      <td>5,747</td>
      <td>3,186</td>
    </tr>
    <tr>
      <td># killed by police per murder victim</td>
      <td>0.022</td>
      <td>0.076</td>
      <td>0.053</td>
    </tr>
  </tbody>
</table>

<p>So what does this prove? Again, not much. The simple fact is that most police killings are <strong>not in the context of a murder or a murder investigation</strong>. Though there are <a href="https://medcraveonline.com/FRCIJ/FRCIJ-06-00237.pdf">exceptions</a>, the precise <em>context</em> of police killings hasn’t had enough study, and definitely not enough to get reliable statistics.</p>



<p>Really, though, it’s not an issue of lacking data. Philosophically, consider the any possible ratio like</p><p>

\[\frac{\text{# of people of a race killed by police}}{\text{# of times act } X \text{ committed by a member of a race}}.\]

</p><p>For what act \(X\) does this really measure police bias? I think it’s pretty clear that <strong>no such act exists</strong>, even if we could measure it. Races vary along too many dimensions. There are too many scenarios for police use of force. Bias interacts with the world in too many ways. You just can’t learn anything meaningful with these sort of simplistic high-level statistics.</p>

<p>This doesn’t mean we need to give up. It just means you need to get closer and try harder. In the next part of this series I’ll look at some valiant attempts to do that. They will disappoint us too, but for different reasons.</p>

<p><strong>Data Used:</strong></p>
<ul>
  <li><a href="https://www.washingtonpost.com/graphics/investigations/police-shootings-database/">Police shootings</a> (average 2017-2019)</li>
  <li><a href="https://www.census.gov/quickfacts/fact/table/US/PST045219">Number of people of each race / sex</a></li>
  <li><a href="https://data.census.gov/cedsci/table?q=S01&amp;d=ACS%201-Year%20Estimates%20Subject%20Tables&amp;tid=ACSST1Y2019.S0101">Number of people by age</a></li>
  <li>Data by race: <a href="https://www.cdc.gov/nchs/data/nvsr/nvsr68/nvsr68_07-508.pdf">Life expectancy</a> / <a href="https://en.wikipedia.org/wiki/List_of_ethnic_groups_in_the_United_States_by_household_income">Income</a> / <a href="https://www.medicinenet.com/height_men/article.htm">Height</a> / <a href="https://news.gallup.com/poll/248837/church-membership-down-sharply-past-two-decades.aspx">Church</a> / <a href="https://datacenter.kidscount.org/data/tables/107-children-in-single-parent-families-by-race#detailed/1/any/false/37,871,870,573,869,36,868,867,133,38/10,11,9,12,1,185,13/432,431">Single-parent homes</a> / <a href="https://news.gallup.com/poll/201731/lgbt-identification-rises.aspx">Identifying LGBT</a> / <a href="https://www.pewresearch.org/hispanic/2016/04/20/the-nations-latino-population-is-defined-by-its-youth/">Median age</a> / <a href="https://www.census.gov/content/dam/Census/library/publications/2016/demo/p20-578.pdf">School</a> / <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5205547/">Drinking</a> / <a href="https://fas.org/sgp/crs/misc/R46294.pdf">Poverty</a> / <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/1475-6773.13106">Urbanity</a> / <a href="https://www.cdc.gov/nchs/data/databriefs/db360_tables-508.pdf#page=2">Obesity</a></li>
  <li><a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/table-43">Arrests for violent crime</a></li>
  <li><a href="https://www.cdc.gov/nchs/data/nvsr/nvsr68/nvsr68_09-508.pdf">Murder victims</a> (p. 43)</li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24724115</guid>
            <pubDate>Thu, 08 Oct 2020 21:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatically Detecting and Documenting API Endpoints with Akita]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24723110">thread link</a>) | @jeanyang
<br/>
October 8, 2020 | https://www.akitasoftware.com/blog/2020/10/8/detecting-and-documenting-api-endpoints-with-akita | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/10/8/detecting-and-documenting-api-endpoints-with-akita">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <header>
          <div data-nc-group="bottom">
            
            <div data-nc-container="bottom-center">

              <p><a href="https://www.akitasoftware.com/" data-nc-element="branding" data-content-field="site-title">
                
                  
                    <img src="https://static1.squarespace.com/static/5b6f6c558ab722caa37858bf/t/5eec170153421321c1245a78/1602184424311/?format=1500w" alt="Akita Software">
                  
                
              </a></p><p>Making software better.</p>

            </div>
            
          </div>
        </header>

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f7f61f98472762c94f2dd1e" data-item-id="5f7f61f98472762c94f2dd1e">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1602184018149" id="item-5f7f61f98472762c94f2dd1e"><div><div><div data-block-type="2" id="block-88e1cf04a79efcc55c84"><div><p>As companies grow, the number of internal services often grows too. What does not grow is the amount of love given to helping developers use internal services. In this blog post, we talk about how we help software teams make sense of the hairball that is your internal services and APIs. We introduce one of our newest features: automatically generated specs for your <em>outbound</em> API calls!</p><h2>😨 The endless attic of internal APIs</h2><p>Think about the last time you used a third-party SaaS API. If it was well-documented, like Stripe or Twilio, it may have been a pleasure to use.</p><p>Now think about the last time you used an internal API at your company. If it was also a pleasure to read, talk to us. We want to know what your company does to make this possible. 😊 But chances are, you hit some roadblocks.</p><p>It turns out that companies that make a lot of money on their external APIs can afford to spend a lot of resources on keeping the documentation up to date and doing things like <a href="https://engineering.shopify.com/blogs/engineering/shopify-manages-api-versioning-breaking-changes"><span>change impact analysis</span></a> to make sure their developer community does not get negatively impacted by changes. But even automatically generated documentation frameworks take work. And even the best change impact analysis systems require manual work, as it’s not simply a matter of running a code checker. So while fancy external-facing APIs get the VIP treatment in terms of documentation and stability, internal APIs are left to run wild.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_196790"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185593697-74G8J6LHAI6UNLYBQVC1/ke17ZwdGBToddI8pDm48kCe4lo_81hB0z5l4CmWwKn1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFczJzr9RKZ_bzU3H3hHgcrxJs6quDTsVn0bUV6XWukvtoqoyhqEat3ZTPGdmbdjAo/brick_facade.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185593697-74G8J6LHAI6UNLYBQVC1/ke17ZwdGBToddI8pDm48kCe4lo_81hB0z5l4CmWwKn1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFczJzr9RKZ_bzU3H3hHgcrxJs6quDTsVn0bUV6XWukvtoqoyhqEat3ZTPGdmbdjAo/brick_facade.jpg" data-image-dimensions="422x281" data-image-focal-point="0.5,0.5" alt="External APIs with the resources for tooling get  some  love—but there could be more." data-load="false" data-image-id="5f7f697995ab451ef92e2270" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185593697-74G8J6LHAI6UNLYBQVC1/ke17ZwdGBToddI8pDm48kCe4lo_81hB0z5l4CmWwKn1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFczJzr9RKZ_bzU3H3hHgcrxJs6quDTsVn0bUV6XWukvtoqoyhqEat3ZTPGdmbdjAo/brick_facade.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>External APIs with the resources for tooling get <em>some</em> love—but there could be more.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_201201"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185737055-J3ZNZR8YRD1N4ZOYCTOG/ke17ZwdGBToddI8pDm48kMFU7B-thr5IpG_tMV5QtbVZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGvaT6n7hOH3sJuy371p6-JR9kiBajMJjd_8d5NGEjnyVtO8nJtk629tZGIWiyY3XQ/weeds.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185737055-J3ZNZR8YRD1N4ZOYCTOG/ke17ZwdGBToddI8pDm48kMFU7B-thr5IpG_tMV5QtbVZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGvaT6n7hOH3sJuy371p6-JR9kiBajMJjd_8d5NGEjnyVtO8nJtk629tZGIWiyY3XQ/weeds.gif" data-image-dimensions="300x224" data-image-focal-point="0.5,0.5" alt="Everybody else is left in a vast unpaved lot with weeds." data-load="false" data-image-id="5f7f69ff5bd8a22c567cf795" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Everybody else is left in a vast unpaved lot with weeds.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_197089"><p>What’s happening is that even though internal APIs are becoming more and more common, they are not getting any easier to use. Finding and figuring out how to use internal APIs, especially at a large organization with many microservices, becomes something like rifling through an endless, poorly organized attic. As a result, developers struggle with everything from finding the right API to use, to figuring out how to use the APIs, to keeping up with changes to those APIs. The tooling is leaving developers behind.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_70089"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184620428-YYBSV753NAGVJ1Z8N8UP/ke17ZwdGBToddI8pDm48kHOLkWwYqWOvR0G_edQ-96VZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEX4JQXcd48CO__8WcidP91C_pJHQ0N8vWPWU86nW7Wgu87Nsj43NRAr6WuWZv5DKs/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184620428-YYBSV753NAGVJ1Z8N8UP/ke17ZwdGBToddI8pDm48kHOLkWwYqWOvR0G_edQ-96VZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEX4JQXcd48CO__8WcidP91C_pJHQ0N8vWPWU86nW7Wgu87Nsj43NRAr6WuWZv5DKs/image-asset.gif" data-image-dimensions="352x260" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f7f65a4cb08614b82e76c40" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_70388"><div><h2>👀 Discovering endpoints with Akita</h2><p>Now we’ll show you how Akita helps developers use internal APIs better!</p><p>In a <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">previous blog post</a>, we introduced our tool that automatically generates API specs by watching network traffic:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_75089"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184704149-FYARR7C1AAHSMSRZMDLW/ke17ZwdGBToddI8pDm48kEE5BRPVFdSFNJ9EWVjnQtJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzBAkhzHXcTUkbSFC51ULQzwiZaehtpr50pAWHTpVqK6r115xOpNXu01MbofqMIiwU/ezgif.com-gif-maker.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184704149-FYARR7C1AAHSMSRZMDLW/ke17ZwdGBToddI8pDm48kEE5BRPVFdSFNJ9EWVjnQtJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzBAkhzHXcTUkbSFC51ULQzwiZaehtpr50pAWHTpVqK6r115xOpNXu01MbofqMIiwU/ezgif.com-gif-maker.gif" data-image-dimensions="600x393" data-image-focal-point="0.5,0.5" alt="ezgif.com-gif-maker.gif" data-load="false" data-image-id="5f7f65fecb08614b82e77b44" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_75388"><div><p>But one question we kept getting was:<em> but how do we even know which APIs we need to document? </em>It turns out that at companies with many services, one reason it’s hard to untangle the services hairball is to figure out which services are involved in the first place.</p><p>We had been very proud of how non-invasive our API spec generation tooling was (no code changes, no proxies!) and we wanted to keep things that way. So we asked ourselves if we could use the same techniques to figure out what requests were also going <em>out</em> to internal services and third-party SaaS. It turns out the answer is yes.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_79995"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184763375-GC3UE7NOE3ZFCXSFIPL2/ke17ZwdGBToddI8pDm48kPNjuB-A-ajUh-wmnV_6IIFZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEslm_1rIN2a3J1-oVQMHpPlo94MczC2UEOraXY_Qw8c_y_8EGDnYcl4fW3rA_CdF4/deathstar.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184763375-GC3UE7NOE3ZFCXSFIPL2/ke17ZwdGBToddI8pDm48kPNjuB-A-ajUh-wmnV_6IIFZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEslm_1rIN2a3J1-oVQMHpPlo94MczC2UEOraXY_Qw8c_y_8EGDnYcl4fW3rA_CdF4/deathstar.jpeg" data-image-dimensions="317x159" data-image-focal-point="0.5,0.5" alt="deathstar.jpeg" data-load="false" data-image-id="5f7f663be4d1b85618915322" data-type="image" src="https://www.akitasoftware.com/blog/2020/10/8/deathstar.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_80294"><p>We’re excited to introduce a new capability that gets us one step closer to unrolling the internal services hairball by doing <strong>automatic API endpoint detection</strong>. When you generate an API spec, Akita is able to now tell you about your<em> outgoing </em>API calls as well.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_84866"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184818205-2KDPK8HJ2WQAWSX2WUIS/ke17ZwdGBToddI8pDm48kGM2NkLZGsNUBDsu12QeHQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpw7w0BOcRTmqxdbnv0IaM2RvCi5Fl42DoZkCpTOSLYtWB_BiH-pPUd5adX8ZF3rohU/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184818205-2KDPK8HJ2WQAWSX2WUIS/ke17ZwdGBToddI8pDm48kGM2NkLZGsNUBDsu12QeHQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpw7w0BOcRTmqxdbnv0IaM2RvCi5Fl42DoZkCpTOSLYtWB_BiH-pPUd5adX8ZF3rohU/image-asset.gif" data-image-dimensions="600x380" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f7f666fbc33371a0ffa9bf0" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_85165"><div><p>As with inbound spec generation, the Akita command-line agent watches outgoing API calls, doing some light analysis and sending metadata back to the Akita cloud. Combining this with our <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">type and data format detection</a>, Akita is also now able to tell you things like which sensitive data types are going to other services:</p><p>Our Outbound Specs allows you to:</p><ul data-rte-list="default"><li><p>See what internal APIs you currently depend on.</p></li><li><p>See the specs for those APIs.</p></li><li><p>See what you’re sending to those APIs.</p></li><li><p>Get alerted about when these internal APIs change.</p></li></ul><p>We’re also working on some cool technology to map requests to responses. More on that soon!&nbsp;</p><h2>⚡️ What now?</h2><p>While generating API specs gives you the ability to understand a single API, outbound API specs detection starts helping you understand the <em>API graph</em>, the interaction graph of your system <em>across</em> services. We are very excited about where this is going!</p><p>If this sounds exciting to you, we’d love to get you involved as we build out the Akita product.</p><ul data-rte-list="default"><li><p>If you’re interested in API spec generation, data format detection, or API endpoint detection, try out the <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">Akita private beta</a>!</p></li><li><p>Help us improve our product by filling out <a href="https://akitasoftware.typeform.com/to/iAbs1tB5?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">our change management survey</a>, with a chance to win a $50 Amazon gift certificate!</p></li><li><p><a href="https://twitter.com/akitasoftware?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">Follow us on Twitter</a> for updates. </p></li><li><p>Help us spread the word about Akita. 💖</p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_158728"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185303115-45NMKUCZO17C3VX5QX3Q/ke17ZwdGBToddI8pDm48kCNvdmxXRFB2FiyH8C0qYTNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVElifA8JgkQH-c2R2A7sIPW6FxJCPsUM8f1waoDkZ_PK6QvevUbj177dmcMs1F0H-0/taylor_swift_thank_you.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185303115-45NMKUCZO17C3VX5QX3Q/ke17ZwdGBToddI8pDm48kCNvdmxXRFB2FiyH8C0qYTNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVElifA8JgkQH-c2R2A7sIPW6FxJCPsUM8f1waoDkZ_PK6QvevUbj177dmcMs1F0H-0/taylor_swift_thank_you.gif" data-image-dimensions="480x264" data-image-focal-point="0.5,0.5" alt="taylor_swift_thank_you.gif" data-load="false" data-image-id="5f7f6855fdc70016bddda391" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>

    

    

    <section id="comments-5f7f61f98472762c94f2dd1e">
      
  


    </section>

  </article>





  <nav>

    

    
      <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">
        <div>
          <p>Next</p>
          <h4>Taking Types to the Next Level: Stop API Bugs By Inferring Data Formats</h4>
          <div>
            <!--

            Categories

            --><p><span>Updates</span></p><!--

            Author

            --><p><span>Jean Yang</span></p><!--

            Date

            --><p><time datetime="2020-09-29">September 29, 2020</time></p><!--

            Tags

            --><p><span>data format inference, API spec generation</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div>
      </div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/10/8/detecting-and-documenting-api-endpoints-with-akita</link>
            <guid isPermaLink="false">hacker-news-small-sites-24723110</guid>
            <pubDate>Thu, 08 Oct 2020 19:51:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A small self-funded company outperforming larger VC backed ones]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24720904">thread link</a>) | @octobereleven
<br/>
October 8, 2020 | https://claritask.com/blog/software-advice-2020-frontrunners | <a href="https://web.archive.org/web/*/https://claritask.com/blog/software-advice-2020-frontrunners">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">	
	
		<p><a href="https://claritask.com/blog/tag/news">Claritask News</a></p>
		
		<p>Claritask, a self-financed bootstrapped company, scores high in Software Advice’s 2020 FrontRunners Task Management Software list, outperforming by far other larger companies.</p>
	    			    
		<div>
			
			<p>Software Advice, one of the leading personalized advice outlets, has rated Claritask high on their 2020 FrontRunners Task Management Software list.</p>

<p><strong>Specifically speaking:</strong><br>
8.4 in Usability and 8.1 on Customer Satisfaction.</p>

<p><img src="https://claritask.com/blog/images/uploads/sa-claritask-w-badge.png" alt="Software Advice Chart for Claritask" height="737" width="825"></p>

<p>What makes this recognition more special is that this rating comes directly from user reviews.</p>

<p><strong>In other words, it’s a reflection of our customers being satisfied with Claritask (the app) and us as a reliable company.</strong></p>

<p>Also, worth mentioning is that Claritask, a self-financed bootstrapped company, has outperformed other companies in the list with millions of dollars in venture capital and years in business.</p>

<p>Thank you! </p>

<p>Full details of this evaluation can be found on the <a href="https://www.softwareadvice.com/project-management/task-management-comparison/#frontrunners" target="_blank">2020 FrontRunners Task Management Software page on the Software Advice website</a>.</p>

		</div>
		
		
		

		<p>Written on October 1, 2020</p>
		

		<p><a href="https://claritask.com/">
		    Claritask helps teams work happier together
		    <span>Learn more</span>
		</a>
									
		
			

					
		
		
	
	</p></div></div>]]>
            </description>
            <link>https://claritask.com/blog/software-advice-2020-frontrunners</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720904</guid>
            <pubDate>Thu, 08 Oct 2020 16:43:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peloton Went from Kickstarter to $33B]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24720869">thread link</a>) | @jakebrereton
<br/>
October 8, 2020 | https://www.launchnotes.io/blog/how-they-launched-it-peloton | <a href="https://web.archive.org/web/*/https://www.launchnotes.io/blog/how-they-launched-it-peloton">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‍</p><p><strong>"</strong><em>How they launched it" is a recurring series of deep dives exploring how the world’s best teams launch new products and features.</em></p><p>‍</p><p><strong>Company:</strong> Peloton<br><strong>Launch:</strong> Peloton<strong><br>Launch date:</strong> July, 2013<br></p><p>Peloton is one of those “why didn’t I think of that” ideas.<br></p><p>World class hardware, software, and content. All vertically integrated into a modern streaming platform and backed by a killer brand. Disrupting a giant industry starved of innovation. Why hadn't anyone thought of it sooner?<br></p><p>In just eight years, the company has gone from a scrappy startup raising funding on Kickstarter (yes, <em>Kickstarter</em>) to a multi-billion-dollar public company with over a million subscribers, 500,000+ bikes sold, and <a href="https://www.cnbc.com/2020/05/06/peloton-pton-reports-fiscal-q3-2020-earnings.html" target="_blank">66% revenue growth in just the last year</a>.</p><figure id="w-node-d80ec6d9faa8-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7d0ce53b21620ad68b663e_launchnotes_peloton_multi_billion_dollar_company.png" loading="lazy" alt=""></p></figure><p>But just getting the company up to cruising speed was a years-long battle. Founder John Foley faced thousands of rejections before he even had a product to launch. Hardware startups require prototypes and supply chains, which means capital. Unlike a slick new mobile app, you can’t vaporware a bicycle. But investors thought at-home fitness was a weak category, filled with goofy jocks hawking infomercial ab machines.<br></p><p>“They would hear: ‘fitness is a dopey category,’” <a href="https://mastersofscale.com/john-foley/" target="_blank">Foley said</a> on the Masters of Scale podcast, “where there’s been no capital and no software and no media and no innovation. And I would say, ‘exactly!’”’</p><p>Fast forward eight years, and today Peloton is one of the most widely recognized brands, and products, in American fitness.</p><p>Here’s how they launched it.<br></p><h2>Summary</h2><p>Dive deeper into a specific area of the Peloton launch:</p><ul role="list"><li>Kickstarter</li><li>SEO</li><li>Sales pitch</li><li>Email&nbsp;</li><li>Highly focused messaging</li><li>Retail space</li><li>High-end hotels</li><li>Personalized delivery service<br></li></ul><p>After years of scraping together small checks from more than 100 investors, tapping personal networks to find the first batch of instructors, and asking early adopters to contribute to a Kickstarter campaign, in 2014 Foley was finally able to, for the first time, actually put a product on the shelf.<br></p><p>Now how—as the marketing adage goes—to get it off the shelf? </p><p>The answers might surprise you, as Peloton’s launch threw a lot of conventional wisdom out the window. </p><h2><strong>Kickstarter campaign</strong><br></h2><figure id="w-node-36376a58d78d-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bb88653bdc5bb6877649b_launchnotes_peloton_john_foley_tweet.png" loading="lazy" alt=""></p></figure><p>Back in 2013, Peloton kicked off its launch with <a href="https://www.kickstarter.com/projects/568069889/the-peloton-bike-bring-home-the-studio-cycling-exp" target="_blank">a Kickstarter campaign</a> that raised over $300,000 from nearly 300 individual funders. They’d built some early prototypes to feature in marketing materials and had some angel funding in the bank, but they turned to Kickstarter when it was time to scale manufacturing.<br></p><p>The stated goal was to raise $250,000. But beyond the stated goal, the Kickstarter campaign was also a strategic tool to build buzz for the company.&nbsp;<br></p><p>Peloton’s Kickstarter campaign led to a lot of early PR mentions, including write-ups in <a href="https://blogs.wsj.com/digits/2013/06/24/startup-melds-indoor-spinning-with-high-tech/" target="_blank">The Wall Street Journal</a>, CNN, and <a href="https://techland.time.com/2013/06/24/this-exercise-bike-features-a-huge-touchscreen-webcam-and-live-streaming-spin-classes/" target="_blank">Time</a>. Interestingly, none of this coverage featured interviews or exclusives. All the information in the articles was generally available and appears to have been pulled from either the Kickstarter page or a press release.<br></p><p>Companies who see great success with their PR efforts (<a href="https://www.launchnotes.io/post/how-they-launched-it-mailchimps-all-in-one-marketing-platform">like MailChimp</a>) often approach those efforts with a series of exclusives, so it’s fascinating that Peloton was able to succeed without such a nuanced approach. We can only conclude that the concept itself, its messaging, and the fundraising method (Kickstarter had a lot of its own hype in 2013) were novel enough to earn the kind of coverage for which most companies have to really hustle.&nbsp;<br></p><h2><strong>SEO</strong><br></h2><p>In addition to getting the word out about Peloton’s unique business plan, at least 25% of those early articles linked to Peloton’s website, with the rest linking out to the Kickstarter.<br></p><p>Since backlinks from high value sites (like The Wall Street Journal) have long been one of the most important factors for good SEO, the early coverage likely not only sent new funders to the Kickstarter campaign, but also gave Peloton’s website an additional boost in Google’s algorithms.&nbsp;<br></p><p>It’s a good lesson for new companies: have your own domain up early. At least as early as you expect to have other people on the internet talking about you. Even if you use a third-party platform like Kickstarter or Youtube to build pre-launch buzz, having your own URL people can link to will significantly help your site show up in search engines down the road.</p><figure id="w-node-8f102ac6b7bb-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bb931efb84947b4d6c2fb_launchnotes_peloton_kickstarter_campaign.png" loading="lazy" alt=""></p></figure><h2>‍<br><strong>Sales pitch</strong><br></h2><p>Not only was Peloton’s choice of Kickstarter unique, so was their sales pitch: a well-crafted bike, yes, but also built-in live and on-demand indoor cycling video classes and—perhaps most importantly—a community where you could share triumphs, compete, and video chat with friends.<br></p><p>Their exact wording on the Kickstarter: “The Peloton Bike delivers live and on-demand indoor cycling classes to your home, while allowing competition &amp; video chat with friends.”<br></p><p>The strategy here starts with the product itself. Exercise bikes weren’t new. Live classes weren’t new. Community wasn’t new. <em>But combining them in the comfort of your own home was</em>. And the pitch succinctly captured all of that. In just one sentence, you knew you were buying a bike, that it came with classes, and that it offered an opportunity to gamify the entire experience. All from your own home.<br></p><p>It’s also been interesting to watch Peloton’s value prop change over the years. They’ve wisely made the transition from positioning themselves as an alternative (“Spin class replacement”) to a category all their own.<br></p><h2><strong>Email</strong><br></h2><p>To keep their Kickstarter campaign momentum going, Peloton sent update emails to encourage their early funders to share the campaign with friends.&nbsp;<br></p><p>Email is a tried-and-true (and arguably essential) part of a good launch. But it’s not always done well. To avoid sending generic marketing messages (a trap many launches seem to fall into), Peloton leveraged the fast development they were doing behind the scenes as a reason to be in touch with people, sharing updates on not only the bikes, but also add-ons coming down the pipeline.&nbsp;<br></p><p>One such add-on? Their own custom-made cycling shoes.</p><p>‍</p><figure id="w-node-fe96fe39b5fd-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bba8444bfe33b0df9158e_launchnotes_peloton_email.png" loading="lazy" alt=""></p></figure><p>‍<br></p><p>Email also helped the Peloton team sharpen their brand voice and messaging early on. Their early emails (and social media posts) reflected the energy and positivity their instructors and brand would later become known for. Liberal use of exclamation marks as well as high-energy language (WOW! Amazing! Fun!) was commonplace.<br></p><div><p>Interestingly, according to <a href="https://knowledge.wharton.upenn.edu/article/say-reveals-think/" target="_blank">a study out of Wharton</a>, emotional language like this increases customer engagement—the exact kind of customer engagement that Peloton’s earliest marketing campaigns had to drive in order to to keep their earliest adopters hooked.</p></div><h2><strong>Highly focused messaging</strong><br></h2><p>Arguably, one of the smartest things about Peloton’s product and its launch was the way they came out of the gate deeply understanding their audience.<br></p><p>Marketers are taught to build messaging around people’s motivations. What does the customer ultimately want? It’s good advice. So for decades, messaging in the fitness industry was all about body image, and how people wanted to see themselves in the mirror the following day. “Get shredded,” “drop pounds today,” “abs in 30 days.”<br></p><p>But this kind of messaging has never appeared in Peloton copy. You won’t see a Peloton ad promising you’ll get ripped fast, because that’s the kind of language you hear from people who often <em>don’t</em> work out. Ask someone who doesn't exercise regularly what the benefits of exercise are and you’ll probably hear about body image and looking good at the beach. But ask someone devoted to fitness (as a vast majority of indoor cyclists already are) and you hear entirely different benefits: the energy and excitement of a good workout, the thrill of competing with others and consistently setting and beating goals, and the community and relationships formed with others at their gym. Just to name a few.<br></p><p>This is the enlightened tone Peloton uses, and it works. It reads more like a text message someone would send their friend after a great workout than the cover of a fitness magazine.</p><figure id="w-node-d551f62d4405-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bbb784d186c147dae4719_launchnotes_peloton_messaging_and_psychology.png" loading="lazy" alt=""></p></figure><h3><strong>A focus on competition</strong><br></h3><p>Peloton’s bread and butter is its high-end equipment, with bikes and treadmills <a href="https://blog.mywallst.com/how-does-peloton-make-money/" target="_blank">making up about 80% of the company’s revenue</a>. But, unlike the stationary cycle companies who came before them, <strong>the brand doesn’t stop there</strong>. Just under $1B per quarter in revenue comes from subscriptions—a secondary revenue stream with enormous long-term value.&nbsp;<br></p><p>(And when we say long-term potential, we mean it: Peloton’s current <a href="https://www.forbes.com/sites/mikeotoole/2019/01/31/want-to-be-the-next-peloton-heres-how-the-fitness-brand-is-expanding-product-line-and-impact/#126c56cc6e93" target="_blank">yearly retention rate is a staggering 96%</a>, and the company expects to add more than a million subscribers in 2020.)<br></p><p>What’s the secret to this retention success? There’s probably more than one answer, but we suspect part of it is in their focus on <strong>competition</strong>, a focus they had <em>from day one of their Kickstarter launch</em>.&nbsp;<br></p><p>Competition, even more than a supportive community, is the top motivator that keeps people exercising, according to <a href="https://www.sciencedirect.com/science/article/pii/S2211335516300936?via%3Dihub" target="_blank">a study by the University of Pennsylvania</a>. In fact, <strong>students in a socially competitive exercise program attended classes 90% more often</strong> than students without the added incentive of competition.&nbsp;<br></p><p>Which is why the frequent mentions of competition in Peloton’s own pitches (such as that on their Kickstarter page) and their early PR coverage are... pretty genius. They were already hinting at one of the most powerful things they’d invested in: gamification.<br></p><h3><strong>A focus on connection</strong><br></h3><p>Another feature of Peloton’s marketing and products from the start? Community.&nbsp;<br></p><p>Instructors had leaderboards and started giving shoutouts early on—congratulating riders on milestone rides, birthdays, and so on. And video chat on the Peloton platform was one of the early selling points for their Kickstarter campaign.<br></p><figure id="w-node-eec8742172ab-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7d0bd96848bf4545c04abd_launchnotes_peloton_community.png" loading="lazy" alt=""></p></figure><p>Having an exercise buddy (or, you know, <a href="https://sgbonline.com/peloton-holds-largest-class-ever/" target="_blank">23,000 in Peloton’s largest attended class so far</a>) makes people significantly more likely to stick with their fitness goals and get more benefit from their workouts, according to <a href="https://jaoa.org/article.aspx?articleid=2661140" target="_blank">study</a> after <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3975263/" target="_blank">study</a> after <a href="https://pubmed.ncbi.nlm.nih.gov/24176780/" target="_blank">study</a>.&nbsp;<br></p><p>Not only does this mean people get a boost from the group structure of the live classes; it also facilitates the long-term retention that Peloton prioritized on launch and continues to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.launchnotes.io/blog/how-they-launched-it-peloton">https://www.launchnotes.io/blog/how-they-launched-it-peloton</a></em></p>]]>
            </description>
            <link>https://www.launchnotes.io/blog/how-they-launched-it-peloton</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720869</guid>
            <pubDate>Thu, 08 Oct 2020 16:41:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Density launches Open Area radar system for buildings]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24720736">thread link</a>) | @afar
<br/>
October 8, 2020 | https://www.density.io/blog/introducing-open-area | <a href="https://web.archive.org/web/*/https://www.density.io/blog/introducing-open-area">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>"Any sufficiently advanced technology is indistinguishable from magic."</blockquote><h6>— Arthur C. Clarke, <em>Profiles of the Future</em> <em>(1962)</em></h6><h4>Open Area</h4><p>In 2017, we had a customer tell us she spent $700,000 every year for each building in a 4 million square foot office portfolio. $700,000 bought her human consultants who would visit her offices and do 7-day observational studies of how busy different spaces were (once per quarter).</p><p>As it turns out, she was not alone. Over the years, hundreds of customers have asked if they could use the infrared technology in our Entry sensors for open space detection (to measure desk availability, lounge use, how people use an amenity, and so on). Our answer has always had to be, no. </p><p>Not yet, anyway.</p><p>Since then we have been thinking about and working to solve the thorny problem of counting people in unbounded space and making it affordable to scale to tens of thousands of business and hundreds of millions of square feet.</p><p>Today, we're proud to introduce the latest addition to our platform — Density Open Area.</p><figure id="w-node-5d0de9b0c67f-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f7cd78f8d47e339ff7661b4_Open%20Area%20in%20hand.png" loading="lazy" alt=""></p><figcaption>Open Area, a radar based sensor</figcaption></figure><h4>Technical Leaps</h4><p>Once, every few years, you get a glimpse of the future and how it might work. The famous ones are well known: the internet growing <a href="https://www.cnbc.com/2020/01/17/at-age-30-jeff-bezos-thought-this-would-be-his-one-big-regret-in-life.html">at 2,300%</a>, Englebart's <a href="https://www.youtube.com/watch?v=yJDv-zdhzMY&amp;t=153s">mother of all demos</a>, Steve's <a href="https://web.stanford.edu/dept/SUL/sites/mac/parc.html">visit to Xerox PARC</a>.</p><p>The importance of a novel observation or technical leap is obvious in retrospect but it's easy to disregard in the moment:&nbsp;hypertext, vaccines, the cambered wing, luggage with wheels, even the steam engine was not of any immediate consequence. It often takes decades even centuries of maturing before any given innovation's future is assured. But every now and then, if you squint, you sometimes get a chance to make out the rough profile of the future.</p><p>This is what we saw:</p><figure id="w-node-7ff48cc6176d-665b10f0"></figure><p>‍</p><h4>The Power of Radar</h4><p>Open Area leverages a radar system of our own design. </p><p>Each dot is a depth value generated from thousands of small movements in three dimensional space. We use these clustered data points to count people and observe movement anonymously.</p><p>Open Area's range and ability is extraordinary. The sensor is accurate up to 20 feet off the ground, can handle 1,325 square feet, and has a dynamic field of view configurable through a web app. </p><p>The technology fits in the palm of your hand, is unaffected by sunlight or reflectivity, and mounts in minutes. It is more accurate than a camera, anonymous at source, and made in America.</p><figure id="w-node-dc27d77422eb-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f7ec280f461fdee990537d7_looping%20animation.gif" loading="lazy" alt=""></p></figure><h4>‍</h4><h4>Features &amp; Benefits</h4><p>The sensor comes with a suite of new applications designed to take advantage of Open Area's unique aerial dataset. Users will be able to access:</p><ul role="list"><li>60% reduction in cost to deploy (vs. camera / optical alternatives).</li><li>20 foot range, 40 foot effective diameter (4x coverage of alternatives).</li><li>1,325 square feet of coverage</li><li>Measure up to 20 desks (early Alpha)</li><li>Historical occupant pathing and heatmaps</li><li>Desk and room availability (+&nbsp;release)</li><li>Touchdowns and dwell time</li></ul><figure id="w-node-3dc275f7db55-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f7ec65d2e837f523f524063_oa%20software.png" loading="lazy" alt=""></p><figcaption>Density web application</figcaption></figure><h4>Availability &amp;&nbsp;Price</h4><p>Available today in limited quantity. Large scale production starts early 2021.</p><ul role="list"><li>Hardware: $399 / sensor*</li><li>Software:&nbsp;$199 / sensor / year*</li></ul><p>‍<em>*Introductory pricing is available on orders through 2020.</em></p><p>‍</p><h4>One more thing ...</h4><p>In the process of exploring Open Area's unique capabilities, we realized something novel – a way of looking at people in space we'd never seen before. </p><p>Synchronize your floorplan and turn on Density Live. It will feel like a fragment of the future.</p><p>‍</p><figure id="w-node-735909241e83-665b10f0"></figure><p>‍</p><p>You can register to see a product demo <a href="https://density.webflow.io/people-counting-resources-webinars/introducing-open-area-densitys-newest-sensor-offering">October 20th</a> or send us an email to learn more – sales@density.io. </p><p>We can't wait to see what you do with the tech.</p><p>Andrew, Density CEO<br></p></div></div></div>]]>
            </description>
            <link>https://www.density.io/blog/introducing-open-area</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720736</guid>
            <pubDate>Thu, 08 Oct 2020 16:31:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Human Learn – Machine Learning models should play by the rules, literally]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24720115">thread link</a>) | @simjue
<br/>
October 8, 2020 | https://koaning.github.io/human-learn/ | <a href="https://web.archive.org/web/*/https://koaning.github.io/human-learn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/koaning/human-learn/edit/master/docs/index.md" title="Edit this page"></a>
                
                
                <p><img src="https://koaning.github.io/human-learn/logo.png" width="225"></p>

<blockquote>
<p>Machine Learning models should play by the rules, literally.</p>
</blockquote>
<h2 id="project-goal">Project Goal<a href="#project-goal" title="Permanent link">¶</a></h2>
<p>Back in the old days, it was common to write rule-based systems. Systems that do;</p>
<p><img alt="" src="https://koaning.github.io/human-learn/examples/rules.png"></p>
<p>Nowadays, it's much more fashionable to use machine learning instead. Something like;</p>
<p><img alt="" src="https://koaning.github.io/human-learn/examples/ml.png"></p>
<p>We started wondering if we might have lost something in this transition. Sure,
machine learning covers a lot of ground but it is also capable of making bad
decision. We've also reached a stage of hype that folks forget that many
classification problems can be handled by natural intelligence too.</p>
<p>This package contains scikit-learn compatible tools that should make it easier
to construct and benchmark rule based systems that are designed by humans. You
can also use it in combination with ML models.</p>
<h2 id="install">Install<a href="#install" title="Permanent link">¶</a></h2>
<p>You can install this tool via <code>pip</code>.</p>
<div><pre><span></span><code><span>python</span> <span>-</span><span>m</span> <span>pip</span> <span>install</span> <span>human</span><span>-</span><span>learn</span>
</code></pre></div>


<h2 id="guides">Guides<a href="#guides" title="Permanent link">¶</a></h2>
<h3 id="tutorial">Tutorial<a href="#tutorial" title="Permanent link">¶</a></h3>
<blockquote>
<p>There is a full course on this tool available on <a href="https://calmcode.io/human-learn/introduction.html">calmcode.io</a>.
This is the first video.</p>
</blockquote>
<iframe src="https://player.vimeo.com/video/463961716" width="100%" height="460" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>

<h3 id="getting-started">Getting Started<a href="#getting-started" title="Permanent link">¶</a></h3>
<p>To help you get started we've written some helpful getting started guides.</p>
<ol>
<li><a href="https://koaning.github.io/human-learn/guide/function-classifier/function-classifier.html">Functions as a Model</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/function-preprocess/function-preprocessing.html">Human Preprocessing</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/drawing-classifier/drawing.html">Drawing as a Model</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/finding-outliers/outliers.html">Outliers and Comfort</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/function-classifier/function-classifier.html">Drawing Features</a></li>
</ol>
<p>You can also check out the API documentation <a href="https://koaning.github.io/human-learn/api/classification.html">here</a>.</p>
<h2 id="features">Features<a href="#features" title="Permanent link">¶</a></h2>
<p>This library hosts a couple of models that you can play with.</p>
<h3 id="interactive-drawings">Interactive Drawings<a href="#interactive-drawings" title="Permanent link">¶</a></h3>
<p>This tool allows you to draw over your datasets. These drawings can later
be converted to models or to preprocessing tools.</p>
<p><img alt="" src="https://koaning.github.io/human-learn/draw-gif.gif"></p>
<h3 id="classification-models">Classification Models<a href="#classification-models" title="Permanent link">¶</a></h3>
<h4 id="functionclassifier">FunctionClassifier<a href="#functionclassifier" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make classification predictions. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search.</p>
<h4 id="interactiveclassifier">InteractiveClassifier<a href="#interactiveclassifier" title="Permanent link">¶</a></h4>
<p>This allows you to draw decision boundaries in interactive charts to create a
model. You can create charts interactively in the notebook and export it as a
scikit-learn compatible model.</p>
<h3 id="regression-models">Regression Models<a href="#regression-models" title="Permanent link">¶</a></h3>
<h4 id="functionregressor">FunctionRegressor<a href="#functionregressor" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make regression predictions. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search.</p>
<h3 id="outlier-detection-models">Outlier Detection Models<a href="#outlier-detection-models" title="Permanent link">¶</a></h3>
<h4 id="functionoutlierdetector">FunctionOutlierDetector<a href="#functionoutlierdetector" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can declare outliers. It's constructed in
such a way that you can use the arguments of the function as a parameter that you
can benchmark in a grid-search.</p>
<h4 id="interactiveoutlierdetector">InteractiveOutlierDetector<a href="#interactiveoutlierdetector" title="Permanent link">¶</a></h4>
<p>This allows you to draw decision boundaries in interactive charts to create a
model. If a point falls outside of these boundaries we might be able to declare
it an outlier. There's a threshold parameter for how strict you might want to be.</p>
<h3 id="preprocessing-models">Preprocessing Models<a href="#preprocessing-models" title="Permanent link">¶</a></h3>
<h4 id="pipetransformer">PipeTransformer<a href="#pipetransformer" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make handle preprocessing. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search. This is especially powerful in combination
with the pandas <code>.pipe</code> method. If you're unfamiliar with this amazing feature, you
may appreciate <a href="https://calmcode.io/pandas-pipe/introduction.html">this tutorial</a>.</p>
<h4 id="interactivepreprocessor">InteractivePreprocessor<a href="#interactivepreprocessor" title="Permanent link">¶</a></h4>
<p>This allows you to draw features that you'd like to add to your dataset or
your machine learning pipeline. You can use it via <code>tfm.fit(df).transform(df)</code> and
<code>df.pipe(tfm)</code>.</p>
<h3 id="datasets">Datasets<a href="#datasets" title="Permanent link">¶</a></h3>
<h4 id="titanic">Titanic<a href="#titanic" title="Permanent link">¶</a></h4>
<p>This library hosts the popular titanic survivor dataset for demo purposes. The goal of
this dataset is to predict who might have survived the titanic disaster.</p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://koaning.github.io/human-learn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720115</guid>
            <pubDate>Thu, 08 Oct 2020 15:36:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generic newsletter confirmation emails suck, here's how we can do better]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24720076">thread link</a>) | @yaroslawbagriy
<br/>
October 8, 2020 | https://newslettercrew.com/improve-your-newsletter-welcome-emails/ | <a href="https://web.archive.org/web/*/https://newslettercrew.com/improve-your-newsletter-welcome-emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div><p>First impressions count, in business, relationships and anything important in life. </p><p>Your welcome email is one of your subscribers’ first interactions with you. It’s like a first date, so you need to make sure you start off making a great first impression! It gives you the opportunity to showcase your unique personality and build your relationship with your subscribers.</p><p>We recently subscribed to over 70+ newsletters and found that many newsletter writers are not making full use of their welcome emails to connect with their subscribers. </p><p>Let's face it. Most newsletter writers aren't professional email marketers. But that doesn't give them the excuse to just send default, system-generated "thanks for subscribing" posts</p></div><p>Substack newsletters are especially guilty of sending poor welcome emails as they don't spend time to modify the default email seen below.</p><figure><img src="https://newslettercrew.com/content/images/2020/10/Twitter-Post---3.png" alt="" srcset="https://newslettercrew.com/content/images/size/w600/2020/10/Twitter-Post---3.png 600w, https://newslettercrew.com/content/images/size/w1000/2020/10/Twitter-Post---3.png 1000w, https://newslettercrew.com/content/images/size/w1600/2020/10/Twitter-Post---3.png 1600w, https://newslettercrew.com/content/images/2020/10/Twitter-Post---3.png 2024w" sizes="(min-width: 720px) 720px"></figure><p><br>This is a missed opportunity, as on average, welcome emails receive a higher open rate than regular emails, making <a href="https://blog.hubspot.com/marketing/plan-execute-welcome-email">them 86% more effective</a>. </p><p>Whether you're writing on Substack, Revue, MailerLite, EmailOctopus or any other email service provider, you should invest time into improving your welcome emails, which are your first point of contact with your readers. </p><h2 id="here-is-a-guide-with-examples-on-how-to-optimize-your-newsletter-s-welcome-email-">Here is a guide with examples on how to optimize your newsletter’s welcome email.</h2><p>Here are 11 tips on how to improve your welcome emails, and a collection of some of the best examples to help you make a stellar first impression.</p><h3 id="set-a-subject-line">Set A Subject Line</h3><p>A good subject line should be specific and unique to your newsletter. It could include either a reference to the name of your newsletter or the type of person your subscriber is.</p><p>Some ideas from the Newsletter Crew’s inbox:</p><ul><li>✅ You're Officially Not Boring ✅ &nbsp;(<a href="https://notboring.email/">Not Boring</a> by Packy McCormick)</li><li>🐣Welcome to the #First1000 Family &nbsp;(<a href="https://thefirst1000.substack.com/">The First 1000</a>)</li><li>Welcome to Mastering the Attention Economy Newsletter! (<a href="https://www.arilewis.com/">Ari Lewis</a>)</li><li>You're the Remotely Inclined type… (<a href="https://remotelyinclined.com/">Remotely Inclined</a>)<br></li></ul><div><p>Bad subject lines are overly simplistic and vague. They could have been from any newsletter. That's boring.</p><p>Avoid using these:</p></div><ul><li>You're on the list!</li><li>Thanks for subscribing</li><li>Thank you for subscribing</li></ul><h2 id="content">Content</h2><div><p>What should go in the body of your welcome email?</p><p>First, let's have a look at Packy McCormick’s brilliant welcome email for his popular newsletter <a href="http://notboring.email/">Not Boring</a> before diving into each section.</p></div><figure><img src="https://lh3.googleusercontent.com/hmT_0aVdjeliHsTBnd_sNfgnhX1MVY81dl51zkBrzfvUiqLYfzXqjhutqGRwet4Ox_uV2UnQgvBkvfwjJMcHpT1xZbLlwWCHYM1H3Toq5AulOuo2Q99BYH4IfBtoTHCuPM_K9gVq" alt="Packy McCormick's Not Boring Teardown"></figure><h3 id="thank-your-new-subscriber">Thank Your New Subscriber</h3><div><p>First, greet your subscriber with a warm welcome and thank them for subscribing! You can use a simple line of text, emojis, images or GIFs to do that.</p><p>You can even wow your subscribers with a personal touch. Check out <a href="https://ytothej.substack.com/">Yue Jun’s</a> handwritten welcome note for his newsletter. </p></div><figure><img src="https://lh4.googleusercontent.com/hEjJ4mC0Bv2bU14V7bUWvXSnlaqL85pfdyak0llyuy5Fk4v_hYkrviIyy88LAf2ADfzdh6rpmKVEqXF47OEYZiGxWnOQbHgnUfmQ-an2x3bvuAwJFovyGZ5hZEZMvLuYpHf1yx3S" alt="Personalized Welcome Note For Newsletter"></figure><h3 id="set-expectations-type-of-content">Set Expectations: Type Of Content</h3><div><p>Tell your subscribers a little bit about who you are and what type of content you’ll send. This helps to set their expectations for future newsletter issues and alleviate any anxiety they have.</p><p>Adrian Alferi of <a href="https://www.theproofwellness.com/about">The Proof</a> makes subscribers feel comfortable by giving a personal introduction to himself and shares that he will be sending wellness-related content.</p></div><figure><img src="https://lh3.googleusercontent.com/qSVxN5hSsBfmEsebx8euJvUo4xYX9ITGxFbhPMkoKiYM5fCzUksGbiUzwEuqd9IxEFxR0_7bm3m-wMBp3dq0bgXvSOq6HMH6BIadBV0hsHMP_PHFPPa4nPoGKpLDPRDcF2icgHv5" alt=""></figure><h3 id="set-expectations-frequency"><br>Set Expectations: Frequency</h3><div><p>Let your subscribers know when they can expect your emails. Are you planning on emailing them weekly, daily or monthly? Be upfront on the day(s) they should expect your newsletter in their inbox.</p><p>Pete from <a href="https://www.nocsdegree.com/">No CS Degree</a> is extremely specific about what time people can expect his newsletter. As he has an international audience, he even states what time they can expect the newsletter to arrive in their inboxes.</p></div><figure><img src="https://lh4.googleusercontent.com/oEtWbcF6_mrdeK-5PSXqO8yZnK3u7r6hBaWbmBRN-poW-VzHxG647BWsbJeG93Z5En4uhPKxQpCGOKqQ9_FA3vVaJctAesSJ3Ak6Pui1ck4POPRgShRDvGg_UBx0Vz6lR7y-PIF8" alt=""></figure><p>Psst... some email service providers allow you to schedule send times by open location, if you're keen on doing that!</p><div><p>Increase engagement by linking to your social channels and encouraging subscribers to connect with you on these platforms.</p><p><a href="https://fs.blog/">Farnam Street</a> points subscribers to the different social media channels it owns.</p></div><figure><img src="https://lh4.googleusercontent.com/f3Coi2ziqg7Jm61mKu9M2YJnYv4kOuKwqLjE7i6nsN8hysUU-b_Q8KS0I5ZYKOFCsTh6emiLwjpxnGLpV_ro0EAAT3cRUL6oAwi8gQwSS7KiqiaLhfMor4icn5cl8FuP1PPshaE9" alt=""></figure><h3 id="showcase-your-best-issues">Showcase Your Best Issues</h3><div><p>Give subscribers a taste of what’s to come by sharing your 3-5 of your best issues with them. </p><p>I do this in the welcome email for <a href="https://brainpint.com/">BrainPint</a>. </p></div><figure><img src="https://lh4.googleusercontent.com/jQnCnGEd-k4WvuJVrM3PFHVQFKTU6HHSKMUZ6VP-e3LPI9wB1bKgvGXWCFzcGTEH_GI0PDqFSi549l9j-5dioJWHw3jzn5rkHBSGN43GWQNbWzSbVwHkc0bYrebhEtJ2sHWg409R" alt=""></figure><h3 id="ask-questions-to-connect-with-your-subscribers">Ask Questions To Connect With Your Subscribers</h3><div><p>Start a two-way conversation &amp; engage with your subscribers by asking them simple questions in your welcome email.</p><p>Get them to share:</p></div><ul><li>Information about themselves - who they are, and what they are working on</li><li>Questions they might have about the niche you’re in</li></ul><p>Anne-Laure from <a href="https://nesslabs.com/newsletter">Maker Mind</a> gives multiple options (including a "hit reply just to say hello" to take out the mental strain of replying)</p><figure><img src="https://lh6.googleusercontent.com/GiNWksy01vN2oxyWFRsTdFJFyIwcUy7YMbxyMf1gLO6IS-6UR-QRt8RhNAx6q3qjIWpfnIP9w5yeqV-Evh9q6SHxTcxbnsXxFIi5zghoF-87hsVCwPvQHWlOQJrn19jSy0rm8F0x" alt=""></figure><p><br>Leon Lin from <a href="https://avoidboringpeople.substack.com/subscribe">Avoid Boring People</a> asks questions to better understand what matters to his audience, so he can tailor his content to be relevant to them.</p><figure><img src="https://lh4.googleusercontent.com/iUdYNNiuSEz68Sp263JCShetJ_OfYItm6WLo-3cbiRkvQNHWHig0QAo82_BwP4zVAAOd3vg_crEb5Rw5z8kMGNilJ4utnDsvFr7JI9UbzpPeGWhCOX_qEIepRztkxZ3P4Ge1ouk5" alt=""></figure><p><br>Terrell from <a href="https://halfmarathons.substack.com/">Half Marathoner</a> asks a specific question related to his niche:</p><blockquote>“In the meantime, I’d love to know how we might help you better — do you have a question about running, training, or anything in between?”</blockquote><p>Asking the right questions helps you build an understanding of who your subscribers are and what matters to them.</p><div><p>Instead of saying “Please tell a few friends if you like” in your welcome email, make it easy for your subscribers to share that they have subscribed to your newsletter by crafting pre-made snippets. You can use either <a href="https://www.sharelinkgenerator.com/">Share Link Generator</a> or <a href="https://clicktotweet.com/">Click To Tweet</a>. </p><p>In fact, here's a template.</p></div><blockquote>"Just joined other (your newsletter's target audience) and subscribed to (your landing page / link to subscribe) by (@your twitter handle) <br>Looking forward to reading (insert a blurb about your newsletter)"</blockquote><p>By decreasing the effort to share, you’ll start to see people dropping your newsletter on social media like it's hot.</p><h3 id="get-subscribers-to-whitelist-you">Get Subscribers To Whitelist You</h3><div><p>Every newsletter writer tries to prevent their newsletter from landing inside Gmail's Promotions tab or the spam folder of doom.</p><p>By asking subscribers to whitelist your newsletter, your future issues are more likely to appear in the Primary inbox. Your deliverability will also improve, and this increases the probability that your issues get seen by your subscribers instead of getting buried in a pile of ads. Of course, this drastically improves open rates.</p><p>Harry Dry of <a href="https://marketingexamples.com/">Marketing Examples</a> gives specific instructions to whitelist his email address to increase deliverability. </p></div><figure><img src="https://lh4.googleusercontent.com/PVezkn8L9rl2NnQ2YGJZ376sT1I0hAykGXCS5nw7mX8Xd2Ma8KiRm0Nrur_UMAzRAB4RvI42reruorgOM0GEoemZQGYwYJRDaTsuKHQcg1BGc7yu4HH1mw26XHyj8g6qcUKZmsM8" alt=""></figure><p>Some of us at Newsletter Crew ask our subscribers to reply with a simple "Done!" when they receive welcome emails.</p><h3 id="make-sure-they-can-unsubscribe">Make Sure They Can Unsubscribe</h3><p>Ensure that you provide an option to unsubscribe in your welcome email. The last thing you want is for subscribers to be marking you as spam when they can’t find the unsubscribe button. If they mark your emails as spam, there will be negative impacts on your domain reputation and deliverability rates.</p><h3 id="keep-welcome-emails-brief">Keep Welcome Emails Brief</h3><div><p>Remember not to make your welcome emails too wordy! They shouldn’t read like an essay. Always respect your reader's time.</p><p>See how Harry Dry does it in the <a href="http://marketingexamples/">Marketing Examples</a> welcome email? It’s short, friendly and tells you everything you need to know.</p></div><figure><img src="https://lh3.googleusercontent.com/LP85uotppOTVDl27wdtvua5ix-t-fsNeVLzFUyBlKVJx9K1ExPFvNqO4V4D0ifbcQFVbcVvpZJz_aAjaenvBvRjriPvMFNNPpSblPHwrU5J8QFbrkITPr7PgIcLKGhURGBFn4Yhf" alt=""></figure><p><br><strong>Write effective welcome emails. They'll improve engagement with your subscribers from the get go and drive more opens and clicks!</strong></p><h3 id="are-you-looking-to-improve-your-welcome-emails-join-the-newsletter-crew-community-and-connect-with-successful-newsletter-creators-who-can-help-">Are you looking to improve your welcome emails? Join the Newsletter Crew community and connect with successful newsletter creators who can help.</h3><!--kg-card-begin: html--><div>
  <div>
    
    <div>
      <ul>
        <li>Full access to all private blogs</li>
        <li>Full access to all private podcasts</li>
        <li>Webinars and AMAs</li>
        <li>Option to be on the Newsletter Crew community podcast episodes</li>
        <li>Private Forums and Chat (200+ members)</li>
      </ul>
      <p><a href="https://newslettercrew.memberful.com/checkout?plan=54344">Choose this plan</a>
    </p></div>
  </div>

  <div>
    
    <div>
      <ul>
        <li>Full access to all private blogs</li>
        <li>Full access to all private podcasts</li>
        <li>Webinars and AMAs</li>
        <li>Option to be on the Newsletter Crew community podcast episodes</li>
        <li>Private Forums and Chat (200+ members)</li>
      </ul>
      <p><a href="https://newslettercrew.memberful.com/checkout?plan=53407">Choose this plan</a>
    </p></div>
  </div>
</div><!--kg-card-end: html-->
    </section></div>]]>
            </description>
            <link>https://newslettercrew.com/improve-your-newsletter-welcome-emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720076</guid>
            <pubDate>Thu, 08 Oct 2020 15:32:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I reverse engineered my cable modem and turned it into an SDR]]>
            </title>
            <description>
<![CDATA[
Score 311 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24719680">thread link</a>) | @0x00000000
<br/>
October 8, 2020 | https://stdw.github.io/cm-sdr/ | <a href="https://web.archive.org/web/*/https://stdw.github.io/cm-sdr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
        <div id="title">
          
          
          <hr>
          <p><span>Project maintained by <a href="https://github.com/stdw">stdw</a></span>
          <span>Hosted on GitHub Pages — Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </p></div>

        

<p><img src="https://stdw.github.io/cm-sdr/img/modem.jpg" alt="cable modem"></p>

<h2 id="introduction">Introduction</h2>
<p>A few weeks ago I got curious about an old cable modem sitting in my closet,
a Motorola MB7220. Initially I was interested in what kind of hardware it had
and if it was running Linux. Some quick searching brought me to a thread on
a web forum where people were discussing the built in spectrum analyzer feature
used for diagnostics. Someone mentioned that they could see spikes
corresponding to FM radio stations. This sparked a thought: if a cable modem 
and a digital TV tuner dongle are fundamentally doing the same thing (receiving 
and demodulating QAM signals), could a modem be turned into an 
<a href="https://en.wikipedia.org/wiki/Software-defined_radio">SDR (software-defined radio)</a>
a la <a href="https://www.rtl-sdr.com/">RTL-SDR</a>?</p>

<p>Going into this project, I knew next to nothing about RF and had no idea if
this goal was even feasible at all for the hardware. I found 
<a href="http://www.hermeslite.com/">an SDR project</a> based on an Analog Devices 
cable modem chip, as well as a <a href="https://forums.qrz.com/index.php?threads/cable-modem-to-software-defined-radio-modification-projects.512433/">forum thread</a>
where someone else was wondering about the same thing a few years ago.</p>

<p>The last post in the thread from user VK4HAT states:</p>

<blockquote>
  <p>I say if you have the skills, time and desire, give it a go and see where you end up. If google shows nothing, then its likely not been tried. With so few firsts available in life, take those that present themselves and have a crack, even if failure is always an option.</p>
</blockquote>

<p>So that is exactly what I did.</p>

<h2 id="gaining-access">Gaining Access</h2>
<p>My first goal was to look for an access vector or a way to communicate with the
device. I knew that there wasn’t much to see on the web interface and telnet
was disabled, so I skipped ahead to opening it up.</p>

<p>After removing a few screws from the plastic housing to get access to the
board, my first thought was to look for <a href="https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter">UART</a> headers to take a peek at the serial console. 
After identifying two candidates consisting of four vias surrounded by a 
rectangle near the edge of the PCB, it was time to identify the pins. 
Using a multimeter, the ground pin can be easily identified by checking 
the continuity with one of the metal shields on board. The VCC pin can be 
identified by measuring the voltage of each pin when powering on the board. 
It should be a steady 3.3v, or in some cases 1.8v or 5v. This pin is not 
needed, but is still useful to identify the operating voltage and eliminate 
one candidate for the Tx and Rx pins.
While booting, the Tx pin will sit on average a little lower than the VCC pin
and drop much lower when a lot of data is being output. This leaves the last 
pin as Rx.</p>

<p>One of the UARTs identified earlier did not seem to be transmitting anything
while the other did. After soldering some wires to the active UART, I connected
the Tx to UART Rx GPIO pin on a Raspberry Pi, the Rx to the Pi’s Tx, and the 
ground to the ground pin. Note that this can only be done because both systems
are 3.3v. Had that not been the case, a USB TTL adapter with an adjustable 
voltage level could be used just as easily, and is probably a better idea most
of the time anyway.</p>

<p>There are a few reasons why the Raspberry Pi is not the best serial interface
such as if you need parity or other features, but in this case I had it on hand
and it works. The serial console of the Pi must also be disabled so that it can 
be freed up for other purposes. There is another reason I chose to use the 
Raspberry Pi which I will get to later.</p>

<p>Finally, to actually see the data I used the <code>cu</code> utility:<br>
<code>cu -l /dev/serial0 -s 115200</code><br>
The baud rate was a lucky guess, but 115200 is very common on such devices.
If the baud rate is wrong you will quickly know when you see a bunch of garbage
on the screen. A logic analyzer could be used to definitively find the baud 
rate and other parameters, but guessing is sometimes quicker and always 
cheaper.</p>

<p>After powering on the device, the terminal filled with output:</p>

<div><div><pre><code>pi@raspberrypi:~/modem $ cu -l /dev/serial0 -s 115200
Connected.
�
B3312inim S C 84(9 m
ose_VS 8
STesldlo rh 83 rs 10
STesldhi: _h 8, _s 13
Sync: 0 
MemSize:            128 M
Chip ID:     BCM3383D-B0

BootLoader Version: 2.4.0 fyl spiboot reduced DDR drive avs
Build Date: Nov 12 2015
Build Time: 14:31:43
SPI flash ID 0xef4016, size 4MB, block size 64KB, write buffer 256, flags 0x0
Cust key size 128

Signature/PID: 3383


Image 1 Program Header:
   Signature: 3383
     Control: 0005
   Major Rev: 0003
   Minor Rev: 0000
  Build Time: 2015/11/26 08:47:57 Z
 File Length: 1692841 bytes
Load Address: 80004000
    Filename: ecram_sto.bin
         HCS: e749
         CRC: 175b753f

Found image 1 at offset 20000

Enter '1', '2', or 'p' within 2 seconds or take default...


Performing CRC on Image 1...
CRC time = 282177012
Detected LZMA compressed image... decompressing... 
Target Address: 0x80004000
decompressSpace is 0x8000000
Elapsed time 736066500

Decompressed length: 8091524

Executing Image 1...


 eCos - hal_diag_init
Ecos memory map:
BLOCK    OWNER        MIPS      SIZE      MEM
Block 0: Owner: 0 - 0x00000000 0x07e00000 0x00000000
Block 0: Owner: 0 - 0 MB 126 MB 0 MB
Block 1: Owner: 3 - 0x07e00000 0x00200000 0x07e00000
Block 1: Owner: 3 - 126 MB 2 MB 126 MB
126MB (129024KB) remaining for eCos
Init device '/dev/BrcmTelnetIoDriver'
Init device '/dev/ttydiag'
Init tty channel: 807bb020
Init device '/dev/tty0'
Init tty channel: 807bb040
Init device '/dev/haldiag'
HAL/diag SERIAL init
Init device '/dev/ser0'
BCM 33XX SERIAL init - dev: b4e00500.2
Set output buffer - buf: 0x80852408 len: 4096
Set input buffer - buf: 0x80853408 len: 4096
BCM 33XX SERIAL config
Init device '/dev/ser1'
BCM 33XX SERIAL init - dev: b4e00520.3
Set output buffer - buf: 0x80854408 len: 4096
Set input buffer - buf: 0x80855408 len: 4096
BCM 33XX SERIAL config

Init device '/dev/ser2'
InitBoard: MIPS frequency 637200000

...

Reading Permanent settings from non-vol...
Checksum for permanent settings:  0xe9d88f65
Setting downstream calibration signature to '5.7.1mp1|die temperature:70.775degC'
Settings were read and verified.


Reading Dynamic settings from non-vol...
Checksum for dynamic settings:  0x6e4a329
Settings were read and verified.

Console input has been disabled in non-vol.
Console output has been disabled in non-vol!  Goodbye...
[00:00:00 01/01/1970] [Reset/Standby Switch Thread] BcmResetStandbySwitchThread::ProcessResetSwitchEvent:  (Reset/Standby Switch Thread) Reset switch released; resetting...
[00:00:00 01/01/1970] [Reset/Standby Switch Thread] BcmResetStandbySwitchThread::ProcessResetSwitchEvent:  (Reset/Standby Switch Thread) Cant Reset pfCmDocsisCtlThread==NULL...
</code></pre></div></div>

<p>This output contains a wealth of information. The device is 
running <a href="https://en.wikipedia.org/wiki/ECos">eCos</a> on a MIPS processor 
which is part of a Broadcom BCM3383 SoC. It turns out there are actually
two MIPS processors on this SoC although one of them is not used on this
modem, explaining the other UART. On some devices, the second processor
will run Linux for additional features.</p>

<p>Also, this seems like the end of the line for serial because shortly after 
booting the actual OS, it disables the serial console. Hitting “p” at the 
bootloader prompt does not lead to much except a way to download new OS 
images via tftp and a utility to read and write memory addresses. This could
be used to bypass the check, but a much greater understanding of the OS and
memory layout would be required.</p>

<h2 id="dumping-the-flash">Dumping the flash</h2>

<p>My goal now was to enable the serial console. Examination of the board reveals
a single <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface">SPI</a> flash
chip which likely contains the bootloader, OS, and configuration as it is the
only non-volatile storage visible on the board.</p>

<p>This is where the Raspberry Pi comes in handy once again. The GPIO header also
conveniently contains a SPI interface which can be used to read the data off
of the flash chip.</p>

<p>Searching the number on the chip, “winbond 25Q32JV”, yields the datasheet
containing the pinout. The important ones are VCC, Chip Select (CS), Clock
(CLK), Data Out (DO), Data In (DI), and ground.</p>

<p>One common issue with dumping a SPI chip on a board is that the chip requires
power, but this will also usually power the board and cause it to start booting
and using the chip. I chose to overcome this by heating the VCC pin with my
soldering iron and very carefully lifting it off the pad. This is a convenient,
but rather crude solution which may result in snapped off leads so use at your
own risk! I also soldered a jumper wire to the pad and another to the floating
leg so that I could easily connect and disconnect them and allow the device to
boot again.</p>

<p>Another note, on some boards the Chip Select pin is assumed to always be 
enabled so it is directly tied to VCC. This means when you power the CS 
pin, the board also starts booting. This can be solved in a similar way
to the VCC pin.</p>

<p>Now, wires can be soldered to the rest of the pins and the they can be
connected to the Raspberry Pi. The ground goes to ground (the UART ground
from earlier can also be used), the VCC to the Pi’s 3.3v pin. (Again, it is
critical to verify with the datasheet that this is a 3.3v chip because the Pi
only supports 3.3v). The DO pin is connected to the Pi’s SPI <code>MISO</code> (master in 
slave out) pin and DI to the <code>MOSI</code> pin (master out slave in). Lastly, the 
Clock is connected to the <code>SCLK</code> GPIO pin and the Chip Select to the <code>CE0</code> pin.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://stdw.github.io/cm-sdr/img/chip.jpg" alt="flash chip"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Not the best soldering job but it will work</em></td>
    </tr>
  </tbody>
</table>

<p>To actually read the chip, there is a fantastic tool called 
<a href="https://flashrom.org/Flashrom">flashrom</a> which supports an enormous number of
chips. <code>flashrom</code> is present in the repos of many distributions including that
of the Raspberry Pi OS (formerly known as Raspbian).</p>

<p>Luckily the W25Q32JV is supported, under the name “W25Q32.V”. A quick check on
the flashrom wiki shows the size and voltage match what is expected and that
the chip is fully supported.</p>

<p>Before proceeding, ensure that the SPI interface on the Pi is enabled by
using the <code>raspi-config</code> utility and checking under “Interfacing Options”.</p>

<p>At last we can read the chip. First verify that it is …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stdw.github.io/cm-sdr/">https://stdw.github.io/cm-sdr/</a></em></p>]]>
            </description>
            <link>https://stdw.github.io/cm-sdr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719680</guid>
            <pubDate>Thu, 08 Oct 2020 15:00:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Guide to Deep Learning and Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24719670">thread link</a>) | @NaeosPsy
<br/>
October 8, 2020 | https://serokell.io/blog/deep-learning-and-neural-network-guide | <a href="https://web.archive.org/web/*/https://serokell.io/blog/deep-learning-and-neural-network-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As a subset of artificial intelligence, deep learning lies at the heart of various innovations: self-driving cars, natural language processing, image recognition and so on. Companies that deliver DL solutions (such as Amazon, Tesla, Salesforce) are at the forefront of stock markets and attract impressive investments. According to <a href="https://www.statista.com/statistics/621468/worldwide-artificial-intelligence-startup-company-funding-by-year/">Statista</a>, the total funding of artificial intelligence startup companies worldwide in 2014–2019 is equal to more than $26 billion. This high interest can be explained by the amazing benefits of deep learning and its architectures — artificial neural networks.</p><p><img src="https://serokell.io/files/3s/3slpcvqe.1_(32)_(1).jpg" alt="AI startup funding graph"></p><h2 id="what-is-deep-learning%3F">What is deep learning?</h2><p><img src="https://serokell.io/files/yc/yctimg60.deviator-1_(1).jpg" alt="what is deep learning"></p><p>Deep learning is one of the subsets of machine learning that uses deep learning algorithms to implicitly come up with important conclusions based on input data.</p><p>Usually, deep learning is unsupervised or semi-supervised. Deep learning is based on <a href="https://en.wikipedia.org/wiki/Feature_learning#:~:text=In%20machine%20learning%2C%20feature%20learning,or%20classification%20from%20raw%20data.">representation learning</a>. Instead of using task-specific algorithms, it learns from representative examples. For example, if you want to build a model that recognizes cats by species, you need to prepare a database that includes a lot of different cat images.</p><p>The main architectures of deep learning are:</p><ul>
<li>Convolutional neural networks</li>
<li>Recurrent neural networks</li>
<li>Generative adversarial networks</li>
<li>Recursive neural networks</li>
</ul><p>We are going to talk about them more in detail later in this text.</p><h3 id="difference-between-machine-learning-and-deep-learning">Difference between machine learning and deep learning</h3><p>Machine learning attempts to extract new knowledge from a large set of pre-processed data loaded into the system. Programmers need to formulate the rules for the machine, and it learns based on them. Sometimes, a human might intervene to correct its errors.</p><p>However, deep learning is a bit different:</p><table>
  <tbody><tr>
   <th>Deep learning
   </th>
   <th>Machine learning
   </th>
  </tr>
  <tr>
   <td>large amounts of data
   </td>
   <td>small datasets as long as they are high-quality
   </td>
  </tr>
  <tr>
   <td>computation-heavy
   </td>
   <td>not always
   </td>
  </tr>
  <tr>
   <td>an draw accurate conclusions from raw data
   </td>
   <td>carefully pre-processed data
   </td>
  </tr>
  <tr>
   <td>take much longer to train
   </td>
   <td>can be trained in a reduced amount of time
   </td>
  </tr>
  <tr>
   <td>you can't know what are the particular features that the neurons  represent
   </td>
   <td>logic behind the machine’s decision is clear
   </td>
  </tr>
  <tr>
   <td>can be used in unexpected ways
   </td>
   <td>algorithm is built to solve a specific problem
   </td>
  </tr>
</tbody></table><h2 id="advantages-of-deep-learning">Advantages of deep learning</h2><p>Now that you know what the difference between DL and ML is, let us look at some advantages of deep learning.</p><ul>
<li>In 2015, a group of Google engineers was conducting research about <a href="https://ai.googleblog.com/2015/07/deepdream-code-example-for-visualizing.html">how NN carry out classification tasks</a>. By chance, they also noticed that neural networks can hallucinate and <a href="https://www.youtube.com/watch?v=uSUOdu_5MPc&amp;t=932s">produce rather interesting art</a>.</li>
<li>The ability to identify patterns and anomalies in large volumes of raw data enables deep learning to efficiently deliver accurate and reliable analysis results to professionals. For example, Amazon has more than <a href="https://www.digitalcommerce360.com/article/amazon-sales/">560 million items on the website and 300+ million users</a>. No human accountant or even a whole army of accountants would be able to track that many transactions without an AI tool.</li>
<li>Deep learning doesn’t rely on human expertise as much as traditional machine learning. DL allows us to make discoveries in data even when the developers are not sure what they are trying to find. For example, you want your algorithms to be able to <a href="https://www.digitalocean.com/community/tutorials/how-to-build-a-deep-learning-model-to-predict-employee-retention-using-keras-and-tensorflow">predict customer retention</a>, but you’re not sure which characteristics of a customer will enable the system to make this prediction.</li>
</ul><p><img src="https://serokell.io/files/b3/b37v6nzo.2_(24)_(1).jpg" alt="Deep learning advantages"></p><h2 id="problems-of-deep-learning">Problems of deep learning</h2><ul>
<li>Large amounts of quality data are resource-consuming to collect. For many years, the largest and best-prepared collection of samples was <a href="https://www.zdnet.com/article/worlds-largest-image-database-to-help-computers-learn-to-see/#:~:text=To%20develop%20a%20system%20that,holds%2014%20million%20labeled%20images.">ImageNet with 14 million different images</a> and more than 20,000 categories. It was founded in 2012, and only last year, <a href="https://neurohive.io/en/datasets/tencent-dataset/">Tencent released a database</a> that is larger and more versatile.</li>
<li>Another difficulty with deep learning technology is that it cannot provide reasons for its conclusions. Therefore, it is difficult to assess the performance of the model if you are not aware of what the output is supposed to be. Unlike in traditional machine learning, you will not be able to test the algorithm and find out why your system decided that, for example, it is a cat in the picture and not a dog.</li>
<li>It is very costly to build deep learning algorithms. It is impossible without qualified staff who are trained to work with sophisticated maths. Moreover, deep learning is a resource-intensive technology. It requires powerful GPUs and a lot of memory to train the models. A lot of memory is needed to store input data, weight parameters, and activation functions as an input propagates through the network. Sometimes deep learning algorithms become so power-hungry that researchers prefer to use <a href="https://serokell.io/blog/how-to-choose-ml-technique">other algorithms</a>, even sacrificing the accuracy of predictions.</li>
</ul><p>However, in many cases, deep learning cannot be substituted.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/0VH1Lim8gL8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe><h2 id="how-can-you-apply-dl-to-real-life-problems%3F">How can you apply DL to real-life problems?</h2><p><img src="https://serokell.io/files/66/66a4xqmg.4_(18)_(1).jpg" alt="Deep learning applications"></p><p>Today, deep learning is applied across different industries for various use cases:</p><ul>
<li><strong>Speech recognition.</strong> All major commercial speech recognition systems (like Microsoft Cortana, Alexa, Google assistant, Apple Siri) are based on deep learning-based.</li>
<li><strong>Pattern recognition.</strong> Pattern recognition systems are already able to give more accurate results than the human eye in <a href="https://www.bbc.com/news/health-50857759#:~:text=Artificial%20intelligence%20is%20more%20accurate,images%20from%20nearly%2029%2C000%20women.">medical diagnosis</a>.</li>
<li><strong>Natural language processing.</strong> Neural networks have been used to implement language models since the early 2000s. The invention of <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a> helped improve machine translation and language modeling.</li>
<li><strong>Discovery of new drugs.</strong> For example, the <a href="https://arxiv.org/abs/1510.02855">AtomNet neural network</a> has been used to predict new biomolecules that can potentially cure diseases such as Ebola and multiple sclerosis.</li>
<li><strong>Recommender systems.</strong> Today, deep learning is being used to study user preferences across many domains. <a href="https://www.netflix.com/">Netflix</a> is one of the brightest examples in this field.</li>
</ul><h2 id="what-are-artificial-neural-networks%3F">What are artificial neural networks?</h2><p><img src="https://serokell.io/files/vd/vd78l0x8.deviator-2_(1).jpg" alt="What are artificial neural networks"></p><p>“Artificial neural networks” and “deep learning” are often used interchangeably, which isn’t really correct. Not all neural networks are “deep”, meaning “with many hidden layers”, and not all deep learning architectures are neural networks. There are also <a href="https://en.wikipedia.org/wiki/Deep_belief_network#:~:text=In%20machine%20learning%2C%20a%20deep,between%20units%20within%20each%20layer.">deep belief networks</a>, for example.</p><p><img src="https://serokell.io/files/vk/vkpzrxrf.5_(12)_(1).jpg" alt="neural networks"></p><p>However, since neural networks are the most hyped algorithms right now and are, in fact, very useful for solving complex tasks, we are going to talk about them in this post.</p><h3 id="definition-of-an-ann">Definition of an ANN</h3><p>An artificial neural network is heavily inspired by the structure of a human brain. Simply put, an ANN represents a sequence of neurons connected by synapses. Those sequences are often organized into layers.</p><p>Having many (sometimes millions) of input neurons in the system, the machine learns to analyze and even memorize various information. Due to this structure, a neural network can process monstrous amounts of information very fast.</p><p>Here is a video for those who want to dive deeper into the technical details of how artificial neural networks work.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/njKP3FqW3Sk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe><p>Artificial neural networs are incredibly valuable not only to analyze incoming information but also to reproduce it from their memory.</p><h2 id="components-of-neural-networks">Components of Neural Networks</h2><p>Every neural network consists of neurons, synapses, weights, biases, and functions.</p><h3 id="neurons">Neurons</h3><p>A neuron or a node of a neural network is a computing unit that receives information, performs simple calculations with it, and passes it further.</p><p>All neurons in a net are divided into three groups:</p><ul>
<li>Input neurons that receive information from the outside world;</li>
<li>Hidden neurons that process that information;</li>
<li>Output neurons that produce a conclusion.</li>
</ul><p><img src="https://serokell.io/files/yt/ytl4jey2.6_(8)_(1).jpg" alt="ML architecture"></p><p>In a large neural network with many neurons and connections between them, neurons are organized in layers. An input layer receives information, n hidden layers (at least 3+) process it, and an output layer provides some result.</p><p>Each of the neurons inputs and outputs some data. If this is the first layer, input = output. In other cases, the information that the neurons have received from the previous layer is passed to input. Then, it uses an activation function to get a new output, which is passed to the next layer of neurons in the system.</p><p>Neurons only operate numbers in the range [0,1] or [-1,1]. In order to turn data into something that a neuron can work with, we need normalization. We talked about what it is in the <a href="https://serokell.io/blog/regression-analysis-overview">post about regression analysis</a>.</p><p>Wait, but how do neurons communicate? Through synapses.</p><h3 id="synapses-and-weights">Synapses and weights</h3><p>If we didn’t have synapses, we would be stuck with a bunch of inactive useless neurons. A synapse is a connection between two neurons. Every synapse has a weight. It is the weight that changes the input information while it is transmitted from one neuron to another. The neuron with the greater weight will be dominant in the next neuron. One can say that the <a href="https://en.wikipedia.org/wiki/Weighing_matrix">matrix of weights</a> is the brain of the whole neural system.</p><p><img src="https://serokell.io/files/b9/b92z8vod.7_(9)_(1).jpg" alt="Neuron weights"></p><p>It is thanks to these weights that the input information is processed and converted into a result. During the initialization (first launch of the NN), the weights are randomly assigned. Later on, they are optimized.</p><h3 id="bias">Bias</h3><p>A bias neuron allows for more variations of weights to be stored. Biases add richer representation of the input space to the model’s weights.</p><p>In the case of neural networks, a bias neuron is added to every layer. It plays a vital role by making it possible to move the activation function to the left or right on the graph.</p><p><img src="https://serokell.io/files/ey/eyarbo1y.8_(5)_(1).jpg" alt="bias neurons"></p><p>It is true that ANNs can work without bias neurons. However, they are almost always added and counted as an indispensable part of the overall model.</p><h2 id="how-anns-work">How ANNs work</h2><p>Every neuron processes input data to extract a feature. Let’s imagine that we have features x1, x2, x3, and three neurons, each of which is connected with all these features.</p><p>Each of the neurons has its own weights that are used to weight the features. During the training of the network, you need to select such weights for each of the neurons that the output provided by the whole network would be true-to-life.</p><p>To perform transformations and get an output, every neuron has an activation function. It allows us to get some new feature space. This combination of functions performs a transformation that is described by a common function F — this describes the formula behind the NN’s magic.</p><p><img src="https://serokell.io/files/ly/ly9z5sh4.9_(3)_(1).jpg" alt="ANN: activation function"></p><p>There are a lot of activation functions, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/deep-learning-and-neural-network-guide">https://serokell.io/blog/deep-learning-and-neural-network-guide</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/deep-learning-and-neural-network-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719670</guid>
            <pubDate>Thu, 08 Oct 2020 14:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here's how Russia could track your every move – without even hacking your phone]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24719602">thread link</a>) | @geek_slop
<br/>
October 8, 2020 | https://www.geekslop.com/features/technology-articles/hacking-and-security-technology-articles/2020/if-you-have-this-popular-app-installed-on-your-phone-consider-this-heres-how-russia-could-track-your-every-move-without-even-hacking-your-phone | <a href="https://web.archive.org/web/*/https://www.geekslop.com/features/technology-articles/hacking-and-security-technology-articles/2020/if-you-have-this-popular-app-installed-on-your-phone-consider-this-heres-how-russia-could-track-your-every-move-without-even-hacking-your-phone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><img width="550" height="366" src="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png" alt="image thumb141" loading="lazy" srcset="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png 550w, https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141-416x277.png 416w, https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141-300x200.png 300w" sizes="(max-width: 550px) 100vw, 550px" data-attachment-id="13840" data-permalink="https://www.geekslop.com/news/technology-news/hacking-and-security/2015/interesting-geographic-attack-vector-from-a-russian-launched-cyber-counter-attack/attachment/russian-and-american-flags" data-orig-file="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png" data-orig-size="550,366" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Russian and American flags" data-image-description="" data-medium-file="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141-300x200.png" data-large-file="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png" title="If you have this popular app installed on your phone, consider this: Russia could track your every move - without even hacking your phone. 1"></p><p>What geek doesn’t like a good conspiracy theory? Well, I’ve got one for you – a follow-the-money chain that leads from the head of Russian state to an app that is installed on millions of personal phones – one that you probably use every day.</p>



<h2>The back-channel links between American media outlets and Russian propaganda</h2>



<p>Russia’s most used back-channel outlet to the Western World is Russia Today (RT or rt.com), a commonly known propaganda outlet for the Russian government. The RT media outlet is directly funded by the Russian federal tax budget and under the <em>Foreign Agents Registration Act</em>, is registered as a “foreign agent” with the <em>United States Department of Justice</em>. There’s no argument – RT is a propaganda machine for the Russian government.</p>



<p>In October 2020, the <a aria-label="Wall Street Journal noted how many Americans are unwittingly directed to RT (opens in a new tab)" rel="noreferrer noopener external" href="https://www.wsj.com/articles/how-russia-today-skirts-high-tech-blockade-to-reach-u-s-readers-11602078094?mod=hp_featst_pos3" target="_blank" data-wpel-link="external">Wall Street Journal noted how many Americans are unwittingly directed to RT</a> from right-leaning websites such as RealClearPolitics, The Blaze, 245WallSt, Newser, The Daily Caller, Newsmax, the National Review, and others. The Journal investigated the bizarre relationship and found that the outlets were a part of a distribution network known as <em>Mixi Media</em> – a company with a privately registered domain and no About page on their website. They also discovered that included in the Mixi Media family was another Russian state-backed outlet, Sputnik – and the that the owner and founder of Mixi Media is a man named Alex Baron. When they contacted Baron about the revelatory article they were going to publish, Mixi Media immediately began dropping partners from the network.</p>



<h2>Alex Baron and ties to the Russian government?</h2>



<p>Alex Baron is not a name known to many. According to WSJ, he is an associate of Russian private-equity magnate Victor Remsha. The Wall Street Journal also says Mixi “has other ties to Russia” and that there are some “technical connections between Mixi and properties owned by Remsha”. </p>



<p>Baron denies all ties with Remsha, his companies, and RT. However, he does not deny that he is the tech director of a piece of software found on millions of phones around the country – an app that in 2017 was scandalously found to be sending user location data to a third-party using WiFi tracking even when GPS location sharing was turned off. The app is one of the most popular and highly-rated apps on Andriod and iPhones – the weather app, AccuWeather.</p>



<h2>AccuWeather</h2>



<p>All it takes is a look at AccuWeather’s permissions to see how easily a foreign country could use an app to track a person. The AccuWeather app has access to and is allowed a terrifying degree of freedom on your smartphone device. As of October 8, 2020, the weather app was allowed:</p>



<h3>Storage</h3>



<ul><li>modify or delete the contents of your USB storage</li><li>read the contents of your USB storage</li></ul><h3>Wi-Fi connection information</h3>



<ul><li>view Wi-Fi connections (this is how they were able to track and send location data even when GPS was turned off)</li></ul><h3>Device ID &amp; call information</h3>



<ul><li>read phone status and identity</li></ul><h3>Location</h3>



<ul><li>precise location (GPS and network-based)</li><li>approximate location (network-based)</li></ul><h3>Microphone</h3>



<ul><li>record audio</li></ul><h3>Other</h3>



<ul><li>receive data from Internet</li><li>pair with Bluetooth devices, including microphones</li><li>read Google service configuration</li><li>draw over other apps, a permission that lets an app cover up warnings or change content of other apps</li><li>run at startup</li><li>connect and disconnect from Wi-Fi</li><li>prevent device from sleeping</li><li>access Bluetooth settings</li><li>disable your screen lock</li><li>control vibration</li><li>change system display settings</li><li>view network connections</li><li>and yes, full network access</li></ul><h2>Could Russia use AccuWeather to track the movements of Americans?</h2>



<p>It’s an indirect link from the Russian state-owned RT media outlet and the AccuWeather app but there is certainly an interesting chain of relationships that could be concerning to most people. Could Russia use an app like AccuWeather to track Americans movements? At this point, nobody knows. But I can tell you that right before I clicked “Publish” for this article, I uninstalled AccuWeather from my phone.</p>
		</div></div>]]>
            </description>
            <link>https://www.geekslop.com/features/technology-articles/hacking-and-security-technology-articles/2020/if-you-have-this-popular-app-installed-on-your-phone-consider-this-heres-how-russia-could-track-your-every-move-without-even-hacking-your-phone</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719602</guid>
            <pubDate>Thu, 08 Oct 2020 14:52:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Joy of Fixing Things]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24719143">thread link</a>) | @kioleanu
<br/>
October 8, 2020 | https://viorel.me/2020/2020-10-08-the-joy-of-fixing-things/ | <a href="https://web.archive.org/web/*/https://viorel.me/2020/2020-10-08-the-joy-of-fixing-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        Viorel
        <br>
        <span>on&nbsp;</span><time datetime="2020-10-08 12:00:18 +0000 UTC">October 8, 2020</time>
</p>
		


		

		

<p>As I’m getting older and grumpier, I find myself more and more attached to my stuff, so I’ve decided that I’ll do two things from now on: 1) try only buying stuff that will give me as many life years as possible and 2) repair as many of the items I already own</p>

<p>I was surprised how much satisfaction I get from repairing things and how much I can learn. Here’s the summary of what I did this week:</p>

<h3 id="my-wife-s-bike-chain">My wife’s bike chain</h3>

<p><em>Which I broke 6 months ago trying to get myself up a steep hill.</em></p>

<p>What I’ve learned:</p>

<ol>
<li>bike chains are consumables</li>
<li>their size depends on how many gears you have (they’re thicker for bikes with many gears)</li>
<li>you buy an approximate length chain, which you have to shorten yourself</li>
<li>there are special tools to shorten bike chains and all bike chains are shortenable<br></li>
<li>it’s really easy to change the chain (once you have the right tools)</li>
<li>you have to oil the chain after mounting it</li>
</ol>

<p>What I’ve had trouble with:</p>

<ol>
<li>I was mounting the chain wrong, which gave me the impression I had to shorten it more than I actually needed. I learned how to shorten and <em>lengthen</em> a bike chain. Tip to future me: when shortening a chain, don’t take the pin all the way out. It’s a pain to fit it back in the hole again. Another tip: when researching, try to find a tutorial on a bike that kinda looks like yours.</li>
</ol>

<h3 id="my-phone-s-battery">My phone’s battery</h3>

<p>I have an iPhone SE, first generation, which I absolutely love, mostly because of the size. The battery was slowly dying (OS showed about 80% capacity) and it meant I more or less can’t use the phone in cold weather anymore.</p>

<p>What I’ve had trouble with:</p>

<ol>
<li>The manual that came in the replacement kit was awful and it mixed the instructions for multiple iPhone models: 5, 5s and 5c, but SE wasn’t listed at all. I had to follow the instructions for 5s, but instead I followed those for 5. For the 5, the battery is glued completely differently</li>
<li>Removing the screen was not very easy as some edges were stuck to the body. Slow and steady did the job.</li>
<li>The battery is glued with two plastic stickers to the body and removing the battery was a real pain, because the instructions only said to find said stickers under the battery and pull them out. Unsurprinsingly I pulled them out wrong and it took an hour to remove the battery using a combination of a wedge tool and dental floss. I flossed the battery out by taking the dental floss between the battery and the body from top to bottom. I would have only used the wedge tool harder, but there was a good change of damaging the battery and I’ve seen how that works out.</li>
</ol>

<p>What I’ve learned:</p>

<ol>
<li>When pulling stuff out, apply the same pressure constantly and have patience. When taking the screen out, there was a good chance of it breaking if I pulled too hard. Applying a medium amount of pressure helped take the screen out slowly but steadily.</li>
<li>Don’t be afraid of jamming the flat tool to get the screen out</li>
<li>Always buy replacement kits that come with tools. It’s better to have too many screwdrivers that not enough screwdrivers.</li>
<li>Absolutely do not trust the instructions manual. Research the procedure from multiple sources before you even start working</li>
</ol>

<h3 id="the-family-external-hard-drive">The family external hard drive</h3>

<p>The 2TB Seagate Expansion drive gave up the ghost a couple of years ago and I was toying with an idea of getting an Western Digital MyCloud. My wife didn’t really agree pointing out that we bought the Seagate only 10 years ago and can’t I fix it? Turns out I can, the HDD was OK, but the bridge board was gone.</p>

<p>What I’ve had trouble with: nothing, the most problematic part was deciding which replacement case to buy</p>

<p>What I’ve learned:</p>

<ol>
<li>OK, I had no idea that there is an actual normal 3,5” HDD in there. There is an actual normal 3,5” HDD in there. You can take it out and put it in another casing. Or in a computer. The possibilities are endless.</li>
<li>You can buy another casing in which to plug the HDD</li>
<li>There are casings in which you can put an old laptop disk drive and then use it as an external drive. Wow, I find this amazing.</li>
<li>Splitting the broken piece of equipment in components helps you identify problems easier and fix them quicker. See what can be simply bought and replaced once it’s broken into pieces.</li>
<li>Dedicated forums are amazing and there’s dedicated forums for just about everything.</li>
</ol>

<h3 id="a-friend-s-laptop">A friend’s laptop</h3>

<p>A friend asked me if reinstalling Windows would bring his Sony Vaio back to life as a last attempt before throwing it away. The laptop took anywhere from 45 minutes to 2 hours to fully boot up and load one program. It initially came with Windows 8 and was updated to 10. I suggested upgrading the drive to a SSD and the RAM from 4 to 8 GB and then reinstall Windows.</p>

<p>I was pleasantly surprised by the Vaio. The drive and RAM had their own separate covers which you just unscrewed. Really easy and future-proof. After installing the SSD and memory board and installing Windows, it started working amazingly: load time in under one minute and absolutely no hiccups.</p>

<p>What I’ve had trouble with:</p>

<ol>
<li>I was mounting the memory board wrong, although I saw a tutorial on exactly how do it: place it a 45 degree angle and slide it in. “Slide” is the keyword here. I ended up jamming it. It worked, but it was risky. Redid one more time aftewards, and it went really smoothly.</li>
<li>I lost one of the drive screws inside the body. Took some (gentle) shaking to recover it. A magnetic screwdriver would have helped.</li>
</ol>

<p>What I’ve learned:</p>

<ol>
<li>If you have to apply too much pressure, you’re doing it wrong.</li>
<li>Do not underestimate what an SSD can do</li>
<li>SSDs are really cheap - 30EUR for a 256 GB one</li>
<li>Windows OEM licences are not affected by changing the disk and adding RAM.</li>
</ol>


		
	</div>

	
</div></div>]]>
            </description>
            <link>https://viorel.me/2020/2020-10-08-the-joy-of-fixing-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719143</guid>
            <pubDate>Thu, 08 Oct 2020 14:00:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn How Augmented Reality Can Boost Growth of E-Commerce]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24719006">thread link</a>) | @myurushkin
<br/>
October 8, 2020 | https://salesvision.ai/e-commerce-blog/how-augmented-reality-can-boost-growth-of-e-commerce/ | <a href="https://web.archive.org/web/*/https://salesvision.ai/e-commerce-blog/how-augmented-reality-can-boost-growth-of-e-commerce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			<div>
				<p><strong>Augmented reality in e-commerce</strong> is a trending topic these days. The coronavirus pandemic has led to brick and mortar stores heading to the online marketplace. E-commerce technology solutions also gained in popularity. Apart from digital marketing and SEO for e-commerce, other technologies can also help with your online stores.</p>

<h2>What Is Augmented Reality and How Is It Used in Business?</h2>
<p>Augmented reality describes technologies that add a digital layer to the physical world. It enables computer-generated content to virtually interact with the real world. Famous examples include Snapchat filters and Pokémon GO.</p>
<p>AR is a broad concept, and its usage can be divided into four different types:</p>
<ol>
<li><b>Marker-based AR</b>: Marker-based AR involves image recognition of image content taken with a camera. Users use their camera to scan an object, and it can be transformed on the screen into an interactive model or widget. Snapchat filters belong in this category.</li>
<li><b>Markerless AR</b>: Markerless AI doesn’t use your camera for recognition. Instead, it generates content based on your location. The most famous example is Pokémon GO, where you needed to get to a specific place to find Pokémon. Often enough, they appear in some random places because there is no marker-based AR involved.</li>
</ol>
<p><img src="https://salesvision.ai/wp-content/uploads/2020/10/pokemon-go-ar.png" alt="Pokemon Go Augmented Reality" width="400" height="803"></p>
<p><i>Credits: </i><a href="https://www.npr.org/2016/07/08/485078495/gotta-catch-em-all-or-at-least-a-few-a-pokemon-neophyte-tries-pokemon-go"><i>Gotta Catch ‘Em All, Or At Least A Few: A Pokemon Neophyte Tries ‘Pokemon GO’</i></a><i> – NPR</i></p>
<ol>
<li><b>Superimposition-based AR</b>: It’s also based on object/image recognition, and it substitutes the original camera view with generated 3D content.</li>
<li><b>Projection AR</b>: This is the simplest type of augmented reality. It uses light that reflects off various surfaces. The best example is holograms often seen in science fiction movies.</li>
</ol>
<p>AR found its way into many areas. Augmented reality e-commerce technology is on the rise, so let’s dive into its uses.</p>

<h2>Current Uses of Augmented Reality in E-Commerce</h2>
<p>E-commerce technology often refers to digital marketing tools. Still, AR and data science in e-commerce started to take off. Let’s check out the current uses of augmented reality in e-commerce:</p>

<ul>
<li>
<h4><b>AR Filters for e-Commerce Apps<br>
</b></h4>
</li>
</ul>

<p>The first item on our list is the simplest one. Still, it’s a great idea to raise brand awareness and reach people on social media. For example,<a href="https://www.adweek.com/digital/ben-jerrys-created-a-facebook-ar-filter-that-challenges-you-to-catch-marshmallows-in-your-mouth/"> Ben &amp; Jerry’s launched an AR filter game on Facebook</a> to promote the new ice cream flavor. Sure, it takes a bit of work, but the result is fun, interactive, and a great thing to share with friends.</p>
<p><img src="https://salesvision.ai/wp-content/uploads/2020/10/ben-and-jerrys-ar-filter-game.png" alt="Ben and Jerrys AR Filter Game" width="890" height="500" srcset="https://salesvision.ai/wp-content/uploads/2020/10/ben-and-jerrys-ar-filter-game.png 890w, https://salesvision.ai/wp-content/uploads/2020/10/ben-and-jerrys-ar-filter-game-768x431.png 768w" sizes="(max-width: 890px) 100vw, 890px"></p>
<p><i>Credits: </i><a href="https://www.adweek.com/digital/ben-jerrys-created-a-facebook-ar-filter-that-challenges-you-to-catch-marshmallows-in-your-mouth/"><i>Ben &amp; Jerry’s Created a Facebook AR Filter That Challenges You to Catch Marshmallows in Your Mouth</i></a><i> – Adweek</i></p>


<ul>
<li>
<h4><b>Augmented Reality in Virtual Fitting Rooms</b></h4>
</li>
</ul>

<p>The lockdown has taken its toll on clothing stores, and many of them switched the emphasis to online retailing. The problem is that many customers are hesitant when it comes to online shopping for fashion items. It’s tough to see how it will fit them, and the process of returning the item is lengthy.</p>
<p>Virtual dressing rooms use 3D image generation for products in the store. This e-commerce technology takes the product image content and creates a 3D model of a product. It involves computer vision and AI in e-commerce. Customers can now see exactly how it will fit and feel more confident about the purchase.</p>


<ul>
<li>
<h4><b>Product Preview Placement</b></h4>
</li>
</ul>

<p>Product preview placement is similar to virtual dressing rooms. Instead of fashion items, users can check out how furniture, home appliances, and decorations will fit into their home. The application of this technology is more significant because it involves more expensive items.</p>
<p><img src="https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product.png" alt="Magnolia Augmented Reality Product" width="1600" height="900" srcset="https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product.png 1600w, https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product-768x432.png 768w, https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product-1536x864.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<p><a href="https://www.shopify.com/enterprise/augmented-reality-ecommerce-magnolia-market">Magnolia Market partnered with Shopify</a> to let customers place the items from their catalog inside their homes to see how they fit.</p>

<ul>
<li>
<h4><b>Augmented Reality in Virtual e-Commerce Stores</b></h4>
</li>
</ul>

<p>Virtual stores are about taking the store to your e-customers. It’s the perfect example of innovative e-commerce technology. It uses 3D image generation to turn your bedroom into an interactive virtual store. With the help of computer vision and AI in e-commerce, customers can look at items from the comfort of their homes.</p>

<h2>The Future of Augmented Reality in E-Commerce</h2>
<p>The coronavirus pandemic has accelerated the development of e-commerce technology solutions. Augmented reality in e-commerce is still far from being the standard. The existing solutions are often clumsy, and they break the illusion.</p>
<p>AR goes to show the importance of data science in e-commerce. These solutions are impossible to implement without using AI in e-commerce applications. Computer vision and 3D image generations are the crucial aspects of building realistic AR experiences.</p>
<p>The future technologies will probably contain more of the following:</p>
<ul>
<li><b>Personalized shopping</b>: How about a virtual store full of items you viewed, shown interest in, or the ones recommended for you based on your past interests? It’s the next best thing with AR and AI in e-commerce.</li>
<li><b>Better e-commerce shopping experience</b>: AR is not just for looking at products. It can be used to display all relevant information right there on your screen. You won’t need to check different tabs and screens on your phone to see if there is a size L available.</li>
<li><b>Virtual assistants</b>: Humanoid robots are challenging to build, but you can feature them virtually as shopping assistants. They can talk about the store, products, or possible discounts for the user.</li>
<li></li>
</ul>
<h2>How AI Can Help Generate 3D Images for Augmented Reality Applications</h2>
<p>Talking about AR is all fun and games until the implementation turns out to be a nightmare. To effectively build AR visual content in e-commerce, you’ll need to perform 3D image generation on all products. The process is a painful one: each product needs to be photographed from all angles hundreds of times. Then&nbsp; the image content needs to go through editing before generating the 3D model. Imagine stores with thousands of clothing items; it would take days to take all needed photos.</p>
<p>This is where AI in e-commerce steps in as a significant e-commerce technology. 3D image generation powered by computer vision can form a 3D model out of image content. The difference is: there’s no need for hundreds of photos as one or two will do the trick.</p>
<p>The solution has countless benefits:</p>
<ul>
<li>Saving money on expensive photoshoots.</li>
<li>The time needed to form all 3D models is measured in hours, rather than in days.</li>
<li>No need for manual editing.</li>
<li>The same computer vision solution can be used for all products.</li>
</ul>
<p>3D image generation needed for embedding augmented reality in your store is an important step. If you’re considering opening your AR online store, <a href="https://salesvision.ai/contact-us/">contact SalesVision</a> to help you generate all required 3D models. We provide all the state-of-art applications of data science in e-commerce, and we can power your online store in a matter of hours!</p>

<h2>How COVID-19 Speeds AR Adoption in E-Commerce</h2>
<p>COVID-19 is a crucial factor in the acceleration of AR adoption. E-commerce technology development was already progressing rapidly before the pandemic, and it just exploded in recent times. The reasons are obvious:</p>
<ul>
<li>Constant lockdowns and epidemiologic measures prevent fashion stores from operating normally.</li>
<li>People spend more time than ever using their electronic gadgets.</li>
<li>Many people would rather shop online than cram with strangers in physical stores.</li>
</ul>
<p>Still, even after the pandemic is over, many customers will realize the convenience of online shopping. If you <a href="https://salesvision.ai/e-commerce-blog/how-to-start-your-online-clothing-store/">own an online store</a>, every new feature you add will remain relevant for a long time.</p>

<h2>Final Words</h2>
<p>There are many different types of augmented reality. Funnily enough, most of them can be used to improve customer experience in online stores. The core idea is to bring the store and your items to the customer. 2D image content doesn’t tell the full story about dimensions and how it will look on you or in your home.</p>
<p>The future will bring new developments. The leading retailers will create advanced stores that will appear more convenient than physical stores. Instead of having human workers in the store to ask many questions about the products, focus on it on your screen, and read everything there is to know.</p>
<p>The challenge behind AR is to generate the required models. However, SalesVision has got you covered on that one, and you’re just <a href="https://salesvision.ai/contact-us/">a message away</a> from obtaining your realistic 3D models.</p>
			</div>
		</div>
	</div></div>]]>
            </description>
            <link>https://salesvision.ai/e-commerce-blog/how-augmented-reality-can-boost-growth-of-e-commerce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719006</guid>
            <pubDate>Thu, 08 Oct 2020 13:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A city with a thousand eyes: mass surveillance in Belgrade]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24718535">thread link</a>) | @milankragujevic
<br/>
October 8, 2020 | https://aboutintel.eu/mass-surveillance-serbia/ | <a href="https://web.archive.org/web/*/https://aboutintel.eu/mass-surveillance-serbia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre><strong><a href="https://aboutintel.eu/automated-video-surveillance">Discussion Prompt</a><a href="https://aboutintel.eu/predictive-policing">:</a> </strong>Should we ban the use of automated 
video-surveillance?

<a href="https://aboutintel.eu/automated-video-surveillance">See all contributions to this question.</a></pre>







<p><em>Modern video surveillance is a far cry from its clumsy predecessor. As technology has improved, and camera prices plummeted, surveillance en masse is likely coming to a city near you. Belgrade is one such city, experiencing the roll-out of thousands of cameras as part of a so-called “Safe Society” project. Installed without any public debate, nor a strong legal framework protecting digital and civil rights, concern by local civil society is high. Facial recognition in public spaces is one tool to fight crime, but residents must ask themselves, should this highly intrusive measure trump the privacy of all citizens</em>?</p>



<hr>



<p>Mass biometric surveillance can adversely affect a society — especially if in the case of Serbia, it is one with an already weak democratic tradition — and can cause serious violations of human rights. This is why it should be banned.</p>



<p>The digital age has brought about the idea that technology can exclusively be a force for good, helping us achieve nearly crime-free societies and peace among nations. Whether it’s preventing terrorist attacks or combating organised crime, one answer has been more surveillance of communications and the movements of citizens – most of whom are law-abiding. Now, entering the 2020s, the next targets of surveillance are our <em>faces</em>.&nbsp;</p>



<p><br><strong>Thousands of new eyes for Belgrade</strong></p>



<p>Citizens of the Serbian capital Belgrade learned in early 2019 that their city will be covered with a thousand<a href="https://www.sharefoundation.info/en/new-surveillance-cameras-in-belgrade-location-and-human-rights-impact-analysis-withheld/"> <span>cutting-edge surveillance cameras</span></a> in the following two years as part of the so-called “Safe Society” project. The project was unveiled without any prior public debate.<em> </em>What especially caught the public’s attention was the fact that these cameras — supplied by<a href="https://www.sharefoundation.info/en/huawei-knows-everything-about-cameras-in-belgrade-and-they-are-glad-to-share/"> <span>Chinese tech giant Huawei</span></a> — will have facial and vehicle license plate recognition capabilities. The news was declared by high-ranking officials in internal affairs, the Police Director of Serbia and the Minister of Interior. The latter is one of the key figures of the ruling party and a close associate of President Vučić, which gave the announcement particular ‘weight’ in public. Since then, a citizen initiative known as<a href="https://hiljade.kamera.rs/en/home/"> <span>“Thousands of Cameras” (“Hiljade kamera”)</span></a>, led by SHARE Foundation — a non-profit organisation dedicated to protecting digital rights, which I work for — has been actively challenging this surveillance system and demanding that such an intrusive technology be discussed in an open and inclusive setting before it is introduced.</p>



<p>Serbia does not have a long democratic tradition and features a <a href="https://www.hrw.org/world-report/2019/country-chapters/serbia/kosovo"><span>problematic human rights record</span></a> to this day. As a remnant of socialist Yugoslavia, which prioritised safety and security, privacy awareness is very low for most of the population. The country’s recent democratic backslide is also quite alarming. Earlier this year,<a href="https://freedomhouse.org/report/nations-transit/2020/dropping-democratic-facade"> <span>Freedom House</span></a> downgraded Serbia to a Transitional/Hybrid regime for the first time since 2003. On the<a href="https://rsf.org/en/serbia"> <span>World Press Freedom Index</span></a> for 2020, Serbia is ranked 93rd out of 180 countries – another 3 places down from the previous year. In its report, Reporters Without Borders <a href="https://rsf.org/en/serbia"><span>states</span></a> that “Serbia has become a country where it is often dangerous to be a journalist”. Data protection and privacy do not rest on a long political tradition. A data protection law has existed in Serbia for just over a decade and the Commissioner for Information of Public Importance and Personal Data Protection (the national data protection authority) was established only 16 years ago, at first as a freedom of information complaints body. Furthermore, video surveillance in Serbia — a country currently negotiating EU membership — has seen its fair share of controversy, with camera footage often being abused, leaked in the pro-government media, or the cameras ‘conveniently’ not working at key moments (i.e. when powerful individuals could have been compromised by the footage).&nbsp;</p>



<p>As the city administration’s infrastructure strategy is quite unpopular, the citizens of Belgrade, despite a general privacy lethargy, have paid attention to the new surveillance system; citizens and “Thousands of Cameras” activists<a href="https://hiljade.kamera.rs/map/"> <span>have mapped hundreds of locations</span></a> across Belgrade where cameras have been installed. This form of crowdsourcing provides more information about surveilled locations than the police itself has published. Photos of cameras from various Belgrade neighbourhoods are regularly posted on the<a href="https://twitter.com/hiljadekamera"> <span>“Thousands of Cameras” Twitter feed</span></a>. With this alarming spread of cameras, we have to ask what the deeper implications of such surveillance are? And can it cause or cement irreversible changes in a world of declining democratic values, particularly in a country like Serbia?</p>



<p><br><strong>The legal framework</strong></p>



<p>Serbia has modernised its data protection legal framework by adopting the new Law on Personal Data Protection (LPDP) in late 2018; its full application began in November 2019. Drafted from a confusing mix of translated GDPR regulations and the EU Law Enforcement Directive, the text of Serbia’s new LPDP was controversial from the start, but at least it provided a more modern approach to data protection. Among its main flaws however, is the fact that the new LPDP does not specifically regulate two important aspects of data processing: biometric data and video-surveillance. Despite this, the law’s general provisions and principles should still apply to any data processing, such as a massive video surveillance system across Belgrade.</p>



<p>Before deploying a public space surveillance system, the LPDP obliges the data controller to conduct a Data Protection Impact Assessment (DPIA) and ask for the Commissioner’s opinion. However the Ministry of Interior of Serbia, which is the implementing body for the “Safe Society” project, failed to comply with the LPDP. It issued two DPIAs, both of which did not satisfy the Commissioner, who refused to approve. Despite this, the cameras were installed anyway.&nbsp;</p>



<p>The latest information gathered from the second DPIA of the Ministry suggests that there will be<a href="https://www.sharefoundation.info/wp-content/uploads/Mini1000.png"> </a>more than 8000 different <a href="https://www.sharefoundation.info/wp-content/uploads/Mini1000.png"><span>cameras and other devices</span></a> in use, such as body cams, mobile cameras and vehicle-mounted cameras. Although facial recognition, i.e. automated detection of people’s faces from a video feed, is not yet rolled out by the Ministry, this feature is expected to be implemented by the end of the project. While little is known about the project’s timeline, this can be expected to be in the next two years.</p>



<p>Apart from the data protection issues related to facial recognition, we also need to ask whether these technologies are necessary and proportionate, particularly from the perspective of the European human rights framework and its underlying values. Is facial recognition in public spaces the only available measure that can be used to prevent serious crime and protect citizens? Can this highly intrusive measure trump the privacy of all citizens, effectively turning whole cities into mass surveillance zones?</p>



<p>All in all, the Belgrade surveillance camera system is of <a href="https://hiljade.kamera.rs/en/law-society/">dubious legality</a>, to say the least, because:&nbsp;</p>



<ol><li>the actual purpose of introducing this system has not been clearly defined;&nbsp;</li><li>it has not been confirmed that the use of this system is necessary for the operations of state bodies;&nbsp;</li><li>its positive influence on the reduction of criminal offences has been overrated and its use is not proportionate to the risks related to the rights and freedom of citizens;&nbsp;</li><li>there is no law to begin with that defines that the police have the right to use smart surveillance in public places; and&nbsp;</li><li>the Data Protection Impact Assessment (DPIA) of the Ministry of Interior does not meet formal and material conditions defined by the law and was not approved by the Commissioner.&nbsp;</li></ol>



<p><br><strong>Point of no return for human rights</strong></p>



<p>Automated biometric video-surveillance may be the pinnacle of today’s<a href="https://www.publicbooks.org/the-folly-of-technological-solutionism-an-interview-with-evgeny-morozov/"> <span>techno-solutionism</span></a> – trying to solve deep and complex social problems with often non-critical use of technology. Sadly, decision makers are usually blind to issues of ethical and legal nature, and far-reaching consequences, if a society sets public safety as its ultimate value. It is all the more troubling if they believe it can be achieved with technology such as mass video-surveillance. Once governments get a hold of such powerful technology, it might be impossible to completely remove it from their arsenal, even after successful legal challenges. In that regard, we can draw a parallel to blanket communications metadata retention — a highly controversial measure in terms of proportionality which is<a href="https://edri.org/eu-member-states-willing-to-retain-illegal-data-retention/"> <span>still alive and kicking in the EU</span></a>, despite two CJEU judgements against it.<sup>1 </sup>Not to mention lucrative infrastructure deals required to install a massive video surveillance network, possibly in every larger city. This is particularly worrisome for countries such as Serbia, which are currently experiencing democratic backslides.</p>



<p>In addition to privacy, other associated human rights and freedoms, such as freedom of expression and the rights to protest and peaceful gathering, would<a href="https://edri.org/facial-recognition-and-fundamental-rights-101/"> <span>also be affected</span></a> in areas covered with automated video-surveillance. Imagine a scenario where a government keeps a biometric database of all citizens who attended anti-government protests; the ways in which this could affect their work, families, social relationships, and other aspects of everyday life are vast. Facial recognition also<a href="https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/"> <span>discriminates against minorities</span></a>, further entrenching bias against disadvantaged communities and making them more vulnerable.</p>



<p>With its high risks and numerous adverse effects, especially once reaching a “point-of-no-return”, automated biometric video surveillance does not uphold the values of respect for human rights, equality and social justice of the EU and the Council of Europe. Therefore, banning automated video surveillance is the right step forward, especially when we take into account other worrying trends, such as <a href="https://www.laquadrature.net/en/2020/02/04/technopolice-resisting-the-total-surveillance-of-our-cities-and-of-our-lives/"><span>the total …</span></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aboutintel.eu/mass-surveillance-serbia/">https://aboutintel.eu/mass-surveillance-serbia/</a></em></p>]]>
            </description>
            <link>https://aboutintel.eu/mass-surveillance-serbia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24718535</guid>
            <pubDate>Thu, 08 Oct 2020 12:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Engineer Guide: Feature Store vs. Data Warehouse]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24718301">thread link</a>) | @nathaliaariza
<br/>
October 8, 2020 | https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; The feature store is a data warehouse of features for machine learning (ML). Architecturally, it differs from the traditional data warehouse in that it is a dual-database, with one database (row-oriented) serving features at low latency to online applications and the other database (column-oriented) storing large volumes of features, used by Data Scientists to create train/test datasets and by batch applications doing offline model scoring.</p><h2>Features Store: Data Warehouse Déjà Vu</h2><p>Data warehouses democratized access to Enterprise data by centralizing data in a single platform and then empowering business analysts with visual tools, such as Tableau and Power BI. No longer did they need to know what data resides where and how to query that data in that platform. They could derive historical insights into the business using BI tools.&nbsp;<br></p><p>Data scientists, in contrast, build predictive models to derive business insights. The feature store is the data warehouse for Data Science - it is a central vault for storing documented, curated, and access-controlled features that can be used across many different models. The feature store ingests data from the Enterprise’s many different sources after transforming, aggregating, and validating the data.&nbsp;<br></p><p>Feature pipelines need to be written to ensure that data reliably flows from existing sources and is available in a format ready to be consumed by ML training pipelines and models.</p><p>Most Data Scientists currently do not have a feature store. They spend most of their time looking for, cleaning, and featurizing data. Hence, the (very real) cliché that 80% of data science is data wrangling. Data Scientists without a feature store work in an era akin to how business analysts worked before the advent of data warehouses, with low individual and organizational productivity.</p><h2>The Data Warehouse is an input <br>to the Feature Store&nbsp;</h2><p>Both platforms are a central store of curated data used to generate insights into the data. Both platforms have pipelines (ETL and feature pipelines, respectively) to ingest data from one or more disparate sources (operational databases, data lakes, etc).</p><p>Both benefit from metadata catalogs to organize data sets and access control to share data with only authorized actors.&nbsp;</p><p>Both platforms can be designed to scale-out on commodity hardware and store large volumes of data, although typically a data warehouse stores only relevant to analysis (modern <a href="#">data lakehouses</a> are designed to store large volumes of data more cost efficiently).<em>‍</em></p><figure id="w-node-d225d8bb42d9-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7eed8f6ff9277909bd9c6e_visual_blog5.jpg" loading="lazy" alt=""></p></figure><h2>Feature Store as a Dual Database</h2><p>The main architectural difference between a data warehouse and a feature store is that the data warehouse is typically a single columnar database, while the feature store is typically implemented as two databases:</p><ul role="list"><li>an <strong>offline feature store</strong> for serving large batches of features to (1) create train/test datasets and (2) batch applications scoring models using those batches of features, and</li><li>an <strong>online feature store</strong> for serving a single row of features (a <em>feature vector</em>) to be used as input features for an online model for an individual prediction.<br></li></ul><p><strong>The offline feature store</strong> is typically required to efficiently serve and store large amounts of feature data, <strong>while the online feature store</strong> is required to return feature vectors in very low latency (e.g., &lt; 10ms). Examples of databases used for the offline feature store are Apache Hive and BigQuery and examples of online feature stores include MySQL Cluster, Redis, and DynamoDB.&nbsp;</p><p>Note that if you want to reuse features in different train/test datasets for different models, your database or application will need to join features together. This is true for both the offline and online feature stores. If your feature store does not support joining features, that is, you do not reuse features across different models, you (or some system) will need to create a new ingestion pipeline for every new model you support in production.</p><figure id="w-node-fbcf667874fd-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7eee044a3a1d737610fc25_visual_blog4.jpg" loading="lazy" alt=""></p></figure><h2>Detailed Comparison</h2><p>In the table below, we see an overview of the main architectural differences between feature stores and data warehouses.<strong> Data warehouses</strong> are used primarily by business analysts for interactive querying and for generating historical reports/dashboards on the business.<strong> Feature stores</strong> are used by both data scientists and by the online/batch applications, and they are fed data by feature pipelines, typically written in Python or Scala/Java.&nbsp;</p><p>Data scientists typically use Python programs to create train/test datasets by joining existing features in the feature store together and materializing the train/test datasets in a <a href="#">file format best suited to the framework</a> they are going to train their model in (e.g., TFRecord for TensorFlow, NPY for PyTorch). Data warehouses and SQL currently lack this capability to create train/test datasets in ML file formats.</p><figure id="w-node-3cbc549719ba-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7ef334aaaf9d602868fc36_table_comparison_04.jpg" loading="lazy" alt=""></p></figure><h2>Feature Data should be Validated <br>before Ingestion</h2><p>The table also shows the differences in the types of data stored, as well as how the data is stored, validated, and queried. A data warehouse stores data in tables along with schemas for describing the type of data and constraints for columns. Similarly, the feature store stores typed data (typically in tables), but as features are typically stored as ready-to-consume numerical values or vectors (embeddings) or tensors, there is less need for a richer set of column types compared to a data warehouse.&nbsp; Foreign key constraints are typically not supported in feature stores, due to the difficulty in enforcing such constraints between online and offline stores.</p><p>As model training is very sensitive to bad data (null values, outliers cause numerical instability, missing values), feature data should be validated before ingestion. Data validation frameworks, such as <a href="#">Great Expectations</a> and <a href="#">Deequ</a>, have appeared to help implement feature pipelines that apply predicates (data validation rules) on all the features ingested into the feature store, ensuring high data quality in the feature store.&nbsp;</p><p>Domain specific languages (DSL) are sometimes used to define the feature transformations, aggregations, and data validation rules in feature pipelines, but general purpose languages (Python, Scala) are commonly used when non-trivial feature engineering is required.&nbsp;</p><h2>Using the feature store to create train/test data</h2><p>Data scientists are one of the main users of the feature store. They use a feature repository to perform exploratory data analysis (EDA) - searching/browsing for available features and inspecting feature values/schemas/statistics. Data Scientists mainly use Python to select features to create train/test datasets. This typically involves joining features together to create a&nbsp; train/test dataset in their file format of choice (.tfrecord, .csv, .npy, .petastorm, etc). Sometimes feature stores support a DSL (domain specific language) to create train/test datasets or other languages such as Scala/Java.&nbsp;</p><h2>Online feature store</h2><p>Online applications use the online feature store to retrieve feature values with low latency to build feature vectors that are sent to models for predictions. In contrast to higher latency data warehouses, feature stores may be required to return feature vectors in single millisecond latency - only really achievable in row-oriented or key-value stores.&nbsp;</p><p>The typical access pattern for retrieving features is a key-value lookup, but if features are to be reused in the online feature store, then joins are again required (either in the database or in the application). In some databases (such as <a href="#">MySQL Cluster</a>), a small number of joins can be performed at very low latency.<br></p><h2>Feature statistics to monitor for feature <br>drift and data drift</h2><p>Descriptive statistics (e.g., mean, standard deviation) for features are also useful when identifying data drift in online models. Your monitoring infrastructure can calculate statistics on live prediction traffic, and compare those statistics with the values in the feature store to <a href="#">identify data drift</a> for the live traffic, potentially required retraining of the model.</p><h2>Time-Travel&nbsp;</h2><p>Temporal databases support <em>time-travel</em>: the ability to query data as it was at a given point-in-time or data changes in a given time-interval. The “AS OF SYSTEM TIME” syntax was introduced to <a href="#">SQL 2011</a> to standardize point-in-time queries, while the “VERSIONS BETWEEN SYSTEM TIME ... AND ... “ syntax was introduced to identify the versioned changes to data in a time interval. Time-travel is supported in some data warehouses, but does not have universal support across all vendors.</p><p>For a feature store time-travel has several important uses: when creating train/test data (e.g., training data is data from the years 2010-2018, while test data is data from the range 2019-2020). Time-travel is also useful to make changes to a dataset (e.g., rollback a bad commit of data to the dataset) or to compare metadata (statistics) for features and how they change over time. We rarely require time-travel for features used in serving. Time-travel is also important when performing point-in-time joins, where we ensure that there is no data leakage from the future when we create train/test datasets from historical data.</p><h2>Feature Pipelines&nbsp;</h2><p>Data warehouses typically have timed triggers for running ETL jobs (or data pipelines) to ingest the latest data from operational databases, message queues, and data lakes. Similarly, feature pipelines can timed triggers to transform and aggregate the latest data from different sources before storing it in both the online and offline feature store for scoring by online and offline applications. However, additional pipelines can also feed features to the feature store.&nbsp;</p><p>Predictions made by models can be stored in the feature store along with the outcomes for those predictions. There can be long lags of even days or months or years before outcomes become available - e.g., a prediction on whether a loan will be repaid or not), but as they arrive new training data becomes available that can be used to trigger re-training of models.</p><figure id="w-node-74c5777df82a-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7ef3219e6baa58c301c833_table_comparison_03.jpg" loading="lazy" alt=""></p></figure><h2>Conclusion</h2><p>Data …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse">https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24718301</guid>
            <pubDate>Thu, 08 Oct 2020 12:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taiwan's Bike-Sharing Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24717228">thread link</a>) | @eric_khun
<br/>
October 8, 2020 | https://erickhun.com/posts/taiwan-youbike-bike-sharing/ | <a href="https://web.archive.org/web/*/https://erickhun.com/posts/taiwan-youbike-bike-sharing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><a href="https://taipei.youbike.com.tw/home">YouBike</a> (or Ubike) is my first choice of transportation when it comes to moving around the city of Taipei. I largely prefer it over taking the subway, bus, or taxi. It is affordable, well maintained, comfortable, at waking distance reach from anywhere, and the cities have built great biking paths in the major cities.</p>
<p>The number of YouBike rides keeps increasing steadily since it was launched in 2012. There were 170 million rides since it was introduced in 2012, and <a href="https://taipei.youbike.com.tw/news/content?5ee1e4b61b994541c0690826">last month it reached  ~3 million rides</a> in Taipei:</p>
<p><img src="https://erickhun.com/img/ubike/youbike-monthly-rental.jpg" alt="Youbike usage statistics"></p>
<h2 id="a-high-quality-infrastructure">A high-quality infrastructure</h2>
<p>YouBikes are <a href="https://taipei.youbike.com.tw/station/map">everywhere</a> in Taipei and New Taipei City. As for October 2020, over <a href="https://gist.github.com/erickhun/f0d3e8f3c3c4f70dc521c2abb43bb8a0">42000 YouBikes are deployed</a>, with over 1000 stations. Stations <a href="https://taipei.youbike.com.tw/news/list?5cb582c1060db454916c643c">get added every few weeks</a>.</p>
<p>Since the first time I arrive in Taipei (2016), I am pleasantly surprised that I rarely got a broken bike. <a href="https://en.wikipedia.org/wiki/Giant_Bicycles">Giant</a> is actually the (local) company that provides them. The bikes feel durable, lightweight, and really well maintained. Each bike is bought by the city for around <a href="https://disp.cc/b/163-6PkZ">9200 TWD (~USD 300)</a>, and comes with a 7 years maintenance.</p>
<p>To make it really convenient, the city has organized each station  <a href="https://english.gov.taipei/News_Content.aspx?n=A11F01CFC9F58C83&amp;s=5888478293ADD1A8">from 200 to 600 meters</a> from each other. What makes you within 5 to 10 minutes walk from wherever you are in the city.</p>
<p><img src="https://i.imgur.com/F5HWa3v.jpg" alt=""></p>
<h2 id="data-driven-decisions">Data-driven decisions</h2>
<p>I’ve noticed that the stations are also rarely empty. From time to time, I’ve spotted some employees “reloading” or “deloading” stations that are full or empty. Who are they? Where do they take those bikes? I’ve discussed with <a href="https://twitter.com/TaipeiUrbanism">Alex Garcia</a> and <a href="https://www.linkedin.com/in/timcho-giser">Tim Cho</a>, two urbanism specialists of the city of Taipei.</p>
<p>1 or 2 employees are responsible for a given area to “unload” or “refill” the stations. But how do they decide if some station should be “refilled” or not? Is a single empty station enough to make an employee move to the station? Not necessarily. Most of the time, an area of few stations being almost empty will make it worthwhile to move. This is a “<a href="https://en.wikipedia.org/wiki/Cluster_analysis">cluster analysis</a>”. Alex mentioned me they also have “re-balancing” trucks equipped with an application with a smart algorithm telling them where which full stations to unload, and which empty ones need a refill.</p>
<p>To make their work easier, historical data are used to predict the flow-in &amp; flow out for each station. They know the patterns on which stations will be empty and which one will need a refill. Those stations often have a “buffer” of bikes nearby locked together in bulk. When the station is about to get empty, the employee responsible for this area will drive there and refill the empty station with the buffer of bikes already present.</p>
<p>To make the decisions to add new stations, <a href="https://www.linkedin.com/in/timcho-giser">Tim</a> explained they use <a href="https://en.wikipedia.org/wiki/Geographic_information_system">GIS spatial analysis</a>,  to realize uncovered area (population density, schools, presence of metro station, POIs, etc…) to make the decision to add or not a new YouBike station.</p>
<h3 id="open-data">Open data</h3>
<p>Taipei City (and <a href="https://data.gov.tw/">Taiwan in general</a>) makes an amazing job at <a href="https://data.taipei/">opening their data</a>. It provides <a href="https://tcgbusfs.blob.core.windows.net/blobyoubike/YouBikeTP.json">real time data</a> showing each Youbike station status. Any developer can offer their own application to help users to find bikes availability or making the service more useful. This open data is how <a href="https://gist.github.com/erickhun/f0d3e8f3c3c4f70dc521c2abb43bb8a0">I’ve calculated the number</a> of YouBikes in Taipei.</p>
<p><a href="https://twitter.com/jakubsvehla/status/1311345837952434176">Jakub told me</a> he used this open data to help him stop being late at class. He depended on the YouBike to go to NTUST but ended up always late because his nearest station was empty. He started recording the patterns/waves of bikes coming and leaving the stations to know the time to go to the station.</p>
<p><a href="http://bdon.org/about/">Brandon</a> created this really <a href="http://bdon.org/youbike-forecast/">interesting visual map</a> showing detailed usage of each station with cool animations. If you live in Taiwan, click on your station, and you’ll see when bikes are more likely to be available!</p>
<p><img src="https://erickhun.com/img/ubike/youbike-realtime.gif" alt=""></p>
<p>Google recently took advantage of it and made a really nice implementation when users are looking for directions in Google Maps. The app will <a href="https://twitter.com/eric_khun/status/1291567323510317057">show you nearest departure/arrival Youbike station</a> and its availability:</p>
<p><img src="https://erickhun.com/img/ubike/GoogleMaps-Youbike.jpg" alt=""></p>
<h2 id="an-universal-and-simple-payment-system">An universal and simple payment system</h2>
<p>One of my favorite this about Taiwan is probably the EasyCard payment system. With a single card, you can use it in the metro, convenient store, supermarkets, and YouBike. Probably the best thing is that you can use that card everywhere in Taiwan.</p>
<p>Banks with their debit/credit cards and phones (via NFC?) have the Easycard payment system integrated. All those following card/debit cards integrate the EasyCard payment chip. Any convenient store will sell you one of those cards, without any requirements.</p>
<p><img src="https://erickhun.com/img/ubike/easy_cards-back-front.jpg" alt="Easy Card solution integrated into every card payment"></p>
<p>A single chip to rule them all.</p>
<h2 id="the-right-pricing">The right pricing</h2>
<p>The Youbike rental system is a pay as you go model. It <a href="https://taipei.youbike.com.tw/use/rates?5cc2971d083e7b55e32b8172">costs</a>  <strong>5 NTD (usd0,17) the first 30 minutes</strong>, then 10NTD (usd0.35) per 30 minute. The city also encourages the usage of YoubBke by taking 5NTD on the first 30 minutes on them. To compare the rate with other cities in the world:</p>
<ul>
<li>Lyon (France) (<a href="https://velov.grandlyon.com/en/offers/groups/list#190">1usd/ 45 minute</a> per rental)</li>
<li>Paris is 1EUR / 30 minute (~ usd1,20)</li>
<li>Germany has a <a href="https://www.callabike.de/en">3euros per 30 minutes</a> rate (~ usd3,50)</li>
</ul>
<h2 id="impressive-dedicated-bike-paths-infrastructure">Impressive dedicated bike paths infrastructure</h2>
<p>Taiwan is famously known for being a paradise for Bike lovers, from the urban city bikers the <a href="https://youtu.be/Sxfd2xzlM6k">most courageous professional bikers</a>. Did you know that Taiwan had more than 4500km of dedicated bike path? The longest one measuring <a href="https://edition.cnn.com/travel/article/taiwan-cycle-tour/index.html">968km long</a>. Taipei alone has 500+ km of dedicated biking path. The city has spent a lot of effort into building a large and safe bike path. It is really pleasant to move around the city:</p>
<p><img src="https://i.imgur.com/5sv48SJ.jpg" alt=""></p>
<p>The riverside bike-path is <a href="https://www.travel.taipei/en/must-visit/riverside-bikeway">more than 100 kilometers</a> long! And they <a href="https://english.gov.taipei/News_Content.aspx?n=A11F01CFC9F58C83&amp;sms=DFFA119D1FD5602C&amp;s=C8487022F5E63064">are planning to extends those biking paths</a> to expand bicycle trails in the city soon.</p>
<h2 id="an-unified-bike-sharing-system-in-all-cities">An unified bike-sharing system in all cities</h2>
<p>Another great thing is that all the biggest cities in Taiwan (Taichung, New Tapei City, Kaoshuing) have YouBike. No matter <a href="https://www.economicshelp.org/blog/265/economics/are-monopolies-always-bad/">great or bad</a>, it makes the discovery of a new city frictionless. You don’t have to subscribe to other services and worry about getting back a deposit.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Taipei has made a great job of implementing an amazing infrastructure bike-sharing infrastructure. With open data, the incentive to use bikes, maintaining a low price, and keeping bikes in great shape. The steady increases in the number of rides in Taipei talks by itself, while <a href="https://www.icmrindia.org/casestudies/catalogue/Operations/V%C3%A9lib_%202.0-Case.htm">other countries see their usage decreasing</a> over years. They’re today transitioning to a second generation of <a href="https://english.gov.taipei/News_Content.aspx?n=A11F01CFC9F58C83&amp;s=5888478293ADD1A8">Youbike 2.0</a>, better, lighter, and with docks taking less space.</p>
<!-- Taiwan also recently stopped the ["dockless bikes" company Ofo to operate](https://www.gvm.com.tw/article/66450) -->
<h4 id="next-reads">Next reads:</h4>
<p>🤖 <a href="https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html">How to build a chat bot with Google’s Sentence Encoder Model and Google Spreadsheet as a database</a></p>
<!-- 🇹🇼 Living in Taiwan? I've recently built [a chat bot](https://m.me/thetaiwanbot) giving you currated recommendations in Taiwan! Where to find the best value cheese? Where is the best pizza? etc...  [Here the details on how it works](https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html) -->
<!-- 🌏 Interested in living and working in Taiwan? Have you checked the [Gold Card program](https://taiwangoldcard.com/application-faq/)?  -->
<p>📚 <a href="https://erickhun.com/posts/why-you-should-have-a-side-project/">Why you should have a side project</a></p>
<p>🤸🏻‍♂️ <a href="https://erickhun.com/posts/traveling-and-working-out/">How to keep working out while travelling</a></p>




        <center>

            
            <a href="https://twitter.com/eric_khun" data-size="large" data-show-count="true">Follow @eric_khun</a>
            <br>
            <a href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;s=fb" target="_blank" rel="noopener" aria-label="Facebook">
              
            </a>
  
            
            <a href="https://twitter.com/intent/tweet/?text=Taiwan%27s%20amazing%20bike-sharing%20system%20by%20@eric_khun%20&amp;url=https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;s=tw" target="_blank" rel="noopener" aria-label="Twitter">
              
            </a>
  
            
            <a href="https://erickhun.com/cdn-cgi/l/email-protection#211e5254434b4442551c75404856404f04131652041311404c405b484f4604131143484a440c52494053484f4604131152585255444c0107404c511a434e45581c75404856404f04131652041311404c405b484f4604131143484a440c52494053484f4604131152585255444c010c014955555152041240041347041347445348424a49544f0f424e4c041347514e52555204134755404856404f0c584e5443484a440c43484a440c52494053484f4604134707521c444c40484d" target="_self" rel="noopener" aria-label="E-Mail">
              
            </a>
  
            
            <a href="https://reddit.com/submit/?url=https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;resubmit=true&amp;title=Taiwan%27s%20amazing%20bike-sharing%20system&amp;s=red" target="_blank" rel="noopener" aria-label="Reddit">
              
            </a>
  
            
            <a href="whatsapp://send?text=Taiwan%27s%20amazing%20bike-sharing%20system%20-%20https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;s=whatsapp" target="_blank" rel="noopener" aria-label="WhatsApp">
              
            </a>
    
          </center>
      </div></div>]]>
            </description>
            <link>https://erickhun.com/posts/taiwan-youbike-bike-sharing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24717228</guid>
            <pubDate>Thu, 08 Oct 2020 08:52:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Luca Concept Car: An Electric Vehicle Made from Plastic Waste]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24717157">thread link</a>) | @jacquesm
<br/>
October 8, 2020 | https://www.smalltechnews.com/archives/62931 | <a href="https://web.archive.org/web/*/https://www.smalltechnews.com/archives/62931">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.smalltechnews.com/archives/62931</link>
            <guid isPermaLink="false">hacker-news-small-sites-24717157</guid>
            <pubDate>Thu, 08 Oct 2020 08:37:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using a Piece of Paper as a Display Terminal – Ed vs. Vim]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24716218">thread link</a>) | @rhabarba
<br/>
October 7, 2020 | https://blog.robertelder.org/paper-display-terminal-ed-vim/ | <a href="https://web.archive.org/web/*/https://blog.robertelder.org/paper-display-terminal-ed-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>


<h5>2020-10-05 - By Robert Elder</h5>




<iframe src="https://www.youtube.com/embed/8vmOTvRXZ0E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This article will focus on discussing why the ancient text editor <a href="https://en.wikipedia.org/wiki/Ed_(text_editor)">'ed'</a> works the way it does.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Despite having its roots in the late 1960s, the 'ed' editor is still installed by default on most modern Linux distributions. &nbsp;Although there are few practical use cases for this editor today, it can still be meaningful to learn how 'ed' works since other Unix tools like vim, grep or sed have features that are significantly influenced from 'ed'.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you try running the 'ed' command with or without a file argument, you'll see something that looks like this:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_prompt-wait_811x349_q92.png" width="811" height="349"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you're waiting for something to happen then you'll be waiting a long time. &nbsp;That's because 'ed' is waiting for you to do something! &nbsp;The 'ed' program doesn't work like other command-line text editors such as vim or nano. &nbsp;The luxury of being able to print the contents of the current file to the terminal is something that 'ed' takes very seriously. &nbsp;That's why you need to explicitly give 'ed' a command to tell it to do so!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For example, if you want to print out an individual line in the file, you can just type the line number and press enter. &nbsp;If you want to append text, use the single-letter command 'a' on a line by itself to enter 'append' mode. &nbsp;Once you're done adding text, write a '.' character on a line by itself and press enter to stop adding text to the file. &nbsp;To review all the lines in the file, you can use the command '1,$p'. &nbsp;Finally, once you're done editing the file, you can use 'wq' to exit:</p>

<p><code><pre>1
Hello World.
a
Here is some more text.
.
1,$p
Hello World.
Here is some more text.
wq
</pre></code></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To make sense of why this editor is so hard to use, it make sense to think about the way in which people interacted with computers in the early days of computing. &nbsp;Around the time when 'ed' was created, it was still common for computers to print their output on <em>paper</em> instead of electronic screens! &nbsp;These early output devices were called <a href="https://en.wikipedia.org/wiki/Teleprinter">'teleprinters'</a>, often abbreviated as TTY. &nbsp;The term TTY is still used on most *nix systems to this day, and if you run this command, you can probably see some of the virtual TTY devices on your system:</p>

<p><code><pre><span>ls</span> /dev/tty*
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This ancient model of sending an infinite stream of characters (sent serially) to a 'terminal' or 'teleprinter' device that 'prints' or 'renders' them is still used today. &nbsp;It is even used by more modern terminal programs like vim or nano! &nbsp;You might not believe that vim works this way because it displays all kinds of information at the top and bottom of the terminal. &nbsp;Vim also lets you scroll up and down or open up screen splits etc. &nbsp;You can't possibly send the output of vim to a printer, right? &nbsp;Yes, you can and that's exactly what we're about to try.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The 'script' command lets you capture all output during a terminal session and save it to a file. &nbsp;This is a great way to log the output when you're running through a sequences of commands that you need to keep track of, but you can also use it to capture everything that gets output to the terminal during a vim session:</p>

<p><code><pre>script
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After running the 'script' command try opening a vim session. &nbsp;After doing a few things in vim, quit and then run the 'exit' command in the shell to exit the 'script' session to finish logging:</p>

<p><code><pre><span>exit</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;All of the output from the terminal session is now saved in a file called 'typescript'. &nbsp;Here's an image of what some of the output in the script looks like:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_vim-script-output_718x292_q92.png" width="718" height="292"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Many of these seemingly gibberish symbols are actually <a href="https://en.wikipedia.org/wiki/ANSI_escape_code">ANSI Escape codes</a>. &nbsp;These are the secret to how vim (and all other terminal applications) can use a serial output to print all sorts of interesting user interfaces. &nbsp;Most importantly, some of these escape sequences allow you to move the printing cursor around to arbitrary positions. &nbsp;That's how vim can keep some text pinned at the bottom or top of the terminal while also giving the illusion that you're scrolling 'up' or 'down' in the file. &nbsp;Some escape codes also control the foreground and background colours.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the old days, these escape codes were not actually processed by the CPU. &nbsp;The were instead interpreted by the 'terminal' monitor device itself. &nbsp;In other words, the oldest 'terminals' can be thought of as physically separate devices that received a serial stream of text, cursor movement instructions, and color changing instructions.  &nbsp;On a 'modern' computer, every 'terminal' window that you open is basically a software emulation of an ancient physical device that you can imagine to look like a small and bulky CRT monitor. &nbsp;Today, these escape codes are processed by the CPU of your laptop or desktop computer inside these software emulated 'terminals' in your graphical desktop environment.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;So, what's stopping us from trying to render the output of vim on a piece of paper to pretend that we're in the year 1969? &nbsp;Nothing! &nbsp;Here's is what the output of vim looks like when I try to render it using my laser printer:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_vim-page_1920x1080_q30.jpeg" width="1920" height="1080"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The reason that this output doesn't look very useful is because my printer isn't expecting to be used as a display terminal for vim. &nbsp;It doesn't know how to deal with all the ANSI escape sequences and we end up with this weird looking mess.  &nbsp;Do you see the '?2004h' part near the start of the output? &nbsp;You can look that up and see that it's an ANSI escape sequence to 'Turn on bracketed paste mode'. &nbsp;It is an exercise left to the reader to look up the rest of the ANSI escape sequences shown on the page above.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Interestingly, my printer seemed to choke when I printed this and got stuck saying 'data remaining' until I printed a blank test page.</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_printer-stuck_1920x894_q50.jpeg" width="1920" height="894"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I didn't bother investigating, but I assume one of the control sequences confused the printer and made it think it was still waiting on data from the computer.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And here is what using ed would look like if you were only able to render its output on a piece of paper:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_ed-page_1920x1080_q30.jpeg" width="1920" height="1080"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Since 'ed' doesn't print any ANSI escape sequences, my printer prints this with no problems!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Based on the two experiences described above, which editor do you think you'd prefer if you had to print all the output on paper?</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you decide to try and learn 'ed', you'll find that the man pages and the '-h' flag are not very helpful. &nbsp;Instead, you should check out the 'info' pages since that's where you'll find out all the details of different editor modes and single-letter commands are:</p>

<p><code><pre>info ed
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After you play around with 'ed' for a while, you'll realize that it acts almost like a command-line shell in itself. &nbsp;The only difference is that the environment in which you're working is a file instead of the user space of your operating system. &nbsp;Every little i/o operation on the file is implemented as a command that requires as little information as possible. &nbsp;This makes complete sense when you have to print everything to paper!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Imagine working on a file with modern Vim where your output always goes to a printer. &nbsp;You now decide to open a log file to check what's on the last line and immediately, your printer starts churning a full page of material. &nbsp;Oops, you opened the wrong file. &nbsp;Try another file, and again, oops! &nbsp;Wrong file again! &nbsp;That's a lot of wasted paper. &nbsp;What is it with these millennials and their fancy text editors that just print every line automatically! &nbsp;I remember the good old days when the users had control over their systems, and programs wouldn't just do whatever they want without asking!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In conclusion, the reason why the 'ed' command works the way it does was due to the higher resources constraints that existed at the time. &nbsp;Features like electronic display terminals and ANSI escape sequences were not in common enough use at the time when 'ed' was created, so there was no reason to consider using them. &nbsp;Instead, a shell-like command-line interface for editing files made way more sense.</p>




<table>
<tbody>
<tr>


	
		<td><a href="https://blog.robertelder.org/recording-660-fps-on-raspberry-pi-camera/"><img src="https://blog.robertelder.org/images/recording-660-fps-on-raspberry-pi-camera-thumb_250x150_q85.jpeg" alt="A Guide to Recording 660FPS Video On A $6 Raspberry Pi Camera" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/recording-660-fps-on-raspberry-pi-camera/"><strong>A Guide to Recording 660FPS Video On A $6 Raspberry Pi Camera</strong></a></p><p>Published 2019-08-01</p></div>
		</td>
	
	
	
	
	
	



	
	
	
	
		<td><a href="https://www.kickstarter.com/projects/2034896774/regular-expression-sticker-collection-and-video-guide?utm_source=blog&amp;utm_medium=link&amp;utm_campaign=k7&amp;utm_content=paper-display-terminal-ed-vim"><img src="https://blog.robertelder.org/images/k7_250x150_q85.png" alt="Regular Expression Laptop Stickers &amp; Video Guide" width="250" height="150"></a><div><p><a href="https://www.kickstarter.com/projects/2034896774/regular-expression-sticker-collection-and-video-guide?utm_source=blog&amp;utm_medium=link&amp;utm_campaign=k7&amp;utm_content=paper-display-terminal-ed-vim"><strong>Regular Expression Laptop Stickers &amp; Video Guide</strong></a></p></div>
		</td>
	
	
	



	
		<td><a href="https://blog.robertelder.org/don-libes-expect-unix-automation-tool/"><img src="https://blog.robertelder.org/images/automation-methods-thumb_250x150_q85.png" alt="Don Libes' Expect:  A Surprisingly Underappreciated Unix Automation Tool" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/don-libes-expect-unix-automation-tool/"><strong>Don Libes' Expect:  A Surprisingly Underappreciated Unix Automation Tool</strong></a></p><p>Published 2016-12-08</p></div>
		</td>
	
	
	
	
	
	



	
	
	
		<td><a href="https://twitter.com/RobertElderSoft">@RobertElderSoft On Twitter</a>
		</td>
	
	
	
	

</tr>
<tr>


	
		<td><a href="https://blog.robertelder.org/virtual-memory-with-256-bytes-of-ram/"><img src="https://blog.robertelder.org/images/256-bytes-virtual-memory-thumb_250x150_q85.png" alt="Virtual Memory With 256 Bytes of RAM - Interactive Demo" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/virtual-memory-with-256-bytes-of-ram/"><strong>Virtual Memory With 256 Bytes of RAM - Interactive Demo</strong></a></p><p>Published 2016-01-10</p></div>
		</td>
	
	
	
	
	
	



	
	
		<td><h2>Subscribe to Updates</h2><form method="post" action="https://api.robertelder.org/v1/message/">Email: </form><br><a href="https://www.robertelder.org/privacy-policy/">Privacy Policy</a>
		</td>
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/what-is-ssh/"><img src="https://blog.robertelder.org/images/what-is-ssh-thumb_250x150_q85.png" alt="What is SSH?  Linux Commands For Beginners" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/what-is-ssh/"><strong>What is SSH?  Linux Commands For Beginners</strong></a></p><p>Published 2017-04-30</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/installing-ubuntu-16-linux-ge62-6qd-apache-pro-msi-notebook/"><img src="https://blog.robertelder.org/images/msi-ge62-6qd-apache-pro_250x150_q85.jpeg" alt="Installing Ubuntu 16 Linux On A GE62 6QD Apache Pro MSI Notebook" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/installing-ubuntu-16-linux-ge62-6qd-apache-pro-msi-notebook/"><strong>Installing Ubuntu 16 Linux On A GE62 6QD Apache Pro MSI Notebook</strong></a></p><p>Published 2016-08-02</p></div>
		</td>
	
	
	
	
	
	

</tr>
<tr>


	
		<td><a href="https://blog.robertelder.org/data-science-linux-command-line/"><img src="https://blog.robertelder.org/images/data-science-linux-commands-thumb_250x150_q85.jpeg" alt="An Introduction To Data Science On The Linux Command Line" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/data-science-linux-command-line/"><strong>An Introduction To Data Science On The Linux Command Line</strong></a></p><p>Published 2019-10-16</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/robert-elder-software-linux-operating-system/"><img src="https://blog.robertelder.org/images/robert-elder-software-linux-operating-system-thumb_250x150_q85.png" alt="Introducing The Robert Elder Software Linux Operating System" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/robert-elder-software-linux-operating-system/"><strong>Introducing The Robert Elder Software Linux Operating System</strong></a></p><p>Published 2016-09-27</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/overlap-add-overlap-save/"><img src="https://blog.robertelder.org/images/overlap-add-overlap-save-thumb_250x150_q85.png" alt="Overlap Add, Overlap Save Visual Explanation" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/overlap-add-overlap-save/"><strong>Overlap Add, Overlap Save Visual Explanation</strong></a></p><p>Published 2018-02-10</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/fast-meme-transform/"><img src="https://blog.robertelder.org/images/fast-meme-transform-thumb_250x150_q85.jpeg" alt="The Fast Meme Transform: Convert Audio Into Linux Commands" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/fast-meme-transform/"><strong>The Fast Meme Transform: Convert Audio Into Linux Commands</strong></a></p><p>Published 2018-02-10</p></div>
		</td>
	
	
	
	
	
	

</tr>
</tbody>
</table>


				</div>
			</div></div>]]>
            </description>
            <link>https://blog.robertelder.org/paper-display-terminal-ed-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24716218</guid>
            <pubDate>Thu, 08 Oct 2020 05:45:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NYU DS-GA 1008 – Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24715307">thread link</a>) | @eugenhotaj
<br/>
October 7, 2020 | https://atcold.github.io/pytorch-Deep-Learning/ | <a href="https://web.archive.org/web/*/https://atcold.github.io/pytorch-Deep-Learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <!-- Provide site root to javascript -->
    

    <!-- Work around some values being stored in localStorage wrapped in quotes -->
    

    <!-- Set the theme before any content is loaded, prevents flash -->
    

    <!-- Hide / unhide sidebar before it is displayed -->
    

    <nav id="sidebar" aria-label="Table of contents" aria-hidden="false">
        
        
    </nav>

    <div id="page-wrapper">
        <div class="page">
            

            <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
            

            <div id="content">
                <main>
                    <div class="page">
                      
                      <p><strong>DS-GA 1008 · SPRING 2020 · <a href="http://cds.nyu.edu/">NYU CENTER FOR DATA SCIENCE</a></strong></p>



<h2 id="description">Description</h2>

<p>This course concerns the latest techniques in deep learning and representation learning, focusing on supervised and unsupervised deep learning, embedding methods, metric learning, convolutional and recurrent nets, with applications to computer vision, natural language understanding, and speech recognition. The prerequisites include: <a href="https://cds.nyu.edu/academics/ms-curriculum/">DS-GA 1001 Intro to Data Science</a> or a graduate-level machine learning course.</p>

<h2 id="lectures">Lectures</h2>

<p><strong>Legend</strong>: 🖥 slides, 📓 Jupyter notebook, 🎥 YouTube video.</p>

<table>
<!-- =============================== HEADER ================================ -->
  <thead>
    <tr>
      <th>Week</th>
      <th>Format</th>
      <th>Title</th>
      <th>Resources</th>
    </tr>
  </thead>
  <tbody>
<!-- =============================== WEEK 1 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01">①</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-1">History and motivation</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb">🖥️</a>
        <a href="https://www.youtube.com/watch?v=0bMe_vCZo30">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-2">Evolution and DL</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-3">Neural nets (NN)</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/01-tensor_tutorial.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/02-space_stretching.ipynb">📓</a>
        <a href="https://www.youtube.com/watch?v=5_qrxVq1kvc">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 2 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02">②</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02-1">SGD and backprop</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1w2jV_BT2hWzfOKBR02x_rB4-dfVUI6SR">🖥️</a>
        <a href="https://www.youtube.com/watch?v=d9vdh3b787Y">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02-2">Backprop in practice</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02-3">NN training</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">🖥</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/04-spiral_classification.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/05-regression.ipynb">📓</a>
        <a href="https://www.youtube.com/watch?v=WAn6lip5oWk">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 3 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03">③</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03-1">Parameter transformation</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=18UFaOGNKKKO5TYnSxr2b8dryI-PgZQmC">🖥️</a>
        <a href="https://youtu.be/FW5gFiJb-ig">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03-2">CNN</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03-3">Natural signals' properties</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/02%20-%20CNN.pdf">🖥</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/06-convnet.ipynb">📓</a>
        <a href="https://youtu.be/kwPWpVverkw">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 4 ================================ -->
    <tr>
      <td rowspan="1"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week04/04">④</a></td>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week04/04-1">1D convolutions</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/07-listening_to_kernels.ipynb">📓</a>
        <a href="https://youtu.be/OrBEon3VlQg">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 5 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05">⑤</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05-1">Optimisation I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1pwlGN6hDFfEYQqBqcMjWbe4yfBDTxsab">🖥️</a>
        <a href="https://youtu.be/--NZb480zlg">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05-2">Optimisation II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05-3">CNN, autograd</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/03-autograd_tutorial.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/extra/b-custom_grads.ipynb">📓</a>
        <a href="https://youtu.be/eEzCZnOFU1w">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 6 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06">⑥</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06-1">CNN applications</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1opT7lV0IRYJegtZjuHsKhlsM5L7GpGL1">🖥️</a>
        <a href="https://drive.google.com/open?id=1sdeVBC3nuh5Zkm2sqzdScEicRvLc_v-F">🖥️</a>
        <a href="https://youtu.be/ycbMGyCPzvE">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06-2">RNNs and attention</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06-3">Training RNNs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/08-seq_classification.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/09-echo_data.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/04%20-%20RNN.pdf">🖥️</a>
        <a href="https://youtu.be/8cAffg2jaT0">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 7 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07">⑦</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-1">Energy-Based Models</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1z8Dz1YtkOEJpU-gh5RIjORs3GGqkYJQa">🖥️</a>
        <a href="https://youtu.be/tVwV14YkbYs">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-2">SSL, EBM</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-3">Autoencoders</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/10-autoencoder.ipynb">📓</a>
        <a href="https://youtu.be/bggWQ14DD9M">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 8 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08">⑧</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08-1">Contrastive methods</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1Zo_PyBEO6aNt0GV74kj8MQL7kfHdIHYO">🖥️</a>
        <a href="https://youtu.be/ZaVP2SY23nc">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08-2">Regularised latent</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08-3">Training VAEs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/11-VAE.ipynb">📓</a>
        <a href="https://youtu.be/7Rb4s9wNOmc">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 9 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09">⑨</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09-1">Sparsity</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1wJRzhjSqlrSqEpX4Omagb_gdIkQ5f-6K">🖥️</a>
        <a href="https://youtu.be/Pgct8PKV7iw">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09-2">World model, GANs</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09-3">Training GANs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/pytorch/examples/tree/master/dcgan">📓</a>
        <a href="https://youtu.be/xYc11zyZ26M">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 10 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10">⑩</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10-1">CV SSL I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=16lsnDN2HIBTcRucbVKY5B_U16c0tNQhR">🖥️</a>
        <a href="https://youtu.be/0KeR6i1_56g">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10-2">CV SSL II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10-3">Predictive Control</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/09%20-%20Controller%20learning.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/14-truck_backer-upper.ipynb">📓</a>
        <a href="https://youtu.be/A3klBqEWR-I">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 11 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11">⑪</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11-1">Activations</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1AzFVLG7D4NK6ugh60f0cJQGYF5OL2sUB">🖥️</a>
        <a href="https://drive.google.com/file/d/1rkiZy0vjZqE2w7baVWvxwfAGae0Eh1Wm">🖥️</a>
        <a href="https://drive.google.com/file/d/1tryOlVAFmazLLZusD2-UfReFMkPk5hPk">🖥️</a>
        <a href="https://youtu.be/bj1fh3BvqSU">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11-2">Losses</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11-3">PPUU</a></td>
      <td>
        <a href="http://bit.ly/PPUU-slides">🖥️</a>
        <a href="http://bit.ly/PPUU-code">📓</a>
        <a href="https://youtu.be/VcrCr-KNBHc">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 12 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12">⑫</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-1">DL for NLP I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/149m3wRavTp4DQZ6RJTej8KP8gv4jnkPW/">🖥️</a>
        <a href="https://youtu.be/6D4EWKJgNn0">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-2">DL for NLP II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-3">Attention &amp; transformer</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/10%20-%20Attention%20%26%20transformer.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/15-transformer.ipynb">📓</a>
        <a href="https://youtu.be/f01J0Dri-6k">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 13 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13">⑬</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13-1">GCNs I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1oq-nZE2bEiQjqBlmk5_N_rFC8LQY0jQr/">🖥️</a>
        <a href="https://youtu.be/Iiv9R6BjxHM">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13-2">GCNs II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13-3">GCNs III</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/11%20-%20GCN.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/16-gated_GCN.ipynb">📓</a>
        <a href="https://youtu.be/2aKXWqkbpWg">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 14 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14">⑭</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-1">Structured Prediction</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1qBu-2hYWaGYEXeX7kAU8O4S2RZ1hMjsk/">🖥️</a>
        <a href="https://youtu.be/gYayCG6YyO8">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-2">Graphical methods</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-3">Regularisation and Bayesian</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/07%20-%20Regularisation.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/12-regularization.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/08%20-%20Bayesian%20NN.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/13-bayesian_nn.ipynb">📓</a>
        <a href="https://youtu.be/DL7iew823c0">🎥</a>
      </td>
    </tr>
  </tbody>
</table>

<h2 id="people">People</h2>

<table>
  <thead>
    <tr>
      <th>Role</th>
      <th>Photo</th>
      <th>Contact</th>
      <th>About</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Instructor</td>
      <td><img src="https://atcold.github.io/pytorch-Deep-Learning/images/Yann.png" width="100" height="100"></td>
      <td><a href="https://twitter.com/ylecun">Yann LeCun</a><br>yann@cs.nyu.edu</td>
      <td>Silver Professor in CS at NYU<br>and Turing Award winner</td>
    </tr>
    <tr>
      <td>Instructor</td>
      <td><img src="https://avatars1.githubusercontent.com/u/2119355" width="100" height="100"></td>
      <td><a href="https://twitter.com/alfcnz">Alfredo Canziani</a><br>canziani@nyu.edu</td>
      <td>Asst. Prof. in CS at NYU</td>
    </tr>
    <tr>
      <td>Assistant</td>
      <td><img src="https://pbs.twimg.com/profile_images/1186879808845860864/czRv3g1G_400x400.jpg" width="100" height="100"></td>
      <td><a href="https://twitter.com/marikgoldstein">Mark Goldstein</a><br>goldstein@nyu.edu</td>
      <td>PhD student in CS at NYU</td>
    </tr>
    <tr>
      <td>Webmaster</td>
      <td><img src="https://pbs.twimg.com/profile_images/673997980370927616/vMXf545j_400x400.jpg" width="100" height="100"></td>
      <td><a href="https://twitter.com/ebetica">Zeming Lin</a><br>zl2799@nyu.edu</td>
      <td>PhD student in CS at NYU</td>
    </tr>
  </tbody>
</table>

<!--
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Serkan Karakulak <br>sk7685@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Raghav Jajodia <br>rj1408@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Priyank Pathak <br>pp1953@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Chiao-Hsun Wang <br>chw371@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Pedro Vidal<br>pmh314@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Bixing Yan <br>by783@nyu.edu|
-->

<h2 id="disclaimer">Disclaimer</h2>

<p>All other texts found on this site are lecture notes taken by students of the New York University during lectures given by Yann Le Cun, Alfredo Canziani, Ishan Misra, Mike Lewis and Xavier Bresson.
Thus the texts in English were written by about 130 people, which has an impact on the homogeneity of the texts (some write in the past tense, others in the present tense; the abbreviations used are not always the same; some write short sentences, while others write sentences of up to 5 or 6 lines, etc.).
It is possible that there may be some omissions: typing errors, spelling mistakes, etc. If you notice any, we invite you to submit a PR on the <a href="https://github.com/Atcold/pytorch-Deep-Learning/pulls">GitHub directory of the site</a> specifying with an <code>[EN]</code> that it concerns the English translation.</p>

<p>Wishing you a deep reading !</p>

                    </div>
                </main>

                <nav aria-label="Page navigation">
                    <!-- Mobile navigation buttons -->
                    <a rel="prev" href="https://atcold.github.io/pytorch-Deep-Learning" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i></i>
                    </a>

                    <a rel="next" href="https://atcold.github.io/pytorch-Deep-Learning/en/about/" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>

                    
                </nav>
            </div>
        </div>

        <nav aria-label="Page navigation">
                <a href="https://atcold.github.io/pytorch-Deep-Learning" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                    <i></i>
                </a>

                <a href="https://atcold.github.io/pytorch-Deep-Learning/en/about/" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                    <i></i>
                </a>
        </nav>

    </div>

    
    
    

    

    

</div>]]>
            </description>
            <link>https://atcold.github.io/pytorch-Deep-Learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715307</guid>
            <pubDate>Thu, 08 Oct 2020 03:13:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New York City thinks up to half of restaurants will close permanently [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24715150">thread link</a>) | @bookofjoe
<br/>
October 7, 2020 | https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf | <a href="https://web.archive.org/web/*/https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715150</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24715148">thread link</a>) | @zoozla
<br/>
October 7, 2020 | https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715148</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recycling was a lie to sell more plastic, recycling industry veteran says]]>
            </title>
            <description>
<![CDATA[
Score 969 | Comments 407 (<a href="https://news.ycombinator.com/item?id=24714880">thread link</a>) | @vivekd
<br/>
October 7, 2020 | https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Less than 10 per cent of the plastics we’ve used have been recycled. A new documentary reveals why</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5755241.1602170985!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/157672506.jpg"></p></div><figcaption>trash on the beach<!-- --> <!-- -->(Getty Images)</figcaption></figure><p><span><p>Although our landfills and oceans are full of it, we are as dependent as ever on plastic. And since COVID-19, it's gotten worse.&nbsp;</p>  <p>Last year, Canada announced it was working on a ban of single-use plastics, which was initally&nbsp;<a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">sidelined by the pandemic</a>. Recently, the government announced that <a href="https://www.cbc.ca/news/politics/single-use-plastics-1.5753327">many single-use plastics will be banned</a> by the end of 2021. At the same time, <a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">CBC News reports</a> our single-use plastic use increased by 250 to 300 per cent as people tossed their personal protective equipment and stopped using reusable bags and containers over fears they would spread the virus.</p>  <p>What makes our lives convenient is also burying us. <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><strong><em>Plastic Wars</em></strong></a>, presented by <em>The Passionate Eye</em>, looks at the mounting crisis and how the industry has spent millions promoting recycling — just to sell more plastic.</p>  <h2>Less than 10% of the plastics we've used have been recycled</h2>  <p>Although activists sounded the alarm about plastic waste in the 1970s, the documentary claims from 1990 to 2010, plastic production more than doubled. We've been sorting our trash for decades, believing it would be recycled. But the truth is the vast majority of the plastic we use won't be. Over the last seven decades, <a href="https://www.oecd.org/environment/waste/policy-highlights-improving-plastics-management.pdf">less than 10 per cent of plastic waste has been recycled</a>.&nbsp;</p>  <p>That's because, says David Allaway, from the Oregon Department of Environmental Quality, the conversation has been almost exclusively about recycling and not reducing and reusing.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Recycling"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1002/935/PlasticWars_Recycling_2500kbps_620x350_1755680835594.jpg" alt=""></p></div></div></div><span>Even as the plastic crisis worsens, the demand for plastic grows and plastic production is rapidly expanding. One issue? Only focusing on recycling, and not reducing the amount of plastic that we use.<!-- --> <!-- -->1:06</span></span></span></p>  <h2>Recycling logo was used as a green marketing tool, says industry expert</h2>  <p>In the '80s, the industry was at the centre of an environmental backlash. Fearing an outright ban on plastics, manufacturers looked for ways to get ahead of the problem. They looked at recycling as a way to improve the image of their product and started labeling plastics with the now ubiquitous chasing-arrows symbol with a number inside.&nbsp;</p>  <p>According to Ronald Liesemer, an industry veteran who was tasked with overseeing the new initiative, "Making recycling work was a way to keep their products in the marketplace."&nbsp;</p>  <p>Most consumers might have assumed the symbol meant the product was recyclable. But according to experts in the film, there was no economically viable way to recycle most plastics, and they have ultimately ended up in a landfill. This included plastic films, bags and the wrapping around packaged goods, as well as containers like margarine tubs.<br> "Our own customers … they would flat out say, 'It says it's recyclable right on it,'" says Coy Smith, former board member of the National Recycling Coalition. "And I'd be like, 'I can tell you, I can't give this away. There's no one that would even take it if I paid them to take it.'" He believes manufacturers used the symbol as a green marketing tool.</p>  <p>"If the public thinks that recycling is working, then they're not going to be as concerned about the environment," says Larry Thomas, another top industry official interviewed in <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>.</p>  <p>According to Lewis Freeman, a former vice-president with the Society of the Plastics Industry, many in the industry had doubts about recycling from the start. "There was never an enthusiastic belief that recycling was ultimately going to work in a significant way," he says.</p>  <p>Yet the plastic industry spent millions on ads selling plastics and recycling to consumers.</p>  <h2>Lots of our plastic was shipped to China, then Southeast Asia, for 'recycling'</h2>  <p>To solve the plastic waste problem, many recyclers started selling their product to China in the 1990s. According to recycling broker Sunil Bagaria, China took waste that North American recyclers couldn't use. "As long as it remotely resembled plastic, they wanted it," he says.</p>  <p>But they used the good stuff and disposed of the rest. And because of a growing plastic waste problem in that country, China finally stopped taking most imported plastic waste in 2018.</p>  <p>"We never asked the question, 'Are they doing it the right way? Are we damaging the environment more in the name of recycling?'" says Bagaria.</p>  <p>Now, Southeast Asian countries like Indonesia have picked up the plastic waste market. And although some North American plastics recyclers are following up to ensure their products are in fact being recycled, plastic waste is now a growing problem there, too.&nbsp;</p>  <p>In <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>, local activist Yuyan Ismawati visits a rural community where locals scour through a huge field of plastic waste for items of value and burn the rest. This creates health problems for the residents in addition to destroying the surrounding environment. "We are struggling to clean up the modern debris and modern litter in Indonesia, the additional burden of waste from overseas — I don't know how we are going to handle it," says Ismawati. "Americans need to know that your waste ended up here."</p>  <h2>Production of plastics expected to triple by 2050</h2>  <p>In 2020, roughly 60 years after concerns about plastic waste were first raised, the focus is still on the consumer to recycle, says Allaway, and not on the environmental impact of the product and overproduction by the industry.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Full Impact"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1004/887/PlasticWars_FullImpact_2500kbps_620x350_1755684419745.jpg" alt=""></p></div></div></div><span>Consumers are constantly told that they should do their part to reduce plastic waste, but in reality, consumers have the lowest amount of leverage in reducing waste - it's plastic producers that should be reporting their full environmental impacts.<!-- --> <!-- -->1:56</span></span></span></p>  <p>According to <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> the problem is only going to get worse. By 2050, it's estimated the global production of plastic will triple. As the oil and gas industry — which provides the source materials for plastics — &nbsp;faces a future of declining demand for fuel, it has turned to other markets.&nbsp;</p>  <p>The stakes are high, says Annie Leonard, executive director of Greenpeace USA. "This is their lifeline," she says. "They are going to double down on single-use plastic like we have never seen. So we're heading towards a real battle.... This is the big war."&nbsp;</p>  <p>Watch <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> on <em>The Passionate Eye</em>.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618</link>
            <guid isPermaLink="false">hacker-news-small-sites-24714880</guid>
            <pubDate>Thu, 08 Oct 2020 02:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the Japanese Sentence]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24714136">thread link</a>) | @sova
<br/>
October 7, 2020 | https://japanesecomplete.com/reverse-engineer/ | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/reverse-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://japanesecomplete.com/reverse-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24714136</guid>
            <pubDate>Wed, 07 Oct 2020 23:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A B.C. research project gave homeless people $7500 each. Results were surprising]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24713991">thread link</a>) | @cpncrunch
<br/>
October 7, 2020 | https://www.cbc.ca/news/canada/british-columbia/new-leaf-project-results-1.5752714 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/new-leaf-project-results-1.5752714">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The results of a B.C. research project that gave thousands of dollars&nbsp;to homeless people&nbsp;are in and, according to one researcher, could challenge stereotypes about people "living on the margins."</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5756225.1602196801!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/strathcona-park.jpg"></p></div><figcaption>A Vancouver-based research project gave homeless individuals cash and tracked their progress for a year. The 50 cash transfer recipients not only found stable housing, they freed up space in shelters and, according to project data, saved the shelter system $8,100 per person over those 12 months.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure><p><span><p>The results of a B.C. research project that gave thousands of dollars&nbsp;to homeless people&nbsp;are in and, according to one researcher, could challenge stereotypes about people "living on the margins."</p>  <p><a href="https://forsocialchange.org/impact">The&nbsp;New Leaf&nbsp;project </a>is&nbsp;a joint study started in 2018 by&nbsp;Foundations for Social Change, a Vancouver-based charitable organization, and the University of British Columbia. After giving homeless Lower Mainland residents cash payments of $7,500, researchers checked on them&nbsp;over a year to see how they were faring.</p>  <p>All 115 participants, ranging in age between 19 and 64,&nbsp;had been homeless&nbsp;for at least six months and were not struggling&nbsp;with serious substance use or mental health issues.&nbsp;Of those,&nbsp;50 people were chosen at random to be given the cash, while the others formed a control group that did not receive any money.</p>  <p>"I had no expectations and really high hopes," said Claire Williams, CEO of&nbsp;Foundations for Social Change, on CBC's&nbsp;<em>The Early Edition</em>&nbsp;on Tuesday.</p>  <p>What researchers found after 12 months, she said, was&nbsp;"beautifully surprising."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5756210.1602196627!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/strathcona-park.jpg 300w,https://i.cbc.ca/1.5756210.1602196627!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/strathcona-park.jpg 460w,https://i.cbc.ca/1.5756210.1602196627!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/strathcona-park.jpg 620w,https://i.cbc.ca/1.5756210.1602196627!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/strathcona-park.jpg 780w,https://i.cbc.ca/1.5756210.1602196627!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/strathcona-park.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5756210.1602196627!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/strathcona-park.jpg"></p></div><figcaption>Strathcona Park is the site of Vancouver's latest tent city, where hundreds of people without homes erected tents this summer.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure></span></p>  <h2>Budget breakdown</h2>  <p>Not only did those who received the money spend fewer days homeless than those in the control group, they had also moved into stable housing after an average of three months, compared to those in the control group, who took an average of five months.</p>  <p>Those who received the money also managed it well over the course of a year.</p>  <p>"We saw people retain&nbsp;over $1,000 for 12 months, which is remarkable in the Lower Mainland," said Williams.</p>  <p>On average, cash recipients spent 52 per cent&nbsp;of their money&nbsp;on food and rent, 15 per cent&nbsp;on other items such as medications and bills, and 16 per cent on clothes and transportation.&nbsp;</p>    <p>Almost 70 per cent of people who received the payments were food secure after one month. In comparison, spending on alcohol, cigarettes and drugs went down, on average, by 39 per cent.</p>  <p>Too often people dismiss the idea of giving homeless people money because they assume it will be mismanaged, Williams said.</p>  <p>"It challenges stereotypes we have here in the West about how to help people living on the margins," she said.&nbsp;</p>  <h2>New beginnings</h2>  <p>Ray, whose last name project researchers did not release&nbsp;for privacy reasons, was living in an emergency shelter before receiving money from the New Leaf project.</p>  <p>He said the money helped him get housing and take a computer class he needed to work toward&nbsp;his goal of becoming a frontline worker for people with substance addictions.</p>  <p><em><strong>WATCH | Ray, a study participant, says what the money meant for him:</strong></em></p>  <p><span><span><iframe src="https://www.youtube.com/embed/icWhu5icsJ0" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>"I kind of want to give back where I've came from," said Ray. "I might one day be that important person that has a powerful voice... a&nbsp;seed can grow into an oak tree."</p>  <p>According to Williams, providing people like Ray the cash they need to get ahead&nbsp;also helps Canadian taxpayers.</p>  <p>She said it costs, on average, $55,000&nbsp;annually for social and health services for one homeless individual.&nbsp;According to study data, the project saved the shelter system approximately $8,100 per person for a total of roughly $405,000 over one year for all 50.</p>    <p>"The common belief is that the status quo is cheap... in fact, it is incredibly&nbsp;expensive," said Williams.</p>  <p>According to the 2018 B.C. Homeless Count, there are about 7,600 homeless people living in the province — meaning a group of 115 study participants is relatively small.</p>  <p><strong>To hear the complete interview with&nbsp;Claire Williams, CEO of&nbsp;Foundations for Social Change, on <em>The Early Edition, </em><a href="https://www.cbc.ca/listen/live-radio/1-91-the-early-edition/clip/15801752-cash-homeless-key-getting-people-living-streets">tap here.</a></strong></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/new-leaf-project-results-1.5752714</link>
            <guid isPermaLink="false">hacker-news-small-sites-24713991</guid>
            <pubDate>Wed, 07 Oct 2020 23:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Politics Is a Game of Addiction]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24713928">thread link</a>) | @midef
<br/>
October 7, 2020 | https://www.superhighway98.com/politics | <a href="https://web.archive.org/web/*/https://www.superhighway98.com/politics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-01c5c32dc615be335f8d"><div><p>I used to be a card-carrying member of a political party. When I voted along party lines, it was like having 50 million Americans who <em>always</em> agreed with me about who was good or bad, who was qualified or not, and what the <em>only</em> solution to a problem was.</p><p>I was fooling myself. There is no single person in the world with whom I agree about everything, let alone a group of people. But there I was, always nodding in agreement. I was fooling myself, and in hindsight, the way I acted made me look like a fool:</p><ul data-rte-list="default"><li><p>I divided America into "us" vs. "them";</p></li><li><p>I participated in political arguments that ruined family occasions;</p></li><li><p>I thought of compromise as a loss and collaboration as a betrayal;</p></li><li><p>I supported free speech only when I agreed with what was being said;</p></li><li><p>I treated brilliant people like idiots based solely upon their political views;</p></li><li><p>I refused to watch, read or listen to media that challenged my viewpoints;</p></li><li><p>I believed every lie told to me as long as it supported things that I wanted to believe;</p></li><li><p>I searched for proof that I was right, but never searched for evidence that I was wrong;</p></li><li><p>I spread misinformation unwittingly or uncaringly because I was so eager to hurt political rivals;</p></li><li><p>I confused integrity with party loyalty, and as a result, distrusted the people most deserving of trust;</p></li><li><p>I assumed that everyone I met had the same beliefs as me (and I was shocked to learn otherwise);</p></li><li><p>I called people anti-American, even when these same men and women risked life and limb in support of our country;</p></li><li><p>I changed my mind in lockstep with my party, wavering between support or opposition, depending on who was in power;</p></li><li><p>I blamed one group for my problems and waited for another group to solve them, allowing myself to lapse into sickness and poverty; and</p></li><li><p>I dismissed any corruption allegations against my party as lies, and when those allegations were proven beyond a shadow of a doubt to be true, then I dismissed them as unimportant or irrelevant.</p></li></ul><p>In short, I sacrificed my intelligence, my integrity and my identity because it made me feel like a part of something and it spared me the pain of ever having to admit a mistake. Addiction is the absolution of personal responsibility; I was addicted to politics.</p><p>Then, one day, it just happened. I'm not sure how or why, but I saw things differently. Today, I am not a political party. I am a person with his own experiences, ideas and moral code and there is no one exactly like me. I am <em>sober</em> from politics.</p><p><a href="https://www.superhighway98.com/">&lt;- RETURN TO SUPERHIGHWAY 98</a></p><p><a href="https://www.superhighway98.com/addiction">HOW ADDICTION RUINED THE INTERNET -&gt;</a></p></div></div></div></div>]]>
            </description>
            <link>https://www.superhighway98.com/politics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24713928</guid>
            <pubDate>Wed, 07 Oct 2020 23:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Pros and Cons of Software Crowdtesting]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24712313">thread link</a>) | @CrankyBear
<br/>
October 7, 2020 | https://www.functionize.com/blog/the-pros-and-cons-of-software-crowdtesting/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/the-pros-and-cons-of-software-crowdtesting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/crowdtesting-duck.jpg" alt="The Pros and Cons of Software Crowdtesting" srcset="https://www.functionize.com/wp-content/uploads/2020/10/crowdtesting-duck.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/10/crowdtesting-duck-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/10/crowdtesting-duck-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/10/crowdtesting-duck-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <p><strong>Crowdsourcing has drawn a lot of attention as a way of predicting and mapping future coronavirus hotspots based on user-reported symptoms. However, it’s also an increasingly popular approach to software application testing, engineering, and quality assurance.</strong></p>
<p>Software crowdsourcing is making inroads in the software industry, as it gives companies quicker and less costly ways of developing and testing apps that meet users’ real needs. Meanwhile, individual crowdsourced testers, also known as crowdtesters, are earning money through remote work, ranging from a few dollars for each detected bug to weekly salaries of $2,000 and up.</p>
<p>Is software crowdtesting a panacea, though? The answer is “No.”</p>
<p>In crowdsourcing, people can contribute to a collaborative platform over the Internet from wherever they are. It’s well known outside the software development field. As one example, there’s the Wikipedia online collaborative encyclopedia. A couple of others are <a href="https://www.quora.com/" target="_blank" rel="noopener noreferrer">Quora</a> and <a href="https://stackexchange.com/" target="_blank" rel="noopener noreferrer">Stack Exchange</a>, web-based platforms where people ask and answer each other’s questions. Crowdsourcing has also made headlines lately as a way of <a href="https://www.wired.com/story/covid-near-you-crowdsources-data-to-predict-new-hotspots/" target="_blank" rel="noopener noreferrer">predicting and mapping future COVID-19 hotspots</a> based on user-reported symptoms.</p>
<p>In software development, crowdsourcing is used in design, requirements analysis, and coding. But as a business endeavor, crowdsourcing is getting especially prevalent in testing and quality assurance tasks. Businesses, as requesters, delegate tasks to outside individuals or groups, as providers, with the support of crowdsourcing platforms. The business pays a fee to the crowdsourcing platform, which then performs various degrees of candidate vetting and task management. The crowdsourcing company also handles payments to testers.</p>
<p>The global crowdsourcing testing market is set to soar from $1.3 billion in 2019 to $2.0 billion in 2024, says a <a href="https://www.marketsandmarkets.com/PressReleases/crowdsourced-testing.asp" target="_blank" rel="noopener noreferrer">recent report from Markets &amp; Markets</a>. The analysts anticipate growth to be particularly strong in two areas: <a href="https://www.functionize.com/blog/the-mobile-testing-gotchas-you-need-to-know-about/">mobile testing</a>, for making sure apps run smoothly on various phones and tablets; and location testing, for seeing to it that language and cultural nuances are well suited to local end users in various countries.</p>
<h3>What’s the appeal?</h3>
<p>Without hiring extra inhouse staff, a company can easily gain extra tech talent for projects at a relatively low cost. This is true whether an organization needs an army of usability testers in 50 nations or <a href="https://www.functionize.com/blog/what-testers-should-know-about-domain-knowledge/">an expert individual in a specialized tech area</a>, such as iOS app design.</p>
<p>Software crowdsourcing does have its downsides, though. “We use software crowdsourcing in our deployments, but while valuable, we use it sparingly, only for initial testing of new deployments where we don’t have the experience to run the basic tests,” notes David Johnson, CTO at <a href="http://mulyticlabs.io/" target="_blank" rel="noopener noreferrer">Mulytic Labs</a>. “We do not base our whole testing strategy around crowdsourcing as it presents too much risk and not enough consistency.”</p>
<p>Before drilling down into the pros and cons of software crowdtesting, here’s a quick look at the evolution of software crowdsourcing.</p>
<h3>Evolution of crowdsourcing</h3>
<p>In a <a href="https://www.wired.com/2006/06/crowds/" target="_blank" rel="noopener noreferrer">2006 Wired article</a>, Jeff Howe defined crowdsourcing as representing “the act of a company or institution taking a function once performed by employees and outsourcing it to an undefined (and generally large) network of people in the form of an open call.”</p>
<p>Yet the concept predated the term. Linus Torvalds, originator of the Linux operating system, is widely credited as an early practitioner of crowdsourcing. When he was a 21-year-old student at the University of Helsinki in Finland way back in 1991, Torvalds put up a quick message on Usenet’s comp.os.minix newsgroup: “<a href="https://www.cs.cmu.edu/~awb/linux.history.html" target="_blank" rel="noopener noreferrer">I’m doing a (free) operating system</a> (just a hobby, won’t be big and professional like gnu) for 386(486) AT clones. This has been brewing since April, and is starting to get ready. I’d like any feedback on things people like/dislike in Minix,” Torvalds wrote. He ultimately lured so many developers that Linux 1.0 was accomplished in just three years.</p>
<p>IDC estimates that today, 24.2 million developers worldwide are <a href="https://www.functionize.com/blog/wheres-the-yelp-for-open-source-tools/">contributing to open source projects</a>, including Linux, LibreOffice, the GIMP photo editing tool, the GNU compiler collection, and many more. Open source developers often are motivated by factors such as the ability to learn new skills, gain recognition, and support a worthy cause. While the contributors aren’t paid directly, many benefit financially, such as contributing while working as paid employees for commercial software organizations.</p>
<h3>The microtasking crowdsourcing model</h3>
<p>However, the paying side of crowdsourcing is a totally different animal from open source. It has itself become, well, crowded with competing platforms.</p>
<p>Many online labor markets use a model known as microtasking. Microtasks are intended to be done in a matter of minutes. Collectively, though, the microtasks add up to a solution for a more complex task.</p>
<p>Some microtasking platforms, such as <a href="https://test.io/become-a-tester/" target="_blank" rel="noopener noreferrer">Test IO</a>, are designed for detecting software defects and pay crowdtesters on a “per bug” basis. Test IO’s testers can generally expect to receive anywhere from $5 for a “low severity bug” to <a href="https://www.wayup.com/i-Computer-Software-j-Crowdtester-Website-and-application-testing-testCloud-758785/" target="_blank" rel="noopener noreferrer">$50 for a “critical bug.”</a></p>
<p>Other sites, such as <a href="https://www.usertesting.com/get-paid-to-test" target="_blank" rel="noopener noreferrer">UserTesting.com</a> and <a href="https://www.trymyui.com/worker/signup" target="_blank" rel="noopener noreferrer">TryMyUI</a>, focus on testing usability, or on applications’ “user-friendliness.” UserTesting.com pledges to return usability tests within an hour. TryMyUI requires no previous experience in software testing and pays $10 per 20-minute online review.</p>
<p>You’ll also find individual sites that <a href="https://www.infoq.com/articles/collaborative-software-development-platforms/#:~:text=Current%20crowdsourcing%20platforms%2C%20such%20as,example%2C%20see%20the%20sidebar" target="_blank" rel="noopener noreferrer">supply a wide range of crowdtesting services</a> and are looking for testers. A recent glance at the project board on <a href="https://www.utest.com/projects?tab=suggested" target="_blank" rel="noopener noreferrer">uTest</a>’s site showed gigs involving bug testing, usability testing, mobile testing, PC game testing, and localization testing. uTest pays on a <a href="https://www.quora.com/How-much-do-you-earn-on-uTest-freelancing" target="_blank" rel="noopener noreferrer">“per performance” basis</a>, depending on the gig type. Some project needs are quite specific, such as Android testers with accessibility switch devices, or people with native Australian, New Zealand, or UK accents.</p>
<p>At the top end of the pay spectrum, testers specializing in cybersecurity have reportedly earned anywhere from $500 to tens of thousands of dollars per security bug detected, either directly from tech companies like Google, Facebook, or Mozilla or through cybersecurity crowdsourcing platforms like <a href="https://www.bugcrowd.com/" target="_blank" rel="noopener noreferrer">Bugcrowd</a> and <a href="https://www.synack.com/lp/synacks-crowdsourced-penetration-testing-platform-explained/" target="_blank" rel="noopener noreferrer">Synack</a>.</p>
<p><a href="https://www.softwaretestingmaterial.com/crowdsourced-testing-guide/" target="_blank" rel="noopener noreferrer">Crowdtesting can also come into play</a> in areas that include <a href="https://www.functionize.com/blog/discerning-the-difference-functional-testing-vs-non-functional-testing/">functional testing</a>, for making sure that applications comply with company-specified requirements; compatibility testing, for <a href="https://www.functionize.com/blog/how-to-deal-with-the-challenges-of-cross-browser-testing/">testing software across various browsers</a> and operating systems; <a href="https://www.functionize.com/blog/regression-testing-what-you-need-to-know/">regression testing</a>, to find out whether a software change broke existing functionality; and connectivity testing, to check out issues related to network connectivity.</p>
<h3>The contest model</h3>
<p>In another model, companies including <a href="https://www.topcoder.com/" target="_blank" rel="noopener noreferrer">Topcoder,</a> <a href="https://leetcode.com/" target="_blank" rel="noopener noreferrer">LeetCode,</a> <a href="http://codeforces.com/" target="_blank" rel="noopener noreferrer">Codeforces,</a> and <a href="https://www.codechef.com/" target="_blank" rel="noopener noreferrer">CodeChef</a> gamify crowdtesting by treating workers as contestants. Typically, after a client proposes a project, a coordinator – called a “copilot” at Topcoder – <a href="https://www.computer.org/csdl/magazine/so/2016/01/mso2016010074/13rRUzpzez2" target="_blank" rel="noopener noreferrer">decomposes the project into tasks</a> or “competitions.” The contests might revolve around requirements, architecture, UI design, implementation, or testing, for example, with each task lasting a matter of days.</p>
<p>Contestants offer competing solutions. From this pool, a winner and runner-up are chosen. Workers who complete the task and has their solution chosen is paid either a bounty award or an hourly wage.</p>
<p>Topcoder, a pioneer of the contest model, has reportedly awarded more than $25,000 per day to contestants. What’s more, after proving themselves in various skill sets in competitions, participants become eligible for Topcoder’s Gig Work engagements. <a href="https://www.topcoder.com/gigs" target="_blank" rel="noopener noreferrer">Gig Work assignments</a> cover the whole gamut of software disciplines; a recent search turned up job titles such as QA lead, testing lead, and cloud testing lead. Typically paying $1,000 to $3,200 a week for U.S. workers, these Gig Work jobs may be as short as a month and as long as a year.</p>
<p>These are independent consulting engagements. As with other independent contractors in today’s gig economy, the crowdsourced workers don’t receive the same benefits that full-time employees might expect, such as health insurance or &nbsp;vacation leave. Nor are they eligible for state unemployment assistance when a job terminates. Plus, there’s no guarantee that crowdsourced work provides the remote workers with a consistent income level. But freelancers are already familiar with that scenario.</p>
<h3>Advantages for software teams</h3>
<p>What are the specific advantages of crowdtesting to software teams? Speed, cost effectiveness, and language testing top the list, according to some practitioners.</p>
<h4>Fast speed</h4>
<p>“Crowdsourcing allows you to hire a large number of people who can quickly test the software in diverse environments, with 24/7 coverage,” says Dan Kelly, founder and senior partner at <a href="https://www.thenegotiator.guru/" target="_blank" rel="noopener noreferrer">The Negotiator Guru,</a> a company specializing in sourcing, negotiating, and managing complex IT contracts.</p>
<p>For example, Microsoft worked with Wipro and crowdsourcing platform Topcoder to increase testing speeds for its Microsoft Teams product to match the development release cadence, executing 24-hour testing cycles for Teams every week. “Via on-demand testing on Topcoder, ramp-up and ramp-down was made simple and a worldwide community of testers continuously provided feedback and documented defects, while helping Microsoft achieve wider test coverage across more devices and operating systems,” <a href="https://www.topcoder.com/case-studies/microsoft/" target="_blank" rel="noopener noreferrer">according to a written statement</a> from Topcoder.</p>
<p>How has crowdtesting gone at Mulytic Labs? “We’ve been able to get initial testing done very quickly with crowdsourcing and to find initial bugs that would have taken us more time and energy than desired,” Johnson says. At first, results from crowdtesters weren’t as detailed as the company wanted, but the company has since made changes to resolve that situation.</p>
<h4>Low cost</h4>
<p>”When you crowdsource your testing, you don’t need to shell out a salary for an employee, something which can make a significant dent in a project’s budget,” remarks Tomasz Hanke, team leader at <a href="https://www.startnearshoring.com/" target="_blank" rel="noopener noreferrer">startne…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.functionize.com/blog/the-pros-and-cons-of-software-crowdtesting/">https://www.functionize.com/blog/the-pros-and-cons-of-software-crowdtesting/</a></em></p>]]>
            </description>
            <link>https://www.functionize.com/blog/the-pros-and-cons-of-software-crowdtesting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24712313</guid>
            <pubDate>Wed, 07 Oct 2020 20:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp and Haskell (2015)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 158 (<a href="https://news.ycombinator.com/item?id=24712207">thread link</a>) | @dunefox
<br/>
October 7, 2020 | https://markkarpov.com/post/lisp-and-haskell.html | <a href="https://web.archive.org/web/*/https://markkarpov.com/post/lisp-and-haskell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          

<p><a href="https://markkarpov.com/tag/haskell.html">haskell</a></p><p>
  <em>
    Published on October 23, 2015, last updated November 23, 2019
  </em>
</p>

  <p>Lisp and Haskell are arguably some of the more peculiar languages out there.
It is always interesting to compare languages, so let me entertain you with
a story how I finally decided which of them is better.</p>
<p>When I first found out about Common Lisp it took my breath away. Seriously,
Lisp has consistent syntax, good design, and unique metaprogramming
capabilities. After Common Lisp, I learned a few other languages, some of
them out of necessity, others because of curiosity: Python, JavaScript,
Prolog, Clojure, and Haskell. I also was doing C and C++ in the past, but I
don’t touch them now. Until recently I considered Common Lisp the best
language I know, and probably the most powerful language in existence.</p>
<p>The fact is, I know what Common Lisp is and what it can do, but the days
when I actually hacked Lisp (more or less) regularly are long gone, and I’m
mainly doing Haskell these days.</p>
<h2 id="goodbye-lisp">Goodbye, Lisp</h2>
<p>Today I actually have had a chance to compare my productivity with Common
Lisp and Haskell. I decided to spend a few hours on my open source projects.
First, I refactored <a href="https://github.com/mrkkrp/megaparsec">Megaparsec</a>, and that was nice and easy,
but I didn’t notice this because I’m already used to the level of efficiency
Haskell gives me.</p>
<p>Next, a user of one of my Common Lisp libraries opened an issue asking to
improve one thing a bit. I estimated the required work in 15 minutes of time
and started Common Lisp hacking for the first time in a couple of months.</p>
<p>It took about 1 hour to write about 20 lines of trivial code. Of course one
might say that I just forgot the details. Yet, from my point of view the
real reasons are:</p>
<ul>
<li>
<p>Common Lisp is dynamically typed and the compiler cannot help you when you
write your code. (Well, it can help you a bit, making sure that your code
is syntactically correct and all your declared variables are used for
something.)</p>
</li>
<li>
<p>Common Lisp mixes functional code with code that has side effects. To
write idiomatic Common Lisp, you usually have to mix functional code with
not-so-functional approaches. See how this works below.</p>
</li>
<li>
<p>Common Lisp’s standard library (the functions that are available to you as
part of the ANSI Common Lisp standard) is quite poor by modern standards.
A lot of useful functions are missing. There are libraries, but I’ll get
to them.</p>
</li>
</ul>
<p>It’s essential for that library I was working on to have minimal
dependencies, so I came up with this function in bare Common Lisp to add
padding to every line of text except for the first line:</p>
<div><pre><code><span>(</span><span>defun</span><span> add-text-padding </span><span>(str &amp;key padding newline)</span>
<span>  </span><span>"Add padding to text STR. Every line except for the first one, will be</span>
<span>prefixed with PADDING spaces. If NEWLINE is non-NIL, newline character will</span>
<span>be prepended to the text making it start on the next line with padding</span>
<span>applied to every single line."</span>
<span>  (</span><span>let</span><span> ((str (</span><span>if</span><span> newline</span>
<span>                 (</span><span>concatenate</span><span> 'string (</span><span>string</span><span> </span><span>#\N</span><span>ewline) str)</span>
<span>                 str)))</span>
<span>    (</span><span>with-output-to-string</span><span> (s)</span>
<span>      (</span><span>map</span><span> 'string</span>
<span>           (</span><span>lambda</span><span> (x)</span>
<span>             (</span><span>princ</span><span> x s)</span>
<span>             (</span><span>when</span><span> (</span><span>char=</span><span> x </span><span>#\N</span><span>ewline)</span>
<span>               (</span><span>dotimes</span><span> (i padding)</span>
<span>                 (</span><span>princ</span><span> </span><span>#\S</span><span>pace s))))</span>
<span>           str))))</span>
</code></pre></div>
<p>In case you don’t speak Common Lisp, let me highlight some parts of the
code:</p>
<ul>
<li>
<p><code>concatenate</code> needs to know the type of its output, so we pass it a symbol
specifying type of desired result as the first argument.</p>
</li>
<li>
<p><code>(string #\Newline)</code> constructs a line containing a single newline
character. There is no syntax in Common Lisp to write something like
<code>"\n"</code>. The alternative approach would be <code>(format nil "~%")</code>. There is no
syntax for all other special characters if you want to put them into
string. To be fair, you have multi-line string literals without funny
escaping instead, which is vital for doc-strings and the like.</p>
</li>
<li>
<p><code>(map 'string …)</code> is used to loop through characters in a string. Note
that here we use <code>map</code> function as a helper for a rather imperative
procedure—printing results to new string using a temporarily created
stream <code>s</code> (with the help of <code>with-output-to-string</code>). But that’s
idiomatic in Common Lisp.</p>
</li>
</ul>
<p>When I ran this in the REPL, I got the following:</p>
<div><pre><code><span>; SLIME 2015-10-18</span>
<span>CL-USER&gt; (asdf:load-system :unix-opts)</span>
<span>T</span>
<span>CL-USER&gt; (</span><span>in-package</span><span> :unix-opts)</span>
<span>#&lt;PACKAGE </span><span>"UNIX-OPTS"</span><span>&gt;</span>
<span>OPTS&gt; (</span><span>defvar</span><span> *foo* </span><span>(</span><span>format</span><span> </span><span>nil</span><span> </span><span>"first line~%second line~%third line"</span><span>))</span>
<span>*FOO*</span>
<span>OPTS&gt; *foo*</span>
<span>"first line</span>
<span>second line</span>
<span>third line"</span>
<span>; compiling (DEFUN ADD-TEXT-PADDING ...)</span>
<span>OPTS&gt; (add-text-padding *foo* :padding </span><span>10</span><span>)</span>
<span>; Evaluation aborted on #&lt;TYPE-ERROR expected-type: CHARACTER datum: NIL&gt;.</span>
</code></pre></div>
<p>The debugger popped up and told me in plain English:</p>
<blockquote>
<p>The value NIL is not of type CHARACTER.</p>
</blockquote>
<p>It is difficult to argue with, <code>nil</code> is definitely not a character. But why
the heck do I get this? Can you tell? Please try as hard as you can! <em>(The
answer is at the end of the blog post.)</em></p>
<p>I decided that I won’t hack Common Lisp anymore. That’s great and expressive
language, but I want to write in something I’m efficient with.</p>
<h2 id="productivity-of-haskell-programmer">Productivity of Haskell programmer</h2>
<p>I use <a href="https://gnu.org/software/emacs/">Emacs</a> for almost everything that is
related to text. One package I love in particular is
<a href="http://www.flycheck.org/">Flycheck</a>. When I edit Haskell source code,
Flycheck is running GHC with <code>-Wall</code> flag and
<a href="https://github.com/ndmitchell/hlint">HLint</a> in the background and displays
warnings and errors interactively underlining my source code. This is a
convenient feature for any language, but only Haskell with its type system
takes this sort of tool to its limits.</p>
<p>In fact, this non-stop interactive conversation with compiler is the most
efficient programming workflow I’ve ever used. Combined with the fact that
<em>if your code compiles, it probably works</em>, Haskell must be the most
efficient (with respect to human resources) programming language in
existence just because of the static type system that works as a powerful
ally for the programmer. Of course, bugs can live in Haskell code too, but
I’m not saying we should abandon writing tests.</p>
<h2 id="problems-of-common-lisp">Problems of Common Lisp</h2>
<p>Speaking of tests, recently I discovered that Zach Beane AKA Xach, an
über-level Common Lisp hacker <a href="http://xach.livejournal.com/278047.html?thread=674335#t674335">doesn’t usually write tests</a>.
FYI, he is the author of <a href="https://www.quicklisp.org/beta/">Quicklisp</a>, that is something like (but
not quite) Cabal or Stack. Quicklisp is de-facto the only widely used
library manager in Common Lisp world, and so it’s written in Common Lisp and
<a href="https://github.com/quicklisp/quicklisp-client">doesn’t have any tests</a>. It is a wonder for me how it
works. Usually when a project is big enough I start to have doubts whether
all parts of it still work after some changes, so I cannot imagine you can
do a thing like Quicklisp without tests and be confident about the result.</p>
<p>But you know what, Lisp, and its most advanced dialect (IMO), Common Lisp is
really cool. If you don’t believe me, you can read <a href="http://www.paulgraham.com/avg.html">Paul Graham</a> at any
time. The author can tell you what a great language Common Lisp is on
many-many pages. I don’t remember where I read this, but he has something
like “There is the problem of lacking libraries, but on a big enough project
benefits of the language itself outweigh the lack of libraries.”</p>
<p><em>Well, take any high-level language like Python, which have all the nice
libraries, and for project of any size it will be better than Common Lisp.
Macros are missing, but you can live without macros after all.</em></p>
<p>Common Lisp doesn’t have enough high-quality, actively maintained libraries.
The fact is, there are some pearls like <a href="https://github.com/fukamachi/caveman">caveman</a> or
<a href="https://github.com/stumpwm/stumpwm">stumpwm</a>, but most libraries don’t look good enough. Sometimes you
start thinking that if you want to end up with a great project you’ll need
to write your own libraries (which you’ll probably do, like many people
before you, not that it has improved the situation though).</p>
<p>Another problem is that some widely-used Common Lisp libraries have no
documentation at all. If you’re to understand how to use them, <em>read the
source code</em>. I can name a couple of them, but I don’t want to do so,
because I don’t think it’s polite. I’ve opened an issue on GitHub of one
quite popular library, asking the maintainer to write documentation. After 6
months it’s still not written (strange, right?). In my opinion, this is not
a serious approach to maintaining your code.</p>
<p>When I was interested in Common Lisp, I had an idea of a pet project to help
me remember all sorts of French words and verbs in particular. Of course I
wanted to do the whole thing decently, even though it’s console app, it
should have decent interface and work smoothly in general. I succeeded, but
I had to do a lot more than I would need to do if I wrote it in, say Python.
This is how (in retrospect I understand) less powerful Python would be
better fit for this (or almost any) project.</p>
<h2 id="the-curse-of-dynamic-languages">The curse of dynamic languages</h2>
<p>There is a blog post called <a href="https://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/"><em>Dynamic Languages are Static
Languages</em></a>. In short, the author makes the point that
dynamic langauges are static languages but with one huge type including all
possible values. Here is a paragraph I find important:</p>
<blockquote>
<p>And this is precisely what is wrong with dynamically typed languages:
rather than affording the <em>freedom</em> to ignore types, they instead impose
the <em>bondage</em> of restricting attention to a <em>single</em> type! Every single
value has to be a value of that type, you have no choice! Even if in a
particular situation we are absolutely certain that a particular value is,
say, an integer, we have no choice but to regard it as a value of the “one
true type” that is <em>classified</em>, not typed, as an integer. Conceptually,
this is just rubbish, but it has serious, tangible penalties. For one, you
are depriving yourself of the ability to state and enforce the <em>invariant</em>
that the value at a particular program point must be an integer. For
another, you are imposing a serious bit of run-time overhead to represent
the class itself (a tag of some sort) and to check and remove and apply
the class tag on the value each time it is used.</p>
</blockquote>
<p>The lack of the power to express meaning of your program on type level is
another downside of Lisp. (You can add types in Common Lisp too, but that’s
used solely for optimization. Common Lisp can be almost as fast …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://markkarpov.com/post/lisp-and-haskell.html">https://markkarpov.com/post/lisp-and-haskell.html</a></em></p>]]>
            </description>
            <link>https://markkarpov.com/post/lisp-and-haskell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24712207</guid>
            <pubDate>Wed, 07 Oct 2020 20:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My app scaled to 46,000 users two weeks after launch and made $0]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24711960">thread link</a>) | @mwood23
<br/>
October 7, 2020 | https://www.marcuswood.io/blog/my-app-scaled-to-46-000-users-two-weeks-after-launch-and-made-0-lessons-learned | <a href="https://web.archive.org/web/*/https://www.marcuswood.io/blog/my-app-scaled-to-46-000-users-two-weeks-after-launch-and-made-0-lessons-learned">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section></section><section><div><p>Last year, I launched <a href="https://www.marcuswood.io/products/guess-the-throne">Guess the Throne</a>, a Game of Thrones death pool app. I built it with a friend of mine in two weeks and launched a few just before the final season premiered. We had one goal: achieve product/market fit. Oh boy did we!</p><p>Below are some of the lessons learned and what we wish we had done differently.</p><h2 id="dont-get-in-the-weeds"><a href="#dont-get-in-the-weeds" aria-label="dont get in the weeds permalink"></a>Don't get in the weeds</h2><p>We coded the bare minimum features for the app. At launch (and after), users couldn't even edit their entry name. That led to a bunch of really funny support emails asking for us to change their name because they created an entry with a very NSFW name 😅.</p><p>The big takeaway here is that people didn't miss that feature or any of the other features we left out. The faster you get your product in someone's hands the more actionable feedback you'll receive.</p><h2 id="be-scrappy"><a href="#be-scrappy" aria-label="be scrappy permalink"></a>Be Scrappy</h2><p>We launched the app with a $150 marketing budget. Most of our users came from engaging with communities on Reddit, Facebook, forums, podcasts, and Twitch. If you can engage the small communities, that'll lead to more growth and knowledge about your market. I wrote up a blog with how we marketed the app on <a href="https://www.marcuswood.io/blog/we-launched-a-product-with-150-here-s-what-happened">my website</a> if you'd like to read more.</p><h2 id="ads-arent-always-the-answer-for-growth"><a href="#ads-arent-always-the-answer-for-growth" aria-label="ads arent always the answer for growth permalink"></a>Ads Aren't Always the Answer for Growth</h2><p>If you have a small marketing budget I encourage you to think about the cost per conversion before considering ads, especially if your app is free/free to try. For example, we found a fan account on Twitter that had a bunch of followers. We reached out and they said for $20 they'd give us one tweet. We tried it out and the tweet blew up! Loads of people came to our site from that one tweet for a $0.20 cost per user, NOT cost per click.</p><h2 id="have-a-monetary-strategy"><a href="#have-a-monetary-strategy" aria-label="have a monetary strategy permalink"></a>Have a Monetary Strategy</h2><p>I will say that we didn't set out to make money off of this app, but once we started receiving thousands of requests per second I could feel my credit card catching fire 😱. By the time it had happened it was too late since we had never thought about making money. We tried making it donation based where we'd donate 50% to charity and 50% to keep the app up, but it only amounted to around $40. The cost for the servers were over $500.</p><h2 id="get-your-bearings"><a href="#get-your-bearings" aria-label="get your bearings permalink"></a>Get your Bearings</h2><p>This was the first product (after many tries) that took off to become popular. There's a variety of reasons I believe it did, but once you find success expand your lens to see the bigger landscape. Why did it become popular? What made it special? What's next? Don't be afraid to paint in broad strokes once you've found something special.</p><p>That leads me to today's launch of <a href="https://guesstherose.com/" target="_blank" rel="noopener noreferrer">Guess the Rose</a>! It is a fantasy league for The Bachelor/Bachelorette that we built from the ground up with everything we learned from Guess the Throne. We want to create a suite of fun games for TV shows for people who want to play fantasy, but aren't into sports.</p><p>Please check it out and sign up if you're a fan of the show! Good luck with your products, think bigger, and stay positive.</p><p>p.s. We also <a href="https://www.producthunt.com/posts/guess-the-rose" target="_blank" rel="noopener noreferrer">launched on Product Hunt</a> today so if this post helped you please consider upvoting.</p></div></section><section><div><div><div><h2>Want more content like this?</h2><p>Sign up to receive my newsletter, where I feature early access to new products, exciting content, and more!</p></div></div><div><p><strong>Marcus Wood</strong> is a JavaScript software engineer that focuses on building products using Typescript, React, and GraphQL. He has built and delivered solutions for some of the largest companies in the world.
    </p></div></div></section></div></div>]]>
            </description>
            <link>https://www.marcuswood.io/blog/my-app-scaled-to-46-000-users-two-weeks-after-launch-and-made-0-lessons-learned</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711960</guid>
            <pubDate>Wed, 07 Oct 2020 19:49:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a New Rust Class at Stanford: Safety in Systems Programming]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24711314">thread link</a>) | @ksml
<br/>
October 7, 2020 | https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html | <a href="https://web.archive.org/web/*/https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Writing quality software is hard. Sometimes, software breaks in entertaining
ways. However, when software runs everything from personal assistants like
Alexa and Google Home to banking to elections, some bugs can be much more
severe.</p>

<p>This past quarter, Armin Namavari and I tried teaching a class about how to
write software that sucks just a <em>little</em> less. We focused on common problems
in computer systems caused by certain kinds of silly (but very serious)
mistakes, such as issues of memory safety and thread safety. The core theme of
the class was, <em>What are common problems with systems programming right now?
How are people responding to those issues? How do those measures fall short?</em>
We wanted students to be aware of problems that have plagued the industry for
decades, and we wanted to teach students how to use tools and mental models
that people have developed to combat those issues. However, these tools are
imperfect, and we also wanted students to experience and understand the
limitations of such tools to be better aware of what to watch out for when
building systems.</p>

<!--more-->

<p>In particular, we focused on teaching the Rust programming language as a way to
build better habits and combat mistakes endemic to C- and C++-based software.
In many ways, Rust <em>requires</em> good practices, and it has an educational
compiler with helpful error messages that help students learn. Additionally, we
looked at how lessons from Rust can be applied to write better code in C++, and
we taught students about tools that can be used to detect common mistakes
before they become a problem.</p>

<p>In contrast with a typical security class, we aimed to build a robust software
engineering aspect into the course, giving code-heavy assignments and trying to
improve students’ processes rather than merely giving awareness about common
problems. Our goal with this class was to train students to be better software
developers, regardless of what programming language they end up using.</p>

<p>I think the class went quite well, and student evaluations were extremely
positive. Even before the quarter ended, students told us that the class was
extremely helpful for implementing and debugging assignments in other classes.
We hope to teach the class again this coming fall, and are looking for input on
how it might be improved.</p>

<p>This blog post aims to be a summary of what we did, why we did it, and what we
are thinking about changing for the future. It’s long, but written so you can
skip around to whatever is interesting to you. Here’s an outline:</p>

<!--* [What is systems programming?](#what-is-systems-programming)-->
<ul>
  <li><a href="#what-is-safety-and-why-should-we-care">What is safety, and why should we care?</a></li>
  <li><a href="#imagining-safety-education">Imagining safety education</a>
    <ul>
      <li><a href="#should-there-be-a-safety-class">Should there be a “safety class”?</a></li>
      <li><a href="#how-would-this-be-different-from-a-security-class">How would this be different from a security class?</a></li>
      <li><a href="#how-does-one-teach-safe-programming">How does one teach safe programming?</a></li>
    </ul>
  </li>
  <li><a href="#summary-of-the-class">Summary of the class</a>
    <ul>
      <li><a href="#lectures">Lectures</a></li>
      <li><a href="#assignments">Assignments</a></li>
    </ul>
  </li>
  <li><a href="#survey-results">Survey results</a></li>
  <li><a href="#takeaways">Takeaways</a>
    <ul>
      <li><a href="#is-there-a-place-for-a-safety-class-in-a-cs-curriculum">Is there a place for a safety class in a CS curriculum?</a></li>
      <li><a href="#whats-it-like-for-students-to-learn-rust-in-a-short-time-frame">What’s it like for students to learn Rust in a short time frame?</a></li>
      <li><a href="#should-we-try-to-incorporate-rust-into-the-stanford-core-curriculum">Should we try to incorporate Rust into the Stanford core curriculum?</a></li>
      <li><a href="#should-this-be-a-standalone-class-or-should-it-remain-an-addon-to-cs-110">Should this be a standalone class, or should it remain an addon class to CS 110?</a></li>
    </ul>
  </li>
  <li><a href="#general-teaching-lessons-learned">General teaching lessons learned</a></li>
</ul>

<p>Major thanks go to Armin Namavari for being a wonderful co-instructor, Sergio
Benitez for giving an excellent guest lecture, Will Crichton for providing
feedback and guidance in designing the class, Jerry Cain for giving us the
opportunity to teach and giving encouragement throughout, and Rakesh Chatrath,
Jeff Tucker, Vinesh Kannan, John Deng, and Shiranka Miskin for reviewing drafts
of this post.</p>

<!--
## What is systems programming?

In this class, we wanted to focus on safety in systems programming &mdash; but what
*is* systems programming, anyways?

"Systems programming" is a frequently-used term that I have never heard a clear
definition for, despite specializing in this track in undergrad. While it is
used in many different ways, I think about it like this: **Systems programming
is when you spend more time thinking about hardware than humans.** An
application programmer must think, *what does a user of my software need, and
how can I implement that in code?* An application programmer might work with
different programming languages and libraries, but rarely needs to think about
exactly what the hardware is doing under the hood. By contrast, a systems
programmer must think, *how can I teach this hardware new tricks in order to do
the things we need to do?* A systems programmer spends much more time thinking
about when memory is allocated, when a processor might switch contexts, when
data might be passed over a network, etc.
-->

<!-- TODO: picture of restaurant -->

<!--
As an application developer, you spend more time implementing business logic using whatever programming languages and tools you've decided to use. You're trying to design something that fits within the physical constraints of whatever you're running on. As a systems programmer, you spend much more time thinking about when memory gets allocated, when a processor switches contexts, when data gets passed over a network, etc.

Humans are still important (I'll admit I deemphasized humans partially for the alliteration), but the focus is less on end users and more on supporting the application developers and the application software that builds on top

Diagram: trying to show humans walking on top, hardware on bottom, and application developers standing on top of the systems developers
Diagram: floor is programming languages, libraries, and abstractions
Have some plumbers, carpenters, etc under the floor, and application devs servicing customers on top

If a computer were a restaurant, systems programmers would be the plumbers etc, and application programmers would be the chefs, waiters, etc

Examples of systems software: the code generating directions for Google Maps, Google Chrome, the infrastructure that does transcription for Siri (not the AI algorithms, but everything in between your phone and the algorithms), banking infrastructure, car firmware, etc.
-->

<h2 id="what-is-safety-and-why-should-we-care">What is safety, and why should we care?</h2>

<p>Safety is an unfortunately vague term lacking a great definition, but for our
purposes, we’ll say <strong>safety is about avoiding harmful mistakes.</strong> I view
safety as being concerned with the subset of potentially serious bugs: if a
button on a website renders as purple instead of blue, that’s a bug we might
not care much about, but if bank account software allows users to withdraw the
same $1000 multiple times, or if autonomous vehicle software can fail under
certain circumstances, that’s a more concerning problem.</p>

<p>Safety is particularly relevant in systems programming because systems
programming is <em>hard</em>. Systems programming often involves pushing the limits of
what hardware can do, and often involves reasoning about the state of multiple
threads sometimes even distributed across thousands of machines. Additionally,
for performance and historical reasons, the majority of systems software is
written in C or C++, which are <em>notoriously</em> difficult to use correctly.
Reasoning about pointers and memory is hard, and C and C++ do little to help.
C/C++’s weak type systems and poorly defined
specifications mean they will happily accept <a href="https://www.radford.edu/ibarland/Manifestoes/whyC++isBad.shtml">clearly broken code with no
sensible
interpretation</a>.
Even worse, there are countless minefields where the languages’ poor designs
are just begging for mistakes to happen. Simple functions like <code>strcpy</code>, which
copies a string from one place in memory to another, are extremely easy to
misuse and have been the cause of countless <a href="https://pointerless.wordpress.com/2012/02/26/strcpy-security-exploit-how-to-easily-buffer-overflow/">security
vulnerabilities</a>.
The <code>strncpy</code> function was introduced to address the weaknesses of <code>strcpy</code>,
yet <a href="https://devblogs.microsoft.com/oldnewthing/20050107-00/?p=36773"><code>strncpy</code> turns out to be almost just as
bad</a>. Even
<a href="https://stackoverflow.com/questions/7459630/how-can-a-format-string-vulnerability-be-exploited"><code>printf</code> can lead to security
vulnerabilities</a>
when called the wrong way.</p>

<figure>
    <a href="https://reberhardt.com/blog/images/designing-cs-110l/strcpy.png">
        <img src="https://reberhardt.com/blog/images/designing-cs-110l/strcpy.png" alt="">
    </a>
    
</figure>

<p>Also, as systems software provides the foundation on which other software runs,
it’s particularly important to get right. Many real-world examples demonstrate
the severe impact of the aforementioned issues.  One of my favorite examples is
presented in <a href="http://www.autosec.org/pubs/cars-usenixsec2011.pdf">Comprehensive Experimental Analyses of Automotive Attack
Surfaces</a>.  It’s a great
read, but as a summary, the authors bought a popular car and attempted to find
as many ways as possible to remotely hijack the car without having physical
access. They examined vectors such as wireless key fobs, Bluetooth, and even
the tire pressure monitoring system (which uses wireless signals to transmit
information from sensors in the tires). Every vector was found to be
exploitable, many of them trivially so. For example, the Bluetooth software had
“over 20 calls to <code>strcpy</code>, none of which were clearly safe.” The authors only
looked at the first instance of <code>strcpy</code>, and found that it copies data to the
stack when handling a Bluetooth configuration command without checking the
length of the string. This results in a trivially exploitable buffer overflow
that allows a paired device to execute arbitrary code in the media system.
Since the subsystems in most cars lack isolation, compromising one subsystem
(such as the media player) can result in the compromise of the entire car. In
2015, researchers demonstrated this, <a href="https://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/">remotely killing a Jeep that was driving
on the
highway</a>.</p>

<p>This isn’t just a problem with the automotive industry. <a href="https://blog.zimperium.com/whatsapp-buffer-overflow-vulnerability-under-the-scope/">Professional</a>
<a href="https://www.theregister.com/2019/08/06/qualcomm_android_security_patches/">programmers</a>
<a href="https://www.biometricupdate.com/202006/acronis-reports-critical-flaws-in-geovision-biometric-devices-man-in-the-middle-attack-risks">across</a>
<a href="https://www.zdnet.com/article/critical-security-flaw-schneider-industrial-software-power-plants-vulnerabilty/">many</a>
<a href="https://blog.zecops.com/vulnerabilities/youve-got-0-click-mail/">industries</a>
<a href="https://www.theverge.com/2017/5/12/15630354/nhs-hospitals-ransomware-hack-wannacry-bitcoin">regularly</a>
<a href="https://tools.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-sdwanbo-QKcABnS2">make</a>
<a href="https://threatpost.com/netgear-zero-day-takeover-routers/156744/">simple</a>
<a href="https://gadgets.ndtv.com/mobiles/news/samsung-critical-bug-fix-skia-sve-2020-16747-zero-click-vulnerability-2224867">but</a>
<a href="https://redmondmag.com/articles/2020/07/16/cisa-windows-server-dns-vulnerability.aspx">serious</a>
<a href="https://threatpost.com/google-squashes-high-severity-flaws-in-chrome-browser/154424/">mistakes</a>.</p>

<p>This seems like something we should be talking about. Would you hand a
chemistry student a bunch of volatile chemicals that regularly explode in
professional labs without a robust discussion of safety?  Probably not. Yet
that’s effectively what our curriculums are doing. We’re handing students a
series of tools that professionals routinely shoot themselves in the foot with,
and we aren’t having a substantial discussion of precautions we can take to
avoid potentially life-threatening mistakes.</p>

<figure>
    <a href="https://reberhardt.com/blog/images/designing-cs-110l/chem-lab.png">
        <img src="https://reberhardt.com/blog/images/designing-cs-110l/chem-lab.png" alt="In many ways, our CS curriculums are like inviting students into a chem lab without any discussion of safety.">
    </a>
    
    <figcaption>In many ways, our CS curriculums are like inviting students into a chem lab without any discussion of safety.</figcaption>
    
</figure>

<p>One might argue that the perils of strcpy are nothing like the dangers of a
fully-stocked chemistry lab; there’s no danger of students dying in front of
the computer here. (Well, we hope.) However, I argue that we deal with dangers
on a much larger scale.  One line of code can easily affect millions (or
billions) of people, and the impacts of our code can be much greater than we
realize, even when we aren’t working on software for cars (which <a href="https://www.safetyresearch.net/blog/articles/toyota-unintended-acceleration-and-big-bowl-%E2%80%9Cspaghetti%E2%80%9D-code">we’ve killed
people
with</a>)
or medical devices (which <a href="https://hackaday.com/2015/10/26/killed-by-a-machine-the-therac-25/">we’ve also killed people
with</a>). It
may seem that the worst-case bugs in a file sharing server would simply prevent
users from sharing files, but one such bug led to the <a href="https://www.telegraph.co.uk/technology/2018/10/11/wannacry-cyber-attack-cost-nhs-92m-19000-appointments-cancelled/">significant disruption
of the National Health Service in the
UK</a>.
Non-critical emergencies had to be refused. It may seem that the worst-case
bugs in a web application library would simply take down some websites, but one
such bug led to the <a href="https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html">exfiltration of extremely sensitive data on nearly every
American adult with a credit
history</a>.</p>

<!--We've spent a lot of effort over the last three decades finding ways to improve
the safety of code. We have linters, which can detect unsafe patterns in code
(e.g. calls to `strcpy`, or use of uninitialized memory). We have fuzzers and
sanitizers, which can stress test our code and identify memory errors and data
races. Most promising (in my opinion), we have new progamming languages such as
Rust and Swift which are safer, competitive on performance, and showing
potential for replacing C and C++ in the settings that those languages have
typically dominated. These languages can prevent entire classes of mistakes
that keep recurring in C and C++ codebases even with the use of other safety
tools. Linters, sanitizers, fuzzers, and static analyzers all help to catch
mistakes, but they don't *prevent* them, and they can't catch everything. While
these new languages are not a panacea and have their own problems, they make
massive strides towards squashing issues we haven't been able to address via
other means. Despite having some of the best security and development practices
in the world, Google Chrome (written in C++) is still plagued with memory
errors that would have been entirely prevented with Rust. Recently, they found
that [70% of security vulnerabilities were caused by memory
errors](https://www.chromium.org/Home/chromium-security/memory-safety).-->

<p>Precautions and safety measures <em>do</em> exist, but people aren’t using them. Part
of this may be because the tooling isn’t good enough or easy enough to use.
Part of this may be because there hasn’t been enough time to see mass adoption.
But I think part of this may also be because of a lack of education and
awareness surrounding these issues. We can teach C and C++ and hope that
students will learn good habits and learn how to use static analyzers,
sanitizers, fuzzers, and safer languages on the job, but then have we not
failed them as educators? Seeing that software engineers keep making pretty
basic mistakes with critical impact, it seems that something is wrong and we
should be trying to do more.</p>

<h2 id="imagining-safety-education">Imagining safety education</h2>

<p>So, we should talk more about safety. But how should we go about it?</p>

<h3 id="should-there-be-a-safety-class">Should there be a “safety class”?</h3>

<p>In planning this class, we couldn’t find any other programming safety class out
there. Is that because no one has thought to do it yet, or is it because it is
better to teach safety in context alongside more central material?</p>

<p>Particularly because “safety” is so broad, it does seem helpful
to cover best practices and helpful tricks/tools while introducing new
material. However, there were two reasons we felt it might make sense to teach
a class entirely focused on safety.</p>

<p>First, teaching a separate safety class gives us room to experiment with
teaching new material that would be difficult to integrate into existing</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html">https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html</a></em></p>]]>
            </description>
            <link>https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711314</guid>
            <pubDate>Wed, 07 Oct 2020 18:47:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Interview Questions Deconstructed: The Knight’s Dialer]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 117 (<a href="https://news.ycombinator.com/item?id=24711094">thread link</a>) | @thanato0s
<br/>
October 7, 2020 | https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/ | <a href="https://web.archive.org/web/*/https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This is the second in a series of posts in which I share my advice for candidates interviewing for tech companies, drawing on my experience as an engineer and interviewer at Google. If you haven’t already, take a look at the <a href="https://alexgolec.dev/introducing-google-interview-questions-deconstructed/">introduction</a> to this series.</p><p><em>Before I start, a disclaimer: while interviewing candidates is one of my professional responsibilities, this blog represents my personal observations, my personal anecdotes, and my personal opinions. Please don’t mistake this for any sort of official statement by or about Google, Alphabet, or any other person or organization.</em></p><p>This was the first problem I used during my interviewing career, and it was also the first to leak and get banned. I like it because it hits number of sweet spots:</p><ul><li>It’s easy to state and understand.</li><li>It has a number of solutions, each requiring varying degrees of algorithms and data structures knowledge. Also, a little bit of insight goes a long way.</li><li>Each solution can be implemented in relatively few lines, making it perfect for a time-constrained environment.</li></ul><p>If you’re a student or otherwise applying to tech jobs, my hope is that you’ll come away from reading this with a better understanding of what to expect from interview problems. If you’re an interviewer, I’d like to share my thought process and stylistic approach to interviewing, the better to inform others and solicit comments.</p><p>Note I’ll be writing code in Python. I like Python because it’s easy to learn, compact, and has an absolutely massive standard library. Candidates like it, too: even though we impose no language constraints, 90% of people I interview use Python. Also I use Python 3 because c’mon, it’s 2018.</p><p><em>Join <a href="https://discord.gg/cKFppJ">our Discord</a> to discuss this problem with the author and the community! </em></p><p>Imagine you place a knight chess piece on a phone dial pad. This chess piece moves in an uppercase “L” shape: two steps horizontally followed by one vertically, or one step horizontally then two vertically:</p><figure><img src="https://alexgolec.dev/content/images/2020/08/1-pE4b3hqGDv7pKivQTQZyPw.png" alt="Image for post"><figcaption>Pay no attention to the poorly-redacted star and pound keys</figcaption></figure><p>Suppose you dial keys on the keypad using only hops a knight can make. Every time the knight lands on a key, we dial that key and make another hop. The starting position counts as being dialed.</p><p>How many distinct numbers can you dial in N hops from a particular starting position?</p><p>Every interview I conduct basically breaks down into two parts: first we find an algorithmic solution and then the candidate implements it in code. I say “we” find a solution because I’m not a mute spectator: 45 minutes is not a lot of time to design and implement anything under the best circumstances, never mind under pressure. I let candidates take the lead in the discussion, generating ideas, solving instances of the problem, etc., but I’m more than happy to give a nudge in the right direction. The better the candidate, the fewer hints I tend to have to give, but I have yet to see a candidate who required no input from me at all.</p><p>I should underscore this, because it’s important: as an interviewer, I’m not in the business of sitting back and watching people fail. I want to write as much positive feedback as I can, and I try to give you opportunities to allow me to write good things about you. Hints are my way of saying “okay, I’m gonna give this bit to you, but only so you can move on and show me what you’ve got on the other parts of the question.”</p><p>With that being said, your first action after hearing the question should be stepping up to the whiteboard and solving small instances of the problem by hand. <em>Never dive right into code!</em> Solving small instances lets you spot patterns, observed and edge cases, and also helps crystallize a solution in your head. As an example, suppose you start on 6 and have two hops to make. Your sequences will be…</p><ul><li>6–1–8</li><li>6–1–6</li><li>6–7–2</li><li>6–7–6</li><li>6–0–4</li><li>6–0–6</li></ul><p>…for a total of six sequences. If you’re following along, try taking a pencil and paper and deriving these. This doesn’t translate well into a blog post, but trust me when I say there’s something magical about working out a problem by hand that leads to many more insights than just staring at it and thinking quietly.</p><p>With all that said, you may have a solution forming in your head. But before we get there…</p><p>One of the surprises I had when I started using this problem is how often candidates get stuck on computing the keys to which we can hop from a given position, also known as the neighbors. My advice is: when in doubt, write an empty placeholder and ask the interviewer if you can implement it later. This problem’s complexity does not lie in the neighbor computation; I’m paying attention to how well you count full numbers. Any time spent on neighbor computation is effectively wasted.</p><p>I would accept “let’s assume there’s a function that gives me the neighbors” along with the following stub. Of course, I’ll probably ask you to double back and implement this later, but only if we have time. You can simply write a stub like this and move on:</p><pre><code>def neighbors(position):
	...</code></pre><p>Also, you don’t really lose much by asking to use a stub: if the question’s complexity is elsewhere I’ll allow it. If not, I’ll ask you to actually implement it. I don’t mind when candidates don’t realize where the complexity of a question lies, especially in the early stages when they might not have fully explored the problem.</p><p>As for the neighbors function here, given that it never changes you can simply create a map and return the appropriate value:</p><pre><code>NEIGHBORS_MAP = {
    1: (6, 8),
    2: (7, 9),
    3: (4, 8),
    4: (3, 9, 0),
    5: tuple(),  # 5 has no neighbors
    6: (1, 7, 0),
    7: (2, 6),
    8: (1, 3),
    9: (2, 4),
    0: (4, 6),
}
def neighbors(position):
    return NEIGHBORS_MAP[position]</code></pre><p>Anyway, on to the solution. Perhaps you’ve already noticed this problem can be solved by enumerating all possible numbers and counting them. You can use recursion to generate these values:</p><pre><code>def yield_sequences(starting_position, num_hops, sequence=None):
    if sequence is None:
        sequence = [starting_position]
    
    if num_hops == 0:
        yield sequence
        return

    for neighbor in neighbors(starting_position):
        yield from yield_sequences(
            neighbor, num_hops - 1, sequence + [neighbor])

def count_sequences(starting_position, num_hops):
    num_sequences = 0
    for sequence in yield_sequences(starting_position, num_hops):
        num_sequences += 1
    return num_sequences</code></pre><p>This works, and it’s a common starting point I saw in interviews. Notice, however, that we generate the numbers and never actually use them. This problem asks for the <em>count</em> of numbers, not the numbers themselves. Once we count a number we never revisit it. As a general rule of thumb, I recommend paying attention to when your solution computes something it doesn’t use. Often you can cut it out and get a better solution. Let’s do that now.</p><p>How can we count phone numbers without generating them? It can be done, but not without an additional insight. Notice how the count of numbers that can be generated from a given starting position in N hops is equal to the sum of the counts of hops that can be generated starting from each of its neighbors in N-1 hops. Stated mathematically as a recurrence relation, it looks like this:</p><figure><img src="https://alexgolec.dev/content/images/2020/08/1-mcwSdrDe69X5FDegPmfgHg.png" alt="Image for post"></figure><p>This is intuitively obvious when you consider what happens with one hop: 6 has 3 neighbors (1, 7, and 0) and in zero hops you can reach one number for each, so you can only dial three numbers.</p><p>How does one arrive at this insight, you might ask? If you’ve studied recursion, this should become evident after some exploration on the whiteboard. Many candidates who’ve practiced recursion immediately notice this problem breaks down into smaller subproblems, which is a dead giveaway. If you’re in an interview with me and you can’t seem to arrive at this insight, I will usually give hints to help get you there, up to and including outright giving it away if prodding fails.</p><p>Once you have this insight in hand, you can already move forward and solve this problem again. There are a number of implementations that use this fact, but let’s start with the one I see most often in interviews: the naive recursive approach:</p><pre><code>from neighbors import neighbors                                 
                                                                
def count_sequences(start_position, num_hops):                  
    if num_hops == 0:                                           
        return 1                                                
                                                                
    num_sequences = 0                                           
    for position in neighbors(start_position):                  
        num_sequences += count_sequences(position, num_hops - 1)
    return num_sequences                                        
                                                                
if __name__ == '__main__':                                      
    print(count_sequences(6, 2))                                </code></pre><p>That’s it! Combine this with a function to compute the neighbors and you’ve produced a working solution! At this point, you should pat yourself on the back. If you scroll down you’ll notice we’ve still got a lot of ground to cover, but this point is a milestone. Producing any working solution already sets you apart from a surprising number of candidates.</p><p>This next question is one you’re going to be hearing a lot from me: what is the Big-O complexity of this solution? For those who don’t know, Big-O complexity is (informally) a sort of shorthand for the rate at which the amount of computation required by a solution grows as a function of the size of the input. For this problem, the size of the input is the number of hops. If you’re interested in the proper mathematical definition, you can read more <a href="https://en.wikipedia.org/wiki/Big_O_notation" rel="noopener nofollow">here</a>.</p><p>For this implementation, every call to <code>count_sequences()</code> recursively calls <code>count_sequences()</code> at least twice, because each key has at least two neighbors. Since we recurse a number of times equal to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/">https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/</a></em></p>]]>
            </description>
            <link>https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711094</guid>
            <pubDate>Wed, 07 Oct 2020 18:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL2 – Installation Tutorial for Graphical Windows Subsystem on Linux]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24711054">thread link</a>) | @todsacerdoti
<br/>
October 7, 2020 | https://l-o-o-s-e-d.net/wsl2 | <a href="https://web.archive.org/web/*/https://l-o-o-s-e-d.net/wsl2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <p><h2>WSL2</h2></p>

            

            <div>
              <p>06:00pm | 10/05/2020<br>Daniel Tompkins</p>
              


 
            </div>

            <p>
              <h3>Microsoft 💔 Linux</h3>
            </p>

            <div>
              <p>In 2001, Microsoft's former CEO— Steve Ballmer— was <a target="_blank" href="https://www.theregister.com/2001/06/02/ballmer_linux_is_a_cancer/">quoted</a> by the online tech news publication, <em>The Register</em>, saying:</p>
              <p>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches</p>
              <p>Fast-forward 15 years into the future— at Microsoft's developer conference, <em>Build 2016</em>— and Gates' tech behemoth reveals a sudden volte-face. The current CEO, Satya Nadella, announces Windows Subsystem for Linux. With WSL, Microsoft is taking some of the most popular Linux distributions and making them available within Windows through the Microsoft Store.</p>
              <p>According to a <a target="_blank" href="https://w3techs.com/technologies/overview/operating_system">W<sup>3</sup>Techs survey</a>, Unix operating systems (the under-pinning OS of Linux, as well as MacOS) make up 71% of the Web, the remaining 29% being Windows. Additionally, every Android phone, tablet and smart TV runs on a modified version of the Linux kernel. So, I guess if you can't beat 'em, join 'em?</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wsl2/w3techs_webservers.jpg">
              <p><img alt="W3Techs Survey on Web OS's, Unix: 71%, Windows: 29%" data-src="assets/img/wsl2/w3techs_webservers.jpg" src="https://l-o-o-s-e-d.net/assets/img/wsl2/w3techs_webservers.jpg">
              </p>
            </a>

            <p>Whether or not its because of Microsoft's good graces or some ulterior motive, I know having an easily accessible Unix-type environment available on Windows has been a godsend for me and for so many other developers.</p>

            <p>
              <h3>What's so great about WSL?</h3>
            </p>

            <div>
              <p>Before WSL, developers running Windows had two options: 1) a virtual machine (VM), or 2) dual-booting. Running a virtual machine uses up more resources than WSL. It can also be difficult to integrate hardware and files between the host machine and the VM. Dual-booting allows for a full-fledged install on a separate disk partition; but it requires a restart any time you want to switch between OS's.</p>
              <p>Windows Subsystem on Linux doesn't integrate with the host's hardware perfectly— for example, NVIDIA is still working on <a target="_blank" href="https://developer.nvidia.com/cuda/wsl">CUDA drivers</a> that will take advantage of GPU resources from within WSL. However, for Linux developers who are frequently running CAD software or Adobe Suite (which are <a target="_blank" href="https://appdb.winehq.org/objectManager.php?iId=17&amp;sClass=application">difficult-to-impossible</a> to install on Linux), WSL can be a fantastic partner.</p>
            </div>

            <p>
              <h3>WSL1 vs WSL2</h3>
            </p>

            <div>
              <p>More recently, Microsoft announced WSL2— an update that allows for a more complete Linux kernel to run on a Windows machine. This made it much easier to install a variety of software that had been difficult to run on the previous, WSL1. WSL2 is very similar to running a virtual machine (in fact it uses Microsoft's hyperV virtual machines).</p>
              <p>However, using WSL2 (as opposed to installing a Linux distro through VirtualBox, or another VM manager) provides some minor performance benefits since Microsoft has optimized it to integrate with Windows' services. If you want, I recommend reading Microsoft's own WSL1-vs-WSL2 <a target="_blank" href="https://docs.microsoft.com/en-us/windows/wsl/compare-versions">feature comparison</a> docs.</p>
            </div>

            <p>
              <h3>Alright, so how do I install WSL2?</h3>
            </p>

            <div>
              <p>Microsoft has clean, straight-forward <a target="_blank" href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">installation documentation</a> for WSL and WSL2. You can refer to that tutorial if you get stuck, or just follow the steps outlined below. Before starting, make sure you update your Windows 10 installation with the most recent build.</p>
              <p>I'll also be going one-step further, and showing you how to run a Linux GUI using WSL2 and VcXsrv (display forwarding). If you're more of a visual-learner, I've also included an installation speedrun <a target="_blank" href="https://www.youtube.com/embed/gtXIzVM5wZE">video</a> that follows the same steps outlined below (<em>edit: I forgot step 11 in the video, and it's a critical one! Make sure you do that!</em>).</p>
            </div>

            <div>
              <p><b>1. Enable WSL Feature</b></p>
              <p>First you need to enable the Windows Subsystem on Linux feature by right-clicking on Powershell from the start menu and clicking "Run as Administrator".</p>
              <p>Then, paste the following command and hit "Enter"— don't close the Powershell!</p>
              <pre><code>dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart</code></pre>
            </div>

            <div>
              <p><b>2. Enable WSL2 Virtual Machine Feature</b></p>
              <p>After the last command is finished, paste the following command in the same Administrator-level shell, and hit "Enter" to enable the WSL2 VM. Again, keep this shell open.</p>
              <pre><code>dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart</code></pre>
            </div>

            <div>
              <p><b>3. Download and Install the WSL2 Linux Kernel Update</b></p>
              <p>Click <a target="_blank" href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">here</a> to download the Microsoft executable for installing the WSL2 Linux Kernel update. Once it's finished downloading, double-click the executable and follow the installation steps. This part's pretty straightforward</p>
            </div>

            <div>
              <p><b>4. Set WSL2 as Default Version</b></p>
              <p>Copy and paste the following command in Powershell to set WSL2 to be the default version:</p>
              <pre><code>wsl --set-default-version 2</code></pre>
            </div>

            <div>
              <p><b>5. Install Ubuntu 20.04 from the Microsoft Store</b></p>
              <p>Click the start menu and open the Microsoft Store. Search for "Ubuntu 20.04" and install this Linux distro. If you want to use another distro, that's fine; but Ubuntu 20.04 is compatible with the Regolith Linux desktop GUI we'll be installing in just a bit.</p>
            </div>

            <div>
              <p><b>6. Ubuntu 20.04 Initial Setup</b></p>
              <p>Once Ubuntu is done installing, click "Launch" to initiate first-time installation setup. You'll be prompted to put in a username and password.</p>
            </div>

            <div>
              <p><b>7. Make sure You're Using WSL2</b></p>
              <p>At this point, it might be a good idea to double-check that WSL is using version 2 by default. Open a command prompt (or use Powershell if it's still open) to paste in the following command:</p>
              <pre><code>wsl --list --verbose</code></pre>
            </div>

            <div>
              <p><b>8. Download and Install VcXsrv</b></p>
              <p>VcXsrv is an X Server that we'll use to view the GUI from WSL2.</p>
              <p>There are a few other display-forwarding servers available (like <a target="_blank" href="https://sourceforge.net/projects/xming/">Xming</a>), but I've found VcXsrv works the best. Download the executable <a target="_blank" href="https://sourceforge.net/projects/vcxsrv/">here</a> and click through the installation steps.</p>
            </div>

            <div>
              <p><b>9. Install Regolith Desktop</b></p>
              <p>I have <a target="_blank" href="https://l-o-o-s-e-d.net/regolith">Regolith Desktop</a> installed on one of my PCs, and it's fantastic. It's preconfigured to use the i3 window manager which I find incredibly efficient for its tiling and hotkey features.</p>
              <p>A <em>loosed</em> reader, Rodrigo, asked me use Regolith for the tutorial; but if you want to install a different GUI you can! To install Regolith Desktop, open your fresh Ubuntu install, and paste in the following lines:</p>
              <pre><code>sudo add-apt-repository ppa:regolith-linux/release</code></pre>
              <pre><code>sudo apt install regolith-desktop i3xrocks-net-traffic i3xrocks-cpu-usage i3xrocks-time</code></pre>
              <p>It's a lot of packages, so it'll take some time.</p>
            </div>

            <div>
              <p><b>10. Change the "Mod" Key</b></p>
              <p>Regolith, or rather i3-wm, uses the Super (Windows) key as the hotkey prefix by default. Since you're running this GUI within Windows, you'll run into a lot of overlap between Windows' and i3-wm's preconfigured shortcuts.</p>
              <p>For this reason, I recommend swapping the Super key for the Alt key. To  change the Mod key mapping use the Vim or Nano text editors to open the configuration file located at:</p>
              <pre><code>vim /etc/regolith/i3/config</code></pre>
              <p>On line 42 and 43, you'll find the Mod key assignment. Switch "Mod1" and "Mod4" and you'll be good to go! Your edited lines should look like this:</p>
              <pre><code>set_from_resource $mod i3-wm.mod Mod1</code></pre>
              <pre><code>set_from_resource $alt i3-wm.alt Mod4</code></pre>
              <p>If you're using Vim, hit "Escape" and type ":wq", then hit "Enter" to write and quit the file. You can check out the <a target="_blank" href="https://regolith-linux.org/regolith-site-r13/docs/howto/super-to-alt/">official Regolith tutorial</a> on making these changes if you get stuck.</p>
            </div>

            <div>
              <p><b>11. Export DISPLAY parameter</b></p>
              <p>Another critical edit (that I forgot to put in the video— oops 🙃) is to export the DISPLAY variable. Since WSL2 is a VM, it has it's own IP address (which can change at each startup). As a result, you'll need to add a couple lines to your bash profile for VcXsrv to connect to WSL2.</p>
              <p>To open your ".bashrc" with Vim:</p>
            </div>
            <div>
              <pre><code>vim ~/.bashrc</code></pre>
              <p>Press and hold Shift then press "G" to jump to the bottom of the file. On two new lines, paste in the following code:</p> 
              <pre><code>export DISPLAY=$(awk '/nameserver / {print $2; exit}' /etc/resolv.conf 2&gt;/dev/null):0<br>export LIBGL_ALWAYS_INDIRECT=1</code></pre>
            </div>

            <div>
              <p><b>12. Open and Configure VcXsrv</b></p>
              <p>Click the start menu and type in "Xlaunch" then hit "Enter" to run VcXsrv. Click the "One window without titlebar" option (you can explore the others later, if you want) and click next. Leave it on "Start no client" and click next. Then, in the "Additional parameters" input, add "-ac" and click next. I recommend clicking "Save configuration" for ease of use.</p>
              <p>At this point, you should have a black screen waiting to accept a display input.</p>
            </div>

            <p><b>13. Run Regolith Desktop</b></p>
            <p>The last thing to do is run the magic line:</p>
            <div>
              <pre><code>i3-gnome-flashback-session</code></pre>
              <p>You should then see a graphical Regolith Desktop appear in the VcXsrv window! Huzzah! Feel free to play around with your new graphical WSL2 setup. To see an overview of the available shortcuts, use "Alt+Shift+?" to bring up the help menu. You can find more help in Regolith's official <a target="_blank" href="https://regolith-linux.org/docs/">documentation</a>.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wsl2/regolith_screenshot.jpg">
              <p><img alt="Regolith Desktop with Windows 10 Taskbar and i3 tiling running on WSL2" data-src="assets/img/wsl2/regolith_screenshot.jpg" src="https://l-o-o-s-e-d.net/assets/img/wsl2/regolith_screenshot.jpg">
              </p>
            </a>

            <p>
              </p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://l-o-o-s-e-d.net/wsl2">https://l-o-o-s-e-d.net/wsl2</a></em></p>]]>
            </description>
            <link>https://l-o-o-s-e-d.net/wsl2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711054</guid>
            <pubDate>Wed, 07 Oct 2020 18:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Translation Units Considered Harmful?]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24710612">thread link</a>) | @ingve
<br/>
October 7, 2020 | https://cor3ntin.github.io/posts/translation_units/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/translation_units/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Let say you have some struct <code>square</code> you want to compute the area of.</p>
<p><code>struct square { int width; }</code></p>
<p>You could of course do that:</p>
<p><code>int area(square s) { return s.width * s.width; }</code></p>
<p>But, your friend Tony told you to use more functions, so instead you do that</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>area</span>(square s) { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(square s) { <span>return</span> s.width; }
</code></pre></div><p><code>area</code> being the function you really care about it is defined first - after all, code reads from top to bottom.</p>
<p>As you may have guessed from the lack of <code>;</code> after the struct’s closing bracket, the above code is written in D.
I figure my readership isn’t really into D, so maybe you would prefer some <strong>Rust</strong>?</p>
<div><pre><code data-lang="rs"><span>pub</span><span> </span><span>fn</span> <span>area</span>(square: <span>Square</span>)<span> </span>-&gt; <span>i32</span> {<span> </span><span>return</span><span> </span>width(s)<span> </span>*<span> </span>width(s)<span> </span>}<span>
</span><span></span><span>pub</span><span> </span><span>fn</span> <span>width</span>(square: <span>Square</span>)<span> </span>-&gt; <span>i32</span> {<span> </span><span>return</span><span> </span>s.width<span> </span>}<span>
</span><span></span><span>pub</span><span> </span><span>struct</span> <span>Square</span><span> </span>{<span> </span>width: <span>i32</span> }<span>
</span></code></pre></div><p>You can even compute the area of you square <strong><em>at scale</em></strong> with go</p>
<div><pre><code data-lang="go"><span>func</span> <span>Area</span>(s square) <span>int</span> { <span>return</span> <span>width</span>(s) * <span>width</span>(s); }
<span>func</span> <span>width</span>(s square) <span>int</span> { <span>return</span> s.width }
<span>type</span> square <span>struct</span> { width  <span>int</span> }
</code></pre></div><p>Or even <strong>Swift</strong>ly.</p>
<div><pre><code data-lang="swift"><span>func</span> <span>area</span>(s: Square) -&gt; <span>Int</span> { <span>return</span> width(s:s) * width(s:s); }
<span>func</span> <span>width</span>(s: Square) -&gt; <span>Int</span> { <span>return</span> s.width }
<span>struct</span> <span>Square</span> { <span>var</span> <span>width</span>:<span>Int</span> = <span>0</span>; }
</code></pre></div><p>But of course, <em>you</em> will worry about the overhead and will want the language the most performant (that’s not a word).
Eager to please and impress, let me copy the D code and add that oh-so-important semi-colon.</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>square</span> { <span>int</span> width; };
<span>int</span> <span>area</span>(square s)  { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(square s) { <span>return</span> s.width; }
</code></pre></div><p>That’s nice, isn’t it?  Interesting how most languages look alike.
Hum, wait, that doesn’t work???!!!</p>
<p><code>error: 'width' was not declared in this scope</code></p>
<p>But, you stupid thing, it’s <em>RIGHT THERE</em>.
I declared everything in the global scope like a maniac, can’t you see?</p>
<p>Alas, the standard makes the compiler blind.</p>
<blockquote>
<p>In the definition of a function that is a member of namespace N, a name used after the function’s declarator-id23 shall be declared before its use in the block in which it is used or in one of its enclosing blocks ([stmt.block]) or shall be declared before its use in namespace N or, if N is a nested namespace, shall be declared before its use in one of N’s enclosing namespaces.</p>
</blockquote>
<p>Of course, this makes no sense, a compiler can really easily parse the declaration independently of the definition, as
proven by other languages. Or you know, C++ classes. (imagine replacing a big namespace with a class full of static methods and nested types)
Unless of course, it’s a performance thing.
But, you are a very great engineer, so you wouldn’t let a source file grow above a few hundred lines of code, would you?
I bet your code is beautiful, like this small self-contained super useful program</p>
<div><pre><code data-lang="cpp"><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span><span></span><span>int</span> <span>main</span> () {
    std::cout &lt;&lt; <span>"Hello world</span><span>\n</span><span>"</span>;
}
</code></pre></div><p>Which on my system expands to about <em>33000</em> lines of code. The freaking thing. But more on that later.</p>
<p>Let’s go back to square one.
C++, in its infinite wisdom, lets us forward-declare functions, so we can write this:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>square</span> { <span>int</span> width; };
<span>int</span> <span>width</span>(<span>const</span> square&amp; s);
<span>int</span> <span>area</span>(<span>const</span> square&amp; s)  { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(<span>const</span> square&amp; s) { <span>return</span> s.width; }
</code></pre></div><p>Which is nice and dandy, if you squint.</p>
<p>Besides requiring you to get the exact declaration of functions perfectly right - which is hard to maintain, lots of entities are not forward-declarable,
notably type alias, templated types, etc.
Which is an odd limitation given that where forward declaring a function require you
to know the precise signature, for types you are merely trying to introduce a name.</p>
<h2 id="noexcept">noexcept</h2>
<p>You will notice that <code>area</code> never throws.
That is, there is no subexpression of <code>area</code> that can throw, ever.</p>
<p>You can check that it does not.</p>
<p><code>static_assert(noexcept(area(square{})));</code></p>
<p>Inevitably,  that fails.
<code>error: static assertion failed</code>.
We indeed forgot to tell the compiler that our function could not throw.</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>width</span>(<span>const</span> square&amp; s) <span>noexcept</span>;
<span>int</span> <span>area</span>(<span>const</span> square&amp; s) <span>noexcept</span> { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(<span>const</span> square&amp; s) <span>noexcept</span> { <span>return</span> s.width; }
</code></pre></div><p>Notice that we need to add <code>noexcept</code> on all declarations, including the forward declarations.
And, you can lie to the compiler pretty easily.</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>area</span>(<span>const</span> square&amp; s) <span>noexcept</span> {
    <span>return</span> width(s) * width(s);
}

<span>int</span> <span>width</span>(<span>const</span> square&amp; s) {
    <span>throw</span> <span>42</span>;
}
</code></pre></div><p>The above code will <code>std::terminate()</code>, you know that the compiler knows that, everybody knows that.</p>
<p>So…what functions should be marked <code>noexcept</code>?
It’s pretty simple actually. All the functions that can not throw.
That is the functions that:</p>
<ul>
<li>Don’t contain a <code>throw</code> exception</li>
<li>Don’t call non-noexcept functions</li>
</ul>
<p>Notice the double (triple?) negative.</p>
<p>So you, as a developer striving to mark all function that can be <code>noexcept</code> as such,
have to walk the call tree recursively until you can ascertain that the call chain will never throw
or actually might (because one callee does throw, or is at a C interface boundary, etc).
One argument against exceptions is that it makes reasoning about control flow harder:
Exceptions more or less force you to reason about the control flow of the whole program at every time.
<code>noexcept</code> is supposed to solve that, but, to put that <code>noexcept</code> keyword confidently, you still need
to do that analyze. The chances you get it wrong are high.
If you write generic code, you will have to tell the compiler that a symbol is noexcept
if all of it’s subexpression is noexcept manually.</p>
<p>And the compiler can not trust you that the function will indeed not throw, so implementers will inject calls to <code>std::terminate</code>
here and there, negating somewhat the performance benefits of marking the function <code>noexcept</code> in the first place.</p>
<p>Let’s rewrite our code using lambda instead</p>
<div><pre><code data-lang="cpp"><span>auto</span> width = [](<span>const</span> square&amp; s) -&gt; <span>int</span> {
    <span>return</span> s.width;
};
<span>auto</span> area = [](<span>const</span> square&amp; s) -&gt; <span>int</span> {
    <span>return</span> <span>width</span>(s) * width(s);
};
</code></pre></div><p>Of course, lambdas cannot be forward declared.
So I had to reorganize the code.</p>
<p>And now, despite the lack of <code>noexcept</code> keyword,
<code>static_assert(noexcept(area(square{})));</code> passes.</p>
<p><strong>What is happening?</strong></p>
<p>It turns out that the compiler is pretty good at knowing which functions are <code>noexcept</code>.
In the case of lambdas, the definition will always be visible to the compiler before any invocation,
so it can implicitly mark it no except and do the work for us. This allowed as part of C++20.</p>
<h3 id="what-does-noexcept-even-mean">What does noexcept even mean?</h3>
<p>I’m not saying that <code>noexcept</code> would not be necessary in an ideal world, because it has more than one meaning
and people use it differently. Notably, <code>noexcept</code> might mean:</p>
<ul>
<li>Do not generate exception handling code for this function</li>
<li>This function does not throw</li>
<li>This function will <em>never</em> throw</li>
</ul>
<p>The first statement is a request for the compiler, the second is an assertion for both the compiler and human readers,
while the last one is exclusively for people.</p>
<p>So <code>noexcept</code> would remain interesting at API boundary as a contract between people even if the compiler could decide
for itself whether the function was actually non-throwing.</p>
<h2 id="transaction_safe">transaction_safe</h2>
<p>The Transactional Memory TS defines the notion of <em>transaction safe expression</em> as follow:</p>
<blockquote>
<p>An expression is transaction-unsafe if it contains any of the following as a potentially-evaluated subexpression (3.2[basic.def.odr]):</p>
</blockquote>
<blockquote>
<ul>
<li>an lvalue-to-rvalue conversion (4.1 [conv.lval]) applied to a volatile glvalue</li>
<li>an expression that modifies an object through a volatile glvalue</li>
<li>the creation of a temporary object of volatile-qualified type or with a subobject of volatile-qualified type</li>
<li>a function call (5.2.2 expr.call) whose postfix-expression is an id-expression that names a non-virtual
function that is not transaction-safe</li>
<li>an implicit call of a non-virtual function that is not transaction-safe</li>
<li>any other <strong>call of a function, where the function type is not “transaction_safe function”</strong></li>
</ul>
</blockquote>
<p>(Emphasis mine)</p>
<p>The details are not important, but, basically, a <code>transaction_safe</code> safe expression is one that doesn’t touch volatile objects.
And only call functions with the same properties.
That’s probably upward of 99% of functions - I suspect the very terrible default exists for compatibility reasons.
The important part is that you have to tag all your functions or hope that the property holds true recursively.
(Like <code>noexcept</code>, you can lie, by marking a function <code>transaction_safe</code> even if a callee is not itself <code>transaction_safe</code>, opening the door to UB).
An issue that seems to hold this TS back.</p>
<h2 id="constexpr">constexpr</h2>
<p><code>constexpr</code> functions are a bit different. The compiler knows what functions are candidate <code>constexpr</code>.
Most of the time it will constant evaluate them regardless of whether they are actually marked as such.
The keyword is required to ensure that the compiler will actually do the constant evaluation when it can and, most importantly,
because removing the constexpr-ness of a function may be a source breaking change - (if that function is called during the evaluation of a <code>constexpr</code> variable).
By its very nature, <code>constexpr</code> implies that <code>constexpr</code> functions are defined somewhere is the TU. And everything not defined in the TU cannot be constant-evaluated.
<a href="https://wg21.link/p1235">A proposal for C++20 proposes to make it implicit in some cases</a></p>
<p>For now, we are left with the following code, and it is on you to use the appropriate qualifiers.</p>
<div><pre><code data-lang="cpp"><span>constexpr</span> <span>int</span> <span>width</span>(square s) <span>noexcept</span> transaction_safe;
<span>constexpr</span> <span>int</span> <span>area</span>(square s) <span>noexcept</span> transaction_safe  { <span>return</span> width(s) * width(s); }
<span>constexpr</span> <span>int</span> <span>width</span>(square s) <span>noexcept</span> transaction_safe { <span>return</span> s.width; }
</code></pre></div><p>As of C++20, <code>constexpr</code> functions can throw. The committee is also considering making <code>new</code> expressions
<code>noexcept</code> by 23 or 26 so we are slowly getting to a place where 95%+ of functions will be both <code>constexpr</code> and <code>noexcept</code>
eligible and will have to be marked manually.</p>
<p><strong>Is there a better way ?</strong></p>

<p>A source file and its included headers form a translation unit.
Multiple translations units form a program.</p>
<p>Sounds simple enough right?
It’s actually <em>simpler</em> than right.</p>
<p>Headers and sources files are a bit of a lie we tell ourselves.
As far as I can tell, the term “header” only appear in the standard as to name the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/translation_units/">https://cor3ntin.github.io/posts/translation_units/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/translation_units/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710612</guid>
            <pubDate>Wed, 07 Oct 2020 17:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C Posix function 'tdelete()' has a memory bug since its inception]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24710605">thread link</a>) | @cee-studio
<br/>
October 7, 2020 | https://www.cee.studio/tdelete.html | <a href="https://web.archive.org/web/*/https://www.cee.studio/tdelete.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="markdown-content">
  <h2 id="tdeletehasabugsinceitsinception">tdelete()'s return values cannot be trusted</h2>
  <p>Latest Update: CVE-1999-0199 was issued for this vulnerability after we presented our argument.
    We applaud MITRE.ORG for sticking to its true mission.
  </p>
    <p>We implemented a map container as a thin wrapper of
        <strong>&lt;search.h&gt;</strong>, a POSIX family functions included in
        libc, in <a href="https://cee.studio/">our Cloud IDE</a> and were caught off 
        guard by the following warning for the return value of <strong>tdelete()</strong>:
    </p><pre><code>    Warning: returning a dangling address.
    # The address-to-be-returned is of a memory-block (start:0x922a070, size:16 bytes) allocated at
    #    file:/tsearch.c::81, 6
    #    file:/prog.c::28, 8
    #    [libc-start-main]
    # The memory-block has been freed at
    #    file:/tdelete.c::45, 2
    #    file:/prog.c::32, 14
    #    [libc-start-main]
    # The memory-block has been freed, and its allocation location could have
    # been distorted by subsequent reuses.
    #
    # Stack trace (most recent call first)
    # [0]  file:/prog.c::32, 14
    # [1]  [libc-start-main]
    https://cee.studio/explanation
</code></pre><p> Here is the
    <a href="https://cee.studio/?bucket=200928-vhV&amp;name=tsearch" target="_blank">live demo</a> to reproduce it.
    </p>

    <p>In <strong>tdelete()</strong>'s man page<sup><a href="#foot_notes">1</a></sup>, the <strong>RETURN
        VALUE</strong> specifies that "tdelete() returns a pointer to the parent of the
        item deleted, or NULL if the item was not found." It seems that
        <strong>tdelete()</strong> can return dangling pointers.
    </p><p>
    In order to verify the warning, we wrote a
    <a href="https://github.com/cee-studio/tdelete" target="_blank">test</a> to
    test both musl libc's and glibc's <strong>tdelete()</strong>.
    The output of the test (as seen below) shows that two dangling pointers
    are returned for each test.

    </p><pre><code>Testing glibc's tdelete
  ...

  call tdelete to delete 2
  &gt;&gt; free(<i>0x7f52e7f503ec</i>)
  tdelete returns <i>0x7f52e7f503ec</i> &lt;-- <i>dangling pointer</i>
  root is 0x7f52e7f50450

  call tdelete to delete 3
  &gt;&gt; free(<i>0x7f52e7f50450</i>)
  tdelete returns <i>0x7f52e7f50450</i> &lt;-- <i>dangling pointer</i>
  root is (nil)

Testing musl libc's tdelete
  ...
    
  call tdelete to delete 2
  &gt;&gt; free(<i>0x7f1d9d9553ec</i>)
  tdelete returns <i>0x7f1d9d9553ec</i> &lt;-- <i>dangling pointer</i>
  root is 0x7f1d9d955450

  call tdelete to delete 3
  &gt;&gt; free(<i>0x7f1d9d955450</i>)
  tdelete returns <i>0x7f1d9d955450</i> &lt;-- <i>dangling pointer</i>
  root is (nil)
</code>
</pre>

    <p>Returning a dangling pointer is dangerous, especially for
        functions included in libc, as dereferencing the dangling pointer
        can cause memory errors and security vulnerabilities. It's evident the
        problematic behavior of <strong>tdelete()</strong> has existed since the
        function's inception.
    </p>

    <p>As pointed out by members of r/C_programming and
        HN, <strong>tdelete()</strong>'s man page on various systems warn
        about the risk of dangling pointers in different but convoluted ways:
    </p>
    <ul>
        <li><a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/tdelete.html">OpenGroup</a></li>
        <p>The <strong>tdelete()</strong> function shall return a pointer to the parent of the deleted node, or an
            unspecified non-null pointer if the deleted node was the root node, or a null pointer
            if the node is not found.
        </p>
        <li>macOS man page:</li>
        <p>The <strong>tdelete()</strong> function deletes a node from the specified binary search tree and returns a pointer
            to the parent of the node that was deleted. It takes the same arguments as tfind()
            and tsearch(). If the node to be deleted is the root of the binary search tree,
            rootp will be adjusted.
        </p>
        <li><a href="https://man7.org/linux/man-pages/man3/tdelete.3.html">Debian buster</a></li>
        <p>
            <strong>tdelete()</strong> returns a pointer to the parent of the node deleted, or NULL if the item was
            not found. If the deleted node was the root node, tdelete() returns a dangling
            pointer that must not be accessed.
        </p>
        <li><a href="https://man.openbsd.org/tdelete#RETURN_VALUES">OpenBSD</a></li>
        <p>
          <strong>tdelete()</strong> returns a pointer to the parent of the deleted node or an
            unspecified non-null pointer if the root node is deleted.
        </p>
    </ul>

    <p>Correctly using the function's return values is counter-intuitive as shown in this
        <a href="https://github.com/cee-studio/tdelete/blob/master/correct_use.c">example</a>.
        It requires a very good understanding of C's memory model and how <strong>tdelete()</strong>
        adjusts the root pointer. To prevent any misuses by less experienced developers,
        we believe the most effective warning as pointed out by u/notaplumber is
        <strong>"the return value of tdelete() should not be relied on at all."</strong>.

        In terms of risk among these systems, OpenBSD's <strong>tdelete()</strong>
        is the safest for developers. Both glibc and musl libc still return
        'legit' dangling pointers that can be dereferenced and therefore leave their
        users more vulnerable.
    </p>

    <p>
    We were lucky because Cee.Studio automatically checks whether all memory
    accesses and pointers violate C's memory model. If we were relying
    on our man page and Google search, we would have introduced use-after-free
    bugs inadvertently.
    </p>

    <p>After being surprised by <strong>tdelete()</strong>'s
        problematic return values, we searched CVE databases with the
        hope that this problem was documented. The search returned no
        such documentation, and we decided to file one. The following
        is the response from cve.mitre.org:
    </p><p><i> Unfortunately, we cannot assign a CVE ID for a documented behavior of
        tdelete. We can assign a CVE ID for an application that accesses the
        dangling pointer in a way that always causes a security-related
        impact. (We cannot assign a CVE ID for a finding that access to the
        dangling pointer is undefined behavior.)</i>
    </p><p>
    MITRE's response is counterproductive to its mission in several ways:
    </p><ol>
        <li>
            The latest glibc and musl libc still return 'legit' dangling
            pointers that could be dereferenced without causing visible
            memory errors.
        </li>
        <li>Many of Legacy OSs' man pages do not warn the user about the dangling pointer risk,
            and CVE# is not just for vulnerabilities in newer OSs.
        </li>
        <li>Many production softwares are NOT developed on the latest OSs.
            Issuing a CVE# would have notified AppSec teams
            so they can to do self-checks as well as warn their developers. Similarly, 
            AppSec companies can add the problem to their checklist.
        </li>
        <li>CVE#s can be issued to existing or future misuses. However, 
            the root cause would still not be addressed, allowing developers to
            introduce more vulnerabilities.
        </li>
    </ol><p>

    The lesson from this example is that employing comprehensive memory access
    violation checking and testing would be a more efficient way to prevent
    memory errors and potential security vulnerabilities.

    </p>

</div></div>]]>
            </description>
            <link>https://www.cee.studio/tdelete.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710605</guid>
            <pubDate>Wed, 07 Oct 2020 17:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generalizing 'jq' and Traversal Systems using optics and standard monads]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24710565">thread link</a>) | @todsacerdoti
<br/>
October 7, 2020 | https://chrispenner.ca/posts/traversal-systems | <a href="https://web.archive.org/web/*/https://chrispenner.ca/posts/traversal-systems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Hi folks! Today I'll be chatting about <strong>Traversal Systems</strong> like <strong>jq</strong> and <strong>XPath</strong>; we're going to discover which properties make them useful, then see how we can replicate their most useful behaviours in Haskell using (almost entirely) pre-ols!existing standard Haskell tools! Let's go!</p>
<h2 id="whats-a-traversal-system">What's a Traversal System?</h2>
<p>First off I'll admit that "Traversal System" is a name I just came up with, you probably won't find anything if you search for it (unless this post really catches on 😉).</p>
<p>A <strong>Traversal System</strong> allows you dive deeply into a piece of data and may allow you to fetch, query, and edit the structure as you go while maintaining references to other pieces of the structure to influence your work. The goal of most Traversal Systems is to make this as painless and concise as possible. It turns out that this sort of thing is <strong>incredibly useful</strong> for manipulating JSON, querying HTML and CSS, working with CSVs, or even just handling standard Haskell Records and data-types.</p>
<p>Some good examples of existing <strong>Traversal Systems</strong> which you may have heard of include the brilliant <a href="https://stedolan.github.io/jq/">jq</a> utility for manipulating and querying JSON, the <strong>XPath</strong> language for querying XML, and the <a href="https://github.com/noprompt/meander">meander</a> data manipulation system in Clojure. Although each of these systems may appear drastically different at a glance, they both <em>accomplish many of the same goals</em> of manipulating and querying data in a concise way.</p>
<p>The similarities between these systems intrigued me! They seem so similar, but yet still seem to share very little in the way of structure, syntax, and prior art. They re-invent the wheel for each new data type! Ideally we could recognize the useful behaviours in each system and build a generalized system which works for any data type.</p>
<p>This post is an attempt to do exactly that; we'll take a look at a few things that these systems do well, then we'll re-build them in Haskell using standard tooling, all the while abstracting over the type of data!</p>
<h2 id="optics-as-a-basis-for-a-traversal-system">Optics as a basis for a traversal system</h2>
<p>For any of those who know me it should be no surprise that my first thought was to look at optics (i.e. Lenses and Traversals). In general I find that optics solve a lot of my problems, but in this case they are particularly appropriate! Optics inherently deal with the idea of diving deep into data and querying or updating data in a structured and compositional fashion.</p>
<p>In addition, optics also allow abstracting over the data type they work on. There are pre-existing libraries of optics for working with JSON via <a href="https://hackage.haskell.org/package/lens-aeson"><code>lens-aeson</code></a> and for html via <a href="https://hackage.haskell.org/package/taggy-lens"><code>taggy-lens</code></a>. I've written optics libraries for working with <a href="https://hackage.haskell.org/package/lens-csv">CSVs</a> and even <a href="https://hackage.haskell.org/package/lens-regex-pcre">Regular Expressions</a>, so I can say confidently that they're a brilliantly adaptable tool for data manipulation.</p>
<p>It also happens that optics are well-principled and mathematically sound, so they're a good tool for studying the properties that a system like this may have.</p>
<p>However, optics themselves don't provide everything we need! Optics are rather obtuse, in fact I wrote <a href="https://leanpub.com/optics-by-example">a whole book</a> to help teach them, and they lack clarity and easy of use when it comes to building larger expressions. It's also pretty tough to work on one part of a data structure while referencing data in another part of the same structure. My hope is to address some of these short comings in this post.</p>
<p>In this particular post I'm mostly interested in explaining a framework for traversal systems in Haskell, we'll be using many standard <a href="https://hackage.haskell.org/package/mtl"><strong>mtl</strong></a> Monad Transformers alongside a lot of combinators from the <a href="https://hackage.haskell.org/package/lens"><strong>lens</strong></a> library. You won't need to understand any of these intimately to get the <em>gist</em> of what's going on, but I won't be explaining them in depth here, so you may need to look elsewhere if you're lacking a bit of context.</p>
<h2 id="establishing-the-problem">Establishing the Problem</h2>
<p>I'll be demoing a few examples as we go along so let's set up some data. I'll be working in both <strong>jq</strong> and <strong>Haskell</strong> to make comparisons between them, so we'll set up the same data in both <strong>JSON</strong> and Haskell.</p>
<p>Here's a funny lil' company as a JSON object:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span>{</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>    <span>"staff"</span><span>:</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>      <span>[</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>        <span>{</span> <span>"id"</span><span>:</span> <span>"1"</span></span>
<span id="cb1-5"><a href="#cb1-5"></a>        <span>,</span> <span>"name"</span><span>:</span> <span>"bob"</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>        <span>,</span> <span>"pets"</span><span>:</span> <span>[</span></span>
<span id="cb1-7"><a href="#cb1-7"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Rocky"</span></span>
<span id="cb1-8"><a href="#cb1-8"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"cat"</span></span>
<span id="cb1-9"><a href="#cb1-9"></a>              <span>}</span><span>,</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Bullwinkle"</span></span>
<span id="cb1-11"><a href="#cb1-11"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"dog"</span></span>
<span id="cb1-12"><a href="#cb1-12"></a>              <span>}</span></span>
<span id="cb1-13"><a href="#cb1-13"></a>            <span>]</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>        <span>}</span><span>,</span></span>
<span id="cb1-15"><a href="#cb1-15"></a>        <span>{</span> <span>"id"</span><span>:</span> <span>"2"</span></span>
<span id="cb1-16"><a href="#cb1-16"></a>        <span>,</span> <span>"name"</span><span>:</span> <span>"sally"</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>        <span>,</span> <span>"pets"</span><span>:</span> <span>[</span></span>
<span id="cb1-18"><a href="#cb1-18"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Inigo"</span></span>
<span id="cb1-19"><a href="#cb1-19"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"cat"</span></span>
<span id="cb1-20"><a href="#cb1-20"></a>              <span>}</span></span>
<span id="cb1-21"><a href="#cb1-21"></a>            <span>]</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>        <span>}</span></span>
<span id="cb1-23"><a href="#cb1-23"></a>      <span>]</span><span>,</span></span>
<span id="cb1-24"><a href="#cb1-24"></a>    <span>"salaries"</span><span>:</span> <span>{</span></span>
<span id="cb1-25"><a href="#cb1-25"></a>        <span>"1"</span><span>:</span> <span>12</span><span>,</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>        <span>"2"</span><span>:</span> <span>15</span></span>
<span id="cb1-27"><a href="#cb1-27"></a>    <span>}</span></span>
<span id="cb1-28"><a href="#cb1-28"></a><span>}</span></span></code></pre></div>
<p>And here's the same data in its Haskell representation, complete with generated optics for each record field.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>data</span> <span>Company</span> <span>=</span> <span>Company</span> {<span> _staff ::</span> [<span>Employee</span>]</span>
<span id="cb2-2"><a href="#cb2-2"></a>                       ,<span> _salaries ::</span> <span>M.Map</span> <span>Int</span> <span>Int</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>                       } <span>deriving</span> <span>Show</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span>data</span> <span>Pet</span> <span>=</span> <span>Pet</span> {<span> _petName ::</span> <span>String</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>               ,<span> _petType ::</span> <span>String</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>               } <span>deriving</span> <span>Show</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span>data</span> <span>Employee</span> <span>=</span> <span>Employee</span> {<span> _employeeId ::</span> <span>Int</span></span>
<span id="cb2-8"><a href="#cb2-8"></a>                         ,<span> _employeeName ::</span> <span>String</span></span>
<span id="cb2-9"><a href="#cb2-9"></a>                         ,<span> _employeePets ::</span> [<span>Pet</span>]</span>
<span id="cb2-10"><a href="#cb2-10"></a>                         } <span>deriving</span> <span>Show</span></span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a>makeLenses '<span>'Company</span></span>
<span id="cb2-13"><a href="#cb2-13"></a>makeLenses '<span>'Pet</span></span>
<span id="cb2-14"><a href="#cb2-14"></a>makeLenses '<span>'Employee</span></span>
<span id="cb2-15"><a href="#cb2-15"></a></span>
<span id="cb2-16"><a href="#cb2-16"></a><span>company ::</span> <span>Company</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>company <span>=</span> <span>Company</span> [ <span>Employee</span> <span>1</span> <span>"bob"</span> [<span>Pet</span> <span>"Rocky"</span> <span>"cat"</span>, <span>Pet</span> <span>"Bullwinkle"</span> <span>"dog"</span>] </span>
<span id="cb2-18"><a href="#cb2-18"></a>                  , <span>Employee</span> <span>2</span> <span>"sally"</span> [<span>Pet</span> <span>"Inigo"</span> <span>"cat"</span>]</span>
<span id="cb2-19"><a href="#cb2-19"></a>                  ] (M.fromList [ (<span>1</span>, <span>12</span>)</span>
<span id="cb2-20"><a href="#cb2-20"></a>                                , (<span>2</span>, <span>15</span>)</span>
<span id="cb2-21"><a href="#cb2-21"></a>                                ])</span></code></pre></div>
<h2 id="querying">Querying</h2>
<p>Let's dive into a few example queries to test the waters! First an easy one, let's write a query to find all the pets owned by any of our employees.</p>
<p>Here's how it looks in <strong>jq</strong>:</p>
<pre><code>$ cat company.json | jq '.staff[].pets[] | select(.type == "cat")'
{
  "name": "Rocky",
  "type": "cat"
}
{
  "name": "Inigo",
  "type": "cat"
}</code></pre>
<p>We look in the <code>staff</code> key, then <em>enumerate</em> that list, then for each staff member we enumerate their cats! Lastly we filter out anything that's not a cat.</p>
<p>We can recognize a few hallmarks of a <strong>Traversal System</strong> here. <strong>jq</strong> allows us to "dive" down deeper into our structure by providing a path to where we want to be. It also allows us to <strong>enumerate</strong> many possibilities using the <code>[]</code> operator, which will forward <strong>each</strong> value to the rest of the pipeline one after the other. Lastly it allows us to <strong>filter</strong> our results using <code>select</code>.</p>
<p>And in Haskell using optics it looks like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>&gt;&gt;&gt;</span> toListOf (staff <span>.</span> folded <span>.</span> employeePets <span>.</span> folded <span>.</span> filteredBy (petType <span>.</span> only <span>"cat"</span>)) company</span>
<span id="cb4-2"><a href="#cb4-2"></a>[ <span>Pet</span> {_petName <span>=</span> <span>"Rocky"</span>, _petType <span>=</span> <span>"cat"</span>}</span>
<span id="cb4-3"><a href="#cb4-3"></a>, <span>Pet</span> {_petName <span>=</span> <span>"Inigo"</span>, _petType <span>=</span> <span>"cat"</span>}</span>
<span id="cb4-4"><a href="#cb4-4"></a>]</span></code></pre></div>
<p>Here we use "toListOf" along with an optic which "folds" over each staff member, then folds over each of their pets, again filtering for "only" cats.</p>
<p>At a glance the two are extremely similar!</p>
<p>They each allow the <em>enumeration</em> of multiple values, in <strong>jq</strong> using <code>[]</code> and in optics using <code>folded</code>.</p>
<p>Both implement some form of <strong>filtering</strong>, <strong>jq</strong> using <code>select</code> and our optics with <code>filteredBy</code>.</p>
<p>Great! So far we've had no trouble keeping up! We're already starting to see a lot of similarities between the two, and our solutions using optics are easily generalizable to any data type.</p>
<p>Let's move on to a more complex example.</p>
<h2 id="keeping-references">Keeping references</h2>
<p>This time we're going to print out each pet and their owner!</p>
<p>First, here's the <strong>jq</strong>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a>$ <span>cat</span> join.json <span>|</span> <span>jq</span> <span>'</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>    .staff[] </span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span>  | .name as $personName </span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span>  | .pets[] </span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>  | "\(.name) belongs to \($personName)"</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span>'</span></span>
<span id="cb5-7"><a href="#cb5-7"></a><span>"Rocky belongs to bob"</span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span>"Bullwinkle belongs to bob"</span></span>
<span id="cb5-9"><a href="#cb5-9"></a><span>"Inigo belongs to sally"</span></span></code></pre></div>
<p>Here we see a new feature in <strong>jq</strong> which is the ability to maintain <strong>references</strong> to a part of the structure for later while we continue to dig deeper into the structure. We're grabbing the name of each employee as we enumerate them and saving it into <code>$personName</code> so we can refer to this later on. Then we enumerate each of the pets and use string interpolation to describe who owns each pet.</p>
<p>If we try to stick with optics on their own, well, it's possible, but unfortunately this is where it all starts to break down, look at this absolute mess:</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>owners ::</span> [<span>String</span>]</span>
<span id="cb6-2"><a href="#cb6-2"></a>owners <span>=</span> </span>
<span id="cb6-3"><a href="#cb6-3"></a>  company <span>^..</span> </span>
<span id="cb6-4"><a href="#cb6-4"></a>    (staff <span>.</span> folded <span>.</span> reindexed _employeeName selfIndex <span>&lt;.</span> employeePets <span>.</span> folded <span>.</span> petName) </span>
<span id="cb6-5"><a href="#cb6-5"></a>    <span>.</span> withIndex </span>
<span id="cb6-6"><a href="#cb6-6"></a>    <span>.</span> to (\(eName, pName) <span>-&gt;</span> pName <span>&lt;&gt;</span> <span>" belongs to "</span> <span>&lt;&gt;</span> eName)</span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a><span>&gt;&gt;&gt;</span> owners</span>
<span id="cb6-9"><a href="#cb6-9"></a>[ <span>"Rocky belongs to bob"</span></span>
<span id="cb6-10"><a href="#cb6-10"></a>, <span>"Bullwinkle belongs to bob"</span></span>
<span id="cb6-11"><a href="#cb6-11"></a>, <span>"Inigo belongs to sally"</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>]</span></code></pre></div>
<p>You can bet that nobody is calling that "easy to read". Heck, I wrote a book on optics and it still took me a few tries to figure out where the brackets needed to go!</p>
<p>Optics are great for handling a <em>single</em> stream of values, but they're much worse at more complex expressions, especially those which require a reference to values that occur <em>earlier</em> in the chain. Let's see how we can address those shortcomings as we build our <strong>Traversal System</strong> in Haskell.</p>
<p>Just for the <strong>jq</strong> aficionados in the audience I'll show off this alternate version which uses a little bit of <em>magic</em> that <strong>jq</strong> does for you.</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a> $ <span>cat</span> company.json <span>|</span> <span>jq</span> <span>'.staff[] | "\(.pets[].name) belongs to \(.name)"'</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span>"Rocky belongs to bob"</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span>"Bullwinkle belongs to bob"</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span>"Inigo belongs to sally"</span></span></code></pre></div>
<p>Depending on your experience may be less <strong>magical</strong> and more <strong>confusing</strong> 😬. Since the final expression contains an <strong>enumeration</strong> (i.e. <code>\(.pets[].name)</code>) <strong>jq</strong> will expand the final term once for each value in the enumeration. This is really cool, but unfortunately a bit "less principled" and tough to understand in my opinion.</p>
<p>Regardless, the behaviour is the same, and we haven't replicated it in Haskell satisfactorily yet, let's see what we can do about that!</p>
<h2 id="monads-to-the-rescue-again">Monads to the rescue (again...)</h2>
<p>In Haskell we love our <strong>embedded DSLs</strong>; if you give a Haskeller a problem to solve, you can bet that 9 times out of 10 they'll solve it with a custom monad and an DSL 😂. Well, I'm sorry to tell you that I'm no different!</p>
<p>We'll be using a monad to address the readability problem of the last optics solution, but the question is... <em>which</em> monad?</p>
<p>Since all we're doing at the moment is <strong>querying</strong> data, we can make use of the esteemed <strong>Reader Monad</strong> to provide a context for our query.</p>
<p>Here's what that last query looks like when we use the <a href="https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Reader.html"><code>Reader</code></a> monad with the relatively …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrispenner.ca/posts/traversal-systems">https://chrispenner.ca/posts/traversal-systems</a></em></p>]]>
            </description>
            <link>https://chrispenner.ca/posts/traversal-systems</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710565</guid>
            <pubDate>Wed, 07 Oct 2020 17:29:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Competition and Quarter-Life Crises]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 88 (<a href="https://news.ycombinator.com/item?id=24710496">thread link</a>) | @arvarik
<br/>
October 7, 2020 | https://www.arvarik.com/competition-quarter-life-crisis | <a href="https://web.archive.org/web/*/https://www.arvarik.com/competition-quarter-life-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Growing up in an Indian household and in one of the most
<a href="https://en.wikipedia.org/wiki/New_Jersey#Demographics">diverse states/towns</a> in the US, it’s not easy to avoid
the competitive stress that derives from first generation families.</p><p>From test scores, which classes I take, SAT scores, college admissions, sports performance, internships received etc.,
the first 22 years of my life have been filled with constant competition with others. As a result I’ve turned out to
be a pretty competitive person - if there was anything that I liked, I not only wanted to be good at it, but I also wanted
to be better at it than others.</p><p>Something happened right around when I graduated college and joined the workforce. My Saturdays were totally free and
weren’t consumed by an all-day track meet where I would compete in the 800m and gruel over two laps trying to edge out
other people over the finish line. After work, my weekday nights consisted of me making dinner instead of living in the
library and taking caffeine pills to study for a test that I’ve been procrastinating to study for. </p><p>For the first time in my life there was no clear next step in what I had to do, and there was no clear competition that
I could engage in with peers. It was a dramatic change and something that I refer to as my quarter life crisis. It’s not
well documented in many places, but it’s a concept that I think is
<a href="https://en.wikipedia.org/wiki/Quarter-life_crisis">picking up steam</a> in recent years.</p><h3>What does a Quarter-Life Crisis look like?</h3><p>I think there’s one song that really encapsulates this feeling, The Beatles’
<a href="https://www.youtube.com/watch?v=8scSwaKbE64">Nowhere Man</a>. The opening lines go:</p><blockquote><p>He's a real nowhere man.
Sitting in his nowhere land.
Making all his nowhere plans for nobody</p></blockquote><p>In fact, the song is what inspired me to name my blog post <strong>Nowhere Plans</strong>. John Lennon was 25 when he wrote this,
and I think he really captures the general feeling of this time in one’s life.</p><p>Back when I was in college and high school I was really competitive with other people, whether in academics or sports,
and I felt I had a strong purpose - anything that I did was to get further in these pursuits. It was a nice and easy
framework to live life by. Decision making was incredibly easy.</p><p>Fast forward to work-life ~&gt; I felt that I couldn’t really relate much to my work peers, and all my college and high
school friends were vibing and doing their own thing in their respective companies. I spent my nights binge watching
shows, my weekends binge watching movies, and my free time working or hanging with peers talking about the binge
watched shows/movies. </p><p>The <a href="https://en.wikipedia.org/wiki/Seattle_Freeze">isolating</a> and incredibly gray city of Seattle didn’t help not
feeling like a nowhere man in nowhere land.</p><p>Maybe I’ll get a cat? Will that help find some purpose to be doing something? I’ll download some dating apps and try to
get a girlfriend, hopefully that should bring me closer to my next stage in life of marriage right? Should I go to grad
school? I have to, no, I need to do these things now! 😬</p><p>I was truly lost in what my next steps in life were going to be, and felt that I was just aimlessly swimming around in a sea of uncertainty.</p><h3>Swimming Out</h3><p>When 2019 had come, I knew I wanted to do something different. I made a list of things that were important to me and that I
wanted to achieve. Visiting friends more, learning to play the piano, getting back into running races, fixing my posture, volunteering etc. </p><p>But the biggest shift in my thinking during this time was to try to bring back competition in my life. No, not competition
with others like I had previously experienced all my life, but instead with something much easier to think about. Myself. </p><p>There’s a saying that you should “Compare yourself to who you were yesterday, not to who someone else is today”. People always
say that you’ll never find happiness comparing yourself to others, and that competitive stress is really bad for you. While that
is true, I also don’t think many people advocate for competition against yourself. It’s possibly because of the stress and
anxiety induced from competition, but if you’re anything like me, it’s necessary to find some purpose and bring back a fire
in you to go about and live life.</p><p>In 2019, I had worked on things I had never done in my life in order to be a better person than who I was in years past.
I’ll probably never be as fit as I was in college on the varsity XC/T&amp;F teams, but hey, in 2019 I
set <a href="https://www.strava.com/athletes/19875553">personal records</a> in
the 10 mile and marathon (granted it was my only time running them but that’s besides the point). </p><p>I also had an entirely different view in perceiving others. Anyone who has spent 5 min on LinkedIn can describe this
feeling - seeing other people who are really successful and do the things that you’ve always want to do is disheartening to
say the least. You feel like somewhere along your life path you made a wrong turn which didn’t lead you to where that other
person is. But, at the end of the day, that’s just life - there’s always going to be someone better than you at everything
you do, you just have to find solace in that you’re better than who you used to be.</p><h3>Where are you now?</h3><p>This past year has been wild. It felt like a decade fit into 9 months so far, but with all the major events and uncertainty
happening, I’ve never felt more certain about myself than I have now.</p><p>I try to focus on things that I really enjoy, and try to be better than my former self. I stopped going to my piano teacher
because of COVID, but still try to play the pieces that I remember learning every now and then while also trying to learn
some more music theory. Writing and deep diving on topics that I find interesting have always been a favorite past-time of
mine, why not start a blog and have others critique me to become better? And finally, if I’m going to make a career out of
my current profession, why not be the best that I can be in more ways than programming. I’ve engaged in more leadership
opportunities to mentor younger engineers and also participate in the daunting interviewing process but this time as an interviewer.</p><p>Through this process I’ve grown to know that I really enjoy helping and teaching others - it’s something that has helped me
envision what I want to be doing as I grow.</p><p>I don’t advise many people to live life with this much analysis on your past self, but if this story resonated with you I
encourage to try it out! It’s helped me get out of a quarter life crisis and will hopefully keep me going until my
inevitable mid-life crisis. Stay tuned for that post.</p></section></div>]]>
            </description>
            <link>https://www.arvarik.com/competition-quarter-life-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710496</guid>
            <pubDate>Wed, 07 Oct 2020 17:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Journey Reviving the SIEM]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24710366">thread link</a>) | @jacknagz
<br/>
October 7, 2020 | https://blog.runpanther.io/streamalert-to-panther/ | <a href="https://web.archive.org/web/*/https://blog.runpanther.io/streamalert-to-panther/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.runpanther.io/content/images/size/w300/2020/10/From-SA-to.jpg 300w,
                            https://blog.runpanther.io/content/images/size/w600/2020/10/From-SA-to.jpg 600w,
                            https://blog.runpanther.io/content/images/size/w1000/2020/10/From-SA-to.jpg 1000w,
                            https://blog.runpanther.io/content/images/size/w2000/2020/10/From-SA-to.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.runpanther.io/content/images/size/w2000/2020/10/From-SA-to.jpg" alt="From StreamAlert to Panther">
            </figure>

            <section>
                <div>
                    <p><em>My Journey Re-Inventing the SIEM for Cloud-First Security Teams </em></p><p>By: <a href="https://www.linkedin.com/in/jacknaglieri/">Jack Naglieri</a></p><p>Five years ago I joined Airbnb’s Security team to create a system for analyzing high volumes of critical security data and identifying suspicious behaviors that could indicate a breach. This system is known as a SIEM, which stands for Security Information and Event Management, and is one of the primary tools used by detection and response teams to secure enterprise environments. </p><p>Over the past 15 years the SIEM market has gone through multiple phases of evolution, from traditional “boxes”, to log analytics platforms, to the cloud-centric solutions offered today. <strong>At Airbnb, we evaluated all of the industry-leading options and ultimately decided to build our own, called <a href="https://github.com/airbnb/streamalert">StreamAlert</a>.</strong> In this blog, I’ll explain the motivation behind that decision and how it inspired me to start <a href="https://runpanther.io/">Panther</a> in August 2018.</p><h2 id="problems-with-siem-a-brief-history-">Problems with SIEM (A Brief History)</h2><p>In the beginning, traditional SIEMs like ArcSight and QRadar were introduced to ingest data and output alerts from built-in detection rules. But for years teams struggled to produce high quality alerts and handle the increasingly larger volumes of data companies produced as they scaled. </p><p>When these limitations became clear, the industry gravitated towards general-purpose log analytics solutions like Splunk, Sumo Logic, and Elastic that were designed for exploration of all types of log data. With some added development work, security teams could use these tools to collect and analyze data for security investigations and threat detection. Eventually, purpose-built SIEM offerings were introduced by these vendors, but the fundamental issues remained: <strong>Their architectures weren’t built for the cloud, and as data volumes and attack surfaces continued to explode, these tools became cumbersome and expensive to operate.</strong></p><p>As we evaluated our options at Airbnb, we felt like the problems with traditional SIEMs had manifested themselves yet again and we were back to square one.</p><h2 id="building-a-new-path-forward">Building a New Path Forward</h2><p>Founded in 2008, Airbnb is a quintessential modern tech company. Its production environment was born in Amazon Web Services and therefore has a very different set of requirements for security. Instead of data centers and on-premise applications, the focus is virtual machines, containers, and SaaS applications that power the business. </p><p>When I joined the Computer Security Incident Response Team (CSIRT) team, <strong>our goal was to build a cloud-native SIEM that could analyze Terabytes of data per day and enable a small team to detect threats faster with more expressivity than was ever possible before. </strong>After learning from our past experiences at other large tech companies (e.g. Facebook, Yahoo, Dropbox), our team decided to take a new approach and <em>not</em> use a log analytics platform. Instead, we set out to use the power of cloud services to avoid the pains of the past and created an open source project called StreamAlert, which I announced at <a href="https://www.youtube.com/watch?v=QVtzMy_tNcQ">Enigma 2017</a>.</p><p>StreamAlert is a serverless, data analysis framework that analyzes logs in real-time. It works by comparing data against Python-based rules and sending alerts when matches are found. StreamAlert addressed many of the challenges we had at the time: It was easy to deploy, could be customized to fit internal business use-cases, and was less expensive to operate than incumbent solutions. <strong>One of the primary ways we drove down costs was by using Serverless technology (or FaaS),</strong> which offers a modern application hosting paradigm where developers can simply provide packaged code and leverage cloud services for orchestration, horizontal/vertical scaling, and reliability. In essence, Serverless is an abstraction above running a container-based application in a platform like Kubernetes or ECS that enables a system to scale with configuration options rather than infrastructure changes.</p><p>For two years I led the development of StreamAlert and helped grow Airbnb’s security engineering team from one to four members, complemented by several analysts. We fostered an open source community, scaled our internal deployment capacity to power Airbnb’s growing incident response (IR) program, and added new features that served both our internal needs and the needs of those in our community. As the project grew, <strong>I continued to see more and more high-tech companies adopting StreamAlert to alleviate the pain they also felt with the status quo for SIEM</strong>. This fueled my desire to work on the problem full-time and take the concept we developed at Airbnb to the next level.</p><h2 id="founding-panther">Founding Panther</h2><p>In 2018, I left Airbnb to start Panther with the goal of redesigning StreamAlert to avoid the pitfalls I had discovered while operating the system at scale. Because StreamAlert is 100% command-line driven, security analysts often struggle to create new detections. In addition, over the years the platform accrued technical debt that’s resulted in issues with its data infrastructure and limited its ability to scale. </p><p><strong>My goal with Panther was to recruit an A-team of engineers to build an Enterprise-grade detection platform that offered an intuitive interface, was designed for 10x scale, and was flexible enough to support the wide range of use cases security teams commonly struggle with today.</strong> </p><p>In early 2020, our team <a href="https://blog.runpanther.io/panther-v1-open-source-siem/">open sourced Panther v1</a>, which incorporates many of the features people love about StreamAlert while also introducing a number of notable improvements, such as:</p><ol><li><strong>A beautiful UI</strong> to write and manage rules, onboard data sources, analyze alerts, query structured data, and configure alert destinations</li><li><strong>Pre-built detections</strong> to identify a variety of suspicious activity across Cloud, SaaS, and endpoint data sources</li><li><strong>A backend written in Golang </strong>capable of processing data at a much higher scale (~10x) at a lower cost</li><li><strong>Support for threat hunting </strong>and interfacing with business intelligence tools</li><li><strong>A pluggable data backend </strong>with support to<strong> </strong>send logs directly into Snowflake</li><li><strong>Faster time to value </strong>with enterprise support and a fully-hosted (single-tenant) SaaS offering</li></ol><p><strong><strong>One of my foundational beliefs is that security teams should focus on detecting the bad guys, not operations. With Panther, more security teams can make this a reality.</strong></strong></p><h2 id="security-at-cloud-scale">Security at Cloud-Scale</h2><p>The world is shifting from analysts and dashboards to automation and code. By enabling security teams to operationalize massive volumes of security data with cloud-first architectures and developer-driven workflows, I believe Panther can serve as the foundation for modern organizations to quickly bootstrap detection and response programs and secure cloud environments. </p><p><strong>Today, Panther is a dedicated team of 20+ people and we <a href="https://blog.runpanther.io/series-a-funding/">just raised $15M</a> to keep growing.</strong> The platform already supports a wide variety of use cases and data integrations and is well-positioned to innovate quickly on new ideas from our community. A few recent features we’re excited to introduce include:</p><ol><li><strong>Indicator Search</strong>: Quickly search all of your data for hits on IPs, domains, hashes, and more.</li><li><strong><strong><strong>Rule Thresholds</strong>: </strong></strong>Only send an alert if a threshold has been exceeded within a time period, which is useful when looking at groups of events over time.</li><li><strong><strong>Alert Statuses</strong>: </strong>Triage, close, or resolve generated alerts along with having confidence that your alert made it to its destination.</li></ol><p>If you’re interested in learning more about upcoming features, check out our <a href="https://portal.productboard.com/runpanther/1-product-portal/tabs/2-in-progress">public roadmap.</a></p><p>My goal when starting Panther was to help all security teams deploy a SIEM that works at a modern scale. <strong>My time at Airbnb taught me that it was possible to decommission older platforms like Splunk in favor of new tools that follow the cloud-native paradigm validated by StreamAlert, and now Panther.</strong> Panther is the next step in this journey, and I’ve incorporated all of the lessons learned from my time at Airbnb and combined it with the diverse backgrounds of my engineering team. </p><p>I’m truly proud of what we’ve built thus far and what we’ll continue to build in the future. We’ll relentlessly push the traditional boundaries of SIEM to help teams prevent breaches at a cloud-scale.</p><p><strong>To see for yourself, <a href="https://docs.runpanther.io/quick-start">Run Panther</a>!</strong></p>
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.runpanther.io/streamalert-to-panther/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710366</guid>
            <pubDate>Wed, 07 Oct 2020 17:12:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wrote a new tool in Rust to convert M4A’s to MP3’s]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24709396">thread link</a>) | @WardyJP
<br/>
October 7, 2020 | http://johnward.net/2020/10/i-wrote-a-new-tool-in-rust-to-convert-m4as-to-mp3s/ | <a href="https://web.archive.org/web/*/http://johnward.net/2020/10/i-wrote-a-new-tool-in-rust-to-convert-m4as-to-mp3s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://johnward.net/2020/10/i-wrote-a-new-tool-in-rust-to-convert-m4as-to-mp3s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24709396</guid>
            <pubDate>Wed, 07 Oct 2020 15:46:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ur-Technical Debt]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24708472">thread link</a>) | @zdw
<br/>
October 7, 2020 | https://www.georgefairbanks.com/ieee-software-v32-n4-july-2020-ur-technical-debt | <a href="https://web.archive.org/web/*/https://www.georgefairbanks.com/ieee-software-v32-n4-july-2020-ur-technical-debt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
	





<p>This column was published in <a href="https://ieeexplore.ieee.org/document/9121630">IEEE Software, The Pragmatic Designer column</a>, July-August 2020, Vol 37, number 4.</p>

<blockquote>
  <p>ABSTRACT:  The term <em>technical debt</em> was coined by Ward Cunningham in 1992.  In recent years, people have broadened the definition to include ideas not present in the original formulation, including lack of skill, expedient hacking, and obliviousness to software architecture.  By lumping these together, it’s harder to choose the right repair. This article proposes that we use the term <em>ur-technical debt</em> to refer to the original idea, which was:  When I build systems iteratively, my understanding of the problem and solution grow gradually, and inevitably my current thoughts do not match code I wrote earlier, so I must expend effort to fix that code, much like paying interest on a debt.</p>
</blockquote>

<!--break-->

<hr>

<p>These days, everyone uses the term technical debt.  It’s so prevalent that we shorten it to <em>tech debt</em> or even just <em>TD</em>.  What counts as technical debt has expanded over the years, which has caused many people to lose sight of the interesting phenomena that Ward Cunningham was talking about when he coined the term in 1992.  Today, any code that a developer dislikes is branded as technical debt.  Tech debt is also hacky code, code written by novices, code written without consideration of software architecture (so-called “big balls of mud”), and code with anti-patterns flagged by static analysis tools.</p>

<p>If you have never read Ward Cunningham’s original paper [1], you might be shocked to learn that it says tech debt originates from using iterative instead of waterfall development.  At the time, refactoring was not a widespread idea, so he invented the debt metaphor to explain to his manager that building iteratively gave them working code faster, much like borrowing money to start a project, but that it was essential to keep paying down the debt, otherwise the interest payments would grind the project to a halt.  That idea is quite different than what we call tech debt today.</p>

<p>It’s easy to understand why the definition has been broadened.  These other topics are worthy of study, they are technical, and the metaphor of debt applies.  Our community has accepted that tech debt is something to pay attention to, so saying an issue is a kind of technical debt is a way to draw people in.</p>

<p>When you set out to pay down your technical debt, having a narrow definition of technical debt is helpful because different ailments require different medicine, and lumping many ailments together makes it harder to choose the right medicine.  The momentum behind the current, broad definition is too strong to be turned back, so, by adding the prefix <em>ur-</em> that means “original”, I can refer to the narrower idea as <em>ur-technical debt</em>.</p>

<h2 id="the-original-idea">The original idea</h2>

<p>What is the original idea, exactly?  Simply put, ur-technical debt arises when my ideas diverge from my code.  That divergence is inevitable with an iterative process.  The original paper connects your software process choices (waterfall or iterative) with financial concepts.  Given that you have some amount of time to build something, say a year, how can you use that time?</p>

<p>When you choose an iterative process, you use that time to deliver several partial solutions.  You don’t understand the full requirements until the last iteration, so for most of the year, the ideas in your head are partial.  The code embodies your partial understanding because it cannot be more insightful than the ideas in your head.  The original paper argues that this is ok, so long as you don’t leave the code in that state forever, and introduces the debt metaphor:  “Shipping first time code is like going into debt. A little debt speeds development so long as it is paid back promptly with a rewrite.” [1]</p>

<p>When you choose the waterfall process, you are using the time to aim carefully and hit your target a year down the road.  Your ideas from the analysis phase match your code because you looked at all the requirements at once and wrote code just once.  The original paper says “working out a program in detail before programming begins … amounts to preserving the concept of payment up-front and in-full.”</p>

<p>Why put up with divergence or rework existing code when waterfall promises code aligned with ideas? Because a waterfall process only looks good if you believe that what you build will be flawless and the requirements will not change.  If either of those happen, then you need a second waterfall, which is just another name for very slow iterative development.</p>

<p>The original paper argued the point this way:  “We believe this process leads to the most appropriate product in the shortest possible time. … The modularity offered by objects and the practice of consolidation make the alternative, incremental growth, both feasible and desirable …”</p>

<h2 id="consolidation-is-critical">Consolidation is critical</h2>

<p>As you tackle new requirements, your understanding changes.  Ward Cunningham called this “consolidation” of ideas.  New abstractions emerge, either arising from better understanding of the problem or recognizing a more suitable design as the solution.  When using iterative development, this consolidation happens repeatedly across iterations.  “Mature sections of the [WyCash] program have been revised or rewritten many times providing the consolidation that is key to understanding and continued incremental development.” [1]</p>

<p>When we use iterative development, it’s inevitable that our ideas will evolve.  What’s not inevitable is that we change the code to match our ideas.  Some developers choose to leave existing code alone, following a process of code accretion, or to coin another term, <em>sedimentary development</em>.  For a while, you can apply brainpower to reason across the gap between what you understand compared to what you see in the code.  But your mind has limits and the greater the divergence, the worse you perform.  “[I]f you develop a program for a long period of time by only adding features and never reorganizing it to reflect your understanding of those features, then eventually that program simply does not contain any understanding and all efforts to work on it take longer and longer.” [2]</p>

<p>Choosing sedimentary development as a process is walking into a dead-end.  I often hear lip service to refactoring and expensive restructuring of code, but I rarely find teams that earnestly embrace Ward Cunningham’s advice.  Teams instead rely on developers reworking code on the side or as off-schedule work, not choosing to make refactoring part of their official process.  A software project that follows iterative development but has no process to restructure code is implicitly declaring bankruptcy as its exit strategy.</p>

<p>Companies often advise employees not to write anything in email that they would feel uncomfortable having read back on the witness stand in a trial.  That’s a vivid image that encourages clear communication that can’t easily be taken out of context and misunderstood.  It would be interesting to hear companies say the same thing about code, advising us not to check in code we’d feel uncomfortable being used to teach programming.  That might be exactly the vivid image we need to keep our ideas and code consolidated.</p>

<h2 id="its-not-about-hacking">It’s Not About Hacking</h2>

<p>Ward Cunningham is known for many ideas, not just technical debt.  You might know him as a ringleader in the Agile software development movement, or for his role in introducing patterns to software development, or for inventing the first wiki.  In 2011, the IEEE interviewed him for the Annals of the History of Computing and the topic of technical debt never came up [3].  However, the idea of technical debt has piqued the interest of the software community over the years, to the point where in 2009 he decided to post an explanation of what he meant by technical debt and contrast it with broader interpretations [2].</p>

<p>In that explanation, he says that technical debt is not bad code, code written by novices, or expedient hacks.  “A lot of bloggers at least have explained the debt metaphor and confused it, I think, with the idea that you could write code poorly with the intention of doing a good job later and thinking that that was the primary source of debt.”  By saying primary source, he’s leaving the door open that there is more than one source of debt, but he doesn’t open it much, as he continues with “I’m never in favor of writing code poorly, but I am in favor of writing code to reflect your current understanding of a problem even if that understanding is partial.”</p>

<p>If you knowingly write hacky code, or you allow inexperienced developers to use their first draft code, you undermine the very thing that makes iterative development viable.  “In other words, the whole debt metaphor, let’s say, the ability to pay back debt, and make the debt metaphor work for your advantage depends upon your writing code that is clean enough to be able to refactor as you come to understand your problem.”</p>

<p>The fascinating, surprising thing about ur-technical debt is that it happens even under the best circumstances, say with expert developers who always choose to fix debt immediately.  It’s inherent to using an iterative process and acting with a partial understanding.  Expanding the definition of technical debt to less ideal circumstances yields a completely unsurprising conclusion, that novices and hacking cause trouble on a project.</p>

<h2 id="its-not-about-decision-making">It’s Not About Decision Making</h2>

<p>These days, most everyone uses iterative development.  Once I start down that path, I am committed to creating technical debt because I am looking at partial requirements and writing code with partial understanding. Like Oedipus, my fate is sealed, and despite my best efforts and accumulated skills, I’m destined to want to gouge my eyes out when I look at my code in a future iteration.</p>

<p>The surprising insight is that doing this counter-intuitive thing – building a system based on partial understanding and fixing debt as I proceed – is better than using a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.georgefairbanks.com/ieee-software-v32-n4-july-2020-ur-technical-debt">https://www.georgefairbanks.com/ieee-software-v32-n4-july-2020-ur-technical-debt</a></em></p>]]>
            </description>
            <link>https://www.georgefairbanks.com/ieee-software-v32-n4-july-2020-ur-technical-debt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708472</guid>
            <pubDate>Wed, 07 Oct 2020 14:18:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust and Raspberry Pi Tide Clock]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24708345">thread link</a>) | @zdw
<br/>
October 7, 2020 | https://thefuntastic.com/blog/rust-tide-clock | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/rust-tide-clock">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-6f4ff34b=""><p><em>In this part 1 of 2 posts, I share the process of a heartwarming maker project built on top of Raspberry Pi and Rust. It's more a story than a how-to guide, but provides an interesting chronology of problems encountered. In part 2 I'll be getting technical and discussing Rust in-depth. Source code for this project can be found on <a href="https://github.com/thefuntastic/rust-tide-clock" target="_blank" rel="nofollow noopener noreferrer">Github</a></em></p>
<p>I had the good fortune to spend my summer with Alice's family who had recently moved to a seaside town. Tim, the patriarch of the family, was distraught to learn that, out of his impressive array of nautical implements, his tide clock readings were never accurate. This is the story of how we built him a surprise 60th birthday present he'd never forget: </p>
<p><img src="https://thefuntastic.com/blog/2020-09-25-Tide-Clock-12.jpg" title="Picture completed Tide-Clock"></p>
<h2 id="the-problem-with-tides">The Problem with Tides</h2>
<p>Most people understand the moons gravitational pull causes a regular ebb and flow in water levels. Those concerned with the sea will likely recite 6 hours and 10-ish minutes as the duration between low and high tide. Consider a wristwatch or wall clock, most mechanical timepieces already track a daily period of 12 hours. With a small adjustment to gearing ratios, it would be easy enough to build a clock that reports instead the tidal cycle of 12 hours and 25 minutes. Indeed this is how most ornamental tide clocks work. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Wikipedia-Tide-clock.jpg" title="Picture of tide clock - Wikipedia"></p>
<p>I was surprised, however, to learn <a href="http://www.coastalwiki.org/wiki/Tidal_asymmetry_and_tidal_basin_morphodynamics" target="_blank" rel="nofollow noopener noreferrer">tides can be asymmetric</a>! Instead of six hours, it might take the tide seven hours to come in and five hours to go out again. Local environmental factors like the shallowness of an estuary basin can have a pronounced effect on tidal regularity. In extreme places, like the Gulf of Mexico, this can be enough to reduce the regular cycle from four tides a day to just two. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-25-Tide-Graph.png" title="WorldTides.info graph of tide station in the Gulf of Mexico showing asymmetry changing to produce single daily tide"></p>
<p>A disaster for the clockmaker! This asymmetry also changes with the lunar cycle, so it's not even possible for a mechanical clock to be consistently wrong. It makes intuitive sense if you think about it. Water is "stuff". When the tide changes that stuff has to go somewhere. If something makes it hard for stuff to move about, like say sandbars in a shallow basin, it's going to make the stuff pile up. The bigger the change in stuff, like say near spring tide, the more piling up is going to happen. If that stuff is still hanging about when the tide changes, the net effect is going to be an asymmetric tide.</p>
<h2 id="making-with-embedded-devices">Making with Embedded Devices</h2>
<p>To my mind, this was the perfect application for an internet-of-things powered device. By outsourcing the problem and fetching data from an API it meant the source of truth would always be accurate. Furthermore, a digital display could accurately visualise the asymmetric ebbs and floods.</p>
<h3 id="on-choosing-raspberry-pi">On choosing Raspberry Pi</h3>
<p>Initially, I considered using an Arduino, as I already had one knocking about my toolbox, together with a compatible LED screen. Ultimately I chose the path of least resistance because the Raspberry Pi comes with an integrated WiFi chip. Unlike the Arduino, the Pi is a mini-computer running an entire operating system. This is the sledgehammer approach, but has advantages considering the project would eventually live in the hands of someone unfamiliar with embedded tech. If the WiFi connection were to drop or need changing, logging onto a desktop would be a much friendlier experience. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-21.jpg" title="Raspbian Desktop Interface running on Raspberry Pi"></p>
<p>Having settled on a Raspberry Pi build, the next job was to find a suitable display. Considering tides change relatively slowly, it was tempting to use an e-ink display for crazy power efficiency. That might be necessary if the clock was battery-powered, however, the need to keep the Pi running meant we were already committed to a plug-in power supply. In the end, I choose the 128x32 pixel <a href="https://thepihut.com/collections/waveshare/products/128x32-2-23inch-oled-display-hat-for-raspberry-pi" target="_blank" rel="nofollow noopener noreferrer">Waveshare 1305</a>. Its convenient "hat" form factor meant no soldering. Also, OLED looks crazy good compared to the standard LED screen I already had. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-3.jpg" title="Waveshare OLED screen shown attached to Raspberry Pi"></p>
<h3 id="on-choosing-rust">On Choosing Rust</h3>
<p>At this point, I was still unsure of which programming language to use. Whilst the Raspberry Pi can run anything that compiles to Linux, communication to the screen happens through the Pi's <code>GPIO</code> pins (<a href="https://en.wikipedia.org/wiki/General-purpose_input/output" target="_blank" rel="nofollow noopener noreferrer">General Purpose Input/Output</a>). All information is transmitted by setting pins high and low and feels reminiscent of working on Arduino and other embedded platforms. Even though the screen is just 128x32 (aka 4096) pixels, that's far more destinations than the Pi's 40 <code>GPIO</code> pins can individually address. Fortunately protocols, in this case <code>SPI</code>, exist to pack data into compressed blocks which can be sent over the limited bandwidth of the IO pins. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-31.jpg" title="Raspberry Pi 3 GPIO Pins"></p>
<p>The screen manufacturer-provided <a href="https://www.waveshare.com/wiki/2.23inch_OLED_HAT#Demo_codes" target="_blank" rel="nofollow noopener noreferrer">3 code samples</a>: 1 written in python and 2 written in C. Python was my immediate choice, given the online nature of the project, however, I simply couldn't get it to work. The two C samples were curious. One was built on top of a bring-your-own driver for the embedded Broadcom chip that controls <code>GPIO</code> pins. The other was written on top of <a href="https://github.com/WiringPi/WiringPi" target="_blank" rel="nofollow noopener noreferrer"><code>wiringPi</code></a>, which ships with Raspbian (aka the Pi flavoured Linux OS) and seems to be the blessed path for doing IO. However, I was saddened to learn this open source project was largely the efforts of a single person who has since <a href="http://wiringpi.com/wiringpi-deprecated/" target="_blank" rel="nofollow noopener noreferrer">stepped down as a maintainer</a> due to open source burnout. It's a worrying trend I'm seeing a lot lately. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-4.jpg" title="Waveshare OLED screen showing Hello World"></p>
<p>Despite the above, the current <code>wiringPi</code> sample still works well. In theory I'm sure it would have been absolutely possible to complete the rest of the project in C. As a language though, C tends to come batteries-not-included. The prospect of stumbling my way through image processing, data parsing, fetching URLs and date-time munging did not fill me with joy, especially given my rudimentary C experience. I'd much rather be building sand-castles in a play pit that didn't require me to build my shovel first.  </p>
<p>I've been "Rust-curious" for a long time, and it's done a great job of establishing itself as <strong>an alternative for workloads where C was historically the only viable candidate </strong>(high performance or memory-constrained). That it does so without forsaking a first-class developer experience is one of the many reasons it's become such <a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages" target="_blank" rel="nofollow noopener noreferrer">a beloved language</a>. Through the package manager, <code>cargo</code>, I'd have a thriving ecosystem of 3rd party libraries (aka crates) within arms reach. Indeed, I quickly found <code>rppal</code> (<a href="https://github.com/golemparts/rppal" target="_blank" rel="nofollow noopener noreferrer">Raspberry Pi Peripheral Access Layer</a>), a Rust crate to manage <code>GPIO</code>.</p>
<pre>

<span>[</span><span>dependencies</span><span>]</span>
<span>image</span> <span>=</span> <span>"0.23.8"</span>
<span>chrono</span> <span>=</span> <span>"0.4"</span>
<span>serde</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"1.0"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"derive"</span><span>]</span> <span>}</span>
<span>serde_json</span> <span>=</span> <span>"1.0"</span>
<span>toml</span> <span>=</span> <span>"0.5"</span>
<span>ordered-float</span> <span>=</span> <span>"2.0"</span>
<span>reqwest</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.10"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"json"</span><span>]</span> <span>}</span>
<span>tokio</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.2"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"full"</span><span>]</span> <span>}</span>
<span>simple-error</span> <span>=</span> <span>"0.1.9"</span>

<span>[</span><span>target.'cfg(target_arch="arm")'.dependencies</span><span>]</span>
<span>rppal</span> <span>=</span> <span>"0.9.0"</span></pre>
<p>There were also plenty of reasons <strong>not</strong> to choose Rust. Scant few weeks remained until the birthday party; if we were going to pull off the surprise it meant sticking to a very aggressive timeline. <code>rppal</code> is not a port of <code>wiringPi</code>, the <code>SPI</code> protocol implementation details might differ in subtle but fundamental ways, enough to bork the entire endeavour. Rust's borrow checker is infamously unforgiving to the uninitiated (it's a bit of an arsehole really). If I was being a responsible lead I'd probably command the troops to trudge on with C. But hack projects really should be about personal edification. So sod it, how hard could it be? </p>
<h2 id="programming-the-app">Programming the App</h2>
<p>Lets just say I got a beating, the likes of which demand a doughnut-shaped cushion afterwards. Rust's learning curve is notoriously steep, and hoping to grok it on such a tight schedule was perhaps optimistic. To Rust's credit, there are plenty of escape hatches to get yourself out of (or into) trouble. This is useful when writing your own code, but by consuming 3rd party libraries you're expected to be more fluent with "idiomatic Rust". </p>
<p><em>(Stay tuned for part 2 where I'll discuss my technical first impressions of Rust)</em>.</p>
<p>Idiomatic understanding is difficult to rush, as it requires a breadth of exposure. I'd fare better now, but as my first-touch point I simply couldn't figure out how I was meant to consume the <code>rppal</code> library. Combing the changelog revealed a big refactor towards a <strong>more</strong> idiomatic and Rust-like API. By reverting to an earlier <strong>less</strong> idiomatic version I'd found a cheeky get out of jail card. Breakthrough, at last, a single pixel signalled business time. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-5.jpg" alt="The happiest pixel" title="Displaying single pixel"></p>
<h3 id="interface-and-ui">Interface and UI</h3>
<p>Now that drawing was possible, the next question was a matter of <em>what</em> to draw? In answer, I cracked open a pixel editor and performed a design sprint in miniature. Several iterations later I had a single image that served as my "design document". </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-6.jpg" title="Designing in the pixel editor"></p>
<p>That's a great example of why this project was so much fun. The problem space left room to flex muscles in every layer of abstraction, whilst being constrained enough to avoid becoming an onerous chore. Font rendering is another example. By using the old school technique of copying slices from a sprite sheet I didn't have to bother myself with font files or font rendering libraries.   </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-7.jpg" title="Designing the font. First on paper, then on screen"></p>
<p>To help me copy slices I relied on the <code>image</code> crate. Again there was a high degree of fumbling to get my head around the API, but once I did I was very impressed by the quality of the library. Even if the ecosystem is still technically maturing, the quality already on display announces Rust's arrival as a serious contender. </p>
<pre>

 
<span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>)</span> <span>-&gt;</span> <span>Font5</span> <span>{</span>
    <span>let</span> p <span>=</span> <span>Path</span><span>::</span><span>new</span><span>(</span><span>"resources/Font-5px.png"</span><span>)</span><span>;</span>

    <span>let</span> img <span>=</span> <span>image<span>::</span></span><span>open</span><span>(</span>p<span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>.</span><span>to_rgb</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> <span>mut</span> faces <span>=</span> <span>HashMap</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    faces<span>.</span><span>insert</span><span>(</span><span>'1'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'2'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>2</span><span>,</span> <span>0</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'3'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>6</span><span>,</span> <span>0</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>...</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'X'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>95</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'Y'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>99</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'Z'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>103</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>

    <span>Font5</span> <span>{</span> faces <span>}</span>
<span>}</span></pre>
<p>Up till now, I had been doing all the development directly on a Raspberry Pi 3. It worked well enough, but I was sorely missing the quality of life features I could enjoy in a full developer environment. The <code>image</code> crate was convenient enough that I started using it for other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/rust-tide-clock">https://thefuntastic.com/blog/rust-tide-clock</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/rust-tide-clock</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708345</guid>
            <pubDate>Wed, 07 Oct 2020 14:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A plain-text eisenhower matrix with end-to-end encrypted sync]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24708258">thread link</a>) | @slymax
<br/>
October 7, 2020 | https://slymax.com/eisenhower | <a href="https://web.archive.org/web/*/https://slymax.com/eisenhower">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div><p><span>Do Now</span><span>Important and Urgent</span></p></div><div><p><span>Do Next</span><span>Important but not Urgent</span></p></div><div><p><span>Delegate</span><span>Urgent but not Important</span></p></div><div><p><span>Delete</span><span>Neither Important nor Urgent</span></p></div>
        <div id="popup">
            <p><span id="close">+</span>
            <img src="https://slymax.com/security.svg" alt="security"></p><p>Create a free account to enable end-to-end encrypted sync accross all your devices.</p>
            <p><a href="https://slymax.com/dashboard">SIGNUP / LOGIN</a>
        </p></div>
        
    </div></div>]]>
            </description>
            <link>https://slymax.com/eisenhower</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708258</guid>
            <pubDate>Wed, 07 Oct 2020 14:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete AWS Lambda Handbook for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24708237">thread link</a>) | @maridashbird
<br/>
October 7, 2020 | https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/ | <a href="https://web.archive.org/web/*/https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Welcome to the Serverless world. One of the first things you’ll hear about is AWS Lambda - and you’ll continue to keep hearing about it! While architecture can be serverless without Lambdas involved, it’s very often the key component within a serverless application. In the first post of this 3-part AWS Lambda Handbook series, we run through what is AWS Lambda, dialling back to basics with the various terminology, how to create a Lambda function and how to run it.&nbsp;</p>
<blockquote>
<p>Read <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-2/">Part 2</a> and <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-3/">Part 3</a></p>
</blockquote>
<h2 id="what-is-aws-lambda-and-what-does-it-do">What is AWS Lambda, and what does it do?</h2>
<p>AWS Lambda is an event-driven serverless compute platform, spinning up the service in response to an event - find out more about Lambda triggers in <a href="https://dashbird.io/blog/complete-guide-lambda-triggers-design-patterns-part-1/">part 1</a> and <a href="https://dashbird.io/blog/complete-guide-lambda-triggers-design-patterns-part-2/">part 2</a> of our Complete Guide to Lambda Triggers series. Your code simply sits there as a file while AWS keeps a lookout for the trigger event you’ve set. When that event occurs, your code is executed and the required operations are carried out. It’s deemed ‘serverless’ because the server doesn’t exist until the user goes out to look for it - this is the epitome of <a href="https://dashbird.io/blog/what-is-faas-function-as-a-service/">Function-as-a-Service (FaaS)</a>.</p>
<p>Another bonus to Lambda is it’s auto-scalability managed by AWS, meaning you don’t need to think about infrastructure. The service will automatically accommodate growing needs and likewise, will scale down to conserve resources. All of this makes AWS Lambda a great solution to reduce waste of resources and budget.&nbsp;</p>
<h2 id="aws-lambda-definitions-explained">AWS Lambda Definitions Explained</h2>
<p>Before getting into how to set up and configure Lambda, below are definitions and terminology commonly used and spoken about.</p>
<p>Lambda Function: a group of related statements that perform a specific task in your application. It consists of code and any dependencies that are associated with it. Each Lambda function has its associated configuration information (name, description, entry point, and resource requirements).</p>
<p>The function itself has the following important aspects associated with it:</p>
<ol>
<li>
<p>Trigger: A set of activities which invokes the function (runs the code you provide). The activity could be anything like a new object coming to your S3 bucket, a website or a service going down, an API call, etc.</p>
</li>
<li>
<p>The actual function: This is the run-time code that constitutes the function. AWS supports Python, Node.js, C#, Go and Java8 as runtime environments.&nbsp;</p>
</li>
<li>
<p>Resources: Each function can be assigned certain Roles, which grants the function certain privileges such as reading S3 bucket contents, writing results to a database and so on.</p>
</li>
</ol>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/1aws-lambda-api-gateway-trigger.png" alt="AWS Lambda anatomy" title="AWS Lambda anatomy"></p>
<p>The triggers are shown to the left, and in this case an API gateway trigger is active. The resources are shown on the right, which in this case, are CloudWatch Logs and DynamoDB.</p>
<p>Event Sources: an entity that publishes events. An event source can be an AWS service or developer-created application that produces events that trigger a function to run.</p>
<p>Invocation: an invocation is called up to execute a specific Lambda function. These are triggers for the code of the function to start running. Invocations can be either <a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-options.html">synchronous or asynchronous</a>.</p>
<p>Event Source Mapping: a configuration of AWS services in which an event source is tied to a specific Lambda function. It enables automatic invocation of a Lambda function when specific events occur.</p>
<p>Lambda Execution Model: When you create a Lambda function, you can specify configuration information, such as the amount of memory and maximum execution time that you allow for your function. When that function is invoked, AWS Lambda launches an <a href="https://docs.aws.amazon.com/lambda/latest/dg/running-lambda-code.html">Execution Context</a> based on the configuration settings you have provided.</p>
<p>Cold Starts: A cold start happens when a Lambda function is invoked after not being used for an extended period of time, which results in increased invocation latency (more on this later).</p>
<h2 id="aws-lambda-configuration-elements">AWS Lambda Configuration Elements</h2>
<p>A Lambda function consists of the code and associated dependencies, and it also has configuration information within it. An API is also provided so you can update some of the configuration data. Lambda function configuration information comes with these critical elements:</p>
<ul>
<li>
<p>Calculating the required resources: specifying the amount of memory that you wish to allocate for your Lambda function. AWS Lambda allocates CPU power in proportion to the memory by the same ratio as a general-purpose AWS EC2 instance type, like an M3 type.&nbsp;</p>
</li>
<li>
<p>Maximum execution time (timeout): specified to prevent the Lambda function from running non-stop. Since you’re paying for the AWS resources that are used to run your Lambda function, this is particularly important. Upon reaching the timeout, AWS Lambda is terminating the execution of your Lambda function. The recommended setting is valued upon the expected execution time.</p>
</li>
<li>
<p>IAM role (execution role): the role that AWS Lambda performs on your behalf when executing a Lambda function.</p>
</li>
<li>
<p>Handler name: the method of entry point that runs your code with any event source dependencies included as a part of your Lambda function. You will be able to discover more details, and the quality features of monitoring and debugging AWS Lambda using this.&nbsp;</p>
</li>
</ul>
<h2 id="creating-a-simple-aws-lambda-function">Creating a Simple AWS Lambda Function</h2>
<p>Let’s create a simple Lambda function that is invoked by an API call, i.e. we generate a URL, which when entered in the browser would invoke the function. Our input would be passed into the function via this URL and the output would be returned and shown in the browser.</p>
<p>Step 1: Creating the function</p>
<p>In the Lambda console panel, click on create function. Give your function a name, in our case, it is DemoFunction. Also select the runtime as Python3, as we will be using that particular language for this example. Lastly, give your function’s role a name and, from Policy Templates, select Simple Microservice permissions.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/2creating-new-aws-serverless-function.png" alt="AWS Lambda Author From Scratch" title="AWS Lambda Author From Scratch"></p>
<p>Click on Create Function and you will be taken to the next screen where you can provide the actual code. We are authoring this API from scratch, but there are tons of templates from Amazon repository that you can explore.</p>
<p>The next page will have an inline text editor with a simple python function in there. Replace that with the following content:</p>
<pre><code>import json

print('Loading function')

def lambda_handler(event, context):

&nbsp;&nbsp;&nbsp;&nbsp;firstName = event['first']

&nbsp;&nbsp;&nbsp;&nbsp;lastName = event['last']

&nbsp;&nbsp;&nbsp;&nbsp;return 'Greetings, ' + firstName + ' ' + lastName +'!' 
</code></pre><p>The first line is for parsing the JSON using the JSON library in Python. The lambda_handler function gets the event as one of its parameters; this event brings along a set of data. The first and second line inside the function extracts whatever data is labeled first and second, and stores them into the respective variables.</p>
<p>The last line returns a message back and that’s what we will see in our browser.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/3creating-new-aws-serverless-function.png" alt="Creating AWS Lambda function" title="Creating AWS Lambda function"></p>
<p>We can add an API Gateway trigger right here, but for the sake of clarity, let’s do it separately. For now, we can click Save and move into the testing phase.</p>
<p>Step 2: Testing your function</p>
<p>To test your function, just click on the top right corner where it says ‘TestEvent’, then click on Configure Test Event.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/4creating-new-aws-serverless-function.png" alt="Testing AWS Lambda function" title="Testing AWS Lambda function"></p>
<p>Here we will have our first encounter with a JSON payload. In the template TestEvent.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/5test-new-aws-serverless-function.png" alt="Testing AWS Lambda JSON function" title="Testing AWS Lambda JSON function"></p>
<p>Replace the file’s content with the following lines:</p>
<pre><code>{

&nbsp;&nbsp;"first": "Jane",

&nbsp;&nbsp;"last": "Doe"

}
</code></pre><p>Now that we have saved the test event. Click on Test in the previous menu. Upon successful execution you should see:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/6creating-new-aws-serverless-function.png" alt="AWS Lambda function output" title="AWS Lambda function output"></p>
<p>Step 3: Setting up a Trigger</p>
<p>As mentioned before, our user would <a href="https://dashbird.io/blog/what-are-aws-lambda-triggers/">invoke the function</a> by accessing a certain URL. To enable that go to the API Gateway Console under your AWS Services and click on Get Started or New API option.</p>
<p>Let’s create one from scratch:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/7creating-new-aws-serverless-function.png" alt="AWS Lambda API creation" title="AWS Lambda API creation"></p>
<p>Our API is named dashbird-api. After clicking on Create API. You will get the resources that the API has access to (listed in the next menu):</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/8creating-new-aws-serverless-function.png" alt="AWS Lambda API resources" title="AWS Lambda API resources"></p>
<p>Since there are no resources, we just get a forward-slash. But you can create a new resource by using the Actions drop-down and picking Create Resource.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/9creating-new-aws-serverless-function.png" alt="AWS Lambda child resources" title="AWS Lambda child resources">
In the resource list, you can select this new resource (named greetings), click on actions and select Create Method. Our HTTP request method is going to be a GET request since our aim is to get an appropriate response from invoking the function.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/91creating-new-aws-serverless-function.png" alt="AWS Lambda GET request" title="AWS Lambda GET request"></p>
<p>The method will have a Lambda integration option, select that and then enter the function name chosen by you earlier Step 2. Also, from Step 2’s screenshot, make note of the function’s <a href="https://dashbird.io/knowledge-base/aws-cloud/arn-amazon-resource-names/">ARN</a> (top-right corner), it has the string eu-central-1 indicating the region it is in. Make sure that the same region is selected for the Lambda region also, as shown above. It would then ask permission for invoking the function; grant that and now we are ready for the final modification.</p>
<p>The GET method execution is explained in this diagram:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/92-GET-method-execution-aws-serverless.png" alt="AWS Lambda modify method" title="AWS Lambda modify method">
We still need to make sure that the input parameters are passed on correctly. For that we need to modify the Integration Request stage from above. You can click on it to make modifications:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/93-GET-method-execution-aws-serverless.png" alt="AWS Lambda body mapping" title="AWS Lambda body mapping"></p>
<p>Leave everything as it is, except at the very bottom of the menu where you will find the Body Mapping Template here we get to describe our input template.The template is going to be of type application/json :</p>
<pre><code data-lang="{">
&nbsp;&nbsp;&nbsp;&nbsp;"first": "$input.params('first')",

&nbsp;&nbsp;&nbsp;&nbsp;"last": "$input.params('last')"

}
</code></pre><p>The dollar sign and the input.params() part act as a placeholder and helps us define the structure of a proper request. Now we can save our changes, and click on Actions and select Deploy API option. It will ask for a stage name; give it a suitable name (in our case it is called prod). All is set! We can now run this function in real-time.</p>
<h2 id="running-the-function">Running the Function&nbsp;</h2>
<p>The function can be invoked using a unique URL associated with it. In the API console, where we first selected Resources, select Stage submenu instead. Then drop down to greetings and then to the GET option.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/94-GET-method-execution-aws-serverless.png" alt="AWS Lambda invoke URL" title="AWS Lambda invoke URL"></p>
<p>It will give you an invoke URL, which you can click on for the function to run. However, on the first try you might get an error message if you didn’t give any input. You can rectify this by modifying the URL like this:</p>
<p><a href="https://.........amazonaws.com/prod/greetings?first=John&amp;last=Doe">https://.........amazonaws.com/prod/greetings?first=John&amp;last=Doe</a></p>
<p>Adding …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/">https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/</a></em></p>]]>
            </description>
            <link>https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708237</guid>
            <pubDate>Wed, 07 Oct 2020 13:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from onboarding emails with no HTML styling]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 171 (<a href="https://news.ycombinator.com/item?id=24707994">thread link</a>) | @pau_alcala
<br/>
October 7, 2020 | https://blog.palabra.io/great-onboarding-plain-text | <a href="https://web.archive.org/web/*/https://blog.palabra.io/great-onboarding-plain-text">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra</a></em></p><p>Great onboarding emails don't need to have impressive design. They should provide a clear path for new users to follow to get as much value from your product and as quickly as possible. While creating <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra's</a> onboarding, we went through our favorite plain text emails. Here's what we learned.</p><h2>Plain text is the way to go 🚀</h2><p>Writing HTML emails takes a lot of time, even with image based builders. As an early stage company, we simply didn't have enough time to design and mark our emails.</p><p>We also have <a href="https://blog.palabra.io/plain-text-engagement">a lot of reasons to go with plain text</a> instead of image-based. It helps deliverability, accesibility and looks much more real and important than ad-looking emails.</p><p>That's why we decided to go with plain text emails all the way. We explored different email sequences that used plain text (or simple styling) to understand what they did best. And where better to start than our very own inbox?</p><p>We noticed a few of the onboarding email sequences we got were really helpful for us as users. They kept simple a simple design and used mostly text to share their best features. </p><p>And we found some awesome examples of onboarding sequences that use little to no HTML styling:</p><ul><li>Notion's awesome and personal onboarding (simple styling).</li><li>Superhuman's daily bits of information on its greatest features (only text and images).</li><li><a href="http://zest.is/">Zest.is</a> drips using only plain text and images or gifs (our personal favorite).</li></ul><p>Here's what we discovered.</p><h2>Welcome emails are more than a confirmation</h2><p>Every SaaS company must start their onboarding sequences with a welcome message that is sent when a user joins the platform. This is a must by now, since everyone who signs up will expect some sort of confirmation of their transaction.</p><p>I mean, it is essentially a welcome message, but it can be so much more.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/f0157/01.png" srcset="https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/5243c/01.png 240w,https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/ab158/01.png 480w,https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/f0157/01.png 809w" sizes="(max-width: 809px) 100vw, 809px" loading="lazy">
    </span></p><p>For example, SuperHuman sends you a warm welcome message that immediately teaches you how to use their Command.</p><p>Another excellent example of welcome email is from Zest:</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/7d769/02.png" srcset="https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/5243c/02.png 240w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/ab158/02.png 480w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/7d769/02.png 960w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/b1884/02.png 994w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>We love these simple but catchy lines. They nail the exact effect that plain text should achieve: make you feel among friends.</p><p>Both Superhuman and Zest suggest a next step you should follow after receiving that first email. This gives a clear path for people to follow if they want to get value from their products. And that's the best thing you can do with a welcome message.</p><h2>A name and a face</h2><p>This is a great tip to increase engagement. I always feel awkward when I don’t know who is writing on the other side. Is it the CEO? Someone from Sales? Is it a super intelligent baby? Who knows.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/0248a/03.png" srcset="https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/5243c/03.png 240w,https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/ab158/03.png 480w,https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/0248a/03.png 658w" sizes="(max-width: 658px) 100vw, 658px" loading="lazy">
    </span></p><p>We can see this information clearly in Notion’s emails. Ivan is not only a name, he is Notion’s Co-founder. It’s flattering to receive a direct message from a co-founder, it also gives the impression of commitment from the very roots of the company. </p><p>At <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra</a> we do the very same thing. Our emails are sent by Paula or Karen, who are the founders (and the heart) of this project. </p><p>A photo is not a requirement in itself, yet, the clearer the image we have of the person who sends and receives the emails, the more engagement we can generate.</p><p>Even if you have hundreds of people working in your business, you can create an identity to address your users.</p><h2>Emojis in the subject (use with caution)</h2><p>This point is more to talk about email subjects, a very important topic that sometimes is forgotten.</p><p>If every email is a gift to your users, the subject is the wrapping paper. You want it to be shining, flashy, stunning so the reader has no other option than to open the email.</p><p>Definitely, most of the plain text onboarding sequences than we observed have emojis (at some stage) in their subjects. </p><p>Remember: emojis are important, but they have to reinforce the idea of the text in the subject. Otherwise you’re gonna look cu-cu or, even worse, desperate.</p><p>Zest win the contest of better subjects seding thing like: </p><ul><li>you here -&gt; 💗</li><li>make yourself at home 🍋</li></ul><p>You can also include them in the body of the email to generate a greater visual impact and a neatear appearance.</p><h2>Email 'til you make it</h2><p>Yes, we received tons of emails per week. In fact, Superhuman mentioned it in their onboarding email sequence.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/a9fc9/04.png" srcset="https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/5243c/04.png 240w,https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/ab158/04.png 480w,https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/a9fc9/04.png 701w" sizes="(max-width: 701px) 100vw, 701px" loading="lazy">
    </span></p><p><em>(this is simply genius)</em></p><p>But preciscely for that reason you have to be present. The first days are critical to impress your users.</p><p>Zest has the strategy of sending an email the first day a user joins. And then three more during the second day, another 4 days after and another one 10 days after.</p><p>Imagine someone you’re dating sends you 4 emails in 10 days (well, in that case, you’re probably Meg Ryan, so maybe it’s not so bad).</p><p>This could sound excessive, but it can take a while until people understand your value. Just make sure the value you're providing is clear, and that each email you send has a reason to be in people's inbox.</p><h2>Thank yous matter</h2><p>Far from recommending you stalk your users, we want to encourage you to use emails as a tool for a meaningful exchange of information. You can learn one thing or two about your own service or product.</p><p>The Superhuman sequence puts feedback as a priority, using sentences like:</p><p>“<strong>We love hearing your feedback: please reply to this email and say hello :)”</strong></p><p><strong>“We love hearing from you! Please reply and let us know what you think 😃”</strong></p><p>In the email sequence that we mentioned from Zest, at the 10 day after the user joins, they ask for the thoughts and feelings about the platform and for the likes and dislikes.</p><p>A “thank you” at the end of every email leaves a good impression. Of course. It’s also a good idea to make a special thanking email. When a business is growing, every user is something to thank, so let them know that in your own words (or emojis!).</p><p>If you read this far, ping us at <a href="https://twitter.com/palabraio">Twitter</a> and tell us who sent you your favorite onboarding emails.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/great-onboarding-plain-text</link>
            <guid isPermaLink="false">hacker-news-small-sites-24707994</guid>
            <pubDate>Wed, 07 Oct 2020 13:35:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Becoming a Consultant in 2020: A How-To Guide]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24707888">thread link</a>) | @ericvanular
<br/>
October 7, 2020 | https://ericvanular.com/becoming-a-consultant-in-2020/ | <a href="https://web.archive.org/web/*/https://ericvanular.com/becoming-a-consultant-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So you’ve decided that you’d like to start consulting. Maybe you’ve heard the siren call of setting your own hours, working on cutting edge stuff with cool clients, making more money, or making a name for yourself. Perhaps you’ve read some of the interesting outcomes that folks like <a href="https://www.nateliason.com/blog/money-or-wealth">Nat Eliason</a> have talked about at length. Freelancing, contracting, consulting - whatever you want to call it. Offering your own services is a great first step in the ladder of self-employment. </p>
<p>There’s a ton of reasons why being a consultant might work for you. One of the great things about starting your own consulting business is that it doesn’t require a big outlay of cash. Starting a consulting business can be accomplished fairly simply by finding businesses that need help with a specific challenge and offering them your help solving that problem. </p>
<p>That said, simple definitely doesn’t mean easy. The low barriers to entry also mean that consulting is fiercely competitive. Ever looked at sites like Upwork, Fiverr, or Freelancer? <em>Dozens of highly skilled people around the world are willing to take on contracts at much lower rates than you’d ever accept.</em> Tons of people try to become self employed as a consultant every year and just as many quit because they can’t make it work.</p>
<p><strong>So the question is, how do you succeed early on as a consultant?</strong> For the sake of this post, I’ll assume you don’t already have an established brand that you can fall back on or an incredible personal network capable of feeding you awesome leads. As we'll find out, succeeding as a consultant is actually more about not failing, hence the title of this post. Failing usually happens because you aren't able to sell your services.</p>
<p>I’m going to give you a process you can use to get off the ground running. We’ll try to avoid vague platitudes and instead focus on the actionable steps that you can take to give yourself the best chances of success. </p>
<h2 id="why-should-i-hire-you"><a href="#why-should-i-hire-you" aria-label="why should i hire you permalink"></a>Why Should I Hire You?</h2>
<p><strong>Consulting is only about one thing: improving the client’s state.</strong> In order to improve a client’s state, they’ll first need to agree to work with you. In order to get them to work with you, they’ll first need to understand your value proposition and agree with it.</p>
<p>Ok, value proposition - <em>vague buzzword alert</em>. What does it mean? The simplest version of this is a statement taking the form: </p>
<blockquote>
<p><span size="6">I help <b><i>who</i></b> do <b><i>what</i></b></span></p>
</blockquote>
<p>Seems easy enough? Not really. The key to a compelling value prop is to get as specific as possible about the answers you are filling in for the who and what.</p>
<p>Also critically - and I can’t stress this enough - you are not just making up answers to this that sound good in your head. You want to get laser focused on understanding exactly who your customers are and exactly what their pain points are. You are NOT focusing on the technical skills you have or features of the solution. </p>
<p>The fatal error many aspiring consultants make is to come up with something like this: “I help ecommerce companies to build machine learning models”. Wrong - no one gives a crap about your ability to build fancy ML models. Selling yourself as a list of technologies or credentials completely exposes your lack of understanding about who should care and why. </p>
<p>Potential clients care about you only in your ability to solve their problems, save them time, and make more money. Anything not directly accomplishing this is a complete waste of time for you to try to sell. Instead of obsessing over anything technical or logistical, focus on how you can improve the client’s life.</p>
<p>Ask yourself the following questions to get closer to what I’m describing:</p>
<ul>
<li><strong>Pain Point</strong>: What is your client’s important problem that they can’t solve?</li>
<li><strong>Imagine</strong>: Where could your client be at the end of this journey with you?</li>
</ul>
<p>Let’s walk through methods you might use to develop your value proposition.</p>
<ul>
<li>Think about past jobs you’ve had. The company you worked for had customers, otherwise they wouldn’t be in business. Those customers have a pain point that they were willing to pay to solve. <strong>Could you help those customers solve that pain point directly?</strong></li>
<li>Have you or anyone you’ve worked with ever complained about something relating to your work? Chances are, other people have complained about that thing too. <strong>Is there a way for you to make that situation less bad for people like yourself or your coworkers?</strong></li>
<li>Ask people what their biggest professional challenges or annoyances are. Simple. Effective.</li>
<li>Are other people selling solutions to the pain points you are planning on solving as well? If not, try again. Why? If it is a real pain point, businesses should already be paying to have it solved. <strong>Sell what sells.</strong></li>
</ul>
<h2 id="the-subtle-art-of-selling-services"><a href="#the-subtle-art-of-selling-services" aria-label="the subtle art of selling services permalink"></a>The Subtle Art of Selling Services</h2>
<p>Ok so you’ve made it this far. Let’s say you have a solid value proposition. You’re ready to start working with clients. Congrats. Now here is the painful truth (you’ve earned the right to hear it):</p>
<blockquote>
<p><span size="4">All your other efforts mean nothing in comparison to your sales efforts.... including actually doing the work that you are selling.</span></p>
</blockquote>
<p><span>Consulting is a sales game.<span> Eventually starting any business is a sales game. Don’t like it? Don’t start a business.</span></span></p>
<p>Let’s assume you’re ok with this and move onto optimizing your sales efforts so you don’t flounder around aimlessly like most (myself included) did when they started.</p>
<p><strong>Getting your first leads consists of getting leads.</strong> Huh? That means not making content. It means pounding the pavement and reaching out to real human beings who hold the bag (of cash). Make cold calls. Send cold emails. Make warm calls to people you know asking them for leads. Send warm emails doing the same. Find any way that you can to get in touch with business owners (the people who actually care about the success of their business) and get talking to them.</p>
<p>Everybody wants to find a clever way to avoid outbound sales. But at the start, there is no other way. Nothing will put dollar bills in your pocket faster than talking to people who own money making machines (businesses) and convincing them to let you solve their problems. No, it is not scalable. But it will keep you afloat, and at this stage that’s all you should care about. </p>
<p>Selling is really hard. The reason being because it is mostly rejection. Being aware of that in advance should help you to mentally deal with it a little, but it will still suck somewhat. Trust the process. Remember that people really only buy 4 things: time, money, sex, and approval. If you try selling something other than those things you will fail. Every proposal and pitch you make should be framed around one of those things. Try to sell solutions to current problems rather than future problems. People buy aspirin more than they buy vitamins.</p>
<p>When you start prospecting for clients, your aim should be targeted on people who buy services. Those are the only people whose opinion matters and who you want to talk to.  Likely they go by the titles of owner (ideal because they have the most skin in the game), manager, director, or executive. </p>
<p><code>Don’t accept a “no” from someone who can’t say “yes”.</code> </p>
<p>The “yes” people are the people we just listed. There are many people who can only say no, including HR, recruiting, and any managers without buying power. It’s okay to go around these folks. Most of their job could be in saying no. You know that you can help this company improve! People who don’t have a vested interest (read: ownership) in the business succeeding likely don’t have any reason to change the status quo. It’s about finding the people who are most incentivized to optimize their business’ profitability and asking them the right questions to see how you can provide value. </p>
<h4 id="your-most-important-asset-is-your-reputation"><a href="#your-most-important-asset-is-your-reputation" aria-label="your most important asset is your reputation permalink"></a>Your most important asset is your reputation.</h4>
<blockquote>
<p>All things being equal people buy from their friends. So make everything else equal then go make a lot of friends. </p>
</blockquote>
<p>Being useful to other people is all you ever need to do to sell things. Help people out. Send interesting content. Write nice cards that show you care. Record videos sharing your ideas for growing their business. Introduce people who would benefit from knowing each other then get out of the way. Don’t expect anything in return for these efforts. Be consistent and authentic about these actions. The reason why you’d do this is because most people think sales pitches are repulsive. Being immediately helpful is attractive. If you find a way to help someone before they are paying you, they will find ways to pay you back. Of course, these tips aren't specific to just consulting but since relationships are the lifeblood driving your services business, the advice is extra relevant for you.</p>
<h4 id="do-what-you-say-you-will-do"><a href="#do-what-you-say-you-will-do" aria-label="do what you say you will do permalink"></a>Do what you say you will do.</h4>
<p>Ok so you’ve got a contract or two by now. In future posts I’ll dive deeper into things like negotiating rates, contracts, and the actual project delivery. For today, I’m assuming you’re a pro in your niche and so once you’ve got a contract the actual project delivery goes fine. Generally that’s not what makes consulting businesses fail.</p>
<p>As a general tip for contract-based service work, make sure that you understand the requirements really well before starting any implementation. Talking to all stakeholders and having a clear picture of what would constitute success is a make-or-break thing. As the project progresses, communicate frequently about any new developments, doubts, opportunities, or questions you might have. When in doubt, over communicate with your client and make sure you are on the same page. Things will never be perfect and if you are proactive about calling issues out, you will bring extra value to the table by acting as a project manager and by solving problems before they even arise. Your client will appreciate not feeling like they have to micromanage you and you will have more breathing room. Win-win. <strong>Above all else, do what you said you will do - it is rare in this business.</strong></p>
<h2 id="catching-waves-on-the-horizon"><a href="#catching-waves-on-the-horizon" aria-label="catching waves on the horizon permalink"></a>Catching Waves On The Horizon</h2>
<p>While you’ve got a project on the go, you can't stop selling. Your project will end and when that happens you don’t want to be “on the beach” …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ericvanular.com/becoming-a-consultant-in-2020/">https://ericvanular.com/becoming-a-consultant-in-2020/</a></em></p>]]>
            </description>
            <link>https://ericvanular.com/becoming-a-consultant-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24707888</guid>
            <pubDate>Wed, 07 Oct 2020 13:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making the Monty Hall problem weirder but obvious]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 265 (<a href="https://news.ycombinator.com/item?id=24707305">thread link</a>) | @dyno-might
<br/>
October 7, 2020 | https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        







<div>
    <div>
        <div>
            
            <p><strong>Sep 17, 2020</strong></p>
            
            



<p>The <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a> is famously unintuitive. This post starts with an extreme version where the solution is blindingly obvious. We then go through a series of small changes. It will be clear that these don’t affect the solution. At the end, we arrive at the classic Monty Hall problem.</p>

<p>For reference, the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">classic formulation</a> goes:</p>

<blockquote>
  <p>Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?</p>
</blockquote>

<p>Intuitively, many people guess it doesn’t matter if you switch. But it does. You get the car 2/3 of the time if you switch, and 1/3 of the time if you don’t. Why?</p>



<p>Here’s our first game.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game1.png">
</p>

<p>There’s nothing mysterious here. You should choose option B. There’s only a 10% chance you picked the right door, so there’s a 90% chance the car is behind one of the others.</p>



<p>Now, we slightly update the game (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty says “Hey! I promise you that there is a goat behind at least 8 of the other 9 doors!”</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game2.png">
</p>

<p>Monty’s statement changes nothing. You don’t need to rely on his <a href="https://en.wikipedia.org/wiki/Monty_Hall#/media/File:Monty_hall_abc_tv.JPG">trustworthy looks</a>. You already <em>knew</em> there were at least 8 goats! Option B still gets you the car 90% of the time.</p>



<p>Let’s update the game again (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty looks behind the other 9 doors. He chooses 8 with goats behind them, and opens them.</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game3.png">
</p>

<p>The key insight is this: When Monty shows you that 8 of the 9 other doors contain goats, you haven’t learned anything relevant to your decision. You <em>already knew there were at least 8 goats behind the other doors</em>! So this is just like game 2. Option B still gets you the car 90% of the time.</p>

<p>Want more intuition? Suppose you picked door 3. Imagne Monty walking past the doors, opening doors 1, 2, 4, 5, 6, <strong>skipping 7</strong>, then opening 8, 9, and 10. Doesn’t door 7 seem special?</p>



<p>Let’s make another change. Finally, we arrive at a game very similar to Monty Hall.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other 9 doors. He chooses 8 of them with goats behind them, and opens them.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind <strong>the other closed door</strong>.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game4.png">
</p>

<p>The only difference with Game 3 is that option B doesn’t get you the 8 visible goats. Since you don’t care about goats, this makes no difference. This is still just like the game 3. You get the car 90% of the time by switching.</p>



<p>Here is the last game. We just change the number of doors from 10 to 3.</p>

<ol>
  <li>There are <strong>3</strong> doors. A car is randomly placed behind one, and goats behind the other <strong>2</strong>.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other <strong>2</strong> doors. He chooses one <strong>1</strong> of them with a goat behind it, and opens it.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind the other closed door.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game5.png">
</p>

<p>Of course, you still want to choose option B. The chance of success is now 2/3 instead of 9/10. This game is exactly Monty Hall, so we’re done.</p>



<ul>
  <li>
    <p>It’s important that Monty looked behind the doors before choosing which to open. This is where people’s intuition usually fails. If he had chosen a door at random — <em>in a way that he risked possibly exposing a car</em>, then the situation would be different. (In that case, there’s no advantage or harm in switching.) But he doesn’t choose the door at random. He deliberately chooses to show you goats. Since this is always possible, it tells you nothing. I think this is the crux of what makes this problem unintuitive. Many people intuitively think it doen’t matter if you switch. And that <em>would be correct</em> if the door had been opened at random!</p>
  </li>
  <li>
    <p>It might be helpful to draw a diagram of the relationship of the different games, starting with classic Monty Hall and ending with the extreme version.</p>
  </li>
</ul>

<blockquote>
  <p>Game 5 (Classic Monty Hall)<br>
 ↓<br>
 ↓ (Use 10 doors instead of 3)<br>
 ↓ <br>
Game 4<br>
 ↓<br>
 ↓ (If you switch, get the contents of <em>all</em> other doors, not just the other closed door.)<br>
 ↓<br>
Game 3<br>
 ↓<br>
 ↓ (Monty promises 8 goats behind the other doors instead of showing you.)<br>
 ↓<br>
Game 2<br>
 ↓<br>
 ↓ (Monty doesn’t bother promsising.)<br>
 ↓<br>
Game 1 (Dyno Might© Monty Hall)</p>
</blockquote>

<ul>
  <li>
    <p>There are <a href="https://marginalrevolution.com/marginalrevolution/2019/09/the-intuitive-monty-hall-problem.html">some</a> <a href="https://twitter.com/jben0/status/1174180200072011776">other</a> <a href="https://statmodeling.stat.columbia.edu/2019/09/19/alternative-more-intuitive-formulation-of-monte-hall-problem/">attempts</a> at <a href="https://math.stackexchange.com/questions/96826/the-monty-hall-problem/3360686#3360686">variants</a> of the Monty Hall problem, also intended to be more intuitive. These involve switching the doors for “boxers”.</p>
  </li>
  <li>
    <p>Monty Hall was actually named “Monte” at birth! Given that <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulations</a> are often used for exploring the Monty Hall problem, that’s either a tragedy for puns or a miracle for confused students.</p>
  </li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24707305</guid>
            <pubDate>Wed, 07 Oct 2020 11:57:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebRTC iOS SDK Lets You Build WebRTC iOS App Easily]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24706846">thread link</a>) | @kerrarbone
<br/>
October 7, 2020 | https://antmedia.io/how-to-use-webrtc-sdk-in-native-ios-app/ | <a href="https://web.archive.org/web/*/https://antmedia.io/how-to-use-webrtc-sdk-in-native-ios-app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Ant Media’s WebRTC iOS SDK lets you build your own iOS application that can publish and play WebRTC broadcasts with just a few lines of code.<br>
In this doc, we’re going to cover the following topics.</p>
<ul>
<li>Run the Sample WebRTC iOS app
<ul>
<li>Publish Stream from your iPhone</li>
<li>Play Stream on your iPhone</li>
<li>P2P Communication with your iPhone</li>
</ul>
</li>
<li>Develop a WebRTC iOS app
<ul>
<li>How to Publish</li>
<li>How to Play</li>
<li>How to use DataChannel</li>
</ul>
</li>
</ul>
<h2>Run the Sample WebRTC iOS App</h2>
<ul>
<li> <h3>Download the WebRTC iOS SDK</h3> <p>WebRTC iOS SDK and WebRTC Android SDK’s are free to download. You can access them through<span>&nbsp;</span><a href="https://antmedia.io/free-webrtc-android-ios-sdk/" target="_blank" rel="noopener noreferrer">this link on antmedia.io</a>. If you’re an enterprise user, it will be also available for you to download in your subscription section in your “my account” page. Anyway, after you download the SDK, you can just unzip the file and open the project with Xcode.</p></li>
<li> <h3>Install Dependency</h3> <p>Open your terminal and go to the directory where the reference project resides and run<span>&nbsp;</span><code>pod install</code><span>&nbsp;</span>. If you are not familiar with pods, visit<span>&nbsp;</span><a href="https://cocoapods.org/" rel="nofollow noopener noreferrer" target="_blank">cocoapods.org</a><span>&nbsp;</span>for documentation and installation.</p> <pre><code>cd /go/to/the/directory/where/you/unzip/the/SDK
pod install
</code></pre> <p>This install the Starscream packet for WebSocket connections.</p></li>
<li> <h3>Open and Run the Project in Xcode</h3> <p>Open the Xcode in your MacOS and Click the Open Another Project if you don’t see the Sample Project in your list.</p> <p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/Xcode_open_another_project.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 1" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 1">Go to the directory where you download and unzip the iOS SDK. Open the<span>&nbsp;</span><code>AntMediaReferenceApplication.xcworkspace</code><span>&nbsp;</span>file</p> <p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/open_sample_project.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 2" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 2">After project is opened, connect your iPhone to your Mac and choose your iPhone in Xcode as shown below.</p> <p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/choose_your_iphone_in_xcode.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 3" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 3">Click<span>&nbsp;</span><code>Run</code><span>&nbsp;</span>button on the top left of the Xcode. Then project is going to be built and deployed to your iPhone.</p> <p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/choose_your_iphone_in_xcode.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 3" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 3"></p></li>
</ul>
<h2>Publish Stream From Your iPhone</h2>
<p>Tap <code>Publish</code> button and then Tap <code>Set Server IP</code> under the connect button in your iPhone.</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/tap_publish_button.png" width="240" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 5" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 5"></p>

<p>Write Your Ant Media Server’s full WebSocket URL and tap <code>Save</code> button. Its format is like this<br>
<code>ws://192.168.7.25:5080/WebRTCAppEE/websocket</code></p>
<p>If you install SSL to Ant Media Server, you can also use<br>
<code>wss://your_domain_address:5443/WebRTCAppEE/websocket</code>.</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/set_server_ip.png" width="240" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 6" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 6"></p>
<p>Set the stream id to anything else then ‘stream1’ and Tap ‘Connect’ button on the main screen. Then it will ask you to access the Camera and Mic. After you allow the Camera and Mic access, stream will be published on Ant Media Server.<br>
<img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/access_camera_ios.png" width="240" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 7" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 7"></p>
<p>Then it will start Publishing to your Ant Media Server. You can go to the web panel of Ant Media Server(http://server_ip:5080) and watch the stream there. You can also quickly play the stream via https://your_domain:5443/WebRTCAppEE/player.html</p>
<h2>Play Stream On Your iPhone</h2>
<p>Playing stream on your iPhone is almost the same as Publishing. Before playing, make sure that there is a stream and it is being published to the server with same stream id in your textbox (You can quickly publish to the Ant Media Server via https://your_domain:5443/WebRTCAppEE). For our sample, stream id is still “stream1” in the image below. Then you just need to tap ‘Play’ button and tap ‘Connect’ button.</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/tap_play_button.png" width="240" height="1334" alt="ant media WebRTC iOS SDK interface" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 8"><span></span></p>
<p>After tapping ‘Connect’ button, stream will start playing.</p>
<h2>P2P Communication With Your iPhone</h2>
<p>WebRTC iOS SDK also supports <a href="https://antmedia.io/how-to-create-webrtc-peer-to-peer-communication/" target="_blank" rel="noopener noreferrer">P2P communication</a>. As you guess, just tap ‘P2P’ and then ‘Connect’ button.</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/tap_p2p_button.png" width="240" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 8" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 9"></p>
<p>When there is another peer is connected to the same stream id via Android, iOS or Web, then P2P communication will be established and peers can talk to each other. You can quickly connect to the same stream id via https://your_domain:5443/WebRTCAppEE/peer.html</p>
<h2>Develop a WebRTC iOS app</h2>
<p>We highly recommend using the sample project to get started with your application. Nevertheless, it’s good to know the dependencies and how it works. Now we’re going to tell how to create a WebRTC iOS app from scratch by using WebRTC iOS SDK. Let’s get started.</p>
<h3>Create Xcode Project</h3>
<p>Open Xcode and Create a project. Choose <code>Single View App</code> from the templates.<br>
<img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/Xcode_new_project.png" width="480" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 9" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 10"></p>
<ul>Name your project as ‘WebRTCiOSApp’ below</ul>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/story_board_new_project.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 10" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 11"><span></span></p>
<p>Open your terminal and go to the directory where you create your project and make the pod installation. You can learn more about pods on <a href="https://cocoapods.org/" rel="nofollow noopener noreferrer" target="_blank">cocoapods.org</a></p>
<pre><code>cd /go/to/the/directory/where/you/create/the/project
pod init
</code></pre>
<p><code>Podfile</code> should be created after running<span>&nbsp;</span><code>pod init</code>. Open the<code>Podfile</code>, paste the following and save it.</p>
<pre><code>target 'WebRTCiOSApp' do
  # Comment the next line if you don't want to use dynamic frameworks
  use_frameworks!

  # Pods for WebRTCiOSApp
 pod 'Starscream', '~&gt; 3.1.1'
end
</code></pre>
<p>Run the following command for pod installation</p>
<pre><code>pod install
</code></pre>
<p>Close the Xcode project and open the<span>&nbsp;</span><code>WebRTCiOSApp.xcworkspace</code><span>&nbsp;</span>in Xcode</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/open_workspace_xcode.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 11" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 12"><br>
Make the Project Target to iOS 10</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/ios_10.png" width="720" height="1928" alt="WebRTC iOS SDK" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 13"><br>
Disable bitcode</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/disable_bitcode.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 12" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 14"></p>
<p>Copy <code>WebRTC.framework</code> and <code>WebRTCiOSSDK.framework</code> folders to your projects directory.</p>
<p><code>WebRTC.Framework</code>: is directly available under<code>WebRTCiOSReferenceProject</code><br>
<code>WebRTCiOSSDK.Framework</code>: is the binary framework version of WebRTC iOS SDK. It’s created after running<span>&nbsp;</span><code>./export_fat_framework.sh</code> in <code>WebRTCiOSReferenceProject</code> directory. Then it will be ready under <code>Release-universal</code> directory. Alternatively, you can import source code of WebRTC iOS SDK to your project directly.</p>
<p>Embed <code>WebRTC.framework</code> and <code>WebRTCiOSSDK.framework</code> to your projects.</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/click_add_items_to_embed.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 13" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 15"></p>
<p>Choose ‘Add Others’ in the coming windows at the bottom left and select <code>Add Files</code>. Then add <code>WebRTC.framework</code> and <code>WebRTCiOSSDK.framework</code>. After it’s done, it should be shown like below.</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/frameworks_added.png" width="720" alt="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 14" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 16"></p>
<p>Try to build and run the app. If you get some errors like some methods are only available in some iOS versions. Use<span>&nbsp;</span><code>@available</code><span>&nbsp;</span>annotation. You can get more info about this<span>&nbsp;</span><a href="https://fluffy.es/allow-app-created-in-xcode-11-to-run-on-ios-12-and-lower/" rel="nofollow noopener noreferrer" target="_blank">on this post</a></p>
<h2>How to Publish</h2>
<p>Create a UIView and add a Button to your StoryBoard. This is just simple iOS App development, we don’t give details here. You can get lots of tutorials about that on the Internet.<br>
Add Mic and Camera Usage Descriptions</p>
<p><img src="https://github.com/ant-media/Ant-Media-Server/wiki/images/camera_mic_usage.png" width="720" height="1928" alt="how to use WebRTC iOS SDK" title="Easy-to-use WebRTC iOS SDK Lets You Build WebRTC iOS App with 4 Lines of Code 17"></p>
<p>It’s now time to write some code. Initialize <code>webRTCClient</code> in <code>ViewController</code></p>
<div> <pre><span>let</span> webRTCClient<span>:</span> AntMediaClient <span>=</span> AntMediaClient.<span>init</span>()</pre></div><p>Add the following codes to <code>viewDidLoad()</code> method.</p>
<div> <pre> webRTCClient.<span>delegate</span> <span>=</span> <span>self</span>
 webRTCClient.<span>setOptions</span>(<span>url</span>: <span><span>"</span>ws://ovh36.antmedia.io:5080/WebRTCAppEE/websocket<span>"</span></span>, <span>streamId</span>: <span><span>"</span>stream123<span>"</span></span>, <span>token</span>: <span><span>"</span><span>"</span></span>, <span>mode</span>: .<span>publish</span>, <span>enableDataChannel</span>: <span>false</span>)
 webRTCClient.<span>setLocalView</span>(<span>container</span>: videoView, <span>mode</span>: .<span>scaleAspectFit</span>)
 webRTCClient.<span>start</span>()</pre></div><p>Implement the delegate in your <code>ViewController</code>. Xcode helps you for implementation.<br>
ViewController should look like below. After you run the Application, it will start publishing with streamId: ‘stream123’ to your server.</p>
<div> <pre><span>class</span> <span>ViewController</span>: <span>UIViewController </span>{

  <span>@IBOutlet</span> <span>var</span> videoView<span>:</span> UIView<span>!</span>

  <span>let</span> webRTCClient<span>:</span> AntMediaClient <span>=</span> AntMediaClient.<span>init</span>()

  <span>override</span> <span>func</span> <span>viewDidLoad</span>() {
    <span>super</span>.<span>viewDidLoad</span>()
    
    webRTCClient.<span>delegate</span> <span>=</span> <span>self</span>
    <span>//Don't forget to write your server url.</span>
<span></span>    webRTCClient.<span>setOptions</span>(<span>url</span>: <span><span>"</span>ws://your_server_url:5080/WebRTCAppEE/websocket<span>"</span></span>, <span>streamId</span>: <span><span>"</span>stream123<span>"</span></span>, <span>token</span>: <span><span>"</span><span>"</span></span>, <span>mode</span>: .<span>publish</span>, <span>enableDataChannel</span>: <span>false</span>)
    webRTCClient.<span>setLocalView</span>(<span>container</span>: videoView, <span>mode</span>: .<span>scaleAspectFit</span>)
    webRTCClient.<span>start</span>()
  }

}</pre></div><h2>How to Play</h2>
<p>Playing a Stream is simpler than Publishing. We just need to change some codes in<span>&nbsp;</span><code>viewDidLoad()</code>. As a result, following code snippets just plays the stream on your server with streamId: ‘stream123’. Make sure that, before you try to play, you need to publish a stream to your server with having stream id ‘stream123’</p>
<div> <pre>  <span>class</span> <span>ViewController</span>: <span>UIViewController </span>{
   
    <span>@IBOutlet</span> <span>var</span> videoView<span>:</span> UIView<span>!</span>
   
    <span>let</span> webRTCClient<span>:</span> AntMediaClient <span>=</span> AntMediaClient.<span>init</span>()
   
    <span>override</span> <span>func</span> <span>viewDidLoad</span>() {
       <span>super</span>.<span>viewDidLoad</span>()
       
      
       webRTCClient.<span>delegate</span> <span>=</span> <span>self</span>
        <span>//Don't forget to write your server url.</span>
<span></span>       webRTCClient.<span>setOptions</span>(<span>url</span>: <span><span>"</span>ws://your_server_url:5080/WebRTCAppEE/websocket<span>"</span></span>, <span>streamId</span>: <span><span>"</span>stream123<span>"</span></span>, <span>token</span>: <span><span>"</span><span>"</span></span>, <span>mode</span>: .<span>play</span>, <span>enableDataChannel</span>: <span>false</span>)
       webRTCClient.<span>setRemoteView</span>(<span>remoteContainer</span>: videoView, <span>mode</span>: .<span>scaleAspectFit</span>)
       webRTCClient.<span>start</span>()
   }
 }</pre></div><h2>How to use Data Channel</h2>
<p>Ant Media Server and WebRTC iOS SDK can use data channels in WebRTC. In order to use <a href="https://antmedia.io/exchange-data-easily-using-webrtc-data-channels/">Data Channel</a>, make sure that it’s enabled both<span>&nbsp;</span><a href="https://github.com/ant-media/Ant-Media-Server/wiki/Data-Channel" target="_blank" rel="noopener noreferrer">server side</a><span>&nbsp;</span>and mobile. In order to enable it for server-side, you can just set the<span>&nbsp;</span><code>enableDataChannel</code><span>&nbsp;</span>parameter to true in<span>&nbsp;</span><code>setOptions</code><span>&nbsp;</span>method.</p>
<div> <pre>webRTCClient.<span>setOptions</span>(<span>url</span>: <span><span>"</span>ws://your_server_url:5080/WebRTCAppEE/websocket<span>"</span></span>, <span>streamId</span>: <span><span>"</span>stream123<span>"</span></span>, 
    <span>token</span>: <span><span>"</span><span>"</span></span>, <span>mode</span>: .<span>play</span>, <span>enableDataChannel</span>: <span>true</span>)</pre></div><p>After that, you can send data with the following method of<span>&nbsp;</span><code>AntMediaClient</code></p>
<div> <pre><span>func</span> <span>sendData</span>(<span><span>data</span></span>: Data, <span><span>binary</span></span>: <span>Bool</span> <span>=</span> <span>false</span>)</pre></div><p>When a new message is received, the delegate’s following method is called.</p>
<div> <pre><span>func</span> <span>dataReceivedFromDataChannel</span>(<span><span>streamId</span></span>: <span>String</span>, <span><span>data</span></span>: Data, <span><span>binary</span></span>: <span>Bool</span>)</pre></div><p>There is also data channel usage example exist in the Sample project.</p>
<p>Lastly, if you need to know more about all methods and delegates in WebRTC iOS SDK, please visit the <a href="https://github.com/ant-media/Ant-Media-Server/wiki/WebRTC-iOS-SDK-Reference" target="_blank" rel="noopener noreferrer">WebRTC iOS SDK Reference</a></p>

</div></div>]]>
            </description>
            <link>https://antmedia.io/how-to-use-webrtc-sdk-in-native-ios-app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706846</guid>
            <pubDate>Wed, 07 Oct 2020 10:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Design an Algorithm (2018)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24706841">thread link</a>) | @rohithkp
<br/>
October 7, 2020 | https://www.adamconrad.dev/blog/how-to-design-an-algorithm/ | <a href="https://web.archive.org/web/*/https://www.adamconrad.dev/blog/how-to-design-an-algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>

            <p>If you missed my <a href="https://www.adamconrad.dev/blog/why-hiring-is-broken-and-how-im-dealing-with-it">previous article</a>, I’m going to spend a series of articles providing notes as I audit <a href="http://www3.cs.stonybrook.edu/~skiena/373/">Steven Skiena’s CSE 373 Analysis of Algorithms class</a>.</p>

<p>In the first lecture, Skiena mentions you should take a data structures course and a linear algebra course before studying this material.</p>

<p>For professional (read: practical) purposes, we’re obviously not starting from scratch, but peaking at the syllabus I do believe we can incorporate data structures by implementing them in JavaScript (this is, after all, a front-end blog) along the way.</p>

<p>And as much as foundational linear algebra will help, there simply won’t be anything in a technical interview that would warrant deep study anyway, so we can safely skip this prerequisite.</p>

<h2 id="what-is-an-algorithm">What is an algorithm?</h2>

<p>An algorithm is <strong>an instruction set.</strong> Kind of like a recipe for a food dish. And just like that recipe for cauliflower rice you found on some random blog, you can translate that recipe into any language you want.</p>

<p>Algorithms are the same way: they are language-agnostic and can be expressed in a human-readable form or machine-readable. The simpler the idea, the easier it’s going to be to express in English. The more complex or nuanced the algorithm is, the more likely you’ll want to lean on a machine language like Python or JavaScript.</p>

<p>For practical purposes, think of the high-level overview of your algorithm as something you’ll explain to an interviewer in English before you dive into the code, but understand that in order to prove your chops as a programmer the code will have to be the primary source for explaining and validating the algorithms you design.</p>

<p>The two defining characteristics of an algorithm that separate an algorithm from other instructions are:</p>

<ol>
  <li><strong>It’s correct.</strong> Has anyone ever received credit for implementing an algorithm in a tech interview that didn’t produce the correct result every single time?</li>
  <li><strong>It’s efficient.</strong> We’d like our algorithms to run sometime before we get old.</li>
</ol>

<p>Now, <em>technically</em>, programs don’t have to run correctly to be acceptable. Programs that run instructions that are <em>mostly</em> correct are known as <em>heuristics</em>. These will become important when studying approximation algorithms later, but for now, assume that correctness is a requirement.</p>

<h3 id="how-do-you-prove-an-algorithm-is-correct">How do you prove an algorithm is correct?</h3>

<p>Proofs were not my strong suit in high school or college. For some reason, it never really clicked for me because the steps in a proof never seemed to line up with the logic my brain used to jump from one step to the next.</p>

<p>Luckily, the easiest way to prove correctness is to prove something <strong>isn’t correct.</strong></p>

<p>Wait, what? How does proving the opposite help us here?</p>

<p>Well, when we’re trying to figure out a correct and efficient algorithm to solve a problem, we can narrow the scope of possible choices by eliminating the ones that are demonstratively incorrect. Proving by counterexample can be far easier than other methods.</p>

<p>As a trivial example, suppose we have a total <em>T = 6</em> we want to strive for by adding up numbers in a valid set like <em>S = [1,2,3]</em>. It might seem like a very simple algorithm that will solve this problem is to pick numbers from left to right until we reach the total <em>T</em>. Even if you add in a big number at the beginning like <em>S = [5,1,2,3]</em> this works since we can just scrap the last two numbers.</p>

<p>What’s a counterexample that wouldn’t work?</p>

<p>How about <em>S = [5,2,4]</em>.</p>

<p>First, we pick 5, which is less than 6. There are no other numbers in our set that could add up to equal 6 after already picking 5, but there <em>is</em> a valid configuration that would still satisfy <em>T</em> (2 and 4). That’s proof by counterexample that our algorithm was not correct. It’s also a pretty simple counterexample. <strong>Counter-examples can be useful in the real-world to quickly help you assess if the path you’re going down is a good one or not.</strong></p>

<p>If you can come up with a relatively simple counterexample (simple meaning it should only require a handful of variables or items) you know that your algorithm is dead on arrival and you’ll need to try something else. If you can’t, you’re probably on the right track, but that doesn’t mean your algorithm is definitively correct.</p>

<h3 id="what-techniques-are-used-to-prove-correctness">What techniques are used to prove correctness?</h3>

<p>One way to prove correctness is induction. <strong>Proof by induction indicates that if we can solve for a base case <em>and</em> the general case for <code>n+1</code>, we know we’ve provided a correct answer for all possible inputs.</strong></p>

<p>There are two important connections to make here about induction which are useful in a professional setting:</p>

<ol>
  <li><strong>Proof by induction is a mathematical form of recursion.</strong> Recursion is a fundamental concept in programming which allows a function to call itself. It allows us to split up large problems into smaller ones.</li>
</ol>

<p>The classic example here is the Fibonacci sequence (a sequence of integers where the current number is the sum of the previous two numbers). To calculate Fibonacci for a value <em>n</em> in the sequence, you <em>could</em> count up all of the previous numbers manually for each input of <em>n</em>, but that would not only be slow and laborious, it would also be difficult to express as a program.</p>

<p>Another way would be to count a few base cases (n = 0 and n = 1) to get the counting started, and then continuously call a <code>Fibonacci</code> function with the summed values from the previous step. Recursion is what allows us to accomplish this in code. It is the programming strategy for tackling induction, which is the mathematical strategy for proving statements for algorithms which operate on our sets of data.</p>

<ol>
  <li><strong>Proof by induction is useful for summation.</strong> If you’re adding up a lot of inputs together, and you need to prove it will work for all cases, even ones larger than the set you have defined, it can be proven with induction.</li>
</ol>

<p>But are you ever going to need to formally prove something at work or in an interview? Absolutely not. <strong>But you will need to test your code, and tests are a form of proof.</strong></p>

<p>So while a formal mathematical proof of induction is likely way more rigorous than you will ever need to showcase in a professional setting, it does set the tone that you can’t simply write code and have people assume what you wrote is correct. It needs to be tested somehow, so if you have the mindset that your algorithm needs to be proven correct in some form, you’re on the right track to writing quality code.</p>

<h3 id="and-how-do-you-prove-something-is-efficient">And how do you prove something is efficient?</h3>

<p>If we’ll primarily be using code to express our algorithms, and tests to prove their correctness, Big O notation will be used to prove our algorithms are efficient.</p>

<p>We’ll cover Big O in a later post in this series, but the important thing to remember now is that in general, you’re going to want to strive for things that take a reasonable amount of time on large data.</p>

<p>For example, if something you design takes an <code>n!</code> factorial amount of time, anything over a measly 30 items and you’re dealing with numbers larger than the number of stars in the known universe. You <em>probably</em> want something that runs a bit faster than that.</p>

<h3 id="the-big-picture-on-the-properties-of-algorithms">The big picture on the properties of algorithms</h3>

<p>Most CS courses (and most schools) only ever care about these two things. If your teachers and TAs can successfully run your program within a reasonable amount of time, you get an A. Real life doesn’t give you an A for these two things because <em>you don’t work in a vacuum</em> as you do on a problem set or exam. So what things are missing from the real world picture?</p>

<ul>
  <li><strong>Orthogonality:</strong> Is your code dependent on other stuff? Are you writing stateful or functional code? Since most coding whiteboard problems are isolated and self-contained, you usually can’t test for this, so make sure you present a portfolio of real-world projects and open source code to demonstrate this</li>
  <li><strong>Readability:</strong> You can write the hackiest crap to get an algorithm to work, but in the real world other people can’t read or use that code, and that’s a fail. Make sure if you have time and your code is correct and efficient, to <em>refactor</em> to demonstrate you can write readable, reusable code that is DRY (don’t repeat yourself) and orthogonal (or at least that it can be written as part of an orthogonal system)</li>
</ul>

<h3 id="the-first-step-in-designing-an-algorithm">The first step in designing an algorithm</h3>

<p>So now that we know what defines an algorithm and what is required to prove it’s worth using to solve our problems, the next step is to decide how we will design our algorithms. Modeling a problem means knowing the objects you’re dealing with, and there are two classes of objects we will cover:</p>

<h4 id="combinatorial-objects">Combinatorial objects</h4>

<p>A <em>combinatorial object</em> is just a fancy way of saying “what kinds of things can I use to count with?” Since machines are just big 0 and 1 factories, combinatorial objects are the way for us to collect and organize all of the 0 and 1 math our machines are performing thousands upon millions of instructions per second. What kinds of things are we talking about?</p>

<ul>
  <li><strong>Permutations:</strong> reorderings of a set. Colloquial terms for this include words like <em>arrangement</em>, <em>tour</em>, <em>ordering</em>, and/or <em>sequence</em>.</li>
  <li><strong>String:</strong> sequence of characters or patterns. Think of strings like permutations but with letters instead of numbers. Words like <em>text</em>, <em>character</em>, <em>pattern</em>, <em>label</em>, <em>sentence</em> are key insights that you’re dealing with string data.</li>
  <li><strong>Subsets:</strong> portions of a set. If you see words like <em>cluster</em>, <em>collection</em>, <em>committee</em>, <em>group</em>, <em>packaging</em>, or <em>selection</em>, you’ve probably got a subset.</li>
  <li><strong>Points:</strong> locations in space. Words like <em>node</em>, <em>site</em>, <em>position</em>, <em>record</em>, or <em>location</em> are all references to <em>points</em>.</li>
  <li><strong>Graphs:</strong> nodes with vertices to connect them and give them direction. We mentioned this much earlier in this article. Words like <em>network</em>, <em>circuit</em>, <em>web</em>, and <em>relationship</em> all describe graphs.</li>
  <li><strong>Trees:</strong> graphs that flow in one direction and don’t end up where they started (acyclic). When they’re perfectly balanced, they literally look like a Christmas tree. Words like <em>hierarchy</em>, <em>dominance relationship</em>, <em>ancestor/descendent relationship</em>, <em>taxonomy</em> are all indicators you’re dealing with trees in your problem.</li>
  <li><strong>Polygon:</strong> …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.adamconrad.dev/blog/how-to-design-an-algorithm/">https://www.adamconrad.dev/blog/how-to-design-an-algorithm/</a></em></p>]]>
            </description>
            <link>https://www.adamconrad.dev/blog/how-to-design-an-algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706841</guid>
            <pubDate>Wed, 07 Oct 2020 10:23:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developing with Squeak on a Cellphone]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24706567">thread link</a>) | @tonyg
<br/>
October 7, 2020 | https://eighty-twenty.org/2020/10/07/developing-with-squeak-on-a-cellphone | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/10/07/developing-with-squeak-on-a-cellphone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Part of a series:</strong> <a href="https://eighty-twenty.org/tag/squeak-phone">#squeak-phone</a></p>

<hr>

<p>One <em>lovely</em> thing about working in Smalltalk is the effortlessness of
development.</p>

<p>I started off developing the code on my desktop machine, and
occasionally testing it on the phone itself. I just <code>rsync</code> the image
and changes files back and forth. This lets me pick up exactly where I
left off on the other device each time I move over.</p>

<p>However, <em>developing</em> on the phone was challenging because of the lack
of a keyboard (though I’ll post soon about an on-screen keyboard I’ve
written). So I installed RFB (from
<a href="http://source.squeak.org/ss/">here</a>) into my image on the desktop,
and tested it. Then I saved the image and <code>rsync</code>ed it to the phone as
usual, and presto, I can develop and test interactively on the phone
itself:</p>

<p><a href="https://eighty-twenty.org/images/bootstrapping-a-cellphone-20201007/vnc-to-phone.jpg"><img src="https://eighty-twenty.org/images/bootstrapping-a-cellphone-20201007/vnc-to-phone-640.jpg" alt="Using VNC to develop on the phone itself"></a>
Using VNC to develop on the phone itself</p>

<p>There were a couple of things I had to do to get this to work:</p>

<ul>
  <li>
    <p>Use this version of RFBServer: <a href="http://source.squeak.org/ss/">http://source.squeak.org/ss/</a></p>
  </li>
  <li>
    <p>Change <code>AllowTcpForwarding no</code> to <code>yes</code> in <code>/etc/ssh/sshd_config</code>
on the phone and then <code>service sshd restart</code></p>
  </li>
  <li>
    <p>Use <code>ssh -L 5900:localhost:5900 pm</code> to log into the phone (that’s
the green-screen transcript in the background in the picture above)</p>
  </li>
</ul>

  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/10/07/developing-with-squeak-on-a-cellphone</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706567</guid>
            <pubDate>Wed, 07 Oct 2020 09:31:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The companies that bring us knife steel]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 100 (<a href="https://news.ycombinator.com/item?id=24706485">thread link</a>) | @severine
<br/>
October 7, 2020 | https://knifesteelnerds.com/2020/09/14/the-companies-that-bring-us-knife-steel/ | <a href="https://web.archive.org/web/*/https://knifesteelnerds.com/2020/09/14/the-companies-that-bring-us-knife-steel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Thanks to AJ, Tobias Hangler, Benjamin Whitaker, Mike Latahm, Mike Pini, Jonathon Pye, Allan Benjamin, and Zaur for becoming <a href="https://www.patreon.com/Knifesteelnerds">Knife Steel Nerds Patreon</a> supporters!</p>
<p>My new book Knife Engineering <a href="https://www.bladehq.com/item--Knife-Engineering-Steel-Heat--115112">is now in stock at BladeHQ</a>.</p>
<p><strong>Steel</strong></p>
<p>There are many companies that bring us knife steel, from steel manufacturers to a whole array of suppliers to individual custom knife makers. So I have written a bit about how the supply chain works and some information on individual steel suppliers.</p>
<p><strong>Steel Manufacturers</strong></p>
<p>There are quite a few companies that produce steel used for knives. These are the companies that melt the steel, add the appropriate elements, and cast it into an ingot. Many of these same companies also hot roll and anneal the steel and perhaps cold roll it. Some of the better known knife steel manufacturers include Crucible (S30V, S35VN, CPM-3V, CruWear, CPM-M4, 154CM), Carpenter (CTS-XHP, CTS-BD1N, Maxamet), Hitachi (White #1, Blue Super, ATS-34, ZDP-189), Uddeholm (AEB-L, Elmax, Vanax, Vanadis 4 Extra), Bohler (M390, N690, K390), and Sandvik (12C27, 14C28N). There are also many other steel companies that sell “standard” or lesser known steel grades like Aichi (AUS-8, AUS-10), Ahonest Changjiang (8Cr13MoV, 9Cr18MoV, 7Cr17), or Latrobe (BG42, 440C, D2).</p>
<p><strong>Steel Processors and Suppliers</strong></p>
<p>The steel companies typically want to sell steel in large quantities to large customers. For knife manufacturers of sufficient size they can order directly from the steel company. However, the sales and distribution teams of steel manufacturers typically aren’t equipped to sell individual bars (or even full sheets) to custom knifemakers. That is where the smaller suppliers and distributors come in. They buy steel in larger quantities than an individual knifemaker is capable of purchasing and then distribute it in manageable sizes for custom knifemakers. And they may also import steel grades into their respective countries that are made elsewhere in the world.</p>
<p>Typically the good knife steel suppliers are also experienced in recommendations and troubleshooting for knifemakers that need help with steel selection or heat treating issues. Again, steel companies typically do not have the staff to answer questions from custom knifemakers. The suppliers may have other value-added services such as surface grinding the bars (removing mill scale and providing a better finish and flatness), waterjet cutting of knife blanks, or heat treating.</p>
<p>Some steel products can be more difficult to obtain than others. If a steel supplier has offered a product in the past it may be worth calling to ask if more stock will be in at some point or if they have issues with sourcing the products regularly.</p>
<p><strong>USA</strong></p>
<p><em>Steel-Focused Suppliers</em></p>
<p><a href="http://nsm-ny.com/"><strong>Niagara Specialty Metals</strong></a></p>
<p>Niagara is a hot rolling company that hot rolls all of the Crucible knife steels into sheets ready for knifemaking. They will also hot roll grades from other companies such as the Carpenter CD1 steel that is available from their online store currently. Niagara also has a knowledgeable sales staff that sells individual bars to knifemakers. They have <a href="http://www.nsm-ny.com/index.cfm?fuseaction=category.display&amp;category_id=1">an online store</a> that lists current stock, which includes all of the regular Crucible knife steels. They are often the best source for rare Crucible products like CPM-S125V or Rex 121 because any steel hot rolled to knife steel dimensions goes through them. However, you have to call to learn the availability of the more obscure products. Niagara has also introduced or re-introduced Crucible steels for knives like <a href="https://knifesteelnerds.com/2020/08/17/cpm-s60v-the-forgotten-super-steel/">S60V</a> and <a href="https://knifesteelnerds.com/2019/11/01/crucible-s45vn-steel/">S45VN</a>, so they have demonstrated a commitment to knives.</p>
<p><strong><a href="http://alphaknifesupply.com/">Alpha Knife Supply</a></strong></p>
<p>AKS is especially good for sourcing Bohler and Uddeholm grades in the USA. They offer products like AEB-L, Elmax, N690, <a href="https://knifesteelnerds.com/2019/08/12/how-to-heat-treat-26c3-steel/">26C3</a>, <a href="https://knifesteelnerds.com/2019/05/06/bohler-m398/">M398</a>, etc. that can be difficult to obtain regularly in the United States. They also offer other products like A2, D2, M2, 8670, 80CrV2, 52100, A8 Modified, <a href="https://knifesteelnerds.com/2018/06/04/toughness-testing-cru-wear-z-wear">Z-Wear</a>, Z-Finit/LC200N, Z-Tuff, 1075, 1084, 15N20, K390, <a href="https://knifesteelnerds.com/2018/03/26/cru-forge-v-toughness-testing-processing-and-background/">CruForgeV</a>, N695, O1, Vanadis 4 Extra, and K390.</p>
<p><strong><a href="http://sb-specialty-metals.com/shop/">SB Specialty Metals</a></strong></p>
<p>SB Specialty Metals is the former Crucible knife steel service division prior to Crucible’s bankruptcy in 2009 at which point Crucible offloaded all of their service centers. So SB has a lot of experience with supplying knife steel. SB is usually the best source for Carpenter steel products like BD1 and <a href="https://knifesteelnerds.com/2019/07/29/xhp-steel-history-and-properties/">XHP</a> which can be particularly difficult to purchase. They offer the sprayform version of D2 called <a href="https://knifesteelnerds.com/2020/08/31/how-to-heat-treat-d2-psf27-and-cpm-d2/">PSF27</a> which has enhanced toughness over standard D2. They also offer a series of Crucible and standard grades like D2, A2, O1, CPM-154, and S30V. There are other products that aren’t listed in the online store like RWL34, Maxamet, S90V, and 3V, and Scott Devanna of SB recommends calling to learn what is currently available.</p>
<p><strong><a href="https://newjerseysteelbaron.com/">New Jersey Steel Baron</a></strong></p>
<p>NJSB offers their proprietary steel <a href="https://knifesteelnerds.com/2019/09/23/nitro-v-its-properties-and-how-to-heat-treat-it/">Nitro-V</a> which is a modification of AEB-L. They also offer Crucible steels like CPM-154, 154CM, S30V, S35VN, CPM-3V, and CPM-M4. And a range of standard grades like W1, W2, 1075, 1084, 1095, 15N20, 52100, 80CrV2, AEB-L, A2, D2, L6, and O1.</p>
<p><strong><a href="https://www.admiralsteel.com/">Admiral Steel</a></strong></p>
<p>Admiral recently started offering Sandvik 14C28N which <a href="https://knifesteelnerds.com/2020/06/15/what-is-the-best-budget-knife-steel/">I named my favorite budget steel</a>. They also have a range of other standard knife steel grades like ATS-34, 440C, 154CM, S30V, S35VN, CPM-154, 3V, 8670, 52100, 15N20, 1095, 5160, O1, and D2.</p>
<p><strong><a href="https://www.hightemptools.com/steel.html">Kelly Cupples</a></strong></p>
<p>Cupples is known for supplying steel for forging and Damascus steel like 1075, 1080, 1095, 5160, 15N20, CruForgeV, and various powders (1084, 1095, 4600KC, 4800KC, nickel).</p>
<p><em>General Knife Supply Including Steel</em></p>
<p><strong><a href="https://knifemaking.com/">Jantz</a></strong></p>
<p>Jantz offers RWL34 and stainless damascus from Damasteel and Mike Norris. And a range of standard knife steels and Crucible steels like 440C, CPM-154, 154CM, S30V, S35VN, S90V, AEB-L, S110V, S60V, CPM-D2, 20CV, 3V, 4V, A2, 80CrV2, 5160, 1084, D2, 1095, CPM-M4, and 52100.</p>
<p><strong><a href="https://usaknifemaker.com/">USA Knifemaker</a></strong></p>
<p>USA Knifemaker has a pretty wide range of knife steel including 1095, 1075, 1084, 15N20, 52100, 80CrV2, 8670, 3V, 10V, CPM-D2, O1, W2, Vanadis 8, Chad Nichols Damascus, Damasteel, AEB-L, 440C, Nitro-V, Elmax, S45VN, CPM-154, S35VN, 20CV, VG10, and S90V. Tracy Mickley of USA Knifemaker tells me they will be getting in 50100 and 5160 in the near future.</p>
<p><strong><a href="https://popsknife.supplies/">Pop’s Knife Supply</a></strong></p>
<p>Pop’s has a medium size range of knife steels but their offerings are good for what they are. Inventory includes CPM-154, 80CrV2, 1084, 440C, O1, 1085, A2, 8670, S35VN, 15N20, W2, 5160, D2, and 52100.</p>
<p><a href="https://trugrit.com/product-category/knife-components/steels/"><strong>Tru-Grit</strong></a></p>
<p>Tru-Grit offers Damasteel, AEB-L, CPM-154, 440C, 5160, 1095, S30V, XHP, D2, O1, and A2.</p>
<p><strong>Europe</strong></p>
<p><strong><a href="https://www.gfsknifesupplies.com/">GFS Knife Supplies</a></strong></p>
<p>I have experienced very fast shipping to the USA from GFS despite their location in the UK. They offer 8670, Blue #2, White #2, 26C3, 1075, 1075+Cr, 1080, 80CrV2, 1095, 15N20, 52100, O1, O2, 1.2419, 1.2519, A8 Mod, A2, D2, D2, S7, D6, M2, 3V, 4V, Z-Tuff, Z-Wear, 1.2210 (Silver steel), RWL34, 440V, Becut, 17N2, Niolox, N690, Z-Finit/LC200N, CPM-154, S35VN, S90V, S110V, <a href="https://knifesteelnerds.com/2019/12/16/vg10-and-super-gold-2-takefu-stainless-steel-properties-and-history/">SG2, and VG10</a>.</p>
<p><strong><a href="https://www.barmondsheffield.com/">Barmond Special Steel</a></strong></p>
<p>Barmond in the UK offers 420, 80CrV2, AEB-L, Damasteel, N695, Becut, X50CrMoV15, 14C28N, Silver steel, N690, 15N20, RWL34, V-Toku 2, 135Cr13, Blue Super, Cobalt Special, VG10, and SG2.</p>
<p><strong><a href="https://www.dictum.com/en/steel-cca">Dictum</a></strong></p>
<p>Dictum in Germany offers Damasteel, RWL34, VG10, 80CrV2, 52100, D2, 1.4112 (440B), O2, and Blue and White steels.</p>
<p><strong><a href="https://www.brisa.fi/supplies/knife-steel">Brisa</a></strong></p>
<p>Brisa in Finland offers X50CrMoV15, 80CrV2, 1074, C130, Silver Steel, O2, N690, RWL34, Elmax, 1095, O1, 15N20, AEB-L, Sleipner, 12C27, D2, Vanas, 52100, VG10, Damasteel, and Balbach Damascus.</p>
<p><strong><a href="https://www.eurotechni.com/en/">Eurotechni</a></strong></p>
<p>Eurotechni in France offers Damasteel, Balbach Damascus, White #2, 10C28Mo2, VG10, Cobalt Special, Vanadis 8, 56Si7, 45Si7, Vanadis 4 Extra, O1, T508, 1045, Nitrobe77, Niolox, 1075, 1.4034 (420HC), RWL34, 440B, 420, D2, 1095, X50CrMoV15, Sleipner, 440A, NCV60, N690, M390, Elmax, C130, O2, 15N20, 80CrV2, 14C28N, W2, 12C27M, and 52100.</p>
<p><strong><a href="https://www.nordisches-handwerk.de/stahl-rohlinge/?p=4">Nordisches Handwerk</a></strong></p>
<p>This supplier in Germany sells O2, O1, 1.4034 (420HC), D2, N690, 12C27, RWL34, 15N20, VG10, 1075+Cr, A8 Mod, M390, Becut, K390, Nitrobe77, N360, 1.2519, 80CrV2, 440B, 115CrV3, and N695.</p>
<p><strong><a href="https://www.gobec.at/webshop/">Messerschmiede Gobec</a></strong></p>
<p>This supplier in Austria sells Damasteel, Balbach Damascus, Zladinox Damascus, Elmax, N540/1.4034, D2, K390, M390, N360, N690, S30V, Nitrobe77, RWL34, Niolox, 1095, 52100, 1.2419, 15N20, K600/1.2767, and K720/O2.</p>
<p><strong><a href="https://www.si-knives.se/">SI Knives</a></strong></p>
<p>SI in Sweden sells Damasteel, RWL34, Nitrobe77, Elmax, 20C, 15N20, and O1.</p>
<p><strong>Other Countries</strong></p>
<p><strong><a href="https://www.knifemaker.ca/">KnifeMaker.ca</a> </strong>(Canada)</p>
<p>KnifeMaker.ca offers Nitro-V, 154CM, CPM-154, S35VN, AEB-L, 440C, 1084, 1095, 15N20, W2, 80CrV2, O1, and 1075.</p>
<p><strong><a href="https://www.artisansupplies.com.au/">Gameco Artisan Supplies</a></strong> (Australia)</p>
<p>Gameco offers Damasteel, 1075, 1084, 1095, 15N20, 52100, 80CrV2, A2, D2, L6, O1, W2, CPM-D2, CPM-M4, S30V, S35VN, CPM-154, 14C28N, Nitro-V, 154CM, 440C, 12C27, and RWL34.</p>
<p><strong><a href="http://www.kmts.co.za/">Knife Machines Tools &amp; Supplies</a></strong> (South Africa)</p>
<p>KMTs offers D2, O1, 14C28N, 5160, and M390 steels.</p>
<p><strong>Damascus</strong></p>
<p>Then there are small companies that turn steel into other steel products like Damascus. Companies like <a href="https://nicholsdamascus.com/">Nichols Damascus</a>, <a href="https://mikenorrisdamascus.com/">Mike Norris Damascus</a>, or <a href="https://damasteel.se/">Damasteel</a>. They don’t make the steel but they are making Damascus Steel. Meaning they have to forge weld, forge out, surface grind, etc steel for distribution. These are more boutique products of course but could be seen as another type of steel manufacturer. Damasteel also distributes some non-Damascus steel products like RWL34 or Nitrobe77.</p>
<p><strong>Influence of Manufacturers vs Suppliers</strong></p>
<p>The steel manufacturers typically have the most power in terms of what steel is going to be made. And especially when it comes to what new products will be developed. However, there have been cases where steel suppliers have been able to push for the development of new products, such as Niagara Specialty Metals with <a href="https://knifesteelnerds.com/2019/11/01/crucible-s45vn-steel/">CPM-S45VN</a> or New Jersey Steel Baron with <a href="https://knifesteelnerds.com/2019/09/23/nitro-v-its-properties-and-how-to-heat-treat-it/">Nitro-V</a>. Sometimes the suppliers are large enough to push for different available sizes (like 1/4″ thick AEB-L) or to bring back defunct products like Niagara did with <a href="https://knifesteelnerds.com/2020/08/17/cpm-s60v-the-forgotten-super-steel/">CPM-S60V</a>. So the suppliers can influence the products that are available. <a href="https://knifesteelnerds.com/2019/03/04/all-about-aeb-l/">AEB-L</a> has become extremely common in custom knives over the past few years in part because its available …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knifesteelnerds.com/2020/09/14/the-companies-that-bring-us-knife-steel/">https://knifesteelnerds.com/2020/09/14/the-companies-that-bring-us-knife-steel/</a></em></p>]]>
            </description>
            <link>https://knifesteelnerds.com/2020/09/14/the-companies-that-bring-us-knife-steel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706485</guid>
            <pubDate>Wed, 07 Oct 2020 09:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BitSyntax for Smalltalk]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24706342">thread link</a>) | @tonyg
<br/>
October 7, 2020 | https://eighty-twenty.org/2020/10/07/bit-syntax-for-smalltalk | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/10/07/bit-syntax-for-smalltalk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Part of a series:</strong> <a href="https://eighty-twenty.org/tag/squeak-phone">#squeak-phone</a></p>

<hr>

<h3 id="hand-written-binary-parsingunparsing-sucks">Hand-written binary parsing/unparsing sucks</h3>

<p>As I’ve been working on a <a href="https://eighty-twenty.org/tag/squeak-phone/">mobile Smalltalk system</a>, I’ve found myself needing to decode
and encode a number of complex telephony packet
formats<sup id="fnref:telephony-complex"><a href="#fn:telephony-complex">1</a></sup> such as the following, an incoming SMS
delivery message containing an SMS-DELIVER TPDU in
<a href="https://en.wikipedia.org/wiki/GSM_03.40">GSM 03.40</a> format,
containing seven-bit (!)
<a href="https://en.wikipedia.org/wiki/GSM_03.38">GSM 03.38</a>-encoded text:</p>

<pre><code>02 01 ffff
01 28 07911356131313f3
04 0b911316325476f8 000002909021044480 0ec67219644e83cc6f90b9de0e01
</code></pre>

<p>It turns out there are a <em>plethora</em> of such binary formats needed to
get a working cellphone.</p>

<p>I started off hand-rolling them, but it quickly became too much, so
I <s>borrowed liberally</s> <strong>stole</strong> from Erlang, and implemented
<a href="https://squeaksource.com/BitSyntax.html">BitSyntax for Smalltalk</a>. (After all, I am
already using
<a href="https://tonyg.github.io/squeak-actors/">Erlang-influenced actors</a> for
the Smalltalk system daemons!)</p>

<p>I’ve
<a href="https://docs.racket-lang.org/bitsyntax/">done this before, for Racket</a>,
and there are plenty of other similar projects for e.g.
<a href="https://github.com/squaremo/bitsyntax-js#readme">JavaScript</a> and
<a href="https://bitstring.software/documentation/">OCaml</a>.</p>

<p>Every language needs a BitSyntax, it seems!</p>

<h3 id="what-does-bitsyntax-do">What does BitSyntax do?</h3>

<p>The BitSyntax package includes a <code>BitSyntaxCompiler</code> class which
interprets <code>BitSyntaxSpecification</code> objects, producing reasonably
efficient Smalltalk for decoding and encoding binary structures,
mapping from bytes to instance variables and back again.</p>

<p>The interface to the compiled code is simple. After compiling a
<code>BitSyntaxSpecification</code> for the data format above, we can analyze the
example message straightforwardly:</p>

<figure><pre><code data-lang="smalltalk"><span></span><span>parsedMessage</span> <span>:=</span> <span>SmsIncoming</span> <span>loadFrom:</span> (<span>ByteArray</span> <span>fromHex:</span>
    <span>'02 01 ffff</span>
<span>     01 28 07911356131313f3</span>
<span>     04 0b911316325476f8 000002909021044480 0ec67219644e83cc6f90b9de0e01'</span>)</code></pre></figure>

<p>and, if we wish, serialize it again:</p>

<figure><pre><code data-lang="smalltalk"><span></span><span>serializedBytes</span> <span>:=</span> <span>ByteArray</span> <span>streamContents:</span> [<span>:</span><span>w</span> <span>|</span> <span>parsedMessage</span> <span>saveTo:</span> <span>w</span>]</code></pre></figure>

<h3 id="how-does-it-work">How does it work?</h3>

<p>Syntax specifications are built using an embedded domain-specific
language (EDSL).</p>

<p>For example, for the above data format, we would supply the following
spec for class <code>SmsIncoming</code>:</p>

<figure><pre><code data-lang="smalltalk"><span></span>        (<span>1</span> <span>byte</span> <span>&gt;&gt;</span> <span>#msgType</span>)<span>,</span>
        (<span>1</span> <span>byte</span> <span>&gt;&gt;</span> <span>#type</span>)<span>,</span>
        (<span>2</span> <span>bytesLE</span> <span>&gt;&gt;</span> <span>#simIndex</span>)<span>,</span>
        (<span>1</span> <span>byte</span> <span>&gt;&gt;</span> <span>#id</span>)<span>,</span>
        ((<span>1</span> <span>byte</span> <span>storeTemp:</span> <span>#payloadLength</span> <span>expr:</span> <span>'payload size'</span>)<span>,</span> <span>'payloadLength'</span> <span>bytes</span>)
            <span>&gt;&gt;&gt;</span> <span>#payload</span> <span>&lt;&lt;&lt;</span>
            (
                (<span>SmsAddress</span> <span>codecCountingOctets</span> <span>&gt;&gt;</span> <span>#smscAddress</span>)<span>,</span>
                (<span>SmsPdu</span> <span>codecIncoming</span> <span>&gt;&gt;</span> <span>#tpdu</span>))</code></pre></figure>

<p>along with appropriate specs for <code>SmsAddress</code> and <code>SmsPdu</code> (omitted
for space reasons here) and the following for the <code>SmsPdu</code> subclass
<code>SmsPduDeliver</code>:</p>

<figure><pre><code data-lang="smalltalk"><span></span>        (<span>1</span> <span>bit</span> <span>boolean</span> <span>&gt;&gt;</span> <span>#replyPath</span>)<span>,</span>
        (<span>1</span> <span>bit</span> <span>boolean</span> <span>&gt;&gt;</span> <span>#userDataHeaderIndicator</span>)<span>,</span>
        (<span>1</span> <span>bit</span> <span>boolean</span> <span>&gt;&gt;</span> <span>#statusReportIndication</span>)<span>,</span>
        (<span>2</span> <span>bits</span>)<span>,</span>
        (<span>1</span> <span>bit</span> <span>boolean</span> <span>&gt;&gt;</span> <span>#moreMessagesToSend</span>)<span>,</span>
        (<span>2</span> <span>bits</span> <span>=</span> <span>0</span>)<span>,</span>

        (<span>SmsAddress</span> <span>codecCountingSemiOctets</span> <span>&gt;&gt;</span> <span>#originatingAddress</span>)<span>,</span>
        (<span>1</span> <span>byte</span> <span>&gt;&gt;</span> <span>#protocolIdentifier</span>)<span>,</span>
        (<span>1</span> <span>byte</span> <span>&gt;&gt;</span> <span>#dataCodingScheme</span>)<span>,</span>
        ((<span>7</span> <span>bytes</span>
                <span>transformLoad:</span> [<span>:</span><span>v</span> <span>|</span> <span>'self class decodeSmscTimestamp: '</span><span>,</span> <span>v</span>]
                <span>save:</span> [<span>:</span><span>v</span> <span>|</span> <span>'self class encodeSmscTimestamp: '</span><span>,</span> <span>v</span>])
            <span>&gt;&gt;</span> <span>#serviceCentreTimeStamp</span>)<span>,</span>
        (((<span>1</span> <span>byte</span> <span>&gt;&gt;</span> <span>#itemCount</span>)
            <span>transformLoad:</span> [<span>:</span><span>v</span> <span>|</span> <span>'self userDataOctetsFor: '</span><span>,</span> <span>v</span>]
            <span>save:</span> [<span>:</span><span>v</span> <span>|</span> <span>'itemCount'</span>])
                <span>storeTemp:</span> <span>#userDataLength</span> <span>expr:</span> <span>'userData size'</span>)<span>,</span>
        (<span>#userDataLength</span> <span>bytes</span> <span>&gt;&gt;</span> <span>#userData</span>)</code></pre></figure>

<p>These are non-trivial examples; the simple cases are simple, and the
complex cases are usually possible to express without having to write
code by hand. The EDSL is extensible, so more combinators and parser
types can be easily added as the need arises.</p>

<h3 id="how-do-i-get-it">How do I get it?</h3>

<p>Load it into an up-to-date trunk Squeak image:</p>

<figure><pre><code data-lang="smalltalk"><span></span>(<span>Installer</span> <span>squeaksource</span> <span>project:</span> <span>'BitSyntax'</span>)
    <span>install:</span> <span>'BitSyntax-Core'</span><span>;</span>      <span>"the compiler and EDSL"</span>
    <span>install:</span> <span>'BitSyntax-Examples'</span><span>;</span>  <span>"non-trivial examples"</span>
    <span>install:</span> <span>'BitSyntax-Help'</span><span>.</span>      <span>"user guide and reference"</span></code></pre></figure>

<p>You can also visit the <a href="https://squeaksource.com/BitSyntax.html">project page</a> directly.</p>

<p>The package <code>BitSyntax-Help</code> contains an extensive manual written for
Squeak’s built-in documentation system.</p>

<p>Enjoy!</p>


  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/10/07/bit-syntax-for-smalltalk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706342</guid>
            <pubDate>Wed, 07 Oct 2020 08:33:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crouching T2, Hidden Danger]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 110 (<a href="https://news.ycombinator.com/item?id=24705645">thread link</a>) | @xrayarx
<br/>
October 6, 2020 | https://ironpeak.be/blog/crouching-t2-hidden-danger/ | <a href="https://web.archive.org/web/*/https://ironpeak.be/blog/crouching-t2-hidden-danger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="info"><div><p><h4><br><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" width="25" height="20"><path fill="currentcolor" d="M448 0H64C28.7.0.0 28.7.0 64v288c0 35.3 28.7 64 64 64h96v84c0 7.1 5.8 12 12 12 2.4.0 4.9-.7 7.1-2.4L304 416h144c35.3.0 64-28.7 64-64V64c0-35.3-28.7-64-64-64zm16 352c0 8.8-7.2 16-16 16H288l-12.8 9.6L208 428v-60H64c-8.8.0-16-7.2-16-16V64c0-8.8 7.2-16 16-16h384c8.8.0 16 7.2 16 16v288z"></path></svg></span>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4></p></div></div><div id="features"><div><p><h4>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4><hr><br></p><p><strong>Let’s talk about that thing nobody’s talking about.
Let’s talk about a vulnerability that’s exposing 2018-2020 Macs while most are declining to act nor report about the matter.
Oh, and did I mention it’s unpatchable?</strong></p><p><strong>Buckle up buckaroo, we’re in for a wild ride.</strong></p><p>Skip to <a href="#security-issues">#security-issues</a> for the technical mumbo-jumbo.</p><h2 id="preface">Preface</h2><h3 id="attribution">Attribution</h3><p>The following post is an industry analysis of the code and research performed by <a href="https://twitter.com/axi0mx/">twitter.com/axi0mx</a>, <a href="https://twitter.com/h0m3us3r/">twitter.com/h0m3us3r</a>, <a href="https://twitter.com/aunali1/">twitter.com/aunali1</a>, <a href="https://twitter.com/mcmrarm/">twitter.com/mcmrarm</a> and <a href="https://twitter.com/su_rickmark/">twitter.com/su_rickmark</a> who poured endless hours of work into this, allowing companies and users to understand their risks concerning this issue.</p><h3 id="intel-vs-silicon">Intel vs Silicon</h3><p>This blog post only applies to macOS systems with an Intel processor and the embedded T2 security chip.
Apple silicon systems will run completely on a set of Apple-designed ARM processors and mighth have a different topology, e.g. based on the A12.
Since the A12 chip seems to have fixed this issue (to be confirmed), it’s highly likely the new Apple Silicon machines will not be vulnerable.
And while the new upcoming Intel Macs at the end of year will probably receive a new hardware revision of the T2 chip (e.g. based on the A12), we are still stuck with this vulnerability on Macs between 2018 and 2020.</p><h3 id="so-about-this-t2-thing">So about this T2 thing</h3><p>In case you are using a recent macOS device, you are probably using <a href="https://support.apple.com/en-us/HT208862">the embedded T2 security chip</a> which runs <em>bridgeOS</em> and is actually based on watchOS. This is a custom ARM processor designed by Apple based on the A10 CPU found in the iPhone 7.
The T2 chip contains a <em>Secure Enclave Processor</em> (SEP), much like the A-series processor in your iPhone will contain a SEP.</p><p>While newer Macs and/or Apple Silicon (including the dev kit) will use a more recent A-series processor such as the one found in the recent iPhone (A12), current Macs still use the A10.</p><p>It performs a predefined set of tasks for macOS such as audio processing, handling I/O, functioning as a <a href="https://en.wikipedia.org/wiki/Hardware_security_module">Hardware Security Module</a> for e.g. Apple KeyChain or 2FA, hardware accelerating media playback, whitelisting kernel extensions, cryptographic operations and <strong>ensuring the operating system you are booting is not tampered with</strong>.
The T2 chip runs its own firmware called <em>bridgeOS</em>, which can be updated when you install a new macOS version. (ever notice the screen flickering? that’s the display driver being interrupted and possibly updated.)</p><p><em>Edit</em>: I first mentioned the iPad Pro to be impacted by the T2 vulnerability, but while it could suffer from the same vulnerability, it does not contain a T2 chip.</p><h3 id="the-macos-boot-sequence">The macOS boot sequence</h3><p>So let’s focus on the boot image verification on macOS. What exactly happens when you press that power button?
<a href="https://eclecticlightdotcom.files.wordpress.com/2018/08/bootprocess.png">There’s also a visual representation for any <em>conaisseurs</em></a>.
For the enthusiasts, I personally find <a href="https://michaellynn.github.io/2018/07/27/booting-secure/">Booting Secure by mikeymikey</a> a more in-depth description.</p><ol><li><p>The T2 chip is fully booted and stays on, even if your Mac device is shutdown.</p></li><li><p>The press of the power button or the opening of the lid triggers the System Management Controller (SMC) to boot.</p></li><li><p>The SMC performs a Power-On-Self-Test (POST) to detect any EFI or hardware issues such as bad RAM and possibly redirect to Recovery.</p></li><li><p>After those basic sanity checks, the T2 chip is triggered and I/O connectors are setup. (USB, NVMe, PCIe, …) It will use NVMe and PCIe to talk to NAND storage.</p></li><li><p>The applicable boot disk is selected and a disk encryption password is asked if enabled to mount <a href="https://en.wikipedia.org/wiki/Apple_File_System">APFS</a> volumes possibly via FileVault2 disk encryption.</p></li><li><p><code>/System/Library/CoreServices/boot.efi</code> is located on your System APFS volume and <a href="https://support.apple.com/en-us/HT208330">depending on your secure boot settings</a> is validated.</p></li><li><p><em>boot.efi</em> is ran which loads the Darwin kernel <em>(throwback to BSD)</em> (or Boot Camp if booting Microsoft Windows) &amp; IODevice drivers. If a kernel cache is found in <code>/System/Library/PrelinkedKernels/prelinkedkernel</code>, it will use that.</p></li><li><p>Any User Approved Kernel Extensions are initialized &amp; added to the kernel space -if- they are approved by the T2 chip.
<em>This will go away with System Extensions</em>.</p></li></ol><h3 id="macos-security-features">macOS security features</h3><p>So Apple has a couple of tricks up its sleeve to limit the attack surface of any potential security vulnerabilities. A small summary of related measures since macOS Big Sur on Intel processors:</p><ul><li><p><em>System Integrity Protection</em> (SIP): a read-only <code>/System</code> partition so the base install of macOS (including the kernel) cannot be tampered with.</p></li><li><p><em>System Extensions</em>: a move to away from Kernel Extensions, getting external code out of the Kernel framework-wise.</p></li><li><p><em>Secure Boot</em>: verifies the signature validity of the operating system on disk.</p></li><li><p><em>Filesystem seals</em>: every byte of data is compared to a hash in the filesystem metadata tree, recursively verifying integrity.</p></li></ul><h3 id="apple-marketing">Apple marketing</h3><p>As you probably all already know, Apple pushes forward privacy &amp; security as important weapons in todays world of technology.
They tout their devices as highly secure and vouch to handle your personal data using a privacy-centric approach.
While there have been mistakes made in the past (who can blame them?), Apple has been generally quick to fix any security issues that were disclosed to <a href="https://support.apple.com/en-gb/HT201220">their responsible disclosure program</a> or in public.</p><h2 id="security-issues">Security issues</h2><h3 id="jailbreaking">Jailbreaking</h3><h3 id="the-core-problem">The core problem</h3><p>The mini operating system on the T2 (<em>SepOS</em>) suffers from a security vulnerable also found in the iPhone 7 since it contains a processor based on the iOS A10. Exploitation of this type of processor for the sake of installing homebrew software is very actively discussed in the <a href="https://reddit.com/r/jailbreak/">/r/jailbreak</a> subreddit.</p><p>So using the <a href="https://checkm8.info/">checkm8 exploit</a> originally made for iPhones, the checkra1n exploit was developed to build a semi-tethered exploit for the T2 security chip, exploiting a flaw. This could be used to e.g. circumvent activation lock, allowing stolen iPhones or macOS devices to be reset and sold on the black market.</p><p>Normally the T2 chip will exit with a fatal error if it is in DFU mode and it detects a decryption call, but thanks to the <a href="https://github.com/windknown/presentations/blob/master/Attack_Secure_Boot_of_SEP.pdf">blackbird vulnerability</a> by team Pangu, we can completely circumvent that check in the SEP and do whatever we please.</p><p>Since sepOS/BootROM is <em>Read-Only Memory</em> for security reasons, interestingly, Apple cannot patch this core vulnerability without a new hardware revision.
This thankfully also means that this is not a persistent vulnerability, so it will require a hardware insert or other attached component such as a malicious USB-C cable.</p><h3 id="debugging">Debugging</h3><p>Every Apple iDevice (which includes the T2 and the Watch, via a port under the band) ships with a firmware recovery USB interface called Device Firmware Update (DFU), which is triggered when the device is not be able to boot or by pressing a particular set of buttons when turned on. It is always available because it is code run from SecureROM. This is the mode in which checkm8 runs.</p><p>Apple also leaves the ability to access various debug functionality which is disabled on production devices unless a special boot payload is used which runs in DFU. Since Apple is the only one who can sign code for DFU, they can demote any device they like, including the most recent A14 processors.
But since the checkm8 vulnerability runs so early in the boot process, we too can demote the T2 into DFU mode.
Without checkm8, we would not be able to run unsigned code in DFU and thus not be able enable debug interfaces. Once the debug interface is enabled Apple uses specialized cables with simian names (see Chimp, Kanzi, Gorilla).</p><h3 id="impact">Impact</h3><p>Once you have access on the T2, you have full <code>root</code> access and kernel execution privileges since the kernel is rewritten before execution.
Good news is that if you are using FileVault2 as disk encryption, they do not have access to your data on disk <em>immediately</em>.
They can however inject a keylogger in the T2 firmware since it manages keyboard access, storing your password for retrieval or transmitting it in the case of a malicious hardware attachment.</p><p>The functionality of locking an Apple device remotely (e.g. via MDM or FindMy) can be bypassed (<em>Activation Lock</em>).</p><p>A firmware password does not mitigate this issue since it requires keyboard access, and thus needs the T2 chip to run first.</p><p>Any kernel extension could be whitelisted since the T2 chip decides which one to load during boot.</p><p>If the attack is able to alter your hardware (or sneak in a malicious USB-C cable), it would be possible to achieve a semi-tethered exploit.</p><p>While this may not sound as frightening, be aware that this is a perfectly possible attack scenario for state actors.
I have sources that say more news is on the way in the upcoming weeks. I quote: <em>be afraid, be very afraid</em>.</p><h2 id="exploitation">Exploitation</h2><pre><code># install devtools
$ xcode-select --install

# check the script &amp; install homebrew
$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"

# install packages
$ brew install libplist automake autoconf pkg-config openssl libtool llvm libusb

# git clone, autogen.sh, make &amp; make install
# https://github.com/sbingner/ldid
# https://github.com/libimobiledevice/libusbmuxd
# https://github.com/libimobiledevice/libimobiledevice
# https://github.com/libimobiledevice/usbmuxd

# Run checkra1n and wait for T2 boot. It will stall when complete.
# TODO describe the checkra1n exploitation 

# Unplug and replug the usb connection. Checkra1n should now send the overlay.
# TODO describe the usb debug mode &amp; overlay

# Bring up a proxy to dropbear
$ iproxy 2222 44 &amp;

# Connect to T2 &amp; enjoy
$ ssh -p 2222 root@127.0.0.1
</code></pre><h2 id="responsible-disclosure">Responsible Disclosure</h2><p>I’ve reached out to Apple concerning this issue on numerous occasions, even doing the dreaded cc <em>tcook@apple.com</em> to get some exposure.
Since I did not receive a response for weeks, I did the same to numerous news websites that cover Apple, but no response there as well.
In hope of raising more awareness (and an official response from Apple), I am hereby disclosing almost all of the details.
You could argue I’m not following responsible disclosure, but since this issue has been known since 2019, I think …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ironpeak.be/blog/crouching-t2-hidden-danger/">https://ironpeak.be/blog/crouching-t2-hidden-danger/</a></em></p>]]>
            </description>
            <link>https://ironpeak.be/blog/crouching-t2-hidden-danger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705645</guid>
            <pubDate>Wed, 07 Oct 2020 05:52:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VSCode on Google Colab]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24705599">thread link</a>) | @amitness
<br/>
October 6, 2020 | https://amitness.com/vscode-on-colab/ | <a href="https://web.archive.org/web/*/https://amitness.com/vscode-on-colab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>

<p>
<span>

2 minute read
</span>
</p>
</header>
<section itemprop="text">
<p>I recently discovered a way to set up VSCode on Google Colab and use it as an editor to write code and run experiments on the Colab VM.</p>
<p>With this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of a full-fledged code editor. Here is how you can replicate my setup.</p>
<h2 id="approach-1-python-package">Approach 1: Python Package</h2>
<p>In this setup, we use the <a href="https://github.com/abhishekkrthakur/colabcode">colab-code</a> package that automates all the manual setup steps previously described in the <strong>Approach 2</strong> section of this blog post. You can make a copy of this <a href="https://colab.research.google.com/github/abhishekkrthakur/colabcode/blob/master/colab_starter.ipynb">notebook</a> directly to get started.</p>
<ol>
<li>
<p>First, install the <code>colab-code</code> package using the following command:</p>

</li>
<li>
<p>Now, import <code>ColabCode</code> class from the package and specify the port and password.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>(</span><span>port</span><span>=</span><span>10000</span><span>,</span> <span>password</span><span>=</span><span>"password123"</span><span>)</span>
</code></pre></div> </div>
<p>You can also use it directly with the default port and without any password as shown below.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>()</span>
</code></pre></div> </div>
</li>
<li>
<p>You will get the ngrok URL in the output. Click the link and a login page will open in a new tab.</p>
<p><img src="https://amitness.com/images/colab-code-step-1.png" alt="Generated NGROK URL"></p>
</li>
<li>
<p>Type the password you had set in step 2 and click submit. If the page gets stuck for more than 4-5 seconds, refresh the page and you should be redirected to the editor.</p>
<p><img src="https://amitness.com/images/colab-code-step-2.png" alt="Authenticating with password in VSCode"></p>
</li>
<li>
<p>Now you will get access to the editor interface and can use it to work on python files.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt="VSCode Interface"></p>
</li>
</ol>
<h2 id="approach-2-manual-setup">Approach 2: Manual Setup</h2>
<p>I have described the setup steps in detail below. After going through all the steps, please use this <a href="https://colab.research.google.com/drive/1yvUy5Gn9lPjmCQH6RjD_LvUO2NE0Z7RM?usp=sharing">colab notebook</a> to try it out directly.</p>
<ol>
<li>
<p>First, we will install the <a href="https://github.com/cdr/code-server">code-server</a> package to run VSCode editor as a web app. Copy and run the following command on colab to install <code>code-server</code>.</p>
<div><div><pre><code> !curl -fsSL https://code-server.dev/install.sh | sh
</code></pre></div> </div>
</li>
<li>
<p>After the installation is complete, we will expose a random port <code>9000</code> to an external URL we can access using the <code>pyngrok</code> package. To install <code>pyngrok</code>, run</p>
<div><div><pre><code> <span>!</span>pip <span>install</span> <span>-qqq</span> pyngrok
</code></pre></div> </div>
</li>
<li>
<p>Then, run the following command to get a public ngrok URL. This will be the URL we will use to access VSCode.</p>
<div><div><pre><code> <span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
 <span>url</span> <span>=</span> <span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>port</span><span>=</span><span>9000</span><span>)</span>
 <span>print</span><span>(</span><span>url</span><span>)</span>
</code></pre></div> </div>
</li>
<li>
<p>Now, we will start the VSCode server in the background at port 9000 without any authentication using the following command.</p>
<div><div><pre><code> !nohup code-server --port 9000 --auth none &amp;
</code></pre></div> </div>
</li>
<li>
<p>Now, you can access the VSCode interface at the URL you got from step 3. The interface and functionality are the same as the desktop version of VSCode.</p>
</li>
</ol>
<p><img src="https://amitness.com/images/colab-vscode.png" alt="Example of a running instance of VSCode server"></p>
<h2 id="usage-tips">Usage Tips</h2>
<ol>
<li>
<p>You can switch to the dark theme by going to the bottom-left corner of the editor, clicking the <strong>settings icon</strong>, and then clicking ‘<strong>Color Theme</strong>’.</p>
<p><img src="https://amitness.com/images/colab-dark-theme-step-1.png" alt="Switching to dark theme on VSCode"></p>
<p>A popup will open. Select <strong>Dark (Visual Studio)</strong> in the options and the editor will switch to a dark theme.
<img src="https://amitness.com/images/colab-dark-theme-step-2.png" alt="Theme selection interface on VSCode"></p>
</li>
<li>
<p>All the keyword shortcuts of regular VSCode works with this. For example, you can use <code>Ctrl + Shift + P</code> to open a popup for various actions.</p>
<p><img src="https://amitness.com/images/vscode-ctrl-shift-p.png" alt="Action popup in VSCode"></p>
</li>
<li>
<p>To open a terminal, you can use the shortcut <code>Ctrl + Shift + `</code>.</p>
<p><img src="https://amitness.com/images/vscode-terminal.png" alt="Opening integrated terminal in VSCode"></p>
</li>
<li>
<p>To get python code completions, you can install the Python(<code>ms-python</code>) extension from the extensions page on the left sidebar.</p>
<p><img src="https://amitness.com/images/vscode-code-completions.png" alt="Installing extensions in VSCode"></p>
</li>
<li>
<p>The Colab interface is still usable as a notebook and regular functions to upload and download files and mount with Google Drive. Thus, you get the benefits of both a notebook and a code editor.</p>
</li>
</ol>
<h2 id="references">References</h2>
<ul>
<li><a href="https://github.com/cdr/code-server/blob/v3.5.0/doc/FAQ.md">Code-Server FAQs</a></li>
<li><a href="https://pyngrok.readthedocs.io/en/latest/">pyngrok - a Python wrapper for ngrok</a></li>
</ul>
</section>



</div></div>]]>
            </description>
            <link>https://amitness.com/vscode-on-colab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705599</guid>
            <pubDate>Wed, 07 Oct 2020 05:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Writing Documents as Important as Writing Code?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24705092">thread link</a>) | @7d7n
<br/>
October 6, 2020 | https://eugeneyan.com/writing/writing-and-coding/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/writing-and-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Does writing become more important (relative to coding) as we transition to senior roles? How is writing beneficial in technical positions? How can we help the team write better?</p>
<p>As a data scientist, I find myself straddling between building and deploying ML systems (<em>coding</em>), and communicating proposals and explaining results (<em>writing</em>). What’s the optimal balance between writing code and writing documents?</p>
<p>Here, we’ll discuss these questions and more. I’m also happy to have several friends who will chime in with their lessons and advice:</p>
<ul>
<li><a href="https://www.linkedin.com/in/david-said-martinez-3836a72b/" target="_blank">David Said</a>, Principal Engineer @ Amazon</li>
<li><a href="https://twitter.com/Al_Grigor" target="_blank">Alexey Grigorev</a>, Lead Data Scientist @ OLX Group</li>
<li><a href="https://twitter.com/nlpguy_" target="_blank">Pratik Bhavsar</a>, NLP Engineer @ Jina AI</li>
<li><a href="https://www.linkedin.com/in/tsmgrace/" target="_blank">Grace Tang</a>, Senior Data Scientist @ Netflix</li>
</ul>
<h2 id="as-we-grow-how-we-can-contribute-most-shifts">As we grow, how we can contribute <em>most</em> shifts</h2>
<p><strong>At the start of our careers, it’s all about delivery</strong>. We contribute by implementing and delivering systems (via <em>writing code</em>). David describes this aptly:</p>
<blockquote>
<p>“[At the start,] you need to focus on getting your fangs [akin to earning your stripes] on real-world problems. Then, as you get your fangs and grow your career, it becomes more important to share what you know.” – David Said</p>
</blockquote>
<p>So as we gain experience and grow our fangs, the way in which we create impact changes. Instead of implementing systems ourselves, it becomes more valuable to <strong>guide and serve the team</strong>. A great way to do this is via <em>writing documents</em>.</p>
<p>One way (to guide the team) is <strong>providing the context and the why</strong>. As we rise in seniority, we gain context—business goals, organization roadmap, budget—that junior members may lack. A straightforward way to increase team effectiveness is sharing this context and helping the team to understand it. With the context, <strong>they can solve the problem better</strong>.</p>
<p>As lead data scientist, Alexey’s role is to connect the different parts of the organization and have a big picture view of the entire system. While he codes less now, he contributes by conveying the big picture and why to the team. He does this through writing documents such as product roadmaps, requirements, API specs, etc. He advises that seeing the context and communicating it becomes more important as our careers progress:</p>
<blockquote>
<p>“When you grow from middle to senior level, having context matters. Communicating with other teams matters. Understanding if the customer really wants to use what you’re building matters. This is when writing becomes <em>especially</em> important, through scoping the context and sharing the message.” – Alexey Grigorev</p>
</blockquote>
<details><summary>Focus on sharing the “why”, not the “what” and “how”</summary>
<div>
<p>Assume that we’re part of an e-commerce platform. Popular products get traffic and continue to stay popular; newer long-tail products don’t get traffic and stay obscure (even though they might be good). Instead of communicating the <strong>what</strong> (increase visibility of new products) and the <strong>how</strong> (randomly pick the latest product to rank high), we should communicate the <strong>why</strong>:</p>
<ul>
<li>Customers get bored seeing the same products and leave the platform</li>
<li>It’s risky to have a disproportionately large amount of sales concentrated on a small number of sellers and products (i.e., poor seller &amp; assortment health)</li>
<li>New sellers who don’t get traffic and sales get discouraged and leave</li>
</ul>
<p>By sharing the context and the why—and giving space to figure out the what and the how—we empower the team to creatively solve the customer’s problem. In my experience, this almost always leads to a far better outcome than expected.</p>
<p>(In this case, we fixed it with a combination of <a href="https://www.slideshare.net/eugeneyan/how-lazada-ranks-products-to-improve-customer-experience-and-conversion#30" target="_blank">understanding customers unmet demands</a> and providing the ability for sellers to place ads.)</p>
</div>
</details>
<p>Also, with the lessons we’ve learned (read: failures), we can contribute by <strong>helping to look around corners</strong>. We do this by <a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#break-it-down-to-spot-rabbit-holes-and-dead-ends" target="_blank">foreseeing potential pitfalls</a> the team should prioritize early. Or we can suggest (or decide) on problem statements, methodology, and technology. This could involve reviewing design docs and leaving feedback, or writing the design doc and <a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#constraints-how-not" target="_blank">setting boundaries</a>. Thus, our contribution transitions from day-to-day execution to longer-term strategic thinking:</p>
<blockquote>
<p>“As you become a tech leader, you need to think about the future. The experienced are those who know what the corners are and how to look around them. They have to parse the business problems, do the (design and code) reviews, and minimize the errors that the team commits.” – David Said</p>
</blockquote>
<p>A well-timed insight can save weeks, if not months, of going down the rabbit hole. Unfortunately, the reverse can also happen if recommendations of tech leads are ignored.</p>
<p>In addition, we’ll need to <strong>learn how to scale our impact</strong>. The number of systems we can build ourselves is limited. To increase our impact, we’ll need to gain leverage by working with other people, by working across multiple teams and projects.</p>
<p>Here’s where writing helps. It scales well—once written, an API spec can be easily distributed without additional effort. It clarifies—the same spec can help achieve alignment and unblock multiple teams at once. Also, by writing about the lessons we’ve learned and the how-tos, we pave the way for those who follow our footsteps:</p>
<blockquote>
<p>“As soon as you get into a senior role (maybe not title-wise, but having increased scope), you’ll have to work with others. A great mechanism for this is via documentation. If you’ve always been a coder, you might find this boring. But writing documentation, such as how to deploy <a href="https://aws.amazon.com/cloudformation/" target="_blank">CloudFormation</a>, is tremendously helpful both for yourself and the team.” – Pratik Bhavsar</p>
</blockquote>
<p>All in all, this suggests that (as we grow in our careers) we’ll find ourselves <strong>writing more and coding less</strong>. Grace observed that in general, individual contributors (ICs) tend to write more code, while tech leads and managers tend to write more docs. Nonetheless, writing documents is important <em>even</em> if you’re an IC:</p>
<blockquote>
 <p>“Both writing docs and writing code are important: Write good code and perform quality analysis, then write good docs to maximize its impact. You need to help stakeholders be aware of and understand your work so it can make an impact. Not sharing your work means no one knows about it and no one can use it.” – Grace Tang</p>
</blockquote>
<details><summary>If you’re mostly writing docs, how can you write more code?</summary>
<div>
<p>If you're a senior member, the team counts on you to provide the strategic long-term vision and roadmap. To do this well, it’s essential to stay grounded on, and understand, the existing systems and codebase.</p>
<p>Consciously think about how to find time to code, perhaps by jumping into a sprint and picking up a task. Choose an area of the design and implementation that you can dig deep into. Focus on tasks with longer-term goals and a lengthier lead time. This way, your work will not become an immediate blocker for the team (when you get waylaid with higher-level tasks that demand your attention).</p>
</div>
</details>
<h2 id="writing-has-several-benefits-especially-in-tech-roles">Writing has several benefits, especially in tech roles</h2>
<blockquote>
<p>“Writing is nature’s way of letting you know how sloppy your thinking is.” – Dick Guindon, via Leslie Lamport</p>
</blockquote>
<p>Without writing, we might believe our designs are sound, our methodology clear, and our understanding complete. Well, trying to write about it will sort that out. Writing is a hack to <strong>gaining clarity</strong>. Here’s Jeff Bezos on why he banned powerpoint (as a medium at meetings) and enforced six-page narratives instead:</p>
<p><img src="https://eugeneyan.com/assets/jeff-bezos-memo.jpg" title="The fateful email that changed Amazon." alt="The fateful email that changed Amazon."></p>
<p>The fateful email that changed Amazon.</p>
<p>Yes, the audience benefits from reading well-structured narrative. <strong>But the main benefit goes to the writer.</strong> By writing long-form prose instead of bullet points, by adding data and connecting ideas, we’re forced to <em>think deeply and resolve inconsistencies</em>. We have to <em>focus on the single thread</em> that ties everything together. We need to <em>remove redundant details</em> (to fit the page limits). There is no way to write a six-page narrative and not come away with clear(er) thinking.</p>
<p>And even if the document is lost, the research and thinking has already been done. The process and outcomes of the thinking are often more important than the document.</p>
<blockquote>
<p>“Reports are more a medium of self-discipline than a way to communicate information. Writing the report is important; reading it often is not.” – Andy Grove</p>
</blockquote>
<p>I fully agree with this and advocate the practice of writing <a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager" target="_blank">one-pagers</a>. (In my previous teams, it was a must before starting on a project.) The process helps to clarify the intent, desired outcome, deliverable, and constraints. Such practices are also common in Amazon, such as the <a href="https://www.quora.com/What-is-Amazons-approach-to-product-development-and-product-management/" target="_blank">working backwards</a> process and the <a href="https://www.businessinsider.com/heres-the-surprising-way-amazon-decides-what-new-enterprise-products-to-work-on-next-2015-3" target="_blank">press release</a> document.</p>
<p>Also, writing is a short cut to <strong>socializing ideas and getting feedback</strong>. Before starting on (costly) implementation, we can (cheaply) share written proposals to gather feedback. With feedback, our initial designs can be refactored at zero development cost. Sharing our designs—in written form—also ensures our eventual implementation meets the intent:</p>
<blockquote>
<p>“When you write your proposal, you have a way to understand if it’s interesting and useful for others. In contrast, you can write code for a very long time and still not know if it’s useful. Thus, writing the proposal is important to helping yourself and others understand if what you’re building is actually solving the problem.“ – Alexey Grigorev</p>
</blockquote>
<p>The same documents we write to gain clarity can also be used to socialize our ideas. In Amazon, when asked about a project, it’s common to share the press release document (and the six-pager if it’s available). In other organizations, this could be in the form of a requirements doc, confluence page, or API specifications.</p>
<p>In addition, writing helps with <strong>knowledge retention and transfer</strong>. Our memory is leaky—we forget <a href="https://eugeneyan.com/writing/reading-note-taking-writing/#note-taking" target="_blank">as much as 90% of what we read within 7 days</a>. Writing is like saving knowledge to a database. And now, instead of asking us, people can access our knowledge via that database (i.e., writing)—this helps us save time:</p>
<blockquote>
<p>“When you have project documentation, it’s easy to onboard someone onto the project. Instead of having to sit with them to explain it, you can just direct them to the docs. Also, as the organization grows larger, it becomes difficult to …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/writing-and-coding/">https://eugeneyan.com/writing/writing-and-coding/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/writing-and-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705092</guid>
            <pubDate>Wed, 07 Oct 2020 03:45:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissertation: Marine Insurance in the Netherlands 1600-1870 (2009) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24705036">thread link</a>) | @johntfella
<br/>
October 6, 2020 | https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf | <a href="https://web.archive.org/web/*/https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Æ}éÔØ(Oþ`oÁœ®üÁ®‚ây¯ëÅ3WU^ 3«ÐÿèÃ_¿O|@�–k»
Öá‡EÒ¼òã¦½Îõ½ä¡=£ÿ`×Šë÷P²o»æR²óJÞ‚Á®;_£ìj±}øÿëÑÎœÞü¯V9/žÊìt®�Yy±Á�&gt;ƒuŽœÎÛ³ò/68ÑçR§S|¸Ø ÕºÁ¿ó¹jm)á§³lé®ê'[?@·	Ü«ü2ö©�Žß“À=ã=|ô"A£²çq¬¥ðDôän
wDoÖÙ*ëf'Žg«®µèêK6Ør<i©¶¯b|[=s£k¯øä¢ËgŽw3 „²h;t="" b¨®1m0^j‰i$rj˜="" Î%="©Ç" å]ÇwlÊ÷‹$†„‡ÆÄll’ø�ñ+ËâkšÀçáš4Ç¯ªs,xßœ:q‘b<vei©ˆ_o´¿!�ð»Þ~�8ªg¢e³tŠqò¯Ô@bpæp="šƒB¢„Í=‚])\¬0�š„)g8fÕM\�©ÓºzK«û%cß´ù}-×ÌMõv™ùË5ƒF[Kq#ñÈÒ$²¢§î;ÞvÌ({´z9ŠË£‹EÑV¬Öè£drm]³{Û¼ŽÚù&quot;âë¾‹JñB1ÓËw">6-LX±·ËÊ”&gt;Âú.Jeá9¨ev›Ê2ûÜ’3ÉQJå¶…g+ÖçU]&lt;÷åƒ·=Mg&amp;=6~7š&lt;{dÒÁ'¾øŽìùYg3|Ÿœùl[žýc0¥îÕ£[ºî¿}ÉÇ®)TyÀ˜X7¢¹ª@`æ:ÃÁÍ&amp;…õ
e:zÂ$@F²Jt(’œkJu™�ö,
ÆzÞTïžß/f+L¡–E.’1	6­[h¬	
Ö&amp;¹V²5ýEìòè¹bˆ$¬Ž¹þ5ý§C�Eòg©éuÌ€©CV‡%Tíð‘_�VÅ+�Þô»•â›J{f·üBå;KFI\¢^þ-ÓËÖîyqÞ~Œ‚Q!YÂ&nbsp;
ÉªêaóÚ‰T‘Qt¬Û…O”9^5Rƒ�ÄzdW"ÇÚq©-]I×$+FªF­í…èW
áôg¹þFk™Øü“©e!­Ãmý‘šk@’‚#áDýz¥ÍêXY&lt;&amp;©¡S¾ªÝ0Â”EXE‘Á0Êþ9Lr"+"¡«Iã‘zQÄ�aúbˆõ)¤—º&amp;k'%™.úÁ¸øi»°êI”ÂIäu%Œ¹x5·¦¨ï_Å�ù/­…¼‰cæ
m÷}ÎG·DN±ž‘E–¬HAî
—My?ñc1ÁÆÎjV5Î&amp;Ýuýæðe’•Æù;žêæÎëmÅˆ½Û"Äúúük.×¯�·ih£DÖi…·Ü�ïú‘òƒê(ìŒD~Ö¤;ž¹¾§ãÉkÞî�¥}"™4WPm.ïè¿Å¬ñ·íðtC®ÌÑä¦â=‹&amp;µ€”ZYZã(´÷ŽÜ'Fè|ªÂ[÷c6tÎê\oÕ»&lt;ú�ÙŽö
ËVWçtÉíÁÚ;¿zífvÎ;}âË¿›Óûv'žž�¾ô?["ìw‡énÛhØÞÃ€RÜÖF,‹²™´#-/Ò®2ò–#2&gt;ÅžÜ«¬¸š‡¥eeÊscÄ¶f•6ùÕªŠK½=7ÜKd¾\Èÿ£†´_ÚÄqŽÈQ¨%6Ü�Qu(,”HT§ÈåŠý 	�t–Q¦_\¹Hâ¤Iâ{¤­QŒxJ6$�ðú\PÂìºŒ£¦\ZéI?ˆ	˜5ÆPßÅ3‚l’|¾��?$›£QÔŠ�Çää¦:Ë(1¡€pÔ…jWF^ìn
`Þ Cð›Œ[”ÇÎ0Æ+ó&nbsp;dPç�ÔXoGÒ&nbsp;d�2M¾7æÐL@ï@ë”¾ë±Û“¼â·ÀV«‹'O.W‘8¥+¿.¶Û=è�ÞãÁ7D‡o²�8¯u¹Šý„Ûåã	"�Ìˆåæ¢¡_¼—ûe~Hï¢M”�Øí‰ÙÙ„ÕnŸâW™ä¼6;;ÛçóñÒ÷ç.!Eô(Š!–dgçP*j˜ü¤#/�d‚¨'‰’‰z¥ «5–¾ÍS²ãqô	[!z‡ÍËÎ£ºÄKÒO”ÃC%gg‰8è‹ruPóüò[œ²&nbsp;�4v¹^É7¤Ïé¨!(«å¼OqÑÐú4rˆ&lt;â0×„’“â¬­­uæ)¢#GS5”ƒUìWùUì‡S”æÔÖJ¯­V+²y&amp;ÂadÐ¼8ÊQ¡‘G!.V'B$É7«u	
?µKÊ)º(\›KåžÖªSR‚RN˜¬V[
Æz°v“.˜k‘	c!;8§UÃQGíñ(Š‚!ç¬VÁRD‡‚B†Âd¤"’åKIƒ¯!ÆH5Lß"oŠÂ¤T–\¬NJžaØ%E`$7qøÄÔ"¬Q´R:b¤ÁBoËiòÊCäÊU:¤VƒrŽo©9àÖG«¦D|].šJ¥ª„\ÍªÄã0K6Jž–«CJa*…@$÷}¹œSUk'ùé‡I&gt;u}H/€Ôl&lt;Š5¤aP�C²/LKó;¤4h»Ã0Æ,÷©R"!I-òÊ@�[½ž•á?É"ÒQtbiÓ H@¦”:yRâ‹‚Q.z½
rË’“¼°K‘¬§‚À�\EJ4²T¡Ï7$+¤oÉ’&lt;ÔÆrUôõÃ&amp;C\?Æyí—¾mÎ„
E+;4‡rþÇ©ËN&amp;SRir	±Nƒª[)…£…Ü§‚û8¹à¤uœ–oîT.K«6m{z�¢Øƒ;½WfÐ«¨=JfºÒ›H(ëÅñ¤
ùà&gt;B+.•zEÏPß”j‚2Åý‡²µPSƒÀE
”úFw1Q7v‹$�¦6t„¼�È&nbsp;¾ÊŸþäÿÓŸüÿOþä�¿$”¼‡àÏi“b4µÖõ&nbsp;c[ÕnÃŒ6ÍÝh²Šùà?ÂÝ‡müyÍgš]/íÓniÃ¥€ÉÐ&nbsp;ÿ-ÜgªóÇ'qÛO3à)Ø&nbsp;æ%±±o^4£žŸîó­Ýv6»â‘òõ€ãoŸ0Ã�È¯NÕÜ“8)çäØ“¦GóÝÜaÝ�§i3¹µÝ1[¶Ûç€ZÝU-k¨'Äp�&nbsp;¦hÚ™ùÓÙ˜@.—Ì÷h®Â¸¨­Ún˜ÅÛ5X:ä§;Z3Hœ¸‰þî‡Cã&lt;�Xû®øÃÍøÿ
0$�*Œ
endstream
endobj
824 0 obj
&lt;&gt;
endobj
825 0 obj
&lt;&gt;/Font&lt;&gt;/ProcSet[/PDF/Text]/ExtGState&lt;&gt;&gt;&gt;/Type/Page&gt;&gt;
endobj
826 0 obj
&lt;&gt;
endobj
827 0 obj
&lt;&gt;
endobj
828 0 obj
&lt;&gt;stream
hÞ´xy|Uºvµ!Õ=¢R¶†*­Š¢‚Š¢È¨pA‡-ì[Â–�ìI'�­÷îÚº–Þ“ÎNV²�I†U@ÀeTdÔA·qÆÑ9ÍÔÌwï©ÎÜß|ß½ÿ}¿ä—¤;ÕïyÏ{ž÷yŸçh�q·!�_°páòÅË§Í_°½$· eqÁã)é™¥¹Û‹Õÿ&gt;%5Ñ¤qQ*á^%å+ï�ÿôoæxpùÎèá»¢§ï~íþíßN@â5šqwL¸ö§5iY¥ùÙ‹f=ótì×³O-((¬(ÎÎÌ2$?=cÆŒéêÏ§’çï*Ø‘ž¼º¢Ä�žW’¼$gAqaAñvCú®'’ççæ&amp;§¨(INI/I/.ƒoŽ=?–\rvIrz¶!+½8y{rqzf6Rœ¾+ÙP¼}WzÞöâœäõ?ÿíeÆÿ²^rv~2Œ•¼6?[}µÚß,IÞž¿ëI¥ ¶ÊÎ‚Ò|CqvzÉÿ�ò ø…üA¢ò‚ü¨AzÍ=
ƒ :Ds;‚Œ¿
ù•FC!š‰ˆ†D4Iˆf¢yÑÜ�h0Ds/‚ˆf2¢IÖhî@4Sä]™t§G�™ñš‡ÍDó‚|Œ w!&lt;ªGä~™�#ï!H2‚¼€hîC�?!ÈÏò‚ù+‚hÍ£ˆ&amp;A^D�¹rAžG�É»
©@øþÓ’� F©G�&amp;iC�7ä¹ˆ  È5ùA¾F4�!šç
«ÑÄ'ïîBú5û‘×Ä“@–!Ë‘�4¯hNÞ¶à¶ž8qÜ3ãêBOkÿ¨{R·IW®{ïWÓoôŽ	Žñ+Ÿ½ó‘»Vßýä„…*±]Ø™{Lzpïð}‹“žšˆO&lt;„Û‰‘ûÏ?Ð@ž£ÖQWŒ{pdÒŸ“wLIž2øð±©áGª]ý1�˜öíôc�g?þ�'f&lt;áz’òúŒÉ3®<uþÔµ§Ûgb3�=óÉ³§fmŸõ—Ùñ³¥__|¾óÝ¯¿x8›Ó4÷�¹û�Áy=ó�¼d hx0¼púÂ="" _="">»hí¢×Ý\\±ø‡%·/�òªøê•ßLùÍ?–}¸¼qEíJËJÿÊë«ÐUÇSžKÙ·úæZrÝŠõS×ïß°iãøMwn¦¶LÜ¶Þ±õ£Ô�cîÑèw£øsòhœ{\”½¹òï,
$å´^™üñà¨’¬×õÅß}Ú¿£©±¿Á\¾F£Çôê_Šú*1±Ô}œ:§Í—ãÀÔzQûzLýÜ‰¯zçÕ¢UåÙ9dAAU&amp;mÐ™X Â’P+SGŽwï%‡ÓrŸJËVf+I”Ýér8q‡Ç"�
z8«@™7ü„_j$ªöÐÁ+ž&nbsp; 
"'ZIœÀ¹yÎa)+µÛuGUu1‘8Ù&gt;îÓŒ~
”R½—Äno‹Á#€Ç¿[å&gt;%~Ö”dEÿýš÷FÎö4„H‘ËS¦Î}"yÇDË°NÜ)¹|$ˆGôÙ‹{~æ¨ßq?}C¼ÝŸòâ&lt;&amp;µ¢„2Våm&amp;ŸUJ†£íï¿fl5NÌ{Ø&nbsp;UJô7~þÜ&amp;O~{J=ÕîŽ“ÐÚ&nbsp;7,SØ:®/pÂD«Ä	&lt;Ïs+í–Âí„2µ±¬�£¶ÂŠ~Uy£@!ðÇ6­ùMn…'h&amp;eº2\A”[ÍÕv%ë
ë21E)ŽD�¾9ø.,»Š]üQ)ÖƒÛ�î:x`4ûÔÃöÙÐàÉ£¿ÃGÓN,|aÝÊ-’cX�»d&amp;à—DŸ—ìhÚ;0Jœè^Ÿ³è¥Eë­”�chî’h?Ob?3LYŒ+èóÛÖ™|5&amp;2h©U•f‹içyÛ•Øà&gt;M4j@ã»qÑU÷ú=R�êÖÉE*Zð,úŽü£ÜF6J.�‹p°ŒÍIÙLJßßo§]ð¨x.$³ð˜mÊ&lt;´Jdäë¨×#)ð²vñI½²/k¼ˆ&amp;FÇWG@üpTÛ
â"š‘ã__}�àñãqÑÙ×ÿþì‘ãû)IvËœèð&amp;1'rœnWþú�/;w…3¨ÔÃös|DwåÐw,/ì$ÛKjŠ"+¹%ˆ©$É-Ê[o¾Ä¼`·Ó&lt;Ë“L¬…Û%OôZ6w¬&amp;§ääPi[�)«ñ…­ë¦‘Y§�gôs½’¦&lt;§ÌT2”`’ò0€b0Ì;A�òxLÉ¢þ‘2N¹WyõKÀ€
 &lt;æƒ	`Å£ŠE™<ky¥”s‰£–Ñ(¾o·qÈ8aøÓÿÔ�vä?‘¬öè°è¿º4r¶—’¼¢‡+ci¬ÈòŒs·½dÍîÄÎÝ¡þjÃ)Ëûƒø'ü‘ï¿#†jz©Ž‚šb¯at ¬,´Éi’àñðÖÀ·Ù¾áv°¤�åxžb­ñxo;Ýv�{+tžÖ¸‚˜—’�[@¥n*]±uÏk¯§’¹}#ew‰d0‰�dõd“"yÝÀø+ é3l8="Ö°�Sîçì$Í;¬f&quot;" exŽ¥°-¥z§ÀÉ¤çc©6ü'®‘è‰â…sÔá‘ðáËøÅgÒÉã+^ñ="">N”.a+Ëç9&amp;Á2–kÐÒ'‘hcÀa(±JœW‰_©Ôc[Bî�…NRIþ&nbsp;Gç¶¸ÃÄÅ“ÅéýTg^Ûf­n«iKI™‘·"çUÂPèÛ({
ªÅù^þ/~&lt;ñæ�l$süp0/ìØÑÀ{	d]ÂŒ7ïŒ;¸Ô­ÜÆ–“®š©"ÊP+Ã;)ÌX¡uJ¬LöK£‡‡ý	“¼¢ì£°ƒ
Z/#:É&lt;´œ
ôR _Ûj„ÈÞ®Hp/ÑÞb/o¦öÊ;WãÏks„u¼‰¬ä�\%a@]<kÃ°•z‡ÈúÈ@dzý�^_,¬ŸÂ"uz+:Èj´¬jª¡š¸s§ð7´'Ä£©ÈÎ‚üÚídÚ*Ãö,Š¾€Žº�aj ›$‡—&\¬h³p¥v¶€×afnÓ6fÑ“ÑÇ·Ëâ:="" +Èlre­9�$1¬@="" Ãš9Š³f)z[&ç’x‰o¤“<¼$ˆÆpo÷{‡ÂºšÁ="" Ü½d»dËÝÊy6Ÿ´ð‹‘x¬nÁi•k]ã'Ã¤o¿ï="" &l="" ’‡jÑúxÉnþ-qÔµsßà}aìïÒ¾þ5wÝm="" k6îÄ•“Úd%t3Ó¨ùá\Üïnfês*Œ†´¶�cùx¿ÅŒoÚžvf$.7gãnzb}~�Ç“0¹1ôÅ…¯ñs[ºsÉd�ÌfÀõ#À1r82á¯—ÀŽkØÕ¿‚€^y©5ðŒ¥œØŒ:8Ž¦jµ´ÈyiÿqéäÈ€7a’g­s½ÖË‰v²-c="" 0Í�û¸¿v(ñÚØýïú?ý÷�)ÿà6-v²@yúâe�÷:="" e|3ú÷ÅÀÙµ§Ó×a4…�uµ”l‡ÌzÇøƒ\�¨ïhjÛŸÖ¸eýêŠ”õö]Ä°¹i±vmÙªuÔ®´‚¥="" âå«´–wñ“ïâ%Úc¼ƒ^úh?Èý^�Ûº××mtÔÓæ="" ®è­è‘.©dweÊ¼\Ù½Ö€‰ã€hõ™ÆÒâ�#–="" cùÙ€ÉŒ¯Ù²©¤”t8ur†œÇú}="">¯7arsÍwïÿ„Ÿ_ß—E&amp;¦û)Í1p&lt;îìZä}	zQ¸O/µ_PÑªô¡NŽwQ‰&nbsp;Õ¼n�÷Zô=í{ú
[ó7ZvUn²ì¡•Û•ù›®9ûnÜY0¤ŸÔòäÀ&lt;òÀ3§×§ë\&gt;ç!¡&nbsp;ÇÃúh/5íû%ëq°ám0ñ›?’^¯ä—q�5`§�í$wìZ³&lt;óÝÎY…Ï'ã¿©ïÆ�Vú§²’Û¿XurÇ&nbsp;ÎãtŠ4a·ÚiZ‚ê‚úöÑ·\Y�+–(§?Bº\¬“Áé�-àñ‰^9¼ÿä¹ÈÇº¡Ï:¯þO³‘ò²è‹‘	@g#Ø¡¨ðúaî¼ç0=¾v"ˆÊ¢$CèCHÐ¤3‹-ËÙéŒæ –¨àñ�
hC�Ëâ¡&lt;iU	.æ¹)øFk©}üª¢¥¬Í)¬¬ó2.ÑDXÜe\•µJ0'L6[Ž`8V
Äˆ�NhW{e&amp;5I«Äsyi`«œ6H*,T‘Êœ"é?$…÷AJñ¨Ó­M+»aZe¨Íje).ÀüpˆÚúŠ«
ÒV2¿¶áðV&gt;¼ißŸSÇÊAg€¨‘‚*l€=¶|˜Ñ¨œ/\‰‹6Ÿ¾UøS^ë
Õ“¨_€[oR»ÞA:V°•¥Ë¬±­Ó”AÍØCî…êÇZF9Ä9…¸]ë`8©”¡.’…_Û-\àuÁPÙ…ú ÷ŒÑEZSØÒâ¥0’ŠKªl¬;ÑÆ�=Ÿ²‰svâÚ*N¹ËŒ—ñ|•�ÈEiŽWWŒ;ü–Ô´çTMÂ¤Ø±ìÑz8‘�<mrz{xŠorß€´qð“  É�äíÚ="" nŠ="" 7°–jrŒç�š="¤çú³RKïÑ€JÏ0»=Z™—2-sy*Àƒ„‘6M8˜aáPß¥">ÆúNFŸ×³"c�è·£š²Óí¸…Sž³§’Õl•9Ÿ0£¬ºŽQë`ÎÞ7¤==#*»’¤æ¬®S�æ™‚†âj@øqì-Ÿžƒ¤ˆÖ–¼®èÂy¾ê/”­­sIí%üž€W‚bá"˜\ÛÞÐ÷	˜ë	Š|’²Akã‚¯&amp;íN«‘ÌA™±u�"œj¾sR{ÿ)¿Êj’Š(¡Xr7Zåªo¢°&gt;w€IîZwXÓ	S‚‚
m¨gî±�eì$k°Ñ¬“‡e™rwUNEú¦©ŽrÖ§LŸÄûØw„ÙÈ¬v%LbÕ¶HüÔ²$íÖ}šáÏ�â*
Ü¯oh’ƒ°U$– –
C2©\ÆÚM®˜8P›€U5EÚÑê4PZ#g6ÛHsUŽ=‹(ØY×]@í.}ã
~hÏñî&gt;rh`0ÔCî2tRm%
¹¾*É!Â×ä…¢‚
çÍðà&gt;N¶;X–áHÚÎ±ŒÛá›.ßÒ¸™X¸¼lçjóö¢åËñ9Ík‡ÒÈõ#Ÿ”#.œw§|’,A²òðÄ¯`—$÷jB`ØÖÅ�OÀ|½ßÐù‚lÔ9»…¬‚š¶p™–hY{Fjj=áéàqµh%µŒåhee&nbsp;ÑL9ƒÛÀíÕ£æ¡
à!Ó�ÎÇq²‹p10;Êî(¨(‡&amp;�ƒ5àY	BÝÇº¬œËU¹R¹ßi*Ù¸AIp:tVG•­’0¡Œž2\ÒMCÖ•šê�ûcè’ÇPì"‹áìªmöRrMï5¹FW×«÷ß�K~�_=B Q¢cDyL6é?`#»ûÀÌn°&gt;’Óq~&lt;ý)Ö%`¹ž_.¬ä7éJ-L	iQáÅÆZQ…×Q©½ï„ïVûÜ:Ó"Ôè
…9
 Ú6­è¸ƒÄ�ºÒe*P}ðù&amp;“ËÚ„Ö`
 °~&gt;èçE"ÖÊÍZ/¬U…YšÈò°¡ÛÔ¼ã´±ÇàÑ‰Ú�»‡.â­æ½¥-äžâÔ†„ùÖR±Œ†ÈQóÁ†!�
¬DÑ®€Õ(PÓ´Xÿe&nbsp;Ñ7ÖÉuC]öÊN²ÑRW˜‡UÎQâÌ6Ap’‰Wá¹.ê#±íRàe&gt;x‹‚�&nbsp;Yß.~[ƒ×zä²ýWÏBúßÆ–d¥Aúwñì`aÑ&amp;Ñ=�ôHž§}IxÊe+ë¢mD©Z.:Æp09ù¤ÔÜõºWe.9Öaj¹ÊP»Õ&nbsp;ÜW=xŸOë
p®t‚x%ÙkÕAqä°4±0µ©Ãm'þFæ ÂªPGµ„ó(³Á{P‡ýÔÕ÷Ð4u5-�nèËÑ:Záã�\9¬1/5V&gt;~Œ
!™Éh�ç(å²)qJRµCç²Ú9\=ñ(Û�k{À3‘ü½°\ê£”Ï°'¢/ê]nÞC6¡MM|¶H	Vñåb|¾+]çžËšH3k·T…PRÂe°eÐ5@ÚmˆH�ûúö%Lzw$î¤úêš÷ãï¤íŸÛJŠZìµó­ÝõçñSwz3YcØîYM”ìbK+Ûáèáa9ÁƒJ¡Û×»W°ì£ö›;s7à¯l(JÝhê:B‚�ã¸O
µ¤à=^A'x}ngMû�ÕÍT{¹§¸/³–“Fs&amp;³UÒ%³=¹‘Ý] ¥¼¸/f~4=Ø‹`Sô9ýÏ\|°ž±ÖP
UGVÃ¤á¬ê}I¢ày™ó|Ît5ô¥Œ™³Š��¯^#U�8U¨F'ˆy™2‰lÂÒuø2-¶E™¦5±ÌÒ&gt;6Š°ƒŠ]�·AHìÅÆF!ðÓÛü¤]~¸Ž—Šc‘Šü,HœÄ	«ñØ\V¤¡µ³Ue¥:\ºÂì&gt;�Ø–/�PµÜé~|Ÿ6ØïvvS.o•§XÇ¢["ZÄxIdŠ¯e{öà÷q1@Ê+2D©ÏÀãÉµ™ŠœçXÉºUé�ÌÿMí��Çýß
p—¥_w‚ž}´qÂ…ƒÛß³;ŠÎaÝ`7´ºG.|8ji7¶PXGqGFhkC¹/³®ºIg­¥[êðÆú×N’XÏÞ=¶Ê:ª¥ÄŸåµê€å›K8VÇ‡íoõá^v8X7Ë‘Œ3ëähZ°yu^K™/�ÈÌ±—Q¥åe¹Ùø¦šœÖRëè.<rÑìÔ7§àÛ6ç�xwÆîæîj Ë®ès·„q™�¬ãa“1pbt9_€6‹–="" çç<�Ù$’è÷ò="">Z‡uW´öW%ÿjÙ}´_3ü8ùyè²è&lt;½ÿÄ~ªû@ðõ#ø—éç¶í'n\ØJ,Yf^¸’Úœâ\±üØË%döÑ3¶~Â»O¿9ù˜y´áÂà~jdº#âÌõ•ûÖÚ”•¨ÄNÈNOwƒ
cŽü2˜ñ9vÒq‰~÷o…vÓÅ–E(ËÆæ€+FÇg Ÿ›öc#6¦fŒv_-ÜVÀ}¥ïÐ²µ|Æ�?öY¤&lt;’ÓBµedùŸ%Êv²–²E®_øô»â1AF#&gt;Ömz¹{ó»zÜ©—­îÑ{µx¡�3Û+©¼ªÃN¢¨R”íTbt|Ì·5�s¤àÈ˜sƒß÷h±wÿ?Û·¾KÝcœx+€ƒLE«¸š0ÅýòùDíûµUK)e²v¦¶‚§!?ïD�,T&nbsp;F­K‚*-¸W:s¾=v ù¨Dr’ÛÐjÆß¨&amp;Ä�F‹E¾tŸ‡ÆÜ'¸=NÂ[ØNaï:²2œé„2ºAñÓ‘£d[KW¨“h[*j©Â–K+±§£¾�§"©½k6Ì)[µ™Ä.nhÚø?A'œ…ÿ³4öTö‹Ðí®X{Ë”EçG4]`5ˆ³â@A4EïQÕ¶k9[R´æ—QY&lt;6³‚h­ßaõS&gt;[÷Œ†­¾Ò$éqeÊž•:‡äqú¡Ø”&lt;å¯ýl´;N€ûššt�@ØÛDÔ£ÿ}|¹RÙ
ÃúnØ1]QBdX^saºGÑÕ›”»\e:uÕg�£]Wø»ÊÁV¼¶N¬%[QY‚.&amp;±ÔrvÿØ­ø¬ºþhÒ××ˆáÁ€(Ú�íiÛ¨uël¯ìÂ_dôo ×œ¯|ƒ¸~ìâP#å	q+˜}I¬&nbsp;j_ÝîÊmYË‰–}ð}«P/(¹[ÿAÓ�½‰·j–ìºœz¤èENt‹"¸ïë¤®AÃþB¢Âl1[©iÊç†„&gt;1aÑð7«ã¢é&nbsp;GÞ9¬ÜãÏÔøì¶¢uÁ£‚;vIp&amp;·öK×®¶4&amp;LòIP	µ«3Ù…vqQM_%eÚ»,7|T~a0”Ÿ×…XÎë"h–¡iÊjJË+péœ0ogdH:¤ÏJ›Y›½ðy%ÇiÌÿõKÊ2g•.Çd2åY(Ã@Ì—ÀvW�Ðé·g†Ã°i$Ñ»‡�ä´Ôâ{Ä&nbsp;à£&lt;-'Áô`»®6¢÷µžZ¨ýdŸLH¢Ó)Qžê«ŠÈÓ%‚,¶7g|ÜzUñGþXn,ÿÖHðžËÿ5§$±2‡¡-¹°q�jßaûŠT†¨!›ÎH£/&amp;LºñF°ãuxoÏ{GñŸ—ž}¬—dÅx¬ÿ£áƒíÄÏ§ô�ÍY¯úæY+Øœ©UPCÅ(káôp=·
Ê
QIÌÀÿ’¾=&lt;ÂW
SgÃëžÇ•;æî|nvéð
�Z0wÖMøBh&amp;^Ÿ_$EˆGGíÅj&nbsp;°fg:žV�º#—¬,Iµ§••n±Þ£ÕoÜÄû5G~ˆ–µÅE§WëÁƒß]ýâ,%A,³¢9˜ÄJP|Óº¥[g.Sâ‰WRü—Ss&gt;¯ñ§qð0	Ì‹‰��go;@Ø¶gsx·j9<b�œ$‚Ì{tt—lmÂÃ�¿ìœÛÅ‘Ž|ÎiófÿÄ–ÌyûfŠæ©-k7pþ#oÚø´~ewi1¹æì‡àv"1ªq�áæ]±3xèfôå±ðpô=¶e£”²edgu”¯ 4Ó e·="" ñ�ôÅ¡Ëç&]¤ûço©·="" õ]zè¶^[zŠüp¦‚Ô)zÂ0•-z*Í="" •u¥x_!.n'ÑÎz¦d¢Äji™t„ß(Òc="" õnpŸp€öÈõá€.Ø0ìÞc€¸ßïj9fy·ï©9øŒÜ_o_o¾ºqvÚbãÎpkenfê›qþæÖbËl«w±™}àý^p`0£xø6ØoÎÖƒel'ßei1ml«þ`:¼œÌjb�?i†"…—Ù`x€="" ë$žiºœ«zäþ"="" ]’%•±+lÓ­Ì#è@Ð™#ca%*wÏÆÕ*6mãÜjª¤®n1t¨¥%Î¨„›ÕÜ%="" €ßñg="" ,ÄŸÝÃ{ˆŸ7="" qÇÁtÉï–h="" *+ØË="" koÄf™="" «xle¥iÖjnÇ•mä+‰â|i6r¹Þâfþ˜®™ûî~n[Ñm�pl¨Ú[&y½Ñ,@ßíöh¢êa[˜#ýx�ûs81d¸wš(†j‹…¸çË#ló\‡#ŸÖq–dÆa$‚Ç="" åô÷þd¶hæþ¬¾="" ùöhŽ&è•yœ2�3’¼ƒ)"rÑØ)ŽÑmÝ~é£Ï‡‚1æuÉ‡…¬¿="" Í¦="�T^ìÆ´õ¿u»F¨=l�ÅW&quot;Y}y‚C&nbsp;¡èšä$ÏX¦Íì‘v_a¦ªp0" ·[Á”©™ší¥="" Ìtk"fµo="" `k-Þ="" f²®vj¯³­²Á°wwgf jrÅd›*’(’uØ7ÎŽ<@°="" :ì+ºjù‹pilÎ…}c°.‚‰aùÇb-#Á­œf;Ã¶rÊ"*¦á‰q´zÐƒÑ»#š#?fwÜˆ‹Þsõë™rƒ‰4fm2½@,]Þzd#µìÌîá„ÿrßµo�Îžk¸h|y.5£›êßÖ°Å_ £‰•‰f1^dÅ‚Õñ="">Îãt14Ã�Õ.‡‹³&amp;vdÏí}–PžÊ^¾�š¿d×c3pe|Ï¬7‘Ï_‰»¯CÍôIëðU*({e¿Ÿ	†q�¤í©õ5’ƒ¨W�cWq&lt;¦vÁâTSÌ«¸¨â±k²hwÈ–	åÑ£ð„/FÀÀ&nbsp;à7¢ßˆ8ø‹¾ˆSÖñ[È¶¤˜\‰ÆJr«¹[»¥Ï/õ7Ý²ØíÚØDß„–Ù‚mPÓ½Çƒ':ñ­O’Bdô6´ÁÃ[)“6“Sž…á
Ùòò7hŒfÕ&lt;àØïî•¾øí¾¦[PiSÃ9É44ÏŽPüHé…îa@sÂxDjØKB½¢&nbsp;&gt;èåáƒå;ØÅ‹·•Å¶öÏ�¡{åòÊ")T
nÓši®šü;ŠÚYÉ5Ô)$…ñ!OÃ&gt;ò([´âÚïòLvÎÌ#ŒÅŽ�4õžlð™6PU¢B,Ãç²*j`Ä�dðgý:VÉ…Á‹ �Äê1ŒáÆC†^“¾ùbH½uQåD‡:iršSíé¡B,¨
âW´5(
âÍuþf¸ŽçŸsšVOìé'6XTjüWÄÓèþ&nbsp;­:ÚjIy¥OTtJÁÏ7;`:`:Àgú—BÊkÅHëîRC©S×cÝ½'›È)©ÈK55^¾øÖûÃT÷QßèÛ­ò÷ÃkÁxÜ#Ô“-BÀßIŒ¢¿4«z&nbsp;ÕYì¬éVõZCÍ€—Éƒè`ÀR*PÒ6·òrdÕˆ�ÓÝà„Š�/�¬„à‰Æë•»9e	o'mœÓQAìP©�þåp½ÒÇïw×ÜºRKë’†šíÕ„90u¿Ô¤­«åÌõT­
¼¬˜F�ÍÃU–ÕcW‰E·œÀ&nbsp;tíÃýÁ1V¹,´$_n©¤ì!Eçí¡×N�ÇÁË�ºÚÆVo˜h+s§z1D“–,6ëKL‡Æns…˜Á¨õØLvÊnV–)ÖÒ*�ÍdeªˆŠQôu	Ì¨ÃÛü¾fØ=ª
SÓW‹eÞÍ¾2/ÏÓ·Pè%ûÑvÔoIY_Kµ›Ì¼9~0Æ&nbsp;…�Aï×cËYE,ÇÍ.S¹�UºXMÂç«&nbsp;ŽÀ
[ö
ƒÄ‰ïÝüu
¸þÏ×RÞÎ!ðkÉ'xÝÐŽVy“`)T‰‰šv­PVÚse“X*êØa7ÈmÀ?×¾'�iµø^9ØCžEý"ì�VõæÈAÚ·³�ÍÎüåˆ¡mh/Äa·ÇV$ªšçÁW!ßuÇ¯^4‘èÕØÐxs©¾–vÉÕ„¥ˆÝ2«Ðvëê©H½3ð’o¢Ã¼É PB¾[™fÂ+X%`YHf»ìEéÄ:”»¤r¼ŸôKŸ]ë%LŠ]é·�]nDsìõoÐÛ/€Ì¼F^9L†-_)†¦­¸G¹(9u6Ùãð~]@¦äˆ~o�'&amp;�wƒµ:•ìneÑüUí|^y‰·�yœÝUI,F�|ì˜]ê�Oí&nbsp;tÜÖX[Þ«ÞB©Ë¯D‹íõû©fÌÅßÓ¾#�‡öâ­Rc7Ä¾ïŸÏÑ¤5›U&amp;Ø!›•·rkT4ŠÅir˜§*S5Ô¯?°ƒ…e7ç
ÆÊ¶{;ˆètýQï�ÑqTÙº¡ê0
¨i�«˜*‚™1ƒ‰&amp;�Ù`c[¶q�eI–¬¬ÜARçî
ÝU�“Ô
­œ“å,gãÆ6–˜4Æ30ãá´¦|ïÜSÝ²gx—·î½ïÍ¼µÞýé¥&gt;}Î&gt;û|;|ß^b„Q)�¶Ï�Y£,ævÞS|KçèÍ.|…a±ó(’½¥æ¦QŠdš�àÉ(wJœF°X¨ñé�æ3½ó*S›{øYƒR¼GëÇí6o�Œ\/9nýÎ~‚á¼¡N¼3FµÇ‚�¦‚^º¨°.êóS¾j'ú�®¦ºr7éT;î³mD¹µ¶”GazKI*ú„¹ KÔ…UÀaq¢£Ñ®‰2FùùU¶Úi3jaØÆ§Ð–;bŒMb{
–AçùEíÈäoFâvý	_Œ�&lt;“[âü‘sGÉ½ï´¾Ä¢‹Ï½I¼=çéÀbüÉ™Š;g“ó¬™µ~õ¾pÍé"åƒß×ŒãîùÂ¢&nbsp;á£þïO¼Ež~ï¤¶&amp;àaA.lz4G¨Ja="Qw8MUñ/€ÿÏ²oA,¨¾Íì0fý;�x¨ä`j9º|•¦ÒËhÕ,Ñý£¼)¸?„tz'öÆ„¸W0A"PZx˜ÕÃÐe²äãˆ%öJ)Ñ‡|£üç_õ£.ä¸m‰¡0Ì@,cÁ;±Èý×ÉÎ¹šÇ¬!ü0�æ	·çQ9U%d^ÙëKð�¼SAJ9=¹5ÊyÅƒà‘»là/qÙÞ‰‡bmÒ©^¶Ñº†.±¦²¯ÙÍÓî¥¦ˆ#˜6‰¼�GC-÷ë,]’Ï
2À*¦†-�ö|¡£UÅZäÎ7ø�í{¯ôæá²,DÂZ¤Dl…›®·‰Âí9ÜÎDíI~ê¿“�$ø«|–õf&amp;Qª6UÁhf±ÒQÜ´ÒnÂ×Êùu;|Î^,þ¢ÝiŒõµÆÆq]\w;(áƒ^«£­´¨ƒô×ízÞnr÷Ïrk=šp¾O�ÖÛ†¹îm´{ÚŒès©»iS%W_M(ƒ‹¾´x��~ÐŒ¾ºÆ
ÊIÀ­]‡v‚[°aåö‚&gt;b(û•ö§pÕƒôŠ'‹®ôf£�#ÑB›‘v¿º ŠL‹žÅdç¾‹å
ŸËAÀŒœóão«-%»+ZÒ×cò„[„W•:_KHÿX;:yÿ�Y‘øîè�€¸zrÒÄ÷àú·U£e½dî¶¡—Â%žá’n´¼ÃÜß…íé{ûüÎÁº’Nb,#°Ñ]±š�
€ìQ"H¶�
k~Ä&lt;´Û"&amp;
BvV£µX,¬Á1Ý­N-Ç__[—ŸK•¥¬Å^	¥ö[Ó&amp;Ê{uè‡›ÞÍž�=2?géÊ•�;‹‰‚=L?Û‡:Eï¨3d«fÈ%zAF•£:&gt;ZÜå°ùœ¤×iw9q‡“6øÉ¢ÍãÕïÀôÞ%Âû”8Ev
ìŽÌ–ÿÓ¤ý5=óÜJÞdcí¶†XRëQÙ°q›ÜÌøÑ6Ì¶EyŠR«Ökè*vºìÔ””dÝ)ÉðÿHJrê§RD¬°G'ï�ûã"wŠ‡ù»ü÷G[‡7“w…ßt~„ò£x&gt;«p7ç%ü&lt;ß5Œ�Ág}æ&lt;ÂPH¿´p½~*LŠ=tå¶!</b�œ$‚ì{tt—lmâã�¿ìœûå‘ž|îiófÿä–ìyûfšæ©-k7pþ#oúø´~ewi1¹æì‡àv"1ªq�áæ]±3xèfôå±ðpô=¶e£”²edgu”¯ 4ó></rñìô7§àû6ç�xwæîæîj></mrz{xšorß€´qð“ ></kã°•z‡èúè@dzý�^_,¬ÿâ"uz+:èj´¬jª¡š¸s§ð7´'ä£©èî‚üúídú*ãö,š¾€žº�aj></ky¥”s‰£–ñ(¾o·qè8aøóÿô�vä?‘¬öè°è¿º4r¶—’¼¢‡+ci¬èòœs·½díîäîý¡þjã)ëûƒø'ü‘ï¿#†jz©ž‚šb¯at></uþôµ§ûgb3�=óé³§fmÿõ—ùñ³¥__|¾óý¯¿x8›ó4÷�¹û�áy=ó�¼d></i©¶¯b|[=s£k¯øä¢ëgžw3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf">https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf</a></em></p>]]>
            </description>
            <link>https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705036</guid>
            <pubDate>Wed, 07 Oct 2020 03:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USB3: Why it's a bit harder than USB2]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 151 (<a href="https://news.ycombinator.com/item?id=24704298">thread link</a>) | @panic
<br/>
October 6, 2020 | https://lab.ktemkin.com/post/why-is-usb3-harder/ | <a href="https://web.archive.org/web/*/https://lab.ktemkin.com/post/why-is-usb3-harder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    <p>A few people on twitter have asked me to explain why the USB3 winds up being much harder to implement than USB2.
The answer is more than will fit in a single tweet, so I thought I'd put a quick-but-rough answer, here. This is
by no means comprehensive; consider it <del>a longer tweet</del> what a tweet would be given I had more than 240 characters and a proclivity to babble. (I do.)</p>
<p>A lot of the challenges come from the way we work around <em>physical-layer</em> limitations. Put poetically, physics gives
us lots of little obstacles we have to work around in order to talk at 5 billion transfers per second (5GT/s).</p>
<h5 id="its-hard-to-establish-common-dc-operating-conditions-on-both-sides-of-a-link">It's hard to establish common “DC operating conditions” on both sides of a link.</h5>
<p>It's not trivial to get the same bias voltages – and common grounds – across a long motherboard or down a cable – and when you're operating at really high frequencies, you're a lot more sensitive to changes in your operating environment. In USB3, we work around this by <em>capacitively isolating</em> both sides of the link from each other – in short, we use capacitors to ensure only signal <em>changes</em> are carried across the link, which means that both sides can establish their own local operating conditions.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/circuit.png" alt="diagram showing the transmitter is connected to the receiver through a pair of AC coupling capacitors"> <figcaption>
            <h4>From the USB3.2 specification: diagram showing how signals are isolated</h4>
        </figcaption>
</figure>

<p>This puts some requirements on the digital protocols used to exchange data. Because data currents are exchanged as the relevant capacitors charge and discharge, <em>capacitive coupling</em> only works when those capacitors have room to charge and discharge. <strong>This means our data must be DC-balanced; we have to spend as much time charging those capacitors as we do discharging them</strong>. In digital terms, this means we have to encode the data in a way that sends the same amount of <code>1</code>s and <code>0</code>s.</p>
<h5 id="its-hard-to-establish-a-common-clock-across-both-sides-of-a-link">It's hard to establish a “common clock” across both sides of a link.</h5>
<p>When sending serial data, you typically have two challenges: you need to make sure both sides are sampling the data <em>at the same rate</em>, and that both sample clocks are <em>synchronized enough</em> that you're sampling at the right point. Many high-speed protocols deal with this using a technique called <em>clock recovery</em>, which essentially means that each receiver looks at the data it receives and tries to figure out what the clock that produced it looks like.</p>
<p>If both sides have agreed on a clock rate, this can be simple, in theory: if the receiver sees a change in its
received data, it can infer that that changed happened <em>on an active edge of the transmitter's clock</em>, and so it can start to figure out how to align its internal clock with the transmitter's.</p>
<p>This introduces another protocol requirement: <strong>for <em>clock recovery</em> to work, the data has to change frequently enough that the two sides can keep synchronized</strong>. At 5GT/s and high data throughputs, there's not much time for clocks to become synchronized when a packet is received; accordingly, it's important that data is encoded with lots of transitions, even when the line is idle.</p>
<p><strong>To ensure both <em>DC-Balance</em> and <em>sufficient transition density</em>, USB3 uses a method of encoding called 8b10b encoding.</strong>
In this encoding scheme, every single byte of data is transmitted as ten bits, with encodings chosen so that:</p>
<ul>
<li>A typical data byte can be transmitted <em>either</em> as a code with <em>one more one than zero</em>, or <em>one more zero than one</em>.
This allows the transmitter to choose between the two encodings, in order to keep the data stream at 50% ones.</li>
<li>Every valid encoding has sufficient <em>transition density</em> to ensure that it's useful for clock recovery.</li>
</ul>
<p>I won't go into more 8b10b background here, but you can read about the typical IBM implementation <a href="https://en.wikipedia.org/wiki/8b/10b_encoding">on wikipedia</a>.</p>
<h5 id="its-hard-to-run-both-sides-of-the-link-at-the-same--clock-rate-">It's hard to run both sides of the link at the same <em>clock rate</em>.</h5>
<p>Even with successful <em>clock recovery</em>, it's difficult to have both sides of the link produce and consume data at
the same rate. Each side's internal logic is running off of its own <em>clock source</em>; and every clock has a bit of deviation from its nominal frequency. For the protocol to function despite these differences, the USB3 specification allows each clock to deviate from its nominal value by up to a certain <em>tolerance</em>; and specifies a method for compensating for this tolerance. This technique is appropriately named <em>clock tolerance compensation</em>, or CTC.</p>
<p><strong>To compensate for mismatches in sender/receiver clock rates, USB3 requires senders to periodically insert filler data into their transmitted data-stream</strong>. Receivers can then discard this data; allowing a brief pause in which the slower
side of the link can “catch up”. For this to be useful, the filler data (called ‘skip sets’) must be sent regularly;
which means additional logic on the transmitter side for insertion, and additional logic on the receiver side for
removal.</p>
<h5 id="its-hard-to-deal-with-varying-electrical-properties-of-different-transmitters-receivers-and-cables">It's hard to deal with varying electrical properties of different transmitters, receivers, and cables.</h5>
<p>When operating at very high frequencies, all of the little non-idealities along your transmission path really add up. At slower data rates, there's plenty of time for digital signals to “settle” after a change; making the non-ideal properties of your transmission lines less important. The faster your data gets, the more important it is for your data
to reach a “readable” value quickly.</p>
<p>To help with this, most high-speed receivers employ a technique called <em>receiver equalization</em>, which uses analog hardware
to help reshape signal transitions, so they can be more reliably sampled. Equalization helps to “cancel out” some of the ways the non-ideal transmission path adversely affects the signal.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/eye.png" alt="diagram showing a variety of slow rises and falls; illustrating that the physical link slows transitions"> <figcaption>
            <h4>From the USB3.2 specification: an 'eye diagram', which shows an overlay of many rising and falling transitions, illustrating how non-ideal properties affect the link.</h4>
        </figcaption>
</figure>

<p>Since every transmission path is different – due to different transmitter, receiver, and cable properties – it's impossible to create a single “one size fits all” equalizer. Instead, each USB3 equalizer needs to be tuned to its transmission path via a process called <em>link training</em>.</p>
<p><strong>At the start of each USB3 communication, link partners repeatedly exchange collections of known data called <em>training sets</em>, which give the opportunity for each side to tune their equalizer.</strong> Training sets include both sets of data chosen to have high transition density and sets designed to include a wide range of “normally-distributed” data.</p>
<p>During a few milliseconds of data exchange – an eternity in fast-protocol terms – both sides of the link gradually
tweak their equalizer settings until they're clearly seeing the expected values from the other side.</p>
<h5 id="its-hard-not-to-generate-harmful-interference">It's hard not to generate harmful interference.</h5>
<p>USB3 has a very high transition rate – it easily qualifies as high radio-frequency signaling – and its link
often tends to exchange repeating data. This has a nasty side effect: even a well-functioning link can act as an
antenna; unintentionally emitting RF that can interfere with nearby systems. The more repeating elements this signaling
has, the more troublesome the interference tends to be.</p>
<p><strong>To reduce the amount of harmful interference generated, USB3 links use a technique called <em>scrambling</em>, in which data is XOR'd with a fixed pattern before transmission.</strong> The receiver is then capable of applying the same transform to <em>descramble</em> the data stream, recovering the relevant data.</p>
<p>You can think of scrambling as being very similar to encryption – except everyone knows the key. Once data is scrambled, it looks a lot more like “random numbers” than the pre-scrambling data – and accordingly, it's a lot less likely to
generate troublesome interference. Once the scrambled data travels the link, it can be <em>descrambled</em> by the receiving end – a process similar to decryption – restoring the original data stream.</p>
<h5 id="in-summary">In summary…</h5>
<p>In summary, before you can even exchange meaningful data, the digital side of your device needs:</p>
<ul>
<li><strong>8b10b encoding and decoding hardware</strong>, so the data exchanged is <em>DC-balanced</em> and contains sufficient transitions as to allow <em>clock recovery</em>;</li>
<li><strong>Clock Tolerance Compensation hardware</strong>, which allows the two sides to communicate even with slightly-varying clock frequencies;</li>
<li>Hardware to orchestrate <strong>link training</strong> and <strong>receiver equalization</strong>, which helps to deal with non-ideal transmission properties;</li>
<li><strong>Scrambling</strong> and <strong>descrambling</strong> hardware, which help to reduce harmful interference.</li>
</ul>
<p>This omits a few minor things, such as USB3's <em>Low Frequency Periodic Signaling</em>; but these are the major components.</p>
<h5 id="oh-and-one-more-thing-its-hard-to-get-good-resources">Oh, and one more thing: it's hard to get good resources.</h5>
<p>Finally, ignoring all the physical layer challenges associated with bringing a link up, there's one more major obstacle: it's hard to get good resources for working with USB3:</p>
<ul>
<li>Most hardware enabling custom USB designs is expensive; and <a href="https://lab.ktemkin.com/post/ab07-usb3fmc-wtf/">still rife with issues</a>.</li>
<li>Most USB3 tooling is <a href="https://www.totalphase.com/products/beagle-usb5000-v2-ultimate/">very expensive</a>, and still rife with issues.</li>
<li>There's very little documentation in support of the specification; and what documentation exists still hasn't been
used enough to <a href="https://lab.ktemkin.com/post/mindshare-usb3/">identify all of its errors</a>.</li>
</ul>
<p>Hopefully, at some point, I'll have built enough tooling to change this.</p>


  </article></div>]]>
            </description>
            <link>https://lab.ktemkin.com/post/why-is-usb3-harder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24704298</guid>
            <pubDate>Wed, 07 Oct 2020 01:11:58 GMT</pubDate>
        </item>
    </channel>
</rss>
