<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 09 Oct 2020 04:28:43 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 09 Oct 2020 04:28:43 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Developing with Squeak on a Cellphone]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24706567">thread link</a>) | @tonyg
<br/>
October 7, 2020 | https://eighty-twenty.org/2020/10/07/developing-with-squeak-on-a-cellphone | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/10/07/developing-with-squeak-on-a-cellphone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Part of a series:</strong> <a href="https://eighty-twenty.org/tag/squeak-phone">#squeak-phone</a></p>

<hr>

<p>One <em>lovely</em> thing about working in Smalltalk is the effortlessness of
development.</p>

<p>I started off developing the code on my desktop machine, and
occasionally testing it on the phone itself. I just <code>rsync</code> the image
and changes files back and forth. This lets me pick up exactly where I
left off on the other device each time I move over.</p>

<p>However, <em>developing</em> on the phone was challenging because of the lack
of a keyboard (though I’ll post soon about an on-screen keyboard I’ve
written). So I installed RFB (from
<a href="http://source.squeak.org/ss/">here</a>) into my image on the desktop,
and tested it. Then I saved the image and <code>rsync</code>ed it to the phone as
usual, and presto, I can develop and test interactively on the phone
itself:</p>

<p><a href="https://eighty-twenty.org/images/bootstrapping-a-cellphone-20201007/vnc-to-phone.jpg"><img src="https://eighty-twenty.org/images/bootstrapping-a-cellphone-20201007/vnc-to-phone-640.jpg" alt="Using VNC to develop on the phone itself"></a>
Using VNC to develop on the phone itself</p>

<p>There were a couple of things I had to do to get this to work:</p>

<ul>
  <li>
    <p>Use this version of RFBServer: <a href="http://source.squeak.org/ss/">http://source.squeak.org/ss/</a></p>
  </li>
  <li>
    <p>Change <code>AllowTcpForwarding no</code> to <code>yes</code> in <code>/etc/ssh/sshd_config</code>
on the phone and then <code>service sshd restart</code></p>
  </li>
  <li>
    <p>Use <code>ssh -L 5900:localhost:5900 pm</code> to log into the phone (that’s
the green-screen transcript in the background in the picture above)</p>
  </li>
</ul>

  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/10/07/developing-with-squeak-on-a-cellphone</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706567</guid>
            <pubDate>Wed, 07 Oct 2020 09:31:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VSCode on Google Colab]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24705599">thread link</a>) | @amitness
<br/>
October 6, 2020 | https://amitness.com/vscode-on-colab/ | <a href="https://web.archive.org/web/*/https://amitness.com/vscode-on-colab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>

<p>
<span>

2 minute read
</span>
</p>
</header>
<section itemprop="text">
<p>I recently discovered a way to set up VSCode on Google Colab and use it as an editor to write code and run experiments on the Colab VM.</p>
<p>With this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of a full-fledged code editor. Here is how you can replicate my setup.</p>
<h2 id="approach-1-python-package">Approach 1: Python Package</h2>
<p>In this setup, we use the <a href="https://github.com/abhishekkrthakur/colabcode">colab-code</a> package that automates all the manual setup steps previously described in the <strong>Approach 2</strong> section of this blog post. You can make a copy of this <a href="https://colab.research.google.com/github/abhishekkrthakur/colabcode/blob/master/colab_starter.ipynb">notebook</a> directly to get started.</p>
<ol>
<li>
<p>First, install the <code>colab-code</code> package using the following command:</p>

</li>
<li>
<p>Now, import <code>ColabCode</code> class from the package and specify the port and password.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>(</span><span>port</span><span>=</span><span>10000</span><span>,</span> <span>password</span><span>=</span><span>"password123"</span><span>)</span>
</code></pre></div> </div>
<p>You can also use it directly with the default port and without any password as shown below.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>()</span>
</code></pre></div> </div>
</li>
<li>
<p>You will get the ngrok URL in the output. Click the link and a login page will open in a new tab.</p>
<p><img src="https://amitness.com/images/colab-code-step-1.png" alt="Generated NGROK URL"></p>
</li>
<li>
<p>Type the password you had set in step 2 and click submit. If the page gets stuck for more than 4-5 seconds, refresh the page and you should be redirected to the editor.</p>
<p><img src="https://amitness.com/images/colab-code-step-2.png" alt="Authenticating with password in VSCode"></p>
</li>
<li>
<p>Now you will get access to the editor interface and can use it to work on python files.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt="VSCode Interface"></p>
</li>
</ol>
<h2 id="approach-2-manual-setup">Approach 2: Manual Setup</h2>
<p>I have described the setup steps in detail below. After going through all the steps, please use this <a href="https://colab.research.google.com/drive/1yvUy5Gn9lPjmCQH6RjD_LvUO2NE0Z7RM?usp=sharing">colab notebook</a> to try it out directly.</p>
<ol>
<li>
<p>First, we will install the <a href="https://github.com/cdr/code-server">code-server</a> package to run VSCode editor as a web app. Copy and run the following command on colab to install <code>code-server</code>.</p>
<div><div><pre><code> !curl -fsSL https://code-server.dev/install.sh | sh
</code></pre></div> </div>
</li>
<li>
<p>After the installation is complete, we will expose a random port <code>9000</code> to an external URL we can access using the <code>pyngrok</code> package. To install <code>pyngrok</code>, run</p>
<div><div><pre><code> <span>!</span>pip <span>install</span> <span>-qqq</span> pyngrok
</code></pre></div> </div>
</li>
<li>
<p>Then, run the following command to get a public ngrok URL. This will be the URL we will use to access VSCode.</p>
<div><div><pre><code> <span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
 <span>url</span> <span>=</span> <span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>port</span><span>=</span><span>9000</span><span>)</span>
 <span>print</span><span>(</span><span>url</span><span>)</span>
</code></pre></div> </div>
</li>
<li>
<p>Now, we will start the VSCode server in the background at port 9000 without any authentication using the following command.</p>
<div><div><pre><code> !nohup code-server --port 9000 --auth none &amp;
</code></pre></div> </div>
</li>
<li>
<p>Now, you can access the VSCode interface at the URL you got from step 3. The interface and functionality are the same as the desktop version of VSCode.</p>
</li>
</ol>
<p><img src="https://amitness.com/images/colab-vscode.png" alt="Example of a running instance of VSCode server"></p>
<h2 id="usage-tips">Usage Tips</h2>
<ol>
<li>
<p>You can switch to the dark theme by going to the bottom-left corner of the editor, clicking the <strong>settings icon</strong>, and then clicking ‘<strong>Color Theme</strong>’.</p>
<p><img src="https://amitness.com/images/colab-dark-theme-step-1.png" alt="Switching to dark theme on VSCode"></p>
<p>A popup will open. Select <strong>Dark (Visual Studio)</strong> in the options and the editor will switch to a dark theme.
<img src="https://amitness.com/images/colab-dark-theme-step-2.png" alt="Theme selection interface on VSCode"></p>
</li>
<li>
<p>All the keyword shortcuts of regular VSCode works with this. For example, you can use <code>Ctrl + Shift + P</code> to open a popup for various actions.</p>
<p><img src="https://amitness.com/images/vscode-ctrl-shift-p.png" alt="Action popup in VSCode"></p>
</li>
<li>
<p>To open a terminal, you can use the shortcut <code>Ctrl + Shift + `</code>.</p>
<p><img src="https://amitness.com/images/vscode-terminal.png" alt="Opening integrated terminal in VSCode"></p>
</li>
<li>
<p>To get python code completions, you can install the Python(<code>ms-python</code>) extension from the extensions page on the left sidebar.</p>
<p><img src="https://amitness.com/images/vscode-code-completions.png" alt="Installing extensions in VSCode"></p>
</li>
<li>
<p>The Colab interface is still usable as a notebook and regular functions to upload and download files and mount with Google Drive. Thus, you get the benefits of both a notebook and a code editor.</p>
</li>
</ol>
<h2 id="references">References</h2>
<ul>
<li><a href="https://github.com/cdr/code-server/blob/v3.5.0/doc/FAQ.md">Code-Server FAQs</a></li>
<li><a href="https://pyngrok.readthedocs.io/en/latest/">pyngrok - a Python wrapper for ngrok</a></li>
</ul>
</section>



</div></div>]]>
            </description>
            <link>https://amitness.com/vscode-on-colab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705599</guid>
            <pubDate>Wed, 07 Oct 2020 05:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Writing Documents as Important as Writing Code?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24705092">thread link</a>) | @7d7n
<br/>
October 6, 2020 | https://eugeneyan.com/writing/writing-and-coding/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/writing-and-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Does writing become more important (relative to coding) as we transition to senior roles? How is writing beneficial in technical positions? How can we help the team write better?</p>
<p>As a data scientist, I find myself straddling between building and deploying ML systems (<em>coding</em>), and communicating proposals and explaining results (<em>writing</em>). What’s the optimal balance between writing code and writing documents?</p>
<p>Here, we’ll discuss these questions and more. I’m also happy to have several friends who will chime in with their lessons and advice:</p>
<ul>
<li><a href="https://www.linkedin.com/in/david-said-martinez-3836a72b/" target="_blank">David Said</a>, Principal Engineer @ Amazon</li>
<li><a href="https://twitter.com/Al_Grigor" target="_blank">Alexey Grigorev</a>, Lead Data Scientist @ OLX Group</li>
<li><a href="https://twitter.com/nlpguy_" target="_blank">Pratik Bhavsar</a>, NLP Engineer @ Jina AI</li>
<li><a href="https://www.linkedin.com/in/tsmgrace/" target="_blank">Grace Tang</a>, Senior Data Scientist @ Netflix</li>
</ul>
<h2 id="as-we-grow-how-we-can-contribute-most-shifts">As we grow, how we can contribute <em>most</em> shifts</h2>
<p><strong>At the start of our careers, it’s all about delivery</strong>. We contribute by implementing and delivering systems (via <em>writing code</em>). David describes this aptly:</p>
<blockquote>
<p>“[At the start,] you need to focus on getting your fangs [akin to earning your stripes] on real-world problems. Then, as you get your fangs and grow your career, it becomes more important to share what you know.” – David Said</p>
</blockquote>
<p>So as we gain experience and grow our fangs, the way in which we create impact changes. Instead of implementing systems ourselves, it becomes more valuable to <strong>guide and serve the team</strong>. A great way to do this is via <em>writing documents</em>.</p>
<p>One way (to guide the team) is <strong>providing the context and the why</strong>. As we rise in seniority, we gain context—business goals, organization roadmap, budget—that junior members may lack. A straightforward way to increase team effectiveness is sharing this context and helping the team to understand it. With the context, <strong>they can solve the problem better</strong>.</p>
<p>As lead data scientist, Alexey’s role is to connect the different parts of the organization and have a big picture view of the entire system. While he codes less now, he contributes by conveying the big picture and why to the team. He does this through writing documents such as product roadmaps, requirements, API specs, etc. He advises that seeing the context and communicating it becomes more important as our careers progress:</p>
<blockquote>
<p>“When you grow from middle to senior level, having context matters. Communicating with other teams matters. Understanding if the customer really wants to use what you’re building matters. This is when writing becomes <em>especially</em> important, through scoping the context and sharing the message.” – Alexey Grigorev</p>
</blockquote>
<details><summary>Focus on sharing the “why”, not the “what” and “how”</summary>
<div>
<p>Assume that we’re part of an e-commerce platform. Popular products get traffic and continue to stay popular; newer long-tail products don’t get traffic and stay obscure (even though they might be good). Instead of communicating the <strong>what</strong> (increase visibility of new products) and the <strong>how</strong> (randomly pick the latest product to rank high), we should communicate the <strong>why</strong>:</p>
<ul>
<li>Customers get bored seeing the same products and leave the platform</li>
<li>It’s risky to have a disproportionately large amount of sales concentrated on a small number of sellers and products (i.e., poor seller &amp; assortment health)</li>
<li>New sellers who don’t get traffic and sales get discouraged and leave</li>
</ul>
<p>By sharing the context and the why—and giving space to figure out the what and the how—we empower the team to creatively solve the customer’s problem. In my experience, this almost always leads to a far better outcome than expected.</p>
<p>(In this case, we fixed it with a combination of <a href="https://www.slideshare.net/eugeneyan/how-lazada-ranks-products-to-improve-customer-experience-and-conversion#30" target="_blank">understanding customers unmet demands</a> and providing the ability for sellers to place ads.)</p>
</div>
</details>
<p>Also, with the lessons we’ve learned (read: failures), we can contribute by <strong>helping to look around corners</strong>. We do this by <a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#break-it-down-to-spot-rabbit-holes-and-dead-ends" target="_blank">foreseeing potential pitfalls</a> the team should prioritize early. Or we can suggest (or decide) on problem statements, methodology, and technology. This could involve reviewing design docs and leaving feedback, or writing the design doc and <a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#constraints-how-not" target="_blank">setting boundaries</a>. Thus, our contribution transitions from day-to-day execution to longer-term strategic thinking:</p>
<blockquote>
<p>“As you become a tech leader, you need to think about the future. The experienced are those who know what the corners are and how to look around them. They have to parse the business problems, do the (design and code) reviews, and minimize the errors that the team commits.” – David Said</p>
</blockquote>
<p>A well-timed insight can save weeks, if not months, of going down the rabbit hole. Unfortunately, the reverse can also happen if recommendations of tech leads are ignored.</p>
<p>In addition, we’ll need to <strong>learn how to scale our impact</strong>. The number of systems we can build ourselves is limited. To increase our impact, we’ll need to gain leverage by working with other people, by working across multiple teams and projects.</p>
<p>Here’s where writing helps. It scales well—once written, an API spec can be easily distributed without additional effort. It clarifies—the same spec can help achieve alignment and unblock multiple teams at once. Also, by writing about the lessons we’ve learned and the how-tos, we pave the way for those who follow our footsteps:</p>
<blockquote>
<p>“As soon as you get into a senior role (maybe not title-wise, but having increased scope), you’ll have to work with others. A great mechanism for this is via documentation. If you’ve always been a coder, you might find this boring. But writing documentation, such as how to deploy <a href="https://aws.amazon.com/cloudformation/" target="_blank">CloudFormation</a>, is tremendously helpful both for yourself and the team.” – Pratik Bhavsar</p>
</blockquote>
<p>All in all, this suggests that (as we grow in our careers) we’ll find ourselves <strong>writing more and coding less</strong>. Grace observed that in general, individual contributors (ICs) tend to write more code, while tech leads and managers tend to write more docs. Nonetheless, writing documents is important <em>even</em> if you’re an IC:</p>
<blockquote>
 <p>“Both writing docs and writing code are important: Write good code and perform quality analysis, then write good docs to maximize its impact. You need to help stakeholders be aware of and understand your work so it can make an impact. Not sharing your work means no one knows about it and no one can use it.” – Grace Tang</p>
</blockquote>
<details><summary>If you’re mostly writing docs, how can you write more code?</summary>
<div>
<p>If you're a senior member, the team counts on you to provide the strategic long-term vision and roadmap. To do this well, it’s essential to stay grounded on, and understand, the existing systems and codebase.</p>
<p>Consciously think about how to find time to code, perhaps by jumping into a sprint and picking up a task. Choose an area of the design and implementation that you can dig deep into. Focus on tasks with longer-term goals and a lengthier lead time. This way, your work will not become an immediate blocker for the team (when you get waylaid with higher-level tasks that demand your attention).</p>
</div>
</details>
<h2 id="writing-has-several-benefits-especially-in-tech-roles">Writing has several benefits, especially in tech roles</h2>
<blockquote>
<p>“Writing is nature’s way of letting you know how sloppy your thinking is.” – Dick Guindon, via Leslie Lamport</p>
</blockquote>
<p>Without writing, we might believe our designs are sound, our methodology clear, and our understanding complete. Well, trying to write about it will sort that out. Writing is a hack to <strong>gaining clarity</strong>. Here’s Jeff Bezos on why he banned powerpoint (as a medium at meetings) and enforced six-page narratives instead:</p>
<p><img src="https://eugeneyan.com/assets/jeff-bezos-memo.jpg" title="The fateful email that changed Amazon." alt="The fateful email that changed Amazon."></p>
<p>The fateful email that changed Amazon.</p>
<p>Yes, the audience benefits from reading well-structured narrative. <strong>But the main benefit goes to the writer.</strong> By writing long-form prose instead of bullet points, by adding data and connecting ideas, we’re forced to <em>think deeply and resolve inconsistencies</em>. We have to <em>focus on the single thread</em> that ties everything together. We need to <em>remove redundant details</em> (to fit the page limits). There is no way to write a six-page narrative and not come away with clear(er) thinking.</p>
<p>And even if the document is lost, the research and thinking has already been done. The process and outcomes of the thinking are often more important than the document.</p>
<blockquote>
<p>“Reports are more a medium of self-discipline than a way to communicate information. Writing the report is important; reading it often is not.” – Andy Grove</p>
</blockquote>
<p>I fully agree with this and advocate the practice of writing <a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager" target="_blank">one-pagers</a>. (In my previous teams, it was a must before starting on a project.) The process helps to clarify the intent, desired outcome, deliverable, and constraints. Such practices are also common in Amazon, such as the <a href="https://www.quora.com/What-is-Amazons-approach-to-product-development-and-product-management/" target="_blank">working backwards</a> process and the <a href="https://www.businessinsider.com/heres-the-surprising-way-amazon-decides-what-new-enterprise-products-to-work-on-next-2015-3" target="_blank">press release</a> document.</p>
<p>Also, writing is a short cut to <strong>socializing ideas and getting feedback</strong>. Before starting on (costly) implementation, we can (cheaply) share written proposals to gather feedback. With feedback, our initial designs can be refactored at zero development cost. Sharing our designs—in written form—also ensures our eventual implementation meets the intent:</p>
<blockquote>
<p>“When you write your proposal, you have a way to understand if it’s interesting and useful for others. In contrast, you can write code for a very long time and still not know if it’s useful. Thus, writing the proposal is important to helping yourself and others understand if what you’re building is actually solving the problem.“ – Alexey Grigorev</p>
</blockquote>
<p>The same documents we write to gain clarity can also be used to socialize our ideas. In Amazon, when asked about a project, it’s common to share the press release document (and the six-pager if it’s available). In other organizations, this could be in the form of a requirements doc, confluence page, or API specifications.</p>
<p>In addition, writing helps with <strong>knowledge retention and transfer</strong>. Our memory is leaky—we forget <a href="https://eugeneyan.com/writing/reading-note-taking-writing/#note-taking" target="_blank">as much as 90% of what we read within 7 days</a>. Writing is like saving knowledge to a database. And now, instead of asking us, people can access our knowledge via that database (i.e., writing)—this helps us save time:</p>
<blockquote>
<p>“When you have project documentation, it’s easy to onboard someone onto the project. Instead of having to sit with them to explain it, you can just direct them to the docs. Also, as the organization grows larger, it becomes difficult to …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/writing-and-coding/">https://eugeneyan.com/writing/writing-and-coding/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/writing-and-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705092</guid>
            <pubDate>Wed, 07 Oct 2020 03:45:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissertation: Marine Insurance in the Netherlands 1600-1870 (2009) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24705036">thread link</a>) | @johntfella
<br/>
October 6, 2020 | https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf | <a href="https://web.archive.org/web/*/https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://research.vu.nl/ws/portalfiles/portal/42182698/complete+dissertation.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705036</guid>
            <pubDate>Wed, 07 Oct 2020 03:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USB3: Why it's a bit harder than USB2]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24704298">thread link</a>) | @panic
<br/>
October 6, 2020 | https://lab.ktemkin.com/post/why-is-usb3-harder/ | <a href="https://web.archive.org/web/*/https://lab.ktemkin.com/post/why-is-usb3-harder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    <p>A few people on twitter have asked me to explain why the USB3 winds up being much harder to implement than USB2.
The answer is more than will fit in a single tweet, so I thought I'd put a quick-but-rough answer, here. This is
by no means comprehensive; consider it <del>a longer tweet</del> what a tweet would be given I had more than 240 characters and a proclivity to babble. (I do.)</p>
<p>A lot of the challenges come from the way we work around <em>physical-layer</em> limitations. Put poetically, physics gives
us lots of little obstacles we have to work around in order to talk at 5 billion transfers per second (5GT/s).</p>
<h5 id="its-hard-to-establish-common-dc-operating-conditions-on-both-sides-of-a-link">It's hard to establish common “DC operating conditions” on both sides of a link.</h5>
<p>It's not trivial to get the same bias voltages – and common grounds – across a long motherboard or down a cable – and when you're operating at really high frequencies, you're a lot more sensitive to changes in your operating environment. In USB3, we work around this by <em>capacitively isolating</em> both sides of the link from each other – in short, we use capacitors to ensure only signal <em>changes</em> are carried across the link, which means that both sides can establish their own local operating conditions.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/circuit.png" alt="diagram showing the transmitter is connected to the receiver through a pair of AC coupling capacitors"> <figcaption>
            <h4>From the USB3.2 specification: diagram showing how signals are isolated</h4>
        </figcaption>
</figure>

<p>This puts some requirements on the digital protocols used to exchange data. Because data currents are exchanged as the relevant capacitors charge and discharge, <em>capacitive coupling</em> only works when those capacitors have room to charge and discharge. <strong>This means our data must be DC-balanced; we have to spend as much time charging those capacitors as we do discharging them</strong>. In digital terms, this means we have to encode the data in a way that sends the same amount of <code>1</code>s and <code>0</code>s.</p>
<h5 id="its-hard-to-establish-a-common-clock-across-both-sides-of-a-link">It's hard to establish a “common clock” across both sides of a link.</h5>
<p>When sending serial data, you typically have two challenges: you need to make sure both sides are sampling the data <em>at the same rate</em>, and that both sample clocks are <em>synchronized enough</em> that you're sampling at the right point. Many high-speed protocols deal with this using a technique called <em>clock recovery</em>, which essentially means that each receiver looks at the data it receives and tries to figure out what the clock that produced it looks like.</p>
<p>If both sides have agreed on a clock rate, this can be simple, in theory: if the receiver sees a change in its
received data, it can infer that that changed happened <em>on an active edge of the transmitter's clock</em>, and so it can start to figure out how to align its internal clock with the transmitter's.</p>
<p>This introduces another protocol requirement: <strong>for <em>clock recovery</em> to work, the data has to change frequently enough that the two sides can keep synchronized</strong>. At 5GT/s and high data throughputs, there's not much time for clocks to become synchronized when a packet is received; accordingly, it's important that data is encoded with lots of transitions, even when the line is idle.</p>
<p><strong>To ensure both <em>DC-Balance</em> and <em>sufficient transition density</em>, USB3 uses a method of encoding called 8b10b encoding.</strong>
In this encoding scheme, every single byte of data is transmitted as ten bits, with encodings chosen so that:</p>
<ul>
<li>A typical data byte can be transmitted <em>either</em> as a code with <em>one more one than zero</em>, or <em>one more zero than one</em>.
This allows the transmitter to choose between the two encodings, in order to keep the data stream at 50% ones.</li>
<li>Every valid encoding has sufficient <em>transition density</em> to ensure that it's useful for clock recovery.</li>
</ul>
<p>I won't go into more 8b10b background here, but you can read about the typical IBM implementation <a href="https://en.wikipedia.org/wiki/8b/10b_encoding">on wikipedia</a>.</p>
<h5 id="its-hard-to-run-both-sides-of-the-link-at-the-same--clock-rate-">It's hard to run both sides of the link at the same <em>clock rate</em>.</h5>
<p>Even with successful <em>clock recovery</em>, it's difficult to have both sides of the link produce and consume data at
the same rate. Each side's internal logic is running off of its own <em>clock source</em>; and every clock has a bit of deviation from its nominal frequency. For the protocol to function despite these differences, the USB3 specification allows each clock to deviate from its nominal value by up to a certain <em>tolerance</em>; and specifies a method for compensating for this tolerance. This technique is appropriately named <em>clock tolerance compensation</em>, or CTC.</p>
<p><strong>To compensate for mismatches in sender/receiver clock rates, USB3 requires senders to periodically insert filler data into their transmitted data-stream</strong>. Receivers can then discard this data; allowing a brief pause in which the slower
side of the link can “catch up”. For this to be useful, the filler data (called ‘skip sets’) must be sent regularly;
which means additional logic on the transmitter side for insertion, and additional logic on the receiver side for
removal.</p>
<h5 id="its-hard-to-deal-with-varying-electrical-properties-of-different-transmitters-receivers-and-cables">It's hard to deal with varying electrical properties of different transmitters, receivers, and cables.</h5>
<p>When operating at very high frequencies, all of the little non-idealities along your transmission path really add up. At slower data rates, there's plenty of time for digital signals to “settle” after a change; making the non-ideal properties of your transmission lines less important. The faster your data gets, the more important it is for your data
to reach a “readable” value quickly.</p>
<p>To help with this, most high-speed receivers employ a technique called <em>receiver equalization</em>, which uses analog hardware
to help reshape signal transitions, so they can be more reliably sampled. Equalization helps to “cancel out” some of the ways the non-ideal transmission path adversely affects the signal.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/eye.png" alt="diagram showing a variety of slow rises and falls; illustrating that the physical link slows transitions"> <figcaption>
            <h4>From the USB3.2 specification: an 'eye diagram', which shows an overlay of many rising and falling transitions, illustrating how non-ideal properties affect the link.</h4>
        </figcaption>
</figure>

<p>Since every transmission path is different – due to different transmitter, receiver, and cable properties – it's impossible to create a single “one size fits all” equalizer. Instead, each USB3 equalizer needs to be tuned to its transmission path via a process called <em>link training</em>.</p>
<p><strong>At the start of each USB3 communication, link partners repeatedly exchange collections of known data called <em>training sets</em>, which give the opportunity for each side to tune their equalizer.</strong> Training sets include both sets of data chosen to have high transition density and sets designed to include a wide range of “normally-distributed” data.</p>
<p>During a few milliseconds of data exchange – an eternity in fast-protocol terms – both sides of the link gradually
tweak their equalizer settings until they're clearly seeing the expected values from the other side.</p>
<h5 id="its-hard-not-to-generate-harmful-interference">It's hard not to generate harmful interference.</h5>
<p>USB3 has a very high transition rate – it easily qualifies as high radio-frequency signaling – and its link
often tends to exchange repeating data. This has a nasty side effect: even a well-functioning link can act as an
antenna; unintentionally emitting RF that can interfere with nearby systems. The more repeating elements this signaling
has, the more troublesome the interference tends to be.</p>
<p><strong>To reduce the amount of harmful interference generated, USB3 links use a technique called <em>scrambling</em>, in which data is XOR'd with a fixed pattern before transmission.</strong> The receiver is then capable of applying the same transform to <em>descramble</em> the data stream, recovering the relevant data.</p>
<p>You can think of scrambling as being very similar to encryption – except everyone knows the key. Once data is scrambled, it looks a lot more like “random numbers” than the pre-scrambling data – and accordingly, it's a lot less likely to
generate troublesome interference. Once the scrambled data travels the link, it can be <em>descrambled</em> by the receiving end – a process similar to decryption – restoring the original data stream.</p>
<h5 id="in-summary">In summary…</h5>
<p>In summary, before you can even exchange meaningful data, the digital side of your device needs:</p>
<ul>
<li><strong>8b10b encoding and decoding hardware</strong>, so the data exchanged is <em>DC-balanced</em> and contains sufficient transitions as to allow <em>clock recovery</em>;</li>
<li><strong>Clock Tolerance Compensation hardware</strong>, which allows the two sides to communicate even with slightly-varying clock frequencies;</li>
<li>Hardware to orchestrate <strong>link training</strong> and <strong>receiver equalization</strong>, which helps to deal with non-ideal transmission properties;</li>
<li><strong>Scrambling</strong> and <strong>descrambling</strong> hardware, which help to reduce harmful interference.</li>
</ul>
<p>This omits a few minor things, such as USB3's <em>Low Frequency Periodic Signaling</em>; but these are the major components.</p>
<h5 id="oh-and-one-more-thing-its-hard-to-get-good-resources">Oh, and one more thing: it's hard to get good resources.</h5>
<p>Finally, ignoring all the physical layer challenges associated with bringing a link up, there's one more major obstacle: it's hard to get good resources for working with USB3:</p>
<ul>
<li>Most hardware enabling custom USB designs is expensive; and <a href="https://lab.ktemkin.com/post/ab07-usb3fmc-wtf/">still rife with issues</a>.</li>
<li>Most USB3 tooling is <a href="https://www.totalphase.com/products/beagle-usb5000-v2-ultimate/">very expensive</a>, and still rife with issues.</li>
<li>There's very little documentation in support of the specification; and what documentation exists still hasn't been
used enough to <a href="https://lab.ktemkin.com/post/mindshare-usb3/">identify all of its errors</a>.</li>
</ul>
<p>Hopefully, at some point, I'll have built enough tooling to change this.</p>


  </article></div>]]>
            </description>
            <link>https://lab.ktemkin.com/post/why-is-usb3-harder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24704298</guid>
            <pubDate>Wed, 07 Oct 2020 01:11:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Meaning and Writing]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24703646">thread link</a>) | @exolymph
<br/>
October 6, 2020 | https://dormin.org/2020/10/06/thoughts-on-meaning-and-writing/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/10/06/thoughts-on-meaning-and-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-870">

	
	<!-- .entry-header -->


			<div>

			
<p>I was once at a dinner party and someone was telling me about her recent trip to Arizona. One of the highlights was visiting a biodome project where scientists had attempted to achieve a totally self-sustained structure in preparation for the colonization of other planets. I told her that Steve Bannon used to run that place. She didn’t believe me. I obnoxiously pulled out my phone and showed her Bannon’s Wikipedia page.</p>



<p>Steve Bannon has lived a fascinating life. That’s not an evaluation of his politics or morality, it’s a statement of fact. Witness Bannon’s life in bullet points:</p>



<ul><li>Born in 1953 in Norfolk, Virginia to a telephone lineman and a housewife</li><li>Attended military prep school and then Virginia Tech for a degree in Urban Planning, was elected president of the student body, worked in a junk yard</li><li>Served in the navy for seven years in the Pacific fleet</li><li>While in the navy, earned a Masters in National Security Studies from Georgetown</li><li>After leaving the navy, earned an MBA from Harvard</li><li>Got a job at Goldman Sachs as an investment banker in the mergers &amp; acquisitions division, worked way up to a Vice President position</li><li>Left Goldman Sachs with some colleagues to launch Bannon &amp; Co., a boutique investment bank specializing in media, nabbed a small slice of syndication rights to mega-hit tv show <strong>Seinfeld</strong>, still receives residual payments from the show to this day</li></ul>



<ul><li>While running Bannon &amp; Co., became the Acting Director of Biosphere 2 in Arizona, a project to design a self-sustaining habitat in preparation for the colonization of other planets</li><li>Dove into film production, executive produced 18 Hollywood films</li><li>Wrote and directed 12 documentaries</li><li>With an investment from Goldman Sachs, founded Internet Gaming Media, a World of Warcraft gold mining operation</li><li>Married and divorced three times, has three daughters</li><li>Charged with misdemeanor domestic violence, battery &amp; assault, and dissuading a witness based on accusations from his wife</li><li>Co-founded Government Accountability Institute, a conservative think tank</li><li>Was senior vice president of Cambridge Analytica, the company known for its influence in the 2016 presidential election and Brexit referendum</li><li>On the founding board of Breitbart News, served as its Editor-in-Chief and eventual Executive Chair, hosted its radio show</li><li>Became Chief Executive of Trump’s presidential campaign 88 days before Election Day, was considered the only person on Trump’s staff (including Trump himself) who thought he could win</li><li>Is generally considered the ideological mastermind behind the “Trumpism” ideology – populist, anti-globalist, culturally conservative, economically liberal</li><li>Served as Chief Strategist in Trump’s White House</li><li>After leaving the White House, built an international “infrastructure” for Trumpism by supporting the formation of a dozen significant political parties across Europe</li><li>Formed a partnership with outlaw Chinese billionaire Guo Wengui, pronounced the formation of an independent Chinese state to overthrow the current communist regime</li><li>Recently arrested for alleged fraud and money laundering connected to the We Build the Wall campaign, currently awaiting trial</li></ul>



<p>Again, I’m not making any moral judgement on Bannon or any of particular actions. I’m just amazed that he has done <em>so much</em>. Almost every one of these bullet points would be one of the most significant events in a normal person’s life.</p>



<p>Arnold Schwarzenegger’s life in bullet points is also incredible:</p>



<ul><li>Born in 1947 in rural Austrian poverty</li><li>Father was a physically abusive (willing) ex-Nazi wounded at Stalingrad who supposedly resented his son for suspected illegitimacy</li><li>Brother died in car crash while drunk driving, left behind a three-year-old son whom Schwarzenegger would later support</li><li>Started lifting weights at age 14 or 15</li><li>Served in the Austrian army for mandatory one year of service</li><li>While in the army, won Junior Mr. Europe weightlifting contest, was arrested and imprisoned for a week for going AWOL to attend the competition</li><li>Moved to London in his late teens to live and train with a weightlifting judge</li><li>At age 20, became the youngest Mr. Universe winner ever, first won the amateur contest, then won the professional contest three years in a row</li><li>Moved to Los Angeles, most likely lived as an illegal immigrant for years</li><li>First won Mr. Olympia at age 23, youngest ever; won contest six more times; became known as one of the greatest bodybuilders of all time</li><li>Attended classes at three different colleges to attain a degree in Business Administration and Marketing</li><li>Appeared in a handful of action films, was told by agents that his body was too “weird,” accent too thick, and name too long</li><li>Started a surprisingly successful bricklaying business and a mail-order business with another bodybuilder, also invested in numerous real estate companies</li><li>Became a millionaire by age 30</li><li>Starred in <strong>Pumping Iron</strong> and then <strong>Conan the Barbarian</strong>, breakthrough roles</li><li>Starred in <strong>Terminator, Predator, Commando, Running Man, Total Recall, Kindergarten Cop, Terminator 2, True Lies, </strong>and became known as one of the great action stars ever</li><li>Invested in Planet Hollywood, a shopping mall in Ohio, a restaurant, Dimensional Fund Advisors, a movie production company, numerous fitness magazines, and a fitness competition</li><li>Appointed Chairman of President Clinton’s Council of Physical Fitness and Sports</li><li>Ran for Governor of California (the most populous and wealthiest state in the wealthiest country in the world) and won despite having no political experience</li><li>Won re-election as a Republican during the height of anti-Bush sentiment</li><li>Went back to acting and continues to star in movies to this day</li><li>Married and divorced a Kennedy, had four children with her, plus another child with his housekeeper</li><li>Current net worth estimated at $100-200 million, may have peaked at $800 million before the divorce</li></ul>



<p>I’ve read a lot of Wikipedia pages and I find they all end up as bullet points in my head. That’s kind of how I think about everything… as lists of the most important things. Everything else fades away over time.</p>



<p>As you can tell from this blog, I’ve spent a lot of time thinking about <em>great</em> people. Napoleon, Cortes, Genghis Khan, Mark Schilling, Hideo Kojima, and Tommy Wiseau are not all good people, but they are <em>great</em>. Each one could easily earn a bullet point list like Bannon’s and Schwarzenegger’s. They’ve all built lives full of notable activities and accomplishments which will live on in history in one way or another.</p>



<p>I don’t think I’ll live on in history for very long after I die except for boring stuff like my tax records. And I’m fine with that. It’s not clear that living a historically noteworthy life is desirable in and of itself.</p>



<p>But I do want a noteworthy life on my own terms. I want my life to resemble one of these bullet point lists within the reasonable bounds of what I can experience and achieve given my abilities, resources, and will. Especially when I’m older, I want to be able to sit at a computer and type out the actions, events, and people that I remember and be proud of the list before me.</p>



<p>This is my personal heuristic for <em>meaning</em> in life. Both in the short and long term I try to do things which one day could be put on a bullet point list about me. Or maybe I just try to do things I’ll <em>remember</em>.</p>



<p>Pick a random year from your life and try to write a bullet point list of things that happened that year. If I do that for any year in the past decade, I usually get…</p>



<ul><li>The girl I was dating at the time (if any)</li><li>Places I traveled</li><li>The job I had (though I rarely remember any particular thing I did in that year on the job)</li><li>Significant money I made or lost</li><li>Significant events experienced with friends</li><li>It’s a bit harder to pinpoint specific years, but I can always remember the general era when I experienced particular passion projects/activities, like movies/tv shows/books/video games/athletics, etc. For instance, I distinctly remember playing <em>Skyrim</em> in college and <em>Faster than Light</em> while at the office in 2015.</li></ul>



<p>So what I tend to remember are relationships, work, money, and passion projects. I don’t think that’s uncommon, though the weight I give each one might be. Regardless, these are the things that matter to me. They should be my major goals in life. They are what I’ll look back on and remember when I’m 30, 40, 50, and close to death. Hopefully.</p>



<p>There’s this Anthony Bourdain quote I like:</p>



<blockquote><p>“I understand there’s a guy inside me who wants to lay in bed, smoke weed all day, and watch cartoons and watch old movies. My whole life is a series of stratagems to avoid and outwit that guy.”</p></blockquote>



<p>I very much sympathize. Though my version of that is sitting on the couch, watching old episodes of <strong>Archer</strong>, and playing my hundredth <strong>Crusader Kings 2</strong> campaign.</p>



<p>I think what Bourdain’s struggle comes down to is finding meaning every day. It’s the easiest thing in the world to let each day go by filled with nothing but obligations and short term stimulation. Nothing long-term is gained, nothing is remembered, and when you wake up the next morning you’re a day older with nothing important added to your existence. This will be 99.9% of the days in your life.</p>



<p>Resisting this reality is literally a constant challenge. One way I try to resist is to consider which specific actions which will result in discrete memorable experiences. That is, I try to do things I’ll remember even if I don’t remember the day itself. For instance, what am I more likely to remember doing tonight: playing another three out of literally thousands of hours of <strong>Crusader Kings 2</strong>, or watching a new movie?</p>



<p>The movie, of course. Even if the movie is bad, or boring, or forgettable, I will still vaguely recall having seen it years from now, but there is almost no chance I’ll remember those random three hours of <strong>Crusader Kings 2</strong> regardless of how much I enjoyed them. </p>



<p>Alternatively, you can deal with Bourdain’s problem by trying to make small contributions to greater acts of meaning each day. I’ve kept an IMDB account since I was …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/10/06/thoughts-on-meaning-and-writing/">https://dormin.org/2020/10/06/thoughts-on-meaning-and-writing/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/10/06/thoughts-on-meaning-and-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24703646</guid>
            <pubDate>Tue, 06 Oct 2020 23:25:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I will never buy another CyberPower UPS]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24703593">thread link</a>) | @monstermunch
<br/>
October 6, 2020 | https://blog.networkprofile.org/cyberpower-ups-avoid/ | <a href="https://web.archive.org/web/*/https://blog.networkprofile.org/cyberpower-ups-avoid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.networkprofile.org/content/images/size/w300/2020/10/2020-10-06-16.50.41-1.JPG 300w,
                            https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-06-16.50.41-1.JPG 600w,
                            https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-06-16.50.41-1.JPG 1000w,
                            https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-06-16.50.41-1.JPG 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-06-16.50.41-1.JPG" alt="Cyberpower UPS's - Try something else...">
            </figure>

            <section>
                <div>
                    <p>This is now the fourth time I have come across these issues with a Cyberpower UPS. It means your UPS really isn't a UPS, so you may want to think twice about picking one up</p><p>First thing to keep in mind is that these are line interactive UPS's, that means the input power isn't going through the batteries at all like with a double conversion UPS, but its just passing right through to your devices while maybe doing some minor filtering and surge protection. These devices simply do not need batteries in them to provide output power</p><h2 id="issue-1">Issue 1</h2><p>What happens is that the UPS will work fine, until it can no longer charge the batteries. When that happens, the UPS will both shut down output power (Even though the power from the wall is fine) and continue to try and charge the batteries while giving you an error code E24 that says "Internal Fault - CONTACT SUPPORT" in the manual </p><p>If you do contact support, they tell you that the UPS needs to be replaced entirely. What it really means is that you have bad batteries, and for around $40 you can be back in business.</p><p>They also claim that the reason it shutdown output power is for safety reasons, but then why does it try and charge the batteries still? Your guess is as good as mine. Even worse, when you turn the UPS off and take the batteries out, they are burning hot, because the UPS is trying its best to charge bad batteries.</p><h2 id="issue-2">Issue 2</h2><p>The second issue with them is that when the batteries are clearly bad and cannot supply a load, but still give a nominal 12v charge, the UPS thinks its fine. Even if it fails the self test, it reports that is has succeeded.</p><p>I have a small USB LED Light that probably doesn't even draw 1w. If I initiate a self test, the UPS just shuts off completely, and when powered back on, reports everything is great, and the software says the test passed. Awesome!</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-06-16.34.55.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-06-16.34.55.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-06-16.34.55.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-06-16.34.55.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-06-16.34.55.JPG 2400w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-06-16_46_30-PowerPanel--Personal-_-CyberPower-Systems.png" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-06-16_46_30-PowerPanel--Personal-_-CyberPower-Systems.png 600w, https://blog.networkprofile.org/content/images/2020/10/2020-10-06-16_46_30-PowerPanel--Personal-_-CyberPower-Systems.png 861w" sizes="(min-width: 720px) 720px"></figure><p>Every other UPS I come across would fail the self test while NOT shutting down output power, and it would alert you that you need new batteries.</p><p>Watch this video: </p><figure></figure><p>In the end of the video you can see the UPS lost connection, but that doesn't even matter as the Cyberpower software marks the test complete before that even happens, as you can see in the screenshot I posted above the video.</p><p>This issue is compounded by the fact that the UPS completely yet again turns itself off. That means if you had a PC plugged into the UPS, and another plugged into the wall and had a very minor power dip, the one directly in the wall would probably remain on, and the one plugged into the UPS would be turned off.</p><p>Doesn't that defeat the entire point of a UPS? If you have one of these units, you need to be prepared that you will lose power unexpectedly at some point. The fact you can't test the batteries without losing power means that you will either need to shutdown your computer/servers/etc every 2 weeks and test, or just replace the batteries WELL ahead of schedule, say every 2 years just to avoid losing power.</p><p>A better solution would be to toss the UPS, and get a better one </p><p>I have found this issue in every single Cyberpower UPS I have ever used which is 4 units in the PFCLCD series and AVRLCD series</p><p>Just avoid them entirely, and go with a different brand.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.networkprofile.org/cyberpower-ups-avoid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24703593</guid>
            <pubDate>Tue, 06 Oct 2020 23:19:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOMPurify bypass: XSS via HTML namespace confusion]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24703230">thread link</a>) | @fanf2
<br/>
October 6, 2020 | https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/ | <a href="https://web.archive.org/web/*/https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1639">
	<!-- .entry-header -->

	
	<div>
		
<p>In this blogpost I’ll explain my recent bypass in <a href="https://github.com/cure53/DOMPurify/">DOMPurify</a> – the popular HTML sanitizer library. In a nutshell, DOMPurify’s job is to take an untrusted HTML snippet, supposedly coming from an end-user, and remove all elements and attributes that can lead to Cross-Site Scripting (XSS).</p>



<p>This is the bypass:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c770359435490" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form</span><span>&gt;</span></p><p><span>&lt;</span><span>math</span><span>&gt;</span><span>&lt;</span><span>mtext</span><span>&gt;</span></p><p><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form</span><span>&gt;</span></p><p><span>&lt;</span><span>mglyph</span><span>&gt;</span></p><p><span>&lt;</span><span>style</span><span>&gt;</span><span>&lt;</span><span>/</span><span>math</span><span>&gt;</span><span>&lt;</span><span>img </span><span>src </span><span>onerror</span><span>=</span><span>alert</span><span>(</span><span>1</span><span>)</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0003 seconds] -->




<p>Believe me that there’s not a single element in this snippet that is superfluous 🙂 </p>



<p>To understand why this particular code worked, I need to give you a ride through some interesting features of HTML specification that I used to make the bypass work.</p>



<h2>Usage of DOMPurify</h2>



<p>Let’s begin with the basics, and explain how DOMPurify is usually used. Assuming that we have an untrusted HTML in <code>htmlMarkup</code> and we want to assign it to a certain <code>div</code>, we use the following code to sanitize it using DOMPurify and assign to the <code>div</code>:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c778625420655" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>div</span><span>.</span><span>innerHTML</span><span> </span><span>=</span><span> </span><span>DOMPurify</span><span>.</span><span>sanitize</span><span>(</span><span>htmlMarkup</span><span>)</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>In terms of parsing and serializing HTML as well as operations on the DOM tree, the following operations happen in the short snippet above:</p>



<ol><li><code>htmlMarkup</code> is parsed into the DOM Tree.</li><li>DOMPurify sanitizes the DOM Tree (in a nutshell, the process is about walking through all elements and attributes in the DOM tree, and deleting all nodes that are not in the allow-list).</li><li>The DOM tree is serialized back into the HTML markup.</li><li>After assignment to <code>innerHTML</code>, the browser parses the HTML markup again.</li><li>The parsed DOM tree is appended into the DOM tree of the document.</li></ol>



<p>Let’s see that on a simple example. Assume that our initial markup is <code>A&lt;img src=1 onerror=alert(1)&gt;B</code>. In the first step it is parsed into the following tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1024x104.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1024x104.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-300x30.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-768x78.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1536x155.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1320x134.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1.png 1956w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then, DOMPurify sanitizes it, leaving the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1024x107.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1024x107.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-300x31.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-768x80.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1536x161.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1320x138.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2.png 1952w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then it is serialized to:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		
<!-- [Format Time: 0.0001 seconds] -->




<p>And this is what <code>DOMPurify.sanitize</code> returns. Then the markup is parsed again by the browser on assignment to innerHTML:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1024x107.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1024x107.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-300x31.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-768x80.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1536x161.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1320x138.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3.png 1952w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The DOM tree is identical to the one that DOMPurify worked on, and it is then appended to the document.</p>



<p>So to put it shortly, we have the following order of operations: <strong>parsing ➡️ serialization ➡️ parsing</strong>. The intuition may be that serializing a DOM tree and parsing it again should always return the initial DOM tree. But this is not true at all. There’s even <a href="https://html.spec.whatwg.org/multipage/parsing.html#serialising-html-fragments:escapingString-3:~:text=It%20is%20possible%20that%20the%20output,not%20return%20the%20original%20tree%20structure">a warning in the HTML spec</a> in a section about serializing HTML fragments:</p>



<blockquote><p>It is possible that the output of this algorithm [serializing HTML], if parsed with an HTML parser, will not return the original tree structure. <strong>Tree structures that do not roundtrip a serialize and reparse step can also be produced by the HTML parser itself</strong>, although such cases are typically non-conforming.</p></blockquote>



<p>The important take-away is that serialize-parse roundtrip is not guaranteed to return the original DOM tree (this is also a root cause of a type of XSS known as <strong>mutation XSS</strong>). While usually these situations are a result of some kind of parser/serializer error, there are at least two cases of spec-compliant mutations.</p>



<h2>Nesting FORM element</h2>



<p>One of these cases is related to the FORM element. It is quite special element in the HTML because it cannot be nested in itself. The specification is explicit that<a href="https://html.spec.whatwg.org/#the-form-element"> it cannot have any descendant that is also a FORM</a>:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1024x279.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1024x279.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-300x82.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-768x209.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1536x419.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1320x360.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4.png 1936w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This can be confirmed in any browser, with the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c780486286585" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>form1</span><span>&gt;</span></p><p><span>INSIDE_FORM1</span></p><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>form2</span><span>&gt;</span></p><p><span>INSIDE_FORM2</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>Which would yield the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1024x80.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1024x80.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-300x24.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-768x60.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1536x121.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1320x104.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5.png 1960w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The second <code>form</code> is completely omitted in the DOM tree just as it wasn’t ever there.</p>



<p>Now comes the interesting part. If we keep reading the HTML specification, it actually gives <a href="https://html.spec.whatwg.org/multipage/parsing.html#serialising-html-fragments:the-script-element-4:~:text=DOM.-,For%20example%2C%20consider%20the%20following%20markup%3A,%3Cform">an example</a> that with a slightly broken markup with mis-nested tags, it is possible to create nested forms. Here it comes (taken directly from the spec):</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c787151961755" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>It yields the following DOM tree, which contains a nested form element:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1024x141.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1024x141.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-300x41.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-768x106.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1536x211.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1320x182.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6.png 1948w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is not a bug in any particular browser; it results directly from the HTML spec, and is described in the algorithm of parsing HTML. Here’s the general idea:</p>



<ul><li>When you open a <code>&lt;form&gt;</code> tag, the parser needs to keep record of the fact that it was opened with a <strong>form element pointer</strong> (that’s how it’s called in the spec). If the pointer is not <code>null</code>, then <code>form</code> element cannot be created.</li><li>When you end a <code>&lt;form&gt;</code> tag, the form element pointer is always set to <code>null</code>. </li></ul>



<p>Thus, going back to the snippet:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c789352570279" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>In the beginning, the form element pointer is set to the one with <code>id="outer"</code>. Then, a <code>div</code> is being started, and the <code>&lt;/form&gt;</code> end tag set the form element pointer to <code>null</code>. Because it’s <code>null</code>, the next form with <code>id="inner"</code> can be created; and because we’re currently within <code>div</code>, we effectively have a <code>form</code> nested in <code>form</code>.</p>



<p>Now, if we try to serialize the resulting DOM tree, we’ll get the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c78d603903002" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>Note that this markup no longer has any mis-nested tags. And when the markup is parsed again, the following DOM tree is created:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1024x101.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1024x101.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-300x30.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-768x76.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1536x151.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-2048x202.png 2048w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1320x130.png 1320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>So this is a proof that serialize-reparse roundtrip is not guaranteed to return the original DOM tree. And even more interestingly, this is basically <strong>a spec-compliant mutation</strong>.</p>



<p>Since the very moment I was made aware of this quirk, I’ve been pretty sure that it must be possible to somehow abuse it to bypass HTML sanitizers. And after a long time of not getting any ideas of how to make use of it, I finally stumbled upon another quirk in HTML specification. But before going into the specific quirk itself, let’s talk about my favorite Pandora’s box of the HTML specification: foreign content.</p>



<h2>Foreign content</h2>



<p>Foreign content is a like a Swiss Army knife for breaking parsers and sanitizers. I used it in my <a href="https://research.securitum.com/dompurify-bypass-using-mxss/">previous DOMPurify bypass</a> as well as in <a href="https://research.securitum.com/html-sanitization-bypass-in-ruby-sanitize-5-2-1/">bypass of Ruby sanitize library</a>.</p>



<p>The HTML parser can create a DOM tree with elements of three namespaces:</p>



<ul><li>HTML namespace (<code>http://www.w3.org/1999/xhtml</code>)</li><li>SVG namespace (<code>http://www.w3.org/2000/svg</code>)</li><li>MathML namespace (<code>http://www.w3.org/1998/Math/MathML</code>)</li></ul>



<p>By default, all elements are in HTML namespace; however if the parser encounters <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> element, then it “switches” to SVG and MathML namespace respectively. And both these namespaces make foreign content.</p>



<p>In foreign content markup is parsed differently than in ordinary HTML. This can be most clearly shown on parsing of <code>&lt;style&gt;</code> element. In HTML namespace, <code>&lt;style&gt;</code> can only contain text; no descendants, and HTML entities are not decoded. The same is not true in foreign content: foreign content’s <code>&lt;style&gt;</code> can have child elements, and entities are decoded.</p>



<p>Consider the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c78f480128252" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;style&gt;</span><span>&lt;a&gt;</span><span>ABC&lt;/style&gt;</span><span>&lt;</span><span>svg</span><span>&gt;</span><span>&lt;</span><span>style</span><span>&gt;</span><span>&lt;</span><span>a</span><span>&gt;</span><span>ABC</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0004 seconds] -->




<p>It is parsed into the following DOM tree</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1024x206.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1024x206.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-300x60.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-768x154.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1536x308.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1320x265.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8.png 1962w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Note:</strong> from now on, all elements in the DOM tree in this blogpost will contain a namespace. So <code>html style</code> means that it is a <code>&lt;style&gt;</code> element in HTML namespace, while <code>svg style</code> means that it is a <code>&lt;style&gt;</code> element in SVG namespace.</p>



<p>The resulting DOM tree proves my point: <code>html style</code> has only text content, while <code>svg style</code> is parsed just like an ordinary element.</p>



<p>Moving on, it may be tempting to make a certain observation. That is: if we are inside <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> then all elements are also in non-HTML namespace. But this is not true. There are certain elements in HTML specification called <strong>MathML text integration points</strong> and <strong>HTML integration point</strong>. And the children of these elements have HTML namespace (with certain exceptions I’m listing below).</p>



<p>Consider the following example:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c793354927935" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>math</span><span>&gt;</span></p><p><span>&lt;style&gt;</span><span>&lt;/style&gt;</span></p><p><span>&lt;</span><span>mtext</span><span>&gt;</span><span>&lt;style&gt;</span><span>&lt;/style&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>It is parsed into the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1024x138.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1024x138.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-300x40.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-768x104.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1536x207.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1320x178.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9.png 1956w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Note how the <code>style</code> element that is a direct child of <code>math</code> is in MathML namespace, while the <code>style</code> element in <code>mtext</code> is in HTML namespace. And this is because <code>mtext</code> is <strong>MathML text integration points</strong> and makes the parser switch namespaces. </p>



<p>MathML text integration points are:</p>



<ul><li><code>math mi</code></li><li><code>math mo</code></li><li><code>math mn</code></li><li><code>math ms</code></li></ul>



<p>HTML integration points are:</p>



<ul><li><code>math annotation-xml</code> if it has an attribute called <code>encoding</code> whose value is equal to either <code>text/html</code> or <code>application/xhtml+xml</code></li><li><code>svg foreignObject</code></li><li><code>svg desc</code></li><li><code>svg title</code></li></ul>



<p>I always assumed that all children of MathML text integration points or HTML integration points have HTML namespace by default. How wrong was I! The HTML specification says that children of MathML text integration points are by default in HTML namespace with two exceptions: <code>mglyph</code> and <code>malignmark</code>. And this only happens if they are a direct child of MathML text integration points.</p>



<p>Let’s check that with the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f7fe6ce9c795119295076" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>math</span><span>&gt;</span></p><p><span>&lt;</span><span>mtext</span><span>&gt;</span></p><p><span>&lt;</span><span>mglyph</span><span>&gt;</span><span>&lt;</span><span>/</span><span>mglyph</span><span>&gt;</span></p><p><span>&lt;</span><span>a</span><span>&gt;</span><span>&lt;</span><span>mglyph</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1024x168.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1024x168.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-300x49.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-768x126.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1536x252.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1320x217.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10.png 1974w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Notice that <code>mglyph</code> that is a direct child of <code>mtext</code> is in MathML namespace, while the one that is a child of <code>html a</code> element is in HTML namespace.</p>



<p>Assume that we have a “current element”, and we’d like determine its namespace. I’ve compiled some rules of thumb:</p>



<ul><li>Current element is in the namespace of its parent unless conditions from the points below are met.</li><li>If current element is <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> and parent is in HTML namespace, then current element is in SVG or MathML namespace respectively.</li><li>If parent of current element is an HTML integration point, then current element is in HTML namespace unless it’s <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code>.</li><li>If parent of current element is an MathML integration point, then current element is in HTML namespace unless it’s <code>&lt;svg&gt;</code>, <code>&lt;math&gt;</code>, <code>&lt;mglyph&gt;</code> or <code>&lt;malignmark&gt;</code>.</li><li>If current element is one of <code>&lt;b&gt;, &lt;big&gt;, &lt;blockquote&gt;, &lt;body&gt;, &lt;br&gt;, &lt;center&gt;, &lt;code…</code></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/">https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/</a></em></p>]]>
            </description>
            <link>https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24703230</guid>
            <pubDate>Tue, 06 Oct 2020 22:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planning to Explore via Self-Supervised World Models]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24703113">thread link</a>) | @headalgorithm
<br/>
October 6, 2020 | https://ramanans1.github.io/plan2explore/ | <a href="https://web.archive.org/web/*/https://ramanans1.github.io/plan2explore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div max-width="100%">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <title>Planning to Explore via Self-Supervised World Models</title>
  <meta name="HandheldFriendly" content="True">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="referrer" content="no-referrer-when-downgrade">

  <meta property="og:site_name" content="Planning to Explore">
  <meta property="og:type" content="video.other">
  <meta property="og:title" content="Planning to Explore via Self-Supervised World Models">
  <meta property="og:description" content="Sekar, Rybkin, Daniilidis, Abbeel, Hafner, Pathak. Planning to Explore via Self-Supervised World Models. ICML 2020.">
  <meta property="og:url" content="https://ramanans1.github.io/plan2explore/">
  <meta property="og:image" content="https://ramanans1.github.io/plan2explore/resources/setting.png">
  <meta property="og:video" content="https://www.youtube.com/v/GftqnPWsCWw">

  <meta property="article:publisher" content="https://github.com/ramanans1">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Planning to Explore via Self-Supervised World Models">
  <meta name="twitter:description" content="Sekar, Rybkin, Daniilidis, Abbeel, Hafner, Pathak. Planning to Explore via Self-Supervised World Models. ICML 2020.">
  <meta name="twitter:url" content="https://ramanans1.github.io/plan2explore/">
  <meta name="twitter:image" content="https://ramanans1.github.io/plan2explore/resources/setting.png">
  <!-- <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Deepak Pathak" /> -->
  <!-- <meta name="twitter:label2" content="Filed under" />
  <meta name="twitter:data2" content="" /> -->
  <meta name="twitter:site" content="@pathak2206">
  <meta property="og:image:width" content="1600">
  <meta property="og:image:height" content="900">

  
  <meta name="twitter:card" content="player">
  <meta name="twitter:image" content="https://ramanans1.github.io/plan2explore/resources/setting.png">
  <meta name="twitter:player" content="https://www.youtube.com/embed/GftqnPWsCWw?rel=0&amp;showinfo=0">
  <meta name="twitter:player:width" content="640">
  <meta name="twitter:player:height" content="360">



      <br>
      <center><span>Planning to Explore via Self-Supervised World Models</span></center><br>
      
      
      <center><span><a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning (ICML), 2020</a></span></center>

      

      <center>
      <iframe width="768" height="432" max-width="100%" src="https://www.youtube.com/embed/GftqnPWsCWw?rel=0" frameborder="0" allowfullscreen=""></iframe></center>
      

      <p>
        Reinforcement learning allows solving complex tasks, however, the learning tends to be task-specific and the sample efficiency remains a challenge. We present Plan2Explore, a self-supervised reinforcement learning agent that tackles both these challenges through a new approach to self-supervised exploration and fast adaptation to new tasks, which need not be known during exploration. During exploration, unlike prior methods which retrospectively compute the novelty of observations after the agent has already reached them, our agent acts efficiently by leveraging planning to seek out expected future novelty. After exploration, the agent quickly adapts to multiple downstream tasks in a zero or a few-shot manner. We evaluate on challenging control tasks from high-dimensional image inputs. Without any training supervision or task-specific interaction, Plan2Explore outperforms prior self-supervised exploration methods, and in fact, almost matches the performances oracle which has access to rewards.
      </p>
      <br><hr>

      <center></center>
      <p>
        The agent first leverages planning to explore in self-supervised manner, without task-specific rewards, to learn a global world model. After the exploration phase, it receives reward functions to adapt to multiple tasks, such as standing, walking, running, and using either zero or few tasks-specific interactions.
      </p>
      <center><a href="https://ramanans1.github.io/plan2explore/resources/setting.png"><img src="https://ramanans1.github.io/plan2explore/resources/setting.png" width="600px"></a><br></center>
      <hr>


      <center></center><br>
      <center><a href="https://ramanans1.github.io/plan2explore/resources/method.png"><img src="https://ramanans1.github.io/plan2explore/resources/method.png" width="800px"></a><br></center>
      <br><hr>


            <center id="sourceCode"></center>
            <p>
            We have released our implementation in Tensorflow on the github page. Try our code!
            </p>
            
            <br><hr>

            <center id="sourceCode"></center>
            
            <br><hr>

              <center></center>
              <table>
              <tbody><tr>
              <td>
              <!-- <p style="margin-top:4px;"></p> -->
              <a href="https://arxiv.org/pdf/2005.05960.pdf"><img src="https://ramanans1.github.io/plan2explore/resources/thumbnail.png"></a>
              <center>
              <span><a href="https://arxiv.org/pdf/2005.05960.pdf">[Paper]</a>
              <span><a href="https://arxiv.org/abs/2005.05960">[ArXiv]</a>
              <!-- <span style="font-size:20pt"><a href="resources/slides.pdf">[Slides]</a></span>
              <span style="font-size:20pt"><a href="resources/poster.pdf">[Poster]</a></span> -->
              </span></span></center>
              </td>
              <td>
              </td>
              <td>
              <!-- <p style="margin-top:4px;"></p> -->
              <p><b><span>Citation</span></b><br><span>&nbsp;<br></span> <span>Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, Deepak Pathak. <b>Planning to Explore via Self-Supervised World Models.</b> ICML 2020.</span></p>
              <!-- <p style="margin-top:20px;"></p> -->
              <span>[Bibtex]</span>
              </td>
              </tr>
              <tr>
              <td>
              </td>
              <td>
              </td>
              <td>
                <div id="plan2explore2019_bib">
<pre xml:space="preserve">@inproceedings{sekar2020planning,
    title={Planning to Explore
    via Self-Supervised World Models},
    author={Ramanan Sekar and Oleh Rybkin
    and Kostas Daniilidis and Pieter Abbeel
    and Danijar Hafner and Deepak Pathak},
    year={2020},
    Booktitle={ICML}
}</pre>
                </div>
                </td>
                </tr>
            </tbody></table>
          <br><hr>
      


</div></div>]]>
            </description>
            <link>https://ramanans1.github.io/plan2explore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24703113</guid>
            <pubDate>Tue, 06 Oct 2020 22:29:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shipping an MVP in Two Weeks During YC Using Repl.it]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24702373">thread link</a>) | @brendanfalk
<br/>
October 6, 2020 | https://blog.repl.it/fig | <a href="https://web.archive.org/web/*/https://blog.repl.it/fig">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>My name is <a href="https://twitter.com/brendanfalk">Brendan Falk</a>. I am one of the co-founders of <a href="http://withfig.com/?ref=replit">Fig</a> (YC S20). Fig adds visual apps and shortcuts to your Terminal. We make it easy for developers to build visual apps that streamline terminal workflows. We then let developers share apps with their team and the community. Our website gives a good demo.</p>
<p>After going through various pivots in early 2020, we realised that the Terminal was a huge pain point for us. We wondered if we could build a tool that would make our own lives easier. But rather than creating a new terminal, we wanted to attach to our existing Terminal.</p>
<p>In late April, we started exploring whether building a tool like Fig was even technically possible. On the 15th of May we decided to go all in on Fig. Roughly two weeks later, we had a simple MVP in users' hands. </p>
<p>YCombinator pushes companies to move fast. Repl.it helped us move fast.</p>
<p><img src="https://blog.repl.it/images/fig/fig.png" alt="fig terminal screenshot"></p>
<h3 id="why-did-i-personally-use-replit">Why Did I Personally Use Repl.it</h3>
<p>Before I answer this, here is some quick context on me: I am the CEO of Fig. Before starting YC I was somewhat technical. Up until about March this year, I knew HTML/CSS and a tiny bit of JavaScript. I had no idea what a server was. <a href="https://news.ycombinator.com/item?id=21795041">Here is my first HN post</a> where I ask how to deploy an ML model haha. My co-founder, <a href="https://twitter.com/mattschrage">Matt</a>, did most of the coding. </p>
<p>I started learning JavaScript in early May 2020. I had always tried to avoid it. I used no-code tools like Bubble.io instead. Because we were starting YC in a month, I decided it was time to get my act together. We could move faster if I could code too.</p>
<p>I don't know how I came across Repl.it. I thought it looked cool so I gave it a go. </p>
<p>Within a few minutes, almost by accident, I had a server up and running.</p>
<p><img src="https://blog.repl.it/images/fig/final_replit_node_demo.gif" alt="final_replit_node_demo"></p>
<p>I thought, wow, not only did I just build a server, it's at a live URL that I can share with people. I can update the app and that URL would update instantly too. I liked that it managed the whole devops / deployment side of things. I could just code. Pretty cool.</p>
<p>Naturally, I just kept building in it. As it turned out, Repl.it was just as helpful to our team. </p>
<h3 id="why-did-fig-use-replit">Why Did Fig use Repl.it</h3>
<p><strong>Instant Deploys</strong></p>
<p>Repl.it let us deploy a live production app to our own domain in a click. Fig is a unique tool. You can think of us like a web browser that attaches to your Terminal. We are a CLI tool that launches a desktop app (built natively in Swift, not Electron) which renders lots of mini web apps (as you can see in the git example below). </p>
<p>We wanted to move quickly. Setting up dev, testing, and staging environments for the app was going to take us longer than we wanted to implement. We have obviously done this now, but at the time, we wanted to move quickly. </p>
<p>We wanted a solution that we could set up &amp; deploy to easily, built our app quickly, and pushed to our own custom url. AWS/GCP are too clunky to set up. Heroku is quick to set up, but takes 20 seconds per build and this is really annoying. Repl.it, however, ticked all our boxes. I would change a line of code and it would be live in Fig in 3 seconds.</p>
<p><strong>Git / Version Control</strong></p>
<p>I know the basics of git, but Repl.it just made it so easy. I connected a new GitHub repo to my Repl.it app. I clicked a button, typed a commit message, then clicked commit and push. Both my co-founder and I were writing better commit message and were committing more often.</p>
<p>In fact, we loved Repl.it's git extension add-on so much, we copied it and turned it into an app on Fig (thanks Amjad haha).</p>
<p><img src="https://blog.repl.it/images/fig/fig-git-demo.gif" alt="fig-git-demo"></p>
<p><strong>Multiplayer</strong></p>
<p>This one is pretty self explanatory... Being able to do pair programming without the hassle of setting it up in VSCode is very very nice. We were very productive with this.</p>
<p><strong>Free</strong></p>
<p>Again, pretty obvious. Premium (Hacker) was free for students (we were still in college when we were doing this). I now pay $7/month for this. It's how much Heroku is but you get a full IDE + speed with it. Totally worth it.</p>
<h3 id="how-do-i-use-replit-now-fig-transitioned-to-heroku-and-aws">How do I use Repl.it Now Fig Transitioned to Heroku and AWS</h3>
<p>We got really far with Repl.it, but we eventually hit some limits and bugs (that has since been fixed). Repl.it's Github integration is limited and we needed to get serious about our git workflow and devops. We decided it was time for us to move from Repl.it to Heroku, AWS, and S3. We now do most of our coding for our main app on VSCode.</p>
<p>Despite this, I still use Repl.it all the time. Whenever I want to test out a new framework or library, I just open up a new repl. I'm also finding my Google searches are yielding more and more posts from the Repl.it's forum. It's a fantastic community.</p>
<h3 id="parting-words">Parting Words</h3>
<p>It's funny, by recommending Repl.it I realise I am shooting myself in the foot a little bit. Fig's bet is that the local Terminal isn't going away. We don't think it will anytime soon 😉. If you want to be a productive programmer, the Terminal is a tool you should know. But tools like Repl.it are making it very easy to code in the cloud and stay there!</p>
<p>If you have any questions about YC, Fig, Repl.it, or just want to say hey, feel free to email me (I'm very responsive): <a href="mailto:brendan@withfig.com">brendan@withfig.com</a></p>
<p>And if you want to sign up for Fig's private beta, mention this blog post in your sign up and we'll get you off the waitlist: <a href="https://withfig.com/?ref=replit">withfig.com</a></p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/fig</link>
            <guid isPermaLink="false">hacker-news-small-sites-24702373</guid>
            <pubDate>Tue, 06 Oct 2020 21:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter – Add WebAuthn on Your Website to Enable Biometric Auth]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24702335">thread link</a>) | @mmarcelline
<br/>
October 6, 2020 | https://docs.cotter.app/sdk-reference/web/sign-in-with-webauthn | <a href="https://web.archive.org/web/*/https://docs.cotter.app/sdk-reference/web/sign-in-with-webauthn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="fa10941de073416cb69b38caad08bb6d" autocorrect="on" spellcheck="true" data-gramm="false"><blockquote data-key="3136b5599b93459ba03269ad4283c750"><p data-key="5ca23876877648d391478d176fbc733e"><span><span data-key="ba4b5efe0ea24609a90456cd64b729b8"><span data-offset-key="ba4b5efe0ea24609a90456cd64b729b8:0"><strong data-slate-leaf="true">Concepts: </strong></span><span data-offset-key="ba4b5efe0ea24609a90456cd64b729b8:1">Learn about how </span></span><a data-key="3176c08f572f46a49699af5805bbfc11" href="https://docs.cotter.app/features/sign-in-with-webauthn"><span data-key="f81980c09e1845e0af42a998894898f4"><span data-offset-key="f81980c09e1845e0af42a998894898f4:0"><strong data-slate-leaf="true">Sign in with WebAuthn</strong></span></span></a><span data-key="9eeba84effc04126afd7b611ba5d7267"><span data-offset-key="9eeba84effc04126afd7b611ba5d7267:0"> works.</span></span></span></p></blockquote><div data-slate-void="true" data-key="b3157655a19b40eb8a22790cfab6180d"><div><figure data-key="b3157655a19b40eb8a22790cfab6180d" contenteditable="false"><div><p><img tabindex="0" src="https://gblobscdn.gitbook.com/assets%2F-M0QGDMRD8y_Kd-BpOvT%2F-MCkI8IfsipR_rpREq-M%2F-MCkIqSr1NpqGEsST7of%2Fimage.png?alt=media&amp;token=443a6b26-0431-45b1-8b66-31e3dd13a92a" loading="lazy"></p></div><p><figcaption><span>WebAuthn with Cotter's JS SDK</span></figcaption></p></figure></div></div><h2 id="overview" data-key="bf8d53a8dade4269bbf0c6ddfb2b3762"><p><span><span data-key="f46696d641e8486e9cc82e997c1e75f4"><span data-offset-key="f46696d641e8486e9cc82e997c1e75f4:0">Overview</span></span></span><a href="#overview" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="77c09eba93874920b84306161cdc62bd"><span><span data-key="1880a9dfda12402eb14d8458e9d432f1"><span data-offset-key="1880a9dfda12402eb14d8458e9d432f1:0">WebAuthn authentication works the following way:</span></span></span></p><ol data-key="2900c8c742b84e028bbeff25e8f924c0"><li><p data-key="1d8ef40aecd8442e981a4d54478093d4"><span><span data-key="821c8c1c7624481aad797a37d2337221"><span data-offset-key="821c8c1c7624481aad797a37d2337221:0">A new user would be prompted to either enter a verification code or magic link sent to their email or phone.</span></span></span></p></li><li><p data-key="afecc97746ae4a71bda70654c571bf7d"><span><span data-key="8b6e8ef7feb94d1c92a33be8059a6782"><span data-offset-key="8b6e8ef7feb94d1c92a33be8059a6782:0">Once the user verified their email/phone, the SDK will automatically prompt the user if they want to register this device for fast logins next time.</span></span></span></p></li><li><p data-key="28518277060849429767ec36916a10a9"><span><span data-key="0b57fdaa54d44c96a09f7b1f024767b4"><span data-offset-key="0b57fdaa54d44c96a09f7b1f024767b4:0">The user can press "Enable TouchID" and successfully register their laptop.</span></span></span></p></li><li><p data-key="bc29b5c2dd484f4aa2173bcdf03f45f3"><span><span data-key="0dcfabca2a384ab0a219de2afc01c97b"><span data-offset-key="0dcfabca2a384ab0a219de2afc01c97b:0">When the user login next time, the user will automatically be prompted to use TouchID to login. As a fallback method, the user can choose to send a link or code to their email/phone instead.</span></span></span></p></li></ol><h2 id="step-1-import-cotter" data-key="eb424b6510db4a76af5ed0efc31ab698"><p><span><span data-key="1544a0c867904c6d9d049a2230b2aabb"><span data-offset-key="1544a0c867904c6d9d049a2230b2aabb:0">Step 1: Import Cotter</span></span></span><a href="#step-1-import-cotter" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><h3 id="include-javascript-sdk" data-key="b8aad131a8744e91afc8fc39559494de"><p><span><span data-key="580564fef0c34e13a1fb0fd656eac2df"><span data-offset-key="580564fef0c34e13a1fb0fd656eac2df:0">Include Javascript SDK</span></span></span><a href="#include-javascript-sdk" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3><p data-key="a2aa6f86a1784f72b63672f6ee4934b0"><span><span data-key="229987941df840c6a85d13d944a5e8b0"><span data-offset-key="229987941df840c6a85d13d944a5e8b0:0">To use our Javascript SDK, include the script below in your HTML page or use the npm package.</span></span></span></p><div><div><div><div><div data-key="d6c0f793da074b81aa30613f608f6671"><div><pre data-key="aa0d5cd9ffb745f68bc92cbf5cc2a2bc" spellcheck="false"><p><span data-key="549559eb8cb8437ab445a7d4f8daf945"><span data-offset-key="549559eb8cb8437ab445a7d4f8daf945:0"><span>&lt;</span></span><span data-offset-key="549559eb8cb8437ab445a7d4f8daf945:1"><span>script</span></span></span></p><p><span data-key="4e53c9f385314ee49d4264a184da4a4a"><span data-offset-key="4e53c9f385314ee49d4264a184da4a4a:0"><span>    </span></span><span data-offset-key="4e53c9f385314ee49d4264a184da4a4a:1"><span>src</span></span><span data-offset-key="4e53c9f385314ee49d4264a184da4a4a:2"><span>="</span></span><span data-offset-key="4e53c9f385314ee49d4264a184da4a4a:3"><span>https://unpkg.com/cotter@0.3.17/dist/cotter.min.js</span></span><span data-offset-key="4e53c9f385314ee49d4264a184da4a4a:4"><span>"</span></span></span></p><p><span data-key="3a569ff45e004b5ca72fca679a647c47"><span data-offset-key="3a569ff45e004b5ca72fca679a647c47:0"><span>    </span></span><span data-offset-key="3a569ff45e004b5ca72fca679a647c47:1"><span>type</span></span><span data-offset-key="3a569ff45e004b5ca72fca679a647c47:2"><span>="</span></span><span data-offset-key="3a569ff45e004b5ca72fca679a647c47:3"><span>text/javascript</span></span><span data-offset-key="3a569ff45e004b5ca72fca679a647c47:4"><span>"</span></span></span></p><p><span data-key="30cfe8f8872f4c8a8b0cd795be7dc912"><span data-offset-key="30cfe8f8872f4c8a8b0cd795be7dc912:0"><span>&gt;</span></span><span data-offset-key="30cfe8f8872f4c8a8b0cd795be7dc912:1"><span>&lt;/</span></span><span data-offset-key="30cfe8f8872f4c8a8b0cd795be7dc912:2"><span>script</span></span><span data-offset-key="30cfe8f8872f4c8a8b0cd795be7dc912:3"><span>&gt;</span></span></span></p></pre></div><p data-key="44395c56a21948878e9138a95c123cfb"><span><span data-key="c53ee8f274034e4e8e3d1b4dbe6c3483"><span data-offset-key="c53ee8f274034e4e8e3d1b4dbe6c3483:0">Make sure you check for the latest version at </span></span><a href="https://www.npmjs.com/package/cotter" target="_blank" rel="noopener noreferrer" data-key="4d1bff7377354dab9d887bde14459f3e"><span data-key="e96faf3a68644ddca90fc6d7f290e97b"><span data-offset-key="e96faf3a68644ddca90fc6d7f290e97b:0">https://www.npmjs.com/package/cotter</span></span></a><span data-key="224e9fb9b4d544a78c062e8804ba0f4a"><span data-offset-key="224e9fb9b4d544a78c062e8804ba0f4a:0"><span data-slate-zero-width="z">​</span></span></span></span></p></div></div></div><div><div><div data-key="f4f8b569920f416f87135db64d4beaa2"><div><pre data-key="eec33684ca2442b8a5a17d1e15b1e342" spellcheck="false"><p><span data-key="bd017dfb81a7434eafda3f8e826637e0"><span data-offset-key="bd017dfb81a7434eafda3f8e826637e0:0">npm install cotter --save</span></span></p></pre></div></div></div></div></div></div><h2 id="step-2-set-up-a-div-element-to-contain-cotters-form" data-key="d597ae1a2982405fa6e561f52aa82508"><p><span><span data-key="322c632a140d43208c276641081346d9"><span data-offset-key="322c632a140d43208c276641081346d9:0">Step 2: Set up a </span><span data-offset-key="322c632a140d43208c276641081346d9:1"><code spellcheck="false" data-slate-leaf="true">div</code></span><span data-offset-key="322c632a140d43208c276641081346d9:2"> element to contain cotter's form</span></span></span><a href="#step-2-set-up-a-div-element-to-contain-cotters-form" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><div><pre data-key="8b7a9ff5114b489384173223f60a33c7" spellcheck="false"><p><span data-key="1970f79bbaa248cba64aef554f616581"><span data-offset-key="1970f79bbaa248cba64aef554f616581:0"><span>&lt;</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:1"><span>div</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:2"><span> </span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:3"><span>id</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:4"><span>="</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:5"><span>cotter-form-container</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:6"><span>"</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:7"><span> </span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:8"><span>style</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:9"><span>="</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:10"><span>width</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:11"><span>:</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:12"><span> 300px</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:13"><span>;</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:14"><span> </span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:15"><span>height</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:16"><span>:</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:17"><span> 300px</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:18"><span>;</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:19"><span>"</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:20"><span>&gt;</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:21"><span>&lt;/</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:22"><span>div</span></span><span data-offset-key="1970f79bbaa248cba64aef554f616581:23"><span>&gt;</span></span></span></p></pre></div><p data-key="8d2a167d0a32406b80794cc5bc3d4c18"><span><span data-key="4962b088fac143aa9ddca3a7e081124b"><span data-offset-key="4962b088fac143aa9ddca3a7e081124b:0">Please note that </span><span data-offset-key="4962b088fac143aa9ddca3a7e081124b:1"><strong data-slate-leaf="true">id</strong></span><span data-offset-key="4962b088fac143aa9ddca3a7e081124b:2"> has to be </span><span data-offset-key="4962b088fac143aa9ddca3a7e081124b:3"><code spellcheck="false" data-slate-leaf="true">cotter-form-container</code></span><span data-offset-key="4962b088fac143aa9ddca3a7e081124b:4"> for the form to show up.</span></span></span></p><h2 id="step-3-initialize-cotter-and-show-the-form" data-key="4a5dd75a52be40f18e105b873b45ffa2"><p><span><span data-key="3eb5a6a5f8654986be26f11e99ae7eac"><span data-offset-key="3eb5a6a5f8654986be26f11e99ae7eac:0">Step 3: Initialize Cotter and show the form</span></span></span><a href="#step-3-initialize-cotter-and-show-the-form" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="ad8c6a0f26fd455281f27c187a60a814"><span><span data-key="536b98c6160445c497d97566de18f1e8"><span data-offset-key="536b98c6160445c497d97566de18f1e8:0">Grab your </span><span data-offset-key="536b98c6160445c497d97566de18f1e8:1"><code spellcheck="false" data-slate-leaf="true">API_KEY_ID</code></span><span data-offset-key="536b98c6160445c497d97566de18f1e8:2"> from </span></span><a href="https://dev.cotter.app/" target="_blank" rel="noopener noreferrer" data-key="b9cba6471ad54468b67330fdbf40f5b9"><span data-key="0ddc903050ea4be69ed7c3b4f8497a4e"><span data-offset-key="0ddc903050ea4be69ed7c3b4f8497a4e:0">the dashboard</span></span></a><span data-key="b333cf1886074019895ea00f567ec70d"><span data-offset-key="b333cf1886074019895ea00f567ec70d:0">, then replace </span><span data-offset-key="b333cf1886074019895ea00f567ec70d:1"><code spellcheck="false" data-slate-leaf="true">&lt;YOUR_API_KEY_ID&gt;</code></span><span data-offset-key="b333cf1886074019895ea00f567ec70d:2"> with your </span><span data-offset-key="b333cf1886074019895ea00f567ec70d:3"><code spellcheck="false" data-slate-leaf="true">API_KEY_ID</code></span><span data-offset-key="b333cf1886074019895ea00f567ec70d:4">.</span></span></span></p><div><pre data-key="239e3c2a76ab4ac39983bbe3c83c4410" spellcheck="false"><p><span data-key="4bafed193fa74dbeaa55971e7cd49803"><span data-offset-key="4bafed193fa74dbeaa55971e7cd49803:0"><span>&lt;</span></span><span data-offset-key="4bafed193fa74dbeaa55971e7cd49803:1"><span>script</span></span><span data-offset-key="4bafed193fa74dbeaa55971e7cd49803:2"><span>&gt;</span></span></span></p><p><span data-key="ef756ddff61549a18bf481da8c198e90"><span data-offset-key="ef756ddff61549a18bf481da8c198e90:0"><span>  </span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:1"><span>var</span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:2"><span> cotter </span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:3"><span>=</span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:4"><span> </span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:5"><span>new</span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:6"><span> </span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:7"><span>Cotter</span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:8"><span>(</span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:9"><span>"&lt;YOUR_API_KEY_ID&gt;"</span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:10"><span>);</span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:11"><span> </span></span><span data-offset-key="ef756ddff61549a18bf481da8c198e90:12"></span></span></p><p><span data-key="b33026119ca640158756335dc498e944"><span data-offset-key="b33026119ca640158756335dc498e944:0"><span data-slate-zero-width="n">​</span></span></span></p><p><span data-key="a3fe471cd0774552a6e652d7478a721e"><span data-offset-key="a3fe471cd0774552a6e652d7478a721e:0"><span>  cotter</span></span></span></p><p><span data-key="350349af7798439391f17ed61d0b4ce1"><span data-offset-key="350349af7798439391f17ed61d0b4ce1:0"><span>    </span></span><span data-offset-key="350349af7798439391f17ed61d0b4ce1:1"><span>.</span></span><span data-offset-key="350349af7798439391f17ed61d0b4ce1:2"><span>signInWithWebAuthnOrLink</span></span><span data-offset-key="350349af7798439391f17ed61d0b4ce1:3"><span>()</span></span><span data-offset-key="350349af7798439391f17ed61d0b4ce1:4"><span> </span></span><span data-offset-key="350349af7798439391f17ed61d0b4ce1:5"></span></span></p><p><span data-key="70e315285268415a9bdee240a3f090d1"><span data-offset-key="70e315285268415a9bdee240a3f090d1:0"><span>    </span></span><span data-offset-key="70e315285268415a9bdee240a3f090d1:1"><span>.</span></span><span data-offset-key="70e315285268415a9bdee240a3f090d1:2"><span>showEmailForm</span></span><span data-offset-key="70e315285268415a9bdee240a3f090d1:3"><span>()</span></span><span data-offset-key="70e315285268415a9bdee240a3f090d1:4"><span>            </span></span><span data-offset-key="70e315285268415a9bdee240a3f090d1:5"></span></span></p><p><span data-key="3db1f3b0c22145d6a13333e6cc96bb3d"><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:0"><span>    </span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:1"><span>.</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:2"><span>then</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:3"><span>(</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:4"><span>payload </span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:5"><span>=&gt;</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:6"><span> console</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:7"><span>.</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:8"><span>log</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:9"><span>(</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:10"><span>payload</span></span><span data-offset-key="3db1f3b0c22145d6a13333e6cc96bb3d:11"><span>))</span></span></span></p><p><span data-key="6e42a8544ac246a3a17c573ac3a5094b"><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:0"><span>    </span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:1"><span>.</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:2"><span>catch</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:3"><span>(</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:4"><span>err </span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:5"><span>=&gt;</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:6"><span> console</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:7"><span>.</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:8"><span>log</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:9"><span>(</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:10"><span>err</span></span><span data-offset-key="6e42a8544ac246a3a17c573ac3a5094b:11"><span>));</span></span></span></p><p><span data-key="b3da3fbe76694014ace7173970e08f44"><span data-offset-key="b3da3fbe76694014ace7173970e08f44:0"><span>&lt;/</span></span><span data-offset-key="b3da3fbe76694014ace7173970e08f44:1"><span>script</span></span><span data-offset-key="b3da3fbe76694014ace7173970e08f44:2"><span>&gt;</span></span></span></p></pre></div><p data-key="f35e9b49c2c14c8eac5f9758d063f153"><span><span data-key="5e1f2bda52dd4351a7af2a386a58cf57"><span data-offset-key="5e1f2bda52dd4351a7af2a386a58cf57:0">There are several options for the fallback method:</span></span></span></p><ul data-key="388cc13c87a9420abd4cf27440120003"><li><div data-key="1f7340d94d904c46bd9f8f44e2459078"><p data-key="50f8150ae7344beaacd696fc22d53623"><span><span data-key="2110f6d7d375419685b90681b26a7e2c"><span data-offset-key="2110f6d7d375419685b90681b26a7e2c:0">Method: </span></span></span></p><ul data-key="8649a7f77dd64df79e55c8c7b685a23d"><li><p data-key="2ea9bd0281a940f2af5ce32fd1139e6c"><span><span data-key="645ca21f55cf458988f7d36357526938"><span data-offset-key="645ca21f55cf458988f7d36357526938:0">Magic Link: use </span><span data-offset-key="645ca21f55cf458988f7d36357526938:1"><code spellcheck="false" data-slate-leaf="true">signInWithWebAuthnOrLink()</code></span><span data-offset-key="645ca21f55cf458988f7d36357526938:2"> </span></span></span></p></li><li><p data-key="31679413ce6945fd8fefdc96b5a12b47"><span><span data-key="06e8c34b0926445ab1314e98436c4946"><span data-offset-key="06e8c34b0926445ab1314e98436c4946:0">OTP: use </span><span data-offset-key="06e8c34b0926445ab1314e98436c4946:1"><code spellcheck="false" data-slate-leaf="true">signInWithWebAuthnOrOTP()</code></span></span></span></p></li></ul></div></li><li><div data-key="0213dd7401804818a046e16d40254dbe"><p data-key="563afa43d175492fa4d47e87291ddb94"><span><span data-key="1eb4b93312f1467a9d737f179f312d0a"><span data-offset-key="1eb4b93312f1467a9d737f179f312d0a:0">Channel: </span></span></span></p><ul data-key="7a49e6ee2fde465aae493bbe1af29f07"><li><p data-key="12a4fb22cad94aa4956b1d272cfa2078"><span><span data-key="b159375e41534deeb8a2e3d12b974a20"><span data-offset-key="b159375e41534deeb8a2e3d12b974a20:0">Email: use </span><span data-offset-key="b159375e41534deeb8a2e3d12b974a20:1"><code spellcheck="false" data-slate-leaf="true">showEmailForm()</code></span><span data-offset-key="b159375e41534deeb8a2e3d12b974a20:2"> </span></span></span></p></li><li><p data-key="68f5241ca50e498f804652f83febff91"><span><span data-key="c4c6e35ed3a746a2954717c8c2df9928"><span data-offset-key="c4c6e35ed3a746a2954717c8c2df9928:0">Phone: use </span><span data-offset-key="c4c6e35ed3a746a2954717c8c2df9928:1"><code spellcheck="false" data-slate-leaf="true">showPhoneForm()</code></span><span data-offset-key="c4c6e35ed3a746a2954717c8c2df9928:2"> (you can send code/link via SMS or WhatsApp by setting it up in Dashboard &gt; Branding)</span></span></span></p></li></ul></div></li></ul><p data-key="82bd87414a114d58a5eabdd14c015f9a"><span><span data-key="8973402e501a425aa2d1cd2b841e9f79"><span data-offset-key="8973402e501a425aa2d1cd2b841e9f79:0"><span data-slate-zero-width="n">​</span></span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.cotter.app/sdk-reference/web/sign-in-with-webauthn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24702335</guid>
            <pubDate>Tue, 06 Oct 2020 21:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“A server hall draws as much electricity as half a nuclear power plant creates”]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24702206">thread link</a>) | @draugadrotten
<br/>
October 6, 2020 | https://tekdeeps.com/a-server-hall-draws-as-much-electricity-as-half-a-nuclear-power-plant-creates/ | <a href="https://web.archive.org/web/*/https://tekdeeps.com/a-server-hall-draws-as-much-electricity-as-half-a-nuclear-power-plant-creates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://tekdeeps.com/a-server-hall-draws-as-much-electricity-as-half-a-nuclear-power-plant-creates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24702206</guid>
            <pubDate>Tue, 06 Oct 2020 20:51:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hootsuite employee fired after speaking out about company's ICE deal]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24702114">thread link</a>) | @foofoo55
<br/>
October 6, 2020 | https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073 | <a href="https://web.archive.org/web/*/https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073</link>
            <guid isPermaLink="false">hacker-news-small-sites-24702114</guid>
            <pubDate>Tue, 06 Oct 2020 20:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clarifying exceptions and visualizing tensor operations in deep learning code]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24701739">thread link</a>) | @parrt
<br/>
October 6, 2020 | https://explained.ai/tensor-sensor/index.html | <a href="https://web.archive.org/web/*/https://explained.ai/tensor-sensor/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">






<p><a href="http://parrt.cs.usfca.edu/">Terence Parr</a></p>

<p>(Terence teaches in <a href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science">University of San Francisco's MS in Data Science program</a>. You might know Terence as the creator of the ANTLR parser generator.)</p>






<p>	Most people solve deep learning problems using high-level libraries such as <a href="https://keras.io/">Keras</a> or <a href="https://www.fast.ai/">fastai</a>,  which makes sense. These libraries hide a lot of implementation details that we either don't care about or can learn later.  To truly understand deep learning, however, I think it's important at some point to implement your own network layers and training loops. For example, see my recent article called <a href="https://explained.ai/rnn/index.html">Explaining RNNs without neural networks</a>. If you're comfortable building deep learning models while leaving some of the details a bit fuzzy, then this article is not for you.  In my quirky case, I care more about learning something deeply than actually applying it to something useful, so I go straight for the details. (I guess that's why I work at a university, not in industry ðŸ˜€.)  This article is in response to a pain point I experienced during an obsessive coding and learning burn through the fundamentals of deep learning in the isolation of Covid summer 2020.</p>

<center>
<a href="https://explained.ai/tensor-sensor/images/teaser.png">
<img src="https://explained.ai/tensor-sensor/images/teaser.png" width="40%" url="images/teaser.png">
</a>
</center>
One of the biggest challenges when writing code to implement deep learning networks, particularly for us newbies, is getting all of the tensor (matrix and vector) dimensions to line up properly. It's really easy to lose track of tensor dimensionality in complicated expressions involving multiple tensors and tensor operations.  Even when just feeding data into predefined <a href="https://www.tensorflow.org/">Tensorflow</a> network layers, we still need to get the dimensions right. When you ask for improper computations, you're going to run into some less than helpful exception messages.  To help myself and other programmers debug tensor code, I built a new library called <a href="https://github.com/parrt/tensor-sensor">TensorSensor</a> (<span>pip install tensor-sensor</span>).  TensorSensor clarifies exceptions by augmenting messages and visualizing Python code to indicate the shape of tensor variables (see figure to the right for a teaser). It works with <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="https://pytorch.org/">PyTorch</a>, and <a href="https://numpy.org/">Numpy</a>, as well as higher-level libraries like <a href="https://keras.io/">Keras</a> and <a href="https://www.fast.ai/">fastai</a>.

<p><i>TensorSensor is currently at 0.1b1 so I'm happy to receive issues created at the</i> <a href="https://github.com/parrt/tensor-sensor">repo</a> <i>or direct email</i>.</p>



<h2 id="sec:1.1">Isolating issues in tensor code is maddening!</h2>


<p>Even for experts, it can be hard to quickly identify the cause of an exception in a line of Python code performing tensor operations.  The debugging process usually involves adding a print statement in front of the offending line to emit the shape of each tensor operand.  That requires editing the code to create the debugging statement and rerunning the training process. Or, we can manually click or type commands to request all operand shapes using an interactive debugger. (This can be less practical in an IDE like PyCharm where executing code in debug mode seems to be much slower.)  The following subsections illustrate the anemic default exception messages and my proposed TensorSensor approach, rather than a debugger or print statements.</p>



<h3 id="sec:1.1.1">Debugging a simple linear layer</h3>


<p>Let's look at a simple tensor computation to illustrate the less-than-optimal information provided by the default exception message. Consider the following simple NumPy implementation for a hardcoded single (linear) network layer that contains a tensor dimension error.</p>


<p>import numpy as np

n = 200                          # number of instances
d = 764                          # number of instance features
n_neurons = 100                  # how many neurons in this layer?

W = np.random.rand(d,n_neurons)  # Ooops! Should be (n_neurons,d) &lt;=======
b = np.random.rand(n_neurons,1)
X = np.random.rand(n,d)          # fake input matrix with n rows of d-dimensions

Y = W @ X.T + b                  # pass all X instances through layer</p>


<p>Executing that code triggers an exception whose important elements are:</p>

<p>...
---&gt; 10 Y = W @ X.T + b
	
ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)-&gt;(n?,m?) (size 764 is different from 100)</p>


<p>The exception identifies the offending line and which operation (<span>matmul</span>: matrix multiply) but would be more useful if it gave the complete tensor dimensions. Also, the exception would be unable to distinguish between multiple matrix multiplications occurring in one line of Python.</p>

<p>Next, let's see how TensorSensor makes debugging that statement much easier. If we wrap the statement using a Python <span>with</span> statement and <span>tsensor</span>'s <span>clarify()</span>, we get a visualization and an augmented error message. </p>


<p>import tsensor
with tsensor.clarify():
    Y = W @ X.T + b</p>


<p>
<a href="https://explained.ai/tensor-sensor/images/numpy-mm-py.svg">
<img nocenter="true" src="https://explained.ai/tensor-sensor/images/numpy-mm-py.svg" url="images/numpy-mm-py.svg">
</a>
</p>

<p>...
ValueError: matmul: Input operand ...
Cause: @ on tensor operand W w/shape (764, 100) and operand X.T w/shape (764, 200)</p>


<p>It's clear from the visualization that <span>W</span>'s dimensions should be flipped to be <span>n_neurons x d</span>; the columns of <span>W</span> must match the rows of <span>X.T</span>. You can also checkout a <a href="https://explained.ai/tensor-sensor/images/numpy-mm.png">complete side-by-side image</a> with and without <span>clarify()</span> to see what it looks like in a notebook.</p>

<p>The <span>clarify()</span> functionality incurs no overhead on the executing program until an exception occurs. Upon exception, <span>clarify()</span>:</p>
<ol>
<li> Augments the exception object's message created by the underlying tensor library.</li>
<li> Gives a visual representation of the tensor sizes involved in the offending operation; only the operands and operator involved in the exception are highlighted, while the other Python elements are de-highlighted.</li>
</ol>
<p>TensorSensor also clarifies tensor-related exceptions raised by PyTorch and TensorFlow. Here are the equivalent code snippets and resulting augmented exception error messages (<span>Cause: @ on tensor ...</span>) and visualization from TensorSensor:</p>
<center>
<table>
<thead>
<tr>
<th>PyTorch</th><th>TensorFlow</th>
</tr>
</thead>
<tbody>
<tr>
<td>

<p>import torch
W = torch.rand(d,n_neurons)
b = torch.rand(n_neurons,1)
X = torch.rand(n,d)
with tsensor.clarify():
    Y = W @ X.T + b</p>

</td><td>

<p>import tensorflow as tf
W = tf.random.uniform((d,n_neurons))
b = tf.random.uniform((n_neurons,1))
X = tf.random.uniform((n,d))
with tsensor.clarify():
    Y = W @ tf.transpose(X) + b</p>

</td>
</tr>
<tr>
<td>

<a href="https://explained.ai/tensor-sensor/images/mm.svg">
<img nocenter="true" src="https://explained.ai/tensor-sensor/images/mm.svg" url="images/mm.svg">
</a>



<p>RuntimeError: size mismatch, m1: [764 x 100], m2: [764 x 200] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: @ on tensor operand W w/shape [764, 100] and operand X.T w/shape [764, 200]</p>

</td><td>
<img src="https://explained.ai/tensor-sensor/images/tf-mm.svg" nocenter="true">

<p>InvalidArgumentError: Matrix size-incompatible: In[0]: [764,100], In[1]: [764,200] [Op:MatMul]
Cause: @ on tensor operand W w/shape (764, 100) and operand tf.transpose(X) w/shape (764, 200)</p>
</td>
</tr>
</tbody>
</table>
</center>
<p>The PyTorch message does not identify which operation triggered the exception, but TensorFlow's message does indicate matrix multiplication. Both show the operand dimensions. These default exception messages are probably good enough for this simple tensor expression for a linear layer. Still, it's easier to see the problem with the TensorSensor visualization.</p>

<p>You might be wondering, though, why tensor libraries don't generate a more helpful exception message that identified the names of the Python variables involved in the offending subexpression.  It's not that the library authors couldn't be bothered. The fundamental issue is that Python tensor libraries are wrappers around extremely efficient cores written in C or C++. Python passes, say, the data for two tensors to a C++ function, but not the associated tensor variable names in Python space. An exception caught deep in C++ has no access to the local and global variable spaces in Python, so it just throws a generic exception back over the fence.  Because Python traps exceptions at the statement level, it also cannot isolate the subexpression within the statement.  (To learn how TensorSensor manages to generate such specific messages, check out <b>Section</b> <i>Key TensorSensor implementation Kung Fu</i> below.)</p>



<h3 id="sec:1.1.2">Debugging a complex tensor expression</h3>


<p>That lack of specificity in default messages makes it hard to identify bad subexpressions within more complicated statements that contain lots of operators. For example, here's a statement pulled from the guts of a Gated Recurrent Unit (GRU) implementation:</p>


<p>h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)</p>


<p>It doesn't matter what it's computing or what the variables represent, just that they are tensor variables. There are two matrix multiplications, two vector additions, and even a vector element-wise modification (<span>r*h</span>).  Without augmented error messages or visualizations we wouldn't know which operator and operands caused an exception. To demonstrate how TensorSensor clarifies exceptions in this case, we need to give some fake definitions for the variables used in the statement (the assignment to <span>h_</span>) to get executable code:</p>


<p>nhidden = 256
Whh_ = torch.eye(nhidden, nhidden)  # Identity matrix
Uxh_ = torch.randn(d, nhidden)
bh_  = torch.zeros(nhidden, 1)
h = torch.randn(nhidden, 1)         # fake previous hidden state h
r = torch.randn(nhidden, 1)         # fake this computation
X = torch.rand(n,d)                 # fake input

with tsensor.clarify():
    h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)</p>


<p>Again, you can ignore the actual computation performed by the code to focus on the shape of the tensor variables.  </p>

<p>For most of us, it's impossible to identify the problem just by looking at the tensor dimensions and the tensor code.  The default exception message is helpful of course, but most of us will still struggle to identify the problem.  Here are the key bits of the default exception message (note the less-than-helpful reference to the C++ code):</p>

<p>---&gt; 10     h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
RuntimeError: size mismatch, m1: [764 x 256], m2: [764 x 200] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
</p>


<p>What we need to know is which operator and operands failed, then we can look at the dimensions to identify the problem.  Here is TensorSensor's visualization and augmented exception message:</p>

<p>
<a href="https://explained.ai/tensor-sensor/images/torch-gru.svg">
<img nocenter="true" src="https://explained.ai/tensor-sensor/images/torch-gru.svg" url="images/torch-gru.svg">
</a>

</p><p>---&gt; 10 h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
RuntimeError: size mismatch, m1: [764 x 256], m2: [764 x 200] at …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://explained.ai/tensor-sensor/index.html">https://explained.ai/tensor-sensor/index.html</a></em></p>]]>
            </description>
            <link>https://explained.ai/tensor-sensor/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24701739</guid>
            <pubDate>Tue, 06 Oct 2020 20:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating Machines in Clojure]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24701737">thread link</a>) | @stopachka
<br/>
October 6, 2020 | https://stopa.io/post/255 | <a href="https://web.archive.org/web/*/https://stopa.io/post/255">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p><a href="https://twitter.com/stopachka/status/1295411936625074178" target="_blank">My cofounder Joe and I recently finished SICP.</a> It was a mind-bending experience: you start from just 3 concepts, and you recursively build up algebraic equation solvers, circuit simulators, 4 interpreters, and a compiler. </p><p>At some point you experience a visceral feeling: If you were dropped in a forest…you could create your own computer. The project that contributed most significantly to this feeling was creating a machine simulator.</p><p>We diverged from the book by writing the simulator in Clojure rather than Scheme. Immutable data structures and higher-level concepts available to us in Clojure compressed the solution, to the point where I think you can build your own in a few days worth of hacking.</p><p>This essay will guide you through doing just that: let’s build a machine simulator, over a good few days worth of hacking! I hope this inspires you to play with Clojure and to take a deeper look at SICP. </p><p>Before we simulate general machines, let’s think about a concrete machine. <strong>How could we create a machine that could figure out factorials?</strong> </p><p>If we were writing code, factorial could look something like this:</p><pre><code><span>(</span><span>defn</span><span> factorial [n]</span>
<span>  (</span><span>loop</span><span> [res </span><span>1</span>
<span>         counter </span><span>1</span><span>]</span>
<span>    (</span><span>if</span><span> (</span><span>&gt;</span><span> counter n)</span>
<span>      res</span>
<span>      (</span><span>recur</span>
<span>        (</span><span>*</span><span> counter res)</span>
<span>        (</span><span>inc</span><span> counter)))))</span></code></pre><p>Let’s see if we could build factorials using <em>physical</em> devices.</p><p>Well, we need a way to keep track of <code value="counter">counter</code>, <code value="res">res</code>, and <code value="n">n</code>. To do that, we’ll need a device that stores information. </p><h2>Bulbs</h2><p>Imagine a device that has some light bulbs inside of it. </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNDUyLTFlNzkzODgwLTA3ZTgtMTFlYi04MjI4LWQwYzE4ZTcwNTZhYS5wbmc" alt="image"></span></p><p>We can say that if a light bulb is <em>on,</em> that represents the number 1, and if a light bulb is <em>off</em> that represents the number 0. </p><p>If we had a bunch of light bulbs in the device, we could interpret the state of these bulbs as larger and larger binary numbers. The light bulbs in the device I just showed you for example, would represent “10101”, which is binary for “21”.</p><h2>Incoming Current</h2><p>Now, imagine that at all times there are a bunch of other wires connected to this device. These wires carry “new” charges for the light bulbs, but with a twist: the incoming charges <em>do not</em> affect the light bulbs inside just yet.</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjIxLTVhMTQwMjgwLTA3ZTgtMTFlYi05ZjM2LTU2MDFkZTIyOWUwOS5wbmc" alt="image"></span></p><p>Notice how the <em>incoming charge</em> for the “a” light bulb is “off”, but the bulb inside is still on. Conversely, the incoming charge "b" is "on", but the bulb is off. If our device can do this, it means that whatever the charges for the light bulbs are inside is a <em>stored value</em>. Very cool! </p><h2>Save</h2><p>Now, we need these incoming wires to do something at some point. What if this device had a “save” button. </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjQ1LTYzMDRkNDAwLTA3ZTgtMTFlYi04NjVjLWE3YTg3OTE5Njg3ZC5wbmc" alt="image"></span></p><p>Once we pressed “save”, the incoming current would transfer inside the box:  </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjU0LTY3Yzk4ODAwLTA3ZTgtMTFlYi04MjU1LTExNmEzMGUxNTcwMy5wbmc" alt="image"></span></p><p>Here, light bulb “a” changes from “on” to “off”, and the light bulb "b" changed from "on" to "off".</p><p>Great, now we have a way to “save” new numbers inside! </p><h2>Outgoing current</h2><p>We also need a way to share the state of what’s inside to other devices.  All we’d need to do to make that work, is to have a bunch of wires that leave our device, which carry the sames charges as the light bulbs: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxNzQ2LWY5ODVjNTAwLTA3ZTktMTFlYi05YzczLTY4ZWYwNzc3OGJlMi5wbmc" alt="image"></span></p><p>Now, if we hooked those outgoing charges to some other device, that device would receive the “number” that was stored in this one. </p><h2>Registers</h2><p>What we just described is analogous to a computer’s <em>register</em> (1). Registers let us store and share information. </p><p>Now, we could use three of registers to store the value of <code value="res">res</code> <code value="counter">counter</code> and <code value="n">n</code>.</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODUxLWIxYjI2ZTAwLTA3ZTgtMTFlYi04NzRjLTQxODgyODAxNTQ2OC5wbmc" alt="image"></span></p><p>Next up, we’ll need a device that that can “add” two registers. Imagine a device that had two register’s worth of incoming wires, and one register’s worth of outgoing wires: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODY5LWI4ZDk3YzAwLTA3ZTgtMTFlYi05ZDM0LTQwMDE0YmQ5NDAyOC5wbmc" alt="image"></span></p><h2>Adder</h2><p>If the device could connect those incoming wires in such a way, that the outgoing wires represented the “addition” of those registers, we’d have an “adder” device! </p><p>In the example above, the left register represents “10101” (21), and the right represents “00001” (1). The output wires are charged as “10110”…which represent 22!</p><p>Similarly, we could have a device that has two register’s worth input wires, and one register’s worth of output wires: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODkyLWMxMzFiNzAwLTA3ZTgtMTFlYi05OTQ1LTI4ZDljNmU4N2IzNy5wbmc" alt="image"></span></p><h2>Multiplier</h2><p>If we could connect the incoming wires in such a way, that the outgoing wires represent the result of a multiplication, boom we would have a multiplying device! </p><p>The left register above represents “00101” (5), the right register represents “00010” (2), and the charge of the outgoing wire is “01010” (10). Nice! That gives us a multiplier machine. </p><h2>Comparator</h2><p>We need one more device. Imagine a device that takes two register’s worth of input wires, and only has <em>one</em> output wire: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwOTE1LWNhMjI4ODgwLTA3ZTgtMTFlYi05Y2RiLWM2ZDEwZTYxNzc1Yi5wbmc" alt="image"></span></p><p>If we could combine the input wires in such a way, that the output wire was “on” when the left register was bigger, and off otherwise, we could use this as a comparator machine! </p><p>If we had all these machines, we can wire them in such a way, that lets us compute factorials: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwOTg1LWRlZmYxYzAwLTA3ZTgtMTFlYi05MDRjLTE2NmUzNTIyMjJkOS5wbmc" alt="image"></span></p><p>Here, we wired the output wires of <code value="res">res</code> and <code value="counter">counter</code> to the <code value="*">*</code> machine. We wired the output wires of the <code value="*">*</code> machine, to <em>be</em> the input wires of <code value="res">res</code>. </p><p>This way, if we press “A”, we would “store” the result of multiplying <code value="counter">counter</code> with <code value="res">res</code>! </p><p>Similarly, we wired up the output wires of <code value="counter">counter</code> and a register that keeps the value <code value="1">1</code>, to the <code value="+">+</code> machine. We wired the output wires of the <code value="+">+</code> machine, to <em>be</em> the input wires of <code value="counter">counter</code>. </p><p>Now, If we pressed “B”, <code value="counter">counter</code> would be stored with the result of adding <code value="1">1</code>! </p><p>Next up, we also wired up <code value="counter">counter</code> and <code value="n">n</code> with the <code value=">">&gt;</code> machine. If we hooked up a light bulb to the output wire of the <code value=">">&gt;</code> machine for example, then whenever it was on, we would know that <code value="counter">counter</code> was larger than <code value="n">n</code>. </p><p>We’ve just drawn out the “data path” of our machine. </p><h2>Manual Recipe</h2><p>Let’s remember our code for factorial: </p><pre><code><span>  (</span><span>loop</span><span> [res </span><span>1</span>
<span>         counter </span><span>1</span><span>]</span>
<span>    (</span><span>if</span><span> (</span><span>&gt;</span><span> counter n)</span>
<span>      res</span>
<span>      (</span><span>recur</span>
<span>        (</span><span>*</span><span> counter res)</span>
<span>        (</span><span>inc</span><span> counter))))</span></code></pre><p>imagine if we had our “data path” machine. What would happen if we followed the following recipe:</p><ol><li>Take a look at the output of the <code value=">">&gt;</code> machine. </li><li>If the light bulb connected to the <code value=">">&gt;</code>  machine is on, <strong>stop</strong></li></ol><p><em>Otherwise…</em></p><ol><li>"Press A". This will update <code value="res">res</code>  with the result of the <code value="*">*</code>  machine on <code value="res">res</code> and <code value="counter">counter</code> </li><li>“Press B“. This will update <code value="counter">counter</code> with the result of the <code value="+">+</code>  machine on <code value="1">1</code> and <code value="counter">counter</code></li><li>Go back up to the start of the recipe</li></ol><p><strong>If we did this over and over again, once the light bulb connected to the output of the</strong>  <strong><code value=">">&gt;</code></strong> <strong>machine turns on,</strong> <strong><code value="res">res</code></strong> <strong>would contain the result of factorial!</strong> </p><h2>Automation</h2><p>Pretty cool, but this kind of manual work would be annoying. If you look at these instructions though, there’s a pretty significant insight: <em>all of those instructions are simple: "look at charge of light bulb", "press button..."</em></p><p>In fact, they’re so simple that we could wire up a machine that goes through that recipe! Imagine if we created a machine that could “press” buttons for us, depending on whether the output wire of the <code value=">">&gt;</code> machine is on:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMDIwLWU5MjExYTgwLTA3ZTgtMTFlYi04MDJlLTI4YzIyNjZiNzQwOC5wbmc" alt="image"></span></p><p>We would be able to automate computing factorials 🙂</p><h2>Balls and Hills</h2><p>Now, at this stage, you may be wondering: exactly <em>how</em> would <code value="*">*</code> produce output wires that represent the multiplication? How would <code value="+">+</code> work, and how would the <code value="controller">controller</code> move along? </p><p>If you think about it, these can all be reduced to very simple machines. They don’t even necessarily have to be electronic: </p><p>Imagine you had a ball rolling down some hill. You could construct something like the <code value=">">&gt;</code> machine, by putting <code value="res">res</code> and <code value="counter">counter</code> on a scale: based on what’s bigger, the ball would take a different path</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMDQ4LWY4MDdjZDAwLTA3ZTgtMTFlYi04NTg3LWRiYjE2ZDU3NGZkMy5wbmc" alt="image"></span></p><p>With sufficient energy, space, time, and ingenuity you really could build all of this with a ball on a hill. Now, you wouldn’t necessarily do that (2), but you can imagine how the electronic parts that make up our machines are similarly simple, logical machines: <em>turn on if off, turn off if on, etc</em>. These logical machines are called “logic gates”. You can look them up, but hopefully I’ll have an essay for you about these machines soon 🙂. </p><p>Now, we drew out our machine and saw how we could build them with simple devices. How could we simulate these machines? </p><p>To simulate these machines, we need to transform our <em>picture descriptions</em> into something that computers can manipulate. Computers can manipulate text much better: let’s create a <em>language</em> for describing these machines. </p><p>If we remember the pictures again:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMTg3LTJmNzY3OTgwLTA3ZTktMTFlYi05ZTNlLTg3Zjg0NDkxZjQxYS5wbmc" alt="image"></span></p><p>we could transform them into a language that looks like this:</p><pre><code><span>(</span><span>def</span><span> factorial-instructions</span>
<span>  '(</span>
<span>     start</span>
<!-- -->
<span>     (</span><span>test</span><span> (</span><span>op</span><span> &gt;) (</span><span>reg</span><span> counter) (</span><span>reg</span><span> n))</span>
<span>     (</span><span>branch</span><span> (</span><span>label</span><span> done))</span>
<!-- -->
<span>     (</span><span>assign</span><span> res (</span><span>op</span><span> *) (</span><span>reg</span><span> counter) (</span><span>reg</span><span> res))</span>
<span>     (</span><span>assign</span><span> counter (</span><span>op</span><span> +) (</span><span>reg</span><span> counter) (</span><span>const</span><span> </span><span>1</span><span>))</span>
<span>     (</span><span>goto</span><span> (</span><span>label</span><span> start))</span>
<!-- -->
<span>     done))</span></code></pre><p>When the <code value="test">test</code> instruction runs, we run the <code value=">">&gt;</code> machine with <code value="counter">counter</code> and <code value="n">n</code>.</p><p>Our <code value="branch">branch</code> instruction checks if the <code value="test">test</code> instruction said <code value="yes">yes</code>. If it did, it moves to <code value="done">done</code>. Otherwise it no-ops and the machine moves forward by one.</p><p>After that, our <code value="(assign res">(assign res</code> expression is analogous to “press A”. <code value="(assign counter">(assign counter</code> is analogous to “press B”, and <code value="(goto (label start)">(goto (label start)</code> is analogous to the arrow bringing us back to the start.</p><p>With this textual representation, we can build an interpreter and simulate our machine. Let’s do this! </p><p>What does the state of our machine look like in Clojure? Well, how do we represent most things in Clojure? With maps!  Let’s represent the state of our machine as a map:</p><pre><code><span>(</span><span>def</span><span> ex-machine-state-v0</span>
<span>  {</span><span>:registry-map</span><span> {'n </span><span>10</span><span> 'res </span><span>1</span><span> 'counter </span><span>1</span><span>}</span>
<span>   </span><span>:label-&gt;idx</span><span> {'start </span><span>0</span><span> 'done </span><span>5</span><span>}})</span></code></pre><p><code value="registry-map">registry-map</code> could keep a mapping of registers to values. 
<code value="label→idx">label→idx</code> could keep a mapping of labels to their <code value="idx">idx</code> in the instruction list</p><p>With this, we can get the most foundational part of our language to work: We use <code value="(const…">(const…</code>  <code value="(reg...">(reg...</code> and <code value="(label…">(label…</code> all over the place.</p><ol><li>If our machine sees <code value="(const 1)">(const 1)</code>, it should return the actual value <code value="1">1</code></li><li>If our machine sees <code value="(reg foo)">(reg foo)</code>, it should look up whatever is in the <code value="foo">foo</code> register, and return that </li><li>If our machine sees <code value="(label foo)">(label foo)</code>, it should return the correct index in our instruction list.</li></ol><p>Let’s write this out in Clojure:</p><pre><code><span>(</span><span>def</span><span> tag first) </span><span>; (tag '(const 1)) =&gt; const</span>
<span>(</span><span>defn</span><span> tag-of? [sym s] (</span><span>=</span><span> sym (</span><span>tag</span><span> s))) </span><span>; (tag-of? 'const '(const 1)) =&gt; true</span>
<!-- -->
<span>(</span><span>defn</span><span> parse-primitive [{</span><span>:keys</span><span> [registry-map label-&gt;idx] </span><span>:as</span><span> machine-state}</span>
<span>                       prim-exp]</span>
<span>  (</span><span>condp</span><span> tag-of? prim-exp</span>
<span>    'const</span>
<span>    (</span><span>second</span><span> prim-exp)</span>
<span>    'reg</span>
<span>    (</span><span>g…</span></code></pre></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/255">https://stopa.io/post/255</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/255</link>
            <guid isPermaLink="false">hacker-news-small-sites-24701737</guid>
            <pubDate>Tue, 06 Oct 2020 20:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Celebrities Explain DevOps]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24700712">thread link</a>) | @jacksonpollock
<br/>
October 6, 2020 | https://cto.ai/blog/celebrities-explain-devops/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/celebrities-explain-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<h3 id="david-hasselhoff-flavor-flav-and-carole-baskin-help-simplify-aws-kubernetes-and-docker"><em>David Hasselhoff, Flavor Flav, and Carole Baskin help simplify AWS, Kubernetes, and Docker</em></h3><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>👋 &nbsp;Hey all you cool cats and kittens! 😺 </p><p>You probably thought this day would never come.</p><p>You might be thinking, have DevOps tools reached this level of adoption? That even the some of the biggest personalities on TV are excited by them.</p><p>Well, the day has come. It's today. And the proof is in the pudding (and the videos below).</p><p>In an effort to bring some lighthearted fun to the complex and serious nature of DevOps, we asked three of our favorite celebrities to explain some of the most popular technologies used in DevOps.</p><p>The Guinness World Record holder as The Most Watched Man on TV, <strong>David 'The Hoff' Hasselhoff</strong>,<strong> </strong>shares with us what Docker means to him.</p><p><strong>Flavor Flav</strong> (yeahhh boy!) of Public Enemy and Flavor of Love teaches us a thing or two about Kubernetes.</p><p>And<strong> Carole Baskin</strong> of Big Cat Rescue and Tiger King shares her excitement of AWS.</p><p>All are in support of our mission to simplify the snowballing complexity of the DevOps universe.</p><p>Please enjoy thoroughly:</p><!--kg-card-begin: embed--><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/QxvmO-QlxJQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-end: embed--><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p><em>Love this video? Love DevOps? Come join <a href="https://w.cto.ai/community">The Ops Community on Slack</a> and trade tips and tricks on workflow automation with us!</em></p>
			</div></div>]]>
            </description>
            <link>https://cto.ai/blog/celebrities-explain-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700712</guid>
            <pubDate>Tue, 06 Oct 2020 18:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I remember what I learn]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 107 (<a href="https://news.ycombinator.com/item?id=24700647">thread link</a>) | @flreln
<br/>
October 6, 2020 | https://vasilishynkarenka.com/learning/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/09/IMG_1517.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_1517.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_1517.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg" alt="How to remember what you learn">
            </figure>

            <section>
                <div>
                    <p><em>“I don’t remember a damn thing.”</em></p><p>The book I held my hands was full of highlights. It seemed like I’ve got all colors of the rainbow on a page. Apparently, this didn’t help. When I tried recalling ideas from the book, I didn’t hear a thing. Just. Silence.</p><p>Terrified, I started questioning how much I <em>really</em> know. If I forget everything I read, I can’t apply my knowledge to the problem at hand. I can’t transfer it. And without transfer, knowledge is very much like music for deaf ears.</p><p>I quickly did the math. I was planning to invest in learning a few hours a day for the next ~75 years of my life. Staring at the number of potentially wasted hours, I knew exactly what I had to do.</p><hr><p>In the past six months, I’ve devoured dozens of books, research papers, and studies on how people learn. As a result, I’ve designed a learning process that works for me. It’s not perfect, but an order of magnitude better than what I had before. </p><p>In this work, I outline my workflow so that you can try it out. It applies to any subject or discipline, from programming to economics. If you stumble upon something where it doesn’t work, let me know.</p><blockquote><em>Make it time-based, take regular breaks, and learn what you’re curious about.</em></blockquote><p>The most important thing is that my learning is time-based, not goal-based. Setting learning goals such as “read X pages today” is a way to fail because you set up the wrong incentives. When you plan to read X pages by lunch, you can’t help but begin optimizing for the goal, which leads to focusing on speed instead of understanding. And when you don’t have those “aha” moments, it is hard to remember what you learn.</p><p>It’s also important to not overload yourself and take breaks. I do 3h learning sessions every day split into 30 min intervals with 5 min breaks. Breaks help to fall back into the diffuse mode of thinking and get access to a broader set of neural networks in my head. They also warm up my body, and I feel better after moving around for a few minutes.</p><p>As for material, I learn what I’m interested in. First, because life is <a href="http://www.paulgraham.com/vb.html">too short</a> to do things that you don’t love. Second, I’ve found that studying stuff I genuinely like awakens my curiosity. And curiosity is essential to develop mastery because mastery is about depth and breadth of knowledge. </p><p>For example, if you’re learning JavaScript and you’re curious about it, you’ll go and figure out how JS runtime environment works in Chrome even though the tutorial doesn’t cover it. Just because you’re interested. But if you’re not curious, then you’ll just memorize the tutorial, and your knowledge will be shallow.</p><h2 id="how-my-learning-session-works">How my learning session works</h2><blockquote>Clean up working memory, apply metacognition, and "siege" the thing with questions to improve understanding.</blockquote><p>When I learn, I always have two devices on my desk. I have my laptop with the study material (ie, a book, a video, an article) on the right, and I have my iPad with a text editor open on the left.</p><p>This is how my current setup looks like:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_2658.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_2658.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_2658.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_2658.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_2658.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Morning learning session.</figcaption></figure><p>When I begin learning, I set a timer for 30 minutes and create three files in Drafts:</p><ol><li>A file with a timestamp where my random thoughts go.</li><li>A file with a timestamp where I think about the subject.</li><li>A file with questions.</li></ol><p><strong>The first file is a mind dump.</strong> When I start learning, I immediately begin thinking about things. It’s almost as if my brain wakes up and starts throwing ideas, tasks, and memories at me. I suspect this comes from the associative memory because I present myself with many triggers when I’m learning; words and sentences that bear special meaning to me and invoke these ideas.</p><p>But here’s the problem. If I don’t write thoughts down, I can’t focus. My working memory is overloaded with todos, ideas, and emotions. You’ve probably experienced this for yourself – your mind is running too fast, and you can’t really concentrate on what you’re learning. Having this “dump” file is immensely useful to a) free up my working memory to focus on my learning instead of thinking about these things, and b) store these thoughts somewhere safe to go back to them later and take action.</p><p><strong>The second file is where I write about what I’m learning.</strong> Folks in the kitchen call it metacognition, which means thinking about thinking. Metacognition is the single best trick I’ve found to improve understanding, and I will write more about it in the future. Whenever I don’t understand something or see that my understanding is shallow, I begin writing in the first person. It looks like this: “So Peter explains that there are four characteristics of a monopoly, but I don’t really understand why branding is one of them; why so?”</p><p>It’s also important to note that I don’t write in a usual sentence-paragraph manner. Instead, I write every thought on a new line. I don’t even put dots at the end of the sentences. This helps me to focus on understanding instead of nitty-gritty styling and typos. The “enter” key on a keyboard serves as the “end of thought” symbol and helps formulate ideas more clearly.</p><p>Another important idea is that my editor is plain text. I’ve found it incredibly liberating to operate in a plain text environment where you don’t have incentives to color, underline, bold, italicize, or do some other weird things with the text you’re writing. Instead of choosing the right font for my heading, I can focus on meaning instead. Also, my plain text app is way faster than all feature-rich text editors, and I’ve found it essential for a thought input environment to be fast. Otherwise, I can't think.</p><p>Here’s a fragment from my learning of React yesterday:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_D7F6BD12F133-1.jpeg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_D7F6BD12F133-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_D7F6BD12F133-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_D7F6BD12F133-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_D7F6BD12F133-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Metacognition notes from studying React.js.</figcaption></figure><p>You’re probably thinking that it’s quite a bit of writing. It is. For an hour-long learning session, I usually do about 500-1000 words in this file. But it’s worth every character, and here’s why:</p><ul><li>When I apply metacognition, I understand things <em>way</em> better than when I don’t. I’ve tested many different learning modes and found metacognition to perform at least 2x better based on my later ability to recall and transfer knowledge. Also, there’s <a href="https://academicpublishingplatforms.com/downloads/pdfs/ati/volume18/201607070302_09_ATI_Vol11_Issue2_2015_Todorova_and_Karamanska_Study_motivation_satisfaction_students_e-learning_pp.82-89.pdf">some</a> <a href="http://www.csun.edu/science/ref/reasoning/how-students-learn/1.html">research</a> on metacognition as well.</li><li>Having a file with my thinking about the subject keeps my working memory clean. I don’t feel overloaded as I usually feel after reading many articles at one go. You’ve probably experienced this yourself; your brain is almost melting after an hour of scrolling through the web. That’s because you present yourself with too much information without really making sense of it. After a few months of applying metacognitive practices, I realized that I can’t go back. It just feels so strange to experience that cognitive load again.</li><li>Metacognition improves remembering through elaboration and interleaving. When I’m writing my thoughts in the file, I can’t help but begin connecting them with other ideas on that topic because of associative memory. And interleaving leads to mastery.</li><li>(Speculation) Training metacognition improves my ability to transform vague notions and thoughts that I have during the day into specific words that I can write down for later analysis. This one is particularly interesting to me, but there’s no evidence besides my own experiments. And I might be biased because I’ve come up with this method.</li></ul><p>Moreover, I type 2-3x faster than most people because I use <a href="https://barehands.substack.com/p/how-to-type-3x-faster">shortcuts</a>. So it’s not that bad.</p><p><strong>The third file is questions. </strong>Whenever I stumble upon something that I don’t understand, I try to break it down into a set of simple questions. Each question in the group takes on a small part of the problem. If the concept is particularly challenging, I try to “siege” it with questions from many many different angles and break it down even further.</p><p>When I’m beginning a new session, I always start from the previous one’s questions file. I only look at questions and answer them before I’m beginning new learning. This doesn’t sound like very much fun, but it’s actually pretty interesting to explain stuff to yourself if you do it out loud. Answering questions improves my understanding and helps to connect ideas together. And yes, answering questions counts as learning – probably the most efficient learning you could be doing.</p><p><em>I'm not going into much detail on questions because Michael Nielsen has done a phenomenal job describing it <a href="http://augmentingcognition.com/ltm.html">here</a>.</em></p><h2 id="what-happens-after-the-session">What happens after the session</h2><blockquote>Write a dense summary, provoke elaboration, interleaving, and transfer, and choose what to never forget.</blockquote><p>After the session is done, and my three files are full of information, I begin the recap process.</p><p><strong>First, I write a three to five sentence-long summary of what I’ve just studied.</strong> Here I try to distill the material’s core idea and compress the whole thing into a maximally dense chunk. When I’m summarizing, my laptop is closed. Not looking at the text helps to “compress” the idea to its core and make a small “hook” to my memory to later see what the whole book was about.</p><p>Here’s how my summary note looks like: </p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_9771D059CFD1-1.jpeg" alt="Recap of studying React.js." srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_9771D059CFD1-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_9771D059CFD1-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_9771D059CFD1-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_9771D059CFD1-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Recap of studying React.js.</figcaption></figure><p>Very often, what I’m writing in the summary section is not what the text was about, but what it means to me. In other words, if both of us read this text and wrote a summary of it, mine would be very different than yours.</p><p>After I’m done with the summary, I write down the answers to three questions:</p><ol><li>What are the key ideas? </li><li>How can I apply this knowledge that I learned? </li><li>How do these ideas relate to what I already know?</li></ol><p><strong>The first question speaks for itself.</strong> I try to remember what I just read and write down as many ideas as I can bring back. When I began applying the metacognition trick that I mentioned earlier, I noticed a 3x increase in the number of concepts I could recall. And as I speculate that long-term memory recall is influenced by initial interleaving and recall, this might actually help to improve your long-term memory.</p><p><strong>The second question is about transfer.</strong> The sole purpose of learning is to apply the knowledge that we learn. Without application, …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/learning/">https://vasilishynkarenka.com/learning/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700647</guid>
            <pubDate>Tue, 06 Oct 2020 18:06:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best of Both Worlds: A New Take on Metal–Plastic Hybrid 3D Printing]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24700553">thread link</a>) | @rustoo
<br/>
October 6, 2020 | https://www.waseda.jp/top/en/news/73810 | <a href="https://web.archive.org/web/*/https://www.waseda.jp/top/en/news/73810">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-type="narrow">
              <div>
                
<h5>Scientists develop a novel and surprisingly simple method to print 3D structures made of metal and plastic, paving the way for 3D electronics</h5>
<p><strong>Current 3D printers employ either plastic or metal only, and the conventional method to coat 3D plastic structures with metal is not environment-friendly and yields poor results. Now, scientists from Waseda University, Japan, have developed a metal–plastic hybrid 3D printing technique that produces plastic structures with a highly adhesive metal coating on desired areas. This approach extends the use of 3D printers to 3D electronics for future robotics and Internet-of-Things applications.</strong></p>
<p><a href="https://www.waseda.jp/top/en/assets/uploads/2020/10/Infographic_Oct_01_2020.jpg"><img src="https://www.waseda.jp/top/en/assets/uploads/2020/10/Infographic_Oct_01_2020-2000x1125.jpg" alt="" width="2000" height="1125" srcset="https://www.waseda.jp/top/en/assets/uploads/2020/10/Infographic_Oct_01_2020-2000x1125.jpg 2000w, https://www.waseda.jp/top/en/assets/uploads/2020/10/Infographic_Oct_01_2020-610x343.jpg 610w, https://www.waseda.jp/top/en/assets/uploads/2020/10/Infographic_Oct_01_2020-768x432.jpg 768w" sizes="(max-width: 2000px) 100vw, 2000px"></a></p>
<p>Three-dimensional (3D) printing technology has evolved tremendously over the last decade to the point where it is now viable for mass production in industrial settings. Also known as “additive manufacturing,” 3D printing allows one to create arbitrarily complex 3D objects directly from their raw materials. In fused filament fabrication, the most popular 3D printing process, a plastic or metal is melted and extruded through a small nozzle by a printer head and then immediately solidifies and fuses with the rest of the piece. However, because the melting points of plastics and metals are very different, this technology has been limited to creating objects of either metal or plastic only—until now.</p>
<p>In a recent study published in <a href="https://www.sciencedirect.com/science/article/pii/S2214860420309283?via%3Dihub">Additive Manufacturing</a>, scientists from Waseda University, Japan, developed a new hybrid technique that can produce 3D objects made of both metal and plastic. <a href="http://www.umeshin.mmech.waseda.ac.jp/en/">Professor Shinjiro Umezu</a>, who led the study, explains their motivation: “Even though 3D printers let us create 3D structures from metal and plastic, most of the objects we see around us are a combination of both, including electronic devices. Thus, we thought we’d be able to expand the applications of conventional 3D printers if we managed to use them to create 3D objects made of both metal and plastic.”</p>
<p>Their method is actually a major improvement over the conventional metallization process used to coat 3D plastic structures with metal. In the conventional approach, the plastic object is 3D-printed and then submerged in a solution containing palladium (Pd), which adheres to the object’s surface. Afterwards, the piece is submerged in an electroless plating bath that, using the deposited Pd as a catalyst, causes dissolved metal ions to stick to the object. While technically sound, the conventional approach produces a metallic coating that is non-uniform and adheres poorly to the plastic structure.</p>
<p>In contrast, in the new hybrid method, a printer with a dual nozzle is used; one nozzle extrudes standard melted plastic (acrylonitrile butadiene styrene, or ABS) whereas the other extrudes ABS loaded with PdCl2. By selectively printing layers using one nozzle or the other, specific areas of the 3D object are loaded with Pd. Then, through electroless plating, one finally obtains a plastic structure with a metallic coating over selected areas only.</p>
<p>The scientists found the adhesion of the metal coating to be much higher when using their approach. What’s more, because Pd is loaded in the raw material, their technique does not require any type of roughening or etching of the ABS structure to promote the deposition of the catalyst, unlike the conventional method. This is especially important when considering that these extra steps cause damage not only to the 3D object itself, but to the environment as well, owing to the use of toxic chemicals like chromic acid. Lastly, their approach is entirely compatible with existing fused filament fabrication 3D printers.</p>
<p>Umezu believes that metal–plastic hybrid 3D printing could become very relevant in the near future considering its potential use in 3D electronics, which is the focus of upcoming Internet-of-Things and artificial intelligence applications. In this regard, he adds: “Our hybrid 3D printing method has opened up the possibility of fabricating 3D electronics so that devices and robots used in healthcare and nursing care could become significantly better than what we have today.”</p>
<p>This study hopefully paves the way for hybrid 3D printing technology that will enable us to get the best of both worlds—metal and plastic combined.</p>
<h3>Reference</h3>
<h4>Authors</h4>
<p>Jing Zhan<sup>(a)</sup>, Takayuki Tamura<sup>(b)</sup>, Gyotong Ri<sup>(b)</sup>, Zhenghao Ma<sup>(b)</sup>, Michinari Sone<sup>(c)</sup>, Masahiro Yoshino<sup>(c)</sup>, Shinjiro Umezu<sup>(b)</sup>, and Hirotaka Sato<sup>(a)</sup></p>
<h4>Title of original paper</h4>
<p>Metal-Plastic Hybrid 3D Printing Using Catalyst-Loaded Filament and Electroless Plating</p>
<h4>Journal</h4>
<p>Additive Manufacturing</p>
<h4>DOI</h4>
<p>10.1016/j.addma.2020.101556</p>
<h4>Affiliations</h4>
<ul>
<li>a: School of Mechanical and Aerospace Engineering, Nanyang Technological University</li>
<li>b: Department of Modern Mechanical Engineering, Waseda University</li>
<li>c: Research and Development div., Yoshino Denka Kogyo, Inc.</li>
</ul>
<p><img src="https://www.waseda.jp/top/en/assets/uploads/2020/10/umezu.jpg" alt="" width="1144" height="817" srcset="https://www.waseda.jp/top/en/assets/uploads/2020/10/umezu.jpg 1144w, https://www.waseda.jp/top/en/assets/uploads/2020/10/umezu-610x436.jpg 610w, https://www.waseda.jp/top/en/assets/uploads/2020/10/umezu-768x548.jpg 768w" sizes="(max-width: 1144px) 100vw, 1144px"></p>
              </div>
                          </div></div>]]>
            </description>
            <link>https://www.waseda.jp/top/en/news/73810</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700553</guid>
            <pubDate>Tue, 06 Oct 2020 17:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q3 Linux touchpad update: Multitouch gesture test packages now ready]]>
            </title>
            <description>
<![CDATA[
Score 379 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24700537">thread link</a>) | @wbharding
<br/>
October 6, 2020 | https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/ | <a href="https://web.archive.org/web/*/https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="comments">

		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://bill.harding.blog/wp-comments-post.php" method="post" id="commentform" novalidate=""><p><span id="email-notes">Your email address will not be published.</span> Required fields are marked <span>*</span></p><p><label for="comment">Comment</label> </p><p><label for="author">Name <span>*</span></label> </p>
<p><label for="email">Email <span>*</span></label> </p>
<p><label for="url">Website</label> </p>
<p> <label for="wp-comment-cookies-consent">Save my name, email, and website in this browser for the next time I comment.</label></p>
<!-- Anti-spam plugin wordpress.org/plugins/anti-spam/ --><div><p><label>Current ye@r <span>*</span></label>
					
					
				  </p>

</div><!--\End Anti-spam plugin --></form>	</div><!-- #respond -->
	
</div></div>]]>
            </description>
            <link>https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700537</guid>
            <pubDate>Tue, 06 Oct 2020 17:54:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A quick introduction to data parallelism in Julia]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24700436">thread link</a>) | @amkkma
<br/>
October 6, 2020 | https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/ | <a href="https://web.archive.org/web/*/https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>If you have a large collection of data and have to do similar computations on each element, <a href="https://en.wikipedia.org/wiki/Data_parallelism">data parallelism</a> is an easy way to speedup computation using multiple CPUs and machines as well as GPU(s). While this is not the only kind of parallelism, it covers a vast class of compute-intensive programs. A major hurdle for using data parallelism is that you need to unlearn some habits useful in sequential computation (i.e., patterns result in mutations of data structure). In particular, it is important to use libraries that help you describe <em>what</em> to compute rather than <em>how</em> to compute. Practically, it means to use generalized form of map and reduce operations and learn how to express your computation in terms of them. Luckily, if you already know how to write <a href="https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions">iterator comprehensions</a>, there is not much more to learn for accessing a large class of data parallel computations.</p>  <p>This introduction primary focuses on the Julia packages that I (Takafumi Arakaki <strong><code>@tkf</code></strong>) have developed. As a result, it currently focuses on thread-based parallelism. There is simple distributed computing support. GPU support is a frequently requested feature but <a href="https://github.com/JuliaFolds/Transducers.jl/issues/236">it hasn't been implemented yet</a>. See also <a href="https://juliafolds.github.io/data-parallelism/explanation/libraries/">other parallel-computation libraries in Julia</a>.</p> <p>Also note that this introduction does not discuss how to use threading primitives such as <a href="https://docs.julialang.org/en/v1/base/multi-threading/"><code>Threads.@spawn</code></a> since it is too low-level and error-prone. For data parallelism, a higher-level description is much more appropriate. It also helps you write more reusable code; e.g., using the same code for single-threaded, multi-threaded, and distributed computing.</p>   <h2 id="getting_julia_and_libraries"><a href="#getting_julia_and_libraries">Getting <code>julia</code> and libraries</a></h2> <p>Most of the examples here may work in all Julia 1.x releases. However, for the best result, it is highly recommended to get the latest released version (1.5.2 as of writing). You can download it at <a href="https://julialang.org/">https://julialang.org/</a>.</p> <p>Once you get <code>julia</code>, you can get the dependencies required for this tutorial by running <code>using Pkg; Pkg.add(["Transducers", "ThreadsX", "OnlineStats", "FLoops", "MicroCollections", "BangBang", "Plots", "BenchmarkTools"])</code> in Julia REPL.</p> <p>If you prefer using exactly the same environment used for testing this tutorial, run the following commands</p> <pre><code>git <span>clone</span> https://github.com/JuliaFolds/data-parallelism
<span>cd</span> data-parallelism
julia --project</code></pre> <p>and then in the Julia REPL:</p> <pre><code><span>julia&gt;</span><span> <span>using</span> Pkg
</span>
<span>julia&gt;</span><span> Pkg.instantiate()</span></code></pre> <h2 id="starting_julia"><a href="#starting_julia">Starting <code>julia</code></a></h2> <p>To use multi-threading in Julia, you need to start it with multiple execution threads. If you have Julia 1.5 or higher, you can start it with the <code>-t auto</code> (or, equivalently, <code>--threads auto</code>) option:</p> <pre><code>$ julia -t auto
               _
   _       _ _(_)_     |  Documentation: https://docs.julialang.org
  (_)     | (_) (_)    |
   _ _   _| |_  __ _   |  Type "?" for help, "]?" for Pkg help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 1.5.2 (2020-09-23)
 _/ |\__'_|_|_|\__'_|  |  Official https://julialang.org/ release
|__/                   |

julia&gt; Threads.nthreads()  # number of core you have
8</code></pre> <p>The command line option <code>-t</code>/<code>--threads</code> can also take the number of threads to be used. In older Julia releases, use the <code>JULIA_NUM_THREADS</code> environment variable. For example, on Linux and macOS, <code>JULIA_NUM_THREADS=4 julia</code> starts <code>juila</code> with 4 execution threads.</p> <p>For more information, see <a href="https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads">Starting Julia with multiple threads</a> in the Julia manual.</p> <h3 id="starting_julia_with_multiple_worker_processes"><a href="#starting_julia_with_multiple_worker_processes">Starting <code>julia</code> with multiple worker processes</a></h3> <p>A few examples below mention <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/">Distributed.jl</a>-based parallelism. Like how multi-threading is setup, you need to setup multiple worker processes to get speedup. You can start <code>julia</code> with <code>-p auto</code> (or, equivalently, <code>--procs auto</code>). Distributed.jl also lets you add worker processes after starting Julia with <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.addprocs"><code>addprocs</code></a>:</p> <pre><code><span>using</span> Distributed
addprocs(<span>8</span>)</code></pre> <p>For more information, see <a href="https://docs.julialang.org/en/v1/manual/distributed-computing/#Starting-and-managing-worker-processes">Starting and managing worker processes</a> section in the Julia manual.</p> <h2 id="mapping"><a href="#mapping">Mapping</a></h2> <p>Mapping is probably the most frequently used function in data parallelism. Recall how Julia's sequential <code>map</code> works:</p> <pre><code>a1 = map(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)</code></pre>
<pre><code>9-element Array{String,1}:
 "1a"
 "2b"
 "3c"
 "4d"
 "5e"
 "6f"
 "7g"
 "8h"
 "9i"</code></pre>
<p>We can simply replace it with <a href="https://github.com/tkf/ThreadsX.jl"><code>ThreadsX.map</code></a> for thread-based parallelism (see also <a href="https://juliafolds.github.io/data-parallelism/explanation/libraries/">other libraries</a>):</p>
<pre><code><span>using</span> ThreadsX
a2 = ThreadsX.map(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)
<span>@assert</span> a1 == a2</code></pre>

<p>Julia's standard library Distributed.jl contains <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.pmap"><code>pmap</code></a> as a distributed version of <code>map</code>:</p>
<pre><code><span>using</span> Distributed
a3 = pmap(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)
<span>@assert</span> a1 == a3</code></pre>

<div><div><p>🔬 Test Code</p>
<pre><code><span>using</span> Test
    <span>@testset</span> <span>begin</span>
        <span>@test</span> a1 == a2
        <span>@test</span> a1 == a3
    <span>end</span></code></pre></div> <div><p>☑ Pass</p>
<pre><code>Test Summary: | Pass  Total
test set      |    2      2
</code></pre></div></div>
<h3 id="practical_example_stopping_time_of_collatz_function"><a href="#practical_example_stopping_time_of_collatz_function">Practical example: Stopping time of Collatz function</a></h3>
<p>As a slightly more "practical" example, let's play with the <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz conjecture</a> which states that recursive application the <em>Collatz function</em> defined as</p>
<pre><code>collatz(x) =
    <span>if</span> iseven(x)
        x ÷ <span>2</span>
    <span>else</span>
        <span>3</span>x + <span>1</span>
    <span>end</span></code></pre>

<p>reaches the number 1 for all positive integers.</p>
<p>I'll skip the mathematical background of it (as I don't know much about it) but let me mention that there are plenty of fun-to-watch explanations in YouTube :)</p>
<p>If the conjecture is correct, the number of iteration required for the initial value is finite.  In Julia, we can calculate it with</p>
<pre><code><span>function</span> collatz_stopping_time(x)
    n = <span>0</span>
    <span>while</span> <span>true</span>
        x == <span>1</span> &amp;&amp; <span>return</span> n
        n += <span>1</span>
        x = collatz(x)
    <span>end</span>
<span>end</span></code></pre>

<p>Just for fun, let's plot the stopping time of the initial values from 1 to 10,000:</p>
<pre><code><span>using</span> Plots
plt = scatter(
    map(collatz_stopping_time, <span>1</span>:<span>10_000</span>),
    xlabel = <span>"Initial value"</span>,
    ylabel = <span>"Stopping time"</span>,
    label = <span>""</span>,
    markercolor = <span>1</span>,
    markerstrokecolor = <span>1</span>,
    markersize = <span>3</span>,
    size = (<span>450</span>, <span>300</span>),
)</code></pre>
<p><img src="https://juliafolds.github.io/data-parallelism/assets/tutorials/quick-introduction/code/output/collatz_stopping_time_scatter.png" alt=""></p><p>We can easily parallelize <code>map(collatz_stopping_time, 1:10_000)</code> and get a good speedup:</p>
<pre><code><span>julia&gt;</span><span> Threads.nthreads()  
</span>4

<span>julia&gt;</span><span> <span>using</span> BenchmarkTools
</span>
<span>julia&gt;</span><span> <span>@btime</span> map(collatz_stopping_time, <span>1</span>:<span>100_000</span>);
</span>  18.116 ms (2 allocations: 781.33 KiB)

<span>julia&gt;</span><span> <span>@btime</span> ThreadsX.map(collatz_stopping_time, <span>1</span>:<span>100_000</span>);
</span>  5.391 ms (1665 allocations: 7.09 MiB)</code></pre>
<h2 id="iterator_comprehensions"><a href="#iterator_comprehensions">Iterator comprehensions</a></h2>
<p>Julia's <a href="https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions">iterator comprehension syntax</a> is a powerful tool for composing mapping, filtering, and flattening. Recall that mapping can be written as an array or iterator comprehension:</p>
<pre><code>b1 = map(x -&gt; x + <span>1</span>, <span>1</span>:<span>3</span>)
b2 = [x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>]         
b3 = collect(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)  
<span>@assert</span> b1 == b2 == b3
b1</code></pre>
<pre><code>3-element Array{Int64,1}:
 2
 3
 4</code></pre>
<p>The iterator comprehension can be executed with threads by using <a href="https://github.com/tkf/ThreadsX.jl"><code>ThreadsX.collect</code></a>:</p>
<pre><code>b4 = ThreadsX.collect(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)
<span>@assert</span> b1 == b4</code></pre>

<div><div><p>🔬 Test Code</p>
<pre><code><span>using</span> Test
    <span>@testset</span> <span>begin</span>
        <span>@test</span> b1 == b2 == b3
    <span>end</span></code></pre></div> <div><p>☑ Pass</p>
<pre><code>Test Summary: | Pass  Total
test set      |    1      1
</code></pre></div></div>
<p>Note that more complex composition of mapping, filtering, and flattening can also be executed in parallel:</p>
<pre><code>c1 = ThreadsX.collect(y <span>for</span> x <span>in</span> <span>1</span>:<span>3</span> <span>if</span> isodd(x) <span>for</span> y <span>in</span> <span>1</span>:x)</code></pre>
<pre><code>4-element Array{Int64,1}:
 1
 1
 2
 3</code></pre>
<p><a href="https://juliafolds.github.io/Transducers.jl/dev/reference/manual/#Transducers.dcollect"><code>Transducers.dcollect</code></a> is for using iterator comprehensions with a distributed backend:</p>
<pre><code><span>using</span> Transducers
c2 = dcollect(y <span>for</span> x <span>in</span> <span>1</span>:<span>3</span> <span>if</span> isodd(x) <span>for</span> y <span>in</span> <span>1</span>:x)
<span>@assert</span> c1 == c2</code></pre>

<div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> c1 == c2 == [<span>1</span>, <span>1</span>, <span>2</span>, <span>3</span>]</code></pre></div> </div>
<h2 id="pre-defined_reductions"><a href="#pre-defined_reductions">Pre-defined reductions</a></h2>
<p>Functions such as <code>sum</code>, <code>prod</code>, <code>maximum</code>, and <code>all</code> are the examples of <em>reduction</em> (aka <a href="https://en.wikipedia.org/wiki/Fold_(higher-order_function)"><em>fold</em></a>) that can be parallelized.  They are very powerful tools when combined with iterator comprehensions.  Using ThreadsX.jl, a sum of an iterator created by the comprehension syntax</p>
<pre><code>d1 = sum(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)</code></pre>
<pre><code>9</code></pre>
<p>can easily be parallelized by</p>
<pre><code>d2 = ThreadsX.sum(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)</code></pre>
<pre><code>9</code></pre>
<div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> d1 == d2</code></pre></div> </div>
<p>For the full list of pre-defined reductions and other parallelized functions, type <code>ThreadsX.</code> and press <kbd>TAB</kbd> in the REPL.</p>
<h3 id="practical_example_maximum_stopping_time_of_collatz_function"><a href="#practical_example_maximum_stopping_time_of_collatz_function">Practical example: Maximum stopping time of Collatz function</a></h3>
<p>We can use <code>maximum</code> to compute the maximum stopping time of Collatz function on a given the range of initial values</p>
<pre><code>max_time = ThreadsX.maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)</code></pre>
<pre><code>350</code></pre>
<div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> max_time == <span>350</span></code></pre></div> </div>
<p>We get a speedup similar to the <code>map</code> example above:</p>
<pre><code><span>julia&gt;</span><span> <span>@btime</span> maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)
</span>  17.625 ms (0 allocations: 0 bytes)
350

<span>julia&gt;</span><span> <span>@btime</span> ThreadsX.maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)
</span>  5.024 ms (1214 allocations: 69.17 KiB)
350</code></pre>
<h3 id="onlinestatsjl"><a href="#onlinestatsjl">OnlineStats.jl</a></h3>
<p><a href="https://github.com/joshday/OnlineStats.jl">OnlineStats.jl</a> provides a <a href="https://joshday.github.io/OnlineStats.jl/latest/stats_and_models/">very rich</a> and <a href="https://joshday.github.io/OnlineStats.jl/latest/collections/">composable</a> set of reductions.  You can pass it as the first argument to <a href="https://github.com/tkf/ThreadsX.jl#onlinestatsjl"><code>ThreadsX.reduce</code></a>:</p>
<pre><code><span>using</span> OnlineStats: Mean
e1 = ThreadsX.reduce(Mean(), <span>1</span>:<span>10</span>)</code></pre>
<pre><code>Mean: n=10 | value=5.5</code></pre>
<div><div><p>🔬 Test Code</p>
<pre><code><span>using</span> OnlineStats; <span>@test</span> e1 == fit!(Mean(), <span>1</span>:<span>10</span>)</code></pre></div> </div>
<div><p>💡 Note</p>
<p>While OnlineStats.jl often does not provide the fastest way to compute the given statistics when all the intermediate data can fit in memory, in many cases you don't really need the absolute best performance. However, it may be worth considering other ways to compute statistics if ThreadsX.jl + OnlineStats.jl becomes the bottleneck.</p></div>
<h2 id="manual_reductions"><a href="#manual_reductions">Manual reductions</a></h2>
<p>For non-trivial parallel computations, you need to write a custom reduction.  <a href="https://github.com/JuliaFolds/FLoops.jl">FLoops.jl</a> provides a concise set of syntax for writing custom reductions.  For example, this is how to compute sums of two quantities in one sweep:</p>
<pre><code><span>using</span> FLoops

<span>@floop</span> <span>for</span> (x, y) <span>in</span> zip(<span>1</span>:<span>3</span>, <span>1</span>:<span>2</span>:<span>6</span>)
    a = x + y
    b = x - y
    <span>@reduce</span>(s += a, t += b)
<span>end</span>
(s, t)</code></pre>
<pre><code>(15, -3)</code></pre> <div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> (s, t) == (<span>15</span>, -<span>3</span>)</code></pre></div> </div>
<p>In this example, we do not initialize <code>s</code> and <code>t</code>; but it is not a typo.  In parallel sum, the only reasonable value of the initial state of the accumulators like <code>s</code> and <code>t</code> is zero.  So, <code>@reduce(s += a, t
+= b)</code> works as if <code>s</code> and <code>t</code> are initialized to appropriate type of zero.  However, since there are many zeros in Julia (<code>0::Int</code>, <code>0.0::Float64</code>, <code>(0x00 + 0x00im)::Complex{UInt8}</code>, ...), <code>s</code> and <code>t</code> are undefined if the input collection (i.e., the value of <code>xs</code> in <code>for
x in xs</code>) is empty.</p>
<p>To control the type of the accumulators and also to avoid <code>UndefVarError</code> in the empty case, you can set the initial value with <code>accumulator = initial_value op input</code> syntax</p>
<pre><code><span>@floop</span> <span>for</span> (x, y) <span>in</span> zip(<span>1</span>:<span>3</span>, <span>1</span>:<span>2</span>:<span>6</span>)
    a = x + y
    b = x - y
    <span>@reduce</span>(s2 = <span>0.0</span> + a, t2 = <span>0</span><span>im</span> + b)
<span>end</span>
(s2, t2)</code></pre>
<pre><code>(15.0, -3 + 0im)</code></pre> <div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> (s2, t2) === (<span>15.0</span>, -<span>3</span> + <span>0</span><span>im</span>)</code></pre></div> </div>
<p>To understand the computation of <code>@floop</code>…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/">https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/</a></em></p>]]>
            </description>
            <link>https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700436</guid>
            <pubDate>Tue, 06 Oct 2020 17:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gradient Boosted Decision Trees]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24700250">thread link</a>) | @simonwardjones
<br/>
October 6, 2020 | https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/ | <a href="https://web.archive.org/web/*/https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
  <div>
    <div>
      
      
      
      <p>What is a <code>gradient boosted decision tree</code>? 🤷‍♂️</p>
<p>This article is the fifth in a series covering fundamental machine learning algorithms. Each post will be split into two parts</p>
<ol>
<li><a href="#the-idea-and-key-concepts"><strong>The idea and key concepts</strong></a>
- Most people should be able to follow this section and learn how the algorithm works</li>
<li><a href="#the-maths"><strong>The maths</strong></a>
- This is for the interested reader and will include detailed mathematical derivations followed by an implementation in Python</li>
</ol>
<p>Click</p>
<ul>
<li><a href="https://www.simonwardjones.co.uk/posts/linear_regression/">here</a> if you missed <code>From zero to Linear Regression</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/logistic_regression/">here</a> if you missed <code>From zero to Logistic Regression</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/decision_trees/">here</a> if you missed <code>From zero to Decision Tree</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/random_forests/">here</a> if you missed <code>From zero to Random Forest</code></li>
</ul>
<p>Great if you have already read these!</p>
<hr>
<h2 id="the-idea-and-key-concepts">The idea and key concepts</h2>
<p>In the last post we talked about <code>underfitting</code>, <code>overfitting</code>, <code>bias</code> and <code>variance</code>. We explained how a <code>random forest</code> uses the average output of multiple trees to reduce the chance of overfitting without introducing bias by oversimplifying (such as using only one tree but restricting the depth).</p>
<p><code>Gradient boosting</code> is a machine learning technique for regression and classification where multiple models are trained <code>sequentially</code> with each model trying to learn the mistakes from the previous models. The individual models are known as <code>weak learners</code> and in the case of <code>gradient boosted decision trees</code> the individual models are decision trees.</p>
<p>In order to give intuition it is easiest to consider first the case of regression. Imagine we are again trying to predict house prices in a desirable area of north London. With training data that looks like the following</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>House size 🏠</th>
<th>Garden size 🌳</th>
<th>Garage? 🚙</th>
<th>True House Price 💰</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>1000</td>
<td>700</td>
<td>Garage</td>
<td>£1m</td>
</tr>
<tr>
<td>2</td>
<td>770</td>
<td>580</td>
<td>No Garage</td>
<td>£0.75m</td>
</tr>
<tr>
<td>3</td>
<td>660</td>
<td>200</td>
<td>Garage</td>
<td>£0.72m</td>
</tr>
</tbody>
</table>

<p><strong>Initial prediction $f_0$</strong></p>
<p>We can make an initial prediction for each of the house prices based on an initial model, let’s call this initial model $f_0$. Often this model is very simple - just using the mean of the target variable in the training data. The following table shows the initial predictions as well as the <code>errors</code> $e_1$ (also known as the <code>residuals</code>) defined for each sample as $e_1 = y - f_0$ where $y$ is the true value and $f_0$ is our initial prediction</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price 💰</th>
<th>Initial Prediction $f_0$</th>
<th>Error $e_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>£1m</td>
<td>£0.82m</td>
<td>£(1m - 0.82) = £0.18m</td>
</tr>
<tr>
<td>2</td>
<td>£0.75m</td>
<td>£0.82m</td>
<td>£(0.75m - 0.82m) = -£0.07m</td>
</tr>
<tr>
<td>3</td>
<td>£0.72m</td>
<td>£0.82m</td>
<td>£(0.72m - 0.82m) = -£0.1m</td>
</tr>
</tbody>
</table>

<p><strong>Predicting the error</strong></p>
<p>Our initial prediction isn’t very accurate as it is just the mean house price of the training data! In order to improve this we introduce another model $f_1$ trying to predict the error $e_1$ from the sample feature values. In gradient boosted decision trees this model is itself a decision tree. So now we can predict what the error $e_1$ will be for each sample using $f_1$</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price 💰</th>
<th>Initial Prediction $f_0$</th>
<th>Error $e_1$</th>
<th>Predicted Error $f_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>£1m</td>
<td>£0.82m</td>
<td>£(1m - 0.82) = £0.18m</td>
<td>£0.17m</td>
</tr>
<tr>
<td>2</td>
<td>£0.75m</td>
<td>£0.82m</td>
<td>£(0.75m - 0.82m) = -£0.07m</td>
<td>£-0.09m</td>
</tr>
<tr>
<td>3</td>
<td>£0.72m</td>
<td>£0.82m</td>
<td>£(0.72m - 0.82m) = -£0.1m</td>
<td>£-0.1m</td>
</tr>
</tbody>
</table>

<p><strong>Updating our prediction using the error prediction</strong></p>
<p>For the first house our initial prediction $f_0$ was £0.82m (using the mean) and as we actually know the true value we can see this gave an error $e_1$ of 0.18m. We then trained $f_1$ - a decision tree - to predict the error $e_1$ for each sample. In practise this is only a prediction of the error so it wont be exactly equal, in this toy example our $f_1$ model predicted an error of £0.17m. We could now combine the two models into a new second prediction called $F_1$ by adding the predicted error $f_1$ to the initial prediction $f_0$ as in the table below</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price 💰</th>
<th>Initial Prediction $f_0$</th>
<th>Predicted Error $f_1$</th>
<th>Prediction $F_1 =f_0 + f_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>£1m</td>
<td>£0.82m</td>
<td>£0.17m</td>
<td>£0.99m</td>
</tr>
<tr>
<td>2</td>
<td>£0.75m</td>
<td>£0.82m</td>
<td>-£0.09m</td>
<td>£0.73m</td>
</tr>
<tr>
<td>3</td>
<td>£0.72m</td>
<td>£0.82m</td>
<td>-£0.1m</td>
<td>£0.71m</td>
</tr>
</tbody>
</table>

<p><strong>Additive model</strong></p>
<p>Now we have a second prediction $F_1$ we can continue in a sequential manner, again calculating the error of our second prediction $e_2$ and training a tree $f_2$ to predict this second error. Then once again we add this second predicted error to the second prediction to get a third prediction $F_2 = F_1 + f_2$ and so on. As the models are summed together this approach is known as an <code>aditive model</code>. In general we have
$$F_m =  F_{m-1} + f_m$$
Where the next prediction $F_m$ is made up of the current prediction $F_{m-1}$ and the prediction of the error $f_m \sim e_m =y - F_{m-1}$ at this stage. In general the number of <code>weak learners</code> is a <code>hyper parameter</code> you have to choose.</p>
<p><strong>learning rate</strong></p>
<p>We can think of each individual <code>weak learner</code> $f_m$ as stepping our predictions closer to the true target values $y$. To reduce the variance and overfitting rather than stepping the whole predicted error we can instead add only a fraction of the step controlled by the learning rate. So rather than
$$F_m =  F_{m-1} + f_m$$
In gradient boosting we use
$$F_m =  F_{m-1} + (\text{learning rate}*f_m)$$
This process requires more steps but reduces the variance and overfitting overall.</p>
<p><strong>Summary of the algorithm</strong></p>
<ol>
<li>Make initial model $f_0$ (often the mean of y)</li>
<li>Train decision tree model $f_1$ on the error $e_1 = y - f_0$ where y is the true value</li>
<li>Calculate new prediction $F_1 = f_0 + \eta * f_1$ where $\eta$ is the learning rate</li>
<li>Repeat 2, 3 as many times as chosen where in general
<ol>
<li>Train model $f_m$ on the error $e_m = y - F_{m-1}$</li>
<li>Calculate new prediction as $F_{m-1} + \eta * f_m$</li>
</ol>
</li>
</ol>
<p>In short gradient boosting uses an initial prediction and then sequentially updates this prediction by fitting a model to the error at that stage.</p>
<p>In the following section we explore the mathematical details and extend the algorithm to the classification setting. We also cover the intuition behind gradient boosting as gradient descent.</p>
<hr>
<h2 id="the-maths">The maths</h2>
<p><strong>Why is it called gradient boosting?</strong></p>
<p>In general in <code>supervised learning</code> we aim to find a model $F$ to fit the data such that the predicted value $\hat{y}_i$ for the $j$th training example $\mathbf{x}_i$ is approximately equal to the $j$th target value $y_i$ or equivalently</p>
<p>
    $$
\hat{y}_i=F(\mathbf{x}_i)\sim y_i \quad\forall j \in {1,\dots,n} 
$$
</p><p>
Where n is the number of training samples.</p>
<p>Equivalently we aim to minimise a loss function $\mathcal{L(y, \hat{y})}$ which tells us how badly the model $\hat{y}$ currently fits the data $y$.</p>
<p>In a <code>parametric</code> setting (e.g. logistic regression) the model can be written as

</p><p>
    $$
\hat{y}_i=F_{\mathbf{\theta}}(\mathbf{x}_i)
$$
</p>
<p>Where the subscript $\mathbf{\theta}$ indicates the models dependence on the parameters. We can also write the loss in terms of $\mathbf{\theta}$ as $\mathcal{L(y, \hat{y}(\mathbf{\theta})})$. In this setting we update the model parameters using gradient descent. That is we iteratively update the model parameters by stepping the parameters in the direction of the negative gradient of the loss function with respect to the parameters (where $\eta$ is the learning rate).</p>

<p>
    $$
\mathbf{\theta}^{m+1} = \mathbf{\theta}^{m} - \eta* \frac{\partial\mathcal{L}}{\partial{\mathbf{\theta}^m}}
$$
</p>
<p>Instead of differentiating the loss with respect to $\mathbf{\theta}$ we can differentiate with respect to the prediction $\hat{y}$ directly. If we think about gradient descent ideally we would update $\hat{y}$ as follows to reduce the cost function</p>

<p>
    $$
\hat{y}_i \to \hat{y}_i - \eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}
$$
</p>
<p>Equivalently we update $F_{m-1}$ by adding another “delta model” $f_{m+1}$</p>

<p>
    $$
\hat{y}_i = F_m(\mathbf{x}_i) + f_{m+1}(\mathbf{x}_i) \quad\forall j \in {1,\dots,n} 
$$
</p>
<p>Where $\eta$ is the learning rate and

</p><p>
    $$
f_{m+1}(\mathbf{x}_i)= -\eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}
$$
</p>
<p>In practise we cannot set this delta model exactly so we train a model on the data to fit

</p><p>
    $$
 - \eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}$$
</p><p>
In general this gradient can be fitted with any model but gradient boosted decision trees use a decision tree - hence the name! Note each tree will have it’s own Loss $\mathcal{L}^{f_{m+1}}$ separate to the global loss $\mathcal{L}$.</p>
<p><strong>Key Point</strong></p>
<p>The gradient boosted decision tree is not trained on the residuals at each step. Rather it is trained on the negative gradient of the loss function evaluated using the prediction of the current step - which happens to be the residual for some common cost functions.</p>
<h3 id="regression">Regression</h3>
<p>In the case of regression we define the loss function as the mean square error</p>
<p>$$
\mathcal{L}(\hat{y}) = \frac{1}{2n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2
$$
hence
$$
-\eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}} = \frac{\eta}{n}(y_i-\hat{y}_i)
$$</p>
<p>How the process looks:</p>
<p>We fit $f_0(x)\sim y$ then $F_0(x) = f_0(x)$<br>
We fit $f_1(x)\sim (y-F_0(x))$ then $F_1(x) = F_0(x) + \eta f_1(x)$<br>
We fit $f_2(x)\sim (y-F_1(x))$ then $F_2(x) = F_1(x) + \eta f_2(x)$<br>
We fit $f_3(x)\sim (y-F_2(x))$ then $F_3(x) = F_2(x) + \eta f_3(x)$<br>
…<br>
We fit $f_m(x)\sim (y-F_{m-1}(x))$ then $F_m(x) = F_{m-1}(x) + \eta f_m(x)$</p>
<p>Then predictions $\hat{y} = F_m(x)$</p>
<h4 id="binomial-classification">Binomial Classification</h4>
<p>Suppose our iterative model was $\hat{y}_i = F_m(x_i)$ where the $\hat{y}_i$ directly represented the probability $x_i$ is in class 1. i.e. $P(x_i \in C_1)$ where $C_1$ represents class 1.</p>
<p>In this case the delta model doesn’t make sense as we would be directly adding to a probability value. As in logistic regression it is often the case to fit the model to a transformation of probability.</p>
<p>We define a model
$$
\hat{y}\sim F(x)
$$
where
$$
\hat{p} = \frac{1}{1+e^{-\hat{y}}}
$$
so
$$
\hat{y} = \log\left(\frac{\hat{p}}{1-\hat{p}}\right)
$$</p>
<p>where $\hat{p}$ represents the probability of being in class 1, $\hat{y}$ is sometimes known as the logit.</p>
<p>Note $\hat{p}\in[0,1],\quad \hat{y}\in(-\infty,\infty),\quad y\in{0,1}$</p>
<p>Hence in the classification setting the gradient boosted decision tree predicts $\hat{y}$ as a sum of multiple delta models. The probability values are then calculated by transforming $\hat{y}$ using the sigmoid function (a.k.a the expit function).</p>
<p>We will use the following fact later on</p>

<p>
    $$
\begin{align}
\hat{p} &amp;= \frac{1}{1+e^{-\hat{y}}} \quad so \\
\hat{p} &amp;= …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/">https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/</a></em></p>]]>
            </description>
            <link>https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700250</guid>
            <pubDate>Tue, 06 Oct 2020 17:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streamlit vs. Dash vs. Shiny vs. Voila vs. Flask vs. Jupyter]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24699616">thread link</a>) | @FHMS
<br/>
October 6, 2020 | https://datarevenue.com/en-blog/data-dashboarding-streamlit-vs-dash-vs-shiny-vs-voila | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/data-dashboarding-streamlit-vs-dash-vs-shiny-vs-voila">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><figure id="w-node-a0ab8e637641-8e0c2194"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5f7726566ebd2b725703e262__2Hb12PVQAZ3AfwKMEbi4iq0Kpkt7HE4TGIm6s61ZrVY2h0dz6on8qxKVpZjM18k21yWF0ZkhQ8QYYNPUa4ZHaJPJS0v-2sOmkIEzYVu9OH0js2UB7zAs6T65uwu2lijmEGFEs9O.png" alt="A graph showing the GitHub star history of Viola, Dash, Shiny, Streamlit, and Jupyter."></p><figcaption>Over the last three years, Dash and Streamlit have surged in popularity as all-in-one dashboarding solutions</figcaption></figure><h2><strong>Data dashboards – Tooling and libraries</strong></h2><p>Nearly every company is sitting on valuable data that internal teams need to access and analyze. Non-technical teams often request tooling to make this easier. Instead of having to poke a data scientist for every request, these teams want dynamic dashboards where they can easily run queries and see custom, interactive visualizations.</p><figure id="w-node-70788e25b038-8e0c2194"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5f77265696bfa94c739ba0c2_TLv7TGplTgg3oqi47Oc042fEPb-c-maCuH8Y2IiXI4P8Yv8pPTlkeM7IT6zhwp0OmTk_gWn0B9c_0wmDgcsKh3b4koNqH-WA32VqaZJzyTW-aUhf9Kz8a_PcP-e0VlepkzfS3qbo.png" alt="A representation of an unhappy person looking at code and a happy person looking at a neat dashboard."></p><figcaption>Data dashboards can make data more accessible to your non-technical teams</figcaption></figure><p>A data dashboard consists of many different components. It needs to:</p><ul role="list"><li><strong>Analyze: </strong>Manipulate and summarize data using a backend library such as Pandas.</li><li><strong>Visualize: </strong>Create plots and graphs of the data using a graphing library such as Bokeh.</li><li><strong>Interact: </strong>Accept user input using a frontend library such as React.</li><li><strong>Serve: </strong>Listen for user requests and return webpages using a web server such as Flask.</li></ul><p>In the past, you’d have had to waste a significant amount of time writing all the “glue” code to join these components together. But with newer libraries like Streamlit and Dash, these components come in a single package.</p><p>Still, figuring out which library to use can be challenging. Here’s how they compare as well as some guidance on how to choose which one is best for your project.</p><p>[Do you want more detailed tooling comparisons that cut through the marketing-speak? <a href="https://datarevenue.com/signup">Sign up to our weekly newsletter</a>.]</p><h2><strong>Just tell me which one to use</strong></h2><p>As always, “it depends” – but if you’re looking for a quick answer, you should probably use:</p><ul role="list"><li><strong>Dash </strong>if you already use Python for your analytics and you want to build production-ready data dashboards for a larger company.</li><li><strong>Streamlit </strong>if you already use Python for your analytics and you want to get a prototype of your dashboard up and running as quickly as possible.</li><li><strong>Shiny</strong> if you already use R for your analytics and you want to make the results more accessible to non-technical teams.</li><li><strong>Jupyter</strong> if your team is very technical and doesn’t mind installing and running developer tools to view analytics.</li><li><strong>Voila </strong>if you already have Jupyter Notebooks and you want to make them accessible to non-technical teams.</li><li><strong>Flask </strong>if you want to build your own solution from the ground up.</li></ul><h2><strong>Quick overview</strong></h2><p>Not all the libraries are directly comparable. For example, Dash is built on top of Flask, and Flask is a more general framework for web application development. Similarly, each library focuses on a slightly different area.</p><ul role="list"><li><strong>Streamlit </strong>and <strong>Dash </strong>are full dashboarding solutions, focused on Python-based data analytics and running on the <strong>Tornado </strong>and <strong>Flask </strong>web frameworks, respectively.</li><li><strong>Shiny</strong> is a full dashboarding solution focused on data analytics with R.</li><li><strong>Jupyter</strong> is a notebook that data scientists use to analyze and manipulate data. You can also use it to visualize data.</li><li><strong>Voila </strong>is a library that turns individual Jupyter notebooks into interactive web pages.</li><li><strong>Flask </strong>is a Python web framework for building websites and apps – not necessarily with a data science focus.</li></ul><p>Some of these libraries have been around for a while, and some are brand new. Some are more rigid, and have their own structure, while others are flexible and can adapt to yours. Some focus on specific languages. Here’s a table showing the tradeoffs:</p><figure id="w-node-f7572045ee4c-8e0c2194"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5f77265751fc03385a5c347f_AzNSARkfeiXpAA7KUiJe_jhcy3KhhHgVboD8AK5lbDi_-exQ2QgOCbk6C5ePQZ3dq7kd5L9cVQpfA8qNdviEHO7CnpQIAcOWGl-MMgjH5NDlw7sh-3P1SWl62YXEeu-lDygPZnei.png" alt=""></p></figure><p>We’ve compared these libraries on:</p><ul role="list"><li><strong>Maturity: </strong>Based on the age of the project and how stable it is.</li><li><strong>Popularity:</strong> Based on adoption and GitHub stars.</li><li><strong>Simplicity: </strong>Based on how easy it is to get started using the library.</li><li><strong>Adaptability: </strong>Based on how flexible and opinionated the library is.</li><li><strong>Focus: </strong>Based on what problem the library solves.</li><li><strong>Language support: </strong>The main languages the library supports.</li></ul><p>These are not rigorous or scientific benchmarks, but they’re intended to give you a quick overview of how the tools overlap and how they differ from each other. For more details, see the head-to-head comparison below.</p><h2><strong>Streamlit vs. Dash</strong></h2><p>Streamlit and Dash are the two most similar libraries in this set. They are both full dashboarding solutions built with Python, and both include components for data analysis, visualization, user interaction, and serving.&nbsp;</p><p>Although they’re both open source, Dash is more focused on the enterprise market and doesn’t include all the features (such as job queues) in the open source version. By contrast, Streamlit is fully open source.&nbsp;</p><p>Streamlit is more structured and focused more on simplicity. It only supports Python-based data analysis and has a limited set of widgets (for example, sliders) to choose from.</p><p>Dash is more adaptable. Although it’s built with Python and pushes users towards its own plotting library (Plotly), it’s also compatible with other plotting libraries and even other languages, such as R or Julia.&nbsp;</p><ul role="list"><li><strong>Use</strong> <strong>Streamlit</strong> if you want to get going as quickly possible and don’t have strong opinions or many custom requirements.</li><li><strong>Use Dash </strong>if you need something more flexible and mature, and you don’t mind spending the extra engineering time.&nbsp;</li></ul><h2><strong>Streamlit vs. Shiny</strong></h2><p>Streamlit is a dashboard tool based on Python, while Shiny uses R. Both tools focus on turning data analysis scripts into full, interactive web applications.&nbsp;</p><p>Because Python is a general-purpose language while R is focused solely on data analytics, the web applications you build with Streamlit (based on the Tornado web server) are more powerful and easier to scale to production environments than those built with Shiny.&nbsp;</p><p>Shiny integrates well with plotting libraries in the R ecosystem, such as ggplot2, while Streamlit integrates with Python plotting libraries such as Bokeh or Altair.</p><ul role="list"><li><strong>Use</strong> <strong>Shiny </strong>if you prefer doing data analysis in R and have already invested in the R ecosystem.</li><li><strong>Otherwise use Streamlit</strong> (or Dash – see above).</li></ul><h2><strong>Streamlit vs. Voila&nbsp;</strong></h2><p>Streamlit is a complete data dashboarding solution, while Voila is a simpler and more limited tool that lets you convert existing Jupyter Notebooks into basic data dashboards and serve them as web applications to non-technical users.</p><p>Like Streamlit, Voila is built on top of the Tornado web framework, so you can use Jupyter notebooks along with Voila to get something broadly similar to Streamlit. But Streamlit is more flexible (it doesn’t require you to use Jupyter), while Voila can be simpler (provided you already have Jupyter Notebooks you want to present).</p><p>Voila uses Jupyter’s widget library, while Streamlit uses custom widgets – so if you’re already familiar with Jupyter, you’ll find Voila easier to work with.</p><ul role="list"><li><strong>Use Streamlit</strong> If you’re looking for an all-in-one solution.</li><li><strong>Use Voila</strong> if you already have Jupyter Notebooks and are looking for a way to serve them.</li></ul><h2><strong>Streamlit vs. Jupyter Notebooks</strong></h2><p>Streamlit is a full data dashboarding solution, while Jupyter Notebooks are primarily useful to engineers who want to develop software and visualizations. Engineers use Streamlit to build dashboards for non-technical users, and they use Jupyter Notebooks to develop code and share it with other engineers.</p><p>Combined with add-ons such as Voila, Jupyter Notebooks can be used similarly to Streamlit, but data dashboarding is not their core goal.</p><ul role="list"><li><strong>Use Streamlit</strong> if you need dashboards that non-technical people can use.</li><li>‍<strong>Jupyter Notebooks </strong>are best if your team is mainly technical and you care more about functionality than aesthetics.</li></ul><h2><strong>Streamlit vs. Flask</strong></h2><p>Streamlit is a data dashboarding tool, while Flask is a web framework. Serving pages to users is an important but small component of data dashboards. Flask doesn’t have any data visualization, manipulation, or analytical capabilities (though since it’s a general Python library, it can work well with other libraries that perform these tasks). Streamlit is an all-in-one tool that encompases web serving as well as data analysis.</p><ul role="list"><li><strong>Use Streamlit</strong> if you want a structured data dashboard with many of the components you’ll need already included. Use Streamlit<strong> </strong>if you want to build a data dashboard with common components and don’t want to reinvent the wheel.</li><li><strong>Use Flask </strong>if you want to build a highly customized solution from the ground up and you have the engineering capacity.</li></ul><h2><strong>Dash vs. Shiny</strong></h2><p>Dash and Shiny are both complete data dashboarding tools, but Dash lives mainly in the Python ecosystem, while Shiny is exclusive to R.&nbsp;</p><p>Dash has more features than Shiny, especially in its enterprise version, and it's more flexible. Python is a general-purpose programming language, while R is focused solely on data analytics. Some data scientists prefer R for its mature libraries and (often) more concise code. Engineers usually prefer Python, since it conforms more closely to other languages.</p><ul role="list"><li><strong>Use Dash</strong> if your team prefers Python.</li><li><strong>Use Shiny</strong> if your team prefers R.</li></ul><h2><strong>Dash vs. Voila and Jupyter Notebooks</strong></h2><p>Dash is an all-in-one dashboarding solution, while Voila can be combined with Jupyter Notebooks to get similar results. Dash is more powerful and flexible, and it’s built specifically for creating data dashboards, while Voila is a thin layer built on top of Jupyter Notebooks to convert them into stand-alone web applications.</p><ul role="list"><li><strong>Use Dash </strong>if you want to build a scalable, flexible data dashboarding tool.</li><li><strong>Use Voila</strong> if you have existing Jupyter Notebooks you want your non-technical teams to be able to use.</li></ul><h2><strong>Dash vs. Flask</strong></h2><p>Dash is built on top of Flask and uses Flask as its web routing component, so it’s not very meaningful to compare them head-to-head. Dash is a data dashboarding tool, while Flask is a minimalist, generic web framework. Flask has no data analytics tools included, although it can work with other Python libraries that do analytics.</p><ul role="list"><li><strong>Use Dash </strong>if you want to build a data dashboard.</li><li><strong>Use</strong> <strong>Flask </strong>if you want to build a far more generic web application and to choose every component in it.</li></ul><h2><strong>Shiny vs. Voila + Jupyter Notebooks</strong></h2><p>Shiny is a data dashboarding solution for R. While you can use Voila and Jupyter Notebooks with R, these are tools that focus primarily on the Python ecosystem.</p><ul role="list"><li><strong>Use Shiny </strong>if you already do your data analytics in R.</li><li><strong>Use Voila </strong>if you already have Jupyter Notebooks you want to make more accessible.</li></ul><h2><strong>Shiny vs. Flask</strong></h2><p>Shiny is a data dashboarding …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/data-dashboarding-streamlit-vs-dash-vs-shiny-vs-voila">https://datarevenue.com/en-blog/data-dashboarding-streamlit-vs-dash-vs-shiny-vs-voila</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/data-dashboarding-streamlit-vs-dash-vs-shiny-vs-voila</link>
            <guid isPermaLink="false">hacker-news-small-sites-24699616</guid>
            <pubDate>Tue, 06 Oct 2020 16:32:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eliminating Task Processing Outages by Replacing RabbitMQ with Apache Kafka]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24699534">thread link</a>) | @sciurus
<br/>
October 6, 2020 | https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/ | <a href="https://web.archive.org/web/*/https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><span>Scaling backend infrastructure to handle hyper-growth is one of the many exciting challenges of working at DoorDash. In mid 2019, we faced significant scaling challenges and frequent outages involving </span><a href="https://en.wikipedia.org/wiki/Celery_(software)"><span>Celery</span></a><span> and </span><a href="https://www.rabbitmq.com/"><span>RabbitMQ</span></a><span>, two technologies powering the system that handles the asynchronous work enabling critical functionalities of our platform, including order checkout and Dasher assignments.&nbsp;</span></p>
<p><span>We quickly solved this problem with a simple, </span><a href="https://kafka.apache.org/"><span>Apache Kafka</span></a><span>-based asynchronous task processing system that stopped our outages while we continued to iterate on a robust solution. Our initial version implemented the smallest set of features needed to accommodate a large portion of existing Celery tasks. Once in production, we continued to add support for more Celery features while addressing novel problems that arose when using Kafka. </span></p>
<h2><span>The problems we faced using Celery and RabbitMQ</span></h2>
<p><span>RabbitMQ and Celery were mission critical pieces of our infrastructure that powered over 900 different asynchronous tasks at DoorDash, including order checkout, merchant order transmission, and Dasher location processing. The problem DoorDash faced was that RabbitMQ was frequently going down due to excessive load. If task processing went down, DoorDash effectively went down and orders could not be completed, resulting in revenue loss for our merchants and Dashers, and a poor experience for our consumers. We faced issues on the following fronts:</span></p>
<ul>
<li><b>Availability:</b><span> Outages caused by demand reduced availability.&nbsp;</span></li>
<li><b>Scalability:</b><span> RabbitMQ could not scale with the growth of our business.&nbsp;</span></li>
<li><b>Observability:</b><span> RabbitMQ offered limited metrics and Celery workers were opaque.&nbsp;</span></li>
<li><b>Operational efficiency:</b><span> Restarting these components was a time-consuming, manual process.&nbsp;</span></li>
</ul>
<h3><span>Why our asynchronous task processing system wasn’t highly available</span></h3>
<p><span>This biggest problem we faced were outages, and they often came when demand was at its peak. RabbitMQ would go down due to load, </span><a href="https://www.rabbitmq.com/connections.html#high-connection-churn"><span>excessive connection churn</span></a><span>, and other reasons. Orders would be halted, and we’d have to restart our system or sometimes even bring up an entirely new broker and manually </span><a href="https://en.wikipedia.org/wiki/Failover"><span>failover</span></a><span> in order to recover from the outage.</span></p>
<p><span>On diving deeper into the availability issues, we found the following sub-issues:</span></p>
<ul>
<li><span>Celery allows users to schedule tasks in the future with a countdown or ETA. Our heavy use of&nbsp; these countdowns resulted in noticeable load increases on the broker. Some of our outages were directly related to an increase in tasks with countdowns. We ultimately decided to restrict the use of countdowns in favor of another system we had in place for scheduling work in the future.</span></li>
<li><span>Sudden bursts of traffic would leave RabbitMQ in a degraded state where task consumption was significantly lower than expected. In our experience, this could only be resolved with a RabbitMQ bounce. RabbitMQ has a concept of Flow Control where it will reduce the speed of connections which are publishing too quickly so that queues can keep up. Flow Control was often, but not always, involved in these availability degradations. When Flow Control kicks in, the publishers effectively see it as network latency. Network latency reduces our response times; if latency increases during peak traffic, significant slowdowns can result that cascade as requests pile up upstream.</span></li>
<li><span>Our python </span><a href="https://uwsgi-docs.readthedocs.io/en/latest/"><span>uWSGI</span></a><span> web workers had a feature called harakiri that was enabled to kill any processes that exceeded a timeout. During outages or slowdowns, harakiri resulted in a connection churn to the RabbitMQ brokers as processes were repeatedly killed and restarted. With thousands of web workers running at any given time, any slowness that triggered harakiri would in turn contribute even more to slowness by adding extra load to RabbitMQ.</span></li>
<li><span>In production we experienced several cases where task processing in the Celery consumers&nbsp; stopped, even in the absence of significant load. Our investigation efforts did not yield evidence of any resource constraints that would’ve halted processing, and the workers resumed processing once they were bounced. This problem was never root caused, though we suspect an issue in the Celery workers themselves and not RabbitMQ.</span></li>
</ul>
<p><span>Overall, all of these availability issues were unacceptable for us as high reliability is one of our highest priorities. Since these outages were costing us a lot in terms of missed orders and credibility we needed a solution that would address these problems as soon as possible.</span></p>
<h3><span>Why our legacy solution did not scale&nbsp;</span></h3>
<p><span>The next biggest problem was scale. DoorDash is growing fast and we were quickly reaching the limits of our existing solution. We needed to find something that would keep up with our continued growth since our legacy solution had the following problems:&nbsp;</span></p>
<p><strong>Hitting the vertical scaling limit</strong></p>
<p><span>We were using the largest available single-node RabbitMQ solution that was available to us. There was no path to scale vertically any further and we were already starting to push that node to its limits.</span></p>
<p><strong>The High Availability mode limited our capacity&nbsp;</strong></p>
<p><span>Due to replication, the primary-secondary High Availability (HA) mode reduced throughput compared to the single node option, leaving us with even less headroom than just the single node solution. We could not afford to trade throughput for availability.</span></p>
<p><span>Secondly, the primary-secondary HA mode did not, in practice, reduce the severity of our outages. Failovers took more than 20&nbsp; minutes&nbsp; to complete and would often get stuck requiring manual intervention. Messages were often lost in the process as well.</span></p>
<p><span>We were quickly running out of headroom as DoorDash continued to grow and push our task processing to its limits. We needed a solution that could scale horizontally as our processing needs grew.</span></p>
<h3><span>How Celery and RabbitMQ offered limited observability</span></h3>
<p><span>Knowing what’s going on in any system is fundamental to ensuring its availability, scalability, and operational integrity.&nbsp;</span></p>
<p><span>As we navigated the issues outlined above, we noticed that :</span></p>
<ul>
<li><span>We were limited to a small set of RabbitMQ metrics available to us.</span></li>
<li><span>We had limited visibility into the Celery workers themselves.</span></li>
</ul>
<p><span>We needed to be able to see real-time metrics of every aspect of our system which meant the observability limitations needed to be addressed as well.&nbsp;</span></p>
<h3><span>The operational efficiency challenges</span></h3>
<p><span>We also faced several issues with operating RabbitMQ:</span></p>
<ul>
<li><span>We often had to failover our RabbitMQ node to a new one to resolve the persistent degradation we observed. This operation was manual and time consuming for the engineers involved and often had to be done late at night, outside of peak times.</span></li>
<li><span>There were no in-house Celery or RabbitMQ experts at DoorDash who we could lean on to help devise a scaling strategy for this technology.</span></li>
</ul>
<p><span>Engineering time spent operating and maintaining RabbitMQ was not sustainable. We needed something that better met our current and future needs.</span></p>
<h2><span>Potential solutions to our problems with Celery and RabbitMQ&nbsp;</span></h2>
<p><span>With the problems outlined above, we considered the following solutions:</span></p>
<ul>
<li><b>Change the Celery broker from RabbitMQ to Redis or Kafka. </b>This would allow us to continue using Celery, with a different and potentially more reliable backing datastore.</li>
</ul>
<ul>
<li><b>Add multi-broker support to our </b><a href="https://www.djangoproject.com/"><b>Django</b></a><b> app so consumers could publish to N different brokers based on whatever logic we wanted. </b>Task processing will get sharded across multiple brokers, so each broker will experience a fraction of the initial load.</li>
</ul>
<ul>
<li><b>Upgrade to newer versions of Celery and RabbitMQ. </b>Newer versions of Celery and RabbitMQ were expected to fix reliability issues, buying us time as we were already extracting components from our Django monolith in parallel.</li>
</ul>
<ul>
<li><b>Migrate to a custom solution backed by Kafka. </b>This solution takes more effort than the other options we listed, but also has more potential to solve every problem we were having with the legacy solution.</li>
</ul>
<p><span>Each option has its pros and cons:</span></p>
<table>
<tbody>
<tr>
<td><b>Option</b></td>
<td><b>Pros</b></td>
<td><b>Cons</b></td>
</tr>
<tr>
<td><span>Redis as broker&nbsp;</span></td>
<td>
<ul>
<li><span>Improved availability with ElasticCache and multi-AZ support</span></li>
<li><span>Improved broker observability with ElasticCache as the broker</span></li>
<li><span>Improved operational efficiency</span></li>
<li><span>In-house operational experience and expertise with Redis</span></li>
<li><span>A broker swap is straight-foward as a supported option in Celery</span></li>
<li><span>Harakiri connection churn does not significantly degrade Redis performance</span></li>
</ul>
</td>
<td>
<ul>
<li><span>Incompatible with Redis clustered mode</span></li>
<li><span>Single node Redis does not scale horizontally</span></li>
<li><span>No Celery observability improvements</span></li>
<li><span>This solution does not address the observed issue where Celery workers stopped processing tasks</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Kafka as broker</span></td>
<td>
<ul>
<li><span>Kafka can be highly available</span></li>
<li><span>Kafka is horizontally scalable</span></li>
<li><span>Improved observability with Kafka as the broker</span></li>
<li><span>Improved operational efficiency</span></li>
<li><span>DoorDash had in-house Kafka expertise</span></li>
<li><span>A broker swap is straight-foward as a supported option in Celery</span></li>
<li><span>Harakiri connection churn does not significantly degrade Kafka performance</span></li>
</ul>
</td>
<td>
<ul>
<li><span>Kafka is not supported by Celery yet&nbsp;</span></li>
<li><span>Does not address the observed issue where Celery workers stop processing tasks</span></li>
<li><span>No celery observability improvements</span></li>
<li><span>Despite in-house experience, we had not operated Kafka at scale at DoorDash.</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Multiple brokers</span></td>
<td>
<ul>
<li><span>Improved availability&nbsp;</span></li>
<li><span>Horizontal scalability</span></li>
</ul>
</td>
<td>
<ul>
<li><span>No observability improvements</span></li>
<li><span>No operational efficiency improvements</span></li>
<li><span>Does not address the observed issue where Celery workers stop processing tasks</span></li>
<li><span>Does not address the issue with harakiri-induced connection churn</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Upgrade versions</span></td>
<td>
<ul>
<li><span>Might improve the issue where RabbitMQ becomes stuck in a degraded state</span></li>
<li><span>Might improve the issue where Celery workers get stuck</span></li>
<li><span>Might buy us headroom to implement a longer term strategy</span></li>
</ul>
</td>
<td>
<ul>
<li><span>Not guaranteed to fix our observed bugs</span></li>
<li><span>Will not immediately fix our issues with availability, scalability, observability, and operational efficiency</span></li>
<li><span>Newer versions of RabbitMQ and Celery required newer versions of Python.</span></li>
<li><span>Does not address the issue with harakiri-induced connection churn</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Custom Kafka solution</span></td>
<td>
<ul>
<li><span>Kafka can be highly available</span></li>
<li><span>Kafka is horizontally scalable</span></li>
<li><span>Improved observability with Kakfa as the broker</span></li>
<li><span>Improved operational efficiency</span></li>
<li><span>In-house Kafka expertise</span></li>
<li><span>A broker change is …</span></li></ul></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/">https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/</a></em></p>]]>
            </description>
            <link>https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24699534</guid>
            <pubDate>Tue, 06 Oct 2020 16:26:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching my five year old to code by cheating]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24699448">thread link</a>) | @gregorymichael
<br/>
October 6, 2020 | https://baugues.com/cheat-code/ | <a href="https://web.archive.org/web/*/https://baugues.com/cheat-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>My wife and I became <a href="https://baugues.com/homeschool">reluctant homeschoolers</a> this year – choosing to teach our five year old daughter without the our school's remote learning. Rachel teaches Reading, Writing, Arts, and Science. My job is Math, Chess, and Technology. </p><p>I started programming on a <a href="https://baugues.com/trs-80">TRS-80</a> when I was six or seven. Back then, the computer booted into BASIC, the most approachable programming language of all time. Hello World in BASIC looks something like:</p><pre><code>10 print "hello world" 
20 goto 10
</code></pre><p>Programming in BASIC was the most instant gratification you could get on a TRS-80. There were few games and no Internet. Had I been introduced to a different programming language at a different age, I'm not sure I would have taken to it.</p><p>That's been a problem I've been wrestling with when introducing our daughter, Emma, to programming. Modern developer environments have a lot of friction and overhead. We've played with Swift Playgrounds, which is great for introducing programming concepts, but feels like you're writing instructions inside a video game as opposed to harnessing the the raw power of code to control the computer.</p><p>A colleague recently introduced me to <a href="https://repl.it/talk/announcements/Announcing-Basic-Language-With-Graphics-Beta/31741">pg-basic on repl.it</a>, which recaptures the simplicity of writing BASIC on a TRS-80.</p><p>Emma and I are working on addition. She likes video games and coding, so I figured we could create a game to practice math. The general idea is: pick two numbers at random, ask her to add them, give her points if she gets it right. We did it in Python, as the code was't that dissimilar to its Basic equivalent. </p><p>Go ahead, run it. (And edit, if you wish.) </p><!--kg-card-begin: html--><!--kg-card-end: html--><p>I composed the code with her sitting next to me, asking for her suggestions along the way.</p><ul><li>"What should we name this variable?"</li><li>"How many points should you get when you get one right?"</li><li>"How many points do you need to win?"</li><li>"What should it say when you win?" </li></ul><p>Then I made her a deal: if she won the game two times, she could cheat and change the code. She loves cheating.</p><p>She quickly figured out she could change the lines that generate numbers to:</p><pre><code>lulu = 0
boonie = random.randrange(11)
</code></pre><p>Math problems got easier. Then she changed it to: </p><pre><code>lulu = 0
boonie = 0
</code></pre><p>Problems got <em>a lot</em> easier.</p><p>She still had to answer a bunch of questions to win the game, and typing zero and enter repeatedly is hard work, so she changed the looping condition to:</p><pre><code>while points &lt; 1:
</code></pre><p>It may be the first time in her short educational career when she's had control over the quiz, instead of the quiz having control over her.</p><p>Thinking back to how I started writing code, it was copying a few dozen lines of BASIC out of the back of <em><a href="http://games.datagrind.com/index.php?pageid=10">3-2-1 Contact</a></em>, getting it to run, and then tweaking it. Today, when I learn a new language or service, it's "copy, paste, edit."</p><p>Composing along side Emma and letting her edit seems to be a winning strategy. Yesterday, after making a modification, she thought for a few seconds, turned to look at me, and said, "... I can use code to do <em>anything</em>."</p><p>She's starting to get it.</p>
			</section></div>]]>
            </description>
            <link>https://baugues.com/cheat-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24699448</guid>
            <pubDate>Tue, 06 Oct 2020 16:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Try out the new Python 3.9 features in a Python sandbox]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24698705">thread link</a>) | @sunaden
<br/>
October 6, 2020 | https://deepnote.com/project/09e2609b-986b-40fa-9f56-fcbbc60eb61d | <a href="https://web.archive.org/web/*/https://deepnote.com/project/09e2609b-986b-40fa-9f56-fcbbc60eb61d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><p><span>You can view this project and add comments, but can't make any changes.</span><span> <!-- -->You can try to<!-- --> <a>sign in</a> <!-- -->to request additional access.</span></p></section></div></div></div>]]>
            </description>
            <link>https://deepnote.com/project/09e2609b-986b-40fa-9f56-fcbbc60eb61d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698705</guid>
            <pubDate>Tue, 06 Oct 2020 15:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time for a WTF MySQL Moment]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 110 (<a href="https://news.ycombinator.com/item?id=24698660">thread link</a>) | @gbl08ma
<br/>
October 6, 2020 | https://gbl08ma.com/time-for-a-wtf-mysql-moment/ | <a href="https://web.archive.org/web/*/https://gbl08ma.com/time-for-a-wtf-mysql-moment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-holder" role="main">
	<div>
		<article id="post-21465">			
			
	<p>
				October 4, 2020 / gbl08ma / 0 Comments	</p>
	<p>Many people have been experiencing strange time perception phenomenon throughout 2020, but certain database management systems have been into time shenanigans for way longer. This came to my attention when a friend received the following exception in one of his projects (his popular Discord bot, <a href="https://accord.abcric.net/">Accord</a>), coming from the MySQL connector being used with EF Core:</p>
<pre>MySqlException: Incorrect TIME value: '960:00:00.000000'</pre>
<p>Not being too experienced with MySQL, as I prefer PostgreSQL for reasons that will soon become self-evident, for a brief moment I assumed the incorrection in this value was the hundreds of hours, as one could reasonably assume that maybe TIME values were capped at 24 hours, or that a different syntax was needed for values spanning multiple days, and that one would need to use, say, “40:00:00:00” to represent 40 days. But reality turned out to be more complex and harder to explain.</p>
<p>With checking the documentation being the most natural next step, the MySQL documentation goes:</p>
<blockquote><p>MySQL retrieves and displays <code>TIME</code> values in <em><code>'hh:mm:ss'</code></em> format (or <em><code>'hhh:mm:ss'</code></em> format for large hours values).</p></blockquote>
<p>So far so good, our problematic TIME value respects this format, but the fact that <code>hh</code> and <code>hhh</code> are explicitly pointed out is already suspect (what about values with over 999 hours?). The next sentence in the documentation explains why, and left me with even more questions of the WTF kind:</p>
<blockquote><p><code>TIME</code> values may range from <code>'-838:59:59'</code> to <code>'838:59:59'</code>.</p></blockquote>
<p>Oooh Kaaay… that’s an oddly specific range, but I’m sure there has to be a technical reason for it. 839 hours is 34.958(3) days, and the whole range spans exactly 6040798 seconds. The documentation also mentions the following:</p>
<blockquote><p>MySQL recognizes <code>TIME</code> values in several formats, some of which can include a trailing fractional seconds part in up to microseconds (6 digits) precision.</p></blockquote>
<p>Therefore, it also makes sense to point out that the whole interval spans <span id="display">6 040 798 </span>000 000 microseconds, but again, these seem like oddly specific numbers. They are not near any power of two, the latter being between 2<sup>42</sup> and 2<sup>43</sup>, so MySQL must be using some awkward internal representation format. But before we dive into that, let me just point out how bad this type is. It is the closest MySQL has to a time interval type, and yet it can’t deal with intervals that are just a bit over a month long. How much is that “bit”? Not even a nice, rounded number of days, it seems.</p>
<p>To make matters worse, it appears that the most popular EF Core MySQL provider maps .NET’s <code>TimeSpan</code> to <code>TIME</code> by default, despite the fact that&nbsp;<code>TimeSpan</code> can contain intervals in the dozens of millennia (it uses a 64 bit integer and has 10<sup>-8</sup> s precision) compared to TIME’s measly “a bit over two months”. This is an <a href="https://github.com/PomeloFoundation/Pomelo.EntityFrameworkCore.MySql/issues/1046">issue other people have run into</a>, and the discussion in that issue includes a “This mimics the behavior of SQL Server” remark, which made me go check and, sure enough, SQL Server’s <code>time</code> is meant to encode a time of day and has a range of 00:00:00.0000000 through 23:59:59.9999999, something which overall makes more sense to me than MySQL’s odd TIME range.</p>
<p>So let’s go back to MySQL. What is the reasoning behind such an <em>interesting</em> range? The <a href="https://dev.mysql.com/doc/internals/en/date-and-time-data-type-representation.html">MySQL Internals Manual</a> says that the storage for the TIME type has changed with version 5.6.4, having gained support for fractional seconds in this version. It uses 3 bytes for the non-fractional type. Now, had they just used these 3 bytes to encode a number of seconds, they would have been able to support intervals spanning over 2330 hours, which would already be a considerable improvement over the current 838 hours maximum, even if still a bit useless when it comes to mapping a <code>TimeSpan</code> to it.</p>
<p>This means their encoding must be wasting bits, probably so it is easier to work with… not sure in what circumstances exactly, but maybe it makes more sense if your database management system (and/or your conception of what the users will do with it) just loves strings, and you really want to speed up the hh:mm:ss representation. So, behold:</p>
<blockquote>
<pre>1 bit sign (1= non-negative, 0= negative)
1 bit unused (reserved for future extensions)
10 bits hour (0-838)
6 bits minute (0-59) 
6 bits second (0-59) 
---------------------
24 bits = 3 bytes</pre>
</blockquote>
<p>This explains everything, right? Well, look closely. 10 bits for the hour… and a range of 0 to 838. I kindly remind you that 2<sup>10</sup> is 1024, not 838. The plot thickens. I’m not the first person to wonder about this, of course, <a href="https://stackoverflow.com/questions/39259910/why-is-mysqls-maximum-time-limit-8385959">this was asked on StackOverflow before</a>. The accepted answer in that question explains everything, but <em>it almost didn’t</em>, as it initially dismisses the odd choice of 838 as “backward compatibility with applications that were written a while ago”, and only later it is explained that this choice had to do with compatibility with MySQL version… 3, from the times when, you know, Windows 98 was a fresh operating system and Linux wasn’t 10 years old yet.</p>
<p>In MySQL 3, the TIME type used 3 bytes as well, but they were used differently. One of the bits was used for the sign as well, but the remaining 23 bits were an integer value produced like this: Hours × 10000 + Minutes × 100 + Seconds; in other words, the two least significant decimal digits of the number contained the seconds, the next two contained the minutes, and the remaining ones contained the hours. 2<sup>23</sup> is 83888608, i.e. 838:86:08, therefore, the maximum valid time in this format is 838:59:59. This format is even less wieldy than the current one, requiring multiplication and division to do basically anything with it, except string formatting and parsing – once again showing that MySQL places too much value on string IO and not so much on having types that are convenient for internal operations and non-string-based protocols.</p>
<p>MySQL developers had ample opportunities to fix this type, or at the very least introduce an alternative one that is free of this reduced range. They changed this type twice from MySQL 3 until now, but decided to retain the range every time, supposedly for compatibility reasons. I am struggling to imagine the circumstances where increasing the value range for a type can break compatibility with an application – do types in MySQL have defined overflow behaviors? Is any sane person writing applications where they are relying on a database type’s intrinsic limits for validation? If yes, who looked at this awkward 838 hours range and thought of it as an appropriate limitation to carry unchanged into their application’s data model? At this point, I don’t even want to know.</p>
<p>Despite having changed twice throughout MySQL’s lifetime, the TIME type is still quite an awkward and limited one. That unused, “reserved for future extensions” bit is, in my opinion, really the <em>pièce de résistance</em> here. Here’s hoping that one day it will be used to signify a “legacy” TIME value and that, by then, MySQL and/or MariaDB will have support for a proper type like <a href="https://www.postgresql.org/docs/current/datatype-datetime.html">PostgreSQL’s INTERVAL</a>, which has a range of +/- 178000000 years and a very reasonable microsecond precision.</p>
	</article>		
	</div>
	</div></div>]]>
            </description>
            <link>https://gbl08ma.com/time-for-a-wtf-mysql-moment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698660</guid>
            <pubDate>Tue, 06 Oct 2020 15:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring for tech jobs has increased more than 100% in these Midwestern cities]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 277 (<a href="https://news.ycombinator.com/item?id=24698449">thread link</a>) | @KaiserSanchez
<br/>
October 6, 2020 | https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities | <a href="https://web.archive.org/web/*/https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img src="https://www.purpose.jobs/hubfs/social-suggested-images/www.michiganbusiness.org49d2d3globalassetsimagesnews1440-bannersdetroit-1440.jpg" alt="Hiring for Tech Jobs has Increased More than 100% in These Midwestern Cities">
</p></div><div>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>When people think tech jobs, they tend to think Silicon Valley or New York City.</p>
<!--more-->
<p>They don’t think about the Midwest, which is better known for rolling farmland and wide-open spaces than a booming tech scene where startups thrive.</p>
<p>But it’s time to think again about the Midwest.&nbsp;</p>
<p><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=600&amp;name=img-1-midwest.jpg" alt="img-1-midwest" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=300&amp;name=img-1-midwest.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=600&amp;name=img-1-midwest.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=900&amp;name=img-1-midwest.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1200&amp;name=img-1-midwest.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1500&amp;name=img-1-midwest.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1800&amp;name=img-1-midwest.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>This region comprises 19 percent of the <em>entire U.S. GDP</em>. Twenty-five percent of all computer science grads get their degrees in the Midwest. Forty-five percent of Fortune 500 countries are located here, as is 60 percent of all U.S. manufacturing.</p>
<p>And, as icing on the cake, seven of the top 10 <a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank">most affordable states</a> in the nation are in the Midwest.</p>
<p>What does that have to do with tech jobs? Well, increasingly, startup founders and investors are taking note of all those things the Midwest has to offer, as well as the excellent quality of life and affordable cost of living you can find in so many cities in the Heartland. They’re realizing you don’t have to be based in the Golden State or the Big Apple if you want your startup to succeed. You can be based in the Midwest and find just as much success.</p>
<div><p>So tech startups are booming in the Midwest. Don’t believe us? The proof is in the numbers.</p></div>
<h2><span>In 3 of the Midwest’s Top 10 Cities, Tech Hiring Is Up More than 100% In the Last 3 Years</span></h2>
<div><p>We’ll let the numbers tell the full story. These are the Midwest’s top 10 cities in terms of growth and offerings for tech workers.&nbsp;</p></div>
<h3><span>Chicago: 8th in the U.S. for Net Tech Employment</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=600&amp;name=img-2-chicago.jpg" alt="img-2-chicago" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=300&amp;name=img-2-chicago.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=600&amp;name=img-2-chicago.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=900&amp;name=img-2-chicago.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1200&amp;name=img-2-chicago.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1500&amp;name=img-2-chicago.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1800&amp;name=img-2-chicago.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p><a href="https://www.purpose.jobs/chicago" rel="noopener" target="_blank">Chicago</a> is the No. 1 city in the Midwest for growth in the tech sector, and it ranks eighth in the country for net tech employment. Currently, there are 344,146 people in Chicago working in tech jobs. The city saw nearly 18 percent growth in its net tech employment from 2010 to 2018, and from just 2017 to 2018, job posting in the tech sector increased by a whopping 73 percent.</p></div>
<h3><span>Detroit: 11th in the U.S. for Net Tech Employment</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=600&amp;name=img-3-detroit.jpg" alt="img-3-detroit" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=300&amp;name=img-3-detroit.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=600&amp;name=img-3-detroit.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=900&amp;name=img-3-detroit.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1200&amp;name=img-3-detroit.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1500&amp;name=img-3-detroit.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1800&amp;name=img-3-detroit.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<p>Coming in just behind Chicago is <a href="https://www.purpose.jobs/detroit" rel="noopener" target="_blank">Detroit</a>, which ranks 11th in the U.S. for its net tech employment. 241,135 people work in the tech sector in Detroit, where net tech employment increased by 37.2 percent from 2010 to 2018. From 2017 to 2018, job postings in tech rose 41 percent, making Detroit a fantastic spot to look for a startup job.</p>
<p><em>Looking to get connected with top startups? Join the purpose.jobs talent community to start applying for Midwest startup jobs.</em> <!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd"><span id="hs-cta-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2873777/6fe04a32-7b40-49d0-873c-8f8ae79aa1dd" target="_blank"><img id="hs-cta-img-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd" src="https://no-cache.hubspot.com/cta/default/2873777/6fe04a32-7b40-49d0-873c-8f8ae79aa1dd.png" alt="Create a free profile."></a></span></span><!-- end HubSpot Call-to-Action Code --></p>

<h3><span>Minneapolis: Nearly 200,000 Tech Jobs and Growing</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=600&amp;name=img-4-minn.jpg" alt="img-4-minn" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=300&amp;name=img-4-minn.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=600&amp;name=img-4-minn.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=900&amp;name=img-4-minn.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1200&amp;name=img-4-minn.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1500&amp;name=img-4-minn.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1800&amp;name=img-4-minn.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Third in the Midwest for growth is Minneapolis, a thriving city many overlook, despite its tech workforce of 196,151 and growing. Minneapolis is ranked 14th in the U.S. overall for net tech employment, which increased 17 percent in the city from 2010 to 2018. What’s even more impressive is that job postings in the tech sector increased 76 percent in Minneapolis from 2017 to 2018.</p></div>
<h3><span>Kansas City: Where New Tech Jobs Have Almost Doubled in Recent Years<br></span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=600&amp;name=img-5-kc.jpg" alt="img-5-kc" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=300&amp;name=img-5-kc.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=600&amp;name=img-5-kc.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=900&amp;name=img-5-kc.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1200&amp;name=img-5-kc.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1500&amp;name=img-5-kc.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1800&amp;name=img-5-kc.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Kansas City has more to boast about than its Super Bowl win. The city is home to 100,782 people who work in the tech sector, making it 24th in the U.S. for net tech employment. Kansas City also saw 17.3 percent growth in its net tech employment from 2010 to 2018, and 82 percent growth in its tech job posting just from 2017 to 2018, indicating that its rate of growth is ramping up even faster in recent years than over the last decade.</p></div>
<h3><span>Cincinnati: Nearly 100,000 Tech Workers and Steady Growth of New Jobs<br></span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=600&amp;name=img-6-cinci.jpg" alt="img-6-cinci" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=300&amp;name=img-6-cinci.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=600&amp;name=img-6-cinci.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=900&amp;name=img-6-cinci.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1200&amp;name=img-6-cinci.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1500&amp;name=img-6-cinci.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1800&amp;name=img-6-cinci.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Fifth on the list of growing Midwest cities in <a href="https://www.purpose.jobs/cincinnati" rel="noopener" target="_blank">Cincinnati</a>, where 82,088 workers already have tech jobs. From 2010 to 2018, the city saw a 23.9 percent increase in its net tech employment, and job postings in the tech sector jumped up 41 percent just from 2017 to 2018. That lands Cincinnati 28th in the U.S. for net tech employment, and there’s plenty of opportunity here as the city continues to grow.</p></div>
<h3><span>Cleveland: Job Growth that Nearly Doubled in Just One Year</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=600&amp;name=img-7-cleveland.jpg" alt="img-7-cleveland" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=300&amp;name=img-7-cleveland.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=600&amp;name=img-7-cleveland.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=900&amp;name=img-7-cleveland.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1200&amp;name=img-7-cleveland.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1500&amp;name=img-7-cleveland.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1800&amp;name=img-7-cleveland.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Sixth in the Midwest is <a href="https://www.purpose.jobs/cleveland" rel="noopener" target="_blank">Cleveland</a>, an oft-overlooked Ohio metropolis that has plenty to offer tech workers —&nbsp;just ask the 76,698 workers who have tech jobs there. Cleveland saw 16.3 percent growth in its net tech employment from 2010 to 2018, which led to its 93 percent increase in tech job postings from 2017 to 2018. Of all the cities in the U.S., Cleveland ranks 29th for net tech employment, making it a place well worth considering whether you’re looking for a tech job or hoping to found a startup in a new home.</p></div>
<h3><span>Indianapolis: More than 100 Percent Job Growth in One Year</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=600&amp;name=img-8-indi.jpg" alt="img-8-indi" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=300&amp;name=img-8-indi.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=600&amp;name=img-8-indi.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=900&amp;name=img-8-indi.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1200&amp;name=img-8-indi.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1500&amp;name=img-8-indi.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1800&amp;name=img-8-indi.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p><a href="https://www.purpose.jobs/indianapolis" rel="noopener" target="_blank">Indianapolis</a> is the first of our three Midwestern cities that increased their startup job growth more than 100 percent —&nbsp;the city saw a 121 percent increase in new tech job postings from 2017 to 2018, after 24.2 percent growth in net tech employment from 2010 to 2018. As of now, there are 74,615 people employed in the tech sector in Indy, and that number is only going up.</p></div>
<h3><span>Milwaukee: Tied for Highest Increase in New Tech Jobs in the Midwest</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=600&amp;name=img-9-milwak.jpg" alt="img-9-milwak" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=300&amp;name=img-9-milwak.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=600&amp;name=img-9-milwak.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=900&amp;name=img-9-milwak.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1200&amp;name=img-9-milwak.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1500&amp;name=img-9-milwak.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1800&amp;name=img-9-milwak.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>With an astonishing 137 percent increase in new tech job postings from 2017 to 2018, Milwaukee is one of the most promising spots in the Midwest for anyone looking for a tech position. The city currently boasts 71,755 tech workers after a 9.2 percent increase in net tech employment from 2010 to 2018. Sure, that’s slower growth over the course of the decade than some of the cities on our list, but the rate of new job postings in Milwaukee show this city is just getting started.</p></div>
<h3><span>Omaha: An Unlikely Hotspot for New Tech Job Postings</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=600&amp;name=img-10-omaha.jpg" alt="img-10-omaha" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=300&amp;name=img-10-omaha.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=600&amp;name=img-10-omaha.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=900&amp;name=img-10-omaha.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1200&amp;name=img-10-omaha.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1500&amp;name=img-10-omaha.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1800&amp;name=img-10-omaha.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Like Milwaukee, Omaha also had a stunning 137 percent increase in new tech job postings from 2017 to 2018. While growth in net tech jobs in the city was only 10.7 percent from 2010 to 2018, all that seems to indicate is that tech workers are <em>just</em> starting to realize what Omaha has to offer. 37,508 tech workers live in the city now, but with such a marked increase in new tech jobs, we can only see that number going up.</p></div>
<h3><span>Des Moines: Second-Highest 10-Year Growth in the Midwest</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=600&amp;name=img-11-des-moines.jpg" alt="img-11-des-moines" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=300&amp;name=img-11-des-moines.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=600&amp;name=img-11-des-moines.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=900&amp;name=img-11-des-moines.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1200&amp;name=img-11-des-moines.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1500&amp;name=img-11-des-moines.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1800&amp;name=img-11-des-moines.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>While Des Moines is 10th in the top 10 Midwestern cities, it’s had the second-highest rate of growth in net tech employment from 2010 to 2018: 26.9 percent, behind only Detroit. Des Moines is currently home to 28,693 tech workers, and from 2017 to 2018, saw a 47 percent increase in new tech job postings.&nbsp;</p></div>
<h2><span>Midwestern Companies Are Hiring Tens of Thousands of Tech Workers Right Now</span></h2>
<div><p>In Chicago, Detroit, and Indianapolis alone, there are nearly 31,000 open tech positions at any given time. The Midwest is next for tech workers. Find out more with a free download of the Midwest Salary and Cost of Living Handbook.</p></div>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-d825b188-3a7f-4d00-ac4a-1ef02e65ec84"><span id="hs-cta-d825b188-3a7f-4d00-ac4a-1ef02e65ec84"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2873777/d825b188-3a7f-4d00-ac4a-1ef02e65ec84" target="_blank"><img id="hs-cta-img-d825b188-3a7f-4d00-ac4a-1ef02e65ec84" height="709" width="1600" src="https://no-cache.hubspot.com/cta/default/2873777/d825b188-3a7f-4d00-ac4a-1ef02e65ec84.png" alt="New call-to-action"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>

<p><strong><br></strong><strong><img src="https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=120&amp;name=Christina%20headshot.png" alt="Christina headshot" width="120" srcset="https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=60&amp;name=Christina%20headshot.png 60w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=120&amp;name=Christina%20headshot.png 120w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=180&amp;name=Christina%20headshot.png 180w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=240&amp;name=Christina%20headshot.png 240w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=300&amp;name=Christina%20headshot.png 300w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=360&amp;name=Christina%20headshot.png 360w" sizes="(max-width: 120px) 100vw, 120px"></strong><em><strong>Christina Marfice</strong> is a born and raised Midwesterner who traveled the globe and came right back. She has been a journalist and freelance writer for almost ten years. In addition to her other projects, she explores startup strategies, business operations, and eCommerce topics for&nbsp;<a target="_blank" data-stringify-link="https://www.yesoptimist.com/" delay="150" data-sk="tooltip_parent" href="https://www.yesoptimist.com/" rel="noopener">Optimist</a>. She currently resides in Chicago with her two cats, Dumpling and Doughnut.</em></p></span>
</p>

</div></div>]]>
            </description>
            <link>https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698449</guid>
            <pubDate>Tue, 06 Oct 2020 15:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy to K8s without YAML using ShuttleOps]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24698326">thread link</a>) | @gscho
<br/>
October 6, 2020 | https://go.shuttleops.io/no-code-docker-kubernetes | <a href="https://web.archive.org/web/*/https://go.shuttleops.io/no-code-docker-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<p><span id="hs_cos_wrapper_module_159802898093264_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><h2><span>See How No-Code </span><span id="5f0fb456-fdf5-4e5b-993a-ec7087c62a86" data-renderer-mark="true" data-mark-type="annotation" data-mark-annotation-type="inlineComment" data-id="5f0fb456-fdf5-4e5b-993a-ec7087c62a86">Continuous Delivery<br></span><span>&nbsp;Can Accelerate Your Business</span></h2>
<h5>The same powerful drag-and-drop interface, true multicloud integration and security and compliance you’ve come to expect from ShuttleOps, now with Docker and Kubernetes support. See how easy it is to onboard your application, your team, and scale your delivery. Get started today for free. No credit card required!&nbsp;</h5>

<p><span><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-fcb53eb1-7328-44f8-b128-f953ffc8bab9"><span id="hs-cta-fcb53eb1-7328-44f8-b128-f953ffc8bab9"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/5669359/fcb53eb1-7328-44f8-b128-f953ffc8bab9"><img id="hs-cta-img-fcb53eb1-7328-44f8-b128-f953ffc8bab9" src="https://no-cache.hubspot.com/cta/default/5669359/fcb53eb1-7328-44f8-b128-f953ffc8bab9.png" alt="Get Started"></a></span></span><!-- end HubSpot Call-to-Action Code --></span></p></span></p>

</div><!--end widget-span -->
</div><!--end row-->
</div></div>]]>
            </description>
            <link>https://go.shuttleops.io/no-code-docker-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698326</guid>
            <pubDate>Tue, 06 Oct 2020 14:58:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FLoWS, a functional language for Time Series Analytics]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24697875">thread link</a>) | @MorganeR
<br/>
October 6, 2020 | https://blog.senx.io/introducing-flows/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/introducing-flows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Discover FLoWS the functional lineage of WarpScript. FLoWS brings enormous value during the first steps with Warp 10. It makes the more than a thousand WarpLib functions available without having to adapt to a syntax new to many.</p><article>
      
<p>The Warp 10 Time Series Platform offers a rich analytics environment which makes it the most advanced platform of its kind. This environment relies on a library (<em>WarpLib</em>) of <strong>over 1000 functions</strong> and a concatenative language called WarpScript.</p>



<p>WarpScript is really powerful and concise. But it has proved challenging to learn for people not familiar with languages of its kind such as <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)" target="_blank" rel="noreferrer noopener">FORTH</a>, <a href="https://en.wikipedia.org/wiki/PostScript" target="_blank" rel="noreferrer noopener">PostScript</a>, or <a href="https://en.wikipedia.org/wiki/RPL_(programming_language)" target="_blank" rel="noreferrer noopener">RPL</a>.</p>



<p>The most difficult part of learning WarpScript was reported as being the mental gymnastics required to visualize the parameters and results of function calls.</p>



<p><strong>Well, this hard time is over. </strong>As we announced in July during the last <a href="https://www.ptsm.io/#ptsm-5" target="_blank" rel="noreferrer noopener">Paris Time Series Meetup</a> before the summer break, we are introducing a companion language to WarpScript which makes those challenges disappear. </p>



<p>We called this language <em>FLoWS</em>, for <em><strong>F</strong>unctional <strong>L</strong>ineage <strong>o</strong>f <strong>W</strong>arp<strong>S</strong>cript</em>. </p>



<p><strong>It is a purely functional language, fully compatible with WarpScript.</strong> And it meant to leverage the whole of WarpLib without the steep learning curve.</p>



<p>You can use FLoWS wherever WarpScript can, including in the various tools with which WarpScript is integrated, such as Spark, <a href="https://blog.senx.io/leveraging-warpscript-from-pig-to-analyze-your-time-series/" target="_blank" rel="noreferrer noopener">Pig</a>, Flink, <a href="https://blog.senx.io/warpscript-loves-kafka-streams/" target="_blank" rel="noreferrer noopener">Kafka Streams</a>, NiFi, and many others.</p>



<p>This article will introduce you to the syntax of FLoWS. You will be able to quickly put it to work to solve your Time Series problems.</p>



<h2>FLoWS 101</h2>



<p>The syntax of FLoWS is easy to grasp, all there is to know about FLoWS fits on the rest of this page.</p>



<h3>Comments</h3>



<p>FloWS supports <code>C</code> and <code>C++</code> style comments.</p>



<pre><code>// C++ Style comments
/* 
C-Style comments
*/</code></pre>



<h3>Supported types</h3>



<p>FLoWS supports <code>LONG</code>s and <code>DOUBLE</code>s.</p>



<pre><code>42 		// LONG
3.14 		// DOUBLE
1.0E-12		// DOUBLE</code></pre>



<p><code>BOOLEAN</code>s are also supported.</p>



<pre><code>true  // Not False
false // Not True</code></pre>



<p>Percent encoded <code>STRING</code>s using UTF-8 are enclosed in single or double quotes.</p>



<pre><code>'Hello'
"%F0%9F%96%96"	// 🖖
'Multiline
Strings'</code></pre>



<p>Lists are comma separated expressions enclosed in square brackets.</p>



<pre><code>[ 'Hello', 3.1415, 42 ]
[ 'Hello', 3.1415, 
  42	// Works on multiple lines too
]</code></pre>



<p>Maps are comma separated <em>key</em>:<em>value</em> pairs enclosed in curly braces.</p>



<pre><code>{ 'A':65, '@':64, 64:'@' }
{ '@':64, 64:'@',
  'A':65  // Works on multiple lines too
}</code></pre>



<p>Accessing list and map elements is done using an intuitive syntax.</p>



<pre><code>map['A']  // 65
map[64]   // '@'
list[0]   // 'Hello'</code></pre>



<h3>Operators</h3>



<p>Simple left to right precedence with optional parentheses grouping.<br>Binary operators: <code>+</code>, <code>+!</code>, <code>|</code>, <code>-</code>, <code>**</code>, <code>*</code>, <code>/</code>, <code>%</code>.<br>Comparison and logical operators: <code>&gt;</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>==</code>, <code>!=</code>, <code>~=</code>, <code>&amp;&amp;</code>, <code>||</code><br>Bitwise operators: <code>&amp;</code>, <code>|</code>, <code>^</code>, <code>&gt;&gt;&gt;</code>, <code>&gt;&gt;</code>, <code>&lt;&lt;</code></p>



<pre><code>A = 5 + 3 / 2.0
X = 8 + (F(x + 1) * 3.14) - 12</code></pre>



<h3>Function calls</h3>



<p>Comma separated list of expressions as function parameters. Functions can return 0 to N values.</p>



<pre><code>F(1,2,'A',b)  // F is the function name
G()           // Parameterless function call</code></pre>



<h3>Assignments</h3>



<p>Assignments assign values to variables.</p>



<pre><code>A = 12
(x, y) = F(1)   // F MUST return two values
M[0][1] = 3.14  // Assign to list/map element</code></pre>



<h3>Macros</h3>



<p><a href="https://blog.senx.io/thinking-in-warpscript-authoring-macros/" target="_blank" rel="noreferrer noopener">Macros</a> are sequences of statements.</p>



<pre><code>M = (a,b,c) -&gt; {  // 3 parameters
  ...
}</code></pre>



<p>Macros can return 0 to N values just like functions, use <code>return</code> as last statement followed by a comma separated list of values to return.</p>



<pre><code>M = (a,b,c) -&gt; {  // 3 parameters
  return F(a,b), G(c)
}</code></pre>



<p>Expected number of return values can be enforced.</p>



<pre><code>M = (a,b,c) -&gt; 2 {  // MUST return 2 values
  return F(a,b), G(c)
}</code></pre>



<p>You can call macros like functions, with a comma separated list of expressions as parameters. Macro name is prefixed with <code>@</code> like in WarpScript.</p>



<pre><code>@M(1,2,3)
(x,y) = @M(1,2,3)  // Assign return values</code></pre>



<p>When using variables in macros you can either use the name of the variable, <em>e.g.</em> <code>A</code>, the variable will be replaced by its value at the time of the execution, or use the name suffixed with <code>!</code> to use the value of the variable at the time of the macro definition.</p>



<h2>Using FLoWS</h2>



<p>FLoWS comes as a WarpScript extension. The extension adds two functions, <code>FLOWS</code> to execute FLoWS code and <code>FLOWS-&gt;</code> to convert FLoWS code to its WarpScript counterpart.</p>



<p>In order to execute FLoWS code from WarpScript simply call FLOWS with a STRING parameter containing the FLoWS code to run. The result of this execution, including the modified or newly set variables, will be available to the enclosing WarpScript code.</p>



<p>The example below demonstrates this:</p>



<pre><code>42 'B' STORE
&lt;'
  // This is FLoWS code using variable B
  // defined in the WarpScript code above
  A = B + 1
'&gt;
FLOWS
// We use variable A defined in the FLoWS code
$A</code></pre>



<p>All of the WarpLib functions are available to FLoWS, the example below will create a Geo Time Series and add values to it, all using the <code><a href="https://warp10.io/doc/NEWGTS" target="_blank" rel="noreferrer noopener">NEWGTS</a></code> and <code><a href="https://warp10.io/doc/ADDVALUE" target="_blank" rel="noreferrer noopener">ADDVALUE</a></code> functions.</p>



<pre><code>&lt;'
  GTS = NEWGTS()
  ADDVALUE(GTS, 0, NaN, NaN, NaN, 1)
  ADDVALUE(GTS, 1, 48.0, -4.5, NaN, 2)
'&gt;
FLOWS
$GTS</code></pre>



<p>The <code>FLOWS</code> function executes the FLoWS code in the calling execution environment. This execution is performed directly without an intermediate transpilation to WarpScript. Nevertheless, if you are curious or if you need to in some specific context, you can generate WarpScript code which will perform the exact same steps as your FLoWS code by calling <code>FLOWS-&gt;</code>.</p>



<p>The generated WarpScript code contains a lot of additional code to enforce parameters and return values checks. As an example, the latter example will transpile to the following WarpScript version:</p>



<pre><code>&lt;%
  // Assignment #0
  'L1:2-1:15' SECTION
  NULL HIDE '# 0' STORE
    // NEWGTS(...)
    'L1:8-1:15' SECTION
    NULL HIDE '# 1' STORE
      NEWGTS
      1 FLOWS.ASSERTDEPTH
    '# 1' DUP LOAD SHOW FORGET
    1 FLOWS.ASSERTDEPTH
    'GTS' STORE
  '# 0' DUP LOAD SHOW FORGET
  // ADDVALUE(...)
  'L2:2-2:35' SECTION
  NULL HIDE '# 2' STORE
    $GTS
    0
    NaN
    NaN
    NaN
    1
    ADDVALUE
    CLEAR
  '# 2' DUP LOAD SHOW FORGET
  // ADDVALUE(...)
  'L3:2-3:37' SECTION
  NULL HIDE '# 3' STORE
    $GTS
    1
    48.0
    -4.5
    NaN
    2
    ADDVALUE
    CLEAR
  '# 3' DUP LOAD SHOW FORGET
%&gt;</code></pre>



<p>If you run <code>EVAL</code> twice on this code, you will end up with the exact same result as its FLoWS counterpart, except more operations, roughly 80, will be performed.</p>



<p>As a comparison, the WarpScript code that you would write manually to do the same thing as the FLoWS code would execute in 16 operations vs 61 for the FLoWS version and 143 for the WarpScript version resulting from the FLoWS transpilation. The extraneous operations add a little performance overhead. Therefore the same program will be slightly slower in FLoWS compared with WarpScript, but nothing too dramatic.</p>



<h2>Availability of FLoWS</h2>



<p>FLoWS is available as a WarpScript extension on <a href="https://warpfleet.senx.io/browse/io.warp10/warp10-ext-flows" target="_blank" rel="noreferrer noopener">WarpFleet</a>. You can deploy it on any Warp 10 instance running version <a href="https://warp10.io/download" target="_blank" rel="noreferrer noopener">2.7.1</a> or above.</p>



<p>The FLoWS extension is distributed under the BSL (Business Source License), making it usable in most contexts and ensuring a license change to Apache 2.0 after a four year period.</p>



<p><strong>The <a href="https://www.warp10.io/doc/reference" target="_blank" rel="noreferrer noopener">Warp 10 documentation</a> has been updated.</strong> You now have access to FLoWS signatures in every function of the doc. Examples will follow soon.</p>



<h2>Conclusion</h2>



<p><strong>FLoWS brings enormous value during the first steps with Warp 10</strong>. It makes the more than a thousand WarpLib functions available without having to adapt to a syntax new to many.</p>



<p>We expect it will bring more people to Warp 10, some of whom will ultimately switch to WarpScript once they are accustomed with WarpLib.</p>



<p>Feel free to share FLoWS around you.</p>



<p>Join the Warp 10 community on <a href="https://lounge.warp10.io/" target="_blank" rel="noreferrer noopener">Slack</a> if you have questions or comments.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/introducing-flows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24697875</guid>
            <pubDate>Tue, 06 Oct 2020 14:18:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A unified CD solution for Kubernetes, Serverless, Infrastructure apps]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24697803">thread link</a>) | @nghialv
<br/>
October 6, 2020 | https://pipecd.dev/blog/2020/10/06/announcing-pipecd/ | <a href="https://web.archive.org/web/*/https://pipecd.dev/blog/2020/10/06/announcing-pipecd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>Continuous Delivery for declarative Kubernetes, Serverless and Infrastructure applications</p>
	
	
	<p>Today we are excited to announce the open-source availability of PipeCD: a continuous delivery system for declarative Kubernetes, Serverless, and Infrastructure applications.
PipeCD aims to provide a unified CD solution for multiple application kinds on multi-cloud that empowers engineers to deploy faster with more confidence.
It is also available as a GitOps tool that enables doing deployment operations by pull request on Git.</p>

<p><img src="https://pipecd.dev/images/deployment-details.png" alt=""></p>
<p>
Deployment Details Page
</p>
<br>
<h3 id="background">Background</h3>
<p>As one of our Developer Productivity team’s missions, we aim to empower engineers to deploy their services faster, more frequently with reliability.
Martin Fowler, in his book <em>Continuous Delivery</em>, points out that “The biggest risk to any software effort is that you end up building something that isn’t useful. The earlier and more frequently you get working software in front of real users, the quicker you get feedback to find out how valuable it really is.”</p>
<p>Recently, with the popularity of cloud services and the container technology, engineers have even more options in choosing the infrastructure model, the cloud services, which are most suitable for their team’s requirements.
At <a href="https://www.cyberagent.co.jp/en/">CyberAgent</a>, we have a large number of services from many teams where each team can have a different infrastructure model and a different cloud service. Some big projects also deploy their services on multi-cloud.
This diversification leads to a problem that we are facing, lacking a robust CD system for all teams.</p>
<p>So we decided to create a new CD system that provides a unified interface for many application kinds to improve the developer experience.</p>
<h3 id="key-features">Key Features</h3>
<p>While designing PipeCD, we focused on the following <a href="https://pipecd.dev/">4 key features</a> with the aim of creating a CD system that provides a good experience for both developers and operators.</p>
<p><strong>Visibility</strong></p>
<p>Visibility is one of the most requested factors we received when surveying engineers in our company.
Visibility is the ability to see what’s going on in the cluster, the ability to see how each component of the application had been deployed, the ability to know quickly why the deployment was failed.
Visibility for a team leader is the ability to know the delivery performance of the team and what metrics should be improved.
With PipeCD, we always strive to maximize the visibility for engineers, operators as well as team leaders. Currently, it includes:</p>
<ul>
<li>Deployment pipeline UI shows clarify what is happening</li>
<li>Separate logs viewer for each individual deployment</li>
<li>Realtime visualization of application component and state</li>
<li>Deployment notifications to slack, webhook endpoints</li>
<li>Insights show the delivery performance</li>
</ul>
<p>In addition, the entire state of the service is managed through Git, so you can view the whole state of the cluster and all audit logs provided by Git.</p>
<p><strong>Automation</strong></p>
<p>Automation reduces or removes repetitive overhead of frequent releases. So maximizing automation helps to minimize human error during the deployment process, as well as reduce the amount of work engineers need to do.
PipeCD has the following automated functionalities:</p>
<ul>
<li>Automated deployment analysis based on metrics, logs, emitted requests</li>
<li>Automatically roll back to the previous state as soon as analysis or a pipeline stage fails</li>
<li>Automatically detect configuration drift to notify and render the changes</li>
<li>Automatically watch and detect the new container images to deploy</li>
</ul>
<p><strong>Secure</strong></p>
<p>The CD system often carries a lot of credentials needed to access the cluster and the necessary services of the teams.
Ensuring the safety of the teams is always on our top priority.
So while designing the PipeCD, we decided not to store those credentials in a central place. Instead of that, all user’s credentials always stay inside their clusters.</p>
<ul>
<li>Support single sign-on and role-based access control</li>
<li>Credentials are not exposed outside the cluster and not saved in the control-plane</li>
<li>Piped makes only outbound requests and can run inside a restricted network</li>
</ul>
<p><strong>Multi-provider &amp; Multi-Tenancy</strong></p>
<p>Multi-provider means supporting multiple cloud services, multiple container registries, multiple monitoring services for doing deployment analysis.
You can use PipeCD to deploy your Kubernetes applications, CloudRun, AWS Lambda application and Terraform application.
It also supports doing progressive delivery with canary and bluegreen strategy.</p>
<ul>
<li>Easy to operate multi-cluster, multi-tenancy by separating control-plane and piped</li>
<li>Support multiple analysis providers including Prometheus, Datadog, Stackdriver, and more</li>
<li>Support multiple application kinds on multi-cloud including Kubernetes, Terraform, Cloud Run, AWS Lambda</li>
</ul>

<p>While designing PipeCD, we simplified its architecture by minimizing the number of components, so you do not have to install many things to enable all features.
In addition, PipeCD also supports storing data in several fully-managed services to minimize the operating cost.</p>
<p>Currently, we have completed the basic features and many of the features are in the alpha status. We are working hard to increase the stability and planning to release a stable version in the next months.</p>

<p>PipeCD team hopes to receive a warm welcome and feedback from the open-source community.
We value every contribution and invite you to join us on GitHub, Slack and Twitter.</p>
<ul>
<li>Visit our website and documentation at <a href="https://pipecd.dev/">https://pipecd.dev</a></li>
<li>Check out the code at <a href="https://github.com/pipe-cd/pipe">https://github.com/pipe-cd/pipe</a> or explore the <a href="https://pipecd.dev/docs/examples/">examples</a></li>
<li>Join us on Slack <a href="https://cloud-native.slack.com/archives/C01B27F9T0X">@cloud-native/pipecd</a> to chat with other developers</li>
<li>Follow us on Twitter <a href="https://twitter.com/pipecd_dev">@pipecd_dev</a> to get the latest news</li>
</ul>
<p>PipeCD team is hiring engineers/interns to work on PipeCD. Please contact us if you are interested.</p>
<h3 id="thanks">Thanks</h3>
<p>Finally, we would like to thank the existing open-source CD projects like Spinnaker, FluxCD, ArgoCD… PipeCD has been built on many great ideas from those great projects.
PipeCD team would also like to thank CyberAgent’s engineers and collaborators from other companies, who have sent us so many valuable feedback throughout the development process to this day.</p>

	

	

</div></div>]]>
            </description>
            <link>https://pipecd.dev/blog/2020/10/06/announcing-pipecd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24697803</guid>
            <pubDate>Tue, 06 Oct 2020 14:11:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4x4 Macro Pad Kit]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24697624">thread link</a>) | @0xC45
<br/>
October 6, 2020 | https://0xc45.com/blog/4x4-macro-pad/ | <a href="https://web.archive.org/web/*/https://0xc45.com/blog/4x4-macro-pad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        
    </header>
    <p>10/6/2020</p>
    <h2>Contents</h2>
    <ul>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#overview">Overview</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#build-process">Build Process</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#flash-firmware">Flash Firmware</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#design-keycaps">Design Keycaps</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#conclusion">Conclusion</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#links">Links</a>
            
        </li>
        
    </ul>
    <section>
<h2 id="overview">Overview</h2>
<p>Last weekend, I built a 4x4 keyboard kit. By this point, many people are familiar with the growing (and outspoken) mechanical keyboard hobbyist community. However, this kit is a bit unique. It's not a full keyboard. Instead, it's a 4x4 "macro pad" intended for sending keyboard shortcut sequences such as muting my microphone, muting my audio, volume up, volume down, etc. Additionally, with some extra software such as AutoHotKey, vastly complex programs could be triggered with the press of a button.</p>
<h2 id="build-process">Build Process</h2>
<p>Overall, building the macro pad was a simple and straightforward process. The <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">kit's build guide</a> provides a nice set of instructions with pictures to explain things. However, unlike many (some?) keyboard kits, the Sweet 16 kit requires soldering a few smaller components, such as the diodes and microcontroller headers. Additionally, the kit requires soldering one "surface-mount" component, the reset switch.</p>
<p>The parts:
<img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-parts.jpg" alt="Sweet16 Parts"></p>
<p>Completed build:
<img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-solder-joints.jpg" alt="Sweet16 Solder Joints"></p>
<h2 id="flash-firmware">Flash Firmware</h2>
<p>To program my custom keymap (including multiple keypress macros), I used <a href="https://qmk.fm/">QMK firmware</a>, the most popular keyboard firmware project.</p>
<p>Using QMK, it's possible to create custom keycodes that, when pressed, trigger a sequence of inputs. So, by pressing one button on the macro pad (or keyboard), the firmware will submit an entire sequence of keycode presses.</p>
<p>To do this, I defined my custom keycodes in an enum:</p>
<pre><code><span>enum </span><span>macro_keycodes {
  MICMUTE = SAFE_RANGE,
  MACRO1,
  MACRO2,
  MACRO3,
  MACRO4,
  MACRO5,
  MACRO6,
  MACRO7,
  MACRO8
};
</span></code></pre>
<p>Next, I defined a "keymap" array. Each position in the array corresponds to a single button on the 4x4 macro pad:</p>
<pre><code><span>const </span><span>uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = {
  [</span><span>0</span><span>] = </span><span>LAYOUT_ortho_4x4</span><span>( </span><span>/* Base */</span><span>
    MICMUTE, KC_MUTE, KC_VOLD, KC_VOLU,
    XXXXXXX, XXXXXXX, XXXXXXX, XXXXXXX,
    MACRO1,  MACRO2,  MACRO3,  MACRO4,
    MACRO5,  MACRO6,  MACRO7,  MACRO8
  ),
};
</span></code></pre>
<p>Lastly, I implemented the <code>process_record_user</code> function to define what should happen when each custom keycode is pressed:</p>
<pre><code><span>bool </span><span>process_record_user</span><span>(uint16_t </span><span>keycode</span><span>, keyrecord_t *</span><span>record</span><span>) {
  </span><span>switch </span><span>(keycode) {
  </span><span>case</span><span> MICMUTE:
    </span><span>if </span><span>(record-&gt;event.</span><span>pressed</span><span>) {
      </span><span>SEND_STRING</span><span>(</span><span>SS_LCTL</span><span>(</span><span>SS_LALT</span><span>(</span><span>SS_LSFT</span><span>(</span><span>SS_TAP</span><span>(X_F10)))));
    }
    </span><span>break</span><span>;
  </span><span>case</span><span> MACRO1:
    </span><span>if </span><span>(record-&gt;event.</span><span>pressed</span><span>) {
      </span><span>SEND_STRING</span><span>(</span><span>SS_LCTL</span><span>(</span><span>SS_LALT</span><span>(</span><span>SS_LSFT</span><span>(</span><span>SS_TAP</span><span>(X_F1)))));
    }
    </span><span>break</span><span>;
  </span><span>/*
   * ... etc
   */
  </span><span>}
  </span><span>return </span><span>true
</span><span>}
</span></code></pre>
<p>As you can see, I have configured the <code>MICMUTE</code> button to send the entire sequence <code>CTRL+ALT+SHIFT+F10</code>. However, in practice, any arbitrary sequence could be sent for any button. And, that's only beginning to scratch the surface of the capabilities of the QMK firmware.</p>
<h2 id="design-keycaps">Design Keycaps</h2>
<p>For this "DIY" kit, it felt important to design my own icons. I'm no graphic designer, but it was kinda fun. To do this, I used "re-legendable" keycaps that snap together with a clear top. Then, I printed the icons on plain white paper, cut them out, and sandwiched each icon in the keycaps. Here's a photo of my efforts:</p>
<p><img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-completed.jpg" alt="Sweet16 Completed"></p>
<h2 id="conclusion">Conclusion</h2>
<p>This was a pretty quick project, but I felt like it deserved a writeup nevertheless. As a relative beginner at soldering, this kit was a fantastic way to increase my skills and ability beyond the "absolute beginner" level required for most keyboard kits. Furthermore, the final product is quite useful and extensible. Beyond the specific purpose as a simple macro pad keyboard, this hardware is essentially a microcontroller connected to a set of buttons. There are numerous possible applications. It's ripe for hacking. This device could become a MIDI controller, home automation remote, or anything else my imagination might dream up. Until next time.</p>
<h2 id="links">Links</h2>
<ol>
<li>Sweeet 16 Macro Pad Kit: <a href="https://www.1upkeyboards.com/shop/keyboard-kits/macro-pads/sweet-16-macro-pad-black/">https://www.1upkeyboards.com/shop/keyboard-kits/macro-pads/sweet-16-macro-pad-black/</a></li>
<li>QMK Firmware: <a href="https://qmk.fm/">https://qmk.fm/</a></li>
<li>My Sweet 16 Keymap: <a href="https://github.com/0xC45/qmk-firmware/blob/master/keyboards/1upkeyboards/sweet16/keymaps/0xC45/keymap.c">https://github.com/0xC45/qmk-firmware/blob/master/keyboards/1upkeyboards/sweet16/keymaps/0xC45/keymap.c</a></li>
</ol>

    </section>
</article></div>]]>
            </description>
            <link>https://0xc45.com/blog/4x4-macro-pad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24697624</guid>
            <pubDate>Tue, 06 Oct 2020 13:49:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On a Typical Day: Daniel Ek]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24697009">thread link</a>) | @tosh
<br/>
October 6, 2020 | https://www.theobservereffect.org/daniel.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/daniel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the second interview on 'The Observer Effect'. We are lucky to have one
									of the most influential founders/CEOs in technology and media - Daniel Ek, Founder
									and CEO of Spotify. This interview was published on 4th October, 2020.

							</em></p><p><em>Daniel does things very differently from other business leaders and was generous to go
								deep with us on his leadership style, time management, decision making, Spotify's impact
								on the world and much, much more. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Let’s start with the basics. Walk me through a typical day in the life of
										Daniel Ek.</strong></em>
							</p><p><strong>Daniel Ek</strong><br>
								So, this will sound incredibly lazy compared to some leaders. I wake up at around 6:30
								in the morning and spend some time with my kids and wife. At 7:30, I go work out. At
								8:30, I go for a walk – even in the winter. I’ve found this is often where I do my best
								thinking. At 9:30, I read for thirty minutes to an hour. Sometimes I read the news, but
								you’ll also find an ever-rotating stack of books in my office, next to my bed, on tables
								around the house. Books on history, leadership, biographies. It’s a pretty eclectic mix
								– much like my taste in music. Finally, my “work” day really starts at 10:30.
							</p><p>
								Many people make big decisions early on in the day, I make them later in the day--at
								least later in the day here in Europe. Ironically, it's not actually because I'm more
								productive then, rather because we have so many of our staff in the US, and as a result,
								I've kind of primed myself to work that way.
							</p><p>
								So the earlier part of my day is focused on coaching, one-on-ones, and planning. Then, I
								typically tackle one topic a day which takes a lot of my time. That's my big thing for
								the day. Before we go into a live team discussion on that particular topic, I invest
								time to prepare beforehand – reading and talking to members of the team who are either
								part of the decision-making process or who have insights and context. I sometimes even
								get external perspectives.
							</p><p>
								I also think about what my role is at that meeting. Sometimes I'm the approver. Other
								times, I'm supposed to come with a thoughtful perspective on whether an initiative makes
								sense or not.
							</p><p>
								I’ve found that creating this clarity of role for myself is critical. It’s something I
								challenge my direct reports to think about as they engage with their own teams. I remind
								them that all meetings are not the same. Even when we are meeting to discuss really,
								really complicated topics I always ask myself: “What am I going to do in this meeting?
								What does my involvement really need to be?”
							</p><p>
								The truth is: it's entirely contextual. I find it crucial to be upfront about everyone’s
								role in different meetings, I think this is super, super important. Often that's my
								number one thing: to make sure I know what role I'm playing.</p><p>
								<b><i>Wow, okay, there are multiple things in there ranging from how you choose to spend
										your time to how you handle meetings. To work backwards, what makes a good
										meeting in your mind?
									</i></b></p><p>A great meeting has three key elements: the desired outcome of the meeting is clear ahead
								of time; the various options are clear, ideally ahead of time; and the roles of the
								participants are clear at the time.
							</p><p>
								I often find that meetings lack one of those elements. Sometimes they lack all those,
								which is when you have to say, “This is a horrible meeting, let's end it and regroup so
								it can be more effective for everyone.”
							</p><p>
								To clarify outcomes, options, and roles ahead of time, we sometimes rely upon a preread.
								Prereads are a great way to share context so that attendees can quickly get into the
								meat of the issue and not waste time getting everyone up to speed. What I find is when
								you use a tool like a Google Doc, you can take in a great deal of information by reading
								comments, assessing options, and understanding how opinions have evolved over time. With
								this uniform background and context, attendees can focus on discussing the matter at
								hand versus getting on the same page. When the latter happens, the meeting becomes an
								incredible waste of time.
							</p><p>
								I think that's the single largest source of optimization for a company: the makeup of
								their meetings. To be clear, it's not about fewer meetings because meetings serve a
								purpose. Rather, it’s key to improve the meetings, themselves. A lot of my efforts focus
								on teaching people this framework. Ironically, I find that most people are just
								challenged by that stuff.
							</p><p>
								Candidly, that’s my role as leader: to coach others on how best to make use of their
								limited time. Not only is time the most precious resource the company has, it’s also the
								most precious resource they have! It’s crucial that they approach the use of their time
								with a holistic perspective. By way of example, I had a recent call with one of my
								directors who had not taken a vacation in six months. Our conversation delved into why
								this person thought that they could not be away for two weeks, and me arguing for why
								the person had to take two weeks to recharge!
							</p><p>
								There is never enough time – for work, for family and friends – and it takes work to
								make the best use of it. It's all about fostering a holistic perspective in life.

							</p><p>
								<b><i>
										That’s fascinating. Let’s turn to your team.

										Your direct reports are highly accomplished people; what are the common mistakes
										you see executives at that level make when it comes to personal time management?
									</i>
							</b></p><div>
							<div><p>
								I don’t think most executives dedicate enough time to thinking. They spend too much time
								in meetings. By the way, I will say as a caveat, I do know people who are incredibly
								organized and succeed with a lot of “do time.” Shishir Mehrotra [Co-founder and CEO of
								Coda] is a great example. If you've seen the docs on how he organizes his time...
								</p><p>

								<b><i>Oh yeah, he has a lot of very well-organized docs! [laughs]</i></b></p></div><p>
								He is a source of inspiration. For a while, I tried to mimic his style because I was so
								impressed with his thinking behind it. But in the end, it just wasn’t for me. It
								actually drove me nuts. <i>[Sriram laughs]</i>
								But I respect him. I would say he's a highly effective executive. His system works for
								him. It's not one size fits all. Some of my direct reports thrive on lots of meetings.
								But, in general, I would say the largest mistake is that they conflate meetings with
								productivity. Often fewer meetings and better decisions drive the business forward.

							</p>
							<h2 id="opencalendar"><b>On Creating an Open Calendar</b></h2>
							<p>


								<b><i>This dovetails nicely with something that fascinates many of your colleagues: how
										do you have so much open time on your calendar?

										This drastically differs from your typical “successful CEO” who is booked from
										8:30am to 6pm. Walk us through your calendar and how you manage to create this
										open space.
									</i></b>

							</p>

							<p>

								My friends know me well! I do keep a lot of open time. I understand this comes from a
								place of privilege and I’m very lucky to have this flexibility.
							</p>
							<p>

								I feel like synchronous time is very costly; asynchronous time is better. I know there
								are some leaders who prefer to have all executive decisions travel through them. But
								then, you have to wait until the leader has availability to review things. Sometimes you
								run into delays in that process.
							</p>
							<p>
								I typically don't have more than really three or four meetings per day. There are
								exceptions; when I travel, I book in a lot more and I don't keep to my normal schedule.
								That said, most of the time it's three or four meetings a day.

							</p>
							<p>
								My way is to plan long term and do so ahead of time so that people better understand the
								direction in which they're going. You have to be incredibly crisp and clear when doing
								that. For instance, right now we're finalizing our five year plans and long range
								planning. These are actual, real targets fueled by real insights. They are made up of
								lots of super-detailed quarterly and annual goals. I don’t spend much time on the
								quarterly goals and instead focus on our so-called “big rocks.”
							</p>


							<h2 id="bets"><b>On Company Bets</b></h2>
							<p>
								At Spotify, we have something called “Company Bets.” These are large-scale initiatives
								that we believe will have a significant impact on the business within a relatively short
								period of time. I find that these bets are a much better use of my time. Our Company
								Bets typically update every six months, so I'm not needed that much in between. This
								way, I can constantly be thinking: “Where are we headed in the next six months?” Right
								now, I am thinking more about H2 2021. From a timeline perspective, that's the earliest
								place where I focus most of my time.
							</p>
							<p>
								It’s also my role to think far beyond that. For instance, I’m immersing myself in our
								2025 plans. I trust my team to manage the day-to-day, shorter-term initiatives and
								iterate as needed based on data and insights. They’re the best at that and I appreciate
								that this then frees me up to think about the long term.
							</p>

							<h2 id="decisionmaking"><b>On Delegated Decision Making<br></b></h2>
							<p>
								<b><i>
										Your system reminds me of Jack [Dorsey] at Twitter a …</i></b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/daniel.html">https://www.theobservereffect.org/daniel.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/daniel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24697009</guid>
            <pubDate>Tue, 06 Oct 2020 12:32:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyclone Scheme]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24696939">thread link</a>) | @andrenth
<br/>
October 6, 2020 | https://justinethier.github.io/cyclone/ | <a href="https://web.archive.org/web/*/https://justinethier.github.io/cyclone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
      <p>Cyclone Scheme is a brand-new compiler that allows real-world application development using the R<sup>7</sup>RS Scheme Language standard. We provide modern features and a stable system capable of generating fast native binaries.</p>

<p><a href="https://github.com/justinethier/cyclone/raw/master/docs/research-papers/CheneyMTA.pdf">Cheney on the MTA</a> is used by Cyclone’s runtime to implement full tail recursion, continuations, and generational garbage collection. In addition, the Cheney on the MTA concept has been extended to allow execution of multiple native threads. An on-the-fly garbage collector is used to manage the second-generation heap and perform major collections without “stopping the world”.</p>



<ul>
  <li>Support for the majority of the Scheme language as specified by the latest <a href="https://justinethier.github.io/cyclone/docs/Scheme-Language-Compliance.html">R<sup>7</sup>RS standard</a>.</li>
  <li>New features from R<sup>7</sup>RS including libraries, exceptions, and record types.</li>
  <li>Built-in support for Unicode strings and characters.</li>
  <li>Hygienic macros based on <code>syntax-rules</code></li>
  <li>Low-level explicit renaming macros</li>
  <li>Guaranteed tail call optimizations</li>
  <li>Native multithreading support</li>
  <li>A foreign function interface that allows easy integration with C</li>
  <li>A concurrent, generational garbage collector based on Cheney on the MTA</li>
  <li>Includes an optimizing Scheme-to-C compiler,</li>
  <li>… as well as an interpreter for debugging</li>
  <li>A <a href="https://github.com/cyclone-scheme/cyclone-winds">Package Manager</a> and a growing list of packages.</li>
  <li>Support for <a href="https://justinethier.github.io/cyclone/docs/API.html#srfi-libraries">many popular SRFI’s</a></li>
  <li>Online user manual and API documentation</li>
  <li>Support for Linux, Windows, FreeBSD, and Mac platforms.</li>
  <li>Known to run on x86-64, x86, and Arm (Raspberry Pi) architectures.</li>
</ul>



<p>There are several options available for installing Cyclone:</p>

<h2 id="docker">Docker</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/docker-thumb.png" alt="Docker" title="Docker"></p>

<p>Cyclone can be run from a <a href="https://hub.docker.com/r/cyclonescm/cyclone">Docker Image</a>:</p>

<div><div><pre><code>docker run -it cyclonescm/cyclone bash
</code></pre></div></div>

<h2 id="homebrew">Homebrew</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/homebrew-thumb.png" alt="Homebrew" title="Homebrew"></p>

<p>Mac (and Linux!) users wanting to use Homebrew can do the following.</p>

<p>Note if Homebrew is not already installed: follow the instructions at <a href="https://brew.sh/">https://brew.sh/</a> to install the homebrew package manager.</p>

<div><div><pre><code>brew tap cyclone-scheme/cyclone
brew install cyclone-scheme/cyclone/cyclone-bootstrap
</code></pre></div></div>

<h2 id="arch-linux">Arch Linux</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/arch-linux-thumb.png" alt="Arch Linux" title="Arch Linux"></p>

<p>Arch Linux users can install using the <a href="https://aur.archlinux.org/packages/cyclone-scheme/">AUR</a>:</p>

<div><div><pre><code>git clone https://aur.archlinux.org/cyclone-scheme.git
cd cyclone-scheme
makepkg -si
</code></pre></div></div>

<h2 id="build-from-source">Build from Source</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/build-thumb.png" alt="Build from Source" title="Build from Source"></p>

<p>To install Cyclone on your machine for the first time on Linux, Windows, FreeBSD, and for Mac users wanting to install without using Homebrew, use <a href="https://github.com/justinethier/cyclone-bootstrap"><strong>cyclone-bootstrap</strong></a> to build a set of binaries. Instructions are provided for Linux, Mac, Windows (via MSYS), and FreeBSD 12.</p>



<p>After installing you can run the <code>cyclone</code> command to compile a single Scheme file:</p>

<div><div><pre><code>$ cyclone examples/fac.scm
$ examples/fac
3628800
</code></pre></div></div>

<p>And the <code>icyc</code> command to start an interactive interpreter. Note you can use <a href="http://linux.die.net/man/1/rlwrap"><code>rlwrap</code></a> to make the interpreter more friendly, EG: <code>rlwrap icyc</code>:</p>

<div><div><pre><code>$ icyc

              :@
            @@@
          @@@@:
        `@@@@@+
       .@@@+@@@      
       @@     @@     Cyclone Scheme-&gt;C compiler
      ,@             http://justinethier.github.io/cyclone/
      '@
      .@
       @@     #@     (c) 2014-2019 Justin Ethier
       `@@@#@@@.     Version 0.11
        #@@@@@
        +@@@+
        @@#
      `@.
   
cyclone&gt; (write 'hello-world)
hello-world
</code></pre></div></div>

<p>Read the documentation below for more information on how to use Cyclone.</p>



<p><img src="https://justinethier.github.io/cyclone/docs/images/cyclone-winds-small.png" alt="Cyclone Winds" title="Cyclone Winds"></p>

<p>The <code>cyclone-winds</code> package manager provides the ability to install packaged libraries and programs for Cyclone. See the <a href="https://github.com/cyclone-scheme/cyclone-winds#cyclone-winds">cyclone-winds</a> site for more information.</p>



<ul>
  <li>
    <p>The <a href="https://justinethier.github.io/cyclone/docs/User-Manual">User Manual</a> covers in detail how to use Cyclone and provides information on the Scheme language features implemented by Cyclone.</p>
  </li>
  <li>
    <p>An <a href="https://justinethier.github.io/cyclone/docs/API">API Reference</a> is available for all libraries provided by Cyclone, including a complete alphabetical listing.</p>
  </li>
  <li>
    <p>If you need a resource to start learning the Scheme language you may want to try a classic textbook such as <a href="https://mitpress.mit.edu/sicp/full-text/book/book.html">Structure and Interpretation of Computer Programs</a>.</p>
  </li>
  <li>
    <p>Finally, this <a href="http://ecraven.github.io/r7rs-benchmarks/benchmark.html">benchmarks</a> page by <a href="https://github.com/ecraven">ecraven</a> compares the performance of Cyclone with other Schemes.</p>
  </li>
</ul>



<p>Cyclone provides several example programs, including:</p>

<ul>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/tail-call-optimization.scm">Tail Call Optimization</a> - A simple example of Scheme tail call optimization; this program runs forever, calling into two mutually recursive functions.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/threading">Threading</a> - Various examples of multi-threaded programs.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/game-of-life">Game of Life</a> - The <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s game of life</a> example program and libraries from R<sup>7</sup>RS.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/game-of-life-png">Game of Life PNG Image Generator</a> - A modified version of game of life that uses libpng to create an image of each iteration instead of writing it to console. This example also demonstrates basic usage of the C Foreign Function Interface (FFI).</p>
  </li>
  <li>
    <p>Finally, the largest program is the compiler itself. Most of the code is contained in a series of libraries which are used by <a href="https://github.com/justinethier/cyclone/blob/master/cyclone.scm"><code>cyclone.scm</code></a> and <a href="https://github.com/justinethier/cyclone/blob/master/icyc.scm"><code>icyc.scm</code></a> to create executables for Cyclone’s compiler and interpreter.</p>
  </li>
</ul>



<ul>
  <li>
    <p><a href="https://justinethier.github.io/cyclone/docs/Writing-the-Cyclone-Scheme-Compiler-Revised-2017">Writing the Cyclone Scheme Compiler</a> provides high-level details on how the compiler was written and how it works.</p>
  </li>
  <li>
    <p>There is a <a href="https://justinethier.github.io/cyclone/docs/Development">Development Guide</a> with instructions for common tasks when hacking on the compiler itself.</p>
  </li>
  <li>
    <p>Cyclone’s <a href="https://justinethier.github.io/cyclone/docs/Garbage-Collector">Garbage Collector</a> is documented at a high-level. This document includes details on extending Cheney on the MTA to support multiple stacks and fusing that approach with a tri-color marking collector.</p>
  </li>
  <li>
    <p>The garbage collector was subsequently enhanced to support <a href="https://justinethier.github.io/cyclone/docs/Garbage-Collection-Using-Lazy-Sweeping">Lazy Sweeping</a> which improves performance for a wide range of applications.</p>
  </li>
</ul>



<p>Copyright (C) 2014 <a href="http://github.com/justinethier">Justin Ethier</a>.</p>

<p>Cyclone is available under the <a href="http://www.opensource.org/licenses/mit-license.php">MIT license</a>.</p>

            <h2>Recent News</h2>
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/09/17/Released-Cyclone-Scheme-0.21.html">Released Cyclone Scheme 0.21</a>
        </h4>
        <span>September 17, 2020</span>
        <br>
        Various bug fixes and continuous integration support for FreeBSD.
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/08/14/Released-Cyclone-Scheme-0.20.html">Released Cyclone Scheme 0.20</a>
        </h4>
        <span>August 14, 2020</span>
        <br>
        We now have official support for calling Scheme from C.
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/08/03/Released-Cyclone-Scheme-0.19.html">Released Cyclone Scheme 0.19</a>
        </h4>
        <span>August  3, 2020</span>
        <br>
        This release improves error reporting and includes many bug fixes.
      


      </section>
    </div></div>]]>
            </description>
            <link>https://justinethier.github.io/cyclone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24696939</guid>
            <pubDate>Tue, 06 Oct 2020 12:23:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I am building permapeople.org]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 141 (<a href="https://news.ycombinator.com/item?id=24696688">thread link</a>) | @roboben
<br/>
October 6, 2020 | https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/why-permapeople.jpg" alt="Two potatoes in an Ikea bag"></p>

<p>Four years ago my grandfather gave me two potatoes. I had no idea what to do, so I put them in bought soil in a big blue Ikea bag on the balcony and with a bit watering, they turned out great and I got hooked on growing food for my family and me. It is really magical if you think of how much you spare our planet with growing your own food: You need to get a job to make money so that you can spend that money on buying food which was produced and delivered close to you by large, complex and very inefficient industries. This system spends incredible amounts of resources (time, energy, labor) which you can save by simply growing your own food. And it doesn’t stop with food only: People grow plants for medicinal uses, to help the nature and wildlife around them, or just for their own pleasure.</p>

<h2 id="the-problem">The Problem</h2>

<p>This season I really tried to scale up and created raised beds all over our small urban plot in Berlin, Germany. I wanted to do it sustainable and close to nature, so I read Toby Hemenway’s Gaia’s Garden, which is probably the most widely read book on permaculture. While it is a good base to start and there are a lot of resources around online, it is actually pretty hard to make all that info useful for my own garden. Most of the time I found myself random googling just to answer simple questions like</p>

<ul>
  <li>What plants in the herb layer are available in my zone?</li>
  <li>What are the best companion plants for Tomatoes?</li>
  <li>What is the best time to sow peas in the garden in my zone?</li>
</ul>

<p>I fell back to having a spreadsheet, a collection of browser bookmarks, and a few books to look up what plants I can grow and how they could fit together in my garden. This took me a lot of time, I’d rather spend in the garden.
After the garden was planned, the next challenge was where to find seeds, seedlings and plants to start the garden. Mostly I googled the plant name I wanted to buy and ordered in whatever shop came up but it would be so much easier to buy it directly from other fellow gardeners.
The season started and another thing I did was writing a diary of all my garden activities. The idea was to learn from past mistakes to grow better next year. It worked well for me but true learning comes from sharing experiences with others, which was not possible with that.
While this worked for this year, I wanted to have something better next year so I started building a platform around all these topics.</p>

<h2 id="a-platform-for-everyone">A Platform for Everyone</h2>

<p>Most of the resources about growing plants you find online are either anecdotal or very scientific. There is no place where a gardening enthusiast can share their experiences, see what other enthusiasts learned already, and collaborate on everything related to growing plants. I think to achieve that, we need:</p>

<p>A <strong>permaculture plant database</strong> which everyone can search easily by common permaculture plant attributes like Layer, preferred light and soil conditions, times when to plant and harvest and benefits for animals, human and the environment. In addition everyone can look up advanced topics like companion planting and guild design. To make this info useful, it needs to be verified by others through ratings, comments and linked sources. If someone could see that most people were successful with growing that specific variety of a plant in your area or that a certain guild really works for a lot of others, that would be a huge help for everyone.</p>

<p>A <strong>permaculture marketplace</strong> where people can share/trade/buy/sell seeds, plants and everything else they might need like equipment, books, courses. Others can use it to sell products from their permaculture gardens to make an income for themselves. Everything happens directly between fellow gardeners.</p>

<p>A <strong>permaculture garden log and planner</strong> where everyone can log their past garden activities, learn from each other and plan their next season or project. If this info is combined with all other gardeners, then it becomes citizen science and we can improve everyone’s gardening results. Imagine you could be notified when all the more advanced gardeners start their tomato seedlings in your area, so you could do that too.</p>

<h2 id="make-the-planet-a-better-place-for-real">Make the planet a better place (for real)</h2>

<p>There are many people who want to grow plants for many reasons but don’t know how. There are also many people already growing a few plants in their garden and learned it the hard way. I believe we need a platform where they can come together and share their experiences and learn from one another to help improve the life of eveveryone. If we would all start growing a bit of our own food, we could help the planet and ourselves in so many impactful ways.</p>

<p>There is a lot to write about the implications of having such a platform, which I will do in future posts.</p>

<p>In the meantime, you can check out the plant database <a href="https://permapeople.org/database">here</a> and if you are interested, either <a href="https://permapeople.org/users/sign_up">sign up</a>, write me an email to hello at permapeople org or sign up for the newsletter where I am posting regular updates.</p>

<p>Thanks for reading 🌱✌️,</p>

<p>ben</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24696688</guid>
            <pubDate>Tue, 06 Oct 2020 11:42:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop blaming spreadsheets (and take a good look in the mirror)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24696283">thread link</a>) | @Foe
<br/>
October 6, 2020 | https://www.felienne.com/archives/3355 | <a href="https://web.archive.org/web/*/https://www.felienne.com/archives/3355">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">

   <!-- end of header -->

<div id="main-content-wrapper">
<div id="main-content">
<div id="content">
<div>
  <div>
    <p>
      
      <span>May 28, 2014</span>
    </p>
    
<p>This week, spreadsheets hit the news again, when data for a book written by economist Pikkety turned out to contain&nbsp;<a href="http://www.slate.com/blogs/moneybox/2014/05/23/financial_times_on_piketty_his_data_is_wrong.html">spreadsheet errors</a>. On this, Daniele Lemire wrote a blog post warning people&nbsp;<a href="http://lemire.me/blog/archives/2014/05/23/you-shouldnt-use-a-spreadsheet-for-important-work-i-mean-it/">not to use spreadsheets for serious work</a>. This is useless advice, let me explain why.</p>
<p><strong>1) Only a fool blames their&nbsp;tool</strong></p>
<p>Heathcare.gov is built in Java. Did people go around the interwebs shouting&nbsp;we all should stop using Java? Of course not! Because it is easy to see that the problems stemmed from other areas: process, time pressure, lack of testing and other (human) factors probably. See how silly it is to blame a tool? The same goes for spreadsheets. Yes, they are not so easy to test,&nbsp;but they have many benefits, like ‘liveness’ (immediate feedback), having data, metadata and calculations in one view, ease of deployment. In that sense, they have&nbsp;benefits over other programming environments.</p>
<p><strong>2) No, we do not know better!&nbsp;</strong></p>
<p>I have been working on spreadsheets as a researcher for about 5 years now, and during that time I spoke with a lot of spreadsheet users. Of course, I asked them why they would run a bank/insurance company/airline on spreadsheets. You know what many of them say?</p>
<p><em>“We asked IT to build this, they said it would take 6 months and half a million euros. And most likely it will be more expensive and not what we want.”</em></p>
<p>The reality is that it is just not feasible to build software for all business processes. We don’t have the manpower, and frankly, in many cases also not the domain skill needed. So what we need to do isn’t ridicule spreadsheet users.&nbsp;They have been disappointed by us many times. I already mentioned healthcare.gov and there are so many other IT screw-ups that it is almost&nbsp;arrogant to claim superiority over the spreadsheet users.</p>
<p><strong>3) Like democracy, spreadsheets are the worst, except for all others</strong></p>
<p>Then, in addition to our riducule, we try to push tools to them, “real” programming languages, that nor fit their needs nor their skills. They will never learn Java or C#. Python maybe, that seems to be easy to use for end-users, but certainly not for all of them. End-users are not programmers, they don’t want to be and they should not need to be.</p>
<p>Instead of shaming spreadsheet users, let’s focus on inventing better spreadsheet-killers tools (Tableau is my personal favorite at the moment). Or, and this is my line of research, help spreadsheet users to&nbsp;<a href="http://www.felienne.com/archives/2957">test</a>,&nbsp;<a href="http://figshare.com/articles/Detecting_and_refactoring_code_smells_in_spreadsheet_formulas/980655">measure</a>&nbsp;and&nbsp;<a href="http://www.felienne.com/archives/2964">refactor</a>. No one, really, no one, is helped with your judgement without thinking about alternatives.</p>
<p>This post was visited 7,162 times.</p>

  </div>
</div>

   
</div> <!-- end of content -->
 <!-- end of sidebar -->
</div> <!-- end of main-content -->
</div> <!-- end of main-content-wrapper -->
  <!-- end of wrapper-footer -->
</div></div>]]>
            </description>
            <link>https://www.felienne.com/archives/3355</link>
            <guid isPermaLink="false">hacker-news-small-sites-24696283</guid>
            <pubDate>Tue, 06 Oct 2020 10:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Chat bot powered by GPT-3]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24695710">thread link</a>) | @piotrgrudzien
<br/>
October 6, 2020 | https://blog.quickchat.ai/post/knowledge-base-chat-bot/ | <a href="https://web.archive.org/web/*/https://blog.quickchat.ai/post/knowledge-base-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://blog.quickchat.ai/images/blog-post-1-bg.png" alt="Knowledge-base chat bot for SaaS product sales"></figure><section><div><p><em>Brief summary of our GPT-3 chat bot for SaaS product sales.</em></p><p>The most natural way for us to communicate is, well, <em>natural language</em>. Chat bots are nothing new but unless they meet a high-enough quality bar, they tend to be a step backwards rather than forward. We believe huge language models such as <a href="https://openai.com/blog/openai-api/">OpenAI’s GPT-3</a> will form a foundation for a truly conversational human-computer interface. It is, however, a foundation rather than a solution in and of itself.</p><p>In this new paradigm, the big challenge becomes to ensure the chat bot strictly sticks to the topic it was designed for and provides accurate information - without depriving it of its creativity.</p><p>I will discuss this briefly in the context of what we refer to as <strong>knowledge-base chat bots</strong>. They are built to answer general questions and hold a conversation about a product, service or a topic delineated by a predetermined unstructured knowledge base.</p><p><img src="https://blog.quickchat.ai/images/zeroth_faster.gif" alt="Start a conversation - image" title="Start a conversation"></p><p>Our chat bot implementation approved by the OpenAI team (try it out live at <a href="https://itemsy.com/">itemsy.com</a>) is an expert on Itemsy - a software product for managing the content you read online. It relies on GPT-3 for its conversational capabilities.</p><p>Thanks to our <a href="https://quickchat.ai/">Quickchat</a> engine (on top of GPT-3), it makes full and accurate use of the Itemsy knowledge base it was provided with, focuses on the topic at hand and cannot be maneuvered away from it:</p><p><img src="https://blog.quickchat.ai/images/first_faster.gif" alt="Avoid off-topic conversations - image" title="Avoid off-topic conversations"></p><p>Ultimately, it’s all about <em>conversation</em>. It requires context, needs to be unscripted, adaptive and creative. You’re still talking to a machine but this time language feels more like natural language. 🙃</p><p><img src="https://blog.quickchat.ai/images/second_faster.gif" alt="Creative conversation guided by the user - image" title="Creative conversation guided by the user"></p><p>We’re ready to work with you and launch conversational chat bots for a wide range of use cases. Reach out to us at <a href="https://quickchat.ai/">quickchat.ai</a>!</p><blockquote>— Dominik Posmyk (@dominikposmyk) <a href="https://twitter.com/dominikposmyk/status/1309497928810213376?ref_src=twsrc%5Etfw">September 25, 2020</a></blockquote></div></section></article><div><h2>Follow the Quickchat blog for product updates, user stories and technical posts about artificial intelligence.</h2><p>
<span>Please correct your email address</span></p></div></div>]]>
            </description>
            <link>https://blog.quickchat.ai/post/knowledge-base-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695710</guid>
            <pubDate>Tue, 06 Oct 2020 08:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fooling Around with Foveated Rendering]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24695275">thread link</a>) | @underanalyzer
<br/>
October 5, 2020 | https://www.peterstefek.me/focused-render.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/focused-render.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>28 September 2020</strong></label></p>
<p>Shadertoy is a wonderful tool which lets users create and share a type of program called a fragment shader online. The true magic of shadertoy is its community of very talented graphics programmers who build incredible works of art despite having access to only a sliver of the traditional graphics pipeline.  </p>
<p>Some of these shaders are very computationally intensive and even in a small window, they crawl along well below their intended 60 frames per second on my old laptop. Inspired by a technique in the VR community called Foveated Rendering, I decided to try to optimize these shaders by only rendering a fully detailed image within a small focal region. As you move away from the focal point the image quality decreases.   </p>
<p>This rendering scheme is motivated by biology. It turns out your eye notices more detail in the center of your vision than in the periphery. Some VR graphics programmers realized they could take advantage of this phenomenon to increase the effective resolution of images by increasing image quality towards the center of your vision. An in depth discussion of foveated rendering can be found in the “previous work section” of this <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a>.  </p>
<p>I did not have the time, equipment or the background necessary to implement a full foveated rendering system but it was fun to fool around with the concept.  </p>
<p>Before diving into the technical details let’s look at a simple shadertoy fragment shader.   </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord)<br>
{
</code></p><p><code>
    // Normalized pixel coordinates (from 0 to 1)<br>
    vec2 uv = fragCoord/iResolution.xy;
<div><pre><span></span><span>//</span> <span>Output</span> <span>the</span> <span>pixel</span> <span>coordinates</span> <span>as</span> <span>a</span> <span>color</span> <span>to</span> <span>screen</span>
<span>//</span> <span>fragColor</span> <span>is</span> <span>a</span> <span>4</span> <span>vector</span> <span>of</span> <span>the</span> <span>form</span>
<span>//</span> <span>(</span><span>red</span><span>,</span> <span>green</span><span>,</span> <span>blue</span><span>,</span> <span>transparency</span><span>)</span>
<span>fragColor</span> <span>=</span> <span>vec4</span><span>(</span><span>uv</span><span>,</span> <span>0</span><span>.</span><span>0</span><span>,</span> <span>1</span><span>.</span><span>0</span><span>);</span>
</pre></div>


</code></p><p><code>
}<br>
</code></p>
<p>This program runs once for each pixel on the screen. Each time it runs, we receive the input variable <code>fragCoord</code>. <code>fragCoord</code> is a 2d vector which contains the x and y coordinates of the pixel being drawn. We normalize those coordinates by dividing by <code>iResolution</code>, another 2d vector, which contains the width and height of the image. Finally we output a color to the screen, whose red and green channels are proportional to the x and y position of the pixel being drawn. The output of this shader looks like this:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/simple-shader-out.png" width="50%"> 
</p>
<p>Side note, why do these shader programs require their own language? Shaders are special because they run on the graphics card instead of the cpu. They are highly parallel. A helpful mental model might be imagining that each pixel is colored simultaneously. Therefore a lot of things that we take for granted in normal program languages such as liberally accessing memory and branching become much more difficult.  </p>
<p>In shadertoy shaders the bottleneck is always in the pixel rendering step. So to speed them up we want to only render a subset of the all the pixels on the screen. It seems like selectively rendering pixels should be as simple as adding a branch to the per pixel shader code that looks like:  </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord) <br>
{<br>
</code></p><p><code>
    if (fragCoord is in the subset of pixels to render) {
      <p>
      ... do computationally intensive work 
      </p> 
    } else {
      <p>
      // return a black pixel<br>
      return vec4(0, 0, 0, 1); 
      </p> 
    } 
</code></p><p><code> 
}
</code></p>
<p>Unfortunately we cannot just use an if statement inside of the shader to save us from rendering all the pixels. Unlike normal programming languages, fragment shaders always execute both parts of each branch due to gpu limitations. So while our above code will still have to spend the sample amount of time evaluating compuationally intensive work.  </p>
<p>Luckily, it turns out that graphics drivers can selectively mark which pixels not to shade by writing their location to a special buffer called the stencil buffer. We can use this stencil buffer to only shade the subset of pixels we are interested in.</p>
<p>Once I could efficiently render a subset of the pixels, I needed to come up with a pre-generated sampling pattern. Most foveated rendering techniques seem to use a grid, but I decided to try a non uniform approach. Searching for some kind of optimal sampling pattern seemed like an interesting problem and if I was going to devote more time to this I'd explore options like <a href="https://blog.demofox.org/2018/01/30/what-the-heck-is-blue-noise/">blue noise</a>. However in the interest of time, I just decided fill in a small circle in the center and then use samples drawn from one low variance and one high variance gaussians centered at the middle of the screen to place the rest of the pixels. The final sampling pattern ended up looking like this:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/final-sample-pattern.png" width="50%"> 
</p>
<p>Next, I needed a way to fill in all the missing pixels in the final image. The approach I took was pretty simple. I started by mapping each pixel in the final screen to its nearest neighbor. Since my sampling pattern was predetermined, I could create this map beforehand and pass it into the shader as a texture. Here's what this mapping looks like:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/nearest-mapping.png" width="50%"> 
</p>
<p>And here’s a gif of the mapping applied to a <a href="https://www.shadertoy.com/view/3lsSzf">shadertoy</a> created by the extremely talented <a href="https://www.iquilezles.org/">Inigo Quilez</a>:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1-neighbor.gif"> 
</p>
<p>The above screen is 420x236 pixels and only 1/10th of those pixels are actually rendered. The focal point is directly in the center of the screen. Here's what the full resolution version looks like:</p>
<p>
  <img src="https://www.peterstefek.me/images/focused-render/original.gif"> 
</p>

<p>And here's what it looks like with only our sampling pixels:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/sample-pixels.gif"> 
</p>
<p>One little improvement I tried was to make 4 different maps. The kth map mapped each pixel in the final image to its kth nearest sampled neighbor. I weighted each of neighbors by the inverse of their distance to the pixel in question. I actually even tried using some gradient descent based optimization to fine tune the weights but ended up seeing little improvement. It also seemed that increasing the number of maps beyond 4 did not improve things much either. Here's what the example from above looks like with weighted interpolation between the four closest neighbors of each pixel (we are still rendering only 1/10th of the total pixels):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/4-neighbors.gif"> 
</p>
<p>Finally, here's the shader with 1/5th of the total pixels rendered (as opposed to 1/10th shown above):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1of5pixels.gif"> 
</p>
<p>Okay that's all cool but does this technique actually increase performance? I did not do a rigerous benchmark, but <a href="https://www.shadertoy.com/view/3l23Rh">this shader</a> goes from around 20-25 fps on my plugged in laptop to 60 fps when reduced to 1/5th of the total pixels. <a href="https://www.shadertoy.com/view/Ms2SD1">Another shader</a> went from around 15 fps to 60 fps.  </p>
<p>One last side note is that this method can be used with any 3d scene and is not exclusive to shader toys. I just chose to use them because they are always bottlenecked by the pixel rendering step and they are really pretty!</p>
<p>Further questions:</p>
<ul>
<li>How do we achive better temporal stability? (the <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a> I mentioned earlier talks about this)</li>
<li>Can we dynamically change the sampling pattern to give us better results? For example what if we sampled along edges or areas where large amounts of motion is occuring? Of course to do this we would need to compute our nearest neighbor mappings on the fly (there are actually <a href="https://www.shadertoy.com/view/XtlGDS">some</a> <a href="https://www.shadertoy.com/view/ldl3W8">shadertoys</a> which already demonstrate capability).</li>
<li>How could this scheme improve if we had access to the internals of the 3d scene? For example, could we adjust our sampling pattern based on depth information?  </li>
<li>How does this actually look in VR?  </li>
</ul>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
<p>Discussion on <a href="https://news.ycombinator.com/item?id=24695275">Hacker News</a></p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/focused-render.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695275</guid>
            <pubDate>Tue, 06 Oct 2020 06:44:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q – Run SQL Directly on CSV or TSV Files: Text as Data]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24694892">thread link</a>) | @pcr910303
<br/>
October 5, 2020 | https://harelba.github.io/q/ | <a href="https://web.archive.org/web/*/https://harelba.github.io/q/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                
<p><a href="https://github.com/harelba/q/stargazers/"><img alt="GitHub Stars" src="https://img.shields.io/github/stars/harelba/q.svg?style=social&amp;label=GitHub%20Stars&amp;maxAge=600"></a>
<a href="https://github.com/harelba/q/network/"><img alt="GitHub forks" src="https://img.shields.io/github/forks/harelba/q.svg?style=social&amp;label=GitHub%20Forks&amp;maxAge=600"></a></p>
<h2 id="overview">Overview<a href="#overview" title="Permanent link">¶</a></h2>
<p>q is a command line tool that allows direct execution of SQL-like queries on CSVs/TSVs (and any other tabular text files).</p>
<p>q treats ordinary files as database tables, and supports all SQL constructs, such as WHERE, GROUP BY, JOINs etc. It supports automatic column name and column type detection, and provides full support for multiple encodings.</p>
<pre><code>q "SELECT COUNT(*) FROM ./clicks_file.csv WHERE c3 &gt; 32.3"
</code></pre>

<pre><code>ps -ef | q -H "SELECT UID,COUNT(*) cnt FROM - GROUP BY UID ORDER BY cnt DESC LIMIT 3"
</code></pre>

<p>Look at some examples <a href="#examples">here</a>, or just download the tool using the links in the <a href="#installation">installation</a> below and play with it.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>完全支持所有的字符编码</td>
<td>すべての文字エンコーディングを完全にサポート</td>
</tr>
<tr>
<td>모든 문자 인코딩이 완벽하게 지원됩니다</td>
<td>все кодировки символов полностью поддерживаются</td>
</tr>
</tbody>
</table>
<p><strong>Non-english users:</strong> q fully supports all types of encoding. Use <code>-e data-encoding</code> to set the input data encoding, <code>-Q query-encoding</code> to set the query encoding, and use <code>-E output-encoding</code> to set the output encoding. Sensible defaults are in place for all three parameters. Please contact me if you encounter any issues and I'd be glad to help.</p>
<p><strong>Files with BOM:</strong> Files which contain a BOM (<a href="https://en.wikipedia.org/wiki/Byte_order_mark">Byte Order Mark</a>) are not properly supported inside python's csv module. q contains a workaround that allows reading UTF8 files which contain a BOM - Use <code>-e utf-8-sig</code> for this. I plan to separate the BOM handling from the encoding itself, which would allow to support BOMs for all encodings.</p>
<h2 id="installation">Installation<a href="#installation" title="Permanent link">¶</a></h2>
<table>
<thead>
<tr>
<th>Format</th>
<th>Instructions</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/harelba/q/releases/download/2.0.19/q-x86_64-Darwin">OSX</a></td>
<td>run <code>brew install q</code></td>
<td>man page is not available for this release yet. Use <code>q --help</code> for now</td>
</tr>
<tr>
<td><a href="https://github.com/harelba/q/releases/download/2.0.19/q-text-as-data-2.0.19-1.x86_64.rpm">RPM Package</a></td>
<td>run <code>rpm -ivh &lt;package-filename&gt;</code> or <code>rpm -U &lt;package-filename&gt;</code> if you already have an older version of q.</td>
<td>A man page is available for this release. Just enter man q.</td>
</tr>
<tr>
<td><a href="https://github.com/harelba/q/releases/download/2.0.19/q-text-as-data_2.0.19-2_amd64.deb">DEB Package</a></td>
<td>Run <code>sudo dpkg -i &lt;package-filename&gt;</code></td>
<td>A man page is available for this release. Just enter <code>man q</code>.</td>
</tr>
<tr>
<td><a href="https://github.com/harelba/q/releases/download/2.0.19/q-AMD64-Windows-installer.exe">Windows Installer</a></td>
<td>Run the installer executable and hit next next next... q.exe will be added to the PATH so you can access it everywhere.</td>
<td>Windows doesn't update the PATH retroactively for open windows, so you'll need to open a new cmd window after the installation is done.</td>
</tr>
<tr>
<td><a href="https://github.com/harelba/q/archive/2.0.19.tar.gz">tar.gz</a></td>
<td>Full source file tree for latest stable version. Note that q.py cannot be used directly anymore, as it requires python dependencies</td>
<td></td>
</tr>
<tr>
<td><a href="https://github.com/harelba/q/archive/2.0.19.zip">zip</a></td>
<td>Full source file tree for the latest stable version. Note that q.py cannot be used directly anymore, as it requires python dependencies</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Older versions can be downloaded <a href="https://github.com/harelba/packages-for-q">here</a>. Please let me know if you plan on using an older version, and why - I know of no reason to use any of them.</strong></p>
<h2 id="requirements">Requirements<a href="#requirements" title="Permanent link">¶</a></h2>
<p>As of version <code>2.0.9</code>, there's no need for any external dependency. Python itself (3.7), and any needed libraries are self-contained inside the installation, isolated from the rest of your system.</p>
<h2 id="usage">Usage<a href="#usage" title="Permanent link">¶</a></h2>
<pre><code>q &lt;flags&gt; "&lt;query&gt;"

  Simplest execution is `q "SELECT * FROM myfile"` which prints the entire file.
</code></pre>

<p>q allows performing SQL-like statements on tabular text data. Its purpose is to bring SQL expressive power to the Linux command line and to provide easy access to text as actual data.</p>
<p>Query should be an SQL-like query which contains <em>filenames instead of table names</em> (or - for stdin). The query itself should be provided as one parameter to the tool (i.e. enclosed in quotes). Multiple files can be used as one table by either writing them as <code>filename1+filename2+...</code> or by using shell wildcards (e.g. <code>my_files*.csv</code>).</p>
<p>Use <code>-H</code> to signify that the input contains a header line. Column names will be detected automatically in that case, and can be used in the query. If this option is not provided, columns will be named cX, starting with 1 (e.g. <code>q "SELECT c3,c8 from ..."</code>).</p>
<p>Use <code>-d</code> to specify the input delimiter.</p>
<p>Column types are auto detected by the tool, no casting is needed. Note that there's a flag <code>--as-text</code> which forces all columns to be treated as text columns.</p>
<p>Please note that column names that include spaces need to be used in the query with back-ticks, as per the sqlite standard.</p>
<p>Query/Input/Output encodings are fully supported (and q tries to provide out-of-the-box usability in that area). Please use <code>-e</code>,<code>-E</code> and <code>-Q</code> to control encoding if needed.</p>
<p>All sqlite3 SQL constructs are supported, including joins across files (use an alias for each table). Take a look at the <a href="#limitations">limitations</a> section below for some rarely-used use cases which are not fully supported.</p>
<h3 id="query">Query<a href="#query" title="Permanent link">¶</a></h3>
<p>Each parameter that q gets is a full SQL query. All queries are executed one after another, outputing the results to standard output. Note that data loading is done only once, so when passing multiple queries on the same command-line, only the first one will take a long time. The rest will starting running almost instantanously, since all the data will already have been loaded. Remeber to double-quote each of the queries - Each parameter is a full SQL query.</p>
<p>Any standard SQL expression, condition (both WHERE and HAVING), GROUP BY, ORDER BY etc. are allowed.</p>
<p>JOINs are supported and Subqueries are supported in the WHERE clause, but unfortunately not in the FROM clause for now. Use table aliases when performing JOINs.</p>
<p>The SQL syntax itself is sqlite's syntax. For details look at http://www.sqlite.org/lang.html or search the net for examples.</p>
<p>NOTE: Full type detection is implemented, so there is no need for any casting or anything.</p>
<p>NOTE2: When using the <code>-O</code> output header option, use column name aliases if you want to control the output column names. For example, <code>q -O -H "select count(*) cnt,sum(*) as mysum from -"</code> would output <code>cnt</code> and <code>mysum</code> as the output header column names.</p>
<h3 id="flags">Flags<a href="#flags" title="Permanent link">¶</a></h3>
<pre><code>Usage: 
        q allows performing SQL-like statements on tabular text data.

        Its purpose is to bring SQL expressive power to manipulating text data using the Linux command line.

        Basic usage is q "&lt;sql like query&gt;" where table names are just regular file names (Use - to read from standard input)
            When the input contains a header row, use -H, and column names will be set according to the header row content. If there isn't a header row, then columns will automatically be named c1..cN.

        Column types are detected automatically. Use -A in order to see the column name/type analysis.

        Delimiter can be set using the -d (or -t) option. Output delimiter can be set using -D

        All sqlite3 SQL constructs are supported.

        Examples:

              Example 1: ls -ltrd * | q "select c1,count(1) from - group by c1"
            This example would print a count of each unique permission string in the current folder.

          Example 2: seq 1 1000 | q "select avg(c1),sum(c1) from -"
            This example would provide the average and the sum of the numbers in the range 1 to 1000

          Example 3: sudo find /tmp -ls | q "select c5,c6,sum(c7)/1024.0/1024 as total from - group by c5,c6 order by total desc"
            This example will output the total size in MB per user+group in the /tmp subtree


            See the help or https://github.com/harelba/q/ for more details.


Options:
  -h, --help            show this help message and exit
  -v, --version         Print version
  -V, --verbose         Print debug info in case of problems
  -S SAVE_DB_TO_DISK_FILENAME, --save-db-to-disk=SAVE_DB_TO_DISK_FILENAME
                        Save database to an sqlite database file
  --save-db-to-disk-method=SAVE_DB_TO_DISK_METHOD
                        Method to use to save db to disk. 'standard' does not
                        require any deps, 'fast' currenty requires manually
                        running `pip install sqlitebck` on your python
                        installation. Once packing issues are solved, the fast
                        method will be the default.

  Input Data Options:
    -H, --skip-header   Skip header row. This has been changed from earlier
                        version - Only one header row is supported, and the
                        header row is used for column naming
    -d DELIMITER, --delimiter=DELIMITER
                        Field delimiter. If none specified, then space is used
                        as the delimiter.
    -p, --pipe-delimited
                        Same as -d '|'. Added for convenience and readability
    -t, --tab-delimited
                        Same as -d &lt;tab&gt;. Just a shorthand for handling
                        standard tab delimited file You can use $'\t' if you
                        want (this is how Linux expects to provide tabs in the
                        command line
    -e ENCODING, --encoding=ENCODING
                        Input file encoding. Defaults to UTF-8. set to none
                        for not setting any encoding - faster, but at your own
                        risk...
    -z, --gzipped       Data is gzipped. Useful for reading from stdin. For
                        files, .gz means automatic gunzipping
    -A, --analyze-only  Analyze sample input and provide information about
                        data types
    -m MODE, --mode=MODE
                        Data parsing mode. fluffy, relaxed and strict. In
                        strict mode, the -c column-count parameter must be
                        supplied as well
    -c COLUMN_COUNT, --column-count=COLUMN_COUNT
                        Specific column count when using relaxed or strict
                        mode
    -k, --keep-leading-whitespace
                        Keep leading whitespace in values. Default behavior
                        strips leading whitespace off values, in order to
                        provide out-of-the-box usability for simple use cases.
                        If you need to preserve whitespace, use this flag.
    --disable-double-double-quoting
                        Disable support for double double-quoting for escaping
                        the …</code></pre></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://harelba.github.io/q/">https://harelba.github.io/q/</a></em></p>]]>
            </description>
            <link>https://harelba.github.io/q/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24694892</guid>
            <pubDate>Tue, 06 Oct 2020 05:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[File Corruption Is Attractive]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24694017">thread link</a>) | @sergioro
<br/>
October 5, 2020 | https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/chaos1.jpg" alt="Chaos, an important theme in hermetism" loading="lazy"></p>

<p>We live in a world that is gradually and incessantly attracted by
over-rationality and order. In this article we’ll burst the enchanted
bubble and embrace corruption and chaos — We’re going to discuss the
topic of image glitch art.</p>

<h2 id="w̸h̸a̷t̴̶s̴-̶a̴-̷g̷l̸i̷t̴c̵h̵">w̸h̸a̷t̴’̶s̴ ̶a̴ ̷g̷l̸i̷t̴c̵h̵</h2>

<p>Welcome to the land of creative destruction: image glitch art. Our story
starts with a simple idea: glitching a wallpaper to create a slideshow
of corrupted pictures.<br>
The unfortunate victim of our crime: The world (Right click <strong>&gt;</strong> View
image, while keeping the <strong>Control</strong> key pressed, to admire it in more
details while its still in its pristine form):</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map.jpg" alt="World Map, nominal case" loading="lazy"></p>

<p>Before we begin, let’s attempt to define what we’re trying to do: What
is glitch art?<br>
Like any art movement, words can barely express the essence behind the
meaning, they are but fleeting and nebulous. Regardless, I’ll be an
infidel and valiantly express what I think glitch art is.</p>

<p>A glitch is a perturbation, a minor malfunction, a spurious signal. In
computers, glitches are predominantly accidental events that are
undesirable and could possibly corrupt data.<br>
Glitch art started as people developed a liking for such unusual events
and the effects glitches had on the media they were perturbing. Some started
to collect these glitches that happened naturally in the wild, and others
started to intentionally appropriate the effects by manually performing them.<br>
In the art scene, some started using image processing to “fake” true
glitching effects.</p>

<p>Glitches happen all the time and everywhere, information is never as
durable and reliable as we might like it to be, and living in a physical
world makes it even less so. You’ve probably encountered or heard of the
effect of putting a magnet next to anything electronic that hasn’t been
rugged to withstand such scenario.<br>
That’s why many techniques have been put in place to avoid glitches,
at all layers, from the hardware storage, to the software reading
and interpreting it. Be it error correcting codes (ECC) or error detection
algorithms, they are all enemies of glitch art and the chaos we like.</p>

<p>However, this niche aesthetic is more than a fun pass-time for computer
aficionado, there is a bigger picture. Similar to painters with
brushes on a canvas, we are offered a material, an object to work with
— a material made of bits and formatted in a specific way.<br>
Like any object, our medium has a form and meaning, it can move, it has
a size, it can be transferred, and interpreted — information theory
is the field interested in this.<br>
Like any object, our medium can be subject and react to deformations,
forces, and stressors. How it flows is what the field of rheology
is interested in (not to be confused with computational rheology, the
field of fluid simulation.) The medium fluidity can be studied to answer
questions such as: is it elastic, solid, viscous, or oily, how does it
respond, within the bound of information theory, to different types of
applied forces.</p>

<p>Here are some words you may encounter and that you definitely want
to know:</p>

<ul>
  <li>
    <p>Misregistration: Whenever a physical medium misread data because of
damages caused by scratches, dirt, smudges, gamma rays, or any other
treasures the universe throws at us.</p>
  </li>
  <li>
    <p>Datamoshing, Photomosh, Imagemosh: Abusing the format of a medium,
normally compression artefacts, to create glitches. For example, video
compression often use i-frames for fixed images and p-frame for the
movement/transition of pixels on that image. <a href="https://www.reddit.com/r/datamoshing/">Removing i-frames is a
common glitching method</a>.</p>
  </li>
  <li>
    <p>Databending: An idea taken from circuit bending, bending the circuit
board of a toy to generate weird sounds. Databending is about bending
the medium into another unrelated one, reinterpreting it as something
it is not meant to be.</p>
  </li>
</ul>

<p>Let me add that glitch art is vast and fascinating, this article is but a
glimpse into this space. If you’re captivated as much as I am, please take
a look at <a href="http://gli.tc/h/0nline/">gli.tc</a> and <a href="https://beyondresolution.info/">Rosa Menkman’s Beyond
Resolution</a>. Images can be pleasantly
destroyed in a great number of ways to create masterpieces.</p>

<h2 id="i̷m̷a̷g̴e̴-̸g̸l̴i̴t̴c̵h̸-̴a̶r̵t̵">I̷m̷a̷g̴e̴ ̸G̸l̴i̴t̴c̵h̸ ̴A̶r̵t̵</h2>

<p>Before starting let’s give some advices:</p>

<ul>
  <li>Back up your precious files before corrupting them.</li>
  <li>Any glitching techniques can be combined and/or applied multiple times.</li>
  <li>Sometimes too little has no effect, and sometimes too much can destroy
the file.</li>
  <li>It’s all about trials and errors, especially errors that result in
glitches.</li>
</ul>

<h3 id="̷h̷o̵w̶-̵t̸o̴-̶i̷n̶d̸u̷c̶e̵-̶a̸-̶g̸l̵i̷t̶c̸h̴">̷H̷o̵w̶ ̵T̸o̴ ̶I̷n̶d̸u̷c̶e̵ ̶A̸ ̶G̸l̵i̷t̶c̸h̴</h3>

<p>Now it’s time to think about how we can apply our mischievous little
stimuli, its size, the level or layer at which it’ll be applied, and
the methodological recipe we’ll concoct to poison our images.</p>

<p>Glitch artist Benjamin Berg classifies glitches into 3 categories:</p>

<ul>
  <li>Incorrect Editing: Editing a file using a software that
wasn’t made to edit such file. Like editing an image file as if it
was a text file.</li>
  <li>Reinterpretation aka Databending: Convert or read a file as if it was
another type of medium. Like listening to an image file as if it was
an audio file (aka sonification).</li>
  <li>Forced errors, Datamoshing, and Misregistration: A software or hardware
bug to force specific errors in the file. This can be about the
corruption of specific bytes in the file to induce glitches, or
something happening accidentally like a device turning off when saving
a file.</li>
</ul>

<p>So let’s get to work!</p>

<h3 id="m̷a̵s̵h̸i̶n̶g̷-̴t̶h̷e̷-̷d̶a̸t̵a̸-̸r̷a̸n̶d̶o̸m̴l̵y̷">M̷a̵s̵h̸i̶n̶g̷ ̴T̶h̷e̷ ̷D̶a̸t̵a̸ ̸R̷a̸n̶d̶o̸m̴l̵y̷</h3>

<p>The easiest, but roughest, way to glitch a file is to put on our monkey
suit and overwrite or add random bytes in our image. As you would have
guessed, this isn’t very efficient but half the time it does the trick
and forces errors.</p>

<p>This technique is better suited for stronger materials like images in
raw format — without metadata and headers. We’ll understand why in a bit.<br>
To convert the file to raw format, open it in GIMP, select <strong>Export As</strong>,
select the file by extension, and choose the raw type. For now, it doesn’t
matter if you pick pixel-ordered or planar, but we’ll come back to this
choice later because it’s an important one.</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/gimp_saveas_raw.jpg" alt="GIMP process to save image as raw" loading="lazy"></p>

<figure><pre><code data-lang="shell">file world_map.data
<span># world_map.data: Targa image data - Map (771-3) 771 x 259 x 1 - 1-bit alpha "\003\003\003\003\003\003\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001"</span></code></pre></figure>

<p>You should also note the width and height of the image as it now doesn’t
contain this information anymore, and we’ll need those to reopen it in
GIMP. In our case it is <code>2000x1479</code>.</p>

<p>We now proceed to hand over the file to our least favorite
staff and let them have an anger tantrum at it. So what does
it look like, let’s take a look at <a href="https://www.youtube.com/watch?v=oj6NMiuU0ys">the result our monkey
did</a>:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_random_bytes.jpg" alt="World Map, monkey have been randomly mashing the
world" loading="lazy"></p>

<p>Not bad at all for something random, but we can do better.</p>

<h3 id="c̸o̶m̸p̷r̶e̷s̸s̵i̸o̶n̴-̶d̵e̵f̶o̶r̴m̷a̶t̷i̵o̸n̷">C̸o̶m̸p̷r̶e̷s̸s̵i̸o̶n̴ ̶D̵e̵f̶o̶r̴m̷a̶t̷i̵o̸n̷</h3>

<p>Some medium are more malleable when squished properly and squished
in different ways. The image sheds a lot of information and only the
essence stays. That’s a form of databending.<br>
For example, increasing the compression of JPEG images can open the path
for glitches to happen more frequently. This is a key asset, especially
when trying to create errors related to the compression parameters within
the format of the file.</p>

<figure><pre><code data-lang="shell">convert <span>-quality</span> 2 world_map.jpg world_map_compressed.jpg</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_compressed.jpg" alt="World Map, compressed to extract its
essence" loading="lazy"></p>

<p>Keep this in your toolbox to use along with other techniques.</p>

<h3 id="g̵e̴t̵t̶i̸n̵g̷-̴i̸n̵t̷i̵m̷a̴t̸e̴-̸w̶i̵t̸h̶-̴t̵h̸e̸-̴f̷o̴r̶m̸a̴t̷">G̵e̴t̵t̶i̸n̵g̷ ̴I̸n̵t̷i̵m̷a̴t̸e̴ ̸W̶i̵t̸h̶ ̴T̵h̸e̸ ̴F̷o̴r̶m̸a̴t̷</h3>

<p>We want to corrupt in the most efficient way possible, to create
attractive chaos from the smallest change possible. To do that we have to
get intimate with the medium, to understand its deepest secrets, tickle
the image in the right places. This is what we previously referred to
as imagemoshing.</p>

<p>There’s a panoply of image formats, and they all are special in their
own ways. However, there’s still some commonality:</p>

<ul>
  <li>Header, Footer, and Metadata: If the format contains these extra
information, be it extraneous or essential, what they represent, and
how they affect the rest of the image.</li>
  <li>Compression: The format can either be compressed or not. When it is
compressed, there can be extra bits of information to help other software
uncompress the image data.</li>
  <li>How the data is laid out: Usually, the image color information is
decomposed into its components such as HSL, RGB, or others. These
components then need to be represented in the image data, either in
an interleaved or planar manner. Planar refers to writing components
independently in the data (<em>ex:</em> all R, then all G, then all B),
while interleaved refers to having them joined non-contiguously in an
alternate sequence (<em>ex:</em> RGB, then RGB, then RGB..).</li>
</ul>

<p>Manipulating these to our advantage can lead to wonderful glitches. For
example, in our previous raw image example — an image bare of header,
footer, and without compression — the pixels were interleaved which
gave rise to the effect we’ve seen, namely shifts and changes in some
colors. Having them in planar form would’ve led to different glitches
in separate color channels.</p>

<h3 id="r̵e̷i̷n̴t̶e̷r̶p̸r̴e̸t̸a̷t̶i̷o̵n̴-̵a̸s̵-̵r̸i̷c̵h̸-̸t̷e̵x̵t̴-̴a̴k̷a̸-̷w̶o̴r̵d̴p̴a̸d̵-̷e̵f̸f̴e̶c̶t̶">R̵e̷i̷n̴t̶e̷r̶p̸r̴e̸t̸a̷t̶i̷o̵n̴ ̵A̸s̵ ̵R̸i̷c̵h̸ ̸T̷e̵x̵t̴ ̴A̴K̷A̸ ̷W̶o̴r̵d̴P̴a̸d̵ ̷E̵f̸f̴e̶c̶t̶</h3>

<p>Let’s give this a try with the well-known WordPad effect, which is about
databending an image into rich text: opening the image in WordPad and
saving it.<br>
Keep in mind that this only works with raw images as it’s highly
destructive and otherwise could break fragile key info in the header
and footer. So let’s reuse our interleaved raw image of earlier but also
get a planar one.</p>

<p>This is our results for interleaved:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_wordpad.interleaved.corrupt.jpg" alt="World Map, WordPad effect interleaved" loading="lazy"></p>

<p>And for planar:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_wordpad.planar.corrupt.jpg" alt="World Map, WordPad effect planar" loading="lazy"></p>

<p>Technically, what happens is that during the bending and interpretations
as rich text, some bytes are inserted in some …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html">https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24694017</guid>
            <pubDate>Tue, 06 Oct 2020 01:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Find Mentors. Find Your Future Self]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24693763">thread link</a>) | @jdcampolargo
<br/>
October 5, 2020 | https://www.juandavidcampolargo.com/blog/future-self | <a href="https://web.archive.org/web/*/https://www.juandavidcampolargo.com/blog/future-self">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1601739309102" id="item-5f789898afa8642a86474931"><div><div><div data-block-type="2" id="block-ba447757312844ef3468"><div><p>Back in 2018, I was fifteen years old, and I wanted to do something over the summer. I could get a job, work on my businesses, sit around, watch Netflix, or work for free at tech startups.&nbsp;</p><p>I chose the latter.</p><p>Why would I work for free in a startup? It wasn’t for free; I had to pay for the train tickets and food. I didn’t care. I knew that being out there meeting founders and investors would be the best way to learn.&nbsp;</p><p>I wanted to be involved in the startup world by creating, developing, and investing in them. I believe that’s the way how we can change the world and have a positive impact.&nbsp;</p><p>But how in the world would I find those startups?</p><p>I sent 500+ emails, called companies, asked family friends, and did everything I could, but I got annoyed. So I was like, “Screw it, I’m just going to go and ask them.”</p><p>I went to this startup incubator called Techstars at 1871 and asked if they were hiring. And that I was willing to work for free or “volunteer.”</p><p>At first, the founders looked at me like, “Kid, how old even are you?” Most founders looked the other way, but two guys were like, “Damn, let’s find something for this kid to do.”</p><p>And that’s how one of my best summers started.</p><p>The founders may have thought a fifteen-year-old won’t be able to do much, but I literally told them, “I’m willing to do anything, I just want to learn and spend as much time as possible at the incubator.” It felt like I was learning by osmosis.&nbsp;&nbsp;</p><p>I would go with the founders to meetings with investors and mentors and take notes, find venture capitalists interested in investing, work on hardware, and anything they told me to do.&nbsp;</p><p>I worked with three startups that developed an AI fitness assistant, solar drones, and a real estate crowdfunding site.&nbsp;</p><p>That summer showed me the world of startups. I met people like the governor, billionaires, and overall people who were heavily involved in the startup world.&nbsp;</p><p>I also experienced the startup world, which I’m sure will pay off in the future.&nbsp;</p><p>But most importantly, I met Paul, the founder who gave me the opportunity.&nbsp;</p><p>I always kept him posted on my progress in my projects and would ask how his company was doing. And Thanksgiving, Christmas, and Happy New Year messages as well.&nbsp;</p><p>Well, it turns out that Paul studied in the same college and did the same major. I’ve talked to him multiple times in the last few weeks and it reminded me of the <strong>importance of having people who were once where you are.</strong></p><p>Some people called people like Paul “mentors,” but that word is misleading because 1) it’s overused and over-hyped 2) it’s transactional and self-centered.&nbsp;</p><p>How do I call people like Paul? I call them, <strong>“My Future Selves.”</strong></p><p>They often can give that little push you need. And you get to cheat because you get to talk to your future self. What’s even better is that you can always do things differently and learn from their mistakes.&nbsp;</p><p>Studying engineering isn’t the easiest thing in the world and when you bomb a test, you can feel like “You don’t have what it takes.” My first chemistry exam? Hmmm. One to forget. I like to do as best as I can and not doing as expected frustrates me, especially when I need to get a good GPA to transfer to the engineering school.&nbsp;</p><p>I felt like I was the only one, but as I talked to “My Future Self” or Paul, I realized I wasn’t the only one and he too didn’t do great on his first chemistry exam. But he improved and could transfer to the engineering school.&nbsp;</p><p>He advised me on how to approach studying and how to approach the test and my grades have improved.&nbsp;</p><p>Sometimes, you can also lose sight of the big picture of what you want. Future selves remind you to keep focused not by scolding you but by asking you simple questions like, “What are your future plans after college?” or “Do you like what you’re studying?”</p><p>In my case, Paul knows I’m into startups and <a href="https://www.juandavidcampolargo.com/blog/ambition" target="_blank">eating the world</a>, so he helps me with choosing a path that aligns with my interests and with my goals.&nbsp;</p><p>Looking back, that was not a normal thing for a teen to do. Yes, you can say it, “I was weird.”&nbsp;</p><p>Well, not really. I knew <strong>who</strong> I was and <strong>where</strong> I wanted to go. That’s how going up to startup founders asking for a job could become your summer.&nbsp;</p><h2>How To Find Your Future Self</h2><p>If I hadn’t talked to Paul a few times since college started, I’d honestly be down and not very excited about the possibilities. <strong>Future selves can you show a path that gets you excited to work harder and more ambitiously.&nbsp;</strong></p><p>If you’re interested in finding a possible future self. I’ve learned a few lessons that can be helpful.&nbsp;</p><p><strong><em>Avoid being artificial. </em></strong>We’ve all heard the talk, “Get a mentor and blah blah blah.” Sure, but that can’t the only reason. You should be genuine. And please please, don’t be asking people to be your mentor.&nbsp;</p><p>How can you be more genuine?</p><ul data-rte-list="default"><li><p>Make yourself useful to them</p></li><li><p>Get a job or internship at that person’s company or lab</p></li><li><p>Ask unique and interesting questions</p></li><li><p>Just DM or email them</p></li></ul><p><strong><em>Understand their motivations. </em></strong>Keep this question in mind, “Why would someone want to mentor you?”</p><p>It usually happens when a high-potential person approaches them, and they can help him/her reach that potential.&nbsp; And if they can see their advice pays off 10x in you. If your future self tells you to walk 5 steps, they want to see you walk 50 steps.&nbsp;&nbsp;</p><p><strong><em>Don’t find mentors. </em></strong>This one will be the hardest to understand, but the most powerful. I don’t ask people, “Do you want to be my mentor?”</p><p>Most people will say “No.” Instead, the way you find mentors or future selves is by:</p><p>1) Finding people who are where you want to be.&nbsp;</p><p>2) Asking great questions and becoming genuinely interested in their work, and finally,&nbsp;</p><p>3) Keeping in contact with them and asking questions and/or advice when you need it. Or if you find something useful for them, this is when you help them.</p><p>I’m grateful to Paul and many of my other future selves because they allow me to learn from their mistakes, pick a unique path for me, and give you the little push and fresh perspective when you most need it.&nbsp;</p><p>Thank you, Paul, and thank you to all my future selves!</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.juandavidcampolargo.com/blog/future-self</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693763</guid>
            <pubDate>Tue, 06 Oct 2020 00:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oswald Spengler – an intellectual life]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24693655">thread link</a>) | @objections
<br/>
October 5, 2020 | https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/ | <a href="https://web.archive.org/web/*/https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="9549bc7" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:500}" data-widget_type="theme-post-content.default">
				<div>
			
<p>Oswald Spengler was one of the most profound pessimists of modern times but at a glance, his legacy appears to have collected decades of dust since his early death in 1936.&nbsp;Considered unessential by historians and troublesome by philosophers, he nonetheless exerted an extraordinary influence over many powerful figures throughout the twentieth century. Wittgenstein said he was one of his chief inspirations; the Jungian theorist Joseph Campbell claimed Spengler’s work was his biggest influence; the philosopher Martin Heidegger was profoundly affected by Spengler’s thinking; and former Secretary of State, Henry Kissinger, wrote favourably about him in his doctoral thesis ‘The Meaning of History’. Kissinger gifted a one-volume edition of Spengler’s The Decline of the West to President Nixon when he served in his administration to ‘emphasise the manifestation of events’. But who was this man whose thought has shaped modern philosophy and the perception of some of our top policy gurus, and what did he believe?&nbsp;</p>



<p>Oswald Spengler was born in the Duchy of Brunswick in 1880 to Protestant parents. His father’s family were traditionally mining engineers and metallurgical inspectors while his mother, Pauline, from whom Spengler received his irascible temperament, hailed from an artistically inclined lineage of ballet dancers and bohemians. Unlike his ancestors, his father worked as a senior postal secretary and severely chastised any hint of intellectualism in his children, a repulsion that must have conditioned the young Spengler to distrust celebrated thinkers later in his life. It was this inherited mixture of two divergent tendencies – engineering and science with bohemianism and the arts – that afforded Spengler a unique intellectual vantage and prepared him to proffer his special perspective to his readers in the future.&nbsp;</p>



<p>After excelling in Greek, Latin, Mathematics and the Sciences at school, he attended the universities of Munich, Berlin and Halle. In 1903, two years after his father’s death, he initially failed to obtain his PhD but managed to pass a year later via an oral equivalent of the examination. He then qualified as a schoolmaster and led a relatively uneventful life teaching in Saarbrucken, Dusseldorf and Hamburg. When his mother died in 1910, he returned to Munich where he lived on his modest inheritance as a private scholar. It is said he owned no books and suffered from great loneliness rather like a latter-day Nietzsche. But, like Nietzsche, these years proved to be formative. It was around this time that he conceived of writing a book that would challenge common preconceptions of history and its meaning. He began work on&nbsp;<em>The Decline of the West&nbsp;</em>in 1911 and completed a first draft in 1914, but due to the war, he had to wait until 1918 for it to be published. Burdened with a weak heart, he was exempted from military service yet this didn’t mean he had an easy time. With much of his inheritance invested abroad, he was forced to persist in a state of serious poverty until the publication of his work.&nbsp;</p>



<p>When it came out, its success made him an instant celebrity and he finally gained the respect and reputation his talents deserved. His explanation of the war as a ‘historical change of phase’ which was ‘preordained for Germany hundreds of years ago’ consoled Germans who were being blamed in the European press for gratuitously starting the greatest military catastrophe of their time. In the early days of the Weimar Republic, he called himself a Socialist, but not a socialist of any obvious orthodoxy. He rejected Marx, whom he saw as the chief critic of the English capitalism he  defined as ‘Get rich, so you don’t have to work anymore’. He believed that the true source of German socialism was not Marx so much as Frederick William I. To succinctly explicate his brand of Prussian Socialism he used the phrase ‘Do your duty, work’.&nbsp;</p>



<p>His Prussian subgenre of Socialism naturally appealed to National Socialists and he became an inspirational figure to some early believers of Nazism. His criticism of the Weimar Republic, of Marxism, pacifism and democracy intellectually aided the Nazis in their ideological advancement to the top of German politics, but once they were in power Spengler famously refused to ‘Heil Hitler’ and was thereafter shunned. He occupied his concluding years by collecting thousands of books and exotic primitive weapons, by reading the comedies of Moliere and Shakespeare and listening to the haunting quartets of his hero, Beethoven. He died three weeks before his fifty-sixth birthday of a sudden heart attack on 8<sup>th</sup>&nbsp;May, exactly nine years before the bloody fall of the Third Reich.</p>



<p>Like Kant, who rarely left his place of birth and was famously not convivial, Spengler lived an externally anodyne existence while his mental interior shone incandescently with original ideas. He worked in an age of Prussian militarism and German nationalism, of extraordinary revelations and dire events, when the tumultuous tide of uncontrollable circumstances invoked an apocalyptic atmosphere. His thinking therefore can be seen as an illuminating response to the blindness of his time. His magnum opus,&nbsp;<em>The Decline of the West</em>, was a rejection of Eurocentric versions of history and a repudiation of traditional structures of scholarship. He deemed the historical phases of ‘classical, medieval and modern’ as inaccurate, random and unhelpful, as a cracked encasement of human activity. He did not want to appraise the past chronologically and solely link cause to effect. He wanted to examine what was common and unique to cultures across the world, what the nature of mass existence is, and how humans see themselves through history, if at all. He called this new approach a ‘Copernican overturning’. For the study of history, it is as seminal a moment as the Newton’s shift in Physics or Descartes’s dramatic declaration of ‘Cogito ergo sum’ in Western Philosophy. This drastic development he hoped would forever transform humanity’s elemental understanding of history. However, his obscurity seems to have precluded his influence on the public and his theories remain widely unread outside the insular circles of academia.&nbsp;Perhaps the pessimism he espoused makes him appear intellectually unprofitable and therefore unattractive to the merely curious reader.&nbsp;</p>



<p>In&nbsp;<em>The Decline of the West</em>, Spengler’s ‘Copernican overturning’ led him to see past eras as loose biographies of isolated cultures. He applied the seasonal system of spring, summer, autumn and winter to the evolution and undoing of every prosperous society. They rise, flourish, wither and vanish like distinct wild flowers on a windswept heath. Spring naturally represents an awakening when the force of cultural expression is so strong that it sets a precedent for centuries thereafter. Summer signifies a stage of pleasing artistic production and clever imitations when creation becomes a personal activity. Autumn is when the soul of a culture depicts its happiness and attempts to return to nature, and winter means the solidifying of culture into a civilisation, when great art is mostly extinguished and the creative energy that drove a culture on is almost entirely spent.&nbsp;</p>



<p>Although there have been innumerable births of culture, Spengler argued only eight ‘high cultures’ have existed: the Babylonian, Egyptian, Indian, Sino-Japanese, Mesoamerican, Classical (Greek-Roman), Magian (or Arabian) and our own, the Faustian. Classical man was more concerned by the near and the present, whereas we children of the Faustian age are forever looking into infinity, searching for the ultimate end of our speculative powers. Sadly, he claims that the Faustian age is the most tragic because although we enjoy unprecedented technological discoveries and rapidly strive and create, we know deep down that our goals will always elude us and that our efforts will eventually be proven futile.&nbsp; To add to the dark tone he used to describe our time, he believed our culture was now in its winter phase. Lawrence Durrell opened his Alexandrian Quartet with the beautiful line ‘in the midst of winter you feel the inventions of spring’. In Spengler, this ‘feeling’ is a remembrance rather than an anticipation. The time of birth and rejuvenation is forever finished, metaphorically speaking. In this present phase, Spengler’s prophesising limns an authoritative ruler or ‘new emperor’ who emerges in response to the disintegration of culture. He called this the Caesarian age. Many Spenglerian commentators have identified the advent of Hitler and Nazism as an example of a Caesarian instance in cultural history and it would be an easy feat to find comparisons in politics today who fit the description of attributes Spengler so eerily expatiates.&nbsp;</p>



<p>Spengler’s approach to the philosophy of history – to how we see history and what meaning we can derive from an appraisal of past events – is informed by a myriad of unorthodox intellectual disciplines. Morphology, the study of the form and structure of organisms and their specific structural features, determines his perception of eras and their attributes. Mathematics is used to reveal the rational divergence of different cultures and to prove the sociocultural relativism of subjects that supposedly seek certainty. Art, economics, politics, literature and architecture are each discussed with a rare authority, but his factual errors and historical inaccuracies have galvanised his critics and stunted his appeal. However, Spengler’s holistic discernments distinguishes him from other philosophers of history and raises his status to a laudable level of exceptional intellectual skill. His analytical insight penetrates more deeply and disturbingly than Toynbee and his Nietzschean prose and encyclopaedically varied knowledge rewards his readers with a weird and widened perspective. Like most great thinkers, it is not the bleak conclusions he draws which are …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/">https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/</a></em></p>]]>
            </description>
            <link>https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693655</guid>
            <pubDate>Tue, 06 Oct 2020 00:30:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Probability and Statistics with Applications to Computing [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24693589">thread link</a>) | @ArtWomb
<br/>
October 5, 2020 | https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf | <a href="https://web.archive.org/web/*/https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><i d]g(*hª®jcš»•ßÕ]¿¿}[xï^îr)Šf3@="ïJ§“ccc–/_^RRbs—¬mÈ" ;ÄçÏeáÚ?§‹€Ñ="" p8]x±<Å<­}ßô‡Ù…‹!kim2Š‹‹m1cÆ¡–›Ï·yyyb¡'��aÀ‡kd¡8ûû£‡="" öØ½+êæ�dôfÔà:qàeuÊju;~×¨)?l7¥="" Â="" Ö®[bc£vciqòÊ!á2ÜÑÃrø="" Ì|ñÝê`‰-»�8&7ž¢Ãý="" ý­¼„_öÇŒ)ŠÇ3™.d¢çl¥&nœxûöí'ož˜o)­Ê�“?yÉŠvw-jþb7r�Å»s="" †�çh<b¦iì²Ó„a-åpËmÉ¬y-g="" "æ³gÏ6nÜh¡�\]°xÎýúz�]gó•†="" mÊ`4Ýî‡qp;iì1™ìôŸÿ|åääÑ«w¯#f,y²äâÅ‹.mqÕ´ˆ�£`‹ýÃŽð¢ß7aïËÙ)ÑsÔŒhŽ,ÚxÕÖò(j®a¬jËk²yœuëÖÙbÎ¡c-7Ÿoóóó÷ìÙ3yòä&mšøøx“Éd"Ñ�nw‹qéŒáÃ¼²–nÛ~ð@ÌÙÓÊ‹çÕ¹Õ9Ô'�+öîŽ=""><b n¸1 ±Ü®3Ô%Õe!�j¡«ŒÁ±�Æcv‰ynglbpa�k¯„«cò,´å�£(ŠÜÊ"Í^¯iî2¢^?å‘×ue‰�m„ÉÝ^ÏsÏ?¿}Çvø–.˜_`6zÞÑ#Ð¶Áo°îŽ;îp©d^¯ô«eÅ\Ë¶ãÛÍŸ|ý±uñ&×™Ëb9%…n)Øäzµ(¶¼'§ oýÚâíw¬žk="" üau¸‰;ïpv”“�@&ë.‘t‰º="" …°ñÁï¬x±â\å¤eíŒ="" nü�?þxe’Ý%buÔ¥Ž°j+r…¤b_›ÀÜuØ.wê‰ˆsæÐimzua@jÑÈœ¡Žê.c!˜Ü�ÛÛ‡ƒú=""><s ‘hª÷*^íÕªjži[j¯Ÿ!±¼šgyä1<`ÀÕ="" Ü8(²gp!z$_õôŒûkÁ”uq�àât‡Ñh6:p<‰ã×îŒ�ÀÞ$bxÀ%µ¨˜‘}h="" !="" l‘"„‡b!qÂhˆ@b"�p¼ze‚‘Œ…ic"�(µ="™41" ¡¤!½ŠlÀÈÌ«fip7ñ¼êþ¿ûÉ‡½sìžž� káu�¤Ñ¼j9Ô3î‰–ïüÿ¥="" wü¤ðú+nŸfíÕcÎ.÷œ÷áÒ•–s‚hh¯r‚Îui’x5–4©¼Ê«�&{¯="" bÚØ™eö«�–®ò®6<uºqµýv="" ï‰oÈcoœuoí·ès="" ‰çu&û�o�ôê˜wš]tc4g˜wii´’gz•'ñê±�mï="" ‹Ÿ:fbªð*="" ;k¯ò¬½Êˆ?Þ@š¾vçùó*d^sŽi‘fêàu¸™Î«êÔÕ«ƒsxv®x5�<òÈc¸ÈÒ"Ï‹üÈ”ª\áåpý0æy0ãe~¤|&®]ƒœ.ªÓû¤�è›a%†hð‰="" šd!¨_<”fƒû™="" Áe™a`l%¤:iÂqæh’Æh\rñ‰Œb¬Ž&„Ç“ÆhhliÁ«Î™3âkû¾5<½j}º©ë�»äknù}qåûi="" ¯ÎµžuÏ|ß·_á="" iƒ©¡¼'��^å="" æu†q¤©Þ«bÝgï›Ö8ñÅdkägÎê€�^½urå%�'[-8t8!="" f€,¯¾ÿiåq�Çoí²i¯ªüéhräÕp¯*œdzuÍc%÷tú�ßõk^­"�h0jêubš*«à¾kŸ¬°ôî�Å”„ÄóªŠ$s¯’„h7dé¿�’x^{dîu±ºaj^="" ½Šo2É#�<òÁ8ƒÉÛ_pj="" n="" ‹¥,jªå ="Cëå" Å="" ‰¨×dq#ò¹z‡p="Õ«¼D‚ú3#¡Êk!’HWa²çÒÐ„&nbsp;Œú{6!" ¬yÌ.mˆ2¦éa�?ªñ*«ñ¼j}¶¥íwºgÙ­¿ºp¾¬€ò*=""><i ‹b#ÅÄ(cŒ##eƒ*mü“rŠ‰‹txƒƒà@1¸Ü•béîÉåÓàúà¸‹i§rŒ¤àpmÆ]Š™Úx="" ‡î-&�©="" b„19[khy”3ƒ§Ç\‹6„"'?Œ“tà´1%•–üejq9›k�r¬ƒ#="" Åx="" Ž¯´98×*="" ¥x="×Âfb&quot;#Eß¥" ój¸ßÂ@€Ý20gÌ5ŠÀÂ‹‰´Çk&†[¶â§9p="" m8le="v]Ð­€$=ˆö+¤" =""><i Ên<y¾"+xÒo%bw�o v!æÇ="" <aëÂÓj‡�´…' `xz(hž,="" bÔa{ñ¬g‡¡‰£:="" ov‰Ìcoº´×of‡!(›Ýxz€µµÏjkkýýý±.ìg£iÓff£áçŸop¨Úpz¸p¡Éh"Ÿ�`ÃÁÑ± °àþƒû¯x�²á="" ®Ïc�jkŸ<~¼lî¤Ô0u=""><i ¼,<-;l]?h�="xÙ‰'¥`Ý�¦ý›úƒvÓ7±Tž?;ºMb7wE62" g”Ôj<b—.kwgº+Úú©ÜcxÚxçø0eç="" c@1ê˜4•éoÊð3vòÕ·ñsÅ´”÷‘="" rd&ˆzh�pf9�eÀ5Ê“š&ì)¢€k@yp[qh¤="" Ü…‹ìÍÇf4°ikahh#&¶*Ä_À$cpå!Õ®hØÂ}ˆÖ="" z¾Üsï spd;¨Âl=""><i Â'@Èâ°jið$*ˆ_³zápýÛa‚ïÀ“j0]Á“ ="" cuwa„¢ ²="" år4ujß§ªÄsj÷mð¤(Øu<5j€½Áô4À�eüýfò$="¬-ñ÷7" žÏ®ÍÜájõ»•.Æ2ÜÌxãuì|y£¦ê¹öãxzó<û¡Û4È;5Ê÷žfwÊ€gjÀ,câd#‡5<‡e\·þ&.Öü™¦z3="" y3e¯ñ§É&&lájojÛ;±mý¹Ã†hƒà|²=""><i âïa5Á“¢="" ÏÙÙû¡i:aaa¹¹¹ÿf<uŒ¢Ü`ºˆ§”fya•xj¦="" ‚Ð(xwwwéÒ¥åË—c3»ûûøá#­‚]À“¨`×ñdÈxr%âšÅil0åo—ð”Òáiu�p…$<¿eü2x=""><s k™-sòšæs\ÿh%=""><i ƒƒ…="" ¨="" ˆfÄƒëšáÿnë1š$•á,—ÁÝŒ‡À'ŸntÜËà="" Ã´3<âùˆ²×��¶Âˆº×#€e0’’�cp0•ñ="" ˜¬»Í`="Æ`+ŒÀv3F�«Á0E|÷2¸Í`ÌðîÔùHQò98€…~Øv`¦íÂÀn³­ìÛ¼k4Uük¤wá³Œ…�·Àð®¹"><i><s Œ¦Ü7ËÈs�\ –xŠµ(`="" Þ�ÿèzðú~ìÿtz~tÙËc�¢ ºœj%�ù¾Å…Œ‹*�Èrò”@ˆ|)pùÀÜÍÖ4íÈ‘#.œ<y2¿ÌÈÈ0="" Ãw¿Ïý­a¢="" Ø="" ª="" 0="" [�o@vr‘ÕjÁ£�–«’Ûüž´ñ³="" Ç�(¸�="" cÆåe{µÀdfbÿr="" sˆ¥áÅ="" ‚="" —="" .0ÄrŠ°}²;–¬¶…a$`Ø°j="" ÜÑy{™ª[z·="" -yqÓpˆ×Ë†rcl*ovŽ£´;v®hb¨r¹ÍÏÉÉy»víÔ©sgÍšµcÇÓ4ub Ê÷Âb]2‰j`¢¡ro,xpå•w~öÙg¹¹¹g•÷ò§:dü#Ú¦m›¶mÛnÚ´é<{ûÕ<Øóøÿyyyü÷ª=""><b><b �bÉöv�j§ÅºdÀ�8ÇgÅ.k\†¨‡Œ="" =""><i ¬ŽqÔ¥w´é:‡õ�ƒóò_fç:§uÒ¶šª7½¾âfrø¹×eøŠ«è5ñ!_¢‘q<dñáeÅ=""><s „û·tb!aÈçù*`lze;‹×5Ñrƒð¬ºÐÌzÒà¸gxl¼Àdiyû-y­;o="" Î†iÂ+j–¶âo\^åÊuÂ“o*1`hžsÛ€="" –©eÊvie;¿¤÷”á£©Öh™c|ÉÙ¨b£p…ed�-í¨r9¹Ü=""><i ’îãqšƒì}="" ¯5À7-}£ðgzfèõ4n¼¦kx˜™~œcri³¯È�g@Å´)î1‰þ_¼alsb÷ˆk=""><b ­Êë%jt�="" Õç¬,p1Áï¾ûn]l="" hj‚‚‚ ÛyÛ¶m _®ì½ñÂ¸="" ="" ¯�öwh�Æë œà÷gÂnj2}²?á§](„pÆa`†cªòð›ñþ@Žd="" t–ø,utyÊ="" Èúìizzj)ð“’§iy™yb–Øluy–Š="" Ÿ=""><b><i o*d´,wÎg·®À+œ¶*‚‹f\y„="" «'yèÏÿ¥¨¿©œÿ›´Îÿroë›®·5¾wëeqÏýy”#Ì—ùÂ‹nçÅ¦pöãyú�Û,ÒÜ­Ýün³yÖÞ²ŽÜ="" 7Îsä="" £íbî&2x«Î‰zqöÚ¢qŒ+¡:ì…]„!Ô“Ü{ÈŽ8^Ç=""><s><b Á7˜ó¸ãÑÇÆa$211y¼hqbb†épØ1*œˆ“g0^3gÎ:tÄ¾ýû¢¢¢Ê�^�³©i“¦äêccggg˜Ýù’üÄÄ„·xq="" „Å‰*)’š·}ûŽvß?zÔè;w$’|x–hpÐk(ÿ="" 9ù0Œ×ömÛë7h�y="" Ï#À"r©”ãâz·jmhˆ="" ÆhÙ²å¹sç�¥¬âÍ|¦ò‡Ì,y�ìŽ‡g³æÍ!u•ªu—ýµìÝ»w"4éø@À-û[-ÿ÷?rim¿þýðÁ="" ºtÐ1bƒ_§ÆüéuÀ"—”•“~Û?jÍå€Á›Üú®Ã×ßŽûÛóˆkðëèô\‰¬@®¬°ývÀÜÔcxÏ`j="" »Â@´5f¨b€ža="Õ€þ&nbsp;¾" §h3˜ç›€Š½lhÓ="" Ào`â€s!½cqó˜xÍ`Û˜="ï�²ÌP'ˆ" ¡Õngìkvp±Ÿ‘÷Ÿ_Ôò‹Ï Ì²ÅÖ3Ž=""><s><u><i sÝs[Ž="" ´‚="" mpn¬i©ø8¦¸_ªs÷w4´:®ƒvaæ="" Ò.v›bó:!®†?jƒzØÅyrìÄáè§ãkãžuËõfË¸ yzïânË="" «="" néìÊÁ�¢‹¿¿Ù="" q="" gwhÚì£åz•à‹„²“¹­Ýã^yˆ="" t­Ž»xhu="" Š5¦c·›=""><u><i hæèÙß&Šê="" ¦m¤’)’�#cm›5k˜ìÑkldº°)u+¡bt•�="" ~yt¨Ö="Ð‰zUiè%�´ºT‰‚ž…" ƒnôht„)w«ÌhÅÐ»wc·Ñ%Äå�À="" Õ@="" èÞbèþÝÛjèüq4tx‰�ˆï:%.¨¬{Ëb)Ælyj‘ã wÑ:¥]uº{i9#nèÝ«bÏ.è’Íiwa'êu¥¡—4Òèr¥Þœx vï$†^onü»·‹6'g®€õdjrwdŽl€$ˆ°cÄhË¤µá*üŒ§d‘j“c¶jÈx¥�ðÒ“|€”1‚$Ì*f4="" |xá'ô#rbŽ¶p#å¡‹deÝ+†_="" tp”…nÅ%Œhµ*kkˆ2w½Øˆ:ˆÐÐåç"#­„n`­äuqs–âu@÷2â„^Îˆzžöty§ø=""><a ä‹Ÿ­9�1ï.“}(—x’dŽ|wÎ-ŒÊÃ“4ÿd¦¼[b="" †©ùo0…œly®h§.ã.Ïú‹�!Ö©€w\ÀïÝvòzvÕc¸‡,jçþ»?Üô%]£uØÞò'v~tØµ˜m¬úÍf¼Å="" Ú¡¨y8jŽ§¸.=""><u ý…�îØ¿?v9å$;bii"iÚßß�ìd¹Âe$&&Š¤*¡×(•j;;;ìbÊèÑlÚ´i$iy?t×®]ØyòÆÙÙÙÑÑq$u="" ý¥­­md¦ad$v="" åmxx8$ÞÜÜ,†ªñññðæ'nœÀÎ’7ÑÑÑl6ºªúknn.Œ#gŽ`—pÞ°©Ü"u� }èää„�"ìqu�ˆ1øøø˜™™uuua—pÞtvvšššŠÑujiia_�êû|�]þ—¶²²¢®1šžž¨!!!œ‹"ØzjjŠ··÷Úµk¿úê+øaß¾}ü·eóóóƒôÁp„u•­¥\wwÇ9="" ï‹="" ¾x×]w-[¶ŒÿÕcccÅë�úë;pÞÑ#!!á™gž¹kðkpž‘äää@úvu="" Än|w¬y³†iŠâ3lfåþýû…u•Ð_ Óe¢££ƒ[!t*•cyôÑg_ýõ×^{í§?ý©æ—<×£`÷ÀáŠj:44„Øi:{öìªu«4b¢ø="" �="" À- ª„þ2<<Ì6âvüà›nîÜ¹pþ|ðÁÑ‹hÁw0„Á^‚�="Ê-$¶•H!”ªÐûcS5¹¥&nbsp;!**jÁ‚£›ˆX">ÈO’ÑrÚ(�ÌüIYæætòÆtÚ²:»·�0È�þêÃ-•£|Ò+e©›¼9V9-‚Îsm5—'«ï­SïoV¿?Ç8×^6ÐíÛ+56é/Óï¬06‡™ç•õhkÆ’‚u¾³æÆRÕÝµÊçˆ«ƒ”¤TÂã‚ª1&gt;ô Us‰êfÂ\gþÆTòÅñ¤¹®4
ßQƒ^æH©9brvg]âL‡ÿL‡Ï¨Ä‡[žÔXœ„‚jm~,=;–UÞÕ`­âXv7˜Ó²}ËƒññÈýa¬¯6©
ïC\^š¯�3kœM}L½OŸ
&gt;1rb&amp;øÄlà‰Ù`#¥¨õ·`ÕW»&nbsp;¬ªëºµ¼B�Qc¥]¬
4YÏª»k€!«jÐ¼ê½»w^Ò¯ÚÞÕ!æ˜¶Ý¯úE’é'‰&amp;ýá¿Ìª0vŠö.À¼ÀªÚ¼*5CÏÆ0bkršÊ±½ÍQ#’hvQF+1½¹4«¿%uY“ry.mu8Kýº‹vÕ”.U&nbsp;yÕks´9%eœOÑšuŸkßÎ¨®©!¨p/
6ƒˆèoŸŽþï¯¡ÚßžN|ÿÁøÿþrþ~^ý¿[ùéã™G3òGsò‡³²{ÓÐíÖ¨ðÆ¨àƒUùŸÁ{þg�:ž^•~rSòùÉg„�¯4_‡ŽLüê�ÑjpðlA«¥11AU_Ö×ýº»˜…àÀŠÉ…Û¬:3¥Œ•Òpì’Ô&amp;pZK «æÆCVÁ¼*`UrZ(!)Œ€ƒ¬ºí×ã“…\õ#©U´k5°ªïóQÈÁ.f€U¯DÃ‘7boDÞŽ2˜/Oz³yU"²~±øõkõu€µ±“î=¿žUõëßcí©þrW^õöíÛ333ûö«ba¿êS¤_õÃD^�‰–Uu£ì_h¸x�UƒVEòª„UÓâ¹Po9	¼Ê¸!Ads,§$�_‘ÞR–¥¦\zïšó¿_|_cdU˜W¥]š¬†¬*&nbsp;"¥¿ŒE­Þö4hõöò`ó½…¶?ûÏo¦ÿþ×¹¿&gt;ÿþñøß¿Yzûß?,ÿhüÑìŽÞ"&amp;7G7Ç]jÿáÓ�o&gt;ìùâAû“ËâOo½v_ðp“»®fM	h3âjð¯?¼ô–¼6V¡á•÷6”õ6à»YEpœ£@L*ÜfÕQ”U“Ù%)Me‰¨ÞÒsâ«‹]4«’R�Þ†¢z‹Þá½Í‰òÒÞ
&amp;¿p7õ6ÜÍ&lt;ÐÙ,ßÃä¢·×co½�4˜¨.|³¬º_Ã…®ãú«.tõV×q]·ÞeU+++ÀªgÎœÑ³ª~ýAÖ/²ê¥ýYu¼,y=äÔ…ðS«á°Ar&gt;ôT´½��:Gì9®‚xøyC\&nbsp;SJ°Kn´sY’Sv„gv„oI¼g
ÎÏ’1Ìkò&lt;Ë“"H©a¤Ô¨¢G‹=³ ¦&amp;/ŽU×PŒm(Nj&amp;$öó‚ç{üz4Â()5CLÎi£æòÒÎ«cWG±çÕI=õ¨VÃ)CM„¡&amp;â0�¸Ð�_Ÿ(i¦N&nbsp;h_Ô®/•Ü8�ßœ ž•B€�Õ®“oœ/¿¹RöþùòõÒ¶å�Œ&gt;#¦ÏÉ©—¦K®/å_š)Xì.m¡Œ¶’Fx•šf¢š‡Žõ7.“dŸWÇ-k¢g:ãäÕ…rZøÙ$”,!)KP™ÞQ3©ð—¹õr½ê‹pu…ÐC&nbsp;6–÷P3ÁÓQ2-�ñßf”,||Pq\À&nbsp;ªÓ—�‚êód�«y˜³i�“‰�½1ËëÔDàñ©Àãã`û4TŠ[eo˜U÷×¸×­å‚üR· ÈèpUWWWÛØØèYu7«&gt;ûòÙ£‡ˆ·dÕ™ÙÙ{wî,-.¾”UÛw|€¡&gt;ÀXãž£YÕúåyÕhmMZ@YR`c©çìWuèá@V¥VÍÇÔÀØ)vH:*�h£'u5&amp;¶×%k„¸óC¸ÍiAeL´å*i«Ö–žë+»µZñp«êêYÊYeÕûž{°Tk»©¼�=ÐšßkýæÃþ&gt;SÿôlôéZÇ£ùWwÿã›ÉŸžMüøùøÇºLA´ûSm0vÝ<ziûöi×³gÊ ÉŸ="lûâ¾øãÛü‡[ÜKõó2ÆŒ„">ÑJ»¨¦Ü]¯º·AÜœ$Œ‹Ë{«²µ¬š/©*kKEúU£&amp;ä	ÇÆ§5•¡¬ÏÈM�×ø#ýª²7Èª¸ç¬úBYÊªÁÎ/eÕgÓ�¨3¨PÎ«gfJÁ	•½QVÝ5X
­ØÛ¬º·yjï¤¿ýKiÏ©öžßÎÎNÏªúõ»^»YõË/&gt;GûUûúÀÙ\X\¼}óæÙ³g_ZÜßÌü4š½ý$ÁäAœQs€ñî¼ª®Þ†¹iõV›W-Çò*ÝÕ­°_UÉ¬
¨-†UM&lt;ÄÕ1ÃâPµ JÆHêlHê¨OãVGq›3)F24‚üœMâŸUuù½uâÃKU[“”iiˆ|Ð6UTo«¢z»}78Ð|gNôíÓþ&gt;×üôÕØ£%ù‹Šïk~þjòçg“ýpôérçƒ©6ÄpÑÛQáÍ1á‡›òo&gt;|®·Ÿß}|‹½i]SÂ§i}ZR½1
'¡ÅÓhù6«6îÌòc@½�éÀ­¨c/G!cw’9øTÎ6«ÆÓs»½4"'µÐAPå	Y÷"«b^dUDo÷²j®»ÉfÔ™›Ñ—¢Î\‰<s-üÌ(µpþ°ê?[o¶·yõõf¨é:Ð[”umll�«‚ëyu¿þë_fu¹¬m¤4y9èär(Üká§§‚odØžö´>ãog&nbsp;‹«Úô
Ð�‡¤@'B²·Ü23Â5-Ä»0ÎMŠ°ªˆjAÉô(‰‡þ·É"ª�‚iS�S�…aäÆ€À˜™ßP¯¨
žVºO·{‹ýEUÉ­ÄAeV;+eº#ri0t±?²—�ÙýRŠºY°øPU_6À)�VäœÈèk ©!]V.õlNglÍd®Ž¡#Ãø”™6âÆDîÖlÖ¥³YGògdÄ1u\˜”2!"^ÉÜ˜J¾0’:-/`W6•îgÃKBð¯íí¨)éçfÎtD.öM)Cd´LQUŽñfç•gð‰¸öºàQ)P]')Í§6/©6^–¢Þìä´HzN&nbsp;œaÚUoÖYgFÎð.Šó/ÀøæÇxï€êvF§Ó¦ºSUh@5ÄÉ±g7bxœö?:âlÈï¨Æç¨Æß@ñæXU÷òp¯{ÀÞq�{àW»µh›UuYÍ×œ<yrÏª;yÕgh^uzxx,v½{çÎâkyµ£«cÄ¿“dÿ�™÷÷0Þè^œqg°‘—Ã¶·ÚtÞÙasy€#x¯g½>Ð¦rtrQ\`ib`ÞsúÛu³�¨™ðTÖäa9ñrô„&lt;`E°:¼&gt;¶1¹&gt;sa{q,im<eº=«�qÔ n?×�ÿ\éÝ5ÂåÙÊ³jò(�2-�ýs="" ªy€–j¬ó;Íªë½œ�¾¦«#Í_Üw|ýaÇ×�;ïÍiÞ|¸®øöcÕw÷~÷tõé•ö›ÃÂ›ˆûÙ�1Ú¸zwiðÅcég÷do®ð="" �²7Ôõûë–”µg%Œ³r:ÕÆ[«—h·v="" ·="" –®oàÇdeªºr;uïÌa–tŒiq‹1ç‡"f%1b2’w-ÝÉ«æ$È¾="" €tìÛ®äÔ]v-|}vu1]�8u1@[‹8½vjŸðÛ±ê~±“–uuÍº_Ý<¥kô±—uaì¤guýú½¯—äu!«^îc¼•o½”u‘ùªý\æ“h£ûqfwâŒ="">@æ«rüŒ|_nâ‘üât°Ø¯ÚBtäA`E­)5°*b�›ÐÆˆ˜ézxa4d}"Ñ[Ì…Ñøµñ¤‹c)£’œŽš¢.VIO=~©ûBé½õŠÍÉÊ))y¼è-4@õµTÒÕÛ3ü/(¾ù°óëÇ]·&amp;Dï?¹ÚþíS¨·ß&lt;îùhSqC#„ÀˆÞ^Ó´^æ?\½ýôŽèÑ&amp;oc°qS]¡—µ ßÖ[&nbsp;íSbê
4œ¼}a¯æ•ƒxÍ«vÀ–U¨·Óí	ç£—‡Âù±­•ÉœX¼�WÍNè¬÷TC`»V’Ç/³êN^5öEVÍq7¾ˆèíÅÈÓëá§7BO
S~#VÕ�¶·Yuo½™nËKõV·ÞLÏªúõ‡]û°ê‚B"þEVU—àæý�ÏŸ{9ìÔhÀñPëî–§|lN\
´7v4Þ5#ÎÇëëXŽ³å-3Ãý½
c�etKÛ¢…hMHö(Ä@!¸*c˜ñˆ6¤Ô¨ª´Èê,€rÑôœØÚü8&gt;)dDì8,vÒˆÜ„äØæ²”æ²t!9¥¿9b®Ç÷l�ÿPkŒ”š'«ÎSÒó@ð©dÀj“1qòÙÎø®Bo}©ª¾|F™¾2Œ]ÁÎu¥
pƒMC\ Ðùðù„ÕQì²:qZž&gt;3Ä-ëk$ª›Kûâ—5Q‹}˜Qf7³Žv…u,E�µ°tº'U*k2†Z#f:=ÇeÞò,��Å«Hm!$³KÒxDLg½ûP«�ŠcßXFÏŽ§eƒ€<w¥‡sÂ©ÙŠšmv%¥yäÇÀ�ªº½o {�”þ†" „Ž½¶1 ºï÷92ès´×ûhŸç‘="">ßÓ
ÑfÕ—ŽkÜÏ=à5`­ £¬ªÕd=«ÂõK¬zg_VíVŠøï'ØÝŠ6¸›ÊoÆ*
Ñ
à—g»JßÛ:ÞñëFZ¨P{%Ô¯„O…±þø„€ºb÷þfë�ÛÎz{Ô„Oôœ81-|Tê£òC5âðIÔXf¾³¢‰½8?Û•ÚQ“pµ�^2)+¼:Wps¥hkºtFQ¡á’'„U;£`×ê¼¼v”#	ÖÕîÆ�AöG7xŸÞ|zWxs†·Õ×|sšÿÑ5Ñ�$ŸÝz[‚¥+C¼+C-—‡Z¶ú›7¸ïÏr?ºÅ}zƒsï4@[�1çeµsmHà$¥MŠ©c&lt;Ê|gÅµ¥’÷Ï\Í–t³J{ê·“ª
zž„œ7*‰Ÿï‹XìV"ùDÀªˆY7ìŸŠÇVJ÷àÙðl¤ÕÎ¤Ô¤_AÖíWÝÝ?¥Û¯êjìYu1ô$ˆš€l.‡ž\
99VòæYu¿©ô¿¾YU;¡¬ª[“¦gUýú½¯�U«ª¸Ì{7c&nbsp;ÞÞ‹5¼mÐàkèã`¢ÛËÌ½M~É|&nbsp;·¥‰þ\‚ÐÛþf[Ã¥2%––ÅÈÅÐs°È�·¯Z4Ø:,Ž‘D�µÅ.
`V†ã.Ž%Œ·eÀhÞÕÏ*nœz[¼1Q:!!·�'…U:¦ëÛz{I°½½2Æùè&amp;ÿ³ûPo¯�¶lö6ß™oýø¦ø‹‡PoŸ^]QC±Eõvèí ÷öÐÛ¦'×Ù·ÏÕÏK˜²ÚyY
Ð[hå!­žR'Z«–T„+ÅïŸË_Õä5ã»ëð¨·™ä4¨·SJÌBøb_poSLÑÛ’m½¥eÇ·×¹
òíZlø•î•)!H¿ªvèüs+`8¹fGoµ7ùH¿ªy�³Y¶»ñRÔÛó;z«¦¼yV}Eo”nðë4«î½Ã×:ooo¯gUýú£­�Uå«'Mû›&lt;6pülð‰A¿£AÇ�ÍOxZžô±&gt;åg{&amp;À­Þž‚
B5  1ž¶øÑ"%È&gt;ÌÙ»$ÁZYk¡b›³Šì
0ž¹Q@‚üË’ü;ë,ùÎ¥	aÉ¡ä´°ªôJF5Ã*Œèm²îo�)žVrxCqRc1ŽƒÇ‰¨˜‰ë¸Üu\æ!¥%·óE¤<iužˆ\¤`d�hbg$‘2*^É(pÐj†…‰s=!ó½!ãmñ�µ¥Ð´è'aÍo?Û±Ø²Ð:¥ˆë©(zÐsw4¥,0ÕÒ×”‚|Ÿ<ÙÊh¹mÈdfiu–˜”%$e*j1€£‡eŽ] ìâ¬Æ’´†âva*ŸÜÝhÕÃ¶�tÛu¥Çk)•”jlÅ'„s�žw×›uÕ™•&zdfødflŠî2sÒõ="" u6a^úÛøÚœv³:er="">Öíu¤ÇëH‡çáN÷CÝÞ§eÂVEG'€•
…J¥ú•¬ºŸ{Êª¿8êMª¾ÔéN+È(«M1°6_sâÄ‰ææf=«îfU¡pæìÙ»wï¾‚U/am¯Fž¹Œ4•_‰2�øŸñ°…³éuÂ§=ck®Fx&nbsp;Kù¿b¬³ÐUÅ¶èm²T0mI©‘”ŒHdlMt[M`_³§ÛXœÄ-Ã5RZÊÒ†ø±½‘+šèÙ®„Îºì6j¡‚V¤æå¯Od^YÈÞ˜Ì›VàØÄ^%œG�z&nbsp;‰ªçd´•^ÚrcA�»W{X7Y�¯×?¾Úpy´qµ«q½Ÿ}k�ýá�Æ'×?|¿ñú4{­‡³¦b¯õ6^èn\í®¿4Îzt…ñðíæyÚ¢¢v[¯÷EÔ	!e¬•¬i&amp;MJ[Ó9—ç2V‡3†5%];&amp;À²ê1)wDs¶;h¶Ë¿·)&lt;#v15VbæÇÒ²°bªWo“Mo“•˜âX™\šRš&nbsp;[¬[®ÿ¢/%;¹˜;™F9›Ì†œQÓ&lt;ØÁ'OÅ¿YV}�i5{›UÑ£úR³î—–ÒžSmì¤gUýú½¯_`Õ¥¥[·níÃª�=MÌ÷ÃÎ&nbsp;z{#Æp+òÓÛÀËÎX'
BõVgô|èöØ&nbsp;·ù&nbsp;·þøx_N™S/ÇBÅ±’T;Uàb¨™Poó¢»ý:ëƒ8øxös½M“Æ,öG®GOÈ“:˜92*´¢aP9&nbsp;·kãùcâ²!ÔÛ±çzK›SÐ/ÐÎu"e-Jæúëá%Do¯4l²�Þ‚�wWØ@iŸ\oüàJãÕ	ö…NÎZ/{MÄ¶qµ§þÚóÑeúýMhApV@Rê´¸Õ[&nbsp;íÃ-•3Š²+Y—Î¦¯¨3¸ &nbsp;*Ñš®·Q¡ÞN*"æº¡ádG}tS)¼�Àaˆ�Guf¼¢Ö¥�kÝË±l©p%&amp;±
Fõ¶p§=jÛX{™ïg¯�‘À«
ô6ÐÉ4ÓÍh.äÄJèIðÕÛrþdÕ7Ò¬ºkZÍKëÍ´¬jiiill|úôi=«ê×dýë¬ÚÖÖ[”4êuTãwTã«Ê÷ˆ¿ÙGã£nfÇ&lt;,NxY�Ô&amp;Xƒ�U¶Št³ˆpµ*ÂZ‰©¦åÉfo§F¼iÇRQcFHvLõÌŒðÊŽò"§;wÕ[P3�
cññÁåIAÉ!Ä”0bJ$=;PQcÞÁ2ïn´h­tcæG×æ%°
€¾Ié~ÃB[�Ð^ÅqS1¼Š4&gt;1­�×ßì?!wëkÅä&lt;)5«¿%|\æ5!÷R·†’m£ÈªóeÕÊš� lRá
ö˜Ô_ÅÆJ)%’ª’vfÊ°È\æ&gt;,öênˆWA�B8ÍT¦·Óø0šÂ-Kk!$(j¼yÖà]¦µÒ‹U¢±Ký¤4ÛîsE�Mm¾_e
†”
žK(\–TTŒ
 g¸Ëè¦LÓv¦)1Õ&gt;#Ü-9Ø=%ØeÇž(ðÎm!â&amp;
@#ÄÙ¼°€RmÏøXŸò°&lt;éd~¢ÜñˆÂã�Òã�Ìý�Âí&nbsp;Üë¤BÔªììzƒ¬úÏŽk|�X·YÕËËKÏª/¬_bÕ{û³j»˜¿k³~z=òô¥È3‘§…¾§ÝmŒ¶�ä&gt;¸š³«nY‘n¹Q¹Q&gt; 0¨Éw¿ÀàÐIi–Éä´pRj#/LVãÕQï~É™ù	õE‰l|RCaZg}ÌtGÈÒ@ÈLgTwcŠ˜W^'+÷Ü n}wq<ur–ß[_>È)Ws+4-0ˆi©š‘‘.j*Î÷’§„tó,(i·–+ï®“î^$_¨YT²–”¬µ¡ÚÛ«Ôû›”û”÷«¡õ™’u®�¹¨»æâõöÂ­Õ²Ë³å³R2M
)ã­U ji�ÝåƒlÂ·lE“º6‘p^�¨nÍVÒ‹Ðé	mÕÙbr¶�”9,�éðú&nbsp;d†#–n	¨ÂŠ}JFœ€ìÞÕ
Ð$û
2_5~gÞßÎÀští¼¿M€³nÓ@'“H'ã‰&nbsp;ã jš;èøŒÿñ¡B„UÛß«¾~³ªîQÕ­ÐmVÕ��tÍºuc'”UAì¤gUýú½¯W±ªLXõÎ­[³/eÕöÎ.órÈé�ˆÓk‘§¯D�¹qšáyÆÓè­ñNd0
ÅÕû�)«®@o³¡ÞzæFùÇù°ñŽ@d@ÔJ²/Kˆ¦d„‘R£™…!�
îRz Ð[ó@½ÅÕ¤÷5GÎvŸ™�c:ëÒ$d˜²ìiÈ¹0š—ÆRGEE½
åƒMåêfToI#ÍUg••ëc„…Ê´ˆ&gt;+¡/«ªo­@½½s±j¹»ê­¢nk¬æÎ¨·w×¨×ÎV/ÊëàÀ¾væ‚œ¹¨¬Ù©º}¡üærÙÖ$a²•&gt;%F¯«FÁ÷o©Ts‰ƒÂp+~m·6n0±¯)OI/TÒQÃÉlÔÛŒ	YÐÛ1©—”ÝP„C3ªT�ÞV¥ÇIiŽÝ�–]
æMå.è„^ì¦Óe�&amp;UÑª³G“4WÃÉm½=ôvÖïxéÍ³êë4«êöFý³Ã´ƒüô¬ª_ÀõkXµ»0qÀóH¿Ï‘&gt;ß#ÃþG;&lt;{²58äl|ØÕô¨»ù1O‹ÞV§|Qbu@K‚MBœÍ±½l‹žF+Õ€j_“-×2-Ô1)Ð5=Ì¥"Å©“e3ØbÙÓ`Ë%Ø–&amp;Â*Äl@yR«Ð½“e×Û¾ÖB¿ƒ5�èÉÈ
§eÇ2rbY…QbªKo“å×º‡ãØUïÒÝèÒÇuäÙõ7;Ji!œâ<iux×k-pÒˆì‡Á‚¿õè®h%fh­ÄÜv¨zà<"†–§j�[g]€²&x�ï®8 ³¹íyn€…åt@¦Ü2\sŽsšÄf:,ê‹axþ)©¶ëio4Ö="" †½œîØÁ²íi°�Ñ­ëŠÝ="" ¸p™s‘kyÀs£f¹i¨¶Ýõ¶}l‹^Že“ew�u[µ="" !Þ»být»s‘«bwsð2‚3ÐÞÐÏöŒ¯õið"ƒ—ÚÕì˜½É±b»cb·ƒr·ƒb×bçb÷="" ±ð�°ê«y·yõõ§Õì="" €qvš¬��õ¬ú‹¬zÿyu19Æz5ìÔrØöÔÝïs®vv†¯ÂuÄ�še‹opÎŠðÊ�ö¦ç:u7˜�˜�o²(m'¦„’¢jd5n’j="" jf|m="">õ@cå'KhÑ#bÿ¹nß)e�ŠË'äJ)Y’ªÜ)%ö¼:fe8vB–Ö]WÜS‡ïkÄ÷³Ë´4'$¥Ëƒs¥ÃÍU à™–�/Ÿ-¼¾Tpm¡h±‹&lt;#¡M‹és
êú(áÆrÑõÅ’ëKÅK]U3:òWÕÓbêRáêBÎ•¹ìµÑÜ±VÒpØDu3q¨‰°Ý]^�ïf•Îv&amp;žŠZì�ä%ˆF
ÐDä~E–€ŒøMÈ]Á‘QÃ˜ù8œJä%†–ENÃð*\:Xàh›ñ+íK“‹âÀöÝU�Wƒ*x©CœLüŒÃŒ†ŽM86êlÜçXV®øMXõ�&gt;^Ý¬ú
£4vÒ³ª~ý›­W³êâ+Yµ»‰¹tÕÛõˆÓçÂNQÝO»[À–¨íû(wÝìê®†ºÔäÛÄºf†{çc¼Jì�Þ©i*·-Ž‹"¥—'F7”ø(YŽ<r@ul;Ö!zËÌo‘×fŒËüæz|ÇeÁ�õ ‚Š)%»­:g®³¬‰yŽ…�k»õ¶rj†_Õäo·fz ÞÎ)‰wæ¶õvnk…Ã.vr¶&ËÞ?õöê|É¼‚:#†õ½s¢ê="" ue ="" èíå³Ù«êm="" °êmÅ¶Þ6–ªêñ½�Å½qËêÈ…¾'è­Õ[r&¿"sx•4*õš�»ô·¸ó*£™ùiˆÞbè9°cŠ”Šqì:ë`c»Ì„leq@o÷Ž›‡zëo¿k:ª·~Æ)Î#ˆÞŽîè­Š”‡ô¿1vÕ-�Ömv}�†‹½ÍªhÃÅ®fu4.¬="" 4vÏªúõg[Ïyõoûéë¯ÿ)ví(hìv;Ôå}¸Ëëð€ï™Ç!÷3ïyžzÏÎà £á!'ã#.�x�#Äú<Ç`oœhr_d,­6•Ðldsr†yj�="" ÖÇ="">ÁÏäXgÇ)3ç”Y´TXÖæ[`Üs£¼óc|Šâ¼©YÎüJ«–
ë–
›¢M+É¦®È­*=%"EÂŒÜ0N™§˜j'¯±TÖš+j,Ûhö²'·&lt;FÑ©-AmtWÃEÆp•3Ü5®ŠZW)Õ›ƒOå–&amp;qði<blÝ|rqþÖmlñvùËk\dt—6ØÎm4')Í©•ä]w˜twˆeb™È5 ´šÉ�¡ç`hÙÐÔ—[Ôff7—3Ì%Õ–ÍzŽwyr`i|pi¼1Ö¯0†¸9q="">€ÍÙxn¹%øØXb6§Ô‚]bVg…õ±Åxm·¦î¢T[Xô^XOËàEv5=êh|ØÆðp¾õ¾ó{­ÎZœßã9¾Çs=®Þ,«êvdèvÀíç°wZ
¿T�Qc¥]1°žU_ÂªÓÍ/³ªˆ¿iµÇÁ©»‹¡'9ž'œ,NûÚœ	°G=Ð`1pÄŽŠ«	þŽINÍ‹Ê4»ôP÷¬Z®CrÏßˆ·*ŠƒMš¥ñuEžš5—àIJÅÒ‘Ž*@¬5¹‰Í„è^®Ï¤Üm¬ÍSÕÊ-ÍT¦ñÊsúšãf»BB&amp;d±ÝõY
@ÜÅ,‚£µe~þ\WÚ„4¿¯ÐeÅ0¿üâXÚÆTÊúdÚ´¬æxd@&nbsp;gÛñ›Óië“é[³©‹ªü1AåŸ4Ì«{FQ¸6‘¸6žpn y°	À)Ø¥}HÈ„6˜w2åÕ%êÖøÙîà³=þ-1
4g�`iDSI¦ˆ5ÀsÙwÔ»sÊ"9	5y1´ìh´hŸ˜ÕLpjgš!¬jW
0Þ/	œà-ÓîŒj(ÒWîkgbgÐïwtÄïèØ&gt;GÕ^GTùqo–U_g°Ô«c§×,µ÷žßÖÖVÏªúõ»^û°ê…á¾Þ_`UðFË©=ïb1êíJØ©¹�“$×“.–§}aK”ÀU¤Øl×õ Ð[€«Òj³’‡´Ïœ(÷úbxÝ­dZ0í
bÂ	¸&lt;6ŠSî"¥Y7”ø“Óâè9Q5ˆÞ2r“x•C­ž“
7À}u‘ÍebzkEö� f^ôvDßÉÌUÒ�„z[S&gt;"Ì[P¥Ž´÷7›*&amp;$øµñT¨·iãÂŠ½­\ì.z»1•&gt;ÎwŽðªFù•Ã-¤&gt;q®+èíÅÑÄUZ_}%&nbsp;` ¶Z·IÄ@©HÉ(cæT�g»ýTl¬¸*S@Ê„o„4niš¤:\#tz+¯õl(‰aäÄƒ 
5œ¬J�¨HŽ’m:X«–:�¨©ã—=v'wgTa°´m8é²m8écg˜äxzÐïè¨ÿÑTo=�tU¾IVÕ-~�á{§ƒéÖ›¡z«Ûp±k�`U###=«ê×gíÏªÐxeUµZ—Uå;¬ªÈKPºTx”{êö&gt;,r;è|òmÓco[�|Çæ4 Ö�X»˜&nbsp;UÁÇaU°õ)›3�†oÃ”ãŒÓ”SŒ§y¤Pèçc›`—f›nŸeŸé�êš}Ý=€:åÇ¸—$¸•$¸—&amp;z”%y’ýù–%–%pAÄä�ŠäðÊÔÐêlÿš|_f¡³À¯&amp;/ˆ–Q�‰¡eÅÒsQF1ÂXá¬‚ˆºB¸ë‹Âë‹"™ù°ò„Yx6®¾(ª¡8|²¾&lt; šUSWÉ*G¾0ŒYZ›Ž`)b�®FiEûO‘ÚÈpbrDej05Ó‡–ãIËñ¨Êð,Çù@÷Ìswßß$÷Ì—œ(ðL3ÃíÁOµM
±I
±Š÷…¯I$RÊ‚
/tJ=ƒP*Ì¥º›”êlrÄÑè��ÁAËS²-Þmr|—ëô.Ûá]¶ý;§cò7Çª»`T�u`ÝªÂW�kÜoZ�–UÑX›¯Ñ³êV]ŸÖ¨_Íª2„UgÂ-f�O��ÓLÐ‰:÷ãf°Dßw´X»8oGÑ‚”fƒpMqcäÙªØæ�u”,û¼hhÃXÚPâ*¤XÕä{’b(aà Ð²Áç(FQëK„N=N	Ž[šÒ„OS†E�3�ÞòÀN¼˜œßFÍ“ÓòŒ|ßßœ6)�Uó3:kÊ`
€]¼Ô�YÖDŸÂhZúQö$¨y%‹½‰0_&nbsp;‰YìÃjøEàóàoA˜4*Ê:7~n |¶3¦»®¤‹	M“:kÛá¤ch�$§çŠÉJ&amp;nDâB»þ	%�[šÕ\žÒTš\_�ÞF÷ék¶ëãZÈÞ�R³bµ­å•©a¥‰MåŽ(«ò*l‘»&amp;ßÜ´ç=ªhàä³c€†Vì;ƒóëogèms&amp;Èæt·74@SyQyîõ8Ü™'«½Ãàÿñ×°ê~ÍS¿X«ÿÒæ©W×êï½ç×³ª~ýÞ×¾¬ÚûË¬ÚÉ©�÷9&gt;t|*èÄBÈÉÉ&nbsp;çãŽæ'½�³X`fìdö\oaØëcïë(§›—ÄÛ&amp;ø¹gE¸4âm€ÞÊè–¤t§Ü¨`|¼_alxK…C+Éš–íW�‹¦d„#zMËÆ²
£»ÝÔB¨·í¬@&gt;è-·4]JÇŽË|gº¼ÇÚ‚:ëpâª&lt;&nbsp;·
¨·m”R57­Äô7åvÕ–v×á‡Zò—¶õv�[É�F„‹ýñPoÕ˜…ÞøÁ¦R&nbsp;·½
@Šñm©@oû#¦Øv¡‹Y„èm�Voe´\IU^G]Â¸Üè­Š$$á¸eÜò&gt;¥±8YQë&gt;À³éåZ·TÀ±Y˜ê,J‘ÓÂ*SÂð	‘­$Èª]uf
%ŽèÝ&gt;4¯Ó5þ}aÖüvé¯ŽÞxÙœ‰·?Õƒèmª·î‡;ˆ¹r…R®ìPüjVÝo8ª·ºŽëû
GØ«·ºŽëºz«:�²ê©S§Àãõ¬ª_„¥Ëª?¾Èªýýý[[[—/]Ò¼˜W•Éd
„U¥¹ñ§b·ƒ`+&lt;µ¸°?ög£Ão™û³Åñ¿Xž|ÇúÔ{vg8t2:xÊÕô˜»ùqË“§ÝÍÏxXz[ûØ˜Ú›‚P9ÜÕIîXF{XG¹ÛE{8`¼â|Q{Òä`g M©Án)Ážé¡^aÞYá¾Ù‘¾¹Ñ¾ùßÂXß¢8¿¬?&gt;&gt;é ƒnE¥‰áå‰á„¤`ÃHiÐ£‰”IJ�&amp;¥Æ�ÒbÈ`§cªÒ1”XpDl&nbsp;ÿ”LxÇVeÄR2à_�]…&lt;ŒŒ~IZ4ò"IKC+SB‰)¡É!\p9.¨,	øÀ'cƒ
0Aù1�yÑ¹Qþ9Q~9QÞ9Q ¬EmB¡iR°3â\ç„õqŠõvŒñtŒö°‹t³�pµ	u¶s�N,Û‰TÄ=ÉÏæ4€}@€Rþ»˜u2&gt;ì`tÈÞà&nbsp;íé÷¬N½kzì�T³·ëìßi°‡i÷Ëæm–ÃQ¹èÍ°ê®øu:à^=®q?AF^kc`”U�?Îårõ¬úÏ²ªBÄµ÷?6pl):­q=jkO¢—å	ðëä«ã�¶ã¶d�¼éÛµTXP2-üœÒBaê¿�cÑF·(À¸fGú€sW€ñç”:µ’l+Ó¼K°áÄ”`pÊÈéáätGÅ´’<zØv}ÍÖ] Î�%Ñ¬‚äÆâdœ(™aj¡ëx›àd15©•˜#"e‹È9jö="" btÔÓˆk£Éiùíµ¹ÓíÁg»f»‚z›2ÚkŠ;k‹;jkºxešÖÄyuÀÙ®à9u š‡cfõ•vÔ="" 4'ÏvúÎtúŽjcäô|¤="" }ÇýŒ’%&gŠhb¿"£«!`hàØßâ(¥�Ÿª¾(¹®0©¡£dÚ©Ø2†m]q="" ¢="" °3·2ð²Ä�¢¸pv©ƒ²ÆnÍ5¥‡yi)uÇ�Ívk€{¦�ÀiÇ�íŒ§Õ)«“="" ÏÃ="ž‡ÛÁö8ÔávH™�º;Þ«ê�ë}ì7éoo°®ÑÇÞæ)ÔX÷ž°*ˆ�lllô¬ª_¿ëõkXµƒS;åul<�êíTÐñá€cxÇ£v&amp;ÇÝ-NxézN:‡ê¸-Åx¹°“1ÌËq–±^®¹Ñö¼JØåÔJ²Ê�qËŽðÍCôV@¶k*·¯HöÃÇ”!¥†Áëñt¢HiÎ*Ô[E­Ð±ºB¢·)]�¾Ãb—1©K'DDIÑê­”’=," ‘u°ÒeÔb9­ »!cº#ÕÛ®úÜ ·Ì¢Žz|w}þ¨8ÕÛyuà�7­£¶èmgm¡šôvºÝo#Œ�t•È«ó ÞrwÜ&µzkÌp5y”îã:‰ªÂŠ“ëà|ùdnidw½•Šc!­¶­É£d@�g(5´õ¶0.”_iÓÁ„z[wlŸå¥«·¸@§ú,t="" 'µ!“�ÍiËs±¶'€Òª<+½ít="¤¬€¬ªhïPÈå¿žUu×_s²ê.Çõ×iVEM×QV577×³ª~ý¡Ö.Výa‡UAÔÛ××·¹µuåòe”UÛÚÚtYˆ³(Ë·�ïòÏå€Äí" Ûé="»£oú“Éá?™yËôèŸÍ�ýÅòøÛÖ'ß$ef;ÍêŒ¤Y=-Ž{[¡Ò}ÚßîÌÎ}#ê?`én†ÌÛ5vêdììq�)!Ž)!Né¡ÎéaÎáp¾�ÀœHÏÜ(¯¼hï|8hÃ»0Ö»(Î§8Î·ë[ïà±ìÄÀ²D8¼" lÝaÉ`wÀœ,ºÁŸƒ‰Ègd#Àà†_rž;gËp&ÅÇû#5½°ß¿(p³o="">b¥žã•
~*�ì÷¬p·Ìp×ô0èè‹Æ´IH• â
•6ÎÛ
qH¶Œò0Ï=ÂÕ4ÌÙ$Ä^Øø#M©^V§Ðr_H©&amp;G ¥²;sÀæÔ{V'ßµ&lt;ñ¶Ù±¿þs¢ñŸé6o×Ø¾M³y›fýºÝa™HÐÞÙ¥üu¬ºŸ[Ë?¿Z�µÆJÚÍ×MÖ³ê¿ÈªB¾:Ø\ãËM‡ýáÇjç#VG^¨v°9ígk&nbsp;ã�ájælÝB4o®0Á'YU¦[+jÌT�–õÅ‰þžð²Å«çÚJ¶VÙP2ÜÀÀÇ�Ã…G£fó*œÓuÖ™·3­›	ž´ìxX'Ÿ›ÄÆG)™ƒ&lt;Ûž}Wƒ‡�ÓZ™(¢`»üG%.C9#NP‘+¡¤¶³âF$cmncR;FÁHm£fK)yRj®²6
|r¼ÍcBæ®øw°’¤Ô9#­·)lTê:"qjõPÔb¥”aeF+–¶ÝÏšË“¹eI�Åé¼ŠÈvìmogÙò*½ë
£ë‹ÂD›Î:‹–»Ô£*=Œ˜Ûr¡Z`1xvI¾•i^&lt;¢M;x^,3Ù²"Å1'Ú59ÈDM¨ÖgWœP4?h€vÄ«®æ'¼-Ž‹Ý*Ýµ�ív°Íå€,£PÈ•]¿«¾¢=ªºµúºÓjtkõuÒ´±“žUõëßoýVmg×ŽxUûB¥¸:àw´Ðîˆ�!Ô[xQo¡SÐ²ãà�è-�ky�9»Ô¤ Î†žgÙÁ2BDÏµÂxfF@½%¦:·Ñ¬Z*ìHi%ðN&gt;zN½M	£e‰ÈvH½‡¹œaË)ó£ç`kóãjrqœ²ˆ®—A¾í@‹};ËGPôVB�Uq|ÆeN<o)' æh«sº¢µzÛÕ€•ÓÓ!u"zÛyŸ8Öæ1.ó˜�»="" µ*kr¥”emrs0ÐÛa‰ë�Ï§�Ž“t¥=""  Þ¦½åíèms f Àa]="" Ðf¾Æ¾™àô–�’t[w7€§iywèmjbnl)ÇƒÈª$="">°çKJ÷UY‚çô–[nU–ä”‰êívø›¤�têóº_c]ÃIOË“.æ'¢¬ŽIÜJ•º’½u&gt; ¯È2«|£¬úŠi5¯Ùp¡ÕÛ½ÀzVÕ¯?øz«ööõmll\¾|yxxx/«ÊÛÚÙXŽí;§wÁæ»`9¾kwl›U·÷¡?™~Ëì(’f=ñŽõ©w!´„Ðjtˆ–µ9„[·}ƒC ·š‚`„ÍQîÈÝ#:ëX¬¯í6ºú;€ä”‚f]C]ÓÂÜÒaÁ0ÀC÷lÄ&gt;'Ê372,œ¾A²l•ÛÙØí�…ƒ9�í_„…ì‰ü~}@aœ_áÎW�ï¾øn“¢½Ð’.;Ò#+Â…</o)'></zøv}íö]></blý|rqþömlñvùëk\dt—6øîm4')í©•ä]w˜twˆeb™è5></r@ul;ö!zëìo‘×fœëüæz|çeá�õ></iux×k-pòˆì‡á‚¿õè®h%fh­äüv¨zà<"†–§j�[g]€²&x�ï®8></ur–ß[_></iužˆ\¤`d�hbg$‘2*^é(pðj†…‰s=!ó½!ãmñ�µ¥ð´è'aío?û±ø²ð:¥ˆë©(zðsw4¥,0õò×”‚|ÿ<ùêh¹mèdfiu–˜”%$e*j1€£‡ež]></w¥‡sâ©ùššmv%¥yäçà�ªº½o></eº=«�qô></yrïª;yõgh^uzxx,v½{çîâkyµ£«cä¿“dÿ�™÷÷0þè^œqg°‘—ã¶·útþùasy€#x¯g½></s-üì(µpþ°ê?[o¶·yõõf¨é:ð[”umll�«‚ëyu¿þë_fu¹¬m¤4y9èär(üká§§‚odøžö´></ziûöi×³gê></u></a></i></u></i></u></s></b></s></i></b></b></i></s></i></b></b></s></i></i></s></i></i></i></i></i></s></b></i></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</a></em></p>]]>
            </description>
            <link>https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693589</guid>
            <pubDate>Tue, 06 Oct 2020 00:17:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical guide to SAML security vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24693133">thread link</a>) | @duckduckwut
<br/>
October 5, 2020 | https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns | <a href="https://web.archive.org/web/*/https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><p>If you’re here, you’ve likely been tasked with building SAML-based SSO as a requirement for an enterprise deal. If you’re just diving into the problem space of SSO / SAML, we’d first suggest checking out <a href="https://workos.com/blog/the-developers-guide-to-sso">The Developer’s Guide to SSO</a>. Otherwise, buckle up for a brief but titillating foray into why XML-based authentication is... challenging.</p><h2>Why is SAML SSO so vulnerability-prone</h2><p>The attack surface for SAML authentication is extensive, mostly due to the fact that SAML is XML-based. <a href="https://everypageispageone.com/2016/01/28/why-does-xml-suck/">XML is a semantic-free meta-language</a> - it’s hard to form, hard to read, and hard to parse. Combined with the high complexity of the <a href="http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.pdf">SAML specification</a> and the number of parties involved in establishing authentication, we get what often feels like a <a href="http://www.laputan.org/mud/mud.html">big ball of mud</a> and all the accompanying implications. Be prepared to tackle a steep learning curve, lots of bugs, high maintenance costs, attack vectors galore, and an absurd spread of edge cases.</p><p>Most SAML SSO security vulnerabilities are introduced by Service Providers (SPs) improperly validating and processing SAML responses received from Identity Providers (IdPs). This happens because SAML SSO is typically not a core-value feature for an application, nor is the implementation common knowledge for most developers. Unknowns become even more unlikely to be identified and addressed when the pressure is on to just deliver <em>something </em>to unblock a high-value contract - as is oftentimes the case. However, to build SAML SSO safely and securely in-house requires significant buy-in and <a href="https://stackoverflow.blog/2019/07/11/single-sign-on-sso-stack-overflow-okta-integration/">investment by teams</a> - on the scale of months, representing hundreds of thousands of dollars in developer time.<strong>‍</strong></p><p><strong>If not done right, you expose your application and your customers to potentially huge security risks. </strong>To drive that home, here are just a few recently published SAML-related vulnerabilities:</p><ul role="list"><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2019-15585">January 27, 2020</a> - “... GitLab SAML integration had a validation issue that permitted an attacker to takeover another user's account.”</li><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-4427">May 7, 2020</a> - “... an attacker could exploit this [SAML] vulnerability to bypass the authentication process and gain full administrative access to the system [IBM Data Risk Manager].”</li><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2018-21263">June 19, 2020</a> - “An attacker could authenticate to a different user's [Mattermost] account via a crafted SAML response.”</li><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-2021">June 29, 2020</a> - “... improper verification of signatures in PAN-OS SAML authentication enables an unauthenticated network-based attacker to access protected resources.”</li></ul><p>It should be evident by now that oversights in SAML implementations are ubiquitous and problematic, even among experienced engineering teams.</p><p>So let’s dive into some of the more common security pitfalls developers building SAML-based SSO should be aware of, as well as cover a few suggested countermeasures. Just to be clear, <strong>this guide is by no means comprehensive</strong> and is meant to provide a starting point for SAML security considerations as well as some follow-on resources.</p><h2>Brief anatomy of a SAML response</h2><p>Let's say we're integrating our application with Okta via SAML. Below is an example of an XML document we might get when attempting to authenticate a user, containing a simplified but valid SAML response:</p><p>Like we mentioned earlier, the SAML spec is complex and responses can get lengthy, so this example is comparatively quite terse. Keeping things to what you should know before we go into SAML vulnerabilities, let’s walk through what the response (<strong><em>&lt;saml2p:Response&gt;</em></strong>) is communicating:<br></p><ul role="list"><li>Line 2 begins the SAML response, which has the unique ID <strong><em>id72697176167120131651975993</em></strong> and is intended for consumption by the <strong><em>workos-test</em></strong> service provider’s Assertion Consumer Service (ACS) URL, i.e. the endpoint <strong><em>https://api.workos-test.com/auth/okta/callback</em></strong>.</li><li>Line 3 specifies the issuer (<strong><em>&lt;saml2:Issuer&gt;</em></strong>) and contains the unique URI (also referred to as EntityID) of the IdP that issued the response, in this case <strong><em>http://www.okta.com/exk1klancwHzz1SNi357.</em></strong></li><li>Line 7 begins the assertion (<strong><em>&lt;saml2:Assertion&gt;</em></strong>) with the unique ID <strong><em>id7269717616793800631152500</em></strong>. An assertion is a package of information asserting the identity of a user, often containing additional user attributes like first / last name, email, ID, etc.</li><li>Line 8 specifies the issuer of the assertion itself, in this case also <strong><em>http://www.okta.com/exk1klancwHzz1SNi357</em></strong>.</li><li>Lines 9 - 30 contains the digital signature (<strong><em>&lt;ds:Signature&gt;</em></strong>) over the assertion, which should be validated to determine the authenticity of the assertion.</li><li>Lines 31 - 36 specify the subject (<strong><em>&lt;saml2:Subject&gt;</em></strong>) of the assertion, i.e. the authenticated principal / user corresponding to the unique identifier found in <strong><em>&lt;saml2:NameID&gt;</em></strong>, who in this case is <strong><em><a href="https://workos.com/cdn-cgi/l/email-protection" data-cfemail="6e0a0b03012e19011c05011d4301051a0f400d0103">[email&nbsp;protected]</a></em></strong>.</li><li>Line 37 (<strong><em>&lt;saml2:Conditions&gt;</em></strong>) defines the window of time for which the assertion should considered valid, i.e. from <strong><em>NotBefore</em></strong> (inclusive) to <strong><em>NotOnOrAfter</em></strong> (exclusive).</li></ul><p>For the purposes of readability, the SAML 2.0 XML snippets in the remainder of this blog will be simplified, use shorthand, and be stripped of nodes that would otherwise be required in reality but are not relevant to what’s being illustrated. We’ll use a mythical IssueTracker, ContractManager, and PayrollService as hypothetical SPs that have implemented SAML authentication, which you should think of as placeholders for your application or other SAML SSO-enabled apps.</p><h2>Disable DTD processing</h2><p>The first step in processing a SAML response is parsing the payload. Parsing and loading an XML document into memory is an inherently expensive set of operations, but can be unexpectedly costly due to a feature of XML that allows references to external or remote documents, i.e. <a href="https://en.wikipedia.org/wiki/Document_type_definition">Document Type Definitions</a> (DTDs).</p><p>When a DTD is encountered, parsers will try to fetch and load the referenced document as well. If the referenced document is large enough or results in infinitely looping references, your server can be slowed or even brought down trying to complete the process. The same holds true if the payload itself is very large, DTDs or not.</p><p>Two low-hanging mitigations you should implement to prevent buffer overflows are:<br></p><ol role="list"><li>Limiting SAML payload size to &lt; 1MB. 1MB is a generous upper limit and should be tuned down based on average received payload size.</li><li>Configuring your XML parser to never fetch remote files or try to load and parse DTDs. Some XML parsers do so by default, for example, Python’s <a href="https://docs.python.org/3/library/xml.etree.elementtree.html"><strong><em>xml.etree.ElementTree</em></strong></a> module.</li></ol><p>XML processing, and thus by extension SAML response processing, is vulnerable to buffer overflow attacks from other scenarios described later on in this post. And unfortunately, protecting your application from a service outage is among the most mild of outcomes compared to the <a href="https://www.vsecurity.com//download/papers/XMLDTDEntityAttacks.pdf">possibilities exploiting XML DTD</a> allows - it is a dark and anxiety-inducing rabbit hole.</p><p>So, if you’re not writing your own XML parser (generally not suggested), it’s important to <strong>vet the XML parser(s) your application and its dependencies use</strong> - ensure they handle other exploits like <a href="https://en.wikipedia.org/wiki/Billion_laughs_attack">Billion Laughs</a> and <a href="https://en.wikipedia.org/wiki/Zip_bomb">Zip Bombs</a>.</p><h2>Validate the SAML response schema first<br></h2><p>The primary security mechanism in the SAML handshake is the cryptographic validation of <a href="https://en.wikipedia.org/wiki/XML_Signature">XML Signatures</a> (XML-DSig) - which establishes the trust chain between IdPs and SPs. XML-DSig validation should always be done prior to executing business logic; however, the separation between signature verification and operating on the rest of a SAML payload opens up SAML authentication to vulnerabilities exposed by what are called XML Signature Wrapping (XSW) attacks. &nbsp;These attacks have numerous permutations which can result in outcomes such as (but not limited to):<br></p><ul role="list"><li>Denial-of-service by inserting arbitrary elements that lead to buffer overflows.</li><li>Escalating permissions by injecting assertions that allow an adversary to impersonate and be authenticated as another user, like an account admin.</li></ul><p>The exploit here consists of modifying the payload without invalidating any signatures - think <a href="https://owasp.org/www-community/attacks/SQL_Injection">SQL Injection</a> or <a href="https://owasp.org/www-community/attacks/xss/">Cross Site Scripting,</a> but for for XML.</p><p>Original response (pre-XSW):</p><p>Modified response (post-XSW):</p><p>The broadest countermeasure to XSW attacks is <strong>validating the schema</strong> of the SAML XML document. Payloads for SAML responses of any given IdP should have a deterministic standard schema that can be used as a reference in a schema compliance validation module, which should be executed prior to XML-DSig verification. Here are <a href="https://github.com/onelogin/python3-saml/tree/master/src/onelogin/saml2/schemas">example schemas</a> used by OneLogin’s <strong><em>python3-saml</em></strong> package to perform <a href="https://pythonhosted.org/python-saml/library/saml2.html#saml2.utils.OneLogin_Saml2_Utils.validate_xml">XML schema validation</a>. <strong>Schemas should be vetted local copies</strong> as opposed to being fetched from 3rd party remote locations at runtime or on server start.</p><p>All of that being said, <a href="https://www.nds.ruhr-uni-bochum.de/media/nds/veroeffentlichungen/2013/03/25/paper.pdf">schema validation isn’t foolproof</a>; there is room for error in the validation module logic itself, as well as in the syntactic rigor of the reference schema. A second low-hanging countermeasure to XSW attacks that should be employed for the sake of redundancy is to <strong>always use absolute XPath expressions</strong> to select elements in processes post-schema validation. Explicit absolute XPath expressions set an unambiguous expectation for the location of elements.</p><p>Here’s an example of a valid response that’s been modified in an XSW attack (specifically a signature exclusion attack, more on that later):</p><p>This modification also exploits the common, incorrect, but not unreasonable assumption that a well-formed SAML response will only ever have a single assertion. So while XML-DSig verification would succeed for the signature returned by <strong><em>doc.getElementsByTagName(“Signature”)[0]</em></strong>, the assertion returned and processed by <strong><em>doc.getElementsByTagName(“Assertion”)[0]</em></strong> would be the injected <strong><em>snek</em></strong> assertion. This attack would have been more likely to fail if the XPath expression&nbsp;<strong><em>“/Response/Assertion[0]/Signature”</em></strong> was used in the assertion signature validation logic.</p><h2>Check that you’re the intended recipient</h2><p>This sounds obvious, but make sure to check that a SAML response is intended for your app. This is low-hanging fruit that can prevent attacks exploiting IdPs that use a shared private signing key for all integrated SPs of a given tenant, as opposed to issuing unique keys per application. The most common attack entails the …</p></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns">https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns</a></em></p>]]>
            </description>
            <link>https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693133</guid>
            <pubDate>Mon, 05 Oct 2020 23:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher-Kinded Data]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24692919">thread link</a>) | @jim-jim-jim
<br/>
October 5, 2020 | https://reasonablypolymorphic.com/blog/higher-kinded-data/ | <a href="https://web.archive.org/web/*/https://reasonablypolymorphic.com/blog/higher-kinded-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Today I want to demonstrate a “well-known” Haskell technique among library authors, that I haven’t ever seen written down. It allows you to do all sorts of amazing things, such as: generate lenses for arbitrary data-types without resorting to TemplateHaskell; <code>sequence</code> over data-types; and automatically track dependencies for usages of record fields.</p>
<p>As for this post, we’ll look at how to build type-level sequencing, and investigate some other uses in subsequent ones. For our examples, let’s define the following (completely arbitrary) data-type:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span>data</span> <span>Person</span> <span>=</span> <span>Person</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>  {<span> pName ::</span> <span>String</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>  ,<span> pAge  ::</span> <span>Int</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>  } <span>deriving</span> (<span>Generic</span>)</span></code></pre></div>
<p>That’s cool and all, I guess. For purposes of discussion, let’s imagine that we want to let the user fill in a <code>Person</code> via a web-form or something. Which is to say, it’s possible they’ll screw up filling in some piece of information without necessarily invalidating the rest of the datastructure. If they successfully filled in the entire structure, we’d like to get a <code>Person</code> out.</p>
<p>One way of modeling this would be with a second datatype:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>data</span> <span>MaybePerson</span> <span>=</span> <span>MaybePerson</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>  {<span> mpName ::</span> <span>Maybe</span> <span>String</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  ,<span> mpAge  ::</span> <span>Maybe</span> <span>Int</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>  } <span>deriving</span> (<span>Generic</span>)</span></code></pre></div>
<p>and a function:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>validate ::</span> <span>MaybePerson</span> <span>-&gt;</span> <span>Maybe</span> <span>Person</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>validate (<span>MaybePerson</span> name age) <span>=</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  <span>Person</span> <span>&lt;$&gt;</span> name <span>&lt;*&gt;</span> age</span></code></pre></div>
<p>This works, but it’s annoying to write by hand, since it’s completely mechanical. Furthermore, having duplicated this effort means we’ll need to use our brains in the future to make sure all three definitions stay in sync. Wouldn’t it be cool if the compiler could help with this?</p>
<p>SURPRISE! IT CAN! And that’s what I want to talk about today.</p>
<p>Notice that we can describe both <code>Person</code> and <code>MaybePerson</code> with the following higher-kinded data (henceforth “<strong>HKD</strong>”) definition:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>data</span> <span>Person'</span> f <span>=</span> <span>Person</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  {<span> pName ::</span> f <span>String</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  ,<span> pAge  ::</span> f <span>Int</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>  } <span>deriving</span> (<span>Generic</span>)</span></code></pre></div>
<p>Here we’ve parameterized <code>Person'</code> over something <code>f</code> (of kind <code>* -&gt; *</code>), which allows us to do the following in order to get our original types back:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>type</span> <span>Person</span>      <span>=</span> <span>Person'</span> <span>Identity</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>type</span> <span>MaybePerson</span> <span>=</span> <span>Person'</span> <span>Maybe</span></span></code></pre></div>
<p>While this works, it’s kind of annoying in the <code>Person</code> case, since now all of our data is wrapped up inside of an <code>Identity</code>:</p>
<pre><code>&gt; :t pName @Identity
pName :: Person -&gt; Identity String

&gt; :t runIdentity . pName
runIdentity . pName :: Person -&gt; String</code></pre>
<p>We can fix this annoyance trivially, after which we will look at why defining <code>Person'</code> as such is actually useful. To get rid of the <code>Identity</code>s, we can use a type family (a function at the type-level) that erases them:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>{-# LANGUAGE TypeFamilies #-}</span></span>
<span id="cb7-2"><a href="#cb7-2"></a></span>
<span id="cb7-3"><a href="#cb7-3"></a><span>-- "Higher-Kinded Data"</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span>type</span> <span>family</span> <span>HKD</span> f a <span>where</span></span>
<span id="cb7-5"><a href="#cb7-5"></a>  <span>HKD</span> <span>Identity</span> a <span>=</span> a</span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span>HKD</span> f        a <span>=</span> f a</span>
<span id="cb7-7"><a href="#cb7-7"></a></span>
<span id="cb7-8"><a href="#cb7-8"></a><span>data</span> <span>Person'</span> f <span>=</span> <span>Person</span></span>
<span id="cb7-9"><a href="#cb7-9"></a>  {<span> pName ::</span> <span>HKD</span> f <span>String</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>  ,<span> pAge  ::</span> <span>HKD</span> f <span>Int</span></span>
<span id="cb7-11"><a href="#cb7-11"></a>  } <span>deriving</span> (<span>Generic</span>)</span></code></pre></div>
<p>Using the <code>HKD</code> type family means that GHC will automatically erase any <code>Identity</code> wrappers in our representations:</p>
<pre><code>&gt; :t pName @Identity
pName :: Person -&gt; String

&gt; :t pName @Maybe
pName :: Person -&gt; Maybe String</code></pre>
<p>and with that, the higher-kinded version of <code>Person</code> can be used as a drop-in replacement for our original one. The obvious question is what have we bought ourselves with all of this work. Let’s look back at <code>validate</code> to help us answer this question. Compare our old implementation:</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1"></a><span>validate ::</span> <span>MaybePerson</span> <span>-&gt;</span> <span>Maybe</span> <span>Person</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>validate (<span>MaybePerson</span> name age) <span>=</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>  <span>Person</span> <span>&lt;$&gt;</span> name <span>&lt;*&gt;</span> age</span></code></pre></div>
<p>with how we can now rewrite it with our new machinery:</p>
<div id="cb10"><pre><code><span id="cb10-1"><a href="#cb10-1"></a><span>validate ::</span> <span>Person'</span> <span>Maybe</span> <span>-&gt;</span> <span>Maybe</span> <span>Person</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>validate (<span>Person</span> name age) <span>=</span></span>
<span id="cb10-3"><a href="#cb10-3"></a>  <span>Person</span> <span>&lt;$&gt;</span> name <span>&lt;*&gt;</span> age</span></code></pre></div>
<p>Not a very interesting change is it? But the intrigue lies in how little needed to change. As you can see, only our type and pattern match needed to change from our original implementation. What’s neat here is that we have now consolidated <code>Person</code> and <code>MaybePerson</code> into the same representation, and therefore they are no longer related only in a nominal sense.</p>
<p>We can write a version of <code>validate</code> that will work for any higher-kinded datatype.</p>
<p>The secret is to turn to <a href="https://www.stackage.org/haddock/lts-11.0/base-4.10.1.0/GHC-Generics.html"><code>GHC.Generics</code></a>. If you’re unfamiliar with them, they provide an isomorphism from a regular Haskell datatype to a generic representation that can be structurally manipulated by a clever programmer (ie: us.) By providing code for what to do for constant types, products and coproducts, we can get GHC to write type-independent code for us. It’s a really neat technique that will tickle your toes if you haven’t seen it before.</p>
<p>To start with, we need to define a typeclass that will be the workhorse of our transformation. In my experience, this is always the hardest part – the types of these generic-transforming functions are exceptionally abstract and in my opinion, very hard to reason about. I came up with this:</p>
<div id="cb11"><pre><code><span id="cb11-1"><a href="#cb11-1"></a><span>{-# LANGUAGE MultiParamTypeClasses #-}</span></span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a><span>class</span> <span>GValidate</span> i o <span>where</span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span>  gvalidate ::</span> i p <span>-&gt;</span> <span>Maybe</span> (o p)</span></code></pre></div>
<p>I only have “soft-and-slow” rules for reasoning about what your typeclass should look like, but in general you’re going to need both an <code>i</code>nput and an <code>o</code>utput parameter. They both need to be of kind <code>* -&gt; *</code> and then be passed this existentialized <code>p</code>, for dark, unholy reasons known not by humankind. I then have a little checklist I walk through to help me wrap my head around this nightmarish hellscape that we’ll walk through in a later installment of the series.</p>
<p>Anyway, with our typeclass in hand, it’s now just a matter of writing out instances of our typeclass for the various GHC.Generic types. We can start with the base case, which is we should be able to validate a <code>Maybe k</code>:</p>
<div id="cb12"><pre><code><span id="cb12-1"><a href="#cb12-1"></a><span>{-# LANGUAGE FlexibleInstances #-}</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span>{-# LANGUAGE TypeOperators     #-}</span></span>
<span id="cb12-3"><a href="#cb12-3"></a></span>
<span id="cb12-4"><a href="#cb12-4"></a><span>instance</span> <span>GValidate</span> (<span>K1</span> a (<span>Maybe</span> k)) (<span>K1</span> a k) <span>where</span></span>
<span id="cb12-5"><a href="#cb12-5"></a>  <span>-- gvalidate :: K1 a (Maybe k) -&gt; Maybe (K1 a k)</span></span>
<span id="cb12-6"><a href="#cb12-6"></a>  gvalidate (<span>K1</span> k) <span>=</span> <span>K1</span> <span>&lt;$&gt;</span> k</span>
<span id="cb12-7"><a href="#cb12-7"></a>  <span>{-# INLINE gvalidate #-}</span></span></code></pre></div>
<p><code>K1</code> represents a “constant type”, which is to say that it’s where our structural recursion conks out. In our <code>Person'</code> example, it’s the <code>pName :: HKD f String</code> bit.</p>
<p>Most of the time, once you have the base case in place, the rest is to just mechanically provide instances for the other types. Unless you need to access metadata about the original type anywhere, these instances will almost always be trivial homomorphisms.</p>
<p>We can start with products – if we have <code>GValidate i o</code> and <code>GValidate i' o'</code>, we should be able to run them in parallel:</p>
<div id="cb13"><pre><code><span id="cb13-1"><a href="#cb13-1"></a><span>instance</span> (<span>GValidate</span> i o, <span>GValidate</span> i' o')</span>
<span id="cb13-2"><a href="#cb13-2"></a>    <span>=&gt;</span> <span>GValidate</span> (i <span>:*:</span> i') (o <span>:*:</span> o') <span>where</span></span>
<span id="cb13-3"><a href="#cb13-3"></a>  gvalidate (l <span>:*:</span> r) <span>=</span> (<span>:*:</span>)</span>
<span id="cb13-4"><a href="#cb13-4"></a>                    <span>&lt;$&gt;</span> gvalidate l</span>
<span id="cb13-5"><a href="#cb13-5"></a>                    <span>&lt;*&gt;</span> gvalidate r</span>
<span id="cb13-6"><a href="#cb13-6"></a>  <span>{-# INLINE gvalidate #-}</span></span></code></pre></div>
<p>If <code>K1</code> referred directly to the selectors of our <code>Person'</code>, <code>(:*:)</code> corresponds roughly to the <code>,</code> piece of syntax we separate our record fields with.</p>
<p>We can define a similar instance of <code>GValidate</code> for coproducts (corresponding to a <code>|</code> in a data definition):</p>
<div id="cb14"><pre><code><span id="cb14-1"><a href="#cb14-1"></a><span>instance</span> (<span>GValidate</span> i o, <span>GValidate</span> i' o')</span>
<span id="cb14-2"><a href="#cb14-2"></a>    <span>=&gt;</span> <span>GValidate</span> (i <span>:+:</span> i') (o <span>:+:</span> o') <span>where</span></span>
<span id="cb14-3"><a href="#cb14-3"></a>  gvalidate (<span>L1</span> l) <span>=</span> <span>L1</span> <span>&lt;$&gt;</span> gvalidate l</span>
<span id="cb14-4"><a href="#cb14-4"></a>  gvalidate (<span>R1</span> r) <span>=</span> <span>R1</span> <span>&lt;$&gt;</span> gvalidate r</span>
<span id="cb14-5"><a href="#cb14-5"></a>  <span>{-# INLINE gvalidate #-}</span></span></code></pre></div>
<p>Furthermore, if we don’t care about looking at metadata, we can simply lift a <code>GValidate i o</code> over the metadata constructor:</p>
<div id="cb15"><pre><code><span id="cb15-1"><a href="#cb15-1"></a><span>instance</span> <span>GValidate</span> i o</span>
<span id="cb15-2"><a href="#cb15-2"></a>    <span>=&gt;</span> <span>GValidate</span> (<span>M1</span> _a _b i) (<span>M1</span> _a' _b' o) <span>where</span></span>
<span id="cb15-3"><a href="#cb15-3"></a>  gvalidate (<span>M1</span> x) <span>=</span> <span>M1</span> <span>&lt;$&gt;</span> gvalidate x</span>
<span id="cb15-4"><a href="#cb15-4"></a>  <span>{-# INLINE gvalidate #-}</span></span></code></pre></div>
<p>Just for kicks, we can provide the following trivial instances, for uninhabited types (<code>V1</code>) and for constructors without any parameters (<code>U1</code>):</p>
<div id="cb16"><pre><code><span id="cb16-1"><a href="#cb16-1"></a><span>instance</span> <span>GValidate</span> <span>V1</span> <span>V1</span> <span>where</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>  gvalidate <span>=</span> <span>undefined</span></span>
<span id="cb16-3"><a href="#cb16-3"></a>  <span>{-# INLINE gvalidate #-}</span></span>
<span id="cb16-4"><a href="#cb16-4"></a></span>
<span id="cb16-5"><a href="#cb16-5"></a><span>instance</span> <span>GValidate</span> <span>U1</span> <span>U1</span> <span>where</span></span>
<span id="cb16-6"><a href="#cb16-6"></a>  gvalidate <span>U1</span> <span>=</span> <span>Just</span> <span>U1</span></span>
<span id="cb16-7"><a href="#cb16-7"></a>  <span>{-# INLINE gvalidate #-}</span></span></code></pre></div>
<p>The use of <code>undefined</code> here is safe, since it can only be called with a value of <code>V1</code>. Fortunately for us, <code>V1</code> is uninhabited, so this can never happen, and thus we’re morally correct in our usage of <code>undefined</code>.</p>
<p>Without further ado, now that we have all of this machinery out of the way, we can finally write a non-generic version of <code>validate</code>:</p>
<div id="cb17"><pre><code><span id="cb17-1"><a href="#cb17-1"></a><span>{-# LANGUAGE FlexibleContexts #-}</span></span>
<span id="cb17-2"><a href="#cb17-2"></a></span>
<span id="cb17-3"><a href="#cb17-3"></a>validate</span>
<span id="cb17-4"><a href="#cb17-4"></a><span>    ::</span> ( <span>Generic</span> (f <span>Maybe</span>)</span>
<span id="cb17-5"><a href="#cb17-5"></a>       , <span>Generic</span> (f <span>Identity</span>)</span>
<span id="cb17-6"><a href="#cb17-6"></a>       , <span>GValidate</span> (<span>Rep</span> (f <span>Maybe</span>))</span>
<span id="cb17-7"><a href="#cb17-7"></a>                   (<span>Rep</span> (f <span>Identity</span>))</span>
<span id="cb17-8"><a href="#cb17-8"></a>       )</span>
<span id="cb17-9"><a href="#cb17-9"></a>    <span>=&gt;</span> f <span>Maybe</span></span>
<span id="cb17-10"><a href="#cb17-10"></a>    <span>-&gt;</span> <span>Maybe</span> (f <span>Identity</span>)</span>
<span id="cb17-11"><a href="#cb17-11"></a>validate <span>=</span> <span>fmap</span> to <span>.</span> gvalidate <span>.</span> from</span></code></pre></div>
<p>I always get a goofy smile when the signature for my function is longer than the actual implementation; it means we’ve hired the compiler to write code for us. What’s neat about <code>validate</code> here is that it doesn’t have any mention of <code>Person'</code>; this function will work for <em>any</em> type defined as higher-kinded data. Spiffy.</p>
<p>That’s all for today, folks. We’ve been introduced to the idea of higher-kinded data, seen how it’s completely equivalent with a datatype defined in a more traditional fashion, and also caught a glimmer of what kind of things are possible with this approach. This is where we stop for today, but in the next post we’ll look at how we can use the HKD approach to generate lenses without resorting to TemplateHaskell.</p>
<p>Happy higher-kinding!</p>
<hr>
<p>Big shoutouts to <a href="http://travis.athougies.net/">Travis Athougies</a> from whom I originally learned this technique, and to <a href="https://github.com/asweingarten">Ariel Weingarten</a> and <a href="https://github.com/FintanH">Fintan Halpenny</a> for proofreading earlier versions of this post.</p>

<p>
    <span>
        <a href="https://reasonablypolymorphic.com/blog/navigation">←</a>
    </span>
    <span>
        <a href="https://reasonablypolymorphic.com/blog/free-lenses">→</a>
    </span>
</p>

</div></div>]]>
            </description>
            <link>https://reasonablypolymorphic.com/blog/higher-kinded-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24692919</guid>
            <pubDate>Mon, 05 Oct 2020 22:48:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NSL (Neural Simulation Language): simulation system for neural networks (2002)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24692422">thread link</a>) | @blacksqr
<br/>
October 5, 2020 | http://www.neuralsimulationlanguage.org/about.html | <a href="https://web.archive.org/web/*/http://www.neuralsimulationlanguage.org/about.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
    <td> 
      
      <blockquote> 
        
        <p><span face="Arial, Helvetica, sans-serif">NSL, Neural 
          Simulation Language, is a simulation system for large-scale general 
          <a href="#" onclick="MM_openBrWindow('definitions.html#NeuralNetworks','def','scrollbars=yes,width=800,height=300')">neural 
          networks</a>. NSL provides a simulation environment simplifying the 
          task of modeling neural networks. In particular, NSL supports neural 
          models having as basic data structure neural layers with similar properties 
          and similar connection patterns, where neurons are modeled as leaky 
          integrators with connections subject to diverse learning rules. Development 
          of NSL has gone hand in hand with modeling of neural mechanisms underlying 
          visuomotor coordination, with special emphasis on the analysis of data 
          from anurans, monkeys, and humans. NSL follows an object-oriented design, 
          providing higher level programming abstraction corresponding to neural 
          elements. NSL provides system development tools, such as visualization 
          capabilities and a run-time interpreter, which give the user powerful 
          tools in developing and analyzing models. NSL has been widely used throughout 
          the world for both teaching and research. </span></p>
        <p><span face="Arial, Helvetica, sans-serif">Current development 
          goals of NSL are to link between the multiple levels of neural modeling 
          and express the fact that neural networks can themselves be interconnected 
          in a hierarchical way, creating higher level assemblages, such as those 
          explained in the schema model in ASL - <a href="#" onclick="MM_openBrWindow('definitions.html#ASL','def','scrollbars=yes,width=800,height=300')">Abstract 
          Schema Language</a>. We are currently working on a soon to be released 
          book on NSL3.0. </span></p>
        <p><span face="Arial, Helvetica, sans-serif">Project Directors</span></p>
        <ul>
          <li><span face="Arial, Helvetica, sans-serif">Alfredo Weitzenfeld</span> (USF)</li>
          <li><span face="Arial, Helvetica, sans-serif">Michael Arbib</span> (USC)</li>
        </ul>
        <h4>Acknowledgements:</h4>
        <center>
          <span face="Arial, Helvetica, sans-serif"> 
          <table bordercolor="#2B54A2">
            <tbody><tr> 
              <td> 
                <p><b><span face="Arial, Helvetica, sans-serif">NSL ITAM Team</span></b></p>
              </td>
              <td> 
                <p><b><span face="Arial, Helvetica, sans-serif">NSL USC</span></b> Team</p>
              </td>
              <td> 
                <p><b><span face="Arial, Helvetica, sans-serif">NSL USF</span></b> Team</p>
              </td>
            </tr>
            <tr> 
              <td> 
                <ul>
                  <li>Eric Galicia</li>
                  <li>Pablo Olmos</li>
                  <li>Héctor De Labastida</li>
                  <li>Josué Rojas</li>
                  <li>Rodolfo Cartas</li>
                  <li>Carlos Aquiles</li>
                  <li>Ramón Bórquez</li>
                  <li>Sebastián Gutiérrez</li>
                  <li>Salvador Mármol</li>
                  <li>Oscar Pequero</li>
                  <li>Claudia Calderas</li>
                  <li>Mirlette Islas</li>
                  <li>Francisco Peniche</li>
                  <li>Francisco Otero</li>
                  <li>Rafael Ramos</li>
                  <li>Munir Estevanné</li>
                  <li>Alejandra Barrera</li>
                </ul>
              </td>
              <td> 
                <ul>
                  <li>Isaac Ta-yan Siu</li>
                  <li>Danjie Pan</li>
                  <li>Erhan Oztop</li>
                  <li>George Kardaras</li>
                  <li>Nikunj Mehta</li>
                  <li>Tejas Rajkotia</li>
                  <li>Weifanf Xie</li>
                  <li>Nitin Gupta</li>
                  <li>Salvador Mármol</li>
                  <li>Amanda Alexander</li>
                </ul>
              </td>
 <td> 
                <ul>
                  <li><span face="Arial, Helvetica, sans-serif">Martin Llofriu</span></li>
                  <li>Gonzalo Tejera (UDELAR)</li>
                </ul>
              </td>           
 </tr>
          </tbody></table>
          </span> 
        </center>
        
        
        <span face="Arial, Helvetica, sans-serif">	    </span>
      </blockquote>
      
      
      
    </td>
  </div></div>]]>
            </description>
            <link>http://www.neuralsimulationlanguage.org/about.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24692422</guid>
            <pubDate>Mon, 05 Oct 2020 21:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Observer Effect: Daniel Ek]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24691710">thread link</a>) | @jger15
<br/>
October 5, 2020 | https://www.theobservereffect.org/daniel.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/daniel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the second interview on 'The Observer Effect'. We are lucky to have one
									of the most influential founders/CEOs in technology and media - Daniel Ek, Founder
									and CEO of Spotify. This interview was published on 4th October, 2020.

							</em></p><p><em>Daniel does things very differently from other business leaders and was generous to go
								deep with us on his leadership style, time management, decision making, Spotify's impact
								on the world and much, much more. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Let’s start with the basics. Walk me through a typical day in the life of
										Daniel Ek.</strong></em>
							</p><p><strong>Daniel Ek</strong><br>
								So, this will sound incredibly lazy compared to some leaders. I wake up at around 6:30
								in the morning and spend some time with my kids and wife. At 7:30, I go work out. At
								8:30, I go for a walk – even in the winter. I’ve found this is often where I do my best
								thinking. At 9:30, I read for thirty minutes to an hour. Sometimes I read the news, but
								you’ll also find an ever-rotating stack of books in my office, next to my bed, on tables
								around the house. Books on history, leadership, biographies. It’s a pretty eclectic mix
								– much like my taste in music. Finally, my “work” day really starts at 10:30.
							</p><p>
								Many people make big decisions early on in the day, I make them later in the day--at
								least later in the day here in Europe. Ironically, it's not actually because I'm more
								productive then, rather because we have so many of our staff in the US, and as a result,
								I've kind of primed myself to work that way.
							</p><p>
								So the earlier part of my day is focused on coaching, one-on-ones, and planning. Then, I
								typically tackle one topic a day which takes a lot of my time. That's my big thing for
								the day. Before we go into a live team discussion on that particular topic, I invest
								time to prepare beforehand – reading and talking to members of the team who are either
								part of the decision-making process or who have insights and context. I sometimes even
								get external perspectives.
							</p><p>
								I also think about what my role is at that meeting. Sometimes I'm the approver. Other
								times, I'm supposed to come with a thoughtful perspective on whether an initiative makes
								sense or not.
							</p><p>
								I’ve found that creating this clarity of role for myself is critical. It’s something I
								challenge my direct reports to think about as they engage with their own teams. I remind
								them that all meetings are not the same. Even when we are meeting to discuss really,
								really complicated topics I always ask myself: “What am I going to do in this meeting?
								What does my involvement really need to be?”
							</p><p>
								The truth is: it's entirely contextual. I find it crucial to be upfront about everyone’s
								role in different meetings, I think this is super, super important. Often that's my
								number one thing: to make sure I know what role I'm playing.</p><p>
								<b><i>Wow, okay, there are multiple things in there ranging from how you choose to spend
										your time to how you handle meetings. To work backwards, what makes a good
										meeting in your mind?
									</i></b></p><p>A great meeting has three key elements: the desired outcome of the meeting is clear ahead
								of time; the various options are clear, ideally ahead of time; and the roles of the
								participants are clear at the time.
							</p><p>
								I often find that meetings lack one of those elements. Sometimes they lack all those,
								which is when you have to say, “This is a horrible meeting, let's end it and regroup so
								it can be more effective for everyone.”
							</p><p>
								To clarify outcomes, options, and roles ahead of time, we sometimes rely upon a preread.
								Prereads are a great way to share context so that attendees can quickly get into the
								meat of the issue and not waste time getting everyone up to speed. What I find is when
								you use a tool like a Google Doc, you can take in a great deal of information by reading
								comments, assessing options, and understanding how opinions have evolved over time. With
								this uniform background and context, attendees can focus on discussing the matter at
								hand versus getting on the same page. When the latter happens, the meeting becomes an
								incredible waste of time.
							</p><p>
								I think that's the single largest source of optimization for a company: the makeup of
								their meetings. To be clear, it's not about fewer meetings because meetings serve a
								purpose. Rather, it’s key to improve the meetings, themselves. A lot of my efforts focus
								on teaching people this framework. Ironically, I find that most people are just
								challenged by that stuff.
							</p><p>
								Candidly, that’s my role as leader: to coach others on how best to make use of their
								limited time. Not only is time the most precious resource the company has, it’s also the
								most precious resource they have! It’s crucial that they approach the use of their time
								with a holistic perspective. By way of example, I had a recent call with one of my
								directors who had not taken a vacation in six months. Our conversation delved into why
								this person thought that they could not be away for two weeks, and me arguing for why
								the person had to take two weeks to recharge!
							</p><p>
								There is never enough time – for work, for family and friends – and it takes work to
								make the best use of it. It's all about fostering a holistic perspective in life.

							</p><p>
								<b><i>
										That’s fascinating. Let’s turn to your team.

										Your direct reports are highly accomplished people; what are the common mistakes
										you see executives at that level make when it comes to personal time management?
									</i>
							</b></p><div>
							<div><p>
								I don’t think most executives dedicate enough time to thinking. They spend too much time
								in meetings. By the way, I will say as a caveat, I do know people who are incredibly
								organized and succeed with a lot of “do time.” Shishir Mehrotra [Co-founder and CEO of
								Coda] is a great example. If you've seen the docs on how he organizes his time...
								</p><p>

								<b><i>Oh yeah, he has a lot of very well-organized docs! [laughs]</i></b></p></div><p>
								He is a source of inspiration. For a while, I tried to mimic his style because I was so
								impressed with his thinking behind it. But in the end, it just wasn’t for me. It
								actually drove me nuts. <i>[Sriram laughs]</i>
								But I respect him. I would say he's a highly effective executive. His system works for
								him. It's not one size fits all. Some of my direct reports thrive on lots of meetings.
								But, in general, I would say the largest mistake is that they conflate meetings with
								productivity. Often fewer meetings and better decisions drive the business forward.

							</p>
							<h2 id="opencalendar"><b>On Creating an Open Calendar</b></h2>
							<p>


								<b><i>This dovetails nicely with something that fascinates many of your colleagues: how
										do you have so much open time on your calendar?

										This drastically differs from your typical “successful CEO” who is booked from
										8:30am to 6pm. Walk us through your calendar and how you manage to create this
										open space.
									</i></b>

							</p>

							<p>

								My friends know me well! I do keep a lot of open time. I understand this comes from a
								place of privilege and I’m very lucky to have this flexibility.
							</p>
							<p>

								I feel like synchronous time is very costly; asynchronous time is better. I know there
								are some leaders who prefer to have all executive decisions travel through them. But
								then, you have to wait until the leader has availability to review things. Sometimes you
								run into delays in that process.
							</p>
							<p>
								I typically don't have more than really three or four meetings per day. There are
								exceptions; when I travel, I book in a lot more and I don't keep to my normal schedule.
								That said, most of the time it's three or four meetings a day.

							</p>
							<p>
								My way is to plan long term and do so ahead of time so that people better understand the
								direction in which they're going. You have to be incredibly crisp and clear when doing
								that. For instance, right now we're finalizing our five year plans and long range
								planning. These are actual, real targets fueled by real insights. They are made up of
								lots of super-detailed quarterly and annual goals. I don’t spend much time on the
								quarterly goals and instead focus on our so-called “big rocks.”
							</p>


							<h2 id="bets"><b>On Company Bets</b></h2>
							<p>
								At Spotify, we have something called “Company Bets.” These are large-scale initiatives
								that we believe will have a significant impact on the business within a relatively short
								period of time. I find that these bets are a much better use of my time. Our Company
								Bets typically update every six months, so I'm not needed that much in between. This
								way, I can constantly be thinking: “Where are we headed in the next six months?” Right
								now, I am thinking more about H2 2021. From a timeline perspective, that's the earliest
								place where I focus most of my time.
							</p>
							<p>
								It’s also my role to think far beyond that. For instance, I’m immersing myself in our
								2025 plans. I trust my team to manage the day-to-day, shorter-term initiatives and
								iterate as needed based on data and insights. They’re the best at that and I appreciate
								that this then frees me up to think about the long term.
							</p>

							<h2 id="decisionmaking"><b>On Delegated Decision Making<br></b></h2>
							<p>
								<b><i>
										Your system reminds me of Jack [Dorsey] at Twitter a …</i></b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/daniel.html">https://www.theobservereffect.org/daniel.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/daniel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24691710</guid>
            <pubDate>Mon, 05 Oct 2020 20:33:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET Orleans]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 271 (<a href="https://news.ycombinator.com/item?id=24691500">thread link</a>) | @swyx
<br/>
October 5, 2020 | http://dotnet.github.io/orleans/ | <a href="https://web.archive.org/web/*/http://dotnet.github.io/orleans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <div>
          <div>
            <article id="_content" data-uid="">

<p>
  <img src="https://raw.githubusercontent.com/dotnet/orleans/gh-pages/assets/logo_full.png" alt="Orleans logo" width="600px">
</p><p><a href="http://www.nuget.org/profiles/Orleans"><img src="https://img.shields.io/nuget/v/Microsoft.Orleans.Core.svg?style=flat" alt="NuGet"></a>
<a href="https://gitter.im/dotnet/orleans?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"><img src="https://badges.gitter.im/Join%20Chat.svg" alt="Gitter"></a></p>
<h3 id="orleans-is-a-cross-platform-framework-for-building-robust-scalable-distributed-applications">Orleans is a cross-platform framework for building robust, scalable distributed applications</h3>
<p>Orleans builds on the developer productivity of .NET and brings it to the world of distributed applications, such as cloud services. Orleans scales from a single on-premises server to globally distributed, highly-available applications in the cloud.</p>
<p>Orleans takes familiar concepts like objects, interfaces, async/await, and try/catch and extends them to multi-server environments. As such, it helps developers experienced with single-server applications transition to building resilient, scalable cloud services and other distributed applications. For this reason, Orleans has often been referred to as "Distributed .NET".</p>
<p>It was created by <a href="http://research.microsoft.com/projects/orleans/">Microsoft Research</a> and introduced the <a href="http://research.microsoft.com/apps/pubs/default.aspx?id=210931">Virtual Actor Model</a> as a novel approach to building a new generation of distributed systems for the Cloud era. The core contribution of Orleans is its programming model which tames the complexity inherent to highly-parallel distributed systems without restricting capabilities or imposing onerous constraints on the developer.</p>
<p>Documentation is located <a href="http://dotnet.github.io/orleans/Documentation/index.html">here</a></p>
</article>
          </div>
          
          
        </div>
      </div></div>]]>
            </description>
            <link>http://dotnet.github.io/orleans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24691500</guid>
            <pubDate>Mon, 05 Oct 2020 20:12:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manipulative tactics are the norm in political emails: Evidence from 100K emails [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24691203">thread link</a>) | @randomwalker
<br/>
October 5, 2020 | https://electionemails2020.org/assets/manipulative-political-emails-working-paper.pdf | <a href="https://web.archive.org/web/*/https://electionemails2020.org/assets/manipulative-political-emails-working-paper.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><ee76bdc99150badef1c33d720a2b3440>] &gt;&gt;
stream
xœcbdàg`b`8	$Ø–‚Xù@‚ë-�`Òq›€w,�`L¼·@@‚'&amp;Ægs)q¶	æ·H¨H	– 7HÞa`bÌŠqG‰¡M°/hÐœ¿«
endstream
endobj
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
150 0 obj
&lt;&lt; /Names 307 0 R /OpenAction 171 0 R /PageMode /UseOutlines /Pages 302 0 R /Type /Catalog &gt;&gt;
endobj
151 0 obj
&lt;&lt; /Type /ObjStm /Length 2435 /Filter /FlateDecode /N 91 /First 814 &gt;&gt;
stream
xœÍZ]o·}ï¯àcòP.?.¿Š @Ã��
œHÆh5‘¶^Í»+;ê¯ï9³”¬U%{5Tê<häÌr8‡ä½÷œkŽmve“s>&nbsp;ðÊÙˆR”ÏePAXF•LF™TŽüuãø~´Ù)›Ñ‰÷¸ÊVYá³¼
³ç]üžEÙùSÀk®rTÎ%V’râñhÎÊÏ§
*ìµå¢Å�bQ‰¼ã”KŽw7Þ^ðÂ”w†w¢òžo/IyÁ•-Yù(ÀRŠò‰�¡�/ÀìŒUb
ï8%NxÇ+ñ�w•©qPB„ÎDT+II´¬d%)¦)JŠãàŒ
“äðsàäb¸*ðŸ³•ÀŠ&nbsp;‚:‹IöÙM3Ä±’P‰èÃÑþBb?=O¯pVEÃ‰ÄÑyÌ„ó*úÌŠ¨(QP	*Ã6™&amp;Ì„ÃôÅÈ±»¢bâŒz£b4Æ “Å¸�w*9öƒÞ“àwçE¥�y'¨¹h–Áµp&gt;¡‚ÅuX¼”ùRôž
çPŒÊãvbUær;q*ncÍUX'¢r
x
°¤èp‹qlœP‰ü)«b…T8cÁ¨âÁá5E&amp;ÛqªDö¼*Ó¸‚¨’a ½—à.&nbsp;ç�'$˜±áP
Úpôöi¦%£©®Ìo2wùÃW_©Åõ“²èÝ¨×jñrµS?«Å÷jñ×ñ‡Q}ýõÔäÏŠÿqó¯_©Å×—=î-w«qØßúâ|·»Üþi±è×ýt»¿èVë-ÌÏèqsö%úQ‹¿Œ›Ó~ƒ—:(ßòÍta÷ßªú~�çq×G¯±Øb¬¦ç´Å¸Å:-pQ"¼:ÙM8þ¶ÞÞb†qw4èç'Ö…�£xáD&gt;‹æÑåÀ¾P_,W»^ŸöÃnàÆår\¯v«e·þòî¢|Ÿù_|&gt;…µºLfëµaTÄ€Ã,|ÝÙº?¹À|:Ý®ß¶ÀLŸ)à¯3cl¼ÍºN/ý²YõÃiº�tm]¤×EÑ‰òû˜&lt;0“‹¬H
Ä&nbsp;…<fâ\Û{Þµ-f'Ä<xãni˜c=8wÌsÀ�wÛm¿^\ìv»nù¶eê Ü�q1yÍ�="" Â„—="" ú¬¯�îm7œm±¤xjg?©�Á„4»lþÂÌÅ'¾ßÂ¬="" :ƒ¹nÑ!.gÒâ|xïwëõª»@ø5a="" œ«s˜\Ózmáp‚¦³@jÍ“0¯üÿ™mÎ‚Àäá‰at)ð[?Á³2Þ·{x{k�æ¼ö1}˜9o´‡#lÐæÍÜ³8„-pˆ[xbue5s="»õI¿Ù‘î—ëUÛjJÐÆu‹-Pžä§�{9»" ßkèfªÓ½ƒ°uñf”qªfw="" ¨µáƒõ‚Œ§¢ÿn3.¿ï‰mñÝ‹—x_ÿ+õ\}Õ�ÒûñŸÿ‚ßbþ�ÑËpµ^¬%¥³9¢d¬.Èz="">´üiÊÆØ†éØ¾”Z†ZÆZ¦ZæZ–©üùÿ7"xSÄR"DÌÌU�¾ü"[@ð5Èãb„•yf]ÐK˜±s³Ø´ú÷[×2iÉéÀh(�ù/ÈS�&nbsp;FÆŽ4‹D'L¾S†|Œw0Á93òÎVLÒ"ƒŒÑÜ- ¦„Ì‰3bjiÆZ0Ù¨™KßbrYCþ´BŠM‰
ä�®.’h�&nbsp;~Z1¥¦ì¤€™Ó‡iŠHIé…À$y¦ÿ\­ðúw}Ï/�Ãz5´Ä"ÊéPÓPI�×˜½�Â4›Ÿ‰¸]‚=áõHG4÷‰2�BÜÒ%NaÆc(oñ
iLÿ
ßóãßOþMDìèÕ…UîæÉ»$v,%P]ðYGðô§Ú	w´rH‰Ùì).ÛZVŠÌ•"s¥È\)2WŠ,µ]©íJmWj»rÓ®Ri©TZöTÊ=Â}i¥Ö~@xÞmNw´Ï¡×oìÀÃ©ÉR•µ&lt;}šûx
¬uo9ž¶8Ž—¬C¾-2¥w4ÿTh¿¬Î®6½^v—ÜRÒÇ1˜�.b0Æ’µwÜàeøKHî“ö¥QVfÅXñJ2é4wÛ9îCúgàÎóÞ(s-ïê¾GFÂ]íXf†§òa 9¢t0¢˜Èü^³C“ÝŒL9¶L!/`³-aUBÒ9CÎ-÷ç#P
øÈÂŸBh³ÚãôÄÃV+1 µ
ñVgACHu±@"n’©ŸD)Ï<wòévvèîbq–´Þýyo‘cðª¨òÔõÓq vúÉqèyth˜Ñfí§ƒ$¦anÊ’ŒêfÏ½Å<ØÃ‹é¨æaíˆÜð9'à6g†;vcñÓádnv}´‚8”ÜûæÁÐa4´5Ú="" m¥nw©ÛÙzº;qrêü~ÂÉÂg#Óé8Œ›?^t»åyã="" ÏÒ<7o§aeÍoŸ¡�l£¹´p)}Üó¼*Þñp51hm'`š§ns|‹ºøÍxÙo6hèßØ–”Þ0»l{mÁœ)½w×eÇ0kº_öÝf}Ñ18¹‹ns¶zðÑ‚<ñ1¦Ÿ‡ÉmøÖcÿ¾¶»~5="" ÞÉåözy="">®Ç³ë&amp;‰‰¬ÂÉí®ª‰'nÃ¢<y�˜ÁÐºc$œ½Ý dÆà¦ýóö="" Â¦4¢rÊƒŽÞ¼·éÇñÉ="Qçjør5|ù¾üã™ÇÛÕúll:¬ƒ‚çöSÒ<Èw‘ÛSÈ5`%ùY†Ðï¶ËsXj">AÎñn5nš¨^4âO¿Jæp|Ä¡hàø~ÖnÂ®¿ZžÃáéNesµ=ï›Nx‘"e:²÷ÌÏM‘˜ã"OÒ°âYP0Šn5t»ó)*ùí²Ûà‡‡‡é$PºDt{”iÊ¡Ût×Ý@ˆÎœv›¯sO«°ªÅEš&gt;Â»¨`
èq–‚¡Ï¯6TœËíò}U,ð6(úø<l÷¨º´d½Ä�"Èôé+“õôu(œŸÃ<ßa g23'?íz(p~*uœ67küóµ¬ñÑ×ø(5="">J•wRÛKm/rOîUýw¤Ü»·TÖ´¬UáNß×Áï÷ýÍþ˜\t�zÏ§¨AÆÄ«‘ùó&gt;¥¢¯S|ª^yN\.b†ò-.‡&lt;*Ç™¸öÄ4þÊhpÖïšÎ|‘£ó¿êO¶òîIúîAŸ{ºgñ»½=¿º`XzÀËþ/“êM¡zS°÷½&amp;á54$™ÉÞC¿…8C°*73‘U•M¨#Ÿ²ÍJþÄ¬&lt;2 n+F<p0}á&§ü „—?="" endstream="" endobj="" 152="" 0="" obj="" <<="" filter="" flatedecode="" s="" 203="" length="" 220="">&gt;
stream
xœc```b`¸ÉÀÊÀÀªÃ Æ`6H”�¥¡A�#ÅÈbb]tY€9ÓéáI3I­‚Â	në…Û0&lt;`–uà2cÐq*c¿Ú^Rýz·f_›éÑ¹ZÉµ¢¥m\·Ñ§ÄBhK=?¤š,Ë“½$òÒ2+‰ë›—ú”¨z'Ç*�›ê5íØ.×¹ZSu{Kº­B�zi-è1˜ˆi! ‹$0ð1t¬¿ÀàSÅžp`ƒïuöá«M&lt;qÖö408~�´«�¥XEÕ#¤æçL0
endstream
endobj
153 0 obj
&lt;&lt; /Annots 191 0 R /Contents 154 0 R /MediaBox [ 0 0 612 792 ] /Parent 267 0 R /Resources 187 0 R /Type /Page &gt;&gt;
endobj
154 0 obj
&lt;&lt; /Filter /FlateDecode /Length 2834 &gt;&gt;
stream
xœÍZÉŽ#¹½×WäMFpIB­VË€o6êfødÌÌižÿ?˜[,d¦¤j`3‡‚T™ÌÈ`,/^e·_7»ýýÍ.Ÿÿ{såÓnnK°%gÍnÓößßÞê5÷Í™œqûýçí—·¾]?ÞþvÇ²8pÁûíã~<gc·¸;c}Þ>~Ûþ}±Ö±Ö}-Ÿ·òÖom¬ß÷zý=¦²&amp;æ~/YkÞÂ´·«ýnYP&gt;á*+Ûw^YåÇåÙòß]_©ï®¯óW¾
õýWu«kªnõŽ~[ÛÃþþŸ�ð†!í&amp;`ÙqˆÆy&nbsp;c•IO@—Vt­OvÛ‹†à’¶�sÞä[ÄÝ$»³(×�Ò”¸Ñ·®�l
SÝV7RSŸ·ªQsÿó�×Ÿ+øRÚÑ¨ñÚe÷O¾Zä†*ÓÕÏé­{ÿÔ®lï`Ô;)öÏ¾ºîÛÇ§J�x§�¶\­§0u!›äÜö`ÜŽdjwí±ÑbóÖÕŒP7\TÛQEr7Ã;VÕÕÅXÝ·.œ¿Ï›Â’3ÁGz_À‹“K»t6	â0'eO*Ž!c6m�"µ_OqèRls¦&amp;csÙ{H¦|ÐÖ¿J&lt;��ûÆŠZŽ’­û´¥ïSµû:oC¡sg`åâ~æŒæ„«Ä
½±ÀÁpHrï9^^ðúÔXïòþ—pDhâžÏñpÛÝ°	æuÕA°S\t¦`Q€½èÆ°_hãŽŸÍ±ÅJOJ�ãÿ�9žT{‘46š½¸Ê‰]…_:$ÖùöI®ñ–¿¥ñ²ºWT«¶´ý¹z�¶@8ß&gt;pk’*öŠÁ&nbsp;iË¡h„]¸T¨%tWÁótmÑQ¢Ä‡xvÄuÀëÒªQ1q¼JXÖèÀëîëóMNø§)ºÛúò%¸¬ƒÎHü&amp;h2JëÓŒŒÅË!­nþs2²&nbsp;C~±µö�7õc²Îgö´ùEI»±Êù*‰�Àu©•YNBJMJ&gt;NÛü¢REƒÅ:¾˜¢,þs+U©š˜òæ}0™M¶Œåóñ4Öí«ˆ$ý&amp;á_ÅÊ%:ôE±&gt;!ø«„(»&gt;ý%&lt;€X!WÐ.g;HVüd¡kðû¯[ÿò/éUŽwY2—&gt;¦8Ï[oŠ1¹€Ä÷æ®W°î4ö"Áë¬°×Qù`4*cÅ#“ÏNªÿaZßîa°ð.	º$nY¢˜¯,ÉbàG	bÜ¿é%D»›ï@o”¼¨bãiLDo&nbsp;ÆçbÖû¨¡yø¼©¾+ö¿çÔÿQC²¶#¦†AÙ[»Yú|àÑ¤„&amp;4.‚dX7÷‰1ÉTpW¹mðý'ï}}ØÊ¶ªz€§p×~YZ§auÚB)Á°û
‹ò.O,¹"Q*]—Só¬f±¦b¢\Éì1nèJ!&lt;)ô§ý»ø²†~¾ŒØêÍcµc¦.òqK]–“})‰šPÂAÛVR‹FqoéU~P&amp;�ÎÉ&nbsp;
ã�éî‘”m[¹-ÐÔÉQÛCšV2øƒdðÀ‚½Tnrèøñ7­%w÷×A(3M&lt;”S‹{¸´jßpÒXX�gK?•9/~•Ô&amp;äðèûP¥|±X‰WwJkFl1¹|‡HE˜a»®Æ‹ò™• ©ûëo!Ìë’½Z‹¼†¬5
åX«gp“ïuÞ0dSÂ¾
´.ðÑø£ëã}�ú£fNOkWÕYµ–|&amp;çÕA�Á 2r~ZuÄtQW®‚ý­¯¸ªxÂ¸Fi{V€sNè´$2E¿Èbÿ—z—¸Þ…í¹È÷ê””?Q$­ó¢¾n�µµ/çEl‘y^D ›TíT�Ómµ‹ŽºÈŽ[Q±Îú’EÝ|/*ÂN�  -ŽŽm*†…|E²K™§™}Ë�½¾“ÏŸÆaÚä…È4í÷Î—¸¯Ï÷Ý�Èõ^©2ÓË¡,å¾¼ü,ýhc‚£
¯“ñ#³{�4¥}uÈRîGÆ`
)a„Ìo(G¦òß�Å"ƒ4]-¥¾=ØËCRÛ#ÞU‘£¯XRÒ…ƒnü·ò´~‡ááFEpWFÚ
�Ož®|O„&amp;®ÛñE„Î¶í÷‘l"©íôØšÀc¼÷¦x?Ò*V)ÝêÀàŒŸ‘Äðì¥å?™…g.ÌêÝÌµZñ~¦Eßu`Ç�ï&lt;3L[Q[ÒXÛñDï®Ÿˆ¸+sÐ&gt;ZÚ…ëŽŠ­&amp;Oû×ºæfú3‚–£ít§u7UÉ¦Œ´'V{@Q“IŠÄ~JE¿8,Âyaê%QÈ¢l¯J	Z™JÄÓÀ(©#´L�WÉ‚Õþ!ØÁê'ûZR4¬ÖëÒNÓ¯RÔQ£Å¬–êTò‹õÅ\ôó�´3à–D×Ÿ’A¦�æüÜÉÜ�U/–þ®4à�iøÊÝ±·Ðñ¢9RëõÜ½ �wùÔ¬Õšn@âz§Ô!ô”Ò"…Š
…›�|÷ó%¢&lt;á.¤«Ü‘7µøÉ:#`ö&amp;�¹¨9oOoºU±Då“â�‚œë\_1™­•Ú¤9¶VwRÿv–23ÑY€O¤¢P€÷êGô�NÚ÷©’…Eµt`Ê�³YxÆ÷tšRg˜³«¦�ç¥ •qÖöy�;$¸XdL&amp;:e‰DLº†ò¹2„%†µ�y?Ü%¼D‹á}êLÞs¹ÎçxRýh†ÒìËcŠq^y2ÒhC|nä¤Œ¢ÖVG€R¼;·–Ô~:R‚˜ZÇz¶�32z8|ÝÑ”J±j2ší‡Ã™›+œ20¥ì'LïèVµxqé˜N:š3Ý&amp;×÷xkÜ&gt;
­&gt;5_±N»õYïhùP›Ø„%êßJò…¤ÒƒC6«9I{ÃI{ŽÃû*zŠ~pÊäèÎtÇkû¤M¼Ï‡|:Ùía¥Ž-'��õxhD+¦ÛRåyˆ:¼‘	§8?›ƒ¾QQ×Uç&amp;QgÜ5.²
ˆ&amp;ø&nbsp;‘\Zä#é\MÝtº�Û?,HÓ&amp;ÇKàÄüøÝãþh)Éiýql!\NØ¯ºjÉB�ýÓþô´ü*Z6‘èÂ.ü%µk�:¢tI—ñK×Ží¢øÞ‰`ÛÑ5Jª,¿&gt;Z Á�Évž'q¨«@\3…Â~Ú4\À…�J3)lR
™ø-9~:Y‚Æg—TÕŸ§`&gt;l
Ö�ƒ‡Jg–up›¥ùRYlXWÅëAZ€øñ•¸°›”ÜAÜ—ƒ¸ˆ&amp;…£v™’}—"1ìpl¨‰ZàH:ÂÛêà¡Ä±
²/@Û¹ai'^+â£‰–µÒA°´:¼¬ÎFu^eÙcÚ±	«˜…Uµ
Ür6…ýJ¿8O8S¨z;S¥µ+e¤SJv´UÃvÊ*ÝSõ�9È÷ñNjº%¹²rr '€\ëoÒ=õIŒš|Nð­Ù^¤MZ6:8Š¦%4Ô•wHª“-‡ŽrºÁŠÍùí³5Þ§Å£#!µ×}ÆÃ¾,äjó:Ëå3¢¥Wé;ÃåLÄøœ3¿àÁ|ÈÅ§·Ókœ¸Ox0Y‡šÑ–”aˆì½ž'Ó1š¦f¨{ã!Fæ¨�,0›�9ØâNÖ-ë€»çZ�Ÿ‰Ã®±*
éËÂ­&amp;sÍ¿Ç:L`¥Å8ÜÛéIÊ1?›vå�&amp;÷Ç0J°6Í�Ã'ÐW­çµDð:¦æùì4¬_e:3EûôŒêœÖã}"†À¿›$†ù¦®rî'¦"(hÓ‰và@¨Ûež±x±Míóå8˜&amp; ù„Ô”÷*Ããá¨ÆÛlJ¹—%‚�l†&gt;¸¢&nbsp;´*j©
Ž7z;�À;î‡5ðf{+µVgŸtJ:ÆTg§ñß&gt;Þþ0ë²ë
endstream
endobj
155 0 obj
&lt;&lt; /Filter /FlateDecode /Length 24 &gt;&gt;
stream
xœc``à`LdTÙ’Ñð ¦ÉÚ:
endstream
endobj
156 0 obj
&lt;&lt; /Filter /FlateDecode /Subtype /CIDFontType0C /Length 3191 &gt;&gt;
stream
xœ}W
XWºžf4DK»fp&amp;ºÖ§Äb­÷¢(¢ˆŠÿ^µþ¡„Ÿ&amp;ù	�„�“„€€"RŒˆðw½Ö§R[ÝþH¥h×§»uukí]o«m·î7éáîs' »]»Ï&amp;yÎä9sÎ¼ï÷�÷{Ï	HH$’I	‰«“–®ŠX¹j�.;%'&gt;%×0;jæ:Mzž6Eï°T˜,LA2V'„I�
8©&nbsp;ÄÓdÒs²À!3¾N~þã=rAHNŽó·�^¹lŠøOþ‰lª¿ãO²‰&nbsp;BBL"¦ßI(‰B2QÂJ¦ý;èèYQQ¯Äërõ™éFutTÔœþö5õâYê¤”=YºCV¦:%'U�4K½j–:YW öfª_Òå¨wk2R´ij]šzƒf³:Ï&nbsp;ÑÔéz]^®aú,õ†ŒLƒº@§ÏR‹W½F«I1hRÕy9©½Ú˜¡Q/Û¸~ƒz©.Ç¨^™¹G“cÐ¨gÎT«
�:ÃhÌ�iÌKŸ¥Ó§G¦‰c‘Ú‘A†Hÿ¼™KW'o˜¹ry|Bòú„YÆ}FušN¯NÕS2µ†Yÿ2ÐêLÖé³S´‹Ru»5ËS59ÆLc!!~Â‰"’˜MD¯‰ÅD‘H$+ˆUÄZb±�ØLì"RˆÝD&amp;‘Eh‰l"—È'
¥bÂ‡ç†ûSH”_KÖK&gt;XÐ-�.MœXL†’^*šª¤nÑóèMôß‚z‚Ëƒ�Ù1¦oìÂ±gdsd]Ð%|ËÃ—’nˆ‚dØ)~ÆÓë+Ü=¥ŽÖ�Ík­‰)©¶”Z934Û”[´ceõD=íôt:&lt;Ì]ÉÓ)N[w½êrv?`aåYO(8”iQéÒQ«§ŸºÈî³Õö6ï„MJ¼šú3XH¹ðE	/˜xIï}AÎK…Ó�&nbsp;¬Gu¥&amp;d)·³“Í1«_e¶àˆÐ�"Û.Þº÷_Xñ&amp;gv:,
Ì!ä~“ƒXº(·Ø«Ë+ÙÔÍ¤'ëù8G`%‹gà ^!Â&gt;ûËŸ8¹/ñ—x!œ—@ðM¸vW*@­Ø©0Oeq·žêw[vsC½ÛjIdõÐMÃä§“¸ya¯§äg±yûwm‰dPV×9N�ÓçÜ®öuÿÂ¶Â&amp;Î£ó¤LSÉ}EÈxï{áU¯¢@:1|
/õ%C£ROá™zÃ"œ ²¤¶U×uqÐú
ý¸)ûŽ‡=õJIöKìt0S]ÎºK,üŠ‚Ù'7ã_5s&lt;¥ƒ<rè®¶�ºã4¥scgéôjÓÖ ¾¡äÂ{ˆ‡}<¤ò¡ÑàÀ`oã�mb»˜q6¤Èð:žÀ`b„=¬ o,ha_×s‰e‹Øx�Žè;jq†€ ö ,i�÷a,9´v4="Ògé¶Ó" Â$ºdäÿofðå'Üs|+˜á‘rxæÒçgÒ="" uÁ8¿j�ãŠÑeþ³Ÿ¾Ý˜¿|„Ërsþ"6âg¸<¢=""  36p¢pe¨"4¼Ä…'„ý¢t­µç9�¢Ï»kûyžÆ„="" .ro£â¹¸æþë{_j~fÃÏ‚p‰wüä)1Ábª(zp="" Í"è«û'ÒÜîoü´á@ÿƒ?q[wqc�ô.«u‰²Ø)÷ýyuÇ}’ã:o¨_}��×="P¤úÚÃ¼ôöÔ›Îa3|" k!ît÷åö¼´bmÛ›…rÅ„ôuÈ•Éié3vw^…jñr…Õ´¿˜Å÷ñnÑ§œ�wØ6j1~xjÆ"¤a›5qÈ•ÁiÛè±´="¥0iiEœ«ç6:Ã(lg">E¶Îk&nbsp;T7žâ`
¡@Á&amp;ÜFÖV6›T9´�',võø'ˆËÝ0œ‡áµVÜ²‡µõ•åÑXÍ¬|V4}ù0úÔŸq‘÷°ôç	"iù�{‘×'kdîqè&lt;5�þ6ÊEh{—ÇRFÚWÉáâ¡ßâb¡Ÿl1[P&gt;ƒcÿ^
6:m›*…`ÛH/=]êà„3´ÃõÿLVÔ¸+˜w}}
}ãvrhp´~(×éè,s¶ÙN‹.Q6à¥'º'ðMŸâ|k~&amp;1B?£´phžh‘¯�R
Ñ‹Ë0"»?ÓŠ£F´)^ÔÀ}©p~Ë^Ís¢ä;ãÑ•cœ ós[=´ëŸ¹­ÒýÜ¢Fµ÷ÙsªÚÞ5"þáÄûy­Å¡_(QòtŒ˜äÄâí§žÓÓŠÔA´ÉÈáË4&gt;!(ÉCÕhƒe~^mÇ‘¹•záßƒé†2èJ$M\¨–iBuorÂ/hÅ’cèÊ +÷�/iÊüž
»/&gt;‡J˜.ºìxüžŽÇàñb!xL¿!0"Ø˜F%Þ‚Ö-Y‚®ÁXÔÛý7€Ü‚W³rá²¿8„ÓÞ¾‚PpÜVì¶„y3èÔÔÍ	¿¡Û�ÓÈnÝšT¼ˆÑÒüUÔq•j¦3QI›1ªæSÑyQœç"Û)nÄ5Ç&nbsp;˜—\µ‰!X9¸ð&amp;¦YÜö¼Ï?_üsAE?ùãõßq1a©he±ÖŽ˜ÑM
BÑÂ=œÑSÉÓ§RÈ¸¢ì4´åä99m†ÎÎ¶¶N1¤Ç"ƒ½Ø;²Õîß-Qøò†Ò�JMöŠ*6Ùœn73‡-\e³åxi_eOyo\gÐ@ËG?T
DŒCXlþÕ§®¿þƒèâ/i¾Ý®õrGó�a§j=*&lt;©e[Î_dúÔÊá•Ð§LµÆã0v,¥xgCƒ›uÕu&nbsp;æö=›ZÌäy…,/Ì?.ìƒ‡}R¡V)ÿú#ÐÁâð.ò•£ù7O©n\»~Ø+Ó^lbK�ÈÚølïÝNAu&amp;3²—U²ikÈŽÜí#=gòŠî‡Š¹K[O˜ï4W±5W½_ÒjõfÕšOdnT-Ù•’xàÂ6©×vËÞTg·8­L)2rx]„Ì�uNW}-{ú2çøÇ»¾gà…Ï¿}*òÝQÂÛyàa†çÿ5ïô„ööÂþ^]¯‚3	0Ey=õ<bÓÎìwÍmÍwg°8ƒ¶´î?{bõÖ¹·ûaÑ‚ƒ³jx³yfcv~°ç³vkyq•%è´fûÁÝlÔòe±ëo¾q°Œ;‘Ýzõuþ»¥ ÕÇòƒž8wugînÕ–Ô�k÷n¬éÙÅîè±½mï:`¯tØfbp,"0c+lÄ~tÙpëpx³b—ÛÝp¸¦6haŠÛÛùŽñcæë�î|&†ôâó<Â±°[àõaØÚ"À;ð•²Ä¿u–q%8–äeÕÕ·¶€”¹êbâæbÐ{ªdçÊå¯÷Ëÿìûè£è:÷="">²�åø|zAU£èÂ}Á…®á)ÂŠúá2»?üð­WòÛÀøP*ÁbÑºmE«JMAfs*aðF
ÂaÜ‘æ·Nµ4O¼þ›÷ßýJÁÓïàðØØ¨Ùë/#×‘žƒçÛÛ3ld·±½úë~æ«+qsÖ–ÅÎãp6.$ËËQµQ%„Srß{y^ß/†OABˆWê³ûÔJ/�ÇØðX©¥¿GÛr9ü„Æ“§ÍŸ¶‡tÂV7êûÔÈVöÜF&amp;£ñÑ]$0^Eù˜…!Ú‹Þú^ÐWÂÃ$nþôt0l�ÕúMv£Ëq8u¢CŽøc�ƒb6/Ë~ñ ¼Ì‚çgçƒ5–]b8´¥9KÙùõ¿Ÿ/¦‚ú¾»åààMúœ£Ýs‘1ò/’ B*ÜAËÏµç3¹:‡3WDë±ÕåïS™l•V‹§à‡øe"+[�³FÕÑ�Žˆ�SläÞÝ#ƒß«5¿ÑÄAòÐJ²´Öi&gt;Ä49k›jÅB¢;®_tvLÝ$ÀßüfH…‡Ï0u?ÁôT×•íWW–™EÌq8	³°“´Ö™T­�èàH˜dî‡3[ýÎAËÞâ«žó™eUµÿÍA
/Â§Þíj:ë\Îóø~é‘\»¼x†®„[Êo*n§
°·4	Þ$fYBf|—³¶8‡¨–ºfþz;ãÊóIæòg-_\âÎ~Zó`P5¯Q¹Í+[Ãâ1ÆX³‘I]éùß|®ôCôàºêÔßx�}Ò:ÐÒÃt”Î8Æ5mBó—¨äþ—Õñ#›&amp;¾r1þ×Ï‡¡bé46ÛXë¡Ø¤
ÚHY0’�åÇ&lt;ëq9§£Îéîm�ÉøÚÖ£�.—«¦Æå’…ü?°Õ(
endstream
endobj
157 0 obj
&lt;&lt; /Filter /FlateDecode /Length 494 &gt;&gt;
stream
xœ�“Mo£0†ïü
ï!Rz&nbsp;ÐVRC‚–UÓTI´Ú+±'YKÁ ‡üûµ=¦•V«h#åãÉ¼3~g&lt;Ì¾}üWÞžÀ�)ÙCßŽŠ�_lëÎ›ÍÖ-�Ã;&gt;Eûò¡Zv€�Ì‹j]I1<hq%Ùuä0©þ-zÁeÈ ‰9‡Ì�ðËß|ßý(·þÛvß6µ,ê®©¿‡Ëx­•omêq="" w�òj¢%äž„Ø‚?aõ¢•="" $|¤”ê?6’mcî½À™&ÁÔÆyh®œsr2}xad¸`ƒ#ûÉ="9“|¸õ4•<·ÞrI}²èu³þ¼`§8(!/d~Ï¨Æ®»‚1E¨—ç„ÃY××s{¯" �™fÅut="" ·»cùj<Þ:="" ‘å­³–cßÕ="" t-="" à-õ8hn–¥~åhþwœbÖéŒ¨ÓÏ(›bìw­l¡°Ð…(mÃÜp´bŠ‘j¤…¥8´´h�"Œ9Ê�r$—÷diá”Ïh="" vy!="a¬@zÅØÉyq´FÚXJÐKZ&quot;á" 1ö�,,e="" oˆ0="" ¥‹�°j‚Ý¦x%sôŒ„½§è%vy8³{oÑy†”¹púËöžaÍ˜æx'öÌõ™�ü\6*¥÷Å.®Ý³="" bÂçnwmg²ìÛ="">ÓójhWzðþ.L
endstream
endobj
158 0 obj
&lt;&lt; /Type /ObjStm /Length 3073 /Filter /FlateDecode /N 46 /First 404 &gt;&gt;
stream
xœµZmsÛ6þ~¿£ëH"Þ‰›Ngb§i|�Û\|íµÍx:´ÄHœH¤†¤“º¿þž ’¢¥8öL&gt;È�Åîbñì@#XÂ„‘Œ+…'~)ÇS3%èi˜64n™qÏ”¥‚Þs:eÂ&amp;Œ'©Dƒ3.8fX�†£°”ü¬BÃj44„pƒ†ACƒ�µh_›2®-1tŒî&nbsp;8§Æyuxj©ÎŽƒ3É“Ä)¸kuRâ.ð'5L&amp;¾a™Š)“J±cÒ:Hw	S	‡PÇ±ÈD&nbsp;!˜²Ì&nbsp;·rŠhÓ\Ò�fZ)td	C
ËtêiRfxB=Ž)HN˜Ñ‚œ+,é»ê‘Ì&amp;\£¡˜u�#ÍÒÔp4s	©™Xæ¸Ñÿøö[6?ËšüeU¶lþý«Ÿÿýòò›×—o«mVžg»†'Ó·ùêv“Õlþ"oy¹ÌÊ–¨öÎ«“°·ìSËEµ,Ê›_,ó²-Ú»é+6¿º½iïv9›ÿ&lt;ª_Ê„9m�ŸêGØÜËÿî»‘&gt;Ï/þs~qµ×ºœU›åqEÌ“®Täì§7?¾&gt;(òY£È'ëb¾À(W/þøáêº\Veõ�*ÉÓUQ«rþû«ó7ßwf§÷'µOW„ŸRä¼ºÅù�Å’ÄpLfhÿ7æ¡‹ÇñÐ)Dx¤þ!;½Éjhæ=j ùM¶Ê›û6xýæ�‹«ŸÐ¸h³M±8nõT+(÷ðn\œ=ÿáÇ·ßœ_¾%“¼,ê¦=_*
3H¡ºØµUí£†ç÷:‹DpÇCñü@ØüÅ²]7&gt;DÒÄ{Âxóëåå9„_^Jç5÷Å'#ñžê‹ä'Cùª€[©‘
û§Ô#6ö¸Ä	…</hq%ùuä0©þ-záeè></bóîìwímíwg°8ƒ¶´î?{bõö¹·ûañ‚ƒ³jx³yfcv~°ç³vkyq•%è´fûáýlôòe±ëo¾q°œ;‘ýzõuþ»¥></rè®¶�ºã4¥scgéôjóö ¾¡äâ{ˆ‡}<¤ò¡ñàà`oã�mb»˜q6¤èð:žà`b„=¬ o,ha_×s‰e‹øx�žè;jq†€ ö></gc·¸;c}þ></p0}á&§ü></l÷¨º´d½ä�"èôé+“õôu(œÿã<ßa></y�˜áðºc$œ½ý></wòévvèîbq–´þýyo‘cðª¨òôõóq></fâ\û{þµ-f'ä<xãni˜c=8wìsà�wûm¿^\ìv»nù¶eê></häìr8‡ä½÷œkžmve“s></ee76bdc99150badef1c33d720a2b3440></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://electionemails2020.org/assets/manipulative-political-emails-working-paper.pdf">https://electionemails2020.org/assets/manipulative-political-emails-working-paper.pdf</a></em></p>]]>
            </description>
            <link>https://electionemails2020.org/assets/manipulative-political-emails-working-paper.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24691203</guid>
            <pubDate>Mon, 05 Oct 2020 19:38:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I bought a SaaS and am modernizing it]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24690705">thread link</a>) | @nathanstitt
<br/>
October 5, 2020 | https://nathan.stitt.org/myclientspot/purchasing-myclientspot/ | <a href="https://web.archive.org/web/*/https://nathan.stitt.org/myclientspot/purchasing-myclientspot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><img alt="MyClientSpot Logo" src="https://nathan.stitt.org/images/myclientspot-logo.svg"></p>
                <p>A few months ago I made the decision to purchase an already operating Software as a Service (SaaS) business. <a href="https://myclientspot.com/">MyClientSpot</a> offers project, client, contractor, and time management software as a service.</p>
<p>This was a pretty big decision for me. Like a lot of developers, I’ve always been of the opinion “Why purchase something that I can easily build?” I’ve had limited success building products from the ground up before and decided to try something different this time by starting with an existing product that had a solid base of loyal customers.  My hope is that the customers will be able to inform product development and speed the discovery processes.</p>






  
  
  
  
  
  
  
  
  
  
  
  
  

<figure>

<img sizes="(min-width: 35em) 250px, 100vw" srcset="
    
      https://nathan.stitt.org/myclientspot/purchasing-myclientspot/original-myclientspot-homepage_hu207aa5aa1d46bdf70618926c75b38c52_1999631_250x0_resize_box_2.png 250w
    
    
      , https://nathan.stitt.org/myclientspot/purchasing-myclientspot/original-myclientspot-homepage_hu207aa5aa1d46bdf70618926c75b38c52_1999631_800x0_resize_box_2.png 800w
    
    
      , https://nathan.stitt.org/myclientspot/purchasing-myclientspot/original-myclientspot-homepage_hu207aa5aa1d46bdf70618926c75b38c52_1999631_1200x0_resize_box_2.png 1200w
    
    
      , https://nathan.stitt.org/myclientspot/purchasing-myclientspot/original-myclientspot-homepage_hu207aa5aa1d46bdf70618926c75b38c52_1999631_1500x0_resize_box_2.png 1500w 
    " src="https://nathan.stitt.org/myclientspot/purchasing-myclientspot/original-myclientspot-homepage.png" alt="Screenshot of MyClientSpot website">

     <figcaption>Original MyClientSpot Website</figcaption>
</figure>



<p>I blame Patrick McKenzie for documenting how he’s sold multiple SaaS businesses for putting the idea in my head.  You can read his excellent account from the seller side <a href="https://training.kalzumeus.com/newsletters/archive/selling_software_business">here</a>.
I plan on documenting the other side of the sales transaction and where I take it from here.</p>
<p>As a full-stack senior web developer/consultant, I’ve worked on legacy SaaS products many times in the past.  I usually parachute in, do some poking around to understand the system then either fix a bad bug or implement a feature that they lack lack the skills and/or time to complete internally.</p>
<p>Something I’ve learned is that there are thousands (millions?) of small applications out there, limping along on shared hosting and making a few thousand dollars a month.  Most haven’t been updated in years and the owner is usually a non-tech person who enjoys the stable revenue but doesn’t have the ability to take the product to the next level.</p>
<p>Why not find one of those businesses that still have a solid customer base, update it’s tech a bit, and grow the user count?  Nothing I haven’t done before but this time I’d be the beneficiary of the growth.  Of course I’d be forgoing the fat consulting check that usually goes along with the job, but hopefully it’ll pay off as the company grows.</p>
<p>I subscribed to the buyers listing at <a href="https://feinternational.com/">FE International</a> and after a few months found a  likely listing.  After signing a non-disclosure agreement they sent me a slim prospectus on “MyClientSpot”.  The company seemed like a cross between project and outsourcing management, with a few weird database type features thrown into the mixture.</p>
<p>The website had that distinct mid-2000’s look and was still using tables for it’s page layouts.  If I was approaching this a consultant, I would have been immediately drafting a “This is a problem and here’s how I can help” proposal with a quote attached, because there was no way it could be signing up many trials let alone converting them to paid accounts.</p>
<p>After discussing it with my team, we were all in agreement that there was potential for this software and made an offer a bit below the listing price. After a little haggling back and forth, we finally came to an agreement to start the purchase process.  In order for our proposal to be more attractive we offered to close very quickly in a matter of weeks.</p>
<p>We then had a few weeks to perform due diligence on the website but were limited here by the lack of technical knowledge by the sellers.  They’d never had to really dig into the operations and had outsourced the support.</p>
<p>Major red flags we found were:</p>
<ul>
<li>There weren’t any analytics running on the website, so no real way to guess at how much traffic the site was getting because the seller also lacked access to the log files.</li>
<li>There was very little ability to allow us to view the source code.  We finally managed to view that via FTP from the (very outdated) cPanel and viewed enough to determine that it was running php with a early version of the codeigniter framework.  Codeigniter was a big plus; that indicated that the code probably had some structure and wasn’t your typical mid-2000’s Php ugly mess.</li>
<li>Email for the site was self hosted on the server and completely overwhelmed with spam.</li>
<li>The non-application web pages were hosted on an outdated and insecure wordpress.</li>
</ul>
<p>The above didn’t deter me because it was all items that I would be working on changing as soon as we took possession.  Some of the issues were potentially very serious, and there wasn’t much time to waste with updates.  It wouldn’t take much for the site to suffer significant downtime which would cause the existing customers to evaporate, leaving the site worthless and our money down the drain.</p>
<p>The good news was the prospectus showed it had a cadre of very stable core customers which had not changed substantially in the past year, and several that had been customers for a few years. To us that said the existing customers must be very satisfied, the challenge would be to attract new ones.</p>
<p>We gave the go-head to FE that we’d like to close the deal and this is where Patrick’s recommendation to “always use a broker” was proven completely correct.  FE made sure that all the documents were in order and had a step-by-step procedure that listed exactly what would be transferred and the steps to do so. This made the transfer of sale and monies go very smoothly. And we had them to go to for advice when there were things we did not quite understand.</p>
<p>Despite that we still managed to encounter a few small hiccups.</p>
<ul>
<li>Credit card processing was with Authorize.net and they required a new merchant account be setup.  Some of the customers were also using American Express for billing and that required an entirely different merchant account to be established.  This took a credit check, validation, and almost 30 days to accomplish which was much longer than we expected.  The seller went above and beyond though and left his merchant account in place and transferred the funds back to us.</li>
<li>We were slow on sending a welcome email out to the customers.  A few noticed that the billing name on their credit cards statement had changed and didn’t know what was going on.  In our defense the invoicing, credit card processing and system customer list did not match.  It took a substantial amount of investigation to even figure out who all of our currently active customers were.</li>
<li>Rackspace is a strange company.  They refuse to transfer service without sending multiple signed and scanned forms.  We finally just gave up on transferring and took over the original account.  We later learned that they ALSO don’t allow renaming accounts without sending more PDFs around.  Come on guys, it’s just a $10/month account that stores a few files.</li>
</ul>
<p>After closing, I immediately went around changing all the passwords, setup hourly backups, put analytics on the website so we could discover how it was actually being used, and downloaded a copy of the website source code for in-depth evaluation.</p>
<p>We sent out an email to all the current users introducing ourselves and requesting feedback on what they’d like to see improved.  We got several fantastic responses that we are currently prioritizing into a proper product road-map. And most importantly, we started using the service for ourselves, not only does this help us to understand the processes, keep our tasks inline, but also gives us a good idea of future improvements also.</p>
<p>Lessons learned from the process:</p>
<ul>
<li>Make sure you completely understand how the billing process works.  Even though we were focused on the financials we didn’t pay attention to the actual invoicing process to understand what was needed for a smoother transfer of receivables.</li>
<li>Use a broker if at all possible!  I shudder to think of what would have went wrong if we’d tried to do this as a private sale without FE’s processes in place, as well as their guidance.</li>
<li>Get a good contact list of current active customers for efficient and transparent communication with them.  Since your customer base is you bread and butter, keep them in the loop so they stick with you!</li>
</ul>
<p>Would we do it again? Absolutely! We’ve been running <a href="https://myclientspot.com/">MyClientSpot</a> for several months now and just completed an update to modernized the user-interface.</p>
<p>I’ll do a further write-up of the updates that’ve been completed next month and how things are progressing.  Want to read about Mysql to Postgresql?  Introducing tests to a code base that utterly lacks them? Augmenting Php with graphql? Then tune in next time to hear more about these transactions.</p>

            </div>
        </div></div>]]>
            </description>
            <link>https://nathan.stitt.org/myclientspot/purchasing-myclientspot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24690705</guid>
            <pubDate>Mon, 05 Oct 2020 18:48:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick video meeting tips we use every day]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24689841">thread link</a>) | @mknighten
<br/>
October 5, 2020 | https://www.sleuth.io/post/3-9-quick-video-meeting-tips-we-use-every-day | <a href="https://web.archive.org/web/*/https://www.sleuth.io/post/3-9-quick-video-meeting-tips-we-use-every-day">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><p id="viewer-dnutn">Here at Sleuth, we live in Zoom, and have accumulated a list of tips to make video meetings better. I'm going to talk about three quick tips to go from a muddled dungeon dweller to a clear, engaging talking head, all without spending a dime. If you want even more,</p><p id="viewer-6c0ca">the above video shows you 9 <em>more</em> tips, including one advanced (but still completely free) tip to turn a video call into a real-time broadcast experience.</p><p id="viewer-aolmv">Remote Zoom or WebEx calls used to be a bit of a novelty but now they are simply how we do business. The better you look and sound on a video call, the more professional and confident your boss and colleagues will perceive you. To improve your video meetings, you need to look at three areas: sound, framing, and lighting.</p><p id="viewer-b3at8"><strong>Tip 1 - Move the microphone closer</strong></p><p id="viewer-dgia5">Sound is the most important factor in the success of your video meeting, because if they can't hear you, you simply can't communicate anything, no matter how great the picture quality. The biggest mistake people make here is to use their laptop mic, multiple feet away from their mouth, where all the noise of the room is picked up at similar volumes as their voice. Worse, they don't use a headphone, so the pic starts picking up the audio of the very meeting they are in.</p><p id="viewer-4g5o9">The fix here is simple - put the mic closer to your mouth. If the mic can pick up your voice louder than the ambient noises, your audio quality will immediately clean up and people will be able to hear you again. If you have an extra set of headphones with a mic, use that, or if you only have your laptop, put it closer to your face.</p><p id="viewer-1m7s8"><strong>Tip 2 - Position the camera at eye level</strong></p><div id="viewer-4cujo"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.sleuth.io/post/3-9-quick-video-meeting-tips-we-use-every-day" data-pin-media="https://static.wixstatic.com/media/e447f2_5f0a591b63fb4aa8b4c1f4bd67ce93f7~mv2.png/v1/fit/w_1000,h_1000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/e447f2_5f0a591b63fb4aa8b4c1f4bd67ce93f7~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-8g28j">Framing is how the camera captures you and your surroundings. You want frame yourself such that the focus is on you and not the distractions in the background. To get the best picture of you, you need to position the camera at eye level.  If you have the laptop on your, well, lap, the camera will be looking up your nose with a lovely view of that double chin that you normally don't have, but you do now.</p><p id="viewer-82fte">Another simple fix - set the laptop on a shelf, stand, or even a few books to raise the camera up to eye level. This will make your face look much better, draw the attention to your eyes, and be more engaging for your audience.</p><p id="viewer-amdcd"><strong>Tip 3 - Light you more than your background</strong></p><div id="viewer-fqan2"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.sleuth.io/post/3-9-quick-video-meeting-tips-we-use-every-day" data-pin-media="https://static.wixstatic.com/media/e447f2_f5cdd0823acf4767bb790ce8fe72a481~mv2.png/v1/fit/w_1000,h_1000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/e447f2_f5cdd0823acf4767bb790ce8fe72a481~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-a5pv0">Lighting is often forgotten about when doing a video call, but the wrong lighting will drown your image, draw unflattering shadows on your face, or distract your audience with what's behind you.</p><p id="viewer-16gbj">First, avoid big light sources behind you such as a window or doorway. These force the camera to try to adjust the exposure to the light, making your face dark and brooding. Second, avoid overhead lights as it casts unflattering shadows on your face, particularly the nose onto the mouth region. Second, light your face from the front with a lamp or sunlight so that your face can be clearly seen.</p><p id="viewer-cq5dn">You can dramatically improve your video meetings without spending a lot of time or money. I've found these tips useful because the better you look over video, the more professional and confidence you come across, giving you that little leg up. For more tips and to see them in action, check out the <a href="https://www.youtube.com/watch?v=ZeoG1z4TZlo" target="_blank" rel="noopener"><u>12 quick video meeting tips to try right now video</u></a>.</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.sleuth.io/post/3-9-quick-video-meeting-tips-we-use-every-day</link>
            <guid isPermaLink="false">hacker-news-small-sites-24689841</guid>
            <pubDate>Mon, 05 Oct 2020 17:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crouching T2, Hidden Danger: the Apple T2 vulnerability nobody talks about]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24689494">thread link</a>) | @voxadam
<br/>
October 5, 2020 | https://ironpeak.be/blog/crouching-t2-hidden-danger/ | <a href="https://web.archive.org/web/*/https://ironpeak.be/blog/crouching-t2-hidden-danger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="info"><div><p><h4><br><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" width="25" height="20"><path fill="currentcolor" d="M448 0H64C28.7.0.0 28.7.0 64v288c0 35.3 28.7 64 64 64h96v84c0 7.1 5.8 12 12 12 2.4.0 4.9-.7 7.1-2.4L304 416h144c35.3.0 64-28.7 64-64V64c0-35.3-28.7-64-64-64zm16 352c0 8.8-7.2 16-16 16H288l-12.8 9.6L208 428v-60H64c-8.8.0-16-7.2-16-16V64c0-8.8 7.2-16 16-16h384c8.8.0 16 7.2 16 16v288z"></path></svg></span>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4></p></div></div><div id="features"><div><p><h4>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4><hr><br></p><p><strong>Let’s talk about that thing nobody’s talking about.
Let’s talk about a vulnerability that’s exposing 2018-2020 Macs while most are declining to act nor report about the matter.
Oh, and did I mention it’s unpatchable?</strong></p><p><strong>Buckle up buckaroo, we’re in for a wild ride.</strong></p><p>Skip to <a href="#security-issues">#security-issues</a> for the technical mumbo-jumbo.</p><h2 id="preface">Preface</h2><h3 id="attribution">Attribution</h3><p>The following post is an industry analysis of the code and research performed by <a href="https://twitter.com/axi0mx/">twitter.com/axi0mx</a>, <a href="https://twitter.com/h0m3us3r/">twitter.com/h0m3us3r</a>, <a href="https://twitter.com/aunali1/">twitter.com/aunali1</a>, <a href="https://twitter.com/mcmrarm/">twitter.com/mcmrarm</a> and <a href="https://twitter.com/su_rickmark/">twitter.com/su_rickmark</a> who poured endless hours of work into this, allowing companies and users to understand their risks concerning this issue.</p><h3 id="intel-vs-silicon">Intel vs Silicon</h3><p>This blog post only applies to macOS systems with an Intel processor and the embedded T2 security chip.
Apple silicon systems will run completely on a set of Apple-designed ARM processors and mighth have a different topology, e.g. based on the A12.
Since the A12 chip seems to have fixed this issue (to be confirmed), it’s highly likely the new Apple Silicon machines will not be vulnerable.
And while the new upcoming Intel Macs at the end of year will probably receive a new hardware revision of the T2 chip (e.g. based on the A12), we are still stuck with this vulnerability on Macs between 2018 and 2020.</p><h3 id="so-about-this-t2-thing">So about this T2 thing</h3><p>In case you are using a recent macOS device, you are probably using <a href="https://support.apple.com/en-us/HT208862">the embedded T2 security chip</a> which runs <em>bridgeOS</em> and is actually based on watchOS. This is a custom ARM processor designed by Apple based on the A10 CPU found in the iPhone 7.
The T2 chip contains a <em>Secure Enclave Processor</em> (SEP), much like the A-series processor in your iPhone will contain a SEP.</p><p>While newer Macs and/or Apple Silicon (including the dev kit) will use a more recent A-series processor such as the one found in the recent iPhone (A12), current Macs still use the A10.</p><p>It performs a predefined set of tasks for macOS such as audio processing, handling I/O, functioning as a <a href="https://en.wikipedia.org/wiki/Hardware_security_module">Hardware Security Module</a> for e.g. Apple KeyChain or 2FA, hardware accelerating media playback, whitelisting kernel extensions, cryptographic operations and <strong>ensuring the operating system you are booting is not tampered with</strong>.
The T2 chip runs its own firmware called <em>bridgeOS</em>, which can be updated when you install a new macOS version. (ever notice the screen flickering? that’s the display driver being interrupted and possibly updated.)</p><p><em>Edit</em>: I first mentioned the iPad Pro to be impacted by the T2 vulnerability, but while it could suffer from the same vulnerability, it does not contain a T2 chip.</p><h3 id="the-macos-boot-sequence">The macOS boot sequence</h3><p>So let’s focus on the boot image verification on macOS. What exactly happens when you press that power button?
<a href="https://eclecticlightdotcom.files.wordpress.com/2018/08/bootprocess.png">There’s also a visual representation for any <em>conaisseurs</em></a>.
For the enthusiasts, I personally find <a href="https://michaellynn.github.io/2018/07/27/booting-secure/">Booting Secure by mikeymikey</a> a more in-depth description.</p><ol><li><p>The T2 chip is fully booted and stays on, even if your Mac device is shutdown.</p></li><li><p>The press of the power button or the opening of the lid triggers the System Management Controller (SMC) to boot.</p></li><li><p>The SMC performs a Power-On-Self-Test (POST) to detect any EFI or hardware issues such as bad RAM and possibly redirect to Recovery.</p></li><li><p>After those basic sanity checks, the T2 chip is triggered and I/O connectors are setup. (USB, NVMe, PCIe, …) It will use NVMe and PCIe to talk to NAND storage.</p></li><li><p>The applicable boot disk is selected and a disk encryption password is asked if enabled to mount <a href="https://en.wikipedia.org/wiki/Apple_File_System">APFS</a> volumes possibly via FileVault2 disk encryption.</p></li><li><p><code>/System/Library/CoreServices/boot.efi</code> is located on your System APFS volume and <a href="https://support.apple.com/en-us/HT208330">depending on your secure boot settings</a> is validated.</p></li><li><p><em>boot.efi</em> is ran which loads the Darwin kernel <em>(throwback to BSD)</em> (or Boot Camp if booting Microsoft Windows) &amp; IODevice drivers. If a kernel cache is found in <code>/System/Library/PrelinkedKernels/prelinkedkernel</code>, it will use that.</p></li><li><p>Any User Approved Kernel Extensions are initialized &amp; added to the kernel space -if- they are approved by the T2 chip.
<em>This will go away with System Extensions</em>.</p></li></ol><h3 id="macos-security-features">macOS security features</h3><p>So Apple has a couple of tricks up its sleeve to limit the attack surface of any potential security vulnerabilities. A small summary of related measures since macOS Big Sur on Intel processors:</p><ul><li><p><em>System Integrity Protection</em> (SIP): a read-only <code>/System</code> partition so the base install of macOS (including the kernel) cannot be tampered with.</p></li><li><p><em>System Extensions</em>: a move to away from Kernel Extensions, getting external code out of the Kernel framework-wise.</p></li><li><p><em>Secure Boot</em>: verifies the signature validity of the operating system on disk.</p></li><li><p><em>Filesystem seals</em>: every byte of data is compared to a hash in the filesystem metadata tree, recursively verifying integrity.</p></li></ul><h3 id="apple-marketing">Apple marketing</h3><p>As you probably all already know, Apple pushes forward privacy &amp; security as important weapons in todays world of technology.
They tout their devices as highly secure and vouch to handle your personal data using a privacy-centric approach.
While there have been mistakes made in the past (who can blame them?), Apple has been generally quick to fix any security issues that were disclosed to <a href="https://support.apple.com/en-gb/HT201220">their responsible disclosure program</a> or in public.</p><h2 id="security-issues">Security issues</h2><h3 id="jailbreaking">Jailbreaking</h3><h3 id="the-core-problem">The core problem</h3><p>The mini operating system on the T2 (<em>SepOS</em>) suffers from a security vulnerable also found in the iPhone 7 since it contains a processor based on the iOS A10. Exploitation of this type of processor for the sake of installing homebrew software is very actively discussed in the <a href="https://reddit.com/r/jailbreak/">/r/jailbreak</a> subreddit.</p><p>So using the <a href="https://checkm8.info/">checkm8 exploit</a> originally made for iPhones, the checkra1n exploit was developed to build a semi-tethered exploit for the T2 security chip, exploiting a flaw. This could be used to e.g. circumvent activation lock, allowing stolen iPhones or macOS devices to be reset and sold on the black market.</p><p>Normally the T2 chip will exit with a fatal error if it is in DFU mode and it detects a decryption call, but thanks to the <a href="https://github.com/windknown/presentations/blob/master/Attack_Secure_Boot_of_SEP.pdf">blackbird vulnerability</a> by team Pangu, we can completely circumvent that check in the SEP and do whatever we please.</p><p>Since sepOS/BootROM is <em>Read-Only Memory</em> for security reasons, interestingly, Apple cannot patch this core vulnerability without a new hardware revision.
This thankfully also means that this is not a persistent vulnerability, so it will require a hardware insert or other attached component such as a malicious USB-C cable.</p><h3 id="debugging">Debugging</h3><p>Every Apple iDevice (which includes the T2 and the Watch, via a port under the band) ships with a firmware recovery USB interface called Device Firmware Update (DFU), which is triggered when the device is not be able to boot or by pressing a particular set of buttons when turned on. It is always available because it is code run from SecureROM. This is the mode in which checkm8 runs.</p><p>Apple also leaves the ability to access various debug functionality which is disabled on production devices unless a special boot payload is used which runs in DFU. Since Apple is the only one who can sign code for DFU, they can demote any device they like, including the most recent A14 processors.
But since the checkm8 vulnerability runs so early in the boot process, we too can demote the T2 into DFU mode.
Without checkm8, we would not be able to run unsigned code in DFU and thus not be able enable debug interfaces. Once the debug interface is enabled Apple uses specialized cables with simian names (see Chimp, Kanzi, Gorilla).</p><h3 id="impact">Impact</h3><p>Once you have access on the T2, you have full <code>root</code> access and kernel execution privileges since the kernel is rewritten before execution.
Good news is that if you are using FileVault2 as disk encryption, they do not have access to your data on disk <em>immediately</em>.
They can however inject a keylogger in the T2 firmware since it manages keyboard access, storing your password for retrieval or transmitting it in the case of a malicious hardware attachment.</p><p>The functionality of locking an Apple device remotely (e.g. via MDM or FindMy) can be bypassed (<em>Activation Lock</em>).</p><p>A firmware password does not mitigate this issue since it requires keyboard access, and thus needs the T2 chip to run first.</p><p>Any kernel extension could be whitelisted since the T2 chip decides which one to load during boot.</p><p>If the attack is able to alter your hardware (or sneak in a malicious USB-C cable), it would be possible to achieve a semi-tethered exploit.</p><p>While this may not sound as frightening, be aware that this is a perfectly possible attack scenario for state actors.
I have sources that say more news is on the way in the upcoming weeks. I quote: <em>be afraid, be very afraid</em>.</p><h2 id="exploitation">Exploitation</h2><pre><code># install devtools
$ xcode-select --install

# check the script &amp; install homebrew
$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"

# install packages
$ brew install libplist automake autoconf pkg-config openssl libtool llvm libusb

# git clone, autogen.sh, make &amp; make install
# https://github.com/sbingner/ldid
# https://github.com/libimobiledevice/libusbmuxd
# https://github.com/libimobiledevice/libimobiledevice
# https://github.com/libimobiledevice/usbmuxd

# Run checkra1n and wait for T2 boot. It will stall when complete.
# TODO describe the checkra1n exploitation 

# Unplug and replug the usb connection. Checkra1n should now send the overlay.
# TODO describe the usb debug mode &amp; overlay

# Bring up a proxy to dropbear
$ iproxy 2222 44 &amp;

# Connect to T2 &amp; enjoy
$ ssh -p 2222 root@127.0.0.1
</code></pre><h2 id="responsible-disclosure">Responsible Disclosure</h2><p>I’ve reached out to Apple concerning this issue on numerous occasions, even doing the dreaded cc <em>tcook@apple.com</em> to get some exposure.
Since I did not receive a response for weeks, I did the same to numerous news websites that cover Apple, but no response there as well.
In hope of raising more awareness (and an official response from Apple), I am hereby disclosing almost all of the details.
You could argue I’m not following responsible disclosure, but since this issue has been known since 2019, I think …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ironpeak.be/blog/crouching-t2-hidden-danger/">https://ironpeak.be/blog/crouching-t2-hidden-danger/</a></em></p>]]>
            </description>
            <link>https://ironpeak.be/blog/crouching-t2-hidden-danger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24689494</guid>
            <pubDate>Mon, 05 Oct 2020 16:52:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corruption Is Attractive]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24688693">thread link</a>) | @todsacerdoti
<br/>
October 5, 2020 | https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/chaos1.jpg" alt="Chaos, an important theme in hermetism" loading="lazy"></p>

<p>We live in a world that is gradually and incessantly attracted by
over-rationality and order. In this article we’ll burst the enchanted
bubble and embrace corruption and chaos — We’re going to discuss the
topic of image glitch art.</p>

<h2 id="w̸h̸a̷t̴̶s̴-̶a̴-̷g̷l̸i̷t̴c̵h̵">w̸h̸a̷t̴’̶s̴ ̶a̴ ̷g̷l̸i̷t̴c̵h̵</h2>

<p>Welcome to the land of creative destruction: image glitch art. Our story
starts with a simple idea: glitching a wallpaper to create a slideshow
of corrupted pictures.<br>
The unfortunate victim of our crime: The world (Right click <strong>&gt;</strong> View
image, while keeping the <strong>Control</strong> key pressed, to admire it in more
details while its still in its pristine form):</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map.jpg" alt="World Map, nominal case" loading="lazy"></p>

<p>Before we begin, let’s attempt to define what we’re trying to do: What
is glitch art?<br>
Like any art movement, words can barely express the essence behind the
meaning, they are but fleeting and nebulous. Regardless, I’ll be an
infidel and valiantly express what I think glitch art is.</p>

<p>A glitch is a perturbation, a minor malfunction, a spurious signal. In
computers, glitches are predominantly accidental events that are
undesirable and could possibly corrupt data.<br>
Glitch art started as people developed a liking for such unusual events
and the effects glitches had on the media they were perturbing. Some started
to collect these glitches that happened naturally in the wild, and others
started to intentionally appropriate the effects by manually performing them.<br>
In the art scene, some started using image processing to “fake” true
glitching effects.</p>

<p>Glitches happen all the time and everywhere, information is never as
durable and reliable as we might like it to be, and living in a physical
world makes it even less so. You’ve probably encountered or heard of the
effect of putting a magnet next to anything electronic that hasn’t been
rugged to withstand such scenario.<br>
That’s why many techniques have been put in place to avoid glitches,
at all layers, from the hardware storage, to the software reading
and interpreting it. Be it error correcting codes (ECC) or error detection
algorithms, they are all enemies of glitch art and the chaos we like.</p>

<p>However, this niche aesthetic is more than a fun pass-time for computer
aficionado, there is a bigger picture. Similar to painters with
brushes on a canvas, we are offered a material, an object to work with
— a material made of bits and formatted in a specific way.<br>
Like any object, our medium has a form and meaning, it can move, it has
a size, it can be transferred, and interpreted — information theory
is the field interested in this.<br>
Like any object, our medium can be subject and react to deformations,
forces, and stressors. How it flows is what the field of rheology
is interested in (not to be confused with computational rheology, the
field of fluid simulation.) The medium fluidity can be studied to answer
questions such as: is it elastic, solid, viscous, or oily, how does it
respond, within the bound of information theory, to different types of
applied forces.</p>

<p>Here are some words you may encounter and that you definitely want
to know:</p>

<ul>
  <li>
    <p>Misregistration: Whenever a physical medium misread data because of
damages caused by scratches, dirt, smudges, gamma rays, or any other
treasures the universe throws at us.</p>
  </li>
  <li>
    <p>Datamoshing, Photomosh, Imagemosh: Abusing the format of a medium,
normally compression artefacts, to create glitches. For example, video
compression often use i-frames for fixed images and p-frame for the
movement/transition of pixels on that image. <a href="https://www.reddit.com/r/datamoshing/">Removing i-frames is a
common glitching method</a>.</p>
  </li>
  <li>
    <p>Databending: An idea taken from circuit bending, bending the circuit
board of a toy to generate weird sounds. Databending is about bending
the medium into another unrelated one, reinterpreting it as something
it is not meant to be.</p>
  </li>
</ul>

<p>Let me add that glitch art is vast and fascinating, this article is but a
glimpse into this space. If you’re captivated as much as I am, please take
a look at <a href="http://gli.tc/h/0nline/">gli.tc</a> and <a href="https://beyondresolution.info/">Rosa Menkman’s Beyond
Resolution</a>. Images can be pleasantly
destroyed in a great number of ways to create masterpieces.</p>

<h2 id="i̷m̷a̷g̴e̴-̸g̸l̴i̴t̴c̵h̸-̴a̶r̵t̵">I̷m̷a̷g̴e̴ ̸G̸l̴i̴t̴c̵h̸ ̴A̶r̵t̵</h2>

<p>Before starting let’s give some advices:</p>

<ul>
  <li>Back up your precious files before corrupting them.</li>
  <li>Any glitching techniques can be combined and/or applied multiple times.</li>
  <li>Sometimes too little has no effect, and sometimes too much can destroy
the file.</li>
  <li>It’s all about trials and errors, especially errors that result in
glitches.</li>
</ul>

<h3 id="̷h̷o̵w̶-̵t̸o̴-̶i̷n̶d̸u̷c̶e̵-̶a̸-̶g̸l̵i̷t̶c̸h̴">̷H̷o̵w̶ ̵T̸o̴ ̶I̷n̶d̸u̷c̶e̵ ̶A̸ ̶G̸l̵i̷t̶c̸h̴</h3>

<p>Now it’s time to think about how we can apply our mischievous little
stimuli, its size, the level or layer at which it’ll be applied, and
the methodological recipe we’ll concoct to poison our images.</p>

<p>Glitch artist Benjamin Berg classifies glitches into 3 categories:</p>

<ul>
  <li>Incorrect Editing: Editing a file using a software that
wasn’t made to edit such file. Like editing an image file as if it
was a text file.</li>
  <li>Reinterpretation aka Databending: Convert or read a file as if it was
another type of medium. Like listening to an image file as if it was
an audio file (aka sonification).</li>
  <li>Forced errors, Datamoshing, and Misregistration: A software or hardware
bug to force specific errors in the file. This can be about the
corruption of specific bytes in the file to induce glitches, or
something happening accidentally like a device turning off when saving
a file.</li>
</ul>

<p>So let’s get to work!</p>

<h3 id="m̷a̵s̵h̸i̶n̶g̷-̴t̶h̷e̷-̷d̶a̸t̵a̸-̸r̷a̸n̶d̶o̸m̴l̵y̷">M̷a̵s̵h̸i̶n̶g̷ ̴T̶h̷e̷ ̷D̶a̸t̵a̸ ̸R̷a̸n̶d̶o̸m̴l̵y̷</h3>

<p>The easiest, but roughest, way to glitch a file is to put on our monkey
suit and overwrite or add random bytes in our image. As you would have
guessed, this isn’t very efficient but half the time it does the trick
and forces errors.</p>

<p>This technique is better suited for stronger materials like images in
raw format — without metadata and headers. We’ll understand why in a bit.<br>
To convert the file to raw format, open it in GIMP, select <strong>Export As</strong>,
select the file by extension, and choose the raw type. For now, it doesn’t
matter if you pick pixel-ordered or planar, but we’ll come back to this
choice later because it’s an important one.</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/gimp_saveas_raw.jpg" alt="GIMP process to save image as raw" loading="lazy"></p>

<figure><pre><code data-lang="shell">file world_map.data
<span># world_map.data: Targa image data - Map (771-3) 771 x 259 x 1 - 1-bit alpha "\003\003\003\003\003\003\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001"</span></code></pre></figure>

<p>You should also note the width and height of the image as it now doesn’t
contain this information anymore, and we’ll need those to reopen it in
GIMP. In our case it is <code>2000x1479</code>.</p>

<p>We now proceed to hand over the file to our least favorite
staff and let them have an anger tantrum at it. So what does
it look like, let’s take a look at <a href="https://www.youtube.com/watch?v=oj6NMiuU0ys">the result our monkey
did</a>:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_random_bytes.jpg" alt="World Map, monkey have been randomly mashing the
world" loading="lazy"></p>

<p>Not bad at all for something random, but we can do better.</p>

<h3 id="c̸o̶m̸p̷r̶e̷s̸s̵i̸o̶n̴-̶d̵e̵f̶o̶r̴m̷a̶t̷i̵o̸n̷">C̸o̶m̸p̷r̶e̷s̸s̵i̸o̶n̴ ̶D̵e̵f̶o̶r̴m̷a̶t̷i̵o̸n̷</h3>

<p>Some medium are more malleable when squished properly and squished
in different ways. The image sheds a lot of information and only the
essence stays. That’s a form of databending.<br>
For example, increasing the compression of JPEG images can open the path
for glitches to happen more frequently. This is a key asset, especially
when trying to create errors related to the compression parameters within
the format of the file.</p>

<figure><pre><code data-lang="shell">convert <span>-quality</span> 2 world_map.jpg world_map_compressed.jpg</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_compressed.jpg" alt="World Map, compressed to extract its
essence" loading="lazy"></p>

<p>Keep this in your toolbox to use along with other techniques.</p>

<h3 id="g̵e̴t̵t̶i̸n̵g̷-̴i̸n̵t̷i̵m̷a̴t̸e̴-̸w̶i̵t̸h̶-̴t̵h̸e̸-̴f̷o̴r̶m̸a̴t̷">G̵e̴t̵t̶i̸n̵g̷ ̴I̸n̵t̷i̵m̷a̴t̸e̴ ̸W̶i̵t̸h̶ ̴T̵h̸e̸ ̴F̷o̴r̶m̸a̴t̷</h3>

<p>We want to corrupt in the most efficient way possible, to create
attractive chaos from the smallest change possible. To do that we have to
get intimate with the medium, to understand its deepest secrets, tickle
the image in the right places. This is what we previously referred to
as imagemoshing.</p>

<p>There’s a panoply of image formats, and they all are special in their
own ways. However, there’s still some commonality:</p>

<ul>
  <li>Header, Footer, and Metadata: If the format contains these extra
information, be it extraneous or essential, what they represent, and
how they affect the rest of the image.</li>
  <li>Compression: The format can either be compressed or not. When it is
compressed, there can be extra bits of information to help other software
uncompress the image data.</li>
  <li>How the data is laid out: Usually, the image color information is
decomposed into its components such as HSL, RGB, or others. These
components then need to be represented in the image data, either in
an interleaved or planar manner. Planar refers to writing components
independently in the data (<em>ex:</em> all R, then all G, then all B),
while interleaved refers to having them joined non-contiguously in an
alternate sequence (<em>ex:</em> RGB, then RGB, then RGB..).</li>
</ul>

<p>Manipulating these to our advantage can lead to wonderful glitches. For
example, in our previous raw image example — an image bare of header,
footer, and without compression — the pixels were interleaved which
gave rise to the effect we’ve seen, namely shifts and changes in some
colors. Having them in planar form would’ve led to different glitches
in separate color channels.</p>

<h3 id="r̵e̷i̷n̴t̶e̷r̶p̸r̴e̸t̸a̷t̶i̷o̵n̴-̵a̸s̵-̵r̸i̷c̵h̸-̸t̷e̵x̵t̴-̴a̴k̷a̸-̷w̶o̴r̵d̴p̴a̸d̵-̷e̵f̸f̴e̶c̶t̶">R̵e̷i̷n̴t̶e̷r̶p̸r̴e̸t̸a̷t̶i̷o̵n̴ ̵A̸s̵ ̵R̸i̷c̵h̸ ̸T̷e̵x̵t̴ ̴A̴K̷A̸ ̷W̶o̴r̵d̴P̴a̸d̵ ̷E̵f̸f̴e̶c̶t̶</h3>

<p>Let’s give this a try with the well-known WordPad effect, which is about
databending an image into rich text: opening the image in WordPad and
saving it.<br>
Keep in mind that this only works with raw images as it’s highly
destructive and otherwise could break fragile key info in the header
and footer. So let’s reuse our interleaved raw image of earlier but also
get a planar one.</p>

<p>This is our results for interleaved:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_wordpad.interleaved.corrupt.jpg" alt="World Map, WordPad effect interleaved" loading="lazy"></p>

<p>And for planar:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_wordpad.planar.corrupt.jpg" alt="World Map, WordPad effect planar" loading="lazy"></p>

<p>Technically, what happens is that during the bending and interpretations
as rich text, some bytes are inserted in some …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html">https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24688693</guid>
            <pubDate>Mon, 05 Oct 2020 15:38:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How healthcare workers, and their phones, coped with a pandemic]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24688558">thread link</a>) | @donohoe
<br/>
October 5, 2020 | https://restofworld.org/2020/whats-on-your-homescreen/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/whats-on-your-homescreen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p>Street network</p>
						<h2>The life and death of SNET, Havana’s alternative internet</h2>
						<p>As Cuba sluggishly got its population online, the shadow internet developed by volunteers provided a lifeline for thousands of people.</p>
						<p>By <span>Priscila Bellini</span></p>
					</div>
				</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/whats-on-your-homescreen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24688558</guid>
            <pubDate>Mon, 05 Oct 2020 15:24:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Separation of concerns between code and service layout (2010)]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24688381">thread link</a>) | @iou
<br/>
October 5, 2020 | https://www.josephkirwin.com/2020/10/04/separation-of-concerns-between-code-and-service-layout/ | <a href="https://web.archive.org/web/*/https://www.josephkirwin.com/2020/10/04/separation-of-concerns-between-code-and-service-layout/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <time datetime="2020-10-04">04 October 2020</time>
  

  <p>No doubt, when I write this (assuming someone reads it) someone might say:</p>

<blockquote>
  <p>“Oh, you should have used Garibaldi…. or Ozymandias or Plato.js”</p>
</blockquote>

<p>…or some other framework. Please let me know in the comments, I couldn’t find anything on this and must have been searching for the wrong keywords.
When that happens I’ll add an ‘edit’ here to route anyone looking for that that way.</p>



<p>Initially you may start out building a piece of software, and that may grow to be a huge monolithic codebase. There’s benefits to everything being together initially, but then it’s frustrating later on if things are glued together and you’re unable to split it apart easily.</p>

<p>An additional challenge is that SREs/ops/devops people don’t have enough fine-grained control to split up the functionality efficiently.</p>

<p>So are these 2 things achievable:</p>

<ol>
  <li>Some design that allows you to easily break apart (or pull together) components of a system</li>
  <li>This design allows a separation-of-concern from the developers and lets operations people chose the layout</li>
</ol>



<p>I learned in this previous project <a href="https://github.com/joekir/indelible/blob/master/cmd/indelible/main.go#L89">github.com/joekir/indelible</a> that <a href="https://grpc.io/">GRPC</a> could easily switch it’s “transport medium” without needing to change the functionality of the code.</p>

<p>This made me think, what if you could abstract the transport mechanism for how a function is called in code. 
Specifically splitting it into:</p>
<ol>
  <li>Normal ptr to address in your current process space and exec
<img src="https://www.josephkirwin.com/assets/inprocess.png" alt="inprocess"></li>
  <li>Interprocess Communication (Unix socket for example)
<img src="https://www.josephkirwin.com/assets/ipc.png" alt="ipc"></li>
  <li>Network Communication (TCP/UDP)
<img src="https://www.josephkirwin.com/assets/network_call.png" alt="network_call"></li>
</ol>



<p>aka <em>“What currently doesn’t exist and would need to for this thing to exist”</em></p>

<p>Firstly, you’d need some way to <a href="https://en.wikipedia.org/wiki/Decorator_pattern">decorate</a> a function/module/class/etc in the coding language to indicate that implicitly a protobuf should be generated for it.</p>

<p>e.g. (in pseudo code)</p>

<div><div><pre><code>  <span>@ComponentBoundary</span>
  <span>func</span> <span>PrintSomething</span><span>(</span><span>String</span> <span>title</span><span>,</span> <span>Integer</span> <span>count</span><span>=</span><span>5</span><span>){</span>
    <span>...</span>
</code></pre></div></div>

<p>which would produce</p>

<div><div><pre><code><span>...</span>
<span>service</span> <span>&lt;</span><span>TODO</span><span>&gt;</span> <span>{</span>
  <span>rpc</span> <span>PrintSomething</span> <span>(</span><span>PrintSomethingArgs</span><span>)</span> <span>returns</span> <span>(</span><span>google.protobuf.Empty</span><span>)</span> <span>{}</span>
<span>}</span>

<span>message</span> <span>PrintSomethingArgs</span> <span>{</span>
  <span>required</span> <span>string</span> <span>title</span> <span>=</span> <span>1</span><span>;</span>
  <span>optional</span> <span>uint32</span> <span>count</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span>
<span>...</span>
</code></pre></div></div>

<p>Once you have that, you’d want every function call that goes between one of those decorated functions to have some interstitial code that makes a GRPC call which can either do</p>
<ul>
  <li>Passthru - where it simply bypasses all the GRPC and allows the normal function call in-process  <br>
        <em>~OR~</em></li>
  <li>Uses some configuration to determine whether it should make the GRPC call over IPC (Interprocess Communication) to another process/container on the same host, or over TCP/UDP to a process over the network.
    <ul>
      <li>Additionally handling authentication and all other nicities that GRPC would usually handle</li>
    </ul>
  </li>
</ul>

<p>Then you’d need some runtime configuration that the operations team could leverage to indicate how that function should be “currently” accessed. 
There’d also need to be some linter/compiler additions to make the language aware of when you’re trying to access something that is over a component boundary and expecting to have some shared state.</p>



<ol>
  <li>Performance/Reliability/Cost engineering can focus on the production layout of a system and have more granular controls to make it efficient</li>
  <li>Developers no longer need to think about GRPC and whether a call will be local or over the network, if it has a decorator it’s assumed “it could be”</li>
</ol>



<p>I’m a security engineer, so I like security stuff sometimes.
There’s another “constraint” that could be interesting here with the decorator.</p>

<p>Generally Network &gt; Container &gt; Shared memory, in terms of defending against exploitation. So it could be that you have some security critical code that you only want to be available at IPC or network level.
This decorator could then include that you do not want to allow passthru behaviour, e.g.</p>

<div><div><pre><code>  <span>@ComponentBoundary</span><span>(</span><span>!</span><span>[</span><span>passthru</span><span>])</span>
  <span>func</span> <span>SecCriticalCode</span><span>(</span><span>Object</span> <span>input</span><span>,</span> <span>Integer</span> <span>count</span><span>){</span>
    <span>...</span>
</code></pre></div></div>
<p><br>
That’s it, I haven’t coded this thing yet because 1 it seems hard, 2 someone else might have already done it, 3 it could be useless and I just haven’t learned why yet. Let me know in the comments! :)</p>


</article></div>]]>
            </description>
            <link>https://www.josephkirwin.com/2020/10/04/separation-of-concerns-between-code-and-service-layout/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24688381</guid>
            <pubDate>Mon, 05 Oct 2020 15:04:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Type-Level Programming in Rust]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24687685">thread link</a>) | @fanf2
<br/>
October 5, 2020 | https://willcrichton.net/notes/type-level-programming/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/type-level-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; — &nbsp;
    April 24, 2020
  </p>
  <p>I show how two domain-specific type systems, information flow control and two-party communication protocols, can be implemented in Rust using type-level programming. I explain how interesting properties of these domains can be verified at compile-time. Finally, I construct a general correspondence between type operators, logic programs, and their encoding in Rust.</p>
  <p>Typestate is the concept of encoding state machines in a programming language’s type system. While not specific to Rust, typestate has been <a href="http://cs242.stanford.edu/f19/lectures/08-2-typestate">explored</a> <a href="https://yoric.github.io/post/rust-typestate/">elsewhere</a> <a href="https://blog.systems.ethz.ch/blog/2018/a-hammer-you-can-only-hold-by-the-handle.html">at length</a> in the context of Rust. Typestate boils down to four ideas:</p>

<ol>
  <li>Each state is represented as a unique type.</li>
  <li>State transitions are only available as methods for the corresponding state type.</li>
  <li>Taking a state transition returns a state machine of the new state type.</li>
  <li>State transitions invalidate old state.</li>
</ol>

<p>For example, here’s a state machine for a send-then-receive channel:</p>

<div><div><pre><code><span>// Each state is a unique type</span>
<span>struct</span> <span>Receiving</span><span>;</span>
<span>struct</span> <span>Sending</span><span>;</span>

<span>// The state machine is parameterized by the state</span>
<span>#[repr(transparent)]</span>
<span>struct</span> <span>Channel</span><span>&lt;</span><span>State</span><span>&gt;</span> <span>{</span>
  <span>chan</span><span>:</span> <span>...</span><span>,</span>
  <span>_</span><span>state</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>State</span><span>&gt;</span>
<span>}</span>


<span>// Methods for the state are uniquely associated with only the state</span>
<span>impl</span> <span>Channel</span><span>&lt;</span><span>Receiving</span><span>&gt;</span> <span>{</span>
  <span>// recv consumes ownership, ensuring old state is invalidated</span>
  <span>fn</span> <span>recv</span><span>(</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Channel</span><span>&lt;</span><span>Sending</span><span>&gt;</span><span>,</span> <span>String</span><span>)</span> <span>{</span>
    <span>let</span> <span>msg</span> <span>=</span> <span>self</span><span>.chan</span><span>.recv</span><span>();</span>
    <span>// The state type changes after executing a transition</span>
    <span>(</span><span>unsafe</span> <span>{</span> <span>transmute</span><span>(</span><span>self</span><span>)</span> <span>},</span> <span>msg</span><span>)</span>
  <span>}</span>
<span>}</span>

<span>impl</span> <span>Channel</span><span>&lt;</span><span>Sending</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>send</span><span>(</span><span>mut</span> <span>self</span><span>,</span> <span>msg</span><span>:</span> <span>String</span><span>)</span> <span>-&gt;</span> <span>Channel</span><span>&lt;</span><span>Receiving</span><span>&gt;</span> <span>{</span>
    <span>self</span><span>.chan</span><span>.send</span><span>(</span><span>msg</span><span>);</span>
    <span>unsafe</span> <span>{</span> <span>transmute</span><span>(</span><span>self</span><span>)</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>#[test]</span>
<span>fn</span> <span>channel_test</span><span>()</span> <span>{</span>
  <span>let</span> <span>c</span><span>:</span> <span>Channel</span><span>&lt;</span><span>Sending</span><span>&gt;</span> <span>=</span> <span>Channel</span><span>::</span><span>new</span><span>();</span>
  <span>let</span> <span>c</span><span>:</span> <span>Channel</span><span>&lt;</span><span>Receiving</span><span>&gt;</span> <span>=</span> <span>c</span><span>.send</span><span>(</span><span>"hi"</span><span>);</span>
  <span>let</span> <span>(</span><span>c</span><span>,</span> <span>msg</span><span>)</span> <span>=</span> <span>c</span><span>.recv</span><span>();</span>
  <span>// and so on</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>There are <a href="https://news.ycombinator.com/item?id=24688233">many</a> <a href="https://www.reddit.com/r/rust/comments/gaxlm3/typelevel_programming_in_rust/fp2gjhg/">readers</a> concerned with the use of <code>transmute</code>. The use of <code>#[repr(transparent)]</code> ensures that the layout of <code>Channel</code> is <a href="https://doc.rust-lang.org/nomicon/other-reprs.html#reprtransparent">stable across transmutations</a> of the marker type.</p>
</blockquote>

<p>This pattern works effectively for simple finite state machines, where the logic to determine the next state is straightforward. In this note, I will explore situations where determining the next state is not so simple. In the process, we’ll talk about <strong>type-level programming</strong>, or how you can use Rust’s type system to encode <strong>computations on types</strong>.</p>

<blockquote>
  <p>Part of the goal of this note is to show the value of type-level programming in practice. These same mechanisms have already been used for more esoteric purposes like <a href="https://sdleffler.github.io/RustTypeSystemTuringComplete/">showing Rust’s type system is Turing complete</a>, but I think type-level programming can really help us design better systems!</p>
</blockquote>

<h2 id="1-information-flow-control">1. Information flow control</h2>

<p>As a first example, consider a basic information flow control problem. In our program we have low security values (anyone can read them) and high security values (only authorized users can read them).</p>

<p>We represent this idea like so:</p>

<div><div><pre><code><span>// Each security level is a type</span>
<span>struct</span> <span>HighSec</span><span>;</span>
<span>struct</span> <span>LowSec</span><span>;</span>

<span>// An Item wraps an arbitrary type T, associating it with a Level</span>
<span>#[repr(transparent)]</span>
<span>struct</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>{</span>
  <span>t</span><span>:</span> <span>Box</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span>
  <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>Level</span><span>&gt;</span>
<span>}</span>

<span>// Constructors for building items of a particular security</span>
<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>low_sec</span><span>(</span><span>t</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
    <span>Item</span> <span>{</span> <span>t</span><span>:</span> <span>Box</span><span>::</span><span>new</span><span>(</span><span>t</span><span>),</span> <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span> <span>}</span>
  <span>}</span>

  <span>pub</span> <span>fn</span> <span>high_sec</span><span>(</span><span>t</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>HighSec</span><span>&gt;</span> <span>{</span>
    <span>Item</span> <span>{</span> <span>t</span><span>:</span> <span>Box</span><span>::</span><span>new</span><span>(</span><span>t</span><span>),</span> <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>// For simplicity, a naked Item can be read by anyone</span>
<span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>Deref</span> <span>for</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Target</span> <span>=</span> <span>T</span><span>;</span>
  <span>fn</span> <span>deref</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>T</span> <span>{</span>
    <span>&amp;</span><span>self</span><span>.t</span>
  <span>}</span>
<span>}</span>

</code></pre></div></div>

<p>We would like to have a vector of these items with the following property:</p>
<ul>
  <li>If all of the items are low security, anyone can read any item.</li>
  <li>If any of the items are high security, only an authorized user can read any item.</li>
</ul>

<p>For example, our vector should pass this test:</p>

<div><div><pre><code><span>let</span> <span>v</span> <span>=</span> <span>SecureVec</span><span>::</span><span>new</span><span>();</span>
<span>let</span> <span>lo</span> <span>=</span> <span>Item</span><span>::</span><span>low_sec</span><span>(</span><span>1</span><span>);</span>
<span>let</span> <span>hi</span> <span>=</span> <span>Item</span><span>::</span><span>high_sec</span><span>(</span><span>2</span><span>);</span>
<span>let</span> <span>v</span> <span>=</span> <span>v</span><span>.push</span><span>(</span><span>lo</span><span>);</span>         <span>// v is still low sec</span>
<span>assert_eq!</span><span>(</span><span>*</span><span>v</span><span>.get</span><span>(</span><span>0</span><span>),</span> <span>1</span><span>);</span>   <span>// ok to read v</span>

<span>let</span> <span>v</span> <span>=</span> <span>v</span><span>.push</span><span>(</span><span>hi</span><span>);</span>         <span>// v is now high sec</span>
<span>// assert_eq!(v.get(0), 1); // can't read any more, compiler error</span>

<span>let</span> <span>w</span> <span>=</span> <span>HighSecWitness</span><span>::</span><span>login</span><span>();</span>
<span>assert_eq!</span><span>(</span><span>*</span><span>v</span><span>.get_secure</span><span>(</span><span>1</span><span>,</span> <span>w</span><span>),</span> <span>2</span><span>);</span> <span>// can read after login</span>
</code></pre></div></div>

<p>A basic type-state attempt looks like this. We can create and read a low-security vector:</p>

<div><div><pre><code><span>#[repr(transparent)]</span>
<span>struct</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>{</span>
  <span>items</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;&gt;</span><span>,</span>
  <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>Level</span><span>&gt;</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>new</span><span>()</span> <span>-&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
    <span>SecureVec</span> <span>{</span> <span>items</span><span>:</span> <span>Vec</span><span>::</span><span>new</span><span>(),</span> <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span> <span>}</span>
  <span>}</span>

  <span>pub</span> <span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>i</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>T</span> <span>{</span>
    <span>&amp;</span><span>self</span><span>.items</span><span>[</span><span>i</span><span>]</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And we can protect a high-security vector through a witness:</p>

<div><div><pre><code><span>struct</span> <span>HighSecWitness</span><span>;</span>
<span>impl</span> <span>HighSecWitness</span> <span>{</span>
  <span>// sprinkle some high-security authentication in here...</span>
  <span>pub</span> <span>fn</span> <span>login</span><span>()</span> <span>-&gt;</span> <span>HighSecWitness</span> <span>{</span> <span>HighSecWitness</span> <span>}</span>
<span>}</span>


<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>HighSec</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>get_secure</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>i</span><span>:</span> <span>usize</span><span>,</span> <span>_</span><span>witness</span><span>:</span> <span>HighSecWitness</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>T</span> <span>{</span>
    <span>&amp;</span><span>self</span><span>.items</span><span>[</span><span>i</span><span>]</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Now, to the main idea: how can we implement <code>push</code>? There are four possible state combinations: a high/low security vector with a high/low security item. While we can implement each combination as a separate method, it’s simpler to consider the underlying logic. <code>push</code> should return a vector of level <code>max(vec_level, item_level)</code> where <code>max(hi, lo) = hi</code>.</p>

<p>Our goal is to encode <code>max</code> as a <em>type-level computation</em>, i.e. an operator on types. The high-level idea:</p>
<ul>
  <li>Traits definitions are function signatures from types to types.</li>
  <li>Trait type parameters represent inputs and associated types represent outputs.</li>
  <li>Trait implementations define individual mappings from inputs to outputs.</li>
</ul>

<p>Here are those ideas in action to compute the max security level:</p>

<div><div><pre><code><span>// Self (implicitly) is the left operand, Other is the right operand,</span>
<span>// and Output is the output</span>
<span>trait</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>Other</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span><span>;</span>
<span>}</span>

<span>// These impls define the core computation</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>LowSec</span><span>&gt;</span>  <span>for</span> <span>LowSec</span>  <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>LowSec</span><span>;</span>  <span>}</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>HighSec</span><span>&gt;</span> <span>for</span> <span>LowSec</span>  <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>HighSec</span><span>;</span> <span>}</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>LowSec</span><span>&gt;</span>  <span>for</span> <span>HighSec</span> <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>HighSec</span><span>;</span> <span>}</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>HighSec</span><span>&gt;</span> <span>for</span> <span>HighSec</span> <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>HighSec</span><span>;</span> <span>}</span>

<span>// The type alias gives us a more convenient way to "call" the type operator</span>
<span>type</span> <span>MaxLevel</span><span>&lt;</span><span>L</span><span>,</span> <span>R</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>L</span> <span>as</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>R</span><span>&gt;&gt;</span><span>::</span><span>Output</span><span>;</span>
</code></pre></div></div>

<blockquote>
  <p>The most confusing part is the <code>MaxLevel</code> alias. In brief: <code>L as ComputeMaxLevel&lt;R&gt;</code> says “treat <code>L</code> as the trait object <code>ComputeMaxLevel&lt;R&gt;</code>”. This is necessary since multiple computation traits may have associated <code>Output</code> with <code>L</code>, so the explicit cast disambiguates the <code>MaxLevel</code> computation from the rest.</p>
</blockquote>

<p>Here’s an example of using the type operator:</p>

<div><div><pre><code><span>let</span> <span>_</span> <span>:</span> <span>MaxLevel</span><span>&lt;</span><span>HighSec</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>=</span> <span>HighSec</span><span>;</span> <span>// ok</span>
<span>let</span> <span>_</span> <span>:</span> <span>MaxLevel</span><span>&lt;</span><span>LowSec</span> <span>,</span> <span>LowSec</span><span>&gt;</span> <span>=</span> <span>LowSec</span><span>;</span>  <span>// ok</span>
<span>let</span> <span>_</span> <span>:</span> <span>MaxLevel</span><span>&lt;</span><span>LowSec</span> <span>,</span> <span>LowSec</span><span>&gt;</span> <span>=</span> <span>HighSec</span><span>;</span> <span>// type error</span>
</code></pre></div></div>

<p>Now, we can implement <code>SecureVec::push</code> in one method:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>VecLevel</span><span>&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>VecLevel</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>push</span><span>&lt;</span><span>ItemLevel</span><span>&gt;</span><span>(</span>
    <span>mut</span> <span>self</span><span>,</span>
    <span>t</span><span>:</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>ItemLevel</span><span>&gt;</span><span>,</span>
  <span>)</span> <span>-&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>MaxLevel</span><span>&lt;</span><span>ItemLevel</span><span>,</span> <span>VecLevel</span><span>&gt;&gt;</span>
  <span>where</span>
    <span>ItemLevel</span><span>:</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>VecLevel</span><span>&gt;</span><span>,</span>
  <span>{</span>
    <span>unsafe</span> <span>{</span>
      <span>self</span><span>.items</span><span>.push</span><span>(</span><span>transmute</span><span>(</span><span>t</span><span>));</span>
      <span>transmute</span><span>(</span><span>self</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Notice the usage of <code>MaxLevel</code> in the return type of <code>push</code>. This is the key use of the type operator as a type-level computation. The other main component is the <code>where</code> clause: when used generically (over any possible <code>ItemLevel</code>), we have to use a trait bound to ensure that <code>ComputeMaxLevel</code> can be “called” on <code>ItemLevel</code>.</p>

<p>Excellent! We’ve now used a type-level computation to more abstractly specify typestate in our information flow control API. Next, we’ll look at an example with a more complex type-level program.</p>

<h2 id="2-two-party-communication-protocols">2. Two-party communication protocols</h2>

<p>When two parties synchronously communicate with each other (e.g. a client and server exchanging information), that communication protocol can be modeled as a session type. We’re going to look at session types <a href="https://munksgaard.me/papers/laumann-munksgaard-larsen.pdf">implemented in Rust</a>. While their full implementation is beyond the scope of the post (see the linked paper or my <a href="http://cs242.stanford.edu/f19/lectures/09-1-session-types">course notes</a>), I will focus on the aspects of session types that showcase type-level programming.</p>

<p>Session types are a domain-specific language of state machines, described by this grammar:</p>



<p>For example, this session type describes a ping server that sends and receives a ping in a loop, exiting on demand. The label/goto scheme uses <a href="https://en.wikipedia.org/wiki/De_Bruijn_index">de Bruijn indices</a> to locally encode label names as integers.</p>



<p>The grammar, and this example, can be encoded in Rust like so:</p>

<div><div><pre><code><span>struct</span> <span>Send</span><span>&lt;</span><span>T</span><span>,</span> <span>S</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>S</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Recv</span><span>&lt;</span><span>T</span><span>,</span> <span>S</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>S</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Offer</span><span>&lt;</span><span>Left</span><span>,</span> <span>Right</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>Left</span><span>,</span> <span>Right</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Choose</span><span>&lt;</span><span>Left</span><span>,</span> <span>Right</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>Left</span><span>,</span> <span>Right</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Label</span><span>&lt;</span><span>S</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>S</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Goto</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>N</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Z</span><span>;</span>
<span>struct</span> <span>S</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>N</span><span>&gt;</span><span>);</span> <span>// Peano encoding for natural numbers</span>
<span>struct</span> <span>Close</span><span>;</span>

<span>struct</span> <span>Ping</span><span>;</span>
<span>type</span> <span>PingServer</span> <span>=</span>
  <span>Label</span><span>&lt;</span>
    <span>Offer</span><span>&lt;</span>
      <span>Send</span><span>&lt;</span><span>Ping</span><span>,</span>
        <span>Recv</span><span>&lt;</span><span>Ping</span><span>,</span>
        <span>Goto</span><span>&lt;</span><span>Z</span><span>&gt;&gt;&gt;</span><span>,</span>
      <span>Close</span><span>&gt;&gt;</span><span>;</span>
</code></pre></div></div>

<p>The runtime communication API uses the type-state concept as a channel whose type changes as the protocol advances. Initially, a <code>Chan</code> is created for the server and the client (the “dual” of the server). Here’s an example where the type annotations show the change.</p>

<div><div><pre><code><span>fn</span> <span>example_ping_server</span><span>()</span> <span>{</span>
  <span>let</span> <span>(</span><span>c</span><span>,</span> <span>_</span><span>):</span> <span>(</span><span>Chan</span><span>&lt;</span><span>(),</span> <span>PingServer</span><span>&gt;</span><span>,</span>
               <span>Chan</span><span>&lt;</span><span>(),</span> <span>Dual</span><span>&lt;</span><span>PingServer</span><span>&gt;</span><span>)</span> <span>=</span> <span>Chan</span><span>::</span><span>new</span><span>();</span>
  <span>let</span> <span>mut</span> <span>c</span><span>:</span> <span>Chan</span><span>&lt;</span><span>(</span><span>Offer</span><span>&lt;</span><span>_</span><span>,</span><span>_</span><span>&gt;</span><span>,</span> <span>()),</span> <span>Offer</span><span>&lt;</span><span>_</span><span>,</span><span>_</span><span>&gt;&gt;</span> <span>=</span> <span>c</span><span>.label</span><span>();</span>
  <span>loop</span> <span>{</span>
    <span>c</span> <span>=</span> <span>match</span> <span>c</span><span>.offer</span><span>()</span> <span>{</span>
      <span>Branch</span><span>::</span><span>Left</span><span>(</span><span>c</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>let</span> <span>c</span><span>:</span> <span>Chan</span><span>&lt;</span><span>_</span><span>,</span> <span>Recv</span><span>&lt;</span><span>_</span><span>,</span><span>_</span><span>&gt;&gt;</span> <span>=</span> <span>c</span><span>.send</span><span>(</span><span>Ping</span><span>);</span>
        <span>let</span> <span>(</span><span>c</span><span>,</span> <span>Ping</span><span>):</span> <span>(</span><span>Chan</span><span>&lt;</span><span>_</span><span>,</span> <span>Goto</span><span>&lt;</span><span>_</span><span>&gt;&gt;</span><span>,</span> <span>_</span><span>)</span> <span>=</span> <span>c</span><span>.recv</span><span>();</span>
        <span>c</span><span>.goto</span><span>()</span>
      <span>},</span>
      <span>Branch</span><span>::</span><span>Right</span><span>(</span><span>c</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>c</span><span>.close</span><span>();</span>
        <span>return</span><span>;</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Note that the <code>Chan</code> has two type arguments: an environment <code>Env</code> and a current action <code>Sigma</code>. The environment contains a list of session types generated by calls to <code>label</code>. When we <code>goto</code>, we look up the corresponding type in the <code>Env</code> list and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willcrichton.net/notes/type-level-programming/">https://willcrichton.net/notes/type-level-programming/</a></em></p>]]>
            </description>
            <link>https://willcrichton.net/notes/type-level-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24687685</guid>
            <pubDate>Mon, 05 Oct 2020 13:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Nested forEach directive in non-standard GraphQL server]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24687470">thread link</a>) | @leoloso
<br/>
October 5, 2020 | https://leoloso.com/posts/scripting-capabilities-in-non-standard-graphql-server/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/scripting-capabilities-in-non-standard-graphql-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last week I made a <a href="https://leoloso.com/posts/proposal-for-embeddable-fields-in-graphql-query/">proposal to add embeddable fields to GraphQL</a>, but it didn't get a lot of support. I got the feedback that the extra complexity added to the server doesn't justify the benefits of this new feature, as in <a href="https://www.reddit.com/r/graphql/comments/j043rw/proposal_for_embeddable_fields_in_graphql/g6pvqcj">this comment on Reddit</a> (which I replied to through <a href="https://leoloso.com/posts/justifying-embeddable-fields-in-graphql-query/">this post</a>).</p><p>My proposed feature then appears to be not about GraphQL as we know it nowadays, but about an über GraphQL, or what GraphQL could possibly be. That's either a problem, or an opportunity. In <a href="https://artsy.github.io/blog/2018/05/08/is-graphql-the-future/">this write-up</a>, Alan Johnson says:</p><blockquote><p>[...] the execution model of GraphQL is in many ways just like a scripting language interpreter. The limitations of its model are strategic, to keep the technology focused on client-server interaction. What's interesting is that you as a developer provide nearly all of the definition of what operations exist, what they mean, and how they compose. For this reason, I consider GraphQL to be a <strong>meta-scripting language</strong>, or, in other words, a toolkit for building scripting languages.</p></blockquote><p>I agree with this observation, but then I wonder: Where do these limitations start? What should be allowed, and what not? If any feature made GraphQL's scripting capabilities a bit more visible, gave a bit more control to the developer, and made the query a bit more powerful, should that be straightforward rejected? Or could it be given a chance?</p><h2 id="heading-show-me-the-stuff!">Show me the stuff!<a href="#heading-show-me-the-stuff!"><span> permalink</span></a></h2><p>Let's talk business now. Here is something that GraphQL is not good at.</p><p>Say that you have a <code>@translate</code> directive that is applied on a <code>String</code>, as in <a href="https://newapi.getpop.org/graphiql/?query=query%20%7B%0A%20%20posts%20%7B%0A%20%20%20%20id%0A%20%20%20%20title%20%40translate(from%3A%20%22en%22%2C%20to%3A%20%22es%22)%0A%20%20%7D%0A%7D">this query</a>:</p><pre><code><span><span>{</span></span><br><span>  posts <span>{</span></span><br><span>    id</span><br><span>    title <span>@translate</span><span>(</span><span>from</span><span>:</span> <span>"en"</span><span>,</span> <span>to</span><span>:</span> <span>"es"</span><span>)</span></span><br><span>  <span>}</span></span><br><span><span>}</span></span></code></pre><p>You cannot apply <code>@translate</code> on a field different than a <code>String</code>. If you need to, you must then create a new directive, which involves extra effort (often being ad-hoc) and pollutes the schema:</p><ul><li><p>If a field returns <code>[String]</code>, you'd need to create another directive <code>@translateArrays</code></p></li><li><p>If only some entries from the array must be translated, you need to add an optional argument <code>$keys: [String]</code> to specify which keys to translate</p></li><li><p>If the keys are not strings, but are numeric, you need another argument <code>$numericKeys: [Int]</code> as to avoid type conflicts</p></li><li><p>If instead of an array, you get an array of arrays, you need yet another directive</p></li></ul><p>And so on, concerning any random requirement from your clients.</p><p>As a result, the schema might eventually become unwieldy.</p><hr><p>So, how could this situation be improved for GraphQL?</p><p>If GraphQL had capabilities to compose or manipulate fields, then a few elements could already satisfy all possible combinations.</p><p><a href="https://graphql-by-pop.com/">GraphQL by PoP</a> (the engine powering the recently launched <a href="https://github.com/GraphQLAPI/graphql-api-for-wp">GraphQL API for WordPress</a>) is a GraphQL server because it respects the <a href="https://spec.graphql.org/">GraphQL spec</a>, but is also a non-standard API server that provides other capabilities, including <a href="https://github.com/graphql/graphql-spec/issues/682">composable fields</a> and <a href="https://github.com/graphql/graphql-spec/issues/683">composable directives</a>.</p><p>Let's see how this server can satisfy all combinations described above, with just a few elements:</p><blockquote><p><strong>Notes:</strong></p><ul><li>GraphQL by PoP relies on the URL-based <a href="https://graphql-by-pop.com/docs/extended/pql.html">PQL syntax</a>, so you can click on the links to execute the query and see its response</li><li>Field <code>Root.echo</code> is used to build the arrays</li><li><code>forEach</code> and <code>advancePointerInArray</code> are directives that composes another directive</li></ul></blockquote><p>Translating posts as strings (<a href="https://newapi.getpop.org/api/graphql/?query=posts.title%3Ctranslate(from:en,to:es)%3E" target="_blank">run query</a>):</p><pre><code><span>posts.title&lt;</span><br><span>  <span>translate</span><span>(</span><span>from</span><span>:</span>en<span>,</span> <span>to</span><span>:</span>es<span>)</span></span><br><span>&gt;</span></code></pre><p>Translating a list of strings (<a href="https://newapi.getpop.org/api/graphql/?query=echo([hello,%20world,%20how%20are%20you%20today?])%3CforEach%3Ctranslate(from:en,to:es)%3E%3E" target="_blank">run query</a>):</p><pre><code><span><span>echo</span><span>(</span>[</span><br><span>  hello<span>,</span></span><br><span>  world<span>,</span></span><br><span>  how are you today?</span><br><span>]<span>)</span>&lt;</span><br><span>  forEach&lt;</span><br><span>    <span>translate</span><span>(</span><span>from</span><span>:</span>en<span>,</span><span>to</span><span>:</span>es<span>)</span></span><br><span>  &gt;</span><br><span>&gt;</span></code></pre><p>Translating only one element from the list of strings, with numeric keys (<a href="https://newapi.getpop.org/api/graphql/?query=echo([hello,%20world,how%20are%20you%20today?])%3CadvancePointerInArray(path:0)%3Ctranslate(from:en,to:es)%3E%3E" target="_blank">run query</a>):</p><pre><code><span><span>echo</span><span>(</span>[</span><br><span>  hello<span>,</span></span><br><span>  world<span>,</span></span><br><span>  how are you today?</span><br><span>]<span>)</span>&lt;</span><br><span>  <span>advancePointerInArray</span><span>(</span><span>path</span><span>:</span> 0<span>)</span>&lt;</span><br><span>    <span>translate</span><span>(</span><span>from</span><span>:</span>en<span>,</span><span>to</span><span>:</span>es<span>)</span></span><br><span>  &gt;</span><br><span>&gt;</span></code></pre><p>Translating only one element from the list of strings, with keys as strings (<a href="https://newapi.getpop.org/api/graphql/?query=echo([first:hello,second:world,third:how%20are%20you%20today?])%3CadvancePointerInArray(path:second)%3Ctranslate(from:en,to:es)%3E%3E" target="_blank">run query</a>):</p><pre><code><span><span>echo</span><span>(</span>[</span><br><span>  <span>first</span><span>:</span>hello<span>,</span></span><br><span>  <span>second</span><span>:</span>world<span>,</span></span><br><span>  <span>third</span><span>:</span>how are you today?</span><br><span>]<span>)</span>&lt;</span><br><span>  <span>advancePointerInArray</span><span>(</span><span>path</span><span>:</span>second<span>)</span>&lt;</span><br><span>    <span>translate</span><span>(</span><span>from</span><span>:</span>en<span>,</span><span>to</span><span>:</span>es<span>)</span></span><br><span>  &gt;</span><br><span>&gt;</span></code></pre><p>Translating an array of arrays (<a href="https://newapi.getpop.org/api/graphql/?query=echo([[one,two,three],[four,five,six],[seven,eight,nine]])%3CforEach%3CforEach%3Ctranslate(from:en,to:es)%3E%3E%3E" target="_blank">run query</a>):</p><pre><code><span><span>echo</span><span>(</span>[[</span><br><span>  one<span>,</span></span><br><span>  two<span>,</span></span><br><span>  three</span><br><span>]<span>,</span> [</span><br><span>  four<span>,</span></span><br><span>  five<span>,</span></span><br><span>  six</span><br><span>]<span>,</span> [</span><br><span>  seven<span>,</span></span><br><span>  eight<span>,</span></span><br><span>  nine</span><br><span>]]<span>)</span>&lt;</span><br><span>  forEach&lt;</span><br><span>    forEach&lt;</span><br><span>      <span>translate</span><span>(</span><span>from</span><span>:</span>en<span>,</span><span>to</span><span>:</span>es<span>)</span></span><br><span>    &gt;</span><br><span>  &gt;</span><br><span>&gt;</span></code></pre><p>And so on, concerning any random requirement from your clients.</p><p>In my opinion, these features make the queries more powerful, and the schema more elegant. So they could be perfectly considered to be added to GraphQL.</p><p>Bringing these additional scripting capabilities to GraphQL, wouldn't it be more valuable than not?</p><p>I understand that there is more complexity added to the server. But that's a one-time off. The GraphQL server maintainers can implement these features in a few months, and developers would be able to use them forever.</p><p>Isn't that a good tradeoff?</p></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/scripting-capabilities-in-non-standard-graphql-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24687470</guid>
            <pubDate>Mon, 05 Oct 2020 13:16:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a lay-down desk]]>
            </title>
            <description>
<![CDATA[
Score 555 | Comments 381 (<a href="https://news.ycombinator.com/item?id=24687458">thread link</a>) | @polote
<br/>
October 5, 2020 | https://blog.luap.info/drafts/i-built-a-lay-down-desk.html?hnn | <a href="https://web.archive.org/web/*/https://blog.luap.info/drafts/i-built-a-lay-down-desk.html?hnn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>After spending part of the last 12 months <a href="https://blog.luap.info/travelling-with-24-monitors.html">travelling in Europe</a> I'm now settling down around Paris and I need to adapt my multi-screens setup.</p>
<p>You probably have seen an ads for <a href="https://altwork.com/">the altwork desk</a> <em>a $7000 desk that let you work laying down</em>. Spending a big part of my day in front of a computer I want to have the most comfortable position as possible, but well $7000 + $1000 for the delivery seems so expensive. There is also <a href="http://www.ergoquest.com/">this company</a> but this is still about $4000 all included. Let's be creative and build it myself.</p>
<p>Here is the result</p>
<p><img alt="complete desk" src="https://blog.luap.info/drafts/static/desk/complete.jpg"> </p>
<p>The things I have to take into account are:</p>
<ul>
<li>
<p>I have three monitors</p>
</li>
<li>
<p>I have no diy tools</p>
</li>
<li>
<p>I want a laying down position</p>
</li>
<li>
<p>This should be easy to use</p>
</li>
<li>
<p>This should be light and not take too much space</p>
</li>
<li>
<p>I have only a bike to move the parts</p>
</li>
<li>
<p>I haven't found anyone who has done something similar and so don't really have examples</p>
</li>
</ul>
<p>So instead of doing the waterfall way I decided to go the agile way and to not do any plans, I didn't know what to expect, so let's do it step by step and see how it goes</p>
<h2>Take care of the chair</h2>
<p>There are several options:</p>
<ol>
<li>
<p>Built a chair from scratch including the 'mattress' part</p>
</li>
<li>
<p>Use a reclined chair</p>
</li>
<li>
<p>Adapt a chair</p>
</li>
</ol>
<p>The issue with the first option is that I will not be sure of the result, is it going to be comfortable ? How I'm going to wash the seat covers ? I have no idea of the things to take into account for building a comfortable chair.</p>
<p>Reclined chairs are great but they are very heavy (except the garden ones but not very comfortable) and expensive. So again let's be creative, I got inspired by <a href="https://www.ikeahackers.net/2017/04/poang-gravity-recliner.html">this</a> and <a href="https://www.ikeahackers.net/2020/04/remove-poang-arms.html">this</a> ikea hacks which use a IKEA POANG chair and transform it into a reclined chair.</p>
<p>Here is the result :</p>
<p><img alt="ikea poang adaptation" src="https://blog.luap.info/drafts/static/desk/chair.jpg"></p>
<p>The chair is 69 euro, I had to buy three cushions to extend it</p>
<p>The most complex part was to do 7km with the chair on a bike. I do not recommend doing the same, particularly because I have done it on a rainy day but well a bit of challenge in my life is always welcome!</p>
<p><img alt="ikea bike" src="https://blog.luap.info/drafts/static/desk/ikea_bike.jpg"></p>
<p>Great, the chair is comfortable, let's do something for the desk part.</p>
<h2>What structure for the desk</h2>
<p>The biggest issue you are going to have with the lay down position, is that the desk is going to be on your legs and you cant 'enter' or 'leave' the desk if you can't move the desk. So you need the 'desk' part to be dynamic from the 'chair' part.</p>
<p>I had two ideas for that, either the Altwork way, the structure goes above your head and can incline, or the the base is on the side and the desk can move somewhere (writing that, having the desk in front of me, I wonder if having the base where the foot are is not an even better solution ? Damn, too late). Having the base on the side seems better because it would be smaller and lighter and also you can balance the weight much better. But the structure also needs to be more rigid and I need to find a way to incline the desk, anyway I haven't found a way to do it :(, after a night of thinking I went the altwork way.</p>
<p>There are two parts to design:</p>
<ol>
<li>
<p>The base + the incline system</p>
</li>
<li>
<p>The desk + the screen supports</p>
</li>
</ol>
<h3>1. Base + incline system</h3>
<p>The base is pretty standard, you need something strong enough so that it can suppot the whole thing. At that point I still didn't know the weight of the complete platform so I didn't know how strong it should be. After a few failing choices, I ended up with a main pole of 7cm x 7cm.</p>
<p>Now the complex part, how to design the rotation part ? How heavy is going to be the rest of desk ? How much does the desk need to move so that I can 'enter' the desk ? So many questions I didnt have an answer for.</p>
<p>So let's try something and see how it goes, I bought an <a href="https://www.amazon.fr/gp/product/B00H8SZ87W">gaz actuator on Amazon</a> which can support 70kg with a range of 31cm, it is built for cars and pretty cheap, 19euro. Actually 70kg is a lot. So at least I have a some freedom on the weight of the structure.</p>
<p>I had two issues with the actuator:</p>
<ul>
<li>70kg IS A LOT, it is so much that when I was fixing it on the wood of the base, it was breaking the wood. The best would be to have an iron piece that I can fix to the wood but I didnt have the tools for that so I used stronger woods but this is still fragile. </li>
</ul>
<p><img alt="fixation verrin" src="https://blog.luap.info/drafts/static/desk/fixation_verrin.jpg"></p>
<ul>
<li>The desk follows a circular trajectory when you move it up and down. As a result the barycenter of the structure changes depending on the Y position of the 'desk part' and so there is more strength applied on the actuator when it is up than when it is down. So basically the desk will not stay by itself when in the up position.  I need to find a way to get the desk in the up position.</li>
</ul>
<p>I'm not really proud of the way I've done it, but it somewhat works. I've built a piece of wood that inserts itself in the area between the two poles where the actuator is. There is a counterweight which drags the piece into the zone when in up position, and when I want to release it, I just need to pull on the rope. (I think I will replace the actuator with a real electric actuator when the current system breaks so that I can control the movement, it is about 120euro)</p>
<p><img alt="system block" src="https://blog.luap.info/drafts/static/desk/blocking_system.jpg"></p>
<h3>2. Desk + screens support</h3>
<p>I bought a chipboard plate of 80cm x 120cm, and cut some space for my body</p>
<p><img alt="plaque bois" src="https://blog.luap.info/drafts/static/desk/agglo.jpg"> </p>
<p>This is pretty solid, so I can directly screw this plate to the pole and we have a desk surface</p>
<p><img alt="plaque bureau" src="https://blog.luap.info/drafts/static/desk/bureau_with_plaque.jpg"></p>
<p>For holding the monitors I did something pretty basic, I created a box for each screen. Then comes the position of the screen, how to know the position of each screen ? I didnt know how to know it beforehand, so I just created dynamic arms and adjusted them while in front of the screens</p>
<p><img alt="support monitor" src="https://blog.luap.info/drafts/static/desk/support_monitor.jpg"></p>
<h2>Next steps</h2>
<p>This is only a few days old so I can't really make a feedback but there are already a few things that I need to fix</p>
<ul>
<li>
<p>I can't use a mouse anymore, as the mouse would fall down, I'm probably going to replace it by a trackball</p>
</li>
<li>
<p>I need to invest in an ergonomic keyboard to get really comfortable, probably going to buy the kenesis advantage 2, but this is expensive !</p>
</li>
</ul>
<p>Here is a video of the complete desk:</p>
<video controls="">
  <source src="https://blog.luap.info/drafts/static/desk/video.mp4" type="video/mp4">
</video>

<h2>Conclusion</h2>
<p>When you want to build this kind of structure, I'm not sure you can plan everything beforehand, there are always things that will happen that you didn't expect, like when you code: if you want to modify the actuator when the 60kg setup is mounted how do you do ? (I have done it 6 times) When your base can't support the weight because it lacks one screw and you need to unmount everything what do you do ? ...</p>
<p>I'm really annoyed by the actuator part, I hope I will find something more reliable</p>
<p>Overall it cost me :</p>
<ul>
<li>
<p>45 euro for tools</p>
</li>
<li>
<p>130 euro for wood pieces, screws, joins, ...</p>
</li>
<li>
<p>110 euro for the IKEA chair + cushions</p>
</li>
</ul>
<p>and I spent 26 hours working, excluding the transport and the time shopping for pieces</p>
<p>Don't forget when you do woodworking to clean afterwards  :)</p>
<p><img alt="dirty" src="https://blog.luap.info/drafts/static/desk/dirty_floor.jpg"></p>
<p>If you have done something similar and know a few advice, please send me an email</p>
<p>PS: If you wonder whether you can do that or not, everyone can do it, basic woodworking is not complex, you need to know how to cut wood, how to join wood, how to screw and a little bit of imagination, you dont even need a car to transport parts, I transported everything: pole of 2m40, big plate ... on a bike</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/drafts/i-built-a-lay-down-desk.html?hnn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24687458</guid>
            <pubDate>Mon, 05 Oct 2020 13:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Concatenative Programming; the Free Monoid of Programming Languages (2019)]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24687026">thread link</a>) | @gbrown_
<br/>
October 5, 2020 | https://doisinkidney.com/posts/2019-05-11-concatenative-free.html | <a href="https://web.archive.org/web/*/https://doisinkidney.com/posts/2019-05-11-concatenative-free.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on May 11, 2019
</p>



<p>This post demonstrates a simple encoding of a (typed) concatenative language in Haskell.</p>
<p>Point-free style is one of the distinctive markers of functional programming languages. Want to sum a list? That’s as easy as:</p>

<p>Now I want to sum every number after adding one to it.</p>
<div id="cb2"><pre><code><span id="cb2-1">sumSuccs <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> <span>.</span> <span>map</span> ((<span>+</span>) <span>1</span>)</span></code></pre></div>
<p>One more step to make this function truly abstract™ and general™: we’ll allow the user to supply their own number to add</p>
<div id="cb3"><pre><code><span id="cb3-1">sumAdded <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> <span>.</span> <span>map</span> <span>.</span> (<span>+</span>)</span></code></pre></div>
<p>And here the trouble begins. The above expression won’t actually type check. In fact, it’ll give a pretty terrible error message:</p>
<pre><code>• Non type-variable argument in the constraint: Num [a]
  (Use FlexibleContexts to permit this)
• When checking the inferred type
    sumThoseThat :: forall a.
                    (Num [a], Foldable ((-&gt;) [a])) =&gt;
                    a -&gt; [a]</code></pre>
<p>I remember as a beginner being confused by similar messages. What’s <code>FlexibleContexts</code>? I had thought that the “point-free style” just meant removing the last variable from an expression if it’s also the last argument:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>sum</span> xs <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> xs</span>
<span id="cb5-2"><span>sum</span> <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span></span></code></pre></div>
<p>Why doesn’t it work here?</p>
<p>Well, it doesn’t work because the types don’t line up, but I’m going to try and explain a slightly different perspective on the problem, which is <em>associativity</em>.</p>
<p>To make it a little clearer, let’s see what happens when we point-fill the expression:</p>
<div id="cb6"><pre><code><span id="cb6-1">sumAdded n xs <span>=</span> (<span>foldr</span>(<span>+</span>) <span>0</span> <span>.</span> (<span>map</span> <span>.</span> (<span>+</span>))) n xs</span>
<span id="cb6-2">             <span>=&gt;</span> <span>foldr</span>(<span>+</span>) <span>0</span> ((<span>map</span> <span>.</span> (<span>+</span>)) n) xs</span>
<span id="cb6-3">             <span>=&gt;</span> <span>foldr</span>(<span>+</span>) <span>0</span> (<span>map</span> ((<span>+</span>) n)) xs</span></code></pre></div>
<p>Indeed, the problem is the placement of the parentheses. What we want at the end is:</p>
<div id="cb7"><pre><code><span id="cb7-1">             <span>=&gt;</span> <span>foldr</span>(<span>+</span>) <span>0</span> (<span>map</span> ((<span>+</span>) n) xs)</span></code></pre></div>
<p>But, no matter. We have to jiggle the arguments around, or we could use something terrible like this:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>infixr</span> <span>9</span> <span>.:</span></span>
<span id="cb8-2">(<span>.:</span>) <span>=</span> (<span>.</span>)<span>.</span>(<span>.</span>)</span>
<span id="cb8-3"></span>
<span id="cb8-4">sumAdded <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> <span>.:</span> <span>map</span> <span>.</span> (<span>+</span>)</span></code></pre></div>
<p>Is there something, though, that could do this automatically?</p>

<p>We run into a similar problem in Agda. We’re forever having to prove statements like:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>(</span>x + y<span>)</span> + z ≡ x + <span>(</span>y + z<span>)</span></span>
<span id="cb9-2">x ≡ x + <span>0</span></span></code></pre></div>
<p>There are a couple of ways to get around the issue, and for monoids there’s a rich theory of techniques. I’ll just show one for now, which relies on the <em>endomorphism</em> monoid. This monoid is created by partially applying the monoid’s binary operator:</p>
<div id="cb10"><pre><code><span id="cb10-1">Endo <span>:</span> <span>Set</span></span>
<span id="cb10-2">Endo <span>=</span> ℕ <span>→</span> ℕ</span>
<span id="cb10-3"></span>
<span id="cb10-4">⟦<span>_</span>⇑⟧ <span>:</span> ℕ <span>→</span> Endo</span>
<span id="cb10-5">⟦ n ⇑⟧ m <span>=</span> n + m</span></code></pre></div>
<p>And you can get back to the underlying monoid by applying it to the neutral element:</p>
<div id="cb11"><pre><code><span id="cb11-1">⟦<span>_</span>⇓⟧ <span>:</span> Endo <span>→</span> ℕ</span>
<span id="cb11-2">⟦ n ⇓⟧ <span>=</span> n <span>0</span></span></code></pre></div>
<p>Here’s the important parts: first, we can lift the underlying operation into the endomorphism:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>_</span>⊕<span>_</span> <span>:</span> Endo <span>→</span> Endo <span>→</span> Endo</span>
<span id="cb12-2">xs ⊕ ys <span>=</span> <span>λ</span> x <span>→</span> xs <span>(</span>ys x<span>)</span></span>
<span id="cb12-3"></span>
<span id="cb12-4">⊕-homo <span>:</span> <span>∀</span> n m <span>→</span> ⟦ ⟦ n ⇑⟧ ⊕ ⟦ m ⇑⟧ ⇓⟧ ≡ n + m</span>
<span id="cb12-5">⊕-homo n m <span>=</span> cong <span>(</span>n +<span>_)</span> <span>(</span>+-identityʳ m<span>)</span></span></code></pre></div>
<p>And second, it’s <em>definitionally</em> associative.</p>
<div id="cb13"><pre><code><span id="cb13-1">⊕-assoc <span>:</span> <span>∀</span> x y z <span>→</span> <span>(</span>x ⊕ y<span>)</span> ⊕ z ≡ x ⊕ <span>(</span>y ⊕ z<span>)</span></span>
<span id="cb13-2">⊕-assoc <span>_</span> <span>_</span> <span>_</span> <span>=</span> refl</span></code></pre></div>
<p>These are all clues as to how to solve the composition problem in the Haskell code above. We need definitional associativity, somehow. Maybe we can get it from the endomorphism monoid?</p>

<p>You’re probably familiar with Haskell’s state monad:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>newtype</span> <span>State</span> s a <span>=</span> <span>State</span> {<span> runState ::</span> s <span>-&gt;</span> (a, s) }</span></code></pre></div>
<p>It can help a lot when you’re threading around fiddly accumulators and so on.</p>
<div id="cb15"><pre><code><span id="cb15-1"><span>nub ::</span> <span>Ord</span> a <span>=&gt;</span> [a] <span>-&gt;</span> [a]</span>
<span id="cb15-2">nub <span>=</span> go Set.empty</span>
<span id="cb15-3">  <span>where</span></span>
<span id="cb15-4">    go seen [] <span>=</span> []</span>
<span id="cb15-5">    go seen (x<span>:</span>xs)</span>
<span id="cb15-6">      <span>|</span> x <span>`Set.member`</span> seen <span>=</span> go seen xs</span>
<span id="cb15-7">      <span>|</span> <span>otherwise</span> <span>=</span> x <span>:</span> go (Set.insert x seen) xs</span></code></pre></div>
<div id="cb16"><pre><code><span id="cb16-1"><span>nub ::</span> <span>Ord</span> a <span>=&gt;</span> [a] <span>-&gt;</span> [a]</span>
<span id="cb16-2">nub <span>=</span> <span>flip</span> evalState Set.empty <span>.</span> go</span>
<span id="cb16-3">  <span>where</span></span>
<span id="cb16-4">    go [] <span>=</span> <span>pure</span> []</span>
<span id="cb16-5">    go (x<span>:</span>xs) <span>=</span> <span>do</span></span>
<span id="cb16-6">        seen <span>&lt;-</span> gets (Set.member x)</span>
<span id="cb16-7">        <span>if</span> seen</span>
<span id="cb16-8">          <span>then</span> go xs</span>
<span id="cb16-9">          <span>else</span> <span>do</span></span>
<span id="cb16-10">              modify (Set.insert x)</span>
<span id="cb16-11">              (x<span>:</span>) <span>&lt;$&gt;</span> go xs</span></code></pre></div>
<p>Of course, these days state is a transformer:</p>
<div id="cb17"><pre><code><span id="cb17-1"><span>newtype</span> <span>StateT</span> s m a <span>=</span> <span>StateT</span> {<span> runStateT ::</span> s <span>-&gt;</span> m (a, s) }</span></code></pre></div>
<p>This lets us stack multiple effects on top of each other: error handling, IO, randomness, even another state monad. In fact, if you <em>do</em> stack another state monad on top, you might be surprised by the efficiency of the code it generates:</p>
<div id="cb18"><pre><code><span id="cb18-1"><span>type</span> <span>DoubleState</span> s1 s2 a <span>=</span> <span>StateT</span> s1 (<span>State</span> s2) a</span>
<span id="cb18-2">                        <span>=&gt;</span> s1 <span>-&gt;</span> <span>State</span> s2 (a, s1)</span>
<span id="cb18-3">                        <span>=&gt;</span> s1 <span>-&gt;</span> s2 <span>-&gt;</span> ((a, s1), s2)</span></code></pre></div>
<p>It’s nothing earth shattering, but it inlines and optimises well. That output is effectively a left-nested list, also.</p>

<p>If we can do one, and we can do two, why not more? Can we generalise the state pattern to an arbitrary number of variables? First we’ll need a generic tuple:</p>
<div id="cb19"><pre><code><span id="cb19-1"><span>infixr</span> <span>5</span> <span>:-</span></span>
<span id="cb19-2"><span>data</span> <span>Stack</span> (<span>xs ::</span> [<span>Type</span>])<span> ::</span> <span>Type</span> <span>where</span></span>
<span id="cb19-3">    <span>Nil</span><span>  ::</span> <span>Stack</span> '[]</span>
<span id="cb19-4"><span>    (:-) ::</span> x <span>-&gt;</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> (x <span>:</span> xs)</span></code></pre></div>
<p>Then, the state type.</p>
<div id="cb20"><pre><code><span id="cb20-1"><span>newtype</span> <span>State</span> xs a <span>=</span> <span>State</span> {<span> runState ::</span> <span>Stack</span> xs <span>-&gt;</span> (a, <span>Stack</span> xs) }</span></code></pre></div>
<p>We can actually clean the definition up a little: instead of a tuple at the other end, why not push it onto the stack.</p>
<div id="cb21"><pre><code><span id="cb21-1"><span>newtype</span> <span>State</span> xs a <span>=</span> <span>State</span> {<span> runState ::</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> (a <span>:</span> xs) }</span></code></pre></div>
<p>In fact, let’s make this as polymorphic as possible. We should be able to change the state is we so desire.</p>
<div id="cb22"><pre><code><span id="cb22-1"><span>infixr</span> <span>0</span> <span>:-&gt;</span></span>
<span id="cb22-2"><span>type</span> (<span>:-&gt;</span>) xs ys <span>=</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> ys</span></code></pre></div>
<p>And suddenly, our endomorphism type from above shows up again.</p>
<p>We can, of course, get back our original types.</p>
<div id="cb23"><pre><code><span id="cb23-1"><span>newtype</span> <span>State</span> xs a <span>=</span> <span>State</span> {<span> runState ::</span> xs <span>:-&gt;</span> a <span>:</span> xs }</span></code></pre></div>
<p>And it comes with all of the instances you might expect:</p>
<div id="cb24"><pre><code><span id="cb24-1"><span>instance</span> <span>Functor</span> (<span>State</span> xs) <span>where</span></span>
<span id="cb24-2">    <span>fmap</span> f xs <span>=</span> <span>State</span> (\s <span>-&gt;</span> <span>case</span> runState xs s <span>of</span></span>
<span id="cb24-3">        (x <span>:-</span> ys) <span>-&gt;</span> f x <span>:-</span> ys)</span>
<span id="cb24-4">        </span>
<span id="cb24-5"><span>instance</span> <span>Applicative</span> (<span>State</span> xs) <span>where</span></span>
<span id="cb24-6">    <span>pure</span> x <span>=</span> <span>State</span> (x <span>:-</span>)</span>
<span id="cb24-7">    fs <span>&lt;*&gt;</span> xs <span>=</span> <span>State</span> (\s <span>-&gt;</span> <span>case</span> runState fs s <span>of</span></span>
<span id="cb24-8">        (f <span>:-</span> s') <span>-&gt;</span> <span>case</span> runState xs s' <span>of</span></span>
<span id="cb24-9">            (x <span>:-</span> s'') <span>-&gt;</span> f x <span>:-</span> s'')</span>
<span id="cb24-10">            </span>
<span id="cb24-11"><span>instance</span> <span>Monad</span> (<span>State</span> xs) <span>where</span></span>
<span id="cb24-12">    xs <span>&gt;&gt;=</span> f <span>=</span> <span>State</span> (\s <span>-&gt;</span> <span>case</span> runState xs s <span>of</span></span>
<span id="cb24-13">        y <span>:-</span> ys <span>-&gt;</span> runState (f y) ys)</span></code></pre></div>

<p>But what’s the point? So far we’ve basically just encoded an unnecessarily complicated state transformer. Think back to the stacking of states. Written in the <a href="https://hackage.haskell.org/package/mtl">mtl</a> style, the main advantage of stacking monads like that is you can write code like the following:</p>
<div id="cb25"><pre><code><span id="cb25-1"><span>pop ::</span> (<span>MonadState</span> [a] m, <span>MonadError</span> <span>String</span> m) <span>=&gt;</span> m a</span>
<span id="cb25-2">pop <span>=</span> get <span>&gt;&gt;=</span> \<span>case</span></span>
<span id="cb25-3">    [] <span>-&gt;</span> throwError <span>"pop: empty list"</span></span>
<span id="cb25-4">    x<span>:</span>xs <span>-&gt;</span> <span>do</span></span>
<span id="cb25-5">        put xs </span>
<span id="cb25-6">        <span>pure</span> x</span></code></pre></div>
<p>In other words, we don’t care about the rest of <code>m</code>, we just care that it has, somewhere, state for an <code>[a]</code>.</p>
<p>This logic should apply to our stack transformer, as well. If it only cares about the top two variables, it shouldn’t care what the rest of the list is. In types:</p>
<div id="cb26"><pre><code><span id="cb26-1"><span>infixr</span> <span>0</span> <span>:-&gt;</span></span>
<span id="cb26-2"><span>type</span> (<span>:-&gt;</span>) xs ys <span>=</span> <span>forall</span> zs<span>.</span> <span>Stack</span> (xs <span>++</span> zs) <span>-&gt;</span> <span>Stack</span> (ys <span>++</span> zs)</span></code></pre></div>
<p>And straight away we can write some of the standard combinators:</p>
<div id="cb27"><pre><code><span id="cb27-1"><span>dup ::</span> '[a] <span>:-&gt;</span> '[a,a]</span>
<span id="cb27-2">dup (x <span>:-</span> xs) <span>=</span> (x <span>:-</span> x <span>:-</span> xs)</span>
<span id="cb27-3"></span>
<span id="cb27-4"><span>swap ::</span> '[x,y] <span>:-&gt;</span> '[y,x]</span>
<span id="cb27-5">swap (x <span>:-</span> y <span>:-</span> xs) <span>=</span> y <span>:-</span> x <span>:-</span> xs</span>
<span id="cb27-6"></span>
<span id="cb27-7"><span>drop</span><span> ::</span> '[x,y] <span>:-&gt;</span> '[y]</span>
<span id="cb27-8"><span>drop</span> (_ <span>:-</span> xs) <span>=</span> xs</span>
<span id="cb27-9"></span>
<span id="cb27-10"><span>infixl</span> <span>9</span> <span>!</span></span>
<span id="cb27-11">(f <span>!</span> g) x <span>=</span> g (f x)</span></code></pre></div>
<p>You’ll immediately run into trouble if you try to work with some of the more involved combinators, though. Quote should have the following type, for instance:</p>
<div id="cb28"><pre><code><span id="cb28-1"><span>quote ::</span> (xs <span>:-&gt;</span> ys) <span>-&gt;</span> '[] <span>:-&gt;</span> '[ xs <span>:-&gt;</span> ys ]</span></code></pre></div>
<p>But GHC complains again:</p>
<pre><code>• Illegal polymorphic type: xs :-&gt; ys
  GHC doesn't yet support impredicative polymorphism
• In the type signature:
    quote :: (xs :-&gt; ys) -&gt; '[] :-&gt; '[xs :-&gt; ys]</code></pre>
<p>I won’t go into the detail of this particular error: if you’ve been around the block with Haskell you know that it means “wrap it in a newtype”. If we do <em>that</em>, though, we get yet more errors:</p>
<div id="cb30"><pre><code><span id="cb30-1"><span>newtype</span> (<span>:~&gt;</span>) xs ys <span>=</span> <span>Q</span> {<span> d ::</span> xs <span>:-&gt;</span> ys }</span></code></pre></div>
<pre><code>• Couldn't match type ‘ys ++ zs0’ with ‘ys ++ zs’
  Expected type: Stack (xs ++ zs) -&gt; Stack (ys ++ zs)
    Actual type: Stack (xs ++ zs0) -&gt; Stack (ys ++ zs0)
  NB: ‘++’ is a type function, and may not be injective</code></pre>
<p>This injectivity error comes up often. It means that GHC needs to prove that the input to two functions is equal, but it only knows that their outputs are. This is a doubly serious problem for us, as we can’t do type family injectivity on two type variables (in current Haskell). To solve the problem, we need to rely on a weird mishmash of type families and functional dependencies:</p>
<div id="cb32"><pre><code><span id="cb32-1"><span>type</span> <span>family</span> (<span>++</span>) xs ys <span>where</span></span>
<span id="cb32-2">    '[] <span>++</span> ys <span>=</span> ys</span>
<span id="cb32-3">    (x <span>:</span> xs) <span>++</span> ys <span>=</span> x <span>:</span> (xs <span>++</span> ys)</span>
<span id="cb32-4">    </span>
<span id="cb32-5"><span>class</span> (xs <span>++</span> ys <span>~</span> zs) <span>=&gt;</span> <span>Conc</span> xs ys zs <span>|</span> xs zs <span>-&gt;</span> ys <span>where</span></span>
<span id="cb32-6"><span>    conc ::</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> ys <span>-&gt;</span> <span>Stack</span> zs</span>
<span id="cb32-7">    </span>
<span id="cb32-8"><span>instance</span> <span>Conc</span> '[] ys ys <span>where</span></span>
<span id="cb32-9">    conc _ ys <span>=</span> ys</span>
<span id="cb32-10">    </span>
<span id="cb32-11"><span>instance</span> <span>Conc</span> xs ys zs <span>=&gt;</span> <span>Conc</span> (x <span>:</span> xs) ys (x <span>:</span> zs) <span>where</span></span>
<span id="cb32-12">    conc (x <span>:-</span> xs) ys <span>=</span> x <span>:-</span> conc xs ys</span>
<span id="cb32-13"></span>
<span id="cb32-14"><span>infixr</span> <span>0</span> <span>:-&gt;</span></span>
<span id="cb32-15"><span>type</span> (<span>:-&gt;</span>) xs ys <span>=</span> <span>forall</span> zs yszs<span>.</span> <span>Conc</span> ys zs yszs <span>=&gt;</span> <span>Stack</span> (xs <span>++</span> zs) <span>-&gt;</span> <span>Stack</span> yszs</span></code></pre></div>
<p>And it does indeed work:</p>
<div id="cb33"><pre><code><span id="cb33-1"><span>pure</span><span> ::</span> a <span>-&gt;</span> '[] <span>:-&gt;</span> '[a]</span>
<span id="cb33-2"><span>pure</span> <span>=</span> (<span>:-</span>)</span>
<span id="cb33-3"></span>
<span id="cb33-4"><span>newtype</span> (<span>:~&gt;</span>) xs ys <span>=</span> <span>Q</span> {<span> d ::</span> xs <span>:-&gt;</span> ys }</span>
<span id="cb33-5"></span>
<span id="cb33-6"><span>quote ::</span> (xs <span>:-&gt;</span> ys) <span>-&gt;</span> '[] <span>:-&gt;</span> '[ xs <span>:~&gt;</span> ys ]</span>
<span id="cb33-7">quote x <span>=</span> <span>pure</span> (<span>Q</span> x)</span>
<span id="cb33-8"></span>
<span id="cb33-9"><span>dot ::</span> <span>forall</span> xs ys<span>.</span> ((xs <span>:~&gt;</span> ys) <span>:</span> xs) <span>:-&gt;</span> ys</span>
<span id="cb33-10">dot (x <span>:-</span> xs) <span>=</span> d x xs</span>
<span id="cb33-11"></span>
<span id="cb33-12"><span>true ::</span> (xs <span>:~&gt;</span> ys) <span>:</span> (xs <span>:~&gt;</span> ys) <span>:</span> xs <span>:-&gt;</span> ys</span>
<span id="cb33-13">true <span>=</span> swap <span>!</span> <span>drop</span> <span>!</span> dot</span>
<span id="cb33-14"></span>
<span id="cb33-15"><span>false ::</span> (xs <span>:~&gt;</span> ys) <span>:</span> (xs <span>:~&gt;</span> ys) <span>:</span> xs <span>:-&gt;</span> ys</span>
<span id="cb33-16">false <span>=</span> <span>drop</span> <span>!</span> dot</span>
<span id="cb33-17"></span>
<span id="cb33-18"><span>test ::</span> '[] <span>:-&gt;</span> '[ '[a] <span>:~&gt;</span> '[a,a] ]</span>
<span id="cb33-19">test <span>=</span> quote dup</span></code></pre></div>
<p>Interestingly, these combinators represent the monadic operations on state (<code>dot</code> = <code>join</code>, <code>pure</code> = <code>pure</code>, etc.)</p>
<p>And can we get the nicer composition of the function from the intro? Kind of:</p>
<div id="cb34"><pre><code><span id="cb34-1">sumAdded <span>=</span> quote add <span>!</span> <span>curry</span> <span>!</span> dot <span>!</span> <span>map</span> <span>!</span> <span>sum</span></span></code></pre></div>
<p>Here are some references for concatenative languages: <span data-cites="okasaki_techniques_2002">Okasaki (<a href="#ref-okasaki_techniques_2002" role="doc-biblioref">2002</a>)</span>, <span data-cites="purdy_big_2012">Purdy (<a href="#ref-purdy_big_2012" role="doc-biblioref">2012</a>)</span>, <span data-cites="kerby_theory_2007">Kerby (<a href="#ref-kerby_theory_2007" role="doc-biblioref">2007</a>)</span>, <span data-cites="okasaki_theoretical_2003">Okasaki (<a href="#ref-okasaki_theoretical_2003" role="doc-biblioref">2003</a>)</span>.</p>


        </div></div>]]>
            </description>
            <link>https://doisinkidney.com/posts/2019-05-11-concatenative-free.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24687026</guid>
            <pubDate>Mon, 05 Oct 2020 12:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Bootstrapping an asset store for AR creators and ML engineers]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24686922">thread link</a>) | @dan_zaitsev
<br/>
October 5, 2020 | https://catchar.io/marketplace | <a href="https://web.archive.org/web/*/https://catchar.io/marketplace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="change-log-app">  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> October 03, 2020</span></p><h2><a href="https://catchar.io/blog/catchar-3-0" title="Catchar 3.0">Catchar 3.0</a></h2> <div><p>Our team is officially announcing the launch of a new 3.0 version of Catchar with a <a href="https://catchar.io/marketplace" rel="noopener noreferrer" target="_blank">marketplace</a> module.&nbsp;</p><p>We found that some creators use Sketchfab, Gumroad and Etsy to sell and monetize their AR/MR assets. However, creators from CIS, Georgia, Ukraine, Asia and some other countries are limited in payouts from these services.</p><p>We released a marketplace and asset store where Augmented Reality creators and Machine Learning engineers can list for sale their templates, source code, 3D models and tutorials. Our system provides direct profit payouts through SWIFT and SEPA.</p><p><img src="https://catchar.io/storage/articles/455/art_img_5f78bd46b8967.jpg"></p><p>Please note! Currently, the marketplace is in the beta phase, so we are looking for early adopters and partners to test the marketplace and improve it. We are especially looking for designers, developers and studios who are ready to upload for sale their 3D models, templates and source code related to Augmented and Mixed Reality, Machine Learning, etc.</p><p>You can join the beta-testing program by using our <a href="http://t.me/catchar" rel="noopener noreferrer" target="_blank">Telegram</a> chat. Using Telegram chat, you can aslo discover Catchar updates that sorts Alice (our AI assistant). Be up to date regarding the latest AR projects, articles, new creators and other activities.</p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> May 23, 2020</span></p><h2><a href="https://catchar.io/blog/catchar-2-4" title="Catchar 2.4">Catchar 2.4</a></h2> <div><p>Some updates and new features available on Catchar 🔥</p><ul><li>Be informed that we rescheduled our weekly AR/MR digest to Tuesday.</li><li>In addition, I would like to let you know that we released the instant post feature ↙️</li></ul><p><img src="https://catchar.io/storage/articles/355/art_img_5ec83bce82e64.jpg"></p><p>This feature is only available for our creators and companies. Upgrade to company or creator role to start sharing. If you are one of them post information only about AR/MR domains otherwise you’ll be muted! Feel free to post related to AR/MR news, tutorials, guides, tips from Medium, TechCrunch, YouTube, Twitter, LinkedIn or private blogs. Please don’t promote yourself too much 😉</p><ul><li><span>We continue working in terms of improving our SEO results, social and direct marketing. As a result, we have reached 350 unique visitors per day. Don’t miss the chance to showcase your AR/MR projects, articles and other updates.</span></li></ul><p><img src="https://catchar.io/storage/articles/355/art_img_5ec83cda45431.jpg"></p></div> </div>    <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> April 13, 2020</span></p><h2><a href="https://catchar.io/blog/catchar-2-3" title="Catchar 2.3">Catchar 2.3</a></h2> <div><p>Catchar has been updated! Our new 2.3 version is available: </p><ul><li><span>List services of your company</span></li></ul><p><span>From now our business users are able to list services, description and prices. If you are one of them please visit your profile to add them.</span></p><p><img src="https://catchar.io/storage/articles/290/art_img_5e947ac6a71d8.jpg"></p><ul><li>Improved page with projects</li></ul><p>Our new feature provides the ability to discover AR apps and lenses through screenshots or list views. Find the button to try it out!</p><p><img src="https://catchar.io/storage/articles/290/art_img_5e947cb780e39.jpg"></p><ul><li><span>We changed project presentations in the newsfeed</span></li></ul><p>We also changed the preview of projects in the newsfeed. Now you can discover them through screenshots.</p><p><img src="https://catchar.io/storage/articles/290/art_img_5e947d49a1c80.jpg"></p><ul><li>SEO improvements</li></ul><p>We continue working on SEO improvements so your profiles and projects can be searchable well across the web.</p><p><span>Feel free to share with us any your suggestions/feedback!</span></p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> March 11, 2020</span></p><h2><a href="https://catchar.io/blog/catchar2-2" title="Catchar 2.2">Catchar 2.2</a></h2> <div><p>Catchar has been updated! Discover below what changed in 2.2 version:</p><ul><li>We have made some updates on our index page (visible for unauthenticated users only). So now we are displaying our top creators, companies and projects with the highest rating there.</li><li>We have also added the ‘What’s new’ feature where you can discover the latest product updates.</li><li>Finally, we released the ‘Instant post’ feature that allows sharing external links and text content. We are still testing it and currently, this feature is only available for our community leaders. If you want to be one of them, please contact @<a href="https://catchar.io/creator/dan-zaitsev" target="_blank">Dan Zaitsev</a>.</li><li>We added the ability to share external articles. Find this feature through the '<a href="https://catchar.io/submit-article" target="_blank">article submission</a>' button.</li><li><span>Our newsfeed has been </span><span>Improved. Also, we</span><span> added more events.</span></li></ul><p><span>Let us know if you have any suggestions/feedback!</span></p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> December 07, 2019</span></p><h2><a href="https://catchar.io/blog/catchar-21-open-beta" title="Catchar 2.1 (open beta)">Catchar 2.1 (open beta)</a></h2> <div><p>We are happy to inform you that Catchar 2.1 (open beta) is available worldwide. We have done a lot of work in terms of creating new features, bug fixing and from the SEO perspective. Here’s the changelog for 2.1 version:</p><ul><li>Product <a href="https://catchar.io/blog?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>blog</strong></a></li><li>Global search has been added</li><li>Improved ranking system of creators and companies</li><li>Improved ranking system of projects and articles</li><li>Improved newsfeed</li><li>Delivered quality SEO</li><li>Fixed responsive layout</li><li>Improved desktop layout</li><li>Lazy loading feature has been added</li><li>Improved design of <a href="https://catchar.io/login?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>Login</strong></a> / <a href="https://catchar.io/register?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>Sign up</strong></a> pages</li><li>Added ability to register and login via <a href="https://catchar.io/login?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>LinkedIn</strong></a></li><li>Added sharing through all social media and email</li><li>Ability to send direct messages via emails to creators and companies</li><li>Improved instant email notifications</li><li>Added different placeholders</li><li>Ability to get AR lenses and apps by scanning QR codes from desktops and laptops</li></ul><p>Guys, the most important thing is that currently, our website works through an open based model (No signup is required). That means our guests can easily visit us and discover AR / MR projects, profiles and articles. So, don't miss your chance to create your portfolio of XR creator by <a href="https://catchar.io/submit-project?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>submitting</strong></a> your AR / MR projects, <a href="https://catchar.io/submit-article?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>articles</strong></a> and updates to be visible worldwide. In addition, it will help you to receive more scores to your profile and appear at the top of search results.</p><p><em>Image credit: Hyper-reality</em></p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> November 28, 2019</span></p><h2><a href="https://catchar.io/blog/catchar-2-0-private-beta" title="Catchar 2.0 (private beta)">Catchar 2.0 (private beta)</a></h2> <div><p>We have some wonderful news! Finally our MVP of <a href="https://catchar.io/" target="_blank">Catchar 2.0</a> is ready and we are going into private beta phase. We greatly appreciate you staying with us. Feel free to sign in and start creating your XR portfolio by submitting and contributing your XR projects, news and updates. It will help you to become #1 XR creator or contributor when we launch globally in the next 3-4 weeks. We apologize if you will find some bugs in our private beta. Just click 'LEAVE FEEDBACK' button at the right section of the website and we would definitely check them and fix them.</p><p>Here’s the list of features that are available in private beta:</p><ul><li><a href="https://catchar.io/login" target="_blank">User login / sign up</a></li><li><a href="https://catchar.io/login" target="_blank">Creator login / sign up</a></li><li><a href="https://catchar.io/login" target="_blank">Company login / sign up</a></li><li><a href="https://catchar.io/creators" target="_blank">List with XR creators and developers</a></li><li><a href="https://catchar.io/companies" target="_blank">List with XR companies and studios</a></li><li><a href="https://catchar.io/articles" target="_blank">List with XR articles, news and tutorials</a></li><li>Profile page of XR creators and developers</li><li>Profile page of XR companies and studios</li><li>Community pages with projects, updates, creators and companies</li><li><a href="https://catchar.io/submit-project" target="_blank">Ability to submit XR projects</a> (apps, lenses and campaigns)</li><li><a href="https://catchar.io/submit-article" target="_blank">Ability to submit XR articles, news and tutorials</a></li><li>Ability to submit project updates</li><li>Activity feed and live updates (Available on home and community pages)</li><li>Ability to share projects, company and creator profiles (Find it at the left section)</li><li>Ability to like XR projects and articles (Find it at the left section)</li><li><a href="https://catchar.io/my-projects" target="_blank">Promotion of XR projects</a> (apps, lenses and campaigns)</li><li>Become a PRO to unlock more features&nbsp;</li><li><a href="https://catchar.io/our-team" target="_blank">Page about our team</a></li><li><a href="https://catchar.io/catchar-mission" target="_blank">Page about our mission</a></li><li><a href="https://catchar.io/ar-categories" target="_blank">Page with XR categories</a></li><li>Secret ranking system for XR projects (apps, lenses and campaigns)</li><li>Secret ranking system for XR creators and companies</li><li>Secret ranking system for XR articles and news</li></ul><p>Feel free to reach out to us regarding any ideas or improvements.</p></div> </div>  </div></div>]]>
            </description>
            <link>https://catchar.io/marketplace</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686922</guid>
            <pubDate>Mon, 05 Oct 2020 12:07:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles of Data Oriented Programming]]>
            </title>
            <description>
<![CDATA[
Score 370 | Comments 130 (<a href="https://news.ycombinator.com/item?id=24686863">thread link</a>) | @viebel
<br/>
October 5, 2020 | https://blog.klipse.tech/databook/2020/09/29/do-principles.html?essence | <a href="https://web.archive.org/web/*/https://blog.klipse.tech/databook/2020/09/29/do-principles.html?essence">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  <div itemprop="articleBody">
    <div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
<p>This chapter is an attempt to illustrate what are the core principles of Data Oriented Programming as I understand them.
It is highly influenced by my programming experience in Clojure, but I believe that those principles are language agnostic.</p>
<p>One could adhere to them in an Object Oriented (OO) language like Java or C# and one could break them
in a Functional Programming (FP) language like Ocaml, Haskell, JavaScript (or even in Clojure).</p>
<p>In fact, in this chapter, I am going to illustrate how those principles could be applied or broken
in JavaScript, a programming language that supports both FP and OOP.</p>
<p>The principles of Data Oriented (DO) Programming are:</p>

<p>Each principle is explored in a separate article.</p>

<p>Enjoy!</p>
<div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
  </div>

</article><p>
  If you enjoy this kind of interactive articles would you consider a (small) donation💸  on <a href="https://www.patreon.com/bePatron?u=18227864">Patreon</a> or at least giving a star⭐ for the Klispe repo on <a href="https://github.com/viebel/klipse/stargazers"> Github</a>?
</p></div>]]>
            </description>
            <link>https://blog.klipse.tech/databook/2020/09/29/do-principles.html?essence</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686863</guid>
            <pubDate>Mon, 05 Oct 2020 11:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s 255:19AM. Do you know what your validation criteria are?]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24686789">thread link</a>) | @FloDo
<br/>
October 5, 2020 | https://hdevalence.ca/blog/2020-10-04-its-25519am | <a href="https://web.archive.org/web/*/https://hdevalence.ca/blog/2020-10-04-its-25519am">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
  
  <p>A basic property of a <a href="https://en.wikipedia.org/wiki/Digital_signature">digital signature scheme</a> is that it should specify which signatures are valid and which signatures are invalid, so that all implementations can accept only valid signatures and reject only invalid signatures. <em>Unfortunately, Ed25519 signatures don’t provide this property, making their use in distributed systems fragile and risky.</em></p>
<p>Although the scheme was standardized in <a href="https://tools.ietf.org/html/rfc8032">RFC8032</a>, the RFC does not specify validation criteria, and does not require conformant implementations to agree on whether a particular signature is valid. In addition, because the specification changed validation criteria years after deployment, it is incompatible with almost all existing implementations. Worse still, some implementations added extra ad-hoc criteria, making them further incompatible.</p>
<p>The result is an extremely wide variation in validation criteria across implemententations. The diagram below plots verification results of a \(14 \times 14\) grid of edge cases, with light squares representing accepted signatures, and dark squares representing rejected ones. As the diagram illustrates, verification results are generally inconsistent not just between implementations, but also between different versions and different modes. <img src="https://hdevalence.ca/images/ed25519-comparison.png"></p>
<p>Some protocols may tolerate this variation, but it is unacceptable for any protocol that requires participants to reach consensus on signature validity. A malicious participant can submit signatures that are accepted by some implementations but rejected by others, causing a network partitition or a consensus fork. Having only a single implementation makes this problem less obvious, but it doesn’t go away, since behavior can vary across versions of the ‘same’ implementation. This occurred in practice with the widely used <code>libsodium</code> library, which made breaking changes to validation criteria in a point release.</p>
<p>Finally, although all of these problems occur when verifying signatures individually, they also prevent the use of batch verification, which can provide a significant performance benefit.</p>
<p>This post describes:</p>
<ol type="1">
<li><p>The structure of Ed25519 signatures and the scope of potential divergence in validation criteria <a href="#points-of-potential-divergence">(jump)</a>;</p></li>
<li><p>The results of a survey of Ed25519 validation behavior <a href="#a-survey-of-implementation-behaviors">(jump)</a>, which revealed:</p>
<ul>
<li><p>that almost no implementations conform to RFC8032;</p></li>
<li><p>that there is a wide variation in behavior not just between implementations, but also across different versions of the same implementation;</p></li>
<li><p>a platform-specific bug in Go’s <code>crypto/ed25519</code> that gave different validation results on the IBM z/Architecture;</p></li>
<li><p>a crash denial-of-service bug in Tor triggered by validating attacker-controlled signatures (though this bug was coincidentally not exploitable because of the way the function is currently used).</p></li>
</ul></li>
<li><p>The ZIP215 rules <a href="#fixing-the-problem">(jump)</a>, a set of precisely defined validation criteria for consensus-critical Ed25519 signatures which resolve this problem. These rules are implemented in <a href="https://docs.rs/ed25519-zebra"><code>ed25519-zebra</code></a> in Rust and and <a href="https://github.com/hdevalence/ed25519consensus"><code>ed25519consensus</code></a> in Go, are backwards-compatible with existing signatures, and will be deployed in Zcash as part of the <em>Canopy</em> network upgrade.</p></li>
</ol>
<h2 id="the-scope-of-potential-divergence">The scope of potential divergence</h2>
<h3 id="the-ed25519-signing-process">The Ed25519 signing process</h3>
<p>Before explaining the validation criteria, it’s useful to briefly review the signing process. An honest signer generates their signing key, a random scalar \(a\), through a complicated procedure not relevant here. Then, they multiply their signing key by the Curve25519 basepoint \(B\) to obtain their verification key, a curve point \(A = [a]B\). The <em>signing</em> and <em>verification</em> keys are more commonly referred to as the <em>private</em> and <em>public</em> keys, but (following Daira Hopwood), I prefer to use the capability-based terminology, since it more precisely captures the role of the key material.</p>
<p>To sign a message <code>M</code>, a signer first generates a secret random nonce \(r\), through a procedure that is also not relevant here, and then form a public commitment to this randomness by computing \(R = [r]B\). Next, they use a hash function \(H\) to compute a challenge scalar as \( k \gets H(R, A, M) \). Finally, they compute a response scalar as \( s \gets r + ka \).</p>
<h3 id="divergence-in-ed25519-signature-validation-criteria">Divergence in Ed25519 signature validation criteria</h3>
<p>To understand the scope of potential divergence in validation criteria, let’s walk through the steps to verify a signature <code>sig</code> with verification key \(A\) on the message <code>M</code>, noting each step with a possibly divergent behavior choice. Then, in subsequent sections, we’ll look at the scope and implications of each divergence.</p>
<p>Ed25519 signatures are 64 bytes long, structured as two 32-byte components: <code>sig = R_bytes || s_bytes</code>. The first 32 bytes store an encoding of \(R\), and the second 32 bytes store an encoding of \(s\). Ed25519 verification keys are 32 bytes long, storing an encoding of \(A\).</p>
<p>Next, the verifier parses <code>s_bytes</code> as \(s\). It’s always possible to interpret a byte string as a little-endian encoded integer, so parsing \(s\) can’t fail. However, \(s\) is supposed to represent an integer \(\mod q\), where \(q\) is the order of the prime-order subgroup of Curve25519. Honestly-generated signatures will have \(0 \leq s &lt; q\), and implementations can choose to reject \(s \ge q\). Call this check <em>canonical \(s\)</em>.</p>
<p>Next, the verifier attempts to parse <code>A_bytes</code> as \(A\). Not all byte strings are valid point encodings, so parsing \(A\) can fail, causing the signature to be rejected. Points can be encoded non-canonically, although in contrast to the encoding of \(s\), the mechanism is somewhat more complicated and subtle, as will be described <a href="#canonical-a-r">below</a>. Implementations can choose to reject non-canonically encoded curve points. Call this check <em>canonical \(A\)</em>.</p>
<p>The verifier then uses <code>A_bytes</code>, <code>R_bytes</code>, and the message <code>M</code> to recompute the challenge value \(k \gets H(R, A, M)\). (Note that since \(H\) is a hash function, it actually operates on the encodings <code>A_bytes</code> and <code>R_bytes</code>, not their decoded internal representations).</p>
<p>Implementations then make a <em>choice of verification equation</em>, choosing which of two verification equations to check. They can use either the <em>batched equation</em> \[ [8]R = [8]([s]B - [k]A), \] or the <em>unbatched equation</em> \[ R = [s]B - [k]A. \] The naming of <em>batched equation</em> versus <em>unbatched equation</em> suggests that the difference is related to batched versus individual verification, but in fact these give different behavior even in the case of individual verification, as will be explained <a href="#choice-of-verification-equation">below</a>.</p>
<p>Finally, to actually check whichever equation is used, an implementation must choose an <em>equality check</em>. Recall that we didn’t actually decode <code>R_bytes</code> to \(R\) yet. When using the batched equation, an implementation must operate on \(R\), so it must decode <code>R_bytes</code> to \(R\), and check equality of curve points. This also means it must make a choice of whether to require <em>canonical \(R\)</em>.</p>
<p>When using the unbatched equation, however, an implementation can choose to either check equality of curve points, or to compute \(R’ \gets [s]B - [k]A\), encode \(R’\) to <code>Rprime_bytes</code>, and check equality of byte strings. When \(R\) is canonically encoded, these equality checks produce the same result. But because the encoding procedure produces canonical encodings, if <code>R_bytes</code> contains a non-canonical encoding of \(R\), then even if \(R’ = R\) (as curve points), <code>Rprime_bytes</code> may differ from <code>R_bytes</code> (as byte strings).</p>
<h3 id="points-of-potential-divergence">Points of potential divergence</h3>
<p>In summary, there are a number of points of potential divergence between implementations:</p>
<ol type="1">
<li>Whether to require <em>canonical \(s\)</em> or to allow non-canonical encodings.</li>
<li>Whether to require <em>canonical \(A\)</em> or to allow non-canonical encodings.</li>
<li>The <em>choice of verification equation</em>, either <em>batched</em> or <em>unbatched</em>.</li>
<li>The <em>choice of equality check</em>, and the related choice of <em>canonical \(R\)</em>.</li>
<li>Any other <em>ad-hoc checks</em> added by a particular implementation.</li>
</ol>
<p>Before comparing the choices made by RFC8032 and actually existing implementations, let’s examine the exact mechanism and implications of each of these points of potential divergence.</p>
<h3 id="canonical-s">Canonical \(s\)</h3>
<p>The values <code>A_bytes</code>, <code>R_bytes</code>, and <code>M</code> are all fed into the hash function, so they cannot be modified without changing the challenge value. However, a third party could replace \(s\) with \(s’ = s + nq\). Because \(s’ \equiv s \pmod q\), the modified signature \((R, s’)\) would still pass verification. Requiring that <code>s_bytes</code> encodes \(s &lt; q\) prevents this.</p>
<p>This check is simple, low-cost, prevents malleability, is required by RFC8032, and is performed by most implementations. The only notable exception is the original reference implementation of Ed25519, which chose to write a paragraph arguing that signature malleability is never a problem instead of performing the check.</p>
<p>Because this check is fairly common, well-known, and unobjectionable, I didn’t focus on it, and didn’t comprehensively test implementation behavior.</p>
<h3 id="canonical-a-r">Canonical \(A\), \(R\)</h3>
<p>While the mechanism for constructing non-canonically encoded scalar values is fairly simple, the mechanism for constructing non-canonically encoded point values is somewhat more complicated, as mentioned <a href="#divergence-in-ed25519-signature-validation-criteria">above</a>. To explain it, we need to describe the “compressed Edwards \(y\)” encoding used by Ed25519.</p>
<p>Curve25519 is defined over the finite field of order \(p = 2^{255} - 19\), so the coördinates of curve points \((x,y)\) are integers \(\mod p\). The curve equation in (twisted) Edwards form is \[ - x^2 + y^2 = 1 + d x^2 y^2, \] where \(d\) is a curve parameter. This means that \[ x^2 = \frac { y^2 - 1} {d y^2 + 1}. \] If the fraction on the right-hand side is nonsquare, then there is no \(x\) so that the right-hand side equals \(x^2\), and the \(y\) value is not the \(y\)-coördinate of a curve point. If it is square, then there is a square root \(x\), and the value of \(y\) is sufficient to recover \(x\) up to a choice of sign.</p>
<p>Because \(p &lt; 2^{255}\), the encodings of field elements fit in 255 bits. The compressed Edwards \(y\) format uses the first 255 bits to store the \(y\) coördinate, and the 256th bit to indicate the sign of the \(x\) …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hdevalence.ca/blog/2020-10-04-its-25519am">https://hdevalence.ca/blog/2020-10-04-its-25519am</a></em></p>]]>
            </description>
            <link>https://hdevalence.ca/blog/2020-10-04-its-25519am</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686789</guid>
            <pubDate>Mon, 05 Oct 2020 11:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Digital Euro]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24686582">thread link</a>) | @perfunctory
<br/>
October 5, 2020 | https://www.ecb.europa.eu/euro/html/digitaleuro.en.html | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/euro/html/digitaleuro.en.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="ecb-content-col">
					<main>
						﻿
<div>
	<div>
		
			<p>The ECB, as guardian of the euro, provides currency in two forms: we issue banknotes and we transfer electronic deposits to banks and other financial institutions.</p>
			<p>Digitalisation has spread to every corner of our lives and transformed how we pay. In this new era, a digital euro would guarantee that citizens in the euro area can maintain free access to a simple, universally accepted, safe and trusted means of payment. A digital euro is not meant to replace cash, but rather to complement it. Together, they give people more choices about how to pay, and make it easier for them to do so,  increasing financial inclusion. </p>

			<p>The Eurosystem will continue to ensure that all citizens have access to euro banknotes and coins across the euro area.</p>


		
	</div>

	
</div>

<!-- <hr class="dark thick no-top-margin"> -->

	  <div>
		
		<!-- <div class="ecb-grid grid-width-6 tablet-grid-width-6 phone-grid-width-12 ecb-grid-bottom-padding ecb-no-phone-grid-inside-padding ecb-no-phone-grid-bottom-padding ecb-grid-fake-inside-padding-left"> 
		  <div class="fullWidth special-box-image min-full-height arrow-right arrow-extra-light" style="background-image:url('../shared/img/Christine_Lagarde_Quote_600x380.jpg'); height: 334px"> </div>
		   </div>
		<div class="ecb-grid grid-width-6 tablet-grid-width-6 phone-grid-width-12 ecb-grid-bottom-padding ecb-grid-fake-inside-padding-right">
		  <div class="ecb-grid inside min-full-height flex flex-column-nowrap container-special-box">
			<div class="ecb-box modernBox flex-grow">
			  <p><em>We need to make sure the euro is future ready. Inaction is not an option.</em></p>
			  <p><strong>Christine Lagarde, President of the ECB</strong></p>
			</div>
		  </div>
		</div> -->
<div>
<p><em>“The euro belongs to Europeans and we are its guardian. We should be prepared to issue a digital euro, should the need arise.”</em></p>
			  <p><strong>Christine Lagarde, President of the ECB</strong></p>
			</div>

		</div>
	<!-- <hr class="dark thick"> -->


<div>
	
	<div>
		<div>
			<div>
				<h3>Why a digital euro?</h3>
				<p>A digital euro would make your daily payments faster, easier and more secure.
						It could support the digitalisation of the European economy and actively encourage innovation in retail payments. 			
				</p>
				<p>The ECB and the national central banks of the euro area are exploring the benefits and risks so that money continues to serve Europeans well.</p>
				<p><a href="https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf#page=4">Report on a digital euro</a>
				</p>
			</div>
		</div>
	</div>
	
	<div>
		<div>
			<div>
				<h3>What are other benefits of a digital euro?</h3>
				<p>A digital euro would preserve the benefits that the euro provides to all of us. It would help to deal with situations in which people no longer prefer cash. </p>
						<p>It would help cushion the impact of extreme events – such as natural disasters or pandemics – when traditional payment services may no longer function. It could also be crucial if people were to turn to foreign digital means of payment, which might undermine financial stability and monetary sovereignty in the euro area.
						</p>
		
			</div>
		</div>
	</div>
	

	
<div>
	<div>
		<div>
			<h3>When will it be ready?</h3>
			<p>During the preparation phase, we are working on the concept, starting practical experimentation on possible designs, and discussing with stakeholders and international partners.
					Towards the middle of 2021 we will decide whether to launch a digital euro project. This will be followed by an investigation phase on user requirements and service providers.
								
			</p>
			<p>It would take time to develop a safe, accessible and efficient digital currency. We will ensure that the systems we use to pay keep up with the needs of the people who use them.   </p>
			
		</div>
	</div>
</div>






</div>
<div>
	<p><em>“We need to make sure that our currency is fit for the future. Inaction is not an option.”</em></p>
				  <p><strong>Fabio Panetta, ECB Executive Board Member</strong></p>
				</div>

<!-- <hr class="dark thick no-top-margin"> -->
<div>
	<div>
		<p>
			<h3>We’ve analysed the possible benefits and challenges of a digital euro
			</h3>
		</p>
	</div>
</div>



<!--<div class="ecb-grid grid-width-12 ecb-grid-bottom-padding">
  <div class="ecb-grid inside min-full-height flex flex-column-nowrap container-special-box">
    <div class="ecb-box modernBox highlight-medium flex-grow centeredText">
      <h3 class="no-margin-bottom">Read more and join the conversation</h3>
    </div>
  </div>
</div>	-->
	
  <div>

	<div>
		<div>
			<div>
				<h3>Why would a digital euro not be a crypto-asset?</h3>
				<p>Crypto-assets are fundamentally different from central bank money: their prices are volatile because they lack any intrinsic value and there is no reliable institution backing them. 
				</p>
			<p>People using a digital euro would have the same level of confidence as with cash, since they are both backed by a central bank, which is something crypto-assets such as stablecoins cannot provide.  </p>
			
			<p><a href="https://www.ecb.europa.eu/explainers/tell-me/html/what-is-bitcoin.en.html">Explainer: What is bitcoin?</a> </p>
					</div></div>
			</div>


 
	  
  <div>
	<div>
	  <div>
		<h3>Share your opinion with us!</h3>
		
		 <p>Like the euro we already use every day, the design of a digital euro should meet the needs of a broad range of users. Any assessment must therefore take into account all of its implications, for instance for monetary policy and financial stability.
  </p>
 <p>We will open a public consultation on 12 October – stay tuned!</p>  
		  <p>Do you have any questions? <a href="mailto:DigitalEuro@ecb.europa.eu">E-mail us</a>.</p>
	  </div>
	</div>
  </div>
   
	</div>


<div>
  <div>
    <p>
      <h3>Speeches, interviews and publications</h3>
    </p>
  </div>
</div>

			
		
							


					</main>
						
				</div></div>]]>
            </description>
            <link>https://www.ecb.europa.eu/euro/html/digitaleuro.en.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686582</guid>
            <pubDate>Mon, 05 Oct 2020 11:19:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fortunately, I don't squash my commits]]>
            </title>
            <description>
<![CDATA[
Score 278 | Comments 324 (<a href="https://news.ycombinator.com/item?id=24686527">thread link</a>) | @lelf
<br/>
October 5, 2020 | https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The story of a bug, and how I addressed it.</em>
	</p>
	<p>
		Okay, I admit it: I could have given this article all sorts of alternative titles, each of which would have made as much sense as the one I chose. I didn't want to go with some of the other titles I had in mind, because they would give it all away up front. I didn't want to spoil the surprise.
	</p>
	<p>
		I recently ran into this bug, it took me hours to troubleshoot it, and I was appalled when I realised what the problem was.
	</p>
	<p>
		This is the story of that bug.
	</p>
	<p>
		There are several insights from this story, and I admit that I picked the most click-baity one for the title.
	</p>
	<h3 id="94bc204499df483897121bb0343f73f7">
		Yak shaving <a href="#94bc204499df483897121bb0343f73f7" title="permalink">#</a>
	</h3>
	<p>
		I was working on the umpteenth variation of an online restaurant reservations system, and one of the features I'd added was a schedule only visible to the <a href="https://en.wikipedia.org/wiki/Ma%C3%AEtre_d%27h%C3%B4tel">maître d'</a>. The schedule includes a list of all reservations for a day, including guests' email addresses and so on. For that reason, I'd protected that resource by requiring a valid <a href="https://en.wikipedia.org/wiki/JSON_Web_Token">JSON Web Token</a> (JWT) with an appropriate role.
	</p>
	<p>
		I'd deployed a new version of the API and went for an ad-hoc test. To my surprise, that particular resource didn't work. When I tried to request it, I got a <code>403 Forbidden</code> response.
	</p>
	<p>
		"That's odd," I though, "it worked the last time I tried this."
	</p>
	<p>
		The system is set up with continuous deployment. I push <em>master</em> to a remote repository, and a build pipeline takes over from there. It only deploys the new version if all tests pass, so my first reaction was that I might have made a mistake with the JWT.
	</p>
	<p>
		I wasted significant time decoding the JWT and comparing its contents to what it was supposed to be. I couldn't find any problems.
	</p>
	<p>
		I also meticulously compared the encryption key I'd used to sign the JWT with the key on the server. They were identical.
	</p>
	<p>
		Incredulous, and running out of ideas, I tried running all tests on my development machine. Indeed, all 170 tests passed.
	</p>
	<p>
		Finally, I gave up and ran the API on my development machine. It takes all of a 30 seconds to configure the code to run in that environment, so you're excused if you wonder why I didn't already do that. What can I say? I've almost two decades of experience with automated test suites. Usually, if all tests pass, the problem is environmental: a network topology issue, a bad or missing connection string, a misconfigured encryption key, an invalid JWT, things like that.
	</p>
	<p>
		To my surprise, the problem also manifested on my machine.
	</p>
	<h3 id="b726532ae06844eb8aeaa2c27ca0d913">
		Not my code <a href="#b726532ae06844eb8aeaa2c27ca0d913" title="permalink">#</a>
	</h3>
	<p>
		Okay, even with hundreds of tests, perhaps some edge case went unnoticed. The only problem with that hypothesis was that this was hardly an edge case. I was only making a <code>GET</code> request with a <code>Bearer</code> token. I wasn't going through some convoluted sequence of steps.
	</p>
	<pre>GET /restaurants/1/schedule/2020/9/30 HTTP/1.1
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5c[...]</pre>
	
	<p>
		I expected a successful response containing some JSON, but the result was <code>403 Forbidden</code>. That was the same behaviour I saw in the production environment.
	</p>
	<p>
		Now, to be clear, this is indeed a protected resource. If you present an invalid JWT, <code>403 Forbidden</code> is the expected response. That's why I wasted a few hours looking for problems with the the JWT.
	</p>
	<p>
		I finally, hesitatingly, concluded that the problem might be somewhere else. The JWT looked okay. So, hours into my troubleshooting I reluctantly set a breakpoint in my code and started the debugger. It isn't rational, but I tend to see it as a small personal defeat if I have to use the debugger. Even so, if used judiciously, it can be an effective way to identify problems.
	</p>
	<p>
		The debugger never hit my breakpoint.
	</p>
	<p>
		To be clear, the beginning of my Controller method looked like this:
	</p>
	<pre>[<span>Authorize</span>(Roles&nbsp;=&nbsp;<span>"MaitreD"</span>)]
[<span>HttpGet</span>(<span>"restaurants/{restaurantId}/schedule/{year}/{month}/{day}"</span>)]
<span>public</span>&nbsp;<span>async</span>&nbsp;<span>Task</span>&lt;<span>ActionResult</span>&gt;&nbsp;Get(
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;restaurantId,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;year,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;month,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;day)
{
&nbsp;&nbsp;&nbsp;&nbsp;<span>if</span>&nbsp;(!AccessControlList.Authorize(restaurantId))
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>return</span>&nbsp;<span>new</span>&nbsp;<span>ForbidResult</span>();</pre>
	
	<p>
		My breakpoint was on the first line (the <code>if</code> conditional), but the debugger didn't break into it. When I issued my <code>GET</code> request, I immediately got the <code>403 Forbidden</code> response. The breakpoint just sat there in the debugger, mocking me.
	</p>
	<p>
		When that happens, it's natural to conclude that the problem occurs somewhere in the framework; in this case, ASP.NET. To test that hypothesis, I commented out the <code>[Authorize]</code> attribute and reissued the <code>GET</code> request. My hypothesis was that I'd get a <code>200 OK</code> response, since the attribute is what tells ASP.NET to check authorisation.
	</p>
	<p>
		The hypothesis held. The response was <code>200 OK</code>.
	</p>
	<h3 id="fdff404f12644a898b6a3e695fb6533f">
		Test interdependency <a href="#fdff404f12644a898b6a3e695fb6533f" title="permalink">#</a>
	</h3>
	<p>
		I hate when that happens. It's up there with fixing other people's printers. The problem is in the framework, not in my code. I didn't have any authorisation callbacks registered, so I was fairly certain that the problem wasn't in my code.
	</p>
	<p>
		I rarely jump to the conclusion that there's a bug in the framework. In my experience, <a href="https://blog.codinghorror.com/the-first-rule-of-programming-its-always-your-fault">select is rarely broken</a>. My new hypothesis had to be that I'd somehow managed to misconfigure the framework.
	</p>
	<p>
		But where? There were automated tests that verified that a client could request that resource with a valid JWT. There were other automated tests that verified what happened if you presented an invalid JWT, or none at all. And all tests were passing.
	</p>
	<p>
		While I was fiddling with the tests, I eventually ran a parametrised test by itself, instead of the entire test suite:
	</p>
	<pre>[<span>Theory</span>]
[<span>InlineData</span>(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>"Hipgnosta"</span>,&nbsp;2024,&nbsp;11,&nbsp;&nbsp;2)]
[<span>InlineData</span>(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>"Nono"</span>,&nbsp;2018,&nbsp;&nbsp;9,&nbsp;&nbsp;9)]
[<span>InlineData</span>(<span>"The&nbsp;Vatican&nbsp;Cellar"</span>,&nbsp;2021,&nbsp;10,&nbsp;10)]
<span>public</span>&nbsp;<span>async</span>&nbsp;<span>Task</span>&nbsp;GetRestaurantScheduleWhileAuthorized(
&nbsp;&nbsp;&nbsp;&nbsp;<span>string</span>&nbsp;name,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;year,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;month,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;day)</pre>
	
	<p>
		This parametrised test has three test cases. When I ran just that test method, two of the test cases passed, but one failed: the <em>Nono</em> case, for some reason I haven't yet figured out.
	</p>
	<p>
		I didn't understand why that test case ought to fail while the others succeeded, but I had an inkling. I commented out the <em>Nono</em> test case and ran the test method again.
	</p>
	<p>
		One passed and one failing test.
	</p>
	<p>
		Now <em>The Vatican Cellar</em> test case was failing. I commented that out and ran the test method again. The remaining test case failed.
	</p>
	<p>
		This reeks of some sort of test interdependency. Apparently, <em>something</em> happens during the first test run that makes succeeding tests pass, but it happens too late for the first one. But what?
	</p>
	<h3 id="c95c3e707f46467abbf8ff02a9594c4c">
		Bisect <a href="#c95c3e707f46467abbf8ff02a9594c4c" title="permalink">#</a>
	</h3>
	<p>
		Then something occurred to me that I should have thought of sooner. This feature used to work. Not only had the tests been passing, but I'd actually interacted with the deployed service, presenting a valid JWT and received a <code>200 OK</code> response.
	</p>
	<p>
		Once than dawned on me, I realised that it was just a manner of performing a binary search. Since, of course, I use version control, I had a version I knew worked, and a version that didn't work. The task, then, was to find the commit that introduced the defect.
	</p>
	<p>
		As I've already implied, the system in question is an example code base. While I have a cloud-based production environment, none but I use it. It had been four or five days since I'd actually interacted with the real service, and I'd been busy making changes, trusting exclusively in my test suite. I tend to make frequent, small commits instead of big, infrequent commits, so I had accumulated about a hundred and fifty commits since the 'last known good' deployment.
	</p>
	<p>
		Searching through hundreds of commits sounds overwhelming, but using binary search, it's actually not that bad. Pick the commit halfway between the 'last known good' commit and the most recent commit, and check it out. See if the defect is present there. If it is, you know that it was introduced somewhere between the commit you're looking at, and the 'last known good' commit. If it isn't present, it was introduced later. Regardless of the outcome, you know in which half to look. You now pick a new commit in the middle of that set and repeat the exercise. Even with, say, a hundred commits, the first bisection reduces the candidate set to 50, the next bisection to 25, then 13, then 7, 4, 2, and then you have it. If you do this systematically, you should find the exact commit in less than eight iterations.
	</p>
	<p>
		This is, as far as I understand it, the algorithm used by <em>Git bisect</em>. You don't have to use the <code>bisect</code> command - the algorithm is easy enough to do by hand - but let's see how it works.
	</p>
	<p>
		You start a <code>bisect</code> session with:
	</p>
	<pre><span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((93c6c35...))</span>
$ git bisect start

<span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((93c6c35...)|BISECTING)</span></pre>
	
	<p>
		This starts an interactive session, which you can tell from the Git integration in Git Bash (it says <code>BISECTING</code>). You now mark a commit as being bad:
	</p>
	<pre>$ git bisect bad

<span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((93c6c35...)|BISECTING)</span></pre>
	
	<p>
		If you don't provide a commit ID at that point, Git is going to assume that you meant that the current commit (in this case <code>93c6c35</code>) is bad. That's what I had in mind, so that's fine.
	</p>
	<p>
		You now tell it about a commit ID that you know is good:
	</p>
	<pre>$ git bisect good 7dfdab2
Bisecting: 75 revisions left to test after this (roughly 6 steps)
[1f78c9a90c2088423ab4fc145b7b2ec3859d6a9a] Use InMemoryRestaurantDatabase in a test

<span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((1f78c9a...)|BISECTING)</span></pre>
	
	<p>
		Notice that Git is already telling us how many iterations we should expect. You can also see that it checked out a new commit (<code>1f78c9a</code>) for you. That's the half-way commit.
	</p>
	<p>
		At this point, I manually ran the test method with the three test cases. All three passed, so I marked that commit as good:
	</p>
	<pre>$ git bisect good
Bisecting: 37 revisions left to test after this (roughly 5 steps)
[5abf65a72628efabbf05fccd1b79340bac4490bc] …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/">https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/</a></em></p>]]>
            </description>
            <link>https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686527</guid>
            <pubDate>Mon, 05 Oct 2020 11:09:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter is holding me hostage]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24686363">thread link</a>) | @mathsm
<br/>
October 5, 2020 | https://blog.s-m.ac/twitter-is-holding-me-hostage/ | <a href="https://web.archive.org/web/*/https://blog.s-m.ac/twitter-is-holding-me-hostage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>“Resistance is futile”</p></header><nav id="TOC"><ul><li><a href="#summary">Summary</a></li><li><a href="#motivation">Motivation</a></li><li><a href="#the-downfall">The downfall</a></li><li><a href="#the-hostage-situation">The hostage situation</a></li><li><a href="#what-ill-do">What I’ll do</a></li><li><a href="#edit-update-mid-september">Edit: Update mid-September</a></li><li><a href="#edit-update-early-october">Edit: Update early-October</a></li></ul></nav><section id="summary"><h2>Summary</h2><p>I opened an account on Twitter where I had none and got suspended without justification before I could do anything. Now my name shows up (it didn’t before!) as someone who violates Twitter rules (I didn’t!) and was accordingly suspended.</p><p>I tried to boost my visibility via social media but ended up hurting it: people <em>have</em> referred to my handle but anyone who looks at it will see a <a href="https://twitter.com/SableMeyer">suspended account with no activity</a></p></section><section id="motivation"><h2>Motivation</h2><p>I consider most social media to be harmful at the individual and societal level. A position I can afford because, while I sometime rant against events organized solely on Facebook, I am lucky to be in an environnement where I can avoid them and remain socially connected.</p><p>Recent discussions and readings made me reconsider this position when it comes to Twitter. While I can wave it off my personal life and lose nothing, evidence piles up that for my professional career in academia, having a presence on twitter matters, notably to improve cites <span data-cites="eysenbach2011can luc2020does">[1, 2]</span> and to be informed of new papers before/as they are published.</p><p>I was convinced to open a Twitter account about a month ago, mid 2020. My research advisor was speaking in a conference of high attendance and presented joint work. After the talk he asked me for my account so that he could cite me when twitting the article he mentioned. I could have replied that I didn’t want or need an account, but my advisor’s account has over 20k followers – including pretty much anywhere I could imagine myself applying after a PhD – and declining seemed so unwise I created an account and sent an email on the spot.</p></section><section id="the-downfall"><h2>The downfall</h2><p>Opening an account was a pleasant experience and done in less than a minute. The “phone number” field is optional: while I don’t doubt they already have it (as of this writing the <a href="https://play.google.com/store/apps/details?id=com.twitter.android">android app</a> requires contact access), this was meant to be a professional account and I consider my phone number personal so I was happy to be given the possibility not to fill that field.</p><p>I proceeded to add two pictures of me, update my profile a bit, and follow my research advisor. Then I could do nothing else. My account was immediately suspended and I received an email stating: “Your account appears to have exhibited automated behavior that violates the Twitter Rules”. Trying to log it now required my phone number. Given the process so far, I thought I could do without so instead I chose to click the “contact support” link and wrote a gentle note saying that I did not have a phone number to give<span><label for="sn-0"></label><span>This was probably a bad call, but I stand by the fact that (i) I was implicitly promised that it would not be a requirement, and (ii) I do not have a “professional” phone number and giving my personal one seemed innapropriate</span></span>, but that my account was legitimate nonetheless. After having to confirm my email address once more, I didn’t hear a thing from Twitter, ever. I wrote follow up emails after two weeks, then waited more, to no avail. Eventually my email received an automated response: “You tried to update a case that has been closed. Please submit a new case at&nbsp;http://support.twitter.com/forms”, which I did.</p></section><section id="the-hostage-situation"><h2>The hostage situation</h2><p>Up until now, looking for me on Twitter resulted in not finding me, which I’m fine with. Where it gets messy is that for the past month, if you look for me you’ll see an account that has both my face and the text “Account suspended: Twitter suspends accounts which violate the Twitter Rules”. In a very Kafkaesque way, no one but twitter know which rule I violated or how (recall, I didn’t have time to do anything!), and I don’t know how to redeem myself in Twitter’s eyes.</p><p>I should have known better: this part of <em>why</em> I think current big social media are harmful: they’re not public spaces and have to answer to close to no one. Twitter is free to do whatever they want on their website, and ultimately they get to decide who has a say. But still, I find what they did rather odd: they have such a dominant position that the incentives to register were stronger than my (very strong!) dislike of the website. This is a net win for them: I could have been part of the snowball, and maybe take other people around me who are Twitter-sceptics. Yet instead of rewarding me for making the jump and embracing their newly gained user, they crushed me, leaving a sour taste of abuse of power.</p></section><section id="what-ill-do"><h2>What I’ll do</h2><p>I don’t think there’s much I can do. The dark pattern “no phone required” into “if you don’t give a phone you’ll get banned” won’t look good if looked into seriously by the French DGCCRF (consumers’ protection) but I doubt they will lift a finger, and even if they did we’re talking long timescale. I could create another account, “give up my phone”, but then I’d also give up the handle and the tweets that already reference it. I can forever give up on twitter after being bitten exactly by what I feared would bite me.</p></section><section id="edit-update-mid-september"><h2>Edit: Update mid-September</h2><p>Waiting for an update, so far I didn’t do anything except, every other week, trying to submit a request again. I get automatic (accurate) replies in the form of “It looks like this is connected with your original case <ticket number="">, so we’ve added it to that first report.” and that’s it.</ticket></p></section><section id="edit-update-early-october"><h2>Edit: Update early-October</h2><p>Nothing to report except automatic “acknowledgement” emails (as if…)</p><hr><div id="refs" role="doc-bibliography"><p>[1] Eysenbach, G. 2011. Can tweets predict citations? Metrics of social impact based on twitter and correlation with traditional metrics of scientific impact. <em>Journal of medical Internet research</em>. 13, 4 (2011), e123.</p><p>[2] Luc, J.G., Archer, M.A., Arora, R.C., Bender, E.M., Blitz, A., Cooke, D.T., Hlci, T.N., Kidane, B., Ouzounian, M., Varghese Jr, T.K. and others 2020. Does tweeting improve citations? One-year results from the tssmn prospective randomized trial. <em>The Annals of Thoracic Surgery</em>. (2020).</p></div></section></article></div>]]>
            </description>
            <link>https://blog.s-m.ac/twitter-is-holding-me-hostage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686363</guid>
            <pubDate>Mon, 05 Oct 2020 10:36:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Tailwind CSS]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24686351">thread link</a>) | @swyx
<br/>
October 5, 2020 | https://www.swyx.io/why-tailwind/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/why-tailwind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I'm not a Tailwind shill. I'm a <a href="https://www.swyx.io/guo-lai-ren/">Guo Lai Ren</a> - someone who has changed their mind on it recently and am a happy user despite acknowledged tradeoffs. "Crossover people" can often be more persuasive to skeptics than born-and-bred believers. So I hope to contribute my perspective to the discussion, if you are open to it.</p>
<p>A while ago Adam Wathan <a href="https://twitter.com/tailwindcss/status/1303740401967390720?s=20">asked</a>: "Did you think Tailwind was a horrible idea until you actually built something with it?"</p>
<p>I <a href="https://twitter.com/swyx/status/1303769383278268416">replied</a>:</p>
<blockquote>
  <p>I once complained to @samselikoff that Tailwind caused ugly unreadable classname soup and said zero-runtime CSS-in-JS could do more with a lower learning curve.</p>
  <p>I was wrong on 2 counts: Tailwind is easier to learn than I thought, and CSSinJS's flexibility can be a <em>negative</em>.</p>
</blockquote>
<p>After shipping a few projects (including my <a href="https://www.swyx.io/">personal site</a> and <a href="https://www.learninpublic.org/">book site</a>) with <a href="https://tailwindcss.com/">Tailwind</a> now, I feel I should probably jot down my thoughts on what I like about it. Since Tailwind is the predominant Utility CSS framework and the only one I've tried, I'll make no effort to distinguish the points below from the general benefits of Utility CSS (but <a href="https://css-tricks.com/need-css-utility-library/">here's a list of others</a>).</p>
<section>
  <h2 id="tldr"><a href="#tldr">TL;DR</a></h2>
  <ul>
    <li><strong>"System" Values reduce Magic Numbers</strong>: Decrease hardcoded values, Increase consistency.</li>
    <li><strong>Responsive Design in the Browser</strong>: Prototype in browser, copy and paste to codebase, using consistent system values.</li>
    <li><strong>Inlining Styles Optimizes for Change</strong>: Make code easy to delete and move, by eliminating all reliance on the cascade.</li>
    <li><strong>Inlining Styles reduces Naming</strong>: Ship faster by solving one of the known hard problems in Computer Science!</li>
    <li><strong>Zero JS &amp; Sublinear Scaling of CSS</strong>: Scale at O(log N), not O(N).</li>
    <li><strong>Utility-First, not Utility-Only</strong>: Respect the Principle of Least Power, use CSS-in-JS only when warranted.</li>
  </ul>
</section>
<section>
  <h2 id="the-utility-first-canon"><a href="#the-utility-first-canon">The Utility-First Canon</a></h2>
  <p>Before you listen to me, you may wish to check out the most influential pieces on the "utility classes" revolution in CSS right now:</p>
  <ul>
    <li>Adam Wathan's blogpost on <a href="https://adamwathan.me/css-utility-classes-and-separation-of-concerns/">CSS Utility Classes and "Separation of Concerns"</a></li>
    <li>Simon Vrachilotis' talk on <a href="https://twitter.com/simonswiss/status/1057078025118871552?s=20">A Real Life Journey into the Opinionated World of Utility-First CSS</a> (see also: <a href="https://www.youtube.com/watch?v=R50q4NES6Iw">Sarah Dayan's talk</a>)</li>
  </ul>
  <p>I am heavily influenced by these people and others, so if I repeat some points poorly below, the fault is mine. At least I gave you the canonical sources first.</p>
</section>
<section>
  <h2 id="system-values-reduce-magic-numbers"><a href="#system-values-reduce-magic-numbers">"System" Values reduce Magic Numbers</a></h2>
  <p>CSS is extremely flexible, which makes it powerful, but also gives you a lot of footguns to shoot yourself with. Constraints are needed, or else we sprinkle "magic numbers" all over our codebase.</p>
  <p><a href="https://css-tricks.com/magic-numbers-in-css/">Magic Numbers in CSS are a bad thing</a>, says Chris Coyier. He defines it to mean "<em>values which “work” under some circumstances but are frail and prone to break when those circumstances change</em>", but honestly any hardcoded number, like <code>px</code> in margins and media queries, or color variants, is difficult to manage well at scale. The temptation to break rules just to ship a fix is there, and the difficulty of refactoring when design requirements change is too high. If you are working by yourself, there is nothing enforcing that you stick to a consistent set of well designed number scales, which can lead to bad-looking design.</p>
  <p>The solution, of course, is to draw only from a preset range of number values, which I call a "system" (note that I don't call this a "Design System", a debate I have no interest in getting into). Tailwind comes with a good set of font and color systems by default. Again, you could try to roll your own system with CSS variables, but you don't have <a href="https://www.steveschoger.com/speaking/">Steve Schoger</a> on your team.</p>
  <blockquote>
    <p>Alternatives exist: <a href="https://styled-system.com/">Styled-System</a> and <a href="https://theme-ui.com/home/">Theme UI</a> from the <a href="https://jxnblk.com/">jxnblk</a>-verse are the basis for this in CSS-in-JS land.</p>
  </blockquote>
</section>
<section>
  <h2 id="responsive-design-in-the-browser"><a href="#responsive-design-in-the-browser">Responsive Design in the Browser</a></h2>
  <p>This point is most relevant to developers-who-do-design: the best development workflow is to preview your site on <code>localhost</code>, make adjustments in the browser until you are happy with it, and then copy-and-paste your changes <strong>straight into your codebase</strong>. Let's call this the <strong>Design in Browser</strong> workflow.</p>
  <p>If you want this workflow, you rule out using React's inline styling (which make you use object syntax). But let's say you do use some form of "Write Real CSS"™ solution like Styled-Components or Vue or Svelte scoped styles, where design-in-browser is possible. What else does Tailwind offer you?</p>
  <ol>
    <li>You can pull directly from preset "system" values (elaborated above) while prototyping in browser</li>
    <li>You can do responsive and pseudo-class design while in browser too - e.g. to apply styles at different breakpoints, or on hover or focus, you can just prefix inline, e.g. for a link, <code>text-green-400 hover:text-green-300 md:text-blue-400</code>.</li>
  </ol>
  <p>I did a demo of this in a recent video:</p>
  
  <p>Designing in the Browser is not quite Bret-Victor-style <a href="https://www.youtube.com/watch?v=PUv66718DII">Inventing on Principle</a>, but you are getting at least closer to being able to "play" in context by reducing the cognitive distance yet again. With Tailwind, you can even add <a href="https://tailwindcss.com/docs/transition-property#app">transitions</a> and <a href="https://tailwindcss.com/docs/animation#app">animations</a> inline while you play. This is extremely underrated - we developers might offer more movement in our apps if only it were easier to prototype and add them.</p>
</section>
<section>
  <h2 id="inlining-styles-optimizes-for-change"><a href="#inlining-styles-optimizes-for-change">Inlining Styles Optimizes for Change</a></h2>
  <p>A lot of production CSS is <a href="https://css-tricks.com/oh-no-stylesheet-grows-grows-grows-append-stylesheet-problem/">append only</a>. This is because the <strong>cognitive distance</strong> between the CSS and the markup it affects is often far - sometimes in a different folder, different file, or same file but dozens of lines away. On top of that, you have to remember the CSS cascade and run every element against every matching rule, in your head.</p>
  <p>Pretty soon, you have a codebase you are scared to even open! Developer velocity slows down, and eventually you back yourself into a corner where nothing less than a full rewrite will do.</p>
  <p>By design, CSS is easy to extend. Just add specificity! But <a href="https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to">it is not easy to delete</a>. This adds complexity, in <a href="https://www.infoq.com/presentations/Simple-Made-Easy/">the best Rich Hickey sense of the word</a> (because position matters in CSS, you know have to remember all positions). It's easy to build up the house of cards, but take one thing out and the whole edifice may fall apart, and you WON'T KNOW until you check for visual regressions or emulate the browser in your head.</p>
  <p>You can use tooling (CSS modules, static CSS in JS, Vue or Svelte <a href="https://svelte.dev/blog/the-zen-of-just-writing-css">scoped styles</a>) or naming conventions (BEM, etc) to control specificity, but that reduces the cognitive distance rather than eliminates it. The only option with zero "spooky action at a distance" is inline styling. Inline styling <a href="https://overreacted.io/optimized-for-change/">optimizes for change</a>.</p>
  <p>"Galaxy Brain" time: Tailwind offers the developer velocity benefits of inline styles without its downsides.</p>
  <blockquote>
    <p>Alternatives exist: Other solutions like Emotion's <code>css</code> prop and <code>styled-jsx</code> offer similar benefits of inline styles, but they run into the standard CSS in JS downsides</p>
  </blockquote>
  <p><a href="https://www.infoq.com/presentations/Simple-Made-Easy/"><img src="https://dev-to-uploads.s3.amazonaws.com/i/hyqokn1sf7yur7t48j73.jpg" alt="Alt Text"></a></p>
</section>
<section>
  <h2 id="inlining-styles-reduces-naming"><a href="#inlining-styles-reduces-naming">Inlining Styles reduces Naming</a></h2>
  <p><a href="https://www.swyx.io/how-to-name-things/">Naming Things</a> is a known hard problem. We waste a lot of time bickering over naming classes. With Styled-Components, you often write a bunch of intermediate styled components you have to name. With <a href="http://getbem.com/naming/">BEM</a>, we replace one naming problem with three and a half naming problems (I've had PRs held up on whether I should've used <code>--</code> or <code>__</code> - what a total waste of time). How many millions in developer-hours do we waste every year bickering over names?</p>
  <p>With utility CSS we significantly reduce the total number of names in our codebase, and perhaps more importantly, the number of names we have to independently invent and remember. This feels minor until you've worked on a codebase where it isn't. What price are you willing to pay to eliminate one of the known known hard problems? I'm not kidding - this is a conversation worth having. Names don't matter to machines but they matter to humans.</p>
  <p>The tradeoff is you have to learn the names from the utility CSS framework. <code>-mb-5</code> and <code>space-x-reverse</code> aren't parseable without docs. The difference is that traditional CSS naming is bespoke per project, whereas you learn Tailwind once and can use them in every project. Yes, you could try to roll your own utilities, but Tailwind's naming is probably more thoughtfully designed than whatever you come up with.</p>
  <blockquote>
    <p>Alternatives exist: Emotion's <code>css</code> prop and <code>styled-jsx</code> also let you skip naming.</p>
  </blockquote>
</section>
<section>
  <h2 id="zero-js--sublinear-scaling-of-css"><a href="#zero-js--sublinear-scaling-of-css">Zero JS &amp; Sublinear Scaling of CSS</a></h2>
  <p>A lot of ink has been spilled about the performance tradeoffs of using CSS in JS, and their mitigating factors. You can check my <a href="https://www.youtube.com/watch?v=Qox56z4xH6o">What's New in React talk</a> for more, but rest assured it is hotly debated with passionate, intelligent people on both sides. But we all agree that the less JS you ship, the better, and we also agree that byte-for-byte, shipping 1kb of JS has a far bigger performance impact than 1kb of CSS. Those are well understood.</p>
  <p>The point I'm keen on exploring here is that many CSS and CSS in JS solutions scale linearly with the number of components in your app. Because CSS scopes each declaration to your identifier, you have to repeat it everywhere you want to apply it. This is how we ended up with &gt;50 declarations of <code>font-weight: bold</code> at a previous workplace. Individually, these don't matter, but in bulk, they add up.</p>
  <blockquote>
    <p>"On our old site, we were loading more than 400 KB of compressed CSS (2 MB uncompressed)... We didn’t start out with that much CSS; it just grew over time and rarely decreased. This happened in part because every new feature meant adding new CSS." - <a href="https://engineering.fb.com/web/facebook-redesign/">Facebook Engineering</a></p>
  </blockquote>
  <p>You can defer this problem with code-splitting, but eventually people ship and implement hacky workarounds to the point where the CSS gets out of control again (particularly if it is append-only!).</p>
  <p>The solution here is (arguably!) to ship "atomic" CSS, so that your CSS scales by <code>O(log N)</code> instead of <code>O(N)</code> (where <code>N</code> is your number of components). <a href="https://twitter.com/wongmjane/status/1187411809667436550">Facebook's unreleased stylex library</a> lets you write CSS in JS and generates atomic CSS for you, but you could also just choose to hand-write atomic CSS, which is what utility frameworks like Tailwind guide you do.</p>
  <p>To be fair, I put this point at the bottom, because it is unlikely that most apps get to the scale where this really starts to matter, especially when taking <a href="https://en.wikipedia.org/wiki/Gzip">gzip</a> into account. However, …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.swyx.io/why-tailwind/">https://www.swyx.io/why-tailwind/</a></em></p>]]>
            </description>
            <link>https://www.swyx.io/why-tailwind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686351</guid>
            <pubDate>Mon, 05 Oct 2020 10:34:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast, consistent, durable and scalable streaming data with Pravega]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24685835">thread link</a>) | @fpj
<br/>
October 5, 2020 | https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/ | <a href="https://web.archive.org/web/*/https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <!-- Share buttons by mashshare.net - Version: 3.7.7--><p><em><a href="https://es.linkedin.com/in/raulgraciatinedo">Raul Gracia</a> and <a href="https://www.linkedin.com/in/flavio-junqueira-bab134/">Flavio Junqueira</a></em></p>
<h2>Introduction</h2>
<p>Streaming systems continuously ingest and process data from a variety of data sources. They build on append-only data structures to enable efficient write and read access, targeting low-latency end-to-end. As more of the data sources in applications are machines, the expected volume of continuously generated data has been growing and is expected to grow further [1][2]. Such growth puts pressure on streaming systems to handle machine-generated workloads not only with low latency, but also with high throughput to accommodate high volumes of data.</p>
<p><a href="https://pravega.io/" target="_blank" rel="noopener">Pravega</a>&nbsp;(“good speed” in Sanskrit) is an open-source storage system for streams that we have built from the ground up to ingest data from continuous data sources and meet the <a href="https://pravega.io/docs/latest/" target="_blank" rel="noopener">stringent requirements</a> of such streaming workloads. It provides the ability to store an unbounded amount of data per stream using&nbsp;<a href="https://pravega.io/docs/latest/pravega-concepts/#a-note-on-tiered-storage" target="_blank" rel="noopener">tiered storage</a>&nbsp;while being <a href="https://pravega.io/docs/latest/pravega-concepts/#elastic-streams-auto-scaling" target="_blank" rel="noopener">elastic</a>, <a href="https://pravega.io/docs/latest/pravega-concepts/#architecture">durable</a> and <a href="https://pravega.io/docs/latest/pravega-concepts/#ordering-guarantees" target="_blank" rel="noopener">consistent</a>. Both the write and read paths of Pravega have been designed to provide low latency along with high throughput for event streams in addition to features such as long-term retention and stream scaling. This post is a performance evaluation of Pravega focusing on the ability of reading and writing.</p>
<p>To contrast with different design choices, we additionally show results from other systems: <a href="https://kafka.apache.org/">Apache Kafka</a> and <a href="https://pulsar.apache.org/">Apache Pulsar</a>. Initially qualified as messaging systems, both Pulsar and Kafka make a conscious effort to become more like a storage system; they have recently added features like tiered storage. These systems have made fundamentally different design choices, however, leading to different behavior and performance characteristics that we explore in this post.</p>
<p>The main aspects covered in this post and the highlights of our results are the following:</p>
<ul>
<li><em><a href="#pravega-ingestion">Overall ingestion performance</a>.</em>&nbsp;A Pravega writer produces over <strong>1 million events</strong>&nbsp;<strong>per second</strong>&nbsp;<strong>for small events</strong> (100 bytes) and <strong>sustains 350MB/s throughput for large events</strong> (10,000 bytes), both with <strong>single-digit millisecond latency</strong>&nbsp;(at the 95th percentile).</li>
<li><a href="#durability"><em>Durability</em></a>. <strong>Pravega always makes the data durable on acknowledgment</strong>. The write throughput of Kafka is at least 40% less compared to Pravega for a single-segment stream, independent of flushing on every message or not. For a 16-segment stream, the Pravega writer provides comparable throughput to the Kafka writer flushing on every message, but Pravega write latency is lower (<em>i.e.</em>, single-digit millisecond vs. 1+ seconds for Kafka).</li>
<li><em><a href="#dynamic-batching">Dynamically adjusting batches</a>.</em>&nbsp;Pravega <strong>does not</strong>&nbsp;<strong>require a complex configuration for client batching</strong>. The Pulsar client can achieve either low latency or high throughput, but not both. For Kafka, configuring large batches is detrimental for throughput when the application uses routing keys (throughput is 80% lower for a 16-segment stream). In both cases, forcing the user to statically configure batching is undesirable.</li>
<li><em><a href="#high-throughput">Behavior in the presence of large events for throughput-oriented workloads</a>. </em><strong>Pravega obtains up to 350MB/s for a 16-segment stream with 10kB events.&nbsp;</strong>The throughput&nbsp;is 40% higher than the one of Pulsar and comparable to the throughput of Kafka (about 6% difference). However, the latency in the case of Kafka is over 800ms while the one of Pravega is in single-digit milliseconds.</li>
<li><em><a href="#end-to-end-latency">End-to-end latency</a></em>. When tailing a stream, the Pravega reader also provides <strong>single-digit millisecond latency</strong>&nbsp;<strong>end-to-end&nbsp;</strong>while serving data at high throughput. It provides a higher throughput (roughly 80% more) for a single-segment stream when compared to Kafka. For Pulsar, adding partitions and readers leads to lower performance (single-partition case achieves 3.6x the throughput of the 16-segment case).</li>
<li><em><a href="#routing-keys">Use of routing keys</a></em>. <strong>Pravega does not present any significant performance difference when using or omitting routing keys.</strong>&nbsp;For moderate/high throughput rates, Kafka and Pulsar show over 2x end-to-end latency when using routing keys and, specifically for Kafka, a maximum read throughput that is over 37% lower.</li>
<li><em><a href="#historical-catchup">Tiered storage for catch-up and historical reads</a>.</em>&nbsp;Pravega can&nbsp;<strong>catch up with 100GB of historical data dynamically</strong>&nbsp;<strong>while ingesting 100MB per second of new data</strong>. Pulsar with tiering enabled was not able to catch up for the same scenario, inducing a backlog that grows without bounds.</li>
<li><em><a href="#auto-scaling">Performance with auto-scaling</a>. </em><strong>Auto-s</strong><strong>caling is a unique feature of Pravega</strong>. Scaling up a stream provides higher ingestion performance. We show that scaling up a stream using a constant ingestion rate of 100MB/s causes&nbsp;<strong>write latency to drop.</strong></li>
</ul>
<p>Except when we show time series, we plot latency along with throughput. It is a problem we commonly find across blog posts; they plot either latency or throughput, whereas both are jointly relevant for streaming workloads. For example, the maximum throughput for a given configuration might look very good while the latency is of the order of hundreds of milliseconds to a few seconds. We plot latency-throughput graphs to avoid misleading conclusions. We additionally provide tables with the data points used to complement the plots. The tables give more data than the plots (<em>e.g.</em>, different percentile ranks) for completeness.</p>
<h2>Background</h2>
<p>Pravega is a complex system, and we encourage the reader to investigate further our documentation, including <a href="https://blog.pravega.io/" target="_blank" rel="noopener">previous blog posts</a>. Here, we provide a very brief summary of the write and read paths, along with some key points of Kafka and Pulsar.</p>
<h3>The Pravega write path</h3>
<p>Pravega has different APIs for adding data to a stream. In this section, we primarily focus on the <a href="https://pravega.io/docs/latest/javadoc/clients/index.html"><em>event stream API</em></a>.</p>
<p>The <em>event stream writer&nbsp;</em>writes events to a stream. A stream can have parallel segments that can change dynamically according to an auto-scaling policy. When an application provides routing keys, the client uses them to map events to segments.&nbsp; If the routing key is omitted when writing an event, then the client selects a segment randomly.</p>
<p>The client opportunistically batches event data, and writes such batches to a segment. The client controls when to open new batches and close them, but the data for a batch accumulates on the server. The component in Pravega managing segments is called the <em><a href="https://blog.pravega.io/2019/04/22/events-big-or-small-bring-them-on/" target="_blank" rel="noopener">segment store</a></em>. The segment store receives such requests to write to a segment, and both add the data to a cache and appends it to a <em>durable log</em>, currently implemented with <a href="https://bookkeeper.apache.org/" target="_blank" rel="noopener">Apache BookKeeper</a>. When appending to the durable log, the segment store performs a second round of batching. We have this second level of aggregation to sustain high throughput for use cases in which the message size is small and possibly infrequent.</p>
<p>The log guarantees durability: Pravega acknowledges events once they are made durable to the log, and uses such logs only for recovery. As the segment store keeps a copy of the written data to its cache, it flushes data out of the cache to tiered storage, called <em>long-term storage </em>(LTS), asynchronously.</p>
<p>BookKeeper splits its storage among journal, entry logger, and index. The journal is an append-only data structure, and it is the only data structure critical for the write path. Entry loggers and indexes are used in the read path of BookKeeper. In Pravega, the BookKeeper read path is only exercised during the recovery of segment stores. Consequently, the capacity of the write path depends primarily on the journal and not the other data structures, setting aside any occasional interference they can induce.</p>
<h3>The Pravega read path</h3>
<p>An application reads events individually using instances of the <em>event stream reader</em>. Event stream readers form part of a reader group and internally coordinate the assignment of stream segments. Stream readers read from the assigned segments, and they pull segment data from the segment store. Each time a reader fetches segment data, it fetches as much as it is available, up to a maximum of 1MB.</p>
<p>The segment store always serves data from the cache. If it is a cache hit, then serving the read does not require an additional IO. Otherwise, the segment store fetches the data from LTS in blocks of 1MB, populates the cache, and responds to the client. The segment store does not serve reads reading data from the durable log.</p>
<h3>Pulsar and Kafka</h3>
<p>Both Pulsar and Kafka define themselves as streaming platforms. Pulsar implements a broker that builds on Apache BookKeeper. The broker builds on the abstraction of a managed ledger, which is an unbounded log comprising BookKeeper ledgers that are sequentially organized. BookKeeper is the primary data store of Pulsar, although it optionally enables as part of a recent feature to <a href="https://pulsar.apache.org/docs/en/concepts-tiered-storage/" target="_blank" rel="noopener">tier data to long-term storage</a>.</p>
<p>Pulsar exposes the topic abstraction, and enables topics to be partitioned. Pulsar producers produce messages to topics.&nbsp; It provides different options for receiving and consuming messages, such as different subscription modes and reading manually from topics.</p>
<p>Kafka also implements a broker and exposes partitioned topics. Kafka does not use an external storage dependency like Pravega and Pulsar; it relies on local broker storage as the primary storage of the system. There is a proposal for <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage" target="_blank" rel="noopener">adding tiered storage to Kafka in open-source</a>, but to our knowledge, it is only available as a <a href="https://www.confluent.io/blog/infinite-kafka-storage-in-confluent-platform/" target="_blank" rel="noopener">preview feature in the Confluent platform</a>. Consequently, we only compare tiered storage with Pulsar.</p>
<p>Both Pulsar and Kafka implement client batching, and enable the configuration of such batching. For both, two main parameters control client-side batching:</p>
<ul>
<li><strong>Maximum batch size</strong>: this is the maximum amount of data that the client is willing to accumulate for a single batch.</li>
<li><strong>Maximum wait time or linger</strong>: this is the maximum amount of time that the client is willing to wait to close a batch and submit it.</li>
</ul>
<p>There is an inherent trade-off between maximum batch size and waiting time: larger batches favor throughput in detriment of latency, whereas shorter waiting times have the opposite effect. If batches can be accumulated fast enough, then it is possible to obtain both high throughput and low …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/">https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/</a></em></p>]]>
            </description>
            <link>https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685835</guid>
            <pubDate>Mon, 05 Oct 2020 08:55:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying “make invalid states unrepresentable”]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 181 (<a href="https://news.ycombinator.com/item?id=24685772">thread link</a>) | @fanf2
<br/>
October 5, 2020 | https://kevinmahoney.co.uk/articles/applying-misu/ | <a href="https://web.archive.org/web/*/https://kevinmahoney.co.uk/articles/applying-misu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="applying-make-invalid-states-unrepresentable">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">02 October 2020</time></p>

<p>Here are some real life cases of applying one of my
<a href="https://kevinmahoney.co.uk/articles/my-principles-for-building-software/">favourite principles</a>.</p>

<p>I’ll try to update this as I come across good examples.</p>

<h2 id="case-1-contiguous-time-periods">Case 1: Contiguous Time Periods</h2>

<p>A straightforward way to represent a period of time is by its start
and end dates (<code>(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c1.png"></p>

<p>If we need to represent a timeline split in to contiguous periods, it
may be tempting to represent this as a sequence of periods (e.g. <code>List
(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c2.png"></p>

<p>However, with this representation there can be both gaps in the
timeline and overlapping periods:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c3.png"></p>

<h3 id="improved-representation">Improved Representation</h3>

<p>We can improve this representation so that the contiguous and
non-overlapping constraints always hold, and we can do this in a way
that may remind you of database normalisation - by removing
redundancy.</p>

<p>In a well formed contiguous timeline, the joint start/end
of the adjacent periods are redundant. Contiguous, non-overlapping
splits can simply be represented by a set of dates (<code>Set Date</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c4.png"></p>

<p>You can begin to see how this representation simplifies the system
when you consider how to make a further split in the timeline. In the
list representation, splitting a period requires carefully modifying
the data-structure and ensuring constraints aren’t violated. In the
‘set of dates’ representation you simply add a date to the set.</p>

<p>It is sometimes still useful to represent the periods as a sequence of
start and end dates. It is trivial to project the set of dates in to
this form. As long as the canonical representation is the set, the
constraints will still hold.</p>

<h2 id="case-2-default-contracts">Case 2: Default Contracts</h2>

<p>In this system, a customer pays us a recurring rent based upon a contract.
Contracts last for a fixed amount of time, and when they expire we fall back to
a ‘default contract’. The customer can have many fixed contracts, and can
sign new contracts at any time.</p>

<p>This was represented as:</p>
<ul>
  <li>A ‘customers’ table storing
    <ul>
      <li>The customer start date.</li>
      <li>An optional end date, should the customer leave.</li>
    </ul>
  </li>
  <li>A ‘contracts’ table storing
    <ul>
      <li>The contract start date.</li>
      <li>An optional end date, for default contracts that don’t end.</li>
      <li>If it was a ‘fixed’ or ‘default’ contract.</li>
    </ul>
  </li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f1.png"></p>
<p>Customer and contract timelines</p>

<p>This representation allows for some undesirable states that are trivial to prevent:</p>
<ul>
  <li>The customer may have gaps in their contracts.</li>
  <li>A fixed contract may not have an end date.</li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f2.png"></p>
<p>Contract gaps</p>

<p>To make matters worse, the API for these contracts allowed you to
modify each individual contract, fixed or default, without guarding against
these states. This shows how a poor choice of
representation propagates itself through the design of a system.</p>

<p>This poor choice was not just a theoretical problem -
gaps in contracts were found on more than one occasion, requiring
hours of engineering effort to hunt down and fix.</p>

<h3 id="improved-representation-1">Improved Representation</h3>

<p>This is easily improved by removing the ‘default’ contracts from the
contract table. If the customer doesn’t have a fixed contract, it is
assumed they are on a default contract:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f3.png"></p>
<p>Inferred default contracts</p>

<p>Now there can no longer be any gaps, and 
the end date of a contract no longer needs to be optional as it only represents fixed contracts.</p>

<p>It’s worth reiterating that this representation can be projected in to the previous
representation using a database view if that form is more convenient. What is
important is that the underlying representation enforces these constraints, it
is not important how you view the data.</p>

<p>As with the first case, a better representation makes the manipulation
of the data structure simpler. In this case, adding a new fixed contract is
greatly simplified. There is no need to create or modify default contracts, or ensure
that the contracts are contiguous.</p>

<h3 id="the-influence-of-object-oriented-thinking">The Influence of Object-Oriented Thinking</h3>

<p>If this improvement seems obvious to you, you may wonder how the
original design happened in the first place.</p>

<p>I think this happens because of atomistic, object-oriented thinking.</p>

<p>In this mindset, the fixed contracts are <em>objects</em>, the default contracts are
<em>objects</em>, and each of these concepts must be reified as a row in a table and
never inferred.
There is a distrust of using any features the database
offers beyond storing or retrieving <em>objects</em>.</p>

<p>This approach is antithetical to quality relational design and
the principle of making invalid states unrepresentable.</p>

<p>It may feel “simpler” on some level, as you don’t really need
to think about your design.
However, as we see here, this lack of forethought inevitably
leads to complexity.</p>

  </div>
</article></div>]]>
            </description>
            <link>https://kevinmahoney.co.uk/articles/applying-misu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685772</guid>
            <pubDate>Mon, 05 Oct 2020 08:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The End of Google?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24685505">thread link</a>) | @copypirate
<br/>
October 5, 2020 | https://seobutler.com/end-of-google/ | <a href="https://web.archive.org/web/*/https://seobutler.com/end-of-google/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				        	
<figure><img loading="lazy" width="1024" height="576" src="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-300x169.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-768x432.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1536x864.png 1536w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-600x338.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-300x169.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-768x432.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1536x864.png 1536w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-600x338.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image.png 1920w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Google, Facebook, Apple, Amazon…</p>



<p>Combined, the “Big 4” tech giants are <a target="_blank" href="https://www.businessinsider.com/most-valuable-tech-companies-total-worth-trillions-alphabet-stock-record-2020-1">worth over $5 trillion dollars.</a></p>



<p>Humans have a <a target="_blank" href="https://www.wsj.com/articles/grasping-giant-numbers-is-far-from-second-nature-1490952621">problem grasping giant numbers</a>, so to put that figure in perspective, it’s equal to the <a target="_blank" href="https://www.investopedia.com/insights/worlds-top-economies/">2019 GDP of Japan</a> — and almost a quarter that of the United States.</p>



<p>Despite being <a target="_blank" href="https://www.forbes.com/the-worlds-most-valuable-brands/#dd07f06119c0">the world’s second-most valuable company,</a> Google’s had a tough month.</p>



<p>The fact that <a target="_blank" href="https://www.nytimes.com/2020/09/24/technology/google-service-outage.html?">a brief service outage in the US</a> made <a target="_blank" href="https://www.the-sun.com/news/1530213/google-gmail-youtube-hangout-crashed-down/">front-page news worldwide</a> goes to show how dependent people have become on Google and its products…</p>



<p>But far more distressing to the C-Suite must be the news that US Attorney General William Barr is hellbent on bringing an <a target="_blank" href="https://www.nytimes.com/2020/09/22/technology/justice-dept-case-google-search-dominance.html">antitrust lawsuit against Google</a> before the election in November — and maybe as early as the beginning of October.</p>



<p>Barr’s Justice Department has set its sights square on Google’s dominance in search.</p>



<p>At the risk of biting the hand that feeds us, I’m going to take a look at what brought Google to this point — and some possible outcomes of the threats to Google’s monopoly on both search and digital advertising.</p>



<h2><strong>Antitrust and Technology</strong></h2>



<p>In the US, antitrust laws <a target="_blank" href="https://www.investopedia.com/terms/a/antitrust.asp">date back to the Sherman Act,</a> passed in the 1890s.</p>



<p>Antitrust regulations are designed to protect consumers from the adverse impact of one or less than a handful of companies having a monopoly on an essential product or service.</p>



<p>Monopolies represent a barrier to competition — and <a target="_blank" href="https://www.consumer.ftc.gov/sites/default/files/games/off-site/youarehere/pages/pdf/FTC-Competition_How-Comp-Works.pdf">competition is essential</a> in a free-market economy.</p>



<figure><img loading="lazy" width="945" height="630" src="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png 945w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-300x200.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-768x512.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-600x400.png 600w" sizes="(max-width: 945px) 100vw, 945px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png 945w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-300x200.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-768x512.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-600x400.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: </em><a target="_blank" href="https://www.thebalance.com/monopoly-4-reasons-it-s-bad-and-its-history-3305945"><em>The Balance</em></a><em>)</em></figcaption></figure>



<p>Some of the <a target="_blank" href="https://www.thebalance.com/monopoly-4-reasons-it-s-bad-and-its-history-3305945">commonly cited adverse effects</a> of a monopoly include price-fixing, inferior products and services, and the stifling of innovation.</p>



<p>The first antitrust lawsuits were brought against <a target="_blank" href="https://www.law.cornell.edu/supremecourt/text/274/693">International Harvester</a> and <a target="_blank" href="https://en.wikipedia.org/wiki/United_States_v._American_Tobacco_Co.">American Tobacco…</a></p>



<p>Apparently, both farm machinery and cigarettes were both viewed as essential at the turn of the twentieth century.</p>



<p>Antitrust laws are often used to prevent mergers between large companies that might harm consumers.</p>



<p>When oil giants Exxon and Mobil merged in the late 1990s, they were forced to sell 2,431 gas stations before the <a target="_blank" href="https://www.dividend.com/how-to-invest/5-major-antitrust-mergers/">$80.3 billion deal</a> was allowed to proceed.</p>



<p>Despite this divestiture, Exxon-Mobil was the world’s most valuable company until <a target="_blank" href="https://money.cnn.com/2012/01/25/markets/apple_stock/index.htm">Apple surpassed it in 2012.</a></p>



<p>Digital technology companies have had their fair share of skirmishes over monopoly and antitrust issues with the government, both in the US and around the world.</p>



<p>IBM faced <a target="_blank" href="https://en.wikipedia.org/wiki/History_of_IBM#Twentieth-century_market_power_and_antitrust">over 20 government and private antitrust actions</a> in the 20th century.</p>



<p>On the cusp of the 2000s, <a target="_blank" href="https://www.investopedia.com/ask/answers/08/microsoft-antitrust.asp">Microsoft was sued by the Department of Justice (DoJ)</a> and others to “determine whether the company’s bundling of additional programs into its operating system constituted monopolistic actions.”</p>



<p>These actions were partly a result of the <a target="_blank" href="https://thehistoryoftheweb.com/browser-wars/">“Browser Wars”</a> between Microsoft’s Internet Explorer and their now long-defunct competitor, Netscape.&nbsp;</p>



<p>Microsoft was accused of intentionally making it difficult for consumers to install software from competitors on Windows machines — and delete Microsoft’s bundled programs.</p>



<p>Microsoft <a target="_blank" href="https://www.theringer.com/tech/2018/5/18/17362452/microsoft-antitrust-lawsuit-netscape-internet-explorer-20-years">lost the case,</a> and the judge called for the company to split into two separate entities called <a target="_blank" href="https://www.investopedia.com/terms/b/babybills.asp">Baby Bills</a>, a reference to the “Baby Bells” created when the government broke up AT&amp;T in the 1980s.&nbsp;</p>



<p>The Windows OS side of Microsoft’s business was to become a separate corporate entity from the software side.</p>



<p>Ultimately, <a target="_blank" href="https://www.seattletimes.com/business/microsoft/long-antitrust-saga-ends-for-microsoft/">Microsoft settled with the US government</a>, and escaped being split up but it was forced to make <a target="_blank" href="https://www.justice.gov/atr/usdoj-antitrust-division-us-v-microsoft-corporation-information-settlement">significant concessions</a> that limited its anticompetitive tactics.</p>



<p>Many observers speculate that the antitrust lawsuits against Microsoft led to Bill Gates stepping down as CEO.</p>



<p>The lawsuits and settlement also fostered a more competitive environment that allowed fledgling startups like Google, Facebook, and Amazon to survive and thrive.&nbsp;</p>



<figure><img loading="lazy" src="https://seobutler.com/wp-content/uploads/2020/09/Sundar-Pichai-Congress.png" alt="" width="860" height="586" data-src="https://seobutler.com/wp-content/uploads/2020/09/Sundar-Pichai-Congress.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>8<strong>Google CEO Sundar Pichai Testifies Remotely to Congress, July 2020</strong><em> (Source: <a target="_blank" href="https://www.cnet.com/news/congress-zeroes-in-on-google-during-historic-tech-antitrust-hearing/">Cnet</a>)</em></figcaption></figure>



<h2><strong>Threats to Google’s Monopoly on Search and Digital Advertising</strong></h2>



<h3><strong>Antitrust in the US</strong></h3>



<p>Federal government concerns about Google’s dominance in both search and online advertising really began to pick up steam in summer 2019 when the Justice Department and Federal Trade Commission (FTC) <a target="_blank" href="https://www.nytimes.com/2020/09/22/technology/justice-dept-case-google-search-dominance.html?searchResultPosition=1">opened antitrust investigations</a> into all of the “Big Four” tech giants.</p>



<p>Additionally, <a target="_blank" href="https://www.theverge.com/2019/9/9/20857440/google-antitrust-investigation-attorneys-general-advertising-search">Google finds itself targeted for investigation by 50 state attorneys general</a> for its anticompetitive practices, particularly its dominant share of the digital advertising market.&nbsp;</p>



<p>Only California and Arizona declined to join the probe.</p>



<figure><img loading="lazy" src="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png" alt="" width="720" height="537" srcset="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png 560w, https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search-300x224.png 300w" sizes="(max-width: 720px) 100vw, 720px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png 560w, https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search-300x224.png 300w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>(<em>Source: <a target="_blank" href="https://www.geekwire.com/2019/amazon-gaining-google-search-advertising-market-share/">Geekwire</a></em>)</figcaption></figure>



<p>In 2019, Google accounted for a 31.6% market share of overall digital ad spending and a 73.1% share of search advertising.</p>



<p>Google’s dominance in search is even more staggering…</p>



<figure><img loading="lazy" width="1000" height="743" src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-600x446.png 600w" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-600x446.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><strong>Global Market Share of Search Engines</strong><em> (Source: <a target="_blank" href="https://www.statista.com/statistics/216573/worldwide-market-share-of-search-engines/">Statista</a>)</em></figcaption></figure>



<p>As of July 2020, Google held an 87% market share in desktop search — its nearest competitor, Bing, accounted for just over 6%.</p>



<p>This disparity has led critics of both major political parties, as well as President Donald Trump, to argue that Google needs to be more strictly regulated — or even split up into smaller entities.</p>



<p>There is precedent for breaking up monopolies in the United States.&nbsp;</p>



<p>In 1904, John D. Rockefeller’s Standard Oil controlled <a target="_blank" href="https://www.cnbc.com/2020/05/15/doj-and-state-ags-likely-to-file-antitrust-lawsuit-against-google-wsj.html">91% of oil production and 85% of oil sales in the US.</a></p>



<p>The Supreme Court ruled in 1911 that Standard Oil was in violation of federal antitrust laws and split the company up into 34 separate entities, including companies that became <a target="_blank" href="https://en.wikipedia.org/wiki/John_D._Rockefeller">ExxonMobil and Chevron.</a></p>



<p>In more recent history, <a target="_blank" href="https://www.investopedia.com/ask/answers/09/att-breakup-spinoff.asp">antitrust lawsuits filed in the early 1970s against AT&amp;T</a> — which operated a legal monopoly on local and long-distance telecommunications for almost a century — broke the company up into seven smaller entities known as <a target="_blank" href="https://www.investopedia.com/terms/b/babybells.asp">“Baby Bells.”</a></p>



<p>In addition to the DoJ and State’s attorney investigations into Google, all of the Big 4’s CEOs were recently summoned to appear remotely before Congress’s <a target="_blank" href="https://judiciary.house.gov/subcommittees/antitrust-commercial-and-administrative-law-116th-congress/">House Judiciary subcommittee on Antitrust.</a>&nbsp;</p>



<figure><img loading="lazy" src="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png" alt="" width="720" height="410" srcset="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png 782w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-300x171.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-768x438.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-600x342.png 600w" sizes="(max-width: 720px) 100vw, 720px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png 782w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-300x171.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-768x438.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-600x342.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><strong>Mark Zuckerburg, Jeff Bezos, Tim Cook, Sundar Pichai testify before Congress, July 2020</strong> <em>(Source: <a target="_blank" href="https://www.exchange4media.com/digital-news/us-congress-accuse-zuckerberg-bezos-cook-pichai-of-crippling-competitors-with-monopoly-106495.html">Exchange4Media</a>)</em></figcaption></figure>



<p>The subcommittee held the hearing after investigating the Big 4 for over a year.</p>



<p>In the current American political environment, where it often seems like Republicans and Democrats agree on practically nothing, the hearing was surprisingly bipartisan.</p>



<p>By many pundit’s accounts, <a target="_blank" href="https://www.cnet.com/news/congress-zeroes-in-on-google-during-historic-tech-antitrust-hearing/">Google’s Sundar Pichai faced the most intense scrutiny</a> by lawmakers during the <a target="_blank" href="https://youtu.be/T0gJYFX8WVc">almost 6-hour session.</a></p>



<p>Here are the elements of Google’s vast empire that are thought to be most vulnerable to punitive antitrust actions.</p>



<figure><img loading="lazy" width="1000" height="743" src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png" alt="Google Ad revenue" srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-600x446.png 600w" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-600x446.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: <a target="_blank" href="https://www.statista.com/statistics/266249/advertising-revenue-of-google/">Statista</a>)</em></figcaption></figure>



<h4>Advertising&nbsp;</h4>



<p>Not only does Google command a lopsided market share in both search advertising and digital advertising as a whole, but it also faces investigation because Google effectively owns and controls every aspect of the online marketplace for selling and purchasing advertising.</p>



<p>Google has achieved its advertising hegemony primarily through acquiring competitors, such as it’s <a target="_blank" href="https://www.wired.com/2008/03/google-seals-do/">2008 buyout of ad-tech firm DoubleClick.</a></p>



<p>Over <a target="_blank" href="https://www.statista.com/statistics/266249/advertising-revenue-of-google/">70% of Google’s revenue comes from advertising</a> — over $160 billion in 2019.</p>



<p>Any threat to this income stream could have devastating effects on the value of the company.</p>



<p>Investigators and competitors charge that allowing Google to have such complete control over digital advertising is harmful to competition and gives Google an unfair advantage.</p>



<h4>Content</h4>



<p>Content creators and publishers big and small were likely thrilled when Rep. David Cicilline, chairman of the antitrust subcommittee <a target="_blank" href="https://news.yahoo.com/why-does-google-steal-content-201052393.html">straight up asked Pichai,</a> “Why does Google steal content?”</p>



<p>Unsurprisingly, Pichai disagreed with the characterization, but Cicilline rejected his response.&nbsp;</p>



<p>Congress, he said, has “heard throughout this investigation that Google has stolen content to build your own business. These are consistent reports, and so your testimony that it doesn’t happen is really inconsistent with what we’ve learned during the course of the investigation.”</p>



<p>As Google continually finds new ways to answer search queries using third party content on its own platform, often without attribution or a link to the source, it seems likely that this strategy will come under growing scrutiny.</p>



<figure><img loading="lazy" width="1024" height="598" src="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png" alt="Google Search Antitrust" srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-300x175.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-768x448.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-600x350.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust.png 1252w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-300x175.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-768x448.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-600x350.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust.png 1252w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<h4>Search</h4>



<p>Google’s near-total dominance of search has led to numerous allegations of anticompetition practices — including favoring its own products above competitors in search results.</p>



<p>Founder’s tales of businesses being decimated by Google’s search manipulation and favoritism towards its own offerings abound online — such as <a target="_blank" href="https://www.usatoday.com/story/opinion/2020/02/14/googles-anti-competitive-practices-decimates-online-shopping-antitrust-column/4718626002/">this one</a> from the founder of comparison shopping site Kelkoo or this <a target="_blank" href="https://www.latimes.com/business/la-fi-google-search-favoritism-20150630-story.html">Harvard and Columbia study funded by Yelp.</a></p>



<p><a target="_blank" href="https://www.nytimes.com/2020/09/22/technology/justice-dept-case-google-search-dominance.html?">According to The New York Times</a>, the DoJ has narrowed its focus to search and may leave action on Google’s advertising practices to the state attorneys, <a target="_blank" href="https://www.reuters.com/article/us-google-doj-idUSKBN22R37I">led by Texas Attorney General, Ken Paxton.</a></p>



<p>Paxton says he has not ruled out any possible punishment, including breaking up the company.</p>



<p>By narrowing the focus to search, the DOJ hopes to have a stronger lawsuit that it can file in a more timely fashion.</p>



<p>The federal case is expected to largely drill down on Google’s agreements with Apple and other companies to have Google set as the default search engine on iPhones and other devices.&nbsp;</p>



<p>The DoJ will likely argue this an anti-competitive practice that puts other search engines at a significant disadvantage.</p>



<figure><img loading="lazy" width="1024" height="683" src="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-300x200.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-768x512.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1536x1025.jpg 1536w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-2048x1367.jpg 2048w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-600x400.jpg 600w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-300x200.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-768x512.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1536x1025.jpg 1536w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-2048x1367.jpg 2048w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-600x400.jpg 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: <a target="_blank" href="https://www.pexels.com/photo/black-google-smartphone-on-box-1482061/">Pexels</a>)</em></figcaption></figure>



<h4>Android</h4>



<p>One other possible vulnerability regulators might exploit is the ubiquity of Google’s Android mobile operating system.</p>



<p>Android is by far the most popular mobile OS globally, with a <a target="_blank" href="https://www.statista.com/statistics/272698/global-market-share-held-by-mobile-operating-systems-since-2009/">74.6% market share.</a></p>



<p><a target="_blank" href="https://www.reuters.com/article/us-tech-antitrust-google-idUSKBN1XO2UQ">Reports say that the state attorneys</a> are also investigating Android for antitrust violations.&nbsp;</p>



<p>The EU has already fined Google €4.34 billion for using Android “as a vehicle to cement the dominance of its search engine.”</p>



<figure><img loading="lazy" width="1024" height="535" src="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-300x157.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-768x402.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-600x314.jpg 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe.jpg 1050w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-300x157.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-768x402.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-600x314.jpg 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe.jpg 1050w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: </em><a target="_blank" href="https://www.nytimes.com/2015/04/16/business/international/european-union-google-antitrust-case.html"><em>NY Times</em></a><em>)</em></figcaption></figure>



<h2><strong>Taxation and Privacy Regulation in Europe</strong></h2>



<p>AG Barr’s antitrust campaign is far …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seobutler.com/end-of-google/">https://seobutler.com/end-of-google/</a></em></p>]]>
            </description>
            <link>https://seobutler.com/end-of-google/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685505</guid>
            <pubDate>Mon, 05 Oct 2020 07:49:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What you could steal from the Kakoune code editor, and get away with]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 93 (<a href="https://news.ycombinator.com/item?id=24685267">thread link</a>) | @todsacerdoti
<br/>
October 5, 2020 | https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
      <h2>What you could steal from the Kakoune code editor right now, and get away with it</h2>

<p><a href="https://kakoune.org/">Kakoune</a> is a (fairly) young modal code editor
that has matured for as long and as well as a good red wine. It places
multiple-selections, operability and interactivity at the heart of its
distinctive characteristics. It provides users with an efficient and
comfortable text editing experience — but that’s not what this article
is about.</p>

<p>Now 8 years old at the time of writing, Kakoune has gone through several
iterations that removed a dependency here, optimised a core feature there,
even factorised entire parts of its codebase! And as any long-term user
will tell you, it’s easy to take all that good stuff for granted.</p>

<p>So here it is. I’m stopping time for a couple minutes, and listing in
this article a few things that the Kakoune project does well in several
dimensions. Some are technical, but the rest should hopefully be easily
adaptable to other projects (whether they are code editors or not), and
generic enough to be adopted seamlessly.</p>

<p>Now why does the title of this piece mention stealing? Read on, that’s item
number one.</p>

<h2 id="from-its-licensing-model">From its licensing model</h2>

<p>If something doesn’t belong to anybody, is it stealing if you take it for
yourself? What if it belongs equally to everybody?</p>

<p>Fortunately we don’t need to solve that problem: Kakoune is a public domain
project. Which means that anyone is free to do anything they want with the
source code of the editor, no questions asked.</p>

<p>This has several advantages:</p>

<ul>
  <li>the tool can be shipped with any distribution or suite, regardless of
licensing</li>
  <li>users can modify the code (to fix bugs, add new features or tweak already
existing ones etc.) and publish it (or compiled binaries) without worrying
about attribution</li>
  <li>it lifts some weight of responsibility of the maintainer for the whole
project, which anyone can re-brand or heavily modify to their liking</li>
</ul>

<p>Users don’t like paying for tools, and when they are free and open-source,
I’d argue that they turn out to be more useful (with several iterations,
over time) in the end if they place no limits on what users are allowed to
do with the code.</p>

<p>I’m not in favour of abolishing licenses, I think it would be more
productive for everyone if specialised tools were in the public
domain. In fact, the Kakoune project <em>is</em> licensed, under the
<a href="https://choosealicense.com/licenses/unlicense/">terms</a> of the
<a href="https://unlicense.org/">UNLICENSE</a>, in order to avoid conflicts with
jurisdictions that don’t recognise the <em>public domain</em> model.</p>

<p>As for the small riddle above, that’s a tough one, bordering on the
philosophical, but since we’re talking about replicating data, we can easily
break out of that paradox: copying is not stealing.</p>

<h2 id="from-its-code">From its code</h2>

<p>New comers like to praise Kakoune for having a clean codebase, easy to
navigate and modify. And for good reason! Written in C++, the code uses the
smallest amount of bells and whistles possible to keep the code elegant,
compilable with (reasonably) old compiler versions, but more importantly
convenient.</p>

<p>And when it comes to convenience, Kakoune has some interesting assets your
project could benefit from:</p>

<ul>
  <li>a header-only implementation of a diffing algorithm
(<a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/diff.hh">diff.hh</a>)</li>
  <li>a regex engine mostly following the ECMA syntax — this implementation
allowed the project to drop
<a href="https://www.boost.org/doc/libs/1_74_0/libs/regex/doc/html/index.html">boost::regex</a>
as a dependency
(<a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/regex.hh">regex.hh</a>)</li>
  <li>a minimal JSON (un)marshaller
(<a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/json.hh">json.hh</a>)</li>
  <li>a custom hash map implementation
(<a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/hash_map.hh">hash_map.hh</a>)</li>
  <li>wrappers for string types (e.g. string view) and associated utilities:
join, wrap, split, quote, pad etc.
(<a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/string.hh">string.hh</a>
· <a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/string_utils.hh">string_utils.hh</a>)</li>
  <li>various functional range filters: filter, transform, gather, map etc.
(<a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/ranges.hh">ranges.hh</a>)</li>
  <li>an implementation of Go’s defer statement that runs code once the execution
flow leaves the current scope
(<a href="https://golang.org/ref/spec#Defer_statements">Go specification</a>
· <a href="https://github.com/mawww/kakoune/blob/v2020.09.01/src/utils.hh#L53">utils.hh</a>)</li>
</ul>

<p>The above snippets are not exactly drop-in, as they are still coupled to
custom types defined for the editor, but should nonetheless be adaptable
without much difficulty to other C++ projects.</p>

<h2 id="from-its-user-interface">From its user interface</h2>

<p>Originally an easter-egg that savvy users found out about by reading the
code that handles the terminal client’s user interface, the Clippy character
has become a mascot that is now enabled out of the box. However, although
it’s undeniable that nostalgia for Microsoft Office’s assistant has fuelled
prolonged interest in Clippy itself, the easter egg’s notoriety has cast a
shadow on the larger feature it’s a prisoner of: the auto-info pop up window.</p>

<p>The auto-info window is a big contributor to the general level of
interactivity the editor provide, as it pops up any time the user hits a
key in normal mode or has typed a function name in the command prompt. Its
purpose is to provide instant feedback to the user, communicate usage
information or possible options that are available to the user. Every time
I’m using a terminal program that lets me type commands but never hints
at what parameters they take, I sorely wished more people would steal that
from Kakoune!</p>

<p>Another command prompt related improvement that the editor proposes is
fuzzy matching: the user doesn’t need to type out letters that make up
the name of the command they need in order, which makes for much faster
completion selection, and increased discoverability.</p>

<p>All command names in Kakoune are WORDS that start with the name of the
functionality group they belong to. The examples below follow:</p>

<ul>
  <li>to figure out what commands interact with the buffer, typing <code>:buff</code>
would return candidates like <code>buffer-next</code>, <code>lint-buffer</code>,
<code>format-buffer</code>…</li>
  <li>to call the <code>lint-buffer</code> command, typing <code>:lb&lt;tab&gt;</code> would insert the
entire command name in the prompt</li>
</ul>

<p>Use Kakoune once, and you’ll wish your browser enabled fuzzy
matching in your history/bookmarks for the rest of your days. But
you might wonder: there are individual tools that handles
fuzzy-matching, like <a href="https://github.com/junegunn/fzf">fzf</a>,
<a href="https://github.com/kien/ctrlp.vim">ctrlp</a> or
<a href="https://github.com/jhawthorn/fzy">fzy</a>, what if the user would rather
use them to handle opening, for example, files? Great question! Read on,
that’s the next dimension I want you to steal from.</p>

<h2 id="from-its-philosophy">From its philosophy</h2>

<p>The UNIX philosophy states that tools should focus on doing one thing,
and do it well. The implications are that tools that implement too many
unrelated features end up providing users with an underwhelming experience
because they only allow so much granularity over their behaviour, and that
their maintainers are spread too thin to improve/fix them.</p>

<p>If we re-frame this into the context of text editing, editors should only
worry about exactly that — text editing. And Kakoune does its job as
a UNIX citizen brilliantly, but it also goes one step further: it allows
other tools to interact with it, via shell scripting.</p>

<p>Remember the case of spawning a third-party fuzzy matching program,
above? Without getting into details, in Kakoune you’d implement that by
spawning a new terminal (or pane/tab), which would run the program, and
its output would be interpreted by the editor. Users are free to run any
program they want, any terminal or multiplexer they prefer.</p>

<p>And the concept isn’t bound to terminal programs either, although they are
probably the type of tools that Kakoune users would intuitively want to
interact with, on account of the editor being one itself. For example, do
you want to edit a file using a graphical interface? Try the following:</p>

<div><div><pre><code>:edit %sh{zenity --file-selection}
</code></pre></div></div>

<p>If that doesn’t sound anything special, it means that it makes
sense. Unfortunately, the field of text editors on UNIX systems has over
the years turned into an archipelago, in which every editor aims at being an
island. Job management, shell, terminal emulation,&nbsp;window multiplexing…
Text editors have turned into closed ecosystems (or Integrated Development
Environments) that provide many (sometimes cardboard-looking) features
unrelated to editing, which new comers have to buy into, or be left out in
the cold.</p>

<p>So here’s an idea everybody should not feel guilty about stealing, if
applicable to their projects: don’t re-invent the wheel, we have enough
bad imitations already<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> — instead, work on ways to make your tools
interface with others more easily!</p>

<p>If you have comments or questions, feel free to drop by the official IRC
channel: #kakoune @ FreeNode.</p>




<p>
    — written by

    

    <a href="https://github.com/lenormf">

    

        Frank Lenormand
    </a>

    · <time datetime="2020-10-01T00:00:00+00:00">
        <i>1st October 2020</i>
    </time>

    · license <strong>CC BY-SA 4.0</strong>
</p>


      
    </div></div>]]>
            </description>
            <link>https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685267</guid>
            <pubDate>Mon, 05 Oct 2020 07:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Principles of Data Oriented Programming]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24684638">thread link</a>) | @viebel
<br/>
October 4, 2020 | https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show | <a href="https://web.archive.org/web/*/https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  <div itemprop="articleBody">
    <div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
<p>This chapter is an attempt to illustrate what are the core principles of Data Oriented Programming as I understand them.
It is highly influenced by my programming experience in Clojure, but I believe that those principles are language agnostic.</p>
<p>One could adhere to them in an Object Oriented (OO) language like Java or C# and one could break them
in a Functional Programming (FP) language like Ocaml, Haskell, JavaScript (or even in Clojure).</p>
<p>In fact, in this chapter, I am going to illustrate how those principles could be applied or broken
in JavaScript, a programming language that supports both FP and OOP.</p>
<p>The principles of Data Oriented (DO) Programming are:</p>

<p>Each principle is explored in a separate article.</p>

<p>Enjoy!</p>
<div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
  </div>

</article><p>
  If you enjoy this kind of interactive articles would you consider a (small) donation💸  on <a href="https://www.patreon.com/bePatron?u=18227864">Patreon</a> or at least giving a star⭐ for the Klispe repo on <a href="https://github.com/viebel/klipse/stargazers"> Github</a>?
</p></div>]]>
            </description>
            <link>https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show</link>
            <guid isPermaLink="false">hacker-news-small-sites-24684638</guid>
            <pubDate>Mon, 05 Oct 2020 04:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking static website hosting providers]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24683403">thread link</a>) | @rencire
<br/>
October 4, 2020 | https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/ | <a href="https://web.archive.org/web/*/https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Static websites are still a hot topic. They are fast, and they’re incredibly secure because there isn’t a CMS to hack. Once you build a static website, however, the question becomes: Where do I host?</p>

<p>In other words: what is the fastest static website hosting provider in 2020? Well, let’s find out!</p>

<!--more-->

<p>I did <a href="https://www.savjee.be/2017/10/Static-website-hosting-who-is-fastest/">a similar test in 2017</a>, so it will be curious to see if the hosting providers have been improving.</p>

<h2 id="test-setup">Test setup</h2>
<p>Just like in 2017, I created a simple webpage that I could host on many services. I opted to use my own homepage, including all the images, CSS, and JS files. I then uploaded these files to the following hosting providers:</p>

<ul>
  <li>
<strong>Pay-as-you-go</strong>
    <ul>
      <li>
<a href="https://aws.amazon.com/s3/" target="_blank" data-no-instant="data-no-instant">AWS S3</a> (Region: <code>eu-west-1</code>, Ireland)</li>
      <li><a href="https://aws.amazon.com/cloudfront/" target="_blank" data-no-instant="data-no-instant">AWS CloudFront</a></li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (regional bucket, <code>europe-west1</code>, Belgium)</li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (multi-region bucket)</li>
      <li>
<a href="https://workers.cloudflare.com/sites" target="_blank" data-no-instant="data-no-instant">Cloudflare Workers Sites</a> ($5/month)</li>
    </ul>
  </li>
  <li>
<strong>Freemium (some parts free)</strong>
    <ul>
      <li><a href="https://firebase.google.com/docs/hosting" target="_blank" data-no-instant="data-no-instant">Firebase Hosting</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Cloudflare CDN</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Netlify</a></li>
    </ul>
  </li>
  <li>
<strong>Free</strong>
    <ul>
      <li><a href="https://pages.github.com/" target="_blank" data-no-instant="data-no-instant">GitHub Pages</a></li>
    </ul>
  </li>
</ul>

<p><em>Quick note</em>: I did not test Microsoft Azure, because I couldn’t sign up for it with my <a href="https://revolut.com/referral/xavierh5x" target="_blank" data-no-instant="data-no-instant">Revolut Visa card</a>. Thanks, Microsoft!</p>

<p>To check the performance, I used Pingdom and <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>. Pingdom measures uptime and response times from <a href="https://my.pingdom.com/probes/feed" target="_blank" data-no-instant="data-no-instant">their worldwide network of probe servers</a> while Oh Dear is located in a single location.</p>

<p>Some other things to keep in mind:</p>

<ul>
  <li>I tested the HTTPS endpoints for all services</li>
  <li>I added <code>index.html</code> to all URL’s, meaning no time wasted resolving the index document</li>
  <li>The services were probed <strong>once every minute</strong> for <strong>10 days</strong>
</li>
  <li>Oh Dear did not only track response times, but also DNS lookup time,  TCP connection time, content download time, and more. Pretty cool! All of the raw data is available at the end of this post.</li>
</ul>

<p><strong>Note:</strong> Pingdom or Oh Dear did NOT sponsor this blog post in any way! <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>, however, gave me a free trial with enough slots for all the test sites. Thanks a lot!</p>

<h2 id="expectations">Expectations</h2>
<p>My expectations are pretty much aligned to when I did this last time around:</p>

<ul>
  <li>I expect paid services to do better than free servers. There must be a reason for the prices they charge, right?</li>
  <li>Firebase and Google Cloud belong to the same company, so I expect them to perform similarly.</li>
  <li>I use CloudFront for my website, so hopefully they don’t come out as a bad option. Otherwise, there’s some additional homework for me ;)</li>
  <li>Netlify performed quite inconsistently last time around. With a few years passing, I hope they were able to address those issues.</li>
  <li>Last time, I didn’t have Cloudflare in the benchmark. I expect them to be a strong contender, given how popular they are and how many edge locations they have.</li>
</ul>

<h2 id="results">Results</h2>
<p>Here’s a screenshot from the Pingdom dashboard after 10 days of testing:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-overview.png" alt="Overview of the Pingdom dashboard">
<em>Overview of the Pingdom dashboard</em></p>

<p>At first glance, it seems that all services perform very consistently, with CloudFront, GitHub Pages, and Google Cloud, leading the pack. But let’s not jump to conclusions.</p>

<h3 id="uptime">Uptime</h3>
<p>Let’s start with uptime. All of these services had 100% uptime, except for Firebase. Pingdom detected 1 minute of downtime. One check returned, “Network is unreachable,” and the other returned “Invalid certificate.”</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-error-log.png" alt="Firebase downtime as reported by Pingdom">
<em>Firebase downtime as reported by Pingdom</em></p>

<p>This was not detected by Oh Dear, so I’m willing to give Firebase the benefit of the doubt and say that this was an issue on Pingdom’s side.</p>

<h3 id="response-times">Response times</h3>
<p>Let’s start with some basic statistics: the median, and average response time of each service (including standard deviation):</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times.png" alt="Median response times, measured by Pingdom">
<em>Median response times as reported by Pingdom</em></p>

<p>A few things might catch your attention:</p>

<ul>
  <li>CloudFront &amp; GitHub Pages are speedy and consistent. They have the lowest median, average, and deviation. Interesting because one is a paid service, while the other is completely free.</li>
  <li>AWS S3 is the slowest of them all (but performs consistently). It is kind of expected from a hosting provider that is located only in a single region (in this case Ireland, <code>eu-west-1</code>)</li>
  <li>Google Cloud’s regional and multi-regional buckets perform fairly alike. Interestingly, both are much faster than S3, which is a comparable service. Is Google doing some caching behind the scenes?</li>
  <li>I expected Cloudflare to be much more competitive with the top rankings, but somehow both their CDN and Workers aren’t the top performers. Their Workers product does, however, perform slightly better than their CDN.</li>
</ul>

<p>Since I used both Pingdom and Oh Dear, let’s check the difference in median response times:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-pingdom-oh-dear.png" alt="Pingdom vs Oh Dear (median response times)">
<em>Pingdom vs Oh Dear (median response times)</em></p>

<p>Interestingly, Oh Dear is reporting much faster response times compared to Pingdom. This is probably related to the fact that they only test from a single (apparently very well connected) location.</p>

<p>Pingdom is testing from various locations around the world, some of which aren’t as well connected, which increases the response times.</p>

<p>Some additional findings:</p>

<ul>
  <li>Somehow, AWS S3 is the fastest performer, even though the content is only hosted in a single location. It also outperformed Amazon’s CDN! Wherever Oh Dear is hosted, it must be somewhere in the EU with good connections to the Ireland region of AWS.</li>
  <li>The difference between CloudFront, S3, Firebase, GitHub Pages, and Google Cloud Storage is minimal. Once more, showing that free and paid services compete quite closely with one another.</li>
</ul>

<h3 id="time-to-first-byte">Time to first byte</h3>
<p>Oh Dear also kept track of other metrics like how long it took for the first bytes to start being transferred. This can give us an indication of how responsive the webserver is (how long does it need to think before being able to fulfill a request).</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-time-to-first-byte.png" alt="Time to first byte: measures responsiveness of web servers">
<em>Time to first byte: measures responsiveness of web servers</em></p>

<ul>
  <li>The “simple” storage services like S3 and Google Cloud Storage are doing very well.</li>
  <li>Once again, GitHub Pages, Firebase, and CloudFront are great performers, delivering the first byte in under 40ms.</li>
  <li>Surprisingly, Cloudflare is taking quite a while to start delivering the first bytes. Maybe this is due to all of their protection services?</li>
</ul>

<h3 id="compared-to-2017">Compared to 2017</h3>
<p>Comparing this new data with the one from 2017 reveals that not much has changed. Note that here I’m comparing the data from Pingdom:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-2017-vs-2020.png" alt="Benchmark from 2017 vs 2020: median response times">
<em>Benchmark from 2017 vs 2020: median response times</em></p>

<p>All providers (except GitHub Pages) have become slightly slower. Most noticeably AWS S3 (+13%) and Firebase (+31%). The others are so close to their 2017 performance that I would consider these differences to be in the margin of error.</p>

<p>Netlify has a slower median response time in 2020 compared to 2017. But it did improve massively on its consistency. Last time around, they had weird spikes in performance but not anymore. Nice!</p>

<p>This could be explained by Pingdom having added additional test servers located in areas that are further away from these providers.</p>

<h3 id="trying-to-find-edge-cases">Trying to find edge cases</h3>
<p>A scatter plot reveals that there aren’t many outliers, and no service is suffering from regular spikes in performance. There are some outliers here and there, but I wouldn’t look into them too much:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-scatter-response-times.png" alt="Scatter plot of all response times">
<em>Scatter plot of all response times</em></p>

<p>If we visualize the response times with a box plot, we see something interesting:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-boxplot-response-times.png" alt="Box plot of response times, showing some high spikes">
<em>Box plot of response times, showing some high spikes</em></p>

<p>All services, except for AWS, GitHub Pages, and Firebase, have weird spikes. Last time around, this was only limited to Netlify. Not sure what to make of these, but I’m guessing it’s more related to Pingdom’s tests than to the services themselves.</p>

<h2 id="conclusions">Conclusions</h2>
<p>Time to draw some conclusions:</p>

<p>The best all-around performer is <strong>AWS CloudFront</strong>, followed closely by <strong>GitHub Pages</strong>. Not only do they have the fastest response times (median), they’re also the most consistent.</p>

<p>They are, however, closely followed by Google Cloud Storage. Interestingly, there is very little difference between a regional and multi-regional bucket. The only reason to pick a multi-regional bucket would be the additional uptime guarantee.</p>

<p><strong>Cloudflare</strong> didn’t perform as well I would’ve expected. It’s certainly faster than a standard S3 bucket but falls away when compared to other CDN’s like CloudFront. Their Workers product is slightly faster than their CDN, but it’s hard to recommend it when it costs $5 a month, and free products like GitHub Pages perform better.</p>

<p>Netlify has improved big time; the spikes in performance are gone and performs in line with Google Cloud and Firebase hosting.</p>

<h2 id="which-should-you-choose">Which should you choose?</h2>
<p>If you want a fast website without breaking the bank, go for GitHub Pages. It’s completely free and super fast. It does, however, require you to open source your site.</p>

<p>If that’s not doable, CloudFront is a good alternative, but its price depends on how much bandwidth you push around. For most personal sites, CloudFront won’t cost more than a couple of dollars per month. The same thing goes for Google Cloud Storage.</p>

<p>Netlify and Firebase Hosting are pretty solid choices as well. While they don’t perform as well as CloudFront or GitHub Pages, they make up for it with excellent development tools. Everything works out-of-the-box with no configuration required on your end. Just push your website live with their easy to use CLI tools.</p>

<h2 id="download-the-data">Download the data</h2>
<p>The raw CSV data <a href="https://github.com/Savjee/static-website-hosting-benchmark" target="_blank" data-no-instant="data-no-instant">is available on GitHub</a>. Both of 2017 and 2020. Feel free to do your analysis and let me know if you find other interesting things in the dataset. Definitely check out the detailed statistics from Oh Dear!</p>

    </div></div>]]>
            </description>
            <link>https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683403</guid>
            <pubDate>Mon, 05 Oct 2020 00:24:13 GMT</pubDate>
        </item>
    </channel>
</rss>
