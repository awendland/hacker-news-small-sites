<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 20 Aug 2020 12:26:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 20 Aug 2020 12:26:26 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Architecture of the Nintendo DS]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24195751">thread link</a>) | @Polylactic_acid
<br/>
August 17, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graphics</h2><p>This section is a bit unusual because not only this console has multiple screens to draw, but also a combination of traditional tile engines working …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24195751</guid>
            <pubDate>Tue, 18 Aug 2020 06:06:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Made in India CSS]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24195745">thread link</a>) | @amitmerchant
<br/>
August 17, 2020 | https://nishantpainter.github.io/made-in-india-css/ | <a href="https://web.archive.org/web/*/https://nishantpainter.github.io/made-in-india-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="introduction">
      <div>
        <div>
          
          <p>
            Tricolor background patterns created using CSS linear and radial
            gradients.
          </p>
          <p><a href="https://nishantpainter.github.io/made-in-india-css/css/made-in-india.css" download="">
            Download CSS
          </a>
        </p></div>
      </div>
    </section></div>]]>
            </description>
            <link>https://nishantpainter.github.io/made-in-india-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24195745</guid>
            <pubDate>Tue, 18 Aug 2020 06:05:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ultraviolet Hubble Movie]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24195667">thread link</a>) | @simonebrunozzi
<br/>
August 17, 2020 | http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq.html | <a href="https://web.archive.org/web/*/http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
     
     <div>
   <p><a href="http://www.planetarylightshow.com/europa/prop_15424/v70-odr370khq-vmax7.html">|&lt;&lt;</a>  &nbsp;&nbsp;
   <a href="http://www.planetarylightshow.com/europa/prop_15424/v18-odr318dhq-vmax7.html">&lt;</a>  &nbsp;&nbsp;
   <a href="http://www.planetarylightshow.com/europa/prop_15424/v07-odr307jfq-vmax7.html">&gt;</a>  &nbsp;&nbsp;
   <a href="http://www.planetarylightshow.com/europa/prop_15424/v09-odr309cfq-vmax7.html">&gt;&gt;|</a> 
  
  
  &nbsp;&nbsp;&nbsp;<span title="Flux stretch maximum (cts/100s/pix)">Saturation level</span>:
    
    &nbsp;<em>7</em>
    
    &nbsp;<a href="http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq-vmax15.html">15</a> 
    
    &nbsp;<a href="http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq-vmax20.html">20</a> 
    
    &nbsp;<a href="http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq-vmax40.html">40</a> 
    
    &nbsp;<a href="http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq-vmax60.html">60</a> 
    
    &nbsp;<a href="http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq-vmax80.html">80</a> 
    
    &nbsp;<a href="http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq-vmax100.html">100</a> 
    
  
</p></div>
     
     <center>
     <p><img src="http://www.planetarylightshow.com/static/img/europa_15424_v16_odr316bcq_vmax7.gif" height="auto" width="85%">
     
     </p><br>
     
     <table>
         
             <tbody><tr>
             <td>target</td>
             <td>europa</td>
             </tr>
         
             <tr>
             <td>targname</td>
             <td>EUROPA-TRANSIT-16</td>
             </tr>
         
             <tr>
             <td>tardescr</td>
             <td>SATELLITE; Europa</td>
             </tr>
         
             <tr>
             <td>proposal</td>
             <td><a href="http://archive.stsci.edu/hst/search.php?sci_pep_id=15424&amp;sci_obset_id=%2A&amp;max_records=50000&amp;max_rpp=5000&amp;ordercolumn1=sci_start_time&amp;action=Search">15424</a></td>
             </tr>
         
             <tr>
             <td>obset</td>
             <td><a href="http://archive.stsci.edu/hst/search.php?sci_pep_id=15424&amp;sci_obset_id=16&amp;max_records=50000&amp;max_rpp=5000&amp;ordercolumn1=sci_start_time&amp;action=Search">16</a></td>
             </tr>
         
             <tr>
             <td>rootname</td>
             <td>ODR316BCQ</td>
             </tr>
         
             <tr>
             <td>start</td>
             <td>2019-06-15 02:05:27</td>
             </tr>
         
             <tr>
             <td>exptime</td>
             <td>2500.2</td>
             </tr>
         
             <tr>
             <td>obstype</td>
             <td>IMAGING</td>
             </tr>
         
             <tr>
             <td>opt_elem</td>
             <td>MIRFUV</td>
             </tr>
         
             <tr>
             <td>aperture</td>
             <td>F25SRF2</td>
             </tr>
         
             <tr>
             <td>distance (AU)</td>
             <td>4.28</td>
             </tr>
         
             <tr>
             <td>pixel scale (km/pix)</td>
             <td>75.974</td>
             </tr>
         
             <tr>
             <td>equatorial angular width (arcsec)</td>
             <td>1.006</td>
             </tr>
         
             <tr>
             <td>solar illumination %</td>
             <td>99.99</td>
             </tr>
         
             <tr>
             <td>Sun-Observer-Target angle (deg)</td>
             <td>175.16 trailing the sun</td>
             </tr>
         
             <tr>
             <td>Sun-&gt;Target-&gt;Observer angle (deg)</td>
             <td>0.92</td>
             </tr>
         
     </tbody></table></center><br>
   
   
   
   
   
   
   <center><p><a href="http://www.planetarylightshow.com/static/img/europa_odr316bcq_slew_correction.png">
   <img src="http://www.planetarylightshow.com/static/img/europa_odr316bcq_slew_correction.png">
   </a></p></center>
   
   
   
   <center><p><a href="http://www.planetarylightshow.com/static/img/multiframe_odr316bcq_vmax175.png">
   <img src="http://www.planetarylightshow.com/static/img/multiframe_odr316bcq_vmax175.png">
   </a></p></center>
   
   
   <div>
   <p><a href="http://www.planetarylightshow.com/europa/prop_15424/v70-odr370khq-vmax7.html#bottom">|&lt;&lt;</a>  &nbsp;&nbsp;
   <a href="http://www.planetarylightshow.com/europa/prop_15424/v18-odr318dhq-vmax7.html#bottom">&lt;</a>  &nbsp;&nbsp;
   <a href="http://www.planetarylightshow.com/europa/prop_15424/v07-odr307jfq-vmax7.html#bottom">&gt;</a>  &nbsp;&nbsp;
   <a href="http://www.planetarylightshow.com/europa/prop_15424/v09-odr309cfq-vmax7.html#bottom">&gt;&gt;|</a> 
</p></div>
   </div></div>]]>
            </description>
            <link>http://www.planetarylightshow.com/europa/prop_15424/v16-odr316bcq.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24195667</guid>
            <pubDate>Tue, 18 Aug 2020 05:46:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let’s Learn x86-64 Assembly: Part 0 – Setup and First Steps]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24195627">thread link</a>) | @nice_byte
<br/>
August 17, 2020 | https://gpfault.net/posts/asm-tut-0.txt.html | <a href="https://web.archive.org/web/*/https://gpfault.net/posts/asm-tut-0.txt.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
    <main role="main">

        
        
<p><img src="https://gpfault.net/assets/post-img/asm-tut-0/header.png">
</p>

<p>
The way I was taught x86 assembly at the university had been completely outdated for many years by the time I had my first class. It was around 2008 or 2009, and 64-bit processors had already started becoming a thing even in my neck of the woods. Meanwhile, we were doing DOS, real-mode, memory segmentation and all the other stuff from the bad old days.
</p>

<p>
Nevertheless, I picked up enough of it during the classes (and over the subsequent years) to be able to understand the stuff coming out of the other end of a compiler, and that has helped me a few times. However, I've never manually written any substantial amount of x86 assembly for something non-trivial. Due to being locked up inside (on account of a global pandemic), I decided to change that situation, to pass the time.
</p>

<p>
I wanted to focus on x86-64 specifically, and completely forget/skip any and all legacy crap that is no longer relevant for this architecture. After getting a bit deeper into it, I also decided to publish my notes in the form of tutorials on this blog since there seems to be a desire for this type of content.
</p>

<p>
Everything I write in these posts will be a normal, 64-bit, Windows program. We'll be using Windows because that is the OS I'm running on all of my non-work machines, and when you drop down to the level of writing assembly it starts becoming incresingly impossible to ignore the operating system you're running on. I will also try to go as "from scratch" as possible - no libraries, we're only allowed to call out to the operating system and that's it.
</p>

<p>
In this first, introductory part (yeah, I'm planning a series and I know I will regret this later), I will talk about the tools we will need, show how to use them, explain how I generally think about programming in assembly and show how to write what is perhaps the smallest viable Windows program.
</p>

<h2>Getting the Tools</h2>
<p>There are two main tools that we will use throughout this series.</p>

<h3>Assembler</h3>

<p>
CPUs execute machine code - an efficient representation of instructions for the processor that is almost completely impenetrable to humans. The assembly language is a human-readable representation of it. A program that converts this symbolic representation into machine code ready to be executed by a CPU is called an <b>assembler</b>.
</p>

<p>
There is no single, agreed-upon standard for x86-64 assembly language. There are many assemblers out there, and even though some of them share a great deal of similarities, each has its own set of features and quirks. It is therefore important which assembler you choose. In this series, we will be using 
<a href="http://flatassembler.net/">Flat Assembler</a> (or FASM for short). I like it because it's small, easy to obtain and use, has a nice macro system and comes with a handy little editor.</p>

<h3>Debugger</h3>

<p>
Another important tool is the debugger. We'll use it to examine the state of our programs. While I'm pretty sure it's possible to use Visual Studio's integrated debugger for this, I think a standalone debugger is better when all you want to do is look at the disassembly, memory and registers. I've always used <a href="http://ollydbg.de/">OllyDbg</a> for stuff like that, but unfortunately it does not have a 64-bit version. Therefore we will be using <a href="https://www.microsoft.com/en-us/p/windbg-preview/9pgjgd53tn86?activetab=pivot:overviewtab">WinDbg</a>. The version linked here is a revamp of this venerable tool with a slightly nicer interface. Alternatively, you can get the non-Windows-store version <a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/debugger-download-tools">here</a> as part of the Windows 10 SDK. Just make sure you deselect everything else besides WinDbg during installation. For our purposes, the two versions are mostly interchangeable.
</p>

<h2>Thinking in Assembly</h2>

<p>
Now that we have our tools, I want to spend a bit of time to discuss some basics. For the purpose of these tutorials I'm assuming some knowledge of languages like C or C++, but little or no previous exposure to assembly, therefore many readers will find this stuff familiar.
</p>
<h3>A 10000-foot view</h3>
<p>
CPUs only "know" how to do a fixed number of certain things. When you hear someone talk about an "instruction set", they're referring to the set of things a particular CPU has been designed to do, and the term "instruction" just means "one of the things a CPU can do". Most instructions are parameterized in one way or another, and they're generally really simple. Usually an instruction is somthing along the lines of "write a given 8-bit value to a given location in memory", or "interpreting the values from registers A and B as 16-bit signed integers, multiply them and record the result into register A".
</p>

<p>
Below is a simple mental model of the architecture that we'll start with.
</p>

<p><img src="https://gpfault.net/assets/post-img/asm-tut-0/diag0.png">
</p>

<p>
 This skips a <i>ton</i> of things (there can be more than one core executing instructions and reading/writing memory, there's different levels of cache, etc. etc.), but should serve as a good starting point.
</p>

<p>
 To be effective at low-level programming or debugging you need to understand that every high-level concept eventually maps to this low-level model, and learning how the mapping works will help you.
</p>

<h3>Registers</h3>
<p>
 You can think of <b>registers</b> as a special kind of memory built right into the CPU that is very small, but extremely fast to access. There are many different kinds of registers in x86-64, and for now we'll concern ourselves only with the so-called <i>general-purpose</i> registers, of which there are sixteen. Each of them is 64 bits wide, and for each of them the lower byte, word and double-word can be addressed individually (incidentally, 1 "word" = 2 bytes, 1 "double-word" = 4 bytes, in case you haven't heard this terminology before).
 </p>
 
 <table>
 <tbody><tr>
  <td><b>Register</b></td>
  <td><b>Lower byte</b></td>
  <td><b>Lower word</b></td>
  <td><b>Lower dword</b></td>
 </tr>
 <tr>
  <td>rax</td> <td>al</td> <td>ax</td> <td>eax</td>
 </tr>
 <tr>
  <td>rbx</td> <td>bl</td> <td>bx</td> <td>ebx</td>
 </tr>
 <tr>
  <td>rcx</td> <td>cl</td> <td>cx</td> <td>ecx</td>
 </tr>
 <tr>
  <td>rdx</td> <td>dl</td> <td>dx</td> <td>edx</td>
 </tr>
 <tr>
  <td>rsp</td> <td>spl</td> <td>sp</td> <td>esp</td>
 </tr>
 <tr>
  <td>rsi</td> <td>sil</td> <td>si</td> <td>esi</td>
 </tr>
 <tr>
  <td>rdi</td> <td>dil</td> <td>di</td> <td>edi</td>
 </tr>
 <tr>
  <td>rbp</td> <td>bpl</td> <td>bp</td> <td>ebp</td>
 </tr>
 <tr>
  <td>r8</td> <td>r8b</td> <td>r8w</td> <td>r8d</td>
 </tr>
 <tr>
  <td>r9</td> <td>r9b</td> <td>r9w</td> <td>r9d</td>
 </tr>
 <tr>
  <td>r10</td> <td>r10b</td> <td>r10w</td> <td>r10d</td>
 </tr>
 <tr>
  <td>r11</td> <td>r11b</td> <td>r11w</td> <td>r11d</td>
 </tr>
 <tr>
  <td>r12</td> <td>r12b</td> <td>r12w</td> <td>r12d</td>
 </tr> 
 <tr>
  <td>r13</td> <td>r13b</td> <td>r13w</td> <td>r13d</td>
 </tr> 
 <tr>
  <td>r14</td> <td>r14b</td> <td>r14w</td> <td>r14d</td>
 </tr> 
 <tr>
  <td>r15</td> <td>r15b</td> <td>r15w</td> <td>r15d</td>
 </tr>   
</tbody></table>  

<p>Additionally, the higher 8 bits of <code>rax</code>, <code>rbx</code>, <code>rcx</code> and <code>rdx</code> can be referred to as <code>ah</code>, <code>bh</code>, <code>ch</code> and <code>dh</code>.</p>

<p>
Note that even though I said those were "general-purpose" registers, some instructions can only be used with certain registers, and some registers have special meaning for certain instructions. In particular, <code>rsp</code> holds the stack pointer (which is used by instructions like <code>push</code>, <code>pop</code>, <code>call</code> and <code>ret</code>), and <code>rsi</code> and <code>rdi</code> serve as source and destination index for "string manipulation" instructions. Another example where certain registers get "special treatment" are the multiplication instructions, which require one of the multiplier values to be in the register <code>rax</code>, and write the result into the pair of registers <code>rax</code> and <code>rdx</code>.
</p>

<p>
In addition to these registers, we will also consider the special registers <code>rip</code> and <code>rflags</code>. <code>rip</code> holds the address of the next instruction to execute. It is modified by control flow instructions like <code>call</code> or <code>jmp</code>. <code>rflags</code> holds a bunch of binary flags indicating various aspects of the program's state, such as whether the result of the last arithmetic operation was less, equal or greater than zero. The behavior of many instructions depends on those flags, and many instructions update certain flags as part of their execution. The flags register can also be read and written "wholesale" using special instructions.
</p>

<p>
There are a lot more registers on x86-64. Most of them are used for SIMD or floating-point instructions, and we'll not be considering them in this series.
</p>

<h3>Memory and Addresses</h3>

<p>
You can think of memory as a large array of byte-sized "cells", numbered starting at 0. We'll call these numbers "memory addresses". Simple, right?
</p>
<p>
Well... addressing memory used to be rather annoying back in the old days. You see, registers in old x86 processors used to be only 16-bit wide. Sixteen bits is enough to address 64 kilobytes worth of memory, but not more. The hardware was actually capable of using addresses as wide as 20 bits, but you had put a "base" address into a special segment register, and instructions that read or wrote memory would use a 16-bit offset into that segment to obtain the final 20-bit "linear" address. There were separate segment registers for code, data and stack portions (and a few more "extra" ones), and segments could overlap. 
</p>
<p>
In x86-64 these concerns are non-existant. The segment registers for code, data and stack are still present, and they're loaded with some special values, but as a user-space programmer you needn't concern yourself with them. For all intents and purposes you can assume that all segments start at 0 and extend for the entire addressable length of memory. So, as far as we're concerned, on x86-64 our programs see memory as a "flat" contiguous array of bytes, with sequential addresses, starting at 0, just like we said in the beginning of this section...
</p>
<p>
Okay, I may have distorted the truth a little bit. Things aren't quite as simple. While it is true that on 64-bit Windows your programs see memory as a flat contiguous array of bytes with addresses starting at 0, it is actually an elaborate illusion maintained by the OS and CPU working together.
</p>
<p>
The truth is, if you were really able to read and write any byte in memory willy-nilly, you'd stomp all over other programs' code and data (something that indeed could happen in the Bad Old Days). To prevent that, special protection mechanisms exist. I won't get too deep into their inner workings here because this stuff matters mostly for OS developers. Nevertheless, here's a very short overview:
</p>
<p>
Each process gets a "flat" address space as described above (we'll call it the "virtual address space"). For each process, the OS sets up a <a href="https://wiki.osdev.org/Paging">mapping</a> between its virtual addresses and actual physical addresses in memory. This mapping is respected by the hardware: the "virtual" addresses get translated to physical addresses dynamically at runtime. Thus, the same address (e.g. 0x410F119C) can map to two different locations in physical memory for two different processes. This, in a nutshell, is how the separation between processes in enforced.
</p>

<p>
The final thing I want to invite your attention to here is how the instructions and data which they operate on are held in the same …</p></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gpfault.net/posts/asm-tut-0.txt.html">https://gpfault.net/posts/asm-tut-0.txt.html</a></em></p>]]>
            </description>
            <link>https://gpfault.net/posts/asm-tut-0.txt.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24195627</guid>
            <pubDate>Tue, 18 Aug 2020 05:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1-Euro Houses]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24195000">thread link</a>) | @Shinobuu
<br/>
August 17, 2020 | https://1eurohouses.com/case-a-1-euro-houses/ | <a href="https://web.archive.org/web/*/https://1eurohouses.com/case-a-1-euro-houses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div>
		<div id="primary">
		<main id="main" role="main">

		
			<article id="post-2882">
	<!-- .entry-header -->


	<div>
		
		<!-- Per Emanuele -->
		<p>This post is also available in: 
    <span><a href="https://casea1euro.it/case-a-1-euro/"><span lang="it">Italiano</span><span><span> (</span>Italian<span>)</span></span></a></span></p><h3>Become a homeowner by spending only 1 euro.</h3>
<p>It seems impossible, however, thanks to a particular initiative that is becoming more and more popular, this can become a reality. The project <strong>Case a 1 euro (1-euro houses)</strong> has sprung from a few Italian municipalities with the intent to counter the population outflow and to give a new birth to troubled areas.<br>
With this operation <strong>Case a 1 euro (1-euro houses)</strong> we try to repopulate gorgeous villages that are being deserted, with the young population leaving and the elderly slowly fading away.</p>
<p>This unprecedented proposal has struggled initially, but it’s gaining popularity in recent times. This long-term strategy is attractive for those who are looking for low-cost real estate investments in Italy, and to simply restore prestige to Italian villages famous all over the world for their extraordinary beauty, and for that vintage spirit so cherished nowadays.</p>
<p>[metaslider id=”207″]
</p><p>Additionally, the <strong>Project Case a 1 euro (1-euro houses)</strong> could positively shock to the Italian real estate market facilitating access to homes by young people, for whom it is becoming increasingly difficult to take out a mortgage.</p>
<p>Last but not least, the repopulation of these small villages also promotes tourist activities, regenerating the economy of the entire area. To enhance the tourism economy, it is possible to repurpose an old building as a boutique hotel, a B&amp;B, or even to create a bigger project involving multiple premises in the same village to create a scattered hotel.</p>
<p>In conclusion, there are many very interesting possibilities and implications.</p>
		
		</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

			
            
		
		</main><!-- #main -->
	</div><!-- #primary -->
	
	

	<!-- #secondary -->
</div>

	</div></div>]]>
            </description>
            <link>https://1eurohouses.com/case-a-1-euro-houses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24195000</guid>
            <pubDate>Tue, 18 Aug 2020 03:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building AGI Using Language Models]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24194407">thread link</a>) | @leogao
<br/>
August 17, 2020 | https://leogao.dev/2020/08/17/Building-AGI-Using-Language-Models/ | <a href="https://web.archive.org/web/*/https://leogao.dev/2020/08/17/Building-AGI-Using-Language-Models/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <!-- TOC -->
        
        <p><img src="https://leogao.dev/images/agi-lms/sunset1-glitch.png" alt=""></p>
<p><span>Despite the buzz around GPT-3, it is, in and of itself, not AGI.</span> In many ways, this makes it similar to AlphaGo or Deep Blue; while approaching human ability in one domain (playing Chess/Go, or writing <em>really</em> impressively), it doesn’t really seem like it will do <span><a href="https://wiki.lesswrong.com/wiki/Intelligence_explosion" target="_blank" rel="noopener">Scary AGI Things™</a></span> any more than AlphaGo is going to be turning the Earth into paperclips anytime soon. While its writings are impressive at emulating humans, GPT-3 (or any potential future GPT-x) has no memory of past interactions, nor is it able to follow goals or maximize utility. However, language modelling has one <em>crucial</em> difference from Chess or Go or image classification. Natural language essentially encodes information about the world—the <em>entire</em> world, not just the world of the Goban, in a much more expressive way than any other modality ever could.<sup><a href="#fn1" id="fnref1">[1]</a></sup> By harnessing the world model embedded in the language model, it may be possible to build a proto-AGI.</p>

<p>The explicit goal of a language model is only to <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" target="_blank" rel="noopener">maximize likelihood</a> of the model on natural language data. In the <a href="https://leogao.dev/2019/10/27/The-Difficulties-of-Text-Generation-with-Autoregressive-Language-Models/">autoregressive formulation</a> that GPT-3 uses, this means being able to predict the next word as well as possible. However, this objective places much more weight on large, text-scale differences like grammar and spelling than fine, subtle differences in semantic meaning and logical coherency, which reflect as very subtle shifts in distribution. Once the former are near-perfect, though, the only place left to keep improving is the latter.</p>
<p>At the extreme, any model whose loss reaches the <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" target="_blank" rel="noopener">Shannon entropy</a> of <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/1999-00/information-theory/entropy_of_english_9.html" target="_blank" rel="noopener">natural language</a>—the theoretical lowest loss a language model can possibly achieve, due to the inherent randomness of language—will be <em>completely indistinguishable</em> from writings by a real human in every way, and the closer we get to it, the more abstract the effect on quality of each bit of improvement in loss. Or, said differently, stringing words together using <a href="https://github.com/jsvine/markovify#markovify-in-the-wild" target="_blank" rel="noopener">Markov chain generators</a> gets you 50% of the way there, figuring out grammar gets you another 50% of the remaining distance, staying on topic across paragraphs gets you another 50% of the remaining distance, being logically consistent gets you another 50% of the remaining distance, and so on.<sup><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p><span><span><span><math><semantics><mrow><mtable><mtr><mtd><mrow><mi>H</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>=</mo><mo>−</mo><mi mathvariant="double-struck">E</mi><mo>[</mo><mi>log</mi><mi mathvariant="double-struck">P</mi><mo>(</mo><mi>X</mi><mo>)</mo><mo>]</mo><mo>=</mo><mo>−</mo><msub><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi></mrow></msub><msub><mi>f</mi><mi>X</mi></msub><mo>(</mo><mi>x</mi><mo>)</mo><mi>log</mi><msub><mi>f</mi><mi>X</mi></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex">\begin{aligned}
H(X) = -\mathbb E[\log \mathbb P(X)] = -\sum_{x \in \Omega} f_X(x) \log f_X(x)
\end{aligned}</annotation></semantics></math></span></span></span></p><p><span>Shannon Entropy: the number of bits necessary, on average to specify one piece of text.</span></p>
<p>Why? Because if you have a coherent-but-not-logically consistent model, becoming more logically consistent helps you predict language better. Having a model of human behavior helps you predict language better. Having a model of the world helps you predict language better. As the low-hanging fruits of grammar and basic logical coherence are taken, the only place left for the model to keep improving the loss is a world model. Predicting text is <a href="http://mattmahoney.net/dc/rationale.html" target="_blank" rel="noopener">equivalent to AI</a>.</p>
<p>The thing about GPT-3 that <a href="https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">makes it so important</a> is that it provides evidence that as long as we keep increasing the model size, we can keep driving down the loss, <a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener">possibly right up until</a> it hits the Shannon entropy of text. No need for clever architectures or complex handcrafted heuristics. Just by scaling it up we can get a better language model, and a better language model entails a better world model.</p>
<p>But how do we use this language model if it’s buried implicitly-represented inside GPT-x, though? Well, we can literally just <em>ask</em> it, in natural language, what it thinks will happen next given a sequence of events, and its output distribution will approximate the distribution of what the average human thinks would happen next after those events. Great—we’ve got ourselves a usable world model.</p>
<p>“But wait!” you say, “<a href="https://aiweirdness.com/post/621186154843324416/all-your-questions-answered" target="_blank" rel="noopener">Various</a> <a href="https://twitter.com/eigenrobot/status/1284042570507542528" target="_blank" rel="noopener">experiments</a> have shown that GPT-3 often fails at world modelling, and just conjecturing that adding more parameters will fix the problem is a <em>massive</em> leap!” If you’re thinking this, you’re absolutely correct. The biggest and most likely to be wrong assumption that I’m making is that larger models will develop better world models. Since as loss approaches the Shannon entropy its world modelling ability has to become about as good than the average human on the internet<sup><a href="#fn3" id="fnref3">[3]</a></sup>, this boils down to two questions: “Will we really make models whose loss gets close enough to the Shannon entropy?” and “How close is close enough, in order to have the world modelling capabilities to make all this practical?”</p>
<p><img src="https://leogao.dev/images/gpt3/perf_scaling_compute.png" alt="Loss keeps going down with more parameters and compute. (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The answer to the first question is “most likely”—that’s the <a href="https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">main takeaway of GPT-3</a>. The answer to the second question is… nobody knows. Some have demonstrated <a href="https://news.ycombinator.com/item?id=23990902" target="_blank" rel="noopener">ways of making GPT-3 better at world modelling</a>, but this alone is probably not sufficient. When models with 1 trillion, then 10 trillion, then 100 trillion parameters become available, we will have empirical evidence to see whether this assumption is correct. If GPT-x demonstrates uncanny ability to predict outcomes in the real world, then this just might work.</p>

<p>A world model alone does not an agent make, though.<sup><a href="#fn4" id="fnref4">[4]</a></sup> So what does it take to make a world model into an agent? Well, first off we need a goal, such as <a href="https://wiki.lesswrong.com/wiki/Paperclip_maximizer" target="_blank" rel="noopener">“maximize number of paperclips”</a>. Then, we just ask the world model “What action can I take to maximize the number of paperclips I have?” Simple, right? Actually, not quite. The problem is that our world model probably won’t be able to consider all the possible things that could happen next well enough to make a reasonable answer.</p>
<p><img src="https://leogao.dev/images/agi-lms/mesa.png" alt="GPT-3 considers mesa-optimization. (Source: OpenAI API)"></p>
<p>So what can we do instead? Well, asking the world model for a list of things you could do in a given world state would probably not be outside the capabilities of a sufficiently powerful language model (think: “I am in situation <span>xyz</span>. Here is a list of things I could do:”). Similarly, asking the world model how much reward you’d get in some hypothetical world where you took a sequence of actions would probably be possible too—imagine asking something along the lines of “I go to ebay. I look up paperclips, sorted by price ascending. I spend $100 on the first item on the list. How many paperclips will I have?”<sup><a href="#fn5" id="fnref5">[5]</a></sup> This will let us figure out what actions the agent can take in any given step (policy function), as well as how much reward each sequence of steps will net the agent (value function).</p>
<p>So now, to estimate the state-action value of any action, we can simply do <a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search" target="_blank" rel="noopener">Monte Carlo Tree Search</a> to estimate the state-action values! Starting from a given agent state, we can roll out sequences of actions using the world model. By integrating over all rollouts, we can know how much future expected reward the agent can expect to get for each action it considers. Then, we can simply use, for example, a greedy policy with that state-action value function, to decide on actions to take.</p>
<p><img src="https://leogao.dev/images/agi-lms/mcts.png" alt="Monte Carlo Tree Search visualized (<a href='https://www.researchgate.net/figure/Phases-of-the-Monte-Carlo-tree-search-algorithm-A-search-tree-rooted-at-the-current_fig1_312172859'>Source</a>)"></p>
<p>Each of these actions is likely to be very high level, such as “figure out the cheapest way to buy paperclips”, but thanks to the flexibility of language we can describe very complex ideas with short sequences of tokens. To actually execute these abstract actions once the agent decides on an action, that action can be broken down using the language model into smaller sub-goals such as “figure out the cheapest paperclips on Amazon”, similar to <a href="https://papers.nips.cc/paper/6233-hierarchical-deep-reinforcement-learning-integrating-temporal-abstraction-and-intrinsic-motivation.pdf" target="_blank" rel="noopener">Hierarchical Reinforcement Learning</a>. Possibly even just breaking actions down into a detailed list of instructions would be feasible, depending on the capabilities of the model and how abstract the actions are.</p>
<p>We can represent the agent state as natural language, too. Since the agent state is just a compressed representation of the observations, we can ask the language model to summarize the important information of any observations for its own internal world state. The language model could be used to periodically prune (i.e forget) the information inside its state, too, to make room for more observations.</p>
<p>Altogether, this gets us a system where we can pass observations from the outside world in, spend some time thinking about what to do, and output an action in natural language.</p>
<p>To handle input, you could have an input module that turns various modalities of observations into summarized text with respect to the current agent state. For instance, you could use something like <a href="https://openai.com/blog/image-gpt/" target="_blank" rel="noopener">iGPT</a> to input camera images or screenshots, or raw HTML from webpages that the agent requests. How exactly this is done is tangential to the point; all that matters is that somehow the inputs are all converted to text and added to the agent state. The examples I have provided are just to convince you that it’s absolutely not insurmountable.</p>
<p>Finally, to get the model to actually act in the world, you could again use the language model to translate natural language into <a href="https://www.pscp.tv/Microsoft/1OyKAYWPRrWKb?t=29m19s" target="_blank" rel="noopener">code that is then executed</a>, or <a href="https://vimeo.com/427943407/98fe5258a7" target="_blank" rel="noopener">shell commands</a>, or sequences of keypresses, or any of a number of other possible ways. Like input, there are an infinitude of different ways to solve the output problem, and which one turns out to be the best is entirely irrelevant to our discussion; all that matters is that it’s possible to get various modalities in and out of the text-only agent.<sup><a href="#fn6" id="fnref6">[6]</a></sup></p>
<p><img src="https://leogao.dev/images/agi-lms/paperclipsamzn.png" alt="An example of an input module taking a screenshot input combined with the current agent state to give an observation with the information needed by the agent."></p>

<p>This is more a thought experiment than something that’s actually going to happen tomorrow; GPT-3 today just isn’t good enough at world modelling. Also, this method depends heavily on at least one major assumption—that bigger future models will have much better world modelling capabilities—and a bunch of other smaller implicit assumptions. <strong><span>However</span></strong>, this might be the closest thing we ever get to a chance to <a href="https://intelligence.org/2017/10/13/fire-alarm/" target="_blank" rel="noopener">sound the fire alarm</a> for AGI: there’s now a concrete path to proto-AGI that has a non-negligible chance of working.</p>
<p><em>Thanks to <a href="https://twitter.com/zitterbewegung" target="_blank" rel="noopener">zitterbewegung</a>, <a href="https://twitter.com/realmeatyhuman" target="_blank" rel="noopener">realmeatyhuman</a>, and <a href="https://twitter.com/theshawwn" target="_blank" rel="noopener">Shawn Presser</a> for taking the time to provide feedback on the draft of this blog post!</em></p>
<!--[^toolai]: One common line of argument is that such "tool AIs" are good enough and have desirable safety properties, and therefore agentistic AI need not ever be developed. One argument against this idea is that [agent AI will inevitably be more economically valuable than tool AI](https://www.gwern.net/Tool-AI), which would encourage their development.-->
<!--

Going from a model that just strings uniformly chosen words together to a simple [Markov chain generator](https://github.com/jsvine/markovify#markovify-in-the-wild) makes a *massive* difference, but the loss difference between a Markov chain generator and GPT-2 is much smaller despite GPT-2 being able to manage grammatically correct sentences nearly all of the time, and the loss difference between GPT-2 and GPT-3 is smaller still, despite massive subjective improvements in quality. 

The difference between "the quick brown fox jumps over the lazy dog" and "shxixpgozcvoomz jcxfgabsdcxfrevogjsqewdnmkj" is *massive*, but the difference between "the quick brown fox jumps over the lazy dog" and "the quick brown fox jumps over the lazy dog"

Going from a model that just strings uniformly chosen words together to a model that uses words in the same [Zipf distribution](https://en.wikipedia.org/wiki/Zipf%27s_law) as regular text earns a large decrease in loss, because if you always pick common words like "the" you have a much better chance of being right than picking rare words. Another big decrease comes from considering n-gram frequencies rather than just single-word frequencies; this is the driving idea behind [Markov chain generators](https://github.com/jsvine/markovify#markovify-in-the-wild), which generate surprisingly good text considering how just how simple they are. Now, these 

-->
<hr>
<section>
<ol>
<li id="fn1"><p>Images aren’t nearly as good as text for encoding unambiguous, complex ideas, unless you put text <em>in</em> images, but at that point that’s just language modelling with extra steps. Also, images <em>can</em> encode complex ideas, but in a much less information-dense manner; I have no doubt that a sufficiently large image model could also learn such information about the world through …</p></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leogao.dev/2020/08/17/Building-AGI-Using-Language-Models/">https://leogao.dev/2020/08/17/Building-AGI-Using-Language-Models/</a></em></p>]]>
            </description>
            <link>https://leogao.dev/2020/08/17/Building-AGI-Using-Language-Models/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24194407</guid>
            <pubDate>Tue, 18 Aug 2020 01:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interview with Simon Kelley, the author of dnsmasq]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24193836">thread link</a>) | @apsec112
<br/>
August 17, 2020 | https://joshuakugler.com/an-interview-with-simon-kelley-the-author-of-dnsmasq.html | <a href="https://web.archive.org/web/*/https://joshuakugler.com/an-interview-with-simon-kelley-the-author-of-dnsmasq.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p><em>This is the first in what will, hopefully, become a series. I would like to highlight projects that are widely used, even to the point of being part of critical infrastructure, but are nevertheless small projects with small (often unsponsored) development teams. We start the series talking to Simon&nbsp;Kelley.</em></p>
<p>dnsmasq is one of the unsung heroes of the Internet: a small piece of software used very widely, but with a <em>very</em> small development team, and no corporate backing. It is used as the <span>DHCP</span> and caching <span>DNS</span> server on a wide variety of home-market routers, as well as other devices, and is the default <span>DHCP</span> and <span>DNS</span> caching server for libvirt, and by extension, OpenStack. A couple years ago, I contacted Simon Kelley, the author of dnsmasq, and asked if he was up for an interview. He was, but my blog wasn’t in a maintainable position at that point, so it got pushed back. I contacted him again recently, and we managed to make it happen. This interview was conducted via e-mail on December 10,&nbsp;2017.</p>

<p>Simon, thank you for taking time out of your schedule (when you could be
programming) to answer my questions. This is quite an honor, and I hope you
enjoy the&nbsp;questions.</p>
<p>What itch were you scratching, that is, what was your original need and
intention for&nbsp;dnsmasq?</p>
<blockquote>
<p>Long ago, around the turn of the century, I had a <span>PC</span>, running Linux, and
a net connection via a dial-up modem. If the <span>PC</span> was not connected to the
net then Netscape navigator would return an error immediately, because
the <span>UDP</span> packet doing a <span>DNS</span> query got a “no route to host” error. Then I
got a second-hand 486 laptop, and discovered that I could connect
that to my <span>PC</span> and give it a net connection too, using this amazing thing
called ip-masquerading (what later became <span>NAT</span>.) But when the Netscape on the
laptop would send the <span>UDP</span> <span>DNS</span> query to the <span>ISP</span>, it would get to the
desktop, where it would evaporate, and Netscape would hang (it was
single-threaded, at least in the <span>DNS</span> code) for a long time-out. I wanted
to fix that annoying behaviour. The <span>IP</span>-masquerade use is where the
DNSmasq name came&nbsp;from.</p>
</blockquote>
<p>Did you intend to release it as open source from the&nbsp;beginning?</p>
<blockquote>
<p>To the extent that I intended to release it,&nbsp;yes.</p>
</blockquote>
<p>How much did you know about <span>DNS</span> and <span>DHCP</span> when you&nbsp;started?</p>
<blockquote>
<p>Almost nothing, about the internals anyway. I started with <span>RFC</span> 1035 and
went from&nbsp;there.</p>
</blockquote>
<p>What is the most interesting bug you’ve run&nbsp;into?</p>
<blockquote>
<p>Not one of mine - I found a Linux kernel bug once, in the <span>API</span> to control
the <span>ARP</span> cache. The bug was long-ago fixed, but in a sense, the
work-around still persists in dnsmasq. It was difficult to find because
it was intermittent and hard to reproduce, and it took a long time to
consider that the problem may not have been mine, but in the&nbsp;Kernel.</p>
</blockquote>
<p>Related: when fixing a bug (found by you or reported), what has been your
most “What was I thinking when I wrote that”&nbsp;moment?</p>
<blockquote>
<p>Plenty of those. I once found a “&amp;” versus “&amp;&amp;” confusion which nobody
had spotted as a functional error, by code&nbsp;inspection.</p>
</blockquote>
<p>Have you ever found bugs in other <span>DHCP</span> and <span>DNS</span> products/libraries as a
result of your testing? What was the most interesting one? Feel free to share
others, if you&nbsp;wish.</p>
<blockquote>
<p>There are lots of <span>DHCP</span> clients in things like printers and scanners and
general IoT devices which behave badly and need workarounds. Intel
produced some awful bugs in <span>PXE</span> implementations which went into netboot
<span>ROMS</span> and never got&nbsp;updated.</p>
</blockquote>
<p>What was your most “you’ve got to be kidding me” moment when learning new
corners of <span>DHCP</span> and <span>DNS</span> and/or your biggest “I wish I had known that when I
started”&nbsp;moment?</p>
<blockquote>
<p>It’s always amused me that the format of a <span>DNS</span> packet - which is very
size constrained to fit into <span>UDP</span> packets, wastes 16 bits for a count of
the number of questions in a query. This has been constrained to be
exactly one for all of the life of <span>DNS</span>, so the 16 bits are completely
wasted. <span>DNS</span> in general is an amazingly under-specified and obscure area.
It’s been around forever, and is developed by people who have been
around for a long time and grown up with it. They tend to vastly
underestimate how much implied knowledge they are assuming when writing
RFCs. As for what I wished I’d known: I wished I’d found the <span>RFC</span> which
is an errata  to the original three <span>DNSSEC</span> RFCs earlier; I found several
of the bugs the hard&nbsp;way.</p>
</blockquote>
<p>What was your reaction when you found out dnsmasq was used as the default
forwarder/<span>DHCP</span> server for OpenStack? What is it like having your project used
in one the most well known open source projects in the&nbsp;world?</p>
<blockquote>
<p>That happened after dnsmasq was incorporated into Android, so it was
sort of an anti-climax after getting into the majority of smart phones on
the&nbsp;planet.</p>
</blockquote>
<p>[ed. note: point&nbsp;taken]</p>
<p>Besides OpenStack, what are some of the most interesting use cases you’ve
heard about for&nbsp;dnsmasq?</p>
<blockquote>
<p>I took some patches from someone who was providing satellite Internet to
trans-oceanic sailors. Bandwidth costs were high enough that it made
sense to audit almost every byte sent and received, including for <span>DNS</span>&nbsp;resolution.</p>
</blockquote>
<p>Have you ever gotten contributions (code or otherwise) back from router
manufacturers that have used&nbsp;dnsmasq?</p>
<blockquote>
<p>Probably, but I don’t remember anything significant in terms of code.
Comcast paid for a year of my time to implement <span>DNSSEC</span>, which was pretty
good of&nbsp;them.</p>
</blockquote>
<p>What kind of contributions have you turned&nbsp;down?</p>
<blockquote>
<p>That’s people who make a patch to solve their particular problem and
don’t give any thought to making it general, or generally&nbsp;useful.</p>
</blockquote>
<p>Could you talk about one significant or difficult contribution you turned down
and why? - From my co-worker <a href="https://twitter.com/eduncan911">Eric Duncan&nbsp;@eduncan911</a></p>
<blockquote>
<p>The one that’s happened over and over again is to change the behaviour
on receiving a “no-such-domain” reply from an upstream nameserver.
People want to implement local <span>DNS</span> hacks by getting dnsmasq to keep
trying another upstream server when the first returns <span>NXDOMAIN</span>, but
that’s always seemed to me to be a really bad thing to do: <span>NXDOMAIN</span> is a
valid answer, and not a failure&nbsp;return.</p>
</blockquote>
<p>Do you have a group of steady contributors, or is it pretty much just you
(and occasional&nbsp;contributions)?</p>
<blockquote>
<p>There are steady contributors, but long-term, it’s just&nbsp;me.</p>
</blockquote>
<p>You are pretty active on the mailing list. For the second quarter of 2017,
nearly 80 messages of the 229 are from you. How much time do you spend on the
project (code and helping&nbsp;users)?</p>
<blockquote>
<p>Very variable, and less than I used to. I used to have a job with a very
<span>FOSS</span>-friendly employer. I was sitting in front of computer most days,
and my boss was happy for me to spend time on dnsmasq. Nowadays, I’m
semi-retired, and I spend my days doing other stuff, so I have to make
time to sit down and work on&nbsp;dnsmasq.</p>
</blockquote>
<p>What is your motivation for self-hosting, vs. moving to something like
Github or&nbsp;Bitbucket?</p>
<blockquote>
<p>The self-hosting setup existed before Github etc, or at least before
they were visible and known to be reliable. It works, so I’ve never had
the activation energy to move it. I’m a sysadmin and I like having a
host to do my stuff, my&nbsp;way.</p>
</blockquote>
<p>Your <span>FAQ</span> says it will run on Linux, *<span>BSD</span>, and embedded systems. What is the
most interesting platform you’ve heard of using&nbsp;dnsmasq?</p>
<blockquote>
<p>Somebody ran it on <span>QNX</span> once, I&nbsp;believe.</p>
</blockquote>
<p>Commit 1 in the dnsmasq git repository happened on January 22, 2004, and
says it is an “import of dnsmasq-2.0.tar.gz.”  When was your first public
release (version 0.4)? How long had you been working on it before&nbsp;then?</p>
<blockquote>
<p>Around 2000. There were quite a few releases in the 1.x series, which
were before the <span>DHCP</span> server was added. It didn’t seem worth adding those
when I moved into&nbsp;git.</p>
</blockquote>
<p>What are your future plans, dreams, and hopes for&nbsp;dnsmasq?</p>
<blockquote>
<p>Like all code that’s 15 years old, there are deep design decisions and
trade-off that are hard to change but which don’t necessarily make sense
any more. I’d like to do a version 3.0 which addresses those, but I’m
not sure I have the commitment left in me to do&nbsp;it.</p>
</blockquote>
<p>In relation to the <a href="https://security.googleblog.com/2017/10/behind-masq-yet-more-dns-and-dhcp.html">recent security fixes contributed by Google</a> did
you know they were working on dnsmasq, or did the fixes come as a&nbsp;suprise?</p>
<blockquote>
<p>They didn’t tell me they were working on dnsmasq before they started,
but once they’d found holes, they let me know well before the public
disclosure. There’s a whole raft of stuff which happens in case like
this, and the Google security people were really good at helping to work
through it.  A lot is helping distributions to get patched packages ready in
advance: I spend a lot of effort helping people backport the fixes to
the older&nbsp;versions.</p>
</blockquote>
<p>Have any steps been taken to do a full audit, or is that what Google&nbsp;did?</p>
<blockquote>
<p>There have been quite a few audits over the years, before Google did its
stuff. <span>SUSE</span> did one, and the Mozilla foundation sponsored one. The
Google people used fuzzing to find the holes that had been missed by the
audits - it’s very&nbsp;impressive.</p>
</blockquote>
<p>Has the  recent security news changed the development process&nbsp;any?</p>
<blockquote>
<p>I plan to use Google’s service to do ongoing fuzzing of new&nbsp;releases.</p>
</blockquote>
<p>Anything significant on the dnsmasq road map? Are there additions that could
be done, or do you cover all of the <span>DNS</span>/<span>DHCP</span> spec&nbsp;now?</p>
<blockquote>
<p>I don’t cover the whole spec - the <span>USP</span> [ed. note: Unique Selling Point] is to cover the bits that my
users need, without carrying the bloat of everything else. I guess that
new stuff is still likely in the area of IPv6 address/name management.
IPv6 will take over the world one day, won’t&nbsp;it?</p>
</blockquote>
<p>[ed. note: We&nbsp;hope.]</p>
<p>Do you have a Patreon, Flattr, or other funding source to which people could&nbsp;contribute?</p>
<blockquote>
<p>I have a PayPal account at simon@thekelleys.org.uk. Contributions
happily&nbsp;accepted.</p>
</blockquote>
<p>Thanks again! I hope our paths will cross some&nbsp;day!</p>
<blockquote>
<p>I hope that’s useful. Please feel free to come back with more questions,
or for clarifications on the&nbsp;answers.</p>
</blockquote>
<p>That wraps it up! I greatly appreciate Simon taking time to do this. If you have questions, ask them in the&nbsp;comments.</p>
<p>The official page for dnsmasq can be found <a href="http://www.thekelleys.org.uk/dnsmasq/doc.html">on the Kelley’s&nbsp;page</a></p>
<p>Who should I interview next? Let me&nbsp;know!</p>
<p><em>Tha…</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://joshuakugler.com/an-interview-with-simon-kelley-the-author-of-dnsmasq.html">https://joshuakugler.com/an-interview-with-simon-kelley-the-author-of-dnsmasq.html</a></em></p>]]>
            </description>
            <link>https://joshuakugler.com/an-interview-with-simon-kelley-the-author-of-dnsmasq.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24193836</guid>
            <pubDate>Tue, 18 Aug 2020 00:12:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using, Understanding, and Unraveling the OCaml Language]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24193795">thread link</a>) | @rabidsnail
<br/>
August 17, 2020 | http://caml.inria.fr/pub/docs/u3-ocaml/index.html | <a href="https://web.archive.org/web/*/http://caml.inria.fr/pub/docs/u3-ocaml/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody><tr><td><h3><a href="http://cristal.inria.fr/~remy"><span size="5">Didier R</span><span size="5">é</span><span size="5">my</span></a><span size="5">
</span></h3><h3><a href="http://www-sop.inria.fr/oasis/Caminha00/index.html">APPSEM'2000 summer school</a><sup><a name="text1" href="#note1">1</a></sup></h3></td></tr>
</tbody></div><p>Copyright ©&nbsp;2000, 2001 by Didier Rémy.
</p><p>
To correctly preview mathematical symbols, you may need 
to adjust your 
<a href="http://pauillac.inria.fr/~maranget/hevea/doc/browser.html">browser configuration</a>. 
</p></div>]]>
            </description>
            <link>http://caml.inria.fr/pub/docs/u3-ocaml/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24193795</guid>
            <pubDate>Tue, 18 Aug 2020 00:08:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A circuit-like notation for lambda calculus (2015)]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24193313">thread link</a>) | @apsec112
<br/>
August 17, 2020 | https://csvoss.com/circuit-notation-lambda-calculus | <a href="https://web.archive.org/web/*/https://csvoss.com/circuit-notation-lambda-calculus">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Lately, I’ve been playing around with inventing a visual writing system for lambda calculus.</p>

<p><a href="http://en.wikipedia.org/wiki/Lambda_calculus">Lambda calculus</a> (λ-calculus) is a sort of proto-functional-programming, originally invented by Alonzo Church while he was trying to solve <a href="http://en.wikipedia.org/wiki/Entscheidungsproblem">the same problem</a> that led Turing to invent Turing machines. It’s another way of reasoning about computation.</p>

<p>Python’s lambda is an idea that was borrowed from λ-calculus. In Python, you can use a <a href="https://docs.python.org/2/tutorial/controlflow.html#lambda-expressions">lambda expression</a> like the following in order to define a function that returns the square of a number:</p>



<p>In λ-calculus, the idea is the same: we create a function by using <code>λ</code> to specify which arguments a function takes in, then we give an expression for the function’s return value. Pure lambda calculus doesn’t include operators of any sort –&nbsp;just functions being applied to other functions –&nbsp;so if we try to write a <code>square</code> function, we have to suppose that <code>multiply</code> is a function of two variables that has already been defined:</p>

<div><div><pre><code>square = λx. multiply x x
</code></pre></div></div>

<p>The <code>square</code> function, once defined, can be applied to arguments and evaluated into something simpler.</p>

<div><div><pre><code>square 4 = (λx. multiply x x) 4
         = multiply 4 4
         = 16
</code></pre></div></div>

<p>One of the cool things about lambda calculus is that we can represent most common programming abstractions using λ-calculus, even though it’s nothing but functions: numbers, arithmetic, booleans, lists, if statements, loops, recursion… the list goes on. Before I introduce the visual writing system I’ve been using, let’s take a detour and discuss how we can represent numbers and arithmetic using lambda calculus.</p>

<h2 id="church-numerals-in-lambda-calculus">Church numerals, in lambda calculus</h2>
<p>Alonzo Church figured out how to represent numbers as lambda functions; these numbers are referred to as Church numerals.</p>

<p>We can represent any nonnegative integer as long as we have two things: (1) a value for <strong>zero</strong>, and (2) a <strong>successor</strong> function, which returns <code>n + 1</code> for any number <code>n</code>. To represent numbers as functions, then, we require that <code>z</code> (zero) and <code>s</code> (successor) be passed in as arguments, and go from there. Each number is actually secretly a function of those two inputs.</p>

<div><div><pre><code>zero = λs. λz. z
one = λs. λz. s z
two = λs. λz. s (s z)
three = λs. λz. s (s (s z))
</code></pre></div></div>

<p>The actual details of how to implement zero and successor should be implemented as are left as someone else’s problem — we can survive without them. All we care about is that our numbers do the right thing, given whatever zero and successor someone may provide.</p>

<p>What about <strong>addition</strong>? Addition is a function that takes in two numbers (let’s call them <code>x</code> and <code>y</code>), and produces a number representing their sum. To sum them together, we’ll want to produce a number that applies <code>s</code>, the successor function, a total of <code>x + y</code> times. For example, we could first apply it <code>y</code> times to the zero, then apply it <code>x</code> more times to that result.</p>

<div><div><pre><code>plus = λx. λy. (λs. λz. x s (y s z))
</code></pre></div></div>

<p>Let’s try proving that one plus one equals two. In λ-calculus, this proof looks like the following:</p>

<div><div><pre><code>one = λs. λz. s z
two = λs. λz. s (s z)

plus = λx. λy. (λs. λz. x s (y s z))

plus one one = (λx. λy. (λs. λz. x s (y s z))) one one
             = λs. λz. one s (one s z)
             = λs. λz. (λs. λz. s z) s (one s z)
             = λs. λz. s (one s z)
             = λs. λz. s ((λs. λz. s z) s z)
             = λs. λz. s (s z)
             = two
</code></pre></div></div>

<p>(Long, but at least conciser than <a href="http://en.wikipedia.org/wiki/Principia_Mathematica">Bertrand Russell’s</a>.)</p>

<h2 id="lambda-circuitry">Lambda circuitry</h2>

<p>There are a lot of lambdas, parentheses, and arguments being pushed around in that proof. Mentally matching up parentheses is annoying. Scope is especially annoying: which <code>s</code> am I looking at again in <code>λs. λz. (λs. λz. s z) s (one s z)</code>, the inner one or the outer one?</p>

<p>A linear string of lambdas and parentheses is an ineffective way to provide intuition for the computations that are taking place. This problem isn’t unique to lambda calculus, either; consider trying to represent a binary tree using a linear string:</p>

<div><div><pre><code>Node(2, Node(7, Leaf(2), Node(6, Leaf(5), Leaf(11))), Node(5, None, Node(9, Leaf(4), None)))
</code></pre></div></div>

<p>Unambiguous, but not very intuitive. Contrast that representation with the diagram we use when we’re trying to explain that same binary tree at a chalkboard, a more visual notation:</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Binary_tree.svg/288px-Binary_tree.svg.png" alt="Binary tree diagram, from Wikipedia"></p>

<p><em>Image from <a href="https://commons.wikimedia.org/wiki/File:Binary_tree.svg">Wikipedia</a>.</em></p>

<p>I remember programming constructs better when I can reason about them visually like this: when I imagine cutting an array in half for binary search, when I imagine pointers in a linked list being shuffled around to insert a new element, and when I imagine traversing up and down the branches of a binary tree.</p>

<p>Why can’t lambda calculus get some visual intuitions, in the same way? Lambda calculus is a dance of variables flowing through and being manipulated by functions, and I want a writing system for lambda calculus that will visually display this dance. It shouldn’t look like strings of parentheses and symbols: it should create visual intuition.</p>

<p>After some trial and error, here is the system I came up with. I aimed for something that would resemble circuitry.</p>

<p><strong>Values</strong> flow along wires, where they may be passed in as arguments to functions or applied as functions themselves. Some are inputs, some are outputs.</p>

<p><strong>Functions</strong> are represented as boxes which are applied to their inputs on one side and produce a single output on the other. The notation must indicate which function is applied; this may either be drawn within the box itself, or wired in to the middle of the box from some other value.</p>

<p><strong>Arguments</strong> are represented as inputs, coming in from the right side of the diagram; these arguments might pass through functions, or they might be functions-to-apply themselves. If an argument has not been passed in yet, it’s an empty arrow beginning a wire; if an argument has been passed in, its value is attached to the wire. Arguments are always passed in from top to bottom, in order.</p>

<p>As an example, here’s a function which takes in two functions, <code>f</code> and <code>g</code>, then a value <code>x</code>, and returns <code>f (g x)</code>:</p>

<p><img src="https://csvoss.com/images/lambda-f-g-x.png" alt="lambda f. lambda g. lambda x. f (g x)"></p>

<p>As another example, here’s the M combinator <code>M = λx. x x</code> (the “mockingbird” in <a href="http://smile.amazon.com/gp/product/B00A1P096Y"><em>To Mock a Mockingbird</em></a>):</p>

<p><img src="https://csvoss.com/images/m-combinator.png" alt="lambda x. x x"></p>

<h2 id="church-numerals-in-lambda-circuitry">Church numerals, in lambda circuitry</h2>

<p>Here’s the Church numeral <code>four = λs. λz. s (s (s (s z)))</code>, drawn out in lambda circuitry:</p>

<p><img src="https://csvoss.com/images/lambda-four.png" alt="Four, in lambda circuitry"></p>

<p>Let’s take that proof from earlier that one plus one is two. What does it look like to draw that proof in lambda circuitry, instead?</p>

<p><img src="https://csvoss.com/images/lambda-oneplusoneistwo.png" alt="Proof that one plus one is two, in lambda circuitry"></p>

<p>∎</p>

<p>We could also consider <strong>multiplication</strong>. A multiply function would take in two numbers, m and n, and computes a new number which is their product. In lambda calculus, we’d write:</p>

<div><div><pre><code>multiply = λm. λn. λs. λz. m (n s) z
</code></pre></div></div>

<p>In the notation of lambda circuitry, this looks like this:</p>

<p><img src="https://csvoss.com/images/lambda-multiply.png" alt="Multiplication function, in lambda circuitry"></p>

<p>Using this function, we can check that <code>multiply 2 3</code> evaluates to <code>6</code>:</p>

<p><img src="https://csvoss.com/images/lambda-multiply-1.png" alt="Multiply(2, 3), step 1"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-2.png" alt="Multiply(2, 3), step 2"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-3.png" alt="Multiply(2, 3), step 3"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-4.png" alt="Multiply(2, 3), step 4"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-5.png" alt="Multiply(2, 3), step 5"></p>

<p>∎</p>

<h2 id="sidenote-de-bruijn-indices">Sidenote: De Bruijn indices</h2>
<p>One of the nice things about lambda circuitry is that it completely removes the need for variable names.</p>

<p>There’s another notation for lambda calculus that does this too: <a href="https://en.wikipedia.org/wiki/De_Bruijn_index"><em>De Bruijn indices</em></a>. A lambda expression written with De Bruijn indices indicates which variables are used where with a positive integer; the smaller the integer, the more recently the argument it refers to was passed in.</p>

<p>For example, the identity function <code>λx. x</code> may be written with De Bruijn indices like so:</p>



<p>The Church numeral for two, <code>λs. λz. s (s z)</code>, may be written like so:</p>



<p>The addition function, <code>λx. λy. (λs. λz. x s (y s z))</code>, may be written like so:</p>

<div><div><pre><code>plus = λ λ (λ λ 4 2 (3 2 1))
</code></pre></div></div>

<p>An evaluation of <code>plus one one</code> looks like this:</p>

<div><div><pre><code>plus one one = (λ λ (λ λ 4 2 (3 2 1))) (λ λ 2 1) (λ λ 2 1)
             = (λ (λ λ (λ λ 2 1) 2 (3 2 1))) (λ λ 2 1)
             = λ λ (λ λ 2 1) 2 ((λ λ 2 1) 2 1)
             = λ λ (λ λ 2 1) 2 (2 1)
             = λ λ 2 (2 1)
</code></pre></div></div>

<p>One of the tricky things about writing a lambda calculus interpreter is getting the renaming rules right; De Bruijn indices are convenient because they remove the need for this. Lambda circuitry is similar in spirit to De Bruijn indices in that it doesn’t require variable names at all, but instead indicates which variables are passed where by connecting values directly to an arrow indicating when they were passed in.</p>

<h2 id="argument-switching-function-in-lambda-circuitry">Argument-switching function, in lambda circuitry</h2>

<p>I’ll provide more examples just to further demonstrate how the notation works in different situations. Let’s consider the “argument-switching” function <code>C</code>, where <code>C f x y</code> returns <code>f y x</code>. (This is actually the <a href="https://en.wikipedia.org/wiki/B,C,K,W_system">C combinator</a>.)</p>



<p><img src="https://csvoss.com/images/c-combinator.png" alt="C combinator"></p>

<p>Suppose we try applying this to a silly function <code>f</code> where <code>f x y</code> discards <code>y</code> and just returns <code>x</code>. Then, <code>C f</code> should switch around <code>f</code>‘s arguments and create a function which returns <code>y</code> instead. Let’s check:</p>

<div><div><pre><code>f = λx. λy. x

C f = λf. λx. λy. (f y x) f
    = λx. λy. f y x
    = λx. λy. (λx. λy. x) y x
    = λx. λy. y
</code></pre></div></div>

<p><img src="https://csvoss.com/images/lambda-f.png" alt="f = lambda x. lambda y. x"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-f-1.png" alt="C(f), step 1"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-f-2.png" alt="C(f), step 2"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-f-3.png" alt="C(f), step 3"></p>

<p>∎</p>

<p>We could also try a function <code>g</code> where <code>g x y</code> returns <code>x y</code>. Then <code>C g x y</code> should return <code>y x</code>. Let’s check:</p>

<div><div><pre><code>g = λx. λy. x y

C g x y = λf. λx. λy. (f y x) g x y
        = g y x
        = (λx. λy. x y) y x
        = y x
</code></pre></div></div>

<p><img src="https://csvoss.com/images/lambda-g.png" alt="g = lambda x. lambda y. x(y)"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-1.png" alt="C(g), step 1"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-2.png" alt="C(g), step 2"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-3.png" alt="C(g), step 3"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-4.png" alt="C(g), step 4"></p>

<p>∎</p>

<p><em>Exercise</em>: Show that applying <code>C</code> twice reverses it. That is, show that <code>C (C f)</code> returns <code>f</code>, for any <code>f</code>.
(Note that <code>C f</code> is a function which takes in two arguments, <code>x</code> and <code>y</code>, and returns <code>f y x</code>. Applying <code>C</code> only to <code>f</code> like this is <a href="http://en.wikipedia.org/wiki/Partial_application">partial application</a>.)</p>

<h2 id="prior-work">Prior work</h2>
<p>There are some other systems that give visual intuition to lambda calculus.</p>

<p><a href="http://dkeenan.com/Lambda/"><em>To Dissect a Mockingbird</em></a> describes a notation that is actually very similar to the one I’ve described, and demonstrates it on various problems from <em>To Mock a Mockingbird</em>. I like the way this looks, especially how every function is enclosed by two halves of a circle which make it obvious how that function might be applied. My notation doesn’t have this feature, but requires drawing fewer enclosing boxes as a result.</p>

<p>Visual Lambda (<a href="https://code.google.com/p/visual-lambda/">code</a>, <a href="http://bntr.planet.ee/lambda/visual_lambda_bubble_notation.gif">basics</a>, <a href="http://bntr.planet.ee/lambda/work/visual_lambda.pdf">paper</a>) represents lambda expressions as colored bubbles, and provides an interface for manipulating them.</p>

<p><a href="http://worrydream.com/AlligatorEggs/">Alligator Eggs</a> is a description of a puzzle game based on lambda calculus, which also happens to provide a visual way of working with and evaluating lambda expressions.</p>

<p>These last two don’t happen to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csvoss.com/circuit-notation-lambda-calculus">https://csvoss.com/circuit-notation-lambda-calculus</a></em></p>]]>
            </description>
            <link>https://csvoss.com/circuit-notation-lambda-calculus</link>
            <guid isPermaLink="false">hacker-news-small-sites-24193313</guid>
            <pubDate>Mon, 17 Aug 2020 23:02:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond jsonb: a generalized, unstructured data type for Postgres]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24191359">thread link</a>) | @ahachete
<br/>
August 17, 2020 | https://www.ongres.com/blog/a_generalized_unstructured_data_type_for_postgres/ | <a href="https://web.archive.org/web/*/https://www.ongres.com/blog/a_generalized_unstructured_data_type_for_postgres/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<main>

        	

	        <section id="post">
	            <p><span>Post</span>
	            </p>

	            <div data-aos="fade-right" data-aos-mirror="false">
	            	
	            	

                    <p> ·
                        <span>Aug 6, 2020</span> ·
                        <span>6 min read</span>
                    </p>

                    

                    

                    <div>
                        
                        <div>
  
  <p><span>Álvaro Hernández</span>
  <span>Founder and CEO</span>
</p></div>
                        
                    </div>
	            </div>

	            <div data-aos="fade-left" data-aos-delay="200" data-aos-mirror="false">
        			<h2 id="jsonb-supports-unsurprisingly-json">jsonb supports, unsurprisingly, JSON</h2>
<p><a href="https://www.postgresql.org/docs/current/datatype-json.html">jsonb</a> is, undeniably, <em>king</em>. It is a very flexible data
type, that allows for unstructured/schema-less storage. It has very powerful
<a href="https://www.postgresql.org/docs/current/datatype-json.html#JSON-INDEXING">indexing mechanisms</a>, and its internal
representation is reasonably compact and efficient. It comes with advanced operators and expressions to query/extract
parts of it, and has
<a href="http://www.sai.msu.su/~megera/postgres/talks/jsonb-roadmap-pgcon-2020.pdf">recently seen the addition of SQL/JSON path</a>
functionality to extend that to comply with the SQL Standard.</p>
<p>There are countless posts and resources explaining the virtues of this data type and what you can accomplish with it. So
nothing else to add, except to reiterate my appreciation for all those who have worked on creating and contributing to
it<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>But there’s a catch. <code>jsonb</code> supports… just JSON! That’s great, but is it enough?</p>
<h2 id="json-data-types">JSON data types</h2>
<p>JSON is a container data type, which means it can store other data types contained within. And which data types it does
support? From the <a href="https://www.json.org/json-en.html">JSON Spec</a>, it supports the following:</p>
<ul>
<li>Number, which is a quite flexible “numeric” data type.</li>
<li>String.</li>
<li>Boolean.</li>
<li>Null.</li>
<li>Array, or probably better called a “bag” or “container”, a sequence of elements of, possibly, mixed types.</li>
<li>Object, a collection of key-value pairs, where the value may be any other JSON data type.</li>
</ul>
<p><code>jsonb</code> maps these JSON data types, internally, to Postgres types. It is easy to see the resolved (JSON) data types:</p>
<div><pre><code data-lang="sql"><span>select</span> <span>key</span>, value, jsonb_typeof(value) <span>from</span> jsonb_each(
<span>'{"a": 42, "b": true, "c": "hi", "d": null, "e": [42, "hi"], "f": {"a": 1}}'</span>
);
<span>┌─────┬────────────┬──────────────┐</span>
<span>│</span> <span>key</span> <span>│</span>   value    <span>│</span> jsonb_typeof <span>│</span>
<span>├─────┼────────────┼──────────────┤</span>
<span>│</span> a   <span>│</span> <span>42</span>         <span>│</span> <span>number</span>       <span>│</span>
<span>│</span> b   <span>│</span> <span>true</span>       <span>│</span> <span>boolean</span>      <span>│</span>
<span>│</span> <span>c</span>   <span>│</span> <span>"hi"</span>       <span>│</span> string       <span>│</span>
<span>│</span> d   <span>│</span> <span>null</span>       <span>│</span> <span>null</span>         <span>│</span>
<span>│</span> e   <span>│</span> [<span>42</span>, <span>"hi"</span>] <span>│</span> <span>array</span>        <span>│</span>
<span>│</span> f   <span>│</span> <span>{</span><span>"a"</span>: <span>1</span><span>}</span>   <span>│</span> <span>object</span>       <span>│</span>
<span>└─────┴────────────┴──────────────┘</span>
</code></pre></div><p>Scalar types are mapped to boolean, text and numeric. Essentially, three different data types. Now check
<a href="https://www.postgresql.org/docs/current/datatype.html">all the data types available in Postgres</a>. There are dozens. And
obviously you can extend with your own. Isn’t it a bit limiting that, in essence, you need to conflate any existing data
type to either a <code>numeric</code> or a <code>text</code>? What if you want to represent a timestamp? Convert it to text (well, Postgres
<a href="https://github.com/postgres/postgres/blob/3ed2005ff595d349276e5b2edeca1a8100b08c87/src/backend/utils/adt/jsonb.c#L45">does it for
you</a>,
but you get the point). What about a <code>inet</code>, or a <code>point</code>? What about my <code>custom-amazing-data-type</code>?</p>
<p>According to the JSON spec, this is correct and there’s nothing else to do. So the question is not about whether <code>jsonb</code>
has any implementation flaws, but if Postgres users are enough with “just JSON”.</p>
<p>I find it particularly frustrating having to store binary data (<code>bytea</code>) in a JSON. Since there’s no <code>bytea</code> data type in
JSON (nor <code>jsonb</code>, consequently) you need to convert it to a text representation. There are several solutions, none of
them a good enough one:</p>
<ul>
<li>
<p>Convert it to a string, byte by byte. Probably a very bad option, as it suffers two main problems: one is that
Postgres strings, not being strictly UTF-8 comformant (and this is a topic for another blog post…), cannot store the
UTF-8 null (<code>\0</code>) character. As such, if one of those bytes had the 0 value (likely), it could not be stored. Second,
a sequence of bytes interpreted as a string does not have the same ordering as the original byte sequence.</p>
</li>
<li>
<p>Encode in <code>base64</code>. Other than the extra space, ordering is not preserved (i.e., an index on the original byte
sequence would yield a different order than an index on the base64-encoded text). The solution is to use expression
indexes on the decoded value, if order needs to be preserved. This adds overhead anyway.</p>
</li>
<li>
<p>Encode in <a href="https://en.wikipedia.org/wiki/Base32#base32hex">base32hex</a>, an even more verbose encoding but that
preserves order. There are no functions in Postgres for this encoding.</p>
</li>
</ul>
<h2 id="looking-beyond-json">Looking beyond JSON</h2>
<p>So how would you store other specific, more compact, or benefit from existing functions from additional datatypes, with
current JSON and <code>jsonb</code>? The only option to avoid data type information erasure is to encode the data type as part of
the JSON string. Something like:</p>
<div><pre><code data-lang="json">{
	<span>"key1"</span>: {<span>"type"</span>: <span>"inet"</span>, <span>"value"</span>: <span>"10.0.0.0/8"</span>},
	<span>"array"</span>: [<span>3</span>, {<span>"key2"</span>: {<span>"type"</span>: <span>"point"</span>, <span>"value"</span>: <span>"(42, -42)"</span>}<span>]</span>
}
</code></pre></div><p>It is easy to see the several drawbacks of this approach: much more verbose and storage needs; need to continuously
cast; and need to do conditional casts depending on the data type.</p>
<p>I’m not alone in the pursue of a more generic, supporting more data type JSON-like language, like:</p>
<ul>
<li><a href="https://docs.mongodb.com/manual/reference/bson-types/">MongoDB’s BSON</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/Ion_(serialization_format)">Amazon’s ION</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/UBJSON">Universal Binary JSON</a>.</li>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.LowLevelAPI.html">DynamoDB’s Item HTTP
API</a>.
This is a very interesting case, as it is a JSON-compliant input/output interface, with type definition following an
approach similar to the one outlined above (where the value is an object which includes both the type and the value
itself), but which is claimed to be stored internally in an optimized form (not as-is). It has interesting composite
types like “homogeneus arrays”, where are elements must be of the same time or sets, which forbid duplicated values.</li>
</ul>
<p><img src="https://www.ongres.com/img/blog/post_jsonb.jpg" alt="Beyond jsonb: a generalized jsonb supertype for Postgres?"></p>
<p>So how would such a generalized unstructured data type work in Postgres? I’d say it could leverage all the existing
jsonb infrastructure. After all, jsonb already knows each element’s data type, so this just needs to be extended to
many, potentially arbitrary data types (to support custom data types too). As such, new data types should be easy to
add. Other features (like ensuring homogeneus-ness across array elements for supporting sets; or ensuring uniqueness
within an element) may require some differentiation. Being a superset, I’d expect the same codebase could accommodate
well both data types (a similar retrofit was performed in the past from <code>hstore</code> to use <code>jsonb</code>'s codebase).</p>
<p>One of the main requisites is that this generalized unstructured data type would be a super set of the actual JSON, so
that any JSON string (and consequently <code>json</code> and <code>jsonb</code> values) can be converted to it implicitly. I envision the
hardest parts, or at least the ones that may trigger more discussion, to be:</p>
<ul>
<li>Analyze existing JSON-superset data types and deciding on the set of features to implement.</li>
<li>Selecting the data types to support, if not <em>all</em>.</li>
<li>Input syntax? Some ideas:
<ul>
<li>Use different value enclosing depending on the data type. E.g. <code>key: {{ dmFsdWU= }}</code> (Amazon Ion).</li>
<li>Wrap the value in constructor-like syntax, like MongoDB shell: <code>key: NumberLong(42)</code>.</li>
<li>Turn values into a nested JSON object with type (document’s key) and value, similar to DynamoDB’s HTTP API:
<code>"key": { "N": "42" }</code>.</li>
</ul>
</li>
<li>And the hardest one: pick the name of the new datatype!</li>
</ul>
<p>So what do you think? <strong>Should Postgres get a JSON-superset data type, a generalized unstructured data type</strong>?  Leave
your comments and/or <a href="https://twitter.com/ongresinc">tweet your responses to @ongresinc</a> to start the conversation.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><em>Personal note</em>: I find it hard to understand why Oleg Bartunov, one of the most significant contributors to JSON in
Postgres, among many other features,
<a href="https://www.postgresql.org/community/contributors/">was recently demoted from being a “Major Contributor” to a “Contributor”</a>.
Not only I believe major contributions cannot be taken back; but in this particular case it feels even harder to understand. Let
this be my public call to ask to revert this situation and provide proper public recognizement for
<a href="http://www.sai.msu.su/~megera/postgres/talks/pgrussian-2016-short.pdf">two decades of Postgres contributions</a>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        		</div>
            </section>

        	

                            
            </main></div></div>]]>
            </description>
            <link>https://www.ongres.com/blog/a_generalized_unstructured_data_type_for_postgres/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24191359</guid>
            <pubDate>Mon, 17 Aug 2020 20:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Proposed Origin for SARS-CoV-2 and the Covid-19 Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24190978">thread link</a>) | @Giorgi
<br/>
August 17, 2020 | https://jonathanlatham.net/a-proposed-origin-for-sars-cov-2-and-the-covid-19-pandemic/ | <a href="https://web.archive.org/web/*/https://jonathanlatham.net/a-proposed-origin-for-sars-cov-2-and-the-covid-19-pandemic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>

		
		<p>by Jonathan Latham, PhD and Allison Wilson, PhD</p>
<p>In all the discussions of the origin of the COVID-19 pandemic, enormous scientific attention has been paid to the molecular character of the SARS-CoV-2 virus, including its novel genome sequence in comparison with its near relatives. In stark contrast, virtually no attention has been paid to the physical provenance of those nearest genetic relatives, its presumptive ancestors, which are two viral sequences named BtCoV/4991 and RaTG13.<span id="more-4485"></span></p>
<p>This neglect is surprising because their provenance is more than interesting. BtCoV/4991 and RaTG13 were collected from a mineshaft in Yunnan province, China, in 2012/2013 by researchers from the lab of Zheng-li Shi at the <a href="http://english.whiov.cas.cn/">Wuhan Institute of Virology</a> (WIV). Very shortly before, in the spring of 2012, six miners working in the mine had contracted a mysterious illness and three of them had died (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4036791/">Wu et al., 2014</a>). The specifics of this mystery disease have been virtually forgotten; however, they are described in a Chinese Master’s thesis written in 2013 by a doctor who supervised their treatment.</p>
<p>We arranged to have this Master’s thesis translated into English. The evidence it contains has led us to reconsider everything we thought we knew about the origins of the COVID-19 pandemic. It has also led us to theorise a plausible route by which an apparently isolated disease outbreak in a mine in 2012 led to a global pandemic in 2019.</p>
<p>The origin of SARS-CoV-2 that we propose below is based on the case histories of these miners and their hospital treatment. This simple theory accounts for all the key features of the novel SARS-CoV-2 virus, including ones that have puzzled virologists since the outbreak began.</p>
<p>The theory can account for the origin of the polybasic furin cleavage site, which is a region of the viral spike protein that makes it susceptible to cleavage by the host enzyme furin and which greatly enhances viral spread in the body. This furin site is novel to SARS-CoV-2 compared to its near relatives (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7114094/">Coutard, et al., 2020</a>). The theory also explains the exceptional affinity of the virus spike protein for human receptors, which has also surprised virologists (<a href="https://www.nature.com/articles/s41564-020-0688-y?report=reader">Letko et al., 2020</a>; <a href="https://arxiv.org/pdf/2005.06199.pdf">Piplani et al, 2020</a>; <a href="https://doi.org/10.1126/science.abb2507">Wrapp et al., 2020</a>; <a href="https://doi.org/10.1101/2020.02.19.956581">Walls et al., 2020</a>). The theory further explains why the virus has barely evolved since the pandemic began, which is also a deeply puzzling aspect of a virus supposedly new to humans (<a href="https://www.biorxiv.org/content/10.1101/2020.05.01.073262v1">Zhan et al., 2020</a>; <a href="https://www.biorxiv.org/content/biorxiv/early/2020/06/22/2020.05.21.108506.full.pdf">van Dorp et al., 2020</a>; <a href="https://jbiomedsci.biomedcentral.com/articles/10.1186/s12929-020-00665-8">Chaw et al., 2020</a>). Lastly, the theory neatly explains why SARS-CoV-2 targets the lungs, which is unusual for a coronavirus (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7159299/">Huang et al., 2020</a>).</p>
<p>We do not propose a specifically genetically engineered or biowarfare origin for the virus but the theory does propose an essential causative role in the pandemic for scientific research carried out by the laboratory of Zheng-li Shi at the WIV; thus also explaining Wuhan as the location of the epicentre.</p>
<h4>Why has the provenance of RaTG13 and BtCoV/4991 been ignored?</h4>
<p>The apparent origin of the COVID-19 pandemic is the city of Wuhan in Hubei province, China. Wuhan is also home to the world’s leading research centre for bat coronaviruses. There are two virology labs in the city, <a href="https://project-evidence.github.io/">both have either collected bat coronaviruses or researched them</a> in the recent past. The Shi lab, which collected BtCoV/4991 and RaTG13, <a href="https://grantome.com/grant/NIH/R01-AI110964-06">recently received grants</a> to evaluate <em>by experiment</em> the potential for pandemic pathogenicity of the novel bat coronaviruses they collected from the wild.</p>
<p>To add to these suggestive data points, there is a long history of accidents, disease outbreaks, and even pandemics resulting from lab accidents with viruses (<a href="https://armscontrolcenter.org/wp-content/uploads/2016/02/Escaped-Viruses-final-2-17-14-copy.pdf">Furmanski, 2014</a>; <a href="https://europepmc.org/article/med/26137650">Weiss et al., 2015</a>). For these and other reasons, summarised in our article <a href="https://www.independentsciencenews.org/health/the-case-is-building-that-covid-19-had-a-lab-origin/"><em>The Case is Building that COVID-19 Had a Lab Origin</em></a>, we (a virologist and a geneticist) <a href="https://thebulletin.org/2020/06/did-the-sars-cov-2-virus-arise-from-a-bat-coronavirus-research-program-in-a-chinese-laboratory-very-possibly/">and others</a> have concluded that a lab outbreak is a credible thesis. Certainly, a lab origin has at least as much circumstantial evidence to support it as does any natural zoonotic origin theory (<a href="https://arxiv.org/pdf/2005.06199.pdf">Piplani et al., 2020</a>; <a href="https://www.researchgate.net/profile/Rossana_Segreto/publication/340924249_Is_considering_a_genetic-manipulation_origin_for_SARS-CoV-2_a_conspiracy_theory_that_must_be_censored/links/5ed7c17992851c9c5e74f7dc/Is-considering-a-genetic-manipulation-origin-for-SARS-CoV-2-a-conspiracy-theory-that-must-be-censored.pdf">Segreto and Deigin, 2020</a>; <a href="https://www.biorxiv.org/content/10.1101/2020.05.01.073262v1">Zhan et al., 2020</a>).</p>
<p>The media, normally so enamoured of controversy, has largely declined even to debate the possibility of a laboratory escape. Many news sites have simply labelled it a conspiracy theory.</p>
<p>The principal reason for media dismissals of the lab origin possibility is a review paper in <em>Nature Medicine</em> (<a href="https://www.nature.com/articles/S41591-020-0820-9">Andersen et al., 2020</a>). Although by Jun 29 2020 this review had almost 700 citations it also has major scientific shortcomings. These flaws are worth understanding in their own right but they are also useful background for understanding the implications of the Master’s thesis.</p>
<h4>Andersen et al., a critique</h4>
<p>The question of the origin of the COVID-19 pandemic is, in outline, simple. There are two incontrovertible facts. One, the disease is caused by a human viral pathogen, SARS-CoV-2, first identified in Wuhan in December 2019 and whose RNA genome sequence is known. Second, all of its nearest known relatives come from bats. Beyond any reasonable doubt SARS-CoV-2 evolved from an ancestral bat virus. The task the <em>Nature Medicine</em> authors set for themselves was to establish the relative merits of each of the various possible routes (lab vs natural) by which a bat coronavirus might have jumped to humans and in the same process have acquired an unusual furin site and a spike protein having very high affinity for the human ACE2 receptor.</p>
<p>When Andersen et al. outline a natural zoonotic pathway they speculate extensively about how the leap might have occurred. In particular they elaborate on a proposed residence in intermediate animals, likely pangolins. For example, “The presence in pangolins of an RBD [Receptor Binding Domain] very similar to that of SARS-CoV-2 means that we can infer that this was probably in the virus that jumped to humans. This leaves the insertion of [a] polybasic cleavage site to occur during human-to-human transmission.” This viral evolution occurred in “Malayan pangolins illegally imported into Guangdong province”. Even with these speculations there are major gaps in this theory. For example, why is the virus so well adapted to humans? Why Wuhan, which is 1,000 Km from Guangdong? (See map).</p>
<figure id="attachment_3105" aria-describedby="caption-attachment-3105"><img src="https://www.independentsciencenews.org/wp-content/uploads/2020/07/china-province-guide-600x503.jpg" alt="china province guide" width="600" height="503"><figcaption id="caption-attachment-3105">china province guide</figcaption></figure>
<p>The authors provide no such speculations in favour of the lab accident thesis, only speculation <em>against</em> it:</p>
<p>“Finally, the generation of the <em>predicted</em> O-linked glycans is also <em>unlikely</em> to have occurred due to cell-culture passage, as such features suggest the involvement of an immune system.” (italics added).</p>
<p>[Passaging is the deliberate placing of live viruses into cells or organisms to which they are NOT adapted for the purpose of making them adapted, i.e. speeding up their evolution.]</p>
<p>It is also noteworthy that the Andersen authors set a higher hurdle for the lab thesis than the zoonotic thesis. In their account, the lab thesis is required to explain <em>all </em>of the evolution of SARS-CoV-2 from its presumed bat viral ancestor, whereas under their telling of the zoonotic thesis the key step of the addition of the furin site is allowed to happen in humans and is thus effectively unexplained.</p>
<p>A further imbalance is that key information needed to judge the merits of a lab origin theory is missing from their account. As we detailed in our previous article, in their search for SARS-like viruses with zoonotic spillover potential, researchers at the WIV have passaged live bat viruses in monkey and human cells (<a href="https://www.mdpi.com/1999-4915/11/4/379/htm">Wang et al., 2019</a>). They have also performed many recombinant experiments with diverse bat coronaviruses (<a href="https://www.nature.com/articles/nature12711">Ge et al., 2013</a>; <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4797993/">Menachery et al., 2015</a>; <a href="https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1006698">Hu et al., 2017</a>). Such experiments have generated international concern over the possible creation of potential pandemic viruses (<a href="https://link.springer.com/protocol/10.1007/978-1-4939-8678-1_29">Lipsitch, 2018</a>). As we showed too, the Shi lab had also won a grant to extend that work to whole live animals. They planned “virus infection experiments across a range of cell cultures from different species and humanized mice” with recombinant bat coronaviruses. Yet Andersen et al did not discuss this research at all, except to say:</p>
<p>“Basic research involving passage of bat SARS-CoV-like coronaviruses in cell culture and/or animal models has been ongoing for many years in biosafety level 2 laboratories across the world”</p>
<p>This statement is fundamentally misleading about the kind of research performed at the Shi lab.</p>
<p>A further important oversight by the Andersen authors concerns the history of lab outbreaks of viral pathogens. They write: “there are documented instances of laboratory escapes of SARS-CoV”. This is a rather matter-of-fact allusion to the fact that since 2003 there have been six documented outbreaks of SARS from labs, not all in China, with some leading to fatalities (<a href="https://armscontrolcenter.org/wp-content/uploads/2016/02/Escaped-Viruses-final-2-17-14-copy.pdf">Furmanski, 2014</a>).</p>
<p>Andersen et al might have also have noted that two major human pandemics are widely accepted to have been caused by lab outbreaks of viral pathogens, H1N1 in 1977 and Venezuelan Equine Encephalitis (summarised in <a href="https://armscontrolcenter.org/wp-content/uploads/2016/02/Escaped-Viruses-final-2-17-14-copy.pdf">Furmanski, 2014</a>). Andersen could even have noted that literally hundreds of lab accidents with viruses have resulted in near-misses or very localised outbreaks (<a href="https://thebulletin.org/2019/02/human-error-in-high-biocontainment-labs-a-likely-pandemic-threat/">summarised by Lynn Klotz</a> and <a href="https://www.independentsciencenews.org/health/the-long-history-of-accidental-laboratory-releases-of-potential-pandemic-pathogens/">Sam Husseini</a> and also <a href="https://europepmc.org/article/med/26137650">Weiss et al., 2015</a>).</p>
<p>Also unmentioned were instances where a lab outbreak of an experimental or engineered virus has been plausibly theorised but remains uninvestigated. For example, the most coherent explanation for the H1N1 variant ‘swine flu’ pandemic of 2009/10 that resulted in a death toll estimated by some as high as 200,000 (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4865181/">Duggal et al., 2016</a>; <a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001558">Simonsen et al. 2013</a>), is that a vaccine was improperly inactivated by its maker (<a href="https://link.springer.com/article/10.1186/1743-422X-6-207">Gibbs et al., 2009</a>). If so, H1N1 emerged from a lab not once but twice.</p>
<p>Given that human and livestock viral outbreaks have frequently come from laboratories and that many scientists have warned of probable lab escapes (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4028196/">Lipsitch and Galvani, 2014</a>), and that <a href="https://www.voanews.com/covid-19-pandemic/chinese-lab-checkered-safety-record-draws-scrutiny-over-covid-19">the WIV itself has a questionable biosafety record</a>, the Andersen paper is not an even-handed treatment of the possible …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathanlatham.net/a-proposed-origin-for-sars-cov-2-and-the-covid-19-pandemic/">https://jonathanlatham.net/a-proposed-origin-for-sars-cov-2-and-the-covid-19-pandemic/</a></em></p>]]>
            </description>
            <link>https://jonathanlatham.net/a-proposed-origin-for-sars-cov-2-and-the-covid-19-pandemic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24190978</guid>
            <pubDate>Mon, 17 Aug 2020 19:35:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-driving cars are bullshit]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24190743">thread link</a>) | @KKKKkkkk1
<br/>
August 17, 2020 | https://pluralistic.net/2020/08/16/combat-wheelchairs/#car-wreck | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/08/16/combat-wheelchairs/#car-wreck">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://pluralistic.net/2020/08/16/combat-wheelchairs/#car-wreck</link>
            <guid isPermaLink="false">hacker-news-small-sites-24190743</guid>
            <pubDate>Mon, 17 Aug 2020 19:15:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Favor of Niceness, Community, and Civilization]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24190221">thread link</a>) | @throwaway894345
<br/>
August 17, 2020 | https://www.slatestarcodexabridged.com/In-Favor-Of-Niceness-Community-And-Civilization | <a href="https://web.archive.org/web/*/https://www.slatestarcodexabridged.com/In-Favor-Of-Niceness-Community-And-Civilization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">

<p><span>February 23, 2014</span>
</p>
<p><em> <strong>Content warning:</strong> Discussion of social justice, discussion of violence, spoilers for Jacqueline Carey books.</em>
</p>
<hr>
<p><em> <strong>Edit 10/25:</strong> This post was inspired by a debate with a friend of a friend on Facebook who has since become somewhat famous. I’ve renamed him here to “Andrew Cord” to protect his identity.</em>
</p>
<h3>I</h3>
<p>Andrew Cord <a href="http://www.patheos.com/blogs/hallq/2014/02/on-some-criticism-of-lesswrong/" rel="nofollow">criticizes me</a> for my bold and controversial suggestion that maybe people should try to tell slightly fewer blatant hurtful lies:
</p>
<blockquote>
<p>I just find it kind of darkly amusing and sad that the “rationalist community” loves “rationality is winning” so much as a tagline and yet are clearly not winning. And then complain about losing rather than changing their tactics to match those of people who are winning.
</p>
<p>Which is probably because if you *really* want to be the kind of person who wins you have to actually care about winning something, which means you have to have politics, which means you have to embrace “politics the mindkiller” and “politics is war and arguments are soldiers”, and Scott would clearly rather spend the rest of his life losing than do this.
</p>
<p>That post [ <a href="https://slatestarcodex.com/2014/02/17/lies-damned-lies-and-social-media-part-5-of-%e2%88%9e/" rel="nofollow">the one debunking false rape statistics</a> ] is exactly my problem with Scott. He seems to honestly think that it’s a worthwhile use of his time, energy and mental effort to download evil people’s evil worldviews into his mind and try to analytically debate them with statistics and cost-benefit analyses.
</p>
<p>He gets *mad* at people whom he detachedly intellectually agrees with but who are willing to back up their beliefs with war and fire rather than pussyfooting around with debate-team nonsense.
</p>
<p>It honestly makes me kind of sick. It is exactly the kind of thing that “social justice” activists like me *intend* to attack and “trigger” when we use “triggery” catchphrases about the mewling pusillanimity of privileged white allies.
</p></blockquote>
<p>In other words, if a fight is important to you, fight nasty. If that means lying, lie. If that means insults, insult. If that means silencing people, silence.
</p>
<p>It always makes me happy when my ideological opponents come out and say eloquently and openly what I’ve always secretly suspected them of believing.
</p>
<p>My natural instinct is to give some of the reasons why I think Andrew is wrong, starting with the history of the “noble lie” concept and moving on to some examples of why it didn’t work very well, and why it might not be expected to work so well in the future.
</p>
<p>But in a way, that would be assuming the conclusion. I wouldn’t be showing respect for Andrew’s arguments. I wouldn’t be going halfway to meet them on their own terms.
</p>
<p>The respectful way to rebut Andrew’s argument would be to spread malicious lies about Andrew to a couple of media outlets, fan the flames, and wait for them to destroy his reputation. Then if the stress ends up bursting an aneurysm in his brain, I can dance on his grave, singing:
</p>
<blockquote>
<p>♪ ♬ I won this debate in a very effective manner. Now you can’t argue in favor of nasty debate tactics any more ♬ ♪
</p></blockquote>
<p>I’m not going to do that, but if I <em>did</em> it’s unclear to me how Andrew could object. I mean, he thinks that sexism is detrimental to society, so spreading lies and destroying people is justified in order to stop it. I think that discourse based on mud-slinging and falsehoods is detrimental to society. Therefore…
</p>
<h3>II</h3>
<p>But really, all this talk of lying and spreading rumors about people is – what was Andrew’s terminology – “pussyfooting around with debate-team nonsense”. You know who got things done? The IRA. They didn’t agree with the British occupation of Northern Ireland and they weren’t afraid to let people know in that very special way only a nail-bomb shoved through your window at night can.
</p>
<p>Why not assassinate prominent racist and sexist politicians and intellectuals? I won’t name names since that would be crossing a line, but I’m sure you can generate several of them who are sufficiently successful and charismatic that, if knocked off, there would not be an equally competent racist or sexist immediately available to replace them, and it would thus be a serious setback for the racism/sexism movement.
</p>
<p>Other people can appeal to “the social contract” or “the general civilizational rule not to use violence”, but not Andrew:
</p>
<blockquote>
<p>I think that whether or not I use certain weapons has zero impact on whether or not those weapons are used against me, and people who think they do are either appealing to a kind of vague Kantian morality that I think is invalid or a specific kind of “honor among foes” that I think does not exist.
</p></blockquote>
<p>And don’t give me that nonsense about the police. I’m sure a smart person like you can think of clever exciting new ways to commit the perfect murder. Unless you do not believe there will <em>ever</em> be an opportunity to defect unpunished, you need this sort of social contract to take you at least some of the way.
</p>
<p>He continues:
</p>
<blockquote>
<p>When Scott calls rhetorical tactics he dislikes “bullets” and denigrates them it actually hilariously plays right into this point…to be “pro-bullet” or “anti-bullet” is ridiculous. Bullets, as you say, are neutral. I am in favor of my side using bullets as best they can to destroy the enemy’s ability to use bullets.
</p>
<p>In a war, a real war, a war for survival, you use all the weapons in your arsenal because you assume the enemy will use all the weapons in theirs. Because you understand that it IS a war.
</p></blockquote>
<p>There are a lot of things I am tempted to say to this.
</p>
<p>Like “And that is why the United States immediately nukes every country it goes to war with.”
</p>
<p>Or “And that is why the Geneva Convention was so obviously impossible that no one even bothered to attend the conference”.
</p>
<p>Or “And that is why, <a href="https://slatestarcodex.com/2013/05/22/apart-from-better-sanitation-and-medicine-and-education-and-irrigation-and-public-health-and-roads-and-public-order-what-has-modernity-done-for-us/" rel="nofollow">to this very day</a>, we solve every international disagreement through total war.”
</p>
<p>Or “And that is why Martin Luther King was immediately reduced to a nonentity, and we remember the Weathermen as the sole people responsible for the success of the civil rights movement”
</p>
<p>But I think what I am <em>actually</em> going to say is that, for the love of God, if you like bullets so much, stop using them as a metaphor for ‘spreading false statistics’ and go buy a gun.
</p>
<h3>III</h3>
<p>So let’s derive why violence is not in fact The One True Best Way To Solve All Our Problems. You can get most of this from <a href="http://smile.amazon.com/gp/product/1619491702/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1619491702&amp;linkCode=as2&amp;tag=slastacod-20&amp;linkId=AYGYZKSORVSJ52VW" rel="nofollow">Hobbes</a>, but this blog post will be shorter.
</p>
<p>Suppose I am a radical Catholic who believes all Protestants deserve to die, and therefore go around killing Protestants. So far, so good.
</p>
<p>Unfortunately, there might be some radical Protestants around who believe all Catholics deserve to die. If there weren’t before, there probably are now. So they go around killing Catholics, we’re both unhappy and/or dead, our economy tanks, hundreds of innocent people end up as collateral damage, and our country goes down the toilet.
</p>
<p>So we make an agreement: I won’t kill any more Catholics, you don’t kill any more Protestants. The specific Irish example was called the Good Friday Agreement and the general case is called “civilization”.
</p>
<p>So then I try to destroy the hated Protestants using the government. I go around trying to pass laws banning Protestant worship and preventing people from condemning Catholicism.
</p>
<p>Unfortunately, maybe the next government in power is a Protestant government, and they pass laws banning Catholic worship and preventing people from condemning Protestantism. No one can securely practice their own religion, no one can learn about other religions, people are constantly plotting civil war, academic freedom is severely curtailed, and once again the country goes down the toilet.
</p>
<p>So again we make an agreement. I won’t use the apparatus of government against Protestantism, you don’t use the apparatus of government against Catholicism. The specific American example is the First Amendment and the general case is called “liberalism”, or to be dramatic about it, “civilization 2.0”.
</p>
<p>Every case in which both sides agree to lay down their weapons and be nice to each other has corresponded to spectacular gains by both sides and a new era of human flourishing.
</p>
<p>“Wait a second, no!” someone yells. “I see where you’re going with this. You’re going to say that agreeing not to spread malicious lies about each other would also be a civilized and beneficial system. Like maybe the Protestants could stop saying that the Catholics worshipped the Devil, and the Catholics could stop saying the Protestants hate the Virgin Mary, and they could both relax the whole thing about the Jews baking the blood of Christian children into their matzah.
</p>
<p>“But your two examples were about contracts written on paper and enforced by the government. So maybe a ‘no malicious lies’ amendment to the Constitution would work if it were enforceable, <em>which it isn’t</em>, but just <em>asking</em> people to stop spreading malicious lies is doomed from the start. The Jews will no doubt spread lies against <em>us</em>, so if we stop spreading lies about them, all we’re doing is abandoning an effective weapon against a religion I personally know to be heathenish! Rationalists should win, so put the blood libel on the front page of every newspaper!”
</p>
<p>Or, as Andrew puts it:
</p>
<blockquote>
<p>Whether or not I use certain weapons has zero impact on whether or not those weapons are used against me, and people who think they do are either appealing to a kind of vague Kantian morality that I think is invalid or a specific kind of “honor among foes” that I think does not exist.
</p></blockquote>
<p>So let’s talk about how beneficial game-theoretic equilibria can come to exist even in the absence of centralized enforcers. I know of two main ways: reciprocal communitarianism, and divine grace.
</p>
<p>Reciprocal communitarianism is probably how altruism evolved. Some mammal started running <a href="https://en.wikipedia.org/wiki/Tit_for_tat" rel="nofollow">TIT-FOR-TAT</a>, the program where you cooperate with anyone whom you expect to cooperate with you. Gradually you form a successful community of cooperators. The defectors either join your community and agree to play by your rules or get outcompeted.
</p>
<p>Divine grace is more complicated. I was tempted to call it “spontaneous …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slatestarcodexabridged.com/In-Favor-Of-Niceness-Community-And-Civilization">https://www.slatestarcodexabridged.com/In-Favor-Of-Niceness-Community-And-Civilization</a></em></p>]]>
            </description>
            <link>https://www.slatestarcodexabridged.com/In-Favor-Of-Niceness-Community-And-Civilization</link>
            <guid isPermaLink="false">hacker-news-small-sites-24190221</guid>
            <pubDate>Mon, 17 Aug 2020 18:29:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inviting employees back to the office – if you dare]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24189670">thread link</a>) | @ohjeez
<br/>
August 17, 2020 | https://www.functionize.com/blog/inviting-employees-back-to-the-office-if-you-dare/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/inviting-employees-back-to-the-office-if-you-dare/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/ft-back-to-the-office.jpg" alt="Inviting employees back to the office – if you dare" srcset="https://www.functionize.com/wp-content/uploads/2020/08/ft-back-to-the-office.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/08/ft-back-to-the-office-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/08/ft-back-to-the-office-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/08/ft-back-to-the-office-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Just because your state or city allows you to bring staff back to the office doesn’t mean that the facilities are ready for them to work safely. Here’s what you need to consider before employees return – assuming you can convince them to do so. Don’t count on that.</p></blockquote>
<p>This is a now-common tale: The developers and the rest of the company staff have been working at home since March. For the most part, things have gone well enough. After <a href="https://www.functionize.com/blog/software-qa-in-the-time-of-coronavirus/">some initial glitches</a>, the team is productive, reasonably happy (given the additional stress), and their goals are met.</p>
<p>However, the day is coming when you no longer have to keep everyone out of the office. You can bring them back. Or can you?</p>
<h3>Decorating the petri dish</h3>
<p>Before you bring staff back to a shared space, you have to comply with a new bunch of rules about office work to meet post-covid-19 guidelines. While the specific details may differ where you are, all of the new workplace rules include social distancing requirements. Almost certainly, your pre-covid-19 workplace doesn’t allow for six feet of space between workers.</p>
<p>The changes aren’t trivial. You need <a href="https://theconversation.com/goodbye-to-the-crowded-office-how-coronavirus-will-change-the-way-we-work-together-137382" target="_blank" rel="noopener noreferrer">physical reconfiguration of work areas</a>. Desks need to be farther apart, possibly with barriers between work stations. (So much for <a href="https://hbr.org/2018/01/sgc-research-when-moving-to-an-open-office-plan-pay-attention-to-how-your-employees-feel" target="_blank" rel="noopener noreferrer">the alleged benefits of collaboration</a> in an open office.) Because you probably don’t have space to move everyone apart, you need to decide whether you need everyone in the office at the same time – which means cultural impacts that are as important to think about as building airflow.</p>
<p>Let’s assume for the moment that you <em>do</em> want to bring people back into the corporate headquarters – or that you need to, for reasons of security. Here are the adjustments to make now, before people return to their commutes.</p>
<h3>Beyond office space</h3>
<p>According to Marina Vaamonde, CEO of real estate investment firm <a href="https://propertycashin.com/" target="_blank" rel="noopener noreferrer">PropertyCashin.com</a>, companies have to arrange for more parking than they had pre-Covid. The reason, she explains, is that <a href="https://time.com/5869375/public-transit-coronavirus-covid/" target="_blank" rel="noopener noreferrer">fewer workers are willing to share space on public transportation</a>. “People want to drive their own cars into work, so you need more parking,” she points out.</p>
<p>The office itself needs <a href="https://vicuspartners.com/articles/6-office-design-trends-post-covid-19/" target="_blank" rel="noopener noreferrer">a significant redesign</a>. “You need to have airflow and outdoor space,” Vaamonde explains. “Now that all of the communal indoor spaces are closed or used for offices, people want to have an outdoor area where they can meet and breathe fresh air.”</p>
<p>In fact, says Giridhara Raam M, product evangelist at <a href="https://www.zohocorp.com/" target="_blank" rel="noopener noreferrer">Zoho Corporation</a>, protecting employees requires a complete rethinking of the office itself. “Considering most of the work spaces operate with a centralized air conditioning system, it is better to avoid it. Work spaces need to be redefined; cubicle systems and socially distanced seating spots with free air flow should be adopted at least for a year. Open offices are even more satisfying than closed spaces, due to droplets.”</p>
<p>The physical configuration of the office has to change. “Cubicles are coming to an end,” Vaamonde says, because they don’t allow for social distancing.</p>
<p>But while barriers can be built around the cubicles, Vaamonde believes they won’t be necessary. The employees won’t be there to use them.</p>
<p>Expect big central offices, such as the ones in downtown Houston where Vaamonde works, to remain mostly empty. Employers may move to smaller offices in the suburbs, she predicts. “They will be more like coworking spaces where you have spaces for a day.” The newly-envisioned office will have more open space, providing larger areas where social distancing can be maintained.</p>
<p>All that assumes your employees are ready to come into the office, however. Don’t count on that.</p>
<h3>You might <em>want</em> employees to return to the office. Good luck with that plan</h3>
<p>Your staff has been <a href="https://www.functionize.com/blog/the-human-backup-establishing-the-teams-unlikely-successors/">working at home for nearly six months</a>. Many of those people are disinterested in coming back to an office for work. Others may feel that they only need to come into the physical plant occasionally, when they need access to services that are only available in the office, such as a specific test platform that can’t be reached via a cloud connection. And with so many cloud services nowadays, those are rare.</p>
<p>Sarah Riegelhuth, CEO and founder of <a href="https://www.growmyteam.com.au/" target="_blank" rel="noopener noreferrer">Grow My Team</a>, which specializes in hiring and engaging remote professionals, thinks that the ultimate resolution is for workforces to be mostly remote. “This allows people to <a href="https://www.theverge.com/interface/2020/5/15/21258793/bay-area-exodus-silicon-valley-san-francisco-facebook-google-apple-twitter-housing" target="_blank" rel="noopener noreferrer">live where they want to be</a>,” she says. It also permits flexible schedules, and other practices that enable staff to be more productive. (One reason: less time lost in social interactions.)</p>
<h3>Still: Some jobs do require on-site participation</h3>
<p>Businesses were forced to accept telework due to the pandemic. But that doesn’t mean everyone in every company can work from home in the long term. Manufacturing jobs, field support, and many service jobs must be done where the work actually is. Employees who deal with intellectual property and personally identifiable information may need to schedule their work so they address sensitive data on their few days in the office.</p>
<p>And there are other factors. This includes choosing which job functions should return to work first.</p>
<p>“Only the data critical roles should return back to corporate premises first, due to security concerns,” says Raam. “Others can stay back and facilitate remote work.” The critical resources can work in shifts assuring there are limited people inside a defined area.</p>
<p>In many cases, the end result is likely to be a mix of in-office workers and people continuing to work from their couches.</p>
<p>Ready or not, you have to change operations to deal with employees who will work at home permanently. Your management, HR, and IT systems need to adjust to a higher percentage of full-time telecommuters, for whom working from home is a better option. It’s your job to find a way to make that work.</p>
<p>That has a significant impact on office IT systems. For example, redefined work spaces mean that workstation locations will change, which affects how office computers connect to the network even if everything is wireless.</p>
<p>Likewise, the business needs to bring communication and security requirements for remote workers up to corporate standards. This may mean providing dedicated lines for employees who don’t have home internet service. Or the company may need to pay for a level of service beyond what the employee might otherwise need. Or a better chair.</p>
<p>Once you admit that the work-at-home phase isn’t temporary, the company may need to provide computers and software if employees are currently using personal computers or laptops. One reason is physical security. When employees use their own computers for work, it’s hard to prevent them from using the same devices for everything from their family’s homework to grocery shopping. The business computer needs client security and communications security products, such as corporate-grade VPNs, firewalls, or network security equipment.</p>
<h3>Split culture</h3>
<p>Finally, there’s the question about how corporate culture affects workers when they’re at home. Office politics will change, if only because it’s hard to get people involved in back-stabbing when their backs are back at home. “The reality is that there’s still a culture,” Riegelhuth says. “In my experience, the culture evolves.”</p>
<p>In many cases, some parts of the corporate culture, notably office politics, are diminished, which helps productivity. In others, such as the informal back channels that help decision making, the impact on the culture may be problematic. But Riegelhuth notes that there are ways to keep back channels and brain storming alive.</p>
<p>“We have a vision, we have a purpose and we have our values. We have a weekly team meeting where everybody comes on to Zoom,” Riegelhuth says. “We get an hour of face time every week.”</p>
<p>“One of the advantages that we’ve seen is looking at our health and wellbeing,” Riegelhuth adds. “Taking sick days used to be frowned on. It used to be a badge of honor not to take sick days.” Now, she says, the company culture has changed to make health and wellbeing important parts of her company’s culture.</p>
<p>There’s a general agreement among both managers and experts that remote working is here to stay. While some employees will always need to be in the building, most won’t. And in many cases, the company will organize itself so that it functions solely online. Some employees need to come to the office occasionally, some on a regular basis and a few most of the time.</p>
<p>But for office workers, the daily 9 – 5 in the building is a thing of the past. It may take some organizations a while to figure that out, but home will be where the heart, and the job, is.</p>
<blockquote><p>While you’re making changes, contemplate the who-does-what questions. For example, have you considered creating a Chief Quality Officer? <a href="https://www.functionize.com/project/why-your-enterprise-needs-a-cqo-chief-quality-officer/">Our white paper</a> goes into the details.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/WR-NBC-Photo-72DPI.jpg" alt="Wayne Rash"></p>
<div>
<p><span>by</span> Wayne Rash</p>
<p>Wayne Rash is based in Washington and has been writing about science and technology for nearly 40 years. He is a contributor to Forbes.com and a columnist for eWEEK. He is a frequent speaker on technology and has been a guest on NPR, NBC, PBS, CNN and Fox News.</p>
</div>

</div>
</div>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/inviting-employees-back-to-the-office-if-you-dare/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24189670</guid>
            <pubDate>Mon, 17 Aug 2020 17:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build an Iconic Company – Keith Rabois [audio]]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24189580">thread link</a>) | @craigcannon
<br/>
August 17, 2020 | https://nugget.fm/rabois/ | <a href="https://web.archive.org/web/*/https://nugget.fm/rabois/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="1"><p>Keith Rabois is a General Partner at Founders Fund. He's been a professional investor for the last seven years at Khosla Ventures and Founders Fund. Before that he spent thirteen years leading organizations such as PayPal, LinkedIn, and Square. He's served on the board of directors from inception to IPO of Yelp and Zoom. He's also an angel investor in Airbnb, Lyft, and other companies.</p></div></div>]]>
            </description>
            <link>https://nugget.fm/rabois/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24189580</guid>
            <pubDate>Mon, 17 Aug 2020 17:38:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amplitude Created a Self-Service Data Democracy, from Their EVP of Product]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24189128">thread link</a>) | @kelseyfecho
<br/>
August 17, 2020 | https://www.avo.app/blog/how-amplitude-created-a-self-service-data-democracy-according-to-their-executive-vp-of-product | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/how-amplitude-created-a-self-service-data-democracy-according-to-their-executive-vp-of-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Imagine the worst cafe rush-hour line you’ve ever had to wade through to get your latte. Now, instead of coffee, imagine that at the end of this hellish line was the data you needed about your products, pipeline, or customer behavior. Each time you need your data fix, you have to get up from your desk, walk down the hall, out of your house or office, and then wait in a queue behind hundreds of other people.</p><p>At the end of that line, instead of baristas, sit your data analysts, handing out the data that each individual person asks for. If anyone ends up needing more context, they have to get back in line and wait all over again.</p><p>If this sounds like a nightmare, that’s because it is. But it reflects a real constraint for many companies who haven’t democratized their data.</p><p>The future isn’t a data dictatorship—it’s self-service data democracy. One where, instead of waiting in line at a cafe for coffee, you can walk up to your own kitted-out setup in your office and get exactly what you need yourself.</p><p>Amplitude is the perfect example of this data-like-home-cafe approach to modern business. So I sat down with Justin Bauer, Amplitude executive vice president of product, to get some insight into how the company created a self-service data democracy that bridges the art and science of product development.</p><p><em>“Just like anything, [building a self-service data democracy is about] people, processes, and tools—in that order.” — Amplitude Executive Vice President of Product Justin Bauer</em></p><p>Sounds simple enough. But, below, we’ll take a closer look at what went into building the self-service data democracy that underpins one of the best data products around.</p><p>‍</p><h2><strong>1. Amplitude’s culture is built around a North Star.</strong></h2><p>A<a href="https://amplitude.com/blog/2018/03/21/product-north-star-metric"> North Star metric</a> is a single bar that everyone on every team at your company can use to measure whether or not your product is living up to the hype. It's the main support pillar that holds up your self-service data democracy.</p><p>The idea isn’t new, but it’s one that Amplitude has taken to heart and made their own.</p><p>For Bauer and the Amplitude team, their North Star is<a href="https://amplitude.com/blog/2018/03/21/product-north-star-metric"> weekly learning users</a> (WLUs). A WLU is an active Amplitude user who shares a resource they created with at least two other people within a week. Basically, it measures both initial user engagement, and whether or not users find the product worth sharing.</p><p>“It really ended up being the perfect metric for us to really reflect on what we were working on,” Bauer said.</p><p>But setting their sights on this guiding light wasn’t enough to align with it. Amplitude needed to create a culture and a system of habits that chased WLUs at every level of the company. To do this, Bauer and his team did three things:</p><ol role="list"><li><strong>Put into words the most basic promise of their product</strong> to understand what all other work should be in service to.</li><li><strong>Identified what <em>one </em>metric most signifies whether or not their product is useful to users.</strong> The performance of this metric was a binary tell of whether or not they’re following through on their promise to customers.</li><li><strong>Created a constellation of metrics that surrounded their North Star</strong> to build out the net of a self-service data democracy and give each team a way to make progress toward their North Star.</li></ol><p>Anyone who has heard of Amplitude knows that their main promise is to make it easier to build good products through data and collaboration. This mission clearly pointed in the direction of the company’s North Star, but the Amplitude team needed to come up with a constellation of metrics that would align work at every level with this guiding goal.</p><p>These supporting metrics were in direct service to boosting WLUs and gave each contributor a way to measure their performance and impact, without the need for data analysts or engineers. No more waiting in a long line to find out how products and features were performing.</p><p>“We really think of it not just as necessarily a single metric but also a constellation of metrics that all help guide you towards your product strategy,” Bauer said.</p><p>By filling their proverbial skies with metrics that all supported the one common goal of driving up WLUs—and, therefore, improving how worthwhile users found the platform—they built a culture that was wholly aligned with their main promise.</p><p>As a result, each team’s daily work furthers their progress toward their North Star metric and fits the transparent data-driven product strategy that supports it.</p><p>‍</p><h2><strong>2. They make sure everyone understands the data.</strong></h2><p>It’s all well and good if your employees have access to the data they—and others—produce, but they can’t make strong business decisions if they don’t understand what that data means. Without informed citizens, your self-service data democracy will shrivel up.</p><p>Back before the days of companies like Amplitude, the only people who understood data were the ones who created it, mainly the aforementioned engineers and data analysts. This created our nightmarish cafe scenario from the beginning.</p><p>Thankfully, Bauer and his team, like many industry leaders, took the secondhand gold of why data dictatorships suck and did the opposite. They intentionally and consistently educated their teams to ensure that they knew where to go for data, how to read its insights, and how to integrate those insights into practice.</p><p>The way that Amplitude began to foster this understanding is the same process for how they maintain the knowledge today:</p><ul role="list"><li><strong>Give each team and contributor a micro metric</strong> <strong>to focus on</strong> that lines up with daily work and supports the overall North Star metric.</li><li><strong>Educate team members on the tools</strong> available to them to pull and read data insights.</li><li><strong>Encourage team members to look closely at data</strong> to answer everyday tasks and experiment with new ideas.</li><li><strong>Anchor all product decisions to data</strong>, and clearly communicate how the work of each team affects higher-level goals.</li></ul><p>By making sure everyone from sales to engineering understands the data they’re creating—and knows how to create high-quality data through data governance (as we’ll discuss below)—Bauer and the Amplitude team empowered their democratic citizens to make the best decisions possible.</p><p>‍</p><h2><strong>3. Amplitude empowers engineers to use data themselves.</strong></h2><p>The truth is, while engineers are an integral part of building a great product, they’re traditionally seen as the last part of the implementation waterfall. This cuts off at the knees the decision-making power and insights of developers, and it’s time that changed.</p><p>In a self-service data democracy, Bauer said, engineers need to be empowered to use data themselves. Doing so lets them see the direct impact of their work and helps them make better cases for features they think would make the product stronger.</p><p>“Engineers can actually even use metrics to try to fight for the areas they want to invest behind,” Bauer said. “It's a great way to actually democratize who's even making product decisions.”</p><p>So, to make both engineers better and the product stronger, Amplitude handed engineers the key to their data democracy. This not only made their engineers happier but also helped them be more engaged in the work they were doing, Bauer said.</p><p><em>“Now they are highly incentivized to actually do the instrumentation because they want to see if the work they're doing is actually helping improve those metrics and helping the business grow.”</em></p><p>But this wasn’t simply a matter of granting engineers access to data tools. The process, like that of educating the company as a whole about data, had to be done intentionally through the following steps:</p><ul role="list"><li><strong>Bring engineers into the strategy and goal setting</strong> early on so everyone is on the same page.</li><li><strong>Educate engineers on how Amplitude measured success</strong> so they can measure their work in relation to the North Star metric.</li><li><strong>Develop a</strong><a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"><strong> well-thought-out tracking plan</strong></a> to ensure analytics implementation is done consistently from the beginning.</li><li><strong>Empower engineers to use data tools</strong> to see how their product decisions affect performance and experiment with new features.</li></ul><p>When Amplitude’s engineers were given a seat at the table and empowered to make the case for new features and improvements through data, the whole organization was able better fulfill its promise to customers.</p><p>‍</p><h2><strong>4. They focus on creating great governance.</strong></h2><p>Good governance is at the heart of all successful democracies and ensures that people have access to high-quality data and that processes are in place to continue this in the future.</p><p>“Leading companies are starting to realize that, in a world of data democracy, governance is important,” Bauer said. “If you invest behind that, then you get the dividends of self-service data democracy ... [But] it actually takes a lot of work to govern data well, to ensure that the people have the right levels of access and what they’re accessing is high quality.”</p><p>Rather than restrict contributors and only give them access to the data directly related to their jobs via analysts, Amplitude created a detailed governance strategy that ensured the free flow of consistent, correct information.</p><p>But this didn’t happen overnight. Good data takes hard work and<a href="https://www.avo.app/blog/data-governance-maturity-model-how-mature-is-your-approach-to-data"> mature governance</a>.</p><p><em>“You can’t just get democracy for free.”</em></p><p>Amplitude “paid” for good governance by investing in and enforcing data best practices, standardization documents, and tracking plans. These efforts helped them create a clean, single source of data truth that evolves with the company as time goes on.</p><p>“There’s a lot more focus on data quality, and people are starting to really treat it the same way you might treat something like code quality,” Bauer said. “You actually have to have even higher data quality to ensure that people make the right decisions.”</p><p>To create governance to guide every team within the company, while granting access to data at every level, Amplitude worked through the following steps:</p><ul role="list"><li><strong>Audited the current state of tracking and governance</strong> to understand what was already in place.</li><li><strong>Created a map of their customer life cycle and the metrics that support it</strong> to ensure that their customer life cycle complemented their North Star metric.</li><li><strong>Assigned a point person</strong>…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.avo.app/blog/how-amplitude-created-a-self-service-data-democracy-according-to-their-executive-vp-of-product">https://www.avo.app/blog/how-amplitude-created-a-self-service-data-democracy-according-to-their-executive-vp-of-product</a></em></p>]]>
            </description>
            <link>https://www.avo.app/blog/how-amplitude-created-a-self-service-data-democracy-according-to-their-executive-vp-of-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-24189128</guid>
            <pubDate>Mon, 17 Aug 2020 17:00:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analogies in Product Management]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24189085">thread link</a>) | @irontinkerer
<br/>
August 17, 2020 | https://www.timothybuck.me/blog/analogies-in-product-management | <a href="https://web.archive.org/web/*/https://www.timothybuck.me/blog/analogies-in-product-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-layout-label="Post Body" data-type="item" data-updated-on="1552622740799" id="item-5c8b2481652dea8792d015d3"><div><div><div data-block-type="2" id="block-826d624db7e34ac6a5e6"><div><p>When I approach a new product problem, after I’ve interacted with users, dug into the data, researched the market, and built a clear problem statement, I've found it incredibly valuable to set aside time to look for analogies. </p><p>Studying your competition can be quite valuable, but that's not what I mean in this case. I'm talking about <strong>researching analogous problems in other fields</strong> that have already been solved (or have failed to be solved) by companies in those markets.</p><p>In my experience, these analogies are hugely beneficial for two primary purposes: storytelling and solution design.</p><h2>Storytelling</h2><p>Analogies should always take a back seat to a clear, compelling, empathy-inducing problem statement, but as a product manager pitching or explaining the problem you're solving, analogies can be powerful frames of reference for others. This can be true in a wide variety of situations such as:</p><ul data-rte-list="default"><li><p>Pitching your work to executives, investors, managers.</p></li><li><p>Getting buy-in from non-product groups who may be necessary to fully solve your problem statement or are impacted by the solution.</p></li><li><p>Building excitement in the product, engineering, design teams who will be working on this problem. </p></li></ul><h2>Solution Design</h2><p>Analogies have the potential to be either beneficial or detrimental to solution design. It’s important to make it clear to your product team that the analogy is not the solution but a jump-start for the solution design process. Without calling that out up front, analogies can stifle creativity and put the team in a copying mindset. When used correctly, analogies will provide the product team with a launching point for conversation and permission to think outside the box.</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.timothybuck.me/blog/analogies-in-product-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-24189085</guid>
            <pubDate>Mon, 17 Aug 2020 16:57:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s Flying Above Us?]]>
            </title>
            <description>
<![CDATA[
Score 487 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24188661">thread link</a>) | @zuhayeer
<br/>
August 17, 2020 | https://skycircl.es/donate/ | <a href="https://web.archive.org/web/*/https://skycircl.es/donate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <figure>
                <!-- <picture>
                    <source srcset="cbp-reaper-over-minneapolis.webp" type="image/webp">
                    <source srcset="cbp-reaper-over-minneapolis.jpg" type="image/jpeg">
                    <img class="hero" src="cbp-reaper-over-minneapolis.png">
                </picture> -->
                <picture>
                    <source srcset="https://skycircl.es/donate/buzzfeed-circles.webp" type="image/webp">
                    <source srcset="https://skycircl.es/donate/buzzfeed-circles.jpg" type="image/jpeg">
                    <img src="https://skycircl.es/donate/buzzfeed-circles.png">
                </picture>
                <figcaption>
                    DHS &amp; DOJ aircraft over Los Angeles (Buzzfeed)
                </figcaption>
            </figure>

            <p>
                What's flying above us?
            </p>
            <p>
                I'm working to make it easy to find out.
            </p>
            <p>
                Here's how:
            </p>

            
            <p>
                My <a href="https://twitter.com/lemonodor/status/1294002338215034880">Advisory Circular network of
                    twitter bots</a> post in real-time whenever they detect aircraft
                flying in circles over cities around the world, including Los Angeles, Baltimore, Portland, Minneapolis,
                and London. The bots often tweet about news and fire aircraft, and because they use an uncensored source
                of data they also tweet police, FBI, DHS, DEA, CBP, and military
                aircraft. They look for circles because it means an aircraft is <i>doing something</i> instead of
                <i>going somewhere</i>. If you've ever asked “what is that helicopter/plane?” there’s a good chance my
                bots can answer your question—even if it's an advanced military surveillance plane:
            </p>

            <blockquote>
                <p lang="en" dir="ltr">91-00504, a military Swearingen RC-26B Metroliner, is circling over Bancroft,
                    Minneapolis at 8675 feet, squawking 0243, 0.06 miles from 39 St E #91_00504 <a href="https://t.co/ZAAowIcvwi">https://t.co/ZAAowIcvwi</a> <a href="https://t.co/9WHKOSiskZ">pic.twitter.com/9WHKOSiskZ</a></p>— Advisory Circular
                Minneapolis-St. Paul (@SkyCirclesMPLS) <a href="https://twitter.com/SkyCirclesMPLS/status/1267681883862650887?ref_src=twsrc%5Etfw">June 2,
                    2020</a>
            </blockquote>
            

            
            <p>
                A few years ago I <a href="https://docs.google.com/presentation/d/1sowJrQQfgxnLCErb-CvUV8VGXdtca6SWYWWLRPZgaHI/edit?usp=sharing">discovered
                    a secret FBI aerial surveillance program</a>, involving more than 100 aircraft
                registered to front companies. I was one of the first people to <a href="https://news.ycombinator.com/item?id=9508812">post online</a> about the program.
            </p>
            <p>From a <a href="https://web.archive.org/web/20150605064602/http://fusion.net/story/143739/how-you-can-track-the-fbis-spy-planes/">Fusion
                    Media
                    article</a>:</p>
            <blockquote>
                This week, the Associated Press reported that the FBI is regularly flying “spy planes” over American
                cities.

                The report, which revealed the front companies the FBI uses to fly the planes, wasn’t a surprise to John
                Wiseman, a technologist in Los Angeles. Based on public records, he had already figured out some of the
                planes the FBI was flying and, using a
                device he programmed to intercept airplane transmissions, had identified over the last month the ones
                flying overhead in L.A. in real time.
                Wiseman wrote in a Hacker News comment in May about his findings, revealing a month ago what the AP
                reported today.
            </blockquote>

            <p>
                I continue to help journalists with stories related to government aerial surveillance.
            </p>
            
            <p>
                I created a <a href="https://twitter.com/lemonodor/status/1238149529469202433">Siri shortcut</a> that
                lets you ask what's overhead at any time, and it will tell you what
                the nearest aircraft is and who it's registered to. It uses the same uncensored data source as
                the Advisory Circular bots.
            </p>

            
            <p>
                I've always funded this work myself, but now I'm in the situation of having been furloughed without pay
                since April.
            </p>
            <p>
                I’ve spent hundreds of hours in development work trying to bring the public this essential
                information for free. I'd like to continue this work, both supporting existing projects and implementing
                new ideas (I'd also like to replace my broken laptop).
            </p>
            <p>
                If you would like to support this effort and help keep the servers running, please donate below. <b>You
                    can
                    give a one-time donation with PayPal or Venmo, or a recurring donation with PayPal.</b>
            </p>

            <p>
                Thanks for your help!<br>
                John Wiseman
            </p>
            <p>psst... if you're a nerd, coder, and/or planetracker and want some more details, check out
                <a href="https://skycircl.es/donate-nerd-mode/">this page.</a></p>

            

            <p><a href="https://skycircl.es/donate/venmo-qr-code.jpg"><img alt="Venmo button" src="https://skycircl.es/donate/venmo-button.png" width="200" height="59"></a></p><!-- <a href="bitcoin:13FjNbDnUrJxku6h8ceg7XzhKTCgJkVSRB"><img alt="bitcoin button" src="bitcoin-button.png" width="200" height="76""></a> -->
            
        </div></div>]]>
            </description>
            <link>https://skycircl.es/donate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24188661</guid>
            <pubDate>Mon, 17 Aug 2020 16:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chat server on a WiFi-enabled SD card]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24188648">thread link</a>) | @l00sed
<br/>
August 17, 2020 | https://l-o-o-s-e-d.net/wartor | <a href="https://web.archive.org/web/*/https://l-o-o-s-e-d.net/wartor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <p><h2>warTOR</h2></p>
            
            <div>
              <p>09:00am | 02/08/2020<br>Daniel Tompkins</p>
              

 
            </div>
            <p>Oddly, I don't remember when or how I got my hands on the <a target="_blank" href="https://www.toshiba-memory.com/products/toshiba-wireless-sd-cards-flashair-w-04/">Toshiba <em>FlashAir</em></a> card. These WiFi-enabled SD cards are made to transfer photos from a digital camera to a computer.</p>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/flashair.png">
              <p><img data-src="assets/img/wartor/flashair.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/flashair.png">
              </p>
            </a>

            <div>
              <p>Imaginging that someone would use a 4MBps wireless connection to transfer photos when the hardware transfer is closer to 70MBps seems ridiculous.</p>
              <p>However, it could come in handy if you're in a situation where you don't have access to an SD card reader, or want to easily preview photos on a phone or tablet.</p>
            </div>

            <p>
              <h3>Digging into the <em>FlashAir</em></h3>
            </p>
            <div>
              <p>What's far more interesting about these Toshiba cards is the fact that they are essentially programmed to act as a <a target="_blank" href="https://en.wikipedia.org/wiki/Wireless_access_point">wireless access point (WAP)</a>. You can setup a custom SSID and password— connecting directly to the card over 2.4GHz.</p>
              <p>After peeking at the filesystem, I realized that the main photo gallery application hosted on the card is essentially a static website— served as basic HTML, CSS and JavaScript.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/flashair-filesystem.png">
              <p><img data-src="assets/img/wartor/flashair-filesystem.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/flashair-filesystem.png">
              </p>
            </a>

            <p>My excitement with this bit of tech was the possibility of building a totally discrete microserver that would be capable of hosting a few pages and services.</p>

            <p>
              <h3>Project Inspiration</h3>
            </p>
            <div>
              <p>My fourth-year undergraduate architecture studio, entitled <em>Dark Rooms</em>, was taught by <a target="_blank" href="https://m-a-u-s-e-r.net/">Mona Mahall</a>. The studio was split into three exhibitions: <em>Pyramid, Server and Backstage</em>. These exhibitions were meant to explore the "spaces between visibility and invisibility".</p>
              <p>In the second exhibition, <em>Server</em>, we were asked to consider the design of an anti-human space— a dark, cold, electronic archive built exclusively for machines. In my preliminary research, I was particularly interested in artists like <a target="_target" href="https://arambartholl.com/dead-drops/">Adam Bartholl</a>.</p>
              <p>His project, a USB "<a target="_blank" href="http://deaddrops.com/">dead drop</a>", drew inspiration from an information-sharing tactic used by spies. A predetermined secret location— such as a hollowed-out rock, brick, log or other object— would be used to discreetly stash an important item.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/USB-dead-drop.png">
              <p><img data-src="assets/img/wartor/USB-dead-drop.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/USB-dead-drop.png">
              </p>
            </a>

            <p>Once the item— perhaps a slip of paper or a key— is "dropped", a second party could then retrieve it without interacting directly with the other person or being detected in the exchange.</p>

            <p>
              <h3>Wireless Anonymous Repository</h3>
            </p>
            <div>
              <p>While a USB is already a much more "invisible" way of storing and exchanging information, I wanted to take this concept a step further. Using the <em>FlashAir</em> cards, I proposed a new wireless dead drop that could be just as affordable and simple as the USB, but with a myriad of superior qualities.</p>
              <p>Writing directly to the card requires an SD card slot; however, the wireless functionality can be powered without a desktop or laptop. A typical SD card takes 2.4-3.6V at about 30mA. I found that by using an SD-to-USB adapter, one could power the wireless module from a standard 5V USB outlet.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-AC.png">
              <p><img data-src="assets/img/wartor/wartor-AC.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-AC.png">
              </p>
            </a>

            <p>Depending on the location of the dead drop, this could be concealed within a false junction box that would be plugged in over the top of a standard 2-outlet 120V AC. If— in the spirit of the original USB dead drop— you wanted to embed the card in a brick wall, then the device could be powered from a USB powerbank.</p>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-outlet.png">
              <p><img data-src="assets/img/wartor/wartor-outlet.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-outlet.png">
              </p>
            </a>

            <p>I named the project <em>warTOR</em> for "wireless anonymous repo" + <a target="_blank" href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">TOR</a>. Though it's not connected to the Tor network in any way, I thought this title captured the spirit of anonymity (plus I wanted to use some Pokémon sprites). If someone would like to try it, the Toshiba cards <em>can</em> be setup as a wireless bridge... from a Tor gateway?</p>

            <p>
              <h3>Future Plans</h3>
            </p>
            <div>
              <p>Something else that I'd like to try is powering the card via a small solar cell, but I haven't gotten there yet... The greatest benefit of the wireless dead drop is that one could log into the WAP from their cellphone, upload or download a file, and no one could discern that any sort of exchange was happening. However, I'm also working on a clientside chat application that could be hosted on the cards.</p>
              <p>With this implemented, then two people could sit down in a café and send messages back and forth over the private network; or, someone could login to the network and type out a message for the other person to see at a later date.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-screenshots.jpg">
              <p><img data-src="assets/img/wartor/wartor-screenshots.jpg" src="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-screenshots.jpg">
              </p>
            </a>

            <div>
              <p>Here are some screenshots from the application 👆. I'll be doing a follow-up post with a GitHub link to the <em>FlashAir</em> CONFIG file that I'm using on my card. I'll also upload the source code for the original <em>warTOR</em> server with instructions on how you can deploy your own <em>warTOR</em> in the wild!</p>
              <p>Hope you enjoyed this project. If you'd like, please subscribe for updates (livestreams, new posts) or follow me on Twitter or leave a note below! Thanks for reading <em>loosed</em>.</p>
            </div>
          </div>
        </div></div>]]>
            </description>
            <link>https://l-o-o-s-e-d.net/wartor</link>
            <guid isPermaLink="false">hacker-news-small-sites-24188648</guid>
            <pubDate>Mon, 17 Aug 2020 16:17:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Bear minimum – Building a super simple blog with Bear.app]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24188353">thread link</a>) | @Essa
<br/>
August 17, 2020 | https://saul.at/building-a-simple-blog-with-bear.html | <a href="https://web.archive.org/web/*/https://saul.at/building-a-simple-blog-with-bear.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        <b>TLDR:</b> Create a super simple minimalist blog with little to no coding
        experience. Get <a href="https://bear.app/" target="_blank">Bear</a> (only available on
        Apple devices), export notes as HTML files, upload to GitHub, then link
        to host/domain. Profit!
      </p>
      
      <p>
        I love things that are stripped down to the bare essentials, but still
        do their job well. I try to replicate this in both my personal and work
        life. Here’s why:
      </p>
      
      <p>Big chunky things = Scary</p>
      <p>Scary = Never gets done</p>
      <p>Small and super simple = Gets done</p>
      
      <p>
        To get stuff done, I break down and simplify tasks to a degree that some
        might consider excessive. This forcing function also helps me consider
        and address core issues versus symptoms. This post is about how I used
        this approach to quickly create a blog.
      </p>
      
      <p>
        Having used Bear for years to keep a daily journal, I decided to start writing online. With Bear as the inspiration, I listed what I needed
        <b>now</b>, ignoring what I might one day use. The first approach leads to a simple but finished project, the momentum of a win, and the option for future
        improvements. The latter invites indecision, complexity, delays, and usually doesn’t get me very far.
      </p>
      
      <p>My ideal blog needed to be:</p>
      <ol start="1">
        <li>Self hosted on a custom domain.</li>
        <li>Exceedingly easy to set up and update.</li>
        <li>Text based. Images were not an immediate priority.</li>
        <li>Styled for readability.</li>
      </ol>
      
      <p>
        By listing problems <b>before</b> looking for solutions, I can quickly
        filter results that don’t match. I’m then less likely to fall prey to
        premature optimisation, marketing or <a href="https://www.nngroup.com/articles/aesthetic-usability-effect/" target="_blank">aesthetic usability bias</a>.
      </p>
      
      <p>
        Most solutions (including Wordpress) simply did too much. Paradox of
        choice was another issue. Having so many off-the-shelf options, each
        with a microcosm of near infinite themes and widgets, was just too overwhemling. 
      </p>
      
      <p>
        I took a step back and considered if my time would instead be better spent building a blog from scratch. A quick Google once again
        presented a paradox of choice; an endless number of ways or frameworks to choose from. I’m not a programmer and didn’t know where to start, so
        I took another step back. I drew up a simple plan, filled in some blanks, and decided to ask a friend about the rest.
      </p>
      
      <p>
        I realised that Bear could export notes in HTML, including all the CSS styling at the bottom. This was a huge win as I could use Bear to create a simple home               
        page with a title, a paragraph, and an unordered list of links to individual posts. As for the posts themselves, I just needed to write them up in Bear 
        and export them.
      </p>
      
      <p>
        Enter <a href="https://kasun.io/" target="_blank">Kasun</a>, a friend, indie-hacker and
        freelance programmer (who’s currently working remotely while travelling
        across Sri Lanka). He was kind enough to teach me some basics about
        HTML, hosting, and linking domains. Here’s what we did:
      </p>
      <br>
      <ol start="1">
        <li>Create and export notes from Bear.</li>
        <li>Create a <a href="https://github.com/" target="_blank">GitHub</a> account and paste the
          exported code into a project.
        </li>
        <li>Use <a href="https://vercel.com/" target="_blank">Vercel’s</a> free tier for hosting
          and link to Github.
        </li>
        <li>Link domain to Vercel.</li>
      </ol>
      
      <p>
        That’s pretty much it really. For someone familiar with the basics, it
        would have taken under 15 mins to have a minimalist, well styled, and
        self-hosted blog, all without writing a single line of code.
      </p>
      
      <p>
        In the end, not only did I get my blog, but I also learned some basic
        web development! It’s a big win in my book and I wanted to share this
        post in case others (especially other Bear fans) want to do something
        similar.
      </p>
      <br>
      <h3 id="Postscript notes:">Postscript notes:</h3>
      <ul>
        <li>Considering the number of available options, it’s likely that I missed something that would have been a good fit. If so, feel free to tweet me a link.
        </li>
        <li>This blog is the first website I’ve built and has helped me realise that code isn’t as “scary” as I once thought 😊.
        </li>
        <li>Images aren’t included by default in Bear HTML exports. To include them, you have to manually upload the picture to your GitHub project and then include a link in the relevant HTML file as part of an image tag.
        </li>
        <li>Developer friends have mentioned that the formatting of the exported html file isn’t great. While not a huge problem for me, I will use it as a way to learn more about formatting best practices.
        </li>
        <li>Big thanks to the talented <a href="https://kasun.io/" target="_blank">Kasun</a> for
          the help! I can’t recommend him enough if you’re on the lookout for a
          freelance developer. If you’re a designer, be sure to check out
          <a href="https://whatthehex.app/" target="_blank">What the Hex?!</a>, one of his
          projects that lets you quickly assign names to your design system
          colour palette.
        </li>
        <li>If you’d like to build something similar and have questions, I’d love
          to hear from you!
        </li>
        <br>
      <a href="https://saul.at/">Return to home</a>
      </ul>
    </div></div>]]>
            </description>
            <link>https://saul.at/building-a-simple-blog-with-bear.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24188353</guid>
            <pubDate>Mon, 17 Aug 2020 15:50:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using a Yubikey as a touchless, magic unlock key for Linux]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24188172">thread link</a>) | @Pneumaticat
<br/>
August 17, 2020 | https://kliu.io/post/yubico-magic-unlock/ | <a href="https://web.archive.org/web/*/https://kliu.io/post/yubico-magic-unlock/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Yubikeys are great for security, but their benefits decrease somewhat when you leave them in your computer unattended.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> I unfortunately have a habit of forgetting my key when I walk away from the computer. I also have login passwords that are way too long and easy to typo.</p>
<p>Thankfully, there’s a way to solve both of these problems: use a Yubikey to unlock your computer when you put it in and lock your computer when you remove it!</p>
<h2 id="prior-art">Prior art<a href="#prior-art" arialabel="Anchor">⌗</a> </h2>
<p>The first example I remember seeing of this concept years ago was <a href="https://www.predator-usb.com/predator/en/index.php">Predator</a>, Windows software (with a delightfully retro website) that locks your computer when you remove a special USB drive. Similar examples for Linux include <a href="https://wiki.debian.org/pamusb">pamusb</a>, which allows you to login using Linux’s PAM by inserting a specially-formatted USB stick.</p>
<p>Of course, nowadays most people use Yubikeys to accomplish this, and Yubico has <a href="https://developers.yubico.com/yubico-pam/Authentication_Using_Challenge-Response.html">convenient guides</a> on how to accomplish this very task. However, I wanted to make it <em>touchless</em> – that is, I wanted to be able to plug in my Yubikey and instantly unlock my laptop, without clicking through logins or touching the Yubikey button. Upon removal, I wanted to instantly lock my computer.</p>

<p>There are some guides on how to do this online (unlock when you plug in, lock when you remove), but unfortunately most of them fall prey to the problem described in <a href="https://medium.com/@d0znpp/how-to-sacrifice-security-using-a-public-yubikey-linux-guides-c823c4c6e2">this article</a>. A lot of them use udev to detect when the Yubikey is plugged in, but they don’t actually authenticate the key beyond checking its vendor ID, model ID, and sometimes serial number, which all can <a href="https://forums.anandtech.com/threads/changing-creating-a-custom-serial-id-on-a-flash-drive-low-level-blocks.2099116/">easily be faked</a>.</p>
<p>To provide actual security, most official guides use either <code>pam_u2f</code> (which authenticates a Yubikey through the <a href="https://en.wikipedia.org/wiki/Universal_2nd_Factor">U2F protocol</a>) or <code>pam_yubico</code> (which uses either online validation through YubiCloud or offline validation through a challenge-response protocol). The U2F method requires a tap on the Yubikey, while the challenge-response process can be done without user interaction, so I went with the latter. I set up traditional Yubikey authentication using <a href="https://support.system76.com/articles/yubikey-login/">this great guide from System76</a>.</p>
<p>However, I still needed some way to test the challenge-response for success when I plugged in the key. Usually, <code>pam_yubico</code> is run when you login or unlock your computer (i.e. when pressing the enter key on the lockscreen). But I didn’t want <em>any</em> clicks, so I needed a way to run it without interaction.</p>
<p>Enter <code>udev</code> (again) and <code>pamtester</code>!</p>
<p>Here’s the udev rules I included:</p>
<pre><code>kevin@you:~ » cat /etc/udev/rules.d/yubikey.rules
ACTION=="remove", ENV{DEVTYPE}=="usb_device", ENV{PRODUCT}=="1050/407*", RUN+="/usr/local/sbin/ykunlock.sh lock"
ACTION=="add", ENV{DEVTYPE}=="usb_device", ENV{ID_BUS}=="usb", ENV{PRODUCT}=="1050/407*", RUN+="/usr/local/sbin/ykunlock.sh unlock"
</code></pre><p>These rules effectively call a script when inserting and removing the key, so I can trigger any action from the script. Note that the script <strong>should not immediately unlock the computer</strong>, to avoid the security issues mentioned earlier.</p>
<p>To actually test the challenge-response from the Yubikey on inserting, I decided to use <a href="http://pamtester.sourceforge.net/">pamtester</a>, a simple utility that pretends to trigger a PAM authentication from the command line. Since <code>pam_yubico</code> is installed, this will naturally test the challenge-response if a Yubikey is plugged in.</p>
<p>Here’s the final script:</p>
<div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>exec 1&gt; &gt;<span>(</span>logger -s -t <span>"</span><span>$(</span>basename <span>"</span>$0<span>"</span><span>)</span><span>"</span><span>)</span> 2&gt;&amp;<span>1</span>
echo <span>"RUN"</span>
<span>if</span> <span>[</span> <span>"</span>$1<span>"</span> <span>=</span> <span>"lock"</span> <span>]</span>; <span>then</span>
        pkill -USR1 swayidle
<span>else</span>
        <span># unlock</span>
        <span>if</span> echo <span>""</span> | pamtester login kevin authenticate; <span>then</span>
                <span># PAM login successful</span>
                <span># kill locker</span>
                kill -KILL <span>$(</span>pgrep swaylock<span>)</span>
                ps aux | grep swaylock
                <span># turn on displays</span>
                SWAYSOCK<span>=</span><span>$(</span>ls /run/user/1000/sway-ipc.*.sock<span>)</span> swaymsg <span>"output * dpms on"</span>
        <span>fi</span>
<span>fi</span>
exit <span>0</span>
</code></pre></div><ul>
<li>On lock, it immediately locks my desktop (by sending a SIGUSR1 to swayidle, the program that manages locking on the Sway window manager)</li>
<li>On unlock, it first sees if it can authenticate using pamtester without interaction (when no Yubikey is inserted or if the key is invalid, pamtester asks for a password). If it can, it kills the lockscreen and turns on all displays using Sway WM protocols.</li>
</ul>
<p>The final result is amazingly convenient, and has successfully made me remember to pull out my Yubikey when leaving my computer unattended more than once<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>! Mission success.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I’ve significantly downgraded this statement in severity after some excellent comments on Hacker News have pointed out that (1) <a href="https://news.ycombinator.com/item?id=24192390">stealing a Yubikey is incredibly unlikely unless you’re a person of interest</a>; (2) <a href="https://news.ycombinator.com/item?id=24192138">even if you have the Yubikey, you still can’t directly extract e.g. a private key</a>; and (3) a <a href="https://news.ycombinator.com/item?id=24190313">Yubikey protects against SSH/GPG fraud because it can require a PIN and lock out over time</a>. Case in point, Yubikeys are good. I’d argue that it’s still not good to have your key stolen (e.g. perhaps if you’re targeted by a government/<a href="https://news.ycombinator.com/item?id=24194081">industrial espionage</a>, or the malicious significant other attack, where they know your password and can steal your key for 2FA if unattended), but I see that it’s not as much of a risk as I originally thought. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>You might call it Yubikey: Coronavirus Edition. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Yes, yes, I know there’s not too much of a danger because we’re all stuck at home right now. But who knows – maybe this will be helpful when we <em>eventually</em> get back on campus. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div></div>]]>
            </description>
            <link>https://kliu.io/post/yubico-magic-unlock/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24188172</guid>
            <pubDate>Mon, 17 Aug 2020 15:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pathological Lying: Theoretical and Empirical Support for a Diagnostic Entity]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24187224">thread link</a>) | @InInteraction
<br/>
August 17, 2020 | https://psychnewsdaily.com/about-13-percent-of-people-are-pathological-liars/ | <a href="https://web.archive.org/web/*/https://psychnewsdaily.com/about-13-percent-of-people-are-pathological-liars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A new study has found that 13% of people think of themselves as pathological liars, or say that others consider them to be pathological liars. Those 13% reported telling about 10 lies per day.</p><p>The study, published in the journal <a href="https://prcp.psychiatryonline.org/doi/10.1176/appi.prcp.20190046#.XvDDrEQ2jzE%20">Psychiatric Research and Clinical Practice</a>,&nbsp;included 623 people. The researchers recruited them in 2019 from various mental health forums, social media, and a university.</p><p>The participants spanned a range of ages, ethnicities, education levels, and income levels. The researchers asked them whether they thought of themselves as pathological liars, or if others thought of them that way. The respondents also took a lie frequency assessment and other questionnaires.</p><h2>Greater distress and impaired functioning</h2><p>The study found the pathological liars were more likely to experience distress and impaired functioning, especially in social relationships. This diminished functioning also applied to legal contexts, work, and finances. Their distress often had to do with worries about whether their lies would be be discovered.</p><p>The pathological liars in the group also reported telling lies for no specific reason, and said many of their lies grew out of an initial lie.</p><p>The majority of participants in the pathological liars group indicated that their problematic lying began during adolescence. People in this group were also more likely to say their lying was out of their control, indicating a kind of compulsiveness. Likewise, people in this group said they felt less anxious after lying.</p><h2>From <em>pseudologia phantastica</em> to pathological liars</h2><p>The phenomenon of the “pathological liar” was first recorded in 1891 by psychiatrist <a aria-label="undefined (opens in a new tab)" href="https://www.amazon.co.uk/pathologische-L%C3%BCge-psychisch-abnormen-Schwindler/dp/3226034618/ref=sr_1_2?dchild=1&amp;qid=1594994372&amp;refinements=p_27%3AAnton+Delbr%C3%BCck&amp;s=books&amp;sr=1-2" target="_blank" rel="noreferrer noopener">Anton Delbr?ck</a>. He initially called it <em>pseudologia phantastica</em>, and used the term to describe people who told so many outrageous lies that their behavior could be considered pathological.</p><p>Since then, research into pathological lying has been surprisingly scant. One <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0447.1988.tb05068.x">analysis</a> of prior case studies found <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Pathological_lying" target="_blank" rel="noreferrer noopener">pathological lying</a> equally represented among men and women, with the <a aria-label="undefined (opens in a new tab)" href="https://psychnewsdaily.com/category/iq/" target="_blank" rel="noreferrer noopener">IQs</a> of the liars in the average to above average range.</p><h2>Formal recognition</h2><p>Pathological lying has not (yet) been classified as a diagnostic entity in either the <a aria-label="undefined (opens in a new tab)" href="https://www.psychiatry.org/psychiatrists/practice/dsm" target="_blank" rel="noreferrer noopener">DSM-5</a> or the <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/ICD-10" target="_blank" rel="noreferrer noopener">ICD-10</a>, but the researchers behind the present study are hoping to change that. As they write, “we suggest that PL should be defined as a persistent, pervasive, and often compulsive pattern of excessive lying behavior that leads to clinically significant impairment of functioning in social, occupational, or other areas.”</p><p>Pathological lying also causes distress, they say, and poses a risk to the self or others; an example of this risk is if a pathological liar conceals the presence of suicidal thoughts.</p><p>Formal recognition of pathological lying as a disorder would bring many benefits, as researchers would then be better able to examine its features and causes. And effective treatments, such as cognitive-behavioral therapy and possibly pharmaceutical drugs, could then be more thoroughly investigated.</p><hr><p><strong>Study:</strong> P<em>athological Lying: Theoretical and Empirical Support for a Diagnostic Entity</em><br><strong>Authors: </strong><a href="https://prcp.psychiatryonline.org/doi/10.1176/appi.prcp.20190046#">Drew A. Curtis</a> and <a href="https://prcp.psychiatryonline.org/doi/10.1176/appi.prcp.20190046#">Christian L. Hart</a> <br><strong>Published: </strong>22 Jun 2020, <a href="https://doi.org/10.1176/appi.prcp.20190046">https://doi.org/10.1176/appi.prcp.20190046</a><br><strong>Image: </strong>via <a aria-label="undefined (opens in a new tab)" href="https://www.flickr.com/photos/80641068@N07/with/8686708312/" target="_blank" rel="noreferrer noopener">Flickr</a>, Creative Commons Attribution 2.0 Generic <a aria-label="undefined (opens in a new tab)" href="https://creativecommons.org/licenses/by/2.0/deed.en" target="_blank" rel="noreferrer noopener">license</a>.</p></div></div>]]>
            </description>
            <link>https://psychnewsdaily.com/about-13-percent-of-people-are-pathological-liars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24187224</guid>
            <pubDate>Mon, 17 Aug 2020 13:55:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to OpenBSD [video]]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 90 (<a href="https://news.ycombinator.com/item?id=24185985">thread link</a>) | @asicsp
<br/>
August 17, 2020 | https://blog.lambda.cx/posts/openbsd-introduction-talk/ | <a href="https://web.archive.org/web/*/https://blog.lambda.cx/posts/openbsd-introduction-talk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://blog.lambda.cx/posts/openbsd-introduction-talk/cover.jpg" alt="The first slide of the OpenBSD introduction presentation" title="An Introduction to OpenBSD"></p><p>
  <iframe src="https://www.youtube.com/embed/EkDVKthufAM" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<p>
I recently gave a talk at work to help introduce OpenBSD to my
colleagues. It's a broad introduction to the fundamentals of security
in OpenBSD, as well as some basic system administration tips and
suggestions anyone coming from a Linux background might find useful.
</p>
<p>
It's roughly split up into four sections; the history of OpenBSD,
what sets it apart from other operating systems, a guided
installation, and the system administration introduction.
</p>
<p>
In the original presentation the guided installation was done
interactively with the participants installing OpenBSD in a VM on
their machines to follow along with the slides.
</p>
<p>
I've tried my best to make it as accessible as possible while still
covering the most important beats. If you find any errors please let
me know so I can correct them, my contact info is on the <a href="https://blog.lambda.cx/about/">about</a> page.
</p>
<p>
I've corrected several small issues with the slides since the
recording. I've replaced the file name <code>/etc/mygateway</code> with <code>/etc/mygate</code>,
replaced the smartquotes with regular quotes, and removed the rebound
program, to name the biggest fixes. These corrections are available at
the slides linked below.
</p>
<p>
<a href="https://blog.lambda.cx/posts/openbsd-introduction-talk/openbsd-introduction.pdf">An Introduction to OpenBSD slides</a>
</p>

    </div></div>]]>
            </description>
            <link>https://blog.lambda.cx/posts/openbsd-introduction-talk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185985</guid>
            <pubDate>Mon, 17 Aug 2020 10:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spectrum Analyzer Software for OpenRAMAN]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24185639">thread link</a>) | @cinntaile
<br/>
August 17, 2020 | http://www.thepulsar.be/article/spectrum-analyzer-software-for-openraman | <a href="https://web.archive.org/web/*/http://www.thepulsar.be/article/spectrum-analyzer-software-for-openraman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<date>Published: 2020-08-15 | Categories: <b><a href="http://www.thepulsar.be/archives/engineering"><span>[»]</span> Engineering</a></b>, <b><a href="http://www.thepulsar.be/archives/optics"><span>[»]</span> Optics</a></b>and<b><a href="http://www.thepulsar.be/archives/programming"><span>[»]</span> Programming</a></b>.</date>
<p>4 Months and 400 hours were necessary to bring life to the Spectrum Analyzer software that I am glad to announce to you today.</p>

<p>The software, which was initially modest, has grown into a fully functional program suite that covers most of the features traditionally implemented in commercial spectroscopy software. It includes single and live acquisition of spectra, loading/saving and export to clipboard, filtering, baseline removal and an automated calibration algorithm that I specially designed for the occasion. A screenshot of the software performing a calibration is shown in Figure 1.</p>

<figure><img src="http://www.thepulsar.be/images/spectrum-analyzer-software-for-openraman/screenshot.png"><figcaption>Figure 1 – Spectrum Analyzer software screenshot</figcaption></figure>

<p>A <a href="http://www.open-raman.org/build/software/" target="_blank"><span>[∞]</span> specific page</a> was created on the companion website to host the latest version of the software for download. As the rest of the project, the software is distributed under the open-source CERN OHL-W v2 license.</p>

<p>Although the software was designed to interface to the OpenRAMAN spectrometers, it will actually work with any dispersion-based spectrometers using PointGrey camera. It may even work with different camera manufacturers or with CCD linear array as long as you provide a DLL to interface to the hardware. The source code is given with a the DLL necessary to interface to PointGrey cameras, which can be used as an example on how to implement other camera types. The program even support multiple spectrometers connected to the same computer using each a different hardware! I don’t know if that will actually be useful but I made it as flexible as possible to avoid restrictions that would later block some users.</p>

<p>The software will work with either .CSV files or with a custom file format that I implemented using an upgraded version of the technique I presented <a href="http://www.thepulsar.be/article/implementing-object-persistence-in-c--"><span>[»]</span> here</a>. One of the most challenging difficulty I had to face was to allow 32 bits version of the software to load the files saved with the 64 bits version. This seems easy at glance but the original technique I developed do not cope well with that. One advantage of the custom file format is that the files contains the data, the blank and all the program settings (filtering, calibration etc.) so that you can tweak them later.</p>

<p>As explained above, the software also features an automated calibration procedure. You simply measured the spectra of a Neon or Argon-Mercury lamp, give the number of peaks that appears on screen and click on the “calibrate!” button. The algorithm is extremely robust to missing peaks and converge to a solution within a few seconds (4 seconds on my super-old laptop). By default, the algorithm will look on a very broad range of parameters, which basically cover the whole visible region of the spectrum, but advanced user can also tune the settings when necessary.</p>

<p>The software also implements many other features like time-lapsed acquisitions to monitor reactions, automatic saving of spectra, baseline removal algorithm and Savitzky-Golay filtering. The user can also freely choose between wavelength and Raman shifts axis, save and import calibration data etc. Also, the calibration will be saved inside the camera so if you connect the spectrometer to a different computer it will remain calibrated!</p>

<p>I invite you to test the software to discover all the possibilities. You don’t have to possess a spectrometer to run the software as you can import any .CSV file where the first column represents the x-axis and the second column the y-axis.</p>

<p>During the next weeks/months, I will post detailed articles on how the major features were implemented. The first article will be about the automated calibration procedure.</p>

<p>I would like to give a big thanks to <b>James</b> who has supported this post through Patreon. I also take the occasion to invite you to <a href="https://www.patreon.com/thepulsar" target="_blank"><span>[∞]</span> donate</a> through Patreon, even as little as $1. I cannot stress it more, you can really help me to post more content and make more experiments!</p><p>[/p]<a href="http://www.thepulsar.be/article/spectrum-analyzer-software-for-openraman/#" id="goto_top"><span>[⇈]</span> Top of Page</a></p>		<p>Copyright The Pulsar (C) 2005-2020. All content of this website, including text, images, formula, and files are the property of The Pulsar unless otherwise explicitely noted. You are allowed to print, distribute page address and display the content. All other usages are prohibited. Some of the experiences and ideas presented here may be dangerous and might result in injuries even when operated accordingly to the author description. We cannot be held responsible for injuries, damage caused to third parties, uses and misuses resulting from applications of the content provided here.</p>
	</div></div>]]>
            </description>
            <link>http://www.thepulsar.be/article/spectrum-analyzer-software-for-openraman</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185639</guid>
            <pubDate>Mon, 17 Aug 2020 09:50:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A-Levels: The Model is not the Student]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 127 (<a href="https://news.ycombinator.com/item?id=24185621">thread link</a>) | @tosh
<br/>
August 17, 2020 | http://thaines.com/post/alevels2020 | <a href="https://web.archive.org/web/*/http://thaines.com/post/alevels2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://thaines.com/post/alevels2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185621</guid>
            <pubDate>Mon, 17 Aug 2020 09:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Response to Google open letter]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 305 (<a href="https://news.ycombinator.com/item?id=24185374">thread link</a>) | @ajdlinux
<br/>
August 17, 2020 | https://www.accc.gov.au/media-release/response-to-google-open-letter | <a href="https://web.archive.org/web/*/https://www.accc.gov.au/media-release/response-to-google-open-letter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-column">
              
            <div id="readspeaker-process">
        <section>
                                
                            </section>
        <div>
          <section>
                                                                                                    <div>
    <section id="block-system-main">

      
  <div>
    <article id="node-87993" about="/media-release/response-to-google-open-letter" typeof="sioc:Item foaf:Document">
    <header>
            <span property="dc:title" content="Response to Google open letter"></span>      </header>
    <div><div><div property="content:encoded"><p>The open letter published by Google today contains misinformation about the draft news media bargaining code which the ACCC would like to address.&nbsp;</p>

<p>Google will not be required to charge Australians for the use of its free services such as Google Search and YouTube, unless it chooses to do so.</p>

<p>Google will not be required to share any additional user data with Australian news businesses unless it chooses to do so.</p>

<p>The draft code will allow Australian news businesses to negotiate for fair payment for their journalists’ work that is included on Google services.</p>

<p>This will address a significant bargaining power imbalance between Australian news media businesses and Google and Facebook.</p>

<p>A healthy news media sector is essential to a well-functioning democracy.</p>

<p>We will continue to consult on the draft code with interested parties, including Google.</p>

<p><a href="https://www.accc.gov.au/focus-areas/digital-platforms/news-media-bargaining-code/draft-legislation">Consultation</a> closes on 28 August 2020.</p>

<p>More information about the draft news media bargaining code can be found here:&nbsp;<a href="https://www.accc.gov.au/media-release/australian-news-media-to-negotiate-payment-with-major-digital-platforms">Australian news media to negotiate payment with major digital platforms</a></p>
</div></div></div>    </article>
  </div>

</section> <!-- /.block -->
<section id="block-service-links-service-links">

        <p>
      <h2>Share</h2>
    </p>
    
  

</section> <!-- /.block -->
  </div>
                                  </section>
                  </div>
      </div>
    </section></div>]]>
            </description>
            <link>https://www.accc.gov.au/media-release/response-to-google-open-letter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185374</guid>
            <pubDate>Mon, 17 Aug 2020 08:59:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Koody – The best savings accounts in the UK]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24185182">thread link</a>) | @Halimah
<br/>
August 17, 2020 | https://www.koody.co/saving/top-savings-accounts | <a href="https://web.archive.org/web/*/https://www.koody.co/saving/top-savings-accounts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Savings accounts allow you to save money with a regulated financial institution and earn some interest. There are several types of savings accounts, but they mostly revolve around three themes - easy access, notice and fixed savings. Easy access accounts allow you to withdraw your money whenever you want. Notice accounts require you to give your provider a few days' notice before making a withdrawal. Fixed accounts allow you to save your money for a fixed period at a guaranteed interest rate. This rate is usually slightly higher than notice or easy access accounts.<br>‍<br><strong>Your money is protected up to £85,000:</strong><br>When you save money in an authorised financial institution, your savings are protected by the Financial Services Compensation Scheme (FSCS). This means if the financial institution goes bust, you can claim your money back up to £85,000 per financial institution (£170,000 for joint accounts). So, if you have a lot of money to save, it might be wise to spread it across different financial institutions. We recommend you save at most £83,000 in one institution, leaving some room for interest.<br>‍<br>Some of these financial institutions have a shared licence, which means they share their licence with another institution. If you put your money in two institutions that share a licence and both go bust, you'll only be entitled to a maximum of £85,000 from the FSCS. Examples of financial institutions that share a licence are Halifax, Bank of Scotland and BM Savings (all three share the same licence).<br>‍<br><strong>Most people won't pay taxes on savings' income:</strong><br>Depending on your income tax band, you may not have to pay taxes on interest earned on savings. For example, basic-rate taxpayers can earn up to £1,000 in interest tax-free every year. Higher-rate taxpayers can earn up to £500. Additional-rate taxpayers have no tax-free allowance. If you are interested in tax-free accounts, have a look at <a href="https://www.koody.co/saving/isa">ISAs</a>.<br>‍<br>Below, you'll find the easy access, notice and fixed-rate savings accounts which pay the highest interest at the moment. These are not recommendations. They are simply the savings accounts with highest interest rates. All financial institutions we list are regulated by the FCA, and their savings accounts are protected by the FSCS up to £85,000.<br></p><p><img src="https://uploads-ssl.webflow.com/5ea8e1014488c25d7742640f/5f227e4d58bbc37bc1507dec_savings-accounts-sign-500x500px.png" alt="Savings accounts are almost tax free" height="300"></p></div></div>]]>
            </description>
            <link>https://www.koody.co/saving/top-savings-accounts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185182</guid>
            <pubDate>Mon, 17 Aug 2020 08:24:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handmade: A Community for Self-Rolled Performant Software (2016)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24184688">thread link</a>) | @TheUndead96
<br/>
August 16, 2020 | https://handmade.network/manifesto | <a href="https://web.archive.org/web/*/https://handmade.network/manifesto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
            <div>
                
                
    <div>
        
        
            

<p> Modern computer hardware is amazing. Manufacturers have orchestrated billions of pieces of silicon into terrifyingly complex and efficient structures that sweep electrons through innumerable tangled paths, branchings, and reunions with the sole purpose of performing computations at more than a billion times per second. This awe-inspiring piece of computational wizardry has at its disposal multiple billions of uniquely addressible silicon plates where it can store the results of millions of computations in an array of several vanishingly small chips. All of this hardware, though each component often sits no further than 7 or 8 centimeters away from the others, cycles so fast that the speed of light, a physical law of the universe, limits the rate at which they communicate with each other.
</p><p><span>So why is software still slow?</span>
</p><p>Why does it take your operating system 10 seconds, 30 seconds, a minute to boot up? Why does your word processor freeze when you save a document on the cloud? Why does your web browser take 3, 4, 10 seconds to load a web page? Why does your phone struggle to keep more than a few apps open at a time? And why does each update somehow make the problem worse?
</p><p><span>We made it slow</span>.
</p><p>Not necessarily you, not necessarily me, not necessarily any single person in particular. But we, the software development community, made it slow by ignoring the fundamental reality of our occupation. We write code, code that runs on computers. Real computers, with central processing units and random access memory and hard disk drives and display buffers. Real computers, with integer and bitwise math and floating point units and L2 caches, with threads and cores and a tenuous little network connection to a million billion other computers. Real computers not built for ease of human understanding but for blindingly, incomprehensibly fast speed.
</p><p><span>A lot of us have forgotten that</span>.
</p><p>In our haste to get our products, our projects, the works of our hands and minds, to as many people as possible, we take shortcuts. We make assumptions. We generalize, and abstract, and assume that just because these problems have been solved before that they never need to be solved again. We build abstraction layers, then forget we built them and build more on top.
</p><p>And it's true that many of us think we do not have the time, the money, the mental bandwidth to always consider these things in detail. The deadline is approaching or the rent is due or we have taxes to fill out and a manager on our back and someone asking us why we always spend so much time at the office, and we just have to stick the library or virtual machine or garbage collector in there to cover up the places we can't think through right now.
</p><p>Others of us were never taught to think about the computer itself. We learned about objects and classes and templates and how to make our code clean and pretty. We learned how to write code to make the client or the manager or the teacher happy, but made the processor churn. And because we did, that amazing speed we'd been granted was wasted, by us, in a death by a thousand abstraction layers.
</p><p><span>But some of us aren't satisfied with that.</span>
</p><p>Some of us take a few extra steps into the covered territory, the wheels sitting, motionless, in a pile behind us, examine their designs and decide there is a better way. The more experienced among us remember how software used to be, the potential that we know exists for computer programs to be useful, general, <em>and</em> efficient. Others of us got fed up with the tools we were expected to use without complaint, but which failed us time and time again. Some of us are just curious and don't know what's good for us. Don't trust what we've been told is good for us.
</p><p>We sat down and looked at our hardware, and examined our data, and thought about how to use the one to transform the other. We tinkered, and measured, and read, and compared, and wrote, and refined, and modified, and measured again, over and over, until we found we had built the same thing, but 10 times faster and incomparably more useful to the people we designed it for. And we had built it by hand.
</p><p>That is what Handmade means. It's not a technique or a language or a management strategy, it isn't a formula or a library or an abstraction. It's an idea. The idea that we can build software that works with the computer, not against it. The idea that sometimes an individual programmer can be more productive than a large team, that a small group can do more than an army of software engineers and *do it better*. The idea that programming is about transforming data and we wield the code, the tool we use to bend that data to our will.
</p><p> It doesn't require a degree, or a dissertation, or a decade of experience. You don't need an
expensive computer or a certificate or even prior knowledge. All you need is an open mind and a sense of
curiosity. We'll help you with the rest.
</p><p><span>Will you join us?</span>
</p><p>Will you build your software by hand?</p>

        
        
        <p>
            
                Last updated by Andrew Chronister on April 23, 2016, 1:39 a.m.
            
        </p>
    </div>

                
            </div>
        
    </div>
    
</div></div>]]>
            </description>
            <link>https://handmade.network/manifesto</link>
            <guid isPermaLink="false">hacker-news-small-sites-24184688</guid>
            <pubDate>Mon, 17 Aug 2020 06:56:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Ecology of Mind]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24184414">thread link</a>) | @apsec112
<br/>
August 16, 2020 | http://www.anecologyofmind.com/thefilm.html | <a href="https://web.archive.org/web/*/http://www.anecologyofmind.com/thefilm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="item4">
		<p><em><span>A</span></em><span><em><span>n Ecology of Mind</span></em></span><span> </span><span> is a film portrait of Gregory Bateson, celebrated anthropologist, philosopher, author, naturalist, systems theorist, and filmmaker, produced and directed by his daughter, Nora Bateson.</span></p>
		<p><span>T<span>he</span></span><span> film includes footage from Bateson’s own films shot in the 1930s in Bali (with Margaret Mead) and New Guinea, along with photographs, filmed lectures, and interviews.  His youngest child, Nora, depicts him as a man who studied the interrelationships of the complex systems in which we live with a depth motivated by scientific rigor and caring integrity.</span></p>
		<p><span>N<span>ora</span></span> Bateson’s rediscovery of his work documents the vast – and continuing – influence Bateson’s thinking has had on the work of an amazingly wide range of disciplines.  Through contemporary interviews, along with his own words, Bateson’s way of thinking reveals practical approaches to the enormous challenges confronting the human race and the natural world.</p>
		<p><span>G<span>regory</span></span> Bateson’s theories, such as “the double bind” and “the pattern which connects”, continue to impact the fields of anthropology, psychiatry, information science, cybernetics, urban planning, biology, and ecology, challenging people to think in new ways.   </p>
		<p><span>U</span><span>ntil now, his work has been largely inaccessible to most of us.  Through this film, Nora Bateson sets out to show that his ideas are not just fodder for academic theory, but can help instruct a way of life. She presents his thinking using a richly personal perspective, focusing on the stories Bateson used to present his ideas and how the beauty of life itself provided the framework of his life’s pursuits.</span></p>
		<p><span>T</span><span>his film hopes to inspire its audience to see our lives within a larger system - glistening with symmetry, play, and metaphor. An invitation to ask the kinds of questions that could help thread the world back together from the inside.</span></p>
	</div></div>]]>
            </description>
            <link>http://www.anecologyofmind.com/thefilm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24184414</guid>
            <pubDate>Mon, 17 Aug 2020 06:01:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How long since Google said a Google Drive Linux client is coming?]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 108 (<a href="https://news.ycombinator.com/item?id=24183399">thread link</a>) | @zdw
<br/>
August 16, 2020 | https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/ | <a href="https://web.archive.org/web/*/https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        
        <p>
          have elapsed since <a href="https://productforums.google.com/forum/#!category-topic/drive/report-a-problem/KeC7Ax76dAA">Google said to "hang tight" about Linux support for Google Drive</a>.
        </p>
        <p>
          <strong><a href="https://tools.google.com/dlpage/drive">We're still waiting</a></strong>.
        </p>
        <p><a href="https://productforums.google.com/forum/#!category-topic/drive/report-a-problem/KeC7Ax76dAA">
          <img src="https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/img/waiting.gif">
        </a></p><hr>
        <p>
          Made with frustration by <a href="https://twitter.com/abevoelker">@abevoelker</a>
        </p>
      </div></div>]]>
            </description>
            <link>https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24183399</guid>
            <pubDate>Mon, 17 Aug 2020 02:47:20 GMT</pubDate>
        </item>
    </channel>
</rss>
