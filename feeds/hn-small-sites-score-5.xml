<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 04 Mar 2021 01:09:33 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 04 Mar 2021 01:09:33 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Proposal for an Internet Service: The Eternal Home Page (1996)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26313569">thread link</a>) | @jstrieb
<br/>
March 2, 2021 | http://neilsloane.com/doc/eternal.html | <a href="https://web.archive.org/web/*/http://neilsloane.com/doc/eternal.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<center><h2>Proposal for an Internet Service: The Eternal Home Page</h2></center><center>
<a href="http://neilsloane.com/index.html"> N. J. A. Sloane</a>
</center>
<center>
Information Sciences Research Center,
</center>
<center>
AT&amp;T Labs - Research, Florham Park, New Jersey 07932, U.S.A.
</center>
<center>
Email address: njasloane@gmail.com.
</center>
<center>
December 13, 1996. Revised November 11, 1997.
</center>
<center>
<h2><strong>Abstract</strong></h2>
</center>
<p>
This paper describes a possible Internet service that
some major organization such as
Harvard University, AT&amp;T,
the Institute of Electrical and Electronic Engineers,
the American Mathematical Society, the American Medical Association,
or even the Vatican, might offer: a home page "in perpetuity".
Such a "perpetual page" or "eternity page" or
"e-memorial page" would be a home page that the organization would
help the customer set up, with a guarantee that it would
last for (say) 500 years, or until the organization no
longer exists.
It would list all the things that the customer would like to
be remembered for (accomplishments, family, etc.).
As the population of the U.S. ages,
such a service should prove very popular.
After all, almost everyone wants to be remembered by posterity.
</p><center><h2> Details </h2></center>
<ul>
<li>
The name for this service needs to be chosen with care, and
of course registered. "Eternity service",
"Perpetual page", "Eternity page", "E-memorial page",
"Everlasting page"
are a few possibilities. I will use "Perpetual page"
in this paper.

</li>
<li>
The first version of this paper was written in
December 1996, although the idea for the "Perpetual home page"
first occurred to me in January 1996.
Not surprisingly,
it turns out that other people have had similar ideas, and there may be some
commercial services that provide electronic gravestones available even now.
But my vision is that
this service would be offered by a major organization or institute,
that has already existed for a long time and
has some chance of existing 500 years from now.
And I'm not thinking of tombstones, but home-pages.

</li>
<li>
The "Perpetual page" could include such things as:
<ul>
<li>
photographs of houses, boats, paintings, other precious possessions
</li>
<li>
lists of awards, accomplishments
</li>
<li>
writings, drawings, songs, even unpublished novels
(disk space is cheap)
</li>
<li>
links to perpetual pages of one's family (including ancestors!) and friends
</li>
</ul>

</li>
<li>
This is the customer's chance to write their own
<em>New York Times</em> obituary page, or "time capsule".
(Many people do not realize that except for a handful of major obituaries,
every obituary item in the <em>New York Times</em> has to be
purchased at about $40 per line -- this can be a humiliating
experience for the next-of-kin.
Setting up a "Perpetual page" in advance for the sick
and elderly could be both therapeutic and comforting for the family.)

</li>
<li>
There should be a generous amount of disk
space available for each page - a minimum of ten megabytes,
to allow a number of photographs to be included. (Most Internet
providers at present do not allow nearly enough disk space.)
As my colleague 
Andrew Odlyzko has pointed out in his
<a href="http://www.research.att.com/~amo/doc/tragic.loss.txt">
discussion of the future of scholarly journals</a>,
the cost of disk space is dropping so rapidly that it is likely that 
the cost of providing a service
in perpetuity will be not much more than that of providing it for
one year.

</li>
<li>
The organization would help the customer set up the initial page, and would
provide instructions on how to maintain it.
A "help desk" would be part of the service.

</li>
<li>
One way to structure the offer might be to tell customers:
For a one-time fee of $X, we will provide you with Y MB of
storage, and as long as you pay a small monthly fee,
you can keep modifying it.  Once you stop paying the monthly fee
(say because you die, or switch to a different
provider) we will keep the latest version <em>forever</em>.

</li>
<li>
Part of the offer would be a guarantee that when the Internet is replaced
by some other service in a few years, all the "Perpetual pages"
would be automatically converted to the new medium.

</li>
<li>
It is important that the organization offering the servce
should have been in existence for a long time, and have a good chance of
still existing 500 hundred years from now.
The organizations mentioned in the Abstract certainly
satisfy these conditions, and it is easy to think of others. 
Such a service would not carry much conviction
if offered by some tiny local Internet service provider.

</li>
<li>
This is the first time in history that such a thing is possible.

</li>
<li>
Incidentally,
the <em>New York Times</em>} for Saturday Dec. 7 1996 describes (on page D2)
a patent, US 5,517,791, for a new tombstone design that can
incorporate a person's life story - including photographs.
So ideas like the one I am proposing are "in the air".

</li>
<li>
As one may verify by visiting cemeteries in New Jersey, tombstones are rarely
legible after a hundred years have passed.  One of the advertisements for the
proposed service could show a family searching through a
cemetery full of grave stones that have been worn smooth,
looking for the lost grave of an ancestor.  Furthermore,
as the world population continues to explode,
cemeteries will become increasingly irrelevant.

</li>
<li>
The "perpetual page" service would especially appeal to mature customers.
There are several ways in which advertisements could point out the futility
of earlier attempts to be remembered, even by world leaders.
For example, one advertisement could show a replica of the original
Mausoleum at Halicarnassus,
after which all later mausoleums are named.
(See <em>The Oxford History of the Classical World</em>,
ed. J. Boardman et al., Oxford, 1993, p. 150.)
<center> <img src="http://neilsloane.com/doc/maus1.jpg"> </center>
<p>
One of the Seven Wonders of the World, it was
built in the year 353 for King Mausolus of Caria by his wife.
It no longer exists.
"But if King Mausolus had had a perpetual page, we could still read
about his victories today ...".

</p></li>
<li>
An alternative way in which the "perpetual page" could be used is
by family and friends after the death of a loved one, by setting up a
permanent memorial for the deceased.  The Page would need to have an
authorized keeper, to screen out inappropriate material.
A certain amount of permanent space would be purchased, to which
interested parties could contribute in any way they wished.


</li>
<li>
Another advertisement could have a voice reading P. B. Shelley's
poem <strong>Ozymandias</strong>,
while the picture shows dust blowing around an appropriate ruin:

<pre>     I met a traveller from an antique land 
     Who said: Two vast and trunkless legs of stone 
     Stand in the desert ... Near them, on the sand,
     Half sunk, a shattered visage lies, whose frown,
     And wrinkled lip, and sneer of cold command,
     Tell that its sculptor well those passions read
     Which yet survive, stamped on these lifeless things,
     The hand that mocked them, and the heart that fed:
     And on the pedestal these words appear: 
     `My name is Ozymandias, king of kings: 
     Look on my works, ye Mighty, and despair!' 
     Nothing beside remains. Round the decay 
     Of that colossal wreck, boundless and bare
     The lone and level sands stretch far away.
</pre>
<center><img src="http://neilsloane.com/doc/ozy4.jpg"> </center>
</li>
<li>
It will also give all the unpublished poets and writers,
the unrecognized painters and musicians, the scientists
whose theories are rejected, the opportunity to have their
work immortalized.

</li>
<li>
Yet another advertisement could have Jessye Norman singing the moving
and unforgettable aria "Remember Me"
from Henry Purcell's "Dido and Aeneas".
(The formal title
is "Thy hand Belinda - when I am laid in Earth"
[Philips CD 434 161-2].)

</li>
</ul>
<p>
<strong>Acknowledgements</strong>:  I am grateful to Colin Mallows, Andrew Odlyzko,
Susanna Cuyler Sloane and Nambi Seshadri for a number of helpful comments.

</p><center>
<img src="http://neilsloane.com/banners/bline.gif" alt=" ">
</center>
<p><strong>See also:</strong> <a href="http://neilsloane.com/index.html"> <strong>My home page</strong></a> | 
<a href="http://neilsloane.com/doc/links.html#ET"><strong>Related links</strong></a>





</p></div>]]>
            </description>
            <link>http://neilsloane.com/doc/eternal.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26313569</guid>
            <pubDate>Tue, 02 Mar 2021 09:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A network of weather stations to help prevent pesticide spray drift]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26313216">thread link</a>) | @Damon_Mesonet
<br/>
March 2, 2021 | https://cotl.com.au/launch.html | <a href="https://web.archive.org/web/*/https://cotl.com.au/launch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <a name="intro"></a>


              <figure>
                <a href="https://riverlandmalleemesonet.com.au/"><img alt="Screenshot of the Riverland Mesonet during the beginning of an inversion" src="https://cotl.com.au/assets/app-screenshot-riverland-inversion-e97e8509021dc60e59f9013061552f9c5589719e56dbf50e5420a2d2ffc36e1a.png"></a>
                <figcaption>Screenshot of the Riverland Mesonet during the beginning of an inversion</figcaption>
              </figure>


              <p>Hi from the team who built the "mesonet" weather station networks in the state of South Australia!</p>
              <p>A <a href="https://en.wikipedia.org/wiki/Mesonet">mesonet</a> is a term for a network of automated weather stations designed to monitor meteorological phenomena at high geographic density and updated frequently.</p>
              <p>We built these networks to help prevent pesticide <a href="#spraydrift">spray drift</a> - the phenomenon in which pesticide spray that is applied to a crop ends up drifting to other crops, sometimes many kilometres away.</p>
              <p>Spray drift can be a huge problem, as it can lead to damage or even destruction of highly valuable crops, and can also cause pollution to waterways and harm to native ecosystems.</p>
              <p>The biggest factor in spray drift the presence of a <a href="#thermalinversions">thermal inversion</a>, a state in which temperature increases with increasing altitude, which usually happens in the evening and overnight when the earth is cooling, but can happen at other times. However other meteorological phenomena also affect the likelihood of spray drift, and different types of spray respond differently.</p>
              <p>So we designed a <a href="#ourweatherstations">weather station</a> to measure all the relevant meteorological phenomena, and in particular to detect thermal inversions, and a custom <a href="#webapp">web app</a> to display the data in format that is very fast and simple to access and understand.</p>
              <p>We've now deployed 70 of these stations across two of the major agricultural regions of South Australia, and so far it seems to be making a difference: no damage due to spray drift has been reported in these regions since the networks were rolled out.</p>


              

              <a name="background"><h2>Background</h2></a>

              <p>A group of stakeholders in the <a href="https://en.wikipedia.org/wiki/Mid_North">Mid North region of South Australia</a> had identified spray drift as a major issue.</p>
              <p>The region, to the north of <a href="https://en.wikipedia.org/wiki/South_Australia">South Australia</a>'s capital of <a href="https://en.wikipedia.org/wiki/Adelaide">Adelaide</a>, has a thriving agricultural sector, producing wheat, barley, wine grapes, pulses, livestock and other produce.</p>
              <p>The total annual output from the region is valued at nearly AUD $2 billion. It has been estimated that the potential loss in production from spray drift could be as high as $178M/year, and potential harm to waterways and native ecosystems is significant.</p>
              <p>The local stakeholders worked with meteorologists and researchers to develop a solution, then sought funding from the South Australia state government to fund the project.</p>
              <p>In 2018, a $1.4M grant was provided, and a pilot rollout of 40 weather stations was undertaken.  It was named the Mid North Mesonet.</p>
              <p>The pilot was deemed successful, and in 2019, another grant was provided by the state government for a network in the <a href="https://en.wikipedia.org/wiki/Riverland">Riverland</a> and <a href="https://en.wikipedia.org/wiki/Murray_Mallee">Mallee</a> region to the north-east of Adelaide.</p>

              <p>In the two years since the Mid North Mesonet was rolled out, there have been no reported instances of crop damage due spray drift.</p>

              <a name="spraydrift"><h2>The Problem of Spray Drift</h2></a>
              <p>Farmers spray pesticides on their crops to manage pests. It is an important feature of modern farming. Herbicide may be applied to target broad-leaf plants, other times to target summer weeds.</p>
              <p>Spray drift occurs when pesticide spray 'drifts' across into non-target areas.</p>
              <p>Spray drift is a problem because:</p>
              <div>
                <ul>
                    <li>The affected non-target area may be particularly susceptible to pesticides (i.e. broad-leaf crops such as grapevines are especially vulnerable)</li>
                    <li>Some markets are highly sensitive to the amount of pesticide residues detectable in the end products (i.e. wine exports to China; organic farms; etc)</li>
                    <li>The affected non-target area might be a sensitive natural ecosystem (i.e. local waterways)</li>
                    <li>The affected non-target area might include rain water tanks used for drinking water</li>
                    <li>It is a waste of pesticide product and labour time costs</li>
                </ul>
              </div>

              <a name="causesofspraydrift"><h2>Causes of Spray Drift</h2></a>
              <p>A combination of conditions can lead to spray drift.</p>
              <h3>Wind Speed</h3>
              <p>Wind speed that is very low or very high.</p>
              <h3>Temperature</h3>
              <p>A temperature over about 28Â°C (83Â°F).</p>
              <h3>Humidity</h3>
              <p>The effect of humidity varies depending on the type of spray. The spray manufacturer's instructions should provide guidance.</p>
              <h3>Atmospheric Stability</h3>
              <p><i>Unstable</i> or <i>stable</i> conditions can lead to spray drift. Conditions should be <i>neutral.</i></p>
              <h3>Thermal Inversions</h3>
              <p>A thermal inversion, in which temperature increases with increasing altitude, is a major risk factor for spray drift.</p>
              <p>Inversions generally happen in the evening and overnight as the earth cools, but they can happen at other times.</p>

              <a name="thermalinversions"><h2>Thermal Inversions</h2></a>
              <p>For current farming practices, long-distance spray drift generally occurs during very stable weather conditions (i.e. little to no air turbulence).</p>
              <p>A thermal inversion occurs when a warm layer of air sits above a cooler layer of air near the ground.</p>
              <p>This reduces air turbulence and can act as a â€˜lidâ€™ for an airborne pollutant source. The lack of air turbulence means the smaller spray droplets float without settling on the target crops.</p>
              <p>A very slight breeze can then carry these floating droplets large distances before they eventually descend into a non-target area.</p>
              <p>It is illegal to spray during a thermal inversion.</p>

              <p><strong>The problem: it is very difficult for farmers to tell if a thermal inversion is underway.</strong></p>

              <figure>
                <img alt="Diagram of an inversion" src="https://cotl.com.au/assets/inversion-diagram-4620f5e78853d307f3eda98282034a2f31990112210498b118a7f7209d362393.png">
                <figcaption>Diagram of an inversion</figcaption>
              </figure>

              <figure>
                <img alt="Photograph of an inversion with smoke" src="https://cotl.com.au/assets/inversion-smoke-photograph-37a8df015d3d946abce8f157b9088b23458cf7be098822bc24c5ccc5c98ac6ac.png">
                <figcaption>Photograph of an inversion with smoke</figcaption>
              </figure>

              <a name="ourweatherstations"><h2>Our Weather Stations</h2></a>

              <p>Our weather stations were designed to:</p>
              <div>
                <ul>
                    <li>Measure temperature at 1.2m and 10m, in order to detect inversions</li>
                    <li>Measure all weather metrics that are relevant in determining whether it is safe to spray</li>
                    <li>Update data every 10 minutes, so farmers have access to the most recent readings</li>
                </ul>
              </div>

              <p>They consist of:</p>
              <div>
                <ul>
                    <li>Temperature sensors at 1.2m</li>
                    <li>Temperature difference between 10m and 1.2m</li>
                    <li>Wind speed and direction sensors at 2m and 10m</li>
                    <li>Tipping bucket rain-gauge</li>
                    <li>Solar radiation sensor</li>
                    <li>Pressure sensor</li>
                    <li>Relative Humidity sensor</li>
                    <li>Antenna</li>
                    <li>DataLogger which takes readings every 10 minutes, does some calculations locally, and uploads over cellular data (3G/4G) to the web server for processing and display</li>
                </ul>
              </div>
              <p>Each tower is self-powered by a solar panel and battery.</p>

              <figure>
                <img alt="Weather Station at Walker Flat, SA" src="https://cotl.com.au/assets/aws-walkerflat-700x400px-4c79a337af8e7993aa961117c4d7ce0714a59cf0d23192272858e23c0c7e8a6f.jpg">
                <figcaption>Weather Station at Walker Flat, SA</figcaption>
              </figure>

              <figure>
                <img alt="Weather Station at Pinkerton Plains, SA" src="https://cotl.com.au/assets/aws_pinkerton_550px-e67cf8f7ec5c635d25d6fd2855bd4144e8209d78f17d71c9443a3b5e924419ce.jpg">
                <figcaption>Weather Station at Pinkerton Plains, SA</figcaption>
              </figure>


              <a name="webapp"><h2>The Web Application</h2></a>

              <p>We initially used an off-the-shelf web application for displaying meteorological data, but soon realised we needed something tailored to our needs. We found a company that was already in the business of building web-applications to display environmental data for farmers, and they were willing to build a customised version for us.</p>

              <p>The key requirements for the application were:</p>
              <div>
                <ul>
                    <li>Each of the monitored metrics displayed on a map, with fast/simple switching between each metric</li>
                    <li>A dashboard of all the current key metrics and recent historical graphs</li>
                    <li>Long-term graphs of all the key metrics also available, and as well as the past 48 hours of data in tabular format</li>
                    <li>The site must display well and be easy to use on a mobile device, and be fast to use even in areas with low cellular signal strength, given that much of the usage will be by farmers out in the field in remote areas.</li>
                </ul>
              </div>

              <p>The key technologies are:</p>
              <div>
                <ul>
                    <li>Ruby on Rails</li>
                    <li>PostgreSQL</li>
                    <li>Redis</li>
                    <li>Sidekiq for queue processing</li>
                    <li>React</li>
                </ul>
              </div>

              <p>Data is uploaded from the data logger via FTP (which may seem primitive, but the world of meteorological data still relies heavily on FTP).</p>

              <p>On detection of new data, the application first takes the most recent readings, and updates the data structures for the map and dashboard views.</p>

              <p>The historical data is then placed in a queue, for updating of historical graphs.</p>

              <p>All the data for the map view, dashboards and historical graphs are formatted into a JSON hash then serialized and stored in the Redis cache. That way, when the React web interface makes a request, the pre-formatted data can be retrieved and sent very quickly, as no querying, processing or formatting of data is required at request time.</p>

              <figure>
                <a href="https://midnorthmesonet.com.au/"><img alt="Screenshot of the Mid North Mesonet Map View with wind speeds shown" src="https://cotl.com.au/assets/app-screenshot-mid-north-mesonet-e2dc04bb613cc2a2607527fb6973e8fd78f938152818a84f184d0f8aeba497d5.png"></a>
                <figcaption>Screenshot of the Mid North Mesonet Map View with wind speeds shown</figcaption>
              </figure>

              <figure>
                <a href="https://riverlandmalleemesonet.com.au/"><img alt="Screenshot of the Riverland Mallee Mesonet Map View with temperatures shown" src="https://cotl.com.au/assets/app-screenshot-riverland-mallee-mesonet-61fdac0ba62e4974f33b61ae5b121162a7078d7320f4be951f2eb55052a59ce2.png"></a>
                <figcaption>Screenshot of the Riverland Mallee Mesonet Map View with temperatures shown</figcaption>
              </figure>

              <a name="results"><h2>Results so far</h2></a>

              <p>In the two years since the Mid North Mesonet was deployed, there have been no reported cases of crop damage due to spray drift.</p>

              <p>Damage and loss had been reported in most of the previous years - though not all. So it is too early to tell if the problem has been completely solved, but indications are promising.</p>

              <p>Other government bodies and NGOs are expressing interest in establishing their own mesonets.</p>


              <a name="contacts"><h2>Contacts</h2></a>
              <p>
                Damon Grace<br>
                Project Engineer<br>
                damon.grace@cotl.com.au<br>
              </p>
              <p>
                Warwick Grace<br>
                Meteorologist<br>
                warwick@graceresearch.com<br>
              </p>
              <p>
                Tom Howard<br>
  â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cotl.com.au/launch.html">https://cotl.com.au/launch.html</a></em></p>]]>
            </description>
            <link>https://cotl.com.au/launch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26313216</guid>
            <pubDate>Tue, 02 Mar 2021 08:42:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DDD Is Overrated]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 70 (<a href="https://news.ycombinator.com/item?id=26312652">thread link</a>) | @mcp_
<br/>
March 1, 2021 | https://tilkov.com/post/2021/03/01/ddd-is-overrated/ | <a href="https://web.archive.org/web/*/https://tilkov.com/post/2021/03/01/ddd-is-overrated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Update: Thereâ€™s a <a href="https://www.innoq.com/en/blog/is-domain-driven-design-overrated/">slightly extended version of this post</a> over at the INNOQ company blog.</em></p>
<p>There, I said it. Now that I have your attention: Domain Driven Design (DDD) has recently gained additional popularity, as evidenced by new books, conference talks (and even complete conferences dedicated to it), and lots of trainings â€“ including some by our very own colleagues at <a href="https://www.innoq.com/">INNOQ</a>. And in contrast to my click-bait headline, Iâ€™m actually a fan. <a href="https://www.dddcommunity.org/book/evans_2003/">Eric Evansâ€™s book</a>, the additional work writing and evangelizing it done by <a href="https://vaughnvernon.com/">Vaughn Vernon</a> (e.g. in <a href="https://www.case-podcast.org/15-domain-driven-design-with-vaughn-vernon">this very good podcast</a> with my colleague Joy) and many others, are all very good additions to our industryâ€™s body of knowledge. In the best sense of pattern languages, DDD gives clear names to things that many developers and designers know how to do, but cannot reliably and compatibly communicate about.</p>
<p>But Iâ€™m annoyed by the fact that recently, it seems that any time somebody talks about how to architect system or service boundaries, or even just mentions non-technical design, everybody feels compelled to bring in the DDD experts â€“ as if they were the only superheroes who could possibly design anything at all. This is just as bad as any other situation where you blindly apply the solution thatâ€™s currently en vogue, just because it is the thing everyone talks about, and not because it is the right solution for the job. DDD is great, but itâ€™s just one of many tools and techniques you should be aware of.</p>
<p>I think there is a more important aspect that people miss, especially when they get into DDD as their introduction to design in general. DDD emphasizes the importance of naming, and it suggests you should strive for a common, ubiquitous language, in the context youâ€™re designing for. But it also uses its own language â€“ concepts like bounded context, aggregates, entities, value objects, etc. â€“ for our domain, the domain of designing systems. And while these are all well and good, theyâ€™re only one possible language. Thereâ€™s value in calling a value object a value object, if this is a term many people understand, to facilitate communication. But the existing, common DDD concepts are not the only concepts you should consider â€“ they are just examples of a very common trait of designing and architecting systems: Coming up with and recognizing patterns, giving them good names, and using them to give the system structure and integrity. If in your architecture, thereâ€™s a common pattern that you use a Filter to route requests to a Handler, or a concept of a Document that is handled by an Agent, then these things may occur again and again, on the same level as Services or Repositories, and end up being way more important to you. This is fine! This concept, that we can and should invent our own languages, is to me way more important than many naÃ¯ve DDD practitioners think. I like to believe that DDD experts know this very well, and view any DDD material as a starting point, not an end result â€“ but if all youâ€™re doing is applying the by-the-book definition of existing DDD terms, and trying to shoe-horn any problem into this existing structure, yours is a very sad designerâ€™s life.</p>
<p>There is a life beyond DDD. Not every good design needs to be Domain-Driven (though I can accept it should always be driven by the domain, just not necessarily in the DDD sense). You can design good systems even if youâ€™re not a DDD expert.</p>

</div></div>]]>
            </description>
            <link>https://tilkov.com/post/2021/03/01/ddd-is-overrated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312652</guid>
            <pubDate>Tue, 02 Mar 2021 07:08:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed Is the Killer Feature]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 51 (<a href="https://news.ycombinator.com/item?id=26312516">thread link</a>) | @bdickason
<br/>
March 1, 2021 | https://bdickason.com/posts/speed-is-the-killer-feature/ | <a href="https://web.archive.org/web/*/https://bdickason.com/posts/speed-is-the-killer-feature/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		        
<p>Do you remember your first time using a modern smartphone? A vibrant screen that responded instantly when you tapped replaced cramped keyboards. You could sign your name, drag and drop apps around the screen, and even spin the giant Price is Right wheel to set your alarm. In 2007, this felt like a the future. There's a reason it was called 'the Jesus phone.'</p>
<p>At that same time, The Motorola Razr (<a href="https://www.youtube.com/watch?v=4_IK295sfxQ">video</a>) was the top phone on the market. It was a flip phone with the ability to take photos, play videos, browse the web, and play music. Sound familiar?</p>
<p>Phones in 2007 had the same features as the iPhone. The Palm Treo (<a href="https://www.youtube.com/watch?v=nK7FvGz4Jkc">video</a>) even had a touch screen.</p>
<img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/smartphones-2007.png">
<p>The difference was <em>speed</em>.</p>
<p>When you touched a Razr or a Palm phone, there was a delay. It felt sluggish and slow. Apple removed the delay between your finger tapping the screen and something happening. Your finger could finally manipulate the UI in realtime, just like in the real world. It felt magical. If there was even a slight delay, the whole experience fell apart.</p>
<p><strong>Speed is a killer feature. Speed is a differentiator.</strong></p>
<p>Yet teams consistently overlook speed. Instead, they add more features (which ironically make things slower). Products bloat over time and performance goes downhill.</p>
<p>New features might help your users accomplish something extra in your product.
<strong>Latency stops your users from doing the job they already hire your product for.</strong></p>
<p>Slow ui acts like tiny papercuts. Every time we have to wait, we get impatient, frustrated, and lose our flow.</p>
<h2>Honestly assess your speed</h2>
<p>I want you to take a moment and approach your product with a fresh set of eyes: Eyes for speed  ðŸ‘€</p>
<p>Go through your onboarding flow and try your core product features. Take mental note of how long each step takes to appear on the page then to be interactive.</p>
<p>How slow is it?
Be honest.
Itâ€™s ok, Iâ€™ve been there too.</p>
<p>Does your checkout page take 10+ seconds to load? Did you have to wait for a loading indicator multiple times along the way? Did things look interactive but werenâ€™t loaded yet?</p>
<p>Every one of these is an opportunity. The great thing about speed (also called â€˜performanceâ€™) is that you can stack rank it and burn it down.</p>
<p>Imagine what your product would feel like if everything happened in real time.</p>
<p><img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/speed-keanu-sandra.png"></p><p>Be like Keanu and fix every slowdown in your product. Your users will thank you.</p>
<h2>Places where speed matters</h2>
<ul>
<li>Speed during Checkout - Every second of page load time kills conversion rates. A 1 second delay <a href="https://neilpatel.com/blog/loading-time/">reduces conversion rate by 7%</a>.</li>
<li>Framerate in Virtual Reality - The early days of Virtual Reality caused intense nausea akin to motion sickness <a href="https://link.medium.com/QyheLe9rbeb">when framerates dropped below 60fps</a>.</li>
<li>Design Tools - Users are consistently frustrated when Sketch or Figma are slow. <a href="https://quizlet.com/blog/everything-i-know-about-design">Designers have high APM</a> (actions per minute) and a small slowdown can occur 5-10 times per minute.</li>
<li>The core interaction of your product - Your product exists to save people time or help them solve a problem. Introducing friction or delay during the most important flow of your product will drive people crazy. Notion has developed a reputation for being a sluggish product:</li>
</ul>
<img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/reddit-notion.png">
<h2>Perception vs. Reality</h2>
<p>If you canâ€™t speed up a specific action, you can often fake it. Perceived speed is just as important as actual speed. Even if you canâ€™t be fast, you should appear to be fast.</p>
<p><strong>Large content</strong> - Render the screen while content loads so the user knows whatâ€™s coming.
<strong>Long load times</strong> - Make the screen interactive, even if everything hasnâ€™t loaded.
<strong>Waiting for an action</strong> - Allow the user to take the action and keep moving but post the action in the background.
<strong>Very long actions</strong> - If you have an action that will take 30s or more, offer to notify the user (e.g. via email) when the action is available.</p>
<p>Here are some examples of products that fake being fast:</p>
<ul>
<li>Facebookâ€™s app pioneered loading images that look like actual content. The structure and UI of the page loads but the content does not. As a result, you can still use the product and prepare to take actions, even if the content hasnâ€™t loaded.</li>
<li>Games have a rule to never block the input thread. You can slow down the visuals but the controls should always feel responsive so the user feels in control.</li>
<li>Robinhood has you swipe up to trade, but runs your transaction in the background and notifies you via email when your trade is complete.</li>
</ul>
<h2>When is it ok to be slow?</h2>
<ul>
<li>When there is a physical constraint that causes things to take a while (e.g. dispensing money from an ATM)</li>
<li>When you want to give people a chance to correct a mistake (e.g. Gmail's "undo" feature)</li>
<li>When a human has to keep up with a machine (e.g. we slow down video game framerates, otherwise the game would run at 60x speed and overwhelm you).</li>
</ul>
<h2>Bonus Fun: What would it be like to live with lag?</h2>
<p>Imagine making breakfast with a 1 second latency added to every action you take. Even something as simple as moving your hands so that an egg rests over a bowl becomes incredibly challenging.</p>
<p><strong>Here's a real life experiment where 0.5-3s of latency was added to everyone's action via a VR headset:</strong></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/_fNp37zFn9Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>This is what we're forcing on people when we ship laggy software. We're making them spend their time waiting for us.</p>
<p><strong>Do you struggle to prioritize speed for your product? I'd love to hear more: <a href="http://twitter.com/bdickason">@bdickason</a></strong></p>
<p><strong>Get my newsletter.</strong>  It features simple improvements you can make to improve your day-to-day PM life. From Product Vision/Strategy to Goals and Metrics to Roadmaps and everything in between.</p>


<center></center>


<p>Soundtrack: <a href="https://www.youtube.com/watch?v=MviNwNKYLN4">Mega Ran &amp; Futurecop! - Slow Down</a></p>

<p> <a href="https://open.spotify.com/playlist/1sjamnHIeKEKqkYVwFtXo9?si=NAShg2i5TzetT69GKQ9Irw">See all songs featured on my site.</a></p>
<p>Post last updated: Feb 25, 2021
</p><h2 id="posts">Posts</h2>
<div>
<ul>
<li>
<p><a href="https://bdickason.com/posts/speed-is-the-killer-feature/">Speed is the killer feature</a> <span>Feb 25, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/manage-your-manager/">How to manage your manager</a> <span>Feb 19, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/social-thinkers-solo-thinkers/">Social thinkers vs. Solo thinkers</a> <span>Feb 11, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/pm-lead-massive-projects-writer-editor/">How top silicon valley PM's lead massive projects</a> <span>Feb 4, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/hardware-release-software-release/">How great hardware and software teams ship</a> <span>Jan 21, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/most-pms-dont-use-their-product/">Most PM's don't use their own product</a> <span>Jan 15, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/the-best-product-management-books-articles/">The Best Product Management books, articles, and videos</a> <span>Jan 8, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/gather-great-feedback-from-power-users/">How to gather great feedback from your power users</a> <span>Jan 4, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/biggest-pm-learning-2020-set-an-intention/">Set an intention for the year (and tell everyone)</a> <span>Dec 27, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/strategy-write-great-prereads/">Write great pre-reads and land your strategy</a> <span>Dec 21, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/write-things-down/">Write Things Down</a> <span>Dec 2, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/strategy-101-unpack-your-assumptions/">Strategy 101: Unpack your assumptions</a> <span>Nov 19, 2020</span></p>
</li>
</ul>
</div>

		


	  </div></div>]]>
            </description>
            <link>https://bdickason.com/posts/speed-is-the-killer-feature/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312516</guid>
            <pubDate>Tue, 02 Mar 2021 06:40:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element Matrix Services Announces Element Home]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 43 (<a href="https://news.ycombinator.com/item?id=26311801">thread link</a>) | @decrypt
<br/>
March 1, 2021 | https://element.io/blog/element-home/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-home/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>Weâ€™ve launched a brand new version of Element, called <a href="https://element.io/element-home">Element Home</a>!<br></p><p>Itâ€™s the Element app, but faster, personalised and under your control - all packaged up so you donâ€™t have to worry about how it works! You can just enjoy the fact you know you chose someone you trust (us!) with your data.<br></p><p>So that you know, hereâ€™s whatâ€™s going on behind the scenes with Element Home; in practice youâ€™re getting your own fully managed, dedicated server alongside your Element app. It means you have a notably faster service than when using a typical free public server - youâ€™re saved the hassle of self-hosting and itâ€™s guaranteed to be kept updated with the very latest and greatest Matrix hosting best practices.<br></p><div><p>On top of faster messaging, Element Home comes with five user accounts. Itâ€™s the ideal way for a family, or groups of friends, to get a super-quick professionally hosted version of Element.</p><p><strong>A new type of messenger</strong></p></div><p>As you know, Element is completely different to most messaging apps. <br></p><p>Because Element is <strong>decentralised</strong>, the app itself (what you see) is separate from the Matrix hosting service behind it (what you donâ€™t see; the movement of messages and where they are stored).<br></p><p>Thatâ€™s important because it lets users decide where their messages and data are kept. In owning that choice, you also get to own your data and messages rather than having them sucked up into the likes of Facebook Messenger, Signal, Telegram or WhatsApp.<br></p><p>Some people choose to host themselves, and thatâ€™s great. As it requires some technical knowledge, many others choose to use a free public hosting service such as Matrix.org to get up and running.<br></p><p>Element Home is a third option; the ability to pay for a fully managed, dedicated server (aka a â€˜homeserverâ€™). Being a dedicated server, it devotes itself to just a handful of users; and thatâ€™s why itâ€™s so much quicker than a typical free public server that constantly juggles thousands of users.</p><p><strong>There are many messaging apps, but surprisingly little choice.</strong></p><figure><img src="https://element.io/blog/content/images/2021/02/Comparison-table-8--1-.png" alt="" srcset="https://element.io/blog/content/images/size/w600/2021/02/Comparison-table-8--1-.png 600w, https://element.io/blog/content/images/size/w1000/2021/02/Comparison-table-8--1-.png 1000w, https://element.io/blog/content/images/size/w1600/2021/02/Comparison-table-8--1-.png 1600w, https://element.io/blog/content/images/2021/02/Comparison-table-8--1-.png 2108w" sizes="(min-width: 720px) 720px"><figcaption>Element compared with centralised messaging apps.</figcaption></figure><p><br><strong>Free vs $10 per month</strong><br></p><p>As you know, Element and Matrix is all about giving you choice. If you want to use the free version, thatâ€™s completely fine by us!<br></p><p>But hereâ€™s the extra you get in return for a few bucks a month:<br></p><ol><li>Element Home means youâ€™re <strong>hosted by Element Matrix Services</strong> - our Matrix-based hosting platform used by big companies and public sector organisations. You have a <strong>dedicated server</strong> (so youâ€™re sharing minimal infrastructure with anyone else), fully managed and maintained by the most Matrix-savvy team in the world.<br></li><li>Professional-hosting means the service is <strong>notably faster</strong> than when hosted by a typical free public server, and <strong>always fully updated</strong> and maintained.<br></li><li>An Element domain that you can name, so you can make <strong>memorable Matrix IDs</strong> such as @yourfirstname:yoursurname.ems.host. Use your surname as the domain, and itâ€™s perfect for family sharing!<br></li><li><strong>Five Element accounts</strong> - so after using one yourself, youâ€™ll have four more for family or friends - so thatâ€™s <strong>just $2 per user per month</strong> for a super-quick data sovereign messaging service (you can add more users if you wish).</li></ol><figure><img src="https://element.io/blog/content/images/2021/02/Element-Home-custom-IDs.png" alt="" srcset="https://element.io/blog/content/images/size/w600/2021/02/Element-Home-custom-IDs.png 600w, https://element.io/blog/content/images/2021/02/Element-Home-custom-IDs.png 848w" sizes="(min-width: 720px) 720px"><figcaption>Matching IDs for all the family!</figcaption></figure><p><strong>Wishing you could turn back time?!</strong></p><p>If youâ€™re an Element user and youâ€™re self-hosting, or using a typical free public server (such as Matrix.org), you can simply copy your existing account over to Element Home. Currently, you can only do this in the Element web app (weâ€™re working on an equally simple upgrade from within Android and iOS). Once youâ€™ve upgraded your â€˜oldâ€™ account will still be live, so feel free to keep it or delete it as you see fit.<br></p><p>For those not already up and running on Element, just <a href="https://element.io/element-home">sign up for Element Home</a> from here.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-home/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311801</guid>
            <pubDate>Tue, 02 Mar 2021 04:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Assembly Language]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 17 (<a href="https://news.ycombinator.com/item?id=26311722">thread link</a>) | @sidcool
<br/>
March 1, 2021 | https://wolchok.org/posts/how-to-read-assembly-language/ | <a href="https://web.archive.org/web/*/https://wolchok.org/posts/how-to-read-assembly-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why, in 2021, does anyone need to learn about assembly language?
First, reading assembly language is the way to know <em>exactly</em> what
your program is doing. Why, <em>exactly</em>, is that C++ program 1 MiB (say)
instead of 100 KiB? Is it possible to squeeze some more performance
out of that function that gets called all the time?</p><p>For C++ in particular, it is easy to forget or just not notice some
operation (e.g., an implicit conversion or a call to a copy
constructor or destructor) that is implied by the source code and
language semantics, but not spelled out explicitly. Looking at the
assembly generated by the compiler puts everything in plain sight.</p><p>Second, the more practical reason: so far, posts on this blog havenâ€™t
required an understanding of assembly language, despite constant
links to <a href="https://godbolt.org/">Compiler Explorer</a>. By <a href="https://twitter.com/ScottWolchok/status/1361022423399755776">popular
demand</a>,
however, our next topic will be parameter passing, and for that, we
will need a basic understanding of assembly language. We will focus
only on <em>reading</em> assembly language, not writing it.</p><p>The basic unit of assembly language is the <strong>instruction</strong>. Each
machine instruction is a small operation, like adding two numbers,
loading some data from memory, jumping to another memory location
(like the dreaded <a href="https://en.wikipedia.org/wiki/Goto">goto</a>
statement), or calling or returning from a function. (The x86
architecture has <a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">lots of not-so-small
instructions</a>
as well. Some of these are <a href="https://stackoverflow.com/questions/5959890/enter-vs-push-ebp-mov-ebp-esp-sub-esp-imm-and-leave-vs-mov-esp-ebp">legacy
cruft</a>
built up over the 40-odd years of the architectureâ€™s existence, and
others are <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">newfangled
additions</a>. )</p><p>Our first toy example will get us acquainted with simple
instructions. It just calculates the square of the
<a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">norm</a>
of a 2D vector:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and here is the resulting x86_64 assembly from clang 11, <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tQVvQAZPLUwA5YwCNMxEADZSAB1QLC62nsMTQS8fNTorG3sjJxd3JRUw2gYCZmICAONTTkVlTFU/ZNSCCLtHZzdFFLSMoOyFKuLrUujy1wBKRVQDYmQOAHIpAGZrZEMsAGpxQZ1kevx6KexxAAYAQRXV%2BuIDVXGANTzJSYB2WTXxi/HrAlduAH0CcYAPKbPVy6v6W4fxgE9XjbiY4AEQBaw212%2Bj1oJCMDAAjgZUph0BADsgjgA3NonN4fYiYAjdWjjTEAOie4wAVKSKZMZLTftTGWD1iC%2Bh1WCA%2BgBWPqkUx9Zb81DcnRyOTjBRdHqYemDTj8gjc4VtDoAaxAg0GZO1ev1BvcXL63H5guFpFFfX5ChAy1IyqFHNIcFgSDQRg8eHYZAoEA9Xp9KGEok4nGW2So3oIzltEAcKv5DmsqV%2B3MVpA9Ri0BAA8rRWGmnaQsEYRMB2ImS3gCflMZhbcXME88gYY%2Bn%2BddlB2hHgHMRU3osD2CMQ8EYOx0aPQmGwODx%2BIIQ2IJTJew5bZAOqgPIlGwBaXODcb7uZTYESGRySQW%2BJ5RKabQ1LKkcwlKIxYLeXx0Z9f0J%2BO%2BZQuHUuT5HQhTVPomSCHe4FJA0QEtCBlRFH%2BdSIU0H7lJwHTSt0vRcJy3J8gKVZWk8AAcrj7rc4yjOW4xhmSyxkpw4wQLghAkPK2TjHonres4vE4uKV4yEqiZqqQmrarqBoKdqRrcqaZHFlaNp2g6UkujAiAoKggk%2BuQlABkJLgMaG4aRtGsaUAmxbJrQqY9lmOb5oWValuWlbFvgtZqPWjYWs2rbtn0GZdsaFqsH2A7EL8Q79Bao7jpOpDTowLCVguAiSEI5YoKu8ixRu8DbrufgHkeJ5noMF7FTeNpgQ%2BEDmOhr7aEhn7ZCEP7%2BNBtSeN%2BiTdThOQJAUDQdXBiSQY0kTAbB02DS%2B9RFGNIF4TKhG4UIJFmuR3JUTRdGWcATGcCxbEcVxRDELxpD8YZgbCUMkiicVklOtJsk6opin7Sah3qdymn2o6qrEX0kggxaGnaT9HT1sQPgaNwQA%3D%3D">via Compiler Explorer</a>:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><div><pre><code data-lang="asm">        <span>imulq</span>   %rdi, %rdi
        <span>imulq</span>   %rsi, %rsi
        <span>leaq</span>    (%rsi,%rdi), %rax
        <span>retq</span>
</code></pre></div><p>Letâ€™s talk about that first instruction: <code>imulq %rdi, %rdi</code>. This
instruction <a href="https://www.felixcloutier.com/x86/imul">performs signed integer
multiplication</a>. The <code>q</code>
suffix tells us that it is operating on 64-bit quantities. (In
contrast, <code>l</code>, <code>w</code>, and <code>b</code> would denote 32-bit, 16-bit, and 8-bit,
respectively.) It multiplies the value in the first given register
(<code>rdi</code>; register names are prefixed with a <code>%</code> sign) by the value in
the second register and stores the result in that second
register. This is squaring <code>v.x</code> in our example C++ code.</p><p>The second instruction does the same with the value in <code>%rsi</code>, which
squares <code>v.y</code>.</p><p>Next, we have an odd instruction: <code>leaq (%rsi,%rdi), %rax</code>. <code>lea</code>
stands for â€œload effective addressâ€, and it stores the address of the
first operand into the second operand. <code>(%rsi, %rdi)</code> means â€œthe
memory location pointed to by <code>%rsi + %rdi</code>â€, so this is just adding
<code>%rsi</code> and <code>%rdi</code> and storing the result in <code>%rax</code>. <code>lea</code> is a quirky
x86-specific instruction; on a more
<a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC</a>-y
architecture like ARM64, we would expect to see a plain old <code>add</code>
instruction.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><p>Finally, <code>retq</code> returns from the <code>normSquared</code> function.</p><p>Letâ€™s take a brief detour to explain what the registers we saw in our
example are. Registers are the â€œvariablesâ€ of assembly
langauge. Unlike your favorite programming language (probably), there
are a finite number of them, they have standardized names, and the
ones weâ€™ll be talking about are at most 64 bits in size. Some of them
have specific uses that weâ€™ll see later. I wouldnâ€™t be able to rattle
this off from memory, but <a href="https://en.wikipedia.org/wiki/X86-64#Architectural_features">per
Wikipedia</a>,
the full list<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> of 16 registers on x86_64 is <code>rax</code>, <code>rcx</code>, <code>rdx</code>, <code>rbx</code>,
<code>rsp</code>, <code>rbp</code>, <code>rsi</code>, <code>rdi</code>, <code>r8</code>, <code>r9</code>, <code>r10</code>, <code>r11</code>, <code>r12</code>, <code>r13</code>,
<code>r14</code>, and <code>r15</code>.</p><p>Now, letâ€™s extend our example to debug print the <code>Vec2</code> in <code>normSquared</code>:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
<span>    <span>void</span> <span>debugPrint</span>() <span>const</span>;
</span>};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
<span>    v.debugPrint();
</span>    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and, again, letâ€™s see <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEJICcpLegAyeWpgByxgEaZiIAGykADqgWE6rR6hiaCfgFqdHYOzkZuHt5KKlG0DATMxAQhxqYWisqYqkHpmQQxTq7uXooZWTlhnLVlFXEJXgCUiqgGxMgcAORSAMz2yIZYANTiwzrICgT49DPY4gAMAILrGwvEBqqTAGpFktMA7LKbk9eT9gSe3AD6BJMAHjOXGze39A/PkwBPD7bb4AN1QeHQkywLgMwAACsQ7hAOpM0LQFsDNuIzgARLFbTZ3P4vWgkIwMACOBkymHQEGOyFOoNROM%2BYIAdDC4YjkR0Cd9iJgCL1aJNQRzXpMAFTiyXTGRygEypUEnG4gZdVggAYAVgGpFMAzWBtQOp0cjkkwUPT6mAVw04BoIOpNHS6AGsQMNhhyff6A4HvNqBtwDUaTaQzQMDQoQGtSC7jZrSHBYEg0EYfHh2GQKBBM9ncyhhKJOJw1k0qDmCO44xAXK6DS57JkATqnaRM0YtAQAPK0Vjt5OkLBGETAdhN0d4IXFUGYOMjzCvIoGWsdg13ZSboR4FzENt6LC7ghIoybro0ehMNgcHj8QSlsSWmR7lxxyBdVA%2BVJLgC0fbDJM/4LOgMy4hIMhyJIkbJEUqSaNoDSmE01itFUHhNBEgR0Ch4T%2BLhtAYfE1RNPBxR0KU9T6LkggUak1HlPYlSkVhzQ0aEqEccxsSYVwXQ2r0/QCUIOr6oa07Rq8AAcnj/g8aLPpM5YcmsHKcJMEC4IQJAOk0kx6FmObuPpqIWtBMjOk27qkF6Pp%2BoGTk%2BsGOphpJI7RrG8aJjZqYwIgKCoMZubkJQhYmR44wTuWlakNWrC1sQ9aNiOLa0G2u7dr2A5DtOY4TlOI74HOagLkukYrmuG4DJ224hpGrD7oexAAsegyRmeeAXrVKbXowLBTg%2BAiSEIE4oK%2B8hNR%2B8Dfr%2BQQAUBIFgRBUGyDIsGxoUlGmBA1j4Zwo3oSxbRkcMviEakB2jThqQke0nDnQxJR1NktGNKNz1Ua991nTx108b9WHDIJtoiZwWrieGUk6rJ8mKdFogqZwakaVpOlEMQ%2BmkIZwVFqZIySOZk3Wcmtn2b6znOWJobQ55OreQmSZupDAySHTkZeb5ZNdAuyVBCA3BAA">the generated assembly</a>:</p><div><pre><code data-lang="asm">        <span>subq</span>    <span>$24</span>, %rsp
        <span>movq</span>    %rdi, <span>8</span>(%rsp)
        <span>movq</span>    %rsi, <span>16</span>(%rsp)
        <span>leaq</span>    <span>8</span>(%rsp), %rdi
        <span>callq</span>   <span>Vec2</span>::<span>debugPrint</span>() <span>const</span>
        <span>movq</span>    <span>8</span>(%rsp), %rcx
        <span>movq</span>    <span>16</span>(%rsp), %rax
        <span>imulq</span>   %rcx, %rcx
        <span>imulq</span>   %rax, %rax
        <span>addq</span>    %rcx, %rax
        <span>addq</span>    <span>$24</span>, %rsp
        <span>retq</span>
</code></pre></div><p>In addition to the obvious call to <code>Vec2::debugPrint() const</code>, we have
some other new instructions and registers! <code>%rsp</code> is special: it is
the â€œstack pointerâ€, used to maintain the <a href="https://en.wikipedia.org/wiki/Call_stack">function call
stack</a>. It points to the
bottom of the stack, which grows â€œdownâ€ (toward lower addresses) on
x86. So, our <code>subq $24, %rsp</code> instruction is making space for three
64-bit integers on the stack. (In general, setting up the stack and
registers at the start of your function is called the <a href="https://en.wikipedia.org/wiki/Function_prologue">function
prologue</a>.) Then, the
following two <code>mov</code> instructions store the first and second arguments
to <code>normSquared</code>, which are <code>v.x</code> and <code>v.y</code> (more about how parameter
passing words in the next blog post!) to the stack, effectively
creating a copy of <code>v</code> in memory at the address <code>%rsp + 8</code>. Next, we
load the address of our copy of <code>v</code> into <code>%rdi</code> with <code>leaq 8(%rsp), %rdi</code> and then call <code>Vec2::debugPrint() const</code>.</p><p>After <code>debugPrint</code> has returned, we load <code>v.x</code> and <code>v.y</code> back into
<code>%rcx</code> and <code>%rax</code>. We have the same <code>imulq</code> and <code>addq</code> instructions as
before. Finally, we <code>addq $24, %rsp</code> to clean up the 24
bytes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> of stack space we allocated at the start of
our function (called the <a href="https://en.wikipedia.org/wiki/Function_prologue#Epilogue">function
epilogue</a>),
and then return to our caller with <code>retq</code>.</p><p>Now, letâ€™s look at a different example. Suppose that we want to print
an uppercased C string and weâ€™d like to avoid heap allocations for
smallish strings.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> We might write something like
the following:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdio&gt;</span><span>
</span><span>#include</span> <span>&lt;cstring&gt;</span><span>
</span><span>#include</span> <span>&lt;memory&gt;</span><span>
</span><span></span>
<span>void</span> <span>copyUppercase</span>(<span>char</span> <span>*</span>dest, <span>const</span> <span>char</span> <span>*</span>src);

<span>constexpr</span> size_t MAX_STACK_ARRAY_SIZE <span>=</span> <span>1024</span>;

<span>void</span> <span>printUpperCase</span>(<span>const</span> <span>char</span> <span>*</span>s) {
    <span>auto</span> sSize <span>=</span> strlen(s);
    <span>if</span> (sSize <span>&lt;=</span> MAX_STACK_ARRAY_SIZE) {
        <span>char</span> temp[sSize <span>+</span> <span>1</span>];
        copyUppercase(temp, s);
        puts(temp);
    } <span>else</span> {
        <span>// std::make_unique_for_overwrite is missing on Godbolt.
</span><span></span>        std<span>::</span>unique_ptr<span>&lt;</span><span>char</span>[]<span>&gt;</span> temp(<span>new</span> <span>char</span>[sSize <span>+</span> <span>1</span>]);
        copyUppercase(temp.get(), s);
        puts(temp.get());
    }
}
</code></pre></div><p>Here is <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEAHZeW9ABk8tTADljAI0zEuANlIAHVAsLqtHqGJua8vv5qdLb2Tkau7pxeSipRtAwEzMQEwcamForKmKqBGVkEMY4ubp6Kmdm5oQUK9RV2VfE1SQCUiqgGxMgcAORSAMx2yIZYANTiYzrILfio89jiAAwAguOT05hzC0sExHbAa5s7khO0Uwaz8zpGmEYkAJ4X25cAbqh46DM0N43gBVbzeNwsJQQZAILIzABUWBapEBdBagLhxERCkG3Xmsi%2B2zQtBamAAHt5sf4AF6YAD6BBmAFktgANekMAAqWx0AGl6VsAEpCrYATU5AEkAFrYQ4AERmnA2km4BMuPz%2BAKpdgIYIhxB0zGhJIxsPhCIU3TmZkJWxmDpmzAMRBmCgYeDpCrdJ3YtAgVvV20dMzwVBmAY9Xse80VrI53N5AuFoolDBl2Gt4ltlxDIfN2IIL284gArNJ3Z6DnIlWX5UH7XmHUDQeDIcbMBAi0ZvKjA2M7U2Hd4XQou8X8QPc47s4rlEobYOhwB6Zc%2B9AgEBGZgAawZBloeAAjgYGTRiPTUN83AB3U5F0MKGZGPAKfyiGZ0GZ6Ht4djY7BKVYEg3AAOmnJtlk3A9j1PelvBOR4CzLWRS3rMY5W7bwIHsG9MSyFDK2jGRazQyclybFt9XbaEsNA4BMAICBejdciILzEcCDHOiGKY7o2ODGczHrL5hOGXpWBAYZS2GUhTGGDZZNQKSdDkGsFH6QZq2uThZIIKTFP40gdxAbgxlAsZlTGABOMxS1LMZSySAAOSQhCk7hZPkxTSGU4ZZIUEANlIfSFPE0g4FgJA0F/f9yEoGLvD/GophEYBOGVThSCoP8i2IQKIGcAzZOcOwsjeKTdNIGLnnoAB5WhWAqsLSCwbdRHYYrWrwYhijUa9ApailihdEYqt1ZRKtk1g8GcYhyr0LAppC04jCm3oaHoJg2A4Hh%2BEEYRRBQNSZCEWbAsgXpUAQwJBoAWjqsYZju5ZYwkGQ5EkDZnqoWhUDu69VBIKsfr%2Bu6D2IfRWDu4DrqfO7fv%2Bikhhu9EAqKEoNAgKxGlMLKrEqOIEkECIAjoXGSb8MnaEJ6pEkKVJSlaCmspSPqmfKWnOnplpyhZupOfaImul6DSBiGLgJKkmS5K6vzyWcjw7o8bhAUO4AlU4UCNlAzgI1wQgSDmHTUR/JL/2NyzrVUj6ZD04qjJMsZzMkUszNLMxrI2MxnIc653OGTzZZavyAqCkKHYimBEBQVBYrceKYTj82UvVjKNiynLWDygqipa0raHK5aaq0AgGqarq2rSzqWvwXqSgGrrhuQUblomySWpmuaFowEYfJOPA1uGXSNroRgWE6vaBDc9Xjtt%2BQu4u5jfNR0kpIep6XoIdA3pO6QvtB/7AaIU4vQRsGIahmHUDhw%2B7uRzBV4UdHGaxnH9DyQQCaFunKciQJ%2BakzSFzYmrMMZpDKA0D%2BoQwGv3SK0EBXQBZQJCHjZBbRYi/04KLTSEtsEBxlt5JSUkFZKxVmrNKmtta631vgE%2BlssrfmTslbE4xJDWz3vbMKjsQDXFAu7VU3AHKK0kNZaypYZ4eS8nLKSYdgqhUMlLYYkhpEh1kRHbhvRrz5UCKZIAA%3D">the generated assembly</a>:<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p><div><pre><code data-lang="asm"><span>printUpperCase</span>(<span>char</span> <span>const</span>*):                  <span># @printUpperCase(char const*)
</span><span></span>        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
        <span>callq</span>   <span>strlen</span>
        <span>leaq</span>    <span>1</span>(%rax), %rdi
        <span>cmpq</span>    <span>$1024</span>, %rax                     <span># imm = 0x400
</span><span></span>        <span>ja</span>      <span>.LBB0_2</span>
        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
.LBB0_2:
        <span>callq</span>   <span>operator</span> <span>new</span>[](<span>unsigned</span> <span>long</span>)
        <span>movq</span>    %rax, %rbx
        <span>movq</span>    %rax, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %rbx, %rdi
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>jmp</span>     <span>operator</span> <span>delete</span>[](<span>void</span>*)                          <span># TAILCALL
</span></code></pre></div><p>Our function prologue has gotten a lot longer, and we have some new
control flow instructions as well. Letâ€™s take a closer look at the
prologue:</p><div><pre><code data-lang="asm">        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
</code></pre></div><p>The <code>pushq %rbp; movq %rsp, %rbp</code> sequence is very common: it pushes
the <a href="https://en.wikipedia.org/wiki/Call_stack#FRAME-POINTER">frame
pointer</a>
stored in <code>%rbp</code> to the stack and saves the old stack pointer
(which is the new frame pointer) in <code>%rbp</code>. The following four
<code>pushq</code> instructions store registers that <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#System_V_AMD64_ABI">we need to save before
using</a>.<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>
Finally, we save our first argument (<code>%rdi</code>) in <code>%r14</code>.</p><p>On to the function body. We call <code>strlen(s)</code> with <code>callq strlen</code> and
store <code>sSize + 1</code> in <code>%rdi</code> with <code>lea 1(%rax), %rdi</code>.</p><p>Next, we finally see our first <code>if</code> statement! <code>cmpq $1024, %rax</code> sets
the <a href="https://en.wikipedia.org/wiki/FLAGS_register">flags register</a>
according to the result of <code>%rax - $1024</code>, and then <code>ja .LBB0_2</code>
(â€œjump if aboveâ€) transfers control to the location labeled <code>.LBB0_2</code>
if the flags indicate that <code>%rax &gt; 1024</code>. In general, higher-level
control-flow primitives like <code>if</code>/<code>else</code> statements and loops are
implemented in assembly using conditional jump instructions.</p><p>Letâ€™s first look at the path where <code>%rax &lt;= 1024</code> and thus the branch
to <code>.LBB0_2</code> was not taken. We have a blob of instructions to create
<code>char temp[sSize + 1]</code> on the stack:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
</code></pre></div><p>We save <code>%rsp</code> to <code>%r15</code> and <code>%rbx</code> for later
use.<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> Then, we add 15 to <code>%rdi</code> (which,
remember, contains the size of our array), mask off the lower 4 bits
with <code>andq $-16, %rdi</code>, and subtract the result from <code>%rbx</code>, which we
then put back into <code>%rsp</code>. In short, this rounds the array size up to
the next multiple of 16 bytes and makes space for it on the stack.</p><p>The following block simply calls <code>copyUppercase</code> and <code>puts</code> as written in the code:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
</code></pre></div><p>Finally, we have our function epilogue:</p><div><pre><code data-lang="asm">        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
</code></pre></div><p>We restore the stack pointer to deallocate our variable-length array
using <code>leaq</code>. Then, we <code>popq</code> the registers we saved during the
function prologue and return control to our caller, and we are done.</p><p>Next, letâ€™s look at the path when <code>%rax &gt; 1024</code> and we branch to
<code>.LBB0_2</code>. This path is more â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolchok.org/posts/how-to-read-assembly-language/">https://wolchok.org/posts/how-to-read-assembly-language/</a></em></p>]]>
            </description>
            <link>https://wolchok.org/posts/how-to-read-assembly-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311722</guid>
            <pubDate>Tue, 02 Mar 2021 03:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National Security Commission on Artificial Intelligence's Final Report]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 43 (<a href="https://news.ycombinator.com/item?id=26311616">thread link</a>) | @AndrewKemendo
<br/>
March 1, 2021 | https://www.nscai.gov/2021-final-report/ | <a href="https://web.archive.org/web/*/https://www.nscai.gov/2021-final-report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><div data-elementor-type="wp-page" data-elementor-id="419" data-elementor-settings="[]"><div><div><section data-id="234355d" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="d8c7098" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><section data-id="deac5bd" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="8ba7a06" data-element_type="column"><div><div><div data-id="d57a85d" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg" data-elementor-open-lightbox="yes" data-elementor-lightbox-title="final-repor__screenshot-1"> <img width="732" height="412" src="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg" alt="" loading="lazy" srcset="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg 732w, https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1-300x169.jpg 300w" sizes="(max-width: 732px) 100vw, 732px"> </a></p></div></div><div data-id="cd4d96d" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg" data-elementor-open-lightbox="yes" data-elementor-lightbox-title="final-repor__screenshot-3"> <img width="732" height="412" src="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg" alt="" loading="lazy" srcset="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg 732w, https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3-300x169.jpg 300w" sizes="(max-width: 732px) 100vw, 732px"> </a></p></div></div></div></div></div><div data-id="4cf2c23" data-element_type="column"><div><div><div data-id="0d42a7d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The mandate of the National Security Commission on Artificial Intelligenceâ€™s (NSCAI) is to make recommendations to the President and Congress to â€œadvance the development of artificial intelligence, machine learning, and associated technologies to comprehensively address the national security and defense needs of the United States.â€</p><p>This Final Report presents the NSCAIâ€™s strategy for winning the artificial intelligence era. The 16 chapters in the Main Report provide topline conclusions and recommendations. The accompanying Blueprints for Action outline more detailed steps that the U.S. Government should take to implement the recommendations.</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="06674a1" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="5e2210f" data-element_type="column"><div><div><div data-id="dc57494" data-element_type="widget" data-widget_type="text-editor.default"><div><p>From quick bites to in depth interviews, hear from leading artificial intelligence and United States defense experts, including insights on how to move recommendations to crucial actions. New podcasts from our latest series, Highlights from 2020 Quarterly Recommendations, will be shared weekly.</p></div></div></div></div></div><div data-id="848e99b" data-element_type="column"><div><div><div data-id="222fe7f" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Read our COVID white paper series, including:</p><ul><li><span>The Role of AI Technology in Pandemic Response and Preparedness: Recommended Investments and Initiatives</span></li><li><span>Mitigating Economic Impacts of the COVID-19 Pandemic and Preserving U.S. Strategic Competitiveness in AI</span></li><li><p><span>Privacy and Ethics Recommendations for Computing Applications Developed to Mitigate COVID-19</span></p></li></ul></div></div></div></div></div></div></div></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://www.nscai.gov/2021-final-report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311616</guid>
            <pubDate>Tue, 02 Mar 2021 03:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract Tables from PDF/Images]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26311562">thread link</a>) | @nishparadox
<br/>
March 1, 2021 | https://docsumo.com/free-tools/extract-tables-from-pdf-images | <a href="https://web.archive.org/web/*/https://docsumo.com/free-tools/extract-tables-from-pdf-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-tool"><div><div><p>Automated table extraction from pdf &amp; images</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>It doesn't support in mobile view. <br>You can copy the link and view it in your desktop.</p></div><div id="rating-section"><div id="rating-block"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div><div><p>How it works?</p><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa7831743ca77a6aa3ee11_Choose%20File.png" loading="lazy" width="93" alt=""></p><div><p>1. Choose File</p><p>Select or drop the files you want to convert.<br></p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa628aeb96926ffa789a4f_edit%20%20and%20review.png" loading="lazy" width="101" alt=""></p><div><p>2. Edit &amp; Review</p><p>Review the extracted information in the review panel and make changes if needed.</p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa629ae8714b4bf57f0719_Convert%20%26%20Download.png" loading="lazy" width="101" alt=""></p><div><p>3. Convert &amp; Download</p><p>Download the converted file. Right after that, the input file is removed from our server.</p></div></div></div></div><div><p>Extract tables from PDF/Images</p><p>Save your crucial time and prevent any error from occurring with Docsumo's free table extraction from a PDF/Image tool. With this tool, extract tables from PDF documents and images in real-time with 100% accuracy.</p></div><div><p>Questions we often hear</p><p>Let's look at the answers</p><div><div role="list"><div role="listitem"><div><div><div><h4>Why do I need to extract tables from a PDF document?</h4></div><p>Tables are cleaner data format, and often you need only the data from tables embedded in a pdf document. That's why, businesses find it useful to extract tables from pdf documents and process the data.</p></div></div></div><div role="listitem"><div><div><div><h4>Do I need to train this free table extractor from pdf tool?</h4></div><p>The efficiency of Artificial Intelligence and Machine Learning technology improves with number of sample documents processed. So, it is highly recommended to have at least couple of sample documents ready for training.</p></div></div></div><div role="listitem"><div><div><div><h4>What fields does it capture?</h4></div><p>The tool lets you capture any text based field. The tool allows you to review the extracted data before downloading the output.</p></div></div></div><div role="listitem"><div><div><div><h4>Can I convert my document without installing the software?</h4></div><p>Documo's free online OCR tool is capable of processing any document online with complete accuracy. So, there is no need to install the tool on your system.</p></div></div></div><div role="listitem"><div><div><div><h4>Is my data secure with Docsumo?</h4></div><p>Docsumo doesn't sell or share your data to any third-party person or organization. Your data is completely secure and confidential.</p></div></div></div><div role="listitem"><div><div><div><h4>Is there any limit on using the tool?</h4></div><p>There's no usage limit on our free tool. No payment required and no credit card details needed. Sign up with us to get access to more of our resources.</p></div></div></div></div></div></div><div><h2>What Our Customers Are Saying</h2><div><div data-animation="slide" data-nav-spacing="4" data-duration="500" data-infinite="1"><div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1ba58812799fe2bd13_paysense.svg" loading="lazy" height="" alt=""></p><p>â€œWe are using Docsumoâ€™s APIs for automating data capture from bank statements and identity cards while on-boarding customers. It has reduced the time our operations team spends on data entry by manifolds while providing a much better customer experience.â€</p><p>Prashanth Ranganathan</p><p>CEO, Paysense.com</p></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1b531b085edc6c1cbf_Onez.jpeg" loading="lazy" height="" width="25" alt=""></p><p>Since the very beginning everything was fine, they always say â€œAsk anything even if you need support from our developers. The support for initial user was exceptional, even for small users like me.</p><div><p>Dario G</p><p>Operations Manager, Onerz</p></div></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1bf817cf304f90e758_dhanwise.svg" loading="lazy" height="" alt=""></p><p>"With Docsumo we were able to automate invoice processing completely. It has reduced invoice processing time from hours to minutes. Since there is no data entry required, our data extraction accuracy has improved. We highly recommend Docsumo to everyone. "</p><p>Subodh Malgonde</p><p>CEO, DhanWise.com</p></div></div></div></div></div><a href="https://docsumo.com/case-studies"><p>View more Customers Stories</p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f62f7ab382b1fa34db4108a_arrow.svg" loading="lazy" height="" alt=""></a></div><div id="free-trial-form"><div><div><div><h2>Start your free trial</h2><p>Weâ€™d love to show you how you can increase your productivity, process your documents faster and save operations cost!</p></div></div><div><div><div id="formId"><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://docsumo.com/free-tools/extract-tables-from-pdf-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311562</guid>
            <pubDate>Tue, 02 Mar 2021 03:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Literate: A Flexible Literate Programming System]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26311089">thread link</a>) | @cableclasper
<br/>
March 1, 2021 | https://zyedidia.github.io/literate/index.html | <a href="https://web.archive.org/web/*/https://zyedidia.github.io/literate/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- This adds the top navigation bar -->
            


            <!-- Jumbotron -->
            <div>
                
                <p>A Flexible Literate Programming System</p>
            </div>

            <!-- What is Literate Programming -->
            <p>View the literate <a href="https://zyedidia.github.io/literate/literate-source">source code</a> for Literate!
            </p><p>View the literate <a href="https://zyedidia.github.io/literate/website-source">source code</a> for this website!
            </p><p>See the <a href="https://github.com/zyedidia/Literate">Github page</a>.</p>
            
            <h2>What is Literate Programming?</h2>
            <p>Literate programming is a style of programming invented by Donald Knuth, where the main idea is
            that a program's source code is made primarily to be read and understood by other people, and
            secondarily to be executed by the computer.</p>
            
            <p>This frees the programmer from the structure of a program imposed by the computer and means that
            the programmer can develop programs in the order of the flow of their thoughts.</p>
            
            <p>A Literate program consists of explanation of the code in a natural language such as English, interspersed
            with snippets of code to be executed. This means that Literate programs are very easy to understand and share,
            as all the code is well explained.</p>
            
            <p>Literate, a tool for literate programming, will allow you to take a literate source file (<code>*.lit</code>) and
            either <em>tangle</em> the source file which will create a file with executable code, or <em>weave</em> the
            source file, which will generate an HTML document to be read as formatted documentation.</p>

            <!-- What are the features of lit -->
            <h2>Features of this tool</h2><p>
            Literate works with any programming language, generates HTML as output (<a href="https://wkhtmltopdf.org/">which can be converted to pdf</a>),
            and generates readable code. The code that is generated is indented properly and is automatically commented using the titles you have written
            for the code blocks.</p><p>
            Here is the full list of features:</p><ul>
                <li>Supports any language including syntax highlighting and pretty printing in HTML</li>
                <li>Generates HTML as output</li>
                <li>Generates readable code and commented in the target language</li>
                <li>Reports syntax errors back from the compiler to the right line in the literate source</li>
                <li>Runs fast -- wc.lit compiled for me in 7ms for both code and html output</li>
                <li>Markdown based -- very easy to read and write Literate source.</li>
                <li>Automatically generates hyperlinks between code sections</li>
                <li>Formatted output similar to CWEB</li>
                <li>Creates an index with identifiers used (you need to have exuberant or universal ctags installed to use this feature)</li>
                <li>Supports TeX equations with <code>$</code> notation</li>
                <li>Compatible with Vim (<a href="https://github.com/zyedidia/literate.vim" target="_blank">literate.vim</a>)</li>
                <li>Highly customizable</li>
            </ul><p>
            
            You can get started by taking a look at the <a href="https://zyedidia.github.io/literate/manual.html">manual</a>.
            In addition, this website is made with Literate, and the source can be viewed
            <a href="https://github.com/zyedidia/literate-website">here</a>.

        </p></div></div>]]>
            </description>
            <link>https://zyedidia.github.io/literate/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311089</guid>
            <pubDate>Tue, 02 Mar 2021 02:05:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CIAâ€™s Plot to Have Climbers Plant Nuclear-Powered Sensors in the Himalayas]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310527">thread link</a>) | @vinnyglennon
<br/>
March 1, 2021 | https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/ | <a href="https://web.archive.org/web/*/https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico"><p>The year is 1964. The United States and the Soviet Union have narrowly avoided full-scale nuclear destruction and resolved the Cuban Missile Crisis, the Vietnam War looms on the horizon, and Mao Zedongâ€™s Chinaâ€”fresh off a split with the Sovietsâ€”has just successfully blown up its first atomic bomb in a dry lakebed in southeastern Xinjiang, near what is now the <a href="https://www.wildcamels.com/what-we-do/lop-nur-nature-reserve/" target="_blank" rel="noreferrer noopener">worldâ€™s largest reserve for Bactrian camels</a>. </p><p>Chinaâ€™s nuclear test announced the country as the worldâ€™s fifth nuclear-armed nation, though unlike France, the USSR, and the United Kingdom, the Chinese nuclear program was a black box for American intelligence. <a href="http://www2.gwu.edu/~nsarchiv/nukevault/ebb488/docs/Doc%2028%2011-2-64%20inr%20on%20chinese%20test.pdf" target="_blank" rel="noreferrer noopener">Recently declassified government files show</a>, for example, that the U.S. was shocked to learn that the bomb was fueled by uranium, not plutonium. Military-industrial honchos were left scratching their heads as to how to gather intelligence, until a chance meeting between General Curtis LeMay and mountaineer Barry Bishop at a Washington D.C. cocktail party led to one of the most quixotic, unsuccessful operations in the CIAâ€™s long history of screwups.</p><figure><img loading="lazy" width="792" height="612" src="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg" alt="" srcset="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg 792w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=300,232 300w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=768,593 768w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=62,48 62w" sizes="(max-width: 792px) 100vw, 792px"><figcaption><a href="https://nsarchive2.gwu.edu/nukevault/ebb488/docs/doc%2033%201-0-65%20circa%20AFtAC%20report.pdf" target="_blank" rel="noreferrer noopener">An Air Force analysis</a> of nuclear debris scatter, which confirmed the use of enriched uranium. The lower of the two large arrows flows from the Xinjiang test site.</figcaption></figure><p>Bishop was part of the first American team to summit Mt. Everest the year prior, and according to <a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">Pete Takedaâ€™s fascinating 2007 <em>Rock And Ice</em> story</a>, he gushed about the unobstructed views he enjoyed from the worldâ€™s (<a href="https://defector.com/a-geologist-rocks-my-world-on-why-earths-tallest-mountain-isnt-so-obvious/" target="_blank" rel="noreferrer noopener">arguably</a>) tallest mountain. Takeda writes that LeMay put the pieces together and, â€œFrom this casual exchange emerged an unlikely inspiration: Recruit Americaâ€™s best high-altitude climbers to place a nuclear powered observation device atop the worldâ€™s greatest mountain range.â€ The hope was that a transceiver could pick up radio communications between Chinese nuclear personnel, remaining functional for years off of the heat from decaying plutonium isotopes. Per Takeda, the CIAâ€™s device was an â€œoven-sized metal bin with five radiating finsâ€ that weighed 125 pounds and was topped by a six-foot long antenna. If this sounds like a crude product of â€™60s nuclear frenzy, consider that <a href="https://mars.nasa.gov/mars2020/spacecraft/rover/electrical-power/" target="_blank" rel="noreferrer noopener">NASAâ€™s Perseverance rover</a> is scooting around on Mars thanks to this exact sort of battery. </p><p>Bishop could no longer climb high alpine peaks after <a href="https://www.nationalgeographic.com/magazine/article/first-successful-us-everest-summit-took-a-toll-on-barry-bishops-boots" target="_blank" rel="noreferrer noopener">losing all of his toes in the Everest expedition</a>, but by 1965, the CIA started putting together a team, picked a name (Operation Hat), and chose a mountain. Everest straddled Chinaâ€™s border, so it was out of contention. CIA officials eventually chose Nanda Devi, the tallest peak entirely within Indiaâ€™s borders. Nanda Devi offered two advantages to the Americans: long sightlines into Western China and the help of an Indian state that the U.S. had just supported in its 1962 border skirmish with China. </p><p>At this point in history, Nanda Devi had only been summited by six people, with three others dying in the process, so the CIA recruited a dream team of famous American climbers. The corps included pioneering El Capitan big-waller <a href="https://www.nytimes.com/2018/09/12/obituaries/tom-frost-dead.html" target="_blank" rel="noreferrer noopener">Tom Frost</a>, <a href="https://www.nytimes.com/1998/11/07/us/luther-jerstad-61-alpinist-who-scaled-everest-in-1963.html" target="_blank" rel="noreferrer noopener">1963 Everest</a> veteran Lute Jerstad, <em>Sports Illustrated</em> cover darling <a href="https://gripped.com/profiles/jim-mccarthy-was-first-climber-on-sports-illustrated/" target="_blank" rel="noreferrer noopener">Jim McCarthy</a>, and the unsung alpinist <a href="https://www.americanjournalofsurgery.com/article/S0002-9610(16)31088-1/pdf" target="_blank" rel="noreferrer noopener">Robert Schaller</a>. They <a href="https://wikileaks.org/plusd/cables/1978STATE094511_d.html" target="_blank" rel="noreferrer noopener">underwent a training course</a> on nuclear technology and â€œthe Asian mentalityâ€ at a South Carolina military base, though the climbers say they mostly spent time â€œplaying volleyball and doing some serious drinking.â€ <a href="https://wikileaks.org/plusd/cables/1978STATE094511_d.html" target="_blank" rel="noreferrer noopener">The full team undertook a training mission on Mount McKinley</a> in June with their Indian counterparts, and even though â€œdistressing weather and other difficulties kept them from the summit,â€ the CIA â€œchose to ignoreâ€ the omens and the American-Indian team set out for Nanda Devi in October 1965. </p><p>The CIA has not yet declassified files from the expedition, including apparently extensive photographs and journal records made by Schaller, so we do not have a detailed account of what happened on the mountain. But we do know how the mission ended: catastrophic failure. A storm pinned several climbers and the device down while they were roughly 1,800 feet from the summit. Indian intelligence lead Capt. M.S. Kohli was forced to call a retreat, and the team stashed the device in a crevice and attempted to anchor it in place, so it would stay put until they could come and retrieve it on the other side of winter.</p><p>McCarthy spoke at length with Takeda <a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">for the <em>Rock And Ice</em> story</a>â€”which really is great, Takeda makes his own attempt on Nanda Devi and narrowly escapes death by avalancheâ€”and he recalled his fury at the expeditionâ€™s failure:</p><blockquote><p>When I realize that theyâ€™re dumping the fucking generator and going down the mountain, Iâ€™m like, â€˜What the fuck are you doing? Have them bring it down! Are you crazy?â€™ Iâ€™m yelling at the top of my lungs.â€ According to McCarthy, the CIA case officer nearly had to pull him off Kohli. â€œHe says to me,â€ McCarthy says, â€˜You are creating an international incident!â€™â€</p><p>â€œBut,â€ McCarthy adds, â€œI had a vision of absolute clarity. Weâ€™re going to lose a SNAP generator, powered by plutonium, in the headwaters of the Ganges!â€</p><cite><a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">Rock And Ice</a></cite></blockquote><p>That might be what wound up happening. Nobody knows where the device ended up, since it disappeared from Nanda Devi at some point in the winter. The CIA ran a total of eight field operations in the region between 1965 and 1968, aimed at both finding the first device and getting another one up and running. Though they eventually implanted a plutonium device on nearby Nanda Kot, they have never been able to find their lost transceiver. The successfully placed device was also quickly buried under the snow and stopped working months later, after producing no useful intelligence.</p><p>The grim failure of Operation Hat resurfaced this month after violent floods killed over 50 people in the Indian state of Uttarakhand. The floods <a href="https://www.nytimes.com/2021/02/07/world/asia/india-glacier-flood-uttarakhand.html" target="_blank" rel="noreferrer noopener">most likely began</a> when a chunk of the Nanda Devi glacier broke off and trapped flowing water, forming a lake that eventually burst through and swept through nearby valleys. The undeniable oddness of a glacial breaking apart during the winter has <a href="https://www.bbc.com/news/world-asia-india-56102459" target="_blank" rel="noreferrer noopener">led some locals to speculate</a> that perhaps the plutonium generator, which is still likely producing heat, led to the deadly floods.</p><p>Thereâ€™s no evidence for the hypothesis, though even after years of reconnaissance missions and rigorous chemical assays of the surrounding area, nobody knows where the CIAâ€™s lost nuclear-powered spy oven is. </p></div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310527</guid>
            <pubDate>Tue, 02 Mar 2021 00:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. asks Google for detailed search data in antitrust case]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 83 (<a href="https://news.ycombinator.com/item?id=26310292">thread link</a>) | @johncena33
<br/>
March 1, 2021 | https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The U.S. government has asked Google to fork over granular data on how its search engine works and is monetized, seeking to prove that the internet giant is a monopoly.</p>

<p>The U.S. Department of Justice and several state attorneys general are seeking comparable data on U.S. search results and related ad from Feb. 2, 2015 to Feb. 8, 2015 and from Feb. 3, 2020 to Feb. 9, 2020, according to a legal filing Monday.</p>

<p>The Alphabet Inc. unit is being asked to share data on how and where users searched in those periods, the quantity of different types of ads, revenue from those ads and what the underlying bids were for them, among other details. The government told the company it wants the information within 30 days.</p>

<p>The Justice Department under former U.S. President Donald Trump and 11 Republican attorneys general originally filed the suit. Three other states have since joined, including California, the site of GoogleÃ¢â‚¬â„¢s headquarters. The latest data request shows the government is pressing ahead under a new administration led by Democrat Joe Biden.</p>

<p>The U.S. government alleges GoogleÃ¢â‚¬â„¢s exclusive deals to distribute its search engine on browsers and phones, including Apple Inc.Ã¢â‚¬â„¢s iPhones, violates the Sherman ActÃ¢â‚¬â„¢s prohibition on monopolization. ItÃ¢â‚¬â„¢s the most significant U.S. monopoly case since the one against Microsoft Corp. more than 20 years ago.</p>

<p>Google has said its deals donÃ¢â‚¬â„¢t prevent consumers from switching to other search providers. The company argues its success rests on superior technology.</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310292</guid>
            <pubDate>Tue, 02 Mar 2021 00:10:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gradients on grids of pixels/voxels â€“ forward, central, and diagonal differences]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26309398">thread link</a>) | @bartwr
<br/>
March 1, 2021 | https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<div><figure><img src="https://lh3.googleusercontent.com/BWwSXvV4LN0Ta6HG1XenEDTm5TnwsPcdWZnJbaNH0aYWJRogW-V7D0BujuJwuDa4c6TcfNzLklDJFzeHNl4jNSXiCjr19Qq8scpGCZrnktYSP6Ns_3x1yMI10rKXZyzghqoySdCt" alt=""></figure></div>



<p>In this post, I will focus on <strong>gradients of image signals defined on grids</strong> in computer graphics and image processing. Specifically, gradients / derivatives of images, height fields, distance fields, when they are represented as discrete, uniform grids of pixels or voxels.</p>



<p>Iâ€™ll start with the very basics â€“ what do we typically mean by gradients (as itâ€™s not always â€œstandardizedâ€), what are they used for, what are the ypical methods (forward or central differences), their cons and problems, and then proceed to discuss an interesting alternative with very nice properties â€“ <strong>diagonal gradients</strong>.</p>



<p>My post will conclude with advice on how to use them in practice in a simple useful scheme, how to extend it with a little bit of computations to a super useful concept of a <strong>structure tensor</strong> that can characterize dominating direction of any gradient field, and finish with some signal processing fun â€“ <strong>frequency domain analysis </strong>of forward and central differences.</p>



<h2>Image gradients</h2>



<p>What are image gradients or derivatives? How do you define gradients on a grid?</p>



<p>Itâ€™s not very well defined problem on discrete signals, but the most common and useful way to think about it is inspired by signal processing and the idea of sampling:</p>



<p><strong>Assuming there was some continuous signal that got discretized, what would be the partial derivative with regards to the spatial dimension of this continuous signal at gradient evaluation points?</strong></p>



<p>This interpretation is useful both for computer graphics (where we might have discretized descriptions of continuous surfaces; like voxel fields, heightmaps, or distance fields), as well as in image processing (where we often assume that images are â€œnatural imagesâ€ that got photographed).</p>



<p>Continuous gradients and derivatives used for things like normals of procedural SDFs are also interesting, but a different story. I will not cover those here, and instead recommend you check out <a href="https://www.iquilezles.org/www/articles/normalsSDF/normalsSDF.htm">this cool post</a> by Inigo Quilez with lots of practical tricks (re-reading it I learned about the tetrahedron trick) and advice. I am sure that no matter your level of familiarity with the topic, you will learn something new.</p>



<p>In my post, I will focus on computer graphics, image processing, and basic signal processing takes on the problem. There are two much deeper connections that I havenâ€™t personally worked too much with. So I leave it as something that I wish I can expand my knowledge in the future, but also encourage my readers to explore it:</p>



<p><strong>Further reading one:</strong> The first connection is with <a href="https://en.wikipedia.org/wiki/Partial_differential_equation">Partial Differential Equations</a> and their discretization. Solving PDEs and solving discretized PDEs is something that many specialized scientific domains deal with, and computing gradients is an inherent part of numerical discretized PDE solutions. I donâ€™t know too much about those, but Iâ€™m sure literature covers this in much detail.</p>



<p><strong>Further reading two:</strong> The second connection is <a href="https://en.wikipedia.org/wiki/Wavelet">wavelets</a>, filter banks, and the frequency precision / localization trade-off. This is something used in communication theory, electrical engineering, radar systems, audio systems, and many more. While I read and am familiar with <em>some </em>theory, I havenâ€™t found too many practical uses of wavelets (other than the simplest Gabor ones or in use for image pyramids) in my work, so again Iâ€™ll just recommend you some more specialized reading.&nbsp;</p>



<h2>Applications</h2>



<p>Ok, why would we want to compute gradients? Two common uses:</p>



<p><strong>Compute surface normals </strong>â€“ when we have something like a scalar field â€“ whether distance field describing an underlying implicit surface, or simply a height field, we might want to compute its gradients to compute normals of the surface, or of the heightfield for normal mapping, evaluating BRDFs and lighting etc. Maybe even for physical simulation, collision, or animation on terrain!</p>



<div><figure><img src="https://lh5.googleusercontent.com/u5cS-rFvdRrpN6iFTGYqDYyF8wMLCtB5-5ir2gQVMaQo8DmURyVdqF8Fyedcx9VW5boiVP8QuQZkL8zAEqG8_TYrkqx6b0bkWajLS-8IJykhlmhtxTH_YEXw_xivXSbd_2rPVLcX" alt=""><figcaption><strong>Left: </strong>an example heightmap image, <strong>right:</strong> partial derivatives (exaggerated for demonstration) that can be used for generating normal maps for lighting, collision, and many other uses in a 3D environment.</figcaption></figure></div>



<p><strong>Find edges, discontinuities, corners, and image features</strong> â€“ the other application that I will focus much more on is simply finding image features like edges, corners, regions of â€œdetailâ€ or texture; areas where signal changes and becomes more â€œinterestingâ€. The human visual system is actually built from many <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1350218/">edge detectors and local differentiators</a> and can be thought of as a <strong>multi-scale spatiotemporal gradient analyzer</strong>! This is biologically motivated â€“ when signal changes in space or time, it means itâ€™s a potential point of interest or a threat.</p>



<p>The bonus use-case of just computing the gradients is finding the orientation and description of those features. This is bread and butter of any image processing, but also very common in computer graphics â€“ from morphological anti-aliasing, selectively super-sampling only edges, or special effects. I will go back to it in the description of local features in the <strong>Structure Tensor</strong> section, but for now letâ€™s use the most common application â€“ just using the gradient vector magnitude, used for example in the <strong>Sobel operator</strong>: <img width="131" height="55" src="https://lh4.googleusercontent.com/XNZ1Arqp0sBJFnwkaJY9qxwOnn75NM57llXbo-aLmwwwPLxv93Sr8qWfaOswcKcWnvc1Hy-HGWKrsW9KHj10G-UkqOICr3SYO_Q6cXWvYBIZu5EALhRiSfp-mqrHpg6rjRFXJpAP">.</p>



<div><figure><img src="https://lh6.googleusercontent.com/B3C3hX34jil9a3GVJJY8e051jxZV-K2v2k0UqMIi9MkajBeYnB8LhKFLMlhRph-8Oe8-R5WyPzWyA9W6X6FISmSwvJ4hPf_adGwpA1Niwpn4qCNkLKYVUTk3ZK5rdLb1guiQu5rN" alt=""><figcaption>Gradient magnitude can be used for simple edge detection in an image, but also many more (described later in the post!).</figcaption></figure></div>



<h3>Test signals</h3>



<p>I will be testing gradients on three test images:</p>



<ul><li><strong>Siemens star</strong> â€“ a test pattern useful to test different â€œanglesâ€ and different frequencies,</li><li>A simple <strong>box</strong> â€“ has corners that can immediately show problems,</li><li>1 0 1 0 <strong>stripe</strong> pattern â€“ frequencies exactly at Nyquist.</li></ul>



<div><figure><img src="https://lh5.googleusercontent.com/y4CZ84at7ie-Rg3S_l1OQLy0qhoBmxHJXkZukiypUwb55r4dQWIPwGwG1qsdNyKCYqlhkG1TBsaYxOFTXhOFNsCIh47xyYCF5tvX6EhCAXAqORWSOOcWuxs0dF2nSyjyk_4NQan_" alt=""><figcaption>Test patterns / images</figcaption></figure></div>



<p>The Siemens star was rendered at 16x resolution and downsampled with a <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">sharp antialiasing filter </a>(windowed sinc). There is some aliasing in the center, but itâ€™s ok for our use-case (we want to see a sharp signal change there and then detect it).</p>



<h2>Forward differences</h2>



<p>The first, most intuitive approach is computing <strong>forward difference</strong>.</p>



<p>This is an approximation of <img src="https://lh5.googleusercontent.com/hPi-mgITwovkqTtAMg1LBk4GVXtKJqG15oSJn0MgJqljSZYk1CiM-mHoGYsW36452xxG3f2X9-72nQ2XVrTknF9v0IanFpTiRHsoGzPk-L_uVBComQrtujBayBlq_uDvpnF5HNVF" width="22" height="39"> by computing f(x+1) â€“ f(x).</p>



<p>What I love about this solution is that it is both intuitive, naive, as well as theoretically motivated! I donâ€™t want to rephrase the wikipedia and most of readers of my blog donâ€™t care so much for formal proofs, so feel free to <a href="https://en.wikipedia.org/wiki/Finite_difference">have a look there</a>, or in specialized courses (<strong>side note</strong>: 2010s+ are amazing, with so many best professors sharing their course slides openly on the internetâ€¦). Itâ€™s basically built around the <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor expansion</a> of the f(x+1) â€“ f(x).</p>



<p>This difference operator is the same as <strong>convolving the image with a [-1, 1] filter</strong>.</p>



<p>Itâ€™s easy, works reasonably well, is useful. But there are two bigger problems.</p>



<h3>Problem 1 â€“ even-shift</h3>



<p>If you have <a href="https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/">read my previous blog post</a> â€“ on bilinear down/upsampling â€“ one of challenges might be visible right away. Convolving with an <strong>even-sized filter</strong>, <strong>shifts the whole image </strong>by a half a pixel.</p>



<p>Itâ€™s easily visible as well:</p>



<div><figure><img src="https://lh5.googleusercontent.com/Mep5NBimKpkG1wHi1JFZ64tEeZH-Bavx8qZ9abnfIG8f_-vAvZERVKQs84hUSbPSiYkjVmBzyjWbTgL2oSWWyQTwuO1z2xv98LOjHp4pHsD4C09msAmnU9Z5U5Q4VO1rdAIgI24Q" alt=""><figcaption>Images vs image gradient magnitude. Notice the shift to left/top.</figcaption></figure></div>



<p>Depending on the application, this can be a problem or not. â€œA solutionâ€ is simple â€“ undo it with another even sized filter. Perfect solution would be resampling, but resampling by a half pixel is surprisingly challenging (see my <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">another blog post</a>), so instead we can blur it with a symmetric filter. Blurring the gradient magnitude fixes it (at the cost of blur):</p>



<div><figure><img src="https://lh4.googleusercontent.com/Ki309swxJtWYakp2nypvE4UjcgYC0uHBduyuyWzr_pamfzXFHjSlctrfAx1XPJYjk8LIECMlbRkvumjbT1TJkM225HiIggoy3lnu508mDUyDlHfRB2tog1VY82GLMcP61LK6GOO9" alt=""></figure></div>



<p>Blurring with an even sized filter fixes the even sized shift. But one other problem might have became much more visible right now.</p>



<p>Note: You might wonder, what would happen if we would <strong>blur just the partial differences</strong> instead? We will see in a second.</p>



<p>But letâ€™s focus on another, more serious problem.</p>



<h3>Problem 2 â€“ different gradient positions for partial differences</h3>



<p><strong>Second problem</strong> is more severe; what happens if we compute <strong>multiple partial derivatives</strong>; like df/dx and df/dy this way?</p>



<p><strong>Partial derivatives are approximated at different positions!</strong></p>



<div><figure><img src="https://lh6.googleusercontent.com/l11K2D7VeRoitc_dAIwMoC5WB4RPBdcKcdDtq4ysm9z-0LzJICmias8fhGIZQWvdEzJElkTp2xCMRxn1z5EbbYH5xb7Le2AlPFhr4ynlultytNqtm98b1n9d6f_Etu3mMTxpjUiF" alt=""><figcaption>Notice how gradient being defined between pixels means that two partial forward derivatives are defined at different points! This is a big problem.</figcaption></figure></div>



<p>Now letâ€™s have a look at the same plot again, this time focusing on â€œsymmetryâ€. This shows why itâ€™s a real, not just theoretical issue. If we look at gradients of a Siemens star and the box, we can see some <strong>asymmetry</strong>:</p>



<div><figure><img src="https://lh4.googleusercontent.com/DxZNozMlWMM6xr2c3NejQXpHB9xbiwfs1GyRBeUBQIMoksEisVz5n3jGZs5zWrPZU6xeUvnBaalc3IPTIV8LDoYevY-ZirN-Gsc-XOLwBiGSRzUCuvqIqio3AcmvU5_b1eKzj2aS" alt="" width="507" height="502"><figcaption>Notice left-top gradients being stronger for Siemens star, and producing a â€œholeâ€ on the box corner. Oops.</figcaption></figure></div>



<p>This is definitely not good and will cause problems in image processing or computing normals, but itâ€™s even worse if we look at the gradient magnitude of a simple â€œsquareâ€ in the center of the image â€“ notice what happens to the image corners, <strong>one corner is cut off, and another one 2x too intense</strong>!</p>



<p>This is a big problem for any real application. We need to look at better approximations.</p>



<h2>Central differences</h2>



<p>I mentioned that â€œblurringâ€ partial derivatives can â€œrecenterâ€ them, right? What if I told you that it is also <strong>numerically more accurate</strong>? This is the so-called <strong>central difference</strong>.</p>



<p>It is evaluated by <img data-attachment-id="4275" data-permalink="https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/gif/" data-orig-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif" data-orig-size="155,39" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gif" data-image-description="" data-medium-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif?w=155" data-large-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif?w=155" src="https://bartwronski.files.wordpress.com/2021/02/gif.gif" alt="">. The division by two is important and intuitively can be understood as dividing by the distance between the pixels, or the differential dx, where dx is 2x larger.</p>



<p>When forward difference was an approximation accurate to the O(h), this one is more accurate, to O(h^2). I wonâ€™t explain those terms here, but <a href="https://en.wikipedia.org/wiki/Finite_difference#Relation_with_derivatives">the wikipedia has some basic intro</a>, and in numerical methods literature you can find a more detailed explanation.</p>



<p>It is also <strong>equivalent to â€œblurringâ€ the forward difference with a [0.5, 0.5] filter</strong>! [0.5, 0.5] o [-1, 1] leads to [-0.5, 0, 0.5]. I was initially very surprised by this connection â€“ of a more accurate, theoretically motivated Taylor expansion, and just â€œsome random ad-hoc practical blurâ€. This is even sized blur, so this also fixes the half pixel shift problem and centers both partial derivatives correctly:</p>



<div><figure><img src="https://lh6.googleusercontent.com/QawQ4QcbqusIHhs7S0h2kekS4VQDqHCS_WizBd7dgstoHaLu5Lwj9bx_SbJImHNZnlc_aSs7FCzdYF0RW7oYjTTF3qzfoKiNENFh4yzTiYYt_GSO6lkFe-7lP2GpDs0G9XNYS52O" alt="" width="424" height="420"><figcaption>Central difference leads to perfectly symmetric (though not isotropic) results!</figcaption></figure></div>



<p>Problem â€“ missing centerâ€¦</p>



<p>However, there is another problem. Notice how the â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/">https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309398</guid>
            <pubDate>Mon, 01 Mar 2021 22:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why does an A note sound different across instruments?]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 90 (<a href="https://news.ycombinator.com/item?id=26308241">thread link</a>) | @OmarShehata
<br/>
March 1, 2021 | https://omarshehata.me/notebook/exploring_sound | <a href="https://web.archive.org/web/*/https://omarshehata.me/notebook/exploring_sound">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="notebook">
	
	<p>From <a href="https://omarshehata.me/notebook">Omar's notebook</a>.</p>
	<hr>
	
	
	<p>
		If you pull up a tuner app on your phone and play an A note on a piano, the tuner will say ~440 hz. Do the same thing on a violin's A note and you'll also get 440 hz.  
	</p>
	<p>
		This seemed impossible based on my understanding of sound, which was: 
	</p>
	<ol>
		<li>Our ears perceive sound by picking up on the frequency of the air vibrating around us.</li>
		<li>Two sounds are different if they have different frequencies, in the same way two colors appear different if they emit light of different wavelengths.</li>
		<li>When we say a sound is 440 hz, that means a point vibrating along that sound wave makes a complete cycle 440 times per second.</li>
	</ol>
	<p>
		So if two sound waves have exactly the same frequency, according to my tuner app, they cannot possibly sound different. But they do! Does that mean there's something else, something <i>more</i> than frequency that can differentiate sound? 
	</p>
	<p>
		There isn't! That's all sound is - vibrations in the air of some specific frequency. 
	</p>
	<p>
		Was the tuner lying? Yes, kind of: when we say a sound is 440 hz, that's not actually a complete description of the sound. It's kind of like telling you a shape has 4 points - you might assume it's a square. But it could be a rectangle, or some completely wacky irregular polygon. 
	</p>
	<h2>Visualizing a couple notes</h2>
	<p>
		Here's an A note from a piano and a violin that I recorded from online virtual instruments. 
	</p>
	<p>
		Click "Play" to hear them. Below each is a small slice of the audio. 
	</p>
	
	<p>Drag and drop your own sound file in these diagrams to use it throughout the article.</p>
	<p>
		They look structurally similar, but they're <i>not</i> the same sound wave. They both have a pattern that repeats ~3 times in 9 milliseconds (or ~440 times per second). So that's what makes them both 440 hz.
	</p>
	<p>
		But that pattern itself that repeats is different. This is why saying "A sound is 440 hz" isn't a complete description, so assumption (3) for me was a misunderstanding.
	</p>
	<p>
		Here is what the sound would look like if the speaker vibrated exactly 440 times per second in a continuous, regular, motion.
	</p>
	
	<p>
		The fact that all 3 of these sound different, even though they are all made of a pattern that repeats at 440 hz, tells me I need to tweak assumption (1). Our ears don't pick up on just a single frequency in the air. If they did, these sounds would be indistinguishable (which I think actually happens for our eyes, see <a href="https://en.wikipedia.org/wiki/Metamerism_(color)">metamerism</a>.)
	</p>
	<p>
		So our ears can detect the internal structure of these patterns. To decompose this structure on a computer, we'll use the Fourier transform.
	</p>
	<h3>
		Performing the Fourier Transform
	</h3>
	<p>
		The Fast Fourier Transform (FFT) algorithm allows you to extract frequencies in a signal.
	</p>
	<p>
		Our signal in this case is a list of amplitudes, how loud the sound is at every sample.
	</p>
	<p>
		When you run the signal through like <code>FFT(signal)</code> you get a list numbers that correspond to a list of frequencies. For example, if the FFT output looks like this:
	</p>
	<p><code>
		[0.001, 0.1, 0.7, 0, 12, 0, 2, 1]
	</code></p><p>
		You'll also have a corresponding list of frequencies:
	</p>
	<p><code>
		[0, 55, 110, 220, 440, 880, 1320, 1760]
	</code></p><p>
		We interpret this to mean 440 is the most significant frequency in this signal, because its FFT coefficient is 12 (the largest), and it's the 5th number. And the 5th frequency in our list is 440. 
	</p>
	<p>
		I've found it easiest to interpret the results of FFT by putting it in a table in terms of the original sound frequency and the relative weights (so I divide all of them by the largest number).
	</p>
	<p>
		Below are the FFT results running on our two 9 ms slices. <a id="compute-fft" href="#">Click to expand</a> the chosen slices. You can also scroll back up to change the slices by hand.
	</p>
	<div id="fft-table-container">
		<div id="fft-table-A-container">
			<h4>Piano A note</h4>
			<p>(<span id="piano-fft-slice-number">10</span> ms slice)</p>
			<table id="fft-table-A">
			  <thead>
			    <tr>
			      <th>Freq. (hz)</th>
			      <th>Weight (%)</th>
			    </tr>
			  </thead>
			  <tbody>
				<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
			</tbody>
			</table>
		</div>
		<div id="fft-table-B-container">
			<h4>Violin A note</h4>
			<p>(<span id="violin-fft-slice-number">10</span> ms slice)</p>
			<table id="fft-table-B">
			  <thead>
			    <tr>
			      <th>Freq. (hz)</th>
			      <th>Weight (%)</th>
			    </tr>
			  </thead>
			  <tbody>
			  	<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
			</tbody>
			</table>
		</div>
	</div>
	<p>Frequencies below 1% weight are omitted from this table.</p>
	<p>
		These tables tell us that both sounds do have ~440 hz as the strongest frequency, but there's other frequencies inside too! The violin one appears a lot more complex, in that it seems to contain a lot more frequencies that contribute significantly.
	</p>
	<p>
		The last step is reconstructing the sound from this table. Representing sound this way is really powerful. This is the basis for a lot of sound analysis/transformations like:
	</p>
	<ul>
		<li><b>Compression?</b> Remove the highest frequencies that our ears can't hear as easily. </li>
		<li><b>Noise filtering?</b> Remove specific known frequencies, that's how you can remove the sound of car horns but keep your voice in a recording.</li>
		<li><b>Auto tune?</b> Check which musical note is closest to the list of frequencies in the sound, and alter/remove/add frequencies to make it sound closer to the note.</li>
		<li><b>Voice recognition?</b> You can think of the frequencies you can create by talking as a unique pattern a software can search for. Like how the letter "E" appears ~11% of the time in most English text. We all have a few frequencies in our voices that appear with predictable probability.</li>
	</ul>
	<p>
		Below is a sandbox for you to explore these ideas of sound reconstruction.
	</p> 
	<p>
		The code returns a <code>outputMultipliers</code> array that scales the original frequencies. A new sound is reconstructed from those new frequencies/weights. You can try <a href="#" id="zero-out">zero-ing out all the high frequencies</a>, or isolate <a href="#" id="single-frequency">a single frequency</a>.
	</p>
	<div id="sandbox">
		
		<p><a href="#" id="run-code">Run</a> <span>(shortcut: CTRL+ENTER)</span><br>
		<a href="#" id="reset-code">Reset code</a></p><div id="note-visualization">
			<div id="output-fft-table">
				<h4>Filtered note</h4>
				<table id="fft-table-output">
				  <thead>
				    <tr>
				      <th>Freq. (hz)</th>
				      <th>Weight (%)</th>
				    </tr>
				  </thead>
				  <tbody>
				  	<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
				</tbody>
				</table>
				<p>Frequencies below 1% weight are omitted from this table.</p>
			</div>
			
		</div>	
	</div>
	<h3>
		Takeaways
	</h3>
	<p>
		So the correct version of assumption (3) is: When we say a sound is 440 hz, we mean that's the frequency with the most weight in the signal. To give a complete description of the sound you need to know (1) all the frequencies it's made of and (2) how much of each frequency to use.  
	</p>
	<p>
		I created this to learn how FFT works. This is the end-to-end demonstration I was looking for to help me understand it. It's best used to test your understanding while reading other materials. I don't have the source code up yet but if you'd like to extend this or use it as a teaching tool just let me know! 
	</p>
	<p>
	 	You can drag and drop any sound file in the very first two figures and all figures will update to use it, including the FFT tables and the code sandbox. Here's a few notes from <a href="https://philharmonia.co.uk/resources/sound-samples/">Philharmonia</a> you can try dragging in:
	</p>
	<ul>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/banjo_a4.mp3" download="">Banjo A note</a></li>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/flute_a4.mp3" download="">Flute A note</a></li>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/saxophone_a4.mp3" download="">Saxophone A note</a></li>
	</ul>
	<p>
		A few key points I needed for a correct implementation:
	</p>
	<ul>
		<li>
			<b>How to retrieve the original frequencies from the FFT output.</b> The FFT only tells you the frequency in terms of how often it repeats in the list of samples. So you need to multiple by the sample rate (like 44100 for most sound) to get frequency per second (Hz). Most FFT libraries in JS do NOT give you a list of the frequencies (just the coefficients). The formula for figuring out what frequency corresponds to what coefficient <a href="https://stackoverflow.com/questions/4364823/how-do-i-obtain-the-frequencies-of-each-value-in-an-fft/4371627#4371627" target="_blank">is described here</a>.
		</li>
		<li>
			<b>You have to take a small slice of the audio.</b> Given that the frequency of the sound changes over time, even when playing a single note, you won't get accurate/expected frequencies if you FFT the entire thing. For example, a piano note has an "attack" and a "decay", you want to take a slice from the middle. 
			<ul>
				<li>See the <a href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform">Short Time Fourier Transform (STFT)</a>. This is computing FFT for a small slice of audio as we just did, but do this for all slices of the audio. You'll get a list of frequencies over time. This is often visualized as a <a href="https://en.wikipedia.org/wiki/Spectrogram">spectrogram</a>.</li>
			</ul>
		</li>
		<li>
			<b>You have to sample an integer number of cycles.</b> If you take an arbitrary slice of a pure A note, you likely will get a lot more than 440 in your FFT table, unless you happen to pick a start and an end that matches a multiple of the cycle length. This article automatically shortens any slice to the nearest cycle (we figure that out by finding the nearest sample where the signal crosses the Y axis). This is also important when playing the reconstructed sound on loop (otherwise you hear a popping sound).
		</li>
		<li>
			<b>The discrete fourier transform (DFT) doesn't include all possible frequencies.</b> In theory, FFT is a continuous sum (AKA an integral) of all possible frequencies in the audio. What we have implemented here is a discrete version, where we sum a finite list of frequencies. In a small slice you may not get 440 exactly as an output, only because it wasn't included as a frequency the algorithm was looking for. I <i>think</i> in principle you could have an implementation that allows you to specify what frequencies must be included (if you know what you're looking for) but I haven't seen such an implementation.
		</li>
		<li>
			<b>FFT isn't magic.</b> A popular analogy is that FFT can take a smoothie and extract all the component that went into it. But this seems impossible??? The trick is the FFT comes in with an assumption of what frequencies might be in there. We go through each possible frequency and ask "How much 440 hz is in this sound?" and "How much 880 hz is in this sound?" and so on. So it's closer to having an unknown substance and figuring out what it is by checking if it reacts to known chemicals/substances.
		</li>
	</ul>
	<p>A few insights I learned from exploring the code sandbox:</p>
	<ul>
		<li><b>The sum of all the frequencies &lt; 1% weight have a big effect.</b> I had these hidden in the FFT tables thinking they weren't significant, and any one of them isn't, but removing them altogether does have a very noticeable effect. Here's a <a href="#" id="remove-low-weight">code snippet</a> (scroll up) that removes all frequencies with weight less than 1%. Or try the opposite, listen to only weights less than 1%.</li>
		<li><b>The high frequencies are a big part of the violin sound.</b> Removing anything at 5000 hz and up makes it no longer really sound like a violin (or just sound really muted). This isn't true for the piano.</li>
		<li><b>A string tuned to 440 hz will never emit frequencies any lower than that</b>. This is true because of the physics of standing waves, but it was really cool to learn about this in theory, and then go back to this interface and see that this was indeed true for all the recordings of notes I had! Without having known this before I â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://omarshehata.me/notebook/exploring_sound">https://omarshehata.me/notebook/exploring_sound</a></em></p>]]>
            </description>
            <link>https://omarshehata.me/notebook/exploring_sound</link>
            <guid isPermaLink="false">hacker-news-small-sites-26308241</guid>
            <pubDate>Mon, 01 Mar 2021 20:52:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teslaâ€™s market share in Europe keeps crumbling, as China reclaims top spot]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26307192">thread link</a>) | @remote_phone
<br/>
March 1, 2021 | http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/ | <a href="https://web.archive.org/web/*/http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Teslaâ€™s share of the critical European battery-electric-vehicle market crumbled in the first month of 2021, and China has taken the top spot from Europe in the EV race, according to new research.</p><p>Teslaâ€™s<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNAS/TSLA" href="http://www.marketwatch.com/investing/stock/TSLA?mod=MW_story_quote" target="_blank" rel="noopener">TSLA,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/203558040/composite">+5.48%</bg-quote></a><br>
       trajectory in Europe is in decline. The U.S. car maker delivered 1,619 battery-electric vehicles to 18 key European markets in January, representing 3.5% of all battery-electric vehicles registered that month, according to a report based on public data by automotive analyst <a href="https://twitter.com/auto_schmidt" target="_blank" rel="noopener">Matthias Schmidt</a>. In 2020, Tesla delivered 1,977 vehicles in January â€” more than a 5% market share.</p><div>
<p>Those 18 markets include the European Union states â€” minus 13 countries in Central and Eastern Europe â€” as well as the U.K., Norway, Iceland, and Switzerland.</p>
<p>Schmidt called Teslaâ€™s January performance â€œconsistently low,â€ noting that the companyâ€™s European delivery schedule sees volumes peak at the end of each quarter. However, the analyst noted that Teslaâ€™s 12-month rolling volumes have now fallen behind Hyundai<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/KR/XKRX/005380" href="http://www.marketwatch.com/investing/stock/005380?countryCode=KR&amp;mod=MW_story_quote" target="_blank" rel="noopener">005380,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206684590/delayed">-3.27%</bg-quote></a><br>
       and Kia<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/KR/XKRX/000270" href="http://www.marketwatch.com/investing/stock/000270?countryCode=KR&amp;mod=MW_story_quote" target="_blank" rel="noopener">000270,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206019389/delayed">+3.12%</bg-quote></a><span>,</span><br>
       which are now the third-most popular EV group in Europe.</p>
<p>Tesla comfortably topped the European EV charts in 2019. It delivered more than 109,000 vehicles that year, making up 31% of the regionâ€™s battery-electric-vehicle market. But the tide turned in 2020, with Tesla dropping behind both the brands of Volkswagen Group<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/XE/XETR/VOW" href="http://www.marketwatch.com/investing/stock/VOW?countryCode=XE&amp;mod=MW_story_quote" target="_blank" rel="noopener">VOW,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206919008/delayed">+0.67%</bg-quote></a><br>
       and the alliance between Renault<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/FR/XPAR/RNO" href="http://www.marketwatch.com/investing/stock/RNO?countryCode=FR&amp;mod=MW_story_quote" target="_blank" rel="noopener">RNO,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/200919924/delayed">+1.37%</bg-quote></a><span>,</span><br>
       Nissan<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/JP/XTKS/7201" href="http://www.marketwatch.com/investing/stock/7201?countryCode=JP&amp;mod=MW_story_quote" target="_blank" rel="noopener">7201,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/208298710/delayed">+1.43%</bg-quote></a><span>,</span><br>
       and Mitsubishi<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/JP/XTKS/8058" href="http://www.marketwatch.com/investing/stock/8058?countryCode=JP&amp;mod=MW_story_quote" target="_blank" rel="noopener">8058,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/208582984/delayed">+0.47%</bg-quote></a><span>.</span><br>
      &nbsp;</p>
<p>Last year, Tesla made up just 13% of the European market despite a smaller proportional decline in the number of vehicles it delivered â€” around 10% â€” from 109,000 in 2019 to nearly 98,000 in 2020.&nbsp;</p>
<p>According to Schmidt, who publishes the <a href="https://www.schmidtmatthias.de/electriccarreports" target="_blank" rel="noopener">European Electric Car Report</a>, it was the introduction of emissions targets, and the specter of massive fines, that accelerated the European car makersâ€™ battle against Tesla for dominance.</p>
<p><strong>Must read:</strong> <a href="https://www.marketwatch.com/story/tesla-is-in-decline-suvs-are-king-and-more-insights-from-the-worlds-largest-electric-vehicle-market-11612201675" target="_blank" rel="noopener">Tesla is in decline, SUVs are king, and more insights from the worldâ€™s largest electric-vehicle market</a></p>
<p>More broadly in January, China raced past Europe to reclaim its crown as the worldâ€™s largest market for electric vehicles. There were 179,000 battery-electric and plug-in hybrid electric vehicles registered in China in January, compared with 110,000 in Europe.&nbsp;</p>
<p>The boost in China comes after a standout year for Europe. There were 1.33 million electric-vehicle registrations in Europe in 2020, topping 1.25 million in China, amid a pedal-to-the-metal push to increase EV adoption from European governments and supercharged demand from consumers.</p>
<p>China is home to a strong domestic electric-vehicle sector, including manufacturers Nio<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNYS/NIO" href="http://www.marketwatch.com/investing/stock/NIO?mod=MW_story_quote" target="_blank" rel="noopener">NIO,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/204905836/composite">+8.61%</bg-quote></a><span>,</span><br>
       Xpeng<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNYS/XPEV" href="http://www.marketwatch.com/investing/stock/XPEV?mod=MW_story_quote" target="_blank" rel="noopener">XPEV,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/219982686/composite">+3.61%</bg-quote></a><span>,</span><br>
       and BYD<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/HK/XHKG/1211" href="http://www.marketwatch.com/investing/stock/1211?countryCode=HK&amp;mod=MW_story_quote" target="_blank" rel="noopener">1211,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206867707/delayed">+8.01%</bg-quote></a><span>.</span>
      </p>
<p>Schmidtâ€™s report shows that Volkswagen Group, which manufactures VW, Audi, Skoda, Seat, and Porsche, remains the most popular battery-electric vehicle group in Europe, with more than 22% of the market share after delivering 10,193 vehicles.</p>
<p><strong>Plus:</strong> <a href="https://www.marketwatch.com/story/audi-is-betting-on-the-chinese-luxury-electric-vehicle-market-in-a-joint-venture-with-the-countrys-oldest-car-maker-11611146679" target="_blank" rel="noopener">Audi is betting on the luxury market in a new electric-vehicle venture with Chinaâ€™s oldest car maker</a></p>
<p>It is closely followed by Stellantis<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNYS/STLA" href="http://www.marketwatch.com/investing/stock/STLA?mod=MW_story_quote" target="_blank" rel="noopener">STLA,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/204248628/composite">+2.26%</bg-quote></a><span>,</span><br>
       a group formed earlier this year through the merger of PSA â€” which included Peugeot and CitroÃ«n â€” and Fiat Chrysler. Stellantis delivered 9,005 vehicles.</p>
<p>Behind Stellantis is Hyundai and Kia, increasingly popular in Europe, which delivered more than 7,087 vehicles. That puts the Korean group ahead of the Renault-Nissan-Mitsubishi Alliance, which delivered 6,018 cars, though Renaultâ€™s Zoe remained the most popular battery-electric vehicle in Europe in January.</p>
<p>Then comes Mercedes-owner Daimler<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/XE/XETR/DAI" href="http://www.marketwatch.com/investing/stock/DAI?countryCode=XE&amp;mod=MW_story_quote" target="_blank" rel="noopener">DAI,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/201850364/delayed">+0.54%</bg-quote></a><span>,</span><br>
       BMW<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/XE/XETR/BMW" href="http://www.marketwatch.com/investing/stock/BMW?countryCode=XE&amp;mod=MW_story_quote" target="_blank" rel="noopener">BMW,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/202432319/delayed">+0.84%</bg-quote></a><span>,</span><br>
       and Volvo<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/SE/XSTO/VOLV.B" href="http://www.marketwatch.com/investing/stock/VOLV.B?countryCode=SE&amp;mod=MW_story_quote" target="_blank" rel="noopener">VOLV.B,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/208939564/delayed">+1.90%</bg-quote></a><span>,</span><br>
       which all delivered more battery-electric vehicles than Tesla in the first month of the year.</p>
<p>Germany remained the single largest market within Europe for electric vehicles. The 16,315 battery-electric vehicles registered in the country in January were more than the totals of the next-two largest markets, France and the U.K., combined.</p>
</div></div>]]>
            </description>
            <link>http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26307192</guid>
            <pubDate>Mon, 01 Mar 2021 19:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing dbt + Materialize]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 22 (<a href="https://news.ycombinator.com/item?id=26306861">thread link</a>) | @jldlaughlin
<br/>
March 1, 2021 | https://materialize.com/introducing-dbt-materialize/ | <a href="https://web.archive.org/web/*/https://materialize.com/introducing-dbt-materialize/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Managing data is hard. Managing data pipelines is even harder. The meaning of individual tables or values in your data warehouse gets lost in translation across organizations. Another teamâ€™s refactor breaks your teamâ€™s pipeline. And, itâ€™s normally very difficult to tell who made what change and when.</p>
<p><a href="https://www.getdbt.com/">dbt</a>, data build tool, alleviates these frustrations by taking over the transformation step in your ETL pipelines. <a href="https://blog.getdbt.com/what--exactly--is-dbt-/">dbt is not itself a data processor</a>, but instead sits on top of your data warehouse that contains your already extracted and loaded data. dbt allows teams to easily test, document, and version-control their data transformations.</p>
<p>While dbt is a great tool for transforming batch data, it cannot currently transform streaming data in real time. (The dbt team explicitly warns users about this in a <a href="https://blog.getdbt.com/is-dbt-the-right-tool-for-my-data-transformations/">few</a> <a href="https://discourse.getdbt.com/t/how-to-create-near-real-time-models-with-just-dbt-sql/1457">places</a>.) Here at <a href="https://materialize.com/">Materialize</a>, we want to help the world stop batching and start streaming. So we* built a dbt adapter that will allow you to transform your streaming data in real time using Materialize as your data warehouse.</p>
<p>The rest of this post will explore why dbt works best with batch data and how using Materialize unlocks streaming transformations. If youâ€™re eager to get started, the <a href="https://github.com/MaterializeInc/materialize/tree/main/misc/dbt-materialize">dbt-materialize adapter is here</a>, and our <a href="https://github.com/MaterializeInc/materialize/tree/main/play/wikirecent-dbt">sample streaming project is here</a>. Note: The dbt-materialize adapter is an <a href="https://github.com/MaterializeInc/materialize/issues/5462">active work in progress</a> and not yet suitable for production use-cases. Please file issues or submit PRs as you see fit, we love feedback!</p>
<p>*The dbt-materialize adapter was originally created by Josh Wills and actively shaped by Jeremy Cohen. Thank you for all of your work and support!</p>
<h2>dbt and batch data</h2>
<p>dbt is great at transforming batch data, but it cannot transform streaming data efficiently in real time. To understand why, letâ€™s take a look at how dbt transforms data under the hood.</p>
<p>dbt users define their desired transformations using <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/">dbt â€œmodelsâ€</a>. dbt models are SQL files that contain:</p>
<ul>
<li>A SELECT statement that performs the desired transformation</li>
<li>A <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/materializations/">â€œmaterializationâ€</a> parameter</li>
</ul>
<p>dbt transforms your data each time you <a href="https://docs.getdbt.com/reference/commands/run/">â€œrunâ€</a> a model. Each time a model is run, dbt queries the underlying data warehouse using that modelâ€™s SELECT statement. The result set of the query (the transformed data) is then either returned directly to the user or persisted into your data warehouse, depending on the modelâ€™s materialization parameter.</p>
<p>Currently, dbt supports four types of materializations: <em>table</em>, <em>view</em>, <em>incremental</em>, and <em>ephemeral</em>. The <em>table</em> and <em>incremental</em> materializations persist a table, the <em>view</em> materialization creates a view, and the <em>ephemeral</em> materialization, instead of persisting anything, returns results directly using a common table expression (CTE). The good news is that these database objects are totally sufficient to transform batch data. The bad news is that none of these database objects transform streaming data efficiently.</p>
<p>First, what do I mean by batch and streaming data? Batch data, as the name suggests, is any type of data that arrives in discrete batches. This can be once a minute, once an hour, or once a day. The important thing is that no new data arrives between batches. Streaming data, on the other hand, arrives continually and at no particular schedule.</p>
<p>So, why are these database objects sufficient to transform batch data, but not able to efficiently transform streaming data?</p>
<p>Views and CTEs do not physically persist data to your data warehouse. This means that each time you query a model that uses a view or CTE, your data warehouse must re-transform the underlying source data. And, each time you transform your source data, you are paying some cost. While views and CTEs always return up-to-date transformations of your batch and streaming data, they do not do so efficiently.</p>
<p>Tables, on the other hand, do physically persist data. More specifically, tables persist the result set of the last time their model â€œdbt run.â€ Unlike views and CTEs, this means that you wonâ€™t pay the price of transforming data each time your table is queried. But, this means that your transformed data can quickly become stale as new data arrives. This is not an issue with batch data because you can simply â€œdbt runâ€ your table each time a new batch arrives. Unfortunately, things arenâ€™t so simple with streaming data.</p>
<p>Because streaming data does not arrive on a schedule, there is no longer a right time to re-run your models to keep them up-to-date. Instead, youâ€™re forced to choose between maximizing data freshness and minimizing transformation costs. You can minimize your costs by limiting how often you recreate your tables, effectively turning your streaming data into batch data. Or, you can maximize your data freshness by continually recreating your tables. But, this approach will cost you time and money, leave you vulnerable to bugs, and still wonâ€™t maintain truly up-to-date results.</p>
<p>So, what should you do if you want to transform streaming data with dbt?</p>
<h2>dbt and streaming data</h2>
<p>dbt currently has one official and one unofficial way to approximate transforming streaming data. Neither of these methods truly transforms streaming data in real-time, and both come at a cost.</p>
<p>The first method to approximate transforming streaming data is to create models with an incremental materialization. The first time you run an incremental model, dbt persists your transformationâ€™s result set into a table in your data warehouse. For subsequent runs, dbt only transforms the subset of source data indicated by your modelâ€™s filter predicate. (For example, you might have a filter predicate that will only transform data with a timestamp greater than your last modelâ€™s run.)</p>
<p>While incremental models reduce the severity of the tradeoff that users face when persisting their transformations in tables (data freshness vs cost), they do not eliminate the tradeoff entirely. By design, you will probably be paying a lesser cost each time you â€œdbt runâ€ an incremental model. (I say â€œprobablyâ€ here because even though youâ€™re only transforming a few rows of data with each run, unless youâ€™re filtering cleverly, your modelâ€™s SELECT statement will still have to scan the entire underlying source table or view to discover these rows). While these lesser costs may free you up to run your incremental models more frequently, you still will not be able to run them continuously. By definition, you are still transforming your streaming data with a batch process.</p>
<p>The second way to approximate transforming streaming data is the <a href="https://discourse.getdbt.com/t/how-to-create-near-real-time-models-with-just-dbt-sql/1457">unofficial â€œlambda viewâ€ approach</a>. This method simulates transformations over â€œnear real-time modelsâ€ by querying a combined historical table and a current view. This approach incurs the cost of querying both of the underlying database objects using some filter, similar to the incremental materialization. The current view of your data returns up-to-date results, but must re-transform the recent data each time.</p>
<p>Neither of these methods can efficiently transform data in real time. (And, they come with <a href="https://discourse.getdbt.com/t/on-the-limits-of-incrementality/303">hairy problems</a> if, say, you have streaming data that might arrive late.) In order to efficiently perform worry-free, real-time transformations of streaming data, dbt would need to persist a database object that updates as new data arrives upstream. Luckily, there is a database object that can do this for us: materialized views.</p>
<h2>dbt and Materialize</h2>
<p>Materialized views in traditional databases behave a bit like dbtâ€™s incremental materialization. When a materialized view is first created, the result set of its query is physically persisted in the database. Then, at some interval or when manually triggered, the stored result set is updated with recent data. Like the incremental materialization, maintaining these materialized views incurs a variety of costs.</p>
<p>This is the exact problem Materialize was created to solve. Unlike traditional materialized views, <a href="https://materialize.com/why-use-a-materialized-view/">our materialized views</a> continually update as new data arrivesâ€“no refreshes needed. Better yet, we provide up-to-date results with millisecond latency. (For more information about Materialize and our materialized views, check out <a href="https://materialize.com/docs/">our documentation</a>.)</p>
<p>So, what does this mean for dbt and streaming data? This means that the first time you run a dbt model on top of Materialize, dbt persists a materialized view. <strong>Then, you never have to run your model again.</strong> No matter how much or how frequently your data arrives, your model will stay up to date. No matter when you query your view, it will return a fresh answer. Just by creating your model with our materialized views, you can confidently and efficiently transform streaming data in real time.</p>
<h2>Try it out!</h2>
<p>Excited? Skeptical? Cautiously optimistic? Try it out for yourself! As mentioned before, we have a <a href="https://github.com/MaterializeInc/materialize/tree/main/misc/dbt-materialize">beta dbt-adapter</a> and a <a href="https://github.com/MaterializeInc/materialize/tree/main/play/wikirecent-dbt">demo streaming project</a>. If you have any thoughts, questions, or concerns, please feel free to contact us in our community Slack or in our dbt repos. (Or, when youâ€™re up and running, tell us what youâ€™re transforming in real time!)</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/introducing-dbt-materialize/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306861</guid>
            <pubDate>Mon, 01 Mar 2021 19:13:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Screenplay Format Reference]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26306809">thread link</a>) | @jstrieb
<br/>
March 1, 2021 | http://www.trilane.com/ref/index.html | <a href="https://web.archive.org/web/*/http://www.trilane.com/ref/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="915" nof="ly">
  <tbody><tr>
   <td>
    <p><img id="Picture3" height="93" width="90" src="http://www.trilane.com/ref/a_reels.jpg" alt="reels" title="reels"></p>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="12" height="1" alt=""></td>
      <td></td>
     </tr>
     <tr>
      <td></td>
      <td nof="NB_BYVTNN000">[Top]</td>
     </tr>
    </tbody></table>
   </td>
   <td>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="15" height="1" alt=""></td>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="559" height="1" alt=""></td>
     </tr>
     <tr>
      <td></td>
      <td>
       <p><b><span>The Ultimate Screenplay Format Reference</span></b></p>
      </td>
     </tr>
    </tbody></table>
    
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="389" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>FADE IN:</span></p>
          <p><b><span>Table of Contents</span></b></p>
          <p><b><span>measurements</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">typeface</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">margins and tabs</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">page numbers</a></span></li>
          </ul>
          <p><b><span>scenes</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html">master scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html#SecHeadings">secondary scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">montage</a>, <a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">series of shots</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashback">flashbacks</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashseq">flashback sequences</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#quickflashes">quick flashes</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html">dreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#daydream">daydreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#imagining">imaginings</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#vision">visions</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#animation">animation</a> and sequences thereof</span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html">establishing shots</a></span></li>
           <li><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingScenes"><span>spacing between scenes</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingLines">spacing between lines</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#transitions">scene transitions<span>, </span><span>MATCH CUT</span></a></span></li>
          </ul>
          <p><b><span>characters</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/chars/chars.html#names"><span>character names</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html#cues">character cues</a></span></li>
          </ul>
          <p><b><span>narrative and action</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/action/action.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/action/action4/action4.html#SUPER"><span>SUPER</span><span>, </span><span>SCROLL</span><span><span>, </span></span></a><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><span>words on TV</span></a></li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV">
           </a><li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><b><span></span></b></a><b><a href="http://www.trilane.com/ref/action/action4/action4.html#insert"><span>INSERT</span></a></b></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#sounds">sounds, MOS</a></span></li><a href="http://www.trilane.com/ref/action/action.html#sounds">
           </a><li><a href="http://www.trilane.com/ref/action/action.html#sounds"><span></span></a><a href="http://www.trilane.com/ref/action/action.html#spfx">special effects (<span>FX</span>, <span>SPFX</span>, <span>SFX</span>)</a></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#POVs"><span>POV</span>, <span>CLOSE UP</span>, <span>PULL BACK</span></a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html">slow motion</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#music">music</a>, <a href="http://www.trilane.com/ref/action/action2/action2.html#lyrics">music lyrics</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#clips">movie clips</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action3/action3.html">unseen characters</a>, <a href="http://www.trilane.com/ref/action/action3/action3.html#phantom">phantom POV</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action4/action4.html#stacking">action stacking</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action5/action5.html">then we see ...</a></span></li>
          </ul>
          <p><b><span>dialog </span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#wrylies">actorâ€™s instructions</a> (a.k.a. wrylies)</span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#os"><span>(O.S.)</span></a> and <a href="http://www.trilane.com/ref/dlg/dlg.html#vo"><span>(V.O.)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg.html#more"><span><span>MORE</span> <span>and</span> </span><span>CONTâ€™D / CONTINUED</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html">telephone conversations</a></span></li>
           <ul>
            <li><span><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span>INTERCUT</span></a></span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a></span></li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a></ul><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a><li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html">overlapping dialog</a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html#computer">computer conversations</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html#foreign">foreign languages</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html">telepathic dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html">mute dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#beat"><span>(beat)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>-- </span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>...</span></a></span></li>
          </ul>
          <p><b><span>miscellaneous</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html">the title page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#firstPage">the first page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#credits">credits and titles</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#lastPage">the last page</a></span></li>
           <li><span>authorâ€™s intrusions</span></li>
           <li><span><a href="http://www.trilane.com/ref/misc/misc.html"><span>notes</span></a></span></li>
          </ul>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <div>
             <p><span>Writing a screenplay is difficult.</span></p>
             <p><span>Formatting should be the least of all problems. Actually itâ€™s the most easiest to master, if you follow a set of simple rules.</span></p>
             <p><span><a href="http://astore.amazon.com/trilane-20/detail/1879505843/105-1611443-6684411">Trottierâ€™s Screenwriterâ€™s Bible</a> is currently considered the final authority on formatting issues. I recommend you read it. It will save you a lot of pain.</span></p>
             <p><span>Here you find a reference to those rules. Follow them and your screenplay will be well formatted.</span></p>
            </div>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="122" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="344" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>If you donâ€™t believe me then take this from a pro:</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="47" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="343" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>â€œReaders in Hollywood do a great deal of inductive reasoning, which goes something like this: â€œI just read 99 screenplays, they were all horrible, and they were all written in improper format. Therefore, if screenplay number 100 is also in improper format, it must be horrible, too.â€</span></p>
          <p><span><span>Michael Hauge, Collins 2007, Writing Screenplays That Sell </span></span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="49" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="340" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>â€˜Writing Screenplays That Sellâ€™ is another good book to read.</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="262" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="80" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="311" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>At the bottom of this page you find a few books that are real helpful in addressing important issues beyond formatting.</span></p>
          <p><span>... all the best for your own screenwriting.</span></p>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
      <td>
       
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="27" height="1" alt=""></td>
         <td>
          <div>
             <p><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture22" height="125" width="83" src="http://www.trilane.com/ref/a_Writer_s_Journey_Vogler.jpg" alt="Writer's Journey_Vogler" title="Writer's Journey_Vogler"></a><br><span><b><br>The Writerâ€™s Journey<br></b>Christopher Vogler</span></p><p>Paperback <br>300 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture16" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          <div>
             <div><p><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture23" height="125" width="79" src="http://www.trilane.com/ref/a_Screenwriter_s_Problem_Solver_Field.jpg" alt="Screenwriter's Problem Solver_Field" title="Screenwriter's Problem Solver_Field"></a></p><p><span><b>The Screenwriterâ€™s Problem Solver<br></b>Syd Field</span></p><p>Paperback <br>384 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture18" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p></div>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
   </td>
  </tr>
 </tbody></div></div>]]>
            </description>
            <link>http://www.trilane.com/ref/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306809</guid>
            <pubDate>Mon, 01 Mar 2021 19:10:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ten seconds to ponder if a thread is worth it]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 44 (<a href="https://news.ycombinator.com/item?id=26306478">thread link</a>) | @eat_veggies
<br/>
March 1, 2021 | https://blog.jse.li/posts/ten-seconds/ | <a href="https://web.archive.org/web/*/https://blog.jse.li/posts/ten-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<p>A userstyle that makes you wait ten seconds before entering a Hacker News thread. I use <a href="https://github.com/openstyles/stylus">stylus</a> to manage mine.</p>
<div><pre><code data-lang="css"><span>.</span><span>subtext</span> <span>{</span>
  <span>--bar-color</span><span>:</span> <span>#f60</span><span>;</span>
  <span>--animation-delay</span><span>:</span> <span>0.5</span><span>s</span><span>;</span>
  <span>--animation-duration</span><span>:</span> <span>9.5</span><span>s</span><span>;</span>

  <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span><span>to</span> <span>left</span><span>,</span> <span>transparent</span> <span>50</span><span>%</span><span>,</span> <span>var</span><span>(</span><span>--</span><span>bar</span><span>-</span><span>color</span><span>)</span> <span>50</span><span>%</span><span>);</span>
  <span>background-position</span><span>:</span> <span>right</span><span>;</span>
  <span>background-size</span><span>:</span> <span>201</span><span>%</span><span>;</span>
  <span>display</span><span>:</span> <span>inline</span><span>-</span><span>block</span><span>;</span>
  <span>transition</span><span>:</span> <span>background</span><span>-</span><span>position</span> <span>0.2</span><span>s</span><span>;</span>
<span>}</span>

<span>.</span><span>subtext</span><span>:</span><span>hover</span> <span>{</span>
  <span>background-position</span><span>:</span> <span>left</span><span>;</span>
  <span>transition</span><span>:</span> <span>background</span><span>-</span><span>position</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>duration</span><span>)</span> <span>linear</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>delay</span><span>);</span>
<span>}</span>

<span>.</span><span>subtext</span> <span>a</span><span>[</span><span>href</span><span>^=</span><span>"item"</span><span>]</span> <span>{</span>
  <span>pointer-events</span><span>:</span> <span>none</span><span>;</span>
<span>}</span>

<span>.</span><span>subtext</span><span>:</span><span>hover</span> <span>a</span><span>[</span><span>href</span><span>^=</span><span>"item"</span><span>]</span> <span>{</span>
  <span>animation</span><span>:</span> <span>enable-click</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>duration</span><span>)</span> <span>forwards</span> <span>step-end</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>delay</span><span>);</span>
<span>}</span>

<span>@</span><span>keyframes</span> <span>enable-click</span> <span>{</span>
  <span>to</span> <span>{</span>
    <span>pointer-events</span><span>:</span> <span>auto</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>Special thanks to Martino di Filippo (<a href="https://github.com/MartinodF">@MartinodF</a>) for showing me the <code>animation-timing-function: step-end</code> CSS property!</p>

    </section></div>]]>
            </description>
            <link>https://blog.jse.li/posts/ten-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306478</guid>
            <pubDate>Mon, 01 Mar 2021 18:46:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Won't Save Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26306372">thread link</a>) | @hackitup7
<br/>
March 1, 2021 | https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A common situation: Things are going fine, but not great at your SaaS business. Your sales teamâ€™s win rates arenâ€™t quite high enough. Your marketing pipeline isnâ€™t quite as full as youâ€™d like. Your customers are happy but some are considering other solutions. Overall, your product doesnâ€™t quite feel differentiated enough.</p>

<p>A natural temptation that Iâ€™ve seen in this situation is to look to machine learning as the solution to your differentiation woes. If we just sprinkle a dash of the olâ€™ ML on this bad boy, the thinking goes, weâ€™ll have a product that stands out in the market and that everyone will love. In general, this strategy just doesnâ€™t work.</p>

<h2 id="machine-learning-is-not-unique">Machine Learning Is Not Unique</h2>

<p>First â€“ at this point in time, everybody vaguely knows what machine learning is and has a rough sense for its capabilities. Youâ€™re not getting a jump on the market by declaring that youâ€™re going to make your product â€œpowered by AI.â€ Every Gartner report has some checkbox about building intelligent or predictive features, and itâ€™s no longer a secret that there appears to be some magical pixie dust out there that you can drizzle on your product to make it special.</p>

<p>Using machine learning to differentiate your product is like driving a fancy sports car to stand out when picking someone up for a date. It can be cool, it might even fit your persona, and <em>some</em> people will be impressed. But ultimately it isnâ€™t revolutionary or inherently game changing.</p>

<p><img src="https://staysaasy.com/assets/ml-wont-save/russ.jpg" alt="Tres comas">
We have an ML product, now are you interested?</p>

<p>ML is a buzzword of the moment â€“ and investing in buzzwords is not the route to enduring differentiation. Thereâ€™s always some technology thatâ€™s gotten enough mindshare that everyone is sharing blog posts, frantic manifestos are being written, and investors are hot and bothered. 2 decades ago it was cloud, itâ€™s currently (roughly speaking) machine learning and crypto, and who knows what it will be next.</p>

<p>This doesnâ€™t mean that ML features are useless â€“ if itâ€™s useful, people will pay. But there is essentially no novelty left in the ML play. Even if the underlying trend is meaningful (for example, cloud transformation was and continues to be a big deal!), the biggest trends rapidly become table stakes.</p>

<h2 id="a-lot-needs-to-go-right-for-ml-to-work">A Lot Needs to Go Right for ML to Work</h2>

<p>The barrier to building a profitable, differentiating ML-driven product is high â€“ not only in a technical sense, but also in terms of the role that it solves for your business. It canâ€™t just be slapped on top of your product like salad dressing:</p>

<ul>
  <li>You need to have an ML application that fits your business model â€“ for example, if ConvertKit (which Stay SaaSy uses for our newsletter) adds a crazy send-time-optimization product, that might simply not matter for sites like us that use them to email out blog content</li>
  <li>You need a problem that <em>you</em> can solve but <em>others</em> canâ€™t. In reality, you are probably not orders of magnitude smarter than your competition</li>
  <li>You need to solve a problem that has a tangible business impact â€“ only the most frivolous buyers will purchase something just because itâ€™s cool technology</li>
  <li>You need to actually prove that whatever ML magic youâ€™ve built actually solves a key problem better than anyone else can, or for that matter solves a real problem at all</li>
</ul>

<p><img src="https://staysaasy.com/assets/ml-wont-save/emeril.png" alt="Bam!">
Letâ€™s just slap some machine learning on there, and Bam!</p>

<p>A situation that checks all of the boxes above is the holy grail, but you need to be honest about whether thatâ€™s the case. Itâ€™s very possible that youâ€™d be better off trying to differentiate your SaaS product by <a href="https://staysaasy.com/product/2020/11/04/selling-to-the-enterprise-expand-playing-field.html">creating a suite of functionality</a> or investing heavily in UX â€“ both strategies that many companies have used to construct defensible product moats.</p>

<p>The concept of provable value is one of the most unknown or unappreciated elements of building a sellable ML product. The more that you can prove that youâ€™re adding revenue or reducing costs, the stickier your revenue will be. When the rubber hits the road and something needs to get cut, the products that add value in a provable and (ideally) deterministic way are the ones who survive.</p>

<p>Many customers want to verify the results of anything that theyâ€™re paying for, and black boxes understandably scare them. Hype has created a litany of startups peddling ML snake oil and buyers are rightfully skeptical. This increases the barrier to entry and means that itâ€™s much harder to build an enduring ML product. Not only does your product need to work, but you often need to build significant reporting functionality that allows customers to dissect your product and verify the advantage that you claim to provide. And keep in mind that many customers will approach the problem of analyzing whether your algorithms add value adversarially â€“ teams that wanted to build ML products in-house rather than buying yours will be especially aggressive critics and naysayers.</p>

<h2 id="the-promise-of-machine-learning-as-a-silver-bullet-is-distracting">The Promise of Machine Learning as a Silver Bullet is Distracting</h2>

<p>Perhaps the worst part of hoping that you can dust magical machine learning on top of your product is that it trains you to look for silver bullets. ML feels like a new, magical solution that will solve all of your problems. In reality magic solutions are near-mythical and itâ€™s dangerous to believe in them.</p>

<p>The earlier your startup, the worse the optics of saying that youâ€™re going to dominate your market by sprinkling machine learning on your product. If you have terabytes of unique data and claim that it will unlock the portal to Machine Learning Narnia, or if you have a unique approach and track record that indicates true expertise, reasonable listeners will hear you out and not immediately assume that youâ€™re full of it. But if your non-specialized team is trying to raise some kind of seed fundraising on the back of a machine learning story (â€œWeâ€™re just going to do X, but with MLâ€), then it should be obvious that you donâ€™t have anything vaguely proprietary. At best, you look overly optimistic; at worst, you look like you have no idea what ML actually entails. Unfortunately, some people will pump you up and make you believe that this strategy is viable â€“&nbsp;the rest will roll their eyes at your â€œ.aiâ€ domain once you leave the room.</p>

<p>Why does this happen? I think itâ€™s because the talk track â€œweâ€™re going to do X but with AIâ€ does work on a certain kind of unsophisticated observer. If boasting about ML products is like driving a McLaren, there are indeed investors / buyers who are the equivalent of someone who is really, really captivated by a fancy car. You canâ€™t count on this to be an enduring advantage.</p>

<h2 id="where-machine-learning-matters">Where Machine Learning Matters</h2>

<p>Where Iâ€™ve seen machine learning make the biggest difference is in extending a lead that youâ€™ve already earned. An example of where ML can really set a product apart is Photoshopâ€™s ability to do <a href="https://blog.adobe.com/en/publish/2020/10/20/photoshop-the-worlds-most-advanced-ai-application-for-creatives.html#gs.mqvj9d">automatic skin smoothing and sky replacement</a>. This is some hardcore stuff, and Adobe has checked the box on the narrow domain where ML products can make a huge difference:</p>

<ul>
  <li>They have the data and team to solve this problem well</li>
  <li>They have a platform (Photoshop itself!) where automatic image manipulation software can be plugged in to add significant value</li>
  <li>You can actually observe that their technology works.</li>
  <li>Photoshop already exists as the most sophisticated graphics editing software, so adding more sophisticated features on top of it extends their advantage on the market</li>
</ul>

<p>Due to the technical moats that it can create machine learning functionality can be a great accelerant when it works well. But you simply canâ€™t rely on it to be the singular differentiator for your business.</p>

<p><img src="https://thumbs.gfycat.com/AdmiredLawfulBunny-size_restricted.gif" alt="These are not the doors of a billionnaire, Richard!"></p>


    

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306372</guid>
            <pubDate>Mon, 01 Mar 2021 18:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Frictionless habit-tracking on iOS (pokeable from your text editor too)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26306018">thread link</a>) | @xenodium
<br/>
March 1, 2021 | http://xenodium.com/frictionless-org-habits-on-ios | <a href="https://web.archive.org/web/*/http://xenodium.com/frictionless-org-habits-on-ios">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-frictionless-org-habits-on-ios">

<p><img src="http://xenodium.com/images/frictionless-org-habits-on-ios/flat_habits.gif" alt="flat_habits.gif" width="80%" height="80%">
</p>

<p>
I've been wanting org to keep track of my daily habits for a little while. The catalist: reading James Clear's wonderful <a href="https://jamesclear.com/atomic-habits">Atomic Habits</a> (along with plenty of lock-down inspiration).
</p>

<p>
As much as I live in Emacs and org mode, it just wasn't practical enough to rely on my laptop for tracking habits. I wanted less friction, so I've been experimenting with building a toy app for my needs. Naturally, org support was a strict requirement, so I could always poke at it from my beloved editor.
</p>

<p>
I've been using the app every day with success. The habits seem to be sticking, but equally important, it's been really fun to join the fabulous world of Emacs/Org with iOS/SwiftUI.
</p>

<p>
This is all very experimental<sup><a id="fnr.1" href="#fn.1">1</a></sup> and as mentioned on <a href="https://www.reddit.com/r/emacs/comments/ljurwx/org_habits_ios_app_want_to_try_it/">reddit</a> (follow-up <a href="https://www.reddit.com/r/emacs/comments/lp62vn/org_habits_ios_app_followup_twoway_edit/">here</a>) and <a href="https://twitter.com/xenodium/status/1361034010047176705">twitter</a>, the app isn't available on the App Store. I may consider publishing if there's enough interest, but in the mean time, you can reach out and install via <a href="https://testflight.apple.com/">TestFlight</a>.
</p>

<p>
Send me an email address to <i>flathabits*at*xenodium.com</i> for a TestFlight invite.
</p>
</div></div>]]>
            </description>
            <link>http://xenodium.com/frictionless-org-habits-on-ios</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306018</guid>
            <pubDate>Mon, 01 Mar 2021 18:18:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doing the impossible, monetising Chrome Extensions]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26305789">thread link</a>) | @thomasisaac
<br/>
March 1, 2021 | https://tillypay.com/blog/how-to-monetise-a-chrome-extension/ | <a href="https://web.archive.org/web/*/https://tillypay.com/blog/how-to-monetise-a-chrome-extension/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>So here you are, youâ€™ve built a tool for the Chrome Web Store and suddenly youâ€™ve been bestowed with a<strong> couple of thousand users across the globe</strong>.</p><p>One question, would be how to monetise such an impressive piece of tech youâ€™ve created.</p><p>If youâ€™ve spent your time on an Android or iOS, the path to monetisation are far easy &amp; a lot simplier. Somehow, however, <strong>Chrome Extensions donâ€™t carry the same weight</strong> in the mind of the user. They are much more inclined to pay for an app or an ongoing service but Chrome Extensions wind up in the realm of â€œshould be free.â€</p><p>A lot of chrome extensions are the child of a large product or a global product itself, cases such as Honey, the coupon finder &amp; Grammerly are super giants that donâ€™t really fall into the realm of developer accidently making a tool valuable to thousands.</p><p>There seems to be a vat of extensions floating around the 20k to 50k mark, not been updated since 2015. What do to?</p><p>Rather than give you a list of things<strong> untried or untested with affiliate links attached, letâ€™s run through stories that I know.</strong></p><p>There's a new platform called <a href="https://monetise.so/">Monetise.so</a>, they have built a Chrome Extension billing platform as a direct replacement for the upcoming sunset of the Chrome Web Store Payments.</p><p>Check them out : <a href="https://monetise.so/">https://monetise.so</a></p><p>Itâ€™s no secret that Adblock Plus with their ~100 Million global users have profited from the blockage of adverts existing on internet.</p><p>The business model is unique &amp; simple, they allowed certain whitelisted ads through, non-intrusive and Google paid them an undisclosed amount.</p><p>They are not the only ones who do what they do, but theyâ€™re very good at it.<br>They aggregate affiliate schemes across the internet and put them into a single JS file for you to plugin to your site. They also built something for Chrome Extensions, after you include in your code, they will start including logos on Google Search Results, like so:</p><figure><img src="https://tillypay.com/blog/content/images/2020/02/1-tf0Kx1jGsc5mmRHPo7VYXA.png"></figure><p>The DJI link is now monetised and everyone is happy, the user who is paying somewhat for the extension, the extension developer but not Google Chrome, understandably.</p><p>This is malvertising, itâ€™s advertising in a malware way of including unwanted code. Even with itâ€™s horrid name, if privacy is not your thing, then thereâ€™s very little impacting the end user. The issue comes when you are allowing a third party with that much access to your google searches, maybe not.</p><p>Actually, I do have access to the maths on this:</p><ul><li><strong>50,000 Weekly Users resulted in about â‚¬2.2k a month.</strong></li><li>Thatâ€™s about <strong>4.4 cent per user,</strong> mostly from Tier 1 GEOs (US, UK, FR, DE)</li></ul><p>Google will kick you out if they find this.<br>It's happened time &amp; time again.</p><p>Revolution, is what they called it.<br>A new way to monetise the internet.</p><p>Yes, but no. Firstly, the UX for your end-user sucks balls.<br>Their brand new computer is down to itâ€™s last leg trying to get the you (the developer), $0.0002 per minute of agony.</p><p>Also, Iâ€™ve tried this.<br>I had 10k Weekly Users, that turned into about 30 concurrent users on average at any one time.</p><p>I made $16 a month from Coinhive at 25% of his userâ€™s CPU.</p><p>Back to the drawing board.</p><p><em>Freemium</em><br>Popular topic on the lips of SaaS models, provide something a bit more &amp; users are willing to pay for it. The problem you may have is that you product just isnâ€™t worth a cup of coffee a month. On a popular VPN Chrome extension, they managed to get 50k users a month to pay for their premium product out of a user base of 4 million MAU. Their premium product was pretty damn great too.</p><p>Here are some great stories of Chrome Extensions being monetised in this way:</p><ul><li><a href="https://www.indiehackers.com/interview/how-sharing-helpful-knowledge-helped-me-grow-to-2-500-month-ad9b94660e">Weather App</a> - $2.5k MRR</li><li><a href="https://beebs.io/">Beebs</a> - <a href="https://www.indiehackers.com/interview/from-no-coding-skills-to-50k-downloads-in-two-years-eca7ea8587">$5K MRR</a></li><li>Nighteye, nightmode - <a href="https://www.indiehackers.com/product/night-eye">$2.3k MRR</a></li></ul><p><em>Paid-Only</em><br>Yes, this works well if your product is good enough for the switch.<br>Might be fairly difficult to encourage users to pay for the simple RSS extension you created.</p><p><em>Paywall or not to Paywall</em><br>Paywalling your current userbase guarantees the maximum number of conversions in that time period, everything else is bad news. Chrome extensions have review mechanisms that mean youâ€™ll paywall your userbase &amp; they turn to the review board for revenge. <a href="https://chrome.google.com/webstore/detail/media-hint/akipcefbjlmpbcejgdaopmmidpnjlhnb" rel="noopener nofollow">See here</a>.</p><p>I decided to paywall all the new users but keep the old users free. This way I had 50,000 people who loved &amp; would recommend the extension and a steady stream of newcomers who some (5%) of them would pay a monthly subscription for it.</p><p><strong>The best way to start paywalling is to use <a href="https://monetise.so/">Monetise.so</a>, they are a direct replacement of the Chrome Web Store.</strong></p><p>This could be a possibility for you, I know of a few examples this works well:</p><p><a href="https://chrome.google.com/webstore/detail/tab-for-a-cause/gibkoahgjfhphbmeiphbcnhehbfdlcgo?hl=en" rel="noopener nofollow">Tab for a Cause</a><br>They have a new tab page with an advert on it, they donate roughly ~30% of their Gross Revenue to charities.</p><p>Total Q1 2019 Revenue: <strong>$139,395.93.</strong><br>$0.25 per user per month, not bad at all.</p><p>They have, what you probably donâ€™t is a lot of coverage being at the new tab page of every single user.</p><p><a href="http://ecosia.org/" rel="noopener nofollow"><strong>Ecosi</strong></a>a is the tree planting search engine, uses its advert revenue into planting trees across the planet. Itâ€™s difficult to quantify as they have many platforms.<br>However, diverting your user-base to a search engine is quite a profitable business, the difficulty is getting them there in the first place.</p><p>Unsure on the user numbers, but they made â‚¬2.5M in the last reported month with 10 million users. &nbsp;</p><p><a href="https://chrome.google.com/webstore/detail/norton-safe-search/gkjahlcnbjiangkneanonnndppicobbd?hl=en" rel="noopener nofollow"><strong>Norton Safe Search</strong></a> is an example of a company forcefully changing your search engine for monetary gain, there is absolutely zero benefit to an anti-virus search engine, none.</p><p>You have to be a position where changing search or implementing adverts seems legitimate. Google will quickly remove your extension if you do that.</p><p>Thee value of switching user for these Bing-copycat search engines is about â‚¬0.80 per weekly user for a tier 1 geo; really not bad going.</p><p><a href="https://chrome.google.com/webstore/detail/panda-5-your-favorite-web/haafibkemckmbknhfkiiniobjpgkebko?hl=de&amp;" rel="noopener nofollow"><strong>Panda</strong></a> offer chrome extension, 60K weekly users that probably wittles down to 10k MAU. Squarespace reportedly pay $4k a month for a spot.</p><p>Donâ€™t do this.<br>Like <a href="https://9to5google.com/2019/12/17/chrome-avast-extensions-removed/" rel="noopener nofollow">Avast have done</a>, they collected clickstream data to feed their other suspicously data rich company, <a href="https://www.jumpshot.com/" rel="noopener nofollow">Jumpshot</a>.<br>Like <a href="https://www.businessinsider.com/evidon-sells-ghostery-data-to-advertisers-2013-6?r=DE&amp;IR=T" rel="noopener nofollow">Ghostery</a> have done.</p><p>Both Firefox &amp; Chrome will kick you out even at a whiff of this.<br>Good money, undoubtedly but I have no numbers.<br>I was recently told of a 6 digit figure for access to search data with Jumpshot.</p><p>Hola Unblocker allow for users to access geo-blocked content, but at a cost.<br>Your computer becomes a part of the appropriately named, <a href="https://luminati.io/" rel="noopener nofollow">Luminati</a> network.<br>They then sell your connection to the highest bidder and all sorts can run through the computer. It makes unblocking a doddle. With access to apparently 40M residential IPs, itâ€™s pretty massive and <a href="https://luminati.io/static/IPPN-analysis-2019.pdf?md5=3109015-85e418b7" rel="noopener nofollow">making $40M a year.</a></p><p>If you don't understand residential proxies, here's a<a href="https://proxyscraper.io/what-is-a-residential-proxy/"> little guide.</a></p><p>Lastly, donations. I only really have non-quantitative information on donations for Chrome Extensions.</p><p>They donâ€™t work as well as they should, you might gather bits &amp; pieces of cash here and there but itâ€™s the lowest form of per user donation, you are not wikipedia or the Guardian, remember that.</p><p>If youâ€™ve gathered enough mass and provide a valuable time/money/effort savings product, then Iâ€™d opt for the Premium tier.<br>If you can place adverts or have an opportunity to, try that out.<br>Ultimately, get to know your users and get a feel for what fits well.</p><p>Anything untoward is unsustainable.<br>Good luck.</p>
    </section></div>]]>
            </description>
            <link>https://tillypay.com/blog/how-to-monetise-a-chrome-extension/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26305789</guid>
            <pubDate>Mon, 01 Mar 2021 18:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The small web is beautiful]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26305585">thread link</a>) | @benhoyt
<br/>
March 1, 2021 | https://benhoyt.com/writings/the-small-web-is-beautiful/ | <a href="https://web.archive.org/web/*/https://benhoyt.com/writings/the-small-web-is-beautiful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">



<div id="content">

<p>March 2021</p>

<blockquote>
  <p>Summary: I believe that small websites are compelling aesthetically, but are also important to help us resist selling our souls to large tech companies. In this essay I present a vision for the â€œsmall webâ€ as well as the small software and architectures that power it. Also, a bonus rant about microservices.</p>

  <p><strong>Go to:</strong> <a href="#small-software">Software</a> | <a href="#small-websites">Web</a> | <a href="#emphasize-server-side-not-javascript">Server-side</a> | <a href="#static-sites-and-site-generators">Static sites</a> | <a href="#fewer-dependencies">Dependencies</a> | <a href="#small-analytics">Analytics</a> | <a href="#small-architectures-not-microservices">Microservices</a></p>
</blockquote>

<p>About fifteen years ago, I read E. F. Schumacherâ€™s <em>Small is Beautiful</em> and, despite not being interested in economics, I was moved by its message. Perhaps even more, I loved the terse poetry of the bookâ€™s title â€“ it resonated with my frugal upbringing and my own aesthetic.</p>

<p>I think itâ€™s time for a version of that book about technology, with a chapter on web development: <em>The Small Web is Beautiful: A Study of Web Development as if People Mattered.</em> Until someone writes that, this essay will have to do.</p>

<p>There are two aspects of this: first, <strong>small teams and companies</strong>. Iâ€™m not going to talk much about that here, but <a href="https://basecamp.com/books">Basecamp</a> and many others have. What Iâ€™m going to focus on in this essay is <strong>small websites and architectures</strong>.</p>

<p>Iâ€™m not the first to talk about the â€œsmall webâ€, but, somewhat surprisingly, only a few people have discussed it using that term. Here are the main web pages I can find that do:</p>

<ul>
  <li><a href="https://neustadt.fr/essays/the-small-web/">Rediscovering the Small Web</a> by Parimal Satyal: a fabulous article about the joy of small, independent (and sometimes retro) websites in contrast to the â€œcommercial webâ€.</li>
  <li><a href="https://ar.al/2020/08/07/what-is-the-small-web/">What is the Small Web?</a>, by Aral Balkan of the Small Technology Foundation: more of a manifesto against the surveillance of Big Tech than something concrete, but still interesting.</li>
</ul>

<p>Why aim small in this era of fast computers with plenty of RAM? A number of reasons, but the ones that are most important to me are:</p>

<ul>
  <li>Fewer moving parts. Itâ€™s easier to create more robust systems and to fix things when they do go wrong.</li>
  <li>Small software is faster. Fewer bits to download and clog your computerâ€™s memory.</li>
  <li>Reduced power consumption. This is important on a â€œsave the planetâ€ scale, but also on the very local scale of increasing the battery life of your phone and laptop.</li>
  <li>The light, frugal aesthetic. Thatâ€™s personal, I know, but as youâ€™ll see, Iâ€™m not alone.</li>
</ul>

<p>So letâ€™s dive in. I want to cover a bunch of different angles, each with its own subheading.</p>

<h2 id="small-software">Small software</h2>

<p>If weâ€™re going to talk about a small web, we need to start with small <em>software</em>.</p>

<p>As a teen, I learned to program using x86 assembly and <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a> â€“ perhaps odd choices, but my dad was heavily into Forth, and I loved how the language was so simple I could write <a href="https://github.com/benhoyt/third">my own bootstrapped compiler</a>.</p>

<p>In terms of career, I started as an embedded programmer â€“ not as in â€œembedded Linuxâ€ but as in microcontrollers where 16KB of RAM was generous. My current laptop has 16GB of RAM, and thatâ€™s not a lot by todayâ€™s standards. We were building IP-networked products with <em>one millionth</em> the amount of RAM. Those kinds of micros are as cheap as chips (ahem), and still widely used for small electronic devices, sensors, internet-of-things products, and so on.</p>

<p>You have to think about every byte, compile with size optimizations enabled, and reuse buffers. Itâ€™s a very different thing from modern web development, where a JavaScript app compiles â€œdownâ€ to a 1MB bundle, or a single Python object header is 16 bytes before youâ€™ve even got any data, or a Go hello-world binary is 2MB even before youâ€™ve added any real code.</p>

<p>How do you create small programs? I think the main thing is that you have to <em>care about size</em>, and most of us donâ€™t think we have time for that. Apart from embedded development, thereâ€™s an entire programming subculture called the <a href="https://en.wikipedia.org/wiki/Demoscene">demoscene</a> that cares about this. They have competitions for the smallest 4KB demos: who can pack the most graphical punch into 4096 bytes of executable. Thatâ€™s smaller than many favicons! (<a href="https://www.youtube.com/watch?v=jB0vBmiTr6o">Elevated</a> and <a href="https://www.youtube.com/watch?v=RCh3Q08HMfs">cdak</a> are two of the highest-rated 4K demos.) Many demosceners go on to become game developers.</p>

<p>Itâ€™s not just about executable size â€¦ when youâ€™re developing your next command line tool, if you use Go or Rust or even C, your program will be much faster, smaller, and use less memory than a Python or Java equivalent. And easier to install. If you donâ€™t understand why, please do learn. (Itâ€™s out of scope for this essay, but to summarize: Go, Rust, and C compile to ready-to-execute machine code, donâ€™t carry around a virtual machine, and donâ€™t have memory overhead for objects like integers.)</p>

<p>But why not apply some of the same principles to web development? In the web world, I think the main trick is to be careful what dependencies you include, and also what dependencies <em>they</em> pull in. In short, know <code>node_modules</code> â€“ or maybe better, <em>no</em> <code>node_modules</code>. More about this <a href="#fewer-dependencies">below</a>.</p>

<p>Niklaus Wirth of Pascal fame wrote a famous paper in 1995 called <a href="https://cr.yp.to/bib/1995/wirth.pdf">A Plea for Lean Software [PDF]</a>. His take is that â€œa primary cause for the complexity is that software vendors uncritically adopt almost any feature that users wantâ€, and â€œwhen a systemâ€™s power is measured by the number of its features, quantity becomes more important than qualityâ€. He goes on to describe Oberon, a computer language (which reminds me of Go in several ways) and an operating system that he believes helps solve the complexity problem. Definitely wirth a read!</p>

<p>Iâ€™ve been mulling over this for a number of years â€“ back in 2008 I wrote a sarcastic dig at how bloated Adobe Reader had become: <a href="https://blog.brush.co.nz/2008/07/adobe-reader-9/">Thank you, Adobe Reader 9!</a> It was a 33MB download and required 220MB of hard drive space even in 2008 (itâ€™s now a 150MB download, and I donâ€™t know how much hard drive space it requires, because I donâ€™t install it these days).</p>

<p>But instead of just complaining, how do we actually solve this problem? Concretely, I think we need to start doing the following:</p>

<ul>
  <li>Care about size: this sounds obvious, but things only change when people think theyâ€™re important.</li>
  <li>Measure: both your executableâ€™s size, and your programâ€™s memory usage. You may want to measure over time, and make it a blocking issue if the measurements grow more than <em>x</em>% in a release. Or you could hold a memory-reduction sprint every so often.</li>
  <li>Language: choose a backend language that has a chance, for example Rust, C or C++, or for servers, Go. These languages arenâ€™t right for everything (like data transformation scripts), but they produce small executables, and theyâ€™re good for CLIs and desktop apps.</li>
  <li>Remove: cut down your feature set. Aim for a small number of high-quality features. My car canâ€™t fly or float, and thatâ€™s okay â€“ it drives well.</li>
  <li>Say no to new features: unless they really fit your philosophy, or add more than they cost over the lifetime of your project.</li>
  <li>Dependencies: understand the size and complexity of each dependency you pull in. Use only built-in libraries if you can.</li>
</ul>

<h2 id="small-websites">Small websites</h2>

<p>Iâ€™m glad thereâ€™s a growing number of people interested in small websites.</p>

<p>A few months ago there was a sequence of posts to Hacker News about various â€œclubsâ€ you could post your small website on: the <a href="https://1mb.club/">1MB Club</a> (<a href="https://news.ycombinator.com/item?id=25151773">comments</a>), <a href="https://512kb.club/">512KB Club</a> (<a href="https://news.ycombinator.com/item?id=25450451">comments</a>), <a href="https://250kb.club/">250KB Club</a> (<a href="https://news.ycombinator.com/item?id=25176663">comments</a>), and even the <a href="https://10kbclub.com/">10KB Club</a> (<a href="https://news.ycombinator.com/item?id=25556860">comments</a>). I think those are a fun indicator of renewed interested in minimalism, but I will say that raw size isnâ€™t enough â€“ a 2KB site with no real content isnâ€™t much good, and a page with 512KB of very slow JavaScript is worse than a snappy site with 4MB of well-chosen images.</p>

<p>Some of my favourite small websites are:</p>

<p><a href="https://news.ycombinator.com/news">Hacker News</a>: I personally like the minimalist, almost brutalist design, but I love its lightness even more. I just downloaded the home page, and loading all resources transfers only 21KB (61KB uncompressed). Even pages with huge comment threads only transfer about 100KB of compressed data, and load quickly. Reddit has become such a bloated mess in comparison. Hacker News, never change!</p>

<p><a href="https://lobste.rs/">Lobsters</a>: a similar news-and-voting site, with slightly more â€œmodernâ€ styling. It uses some JavaScript and profile icons, but itâ€™s still clean and fast, and the total transfer size for the homepage is only 102KB. You just donâ€™t need megabytes to make a good website.</p>

<p><a href="https://sourcehut.org/">Sourcehut</a>: I like the concept behind Drew DeVaultâ€™s business, but I love how small and anti-fluff the website is. He has set up a mini-site called the <a href="https://forgeperf.org/">Software Forge Performance Index</a> that tracks size and browser performance of the prominent source code websites â€“ Sourcehut is far and away the lightest and fastest. Even his homepage is only 81KB, including several screenshot thumbnails.</p>

<p><a href="https://sqlite.org/">SQLite</a>: not only is SQLite a small, powerful SQL database engine, the website is fantastically small and content-rich. Even their 7000-word <a href="https://sqlite.org/testing.html">page about testing</a> is only 70KB. How do they do this? Itâ€™s not magic: focus on high-quality textual content, minimal CSS, no JavaScript, and very few images (a small logo and some SVGs).</p>

<p><a href="https://lwn.net/">LWN</a>: Iâ€™m a little biased, because Iâ€™ve written <a href="https://lwn.net/Archives/GuestIndex/#Hoyt_Ben">articles</a> for them, but theyâ€™re an excellent website for Linux and programming news. Extremely high-quality technical content (and a high bar for authors). Theyâ€™re definitely niche, and have a â€œwe focus on quality content, not updating our CSS every yearâ€ kind of look â€“ theyâ€™ve been putting out great content for 23 years! Their homepage only downloads 44KB (90KB uncompressed).</p>

<p><a href="https://danluu.com/">Dan Luuâ€™s blog</a>: this is one of the more hardcore examples. His inline CSS is only about 200 bytes (the pages are basically unstyled), and his HTML source code doesnâ€™t use any linefeed characters. Kind of a fun point, although then he goes on to load 20KB of Google Analytics JavaScriptâ€¦</p>

<p>As a friend pointed out, those websites have something of an â€œanti-aesthetic aestheticâ€. I confess to not minding that at all, but on the other hand, small doesnâ€™t have to mean ugly. More and more personal blogs and websites have adopted a small web approach but are more typographically appealing:</p>

<ul>
  <li><a href="https://lucumr.pocoo.org/">Armin Ronacherâ€™s Thoughts and Writings</a></li>
  <li><a href="https://nullprogram.com/">Chris Wellonsâ€™ â€œNull programâ€ blog</a></li>
  <li><a href="http://eradman.com/">Eric Radmanâ€™s BSD and SQL blog</a></li>
  <li><a href="https://hugotunius.se/">Hugo Tuniusâ€™ programming blog</a></li>
  <li><a href="https://prog21.dadgum.com/">James Hagueâ€™s â€œProgramming in the â€¦</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benhoyt.com/writings/the-small-web-is-beautiful/">https://benhoyt.com/writings/the-small-web-is-beautiful/</a></em></p>]]>
            </description>
            <link>https://benhoyt.com/writings/the-small-web-is-beautiful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26305585</guid>
            <pubDate>Mon, 01 Mar 2021 17:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presenting the first condensed database]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26304202">thread link</a>) | @Malexik
<br/>
March 1, 2021 | https://condensationdb.com/white-paper/ | <a href="https://web.archive.org/web/*/https://condensationdb.com/white-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

          <div>
            <div>
              
              <p>Inspired by the blockchain system, the email system, and git versioning, Condensation is a unique solution to develop scalable and modern applications while providing the features to protect digital rights. Having a system that doesn't need to trust the Cloud enables to ensure the security and the ownership of data.</p>
            </div>

            <figure>
              <video poster="https://condensationdb.com/assets/img/overview-video-poster.png" autoplay="autoplay">
                  <source src="https://condensationdb.com/assets/img/overview-video.mp4" type="video/mp4">
              </video>
              <figcaption>Condensation extends the Cloud with distributed storage servers</figcaption>
            </figure>

          </div>
          
        </section><section>
        <div>
          <div>
            <div>
              <article>
                <h2>The emergence of condensed systems</h2>

                <p>
                While being entirely distributed, Condensation can store and retrieve data like a database or a file system, send data to other users or devices like a messaging system, and share and synchronize data like cloud services. Thereby, Condensation follows a distributed actor-message-passing approach and encrypts all data end-to-end.
                </p>

                <p>
                Condensation builds the bridge between the simplicity of immutable data and the easiness of implementation of mutable documents. On the client, documents are split efficiently into smaller immutable units that can be transferred freely across the network. Then, they can be condensed back when they arrive on the receiver's device. Condensed systems are free from trusting a third-party server and many new features come by design to create trust between clients such as data certification.
                </p>

                <p>
                This shift from merging data on the server to doing it on the client side, opens many new possibilities for application design. Furthermore, it is significantly more efficient if compared to existing solutions which need to build several application layers on top of existing systems to achieve the same functionalities. Before to start explaining the mechanics, this section explains the history of databases and what makes Condensation the next step in the evolution of databases.
                </p>

                <h3>Bridging the gap between mutable and immutable data structures</h3>
                    <p>
                    The structure of today's file and database systems dates back to the 1970s, when storage space was extremely scarce and computers were few. These systems were designed to run on a single machine, and mostly on a single disk.
                    </p>
                    <p>
                    While both databases and file systems have greatly evolved over time, their main structure has hardly changed. Database systems are based on tables with mutable records (rows), while file systems use a hierarchy of folders with mutable files inside. In both systems, data can be modified with little effort, and at any time. It also has the advantage of being very efficient with regards to storage space needs. Data synchronization, however, is notoriously difficult and error prone.
                    </p>
                    <p>
                    In todays' connected world, data is used on different devices, or is shared with other people. And, for most applications, storage space is not a limiting factor any more. Hence, efficient data synchronization is key.
                    </p>

                    <figure>

                      <img src="https://condensationdb.com/assets/img/historic-evolution.png" alt="Image">

                      <figcaption>A historical evolution of data systems</figcaption>
                    </figure>

                    <p>
                    Aside of file and database systems, revision control systems have been developed and used since the 1980s. Some of them, such as git or hq, are fully distributed and do not require any central server whatsoever. Each user has their own version of the data and can merge changes from other users. Such systems allow for efficient and provably correct data synchronization.
                    </p>
                    <p>
                    While they are great for source code management, current version control systems are not suited as general purpose data systems. In order to benefit from such systems, the user needs to have a certain understanding of branches, merging, and conflict resolution, which is far beyond the knowledge of an average computer user. In addition, occasional merge conflicts are inevitable, and prevent such systems from being used in a transparent way.
                    </p>
                    <p>
                    Condensation has been designed from the ground up to address this. The result is a general-purpose data system with lightweight transactions and efficient data synchronization in a completely distributed setting. Merge conflicts are impossible by design, hence no user intervention is required during the synchronization process. The data itself is end-to-end encrypted and may be spread across multiple storage systems.
                    </p>

                    <h3>The evolution of architectures from online to offline and serverless systems.</h3>

                    <p>
                    The structure of the data has a direct influence on the dependency from and the role of a server. With SQL and noSQL databases, the centralized server is needed to synchronize data. Accordingly, it is the place where the application logic occurs. As a result, the system only works when being online. Also, as the data is read and processes by the server, it is vulnerable to data breaches.
                    </p>
                    <p>
                    Working offline became possible later, by storing documents in the application and defining schemas for synchronization when the application is turned back to online mode. However, this process is complex and requires a handling logic on both the client and the server side. Moreover, scaling a central database was a major issue. Many systems developed distributed systems for horizontal scaling but in a controlled data center setup where all servers are entrusted and available.
                    </p>
                    <p>
                    As described previously, Condensation only transfer immutable data on the network, which allows to build fully distributed but yet very simple systems. The following scheme summarizes the comparison between existing systems types.
                    </p>

                    <figure>
                        <img src="https://condensationdb.com/assets/img/cn-architectures.png" alt="Architectures">
                        <figcaption>Condensation shifts intelligence to the client-side and makes servers a simple encrypted storageâ€‹</figcaption>
                    </figure>

                    <figure>

                                <table id="table1">
                                  <thead>
                                    <tr>
                                      <th scope="col-3"></th>
                                      <th scope="col-3">
                                        <b>Online-only</b><br>
                                        2000-2015
                                      </th>
                                      <th scope="col-3">
                                        <b>Offline-first</b><br>
                                        2015-2020
                                      </th>
                                      <th scope="col-3">
                                        <b>Condensated</b><br>
                                        2021
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <th scope="row">
                                        <span>Code base</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Small
                                      </td>
                                      <td>
                                          Large
                                      </td>
                                      <td>
                                          Small
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Architecture</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Simple architecture, easy to understand
                                      </td>
                                      <td>
                                          Relatively complex architecture
                                      </td>
                                      <td>
                                          Simple architecture but requires "distributed mindset"
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Structure</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Centralized with full trust in cloud
                                      </td>
                                      <td>
                                          Centralized with full trust in cloud
                                      </td>
                                      <td>
                                          Distributed/Federated
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Synchronization</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          No synchronization necessary
                                      </td>
                                      <td>
                                          Correct data synchronization (two-way) is hard. Potentially different database schemas on client and server.
                                      </td>
                                      <td>
                                          Based on synchronization<br>
                                          Direct device-to-device sync possible
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Security</span>
                                        <span></span>
                                      </th>
                                      <td>
                                        Transport encryption only
                                      </td>
                                      <td>
                                        Transport encryption and SPOF engineered mitigation
                                      </td>
                                      <td>
                                        End-to-end encryption
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Authentication</span>
                                        <span></span>
                                      </th>
                                      <td>
                                        Login required
                                      </td>
                                      <td>
                                        Login required
                                      </td>
                                      <td>
                                        Login not necessary (but sometimes desired)
                                      </td>
                                    </tr>

                                  </tbody>
                                </table>
                    </figure>

                <p>
                Condensation leverage the advantages of immutable objects. You never have to lock them, which extremely improves concurrency also it improves simplicity as persistance to certify the data isn't compromised and exactly the same as the source. Furthermore, it allows to reduce the memory usage as objects can be reused to create new trees.
                </p>
                <p>
                Developers can benefit from features available by design such as: data certification with user signature, versionning with transaction history, and conflict free merge based on CRDTs.
                </p>
                <p>
                So, Condensation has a hybrid data structure, it merge data into mutable documents stored locally and transfers immutable objects through stores. The stores can be managed in a single server or in a purely distributed manner without introducing complexities.
                </p>
                <p>
                In the following sections, first the data structure is technically described to explain how Condensation transform a document into an immutable merkle tree. Next, to better understand how Condensation manage securely data on the network, the flow of the data through a â€¦</p></article></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://condensationdb.com/white-paper/">https://condensationdb.com/white-paper/</a></em></p>]]>
            </description>
            <link>https://condensationdb.com/white-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304202</guid>
            <pubDate>Mon, 01 Mar 2021 16:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A case for funding Open Source Software]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26303592">thread link</a>) | @jackyzhao
<br/>
March 1, 2021 | https://blog.jzhao.xyz/posts/paid-open-source/ | <a href="https://web.archive.org/web/*/https://blog.jzhao.xyz/posts/paid-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainText"><h2 id="making-of-open-source-software">Making of Open Source software</h2><p>Iâ€™ve recently made my way through <em>Working in Public: The Making and Maintenance of Open Source Software</em> by Nadia Eghbal. Not only does it have some absolutely stunning cover art, it also touches on some thoughts that have been marinating in my head about the intersection of open source and funding. So much so, that Iâ€™ve started experiencing the Baader-Meinhof effect, seeing something to do with open source and funding everywhere I look in tweets, conversations, and blogs.</p><p>This blog post is an exploration of processes in open source, the value it provides, and how money fits into the picture.</p><p><img src="https://blog.jzhao.xyz/img/oss_book.jpg" alt="Working in Public: The Making and Maintenance of Open Source Software"><em>Working in Public: The Making and Maintenance of Open Source Software</em></p><h3 id="how-its-made">How itâ€™s made</h3><blockquote><p>â€œOpen source developers were frequently characterized as â€˜hobbyâ€™ developers, because the assumption was that only companies could make â€˜realâ€™ software."<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p></blockquote><p>As it stands, there are two primary schools of thought about how open source software is created.</p><ol><li><p><strong>Firm-based</strong> production involves companies, organizations, governments, or any institution with centralized resources. Their driving thesis is that only companies make software because, from a coordination standpoint, centralized firms are the most efficient way to manage resources. Most development done this way is motivated extrinsically by means of monetary compensation.</p></li><li><p><strong>Commons-based</strong> production is a more vague concept that involves a distributed group of developers that work on a resource that is used, owned, and governed by its own community - free of employer affiliations. Most development done this way is motivated intrinsically, people do work because they want to do it.</p></li></ol><p>Traditionally, software has been seen as a product of firms. Open source developers were often treated as hobbyists and the projects they made trivialized as toys. The assumption was that only companies could make â€˜realâ€™ software. However, the rise of Internet computing and collaboration tools like Git have decreased the barrier to entry enough that producing software through a commons is now feasible and very much alive. The success of projects like Apache, Linux, and FreeBSD proved just how successful a commons-based method of production could be.</p><p>Surprisingly, this may also help to explain why some developers view open source and money as completely separate. If the commons-based method of production is rooted in intrinsic motivation, then money, an extrinsic motivator, will be seen as opposite to core ideals that open source stands for.</p><h2 id="creation-vs-maintenance">Creation vs Maintenance</h2><blockquote><p>â€œCreation is an intrinsic motivator, maintenance usually requires extrinsic motivationâ€</p><p>@balupton, isaacs/github <a href="https://github.com/isaacs/github/issues/167">#167</a></p></blockquote><p>When an artist finishes a painting, or a runner finishes a marathon, that usually signifies the end of said responsibility. There is no such finish line for an open source project, even after pushing out an initial product.</p><p>Creating a project is fun. Itâ€™s a wild exploration into a new idea, a frivolous journey to create something useful or to learn something new. As cloud platforms continue to eat the world, the costs of distributing and sharing a project are almost completely nullified.</p><p>Just a few clicks and a few taps of your keyboard and your project is readily available to any of the 4.66 billion people around the world with internet access. This adrenaline rush of finally releasing the labour of your work onto the world is the moment developers are constantly chasing. For most developers, the process of creation and distribution is intrinsically motivated; itâ€™s an enjoyable process.</p><p>Maintenance is less so. This is akin to a writer thatâ€™s been asked to edit and revise the same book day in and day out, long after theyâ€™ve reaped the initial financial and reputational rewards from its creation. Even when the creator wants to leave the project to work on something else, they canâ€™t. Theyâ€™re tightly shackled by the fact that hundreds of thousands of other organizations, companies, and tools rely on their code to keep their operations running. Bringing on additional developers may not help either, as they still require onboarding, code reviews, and general guidance.</p><p>Code may be nearly free to create and distribute, but maintenance is still expensive.</p><h2 id="types-of-code">Types of code</h2><h3 id="code-as-an-artifact">Code as an artifact</h3><p>There are two main ways we can look at code. The first of which is <em>static</em> code. Code that, on its own, does nothing but exists as an archive. Others can copy and download the code without incurring any additional costs to the author. For the maintainers, it should make no difference in regards to cost whether 10 or 10,000 people use it.</p><p>This type of code is a pool resource, it is</p><ol><li><strong>Non-rivalry.</strong> My ability to copy the code doesnâ€™t affect your ability to copy it. (This isnâ€™t exactly true due to some marginal costs but Iâ€™ll discuss this later)</li><li><strong>Non-excludable.</strong> If someone has a copy of the code, it is very difficult to prevent them from sharing that code with others.</li></ol><p>Any code that is in this state is easy to share, copy, and distribute. This is the type of code that lives dormant on Github, on StackOverflow answers, and in GitHubâ€™s Arctic Vault<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. However, the main purpose of consuming code is not to simply read and study it, but to actually use it and to let it interact with other code.
In doing so, we bring it to life.</p><h3 id="code-as-an-organism">Code as an organism</h3><blockquote><p>â€œOpen source code derives its value not from its static qualities but from its living ones."<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p></blockquote><p>As soon as you hit CTRL-V on that snippet of code, as soon as that static code is inserted into your own, that code comes to life. It might surface ridiculous amounts of red squigglies, break other code, or force you to rewrite your previous code just to make it work. When code transitions from a resting static state to an active living state, it starts to incur a set of hidden costs.</p><p>Like a living organism in a symbiotic relationship, there is a mutual interdependence between it and others in the software â€˜ecosystemâ€™ in order to survive. As a result, this ecosystem requires constant upkeep to ensure that components donâ€™t fall out of balance: dependency bumps, documentation updates, and infrastructure changes.</p><h2 id="free-as-in-speech-not-as-in-beer">Free as in speech, not as in beer</h2><p>â€˜Freeâ€™ software doesnâ€™t refer to its price. In fact, â€˜freeâ€™ software is often extremely expensive. As Richard Stallman first described free software, itâ€™s â€œfree as in speech, not free as in beer.â€ The point Stallman was trying to make was that â€˜freeâ€™ refers to what one could do with the software, rather than the price tag.</p><h3 id="latent-cost-of-software">Latent cost of software</h3><p>In reality, code in its alive state is more like a free puppy. In the beginning, itâ€™s a great and wonderful thing! Super fun and super cute. As it grows and gets older, you realize â€œgeez, it actually takes a lot of my own time to take care of this thing.â€ Unlike a piece of inanimate furniture, bringing a living creature into oneâ€™s home comes with bringing in a new set of responsibilities too.</p><p><strong>Marginal costs</strong> are costs increase on a per-user basis. I mentioned earlier that these costs mean that software is actually rivalrous, meaning that at some point, the project wonâ€™t be able to support the n+1th user. Some of this cost comes from physical infrastructure like code hosting and infrastructure. However, the majority of the cost comes from user support. Say you have a billion users and only 0.1% of them require support. If it takes you roughly 10 minutes to resolve each issue, you would still need 20,833 people working 8-hour shifts a day just to be able to keep up with the support volume. Maintainers are constantly wrestling with keeping their issue volume low and questions answered. Eventually, it just becomes a hindrance preventing them from working on the core product.</p><p><strong>Temporal costs</strong> are those which build up and compound over time. Most of it comes from technical debt, choices that are easier today at the expense of time and money in the future. This is the eternal battle against entropy: the inevitable decay of systems over time. When code changes, all the supporting knowledge that surrounds it must be updated too. Documentation, tutorials, programming books, videos, and more slowly become obsolete.</p><p>Paying off these latent costs is seldom intrinsically motivated. When people talk about how fun making new projects is or contributing to open source, itâ€™s never referring to writing documentation or refactoring code. This isnâ€™t the â€˜funâ€™ part of writing software. This is the nasty upkeep that goes into maintaining a building from the 1850s thatâ€™s had new rooms, plumbing, and electric wiring frankenstein-ed into it over the years.</p><h2 id="funding-open-source">Funding Open Source</h2><p>I first started on BentoML<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> as a casual contributor last summer, submitting a few decently sized PRs. It was almost all intrinsically motivated; I found issues that I enjoyed working on and that I knew I would learn lots from. Satisfied with my experience, I decided to join the team as a paid contractor expecting to just continue the type of work I was doing in the summer. As issue after issue piled on, I slowly started to realize just how much extra work being a maintainer meant and why it was a paid position. Making proposals, triaging issues, adding tests, and writing documentation took up the majority of my time. While I recognized it was important work, it was not work I was intrinsically motivated to do. Thus, to motivate people like me to get that work done, an extrinsic motivator â€“ in this case, money â€“ needed to be applied.</p><p>How do we best incentivize maintainers to work tasks stripped of the very excitement and promise of creation that initially drew them to the project in the first place? There is a jarring disconnect between work that is needed versus work that is intrinsically motivated. This is where I believe open source funding should play a role. There are two main potential avenues to go about this.</p><h3 id="funding-projects">Funding projects</h3><p>One possibility is to fund projects directly. This route builds a brand around the project. The status of the project then transcends any single personâ€™s contributions and becomes a tangible entity â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jzhao.xyz/posts/paid-open-source/">https://blog.jzhao.xyz/posts/paid-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.jzhao.xyz/posts/paid-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303592</guid>
            <pubDate>Mon, 01 Mar 2021 15:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Simple decentralized web hosting on Peergos]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26303144">thread link</a>) | @ianopolous
<br/>
March 1, 2021 | https://peergos.org/posts/p2p-web-hosting | <a href="https://web.archive.org/web/*/https://peergos.org/posts/p2p-web-hosting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You already know that Peergos lets you store and share files securely and privately. Now, you can also host your own website on it!</p>
<p>We always thought getting a website up and running should be one of the easiest things to do on the web. There are plenty of options available for website hosting, but with Peergos there's no need to buy a domain name, arrange TLS certificates, or run a server to host the content. You also don't need any cryptocurrency to post or update your website, so you can get free instantaneous updates and peer-to-peer authenticated delivery. You can sign up to <a href="https://beta.peergos.net/?signup=true">our beta</a> today and get started right away in just two easy steps:</p>
<ol>
<li>
Upload your website files to a directory in Peergos.
</li>
<li>
Go to your profile, set that directory as your website and click publish.
</li>
</ol>

<p>Your personal website will now be available at <tt>https://&lt;your-user-name&gt;.peergos.me</tt>. It doesn't get any simpler than that. Let's see this in action!</p>
<center>
<img alt="www" id="id" src="https://peergos.org/theme/img/blog/p2p-webhosting.gif" width="90%">
<br>
Host your decentralized website directly from Peergos.
</center>
<p>Any changes made to your website files are automatically and instantly reflected in your website. When we say instantaneous, we mean it. Check it out below!</p>
<center>
<img alt="www-update" id="id" src="https://peergos.org/theme/img/blog/p2p-web-update.gif" width="90%">
<br>
Instantaneous and free updates to your decentralized website.
</center>
<p>When you publish a website from Peergos, you can view it through any Peergos gateway. We're running one at <tt>peergos.me</tt>, so your website will be available at <tt>https://&lt;your-user-name&gt;.peergos.me</tt>, and viewable in any browser today. Bear in mind that viewing through a public gateway like that still relies on DNS and the TLS certificate authorities, which are both single points of failure that are vulnerable to attack. However, we can actually get around both of these by viewing someone's site through a local Peergos gateway. To visit someone's site in this way, you just run a local Peergos instance and browse to <tt>http://&lt;username&gt;.peergos.localhost:9000</tt>. The gateway looks up the public key of the username provided in the localhost subdomain via the Peergos PKI, then retrieves the website and serves it. All this is done without relying on DNS or TLS certificates anywhere. We are thus able to use localhost subdomains to achieve isolation and security between different sites served from one local gateway. </p>
<p>Websites hosted on Peergos benefit from our resilient and reliable decentralized architecture. Most of the heavy lifting is done by <a href="https://ipfs.io/">IPFS</a> through content addressing and public key based routing. With our architecture, we add fast mutable pointers and human-readable names. Therefore, you can trust that the content of your website will be readily available without having to rely on a single-point-of-failure-server anywhere. </p>
<p>In the future, we will enable viewing such websites directly inside the Peergos web interface. At that point, Peergos will really start to look like a new web.</p>
<p>There are still a few free accounts available on <a href="https://beta.peergos.net/?signup=true">our beta</a>. Let us know what you think. We're always looking for feedback, so either <a href="mailto://peergos@peergos.org">drop us a line</a> or come say hi in our <a href="https://app.element.io/#/room/#peergos-chat:matrix.org">Matrix chatroom</a>.</p>
<p>Stay tuned for introductions to a few other new features and apps we're building as part of our <a href="https://peergos.org/posts/next-generation-internet">grant</a> from the Next Generation Internet program (<a href="https://pointer.ngi.eu/">NGI POINTER</a>).</p>

<hr>
<center>
<img alt="NGI Pointer" height="65px" id="id" src="https://peergos.org/theme/img/ngi-logo.png">
<img alt="NGI Pointer" height="65" id="id" src="https://peergos.org/theme/img/eu.png">
</center>
<p>
This project has received funding from the European Unionâ€™s Horizon 2020 research and innovation programme within the framework of the NGI-POINTER Project funded under grant agreement No 871528</p>

<h4>RECENT POSTS</h4>
    </div></div>]]>
            </description>
            <link>https://peergos.org/posts/p2p-web-hosting</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303144</guid>
            <pubDate>Mon, 01 Mar 2021 14:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MKBHD TLDR: Summarizing YouTube Video Reviews with AI]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26302959">thread link</a>) | @tlochhead
<br/>
March 1, 2021 | https://tavis.cc/mkbhd-tldr/ | <a href="https://web.archive.org/web/*/https://tavis.cc/mkbhd-tldr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>YouTube is the fastest-growing platform for all sorts of content. Video reviews being one of them. I love the quality that goes into these reviews.</p>
<p>But what if there was a way to quickly grab consensus of these videos without spending hours watching them all?</p>
<p>TLDR: Yes. With AI.</p>
<p>See the results ðŸ‘‰&nbsp;<a href="https://twitter.com/MKBHDtldr" target="_blank" rel="nofollow noreferrer noopener">twitter.com/MKBHDtldr</a></p>
<p>
  <span>
    <span>
      <img alt="tw1" title="tw1" src="https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/07484/tw1.png" srcset="https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/d76be/tw1.png 135w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/01bf6/tw1.png 270w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/07484/tw1.png 540w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/d7542/tw1.png 810w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/302a4/tw1.png 1080w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/51800/tw1.png 1196w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<h2>Evolution of AI</h2>
<p>Alongside the rapid growth of YouTubeâ€™s popularity is AI innovation. One particular company that is gaining a lot of attention is Elon Musk-backed <a href="https://openai.com/" target="_blank" rel="nofollow noreferrer noopener">OpenAI</a>.</p>
<p>Last week, I was fortunate enough to join their private beta program. So very quickly, I decided to try something I have wanted to do with <a href="https://recorank.com/" target="_blank" rel="noopener">RecoRank</a> for some time: automated YouTube video review analysis using AI.</p>
<p>Iâ€™m a huge MKBHD fan. And as one of the top YouTube video reviewers, I tried using OpenAI to summarize his video review transcripts.</p>
<p><a href="https://twitter.com/MKBHDtldr" target="_blank" rel="nofollow noreferrer noopener">The results have been amazing so far.</a></p>
<p>
  <span>
    <span>
      <img alt="tw2" title="tw2" src="https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/07484/tw2.png" srcset="https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/d76be/tw2.png 135w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/01bf6/tw2.png 270w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/07484/tw2.png 540w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/d7542/tw2.png 810w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/302a4/tw2.png 1080w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/51800/tw2.png 1196w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<h2>Achieving These Results</h2>
<p><strong>Step 1: Extract Transcripts</strong></p>
<div data-language="text"><pre><code>from youtube_transcript_api import YouTubeTranscriptApi

subtitles = YouTubeTranscriptApi.get_transcript("dhAmMXCBIcg")

sub_list = []

for subtitle in subtitles:
    sub_list.append(subtitle['text'])

txt = " ".join(sub_list)

print(txt)</code></pre></div>
<p>This simple Python script using <a href="https://pypi.org/project/youtube-transcript-api/" target="_blank" rel="nofollow noreferrer noopener">YouTubeTranscriptApi</a> quickly gets you the transcript of any YouTube video - given that the video has a transcript. The API will produce an error if one does not exist.</p>
<p><strong>Step 2: Summarize with OpenAI</strong></p>
<p>
  <span>
    <span>
      <img alt="openai" title="openai" src="https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/07484/openai.png" srcset="https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d76be/openai.png 135w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/01bf6/openai.png 270w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/07484/openai.png 540w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d7542/openai.png 810w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/302a4/openai.png 1080w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d9ed5/openai.png 2880w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<p>I used OpenAIâ€™s <code>tl;dr:</code> (too long; didnâ€™t read) function to achieve AI-generated transcript summaries.</p>
<p>On top of the default settings, I also:</p>
<ul>
<li>Set temperature to <code>0</code> to exclude any improvisation of the results and get the summary with no guesswork</li>
<li>Added <code>The [product name]</code> right after <code>tl;dr:</code> to guide OpenAI on what I wanted (i.e. <code>The iPhone 12 is a great phone, but it's not a huge leap forward.</code> - I didnâ€™t do this for all summaries, but I did find that this method delivered the most consistent results than just using <code>tl;dr</code> on its own)</li>
<li>Deleted enough of the start of the transcript to fit within the 2048 token limit (in the case with most reviews, more of the meat is at the end than the beginning, particularly final thoughts)</li>
<li>Added a return break <code>âŽ</code> as a Stop Sequence to limit the results to one paragraph</li>
</ul>
<h2>Whatâ€™s Next?</h2>
<p>These are just the results of one week of experimentation with OpenAI. Pros and cons are other areas to explore.</p>
<p>These are the pros and cons results for MKBHDâ€™s Samsung Galaxy S21 review:</p>
<div data-language="text"><pre><code>Pros:
â€“ Great display
â€“ Great performance
â€“ Great cameras
â€“ Great battery life
â€“ Great design
â€“ Great value

Cons:
â€“ No expandable storage
â€“ No MST
â€“ No S Pen
â€“ No wireless charging</code></pre></div>
<p>Iâ€™m hoping to add these insights to <a href="https://recorank.com/" target="_blank" rel="noopener">RecoRank</a> soon.</p>
<p>My friend Adrian Krebs has a <a href="https://www.buyforlife.com/blog/548RijnkRdPwn1cAI5RDjw/make-better-and-faster-purchasing-decisions-with-ai" target="_blank" rel="noopener">blog post</a> about his trials in this area for his business, <a href="https://buyforlife.com/" target="_blank" rel="noopener">BuyForLife.com</a>. Definitely worth a read.</p>
<p>Have an idea of how OpenAI could be applied for review analysis and summarization? Iâ€™d love to hear from you. Hit me up on <a href="https://twitter.com/tavislochhead" target="_blank" rel="nofollow noreferrer noopener">Twitter</a> or send me an email @ tavislochhead [ at ] gmail [ dot ] com.</p></div><p><img src="https://tavis.cc/static/headshot-37e68c3c90409f03180397ce570be16e.jpeg" alt="profile pic"><strong><a href="https://tavis.cc/about">Tavis Lochhead</a></strong> <!-- -->is a seasoned marketer who loves tech and data. Tavis is the founder of<!-- --> <a href="https://recorank.com/" target=" _blank">RecoRank</a> <!-- -->and also consults as a marketer, programmer, and data analyst.</p></div>]]>
            </description>
            <link>https://tavis.cc/mkbhd-tldr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302959</guid>
            <pubDate>Mon, 01 Mar 2021 14:18:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving ADA a Chance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26302344">thread link</a>) | @jayp1418
<br/>
March 1, 2021 | https://ajxs.me/blog/Giving_Ada_a_chance.html | <a href="https://web.archive.org/web/*/https://ajxs.me/blog/Giving_Ada_a_chance.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<header>
				<a id="header-link" href="https://ajxs.me/">
					
				</a>
			</header>
			<section id="blog-entry">
	
	<div>
		<p><span>TL;DR:</span> Ada is an extremely interesting and robust programming language that has a lot to offer modern developers of system 
	and bare-metal software. At very least, Ada presents many interesting ideas that designers of modern programming languages could stand to learn much from. If you want a 30 second version of this article, check out the 
	<a href="#practical_example">practical example</a> that I provide for a comparison of Ada with C.</p>

<p>
	Much of the technical material presented in this article is available as part of <a href="https://wiki.osdev.org/User:Ajxs">my contributions</a> to <a href="https://wiki.osdev.org/Main_Page">osdev.org</a>
</p>
<p>
	I consider myself a rational man. While I may believe in an entirely deterministic model of the universe, I certainly
	do not believe it to be guided by any conscious process.
	I do not believe in destiny. This absence of guidance makes such fortuitous occurrences as the one I will discuss all
	the more extraordinary, and for this I am all the more grateful.
</p>

<h2>A Chance Collision</h2>
<p>
	By no deliberate design of my own, I happen to live close to a university. Not in the kind of â€˜University townâ€™ common
	to much of Europe or the United States, but in the densely packed suburban sprawl of the inner-city. My regular walk
	to and from the local shopping centre takes me past several of the buildings belonging to the highly regarded
	engineering faculty of the aforementioned University.
</p>
<p>
	Making my way home one serendipitous afternoon, I happened across a sizeable stack of books sitting on the curb
	outside one of the Universityâ€™s engineering buildings. The university was ostensibly in the process of liquidating its stockpile
	of old engineering books, and had left them in a pile for the local council to collect. Amongst material covering a
	wide variety of academic disciplines, two books in particular caught my eye: <i>Building Parallel, Embedded, and
	Real-Time Applications with Ada</i>, and <i>Concurrent and Real-Time Programming in Ada</i>.
</p>
<p>
	I had heard of Ada before. I understood that it came from a pedigree of languages developed for the United States
	military, and that it still occupied a niche in the development of safety-critical applications, nothing more.
	Curious, I threw the books in my bag and off I went.
</p>


<h2>Exceeding My Expectations</h2>
<p>Admittedly, I had pictured Adaâ€™s syntax resembling the uncompromising verbosity and rigid construction of COBOL, or
	perhaps the Lovecraftian hieroglyphics of Fortranâ€™s various eldritch incarnations. Turning the pages, I was pleasantly
	surprised by modern constructs associated with modern high-level languages such as ranges, slicing and
	exception-handling. The syntax â€” Admittedly verbose by modern standards<sup><a href="#footnote_3">3</a></sup> â€” seemed deliberately and purposefully
	constructed to make the language comprehensible at a glance.</p>
<p>The fact that Ada was designed with embedded-software in mind was of particular interest to me. I already had some
	limited experience with bare-metal development on the x86 and ARM platforms using C and assembly, so the prospect of
	using higher-level constructs on bare-metal seemed promising to me.</p>

<h2>Not the Camel You Expected</h2>
<p>A common pejorative refrain directed at Ada by its many detractors is that it is a language â€œdesigned by committeeâ€,
	or even worse, a language â€œdesigned by committee <i>for the military</i>â€<sup><a href="#footnote_1">1</a></sup>. The implication of which being that (so-called)
	design by committee precludes it from any real-world practicality. I contend that it is better to design a language to fit an
	existing problem domain than to pick your weapon of choice and set out in search of new problem domains to apply it
	to<sup><a href="#footnote_2">2</a></sup>. I will spare readers a detailed retelling of Adaâ€™s conception within the Department of Defenceâ€™s <a href="http://archive.adaic.com/pol-hist/history/holwg-93/holwg-93.htm">â€˜High Order
	Language Working Groupâ€™</a>, save to say that the Ada programming language was born of the need for single, unified
	higher-level language suitable for use in the multitude of Real-Time Embedded systems developed by the DoD<sup><a href="#footnote_4">4</a></sup>. In the
	wise words of the working-groupâ€™s chair, Colonel William A. Whitaker: â€œIt was concluded that no existing language
	could be adopted as a single common high order language for the DoD, but that a single language meeting essentially
	all the requirements was both feasible and desirable.â€. If such a thing was indeed feasible, the DoDâ€™s deep pockets
	would help it bring it into existence. Ironically, given its status as the de-facto standard language of modern embedded-system development, the C language was considered unsuitable for this purpose: â€œWhen Bell Labs were
	invited to evaluate C against the DoD requirements, they said that there was no chance of C meeting the requirements
	of readability, safety, etc.â€ (Whitaker, 1993). After its successful implementation, in what would prove a controversial decision, the DoD would go so far as to mandate 
	the use of Ada for all in-house software engineering.</p>

<h2>So What Makes It Special?</h2>
<p>
	Ada has many useful features that are of particular interest for low-level programming and operating-system development. One
	feature in particular that impressed me greatly was Adaâ€™s <i>representation clauses</i> (see below). They provide a highly granular way to define the
	in-memory representation of low-level data structures. I was very quickly able to adapt my own long suffering operating-system development project to Ada, improving the
	quality of my codebase greatly in the process. The following section details some of Adaâ€™s features:
</p>

<h3>Custom Types</h3>
<p>
	In addition to being a strongly typed language, Ada allows for the definition of new scalar, enumerated and record types.
	Custom primitive types can also be constrained to a predefined range of values.
	The example below demonstrates the definition of a new integer type based upon Adaâ€™s native <code>Natural</code> type, restricted
	to a predefined range.
	The use of the subtype directive informs the compiler that other variables of the <code>Natural</code> type are compatible with
	the newly defined subtype.
</p>

<div><pre><span></span><span>VGA_COL_COUNT</span> <span>:</span> <span>constant</span> <span>:=</span> <span>80</span><span>;</span>
<span>VGA_ROW_COUNT</span> <span>:</span> <span>constant</span> <span>:=</span> <span>24</span><span>;</span>

<span>subtype</span> <span>Col</span> <span>is</span> <span>Natural</span> <span>range</span> <span>0</span> <span>..</span> <span>VGA_COL_COUNT</span> <span>-</span> <span>1</span><span>;</span>
<span>subtype</span> <span>Row</span> <span>is</span> <span>Natural</span> <span>range</span> <span>0</span> <span>..</span> <span>VGA_ROW_COUNT</span> <span>-</span> <span>1</span><span>;</span>
</pre></div>

<p>
	The below example illustrates the creation of incompatible custom integer types. While their base type and range
	constraints are identical, Ada treats both as separate, incompatible types. An assignment of a variable of one type
	to the value of another is illegal, and will trigger a compile-time error.
</p>

<div><pre><span></span><span>type</span> <span>Integer_1</span> <span>is</span> <span>range</span> <span>1</span> <span>..</span> <span>10</span><span>;</span>
<span>type</span> <span>Integer_2</span> <span>is</span> <span>range</span> <span>1</span> <span>..</span> <span>10</span><span>;</span>
<span>A</span> <span>:</span> <span>Integer_1</span> <span>:=</span> <span>8</span><span>;</span>
<span>B</span> <span>:</span> <span>Integer_2</span> <span>:=</span> <span>A</span><span>;</span> <span>-- illegal!</span>
</pre></div>

<p>
	The following example demonstrates the creation of a custom enumerated type. It also demonstrates a subtype of an enumerated type with a constrained range of values.
</p>

<div><pre><span></span><span>type</span> <span>Day_Of_Week</span> <span>is</span> <span>(</span><span>Monday</span><span>,</span> <span>Tuesday</span><span>,</span>
  <span>Wednesday</span><span>,</span> <span>Thursday</span><span>,</span> <span>Friday</span><span>,</span> <span>Saturday</span><span>,</span> <span>Sunday</span><span>);</span>

<span>subtype</span> <span>Work_Day</span> <span>is</span> <span>Day_Of_Week</span> <span>range</span> <span>Monday</span> <span>..</span> <span>Friday</span><span>;</span>
</pre></div>


<p>
	A variable with the type of <code>Work_Day</code> is restricted to its constrained range. Any attempt to assign a value outside
	of this range to a variable of this type will raise a <code>Constraint_Error</code> exception at runtime.
</p>

<h2>Representation Clauses</h2>
<p>
	Ada allows for explicitly defining the in-memory representation of scalar and compound types. The following example
	demonstrates the definition of a record type (equivalent to structures in C), as well as its associated
	representation in memory.
</p>

<div><pre><span></span><span>----------------------------------------------------------------------------</span>
<span>--  The format of the System Table Descriptor pointer used by the processor</span>
<span>--  to load descriptor tables like the GDT and IDT.</span>
<span>----------------------------------------------------------------------------</span>
<span>type</span> <span>System_Table_Descriptor</span> <span>is</span>
   <span>record</span>
      <span>Size</span>   <span>:</span> <span>Unsigned_16</span><span>;</span>
      <span>Offset</span> <span>:</span> <span>System</span><span>.</span><span>Address</span><span>;</span>
   <span>end record</span>
<span>with</span> <span>Size</span> <span>=&gt;</span> <span>48</span><span>;</span>
<span>for</span> <span>System_Table_Descriptor</span> <span>use</span>
   <span>record</span>
      <span>Size</span>   <span>at</span> <span>0</span> <span>range</span> <span>0</span>  <span>..</span> <span>15</span><span>;</span>
      <span>Offset</span> <span>at</span> <span>0</span> <span>range</span> <span>16</span> <span>..</span> <span>47</span><span>;</span>
   <span>end</span> <span>record</span><span>;</span>
</pre></div>

<p>
	The <code>Size</code> aspect specifier instructs the compiler that the <code>System_Table_Descriptor</code> type must be 48 bits in size. The
	record representation clause instructs the compiler as to the required layout of this record type in memory. This
	example specifies that the <code>Size</code> member should occupy bits 0 to 15, and the <code>Offset</code> member should occupy bits 16 to
	47. This feature is analogous to Câ€™s bit-fields. The following example demonstrates defining the in-memory
	representation of an enumerated type.
</p>

<div><pre><span></span><span>----------------------------------------------------------------------------</span>
<span>--  The privilege level for a particular descriptor.</span>
<span>--  These correspond to the 'protection ring' that this descriptor is</span>
<span>--  accessible from.</span>
<span>----------------------------------------------------------------------------</span>
<span>type</span> <span>Descriptor_Privilege_Level</span> <span>is</span> <span>(</span>
   <span>Ring_0</span><span>,</span>
   <span>Ring_1</span><span>,</span>
   <span>Ring_2</span><span>,</span>
   <span>Ring_3</span>
<span>)</span>
<span>with</span> <span>Size</span> <span>=&gt;</span> <span>2</span><span>;</span>
<span>for</span> <span>Descriptor_Privilege_Level</span> <span>use</span> <span>(</span>
   <span>Ring_0</span> <span>=&gt;</span> <span>0</span><span>,</span>
   <span>Ring_1</span> <span>=&gt;</span> <span>1</span><span>,</span>
   <span>Ring_2</span> <span>=&gt;</span> <span>2</span><span>,</span>
   <span>Ring_3</span> <span>=&gt;</span> <span>3</span>
<span>);</span>
</pre></div>


<p>
	The <code>Size</code> aspect specifier instructs the compiler that the <code>Descriptor_Privilege_Level</code> type must be 2 bits in size.
	The representation clause instructs the compiler as to required representation of each possible value of the
	enumerated type in memory. In this example the value of <code>Ring_0</code> will be represented by a value of <code>0x0</code> in memory, the
	value of <code>Ring_1</code> will be represented by <code>0x1</code>, and so on.
</p>

<h2 id="practical_example">A Practical Example</h2>

<p>
	The following example, and accompanying comparison with C, demonstrates the configuration of a hypothetical UART device by interfacing with an 8-bit memory-mapped configuration register. 
	This example has been adapted from a presentation by AdaCore viewable <a href="https://www.youtube.com/watch?v=qvmDqbuQe-M">here</a>.
</p>

<div><pre><span></span><span>with</span> <span>System.Storage_Elements</span><span>;</span> <span>use</span> <span>System.Storage_Elements</span><span>;</span>

<span>-------------------------------------------------------------------------------</span>
<span>--  Main</span>
<span>-------------------------------------------------------------------------------</span>
<span>procedure</span> <span>Main</span> <span>is</span>
   <span>----------------------------------------------------------------------------</span>
   <span>--  Baud rate type.</span>
   <span>----------------------------------------------------------------------------</span>
   <span>type</span> <span>Baud_Rate_T</span> <span>is</span> <span>(</span><span>b_9600</span><span>,</span> <span>b_14400</span><span>,</span> <span>b_115200</span><span>);</span></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ajxs.me/blog/Giving_Ada_a_chance.html">https://ajxs.me/blog/Giving_Ada_a_chance.html</a></em></p>]]>
            </description>
            <link>https://ajxs.me/blog/Giving_Ada_a_chance.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302344</guid>
            <pubDate>Mon, 01 Mar 2021 13:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolidRun 1U 2 node Arm Server]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26302237">thread link</a>) | @cameron_b
<br/>
March 1, 2021 | https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg" data-caption="SolidRun Honeycomb LX2 Server"><img width="696" height="448" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-652x420.jpg 652w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="SolidRun Honeycomb LX2 Server" title="SolidRun Honeycomb LX2 Server"></a><figcaption>SolidRun Honeycomb LX2 Server</figcaption></figure></div>
            <!-- content --><p>SolidRun has a new development in their NXP Layerscape LX2160A based systems this week. The new SolidRun HoneyComb LX2 Server packages two of their familiar HoneyComb LX2K boards into a single chassis. This includes a power supply and accommodations for 2.5â€³ or 3.5â€³ SATA storage. While the board at the core of this system is not a new part this does mark a milestone for deploy-ability of Arm systems at a tier that does not have a lot of other attention.<span id="more-51095"></span></p>
<h2>SolidRun HoneyComb LX2 Server Background</h2>
<p>To take a step back and look at where this system lands, the Arm ecosystem currently has a lot of activity at the top and bottom of the price and performance spectrum, with not a lot of options in the middle. That is where SolidRunâ€™s new dual-node server aims to compete.</p>
<figure id="attachment_51102" aria-describedby="caption-attachment-51102"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-server-front/" rel="attachment wp-att-51102"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front.jpg" alt="SolidRun Honeycomb LX2 Server Front" width="1110" height="722" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front.jpg 1110w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-400x260.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-800x520.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-696x453.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-1068x695.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-646x420.jpg 646w" sizes="(max-width: 1110px) 100vw, 1110px"></a><figcaption id="caption-attachment-51102">SolidRun HoneyComb LX2 Server Front</figcaption></figure>
<p>Raspberry Pi systems between $5 and $100 have shipped over 30 million units. Developer kits such as these have earned a level of ubiquity in learning and DIY spaces for making it really easy to try out new concepts in programming or â€œphysical computing.â€ While the Raspberry Pi Foundation has demonstrated using the Raspberry Pi 4 in production, including running Raspberry Pi 4s to serve their website for the launch of the Pi 4, that is not quite what they are designed for. In that example, the Foundation included their own hardware between more performant load balancers and database machines as a demonstration of their very capable new devices, not quite as a shot across the bow to the Xeons they may have replaced.</p>
<figure id="attachment_49430" aria-describedby="caption-attachment-49430"><a href="https://www.servethehome.com/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-review/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-4/" rel="attachment wp-att-49430"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4.jpg" alt="MyElectronics.nl Apple Mac Mini And Raspberry Pi Rack 4" width="800" height="534" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-629x420.jpg 629w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-49430">MyElectronics.nl Apple Mac Mini And Raspberry Pi Rack</figcaption></figure>
<p>On the other end of the spectrum, several orders of magnitude away, Ampere Altra is making a case for permanently replacing some of those Xeons for certain customers. Ampereâ€™s price-to-performance numbers are impressive, as are figures like 160 cores for a 2 socket server and 128 lanes of PCIe Gen4 per socket. This underscores that this is a platform designed for cloud providers and hyperscalers. You can check out STHâ€™s <a href="https://www.servethehome.com/ampere-altra-wiwynn-mt-jade-server-review-the-most-significant-arm-server/">Ampere Altra Wiwynn Mt. Jade Server Review</a> to learn more.</p>
<figure id="attachment_49505" aria-describedby="caption-attachment-49505"><a href="https://www.servethehome.com/ampere-altra-wiwynn-mt-jade-server-review-the-most-significant-arm-server/amd-epyc-ampere-altra-intel-xeon-cascade-lake-small-2/" rel="attachment wp-att-49505"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1.jpg" alt="AMD EPYC Ampere Altra Intel Xeon Cascade Lake Small" width="800" height="487" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-400x244.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-696x424.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-690x420.jpg 690w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-49505">AMD EPYC Ampere Altra Intel Xeon Cascade Lake Small</figcaption></figure>
<p>There is enough intrigue over the top-of-line Arm servers that developers wonder if there is not a better workstation-level/ or entry/mid-range server system. A prospective Arm developer would want something between $100 for a dev board and $4000 per socket for a screaming 2U. (Apologies to the $800 32-core 1.7GHz SKU at the other end of the Ampere Altra line.)</p>
<p>SolidRun has been positioning itself in this space for several years. Its LX2 products continue in active development. HoneyCombâ€™s maturity dovetails with the work SolidRun has been doing on two fronts. It is servicing its niche and driving specific development (for example their high bandwidth networking) but return their development work to benefit the ease of adoption from mainline Linux.</p>
<figure id="attachment_51103" aria-describedby="caption-attachment-51103"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-board-with-annotations/" rel="attachment wp-att-51103"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations.jpg" alt="SolidRun HoneyComb LX2 Board With Annotations" width="1030" height="789" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations.jpg 1030w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-392x300.jpg 392w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-800x613.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-696x533.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-548x420.jpg 548w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-80x60.jpg 80w" sizes="(max-width: 1030px) 100vw, 1030px"></a><figcaption id="caption-attachment-51103">SolidRun HoneyComb LX2 Board With Annotations</figcaption></figure>
<p>The HoneyComb LX2K is a COM Express Type 7 carrier for an NXP Layerscape LX2160A System-on-Chip with 16x Arm A72 cores running up to 2GHz. The COM Express Type 7 module has dual-channel DDR4 in SODIMMs for up to 64GB total. The carrier board exposes 4x SATA, one M.2 and one Micro SD slot for storage, four SFP+ (directly from the SoC) and one RJ45 at 1Gb for networking, dual USB 3.0 ports, and an open-ended PCIe x8 slot on a standard mini ITX form factor using standard ATX power. There is even the ATX standard power indicator and reset button header. The goal seems to be to create a platform that is easy to integrate into existing chassis and systems.</p>
<figure id="attachment_51101" aria-describedby="caption-attachment-51101"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-server/" rel="attachment wp-att-51101"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg" alt="SolidRun Honeycomb LX2 Server" width="800" height="515" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-652x420.jpg 652w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-51101">SolidRun HoneyComb LX2 Server</figcaption></figure>
<p>In the context of running highly deployable servers to replace Xeons, this may not be quite the same level of hardware maturity. On the other hand, having a dual-node 1U platform that one can deploy in racks and do Arm development is a big step forward. Not only do we get a bigger CPU, but we also get the ability to use a lot of standard components which will help boost the ecosystem as well. Adding a chassis with cooling and power may not seem like a big deal, but there is a large segment of the market that does not want to search for or cobble together these solutions. Instead, if the nodes are already in a 1U chassis, that lowers the friction and barriers to entry for development. This is still not a $400-500 PC or Atom server. Still, it is an important step in the right direction.</p>
<h2>Final Words</h2>
<p>SolidRunâ€™s HoneyComb LX2K is a platform that is accessible and capable for development on 64-bit Arm architecture as a workstation. It is also becoming more deployment-ready for appliance-type power-conscious edge applications with the 1U chassis. Developers interested in using the HoneyComb board in production have faced the challenge of trying to rack-mount an ITX board. Bamboo Systems in the UK have an answer for developers ready to deploy an 8-node 1U, but that raises the bar back up the scale of Ampere Altra. The challenge with small server nodes is that as one scales, it tends to be more efficient having larger nodes. AWS Gravition2 is an important product for the industry, but it is also tied to the AWS ecosystem. The new availability to deploy two nodes in 1U targets the intersection of accessibility and capability for those interested to kick the tires on Arm in the wild.</p>
<p>We look forward to getting our hands on the dual sled system and doing an in-depth review. We will also pair that with approaching the HoneyComb Board as a workstation for daily-driver use. Leave a comment if you would like to see specific applications explored for either system.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302237</guid>
            <pubDate>Mon, 01 Mar 2021 12:46:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts Around Naming Variables]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26301622">thread link</a>) | @todsacerdoti
<br/>
March 1, 2021 | https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1 | <a href="https://web.archive.org/web/*/https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        
<blockquote>
<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
</blockquote>
<p>I don't remember when I heard that, but it stuck. When a quip "clicks" for me, I can't rest until I find a framing in which it's disproved. But it's been 6 years now, and I'm still unable to muster a reply to the above other than "Yeah, yeah, it seems so".</p>
<p>I'm pretty sure cache invalidation is the harder of the two, because of some underlying OCD most of us have about picking two arbitrary constants that dictate sweep frequency and TTL. I'd even go as far as to speculate most of the evolution of programming has been a weird spiritual exercise around trying not to pick those two arbitrary numbers. Functional programming as a whole can even be understood as a set of taboos around this, because what good is shared OCD if it doesn't lead to religion.</p>
<p>I digress, I'm neither old, wise nor crazy enough to talk about cache invalidation, so I'll talk about the second hardest thing in programming instead, naming things.</p>
<h2>i - Naming necessity</h2>
<p>Maybe I'm being vague here, but please bear with me, I am trying to introduce the practice that leads to the creation of civilization and distinguishes us from apes</p>
<p>Naming helps one make sense of code.</p>
<p>That's not quite right... naming <em>gives</em> sense to code.</p>
<p>In theory, names could be arbitrary, at the ASM level it's more than reasonable to replace names with addresses. Yet names are so useful, that they persist even when code is compiled, presumably because they help preserve sanity when one is forced to look at the generate ASM.</p>
<p>In so far as names help make sense of code, they operate at different levels.</p>
<p>Names help connect the developer with the end goal of the software. I think the main reason OO became popular as a paradigm for teaching was a culture of example programs that used names referencing the "real world". Using words like "Shop" and "Transaction" and "buy" and "transfer_to", that give the student's bored brain some bit of reality to hang on to.</p>
<p>Names help in building a mental map of software. In this regard, names function much like <a href="https://slatestarcodex.com/2014/11/21/the-categories-were-made-for-man-not-man-for-the-categories/">any other arbitrary category we instil upon the world</a>, be it those that we use to refer to animals, other people, the night's sky or, to make the similarity to code more obvious, the content of one's bowel movement. In this sense, names should optimize for a map of the code that makes sense to the one writing it, you.</p>
<p>I'm just kidding though, the "you" here is really "a team" and the "a team" here is really "a team with people coming and going, people which have imperfect memory and ever-changing minds with which they read that map".</p>
<p>We can already see some tradeoffs here. Names that will help you now are not necessarily ones that will help the team 5 years from now. Maybe <code>let IHateThisFingLoop</code> is a useful outlet for one's anger or <code>val steves_moms = FAT32()</code> provided some much needed comedic relief. But naming for the moment can often backfire. Not only when naming for catharsis. We have such a good map of the code we're working on <strong>now</strong> that an "obvious" name can be a horrible choice in hindsight. Depending on our mental context, the name <code>trx</code> might be a much-welcomed shorthand for <code>write_new_credentials_transaction</code>, or it might be the cause of a security error that makes the news.</p>
<p>Names aren't there just to express the concepts we already have, once a name is chosen, if encountered often enough, it becomes its own concept. One need only looks at the old sciences to see arbitrary variable names that are now rooted in people's mindsdb as describing the fundamental nature of reality in an irreducible way. <code>pi</code> and <code>e</code> as representations of the circle, <code>x</code> as describing the concept of unkown, <code>c</code> as describing the maximum speed an object can travel with if Maxwell's equations are to hold... etc).</p>
<p>If a perfectly-named codebase were to exist, it would provide the reader with an amazing understanding of the things it's used for, in addition to being easy to grok. The sad thing is that "perfectly-named" is something that varies between people and even within people (over time).</p>
<p>I also think that the "experience" people have with names might vary greatly based on the codebases they worked on. Working in a large codebase with loads of existing names and naming standards provides a completely different naming-experience from building something from scratch.</p>
<p>Indeed, understanding a codebase or even a language can probably be boiled down to being familiar with all of its names and naming convention.</p>
<p>There might be a type of person that can remember all the names of the functions in a stdlib and yet know nothing about a language. But, in spite of our education system trying to optimize for the psychiatric illness which would allow this, for the vast majority of people understanding a language still boils down to knowing the vocabulary.</p>
<h2>ii - Naming convention</h2>
<p>The foreplay to naming things is coming up with conventions about naming things. A convention dictates the boundaries of what names one can give in various situations. For example, the conventions I usually impose are:</p>
<ul>
<li>class and struct names should be CammelCase</li>
<li>function and variable names should be snake_case</li>
<li>constants (in the constexpr sense), enum members and global aliases should be ALL_CAPS_SANKE_CASE</li>
<li>function only used inside the file they are in have names starting with <code>_</code></li>
<li>names should be &gt;1 and &lt;20 letters, &gt;0 and &lt;5 words, exceptions are allowed</li>
<li>If the type of a variable is not obvious from usage, have a name that implies the type (e.g. <code>customer_arr</code>, <code>equation_dict</code>)</li>
</ul>
<p>None of it is written down in our coding guidelines, people just sort of "catch onto it", even first-time contributors, I find this fascinating.</p>
<p>There are many things new people seem to miss that I have to re-iterate time and time again, but naming is never one of them. Nor was it ever a problem for me when joining a new team to pick up on their conventions.</p>
<p>Though maybe this ease of adoption would disappear if the conventions were too niche or too many?</p>
<p>Conventions are useful for two major reasons:</p>
<ol>
<li>They reduce the thought space when searching for a good name.</li>
<li>They add meaning to existing names without making them longer.</li>
</ol>
<p>If you want to understand naming go digging for conventions, but due to the above issue (people catch onto them instinctively), good conventions are hard to find. Some conventions were so good they got codified into language syntax.</p>
<p>Did you know <code>const</code> (i.e. immutability) wasn't a thing in any popular programming language until the early 80s when C++ came along? People (presumably) used to write it as part of variable names and hope that it would be respected by convention.</p>
<p>The idea of objects and classes are essentially a mix of naming and file-placement conventions that got mixed, at least in imperative land.</p>
<p>Even more so, one suspects that "types" were originally a mere naming convention, though the asteroid destroyed most of the evidence that could be used to conclude that with certainty. But nowadays "types" seem to be used as part of names in language lacking a type system.</p>
<h2>iii - Naming history</h2>
<p>But, asks the reader of 2050, I heard that back in your days there as a field called "mathematics", a thing humans did before computers, where they tried (and often failed miserably) to <a href="https://blog.cerebralab.com/Neural_networks_as_non-leaky_mathematical_abstraction">use their brains to execute formal logic</a>.</p>
<p>You are quite perceptive in remaking that, and I agree we can't understand naming in programming while ignoring 3000 years of naming in mathematics. The most basic names in programming, those shared between most languages, those of the operators (+,-,*,/,^,&amp; ...etc) are pulled out or inspired from math.</p>
<p>In my arbitrarily chosen view of the world, mathematics was an imperfect tool with imperfect creators built in a time before modern brains and modern machines, thus it's riddled with <a href="https://cerebralab.com/Named_Distributions_as_Artifacts">flaws and limitations</a>. One of the most obvious flaws in the way things were named.</p>
<p>When using "math notation" people tended to prefer very short names, namely 1 symbol long. A programmer might write something akin to:</p>
<pre><code>function calc_quarterly_interest(principal, rate, quarters):
    return principal*rate*time
</code></pre>
<p>Though the most obsessive might go all the way to writing:</p>
<pre><code>function calculate_quarterly_interest(principal, rate, quarters):
    quarterly_returns = multiply(principal, rate)
    return multiply(quarterly_returns, time)
</code></pre>
<p>However, in math notation, it would be considered bad form to write anything longer or more expressive than</p>
<pre><code>i(p,r,q)=p*r*q

</code></pre>
<p>The reason for this, I presume, boils down to two things:</p>
<ol>
<li>Saving paper, which could often be quite expensive and impossible to erase.</li>
<li>Reducing the amount of writing in materials like sand or clay, which are cheap and easy to erase, but difficult to write in.</li>
</ol>
<p>This didn't cause many issues because our brains are not very good at executing formal logic. So a given mathematical construct might have included 2, 3, 5 maybe 10 entities playing around. But to postulate an equation with thousands of variable probably seemed like madness even to a genius like Euler or grand curator like Euclid.</p>
<p>Of course, we live in an age where a mildly talented 8-year-old can pick up a toy language like Scratch and construct such an equation incidentally while writing a web app. Nowadays we need only write the equations, historically our brains were also responsible for executing them. This restricted the realm of possibilities to one so tiny I shudders to think about the lamentable condition of the poor souls that helped us get to where we could build computers.</p>
<p>Still, the reason why the previously mentioned interest computing function would work is that the writer could simply specify beforehand: "p stands for principal, r for rate, q for number of quarters".</p>
<p>This is a practice that remained with us until the 80s in a weird way, the name of variables used to be declared at the beginning of a file before they were initialized. Though it may seem crazy to you, C and C++ allow you to compile the following code:</p>
<pre><code>int a;</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1">https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301622</guid>
            <pubDate>Mon, 01 Mar 2021 11:12:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applicative Parsing]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26301543">thread link</a>) | @gbrown_
<br/>
March 1, 2021 | https://jobjo.github.io/2019/05/19/applicative-parsing.html | <a href="https://web.archive.org/web/*/https://jobjo.github.io/2019/05/19/applicative-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p><a href="https://en.wikipedia.org/wiki/Parser_combinator">Parser combinators</a> are
sets of functions for building parsers in a composable fashion. Haskellâ€™s
<a href="http://hackage.haskell.org/package/parsec">Parsec library</a> and OCamlâ€™s
<a href="https://github.com/inhabitedtype/angstrom">Angstrom</a> are two examples.
Both of these libraries expose <em>monadic</em> interfaces for
describing context-sensitive grammars. This post looks at implementing a more
restricted parsing library, structured around <a href="https://en.wikipedia.org/wiki/Applicative_functor">applicative
functors</a> rather
than monads.</p>

<p>What could justify giving up on monads? Depending on the design, one may get
a few things in return. In this exercise, the aim is for an API with the following
features:</p>

<ol>
  <li>The ability to extract all valid symbols from a parser.</li>
  <li>Allow some form of pretty printing.</li>
  <li>Support multiple evaluation strategies (e.g. backtracking and non-backtracking).</li>
</ol>

<p>To see why (1) is not possible to accomplish with monads, consider a parser
constructed using the monadic <em>bind-operator</em>:</p>



<p>Here, <code>f</code> is a function of the form <code>'a -&gt; 'b parser</code>; that means we donâ€™t
know what sort of parser it produces until itâ€™s provided with a value. Therefore,
we cannot infer all possible symbols consumed by those parsers. The same
reasoning applies to pretty printing.</p>

<h3 id="designing-a-parser-type">Designing a parser type</h3>

<p>The essence of a parser is a function with a type analogous to:</p>

<div><div><pre><code><span>char</span> <span>list</span> <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>*</span> <span>char</span> <span>list</span><span>)</span> <span>option</span>
</code></pre></div></div>

<p>A parser takes a list of characters as input, and, when successful, returns a
parsed value along with the remaining input.</p>

<p>This representation, however, falls short of supporting symbol
extraction, pretty printing, or allowing for multiple evaluation strategies.
To accommodate for those weâ€™d have to embellish the type with more context.
The problem is we donâ€™t necessarily know the complete feature set upfront.
Every time a request for some new capability comes in â€“ be it error reporting,
logging or something else â€“ we would have to go back and change the definition
to accommodate for the new functionality.</p>

<p>Rather than trying to anticipate all use cases upfront, an alternative
approach is to choose a representation that preserves as much structure as
possible, so that alternative interpreters may be added later on. To do that,
weâ€™re effectively going to enumerate the set of parsers, and ways of
combining them, by defining a type for representing an abstract syntax tree
(AST). To this purpose, weâ€™ll use a
<a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>, that
also expresses that different parsers are indexed by different types. The
initial constructors are split into two sets â€“ primitive ones (the
leaf nodes of the tree), and combinators for composing parsers:</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>(* Primitive parsers *)</span>
  <span>|</span> <span>Fail</span>      <span>:</span> <span>string</span>            <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
  <span>|</span> <span>Empty</span>     <span>:</span>                       <span>unit</span> <span>t</span>
  <span>|</span> <span>Return</span>    <span>:</span> <span>'</span><span>a</span>                <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
  <span>|</span> <span>Symbol</span>    <span>:</span> <span>char</span>              <span>-&gt;</span> <span>char</span> <span>t</span>
  <span>(* Composition - applicative *)</span>
  <span>|</span> <span>Map</span>       <span>:</span> <span>(</span><span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span><span>)</span> <span>*</span> <span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>'</span><span>b</span> <span>t</span>
  <span>|</span> <span>Product</span>   <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>*</span> <span>'</span><span>b</span> <span>t</span>       <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>*</span> <span>'</span><span>b</span><span>)</span> <span>t</span>
  <span>(* Composition - alternative *)</span>
  <span>|</span> <span>Either</span>    <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>*</span> <span>'</span><span>a</span> <span>t</span>       <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
</code></pre></div></div>

<p>The primitive parsers are:</p>

<ul>
  <li><code>Fail msg</code> - a parser that always fails.</li>
  <li><code>Empty</code> - a parser that succeeds when given empty input.</li>
  <li><code>Return x</code> - a parser that does not consume any input and always returns <code>x</code>.</li>
  <li><code>Symbol c</code> - a parser that matches input when the first character is <code>c</code>.</li>
</ul>

<p>The applicative interface is what provides sequential composition, as in:
first parse <code>x</code> with parser <code>p1</code>, then parse <code>y</code> with parser <code>p2</code> and combine
their results.</p>

<p>The <code>Either</code> constructor makes it possible to provide alternative execution
paths, i.e. parsers that succeed on different types of input.</p>

<p>As we donâ€™t want to give users direct access to the type, weâ€™ll mechanically
add some smart constructors:</p>

<div><div><pre><code><span>let</span> <span>empty</span> <span>=</span> <span>Empty</span>

<span>let</span> <span>fail</span> <span>m</span> <span>=</span> <span>Fail</span> <span>m</span>

<span>let</span> <span>return</span> <span>x</span> <span>=</span> <span>Return</span> <span>x</span>

<span>let</span> <span>symbol</span> <span>c</span> <span>=</span> <span>Symbol</span> <span>c</span>

<span>let</span> <span>map</span> <span>f</span> <span>x</span> <span>=</span> <span>Map</span> <span>(</span><span>f</span><span>,</span> <span>x</span><span>)</span>

<span>let</span> <span>product</span> <span>p</span> <span>q</span> <span>=</span> <span>Product</span> <span>(</span><span>p</span><span>,</span><span>q</span><span>)</span>

<span>let</span> <span>either</span> <span>p</span> <span>q</span> <span>=</span> <span>Either</span> <span>(</span><span>p</span><span>,</span><span>q</span><span>)</span>
</code></pre></div></div>

<p>Having an applicative interface means that it is also possible to leverage
the new syntax extension â€“ the <code>let+ .. and+</code> notation â€“ which Iâ€™ve described
<a href="http://jobjo.github.io//2019/04/24/ocaml-has-some-new-shiny-syntax.html">here</a>.
Assuming OCaml 4.08 or the dune
<a href="https://discuss.ocaml.org/t/let-syntax-backported-to-ocaml-4-02/3447">future_syntax stanza</a>
, we can add a syntax module, like so:</p>

<div><div><pre><code><span>module</span> <span>Syntax</span> <span>=</span> <span>struct</span>
  <span>let</span> <span>(</span><span>let</span><span>+</span><span>)</span> <span>p</span> <span>f</span> <span>=</span> <span>map</span> <span>f</span> <span>p</span>
  <span>let</span> <span>(</span><span>and</span><span>+</span><span>)</span> <span>p</span> <span>q</span> <span>=</span> <span>product</span> <span>p</span> <span>q</span>
<span>end</span>
</code></pre></div></div>

<p>In addition to these, weâ€™ll include an <code>Ops</code> module with infix versions
and some derived combinators:</p>

<div><div><pre><code><span>module</span> <span>Ops</span> <span>=</span> <span>struct</span>
  <span>open</span> <span>Syntax</span>
  <span>let</span> <span>(</span> <span>&lt;$&gt;</span> <span>)</span> <span>f</span> <span>p</span>   <span>=</span> <span>map</span> <span>f</span> <span>p</span>
  <span>let</span> <span>(</span> <span>&lt;|&gt;</span> <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>either</span> <span>p</span> <span>q</span>
  <span>let</span> <span>(</span> <span>&lt;*&gt;</span> <span>)</span> <span>pf</span> <span>px</span> <span>=</span> <span>let</span><span>+</span> <span>f</span> <span>=</span> <span>pf</span> <span>and</span><span>+</span> <span>x</span> <span>=</span> <span>px</span> <span>in</span> <span>f</span> <span>x</span>
  <span>let</span> <span>(</span> <span>*&gt;</span>  <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>(</span><span>fun</span> <span>_</span> <span>x</span> <span>-&gt;</span> <span>x</span><span>)</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>q</span>
  <span>let</span> <span>(</span> <span>&lt;*</span>  <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>const</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>q</span>
<span>end</span>
</code></pre></div></div>

<p>Before moving on, some of the code examples also assume a few general
utility functions:</p>

<div><div><pre><code><span>(* Identity *)</span>
<span>val</span> <span>id</span> <span>:</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>a</span>

<span>(* Const *)</span>
<span>val</span> <span>const</span> <span>:</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span> <span>-&gt;</span> <span>'</span><span>a</span>

<span>(* Forward composition *)</span>
<span>val</span> <span>(</span> <span>&gt;&gt;</span> <span>)</span> <span>:</span> <span>(</span><span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span><span>)</span> <span>-&gt;</span> <span>(</span><span>'</span><span>b</span> <span>-&gt;</span> <span>'</span><span>c</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>c</span>

<span>(* Converting a char list to a string *)</span>
<span>val</span> <span>string_of_list</span> <span>:</span> <span>char</span> <span>list</span> <span>-&gt;</span> <span>string</span>

<span>(* And back again *)</span>
<span>val</span> <span>list_of_string</span> <span>:</span> <span>string</span> <span>-&gt;</span> <span>char</span> <span>list</span>
</code></pre></div></div>

<p>Their implementation, along with the complete code is available
<a href="https://gist.github.com/jobjo/13376aaea1151100dd7915dedb35d9d7">here</a>.</p>

<h3 id="building-simple-parsers">Building simple parsers</h3>

<p>How can we use the API to build actual parsers? Letâ€™s consider a few simple
examples. First, a parser that parses a specific string, i.e. a function:</p>

<div><div><pre><code><span>val</span> <span>string</span> <span>:</span> <span>string</span> <span>-&gt;</span> <span>string</span> <span>t</span>
</code></pre></div></div>

<p>To implement the <code>string</code> parser, we can use the <code>symbol</code> primitive and fold over the
given string to combine the parsers using applicative (<code>let+ .. and+)</code> syntax:</p>

<div><div><pre><code><span>let</span> <span>string</span> <span>s</span> <span>=</span>
  <span>let</span> <span>accum</span> <span>c</span> <span>p</span> <span>=</span>
    <span>(* Parse 'x' using the 'symbol c' parser *)</span>
    <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>symbol</span> <span>c</span>
    <span>(* Then parse 'xs' using the 'p' parser *)</span>
    <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>p</span> <span>in</span>
    <span>(* Combine 'x' and 'xs' in a string *)</span>
    <span>Printf</span><span>.</span><span>sprintf</span> <span>"%c%s"</span> <span>x</span> <span>xs</span>
  <span>in</span>
  <span>List</span><span>.</span><span>fold_right</span> <span>accum</span> <span>(</span><span>list_of_string</span> <span>s</span><span>)</span> <span>(</span><span>return</span> <span>""</span><span>)</span>
</code></pre></div></div>

<p>Next, letâ€™s attempt a parser for parsing digits. A version that
detects a single digit may be defined as:</p>

<div><div><pre><code><span>let</span> <span>digit</span> <span>=</span>
  <span>list_of_string</span> <span>"0123456789"</span>
  <span>|&gt;</span> <span>List</span><span>.</span><span>map</span> <span>symbol</span>
  <span>|&gt;</span> <span>List</span><span>.</span><span>fold_left</span> <span>either</span> <span>fail</span>
</code></pre></div></div>

<p>Choosing between a list of parsers is a natural generalization of the binary <code>either</code>
combinator, and deserves its own version:</p>

<div><div><pre><code><span>let</span> <span>choose</span> <span>xs</span> <span>=</span> <span>List</span><span>.</span><span>fold_left</span> <span>either</span> <span>fail</span>
</code></pre></div></div>

<p>We may also generalize the <code>digit</code> definition to take a list of symbols as an argument:</p>

<div><div><pre><code><span>let</span> <span>one_of</span> <span>cs</span> <span>=</span> <span>choose</span> <span>@@</span> <span>List</span><span>.</span><span>map</span> <span>symbol</span> <span>cs</span>
</code></pre></div></div>

<p>Now, <code>digit</code> is achieved by:</p>

<div><div><pre><code><span>let</span> <span>digit</span> <span>=</span> <span>one_of</span> <span>"0123456789"</span>
</code></pre></div></div>

<h3 id="hitting-the-boundaries">Hitting the boundaries</h3>

<p>Next, consider a parser that recognizes arbitrary integers? An integer
consists of at least one digit but we donâ€™t know exactly how many. How can we
define a parser that captures this semantics? As a first try:</p>

<div><div><pre><code><span>let</span> <span>int</span> <span>=</span>
  <span>let</span> <span>rec</span> <span>digits</span> <span>()</span> <span>=</span>
    <span>let</span><span>+</span> <span>d</span>  <span>=</span> <span>digit</span>
    <span>and</span><span>+</span> <span>ds</span> <span>=</span> <span>either</span> <span>(</span><span>digits</span> <span>()</span><span>)</span> <span>(</span><span>return</span> <span>[]</span><span>)</span> <span>in</span>
    <span>d</span> <span>::</span> <span>ds</span>
  <span>in</span>
  <span>map</span> <span>(</span><span>string_of_list</span> <span>&gt;&gt;</span> <span>int_of_string</span><span>)</span> <span>@@</span> <span>digits</span> <span>()</span>
</code></pre></div></div>

<p>Can you spot the problem with the above definition? If not, just try running
it and youâ€™ll find it throwing a <em>stack-overflow</em> exception. The problem is
that the recursive call is never conditional on any base case and is always
eagerly evaluated. We need a way to describe parsers that may consume
arbitrarily large inputs without constructing infinite parsing expressions!
To generalize from the <code>int</code> example, weâ€™re aiming for a combinator with the
following signature:</p>

<div><div><pre><code><span>val</span> <span>many</span> <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>t</span><span>)</span> <span>list</span>
</code></pre></div></div>

<p>One solution would be to introduce a constructor, say <code>Delay</code>,
for representing lazy parsers:</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>...</span>
  <span>|</span> <span>Delay</span> <span>:</span> <span>(</span><span>unit</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>

<span>let</span> <span>delay</span> <span>f</span> <span>=</span> <span>Delay</span> <span>f</span>
</code></pre></div></div>

<p>That is a parser with delayed construction. We may use <code>delay</code> to define
<code>many</code>, as in:</p>

<div><div><pre><code><span>let</span> <span>rec</span> <span>many</span> <span>p</span> <span>=</span>
  <span>let</span> <span>many_one</span> <span>=</span>
    <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>p</span>
    <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>delay</span> <span>@@</span> <span>fun</span> <span>_</span> <span>-&gt;</span> <span>many</span> <span>p</span><span>)</span> <span>in</span>
    <span>x</span> <span>::</span> <span>xs</span>
  <span>in</span>
  <span>either</span> <span>many_one</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>
</code></pre></div></div>

<p>Now, each step of the recursion is evaluated on demand rather than upfront.
This solution would work well if it werenâ€™t for the more ambitious set of constraints
having to do with pretty printing and symbol extraction. The problem is that
in order to extract all possible symbols of a delayed parser, weâ€™d need to evaluate
it; this would unroll the infinite recursion expressed in the <code>many</code> definition, and
once again kill the stack.</p>

<h3 id="fixing-the-parser-definition"><em>Fixing</em> the parser definition</h3>

<p>Is there any fix for the problem of simultaneously having a finite
traversable representation, and providing sufficient expressive power for
describing infinite parsers? The clue is in the question. A way of expressing
recursive structures without recursion is exactly what is offered by the <a href="https://en.wikipedia.org/wiki/Fixed-point_combinator">fixed-point
combinator</a>.</p>

<p>Letâ€™s extend the parser type with a fixed-point constructor (and also get rid of <code>Delay</code>):</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>...</span>
  <span>|</span> <span>Fix</span> <span>:</span> <span>(</span><span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>

<span>let</span> <span>fix</span> <span>f</span> <span>=</span> <span>Fix</span> <span>f</span>
</code></pre></div></div>

<p>We can then use <code>fix</code> as a remedy for the recursiveness of the definition of <code>many</code>,
from above:</p>

<div><div><pre><code><span>let</span> <span>many</span> <span>p</span> <span>=</span>
  <span>fix</span> <span>@@</span> <span>fun</span> <span>many</span> <span>-&gt;</span>
    <span>let</span> <span>many_one</span> <span>=</span>
      <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>p</span>
      <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>many</span> <span>in</span>
      <span>x</span> <span>::</span> <span>xs</span>
    <span>in</span>
    <span>either</span> <span>many_one</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>
</code></pre></div></div>

<p>Note that there is <em>no</em> <code>rec</code> keyword in sight. The function <code>fix</code> is just a
handy tool for allowing us to mimic recursive functions. You may be left
wondering how exactly this solves the problem of symbol extraction, given
that we still end up with <code>Fix</code> nodes â€“ functions of type <code>('a t -&gt; 'a t)</code>
â€“ that need to be evaluated. Hopefully, the next sections on interpreting
parsers will bring some clarity on that matter.</p>

<p>Coming back to the example of integer-parsing, hereâ€™s how <code>int</code> may be defined
in terms of <code>many</code>:</p>

<div><div><pre><code><span>let</span> <span>int</span> <span>=</span>
  <span>let</span><span>+</span> <span>d</span>  <span>=</span> <span>digit</span>
  <span>and</span><span>+</span> <span>ds</span> <span>=</span> <span>many</span> <span>digit</span> <span>in</span>
  <span>int_of_string</span> <span>@@</span> <span>string_of_list</span> <span>(</span><span>d</span> <span>::</span> <span>ds</span><span>)</span>
</code></pre></div></div>

<p>Again, we may extract the common pattern of parsing one or more times using the same
parser (one or more digits in the example above) by adding a new combinator, as in:</p>

<div><div><pre><code><span>let</span> <span>many_one</span> <span>p</span> <span>=</span>
  <span>let</span><span>+</span> <span>x</span> <span>=</span> <span>p</span>
  <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>many</span> <span>p</span>
  <span>x</span> <span>::</span> <span>xs</span>
</code></pre></div></div>

<p>Given a parser <code>p</code>, the parser <code>many p</code> succeeds if it can apply <code>p</code> <em>at least</em> one
time on its input.</p>

<p>As a side note, the code generously makes use of the new applicative syntax to
demonstrate how it may be used to write declarative code that also avoids
infix operators. As an alternative, we can define the same functions
without relying on the syntax extension; for instance:</p>

<div><div><pre><code><span>(* Requires Ops module to be open *)</span>

<span>let</span> <span>many</span> <span>p</span> <span>=</span> <span>fix</span> <span>@@</span> <span>fun</span> <span>many</span> <span>-&gt;</span>
  <span>either</span> <span>(</span><span>List</span><span>.</span><span>cons</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>many</span><span>)</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>

<span>let</span> <span>many_one</span> <span>p</span> <span>=</span> <span>List</span><span>.</span><span>cons</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>many</span>â€¦</code></pre></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jobjo.github.io/2019/05/19/applicative-parsing.html">https://jobjo.github.io/2019/05/19/applicative-parsing.html</a></em></p>]]>
            </description>
            <link>https://jobjo.github.io/2019/05/19/applicative-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301543</guid>
            <pubDate>Mon, 01 Mar 2021 10:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DataOps: How to develop, maintain and scale data intensive projects]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26301474">thread link</a>) | @javisantana
<br/>
March 1, 2021 | https://blog.tinybird.co/2021/02/27/dataops/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/02/27/dataops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>As we build Tinybird, we work hand in hand with many data and engineering teams. In the process we are discovering new ways to develop, maintain and scale data intensive projects.</p> <h2 id="anatomy-of-a-modern-data-team"> Anatomy of a modern Data Team <a href="#anatomy-of-a-modern-data-team">Â¶</a> </h2> <p>If you are into development you have probably heard of the <strong>DevOps</strong> culture: a set of practices and tools that allow development teams to improve their productivity and collaboration when building high quality software products.</p> <p>DevOps is also key for teams that need to <strong>iterate faster</strong> on their quest to find the right thing to build.</p> <p>Things like automated testing, continuous integration and deployment, monitoring, configuration and change managementâ€¦ enable the development and operations teams to work as a single team, with end-to-end ownership of the product they are building.</p> <p>When it comes to data teams things are starting to change. There have been typically three groups in a data team:</p> <ul> <li><em>Data scientists</em>: which most of the time work locally running experiments and analyses, or machine learning models that may later need be productised.</li> <li><em>Data engineers</em>: which write and maintain data pipelines.</li> <li><em>Infrastructure engineers</em>: which are in charge of the â€œ<em>big data</em>â€ infrastructure.</li> </ul> <p>They used to be siloed groups, with long development cycles and most of the time their outputs are cascaded to the next group. Even more, their final product needed to be integrated by a separate team of developers which built the data product for the end users.</p> <blockquote> <p>The technology and tools that support data intensive applications are only good if they are applied such that it is possible for several people in an organization to collaborate around the same context (the data and the business), iterate on the problem, and continuously deliver high quality solutions.</p> </blockquote> <h2 id="dataops-working-with-data-as-if-it-were-code"> DataOps: working with Data as if it were Code <a href="#dataops-working-with-data-as-if-it-were-code">Â¶</a> </h2> <p><strong>A similar culture to DevOps can be applied to data teams</strong>: itâ€™s known as DataOps.</p> <p>DataOps is a set of practices and tools that allow data scientists, data engineers, infrastructure engineers and <strong>also developers</strong> to collaborate together having full autonomy, ownership and accountability of the data product.</p> <p>The goal is enabling data teams to handle requirements, develop, deploy and support the data product. With tools that allow them to measure performance, latencies or control SLAs.</p> <p>In the end, making data teams <strong>work with data as if it was source code</strong>, so they can iterate faster towards high quality data products.</p> <p>Continue reading to learn about <a href="https://blog.tinybird.co/2021/02/27/dataops-principles/">10 principles of DataOps we make available for data teams</a>.</p> <p><strong><em>What are your main challenges when dealing with large quantities of data?</em></strong> <a href="https://www.tinybird.co/survey">Tell us about them</a> and get started solving them with Tinybird right away.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/02/27/dataops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301474</guid>
            <pubDate>Mon, 01 Mar 2021 10:46:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spectre exploits in the "wild"]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26301326">thread link</a>) | @todsacerdoti
<br/>
March 1, 2021 | https://dustri.org/b/spectre-exploits-in-the-wild.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/spectre-exploits-in-the-wild.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Someone was silly enough to upload a
<a href="https://www.virustotal.com/gui/file/6461d0988c835e91eb534757a9fa3ab35afe010bec7d5406d4dfb30ea767a62c">working spectre (CVE-2017-5753) exploit</a>
for Linux (there is also a
<a href="https://www.virustotal.com/gui/file/ecc0f2aa29b102bf8d67b7d7173e8698c0341ddfdf9757be17595460fbf1791a">Windows one</a> with symbols that I didn't look at.)
on VirusTotal last month, so here is my quick Sunday afternoon lazy analysis.</p>
<p>The binary has its <code>-h</code> option stripped, likely behind a <code>#define</code> to avoid
detection, but some of its parameters are obvious, like specifying
what file to leak, or the kernel base address. The authors didn't check (or care)
that the logging function hasn't been entirely optimized out, leaving a bunch
of strings helping in the reversing process.</p>
<p>The exploit works in four stages:</p>
<ol>
<li>Find the <a href="https://www.halolinux.us/kernel-reference/inode-objects.html">superblock</a>,</li>
<li>Find the <a href="https://en.wikipedia.org/wiki/Inode">inode</a> of the file to dump</li>
<li>Find the corresponding page address</li>
<li>Dumps the content of the file.</li>
</ol>
<p>In the case of <code>/etc/shadow</code>, the default option, the content of the
file is shoved in memory by running the following command in the
background: <code>return system("echo \"whatever\n\" | su - 2&gt; /dev/null")</code>.
In my lab, on a vulnerable Fedora, the exploit is successfully dumping <code>/etc/shadow</code> in a couple of minutes.
Interestingly, there are checks to detect <a href="https://en.wikipedia.org/wiki/Supervisor_Mode_Access_Prevention">SMAP</a>
and abort if it's present. I didn't manage to understand why the exploit was
failing in its presence.</p>
<p>The crux of the exploit is at <code>0x4092f0</code>, using <code>cpuid</code> as a serializing
instruction, <code>rdtsc</code> for timing, and <code>mfence</code>/<code>lfence</code> as barrier, as
documented in the paper. It's also using some tricks to minimize the amount of
readings, like type-specific functions, for example a kernel address has a
specific <em>format</em>.
Thanks to <a href="https://twitter.com/spendergrsec">spender</a> for confirming that the gadget used is likely <code>get_user()</code> in the <code>FIOASYNC ioctl</code>,
which was <a href="https://patchwork.kernel.org/project/kernel-hardening/patch/20180209133935.811950747@linuxfoundation.org/">fixed in 2018</a></p>
<p><a href="https://en.wikipedia.org/wiki/KASLR">KASLR</a> is bypassed when present either by
looking at <code>/proc/kallsyms</code> when available to unprivileged users like it used
to be the case on Fedora until ~recently, or by using the generic
bypass from the <a href="https://gruss.cc/files/prefetch.pdf">prefetch side-channel</a> by Gruss and al.
originating from a library called <code>libkaslr</code>. Amusingly, this method is still
working on an up to date Linux, proving again that <a href="https://grsecurity.net/kaslr_an_exercise_in_cargo_cult_security">KASLR is useless at
best</a>.
For systems that don't have the <code>/proc/kallsym</code> file accessible, the exploit
relies on hardcoded offsets, and while only Fedora, ArchLinux and Ubuntu are currently
supported, there are functions to check for Debian and CentOS. It's a bit
surprising to see hardcoded offsets in an exploit with arbitrary read in
2021.</p>
<p>Unsurprisingly, it had a 
<a href="https://www.virustotal.com/gui/file/6461d0988c835e91eb534757a9fa3ab35afe010bec7d5406d4dfb30ea767a62c/detection">0 detection</a>
rate before I published this blogpost.</p>
<p>Attribution is trivial and left as an exercise to the reader.</p>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/spectre-exploits-in-the-wild.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301326</guid>
            <pubDate>Mon, 01 Mar 2021 10:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Business, Not an Audience]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26301030">thread link</a>) | @jakobgreenfeld
<br/>
March 1, 2021 | https://jakobgreenfeld.com/build_an_audience | <a href="https://web.archive.org/web/*/https://jakobgreenfeld.com/build_an_audience">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If youâ€™re reading this, Iâ€™m pretty sure youâ€™ve seen the following pattern over and over again:</p>

<ul>
  <li>Creative nonfiction pioneer John McPhee distilled decades of experience and first-hand learnings in a series of essays. (The best of them are now available in a book called â€œDraft No. 4â€.)</li>
  <li>A savvy entrepreneur repackages the advice in a $1000+ cohort-based course.</li>
  <li>Someone takes the course and summarizes what he learned.</li>
  <li>People on Twitter start creating threads summarizing the studentâ€™s summaries.</li>
  <li>At some point, the guy who summarized the studentâ€™s summaries will get invited to a podcast to summarize his summary of the studentâ€™s summary.</li>
</ul>

<p>I wish I was kidding.</p>

<p>This is a picture-perfect example of what Sean Blanda calls the <a href="https://99u.adobe.com/articles/55974/the-creative-worlds-bullshit-industrial-complex">Creative Worldâ€™s Bullshit Industrial Complex</a>. But my goal here is not to dunk on anyone. Instead I want to focus on something far more important.</p>

<p>The Bullshit Complex is just a symptom. Whatâ€™s the underlying cause?</p>

<p>First, let me clarify one thing. While Iâ€™m convinced that remixed content is largely a waste of time for writers and readers, itâ€™s a free world out there. Do whatever makes you happy. If you focus on remixed or â€œcuratedâ€ content Iâ€™ll probably not follow you on Twitter or read your blog, but thereâ€™s no reason why you should care about that. Ultimately, itâ€™s your own responsibility to decide how you spend your time and what kind of content you consume.</p>

<p>With that out of the way, letâ€™s talk about entrepreneurship.</p>

<p>In recent years one of the most common pieces of advice for aspiring entrepreneurs has become that you should focus on building an audience. Everyone is screaming it from the rooftops.</p>

<p>So when I started to get into entrepreneurship a few months ago, thatâ€™s exactly what I did. I spent a lot of time researching what kind of tweets get attention and set the goal for myself to post at least two tweets per week and two blog posts per month. After all, churning out content regularly is key if you want to build an audience, <a href="https://www.youtube.com/watch?t=67&amp;v=cubPiuD7_dA&amp;feature=youtu.be">right</a>?</p>

<p>If you need any evidence how serious I was about the whole building an audience thing, here it is: I created a <a href="https://whattotweet.com/">What to Tweet</a> tool because I was struggling to stick to my Twitter schedule.</p>

<p>Looking back at it now I think I largely wasted my time. And more importantly I see so many people falling into the exact same trap.</p>

<p>Their goal is to become entrepreneurs. But instead of building products, they create content. Or even worse, they do research and take courses on how to create content.</p>

<p>But this doesnâ€™t bring them one inch closer to their goal. Itâ€™s just a form of procrastination.</p>

<p>While charging money for something you created is <a href="https://jakobgreenfeld.com/free">scary</a>, there is almost zero risk in putting out free content. And if youâ€™re just remixing other peopleâ€™s content, the intellectual risk is effectively zero. After all, you can always reply â€œhey, donâ€™t shoot the messengerâ€.</p>

<p>This trap is particularly dangerous because it feels like youâ€™re making progress while really you donâ€™t.</p>

<p>Aspiring entrepreneurs are not just wasting a lot of time but also lots of money this way. They spend thousands of dollars on courses that teach them how to remix other peopleâ€™s content more effectively. They buy the latest hyped-up courses that teach them how to craft more effective tweets, blog posts and Youtube videos.</p>

<p>But donâ€™t get me wrong. <em>Having</em> an audience is awesome and I love great content.</p>

<p>What Iâ€™m saying is that too many beginners have their priorities backwards and fall into the â€œbuild an audience!â€ trap.</p>

<p>An exemplary plan looks as follows: â€œI donâ€™t know what product I should create. So Iâ€™m planning to create articles or carousels on Linkedin to find my voice and build an audience.â€ Thatâ€™s almost verbatim a paragraph from an email I received two days ago.</p>

<p>You can certainly get a lot of followers by churning out remixed content and feel-good platitudes. But everyone seems to forget that not all audiences are alike.</p>

<p>Letâ€™s say you have 2000 followers that you got by posting feel-good platitudes, whereas I only have two followers called Elon Musk and Paul Graham. Would you swap accounts?</p>

<p>With feel-good platitudes and remixed content youâ€™ll only attract fellow beginners. Everyone else recognizes the content immediately for what it is. Hence, the primary value of your much larger audience is that youâ€™re able to sell them a â€œHow to grow your Twitter followingâ€ Gumroad course for $47.</p>

<p>A high-quality audience is an endless source of opportunities. A low quality one is at most a Ponzi scheme.</p>

<p>Many people <a href="https://twitter.com/m_ashcroft/status/1364334719970721793">learn</a> this the hard way. They get lured by the promise that theyâ€™ll be able to create content effortlessly and build an audience this way. This is exactly what beginners want to hear and hence what gurus are preaching. â€œEverything is a remixâ€. So just progressively summarize a bunch of books and then start sharing pieces you remixed from your summaries.</p>

<p>Students of these courses spent months recording videos and writing thousands of words only to discover that they never said anything meaningful.</p>

<p>Valuable content that truly advances the conversation and gets the attention of people you really want to connect with is never effortless. Itâ€™s painful. And Iâ€™m not talking about some kind of sophisticated editing process, but the writing itself.</p>

<p>In fact, this is how you know that youâ€™re creating valuable content. You should at least be a little scared before you hit the publish button.</p>

<p>Publishing content online is the best way to become visible so that opportunities can find you. But please donâ€™t try to improve your ability to come up with interesting things by reading and connecting ideas just so that you have something to write about.</p>

<p>If you ever notice that youâ€™re trying to â€œsay something interestingâ€, stop. Youâ€™re just going to feed the Creative Worldâ€™s Bullshit Industrial Complex.</p>

<p>Your main priority always should be to <em>do</em> meaningful things, to solve real-world problems, to be the man in the arena. And if you share what you learn along the way, people will start to listen. Write when you have something meaningful to say, and not to stick to some self-imposed writing schedule.</p>

<p>A hidden benefit of this strategy is that your writing skills become largely irrelevant. Itâ€™s certainly true that great writers like John McPhee can make a topic as boring as <a href="https://www.goodreads.com/book/show/54983.Oranges">Oranges</a> exciting. But if you have a great story to tell or learned something important, people will pay attention no matter how bad your writing is. Not convinced? Just look at the essay youâ€™re reading right now.</p>

<p>Save yourself thousands of dollars. Hereâ€™s all the writing advice you need:</p>

<ul>
  <li>Share meaningful first-hand experiences.</li>
  <li>Write as if you were emailing a friend, not to impress an imaginary teacher.</li>
</ul>

<p>Now Iâ€™m definitely scared to publish this essay. This is exactly why Iâ€™ll do it.</p>

  </div></div>]]>
            </description>
            <link>https://jakobgreenfeld.com/build_an_audience</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301030</guid>
            <pubDate>Mon, 01 Mar 2021 09:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gerald Weinberg]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300409">thread link</a>) | @ingve
<br/>
February 28, 2021 | https://deprogrammaticaipsum.com/gerald-weinberg/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/gerald-weinberg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Some books are like mirrors. By that I mean that reading them involves a great deal of looking at oneself, both for praise and loathing. Taking a look back in time, reflecting on all those times we thought we were right and we were wrong, bringing back memories of times long gone, some of them painful, most hopefully fun and joyful.</p>
<p>â€œThe Psychology of Computer Programmingâ€ is one of those. In every one of its chapters, Dr. Weinberg reflects on the human aspects of programming. It is, most probably, the first book ever written on the subject of the personality, the interactions and the characteristics of software developers. Let me be clear: this book has been written in 1971, and it has been continuously in print until at least the end of the twentieth century, for almost 30 years. This is the stuff of classics.</p>
<p>There has even been a reviewed â€œanniversaryâ€ edition published in 1999, but I bought a copy of the first edition of the book, and besides the delightful look and feel of the pages, representatives of the typography and design of the seventies, the structure, the flow and the discussion of this book make it stand in a class of its own, and represent a hallmark in our field.</p>
<p>Dr.&nbsp;Weinberg analyzes programming from both individual and collective points of view, including the issues of education, human resources management, and even programming language design. The author actually devotes a section of his book to explain how the design of a programming language impacts the readability and the subsequent maintainability (or lack thereof) of the programs written in it.</p>
<p>Sounds familiar?</p>
<p>Regarding team interactions, the author highlights the issues brought from scaling up programming teams: do small teams face the same issues as larger ones? How do communication patterns emerge and evolve? The author takes pleasure in debunking common myths and misconceptions, some of them still held today by managers all over the world: what are the factors that can cause a project to break down in pieces? The answers will surprise you, and you will wonder why nobody had ever told you to read this book first.</p>
<p>Dr. Weinberg also pays close attention to the individual characteristics of programmers. What defines a good programmer? Why do they take pride in their jobs? What kind of incentives should a company offer to their developers? Nice offices or challenging problems? (I think you can guess the answer to that last question.)</p>
<p>In the humble opinion of the author of these lines, software is primarily a social process, and only later a technical feat. Software is no more a technical product than a book is just a printed object. Software is the result of interactions among people, and as such it will reflect all the contradictions, the failures, the wonders and the joy of the people involved in it. Every single piece of software ever written by humans reflects the underlying moods, psyche and interactions of a group of people. As such, studying the psychology of a programmer yields naturally in a process in which, invariably, the software will be better at the end.</p>
<p>I once saw a joke on Twitter, saying that managing programmers was subject to Heisenbergâ€™s Principle, in that observing programmers changes their behavior. I do not think it is a joke, for I believe that all social systems are, actually, quantum-like systems subject to this principle; the actions of the observer will invariably alter the behavior of the observed. And that is OK, as far as I am concerned. If managers are conscious of this fact, and if they can use this to their advantage, they will be able to build sustainable teams.</p>
<p>Maybe Dr. Weinberg took some inspiration from Melvin Conway, who <a href="https://en.wikipedia.org/wiki/Conway%27s_law" target="_blank" rel="noopener">in 1967 stated</a> that â€œorganizations design systems mirroring their own communication structuresâ€. Now you start to understand why your microservice architecture is a mess, and no, neither Istio nor Prometheus is going to help you with that.</p>
<p>Finally, regarding recruiting: we all know how hard it is to find and recruit software developers, yet I am appalled to see how many companies do as much as they can to destroy the teams they spent so much time and money to build. Why is this? I can only recommend all human resources managers, all project managers, and all developers as well, to get a copy of this book and, as I said at the beginning of this chapter, to take a good look at ourselves in the mirror. We all need a little bit of introspection, and Dr. Weinberg can help.</p>
<p>Legacy buzzword warning: this book is mostly accessible to general audiences, but there are a few sections where the author assumes a certain experience with programming languages, compilers, hardware design or even project management; and in some cases, with the 1971 versions of those.</p>
<p>Cover photo by the author.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/gerald-weinberg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300409</guid>
            <pubDate>Mon, 01 Mar 2021 07:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Message Sent on AIM]]>
            </title>
            <description>
<![CDATA[
Score 392 | Comments 204 (<a href="https://news.ycombinator.com/item?id=26300266">thread link</a>) | @luu
<br/>
February 28, 2021 | https://justanman.org/posts/the-last-message-sent-on-aim/ | <a href="https://web.archive.org/web/*/https://justanman.org/posts/the-last-message-sent-on-aim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://justanman.org/images/aol-instant-messenger-shuts-down.png" alt="AOL Instant Messenger â€˜Running Manâ€™ waving goodbye"></p>
<p>In the early 2000s social media sites like Facebook and Twitter werenâ€™t commonplace yet. Even text messages, at ten cents each, were something to be rationed. For many teenagers the primary means of communication outside school was AOL Instant Messenger (AIM). So when it was announced in October that they were shutting down AIM after 20 years, I felt a wave of nostalgia for the messaging app of my youth.</p>
<p>It wasnâ€™t clear when they would be pulling the plug for good, but a high school friend and I planned to be online for the occasion. Their website indicated that AIM would continue to work until the morning of December 15, 2017. Assuming this meant UTC time, that put it going offline sometime after 7:00 PM EST on the 14th.</p>
<p>I wondered: Could I be the last person to sign off? The last person to send a message? Would I have anything profound to say?</p>
<p><strong>Research</strong></p>
<p>I decided to research famous last words. First stop: the Book of Revelation. Final chapter, final verse.</p>
<blockquote>
<p>â€œThe grace of our Lord Jesus Christ be with you all. Amen.â€</p>
</blockquote>
<p>Not quite what I was looking for.</p>
<blockquote>
<p>â€œLast words are for fools who havenâ€™t said enough!â€</p>
</blockquote>
<p>Too cantankerous. And as a somewhat libertarian leaning person, I wasnâ€™t going to let Karl Marx have the last word.</p>
<p>Iâ€™d figure out what to say later and in the meantime started reading about the technology behind AIM. I learned about OSCAR, the proprietary protocol used by AIM and ICQ. Parts of the protocol were documented by AOL in an official SDK. This is what made third-party AIM clients possible. I had used Gaim (now Pidgin) on Linux machines before and indeed, there was even BSFlite, an AIM client for the command line.</p>
<p>AOLâ€™s desktop client no longer worked for me. They had already pulled the iOS app from the App Store. Ditto for Android. Fortunately browser sign on still worked. I was greeted by a familiar interface that supported new features like embedded media and SMS.</p>
<p>I sent a couple test messages from the browser to my phone. Monitoring outbound activity in the Chrome network panel revealed the structure of a request: a simple HTTP POST to a url, with what appeared to be a session ID in the query string and a message body. I tried to send a message using <code>curl</code> and it worked. As long as I was signed on in the browser the request was accepted.</p>
<p>There were several paths to automating this but given the time constraint, something quick and easy would probably suffice. All I had to do was keep sending messages until the server stopped responding.</p>
<p><strong>December 14, 2017: The final countdown</strong></p>
<p>It was almost midnight UTC time. It would be the 15th soon and I didnâ€™t want to miss the shutdown, so I set up a Bash script to run the <code>curl</code> command at one second intervals. Every now and then I had to manually reauthenticate in the browser. It wasnâ€™t elegant but it worked. Now I had to waitâ€¦</p>
<p>To pass time I searched Twitter for mentions of AIMâ€™s last day. Plenty of people were reminiscing about their old screen names, but only a handful were actually signing on one last time. I added them to my buddy list and we talked for a bit. One lived in DC, one in Toledo. Another somewhere in Maryland. Two were engineers, one was a wrestling announcer! I made dinner and watched <em>The Office</em> while occasionally checking on the script.</p>
<p>It ran for another six hours until 1:21 AM EST. I witnessed the drama play out in HTTP status codes:</p>
<pre><code>200 OK
200 OK
200 OK
408 Request Timeout
408 Request Timeout
401 Unauthorized
</code></pre><p>And like that, AIM was gone. Requests to aim.com returned an Invalid URL status page. <code>curl</code> returned nothing but 401s.</p>
<p><strong>Epitaph</strong></p>
<p>I examined the script logs and found it â€“ the last message sent on AIM. [1] It was timestamped Fri Dec 15 01:21:42 EST 2017. From me, to me. (I didnâ€™t want to spam anyone.)</p>
<p>I had borrowed the words from Leonard Nimoyâ€™s final tweet:</p>
<blockquote>
<p>â€œA life is like a garden. Perfect moments can be had, but not preserved, except in memory. LLAPâ€</p>
</blockquote>
<p>ðŸ––</p>
<p><strong>Notes</strong></p>
<p>[1] At least in my server region.</p>
<p><strong>Thanks</strong> to behind2greeneyes, dalilmoo, croftonworldwide, nuklermuleburger, and sirmatthew84.</p>
<p>If you enjoyed reading this, please consider a donation to the <a href="https://archive.org/donate/">Internet Archive</a>.</p>
<p>You can also read Kat Timpfâ€™s brilliant <a href="https://www.nationalreview.com/2017/10/aol-instant-messenger-eulogy-aim-social-media-millennials/">eulogy for AIM</a>.</p>

      <hr>
      <p>
        For more frequent updates, follow me on Twitter.
      </p>
      <p>
        <a href="https://twitter.com/jtangofx?ref_src=twsrc%5Etfw" data-show-count="false">Follow @jtangofx</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://justanman.org/posts/the-last-message-sent-on-aim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300266</guid>
            <pubDate>Mon, 01 Mar 2021 06:40:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The curious case of CVE-2020-14381]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300234">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://blog.frizn.fr/linux-kernel/cve-2020-14381 | <a href="https://web.archive.org/web/*/https://blog.frizn.fr/linux-kernel/cve-2020-14381">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://blog.frizn.fr/linux-kernel/">Kernel Linux</a> &gt; <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">The curious case of CVE-2020-14381</a></p>

                    <h3>The curious case of CVE-2020-14381</h3>                    
                    <p>Today is the one-year anniversary of this interesting kernel bug I worked
on last year with <a href="https://twitter.com/bluec0re" target="_blank">@bluec0re</a>,
and as it turns out I wrote something about it during one of these lockdown
weekends so I thought I'd release it. <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2015" target="_blank" title="CVE-2020-14381 get_futex_key use-after-free">The bug itself</a>
was discovered by <a href="https://twitter.com/tehjh" target="_blank">Jann Horn</a>
of Project Zero. While I touch most of the elements required to exploit the
bug, I stay superficial here since the exploit itself is not particularly
exciting. What makes this bug interesting to me is its lifecycle, in particular
how unevenly the patch was applied to the various distributions. I also talk
briefly about hardware side-channels since it was the first time I had ever
used one.</p>

<p><strong>The bug</strong></p><p>Itâ€™s already well-described in the bug tracker, but here is another summary.
The <span>futex</span> syscall's main parameter is a userland address, and this address
may belong to a file-backed mapping. In that case, the futex key kernel object
<a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L707" target="_blank">held</a>
and <a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L724" target="_blank">kept</a>
a reference to the inode object, but didnâ€™t hold a reference to the fileâ€™s mountpoint.
If the mountpoint were to go away, its associated kernel structures would be
freed, but the inode wouldnâ€™t. Thatâ€™s an issue because the inode itself has
fields that point to some of these structures, such as its <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L641" target="_blank">super_block</a>
struct.</p>

<p>Further use of the inode by <span>futex</span> code paths may therefore trigger
use-after-frees. One particular code path highlighted by Jann in the bug happens
when the <span>futex</span> is destroyed: the last reference to the inode is released
and the inode needs to be freed. This is done in <span>iput</span> which then calls
<span>iput_final</span>. <span>iput_final</span> and its subcalls will then call inode
management functions stored in the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L1942" target="_blank">super_operations</a>
struct accessed <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1533" target="_blank">from the super_block</a>
object. The first instance happens right at the beginning of <span>iput_final</span> with
a call to the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1539" target="_blank">drop_inode</a>
function.</p>

<p>Exploiting this bug requires being able to:
</p><ul>
  <li>Successfully <span>umount</span> a mountpoint. A no-go a few years ago, but
  possible nowadays with the normalization of unprivileged user namespaces.
  Itâ€™s a good example that this feature was never a trivial security tradeoff
  (unprivileged sandboxes v. augmented kernel attack surface) which in turn
  makes it somewhat surprising that all mainstream distributions enabled them by default
  without much debate</li>
  <li>Survive the <span>op-&gt;drop_inode()</span> execution (non-SMEP or a KASLR bypass)</li>
  <li>Survive the <span>op-&gt;drop_inode</span> indirection just before that (non-SMAP
  or a stack/heap leak)</li>
  <li>Do everything in one call, because with an incorrect inode state, a corrupted
  super_block and some linked lists unlinks to do in the remainder of <span>iput_final</span>,
  itâ€™s doubtful we can even get as far as the second <span>super_operations</span>
  function pointer call (<span>evict_inode</span>)</li>
</ul>


<p><strong>Exploitation</strong></p><p>The first exploitation pathway that comes to mind goes as follows:
</p><ul>
  <li>wait for the <span>super_block</span> to be freed. Itâ€™s done in <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/super.c#L299" target="_blank">an RCU callback</a>
  so one way or another you need to wait for the end of the RCU grace period
  after <span>umount</span> returns, e.g. with <span>membarrier</span>. For a PoC, spraying
  allocs for the duration of the expedited grace period works well enough since
  the <span>super_block</span> slab, <span>kmalloc-2k</span>, is not super busy.</li>
  <li>overwrite the freed <span>super_block</span> via a dynamic heap allocation primitive
  (e.g. <a href="https://elixir.bootlin.com/linux/v5.4.7/source/net/socket.c#L2264" target="_blank">sendmsg ancillary data</a>).</li>
  <li>point <span>s_op</span> to an attacker-controlled buffer</li>
  <li>point <span>drop_inode</span> to a chain of gadgets that pivot the stack to
  either the <span>super_block</span> or <span>super_operations</span> bufffers (which
  are both necessarily in registers and almost fully controlled). Example of
  common gadgets that would work in this situation would be <span>push reg; jmp/call [reg+x]</span>
  that can then be chained with a <span>pop rsp; ret</span> gadget placed at <span>[reg+x]</span></li>
  <li>do whatever with your unconstrained ROP, fixup the stack and return</li>
</ul>


<p>This would be a sucky exploit to maintain as it relies on precise knowledge
of the kernel image, but thatâ€™s as good as it gets for a raw function pointer
execution without a read primitive in kernel space. The portability issues
for exploits like this are in themselves a significant bonus of SMEP: it rarely
prevents exploitation but makes many candidates much less appealing for weaponization.</p>

<p>We can take SMEP for granted. Itâ€™s only one CPU generation / 2 years older
than SMAP, but not having it is getting really rare. Plus if your exploit does
rely on no-SMEP but your target ends up having software SMEP enabled, which
you sometimes can't really tell at runtime, you've just turned a privesc attempt into
a lost foothold. No-SMAP however is still a thing for the time being. As a
random example the <a href="https://aws.amazon.com/intel/" target="_blank" title="AWS EC2 intel CPUs">AWS EC2 CPU roster</a>
shows some CPUs that do not support SMAP.</p>

<p><strong>On infoleak bugs</strong></p><p>In any case, to exploit this bug one needs at least one infoleak. The most
important is to get kernel base for gadgets, and then we could use a heap leak
or similar to support SMAP-capable CPUs (to have our "attacker-controlled
buffer" in point 3 above in kernel space). A heap/stack leak can often yield
a .text address as well so having one would kill two birds with one stone.
But, not everyone has the right infoleak in their stash ready to go, contrary
to a common anti-KASLR argument. And even when you do have an infoleak bug,
it doesn't mean that it will help with your current exploit.</p>

<p>For instance, a good infoleak candidate which was released around the same
time last year would be the one with uninitialized memory in coredumps, <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-10732" target="_blank">CVE-2020-10732</a>.
But short of a public proof-of-concept, one needs to understand the coredump
generation code, then find an object in that slab that allows us to get
.text, and another one to deduce a heap address you control. In short, at least
as much work as the rest of the exploit we are looking at. And that's without
considering that using two bugs in one exploit also means that you need to
take into account both bugs limitations. Unprivileged user namespaces for the
main bug we are looking at (not a thing on e.g. RHEL 7), and for the coredump,
well the ability to retrieve the core files, i.e. not running in a container.
Luckily for our project, we already knew we were targeting non-SMAP containers
so we were able to avoid spending all that effort on an infoleak bug that
would have ended up being worthless; a luxury that real exploit developpers
preparing capabilities ahead of time do not have. But if we were targeting
SMAP containers, well that would have been it since more effort would have
exceeded our resource budget for this project.</p>

<p><strong>Hardware side-channels</strong></p><p>For kernel .text however, the situation is different since there are generic,
publicly-documented ways to obtain kernel base: hardware vulns. I personally
hadnâ€™t ever used any and even saw them as a niche exploitation technique
relying on opaque CPU heuristics that donâ€™t hold across models - not something
to be considered for resilient exploits. I was simply wrong, but thankfully
had access to many specialists (<a href="https://twitter.com/tehjh" target="_blank">@tehjh</a>,
<a href="https://twitter.com/_fel1x" target="_blank">@_fel1x</a>, <a href="https://twitter.com/_tsuro" target="_blank">@_tsuro</a>)
who knew better.</p>

<p>While side-channels that allow leaking memory across security boundaries
are hopefully bound to be mitigated, there are many side-channels that leak
addresses and which we havenâ€™t heard much about since Spectre and friends.
These ones are probably here to stay even longer. For this project I used <a href="https://github.com/tpn/pdfs/blob/master/Jump%20Over%20ASLR%20-%20Attacking%20Branch%20Predictors%20to%20Bypass%20ASLR%20-%202016%20(micro16).pdf" target="_blank" title="jump over aslr paper">Jump Over ASLR</a>,
which was published before Spectre in 2016. Itâ€™s simple to understand (especially
with access to the aforementioned people) and there are PoCs that are just
waiting to be adjusted to your own scenario (e.g. <a href="https://github.com/felixwilhelm/mario_baslr" target="_blank" title="mario_baslr jump over aslr">mario_baslr</a>
from @_fel1x). Jump Over ASLR relies on the inner workings of the Branch Target
Buffer where user and kernel branches may collide. When that happens, the CPU
has more work to do and that can be observed. This allows leaking kernel base 
as long as you have offsets of branches hit during a short kernel path you
can trigger at will: you can then leverage the low entropy of KASLR to try
all possible base addresses and find the one where the branches are hit.</p>

<p>For the parameters (the branches to measure) you can really use whatever
you want. I only tried the <span>creat</span> syscall with arguments that cause a
fast return to userland, and then measured whether the <span>sys_creat</span> and
<span>do_sys_open</span> offsets had been hit. The offsets need to be fairly precise
but not to the byte since there seems to be some aliasing going on in the branch
predictor: I originally used <span>__fentry__</span> as an additional branch target
at a +5 offset for both symbols which still worked even though I later learned
these calls get <a href="https://lwn.net/Articles/747256/" target="_blank">dynamically patched out</a>.
</p>

<p>With proper filtering of both false negatives and false positives (essentially
double checking each address) this works like a charm on recent Intel CPUs,
and itâ€™s one of many such techniques that have been published in the past
6 years or so. That makes it something we should be able to rely on as exploit
developers for the foreseeable future. So for a known kernel image at least,
we are essentially back to pre-KASLR times - and keep in mind that itâ€™s a
field I know fairly poorly so other side-channels are probably even better.</p>

<p><strong>Patch gap</strong></p><p>Ok here is what I personally found really interesting because I had never
looked into kernel bug timelines before. This bug was initially reported on
February 28 2020, and fixed in tip on March 3. At this point itâ€™s essentially
public for anyone keeping an eye out for interesting kernel patches - even
if you donâ€™t spend too much time on it, a <span>reported-by</span> Jann Horn is
worth looking into. The main kernel lines were fixed either on March 25 or
April 2. If youâ€™re thinking â€œoh wow one whole monthâ€, please be seated for
whatâ€™s coming.</p>

<p>Some distros applied the patch almost immediately:
</p><ul>
  <li>Arch Linux: Mar 25</li>
  <li>Gentoo: Mar 25</li>
  <li>Fedora: Mar 26</li>
</ul>


<p>I know they are not supposed to target workstations specifically but outside
of personal servers I don't think I have ever seen them used otherwise. The
2nd batch of distributions that fixed the bug is arguably more server-ready:
</p><ul>
  <li>Ubuntu 18.04 LTS: Apr 7</li>
  <li>Ubuntu 16.04 LTS: Apr 24</li>
  <li>Debian Buster â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">https://blog.frizn.fr/linux-kernel/cve-2020-14381</a></em></p>]]>
            </description>
            <link>https://blog.frizn.fr/linux-kernel/cve-2020-14381</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300234</guid>
            <pubDate>Mon, 01 Mar 2021 06:31:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Paying Me]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300165">thread link</a>) | @hiphipjorge
<br/>
February 28, 2021 | https://www.spakhm.com/p/please-stop-paying-me | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/please-stop-paying-me">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few days ago I realized something. I donâ€™t like writing.</p><p>I realized it because I found creative energy to work on programming projects again, and I experience writing programs differently from how I experience having to write. Even the turn of phrase â€œhaving to writeâ€ betrays my disposition toward the craft.</p><p>When Iâ€™m very excited to build products or just program computers for the joy of programming, I dread going to sleep and every part of me <em>cannot wait</em> to wake up and write code again. Iâ€™ve never felt that about writing. Writing has always been a chore. I think Iâ€™ve known this all along, but have never been able to admit this to myself until now.</p><p>When you read anything about anything anywhere, it tells you what great [INSERT CALLING HERE] do. Great startup founders and engineers write well and write a lot because without clear writing there is no clear thinking. I think I bought into that too much for my own good. So it feels liberating to say: <strong>I hate writing.</strong> Itâ€™s painful and laborious and every good piece of writing I make feels like delivering a baby. A rewarding experience for sure, but I think even the most loving of mothers would stop being so loving if she had to deliver a new baby every week.</p><p>One thing that duped me is a lot of positive reenforcement. My best pieces of writing get tens, sometimes hundreds of thousands of readers, and that gives me an addicting sense of elation. I certainly never expected to make money doing it, but enough of you find my writing sufficiently interesting to offer the ultimate seal of approvalâ€” you transfer money from your wallet into mine. I deeply appreciate it, and deeply appreciate you spending time on reading my essays, but unfortunately this isnâ€™t sufficient impetus for me to produce good work. When Iâ€™m forced to write on a schedule, my writing sucks and my life is miserable.</p><p>Which is a good reminder why some of my writing is good. Itâ€™s good when I have something important to say. Important things are hard to say by definitionâ€” if they were easy people would have already talked them out and they probably would have lost their importance. At least theyâ€™re hard to say for me. So when I do it itâ€™s always very slow and painful, and it turns out good because I say something that matters to me in a way that nobody else bothered or managed to say. With my particular idiosyncrasies the intersection of that and the business of running a newsletter is an empty set.</p><p>So please stop paying me. For the folks that have prepaid, Iâ€™m not exactly sure how Substack tooling handles this situation, but shoot me an email and Iâ€™ll figure out how to return a prorated amount.</p><p>I will continue writing. When I have something important to say, Iâ€™ll go through the pain necessary for me to say it. Iâ€™ll also write about my observations as I pursue my product and programming workâ€” technical, anthropological, and simply keeping you up to do date on what Iâ€™m up to. I donâ€™t expect youâ€™ll be hearing from me less often. In fact, Iâ€™m hoping this will allow me to write more. But owing people weekly essays as a matter of business isnâ€™t my tao. For all the reasons above, and primarily because it makes the essays suck, and I donâ€™t like producing bad work.</p><p>Until next week, hopefully. Slava.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/please-stop-paying-me</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300165</guid>
            <pubDate>Mon, 01 Mar 2021 06:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Random effects and penalized splines are the same thing]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300028">thread link</a>) | @whoisnnamdi
<br/>
February 28, 2021 | https://www.tjmahr.com/random-effects-penalized-splines-same-thing/ | <a href="https://web.archive.org/web/*/https://www.tjmahr.com/random-effects-penalized-splines-same-thing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        
        <p>For a long time, Iâ€™ve been curious about something. It is a truth Iâ€™ve
seen casually dropped in textbooks, package documentation, and tweets:
<strong>random effects and penalized smoothing splines are the same thing</strong>. 
It sounds so profound and enlightened. What does it mean? How are they
the same? What deep statistical <em>gnosis</em> was I missing out on?</p>

<p>I have spent months, off and on, trying to understand this equivalence.
I canâ€™t give you the full mathematical treatment, but I have the gist of
it and I can point you to the equations. In this post, I will try to 
highlight the connections between the two.</p>

<p>Here are the main takeaways:</p>

<ul>
  <li>Mixed effects models (a.k.a. hierarchical models or multilevel
models) use partial pooling to strike a balance between a grand
population mean (complete pooling) and individual group means (no
pooling).</li>
  <li>Smoothing splines work by penalizing model coefficients to reduce
the model degrees of freedom.</li>
  <li>You can use the computational machinery of one framework to estimate
the other.</li>
</ul>

<blockquote data-conversation="none" data-lang="en" data-dnt="true" data-theme="light">
  <p lang="en" dir="ltr">Sadly, I feel like my career has peaked with the creation of this meme <a href="https://t.co/5ilRFonsy7">pic.twitter.com/5ilRFonsy7</a></p>

  <img src="https://www.tjmahr.com/assets/images/spider-smooth.jpg" alt="Spiderman (Penalized smooths) pointing at (and being pointed at) by Spiderman (Random effects)">
  <br>
  â€” Eric Pedersen (@ericJpedersen) <a href="https://twitter.com/ericJpedersen/status/1293508069016637440?ref_src=twsrc%5Etfw">August 12, 2020</a>
</blockquote>

<h2 id="mixed-model-review">Mixed model review</h2>

<p>Letâ€™s review what these things means. Mixed effects models,
<a href="https://www.tjmahr.com/another-mixed-effects-model-visualization/">apparently</a> the <a href="https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/">main
focus</a> of <a href="https://www.tjmahr.com/iccbot-comes-online/">this
blog</a> over the years, are used to estimate
â€œrandomâ€ or â€œvaryingâ€ effects. Here is the classic equation set up:</p>

\[\mathbf{y} = \mathbf{X\beta} + \mathbf{Zb} + \mathbf{\epsilon} \\
\mathbf{b} \sim \textsf{Normal}(0, \sigma_b) \\
\mathbf{\epsilon} \sim \textsf{Normal}(0, \sigma_y) \\
\mathbf{X}: \textrm{fixed effects model matrix} \\
\mathbf{Z}: \textrm{random effects model matrix} \\
\sigma_b, \sigma_y : \textrm{variance components} \\
\sigma_b : \textrm{where the magic happens} \\\]

<p>The magic here is the <em>Ïƒ</em><sub><em>b</em></sub>, as it ties all of the
individual effects in <strong>b</strong> under a common distribution. If
<em>Ïƒ</em><sub><em>b</em></sub> were replaced with a fixed number like 10, then all
of the effects in <strong>b</strong> would be independent and unaware of each other:
There would be <em>no pooling</em> of information between the groups. If we
remove it from the modelâ€”replace <em>Ïƒ</em><sub><em>b</em></sub> with 0, so to
speakâ€”then all the group variability is ignored, and there is
<em>complete pooling</em> of information into a single mean effect. With 
<em>Ïƒ</em><sub><em>b</em></sub> all the groups can contribute information about the 
distribution of plausible effects, and so, there can be 
<em>partial pooling</em> of information between groups.</p>

<p>Consider the <a href="https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html" title="Documentation on the radon dataset"><code>radon</code> dataset</a> example from <a href="https://amzn.to/3aVa9tB" title="An Amazon Affliate link to Gelman and Hill">Gelman and Hill
(2007)</a>. Radon measurements were taken in Minnesota
counties. We would like to estimate the average radon measurement for
each county. We have a repeated measures situation, and some counties
have more observations than others. We use a Bayesian mixed effects
model with <a href="https://github.com/paul-buerkner/brms">brms</a> to estimate a
population distribution of county estimates, and the county-level
estimates are randomly varying effects. They are drawn from a random
distribution, the scale of which we estimate from the data.</p>

<div><div><pre><code><span>library</span><span>(</span><span>tidyverse</span><span>)</span><span>
</span><span>theme_set</span><span>(</span><span>theme_grey</span><span>(</span><span>base_size</span><span> </span><span>=</span><span> </span><span>14</span><span>))</span><span>
</span><span>library</span><span>(</span><span>brms</span><span>)</span><span>
</span><span>radon</span><span> </span><span>&lt;-</span><span> </span><span>rstanarm</span><span>::</span><span>radon</span><span>

</span><span>b_radon</span><span> </span><span>&lt;-</span><span> </span><span>brm</span><span>(</span><span>
  </span><span>log_radon</span><span> </span><span>~</span><span> </span><span>1</span><span> </span><span>+</span><span> </span><span>(</span><span>1</span><span> </span><span>|</span><span> </span><span>county</span><span>),</span><span> 
  </span><span>radon</span><span>,</span><span> 
  </span><span>family</span><span> </span><span>=</span><span> </span><span>gaussian</span><span>,</span><span> 
  </span><span>file</span><span> </span><span>=</span><span> </span><span>"radon"</span><span>
</span><span>)</span><span>
</span><span>b_radon</span><span>
</span><span>#&gt;  Family: gaussian </span><span>
</span><span>#&gt;   Links: mu = identity; sigma = identity </span><span>
</span><span>#&gt; Formula: log_radon ~ 1 + (1 | county) </span><span>
</span><span>#&gt;    Data: radon (Number of observations: 919) </span><span>
</span><span>#&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span><span>
</span><span>#&gt;          total post-warmup samples = 4000</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Group-Level Effects: </span><span>
</span><span>#&gt; ~county (Number of levels: 85) </span><span>
</span><span>#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; sd(Intercept)     0.30      0.05     0.22     0.40 1.00     1782     2894</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Population-Level Effects: </span><span>
</span><span>#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; Intercept     1.35      0.05     1.26     1.45 1.00     2749     3198</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Family Specific Parameters: </span><span>
</span><span>#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; sigma     0.77      0.02     0.73     0.80 1.00     7374     3105</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS</span><span>
</span><span>#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span><span>
</span><span>#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span><span>
</span></code></pre></div></div>

<p>Here <code>sd(Intercept)</code> corresponds to <em>Ïƒ</em><sub><em>b</em></sub>.</p>

<p>We can plot the observed county means alongside the model estimated
ones. First, I do some wrangling so that the difference between observed
means and estimated means are computed for use later on.</p>

<div><div><pre><code><span>radon_aug</span><span> </span><span>&lt;-</span><span> </span><span>radon</span><span> </span><span>%&gt;%</span><span>
  </span><span># add ns and means</span><span>
  </span><span>group_by</span><span>(</span><span>county</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>mutate</span><span>(</span><span>
    </span><span>observed_mean</span><span> </span><span>=</span><span> </span><span>mean</span><span>(</span><span>log_radon</span><span>),</span><span>
    </span><span>county_n</span><span> </span><span>=</span><span> </span><span>n</span><span>()</span><span>
  </span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span> 
  </span><span># add fitted values</span><span>
  </span><span>tidybayes</span><span>::</span><span>add_fitted_draws</span><span>(</span><span>b_radon</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>mutate</span><span>(</span><span>
    </span><span>observed_minus_model</span><span> </span><span>=</span><span> </span><span>observed_mean</span><span> </span><span>-</span><span> </span><span>.value</span><span> 
  </span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span># summarize fitted values</span><span>
  </span><span>ggdist</span><span>::</span><span>median_qi</span><span>(</span><span>.value</span><span>,</span><span> </span><span>observed_minus_model</span><span>)</span><span> 

</span><span>radon_aug</span><span>$</span><span>type</span><span> </span><span>&lt;-</span><span> </span><span>"mixed model estimates"</span><span>
</span><span>radon</span><span>$</span><span>type</span><span> </span><span>&lt;-</span><span> </span><span>"observed means"</span><span>

</span><span>ggplot</span><span>(</span><span>radon_aug</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>aes</span><span>(</span><span>
    </span><span>x</span><span> </span><span>=</span><span> </span><span>fct_rev</span><span>(</span><span>fct_infreq</span><span>(</span><span>county</span><span>)),</span><span> 
    </span><span>y</span><span> </span><span>=</span><span> </span><span>log_radon</span><span>,</span><span> 
    </span><span>color</span><span> </span><span>=</span><span> </span><span>type</span><span>,</span><span> 
    </span><span>shape</span><span> </span><span>=</span><span> </span><span>type</span><span>
  </span><span>)</span><span> </span><span>+</span><span>
  </span><span>stat_summary</span><span>(</span><span>data</span><span> </span><span>=</span><span> </span><span>radon</span><span>,</span><span> </span><span>fun</span><span> </span><span>=</span><span> </span><span>mean</span><span>,</span><span> </span><span>geom</span><span> </span><span>=</span><span> </span><span>"point"</span><span>)</span><span> </span><span>+</span><span>
  </span><span>geom_point</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>.value</span><span>))</span><span> </span><span>+</span><span> 
  </span><span># Want to include y = 0 in the figure</span><span>
  </span><span>geom_blank</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>0</span><span>))</span><span> </span><span>+</span><span>
  </span><span>labs</span><span>(</span><span>
    </span><span>x</span><span> </span><span>=</span><span> </span><span>"county (in increasing order by sample size)"</span><span>,</span><span> 
    </span><span>y</span><span> </span><span>=</span><span> </span><span>"log(radon)"</span><span>
  </span><span>)</span><span> </span><span>+</span><span>
  </span><span>geom_hline</span><span>(</span><span>yintercept</span><span> </span><span>=</span><span> </span><span>fixef</span><span>(</span><span>b_radon</span><span>)[</span><span>1</span><span>])</span><span> </span><span>+</span><span>
  </span><span>scale_color_manual</span><span>(</span><span>values</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>"blue"</span><span>,</span><span> </span><span>"grey40"</span><span>))</span><span> </span><span>+</span><span>
  </span><span>labs</span><span>(</span><span>color</span><span> </span><span>=</span><span> </span><span>NULL</span><span>,</span><span> </span><span>shape</span><span> </span><span>=</span><span> </span><span>NULL</span><span>)</span><span> </span><span>+</span><span>
  </span><span>theme</span><span>(</span><span>
    </span><span>axis.text.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>axis.ticks.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>panel.grid.major.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>panel.grid.minor.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>legend.title</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>legend.position</span><span> </span><span>=</span><span> </span><span>"top"</span><span>,</span><span> 
    </span><span>legend.direction</span><span> </span><span>=</span><span> </span><span>"horizontal"</span><span>,</span><span>
    </span><span>legend.justification</span><span> </span><span>=</span><span> </span><span>"left"</span><span>,</span><span>
  </span><span>)</span><span> 
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/county-means-1.png" title="A plot showing log radon on the y axis and county on the x asis. There are two sets of overlapping points. There are the observed means in each country and the model estimated means. There is much less variability in the modeled means." alt="A plot showing log radon on the y axis and county on the x asis. There are two sets of overlapping points. There are the observed means in each country and the model estimated means. There is much less variability in the modeled means." width="80%"></p>

<p>We see a classic example of partial pooling. First note that model
estimates (blue circles) are less variable: None go above <em>y</em> = 2 and
only four go below <em>y</em> = 1. For counties with many observations (right
side), the estimated mean is hardly adjusted. There is less of a visual
gap between the observed mean and estimated mean. For counties with less
data (left side), the estimate is pulled towards the population mean
(<code>Intercept</code> in the summary above).</p>

<p>The following plot shows difference between the observed means and
the estimated means, subtracting the grey triangles from the blue squares
in the plot above.</p>

<div><div><pre><code><span>radon_aug</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span> 
  </span><span>distinct</span><span>(</span><span>county</span><span>,</span><span> </span><span>county_n</span><span>,</span><span> </span><span>observed_minus_model</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ggplot</span><span>()</span><span> </span><span>+</span><span> 
    </span><span>aes</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>county_n</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>observed_minus_model</span><span>)</span><span> </span><span>+</span><span> 
    </span><span>geom_point</span><span>(</span><span>alpha</span><span> </span><span>=</span><span> </span><span>.5</span><span>)</span><span> </span><span>+</span><span>
    </span><span>labs</span><span>(</span><span>
      </span><span>x</span><span> </span><span>=</span><span> </span><span>"Number of observations in county"</span><span>,</span><span>
      </span><span>y</span><span> </span><span>=</span><span> </span><span>"Observed mean - estimated mean"</span><span>
    </span><span>)</span><span> 
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/shrinkage-by-n-1.png" title="Plot with number of observations on the x axis and the difference between the observed and estimated means on the y axis. There is a smaller difference for counties with more data." alt="Plot with number of observations on the x axis and the difference between the observed and estimated means on the y axis. There is a smaller difference for counties with more data." width="66%"></p>

<p>The contention behind the <em>smooths = random effects</em> claim is that what we
just did is a case of <em>smoothing</em>. These random effects are, in a way, 
smoothed fixed effects.</p>

<blockquote>
  <p>The function <code>random()</code> can be seen as a smoother for use with factors
in <code>gamlss()</code>. It allows the fitted values for a factor predictor to
be shrunk towards the overall mean [â€¦]</p>

  <p>â€” <a href="https://rdrr.io/cran/gamlss/man/random.html" title="random: Specify a random intercept model in a GAMLSS formula">GAMLSS documentation</a> describing a random intercept as a smoother</p>
</blockquote>

<h2 id="but-whats-smoothing">But whatâ€™s smoothing?</h2>

<p>Now letâ€™s walk through a generalized additive model in
<a href="https://cran.r-project.org/web/packages/mgcv/index.html">mgcv</a> to
demonstrate a penalized smoothing spline. That was a mouth full, but
basically additive models are like the smoothing expansion pack for the
standard linear model. Weâ€™re still doing regression, but we have some
new syntax and our models can do nonlinear relationships more easily
now.</p>

<p>I will walk through a basic example of how a splineâ€™s basis functions
are weighted to approximate a nonlinear trend, but this is not going to
be a full tutorial. Other people have made video introductions to
<a href="https://youtu.be/Zxokd_Eqrcg?t=506" title="Dr. Gavin Simpson - Learning When, Where, and by How Much, Things Change [Remote]">additive models</a> or the <a href="https://youtu.be/q4_t8jXcQgc" title="Noam Ross - Nonlinear Models in R: The Wonderful World of mgcv">mgcv package</a>. I first
learned them from <a href="https://arxiv.org/abs/1703.05339" title="Generalised additive mixed models for dynamic analysis in linguistics: a practical introduction">a tutorial for linguists</a> and then from
<a href="https://amzn.to/37PLa8W" title="An Amazon Affliate link to Simon Wood's GAM textbook">the mgcv textbook</a>, but there are <a href="https://github.com/noamross/gam-resources" title="Resources for Learning About and Using GAMs in R">other resources
online</a>.</p>

<p>We use the <a href="https://rdrr.io/pkg/MASS/man/mcycle.html" title="Documentation on the mcycle dataset"><code>mcycle</code></a> dataset which gives the head
acceleration in a simulated motorcycle accident. We are going to fit a
model, plot the smooth from it, and then we are going to work through
what the model did.</p>

<div><div><pre><code><span>library</span><span>(</span><span>mgcv</span><span>)</span><span>

</span><span>mcycle</span><span> </span><span>&lt;-</span><span> </span><span>MASS</span><span>::</span><span>mcycle</span><span> </span><span>%&gt;%</span><span> 
  </span><span>tibble</span><span>::</span><span>rowid_to_column</span><span>()</span><span>

</span><span># Fit the model</span><span>
</span><span>gam_20</span><span> </span><span>&lt;-</span><span> </span><span>gam</span><span>(</span><span>
  </span><span>accel</span><span> </span><span>~</span><span> </span><span>1</span><span> </span><span>+</span><span> </span><span>s</span><span>(</span><span>times</span><span>,</span><span> </span><span>bs</span><span> </span><span>=</span><span> </span><span>"cr"</span><span>,</span><span> </span><span>k</span><span> </span><span>=</span><span> </span><span>20</span><span>),</span><span> 
  </span><span>data</span><span> </span><span>=</span><span> </span><span>mcycle</span><span>,</span><span> 
  </span><span>method</span><span> </span><span>=</span><span> </span><span>"REML"</span><span>
</span><span>)</span><span>

</span><span>mcycle</span><span>$</span><span>.fitted</span><span> </span><span>&lt;-</span><span> </span><span>fitted</span><span>(</span><span>gam_20</span><span>)</span><span>

</span><span>ggplot</span><span>(</span><span>mcycle</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>aes</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>times</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>accel</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>geom_point</span><span>(</span><span>alpha</span><span> </span><span>=</span><span> </span><span>.5</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>geom_line</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>.fitted</span><span>),</span><span> </span><span>color</span><span> </span><span>=</span><span> </span><span>"blue"</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>labs</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>"time after impact [ms]"</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>"acceleration [g]"</span><span>)</span><span>
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/smooth-demo-1.png" title="Scattplot showing time on the x axis and acceleration on the y axis. The model fit is shown in blue. It makes two big turns down and then up." alt="Scattplot showing time on the x axis and acceleration on the y axis. The model fit is shown in blue. It makes two big turns down and then up." width="80%"></p>

<p>So what happened here? We will cover it visually.</p>

<h3 id="splines-are-the-sums-of-weighted-wiggles">Splines are the sums of weighted wiggles</h3>

<p>Letâ€™s look at the regression formula.</p>

<div><div><pre><code><span>formula</span><span>(</span><span>gam_20</span><span>)</span><span>
</span><span>#&gt; accel ~ 1 + s(times, bs = "cr", k = 20)</span><span>
</span></code></pre></div></div>

<p>We told <code>gam()</code> to estimate <code>accel</code> using an intercept term and a smooth
term on the time predictor (<code>s(times, ...)</code>). Specifically, we created
our smooth using a cubic regression spline basis (<code>bs = "cr"</code>) with <code>k
= 20</code> - 1 curves. Our model is
estimating a function by adding up smaller components called <em>basis
functions</em>, and the space that defines those components is the <em>basis</em>.
These basis functions are weighted and summed together to produce a
smooth trend called a <em>spline</em>. The name <em>splines</em> is inspired by
drafting splines which are flexible strips of wood that can be weighted
and anchored in place to make a nice curve.</p>

<p>To reiterate, conceptually, we are decomposing the <code>times</code> predictor
into a bunch of individual wiggly lines (basis functions), and these are
weighted and summed together to approximate some nonlinear function. My
post on <a href="https://www.tjmahr.com/polypoly-package-released/">orthogonal polynomials</a>
illustrates the same principle but with polynomial basis functions.
Richard McElreath provides <a href="https://youtu.be/ENxTrFf9a7c?t=2226" title="Statistical Rethinking Winter 2019 Lecture 04">a friendly 30-minute introduction
splines</a> in a Bayesian model in his Statistical
Rethinking course. One line I appreciate from his description is that
with splines, we replace a predictor variable, like <code>times</code>, with a set
of â€œsyntheticâ€ predictor variables.</p>

<figure>
  <img src="https://www.tjmahr.com/assets/images/2021-02-spline.png" alt="An illustration of a drafting spline."><figcaption>
      A drafting spline is a flexible strip of wood that is anchored at a few points so that one can create smooth curves. â€¦</figcaption></figure></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tjmahr.com/random-effects-penalized-splines-same-thing/">https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</a></em></p>]]>
            </description>
            <link>https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300028</guid>
            <pubDate>Mon, 01 Mar 2021 05:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animated PNG vs. Animated Webp vs. GIF]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300015">thread link</a>) | @panabee
<br/>
February 28, 2021 | https://corydowdy.com/blog/apng-vs-webp-vs-gif | <a href="https://web.archive.org/web/*/https://corydowdy.com/blog/apng-vs-webp-vs-gif">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>With Chrome now supporting Animated PNG as of Chrome 59 we have two image formats that can supplant the old and tired GIF format. Varying posts and sites have different conclusions on when to use APNG versus an animated Webp. In all my findings (linked below where the source Gif comes from) animated webp beats apng in filesize each and every time. Sometimes by not very much. This of course is anecdotal and I'm not as familiar with apng as the creators and others may be so they may be able to squeeze more out of an apng than I can.</p>

<p>All that being said I've heard and read people say "APNG might be bigger but webp takes longer to decode in the browser". That assumes the larger APNG will load faster than the smaller webp. Is that the case though? I assume the smaller webp gets downloaded to the client faster then it'll start decoding faster. Thus animating faster. So lets actually test that instead of me spouting off haha. On to the source GIF.</p>

<p>The GIF I'm using for this post comes from my post on <a href="https://corydowdy.com/blog/converting-mp4-to-webm">Converting MP4 To Webm <span>&nbsp;</span></a>. That was a 1080p video stripped down to about 5 seconds and resized to a width of 800.</p>

<p>Here are the relevant details of the unoptimized GIF:</p>

<ul>
<li>Dimensions: 800x450</li>
    <li>Length: 5s</li>
    <li>Size: â‰ˆ37.9MB</li>
</ul>
<h2>Setup</h2>

<p>Before we can even embark on this trip we have to convert the GIF above to an APNG and an Animated Webp. Maybe you can convert the GIF on this page to an APNG and get better results. Please try I don't want to dismiss APNG as much as I think I'm probably coming off as.</p>

<h3>Converting to an Animated PNG (apng)</h3>

<p>Gif2apng offers three different options for converting a GIF to an animated PNG. We have zlib, 7zip and Zopfli compression. Each compression option besides zlib allows you to set an iteration amount which defaults to 15.</p>

<p>I'm using gif2apng version 1.9 <a href="#footnotes-apng">[ 1 ] [ 2 ]</a>. For both 7zip and zopfli I'll use the "default" iterations of 15 and a more aggressive version of 100. Be warned if you want to do this. Depending on your server specs or locally on your own computer and it's specs Zopfli will take a long time. Increasing the iterations for either of the compression algorithms will also increase how long it takes to convert your image to an APNG. Be prepared to set aside a pretty big chunk of time if you do this on your computer :).</p>

<p>After converting the GIF to an Animated PNG I'll also run it through APNGOPT. This should "optimize" the Animated PNG. This too offers differing amount of iterations. I'll use the "default" of 15 for each apng that was converted with the defaults above and 100 for all the 100 iterations.</p>

<h4>APNG Filesize Results</h4>



<p>We can see that Zopfli compression saves the most before running these through apngopt. It's very CPU intensive though. After running these through apngopt things didn't change much or at all.</p>

<div>
<table>
<caption>Filesize of APNG after using APNGOPT</caption>
    <thead><tr>
<th>Compression Type</th>
            <th>Original Size in MB</th>
            <th>APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th>Unoptimized Gif</th>
            <td>â‰ˆ37.9MB</td>
            <td></td>
        </tr>
<tr>
<th>Animated PNG with Zlib</th>
            <td>â‰ˆ33.01MB</td>
            <td>â‰ˆ33.04MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 15 iterations</th>
            <td>â‰ˆ31.22MB</td>
            <td>â‰ˆ31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 100 iterations</th>
            <td>â‰ˆ31.22MB</td>
            <td>â‰ˆ31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 15 iterations</th>
            <td>â‰ˆ30.92MB</td>
            <td>â‰ˆ30.91MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 100 iterations</th>
            <td>â‰ˆ30.87MB</td>
            <td>â‰ˆ30.86MB</td>
        </tr>
</tbody>
</table>
</div>

<h5 id="apng-footnote-label">APNG Footnotes</h5>

<ol id="footnotes-apng">
<li>On a windows machine just use the GUI they package from sourceforge. It seems to be the most up to date. I haven't had the time to see if the GUI and CLI differ in anyway so that'll be up to you unless you're ok with the output of the GUI then keep on keepin on!</li>
    <li>If you install gif2apng through your OS's package manager (ie: apt-get/apt) depending on your OS's you'll more than likely get version 1.7.</li>
    <li>Depending on your OS again if you use the CLI version of apngopt you'll get versions ranging from 1.1 to 1.4.</li>
</ol>
<h2>Animated Webp</h2>

<p>The same reference gif was converted to a webp using three different options and WebP Encoder version: 0.6.0 (WebP Mux version: 0.4.0).</p>

<p>I didn't dive into the different CLI options available for gif2webp. Things such has <code> -kmin </code> , <code> -kmax </code> â€” which specify the minimum and maximum distance between consecutive key frames and can improve decoding performance â€” or adjust the deblocking filter <code> -f </code> from the docs suggested 50. These could with adjustments and tweaking produce smaller or in some instances bigger files. You'll have to test those out for specific images, or use the defaults such as I have.</p>

<ul>
<li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.default.webp">It's default settings (quality 75) <span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.webp">quality of 70 and 6 (-m 6) for the compression mode. It's highest.<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.webp">A quality of 70 with default compression of 4 (lossless)<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.mixed.webp">an unfair mixed mode (lossless and lossy compression) with a quality of 70<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.mixed.webp">another unfair Quality 70 with Commpression of 6 &amp; Mixed compression (lossy and lossles)<span>&nbsp;</span></a></li>
</ul>
<p>Webp at it's default settings beats (barely) each of the converted APNG's, 30.86MB for the Webp compared to 33.01MB using default APNG settings (zlib) and 30.87MB using zopfli compression @ 100 iterations.</p>

<div>
<table>
<caption>Filesize of Webp &amp; Optimized APNG</caption>
    <thead><tr>
<th>File</th>
            <th>Quality</th>
            <th>Compression Mode</th>
            <th>Webp Size in MB</th>
            <th>Best APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th rowspan="5">Animated Webp</th>
            <td>Default (75)</td>
            <td>Default (4)</td>
            <td>â‰ˆ30.82MB</td>
            <td rowspan="5">â‰ˆ30.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>6 highest</td>
            <td>â‰ˆ31.80MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Default (4)</td>
            <td>â‰ˆ30.82MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed</td>
            <td>â‰ˆ5.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed &amp; 6 (highest)</td>
            <td>â‰ˆ5.32MB</td>
        </tr>
</tbody>
</table>
</div>

<p>Ok cool all the file size mumbo jumbo is out of the way. Does a few kb/mb matter when they are so close? The default webp settings gives us the same size file of an apng using apngout and zopfli @ 100 iterations.</p>

<p>Yep. The larger apng will in fact decode faster. But does that matter? Kind of.</p>
<!-- /#setup --><h2>Summoning the WebPageTest Gods!</h2>

<p>Typically in a situation like this I would use <a href="http://www.webpagetest.org/video/">Webpagetest's "visual comparison" <span>&nbsp;</span></a> option that way we could see the pages load side by side. I'd run a desktop test and then I'd run a mobile test using the "emerging markets" settings. I can't right now since as mentioned above APNG support is in Chrome 59+. The visual comparison tool uses the current stable release of Chrome (which just happened to be updated while I was testing these out. Still to be sure I ran with the Canary version). What most everyone using a non dev/beta version of Chrome uses.</p>

<p>So I'm running these tests on Chrome Canary and will use the median from the first view as the comparison. I'll run each image option/type three (3) times on Chrome desktop using a cable connection â€” 5Mbps 28ms Latency â€” and three times using a Fourth Generation Moto G and their "Mobile 3g" connection â€” 768 Kbps 3G connection with 300ms of latency.</p>
<h3>Webp Defaults vs. Best Animated PNG</h3>

<p>The first comparison I ran is the default settings of gif2webp. As mentioned above this defaults to a quality of 75, compression mode of 4 and is lossless like APNG. You can download these animated images and run them yourself. You'll see which actually loads faster without even having to read haha.</p>

<p>Webp at it's default settings might in fact be smaller in file size (for this particular animation) than the APNG. It helps in the fact that we are sending less bytes down the wire but as for over all page load performance you can see below it's not helping much or if any at all.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Desktop Cable Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>3108</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>44.7s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>53.341s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.984s</td>
        </tr>
</tbody>
</table>
</div>

<p>Here we can see the visual differences between both of these formats.</p>



<p>These are large files. You're doing yourself and your users a disservice if you send these big honking things down the wire to them.</p>

<h3>Webp and APNG on Mobile 3g Connection</h3>

<p>Webp's defaults will help you out on a a slow 3g connection because it's sending less data. APNG gets frames faster to the screen since it decodes faster, hence the better speed index below.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Mobile 3g Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-mobile.png" title="Webp Defaults Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-mobile-3g.png" title="APNG Zopfli 100 Iterations Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>5157</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>41.014s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>4.485s</td>
            <td>3.327s</td>
        </tr>
</tbody>
</table>
</div>



<p>So don't use APNG nor the Webp Defaults on a slow connection in my opinion. They are big files.</p>

<h2>Your Best Bet</h2>

<p>So is there a solution for smaller file size than gif and that actually helps your page performance? Yes if you don't mind a possible lossy compressed image.</p>

<p>We can take the Webp image converted with the defaults, the mixed compression (lossy &amp; lossless), the lossy converted webp, and a lossy compressed and filtered webp image and compare those to the "best" file size wise APNG and an unoptimized GIF.</p>

<p>Before I show you those here are the numbers from those runs on a desktop.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Desktop Cable Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>962</td>
            <td>785</td>
            <td>882</td>
            <td>3108</td>
            <td>2282</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>1.200s</td>
            <td>4.400s</td>
            <td>4.200s</td>
            <td>44.7s</td>
            <td>45.100s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>11.600s</td>
            <td>11.446s</td>
            <td>9.734s</td>
            <td>53.341s</td>
            <td>66.486s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.879s</td>
            <td>0.681s</td>
            <td>0.783s</td>
            <td>0.984s</td>
            <td>0.778s</td>
        </tr>
<tr>
<th></th>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-desktop.png" title="Webp Lossy Desktop Cable Connection">test screenshot </a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-filtered-desktop.png" title="Webp Lossy &amp; Filtered Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-mixed-desktop.png" title="Webp Mixed Compression Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/gif-desktop.png" title="Unoptimized GIF Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
        </tr>
</tbody>
</table>
</div>

<p>Here is the visual comparison.</p>



<p>What I was most surprised by was how close a default settings animated webp and an unoptimized gif page load times and speed index were.</p>

<p>These aren't fair comparision to APNG either since there is lossy compression. There's also high variance in the load times. Much like you'd have in a real world scenario. So take these results with a grain of salt. I didn't put much effort into making them all variable free.</p>

<h3>APNG and Webp Mobile 3g</h3>

<p>Where you'll get the most benefit with this animated webp is on a slow 3g connection.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Mobile 3g Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>37.631s</td>
            <td>37.408s</td>
            <td>31.839s</td>
            <td>146.060s</td>
            <td>124.712s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>3811</td>
            <td>3964</td>
            <td>3858</td>
            <td>5157</td>
            <td>29382</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>6.871s</td>
            <td>34.057s</td>
            <td>30.033s</td>
            <td>41.014s</td>
            <td>106.860s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td></tr></tbody></table></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corydowdy.com/blog/apng-vs-webp-vs-gif">https://corydowdy.com/blog/apng-vs-webp-vs-gif</a></em></p>]]>
            </description>
            <link>https://corydowdy.com/blog/apng-vs-webp-vs-gif</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300015</guid>
            <pubDate>Mon, 01 Mar 2021 05:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[7 Reasons not to join a startup and 1 reason to]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299940">thread link</a>) | @czhu0217
<br/>
February 28, 2021 | https://huyenchip.com/2021/02/27/why-not-join-a-startup.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In 2018, I wrote <a href="https://huyenchip.com/2018/10/08/career-advice-recent-cs-graduates.html">Career advice for recent Computer Science graduates</a> about joining a big company instead of a startup after college.</p>

<p>In 2019, when I left NVIDIA, I wrote <a href="https://huyenchip.com/2019/12/23/leaving-nvidia-lessons.html">Lessons learned after my first full-time job</a> about leaving a big company for a startup.</p>

<p>Now that Iâ€™ve left my first full-time job at a startup, I want to revisit the topic. This is based on some personal experience, but most come from friendsâ€™ experiences, including the intensive note on startups from a friend who had worked at 3 startups before and who would like to remain anonymous. I hope that itâ€™ll give some pointers to those trying to decide whether to take the leap.</p>

<p>Some asked if this post is about Snorkel. Itâ€™s not. Snorkel is an exception. Itâ€™s a great startup, which is a reason why I joined in the first place, and I recommend it to all my friends who are looking to join a startup.</p>

<p><strong>Disclaimer</strong>:</p>
<ol>
  <li>Each of the points below is true for many startups, but not for all startups, and itâ€™s more true for early-stage startups (e.g. before series B). There are always exceptions, extreme exceptions, unreasonable exceptions, which make the startup world so exciting.</li>
  <li>A friend told me that these points are only true for bad startups. Most startups are, unfortunately, bad startups.</li>
</ol>

<hr>
<p><b>Table of contents</b><br>
â€¦. <a href="#why_not_join_a_startup">7 reasons not to join a startup</a><br>
â€¦â€¦.. <a href="#1_work_life_balance">Reason 1. Goodbye work-life balance</a><br>
â€¦â€¦.. <a href="#2_bad_engineering">Reason 2. Youâ€™ll pick up bad engineering practices</a><br>
â€¦â€¦.. <a href="#3_mentorship">Reason 3. Less mentorship</a><br>
â€¦â€¦.. <a href="#4_equity">Reason 4. You wonâ€™t get rich</a><br>
â€¦â€¦.. <a href="#5_management">Reason 5. Bad management</a><br>
â€¦â€¦.. <a href="#6_enjoyment">Reason 6. You might have to do a lot of things you donâ€™t want to do</a><br>
â€¦â€¦.. <a href="#7_career_growth">Reason 7. No clear career growth trajectory</a><br>
â€¦. <a href="#why_join_a_startup">One reason to join a startup</a><br>
â€¦. <a href="#next">Whatâ€™s next for me?</a><br></p>

<hr>

<h2 id="why_not_join_a_startup">7 reasons not to join a startup</h2>

<h3 id="1_work_life_balance">Reason 1. Goodbye work-life balance</h3>

<p>A friend at a tech giant told me that he and his co-workers once mused about how long they could go on not working until someone noticed. The answers were between a week and two months. At an early-stage startup, the answer is likely a couple of hours.</p>

<p>My transition from NVIDIA to Snorkel was a culture shock. At NVIDIA, you can have a predictable schedule, e.g. coming in at 9am and leaving at 6pm every day. If you donâ€™t finish something by Friday afternoon, just push the deadline to next week and go to happy hour. Itâ€™s okay, even expected, to not check emails or Slack for the entire weekend.</p>

<p>On my first day at Snorkel, when I left at 7pm, I was the first one to leave.</p>

<p>Nobody told me how to spend my time, but when everyone else worked over the weekend and responded to my Slack messages any time of the night, I wanted to do the same. Nobody forced me to take on a hefty task that would require me to cancel plans with friends, but I also knew that everybody else had their hands full and if I didnâ€™t do it, we wouldnâ€™t be able to finish this feature on time and the company would lose a contract or even die.</p>

<p>By the time that I left, the work-life balance had got a lot more balanced. Snorkel had hired a ton more people to share the workload and we had worked out processes to speed things up.</p>

<p>In general, Iâ€™ve observed that the bigger the startup, the better the work-life balance. Possible explanations:</p>

<ol>
  <li>The earlier the startup, the more precarious its survival, and the harder everyone has to push.</li>
  <li>In very early-stage startups, the working culture is dominated by those with high ownership in the company (the founding team), who are incentivized to work harder. Later on, the working culture is dominated by people with much lower ownership in the company (e.g. 0.1% over 4 years for the 20th engineer vs. 20% for the founder), who are more incentivized to keep a work-life balance.</li>
</ol>

<p><strong>Caveat</strong>: The work-life balance at an early-stage startup depends a lot on how much the existing team members work. When interviewing at a startup, donâ€™t ask the founders how much they value work-life balance (theyâ€™ll say â€œA lotâ€), but ask every team member you can talk to how much they work. If all of them work during evenings and weekends, you might likely feel pressured to do the same.</p>

<h3 id="2_bad_engineering">Reason 2. Youâ€™ll pick up bad engineering practices</h3>

<p>Consider the following scenario. A customer requires a new feature and you have to deliver it in a week. This feature is similar to one of your existing features, so the best solution is to refactor the existing code to allow some of it to be reused.</p>

<p>However, refactoring alone would require a week. Your tech lead decides that you should just duplicate the existing code and turn it into a new feature. Now you have two massive code structures that are similar but not quite. When making changes to one structure, you have to remember to change the other too.</p>

<p>Then, somebody forgets and a wild bug appears. The person assigned to fix it isnâ€™t given a lot of time, so instead of investigating the duplicate code, they write a hacky function on top.</p>

<p>Startups build 1 from 0, something from nothing. <em>Adding new things fast</em> takes precedence over both <em>adding good things slow</em> and <em>fixing existing things</em>. You might get used to writing quick and dirty code, <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">cargo cult programming</a>, merging code that has no tests, merging before tests complete, committing without comments, spaghetti code, magic numbers.</p>

<p>Bad practices might be a mere dissatisfaction at first, but can gradually become a habit, then become the only way you know how to work.</p>

<h3 id="3_mentorship">Reason 3. Less mentorship</h3>

<p>The thing I missed the most when leaving NVIDIA was mentorship. Large companies, by virtue of having a lot of employees, tend to have many people whose diverse life experience can provide you invaluable advice. At NVIDIA, I could come to my mentors for questions from general career dilemmas to obscure engineering knowledge. Once in a while, I browsed the org chart of tens of thousands of employees, identified people I want to learn from, and asked them to meet at the coffee machine, which they usually accepted.</p>

<p>Startups donâ€™t have that many people for you to reach out to in the first place. Your handful of coworkers might have backgrounds and experiences similar to yours (cue founders who say they prefer hiring from their existing networks) and are unlikely to give you dramatically different perspectives. Even if there are people who could mentor you, given the pace at which startups move, they might not have the time for it.</p>

<p>To be clear, you can still learn a lot from your coworkers at startups, just a different kind of learning.</p>

<h3 id="4_equity">Reason 4. You wonâ€™t get rich</h3>

<p>Despite a plethora of articles warning people that joining startups is a bad way to get rich (<a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/">1</a>, <a href="https://danluu.com/startup-tradeoffs/">2</a>, <a href="https://hunterwalk.medium.com/sorry-startup-employee-100-your-equity-probably-won-t-make-you-rich-d6549ece71bd">3</a>), many people still think joining a startup is a get-rich-quick scheme. Hereâ€™s the gist of the math. Imagine youâ€™re an <strong>engineer with 2-3 years of experience</strong>.</p>

<p>If you join a startup as the <strong>15th engineer</strong> (not executive), your compensation might look like the following.</p>

<ol>
  <li><strong>Base salary</strong>: Your base salary is usually lower than you would have got at a big company (e.g. <strong>$120K instead of $160K</strong>) because at startups, equity makes a large chunk of your compensation.</li>
  <li><strong>Equity</strong>: You might get <strong>0.05% - 0.25%</strong> equity vested over <strong>4 years</strong>. After subsequent fundraising rounds, this amount of equity is diluted to <strong>0.02% - 0.1% for 4 years</strong>.</li>
</ol>

<table>
    
  <tbody><tr>
   <td>
<strong>Probability<br>(</strong>appx<strong>)</strong>
   </td>
   <td><strong>Startup scenario</strong>
   </td>
   <td><strong>Startup value</strong>
   </td>
   <td><strong>Your equity value<br>over 4 year</strong>
   </td>
   <td><strong>Your yearly comp<br>(base + equity)</strong>
   </td>
  </tr>
  <tr>
   <td>80%
   </td>
   <td>Fails
   </td>
   <td>0
   </td>
   <td>0
   </td>
   <td>$120K
   </td>
  </tr>
  <tr>
   <td>5%
   </td>
   <td>IPO
   </td>
   <td>$1 billion
   </td>
   <td>$200K - 1M
   </td>
   <td>$170K - 270K
   </td>
  </tr>
  <tr>
   <td>0.5%
   </td>
   <td>IPO
   </td>
   <td>$10 billion
   </td>
   <td>$2M - 10M
   </td>
   <td>$620K - 2.62M
   </td>
  </tr>
  <tr>
   <td>0.05%
   </td>
   <td>IPO
   </td>
   <td>$100 billion
   </td>
   <td>$20M - 100M
   </td>
   <td>$5M - 25M
   </td>
  </tr>
  <tr>
   <td>14.45%
   </td>
   <td>Acquired
   </td>
   <td>$$$
   </td>
   <td>$0 - 8M
   </td>
   <td>$120K - 2.12M
   </td>
  </tr>
</tbody></table>

<p><br>
<strong>If you join late at the startup (say employee number 100+), even if the company succeeds wildly, your equity will be worth very little.</strong></p>

<p>If you want to get rich, join a big company and climb their rank. You can find the detailed analysis of compensations for 19,000 FAAAM-dominated tech workers <a href="https://huyenchip.com/2020/01/18/tech-workers-19k-compensation-details.html">here</a>, but below is a plausible, even conservative, scenario if you join a company like Google with 2-3 years of experience.</p>

<ul>
  <li>1st year, L4 $250K/year.</li>
  <li>2nd year, L4, $280K/year.</li>
  <li>3rd year, L4, $320K/year.</li>
  <li>4th year, L5, $360K/year.</li>
</ul>

<p>After the first 4 years at Google, youâ€™ve already made over $1 million, not counting â€œperksâ€ like work-life balance.</p>

<h3 id="5_management">Reason 5. Bad management</h3>

<p>Thereâ€™s a trend among startups to not fixate on titles until they have to. Some avoid â€œmanagerâ€ to not endanger the â€œeveryone is equalâ€ mindset (protip: everyone isnâ€™t equal at startups â€“ some have much more equity than others). In the early stage of a startup (e.g. before the 20th employee), there might not be anyone with â€œmanagerâ€ in their title. If you join during that phase, youâ€™re expected to get things done with little to no guidance.</p>

<p>Even if your startup has managers, they are likely bad managers. A startupâ€™s first managers are likely its founding team who might have little to no real-world working experience, let alone managerial experience (e.g. recent dropouts, recent graduates). It doesnâ€™t mean that people without working experience canâ€™t be good managers (I know a few), itâ€™s just more rare.</p>

<p>Bad management can manifest in the lack of feedback. At startups, you might get a lot of work-specific feedback â€“ demos, design docs, even code (though it might not be good feedback) â€“ because people at startups are generally more invested in the company. However, you wonâ€™t get much you-specific feedback that can help you grow such as what skills youâ€™re lacking or what you need to do to get to the level you want to get to.</p>

<p>Even if there are processes in place for feedback, everyone might be too caught up in sprinting to think about you, what you want, or what opportunities they can give you to grow.</p>

<p>Bad management can be especially frustrating during conflicts, which will inevitably arise when you work in a high-stress environment (e.g. youâ€™re all trying to push a feature at 11pm on a Saturday, everyone is tired and snappy). When something bothers you, you might feel like thereâ€™s no one you can talk to because you either â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299940</guid>
            <pubDate>Mon, 01 Mar 2021 05:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp Machine Manual (1984)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298553">thread link</a>) | @caslon
<br/>
February 28, 2021 | https://hanshuebner.github.io/lmman/title.xml | <a href="https://web.archive.org/web/*/https://hanshuebner.github.io/lmman/title.xml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><center><heading>Lisp Machine Manual</heading></center><center>Sixth Edition, System Version 99</center><center>June 1984</center><center>Richard Stallman</center><center>Daniel Weinreb</center><center>David Moon</center><nopara></nopara>
<p>This report describes research done at the Artificial Intelligence
Laboratory of the Massachusetts Institute of Technology.  Support for the
laboratory's artificial intelligence research is provided in part by the
Advanced Research Projects Agency of the Department of Defense under Office
of Naval Research Contract number N00014-80-C-0505.
<page></page></p><center><sub-heading>Preface</sub-heading></center>

<p>The Lisp Machine manual describes both the language and the operating system
of the Lisp Machine.  The language, a dialect of Lisp called Zetalisp,
is completely documented
by this manual.  The software environment and operating-system-like parts of
the system contain many things which are still in a state of flux.
This manual confines itself primarily to the stabler parts of the
system.  It describes how to program, but not for the most part how to
operate the machine.  The window system is documented separately in
the Lisp Machine Window System manual.
</p>

<p>Any comments, suggestions, or criticisms will be welcomed.  Please send
Arpa network mail to BUG-LMMAN@MIT-MC.
</p>

<p>Those not on the Arpanet may send U.S. mail to

<lisp><standard>Richard M. Stallman
Artificial Intelligence Lab
545 Technology Square
Cambridge, Mass. 02139</standard>
</lisp></p>

<p>Portions of this manual were written by Mike McMahon and Alan Bawden.
The chapter on the LOOP iteration macro is mostly a reprint of
Laboratory for Computer Science memo TM-169, by Glenn Burke.  Sarah
Smith, Meryl Cohen and Richard Ingria of LMI, and Richard Mlynarik of
MIT, helped to correct the manual.
</p>
<nopara></nopara><center><sub-heading>Personal Note from Richard Stallman</sub-heading></center>
<p>The Lisp Machine is a product of the efforts of many people too
numerous to list here and of the former unique unbureaucratic,
free-wheeling and cooperative environment of the M.I.T. Artificial
Intelligence Laboratory.  I believe that the commercialization of
computer software has harmed the spirit which enabled such systems to
be developed.  Now I am attempting to build a software-sharing movement to
revive that spirit from near oblivion.
</p>

<p>Since January 1984 I have been working primarily on the development of
GNU, a complete Unix-compatible software system for standard hardware
architectures, to be shared freely with everyone just like EMACS.
This will enable people to use computers and be good neighbors legally
(a good neighbor allows his neighbors to copy any generally useful
software he has a copy of).  This project has inspired a growing
movement of enthusiastic supporters.  Just recently the first free
portable C compiler compiled itself.  If you would like to contribute
to GNU, write to me at the address above.  Restrain social decay--help
get programmers sharing again.
</p>
<page></page>
</div></div>]]>
            </description>
            <link>https://hanshuebner.github.io/lmman/title.xml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298553</guid>
            <pubDate>Mon, 01 Mar 2021 00:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Planck 6502, an open hardware extensible retro computer]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26298278">thread link</a>) | @jfoucher
<br/>
February 28, 2021 | https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html | <a href="https://web.archive.org/web/*/https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>February 28, 2021 | <span>7</span> Minute Read</p>
  
  <p><img src="https://jfoucher.com/uploads/2021/02/1.jpg" alt="">
    </p>

  <h3 id="retro-computing">Retro computing</h3>

<p>Going back to the roots of your field can provide new insights into your day to day experience. For me, the roots are located in the 70s / 80s a time when personal computers were much simpler and could be fully understood by a regular person. This is a time when the most popular computers were the Vic20, Apple II and later Commodore 64.</p>

<p><img src="https://jfoucher.com/uploads/2021/02/VIC-20.jpg" alt="Vic-20">
<img src="https://jfoucher.com/uploads/2021/02/Apple_II.jpg" alt="Apple II"></p>



<p>These computers booted in less than a second to a raw basic prompt. To be clear: you turn on your computer, and less than one second later you start programming. How wonderful would that be, in our land of a thousand node dependencies, failing composer upgrades and wrong vagrant configurations?</p>

<h3 id="what-to-build">What to build?</h3>

<p>I was increasingly interested in electronics since doing a project for a friend, so I thought to myself â€œHow hard can it be?â€ Well, as it turns out, quite, but thatâ€™s hardly the point right now. The point is: what should I build? I started by building a simple 6502 based computer on a breadboard. I soon realised that if I was to have anything half useful I was going to need the entire breadboard production of China to be delivered to my house. Also breadboard computers are buggy and you canâ€™t move them around because then a cable will come loose and you will spend five hours troubleshooting your code instead.</p>

<p>So I decided I would convert it to PCBs. They are pretty cheap to get delivered from China, but since they take about a month to arrive the rate of iteration is not so great. Better to get it right the first time obviously.</p>

<p>Well I almost did. The first one was very simple, only having a 6502 processor and an 6522 parallel port interface. I interfaced with it from my computer via SPI through an arduino: the 6522 Versatile Interface Adapter can bit bang SPI easily enough. The Arduino Uno/Nano can be an SPI slave easily enough and receive that data. It can then transmit that data to my computer using serial over USB.</p>

<p>That worked fine (after a couple of bodge wires) but was a bit kludgy, having the Arduino sort of hanging there by a few cables.</p>

<p>I then tried to design a single board computer with everything I would ever want on it: serial communication, parrallel port, SPI port(s), i2c port(s), PS/2 port for a keyboard, sound chip, VGA output, etcâ€¦ The board to house all of this was very big and thus very expensive. Combining this with the previous point regarding getting it right the first time, a single board computer suddenly seemed like not that great of an idea.</p>

<h3 id="the-plan">The plan</h3>

<p>I then decided to build a board with basic circuitry into which other boards that provided actual functionality will be able to plug in. Turns out that already exists and is called a <a href="https://en.wikipedia.org/wiki/Backplane">backplane</a></p>

<p>So backplane it is then. The size limit for this board and all others will be 10cm x 10cm as that it the cheap price limit for most cheap board houses (yes Iâ€™m cheap and I like cheap, preferably cheap that works).</p>

<p>Here is the backplane design:</p>

<p><img src="https://jfoucher.com/uploads/2021/02/backplane.png" alt="backplane 3D view"></p>

<p>As you can see, it is mostly just slots to plug in the extension boards. The only active components are the clock generation circuit, and some decoding to activate the expansion slots when they are needed.</p>

<p>The rightmost slot is reserved for the CPU card. The CPU card includes some RAM and ROM, which means the computer is already functional with just this single board plugged in, although admittedly it wonâ€™t <em>do</em> much in that configuration.</p>

<p>To get the computer to do stuff itâ€™s best to plug in some additional boards.</p>

<p>The initial design includes an IO board with PS/2 port, SPI ports and a parallel port (and LEDs, of course it has LEDs!) as well as a serial board to allow the user to communicate with the computer.</p>

<p>After waiting patiently forever for the boards to arrive, I put it all together and gave it a try. It did not work at all. Of course there were mistakes on the boards, which confirmed the soudness of my choice of not doing one huge board at once.
However not all the boards were defective, and the bad ones were quickly fixed with a few wires here and there.</p>

<p>After which, plugging a usb to serial adapter into the serial board, and into a usb port on my computer, I could see the Planck computer doing something!</p>

<p>Here it is running <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a> over serial</p>

<p><img src="https://jfoucher.com/uploads/2021/02/running-forth.jpg" alt="Forth over serial on the Planck computer"></p>

<p>I am currently working on more expansion boards, such as an LCD board, a sound card, and a VGA card. <a href="https://jfoucher.com/feed.xml">Stay tuned</a> for more.</p>

<p>For more details about this project, please use the links below:</p>

<ul>
  <li><a href="https://planck6502.jfoucher.com/">Project website</a></li>
  <li><a href="https://gitlab.com/planck-6502/planck-6502">Hardware and source code</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298278</guid>
            <pubDate>Sun, 28 Feb 2021 23:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak: A Free Smalltalk System â€“ On RISC OS]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26298075">thread link</a>) | @lproven
<br/>
February 28, 2021 | http://www.rowledge.org/tim/squeak/ | <a href="https://web.archive.org/web/*/http://www.rowledge.org/tim/squeak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- .sidebarContainer -->
			<div>
				<p><span>Squeak: A Free Smalltalk system</span></p><p><img alt="" src="http://www.rowledge.org/tim/squeak/files/page17_1.jpg" width="295" height="205"><br></p><p><span>What is Squeak?</span><br>Squeak is a free Smalltalk system originally released by a team including Alan Kay, Dan Ingalls, Ted Kaehler, John Maloney and Scott Wallace in 1996 when they were working at Apple. You might recognise the first three names from early Smalltalk papers from Xerox PARC. They produced a rather nice Smalltalk system with the unusual virtue that both the image and the Virtual Machine are open source - i.e. free, gratis and "no charge to you sir".<br><span>Finding Out More About Squeak</span><br>To find most of the web resources for Squeak, look at the <a href="http://www.squeak.org/" rel="self">Squeak.Org</a> site. There are lots of pointers to information about Smalltalk, instructions for downloading Squeak, tutorials, FAQs etc. I won't waste space by duplicating any of it here. I do most strongly recommend that you read many of them.<br><span>Squeak runs on...</span><br>Macs, iPhones, most UNIX &amp; Linux systems, Windows of various versions, <a href="http://www.riscos.org/" rel="external">RISC OS</a> and some obscure specialised systems. See the above mentioned master page for details on how to get the files.<br>Iâ€™ve spent many years making Smalltalk available for RISC OS and other <a href="http://www.arm.com/" rel="self">ARM</a> based systems including the original Acorn Archimedes &amp; RPC desktops, the Active Book, an early prototype version of the Compaq â€˜iPaqâ€™ handheld, the Interval Research â€˜MediaPadâ€™, an HP prototype pad-thing and other stuff still secret.<br><span>New News of a newsish nature</span><br>2013 - Squeak is back on RISC OS! Those nice people at the <a href="http://www.rowledge.org/tim/squeak/www.raspberrypi.org" rel="external">Raspberry Pi Foundation</a> sent me a Pi; it has RISC OS on it and Iâ€™ve been getting things working on it. </p><p><img alt="IMG_0467" src="http://www.rowledge.org/tim/squeak/files/img_0467.jpg" width="519" height="388"><br></p><div><p>It runs quite nicely in general; the Piâ€™s RISC OS graphics kernel is a bit slow seeming right now but there is work being done that should improve that significantly. It supports <a href="http://scratch.mit.edu/" rel="external">Scratch</a> as well and runs it decently - though there is a lot of work being done to improve that, too. Somewhat perversely, MIT decided to rewrite Scratch in Flash (belch) â€˜for better browser supportâ€™ and seem to have abandoned the â€˜oldâ€™ Squeak based system. Since Flash doesnâ€™t run on RISC OS  nor indeed on ARM systems in general, weâ€™ll be supporting â€˜oldâ€™ Scratch for a while.<br>You can download a copy of Squeak for RISC OS from the central <a href="http://www.squeakvm.org/riscos" rel="external">squeakvm.org </a>site.<br>Currently Iâ€™m working for the Pi foundation to improve Scratch under Raspbian (their linux version) by rewriting some of the more egregiously ugly code, improve algorithms, tweak vm configurations and so on. As of early-2014 itâ€™s significantly faster than the original version with a fair bit more to come. A major project has been <a href="http://www.raspberrypi.org/test-tims-nuscratch-beta/" rel="external">porting the code forwar</a>d to the latest Squeak image so that it can run on the most modern VMs; right now it is using the â€˜StackVMâ€™. I hope to get the newer design dynamic translating VM working soon.<br>When and if possible all of this will get moved over to RISC OS but making a living comes first!</p><p> <span>Building the VM with VMMaker</span><br>I also developed and for many years maintained the VMMaker package, the lump of Squeak code that defines and generates the bulk of the VM. See the VMMaker page on the <a href="http://wiki.squeak.org/squeak" rel="self">Squeak Swiki</a> for more info. You can fetch the VMMaker package from <a href="http://map1.squeakfoundation.org/sm" rel="self">SqueakMap</a> or use the SqueakMap tool in the image and look for (guess what) VMMaker. You will also need a <a href="http://subversion.tigris.org/" rel="external">SubVersion</a> client so that you can fetch the handwritten parts of the VM source code from the repository.<br>Once you have mastered the complexities of the VMMaker and successfully built yourself a custom VM you should download<a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/SqueakVMBuilderCertificate.pdf" rel="self"> this certificat</a>e to attest to your mighty geekiness.<br><span>Stuff wot I wrot</span><br>	â€¢	I contributed a chapter describing the structure, function, design and implementation of virtual machines and the lowest level of Smalltalk code to <a href="http://www.amazon.com/Squeak-Open-Personal-Computing-Multimedia/dp/0130280917" rel="external">"Squeak: Open Personal Computing and Multimedia"</a> edited by Mark Guzdial and Kim Rose, published by Prentiss-Hall. An online version of <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/OE-Tour.pdf" rel="self">that chapter is here</a>.<br>	â€¢	I worked on a <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/RTOSinSmalltalk.html.pdf" rel="self">realtime OS in Squeak</a> whilst employed at Interval Research Corp<br>	â€¢	A short paper on making <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/LEBB.pdf" rel="self">BitBlt work for little-endian</a> machines without having an intermediate display-on-screen conversion<br><span>Squeak logo artwork</span><br>At the dawn of Squeak-time we needed a logo. Every project needs a logo. I designed one, it caught on and can be found all over the web, on T-shirts, sweatshirts, books, badges, underwear, hats and probably secret spy satellites in geosynchronous orbit. (No, seriously; there is now at least one satellite running Squeak code!)<br>Here are some files of the Squeak logo that you may like to use:-</p></div><p>Feel free to download them and use them for links etc. If you'd like any other size, I can easily generate them for you from vector artwork. If you want to use it for a project of some sort relating to Squeak you are most welcome to do so - if you are making a neat badge or shirt or publishing a book Iâ€™d love a copy if at all practical.</p>
				
			</div><!-- .content -->
		</div></div>]]>
            </description>
            <link>http://www.rowledge.org/tim/squeak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298075</guid>
            <pubDate>Sun, 28 Feb 2021 23:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OMU â€“ â€œOne Man Unixâ€]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 56 (<a href="https://news.ycombinator.com/item?id=26298022">thread link</a>) | @marcodiego
<br/>
February 28, 2021 | http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html | <a href="https://web.archive.org/web/*/http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<center>

</center>
<h2>
History:
</h2>
In the late 1970s and early 1980s (the good old days of "hobby computing") before
the IBM PC and its clones took over the world, various microprocessor based kits
appeared on the hobbyist market. You could build a Z80-based board with 8K of
RAM, and with its hexadecimal keypad and LED display you could run simple
programs laboriously keyed in hex.
<p>
The first generation commercial machines also appeared - usually based on
the 8080 or the Z80 or 6502. The Commodore PET was one of the early sucesses
and it, along with the Commodore 64, Sinclair's three machines (ZX80, ZX81 and
Spectrum) and the BBC Micro probably accounted for most of the infant home-computer
market in Britain.
</p><p>
I decided on a different approach. Unhappy with the concept of having to re-live
the glory-days of the
<a href="http://www.computer50.org/mark1/MM1.html">
Manchester MkI
</a>
with the hobby-boards fraternity (!), and unhappy with the straitjacketed
architectures and joke operating systems of the 1st generation home computers,
I yearned for more. Specifically, what I wanted was something
more like a Unix clone at home. I was used to V7 Unix on the PDP-11 at university
and wasn't keen to step backwards 10 years to the technology of CP/M and BASIC
programming.
<br>
<i>
I wasn't to know that eight years later a guy called Linus
Torvalds was going to think the same thoughts and do much the same things. The
big difference was that he was in the right place and the right time and 
had internet connectivity - I didn't have any of these advantages!
</i>
</p><p>
I went off and built myself a 6809 based computer with 64K of RAM, a 360K
floppy disk drive and an RS232 interface which could drive a glass-TTY.
Please remember that this was 1982. Hard disks, megabytes of RAM and other
familiar modern things were a long way off.
</p><p>
After going through the usual hard work of writing a BIOS complete with
an S-records downloader, I was in a position to write myself an operating
system. Preliminary work on OMU started in late 1983. My earliest surviving
printouts of the sources on yellowed, faded lineprinter paper show that the
bulk of the work on OMU dates from March/April/May 1984.
</p><p>
Work was not helped by the fact that I was having to write a 'C' compiler
in parallel, but certainly by mid 1984 I had a perfectly usable O/S with a
primitive shell, a port of Unix 'ed' for an editor, and with 'fsck' and other
such tools available to repair the filestore disks when they got damaged by
miswrites from the rather dodgy floppy-disk hardware. I remember taking
the machine home over Christmas 1984 and typing up several reports using it
on the kitchen table.
</p><p>
<table>
<tbody><tr>
<td>
I just found this photo of the 1984 machine amongst a box of slides taken
over that Christmas. It appears to be the only photo of the machine I ever
took at the time.
<p>
At this point in its evolution, the hardware was mostly on one double
eurocard, with a floppy-disk interface piggybacked onto it. The floppy-disk
drive is in the metal box at front, and the bigger metal box at the RHS
of the PCBs is the power-supply.
</p></td>
<td>
<a href="http://www.pix.net/mirrored/discordia.org.uk/~steve/omu-big.jpg">
<img src="http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.jpg">
</a>
</td>
</tr>
</tbody></table>
</p><h2>
Features and misfeatures list:
</h2>
<ul>
<li>
Tiny (24K) Kernel.
</li><li>
V7 Unix-compatable filestore (doesn't support triple-indirection blocks).
Not exactly critical on a floppy-disk-only system!
</li><li>
Normal Unix-style use of /dev/* files to interface to devices.
</li><li>
Mountable/dismountable filestores as expected.
</li><li>
Shell is built-in to save space, rather than run as a process.
</li><li>
tty driver is exceedingly minimal, but functional.
</li><li>
No true multitasking (see below).
</li><li>
UIDs and GIDs not implemented. They're ignored on the filestore, and the
process table doesn't bother to hold them. Any files created would be given
UID = GID = 0.
</li></ul>
<p>
The lack of an MMU and the small amount of RAM available meant that I
decided against trying to implement true multitasking. Instead (like DOS
as it happens) I came up with a scheme whereby a process could launch another
process, but would have to wait for it to complete. Clunky, but it worked
OK.
</p><p>
For your entertainment (or possibly if you're interested in the possibility
of porting my old O/S to more modern hardware like that old XT that's
gathering dust under your table) here's a downloadable copy of my
final version of the 6809 OMU as it stood in 1987:
</p><center>

</center>
<p>
In order to make any use of OMU, I had compiled up a set of utilities like
'ed' and 'mount' and 'fsck'. Sadly I don't think I can make their sources
downloadable here as they were based on the Unix V7 sources for which we had
a Bell Labs "academic use" licence at the university.
</p><p>
<strong>
<span color="#FF0000">
NEW!
</span>
</strong>
The above packages now include some utilities which I did write from scratch:
</p><ul>
<li><strong>adb</strong>
An interactive disassembler. (Doesn't debug core-dumps though, just lets
you look at code in files).
</li><li><strong>aka</strong>
("Also Known As") - finds other files hardlinked to the one mentioned on the
command-line.
</li><li><strong>chbase</strong>
Prints the number(s) given on the command-line in octal, decimal &amp; hex.
</li><li><strong>hex</strong>
Makes Motorola S-record files for sending to the 6809. Usually runs on a
host machine (a PDP-11 originally).
</li><li><strong>ida</strong>
An intelligent disassembler - shares source-code with 'adb' above.
</li><li><strong>sh</strong>
The tiny shell needed by the OMU kernel. OMU runs this as if it was the
'init' process.
</li><li><strong>sirius</strong>
An interactive disk-examination program.
</li><li><strong>unhex</strong>
A program to convert Motorola S-records into an OMU-loadable file. Usually
runs on the 6809 itself of course.
</li></ul>
Sorry, no documentation, but the source-code should be documentation enough!
<p>
I
<strong>
don't
</strong>
suggest any modern user of OMU on a 6809 tries getting GNU utilities running
with it! Bear in mind that V7 sources would compile into a smaller executable
than any modern GNU equivalents. With the 64K memory-address limitation of my
6809, this was important! The BIOS and O/S accounted for about 24K of this, so
user-programs were limited to about 40K total. I never did complete my
page-switched 256K memory system.....
</p><p>
Mind you, if you're contemplating porting to a 68000 or IBM-PC, the size
constraints will be much less of a problem.
</p><hr>
<p>
My work on OMU was pretty much unnoticed by anyone else in the world (we didn't
have an internet connection in those days), but others in the Electrical
Engineering dept at Swansea University saw the potential to port OMU to one of
several 68000 single-board-computers which began to appear in the department
from about 1984/85 onwards.
</p><p>
My colleage Terry Barnaby and I were variously involved with porting OMU
to several of these 68000 based SBCs. Terry did most of the work!
The first stage was merely to take OMU and get it to run on the new
hardware much as my 6809 version was doing already. This was accomplishe
reasonably quickly, complete with the addition of the OMU's first driver
for a hard-disk.
The much greater memory-addressing ability of the 68000 coupled with the
fact that the SBCs typically had 256K of RAM on board meant that this version
of OMU soon featured some multi-tasking capabilities (though with no MMU
available the processes had to be well-behaved).
</p><p>
For convenience, the details of the filestore layout and the system-call
interface of 68000 OMU was designed to duplicate those of the commercial 68000
V7 Unix system made by "Codata" (we had just taken delivery of two of these
units to augment the aging PDP-11).
It is I think a credit to OMU's potential that
it soon became possible to compile programs on the Codata, and run them on
OMU with no problems. Indeed, it was also possible to take system binaries
shipped with the Codata and run them on OMU too - an easy way to get 'vi'
and other state-of-the-art (!) software on OMU without having to dig out the
sources and recompile!
</p><center>

</center>
<p>
Terry Barnaby and another of his colleages Tim Ingersoll then made some
fundamental changes to the message-handling abilities of the 68000 OMU port to
make it suitable for Real-Time signal processing and control applications.
This was after all what the two of them really
wanted as part of their Ph.D projects...! In 1988 they finished their
projects, wrote up and left. Part of their legacy was the RTOS version of OMU,
and I managed to salvage a set of sources for that too:
</p><center>

</center>
<p>
If any reader of these pages feels suitably daring they may be able to
beat me to the target of porting OMU (probably working from Terry's and my
initial 68000 version above) to the IBM PC. I consider that there really is no
point in aiming for the 386 processor machines onwards as Linux already does
everything you could hope for on that class of machines.
</p><p>
It does however seem that there is mileage in starting with the boot-loader
that comes with
<a href="http://metalab.unc.edu/pub/micro/pc-stuff/freedos/">
FreeDOS
</a>,
and getting OMU to run on 8086/80286 machines of which there must be
<strong>
loads
</strong>
lying around virtually unwanted these days.
</p><p>
If you do decide to try such a thing, then I wish you the best of luck and
I'll offer any email help I can. My email address is in the README file
included with the any of the sets of downloadable sources.
</p><h2>
Acknowledgements:
</h2>
My thanks go to Terry and Tim whose work in enhancing OMU is credited here
and really should have been reflected in a name-change from OMU back in the
Eighties! (I never did get it straight in my mind as to whether the "one man"
mentioned in the title were there to signify the number of authors or
the number of simultaneous users. Either way, neither was very relevant once
as the software started its modest spread in the department.)
<p>
My thanks also go to Alan Cox (he of Linux networking and kernel hacking fame)
without whose prodding this page might never have been written.
</p><center>
<a href="http://www.pix.net/mirrored/discordia.org.uk/~steve/steve.html">
Home
</a>
</center>
<hr>
<p>
Copyright (c) 1999, Steve Hosgood


</p></div>]]>
            </description>
            <link>http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298022</guid>
            <pubDate>Sun, 28 Feb 2021 23:15:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Associative Arrays in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26297204">thread link</a>) | @avivallssa
<br/>
February 28, 2021 | https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/ | <a href="https://web.archive.org/web/*/https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="664a6773" data-element_type="section">
						<div>
					<div data-id="69dd5814" data-element_type="column">
			<div>
								<div data-id="768afe71" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>While migrating from Oracle to PostgreSQL, most of the developers ask about the options available in Handling Global associative arrays in PostgreSQL. It might get challenging if the variables need to be accessible in the Exception block. To avoid developers from finding it difficult while performing conversions of PL/SQL from Oracle to PostgreSQL, we are writing this blog post to demonstrate the workarounds available with not much of additional programming effort. <img loading="lazy" src="https://www.migops.com/blog/wp-content/uploads/2021/02/Word-Art.jpeg" alt="" width="500" height="343"></p>
<p>By the way, the fact to note after reading this blog post is that, several features you want to observe in PostgreSQL during migrations or Code conversions are available without the need of an additional Enterprise license with PostgreSQL (which could create a vendor lock-in).</p>

<p>Ask us about possibilities with Community PostgreSQL (Open Source) before switching to an Enterprise licensing. ðŸ™‚</p>

<p><b>What is an Associative Array ?</b></p>
<p>Before getting to the workarounds, let us understand what is an associative array. In programming languages, an associative array may either be called a <strong>map</strong> or a <strong>dictionary</strong>. Associative array is a collection of (key, value) pairs where a key associates to a value. This association between a key and a value may be referred to as mapping. The key can either be of a text or a numeric type that can be mapped to any value type.&nbsp;</p>
<p><b>PostgreSQL Array type</b></p>
<p>PL/pgSQL in PostgreSQL allows us to declare a variable as an ARRAY type. This ARRAY can be either a <strong>base</strong> or a <strong>custom</strong> type. For example, if we want to store a list of <strong>PINCODE</strong> values, then, we can declare the variable as <strong>v_pincode INT[]</strong>. Once we declare this variable, then, we can load all the pincode values from a table/view/function into this array.&nbsp;</p>
<p>We can also initialize the <strong>v_pincode</strong> array type with a static set of pincode values. Here, the <strong>v_pincode</strong> holds all the values and we can fetch a specific stateâ€™s pincode value, by providing an index. Which means, if we want to access the 1st state pincode, then, we can access the value using <strong>v_pincode[1]</strong>. If we want to access the pincode value of 3rd state, then, we have to pass the index value 3 using <strong>v_pincode[3]</strong>.</p>
<p>Here is a sample code to illustrate the above with an example.</p>
<pre>postgres=&gt; CREATE OR REPLACE FUNCTION process_orders() RETURNS BOOL<br>AS<br>$$<br>DECLARE<br>--initializing static pincodes<br>v_pincode INT[]=ARRAY[123456, 123457, 123458, 123459];<br>BEGIN<br>RAISE NOTICE '1st state pincode %', v_pincode[1];<br>RAISE NOTICE '3rd state pincode %', v_pincode[3];<br>RETURN true;<br>END;<br>$$ LANGUAGE PLPGSQL;<br>CREATE FUNCTION</pre>
<p>Let us execute the function created above and see the results.</p>
<pre>postgres=&gt; SELECT process_orders();<br>NOTICE: 1st state pincode 123456<br>NOTICE: 3rd state pincode 123458<br>process_orders<br>----------------<br>t<br>(1 row)</pre>
<p>We got the results as expected. However, this code has some limitations because we are unable to fetch the values based on their keys. For example, the pincodes (1st and the 3rd elements) are fetched using their Indexes. If we are able to access the same pincodes based on their keys, then, the lookup will be more powerful. So, how to approach this requirement ? Let us discuss the approach further.&nbsp;</p>
<p><b>Associating or mapping a name or a key to a value</b></p>
<p>Thanks to PostgreSQLâ€™s rich data types such as <strong>hstore</strong> or <strong>json</strong> which can be leveraged to perform such mapping.</p>
<p>Following is a sample code using a <strong>json</strong> static object.</p>
<pre>CREATE OR REPLACE FUNCTION process_orders() RETURNS BOOL<br>AS<br>$$<br>DECLARE<br>--initializing static pincodes<br>v_pincode JSON= '{"CA": 123456, "AZ": 123457, "OH": "123458", "CO": 123459}';<br>BEGIN<br>RAISE NOTICE 'CA state pincode %', v_pincode-&gt;&gt;'CA';<br>RAISE NOTICE 'OH state pincode %', v_pincode-&gt;&gt;'OH';<br>RETURN true;<br>END;<br>$$ LANGUAGE PLPGSQL;</pre>


<p>Let us execute the above created function and see the results.</p>

<pre><code>postgres=&gt; SELECT process_orders();
NOTICE:  CA state pincode 123456
NOTICE:  OH state pincode 123458
process_orders
----------------
t
(1 row)</code></pre>

<p>Now, we are able to make the lookup using a key possible with our PL/pgSQL code. Thus, by using a json type instead of an ARRAY we can implement the concept of associative arrays.&nbsp;</p>

<p><strong>Global Associative Arrays</strong></p>

<p>The json approach demonstrated above seems to be perfect, but it does not solve the problem of global or session level associative arrays. What this means is that the same associative array cannot be accessed using another function running in the same session. This is because of the lack of global variables or global arrays.&nbsp;</p>

<p><strong>How to make Global Associate Arrays possible with PostgreSQL ?</strong></p>

<p>Following are the 5 possible solutions with some or no limitations to each approach.&nbsp;</p>

<ol>
<li><strong>Declare the same json object in the other function.</strong></li>
</ol>

<ul>
<li>Requires duplicating the same variable and the same context.&nbsp;</li>
</ul>

<ol start="2">
<li><strong>Pass the json argument as a parameter to the other function.</strong></li>
</ol>

<ul>
<li>Pass the same value across functions. However, the argument lists may become huge to manage or debug.</li>
</ul>

<ol start="3">
<li><strong>Store this object in a table and load it in the function.</strong></li>
</ol>

<ul>
<li>Storing it in a Table and accessing the elements by selecting from the Table. This can be a heavy overhead.&nbsp;</li>
</ul>

<ol start="4">
<li><strong>Use set_config() approach, which set the object at a session level, and read it from the current_setting().&nbsp;</strong></li>
</ol>

<ul>
<li>If any value is set, an Exception block cannot view the configured settings. May become challenging while performing conversions from Oracle to PostgreSQL where a good amount of logic is written in the Exception block. May be great when we are not accessing any global variables in the exception block. We will be discussing this in detail in our future blog post.&nbsp;</li>
</ul>

<ol start="5">
<li><strong>Using a supported PostgreSQL language context.&nbsp;</strong></li>
</ol>

<ul>
<li>With this approach, we should be able to access the global variables across the exception blocks and also the non exception blocks.</li>
</ul>

<p>The first 4 approaches seem to be pretty straight forward and simple with their own limitations. But the last approach about using another languageâ€™s session context is something interesting and we are discussing that further.</p>

<p><strong>Using TCL to support Global Associative Arrays</strong></p>

<p>As we all know, PostgreSQL supports many trusted procedural languages such as PLPerl, PLPython, PLTCL, PLv8 etc. All these trusted languages guarantee that the program code written in that language will not be accessing the underlying physical files. Out of all these programming languages, we will be choosing a simple, safe and a powerful language called <span><a href="https://wiki.tcl-lang.org/page/pltcl">tickle (PLTCL)</a>.</span>&nbsp;</p>

<p>TCL language does support the associative array concepts and we will be leveraging this feature in a global way. This will give more flexibility of lookup of values using keys. Let us see the following example code to see how we can make the declaration of a global variable with tickle (TCL).</p>

<p><strong>TCL instructions<br></strong>As the first step, letâ€™s declare a global variable (namespace) using the following TCL code.</p>

<pre><code>$ tclsh
% # Here, arr_ptr is a pointer to the namespace/global variable "pincodes"
% upvar 0 ::"pincodes" arr_ptr</code></pre>

<p>Now, letâ€™s add a pincode value to this namespace (or the global variable).</p>

<pre><code>% set arr_ptr('CA') 123456
123456</code></pre>

<p>Let us now get the value which we set in the associative array.</p>

<pre><code>% set arr_ptr('CA')
123456</code></pre>

<p>Using the simple example created above, we have seen how we can declare a global variable and store the values using TCL.</p>

<p><strong>Using PLTCL to support Global Associative Arrays in PostgreSQL.</strong></p>

<p>To achieve the functionality of global associative arrays, let us embed the same code in PLTCL as seen in the following steps.</p>
<p><strong>Step 1 :</strong> Create the PLTCL Extension</p>

<pre><code>postgres=&gt; CREATE EXTENSION pltcl;
CREATE EXTENSION</code></pre>

<p><strong>Step 2 : </strong>Create a function using PLTCL to declare the Global Associative Array and set a value.</p>

<pre><code>postgres=&gt; CREATE OR REPLACE FUNCTION pltcl_set(TEXT, TEXT, TEXT) RETURNS VOID AS $$
upvar 0 ::$1 arr_ptr
set arr_ptr($2) $3
$$ LANGUAGE PLTCL;
CREATE FUNCTION</code></pre>

<p><strong>Step 3 : </strong>Create a function using PLTCL to get the value mapped to the key.</p>

<pre><code>postgres=&gt; CREATE OR REPLACE FUNCTION pltcl_get(TEXT, TEXT) RETURNS TEXT AS $$
upvar 0 ::$1 arr_ptr
set arr_ptr($2)
$$ LANGUAGE PLTCL;
CREATE FUNCTION</code></pre>

<p><strong>Testing</strong></p>

<p>Let us perform a test using the newly created PLTCL functions.</p>

<pre><code>postgres=&gt; SELECT pltcl_set('pincodes', 'CA', '123456');
pltcl_set
-----------
(1 row)
postgres=&gt; SELECT pltcl_get('pincodes', 'CA');
pltcl_get
-----------
123456
(1 row)</code></pre>

<p>As seen in the above example, we are able to get data from the TCL context which is global. Which means, we are able to set the <strong>pincodes</strong> from one statement (using pltctl_set() ), and able to access itâ€™s value from another statement (using pltcl_get()).&nbsp;</p>

<p><strong>Iterating over the Global Associative Arrays</strong></p>

<p>What is an array without an iterator, right? Let us leverage the same TCL code and create another function which iterates over the global array.</p>

<pre><code>postgres=&gt; CREATE OR REPLACE FUNCTION pltcl_itr(TEXT) RETURNS TABLE(key TEXT, value TEXT)
AS
$$
upvar 0 ::$1 arr_ptr
    foreach i  [array names arr_ptr] {
        return_next [list key $i value [set arr_ptr($i)]]
    }
$$ LANGUAGE PLTCL;
CREATE FUNCTION</code></pre>

<p>Now, letâ€™s add a few more entries to `pincodes` global array and do the iteration test.</p>

<pre><code>postgres=&gt; SELECT pltcl_set('pincodes', 'AZ', '123457');
pltcl_set
-----------
(1 row)
postgres=&gt; SELECT pltcl_set('pincodes', 'OH', '123458');
pltcl_set
-----------
(1 row)
postgres=&gt; SELECT pltcl_set('pincodes', 'CO', '123459');
pltcl_set
-----------
(1 row)</code></pre>

<p>Letâ€™s use the iterator function to get all the lists of available <strong>pincodes</strong> from the global array, as seen in the following block.</p>

<pre><code>postgres=&gt; SELECT * FROM pltcl_itr('pincodes');
key | value
-----+--------
CA  | 123456
CO  | 123459
OH  | 123458
AZ  | 123457
(4 rows)</code></pre>

<p>As seen above, this iterator is actually helping to iterate over the global associative array. We can use these values across multiple functions across the same session.&nbsp;</p>

<p><strong>Conclusion</strong></p>

<p>PostgreSQL offers a lot of flexibility in writing the code in multiple languages, which eventually enables us to inherit the power of other programming languages. As you have witnessed in this blog post, we leveraged the TCLâ€™s features and are able to achieve the global associative arrays, which â€¦</p></div></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/">https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/</a></em></p>]]>
            </description>
            <link>https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297204</guid>
            <pubDate>Sun, 28 Feb 2021 21:25:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little League wants all your information]]>
            </title>
            <description>
<![CDATA[
Score 383 | Comments 184 (<a href="https://news.ycombinator.com/item?id=26296845">thread link</a>) | @ColinWright
<br/>
February 28, 2021 | https://honeypot.net/post/little-league-wants-all-your-information/ | <a href="https://web.archive.org/web/*/https://honeypot.net/post/little-league-wants-all-your-information/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
                <h3>Little League wants all your information</h3>
                
                    <p><em></em>
                        <span> Sun, Feb 28, 2021 
                                           </span>
                        <em></em>
                        <span>2-minute read</span>
                    </p>
                
            </div>

            <p>To sign kids up for our cityâ€™s Little League baseball program, you have to prove that theyâ€™re residents, which is reasonable. Whatâ€™s not reasonable is the amount of information you have to provide on the registration website. You have to upload scans of a document in each of 3 categories:</p>
<blockquote>
<p><strong>Proof of Residency 1</strong>
Choose one of the following: Driverâ€™s license, School records, Vehicle records, Employment records, Insurance documents</p>
<p><strong>Proof of Residency 2</strong>
Choose one of the following: Welfare/child care records, Federal records, State records, Local records, Support payment records, Homeowner or tenant records, Military records</p>
<p><strong>Proof of Residency 3</strong>
Choose one of the following: Voterâ€™s registration, Utility bills, Financial records, Medical records, Internet, cable, or satellite bills</p>
</blockquote>
<p>That alone is ripe for identity theft, but couple it with their privacy policy which includes this (emphasis mine):</p>
<blockquote>
<p>Without limitation, this typically requires the use of certain personal information, including registration data, event data, and other personal information, to provide program information, <strong>special offers or services through Little League and/or its trusted sponsors, partners, or licensees</strong>, to fulfill your requests for information or products/services, to maintain a list of verified and eligible participants, to maintain a list of volunteers and provide them with the operating tools to manage leagues, or to respond to your inquiries about our programs.</p>
</blockquote>
<p>In other words, you have to upload your most private information and agree to allow them to do as they like with it, including sharing it with whomever they like for any reason they choose.</p>
<p>This is unacceptable.</p>
</div></div>]]>
            </description>
            <link>https://honeypot.net/post/little-league-wants-all-your-information/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296845</guid>
            <pubDate>Sun, 28 Feb 2021 20:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The American-Dream-as-a-Service]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 20 (<a href="https://news.ycombinator.com/item?id=26296397">thread link</a>) | @jger15
<br/>
February 28, 2021 | https://www.thepullrequest.com/p/the-american-dream-as-a-service | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/the-american-dream-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h5>Austen Allred is the CEO and founder of Lambda School, a unique coding school that pioneered the â€˜income-sharing agreementâ€™ (ISA) model, whereby students only pay if theyâ€™re hired in their field of study. Lambda came out of incubator Y Combinator, before which he lived in his two-door Honda Civic and scalped soccer tickets at Stanford Stadium to get by. Prior to Bay Area entrepreneurship, he did a two-year mission to the Ukraine where he learned Russian and knocked on lots of doors. The interview was conducted via Zoom with Austen in Southern Utah, from where he routinely tweets out enviable photography of Utahâ€™s stunning landscape.</h5><p><strong>Your posts are some of the most uplifting things in my feed. Theyâ€™re either screenshots from an internal Slack or a retweet, and itâ€™s a Lambda student saying: I went from making $20,000 in some service job, and now I'm making $80,000/year doing something technical at (say) Cisco, and you've totally changed my life. </strong></p><p><strong>One thing you often post that I think isnâ€™t obvious to people who don't run a socio-economic escalator is all the necessary polish and look-and-feel of being part of the bougie techie class. For example, how you have this email protocol to set up a meeting. Or that if you think you're underpaid, you go in and you say, </strong><em><strong>screw you, pay me more or I leave</strong></em><strong>. It's intriguing that you donâ€™t only have to educate them to turn them into front end engineers, you also have to teach them the social skills around that to become that bougie techie person.</strong></p><p>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. It's very clear in all these protocols that we have in tech that you and I understand, you have to learn them the hard way. I'll give you a couple of examples. When I was in sixth grade, I was selling stuff on eBay. I was just this kid trying to hustle, and I had this mentor/entrepreneur who came into high school every now and then and just talked with us. And I was like, okay, real talk! What do I need to do to be taken seriously, because nobody takes me seriously because I'm a 15-year-old kid? And he sat me down and he said: <em>We are going to start using this thing called Gmail</em>. <em>I'm going to send you an invite, and you're going to set up firstname.lastname@gmail.com, no numbers, no nonsense, nothing else, you're going to have no signature, and you're only ever going to send text emails for the rest of your life.</em> <em>That's step one</em>. He just walked me through all this really, really basic stuff. </p><p>There was this other time I was in collegeâ€¦I was hustling and trying to get into startups and there was this guy at a conference I wanted to work with, so I went up and talked to him. And I said <em>what can I do to be like you? </em>He gave me his business card and said <em>just ping me next week</em>. </p><p>I spent hours and hours and hours looking up what <em>ping me</em> meant. I couldn't find anything. So eventually I called somebody and said <em>hey, this guy said ping me. What does that mean?</em> <em>How do I ping? </em>And that person was like, <em>no, no, itâ€™s a call or an email or anything really, just reach out to them. Doesnâ€™t matter how.</em> <em>That's all that ping means</em>. <em>You know, like a cell tower. Ping!</em> I was like, <em>ohhhhhhhh!</em> There's so much little stuff like that. Another classic example is intros, right? Or using Google Calendar. I didn't know how to use Google Calendar until I showed up in my first job. Someone tells me, <em>I am gonna put some time on your calendar</em>. And I think: <em>Oh, I guess I have a calendar</em>. That's not obvious if you don't come from, frankly, a certain class. But all of those things are important; if you don't intro somebody the right way to a VC, they know you're a dunce, automatically. Thereâ€™s nobody that sits you down and says <em>hey, you're gonna say thank you so-and-so, moving you to BCC</em>. It's not hard, but nobody ever tells you that anywhere.</p><h4>I've heard it described as â€˜the bottom 1000 universitiesâ€™: Assume there's some algorithm that spits out the combination of <em>is expensive</em> and <em>is ineffective</em>. There are at least 1000 universities in the US that should cease to exist. There are many universities that net do more harm than good.</h4><p><strong>There's no tech charm school that teaches you how to do all that stuff.</strong></p><p>Totally. And I'm sure there's more stuff. When one of our first students got hired at Uber, he showed up with his laptop. They tell him: <em>you're a mobile developer</em>. And he's like, <em>I can't be a mobile developer, I don't have a phone</em>. He didn't have a smartphone. So he called me freaking out: <em>What am I gonna do!? Uber wants to hire me. I don't have a smartphone.</em> I told him: <em>Uber does not care about that, Uberâ€™s gonna have a thousand phones, that's the least of Uberâ€™s worries. They're gonna give you a laptop too.</em> </p><p>Then he shows up to work on day one and they tell him: <em>Alright, you know, put in your bank account information here to get direct deposit.</em> He's like, <em>no just cut me a check and Iâ€™ll run to the check-cashing store.</em> </p><p>The Uber people reached out to me and said: <em>We donâ€™t know if this is going to work.</em> I was like, <em>he's a smart guy, itâ€™s just that he doesn't have a bank account</em>. So now we set up bank accounts for every student that doesn't have a bank account. The best way I think to describe Lambda School is the American-Dream-as-a-service. </p><p><strong>Wow. Thatâ€™s the corporate anthem right there.</strong></p><p>(Laughs.)</p><p><strong>There so much cultural encoding in an interview which, as you said, is just filtering for class. Butâ€¦as these are technical people, thereâ€™s actually an objective standard of merit. </strong></p><p>There are a whole swath of white collar jobs that the interview process literally is like, <em>Hey, I'm gonna play a little verbal tennis with you and see if you can stand your ground and if you can, you get the job</em>. That's probably the average white collar job.</p><h4>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. </h4><p><strong>Speaking of other jobs, do you see Lambda expanding to other fields? Is that even possible? </strong></p><p><strong>The thing that obviously aligns incentives is to look at education as a hard-nosed business proposition. I'm sure you personally care, but the reason why you care as a business owner is because you want them to get the job because otherwise you're not gonna get paid, right? Youâ€™ve invested a year and a half in this person, and they can't blow it up because they donâ€™t know about direct deposits, so you fix that. Which is good, and certainly a lot better than the business model universities have. But that model only works if there's some pretty predictable future stream of income along with pretty predictable employment demand. Can you imagine non-technical professions like trucking and nursing that have high demand and high wages? </strong></p><p>The cool thing about the incentive alignment is that we're not going to train you to be a sociologist, because it just doesn't work. A common critique of the ISA model is: <em>oh, now people aren't going to study poetry anymore.</em> And my response to that is: <em>yeah, we're not a university, we're a trade school</em>. The university has 18 million things that it does for you, and we cut cut off a tiny sliver of that, which is: we're going to help you get a better job, we're going to help you improve your state in life. That's all we do. </p><p>There are actually more high-paying jobs available than there are people to fill those roles. And that's true all over the place. I think about it as an optimization problem. You've got all this latent human potential, and it's just kind of bouncing around. Sometimes it goes to school, and it picks stuff at random to study, and you know what you know because of who youâ€™re surrounded by.</p><p>One aspect of Lambda School that I think is underappreciated is a whole lot of people come in having no idea of what software is, having no idea that there's such a thing as a software engineer. We have people who join and think it's like, <em>I'm gonna fix printers</em>. They know that tech is a high-paying field, but they're not surrounded it. If you're in the inner city, or in a rural area, you don't know a computer programmer. </p><p>One way to think about Lambda is like fintech: You have all these transactions that are moving all over the place, but what makes it all work is a clearinghouse that moves all the money to where it needs to go. I think of Lambda as kind of an economic clearinghouse: Here's all of the untapped human potential, here's all the would-be labor, and over hereâ€™s all the jobs that need to be done. There's nothing connecting the two right now other than sheer happenstance and going to university, or maybe you hear that there's a good job over here somewhere.</p><p>But right now the situation is not: <em>I'm making $50k, here's my skill set and my interest, I want to make $90k</em>. Somebody should be able to tell you how to do that, and right now, nobody can. Thatâ€™s crazy. More than half of GDP is just people working, and that's completely unoptimized. </p><p><strong>Right. Even I, who came from a middle-class background and went to the university track, it seemed like a recently poorly-managed process and I only ended up in science and technology by sheer happenstanceâ€¦</strong></p><p>You stumbled in, yeah? I feel the same way, and the interesting thing now is, depending on which way you happen to stumble, you can end up fabulously rich or destitute based on your stumblings. </p><h4>The other broken piece is the notion that you go to school once for 10 years when you're 18, and you'll be able to ride that for the rest of your career. Thatâ€™s probably false for a whole lot of people.</h4><p><strong>So this model youâ€™re describing, where you basically connect people from one income level to another higher one via various different processes. Iâ€™m curious what other connections you can imagine existing. </strong></p><p>The way to answer that is to see where all the shortages are, where are people trying to hire and those people donâ€™t exist? Tech is an obvious one, but itâ€™s all over the place in â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/the-american-dream-as-a-service">https://www.thepullrequest.com/p/the-american-dream-as-a-service</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/the-american-dream-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296397</guid>
            <pubDate>Sun, 28 Feb 2021 19:46:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I cut GTA Online loading times by 70%]]>
            </title>
            <description>
<![CDATA[
Score 3669 | Comments 664 (<a href="https://news.ycombinator.com/item?id=26296339">thread link</a>) | @kuroguro
<br/>
February 28, 2021 | https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/ | <a href="https://web.archive.org/web/*/https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>GTA Online. <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/9vgo0g/how_the_fuck_are_20_minute_load_times_acceptable/">Infamous</a> for its slow loading times. Having picked up the game again to finish some of the newer heists I was <em>shocked</em> (/s) to discover that it still loads just as slow as the day it was released 7 years ago.</p>
<p>It was time. Time to get to the bottom of this.</p>
<h2 id="Recon"><a href="#Recon" title="Recon"></a>Recon</h2><p>First I wanted to check if someone had already solved this problem. Most of the results I found pointed towards anecdata about <a target="_blank" rel="noopener" href="https://metro.co.uk/2017/11/01/why-does-gta-v-take-so-long-to-load-7041927/">how the game is so sophisticated</a> that it needs to load so long, stories on how the <a target="_blank" rel="noopener" href="https://steamcommunity.com/app/271590/discussions/0/217690940938819317/">p2p network architecture</a> is rubbish (not saying that it isnâ€™t), some elaborate ways of <a target="_blank" rel="noopener" href="https://gtaforums.com/topic/908000-fastest-way-to-load-into-gtao-single-player-first-or-straight-in/">loading into story mode and a solo session after that</a> and a couple of mods that allowed skipping the startup R* logo video. Some more reading told me we could save a whopping 10-30 seconds with these combined!</p>
<p>Meanwhile on my PCâ€¦</p>
<h2 id="Benchmark"><a href="#Benchmark" title="Benchmark"></a>Benchmark</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></pre></td><td><pre><span>Story mode load time:  ~1m 10s</span><br><span>Online mode load time: ~6m flat</span><br><span>Startup menu disabled, time from R* logo until in-game (social club login time isn't counted).</span><br><span></span><br><span>Old but decent CPU:   AMD FX-8350</span><br><span>Cheap-o SSD:          KINGSTON SA400S37120G</span><br><span>We have to have RAM:  2x Kingston 8192 MB (DDR3-1337) 99U5471</span><br><span>Good-ish GPU:         NVIDIA GeForce GTX 1070</span><br></pre></td></tr></tbody></table></figure>

<p>I know my setup is dated but what on <em>earth</em> could take 6x longer to load into online mode? I couldnâ€™t measure any difference using the story-to-online loading technique <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/kycy7a/gtao_loading_times_using_different_methods/">as others have found before me</a>. Even if it did work the results would be down in the noise.</p>
<h2 id="I-Am-Not-Alone"><a href="#I-Am-Not-Alone" title="I Am (Not) Alone"></a>I Am (Not) Alone</h2><p>If <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/ht4i56/your_average_online_loading_time/">this poll</a> is to be trusted then the issue is widespread enough to mildly annoy more than 80% of the player base. Itâ€™s been 7 years R*!</p>
<p><img src="https://nee.lv/images/pasted-0.png" alt="ðŸŽµWhat does the poll say?ðŸŽµ"></p>
<p>Looking around a bit to find who are the lucky ~20% that get sub 3 minute load times I came across <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RdCqDdjp6iU">a</a> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=pJzr3qfyCyg">few</a> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RK7BUFx_NGk">benchmarks</a> with high-end gaming PCs and an online mode load time of about 2 minutes. I would <del>kill</del> <em>hack</em> for a 2 minute load time! It does seem to be hardware-dependent but something doesnâ€™t add up hereâ€¦</p>
<p>How come their story mode still takes near a minute to load? (The M.2 one didnâ€™t count the startup logos btw.) Also, loading story to online takes them only a minute more while Iâ€™m getting about five more. I know that their hardware specs are a lot better but surely not 5x better.</p>
<h2 id="Highly-accurate-measurements"><a href="#Highly-accurate-measurements" title="Highly accurate measurements"></a>Highly accurate measurements</h2><p>Armed with such powerful tools as <em>the Task Manager</em> I began to investigate what resources could be the bottleneck.</p>
<p><img src="https://nee.lv/images/pasted-1.png" alt="Can you smell it?"></p>
<p>After taking a minute to load the common resources used for both story and online modes (which is near on par with high-end PCs) GTA decides to max out a single core on my machine for four minutes and do nothing else.</p>
<p>Disk usage? None! Network usage? Thereâ€™s a bit, but it drops basically to zero after a few seconds (apart from loading the rotating info banners). GPU usage? Zero. Memory usage? Completely flatâ€¦</p>
<p>What, is it mining crypto or something? I smell code. <em>Really bad code</em>.</p>
<h2 id="Single-thread-bound"><a href="#Single-thread-bound" title="Single thread-bound"></a>Single thread-bound</h2><p>While my old AMD CPU has 8 cores and it does pack a punch, it was made in the olden days. Back when AMDâ€™s <a target="_blank" rel="noopener" href="https://valid.x86.fr/bench/6u7sdy/1">single-thread performance</a> was <em>way</em> behind Intelâ€™s. This might not explain all of the load time differences but it should explain most of it.</p>
<p>Whatâ€™s odd is that itâ€™s using up <em>just</em> the CPU. I was expecting vast amounts of disk reads loading up resources or loads of network requests trying to negotiate a session in the p2p network. But this? This is probably a bug.</p>
<h2 id="Profiling"><a href="#Profiling" title="Profiling"></a>Profiling</h2><p>Profilers are a great way of finding CPU bottlenecks. Thereâ€™s only one problem - most of them rely on instrumenting the source code to get a perfect picture of whatâ€™s happening in the process. And I donâ€™t have the source code. Nor do I need microsecond-perfect readings - I have 4 minutesâ€™ worth of a bottleneck.</p>
<p>Enter stack sampling: for closed source applications thereâ€™s only one option. Dump the running processâ€™ stack and current instruction pointerâ€™s location to build a calling tree in set intervals. Then add them up to get statistics on whatâ€™s going on. Thereâ€™s only one profiler that I know of (might be ignorant here) that can do this on Windows. And it hasnâ€™t been updated in over 10 years. Itâ€™s <a target="_blank" rel="noopener" href="http://lukestackwalker.sourceforge.net/">Luke Stackwalker</a>! Someone, please give this project some love :)</p>
<p><img src="https://nee.lv/images/pasted-2.png" alt="The power of statistics compels you!"></p>
<p>Normally Luke would group the same functions together but since I donâ€™t have debugging symbols I had to eyeball nearby addresses to guess if itâ€™s the same place. And what do we see? Not one bottleneck but two of them!</p>
<h2 id="Down-the-rabbit-hole"><a href="#Down-the-rabbit-hole" title="Down the rabbit hole"></a>Down the rabbit hole</h2><p>Having borrowed <em>my friendâ€™s</em> completely legitimate copy of <em>the industry-standard disassembler</em> (no, I really canâ€™t afford the thingâ€¦ gonna learn to <a target="_blank" rel="noopener" href="https://ghidra-sre.org/">ghidra</a> one of these days) I went to take GTA apart.</p>
<p><img src="https://nee.lv/images/pasted-3.png" alt="Gibberish Galore"></p>
<p>That doesnâ€™t look right at all. Most high-profile games come with built-in protection against reverse engineering to keep away pirates, cheaters, and modders. Not that it has ever stopped them.</p>
<p>There seems to be some sort of an obfuscation/encryption at play here that has replaced most instructions with gibberish. Not to worry, we simply need to dump the gameâ€™s memory while itâ€™s executing the part we want to look at. The instructions have to be de-obfuscated before running one way or another. I had <a target="_blank" rel="noopener" href="https://github.com/glmcdona/Process-Dump">Process Dump</a> lying around, so I used that, but there are plenty of other tools available to do this sort of thing.</p>
<h2 id="Problem-one-Itâ€™sâ€¦-strlen"><a href="#Problem-one-Itâ€™sâ€¦-strlen" title="Problem one: Itâ€™sâ€¦ strlen?!"></a>Problem one: Itâ€™sâ€¦ strlen?!</h2><p>Disassembling the now-less-obfuscated dump reveals that one of the addresses has a label pulled out of somewhere! Itâ€™s <code>strlen</code>? Going down the call stack the next one is labeled <code>vscan_fn</code> and after that the labels end, tho Iâ€™m fairly confident itâ€™s <a target="_blank" rel="noopener" href="https://github.com/chakra-core/ChakraCore/blob/master/pal/src/safecrt/sscanf.c#L47"><code>sscanf</code></a>.</p>
<p><img src="https://nee.lv/images/pasted-4.png" alt="A graph a day keeps the skeptics away"></p>
<p>Itâ€™s parsing something. Parsing what? Untangling the disassembly would take forever so I decided to dump some samples from the running process using <a target="_blank" rel="noopener" href="https://x64dbg.com/">x64dbg</a>. Some debug-stepping later it turns out itâ€™sâ€¦ JSON! Theyâ€™re parsing JSON. A whopping <strong>10 megabytes</strong> worth of JSON with some <strong>63k item entries</strong>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span>...,</span><br><span>{</span><br><span>    <span>"key"</span>: <span>"WP_WCT_TINT_21_t2_v9_n2"</span>,</span><br><span>    <span>"price"</span>: <span>45000</span>,</span><br><span>    <span>"statName"</span>: <span>"CHAR_KIT_FM_PURCHASE20"</span>,</span><br><span>    <span>"storageType"</span>: <span>"BITFIELD"</span>,</span><br><span>    <span>"bitShift"</span>: <span>7</span>,</span><br><span>    <span>"bitSize"</span>: <span>1</span>,</span><br><span>    <span>"category"</span>: [<span>"CATEGORY_WEAPON_MOD"</span>]</span><br><span>},</span><br><span>...</span><br></pre></td></tr></tbody></table></figure>

<p>What is it? It appears to be data for a â€œnet shop catalogâ€ according to some references. I assume it contains a list of all the possible items and upgrades you can buy in GTA Online.</p>
<p><strong>Clearing up some confusion: I beleive these are in-game money purchasable items, not directly linked with <a target="_blank" rel="noopener" href="https://gta.fandom.com/wiki/Cash_Cards">microtransactions</a>.</strong></p>
<p>But 10 megs? Thatâ€™s nothing! And using <code>sscanf</code> may not be optimal but surely itâ€™s not that bad? Wellâ€¦</p>
<p><img src="https://nee.lv/images/pasted-5.png" alt="Ouch!"></p>
<p>Yeah, thatâ€™s gonna take a whileâ€¦ To be fair I had no idea most <code>sscanf</code> implementations called <code>strlen</code> so I canâ€™t blame the developer who wrote this. I would assume it just scanned byte by byte and could stop on a <code>NULL</code>.</p>
<h2 id="Problem-two-Letâ€™s-use-a-Hash-â€¦-Array"><a href="#Problem-two-Letâ€™s-use-a-Hash-â€¦-Array" title="Problem two: Letâ€™s use a Hash- â€¦ Array?"></a>Problem two: Letâ€™s use a Hash- â€¦ Array?</h2><p>Turns out the second offender is called right next to the first one. Theyâ€™re both even called in the same <code>if</code> statement as seen in this ugly decompilation:</p>
<p><img src="https://nee.lv/images/pasted-6.png" alt="Beggar thy neighbour"></p>
<p>All labels are mine, no idea what the functions/parameters are actually called.</p>
<p>The second problem? Right after parsing an item, itâ€™s stored in an array (or an inlined C++ list? not sure). Each entry looks something like this:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></pre></td><td><pre><span><span><span>struct</span> {</span></span><br><span>    <span>uint64_t</span> *hash;</span><br><span>    <span>item_t</span>   *item;</span><br><span>} entry;</span><br></pre></td></tr></tbody></table></figure>

<p>But before itâ€™s stored? It checks the <em>entire</em> array, one by one, comparing the hash of the item to see if itâ€™s in the list or not. With ~63k entries thatâ€™s <code>(n^2+n)/2 = (63000^2+63000)/2 = 1984531500</code> checks if my math is right. Most of them useless. You have unique <em>hashes</em> why not use a <em>hash map</em>.</p>
<p><img src="https://nee.lv/images/pasted-7.png" alt="Oof!"></p>
<p>I named it <code>hashmap</code> while reversing but itâ€™s clearly <code>not_a_hashmap</code>. And it gets even better. The hash-array-list-thing is empty before loading the JSON. And all of the items in the JSON are unique! They donâ€™t even <em>need</em> to check if itâ€™s in the list or not! They even have a function to directly insert the items! Just use that! Srsly, WAT!?</p>
<h2 id="PoC"><a href="#PoC" title="PoC"></a>PoC</h2><p>Now thatâ€™s nice and all, but no one is going to take me seriously unless I test this so I can write a clickbait title for the post.</p>
<p>The plan? Write a <code>.dll</code>, inject it in GTA, <a target="_blank" rel="noopener" href="https://github.com/TsudaKageyu/minhook">hook</a> some functions, ???, profit.</p>
<p>The JSON problem is hairy, I canâ€™t realistically replace their parser. Replacing <code>sscanf</code> with one that doesnâ€™t depend on <code>strlen</code> would be more realistic. But thereâ€™s an even easier way.</p>
<ul>
<li>hook strlen</li>
<li>wait for a long string</li>
<li>â€œcacheâ€ the start and length of it</li>
<li>if itâ€™s called again within the stringâ€™s range, return cached value</li>
</ul>
<p>Something like:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br></pre></td><td><pre><span><span><span>size_t</span> <span>strlen_cacher</span><span>(<span>char</span>* str)</span></span></span><br><span><span></span>{</span><br><span>  <span>static</span> <span>char</span>* start;</span><br><span>  <span>static</span> <span>char</span>* end;</span><br><span>  <span>size_t</span> len;</span><br><span>  <span>const</span> <span>size_t</span> cap = <span>20000</span>;</span><br><span></span><br><span>  </span><br><span>  <span>if</span> (start &amp;&amp; str &gt;= start &amp;&amp; str &lt;= end) {</span><br><span>    </span><br><span>    len = end - str;</span><br><span></span><br><span>    </span><br><span>    </span><br><span>    <span>if</span> (len &lt; cap / <span>2</span>)</span><br><span>      MH_DisableHook((LPVOID)strlen_addr);</span><br><span></span><br><span>    </span><br><span>    <span>return</span> len;</span><br><span>  }</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  </span><br><span>  len = builtin_strlen(str);</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  <span>if</span> (len &gt; cap) {</span><br><span>    start = str;</span><br><span>    end = str + len;</span><br><span>  }</span><br><span></span><br><span>  </span><br><span>  <span>return</span> len;</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<p>And as for the hash-array problem, itâ€™s more straightforward - just skip the duplicate checks entirely and insert the items directly since we know the values are unique.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></pre></td><td><pre><span><span><span>char</span> __fastcall <span>netcat_insert_dedupe_hooked</span><span>(<span>uint64_t</span> catalog, <span>uint64_t</span>* key, <span>uint64_t</span>* item)</span></span></span><br><span><span></span>{</span><br><span>  </span><br><span>  <span>uint64_t</span> not_a_hashmap = catalog + <span>88</span>;</span><br><span></span><br><span>  </span><br><span>  <span>if</span> (!(*(<span>uint8_t</span>(__fastcall**)(<span>uint64_t</span>*))(*item + <span>48</span>))(item))</span><br><span>    <span>return</span> <span>0</span>;</span><br><span></span><br><span>  </span><br><span>  netcat_insert_direct(not_a_hashmap, key, &amp;item);</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  <span>if</span> (*key == <span>0x7FFFD6BE</span>) {</span><br><span>    MH_DisableHook((LPVOID)netcat_insert_dedupe_addr);</span><br><span>    unload();</span><br><span>  }</span><br><span></span><br><span>  <span>return</span> <span>1</span>;</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<p>Full source of PoC <a target="_blank" rel="noopener" href="https://github.com/tostercx/GTAO_Booster_PoC">here</a>.</p>
<h2 id="Results"><a href="#Results" title="Results"></a>Results</h2><p>Well, did it work then?</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span>Original online mode load time:        ~6m flat</span><br><span>Time with only duplication check patch: 4m 30s</span><br><span>Time with only JSON parser patch:       2m 50s</span><br><span>Time with both issues patched:          1m 50s</span><br><span></span><br><span>(6*60 - (1*60+50)) / (6*60) = 69.4% load time improvement (nice!)</span><br></pre></td></tr></tbody></table></figure>

<p>Hell yes, it did! :))</p>
<p>Most likely, this wonâ€™t solve everyoneâ€™s load times - there might be other bottlenecks on different systems, but itâ€™s such a gaping hole that I have no idea how R* has missed it all these years.</p>
<h2 id="tl-dr"><a href="#tl-dr" title="tl;dr"></a>tl;dr</h2><ul>
<li>Thereâ€™s a single thread CPU bottleneck while starting up GTA Online</li>
<li>It turns out GTA struggles to parse a 10MB JSON file</li>
<li>The JSON parser itself is poorly built / naive and</li>
<li>After parsing thereâ€™s a â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/</a></em></p>]]>
            </description>
            <link>https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296339</guid>
            <pubDate>Sun, 28 Feb 2021 19:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create animated GIF and WebP from videos using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 51 (<a href="https://news.ycombinator.com/item?id=26296315">thread link</a>) | @Audiolite
<br/>
February 28, 2021 | https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page">
    <div>
      
      <div>

        

<p>Saturday, February 27, 2021</p>

<p><a href="https://mattj.io/posts/">Click here to go to all posts</a>. <em>Also published on <a href="https://mattjoseph.medium.com/create-animated-gif-and-webp-from-videos-using-ffmpeg-f1012267935a" target="_blank" rel="noopener">Medium</a></em></p>

<p><em>A guide to using FFmpeg to create all the animated content you want.</em></p>

<p>Whether itâ€™s for a website, a presentation, or sharing a fun clip with a friend on chat, you might want to convert a video to an animated GIF or animated WebP. Unfortunately, the visual tools for doing this vary by your operating system. Additionally, most conversion tools donâ€™t support <a href="https://en.wikipedia.org/wiki/WebP" target="_blank" rel="noopener">the WebP format</a>, even in 2021. WebP is based on VP8, a relatively recent video codec standard compared to the <a href="https://en.wikipedia.org/wiki/GIF" target="_blank" rel="noopener">GIF image format</a>.</p>

<p>So, this guide is for those who are willing to learn a bit of terminal in order to convert any video to the animated format of their choosing. The best part: this will work on all major operating systems and gives you all the control of the output you could want!</p>


<figcaption>Example GIF of typing "GIF" on a mechanical keyboard</figcaption>

<p>Letâ€™s get started!</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>To use this guide, you will need the following:</p>

<ul>
  <li>Basic knowledge of how to open and use the terminal on your operating system. If you need a cheat sheet or introductory guides, check out <a href="https://terminalcheatsheet.com/" target="_blank" rel="noopener">Terminal Cheat Sheet</a>.</li>
  <li>FFmpeg v4+ installed on your operating system and executable from your path. Here are some suggested places to learn down to do this:
    <ul>
      <li>macOS: <a href="https://superuser.com/a/624562" target="_blank" rel="noopener">https://superuser.com/a/624562</a></li>
      <li>Windows: <a href="https://video.stackexchange.com/a/20496" target="_blank" rel="noopener">https://video.stackexchange.com/a/20496</a></li>
      <li>Linux: Use your preferred package manager (e.g., <code>sudo apt install ffmpeg</code> on Ubuntu)</li>
    </ul>
  </li>
</ul>

<h2 id="what-isffmpeg">What is&nbsp;FFmpeg?</h2>

<p><a href="https://en.wikipedia.org/wiki/FFmpeg" target="_blank" rel="noopener">From Wikipedia</a>:</p>

<blockquote>
  <p>FFmpeg is a free and open-source software project consisting of a large suite of libraries and programs for handling video, audio, and other multimedia files and streams.</p>
</blockquote>

<p>For our purposes, we will use it to convert between formats, such as videos to GIFs or animated WebP. It has many uses, so I recommend checking it out for all your video processing needs!</p>

<h2 id="before-you-start-make-sure-you-can-run-ffmpeg-from-yourterminal">Before you start: make sure you can run FFmpeg from your&nbsp;terminal</h2>

<p>Since all of these commands require FFmpeg, we need to make sure itâ€™s available.</p>

<p>Open your terminal, and run this:</p>



<p>If FFmpeg is available, you will note output similar to this:</p>

<div><div><pre><code>FFmpeg version 4.3.1 Copyright Â© 2000â€“2020 the FFmpeg developers
...
</code></pre></div></div>


<figcaption>Checking the FFmpeg version on Linux</figcaption>

<p>Version 4 or higher of FFmpeg is recommended for this guide.</p>

<p>If you get an output that says something similar to <code>command not found: ffmpeg -version</code>, then check the <strong>Prerequisites</strong> section above and make sure you have FFmpeg installed on your system.</p>

<h2 id="convert-to-an-animated-gif-usingffmpeg">Convert to an animated GIF using&nbsp;FFmpeg</h2>

<h3 id="convert-a-whole-video-togif">Convert a whole video to&nbsp;GIF</h3>

<p><strong>Base command</strong></p>

<div><div><pre><code>ffmpeg -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop $NUMBER_OF_LOOPS $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated GIF.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop 0 sample_recording.gif
</code></pre></div></div>

<h3 id="convert-part-of-a-video-togif">Convert part of a video to&nbsp;GIF</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting part of a video to an animated GIF:</p>

<div><div><pre><code>ffmpeg -ss $INPUT_START_TIME -t $LENGTH -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop $NUMBER_OF_LOOPS $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_START_TIME - number of seconds in the input video to start from.
# * $LENGTH - number of seconds to convert from the input video.
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated GIF.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -ss 32.5 -t 7 -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop 0 sample_recording.gif
</code></pre></div></div>

<h2 id="convert-to-an-animated-webp-usingffmpeg">Convert to an animated WebP using&nbsp;FFmpeg</h2>

<h3 id="convert-a-whole-video-to-animatedwebp">Convert a whole video to animated&nbsp;WebP</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting an entire video to an animated WebP. You can use options like FPS, output width, and quality to determine the file size and quality of your output:</p>

<div><div><pre><code>ffmpeg -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v $OUTPUT_QUALITY -loop $NUMER_OF_LOOPS \
-preset picture -an -vsync 0 $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $OUTPUT_QUALITY - quality of the WebP output. Start with `50`.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated WebP.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v 50 -loop 0 \
-preset picture -an -vsync 0 sample_recording.webp
</code></pre></div></div>

<h3 id="convert-part-of-a-video-to-animatedwebp">Convert part of a video to animated&nbsp;WebP</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting part of a video to an animated WebP:</p>

<div><div><pre><code>ffmpeg -ss $INPUT_START_TIME -t $LENGTH -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v $OUTPUT_QUALITY -loop $NUMER_OF_LOOPS \
-preset picture -an -vsync 0 $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_START_TIME - number of seconds in the input video to start from.
# * $LENGTH - number of seconds to convert from the input video.
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $OUTPUT_QUALITY - quality of the WebP output. Start with `50`.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated WebP.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -ss 32.5 -t 7 -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v 50 -loop 0 \
-preset picture -an -vsync 0 sample_recording.webp
</code></pre></div></div>

<h2 id="when-should-i-use-an-animated-gif-versus-an-animatedwebp">When should I use an animated GIF versus an animated&nbsp;WebP?</h2>

<p>This depends on the quality, size, and support you want for your output. Modern browsers have support for animated WebP and the quality tends to be higher, but the processing power required is also higher.</p>

<h2 id="next-steps">Next steps</h2>

<p>This guide serves as a brief introduction to using FFmpeg to create an animated GIF or animated WebP from a video, but there is so much more you can do with the tool. There are also many options that FFmpeg supports for these formats that are not covered.</p>

<p>You can also get the code for all the commands and examples in one place by <a href="https://gist.github.com/devadvance/f2ad3cfe38afe3eeef64c72c46692158" target="_blank" rel="noopener">visiting the GitHub Gist here</a>.</p>


      </div>
    </div>
  </article></div>]]>
            </description>
            <link>https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296315</guid>
            <pubDate>Sun, 28 Feb 2021 19:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[World Beer Index 2021: The Cost and Consumption of Beer Around the World]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26295875">thread link</a>) | @giuliomagnifico
<br/>
February 28, 2021 | https://www.expensivity.com/beer-around-the-world/ | <a href="https://web.archive.org/web/*/https://www.expensivity.com/beer-around-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry-content">
<p>Beer. Everybody likes to drink it. Nobody likes to pay for it. Still, the cost of a beer stings more or less depending on where in the world youâ€™re drinking.</p>
<p>Expensivity wondered just how much the cost of beer differs from country and the effect the price of beer has on national consumption. We researched the price of a beer around the world and used World Health Organization statistics to figure out whoâ€™s drinking it all.</p>
<p><em>All prices are in US dollars. All beers are 33cl (330ml) bottles.</em></p>
<h2><strong>Key Findings</strong></h2>
<ul><li><strong>Qatar</strong> has the <strong>most expensive beer in the world</strong>, with an average price of <strong>US$11.26</strong> per 33cl (330ml) bottle.</li><li>The <strong>cheapest beer</strong> is in <strong>South Africa</strong>, where the average price is <strong>$1.68</strong> per bottle.</li><li>The <strong>Czech Republic</strong> has the <strong>highest consumption rate</strong>, with <strong>468 beers</strong> per person per year.</li><li><strong>Germans</strong> spend an average <strong>$1,907.78 per year</strong> on beer, the <strong>top figure</strong> in our study.</li></ul>
<h2><strong>Qatar Wins World Cup for Expensive Beer</strong></h2>
<p>A beer in Qatar is expensive. The mostly Muslim country introduced a <a href="https://www.nytimes.com/2019/01/01/world/middleeast/qatar-tax-alcohol.html">100% tax</a> on alcohol imports ahead of the 2022 World Cup, and visitors need a special permit to drink alcohol. China looks pretty expensive too, but consider that we averaged the price of a hotel beer ($13.61) and a supermarket beer ($1.81). </p>
<figure><a href="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg"><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg" alt="The Price of Beer Around The World" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>
<p><a href="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg"><strong>Tap on the map to see it full size</strong></a></p>
<p>Itâ€™s clear the steep prices are aimed at visitors. Beer is cheapest in South Africa, where a <a href="https://www.dailymaverick.co.za/article/2020-10-26-counting-the-cost-of-cheap-easily-available-alcohol-in-south-africa/">culture of buying in bulk</a> tends to keep prices down.</p>
<h2><strong>The International Beer Index in Full</strong></h2>
<p>Where there is beer, there are beer geeks. Here is Expensivityâ€™s data in full so you can find out exactly what kind of beer culture to expect from country to country. Click the arrows to sort by price, consumption, or total spend.</p>

<p>The ten countries with the highest average annual beer bill each have beer that costs upwards of four bucks. However, second-placed Poland is notable for its 62Â¢ carry-out beer, suggesting that much of Polandâ€™s $1,738 average beer bill is built up by hotel-faring bachelor parties.</p>
<p>Bosnia is an outlier among the big drinkers: the country is in eighth place for beer consumption by bottle (331/year) but 30<sup>th</sup> for overall spend ($647.21), thanks to an average price that comes in under two bucks.</p>
<h2><strong>Germany Spends the Most On Beer</strong></h2>
<p>Haitians just arenâ€™t that into beer. Spirits account for a whopping<a href="https://www.statista.com/statistics/973941/alcohol-consumption-latin-america-country-drink-type/"> 97% of booze consumed</a> in Haiti, where people drink fewer than four beers per year on average, with an annual beer bill of $10.02. Thatâ€™s the lowest beer consumption and spend in our study.</p>
<div><figure><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg" alt="How Much Do People Spend on Beer Annually?" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></figure></div>
<p><a rel="noreferrer noopener" href="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg" target="_blank"><strong>Tap on the map to see it full size</strong></a></p>
<p>At the other end of the scale, Germans spend just shy of $2k/year on beer. We found 15 countries with more expensive beer than Germany, but the nation sinks 411 bottles per person annually, so it pays the most in total. Germany is known for its<a href="https://www.dw.com/en/beer-culture-this-is-how-germany-drinks/a-19201434"> beer culture</a> and a stringent (delicious) beer purity law that has stood for over 500 years.</p>
<h2><strong>Czechia and Spain Lead Drinking Contest</strong></h2>
<p>So, whoâ€™s drinking all the beer? The Czech Republic takes the title, with 468 beers per person per year. However, capital Prague is the fourth most-visited city in Europe and infamous for its bachelor parties (<a href="https://www.lonelyplanet.com/articles/prague-different-type-visitor-after-lockdown">for now at least</a>). Like sunny Spain, in second place, Czechiaâ€™s beer consumption may be significantly swelled by visiting merry-makers.</p>
<div><figure><a href="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg"><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg" alt="How Much Beer Do People Drink In Different Countries?" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure></div>
<p><a href="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg"><strong>Tap on the map to see it full size</strong></a></p>
<p>Haiti drinks the least beer, counted per bottle or per spend. Most of the countries with a low beer intake can credit their predominantly Muslim populations for the abstinence. Armenia is an exception. The west Asian country drinks just 40 beers per person annually, with locals favoring<a href="https://theculturetrip.com/europe/armenia/articles/alcoholic-drinks-you-should-try-in-armenia/"> brandy, vodka, and wine</a>.</p>
<p>Armenians might not drink much beer, but the beer they drink is delicious, cheap, and<a href="https://www.smithsonianmag.com/travel/armenia-might-be-one-oldest-and-youngest-beermaking-countries-world-180964860/"> finely crafted</a>. Wherever youâ€™re drinking in the world, be sure to check out the tradition behind your beer, as well as the cost â€“ nothing adds<a href="https://www.expensivity.com/expensivity-by-the-ounce/"> value</a> to your experience like a beer with a story!</p>
<figure><img width="1024" height="690" src="https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1024x690.jpg" alt="" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1024x690.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-300x202.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-768x517.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1536x1034.jpg 1536w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<h3><strong>METHODOLOGY &amp; SOURCES</strong></h3>
<p>We collated the prices of a 330ml bottle of beer in supermarkets around the world using online shops, focusing on well-known beer brands such as Corona and Heineken. When we couldnâ€™t find the price via an online shop, we used <a href="https://www.numbeo.com/cost-of-living/">numbeo.com</a>.</p>
<p>To gain an average price, we called up hotels to find out the price of a beer from their lobby bar, and when this wasnâ€™t available, we used menus from bars found online. Once all the data was collected, we calculated the average price in US dollars using <a href="http://xe.com/">xe.com</a>.</p>
<p>Using the <a href="https://www.who.int/data/gho/data/indicators/indicator-details/GHO/alcohol-total-per-capita-(15-)-consumption-(in-litres-of-pure-alcohol)-with-95-ci">World Health</a> <a href="https://www.who.int/data/gho/data/indicators/indicator-details/GHO/alcohol-consumption-of-pure-alcohol-by-type-of-beverage-(-)">Organisation statistics</a>, we found the amount of alcohol consumption per capita and the percentage of annual beer consumption.</p>
</div></div>]]>
            </description>
            <link>https://www.expensivity.com/beer-around-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295875</guid>
            <pubDate>Sun, 28 Feb 2021 18:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lean into Procrastination]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26295774">thread link</a>) | @patapizza
<br/>
February 28, 2021 | https://jodent.io/posts/lean-into-procrastination | <a href="https://web.archive.org/web/*/https://jodent.io/posts/lean-into-procrastination">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jodent.io/posts/lean-into-procrastination</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295774</guid>
            <pubDate>Sun, 28 Feb 2021 18:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird architectures weren't supported to begin with]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 254 (<a href="https://news.ycombinator.com/item?id=26294397">thread link</a>) | @woodruffw
<br/>
February 28, 2021 | https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Feb 28, 2021</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#rant">rant</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<hr>

<h4 id="preword">Preword</h4>

<p>This post contains my own opinions, not the opinions of my employer or any open source groups I
belong or contribute to.</p>

<p>Itâ€™s also been rewritten 2Â½ times, and (I think) reads confusingly in places. But I promised
myself that Iâ€™d get it out of the door instead of continuing to sit on it, so here we go.</p>

<hr>

<p>Thereâ€™s been a decent amount of <del>drama</del> debate in the open source community about <em>support</em>
recently, originating primarily from
<a href="https://github.com/pyca/cryptography/issues/5771">pyca/cryptographyâ€™s decision to use Rust for some ASN.1 parsing routines</a><sup id="fnref:asn1" role="doc-noteref"><a href="#fn:asn1">1</a></sup>.</p>

<p>To summarize the situation: building the latest <code>pyca/cryptography</code> release from scratch now requires
a Rust toolchain. The only currently<sup id="fnref:gccrust" role="doc-noteref"><a href="#fn:gccrust">2</a></sup> Rust toolchain is built on <a href="https://llvm.org/">LLVM</a>, which
supports a (relatively) limited
<a href="https://llvm.org/docs/CompilerWriterInfo.html">set of architectures</a>. Rust further whittles this
set down into <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">support tiers</a>, with
some targets not receiving automated testing (tier 2) or official builds (tier 3).</p>

<p>By contrast, upstream<sup id="fnref:gcchell" role="doc-noteref"><a href="#fn:gcchell">3</a></sup> GCC supports a <a href="https://gcc.gnu.org/backends.html">somewhat larger</a>
set of architectures. But C<sup id="fnref:c" role="doc-noteref"><a href="#fn:c">4</a></sup>, cancer that it is, finds its way onto every architecture with or
without GCC (or LLVMâ€™s) help, and thereby bootstraps <a href="https://github.com/python/cpython">everything</a>
<a href="https://www.gnome.org/">else</a>.</p>

<p>Program packagers and distributors (frequently separate from project maintainers themselves)
are very used to Câ€™s universal presence. Theyâ€™re so used to it that theyâ€™ve built generic
mechanisms for putting entire distributions onto new architectures with
only a single assumption: the presence of a serviceable C compiler.</p>

<p>This is the heart of the conflict: Rust (and many other modern, safe languages) use LLVM for its
relative simplicity<sup id="fnref:simple" role="doc-noteref"><a href="#fn:simple">5</a></sup>, but LLVM does not support either native or cross-compilation to many
less popular (read: niche) architectures. Package managers are increasingly finding that one of
their oldest assumptions can be easily violated, and theyâ€™re not happy about that.</p>

<p>But hereâ€™s the problem: <em>itâ€™s a bad assumption</em>. The fact that itâ€™s the default
represents an <strong>unmitigated</strong> security, reliability, and reproducibility <em>disaster</em>.</p>

<h2 id="a-little-thought-problem">A little thought problem</h2>

<p>Imagine, for a moment, that youâ€™re a maintainer of a popular project.</p>

<p>Everything has gone right for you: you have happy users, an active development base, and maybe even
corporate sponsors. Youâ€™ve also got a CI/CD pipeline that produces canonical releases of your
project on tested architectures; you treat any issues with uses of those releases as a bug in the
project itself, since youâ€™ve taken responsibility for packaging it.</p>

<p>Because your project is popular, <strong>others</strong> also distribute it: Linux distributions, third-party
package managers, and corporations seeking to deploy their own controlled builds. These others have
slightly different needs and setups and, to varying degrees, will:</p>

<ul>
  <li>Build your project with slightly (or completely) different versions of dependencies</li>
  <li>Build your project with slightly (or completely) different optimization flags and other potentially
ABI-breaking options</li>
  <li>Distribute your project with insecure or outright broken defaults</li>
  <li>Disable important security features because other parts of their ecosystem havenâ€™t caught up</li>
  <li>Patch your project or its build to make it â€œworkâ€ (read: compile and not crash immediately) with
completely new dependencies, compilers, toolchains, architectures, and environmental constraints</li>
</ul>

<p>You donâ€™t know about <em>any</em> of the above until the bug reports start rolling in: users will report
bugs that have already been fixed, bugs that you explicitly document as caused by unsupported
configurations, bugs that <em>donâ€™t make any sense whatsoever</em>.</p>

<p>You struggle to debug your usersâ€™ reports, since you donâ€™t have access to the niche
hardware, environments, or corporate systems that theyâ€™re running on. You slowly burn out
as an unending torrent of already fixed bugs that never seem to make it to your users. Your
user base is unhappy, and you start to wonder why youâ€™re putting all this effort into
project maintenance in the first place. Open source was supposed to be fun!</p>

<p>Whatâ€™s the point of this spiel? Itâ€™s <em>precisely</em> what happened to <code>pyca/cryptography</code>:
nobody asked them whether it was a good idea to try to run their code on
<a href="https://en.wikipedia.org/wiki/PA-RISC">HPPA</a>, much less
<a href="https://en.wikipedia.org/wiki/IBM_System/390">System/390</a><sup id="fnref:s390" role="doc-noteref"><a href="#fn:s390">6</a></sup>; some packagers just went ahead
and did it, and are frustrated that it no longer works. People just <em>assumed</em> that it
would, because there is <em>still</em> a norm that everything flows from C, and that any
host with a halfway-functional C compiler should have the entire open source ecosystem
at its disposal.</p>

<h3 id="reflections-on-trusting-random-platforms">Reflections on trusting random platforms<sup id="fnref:rott" role="doc-noteref"><a href="#fn:rott">7</a></sup></h3>

<p>Security-sensitive software<sup id="fnref:security" role="doc-noteref"><a href="#fn:security">8</a></sup><sup>,</sup><sup id="fnref:reliability" role="doc-noteref"><a href="#fn:reliability">9</a></sup>, <em>particularly</em> software written
in unsafe languages, is <strong>never</strong> secure in its own right.</p>

<p>The security of a program is a function of its own design and testing,
<em>as well as</em> the design, testing, and basic correctness of its underlying platform: everything from
the userspace, to the kernel, to the compilers themselves. The latter
is an <strong>unsolved problem</strong> in the <em>very best of cases</em>: bugs are <em>regularly</em>
found in even the most mature compilers (Clang, GCC) and their most mature backends (x86, ARM). Tiny
changes to or differences in build systems can have profound effects at the binary level, like
<a href="https://insights.sei.cmu.edu/cert/2018/08/when-aslr-is-not-really-aslr---the-case-of-incorrect-assumptions-and-bad-defaults.html">accidentally removing security mitigations</a>.
Seemingly innocuous patches can make otherwise safe code
<a href="https://wiki.gentoo.org/wiki/Hardened/GNU_stack_quickstart">exploitable</a> in the context of
other vulnerabilities.</p>

<p>The problem gets worse as we move towards niche architectures and targets that are used
primarily by small hobbyist communities.
Consider <a href="https://en.wikipedia.org/wiki/Motorola_68000_series">m68k</a>
(one of the other architectures affected by <code>pyca/cryptography</code>â€™s move to Rust): even
GCC <a href="https://gcc.gnu.org/legacy-ml/gcc-patches/2019-10/msg02044.html">was considering</a> removing
support due to lack of maintenance, until hobbyists stepped in. That isnâ€™t to say that any
<em>particular</em> niche target is full of bugs<sup id="fnref:although" role="doc-noteref"><a href="#fn:although">10</a></sup>; only to say that itâ€™s a greater likelihood
for niche targets <em>in general</em>. <strong>Nobody</strong> is regularly testing the mountain of userspace
code that implicitly forms an operating contract with arbitrary programs on these platforms.</p>

<p>Project maintainers donâ€™t want to chase down compiler bugs on ISAs or systems that they never
intended to support in the first place, and arenâ€™t receiving any active support feedback about.
They <em>especially</em> donâ€™t want to have vulnerabilities associated
with their projects because of buggy toolchains <em>or</em> tooling inertia when working on security
improvements.</p>

<h3 id="some-more-finger-pointing">Some more finger-pointing</h3>

<p>As someone who <em>likes</em> C: this is all Câ€™s fault. Really.</p>

<p>Beyond language-level unsafety (plenty of people have
<a href="https://fishinabarrel.github.io/">covered that already</a>), C is <em>organizationally</em> unsafe:</p>

<ul>
  <li>
    <p>Thereâ€™s no standard way to write tests for C.</p>

    <p>Functional and/or unit tests <em>alone</em> would go a long
way in assuring baseline correctness on weird architectures or platforms, but the cognitive
overhead of testing C <em>and</em> getting those tests running ensures that well-tested builds of C
programs will continue to be the exception, rather than the rule.</p>
  </li>
  <li>
    <p>Thereâ€™s no standard way to build C programs.</p>

    <p><a href="https://blog.yossarian.net/2019/04/23/Make-is-probably-fine">Make is fine</a>, but itâ€™s not standard.
Disturbingly large swathes of critical open source infrastructure are compiled using a hodgepodge
of Make, autogenerated rules from autotools, and the maintainerâ€™s boutique shell scripts. One
consequence of this is that C builds tend to be flexible <em>to a fault</em>: prospective packagers
can inject all sorts of behavior-modifying flags that may not be attested directly
in the compiled binary or other build products. The result: itâ€™s almost impossible to prove that
two separate builds on different machines are the same, which means more maintainer pain.</p>
  </li>
  <li>
    <p>Thereâ€™s no standard way to distribute C programs.</p>

    <p>Yes, I know that package managers exist. Yes, I know how to statically link. Yes, I know how to
vendor libraries and distribute self-contained program â€œbundlesâ€. None of these are or amount to
a <em>complete</em> standard, and each introduces additional logistical or security problems.</p>
  </li>
  <li>
    <p>Thereâ€™s no such thing as truly cross-platform C.</p>

    <p>The C abstract machine, despite looking a lot like a PDP-11, leaks the underlying memory
and ordering semantics of the architecture being targeted. The result is that even seasoned
C programmers regularly rely on architecture-specific assumptions when writing ostensibly
cross-platform code: assumptions about the atomicity of reads and writes, operation ordering,
coherence and visibility in self-modifying code, the safety and performance of unaligned accesses,
and so forth. Each of these, apart from being a potential source of unsafety, are <strong>impossible
to detect</strong> statically in the general case: they are, after all, perfectly correct
(and frequently intended!) on the programmerâ€™s host architecture.</p>
  </li>
</ul>

<p>By contemporary programming language standards, these are conspicuous gaps in functionality:
weâ€™ve long since learned to bake testing, building, distribution, and sound abstract machine
semantics into the standard tooling for languages (and language design itself). But their absence
is <strong>doubly pernicious</strong>: they ensure that C remains a perpetually
unsafe development ecosystem, <em>and</em> an appealing target when bootstrapping a new platform.</p>

<h2 id="the-life-of-a-package-maintainer-is-hard">The life of a package maintainer is hard</h2>

<p>The project maintainer isnâ€™t the only person hurting in the status quo.</p>

<p>Everything stated above <em>also</em> leads to a bum job for the lowly package maintainer<sup id="fnref:yt" role="doc-noteref"><a href="#fn:yt">11</a></sup>. Theyâ€™re
(probably) also an unpaid open source hobbyist, and theyâ€™re operating with constraints that
the upstream isnâ€™t likely to immediately understand:</p>

<ul>
  <li>The need to link against versions of dependencies that have already been packaged (and perhaps patched)</li>
  <li>ABI and ISA subset constraints, stemming from a need to distribute binaries that function with
relatively old versions of <code>glibc</code> or x86-64 CPUs without modern extensions</li>
  <li>Limited visibility into each projectâ€™s test suite and how to run it, much less what to do when
it fails</li>
</ul>

<p>They <em>also</em> have to deal with users who are unsympathetic to those reports, and who:</p>

<ul>
  <li>Rarely submit reports to the packager (they bug the project directly instead!), or â€¦</li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with">https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294397</guid>
            <pubDate>Sun, 28 Feb 2021 16:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging K8s services: 3 tools for 3 scenarios]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26294015">thread link</a>) | @erkanerol
<br/>
February 28, 2021 | https://erkanerol.github.io/post/debugging-k8s-services/ | <a href="https://web.archive.org/web/*/https://erkanerol.github.io/post/debugging-k8s-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Feb 28, 2021 Â· <a href="https://erkanerol.github.io/post/debugging-k8s-services/#disqus_thread">Comments</a><br><a href="https://erkanerol.github.io/categories/software">Software</a><a href="https://erkanerol.github.io/categories/k8s">k8s</a><a href="https://erkanerol.github.io/categories/en">EN</a></span></p><p>While developing/debugging applications that serve services on k8s in production, you need some tools/commands. This blog post explains three different scenarios+tools for you.</p><blockquote><p>Please ping me if there is something wrong. <a href="https://twitter.com/erkan_erol_">https://twitter.com/erkan_erol_</a></p></blockquote><h2 id="setup">Setup</h2><p>Here is our basic setup to explain the scenarios.</p><p><img src="https://erkanerol.github.io/img/k8s-services/Setup.png" title="Setup"></p><p>We have 3 services. <code>service-front</code> is exposed to the public via an ingress. <code>service-front</code> depends on <code>service-middle</code> and <code>service-middle</code> depends on <code>service-back</code>. The communications are done through k8s services.</p><p>To install this setup, here are the necessary commands:</p><pre><code>kubectl create ns service-debug
kubectl -n service-debug run service-back --image=erkanerol/service-back:v1 --port=8080 --expose=true --labels="app=back"
kubectl -n service-debug run service-middle --image=erkanerol/service-middle:v1 --port=8081 --expose=true --labels="app=middle"
kubectl -n service-debug run service-front --image=erkanerol/service-front:v1 --port=8082 --expose=true --labels="app=front"
</code></pre><p>Here is the source code of these services: <a href="https://github.com/erkanerol/service-examples-for-blog">https://github.com/erkanerol/service-examples-for-blog</a></p><h4 id="scenario">Scenario:</h4><p>As a developer, I want to send some requests to <code>service-back</code> directly and see the result without touching the other services.</p><h4 id="problem">Problem:</h4><p><code>service-back</code> is not exposed to the public and you cannot send requests to it directly.</p><h4 id="solution">Solution:</h4><p>With <code>kubectl port-forward</code>, it is possible to open a tunnel from your local machine to the <code>service-back</code> in the cluster. See <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward">https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward</a></p><h4 id="steps">Steps:</h4><p>Run the command below in a terminal.</p><pre><code>$ kubectl -n service-debug port-forward service/service-back 8080:8080
Forwarding from 127.0.0.1:8080 -&gt; 8080
Forwarding from [::1]:8080 -&gt; 8080
</code></pre><p><br>Then run the curl command below in another terminal to see that you are able to access <code>service-back</code></p><pre><code>$ curl localhost:8080
Timestamp from back:1614508193
</code></pre><h4 id="how-does-it-work">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level1.png" title="Level1"></p><p><code>kubectl</code> starts a process which binds <code>localhost:8080</code>. It listens that port and establishes a connection to api-server, which forwards the requests to <code>service-back</code>.</p><h4 id="scenario-1">Scenario:</h4><p>As a developer, I want to run <code>service-front</code> in my local machine so that I can put breakpoints in my IDE to debug my application.</p><h4 id="problem-1">Problem:</h4><p><code>service-front</code> is designed to run in Kubernetes and it accesses <code>service-middle</code> via the k8s service. The service name is hardcoded or hard to be configurable or you are too lazy to mock the dependencies in your local machine.</p><h4 id="solution-1">Solution:</h4><p><code>kubefwd</code> is a useful tool for this problem. It does bulk port-forwarding and manages dns entries in your local machine. See <a href="https://github.com/txn2/kubefwd">https://github.com/txn2/kubefwd</a></p><h4 id="steps-1">Steps:</h4><p>Run the command below in a terminal</p><pre><code>$ sudo KUBECONFIG=$KUBECONFIG kubefwd svc -n service-debug -l app=middle
</code></pre><blockquote><p>Note that <code>kubefwd</code> requires root privileges and it has to be run with <code>sudo</code>. Set <code>KUBECONFIG</code> variable without any home folder reference beforehand.</p></blockquote><p>In another terminal, run <code>front</code> application in your local machine. Note that you can run it in debug mode as well and put breakpoints.</p><pre><code>$ cd /tmp
$ git clone https://github.com/erkanerol/service-examples-for-blog.git
$ cd service-examples-for-blog/front
$ go run main.go
</code></pre><p>In another terminal, Send a request to <code>front</code> app to see that your front app serves locally and it accesses <code>service-middle</code> in the cluster.</p><pre><code>$ curl localhost:8082
Response from service middle:'Response from service back:'Timestamp from back:1614513901''
</code></pre><h4 id="how-does-it-work-1">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level2.png" title="Level2"></p><p>As you can see from the logs of <code>kubefwd</code></p><pre><code>...
INFO[14:07:38] 'cat /etc/hosts' to see all host entries.    
INFO[14:07:38] Loaded hosts file /etc/hosts                 
INFO[14:07:38] HostFile management: Original hosts backup already exists at /root/hosts.original 
...
INFO[14:07:38] Port-Forward: 127.1.27.1 service-middle:8081 to pod service-middle:8081 
...
</code></pre><p>It starts a process that binds <code>127.1.27.1:8081</code> and manipulates the <code>/etc/hosts</code> for <code>service-middle</code></p><pre><code>$ cat /etc/hosts |grep service-middle
127.1.27.1       service-middle.default service-middle.default.svc service-middle.default.svc.cluster.local service-middle.default.minikube service-middle.default.svc.minikube service-middle.default.svc.cluster.minikube service-middle service-middle.service-debug service-middle.service-debug.svc service-middle.service-debug.svc.cluster.local service-middle.service-debug.minikube service-middle.service-debug.svc.minikube service-middle.service-debug.svc.cluster.minikube
</code></pre><div><p>Then your local <code>front</code> app can access the <code>service-middle</code> like in k8s cluster without any extra effort.</p></div><h4 id="scenario-2">Scenario:</h4><p>As a developer, I want to run <code>service-middle</code> in my local machine so that I can put breakpoints in my IDE to debug my application.</p><h4 id="problem-2">Problem:</h4><p><code>service-middle</code> is designed to run in Kubernetes. It accesses <code>service-back</code> via k8s services. Also, its consumer <code>service-front</code> is running on k8s. The services are not available in your local machine and it is hard to mock all these environments in your local machine.</p><h4 id="solution-2">Solution:</h4><p><code>telepresence</code> is a useful tool for this problem. See <a href="https://www.telepresence.io/">https://www.telepresence.io/</a></p><h4 id="steps-2">Steps:</h4><p>Delete <code>service-middle</code> from your k8s cluster at first. We will run it locally.</p><pre><code>kubectl -n service-debug delete service service-middle --ignore-not-found=true
kubectl -n service-debug delete pod service-middle --ignore-not-found=true
</code></pre><p><br>Run telepresence for <code>service-middle</code></p><pre><code>telepresence --namespace service-debug --new-deployment service-middle --expose 8081
</code></pre><p><br>In another terminal, run <code>middle</code> application in your local machine. Note that you can run it in debug mode as well and put breakpoints.</p><pre><code>$ cd /tmp
$ git clone https://github.com/erkanerol/service-examples-for-blog.git
$ cd service-examples-for-blog/middle
$ go run main.go
</code></pre><p><br>In another terminal, run the command below to send a request to <code>service-front</code> via a temporary pod in the cluster.</p><pre><code>$ kubectl -n service-debug run curl -it  --rm=true --image=curlimages/curl --restart=Never -- http://service-front:8082 
Response from service middle:'Response from service back:'Timestamp from back:1614517363''pod "curl" deleted
</code></pre><p>Note that your request goes to <code>service-front</code> in k8s, which sends a request to <code>service-middle</code> in your local machine, which sends a request to <code>service-back</code> in the cluster.</p><h4 id="how-does-it-work-2">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level3.png" title="Level3"></p><p>Basically, <code>telepresence</code> deploys a proxy/fake agent into cluster and opens a two-way tunnel between your local environment and the cluster via that agent. Then you are able to run the <code>middle</code> service in your local machine without adapting the consumers/dependent services.</p><p>A detailed explanation about how telepresence works is available here: <a href="https://www.telepresence.io/discussion/how-it-works">https://www.telepresence.io/discussion/how-it-works</a></p><h2 id="summary">Summary</h2><ul><li>If you need to access a service without exposing it to public, <code>kubectl port-forward</code> is enough.</li><li>If you need to run a service locally for debugging and your service needs to access other services on k8s, <code>kubefwd</code> is enough. It manages DNS entries in your local machine and opens a one-way tunnel from your machine to cluster for the dependencies of your service.</li><li>If you need to run a service locally for debugging and your application has some consumers in the cluster, <code>telepresence</code> is your tool. It opens two-way network channel and it forwards requests from cluster to your local instance as well.</li></ul><p>p.s. Admission webhooks in Kubernetes are similar to <code>service-middle</code>. They receive some requests from api-server and they may send some requests to other services in the cluster. Therefore, <code>telepresence</code> is a useful tool for debugging admission webhooks. In the next blog post, I am going to explain how to debug validating webhooks.</p></div></div></div>]]>
            </description>
            <link>https://erkanerol.github.io/post/debugging-k8s-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294015</guid>
            <pubDate>Sun, 28 Feb 2021 15:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Email Cleaner: Clean tracking links and pixels from email newsletters]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26293424">thread link</a>) | @bengtan
<br/>
February 28, 2021 | https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/ | <a href="https://web.archive.org/web/*/https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
  <article>
    

    

    
    
    <h2>Overview</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#what-is-it">What is it?</a></li>
    <li><a href="#email-cleaner">Email Cleaner</a></li>
    <li><a href="#getting-started">Getting started</a>
      <ul>
        <li><a href="#forwarding-loops">Forwarding loops</a></li>
      </ul>
    </li>
    <li><a href="#how-it-works">How it works</a></li>
    <li><a href="#benefits">Benefits</a></li>
    <li><a href="#plain-text-emails">Plain text emails</a></li>
    <li><a href="#caveats">Caveats</a></li>
    <li><a href="#privacy">Privacy</a></li>
    <li><a href="#feedback">Feedback</a></li>
  </ul>
</nav>
    <p>Iâ€™m supposed to be blogging instead of doing <a href="https://bengtan.com/blog/app-startup-vs-content-startup/">â€œapp startupâ€</a> things but I got sidetracked and built another side project (again).</p>
<p>Iâ€™ve been getting into email newsletters. Over the last month, Iâ€™ve gone from zero newsletters to eleven of them. My inbox is now overflowing with newsletters. Maybe Iâ€™ll have to cut back but thatâ€™s a story for another time.</p>
<p>I have a new pet hate: Links in email newsletters.</p>
<p>They are user-hostile. Substack is the worst. Their URLs look like this:</p>
<p><a href="http://email.substack.com/c/ejXDKM2OhCAMgJ9muI3hT3QOHPayr2EKVIesgwbquL794njbhEIhNP36eSCclnzYdSnEzm2gY0WbcC8zEmFmW8E8xGBlb1pljGTBdsJpLVksw5gRXxBnS3lDtm5ujh4oLulTIVvJnjbgCKC51hxawbuuxzCCcwHAo0CprrawhYjJo8U35mNJyGb7JFrLTX3d5Hdd-743CWjL2PjlVR8gU_qZLpoGLdre3LkUd87Vw9wrnZX1ymUN3XbtoxENjIYbFKBVq3wrxlF47oLolZNKonrcNC-bKwT-RzT4u1aKRBHmd8S99mTZOkwTQRL153TOfZKcYw_1fG0p0jFgAjdjuIzQJfbjaJgwYa7CwwBkhRGq75Xu-4fpLgVVmZKdFNUzqxxhqVXJ_uP4AyNKkNQ">http://email.substack.com/c/ejXDKM2OhCAMgJ9muI3hT3QOHPayr2EKVIesgwbquL794njbhEIhNP36eSCclnzYdSnEzm2gY0WbcC8zEmFmW8E8xGBlb1pljGTBdsJpLVksw5gRXxBnS3lDtm5ujh4oLulTIVvJnjbgCKC51hxawbuuxzCCcwHAo0CprrawhYjJo8U35mNJyGb7JFrLTX3d5Hdd-743CWjL2PjlVR8gU_qZLpoGLdre3LkUd87Vw9wrnZX1ymUN3XbtoxENjIYbFKBVq3wrxlF47oLolZNKonrcNC-bKwT-RzT4u1aKRBHmd8S99mTZOkwTQRL153TOfZKcYw_1fG0p0jFgAjdjuIzQJfbjaJgwYa7CwwBkhRGq75Xu-4fpLgVVmZKdFNUzqxxhqVXJ_uP4AyNKkNQ</a></p>
<p>What is that, Substack?! Is that really a URL with 400+ characters?!</p>
<p>I have an ingrained habit of hovering over links. This allows me to see where it links to and decide whether to click on it.</p>
<p>Itâ€™s a good habit.</p>
<p>Itâ€™s also a security â€œbest practiceâ€. Hovering over a link helps to check whether itâ€™s a phishing link.</p>
<p>Email newsletters have broken this. I have no idea where these user-hostile links go. For their own self interest, mailing list service providers have denied me a basic tenet of the web: Knowing what Iâ€™m clicking on before I click.</p>
<p>Itâ€™s also demeans the newsletter. A newsletter which purports to send me a â€˜list of interesting linksâ€™ is just sending me a list of crap because Iâ€™m not clicking on those I-have-no-idea-where-itâ€™s-going links.</p>
<p>If the link was something like <a href="http://www.google.com/url?sa=t&amp;url=https://www.wikipedia.org/&amp;usg=AOvVaw3ay7vaEtH0yTTYdDmrvinX">http://www.google.com/url?sa=t&amp;url=https://www.wikipedia.org/&amp;usg=AOvVaw3ay7vaEtH0yTTYdDmrvinX</a> I wouldnâ€™t be as peeved because I can see where it links to.</p>
<p>But no, I donâ€™t think theyâ€™ll compromise.</p>
<p>Not happy.</p>
<p>I set about trying to make the situation palatable. I asked <a href="https://news.ycombinator.com/item?id=26188976">here</a>, <a href="https://www.reddit.com/r/SomebodyMakeThis/comments/ln4dep/smt_hover_over_links_in_email_newsletters_and_see/">here</a>, and <a href="https://www.indiehackers.com/post/17a17962db">here</a> but I didnâ€™t find anything satisfactory.</p>
<p>So I built my own solution.</p>
<h2 id="what-is-it">What is it?</h2>
<p>I hooked a script up to an email address. Upon receiving an email, the script will replace tracking links with their destination URL, remove tracking pixels, and send it back to the sender.</p>
<p>Then, I set up a gmail filter to forward my newsletters to the script.</p>
<p>Yay!</p>
<p>Now, when I receive an email newsletter, gmail forwards it to the script. The script sends it back to me with nice clean URLs. Once again, I can see where links lead to before I decide whether to click.</p>
<p>Tracking parameters (ie. <code>utm_*</code>) and tracking pixels are removed as well. (I donâ€™t care strongly about this but it was easy to add so I did.)</p>
<h2 id="email-cleaner">Email Cleaner</h2>
<p>For lack of a better name, Iâ€™m calling it <strong>Email Cleaner</strong>. <strong>It cleans crap from email newsletters</strong>.</p>
<p>(Alternatively, I considered calling it â€˜<strong>UntrackMe: Remove tracking from email newsletters</strong>â€™. Which sounds better?)</p>
<p>Iâ€™m letting others try it. Maybe other people find it useful too. If thereâ€™s enough interest, Iâ€™ll turn it into a proper side project.</p>
<h2 id="getting-started">Getting started</h2>
<p>To try Email Cleaner, forward an email newsletter to <code>email-cleaner@bengtan.com</code>.</p>
<p>In a minute or two, you should get the newsletter sent back to you (from <code>no-reply@bengtan.com</code>) with cleaned links and tracking pixels removed.</p>
<p>If you decide you like it, you can set up your email program to automatically forward email newsletters to <code>email-cleaner@bengtan.com</code>.</p>
<p>How you do this depends on your email program so youâ€™ll have to work it out youself.</p>
<p>Note: Please donâ€™t set up your email program to automatically delete after forwarding. Since this is a new service, itâ€™s a good idea to retain the original emails in case something goes wrong.</p>
<h3 id="forwarding-loops">Forwarding loops</h3>
<p>If your automatic forwarding configuration mistakenly forwards the cleaned email (from Email Cleaner) back to Email Cleaner, it will detect this and send you an email with the message â€œInfinite loop detectedâ€. If you get such an email, please adjust your forwarding configuration so you donâ€™t forward cleaned emails to Email Cleaner.</p>
<p>If you use gmail (like I do), this can be accomplished by adding the condition <code>-subject:[email-cleaner]</code> to your forwarding filter.</p>
<h2 id="how-it-works">How it works</h2>
<p>Email Cleaner works as follows:</p>
<ul>
<li>It scans the email for links which match the following regular expressions:</li>
</ul>
<div><pre><code data-lang="js">	<span>'\.list-manage\.com/track/click'</span>,
	<span>'//click\.convertkit-mail\.com/'</span>,
	<span>'//email\.substack.*/c/'</span>,
	<span>'//apple\.co/'</span>,
	<span>'//t\.co/'</span>,
</code></pre></div><ul>
<li>If a link matches, then itâ€™s a tracking link. Email Cleaner crawls the link to see if itâ€™s a 3xx redirect. If it is, then the link is replaced by the destination URL.
<ul>
<li>Any URL query parameters which are <code>mc_cid</code>, <code>mc_eid</code>, or start with <code>utm_</code> are also removed.</li>
</ul>
</li>
<li>Then, Email Cleaner scans the email for tracking pixels. If any are found, it removes them.</li>
<li>Finally, the email is sent back to the sender.</li>
</ul>
<p>Email Cleaner is quite safe and conservative. It will only crawl links which are obviously tracking links.</p>
<p>Email Cleaner currently handles three major mailing list service providers (MailChimp, ConvertKit, Substack). Iâ€™d happily add more. Just let me know.</p>
<p>Note that Email Cleaner doesnâ€™t magically bypass the tracking links. Instead, it triggers all of them from a data centre somewhere. Itâ€™s privacy-by-obfuscation instead of privacy-by-abstention. But it does prevent your web browser/IP address/location from being leaked.</p>
<h2 id="benefits">Benefits</h2>
<ul>
<li>Email newsletters are more user friendly. (Iâ€™m more inclined to click on a link if I see itâ€™s a reputable website.)</li>
<li>Helps detect phishing attacks.</li>
<li>Better user privacy.</li>
<li>Plain text emails are readable again.</li>
</ul>
<h2 id="plain-text-emails">Plain text emails</h2>
<p>The last benefit was an unexpected side effect.</p>
<p>Whilst writing Email Cleaner, I discovered that plain text versions of email newsletters are completely unreadable.</p>
<p>They look something like this:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [httÑ€://email.substack.com/c/eJxdkc-OgyAQh5-m3Grkr3rgsJd9DQM4WlIFA2O7vv1O2-xlE2CSHzPhy0dwCEsup91zRfY6Rjx3sAmegAiF7BsUE71mvZJcKUa87qgTgpG4mVAAXjYuGssOZN3dEkeLMafPBpOMzFp1wluppHM9Z2FoQQQbnAqd8tx2A7_P2t1HSCNoeEM5cwKy6Blx3R7868F-qkFqjviMK_hom1ym2rrqmr5twVfecTZHLs9tziuJmrWMtqy6kJ0cGtrYoFoF1Aou-ShpCHRsnac9d4wz4MNDtNvuNrTjkzbwu1YNCaNd3hGOZsykaAdpQptonZyur2v3dT1tan7tKeJpIFm3gL954I31Q8hMkKBU3N5Y1FRR3vdc9P2guhtABcZZx2ilTKoOn-tW0v90_AEVdJLl]. At a conference five years earlier [httÑ€://email.substack.com/c/eJxdkEtuhDAMhk8zWSLyBBZZVKp6jSghDkTDJCiYody-YdhV8kO2bPn3N1qEKZdTr3lDcgWD5wo6wbEtdQVEKOyoUMY4WdEbLY0RbLId90oJFus4F4DNxdViOYDth19jcBhzek8ILdjNDk5xrQxozWenoTNmkL2cvQoimFaZz7PumCKkABYeUM6cgK32hrjXi_y6iG9aIW_7QUS3WJGQm1wWSv2aXwVvMd1jWq7O5wOvmwsUQL26NF3_7qiNRStawVtBW-lODw1v3GxaA9wpqWUgxpmH1k-8l15IAXK4qLYevqILd97Az05sCaNbHxGeTcisWA9pQZc4dS4vG5RuLxkj1e1IEc8RkvMrTB9P-NH9NjcukKDQN0yjQ8sNl30vVd8PpvuIIZFSdIKTfUYcU6apZP9x_AIL9Jrk], however, the concepts were discussed in detail, just not named.&nbsp;</p>
</blockquote>
<p>Is that supposed to be readable?! (Itâ€™s not just Substack. The other providers are almost just as bad.)</p>
<p>Email Cleaner changes it to:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [httÑ€s://en.wikipedia.org/wiki/Dartmouth_workshop]. At a conference five years earlier [httÑ€s://computerhistory.org/blog/thinking-about-machines-and-thinking/], however, the concepts were discussed in detail, just not named.&nbsp;</p>
</blockquote>
<p>which is moderately readable.</p>
<p>It would be even better if it was:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [0]. At a conference five years earlier [1], however, the concepts were discussed in detail, just not named.&nbsp;</p>
<p>[0] httÑ€s://en.wikipedia.org/wiki/Dartmouth_workshop<br>
[1] httÑ€s://computerhistory.org/blog/thinking-about-machines-and-thinking/</p>
</blockquote>
<p>but thatâ€™s a story for another time. (I donâ€™t know if itâ€™s worth the effort to do this. Do many people still read emails in plain text?)</p>
<h2 id="caveats">Caveats</h2>
<p>Please note that Email Cleaner is only a proof of concept. Itâ€™s an experiment. I wouldnâ€™t even call it an MVP.</p>
<p>Itâ€™s useful to me, but I donâ€™t know if itâ€™s useful for others. Iâ€™d like to find out.</p>
<p>I donâ€™t know how long Email Cleaner will last since:</p>
<ul>
<li>Itâ€™s vulnerable to spam (Thereâ€™s no authentication or access control), and</li>
<li>Itâ€™s not scalable (Itâ€™s running on a tiny server).</li>
</ul>
<p>Once the spam bots arrive, or too many people use it, itâ€™ll probably have to stop.</p>
<p>Or if thereâ€™s sufficient interest, Iâ€™ll rewrite it into a proper side project.</p>
<h2 id="privacy">Privacy</h2>
<p>Please donâ€™t forward any personal or private emails to Email Cleaner. Only forward publicly available email newsletters (Paid newsletters are okay).</p>
<p>All received emails go to Email Cleanerâ€™s inbox. I hope to accumulate more test data with which to conduct further research on mailing list service providers and improve Email Cleaner.</p>
<p>Thereâ€™s not really a privacy policy. This is an experiment.</p>
<p>If you forward emails to Email Cleaner, I consider that as your opt-in.</p>
<p>Anything you forward to Email Cleaner could be used to improve Email Cleaner.</p>
<p>OTOH, I donâ€™t know anything about you anyway. All I have is an email address and what email newsletters you subscribe to (whatever can be inferred from that).</p>
<h2 id="feedback">Feedback</h2>
<p>Since this is a new and experimental service, please donâ€™t expect it to be perfectly reliable nor correct. If you forward an email to Email Cleaner and donâ€™t get a reply in a few minutes, maybe something broke. Please get in touch with me and Iâ€™d be happy to look into it.</p>
<p>If you have any questions, suggestions, criticisms, etc. â€” please also let me know. Iâ€™d be happy to talk.</p>
<p>I hope you like Email Cleaner! Thanks for reading!</p>




  </article>


  
</div>
    </div></div>]]>
            </description>
            <link>https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293424</guid>
            <pubDate>Sun, 28 Feb 2021 13:55:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can do better than Redis as a data layer for your models]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26293114">thread link</a>) | @jamesblonde
<br/>
February 28, 2021 | http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it | <a href="https://web.archive.org/web/*/http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293114</guid>
            <pubDate>Sun, 28 Feb 2021 13:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reasoning about Taxes]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 78 (<a href="https://news.ycombinator.com/item?id=26292993">thread link</a>) | @acqbu
<br/>
February 28, 2021 | https://www.billdietrich.me/ReasonTaxes.html | <a href="https://web.archive.org/web/*/https://www.billdietrich.me/ReasonTaxes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.billdietrich.me/ReasonTaxes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292993</guid>
            <pubDate>Sun, 28 Feb 2021 12:42:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting two PDP-1 photos (which are not what they seem)]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26292781">thread link</a>) | @masswerk
<br/>
February 28, 2021 | https://www.masswerk.at/nowgobang/2021/train-spotting-1 | <a href="https://web.archive.org/web/*/https://www.masswerk.at/nowgobang/2021/train-spotting-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.masswerk.at/nowgobang/2021/train-spotting-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292781</guid>
            <pubDate>Sun, 28 Feb 2021 12:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indeed MPH: Fast and Compact Immutable Key-Value Stores]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292427">thread link</a>) | @gbrown_
<br/>
February 28, 2021 | https://engineering.indeedblog.com/blog/2018/02/indeed-mph/ | <a href="https://web.archive.org/web/*/https://engineering.indeedblog.com/blog/2018/02/indeed-mph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://engineering.indeedblog.com/blog/2018/02/indeed-mph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292427</guid>
            <pubDate>Sun, 28 Feb 2021 10:56:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The KimKlone Microcomputer]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26292235">thread link</a>) | @gbrown_
<br/>
February 28, 2021 | https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html | <a href="https://web.archive.org/web/*/https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292235</guid>
            <pubDate>Sun, 28 Feb 2021 10:19:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Actually Portable Executables]]>
            </title>
            <description>
<![CDATA[
Score 667 | Comments 152 (<a href="https://news.ycombinator.com/item?id=26292166">thread link</a>) | @krab
<br/>
February 28, 2021 | https://ahgamut.github.io/c/2021/02/27/ape-cosmo/ | <a href="https://web.archive.org/web/*/https://ahgamut.github.io/c/2021/02/27/ape-cosmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>  <p><span>27 Feb 2021</span></p><p>I came across <a href="https://github.com/jart/cosmopolitan">Cosmopolitan</a> on Hacker News, and I was initially confused, due to a few memories of cross-compilation nightmares: while it should be possible to compile for the same architecture regardless of operating system, wouldnâ€™t the OS get confused by the leading bytes of the executable? I read the <a href="https://justine.lol/ape.html">article</a> explaining how it works, but most of it went over my head.</p> <p>The example on the <a href="https://github.com/jart/cosmopolitan">Github README</a> used the following script for compilation:</p> <div><div><pre><code>gcc <span>-g</span> <span>-O</span> <span>-static</span> <span>-nostdlib</span> <span>-nostdinc</span> <span>-fno-pie</span> <span>-no-pie</span> <span>-mno-red-zone</span> <span>\</span>
  <span>-o</span> hello.com.dbg hello.c <span>-fuse-ld</span><span>=</span>bfd <span>-Wl</span>,-T,ape.lds <span>\</span>
  <span>-include</span> cosmopolitan.h crt.o ape.o cosmopolitan.a
objcopy <span>-S</span> <span>-O</span> binary hello.com.dbg hello.com
</code></pre></div></div> <p>I converted it into a simple Makefile to run the compilation commands. I tried a bunch of simple C programs (basic arithmetic, reading and writing to files) on Linux+Windows (compiled on Linux), and all of them worked.</p> <h2 id="compiling-lua-with-cosmopolitan">Compiling Lua with Cosmopolitan</h2> <p>I decided to try compiling a high-level language built on C. I originally picked Python, but the Makefile for Python seemed too complicated to mess with, so I then picked <a href="https://www.lua.org/download.html">Lua</a>, which looked much simpler in comparison.</p> <p>I started out by blindly copy-pasting the flags and includes used in the sample compilation on Github. Ah, it would have been wonderful for my laziness if it compiled out of the box. Following is a play-by-play commentary of trying to compile Lua.</p> <p>First problem I ran into was header clashes: if I didnâ€™t put <code>-nostdlib -nostdinc</code> while compiling each object file, <code>-include cosmopolitan.h</code> would clash with the system headers. But blocking the system headers meant I would have to change every <code>#include</code> of a system header. I created a bunch of dummy headers with the same names as those in the <a href="https://en.cppreference.com/w/c/header">C stdlib</a> and and included to those instead.</p> <p>Naming clashes: some of the macros in <code>cosmopolitan.h</code> clashed with macro/function names in Lua: <code>reverse</code> and <code>isempty</code>. I changed the Lua source to avoid this.</p> <p>A macro <code>FIRST_RESERVED</code> was broken because <code>UCHAR_MAX</code> was missing. I thought <code>UCHAR_MAX</code> was supposed to be in <code>limits.h</code> â€“ the <code>limits.h</code> part of <code>cosmopolitan.h</code> did not have <code>UCHAR_MAX</code> (It had <code>SCHAR_MAX</code>, though.) I added in a <code>#define</code> stating <code>UCHAR_MAX</code> as <code>__UINT8_MAX__</code> (ie 255).</p> <p>The default Lua Makefile attempts to use <code>_setjmp</code>/<code>_longjmp</code> in <code>ldo.c</code> when on Linux. I disabled the <code>LUA_USE_LINUX</code> flag for compiling the object files, but this caused an issue with <code>tmpnam</code> in <code>loslib.c</code> (<code>mkstemp</code> is available in Cosmopolitan). I changed the Lua source to use <code>setjmp</code>/<code>longjmp</code>. A similar issue showed in <code>lauxlib.c</code> for <code>sys/wait.h</code> (which is a no-op in non-POSIX systems, as per the Lua source code), and in <code>liolib</code> for <code>sys/types.h</code> so disabled <code>LUA_USE_POSIX</code> over there as well.</p> <p>The <code>localeconv()</code> function (part of <code>locale.h</code>) was not implemented in <code>cosmopolitan.h</code>, and this caused an error while compiling <code>lobject.c</code> (macro <code>lua_getlocaledecpoint()</code> depended on <code>localeconv()</code>). Changed the macro to just return <code>'.'</code>.</p> <p>The <code>panic</code> function in Lua <code>static int panic (lua_state*)</code> clashed with that in Cosmopolitan <code>void panic(void)</code>. Renamed the lua function to <code>lua_panic</code>. This triggered an error where the <code>panic</code> function was being called in <code>luaL_newstate</code>, so I changed the name there as well.</p> <p><code>luaL_loadfilex</code> caused a <em>frame size error</em> â€“ I have never seen this before. A quick internet search shows that this is because a large buffer is allocated on stack when entering the function, and yes, <code>luaL_loadfilex</code> allocates a <code>loadF</code> object containing a <code>char</code> buffer of <code>BUFSIZ</code>. I reduced the size of the buffer to <code>BUFSIZ - 64</code>.</p> <p><code>loslib.c</code> reuiqres the <code>setlocale()</code> and <code>LC_*</code> from <code>locale.h</code>, which is defined as an extern value in <code>cosmopolitan.h</code>, but that definition is somehow not enough.. screw it, I just disabled <code>os_setlocale</code> in <code>loslib.c</code>, and then it compiles.</p> <h2 id="linking-the-object-files">Linking the object files</h2> <p>Ok, time for linking â€¦</p> <div><div><pre><code>gcc -std=gnu99 -o lua   lua.o liblua.a -lm -Wl,-E -ldl
/usr/bin/ld: errno: TLS definition in //lib/x86_64-linux-gnu/libc.so.6 section
.tbss mismatches non-TLS reference in liblua.a(lauxlib.o)
/usr/bin/ld: //lib/x86_64-linux-gnu/libc.so.6: error adding symbols: bad value
collect2: error: ld returned 1 exit status
</code></pre></div></div> <p>I forgot, I shouldnâ€™t <code>-lm</code> or <code>-ldl</code>. Ok, letâ€™s try with all the object files instead of <code>liblua.a</code>:</p> <div><div><pre><code>/usr/bin/ld.bfd: lvm.o: in function `l_strcmp':
lvm.c:(.text+0x59): undefined reference to `strcoll'
/usr/bin/ld.bfd: lmathlib.o: in function `math_tanh':
lmathlib.c:(.text+0x21f): undefined reference to `tanh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_sinh':
lmathlib.c:(.text+0x24f): undefined reference to `sinh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_cosh':
lmathlib.c:(.text+0x27f): undefined reference to `cosh'
collect2: error: ld returned 1 exit status
</code></pre></div></div> <p>Ummâ€¦ okay, it looks like some of the functions defined in the cosmopolitan header are yet to be implemented in the static library. Thatâ€™s okay, I can just quickly fill in the math functions, and Iâ€™ll comment out <code>strcoll</code> for now, just because I want to see it compileâ€¦. and it successfully compiles!! Letâ€™s run <code>objcopy</code> before trying it out on a system though.</p> <div><div><pre><code>$ objcopy -S -O binary lua lua.exe
$ ls -al
-rwxr-xr-x 1 1953720 Feb 27 01:33 lua
-rwxr-xr-x 1 344064 Feb 27 01:39 lua.exe
</code></pre></div></div> <p>That size reduction seems a little too drastic, but letâ€™s see if it runs on Linux:</p> <p><img src="https://ahgamut.github.io/assets/images/linux_screen.png" alt=""></p> <p>Awesome. How about Windows?</p> <p><img src="https://ahgamut.github.io/assets/images/windows_screen.png" alt=""></p> <h2 id="summary-it-is-actually-portable">Summary: it <em>is</em> actually portable</h2> <p>This is pretty incredible: I just had to modify a few lines in a Makefile and some C source files, and I got a Lua executable that works both on Linux and Windows (and possibly others as well). Granted, there are still some details to be filled out (floating point calculation above prints a <code>g</code>), but Cosmopolitan is currently at release 0.0.2, so there is a lot of time.</p> <p>Hopefully this means that other languages that have source code completely in C can also be compiled once and run anywhere. Actually Portable Python next, maybe?</p> </div> </div></div>]]>
            </description>
            <link>https://ahgamut.github.io/c/2021/02/27/ape-cosmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292166</guid>
            <pubDate>Sun, 28 Feb 2021 10:06:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take a look at Nomad before jumping on Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 80 (<a href="https://news.ycombinator.com/item?id=26291975">thread link</a>) | @sofixa
<br/>
February 28, 2021 | https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/ | <a href="https://web.archive.org/web/*/https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
        <h2>Table of Contents</h2>
        
         
      
      <h2 id="pre-introduction">Pre-introduction</h2>
<p>Recently I stumbled upon and then stumbled upon again on <a href="https://blog.dave.tf/post/new-kubernetes/">David Anderson</a>â€™s interesting post about â€œnew Kubernetesâ€, based on a discussion he had with <a href="https://timewitch.net/">Vallery Lancey</a> about what they would do differently if they were rewriting Kubernetes from scratch. Interestingly, a decent part of the proposals for a â€œnew Kubernetesâ€ are design choices made by Hashicorp for <a href="https://www.nomadproject.io/">Nomad</a>, which is a pretty underrated orchestrator, and drastically simpler ( one of the main goals of said â€œnew Kubernetesâ€).</p>
<p>Some people are aware that Docker Swarm kinda exists but is abandonware/on life support, and isnâ€™t really recommended anymore, but it still comes up in discussions due to how easy it is to use. For most, that leaves Kubernetes as the only â€œseriousâ€ option, but it is a <em>very</em> complex piece of software, with a lot of moving parts, which isnâ€™t actually required or need in most cases.</p>

  <figure>
    <img src="https://atodorov.me/img/nomad/kubernetes.jpg#center">
    
  </figure>


<p>This inspired me to write a series on Nomad, what it is, why itâ€™s great, where itâ€™s lacking and how to use it.</p>
<h2 id="introduction---what-is-nomad-and-why-its-great">Introduction - what is Nomad and why itâ€™s great</h2>
<p>Hashicorpâ€™s Nomad is a simple to run and maintain, yet very flexible task scheduler/orchestrator. It relies on plugins for execution, autoscaling and other features, and can run pretty much anything via its <code>task drivers</code> - Docker, contairnerd, LXC, rkt, podman, Java, fork/exec, QEMU, firecracker, FreeBSD jails.</p>
<p>It comes in the form of a single binary, run in two modes (<code>server</code>, in groups of 3 or 5, which make scheduling decisions and host the APIs and configuration, and an unlimited number of <code>worker</code>s which actually run whatever it is you want to run), and can be automatically clustered via <a href="https://consul.io/">Consul</a>. The configuration ( both for jobs and of Nomad itself) is in <a href="https://github.com/hashicorp/hcl">HCL</a> (Iâ€™ll get into more detail about how great that is a bit later) or JSON (mainly for when the jobs are submitted by machines/scripts/tooling and not humans). Multiple clusters can be connected via <a href="https://learn.hashicorp.com/tutorials/nomad/federation?in=nomad/manage-clusters">multi-region federation</a> for sharing ACLs and for API forwarding ( you can submit a job or request logs to any server for any region and it will be forwarded to the appropriate server). Deployments can be complex out of the box ( rolling, canary, blue/green), and everything is version controlled and rollbackable.</p>
<p>Like most HashiCorp tools, itâ€™s â€œopen coreâ€, meaning that the majority of features are available in an <a href="https://github.com/hashicorp/nomad">open source</a> version, and some more advanced/enterprise-y ones ( in Nomadâ€™s case, <a href="https://www.hashicorp.com/blog/hashicorp-nomad-multi-cluster-deployment">multi-region/cluster deployments</a> - deploying something simultaneously to multiple separate clusters, policy as code with <a href="https://docs.hashicorp.com/sentinel/nomad">Sentinel</a> and similar ) require upgrading to Nomad Enterprise.</p>
<h2 id="primitives">Primitives</h2>
<ul>
<li><code>job</code> is a declarative file which contains groups of tasks, each task being a container/binary/anything run by an exec driver</li>
<li><code>system</code> jobs (run on all client nodes, equivalent to Kubernetes DaemonSets, for monitoring/logging agents/load balancers)</li>
<li><code>periodic</code> jobs (equivalent to cronjobs)</li>
<li><code>service</code>, which registers as a Consul service and is thus discoverable ( via API or DNS)</li>
<li><code>deployment</code>, each version of a job, theyâ€™re tracked and can be rollbacked to</li>
<li><code>allocation</code>, each instance of a task ( group ) on a node</li>
<li><code>namespace</code>, a logical unit to organise jobs in and ACLs around</li>
</ul>
<h3 id="jobs">Jobs</h3>
<p>Example of a very basic job that runs a Docker container (<code>jaegertracing/all-in-one:1.21</code>), with limits of 1000Mhz of CPU and 1024MB of RAM, and registers the service with Consul:</p>
<div><pre><code data-lang="hcl"><span>job</span> <span>"jaeger"</span> {
        type <span>=</span> <span>"service"</span>
        <span>group</span> <span>"api"</span> {
            <span>task</span> <span>"jaeger"</span> {
                driver <span>=</span> <span>"docker"</span>
                <span>config</span> { 
                  image <span>=</span> <span>"jaegertracing/all-in-one:1.21"</span>
                }
                <span>resources</span> {
                  cpu <span>=</span> <span>1000</span>
                  memory <span>=</span> <span>1024</span>
                }
                <span>service</span> {
                  name <span>=</span> <span>"jaeger-query"</span>
                }
            }
        }            
}
</code></pre></div><p>Note that this is a <em>very</em> basic job, there are no healthchecks, no persistent storage, no extra configuration, no update strategy, no autoscaling, no exposed ports.</p>
<h4 id="deployment-history-and-rollback">Deployment history and rollback</h4>
<p>Nomad tracks each jobâ€™s full definitions and deployment history, and allows you to easily rollback and compare them, via the UI, CLI or API, e.g.:</p>
<div><pre><code data-lang="bash"><span># List the versions of the job named "opentelemetry-collector"</span>
$ nomad job history opentelemetry-collector
Version     <span>=</span> <span>1</span>
Stable      <span>=</span> false
Submit Date <span>=</span> 2021-01-08T21:30:30+01:00

Version     <span>=</span> <span>0</span>
Stable      <span>=</span> true
Submit Date <span>=</span> 2021-01-08T21:29:48+01:00

<span># Check the difference between versions</span>
$ nomad job history -p opentelemetry-collector
Version     <span>=</span> <span>1</span>
Stable      <span>=</span> false
Submit Date <span>=</span> 2021-01-08T21:30:30+01:00
Diff        <span>=</span>
+/- Job: <span>"opentelemetry-collector"</span>
+/- Task Group: <span>"opentelemetry-collector"</span>
  +/- Task: <span>"opentelemetry-collector"</span>
    +/- Config <span>{</span>
          args<span>[</span>0<span>]</span>:  <span>"--config=local/otel/config.yaml"</span>
      +/- image:    <span>"otel/opentelemetry-collector-contrib:0.15.0"</span> <span>=</span>&gt; <span>"otel/opentelemetry-collector-contrib:0.16.0"</span>
          ports<span>[</span>0<span>]</span>: <span>"health"</span>
          ports<span>[</span>1<span>]</span>: <span>"jaeger_thrift_compact"</span>
        <span>}</span>

Version     <span>=</span> <span>0</span>
Stable      <span>=</span> true
Submit Date <span>=</span> 2021-01-08T21:29:48+01:00

<span># Revert job "opentelemetry-collector" to version 0</span>
$ nomad job revert opentelemetry-collector <span>0</span>

</code></pre></div><h4 id="state-tracking-and-job-planning">State tracking and job planning</h4>
<p>Nomad keeps the desired state and its history, and with <code>nomad job plan</code>, similar to <code>terraform plan</code>, allows us to preview what will change upon applying a new job file. Thereâ€™s also a feature to verify nothing has changed between the <code>plan</code> and <code>run</code> (equivalent to <code>terraform apply</code> with a plan file) with the <code>-check-index</code> flag:</p>
<div><pre><code data-lang="bash">$ nomad job plan otel.nomad
+/- Job: <span>"otel"</span>
+/- Task Group: <span>"opentelemetry"</span> <span>(</span><span>1</span> create/destroy update<span>)</span>
  +/- Task: <span>"opentelemetry-collector"</span> <span>(</span>forces create/destroy update<span>)</span>
    +/- Config <span>{</span>
          args<span>[</span>0<span>]</span>:  <span>"--config=local/otel/config.yaml"</span>
      +/- image:    <span>"otel/opentelemetry-collector-contrib:0.15.0"</span> <span>=</span>&gt; <span>"otel/opentelemetry-collector-contrib:0.20.0"</span>
          ports<span>[</span>0<span>]</span>: <span>"health"</span>
          ports<span>[</span>1<span>]</span>: <span>"jaeger_thrift_compact"</span>
        <span>}</span>
Scheduler dry-run:
- All tasks successfully allocated.

Job Modify Index: <span>413</span>
To submit the job with version verification run:

nomad job run -check-index <span>413</span> otel.nomad

When running the job with the check-index flag, the job will only be run <span>if</span> the
job modify index given matches the server-side version. If the index has
changed, another user has modified the job and the plan<span>'</span>s results are
potentially invalid.
</code></pre></div><p>Overall, itâ€™s a very useful feature, especially when collaborating, locally or via CI/CD.</p>
<h4 id="checking-the-status-and-logs">Checking the status and logs</h4>
<p>To check the status of a job, there are a few commands under <code>nomad job</code> and <code>nomad alloc</code></p>
<div><pre><code data-lang="bash">$ nomad job status otel
ID            <span>=</span> otel
Name          <span>=</span> otel
Submit Date   <span>=</span> 2021-02-27T20:41:29+01:00
Type          <span>=</span> service
Priority      <span>=</span> <span>50</span>
Datacenters   <span>=</span> dc1
Namespace     <span>=</span> default
Status        <span>=</span> running
Periodic      <span>=</span> false
Parameterized <span>=</span> false

Summary
Task Group  Queued  Starting  Running  Failed  Complete  Lost
otel      <span>0</span>       <span>0</span>         <span>1</span>        <span>0</span>       <span>0</span>         <span>0</span>

Latest Deployment
ID          <span>=</span> ea533b6f
Status      <span>=</span> successful
Description <span>=</span> Deployment completed successfully

Deployed
Task Group  Desired  Placed  Healthy  Unhealthy  Progress Deadline
otel      <span>1</span>        <span>1</span>       <span>1</span>        <span>0</span>          2021-02-27T20:51:45+01:00

Allocations
ID        Node ID   Task Group  Version  Desired  Status   Created  Modified
89031cfd  d3cbeb7e  otel      <span>0</span>        run      running  20s ago  4s ago

<span># logs are at the allocation level ( similar to Kubernetes, where they're at the container level), so we get them with the alloc id</span>
$ nomad alloc logs 89031cfd
<span>[</span>...<span>]</span>
</code></pre></div><h4 id="lifecycle-and-sidecars">lifecycle and sidecars</h4>
<p>Nomad allows defining the lifecycle of tasks in task groups, and their status, with the <code>lifecycle</code> stanza. We can have <code>prestart</code> ( for initialisation ), <code>poststart</code> ( companion, for proxying (aka ambassador and adapter pattern in Kubernetes )) or <code>poststop</code> for clean up, and via the <code>sidecar</code> bool we define whether or not it should run as long as the main task(s), e.g.:</p>
<div><pre><code data-lang="hcl">  <span>task</span> <span>"init"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"prestart"</span>
      sidecar <span>=</span> <span>false</span>
    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"alpine/httpie"</span>
      command <span>=</span> <span>"http"</span>
      args <span>=</span> [
        <span>"POST"</span>,
        <span>"https://some-internal-service-for-provisioning-stuff.local/v1/new"</span>,
        "job_id<span>=</span><span>'</span><span>${</span><span>NOMAD_JOB_ID</span><span>}</span><span>!'"</span>
      ]
    }
  }

  <span>task</span> <span>"fluentd"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"poststart"</span><span> # should start after the main task
</span><span></span>      sidecar <span>=</span> <span>true</span><span> # should run as long as the main task does, and be restarted if it fails
</span><span></span>    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"fluentd/fluentd"</span>
    }
    ...
  }

  <span>task</span> <span>"main-app"</span> {
    ...
  }

  <span>task</span> <span>"cleanup"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"poststop"</span>
    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"alpine"</span>
      command <span>=</span> <span>"rm -rf"</span>
      args <span>=</span> [
        <span>"/var/lib/volume-with-super-secret-data"</span>
      
    }
  }
</code></pre></div><h3 id="aclrbac">ACL/RBAC</h3>
<p>ACL ( access-control list ), or RBAC ( role-based access control ) as itâ€™s known in Kubernetes, allow defining who can do what, so that not everyone with network access can have full administrator privileges and run/stop whatever. Nomadâ€™s ACL system is pretty similar to Consul and Vaultâ€™s, and uses JSON ( mostly for non-humans ) or HCL to define <code>policies</code> with <code>rules</code>, which describe what action is allowed on what object.</p>
<div><pre><code data-lang="hcl"><span># a basic policy which allows the predefined read policy with read-only access to list and read:
</span><span># job, volume and scaling details, and extra capabilities for job creation and log access within the default namespace
</span><span></span><span>namespace</span> <span>"default"</span> {
  policy <span>=</span> <span>"read"</span>
  capabilities <span>=</span> [<span>"submit-job","dispatch-job","read-logs"</span>]
}
</code></pre></div><p>Assignment of policies is done only via the CLI, unlike Kubernetes where that happens in YAML, as does policy management:</p>
<div><pre><code data-lang="bash"><span># create/update the policy within Nomad</span>
nomad acl policy apply -description <span>"Application Developer policy"</span> my-policy my-policy.hcl
nomad acl token create -name<span>=</span><span>"Test token"</span> -policy<span>=</span>my-policy -type<span>=</span>client
Accessor ID  <span>=</span> â€¦</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/">https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/</a></em></p>]]>
            </description>
            <link>https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291975</guid>
            <pubDate>Sun, 28 Feb 2021 09:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ROG AI Overclocking on Linux]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26291486">thread link</a>) | @dragon-rabbit
<br/>
February 27, 2021 | https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>ASUS Republic of Gamers (ROG) has released an AI overclocking tool on BIOS, which allows the PC users who are not experienced in overclocking to overclock the CPU and boost the operating system performance.</p>



<p>I am using a ROG Z390 MAXIMUS XI HERO (WI-FI) motherboard and an Intel i9-9900K CPU. In this blog post, I would like to share my experience with the ROG AI overclocking on Linux.</p>

<h3 id="benchmark-tools">Benchmark Tools</h3>

<p>Here are some benchmark tools that are available on Linux.</p>

<h4 id="blender">Blender</h4>

<p>Blender has a benchmark tool called <a href="https://opendata.blender.org/">Blender Open Data</a>, which allows you to benchmark your CPU or GPU.</p>

<div><div><pre><code>$ wget https://opendata.blender.org/cdn/BlenderBenchmark2.0/launcher/benchmark-launcher-2.0.5-linux.tar.gz
$ tar xvf benchmark-launcher-2.0.5-linux.tar.gz 
$ ./benchmark-launcher 
</code></pre></div></div>

<!-- <div class = "titled-image">
<figure class = "titled-image">
    <img src = "https://leimao.github.io/images/blog/2021-03-29-ROG-Linux-AI-Overclocking/blender.png" style = "width: 70%; height: 70%">
    <figcaption>Causal Diagram</figcaption>
</figure>
</div> -->

<p>Blender is also a free and open source 3D creation suite. We could install it on Ubuntu using the following command.</p>

<div><div><pre><code>$ sudo apt-get update
$ sudo apt-get install blender
</code></pre></div></div>

<h4 id="prime95">Prime95</h4>

<p>Prime95 is used for Ã¢â‚¬Å“burningÃ¢â‚¬ï¿½ your CPU. It is also available on Linux.</p>

<div><div><pre><code>$ wget http://www.mersenne.org/ftp_root/gimps/p95v303b6.linux64.tar.gz
$ tar xvf p95v303b6.linux64.tar.gz
$ ./mprime
</code></pre></div></div>

<h4 id="openssl">OpenSSL</h4>

<p>OpenSSL comes with Linux by default. It can also be used for Ã¢â‚¬Å“burningÃ¢â‚¬ï¿½ your CPU.</p>

<div><div><pre><code>$ openssl speed -multi 16
</code></pre></div></div>

<h4 id="turbostat">TurboStat</h4>

<p>TurboStat is a tool to monitor Intel CPU usages. We will mainly use it to monitor the CPU clock speed.</p>

<div><div><pre><code>$ sudo apt-get install linux-tools-$(uname -r) linux-cloud-tools-$(uname -r)
$ sudo modprobe msr
$ sudo turbostat
</code></pre></div></div>

<h3 id="rog-ai-overclocking">ROG AI Overclocking</h3>

<p>ROG AI overclocking could be done at BIOS level.</p>

<ol>
  <li>Go into BIOS and set all the BIOS configurations to default, save and reboot.</li>
  <li>Go into OS and run one of the benchmark tools mentioned above, reboot.</li>
  <li>Go into BIOS and turn on AI overclock and XMP, save and reboot.</li>
</ol>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2021-03-29-ROG-Linux-AI-Overclocking/bios.png">
    <figcaption>ROG BIOS AI Overclocking</figcaption>
</figure>
</div>

<p>Before ROG AI overclocking, the stabilized CPU clock speed for all 8 cores of my i9-9900K during OpenSSL benchmarking was around 4.1-4.2 GHz. After ROG AI overclocking, it became 4.6-4.7 GHz.</p>



<p>For i9-9900KS, I believe it is possible to overclock all 8 cores to 5.0 GHz.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.asus.com/Microsite/motherboard/Intelligent-motherboard/AI-Overclocking.html">ROG AI Overclocking</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291486</guid>
            <pubDate>Sun, 28 Feb 2021 07:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust, Zig, and the Futility of â€œReplacingâ€ C]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 121 (<a href="https://news.ycombinator.com/item?id=26291054">thread link</a>) | @ghoward
<br/>
February 27, 2021 | https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/ | <a href="https://web.archive.org/web/*/https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>This post has been discussed on <a href="https://news.ycombinator.com/item?id=26291054#26294846">Hacker News</a>, <a href="https://www.reddit.com/r/rust/comments/luawx6/rust_zig_and_the_futility_of_replacing_c/"><code>/r/rust</code></a>, and
<a href="https://lobste.rs/s/1iiifg"><code>lobste.rs</code></a>.</p><p>I should not have posted this to Hacker News on a Saturday night right before
going to bed, but in my defense, this post blew up in a way I didnâ€™t expect.</p></div><h2 id="introduction">Introduction</h2><p>There was a recent <a href="https://github.com/pyca/cryptography/issues/5771">dust-up on GitHub</a> surrounding the decision by the
<a href="https://github.com/pyca/cryptography">Cryptography library</a> (which I will call <code>cryptography</code> for convenience) to
switch to <a href="https://www.rust-lang.org/">Rust</a>.</p><p>One of the distro maintainers of my distro of choice, <a href="https://www.gentoo.org/">Gentoo</a>, filed a bug
report with the <code>crytography</code> saying that the switch broke builds on several
platforms that Gentoo still supports. The <code>cryptography</code> authors replied that
those platforms are not really used anymore, and that they were going to stick
with Rust because it has better memory safety than C. They also argued that it
is better to force better programming languages on people because of better
security.</p><p>At first glance, it appears that the better argument is on the side of the
<code>cryptography</code> maintainers, but after thinking about it carefully, I think they
are wrong.</p><h2 id="reasons">Reasons</h2><p>There are a few reasons why I believe the <code>cryptography</code> maintainers are at
fault.</p><h3 id="due-diligence">Due Diligence</h3><p>First, their argument for Rust (and against C) because of memory safety implies
that they have not done due diligence in finding and fixing such bugs.</p><p>I can almost hear the rage of my readers against that paragraph above and
against the fact that I donâ€™t have a commenting system on my blog. So let me
answer the comments preemptively.</p><p>â€œThey are volunteers, giving their time away for free!â€</p><p>Yes, but they also <em>intend</em> for their code to be used widely. They managed to
succeed in that, so they now have some obligation to their users.</p><p>â€œThey donâ€™t have any obligation!â€</p><p>If a software project actively goes out and gets users, which just about any
project with a serious number of users has done, then yes, they have an
obligation to those users. The reason is that they sold users on the idea of
using their software. In other words, they were marketing their software, which
means making promises.</p><p>In fact, when people release <em>libraries</em> and try to get users for them, itâ€™s
<em>because</em> they want them to be used by downstream programmers. A programmer
might write a program to scratch an itch and release it, but that reasoning
applies much less to libraries, in my opinion.</p><p>â€œOkay, but they didnâ€™t get anything in return, so thereâ€™s still no obligation.â€</p><p>In return, the users gave them <strong>relevance</strong>.</p><p>One of the most vocal (in favor of Rust) developers of <code>cryptography</code> works for
Red Hat Security Engineering (if I read his GitHub profile right). I donâ€™t know
if his work on <code>cryptography</code> helped him get that job, but it might have.</p><p>Another of the most vocal developers has a computer security company. I would
bet money that his work on <code>cryptography</code> gives his company relevance.</p><p>So they did <em>not</em> get â€œnothingâ€ from users. Quite the opposite, in fact.</p><p>By the way, this position comes from my own experience pushing my <a href="https://git.yzena.com/gavin/bc"><code>bc</code></a>. I
managed to convince the FreeBSD project to <a href="https://github.com/freebsd/freebsd-src/tree/main/contrib/bc">make it the default</a> in FreeBSD
13.</p><p>Once I did that, I shouldered, willingly, the need to keep FreeBSD happy. And
while I have made mistakes, I have done well so far.</p><p>And with my <code>bc</code>, <strong>I did my due diligence with memory safety</strong>. I fuzzed my
<code>bc</code> and eliminated all of the bugs. I even run the generated fuzzer test cases
through AddressSanitizer, and my entire test suite is run through Valgrind
<em>and</em> AddressSanitizer. I also add failing fuzzer cases to my test suite, which
means I run more and more test cases through both of those frightfully
effective tools.</p><p>For the record, those tools are only effective with effective test suites, which
I spent a lot of time building. But <em>building</em> such a test suite is part of due
diligence itself.</p><p>So it follows that if the developers have <em>not</em> done their due diligence, their
users should <strong>leave</strong>, either by forking the project or creating a new one.
The relevance they gave to the <code>cryptography</code> authors should disappear.</p><h3 id="battle-tested-c-code">Battle-Tested C Code</h3><p>In fact, I have done enough due diligence with my <code>bc</code> that I would consider it
a dereliction of duty to Rewrite It in Rust (RIIR).</p><p>Why would it be a dereliction of duty? Because rewriting it in Rust would cause
<em>more</em> bugs, not less. This is because of several reasons:</p><ol><li>I would need to <em>redesign</em> it to fit the language.</li><li>I would need to <em>reimplement</em> it, and new implementations always have bugs.</li><li>The C code is battle-tested, both by me (using fuzzing and other techniques)
and by users.</li></ol><p>That last point is the most crucial, especially in the case of <code>cryptography</code>.</p><p>If the developers of <code>cryptography</code> claim that they have, in fact, done their
due diligence with regards to memory safety in their C code, then they are
claiming that itâ€™s battle-tested.</p><p>The saying that â€œa bird in the hand is worth two in the bush,â€ and in this case,
<em><strong>if</strong></em> the <code>cryptography</code> developers are claiming that they have done their
due diligence, they are throwing away a bird in the hand for a single one in the
bush.</p><div><p><strong>Edit (28 Feb 2021)</strong>: This part of the post seems to be misunderstood widely,
so I am going to attempt to clarify.</p><p>People are arguing that having safe C code requires a frozen, small codebase
with a thorough test suite. And then they debate my position based on the belief
that the codebase needs to evolve.</p><p>For the record, I agree with them that in order to have safe C code, the
codebase must be small and frozen.</p><p>What I am arguing is that <strong>crypto</strong> code <em>should</em> be small and frozen, with a
thorough test suite. I wrote about that <a href="https://gavinhoward.com/2019/11/finishing-software/">here</a>.</p></div><p>And if thatâ€™s the case, their users should <strong>leave</strong> and take <code>cryptography</code>'s
relevance with them.</p><h3 id="desktops-and-smartphones-are-not-the-only-computers">Desktops and Smartphones Are Not the Only Computers</h3><p>The users of <code>cryptography</code> were claiming in the bug report discussion that Rust
is not portable to many platforms, and the authors said that they donâ€™t have the
time or resources to target those platforms. Fair enough.</p><p>But then they claim that the <em>users</em> should put in the effort to port Rust to
their platforms. This is wrong.</p><p>The <code>cryptography</code> authors also claim that the platforms that Rust doesnâ€™t
support do not matter. As we will see below, this is false.</p><p>While I agree that the <code>cryptography</code> authors are not responsible for porting
Rust to other platforms, the users of those platforms are not either.</p><p>That responsibility falls on the Rust developers.</p><p><em>They</em> were the ones who sold Rust to those who have used it, so as above,
<em>they</em> have the responsibility for supporting their users.</p><p>Granted, the Rust developers have made no claim about being portable to every
platform. But they <em>have</em> claimed that it is <a href="https://www.rust-lang.org/what/embedded">appropriate for embedded
software</a>.</p><p>If it were true, this would be great. After all, <a href="https://youtu.be/3HxPzutkNYw?t=257">IoT devices outnumber
desktops and smartphones by at least one order of magnitude</a>.</p><p>But there are a lot of them that LLVM, Rustâ€™s backend, cannot generate code
for. In fact, there are a lot of them that <em>C++</em> cannot run on.</p><div><p><strong>Edit (28 Feb 2021)</strong>: Also, the Rust developers are the developers with the
most experience reading ISA manuals knowing how to make a compiler generate
code. So they are still the best placed to support those â€œesotericâ€
architectures.</p><p>And if they do not know how to read ISA manuals and generate code, itâ€™s because
they lean too heavily on LLVM.</p></div><p>Make no mistake; embedded software is still running the majority of devices in
the world. And C is the king of embedded software.</p><p>I donâ€™t know exact numbers, but I wouldnâ€™t be surprised if the majority of
programmable devices in the world cannot run Rust.</p><p>Thus, because Rust uses LLVM, it is not portable.</p><p>And in my opinion, Rust is not appropriate for the embedded space.</p><p>So in this case, I would consider that the <code>cryptography</code> developers were
victims of the Rust developers.</p><h3 id="gcc-is-not-the-only-compiler"><code>gcc</code> Is Not the Only Compiler</h3><p>That isnâ€™t the only problem.</p><p>There is a <a href="https://github.com/Rust-GCC/gccrs">project to make <code>gcc</code> able to compile Rust</a>. Thatâ€™s commendable.</p><p>However, many people seem to believe that once itâ€™s done, Rust will be portable.
That is not the case.</p><p>Why? Simple: <strong><code>gcc</code> is not the only compiler</strong>.</p><p>There is plenty of code out there that uses dead simple C compilers, like
<a href="https://bellard.org/tcc/">tcc</a>, <a href="http://sdcc.sourceforge.net/">sdcc</a>, and others. And often, they have <a href="https://embeddedgurus.com/stack-overflow/2012/06/optimizing-for-the-cpu-compiler/">good reason to do
so</a>.</p><p>Adding a <code>gcc</code> frontend, while it will improve the situation, will not make Rust
as portable as C. Period.</p><h3 id="pushing-for-progress-hinders-it">Pushing for Progress Hinders It</h3><p>The other thing that the <code>cryptography</code> authors claim is that their users who
refuse to adopt Rust are hindering progress.</p><p>That may be true, but it is also true that forcing â€œprogressâ€ on others hinders
<em>true</em> progress.</p><p>By forcing users to either adopt Rust or pin their dependency on <code>cryptography</code>
to the most recent version without it, they are forcing those users to use
stagnant code.</p><p>Isnâ€™t that the very opposite of progress?</p><h2 id="cryptography-at-fault"><code>cryptography</code> at Fault</h2><p>Those reasons lay out why I think the <code>cryptography</code> authors should shoulder the
blame for this situation, and I think I can explain where they went wrong.</p><ol><li>They let ideology come before pragmatic engineering.</li><li>They sold <code>cryptography</code> to users.</li><li>They knew that switching to Rust would break existing users and did it
anyway.</li><li>They either did not do their due diligence for memory safety, or they did
and threw that battle-tested code out.</li></ol><h2 id="portability">Portability</h2><p>To be honest, I used to think that it was better to switch to a better language
than C.</p><p>I had several talks with Linux distro maintainers, as well as a talk with my
father-in-law, that convinced me that Câ€™s portability is still important enough
that it should be used.</p><p>Unless, of course, you <em>explicitly</em> target only certain platforms. But you had
better be prepared to never target others.</p><p>In fact, after talking with the distro maintainers, who have had to build Rust,
I am also convinced that itâ€™s not just about being portable, itâ€™s also about how
<em>easy</em> it is to <em>build</em> software.</p><p>Rustâ€™s bootstrap is <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">complicated</a>, and it is one of the worst things about
it.</p><p>If building software in Rust means building Rust for a <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">Tier 3</a> platform,
you can bet that <a href="https://drewdevault.com/2021/02/09/Rust-move-fast-and-break-things.html">people will stick with C</a>.</p><h3 id="zig">Zig</h3><p>I want to take a moment to talk about Zig.</p><p>Zig might be one of the most promising up-and-coming languages of recent memory.</p><p>But it will ultimately fail to reach its goal.</p><p>You see, Zig is meant to replace C. But â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/">https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/</a></em></p>]]>
            </description>
            <link>https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291054</guid>
            <pubDate>Sun, 28 Feb 2021 06:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Horizonator: Terrain renderer based on SRTM DEMs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290718">thread link</a>) | @pabs3
<br/>
February 27, 2021 | http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
Check this out:
</p>


<p><img src="https://github.com/dkogan/horizonator/raw/master/example-interactive.png" alt="example-interactive.png">
</p>

<p>
I just resurrected and cleaned up an old tool I had lying around. It's now nice
and usable by others. This tool loads terrain data, and renders it from the
ground, simulating what a human or a camera would see. This is useful for
armchair exploring or for identifying peaks. This was relatively novel when I
wrote it &gt;10 years ago, but there are a number of similar tools in existence
now. <i>This</i> implementation is still useful in that it's freely licensed and
contains APIs, so fancier processing can be performed on its output.
</p>

<p>
Sources and (barely-complete-enough) documentation live here:
</p>

<p>
<a href="https://github.com/dkogan/horizonator">https://github.com/dkogan/horizonator</a>
</p>

  </div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290718</guid>
            <pubDate>Sun, 28 Feb 2021 04:38:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Thoughts on Community]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290434">thread link</a>) | @sarvasvkulpati
<br/>
February 27, 2021 | https://sarvasvkulpati.com/blog/community | <a href="https://web.archive.org/web/*/https://sarvasvkulpati.com/blog/community">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><main><article><div><p>There's been an explosion of people creating communities on the internet. I've thought about them a lot, and wrote this to compile some of those thoughts in a single document.</p><p>What is a community? For my purposes, Iâ€™ve found a useful definition.</p><blockquote><p>A group of people, united by a shared passion or purpose, who interact with each other.</p></blockquote><p>Looking at the definition, there are only two things a community needs.</p><ul><li>A shared passion or purpose</li><li>People interacting with each other</li></ul><p>Hereâ€™s some examples of communities:</p><table><thead><tr><th>Community</th><th>Shared passion/purpose</th><th>People interacting</th></tr></thead><tbody><tr><td>Your high school</td><td>Learn (apparently)</td><td>Talking in classrooms, lunches, groupchats</td></tr><tr><td>React developers</td><td>Using the same language, interested in the development of the language</td><td>Tweeting at each other, reddit, forums</td></tr></tbody></table><p>The strength of a community, then, comes from the strength of this shared passion/purpose and the depth and frequency of interactions. And so, a useful formula for measuring the strength of a community could be:</p><p><span></span> = strength of the passion/ideal</p><p><span></span> = the ith connection</p><p><span></span> = the depth of the ith connection</p><p>We can come up with a few interesting observations through this formula.</p><ul><li><p>Notice that this definition doesnâ€™t talk about technology or the platform used to bring these people together. <strong>Putting people into a group chat doesnâ€™t make it a community.</strong> In fact, a group chat isnâ€™t even necessary to build a community. Thereâ€™s clearly a React developer community on the internet, but there isnâ€™t any specific platform or group chat they congregate at. In that sense, communities can be thought of as the superset of the platform they exist on. A single community can use many platforms to interact with each other, but the discord server or slack channel they use isnâ€™t the community itself.</p></li><li><p><strong>The strength of the shared passion/purpose acts as a force multiplier on the connections in a community.</strong> If there is no shared P, the community has no strength. Getting people together who donâ€™t have a shared passion is the same thing as putting a bunch of random people in a group chat and calling it a community.</p></li><li><p><strong>Itâ€™s much easier to connect with people who have the same values and passions as you do, so the stronger P is, the stronger every single connection is right at the outset.</strong> So (somewhat obviously), the more passionate people are, the easier is it so make a community with them. Conversely, without a strong shared ideal, itâ€™ll be very difficult to get people to interact and form deep connections.</p></li><li><p>The shared purpose can even be something as trivial as having to be in the same place at the same time. But if youâ€™ve left high school, youâ€™ll notice how you probably havenâ€™t kept in touch with 90% of the people you knew, even if it felt like you knew them really well during your time there. That leads us to another important point- <strong>there is a hierarchy of shared experiences that bring people together.</strong> You didnâ€™t keep in touch simply because the strength of your connection was based on location, which is very weak compared to shared passions or experiences.</p></li></ul><p><img src="https://sarvasvkulpati.com/hierarchy.jpeg" alt="shared purpose hierarchy"></p><p>A community with a few deeply passionate people is much stronger than one with many shallow ones. Youâ€™d think that itâ€™s merely the area under the curve (connections x depth of connections), but thereâ€™s a third dimension here-  P would likely be much higher in communities with deeper connections, making those communities stronger.</p><p><img src="https://sarvasvkulpati.com/3d.jpeg" alt="3d graph of P, depth and connections"></p><p>Notice that frequency of interaction is not a factor at all. Itâ€™s only useful to the extent that it increases the depth of relationships in a community- beyond that, it doesnâ€™t make a difference.</p><p>Think of your closest group of friends. You could meet them all after months and youâ€™d still feel the same sense of community you did before. The strength of your connection superseded the need to constantly interact. And so, the DAUs of a community is a terrible way to measure its strength. This is not to say it doesnâ€™t matter, just that while frequent interactions may lead to deep connections, deep connections donâ€™t necessarily mean frequent interactions.</p><h2>Whoâ€™s a community for?</h2><p>The need for deep connections means that communities specifically built for the internet can only fulfill a certain set of users.</p><p>The issue is <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbarâ€™s number</a>. Humans can only maintain ~150 deep connections, and the vast majority of these are taken up by in person relationships. But to make online communities, you need people to make strong relationships. So, in a sense, you need people with enough â€˜mental social capacityâ€™ to form those deep relationships with people online.</p><p>This required â€˜mental social spaceâ€™ means that online communities need to cater to people who are missing some sort of social interaction offline. And so, they need to find a way to offer connections that people cannot find in person.</p><p>From a social lens, the internet is an aggregation of extremes. It allows everyone in the long tail to suddenly have an abundance of people like them. This means that people with unconvential interests who couldn't find their people in person, can do so online. So the the gamer, the programmer, the digital artist in school- they donâ€™t need to feel so different anymore.</p><p>For example, Iâ€™ve been interested in startups for years now, and after bingeing <a href="https://blog.ycombinator.com/category/podcast/">YCâ€™s podcasts</a>, I realised that I needed a way to find people with the SV mindset. Twitter allowed me to find many people my age with similar interests, <a href="https://twitter.com/sarvasvkulpati/status/1247181074611851267?lang=en">Enlite</a> allowed me to meet a bunch of really interesting people, and interning at <a href="https://pioneer.app/">Pioneer</a> gave me a glimpse of what itâ€™s like to work at startups. All of these happened without meeting a single one of of these people in person.</p><p><a href="https://hackclub.com/">HackClub</a> is a perfect example of a community thatâ€™s built to cater to a group of people who miss some sort of social interaction offline. Itâ€™s still strangely difficult to find kids who are interested in coding and building things, and Hack Club fills that gap by giving young hackers an online community of people just like them. It works so well because it manages to both</p><ul><li>Cater to highly passionate people</li><li>Cater to people who donâ€™t usually find their communities in person</li></ul><h2>Building strong community</h2><p>While finding many people with a high P is a prerequisite, you need to then get them to interact with each other, to weave the web of connections that form the thing youâ€™ll call your community. When you first bring people together, each individuals connections will look like this:</p><p><img src="https://sarvasvkulpati.com/connections.jpeg" alt="a graph of connections against depth"></p><p>Each member will have fairly weak connections with all the other members.The mistake I made when I first started Enlite was thinking that putting a bunch of people in a slack channel would mean that all of them interact with every other member all the time. That wasnâ€™t the case. Instead, a small, core group of people emerged.</p><p>When youâ€™re in school, youâ€™ll notice that cliques naturally form. No amount of social engineering would get the jocks to suddenly integrate with the nerds. Similarly, the formation of cliques in a community is pretty normal, and in fact, is a great thing. It means people are falling into subsets of others they are comfortable with.</p><p>However, you donâ€™t want insulated cliques. While there should be strong connections within them, they should also be connected to each other. Should this succeed, your community will look like this:</p><p><img src="https://sarvasvkulpati.com/graph.jpeg" alt="network of members in a community"></p><p>Any individual in your community will end up with a T shaped profile- many fairly shallow connections, a few very deep ones. The width of the stem would depend on the number of online friends they mentally have space to make as well as their success with connecting to people within the community.</p><p><img src="https://sarvasvkulpati.com/depth.jpeg" alt="depth"></p><p>Much like any social product, Enlite has a retention curve, and about a third are still active. An interesting observation is that the members who initially attended the most video calls are the ones who are now the most active in chat. My theory is that they acquired the best relationships and so, felt incentivised to talk and share opinions and progress on projects.</p><h2>Creating strong connections</h2><p>But how do you facilitate creating these strong connections? Something Iâ€™ve noticed is that every relationship: teacher-student, parent-child, friend-friend, follows a timeline</p><p><img src="https://sarvasvkulpati.com/friendGraph.jpeg" alt="friendship timeline"></p><p>In a sense, the depth of a relationship could be measured by how much a pair knows and understands about what makes the other tick. You could have a wild drinking buddy and always have fun but unless you have some deep conversations, you donâ€™t have a deep relationship. To increase the depth of the relationship quickly, you need to increase the bandwidth of communication- doing so allows both people to understand each other faster, and so, speeds up the timeline of the relationship.</p><p>For example, <a href="https://twitter.com/aadillpickle">Aadil</a> and I followed each other on twitter for a while. I saw his tweets, he saw mine, sometimes we interacted with each other. But then, when making Enlite, I got on a zoom call with him. Within 30 minutes, we were much, much better friends. It felt like the amount our friendship progressed in a few months of interacting with each other on Twitter was repeated several times over in 1 zoom call.</p><p>Of course, different mediums have different bandwidth, but thereâ€™s a tradeoff- the higher the bandwidth, the higher the barrier of entry. Scheduling a zoom call, for example, is much harder than sending a Twitter DM.</p><p><img src="https://sarvasvkulpati.com/bars.jpeg" alt="bar charts of communication mediums compared"></p><p>In this sense, audio is probably best placed at the intersection of bandwidth and friction. On audio calls, you donâ€™t need to care about how you look, you donâ€™t need to constantly stay in a â€˜switched onâ€™ state and stare at the camera throughout, and itâ€™s much easier to hop on and off. This is probably why platforms like Discord and Clubhouse are growing so fast as a tool to grow communities.</p><h2>A summary</h2><p>In conclusion:</p><ul><li>Communities = passion x interaction x strength of interactions</li><li>You don't need a group chat for a community, and putting people into a group chat doesn't make it one</li><li>Communities need to cater for connections people don't find in person</li><li>Creating connections requires a high bandwidth of communication. When in doubt, choose video</li><li>Frequent activity doesn't necessarily mean a strong community</li></ul></div></article></main></div></div>]]>
            </description>
            <link>https://sarvasvkulpati.com/blog/community</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290434</guid>
            <pubDate>Sun, 28 Feb 2021 03:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before you buy a Soviet Camera]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 62 (<a href="https://news.ycombinator.com/item?id=26290128">thread link</a>) | @brudgers
<br/>
February 27, 2021 | https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/ | <a href="https://web.archive.org/web/*/https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
 <!-- A generated by theme --> 



 <!-- end A --> 

<p><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web.jpg" alt="Drug and Zenit-3M cameras (Pic: Stephen Dowling)" width="2500" height="1633" srcset="https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web.jpg 2500w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-300x196.jpg 300w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1024x669.jpg 1024w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-768x502.jpg 768w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1536x1003.jpg 1536w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-2048x1338.jpg 2048w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-696x455.jpg 696w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1068x698.jpg 1068w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-643x420.jpg 643w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-600x392.jpg 600w" sizes="(max-width: 2500px) 100vw, 2500px"></p>
<p>It begins in October 1927, with a single camera exhibited in Moscow at an Exposition of Photographic Technique in the new Soviet capital, Moscow. Bostelmanâ€™s camera is a small 35mm camera with a simple, single-speed shutter and a winding key to advance the film. The cameraâ€™s back is removable, and removing it turns the rest of the camera into an enlarger which can be used to make prints.<span data-ez-name="kosmofoto_com-box-3"></span></p>
<p>It never makes it into production, but Bostelmanâ€™s simple snap-shooter is the first Soviet camera. What comes after this is first a trickle, and then a flood.</p>
<p>Fifty years later, and the Soviet camera industry is the second-largest in the world â€“ second only to Japan, whose bands such as Nikon, Canon, Minolta Olympus and Pentax have become household names. The Soviet Union has its own heavyweights, and between them they have churned out dozens and then hundreds of different camera designs as the decades tick by.</p>
<p>Thanks to a mix of espionage, war reparations, ingenious design and a desire to show the West a thing or two, the USSRâ€™s camera makers come up with a Soviet answer to almost every camera type made in the West, though not necessarily at the same time. Soviet designers devised a myriad of different models, some of the brutishly simple, others showing real flair and ingenuity.</p>
<p>Odd, then, that the entirety of a photographic industry spread across the largest country ever formed and spanning more than 60 years can get judged off first impressions. In the last 20 years, Iâ€™ve lost count of the number of times Iâ€™ve seen people declaim the quality of all Soviet cameras based off a single flea-market <a href="https://kosmofoto.com/2018/12/zenit-e-russian-camera-review/">Zenit-E</a> which might have mouldering in someoneâ€™s basement for the last 30 years.<span data-ez-name="kosmofoto_com-medrectangle-4"></span></p>
<p>This is something Iâ€™ve learned having spent the last 20 years collecting and using Soviet cameras. The first one I came across was a Soviet-era <a href="https://kosmofoto.com/2017/06/lomo-lc-a-cameras-lc-wide-lca-120/">Lomo LC-A</a> compact in a camera shop in Londonâ€™s West End; a solid black rectangle with surprising heft and exotic Cyrillic lettering. That Lomo sparked an enduring love for film cameras of all shapes and sizes, and a particular interest in those made behind the Iron Curtain.</p>
<p>In New Zealand, where I grew up, Soviet cameras were almost unknown. But that wasnâ€™t the case in Western Europe. The boom years of the Soviet photographic industry during the Cold War coincided with a new age of prosperity and consumerism west of Berlin. More people had the money and time to travel, and they wanted cameras with which to document it. The Soviet Union wanted hard currency and had a smorgasbord of cameras that could be sold at subsidised prices. Along with the Praktica cameras of East Germanyâ€™s vast Pentacon, Soviet cameras appealed to a huge swathe of photographers with a limited budget.</p>
<figure id="attachment_24709" aria-describedby="caption-attachment-24709"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C.jpg" alt="Zorki-3C (Pic: Paulo Moreira)" width="1000" height="713" srcset="https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C.jpg 1000w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-300x214.jpg 300w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-768x548.jpg 768w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-696x496.jpg 696w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-589x420.jpg 589w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-100x70.jpg?crop=1 100w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-600x428.jpg 600w" sizes="(max-width: 1000px) 100vw, 1000px"><figcaption id="caption-attachment-24709">The Zorki-3C is typical of Soviet rangefinder design from the 1950s and 60s (Pic: Paulo Moreira)</figcaption></figure>
<p><span data-ez-name="kosmofoto_com-box-4"></span>This article â€“ and itâ€™s a big one, so get a drink handy â€“ is an attempt to dispel some of the myths that have developed around Soviet cameras, especially since the 1990s. Itâ€™s not trying to pretend that itâ€™s only politics got in the way of the USSRâ€™s cameras, and that every Zenit and Zorki is a match for a Nikon or a Leica. Some of the horror stories you might have heard about Soviet camera quality are 100% true. But not every Soviet camera is a lemon, and some are capable of taking fantastic images if you take the trouble to learn their strengths and, yes, their weaknesses.</p>

<h4><span id="The_big_five"></span><strong>The big five</strong><span></span></h4>
<p>But first, a little history.</p>
<p>The Soviet camera industry was dominated by five big names: <a href="http://camera-wiki.org/wiki/KMZ"><strong>KMZ</strong></a> (<em>Krasnogorskiy Mechanicheskiy Zavod</em>) in Moscow, <a href="https://en.wikipedia.org/wiki/LOMO"><strong>Lomo</strong></a> in St Petersburg, <a href="https://en.wikipedia.org/wiki/Kiev_(brand)"><strong>Kiev-Arsenal</strong></a> and <a href="https://en.wikipedia.org/wiki/FED_(camera)"><strong>FED</strong></a> in Ukraine and <a href="https://vintagecameralab.com/brand/mmz/"><strong>MMZ</strong></a> (the home of BelOMO) in what is now Belarus. Some of these bureaus concentrated on one particular style of camera â€“ FED, for instance, became known for Leica-copy rangefinders they started making in the 1930s and they were kept in production until almost the end of the Soviet Union itself.</p>
<p><a href="https://ko-fi.com/Z8Z2KH28" target="_blank" rel="noopener"><img src="https://az743702.vo.msecnd.net/cdn/kofi2.png?v=0" alt="Buy Me a Coffee at ko-fi.com" height="36"></a> <em>Found this guide useful? Please add a contribution via Ko-Fi. Youâ€™ll help pay for the siteâ€™s hosting and make sure Kosmo Foto is free to read for years to come.</em></p>
<p>The cameras created ranged from rudimentary compacts simple enough for children to ambitious designs intended to compete with the very best the West had to offer. The latter were a kind of photographic soft power â€“ with no internal market to pay top dollar for them, the higher-spec cameras were touted as evidence of Soviet ingenuity and engineering prowess</p>
<figure id="attachment_22492" aria-describedby="caption-attachment-22492"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2018/12/zenite4-e1590396414210.jpg" alt="Zenit-e (Pic: Stephen Dowling)" width="2000" height="1500"><figcaption id="caption-attachment-22492">The Zenit-E is the most-produced 35mm SLR in history (Pic: Stephen Dowling)</figcaption></figure>
<p>Much simpler cameras were made in Soviet industrial quantities: million after million. This model became the dominant one from the mid 1970s. Camera designers were no longer urged to make cameras to compete with the best of the West, but to tweak tried-and-trusted designs a little each time. You can see this in the successive designs that came after the ubiquitous Zenit-E SLR and Lomoâ€™s simple <a href="https://en.wikipedia.org/wiki/Smena_(camera)">Smena viewfinder camera</a>. Despite cosmetic changes on the outside, underneath little changed from camera to camera.</p>
<p>A leading Soviet camera collector named Viktor Suglob recently produced a Russian-language book called â€˜<a href="http://ussrphoto.com/Wiki/default.asp?WikiCatID=39&amp;ParentID=4&amp;ContentID=311&amp;Item=1200+Cameras+from+USSR+by+Suglob%2C+Shaternik%2C+Kochergin">1200 Soviet Cameras</a>â€™, an encyclopaedia of almost every prototype and production camera devised over nearly 75 years of the USSR. Many of these, of course, were never produced beyond a few samples or pre-production models. But hundreds of designs did make it into production. Today, millions of these cameras â€“ from KMZ and Lomo, MMZ and FED â€“ still survive in working condition.</p>
<h4><span id="The_major_models"></span><strong>The major models</strong><span></span></h4>
<p>If youâ€™re curious about Soviet cameras, youâ€™ll find the easily available cameras falling into seven main groups:<span data-ez-name="kosmofoto_com-large-leaderboard-2"></span></p>
<ul>
<li><strong>Leica copy rangefinders:</strong> Mostly made by FED in Kharkiv in the Ukraine and under the â€œZorkiâ€ name from KMZ in Moscow. These cameras use the same <a href="https://camerapedia.fandom.com/wiki/39mm_screw_lenses">L39 screw mount</a> that Leica rangefinders did up until the mid-1950s. These cameras were produced, in various forms, until the early 1990s.</li>
<li><strong>Contax-style rangefinders:</strong> The Kiev brand started out copying the Contax II rangefinder produced in Germany before the war, initially with Contax parts taken as war reparations. The â€œ<a href="http://camera-wiki.org/wiki/Kiev_rangefinder">Kiev Contax</a>â€ line of cameras was made until the late 1980s</li>
<li><strong>Zenit SLRs:</strong> KMZ produced the Soviet Unionâ€™s widest array of SLR cameras under the Zenit name. The earliest versions were little more than a <a href="https://en.wikipedia.org/wiki/Zorki_1">Zorki rangefinder</a> with a reflex prism attached, but the line grew more popular in the late 1960s with the Zenit-E, the first Soviet SLR to use the M42-screw mount. M42 Zenits were made until the early 2000s, and a narrower range of cameras from the mid-1980s until the mid-2000s used the Pentax K mount. Lomo, and Kiev also produced SLRs, but these are far less common.</li>
<li><strong>Simple viewfinder cameras:</strong> Both Lomo in St Petersburg and MMZ in Minsk produced very similar families of snapshooters, rectangular viewfinder cameras with a simple shutter and a three-element glass lens. MMZâ€™s were called <a href="https://camerapedia.fandom.com/wiki/Vilia">Vilia</a> and Lomoâ€™s were known as Smenas. Just two Smenas â€“ the <a href="https://kosmofoto.com/2020/03/these-are-the-most-produced-35mm-cameras-of-all-time/">Smena-8 and the 8M</a> â€“ were built to the tune of around 21 million, making them the most-produced 35mm cameras of all time. These cameras are cheap and rudimentary, but their glass lens definitely elevate them out of toy camera territory.</li>
<li><strong>Simple TLRs:</strong> Medium format cameras were not produced in the same breadth and scale as 35mm cameras, but there were still some successful models. The <a href="https://en.wikipedia.org/wiki/Lubitel">Lubitel family</a> of cheap 120-format TLRs are the easiest to find. Built out of plastic but with glass Triplet-style lenses, these Lomo-made cameras were produced from the 1940s until after the fall of the Soviet Union.</li>
<li><strong>Medium format SLRs:</strong> The Soviet Unionâ€™s equivalent to the <a href="https://www.japancamerahunter.com/2019/04/camera-geekery-pentax-67/">Pentax 67</a> was the <a href="https://vintagecameradigest.wordpress.com/2016/09/08/the-kiev-6c-a-photographic-artifact-of-the-cold-war/">Kiev-6C</a>, which eventually evolved into the <a href="http://mattsclassiccameras.com/slr/kiev-60/">Kiev-60</a>. These are big, heavy SLR cameras with a rougher finish than their Western counterparts but with a range of very well-regarded lenses.</li>
<li><strong>Hasselblad-style medium-format cameras: </strong>The Kiev factory also produced a series of Hasselblad-style focal plane cameras, the Kiev-80 and <a href="http://camera-wiki.org/wiki/Kiev_88">88</a> being the best-known of them. The lenses made for the Kiev-6/60 were also produced for some versions of this camera range. They are cheap â€“ especially compared to Hasselblads â€“ but they donâ€™t come with a great reputation for reliability.</li>
</ul>
<p>There were many other brands and minor camera ranges made in the USSR (the plucky Lomo LC-A compact spawned a movement in photography all on its own), but these are the main ones. They are all reasonably easy to find â€“ very easy in the case of Zenit SLRS and FED rangefinders â€“ and thereâ€™s no shortage of spare parts or repairers that can coax them back to life should anything be wrong.</p>
<p>Kosmo Foto released the video below last year as a guide for common models to investigate:</p>
<p><iframe src="https://www.youtube.com/embed/wGlfbl5Oa_k" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h4><span id="Better_dead_than_Red"></span><strong>Better dead than Red?</strong><span></span></h4>
<p>Make no mistake â€“ many film camera shooters regard Soviet cameras as uniformally awful, junk that should live in a landfill rather than a camera cabinet. Most of these photographers would sooner cut off a limb than handle a clunky Zenit or Zorki.</p>
<p>But the Soviet camera industry had peaks and troughs â€“ periods when construction and quality control were high and times when standards were lax and reliability low. A Soviet rangefinder from the mid-1950s is from a very different system to one produced in the â€œYear of Stagnationâ€ of the late 1970s.</p>
<figure id="attachment_21874" aria-describedby="caption-attachment-21874"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder.jpg" alt="Zorki 1 (Pic: Paulo Moreira)" width="1840" height="1840" srcset="https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder.jpg 1840w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-300x300.jpg 300w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1024x1024.jpg 1024w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-150x150.jpg 150w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-768x768.jpg 768w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1536x1536.jpg 1536w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-696x696.jpg 696w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1068x1068.jpg 1068w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-420x420.jpg 420w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-600x600.jpg 600w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-100x100.jpg 100w" sizes="(max-width: 1840px) 100vw, 1840px"><figcaption id="caption-attachment-21874">The Zorki 1, fitted here with an external turret finder for different lenses (Pic: Paulo Moreira)</figcaption></figure>
<p>The bad reputation which Soviet cameras isnâ€™t undeserved,â€ says Jay Javier, the Filipino photographer and camera collector behind the <a href="https://www.fedka.com/jay/">Fed Zorki Survival Site</a>. â€œMany were really badly designed or made. As these creatures become more known, thanks to the internet, the bad ones get to be publicly shamed and justly avoided. Many of the generalisations in this respect turn out to be valid.â€</p>
<p>Soviet quality control, especially in later years, sometimes left a lot to be desired. Cameras leaving the factory were supposed to be inspected and given a passport signed by a factory foreman ensuring they were working correctly. This The older â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/">https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/</a></em></p>]]>
            </description>
            <link>https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290128</guid>
            <pubDate>Sun, 28 Feb 2021 02:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How fighting games use delay-based and rollback netcode (2019)]]>
            </title>
            <description>
<![CDATA[
Score 293 | Comments 106 (<a href="https://news.ycombinator.com/item?id=26289933">thread link</a>) | @Kinrany
<br/>
February 27, 2021 | https://ki.infil.net/w02-netcode.html | <a href="https://web.archive.org/web/*/https://ki.infil.net/w02-netcode.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<div>
					<div id="content">

						<!-- Content -->
					
							<article>

								<div>
								
								<div>
								<p><a href="https://ki.infil.net/words.html">
								<img src="https://ki.infil.net/images/words/header.gif"></a>
								
								</p></div>
								
								
								
								
								<hr>
								
								<div>
								
								<div>
								<p>Netcode</p>
								<p>Explaining how fighting games use delay-based and rollback netcode</p>
								<p>October 16, 2019</p>
								
								
								
								
								</div>
								
								</div>
							
								
								<!-- blog navigation -->
								
								
								

								<div>
								<div><p>
								<em>I would like to thank <a href="https://twitter.com/Krazhier">krazhier</a> and <a href="https://twitter.com/TheKeits">Keits</a> for taking hours out of their busy schedules to discuss technical aspects of netcode with me, and <a href="https://twitter.com/Sajam">Sajam</a> for taking time to answer interview questions and being supportive throughout the writing process. I would also like to especially thank <a href="https://twitter.com/MagicMoste">MagicMoste</a> for making all the wonderful videos you see in this article. All their help was offered for free and I am thankful for their friendship.
								</em></p><p><em>

								This article has been <a href="https://arstechnica.com/gaming/2019/10/explaining-how-fighting-games-use-delay-based-and-rollback-netcode/">cross-posted on Ars Technica</a>.
								</em></p><p><em>

								You may also enjoy <a href="https://www.youtube.com/watch?v=1RI5scXYhK0">watching a video feature</a> on the topics in this article.
								</em>							
								</p></div>
								</div>

								
															
								<!-- Infil -->
								<div><p><img src="https://ki.infil.net/images/words/infil_smiling_2.jpg"></p>
								<p>
								Welcome back to Fightinâ€™ Words! Itâ€™s been a while since we last discussed how the <a href="https://ki.infil.net/w01-bugs.html">most famous fighting game bugs</a> have impacted the communityâ€™s favorite games. Todayâ€™s topic is a bit more technical, but itâ€™s an equally important factor in how our favorite modern games are played -- weâ€™re going to be doing a <strong>deep dive into netcode</strong>.								
								</p>
								</div>

								<hr><!-- Infil -->
								<div><p><img src="https://ki.infil.net/images/words/infil_lecture.jpg"></p>
								<div><p>
								At its core, netcode is simply a method for two or more computers, each trying to play the same game, to talk to each other over the internet. While local play always ensures that all player inputs arrive and are processed at the same time, <strong>networks are constantly unstable</strong> in ways the game cannot control or predict. Information sent to your opponent may be delayed, arrive out of order, or become lost entirely depending on dozens of factors, including the physical distance to your opponent, if youâ€™re on a WiFi connection, and whether your roommate is watching Netflix.
								</p><p>
								Online play in games is nothing new, but fighting games have their own set of unique challenges. They tend to involve direct connections to other players, unlike many other popular game genres, and <strong>low, consistent latency</strong> is extremely important because muscle memory and reactions are at the core of virtually every fighting game. As a result, two prominent strategies have emerged for playing fighting games online: <strong>delay-based netcode</strong> and <strong>rollback netcode</strong>. 
								</p></div>
								</div>

								<div><p><img src="https://ki.infil.net/images/words/infil_thoughtful.jpg"></p>
								<div><p>
								Thereâ€™s been a renewed passion in the fighting game community that <strong>rollback is the best choice</strong>, and fighting game developers who <a href="https://www.youtube.com/watch?v=qW61xJNJ9m8">choose to use delay-based netcode</a> are <a href="https://www.youtube.com/watch?v=iTUtnclr2hs">preventing the growth of the genre</a>. While people have been passionate about this topic <a href="https://www.youtube.com/watch?v=Tu2kAdmUCaI&amp;t=42m34s">for many years</a>, frustrations continue to rise as new, otherwise excellent games repeatedly have bad online experiences.
								</p><p>

								There are relatively few easy-to-follow explanations for what exactly rollback netcode is, how it works, and why it is so good at hiding the effects of bad connections (though <a href="http://mauve.mizuumi.net/2012/07/05/understanding-fighting-game-networking.html">there are some</a>). Because I feel this topic is extremely important for the future health of the fighting game community, I want to help squash some misconceptions about netcode and explain both netcode strategies thoroughly so everyone can be informed as they discuss. If you stick around to the end, Iâ€™ll even <strong>interview some industry experts and community leaders</strong> on the topic!
								</p><p>
								Before we dig into the details, though, letâ€™s get one thing straight.
										
								</p></div>
								</div>

								<hr><!-- Infil -->
								<!-- header -->
								

								<div><p><img src="https://ki.infil.net/images/words/infil_smiling_3.jpg"></p>
								<div><p>
										Both companies and players should care about good netcode because <strong>playing online is no longer the future -- it's the present</strong>. 
								</p><p>
										While most other video game genres have been this way for a decade or longer, fighting game developers seem to be resistant to embracing online play, perhaps because of the genreâ€™s roots in offline settings such as arcades and tournaments. Playing offline is great, and it will always have considerable value in fighting games, but itâ€™s simply a reality that <strong>a large percentage of the player base will never play offline</strong>. For many fighting game fans, playing online <em>is</em> the game, and a bad online experience prevents them from getting better, playing or recommending the game to their friends, and ultimately causes them to <a href="https://youtu.be/iTUtnclr2hs?t=758">simply go do something else</a>.
								</p><p>
										Even if you think you have a good connection, or live in an area of the world with robust internet infrastructure, good netcode is still mandatory. Plus, lost or delayed information happens regularly even on the best networks, and poor netcode can <a href="https://twitter.com/john_takeuchi/status/1162562266027327488">actively hamper matches</a> no matter how smooth the conditions may be. Good netcode also has the benefit of connecting regions across greater distances, effectively uniting the global player base as much as possible.

										<!-- gif 1A -->
										</p><div><!-- image -->
											<figure>
												
											<figcaption>Bad netcode can ruin matches. This match, played online between two Japanese players, impacted who gets to attend the Capcom Pro Tour finals. <a href="https://twitter.com/john_takeuchi/status/1162562266027327488">(source)</a>
											</figcaption></figure></div>
										
								</div>
								</div>

								<div><p><img src="https://ki.infil.net/images/words/infil_content.jpg"></p>
								<div><p>
										What about those who never play online because they much prefer playing offline with their friends? The <strong>healthy ecosystem</strong> that good netcode creates around a game benefits everyone. There will be more active players, more chances to consume content for your favorite game -- from tech videos to spectating online tournaments to expanding the strategy of lesser-used characters -- and more excitement surrounding your game in the FGC. Despite <a href="http://ki.infil.net/">Killer Instinct</a>â€™s pedigree as an excellent game, thereâ€™s no doubt that its superb rollback netcode has played a huge part in the sustained growth of its community.
								</p><p>

										Good netcode matters, period. So letâ€™s talk about it.
										
								</p></div>
								</div>
								
								
								<!-- blog navigation -->
								
								
								

								</div>
								
							</article>
				
					</div>
				</div>
			</section></div>]]>
            </description>
            <link>https://ki.infil.net/w02-netcode.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289933</guid>
            <pubDate>Sun, 28 Feb 2021 01:47:03 GMT</pubDate>
        </item>
    </channel>
</rss>
