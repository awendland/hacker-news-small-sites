<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 21 Oct 2020 20:28:53 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 21 Oct 2020 20:28:53 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Assorted Thoughts on Zig (and Rust)]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24835357">thread link</a>) | @ikskuh
<br/>
October 20, 2020 | https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I've been using <a href="https://ziglang.org/">zig</a> for ~4 months worth of side projects, including a <a href="https://git.sr.ht/%7Ejamii/focus/tree">toy text editor</a> and an <a href="https://git.sr.ht/%7Ejamii/imp">interpreter for a relational language</a>. I've written ~10kloc.</p>
<p>That's not nearly enough time to form a coherent informed opinion. So instead here is an incoherent assortment of thoughts and experiences, in no particular order :)</p>
<p>This is not meant to be an introduction to zig - check out the excellent <a href="https://ziglang.org/documentation/master/">language docs</a> or the new <a href="https://ziglearn.org/">ziglearn.org</a> instead. I'll try to focus instead on things that are not immediately obvious from reading intro material.</p>
<p>The obvious point of comparison is to rust. For context, I've been using rust <a href="https://scattered-thoughts.net/writing/three-months-of-rust/">since 2015</a>. Mostly in research positions writing throwaway code, but also ~14 months working on <a href="https://materialize.io/">a commercial database</a> which is ~100kloc.</p>
<hr>
<p>Zig is dramatically simpler than rust. It took a few days before I felt proficient vs a month or more for rust.</p>
<p>Most of this difference is <strong>not</strong> related to lifetimes. Rust has patterns, traits, dyn, modules, declarative macros, procedural macros, derive, associated types, annotations, cfg, cargo features, turbofish, autoderefencing, deref coercion etc. I encountered most of these in the first week. Just understanding how they all work is a significant time investment, let alone learning when to use each and how they affect the available design space.</p>
<p>I still haven't internalized the full rule-set of rust enough to be able predict whether a design in my head will successfully compile. I don't remember the order in which methods are resolved during autoderefencing, or how module visibility works, or how the type system determines if one impl might <a href="https://github.com/Ixrec/rust-orphan-rules#what-are-the-orphan-rules">overlap another or be an orphan</a>. There are frequent moments where I know what I want the machine to do but struggle to encode it into traits and lifetimes.</p>
<p>Zig manages to provide many of the same features with a single mechanism - compile-time execution of regular zig code. This comes will all kinds of pros and cons, but one large and important pro is that I already know how to write regular code so it's easy for me to just write down the thing that I want to happen.</p>
<hr>
<p>One of the key differences between zig and rust is that when writing a generic function, rust will prove that the function is type-safe for every possible value of the generic parameters. Zig will prove that the function is type-safe only for each parameter that you actually call the function with.</p>
<p>On the one hand, this allows zig to make use of arbitrary compile-time logic where rust has to restrict itself to structured systems (traits etc) about which it can form general proofs. This in turn allows zig a great deal of expressive power and also massively simplifies the language.</p>
<p>On the other hand, we can't type-check zig libraries which contain generics. We can only type-check specific uses of those libraries.</p>
<pre><span>// This function is typesafe if there exist no odd perfect numbers
// https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers
fn foo(comptime n: comptime_int, i: usize) usize {
  const j = if (comptime is_odd_perfect_number(n)) "surprise!" else 1;
  return i + j;
}
</span></pre>
<p>This means zig also doesn't get the automatic, machine-checked documentation of type constraints that rust benefits from and may face more challenges providing IDE support.</p>
<p>This might harm the zig ecosystem by making it harder to compose various libraries. But <a href="https://julialang.org/">julia</a> has a similar model and in practice it has worked very well (<a href="https://youtu.be/dmWQtI3DFFo?t=1710">eg</a>, <a href="https://www.oxinabox.net/2020/02/09/whycompositionaljulia.html">eg</a>).</p>
<hr>
<p>Zig's comptime allows expressing <a href="https://scattered-thoughts.net/writing/open-multiple-dispatch-in-zig/">open multiple dispatch</a> as a library.</p>
<p>It should be relatively trivial to implement specialization the same way, which has been a <a href="https://github.com/rust-lang/rust/issues/31844">work in progress</a> in rust for years and is critical to many optimizations in julia's math libraries.</p>
<p>Julia chose dynamic typing because it's very difficult to encode the types of various mathematical operations into a general schema (eg fortress <a href="https://youtu.be/EZD3Scuv02g?t=3011">struggled with this</a>). Zig's approach of not requiring general schemas but still type-checking individual cases may be an interesting sweet spot.</p>
<hr>
<p>I used the <a href="https://cwe.mitre.org/data/definitions/1350.html">2020 CWE Top 25 Most Dangerous Software Weaknesses</a> to get a sense of the relative frequency of different causes of memory unsafety.</p>
<p>(I'm assuming that the zig programmer is using release-safe mode instead of the unfortunately named release-fast mode which disables all runtime safety checks.)</p>
<ul>
<li>Out-of-bounds Write (787/1350)</li>
<li>Out-of-bounds Read (125/1350)</li>
<li>Improper Restriction of Operations within the Bounds of a Memory Buffer (119/1350)</li>
</ul>
<p>Both languages primarily use bounds-checked slices and relegate pointer arithmetic to a separate type (<code>*T</code> in rust, <code>[*]T</code> in zig).</p>
<ul>
<li>NULL Pointer Dereference (476/1350)</li>
</ul>
<p>Both languages require explicit annotations for nulls (<code>Option&lt;T&gt;</code> in rust, <code>?T</code> in zig) and require code to either handle the null case or safely crash on null (<code>x.unwrap()</code> in rust, <code>x.?</code> in zig).</p>
<p>Dereferencing/casting a null c pointer is undefined behavior in both languages, but is checked at runtime in zig.</p>
<ul>
<li>Integer Overflow or Wraparound (190/1350)</li>
</ul>
<p>Rust catches overflow in debug and wraps in release. Zig catches overflow in debug/release-safe and leaves behavior undefined in release-fast.</p>
<p>Both languages allow explicitly asking for wraparound (<code>x.wrapping_add(1)</code> in rust, <code>x +% 1</code> in zig).</p>
<ul>
<li>Use After Free (416/1350)</li>
</ul>
<p>As long as all unsafe code obeys the aliasing and lifetime rules, rust protects completely against UAF.</p>
<p>Zig has little protection. The recently merged
<a href="https://github.com/ziglang/zig/blob/575fbd5e3592cff70cbfc5153884d919e6bed89f/lib/std/heap/general_purpose_allocator.zig">GeneralPurposeAllocator</a> avoids reusing memory regions (which prevents freed data from being overwritten) and reusing pages (which means that UAF will eventually result in a page fault). But this comes at the cost of fragmentation and lower performance and it also won't provide protection for child allocators using the GPA as a backing allocator.</p>
<hr>
<p>Both languages will insert implicit casts between primitive types and pointers whenever it is safe to do so, and require explicit casts otherwise. (With the odd exception that rust will not implicitly upcast numbers).</p>
<p>Both languages support generics which almost entirely avoids the need to cast void pointers.</p>
<hr>
<p>In rust the Send/Sync traits flag types which are safe to move/share across threads. In the absence of unsafe code it should be impossible to cause data races.</p>
<p>Zig has no comparable protection. It's possible to implement the same logic as Send/Sync in comptime zig, but without the ability to track ownership the rules would have to be much more restrictive.</p>
<hr>
<p>Rust prevents having multiple mutable references to the same memory region at the same time.</p>
<p>This means that eg iterator invalidation is prevented at compile time, because the borrow checker won't allow mutating a data-structure while an iterator is holding a reference to the data-structure. Similarly for resizing a data-structure while holding a reference to the old allocation. Both examples are easy sources of UAF in zig.</p>
<hr>
<p>Neither language is able to produce stack traces for stack overflows at the moment (<a href="https://github.com/rust-lang/rust/issues/51405">rust</a>, <a href="https://github.com/ziglang/zig/issues/1616">zig</a>)</p>
<p>In the future zig is <a href="https://github.com/ziglang/zig/issues/1006">intended</a> to statically check the maximum stack usage of your program and force recursive code to explicitly allocate space on the heap, so that stack overflows produce a recoverable OutOfMemory error rather than a crash.</p>
<p>This is not an academic problem - I've seen real-world crashes from recursive tree transformations in compilers (<a href="https://github.com/MaterializeInc/materialize/pull/3996">eg</a>) and it's often painful to write the same logic without recursion.</p>
<hr>
<p>Undefined behavior in rust is defined <a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">here</a>. It's worth noting that breaking the aliasing rules in unsafe rust can cause undefined behavior but these rules are not yet well-defined. So far this hasn't caused me any problems but it is a little unnerving.</p>
<p><a href="https://github.com/rust-lang/miri">Miri</a> is an interpreter for rusts Mid-level Intermediate Representation which will detect many (but not all) cases of undefined behavior in unsafe rust. It's far too slow to use for the whole materialize test suite but was useful for unit-testing an unsafe module.</p>
<p>Undefined behavior in zig is defined <a href="https://ziglang.org/documentation/master/#Undefined-Behavior">here</a>. This list is <a href="https://github.com/ziglang/zig/issues/1966">probably incomplete</a> given that the core language is still under development.</p>
<p>Zig <a href="https://github.com/ziglang/zig/issues/2301">aspires</a> to insert runtime checks for almost all undefined behavior when compiling in debug mode. So far all the easy cases are handled, which is already a dramatic improvement over c.</p>
<p>Zigs compile-time partial evaluation is done by an IR interpreter - it seems plausible that this could also be used as a miri-like tool in the future.</p>
<hr>
<p><code>@import</code> takes a path to a file and turns the whole file into a struct. So modules are just structs. And vice-versa - if you have a large struct declaration you can move it into a file to reduce the indentation.</p>
<p>Zig doesn't care at all where you put files on the filesystem.</p>
<p><code>@import</code> is part of the compile-time execution system so things like platform-specific modules and configurable features can be specified in regular code rather than rust's limited set of <code>#[cfg(...)]</code> macros.</p>
<hr>
<p>Array, struct, enum and union literals can be anonymous - <code>.{.Constant = 1.0}</code> is an anonymous union with it's own type, but can be implicitly cast to any union with a <code>Constant: f64</code> field because they share the same structure.</p>
<p>In rust my code is littered with <code>use Expr::*</code> and I'm careful to avoid name collisions between different enums that I might want to import in the same functions. In zig I just use anonymous literals everywhere and don't worry about it.</p>
<hr>
<p>Anonymous literals are also nice when using structs to simulate keyword arguments. No need to find and import the correct type:</p>
<pre><span>fn do_things(config: struct {
  max_things: usize = 1000, // default value
  flavor: Flavor,
}) void {
  ...
}

do_things(.{.flavor = .Strawberry});
</span></pre>
<hr>
<p>There is a pattern that shows up a lot in the materialize codebase:</p>
<pre><span>let</span><span> constant </span><span>= </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(constant) </span><span>=</span><span> expr { constant } </span><span>else </span><span>{ </span><span>panic!</span><span>() }</span><span>;
</span></pre>
<p>It's common enough that many types have methods like <code>expr.unwrap_constant()</code>.</p>
<p>In zig:</p>
<pre><span>const constant = expr.Constant;
</span></pre>
<p>A similar pattern is:</p>
<pre><span>if</span><span> some_condition {
    </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(</span><span>_</span><span>) </span><span>=</span><span> expr {
        </span><span>...
    </span><span>}
}
</span></pre>
<p>Again, many types get methods like <code>expr.is_constant()</code>.</p>
<pre><span>if</span><span> some_condition </span><span>&amp;&amp;</span><span> expr</span><span>.</span><span>is_constant</span><span>(…</span></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</a></em></p>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835357</guid>
            <pubDate>Tue, 20 Oct 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Design Stripe or HackerNews-like favicons in seconds!]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24835219">thread link</a>) | @hosshams
<br/>
October 20, 2020 | https://formito.com/tools/favicon | <a href="https://web.archive.org/web/*/https://formito.com/tools/favicon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Copy the following code and put it inside the<!-- --> <code>&lt;head&gt;</code> tag of your website.</p><pre><code></code></pre><p>Or, download the SVG file, add the following code to<!-- --> <code>&lt;head&gt;</code> tag of your website, and replace<!-- --> <code>href</code> attribute with URL to your SVG file.</p><pre><code>&lt;link rel="icon" type="image/svg+xml" href="favicon.svg" /&gt;</code></pre></div></div>]]>
            </description>
            <link>https://formito.com/tools/favicon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835219</guid>
            <pubDate>Tue, 20 Oct 2020 08:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Long Road to HTTP/3]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24834767">thread link</a>) | @todsacerdoti
<br/>
October 20, 2020 | https://scorpil.com/post/the-long-road-to-http3/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/the-long-road-to-http3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>While HTTP/3 specification is still in the draft stage, the latest version of the Chrome browser already <a href="https://blog.chromium.org/2020/10/chrome-is-deploying-http3-and-ietf-quic.html" target="_blank" rel="nofollow">supports it by default</a>
. With Chrome holding around 70% of browser market share, you could say HTTP/3 has gone mainstream.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/quic-logo.png" alt="QUIC logo"></p><p>The new revision of this foundational protocol aims to make the web more efficient, secure, and shorten the content-delivery latencies. In some ways, it’s a braver take of HTTP2: similar goals addressed by replacing the underlying TCP protocol with a new, purpose-built protocol QUIC. The best way to explain the benefits of QUIC is to illustrate where TCP falls short as a transport for HTTP requests. And to do that, we’ll start at the very beginning.</p><h3 id="http-the-original">HTTP. The Original.</h3><p>When Sir Tim Berners-Lee formalized the design of a simple <a href="https://www.w3.org/Protocols/HTTP/AsImplemented.html" target="_blank" rel="nofollow">one-line hyper-text-exchange protocol</a>
in 1991, TCP was already an old, reliable protocol. The original definition document of what later became known as HTTP 0.9 specifically mentions TCP as a preferred, albeit not exclusive, transport protocol:</p><blockquote><p>Note: HTTP currently runs over TCP, but could run over any connection-oriented service.</p></blockquote><p>Of course, this proof-of-concept version of HTTP had very few similarities to HTTP we now know and love today. There were no headers and no status codes. The typical request was as simple as <code>GET /path</code>. The response contained only HTML and ended with the closing of the TCP connection.
Since browsers were not yet a thing, user was supposed to read HTML directly. It was possible to link to other resources, but none of the tags present in this early version of HTML requested additional resources asynchronously. A single HTTP request delivered a complete, self-sufficient page.</p><h3 id="emergence-of-http10">Emergence of HTTP/1.0</h3><p>In subsequent years the internet has exploded, and HTTP evolved to be an extendable and flexible general-purpose protocol, although transporting HTML remained its chief specialty. There are three critical updates to HTTP that enabled this evolution:</p><ul><li>introduction of methods allowed the client to identify the type of action it wants to perform. For example, POST was created to allow client sending data to the server to process and store</li><li>status codes provided a way for client to confirm that the server has processed the request successfully, and if not - to understand what kind of error has occured</li><li>headers added an ability to attach structured textual metadata to requests and responses that could modify the behavior of the client or server. Encoding and content-type headers, for example, allowed HTTP to transfer not just HTML, but any type of payload. “Compression” header allowed the client and server to negotiate supported compression formats, thus reducing the amount of data to transfer over the connection</li></ul><p>At the same time, HTML advanced to support images, styles, and other linked resources. Browsers were now forced to perfrom multiple requests to display a single web page, which the original connection-per-request architecture was not designed to handle. Establishing and ending a TCP connection involves a lot of back-and-forth packet exchange, so it is relatively expensive in terms of latency overhead. It didn’t matter much when a web-page consisted of a single text file, but as the number of requests per page increased, so did the latency.</p><p>The picture below illustrates how much overhead was involved in establishing a new TCP connection per request.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-tcp-overhead.png" alt="TCP connection requires three requests to establish connection and four to close it cleanly"></p><p>A “connection” header was created to address this problem. Client sends a request with “connection: keep-alive” header to signal intent to keep the TCP connection open for subsequent requests. If server understands this header and agrees to respect it, its response will also contain the “connection: keep-alive” header. This way, both parties maintain TCP channel open and use it for subsequent communication until either party decides to close it. This became even more important with the spread of SSL/TLS encryption, because negotianting an encryption algorithm and exchanging cryptographic keys requires an additional request/response cycle on each connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-keepalive.png" alt="A single TCP connection can be reused for multiple requests with “connection: keep-alive” header"></p><p>At the time, many of the HTTP improvements appeared spontaneously. When a popular browser or a server app saw a need for a new HTTP feature, they would simply implement it themselves and hoped that other parties would follow the suit. Ironically, a decentralized web needed a centralized governing body to avoid fragmentation into incompatible pieces. Tim Berners-Lee, the original creator of the protocol, recognized the danger and founded the World Wide Web Consortium (W3C) in 1994, which together with the Internet Engineering Task Force (IETF) worked on formalizing stack of internet technologies. As the initial step to bring more structure to the existing environment, they documented the most common features used in HTTP at the time and named the resulting protocol HTTP/1.0. However, because this “specification” described varied, often inconsistent techniques as seen “in the wild”, it never received a status of a standard. Instead, the work on the new version of the HTTP protocol has begun.</p><h3 id="standardization-of-http11">Standardization of HTTP/1.1</h3><p>HTTP/1.1 fixed inconsistencies of HTTP/1.0 and adjusted the protocol to be more performant in the new web ecosystem. Two of the most critical changes introduced were the use of persistent TCP connections (keep-alive’s) by default and HTTP pipelining.</p><p>HTTP pipelining simply means that client does not need to wait for the server to respond to a request before sending subsequent HTTP requests. This feature resulted in even more efficient use of bandwidth and reduced latencies, but it could be improved even more. HTTP pipelining still requires from server to respond in the order of requests received, so if a single request in a pipeline is slow to fulfill, all subsequent responses to a client will be delayed accordingly. This problem is known as head-of-the-line blocking.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http11-blocking.png" alt="Since large-picture.jpg was requested first, it’s blocking the delivery of the style.css"></p><p>At this point in time, the web is gaining more and more interactive capabilities. Web 2.0 is just around the corner, some webpages include dozens or even hundreds of external resources. To work around the head-of-the-line blocking, and to decrease page loading speeds, clients establish multiple TCP connections per host. Of course, the connection overhead never went anywhere. In reality, it got worse, since more and more applications encrypt HTTP traffic with SSL/TLS. So most browsers set the limit of maximal possible simultaneous connections in an attempt to strike a delicate balance.</p><p>Many of the larger web-services have recognized that existing limitations are too restricting for their exceptionally heavy interactive web-applications, so they “gamed the system” by distributing their app through multiple domain names. It all worked, somehow, but the solution has been far from elegant.</p><p>Despite a few shortcomings, the simplicity of HTTP/1.0 and HTTP/1.1 has made them widely successful, and for over a decade no one has made a serious attempt to change them.</p><h3 id="spdy-and-http2">SPDY and HTTP/2</h3><p>In 2008 Google released the Chrome browser, which rapidly gained popularity for being quick and innovative. It has given Google a strong vote on matters of internet technologies. In the early 2010s, Google adds support for its web protocol SPDY to Chrome.</p><p>HTTP/2 standard was based on SPDY with some improvements. HTTP/2 solved the head-of-the-line blocking problem by multiplexing the HTTP requests over a single open TCP connection. This allowed server to answer requests in any order, client could then re-assemble the responses as it received them, making the whole exchange faster within a single connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http2-multiplexing.png" alt="style.css was returned before the large-picture.jpg, becuase of HTTP/2 multiplexing"></p><p>In fact, with HTTP/2 server can serve the resources to a client before it even asked for it! To give an example, if the server knows that client will most likely need a stylesheet to display an HTML page, it can “push” the CSS to the client without waiting for a corresponding request. While beneficial in theory, this feature rarely seen in practice, since it requires a server to understand the structure of the HTML it serves, which is rarely the case.</p><p>HTTP/2 also allows compressing request headers in addition to the request body, which further reduces the amount of data transferred over the wire.</p><p>HTTP/2 solved a lot of problems for the web, but not all of them. A similar type of head-of-the-line problem is still present on the level of TCP protocol, which remains a foundational building block of the web. When a TCP packet gets lost in transit, the receiver can’t acknowledge incoming packages until the lost package is re-sent by a server. Since TCP is by design oblivious to higher-level protocols like HTTP, a single lost packet will block the stream for all in-flight HTTP requests until the missing data is re-sent. This problem is especially prominent on an unreliable connection, which is not rare in the age of ubiquitous mobile devices.</p><h3 id="http3-revolution">HTTP/3 revolution</h3><p>Since issues with HTTP/2 can not be resolved purely on the application layer a new iteration of the protocol must update the transport layer. However, creating a new transport-layer protocol is not an easy task. Transport protocols need to be supported by hardware vendors and deployed by the majority of network operators, which are reluctant to update because of the costs and efforts involved. Take IPv6 as an example: it was introduced 24 years ago and is still far from being universally supported.</p><p>Fortunately, there is another option. UDP protocol is as widely supported as TCP but is simple enough to serve as a building block for custom protocols running on top of it. UDP packets are fire-and-forget: there are no handshakes, persistent connections, or error-correction. The primary idea behind HTTP3 is to abandon TCP in favor of a UDP-based QUIC protocol. QUIC adds the necessary features (those that were previously provided by TCP, and more) in a way that makes sense for the web environment.</p><p>Unlike HTTP2, which technically allowed an unencrypted communication, QUIC strictly requires encryption to establish a connection. Additionally, encryption is applied to all data …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scorpil.com/post/the-long-road-to-http3/">https://scorpil.com/post/the-long-road-to-http3/</a></em></p>]]>
            </description>
            <link>https://scorpil.com/post/the-long-road-to-http3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834767</guid>
            <pubDate>Tue, 20 Oct 2020 07:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My chatbot is dead – Why yours should probably be too]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24834552">thread link</a>) | @raphaelsaunier
<br/>
October 19, 2020 | https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/ | <a href="https://web.archive.org/web/*/https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                
<audio controls="controls"><source src="https://azumbrunnen.me/audio/chatbot-is-dead" type="audio/mpeg"></audio>



<p>Personal websites are usually like old books in a shelf. They languish, accumulate dust, and their wrinkles and cracks become more apparent over time. About 3 years ago I embarked on a simple experiment that would end up prolonging the shelf-life of my website by an unusually large margin.</p>



<p>Back in 2017, it seemed like Conversational UI was poised to take over the world. We saw Quartz turning news into a conversation, WeChat being featured as the poster-child of a post application world, iMessage turning into an unnecessarily complex mess, and chatbots popping up like mushrooms in moist forests.</p>



<p>Of course, any trend gaining so much traction and interest needs to be taken seriously. As such, I decided to familiarize myself with the topic, and turned my website into a chatbot.</p>



<p>Instead of being greeted by the internationally standardized greeting every designer used at some point in their career, there was no bold, dramatically oversized, and deep black sans-serif reading: <em>Hi, I’m a designer.</em> (To be fair, I didn’t use Proxima Nova either)</p>



<p>Instead, a couple of chat bubbles exuberantly ushered onto the canvas to greet users as if we had all been long time friends.</p>



<figure><video autoplay="" loop="" muted="" src="https://azumbrunnen.me/wp-content/uploads/chatbot-animated.mp4" playsinline=""></video><figcaption>Conversational intro</figcaption></figure>



<p>It was witty, new, and slightly awkward. People would send messages that ranged from simple chit chat, to deep philosophical topics, to downright disturbing and ridiculous insults.</p>



<p>The experiment got featured on Hackernews, Medium, was used in psychological studies conducted by Dan Ariely’s team, and the source code was ripped and edited by various startups to fit their needs. One business in the Bay Area had an idea to use it to sell flowers in a conversational way. It looks like they went out of business.</p>



<p>The reaction and feedback was surprising to say the least. It was an idea so simple, so silly, that the outcome was in many ways unexpected. After all, the only one who really cares about your website, is usually yourself.</p>



<p>That didn’t stop me from revamping my website and kill the very thing that had turned it into a micro-celebrity before. With the death of my old chatbot, some angry emails by schools who are using it as a reference for “creative” web design, and a good amount of time that has passed ever since, I wanted to take a step back and set the record straight.</p>



<hr>



<h2>When chatbots matter</h2>



<p>So let’s be honest with ourselves for a moment: <em>when did you actually ever enjoy talking to a chat bot?</em> And I’m not talking about the type of bots you talk to when you’re bored, but about those that provide a deeper purpose.</p>



<p>It turns out that the answer is, at least for most of us, almost never.</p>



<p>I love you Intercom, except when I don’t. 99% of time I don’t want to talk to a silly and obtrusive avatar popping up from some corner of the screen before I even had a chance to check out what’s going on. Somehow, I can’t help but think others feel the same.</p>



<p>In fact, we do know that others feel the same. Chat heads jumping at us unasked, are the quintessential equivalent of the infamous sales clerk who eagerly talks to us upon entering a store.</p>



<p>To further add to the challenges: as soon as users go off-script, chat bot’s don’t just become awkward and unpredictable—they turn into little sociopaths that might rub users the wrong way.</p>



<figure><img loading="lazy" width="400" height="346" src="https://azumbrunnen.me/wp-content/uploads/grandma.png" alt="" srcset="https://azumbrunnen.me/wp-content/uploads/grandma.png 400w, https://azumbrunnen.me/wp-content/uploads/grandma-300x260.png 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption>UX Chat.me —&nbsp;Conversational UX News</figcaption></figure>



<p>The moment you create a chat bot is the moment you allow customers to have a conversation with <em>your brand</em>. Not with yourself, not with your friend, but with an uber entity—a symbol—that represents everything you and your team stand for. That’s not a step to be taken lightly.</p>



<p>This simple conversational entity can be a fun tool to engage with people but depending on how the conversation goes, it can quickly turn into a misrepresentation of the values of your team and your company. So building a chat bot should never be the default choice, but an intentional one.</p>



<p>That’s why it’s worth asking yourself the following three questions before venturing into this space:</p>



<h3>1. Is your use case simple enough to be solved through chat?</h3>



<p>Conversation is incredibly complex and it’s challenging enough to keep it on track in the real world. If the use case isn’t simple, chances are, chat bots are not the right tool for the job.</p>



<h3>2. Is your NLP capable and sophisticated enough?</h3>



<p>There are two types of bots: pre-scripted bots with a range of default answers users can choose from, and Natural Language Processing based ones.</p>



<p>Choosing the right one is hard. While pre-scripted can feel too limiting, NLP can break at every corner. Often times, teams quickly fall into the trap of spending a huge amount of time focusing on personality and silly jokes, instead of solving the problem users hired you for in the first place.</p>



<p>Therefore, building on top of the first point above, within the conversational landscape, simple always wins.</p>



<h3>3. Are your users actually in chat based environments?</h3>



<p>Chat bots work best where users already are. If your users are primarily spending time in messaging platforms where bots and micro-apps can be seamlessly embedded, great. That can serve as an effective and natural way to engage with your audience because it matches the “be where users already are” principle.</p>



<p>If on the other hand, people come to your website, a medium that has made great strides to provide content in a non-linear and quick way, it often unnecessarily slows users down. </p>



<hr>



<h2>Farewell chatbot</h2>



<p>I don’t want to discredit chat bots as a paradigm. They have their use in certain industries, medium, and work well for a specific set of use cases. The important part is being deliberate, rather than jumping ship blindfolded.</p>



<p>So whereas turning my website into a chat was a fun experiment, I ultimately feel like it has slowly turned into a fad. I got fooled by the trend, and as a by-product became part of the trend itself.  Fads come and go, and as they get refined and re-interpreted, they ultimately find their true purpose. What we’re left with is the age old insight that it’s only through experimentation, that we can unlock concepts and ideas that last.</p>



<p>Rest in peace chat bot, long live chat bots.</p>
            </article></div>]]>
            </description>
            <link>https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834552</guid>
            <pubDate>Tue, 20 Oct 2020 06:52:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moana Motunui Renderer on GPU]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24833218">thread link</a>) | @Impossible
<br/>
October 19, 2020 | https://www.render-blog.com/2020/10/03/gpu-motunui/ | <a href="https://web.archive.org/web/*/https://www.render-blog.com/2020/10/03/gpu-motunui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>03 Oct 2020</span></p><p>Disney Animation’s Moana island dataset is a production-scale scene with memory requirements that make it challenging to render. This post summarizes some of those challenges, and describes how the <a href="https://github.com/chellmuth/gpu-motunui">GPU-Motunui</a> project is able to efficiently render the scene on a consumer-grade GPU with less than 8GB of memory. <a href="#renders">Click here</a> to skip ahead to the results.</p>

<h2 id="the-moana-island">The Moana island</h2>

<p>In 2018, Disney Animation released the Moana island dataset to the rendering research community. Compared to traditional research scenes, the scale of the Moana island scene is massive: the scene contains 90 million quad primitives, 5 million curves, and more than 28 million instances. All told, the island consists of over 15 billion primitives, weighing in at just under 30GB of geometry files.</p>

<p>The shots included with the dataset are beautiful, and showcase the amazing imagery that can be created by combining the best artists in the world with path tracing techniques and modern hardware. Here are two reference images, rendered with Disney’s proprietary Hyperion renderer:</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-shotCam.png" alt="Hyperion shotCam reference"></p><p>Hyperion shotCam reference</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-beachCam.png" alt="Hyperion beachCam reference"></p><p>Hyperion beachCam reference</p>
</div>

<h2 id="gpu-motunui-project">GPU-Motunui Project</h2>

<p>The goal of the GPU-Motunui project is to render all the Moana shots efficiently and accurately on a consumer-grade graphics card. There are two main challenges to accomplishing this with the Moana dataset. First, with a typical graphics card having only 8GB of memory, an out-of-core rendering solution is required to handle the large amounts of geometry. Second, the scene’s textures are provided in the Ptex format, and Ptex doesn’t have a publicly available CUDA implementation. This project currently only solves the first problem, and Ptex texture lookup is done on the CPU (although conveniently its cost is fully hidden by being computed concurrently with GPU shadow ray tracing).</p>

<p>The Hyperion reference images are impossible to match exactly; for example the varying brown and green colors along the palm tree fronds in the palmsCam shot are not provided in the dataset. Other features of the scene are possible to render but out of my initial scope, notably subdivision surfaces and their displacement maps, and a full Disney BSDF implementation.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-unique-palmsCam.png" alt="Example of an unreproducible material variation on the palm tree frond"></p><p>Example of an unreproducible material variation on the palm tree frond</p>
</div>

<p>All ray tracing operations are run through Nvidia’s OptiX 7 API. This means GPU-Motunui gets the full benefits of available RT cores and a world-class BVH implementation. The following sections describe how GPU-Motunui maps dataset assets to OptiX data structures, and how GPU-Motunui’s out-of-core rendering solution works.</p>

<h3 id="scene-representation">Scene representation</h3>

<p>The Moana scene makes widespread use of multi-level instancing. In OptiX, this requires a three-level hierarchy of acceleration structures to manage: two levels of IASs, and a base level of GASs (Instance Acceleration Structures and Geometry Acceleration Structures, respectively). GPU-Motunui makes use of OptiX’s AS compaction and relocation APIs to further reduce memory usage.</p>

<p>The isHibiscus element makes a good example of how a typical element in the scene is organized and built. The tree is assembled from a base model in one Wavefront .obj file (containing the trunk and branches), and four primitives: one flower and three leaf models (each with their own .obj file).</p>

<div>

<p>Left: The four simple primitives that will be instanced to fill out the hibiscus tree <br>Right: The base trunk and branches model </p>
</div>

<p>In OptiX, each of these models has an associated GAS, and each GAS can be subdivided into multiple build inputs. Build inputs are used to map sections of the model to information needed at shading time by indexing into OptiX’s shader binding table. These GASs form the bottom level of the hierarchy.</p>

<p>Next, an IAS is used to build the full isHibiscus element. This IAS is in the middle level of the hierarchy. The figure below shows each primitive’s instances in isolation, and combined to make the full element:</p>

<div>

<p>Left: Isolated instances for each primitive<br>Right: Full isHibiscus element</p>
</div>

<p>Finally, a second IAS is built to track all of the element’s instances present in the scene. This second IAS is the top level of the instance hierarchy.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/isHibiscus-instanced-elements.png" alt="The shotCam view rendered with only isHibiscus instances"></p><p>The shotCam view rendered with only isHibiscus instances</p>
</div>

<p>Although the isHibiscus element has a typical structure, there are some more complicated elements included in the dataset. The isCoral element, for example, has different base geometry and instanced primitives for each of its element instances, but the underlying primitive geometries are shared across all the element instances.</p>

<p>The Moana GAS and IASs alone require 18.5 GB, well past the memory budget of my 8GB RTX 2070. Because OptiX has no native support for out-of-core rendering, the traditional OptiX pipeline had to be put aside for a custom-made solution.</p>

<h3 id="out-of-core-rendering">Out-of-core rendering</h3>

<p>To solve the out-of-core rendering problem, GPU-Motunui divides the scene’s geometry into different sections, and ray traces each separately, while tracking the closest hit. Replacing a traditional device trace call with a host loop comes with many design consequences to the renderer, from asset loading to the core path tracing loop that sends rays through the scene.</p>

<p>Before rendering, the asset loading process allocates a large chunk of GPU memory (currently 6.7GB). A custom allocator is implemented that manages this block of memory. It is responsible for allocating two types of memory: output and temporary. Output memory is allocated from the left of the block, and is used for OptiX structures. Temporary memory is managed on a stack from the right end of the memory block. Managing the temporary memory this way ensures that the output structures are always tightly packed.</p>

<p>After elements are processed into their accelerator structures on the GPU, their used memory is snapshotted onto the host, and the allocator is cleared. The process is repeated until all of the scene’s geometry is processed, resulting in the host managing a list of GPU memory snapshots. The figure below shows an example layout of GPU memory that could be snapshotted:</p>

<div>
  <p>GPU memory layout after loading the isHibiscus element.<br>(Dotted arrows show that an IAS holds instances of the pointed-at AS)</p>

</div>

<p>As mentioned above, when it comes time to ray trace, each snapshot is processed in a loop. This means a call to <code>cudaMemcpy</code> and <code>optixLaunch</code> for each snapshot. A global buffer is maintained that indicates the depth of the current closest intersection. This value is used as the <code>tmax</code> parameter for the CUDA kernel’s call to <code>optixTrace</code>, and a successful intersection will update the depth buffer for the next launch.</p>

<p>In a traditional OptiX path tracer, the entire render loop can run in device code inside a single call to <code>optixLaunch</code>; i.e., a successful intersection will lead to more BSDF and shadow rays being traced in the same kernel launch. Because GPU-Motunui’s design mandates multiple launches for tracing each path segment, the render loop is pulled out into host code. While this potentially diminishes OptiX’s ability to efficiently schedule program execution, it also opens up opportunties for optimization, such as running Ptex texture lookups on the CPU concurrently with GPU kernels and I/O.</p>

<h3 id="shading">Shading</h3>
<p>As with any OptiX application, GPU-Motunui makes use of the shader binding table (SBT). SBT records contain pointers to normal buffers and material attributes. The underlying data for the normal buffers is stored alongside OptiX acceleration structures and included in geometry snapshots. This ensures that GPU memory is never wasted on unreachable normal buffer data.</p>

<h2 id="renders">Renders</h2>
<p>Included below are GPU-Motunui renders of the six scenes included in the dataset. shotCam is the slowest to render at 18.2 seconds per sample at 1024x429 resolution, and took just over five hours total for the final image. All shots are 1024spp, capped at a maximum of five bounces, and were run on an Nvidia RTX 2070.</p>
<div>
  <p><img src="https://www.render-blog.com/assets/ours-shotCam.png" alt="shotCam"></p><p>shotCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-beachCam.png" alt="beachCam"></p><p>beachCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-dunesACam.png" alt="dunesACam"></p><p>dunesACam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-palmsCam.png" alt="palmsCam"></p><p>palmsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-birdseyeCam.png" alt="birdseyeCam"></p><p>birdseyeCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-rootsCam.png" alt="rootsCam"></p><p>rootsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-grassCam.png" alt="grassCam"></p><p>grassCam</p>
</div>

<h2 id="optimization">Optimization</h2>
<p>The initial implementation of the renderer required 42.6 seconds per 1spp on the shotCam scene. A few optimizations combined to make significant reductions in rendering time, cutting each pass down to 18.2 seconds (a 57.3% reduction).</p>

<h4 id="cpugpu-concurrency">CPU/GPU concurrency</h4>
<p>Tracing shadow rays on the GPU in parallel with Ptex lookups on the CPU cut rendering time by 23.4%. It was disappointing to be forced to do texture lookups on the CPU, but the time savings make up for it.</p>

<h4 id="multiple-ptex-caches">Multiple Ptex caches</h4>
<p>Parallelizing the Ptex lookups and using multiple Ptex caches eliminated texture lookups as a bottleneck to the system; shadow ray casting time fully dominates the texture lookup. Empirically, spawning two threads per core (totaling 12 on an Intel i7-8700K) and sharing three Ptex caches comfortably reduced the texture lookup time beneath the shadow ray budget. This improved the time savings to a 33.9% reduction over the baseline.</p>

<h4 id="pinned-memory">Pinned memory</h4>
<p>The acceleration structure snapshots are all saved to pinned host memory. Switching from normal to pinned host memory increased the transfer throughput from 7.73 GB/s to 11.84 GB/s, cutting the baseline render time by 19.5%.</p>

<h2 id="future-steps">Future Steps</h2>
<p>Getting this scene running on my RTX 2070 card was a very fun and rewarding project, but there are still many improvements to be made:</p>
<ul>
  <li>Implementing the Disney BSDF</li>
  <li>Rendering subdivision surfaces along with displacement mapping</li>
  <li>More efficiently packing the acceleration structures, and optimizing ray tracing throughput</li>
  <li>Experimenting with how various research results hold up on production scenes (e.g., testing select path guiding techniques)</li>
</ul>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://github.com/chellmuth/gpu-motunui/">GPU-Motunui</a></li>
  <li><a href="https://technology.disneyanimation.com/islandscene/">Moana Island Scene</a></li>
  <li><a href="https://pharr.org/matt/blog/2018/07/16/moana-island-pbrt-all.html">Swallowing the elephant</a> - Matt Pharr</li>
  <li><a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">Disney Animation Data Sets</a> - Yining Karl Li</li>
  <li><a href="https://schuttejoe.github.io/post/disneypostmortem/">Rendering the Moana Island Scene Part 2: A production scene from a hobby renderer</a> - Joe Schutte</li>
  <li><a href="https://ingowald.blog/2020/01/09/digesting-the-elephant/">Digesting the elephant</a> - Ingo Wald</li>
  <li>Brent Burley and Dylan Lacewell. <a href="http://ptex.us/ptexpaper.html">Ptex: …</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.render-blog.com/2020/10/03/gpu-motunui/">https://www.render-blog.com/2020/10/03/gpu-motunui/</a></em></p>]]>
            </description>
            <link>https://www.render-blog.com/2020/10/03/gpu-motunui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833218</guid>
            <pubDate>Tue, 20 Oct 2020 01:45:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Junior Developer]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24833142">thread link</a>) | @mooreds
<br/>
October 19, 2020 | https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html | <a href="https://web.archive.org/web/*/https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          


        </header>
      

      <section itemprop="text">
        
        <p>So first off a personal update – last year, I got laid off the day I returned from maternity leave! Within a half hour of returning to my desk! Whew boy! It was a blessing in disguise in some ways, because 1) I’d been thinking for some time I could be more effective in a consulting role and 2) as part of my severance package, I got to attend a General Assembly coding bootcamp.</p>

<p>I ended up auditing the bootcamp because wow, it demands a ton of sacrifice with the end goal of getting a developer job. In contrast, I am happy to do a bit of scripting on the side, work with developers, and improve their experiences. Nonetheless, I worked through all the lectures, did a few homework assignments, and got a lot out of it. Not the least of which is that I validated my existing coding skills, gained deeper insight into the “junior developer” persona, and reaffirmed my conviction that tailoring your developer experience and docs to junior developers is a <strong>Good Thing</strong>.</p>

<p>There are a couple of big takeaways I’d like to share:</p>

<h3 id="everyone-is-a-junior-developer">Everyone is a junior developer</h3>

<p>Well, no, not actually … but every developer has to learn new concepts.  And yes, of course, as you gain experience as a developer, “totally new” concepts get rarer and rarer. Still, there’s a lot of learning:</p>

<p>Some developers must learn a breakneck pace (think of all the Javascript frameworks coming out all the time! Those front-end folks have to sprint just to stay in place). Others face big disruptions to their coding world only occasionally (your Enterprise Java programmer with a 20 year career in monolithic app development who now lives in a brave new world of microservices, CI/CD, devops, oh my!)</p>

<p>I felt I experienced this disruption myself as part of the coding bootcamp. Up till then, my background was in writing Python scripts, and in documenting big Java applications in a analytics microservices context. I knew about RedHat, Docker, Kubernetes, Spark, Lucene, Cassandra, etc.</p>

<p>Now, I was learning about a whole new world: the ecosystems, the mindset, the business of ….  JavaScript.  Like probably many people outside the JavaScript world, I was fooled by the “script” part of the name – especially since I’d only used JavaScript myself to write macros in an XML docs tool.  Now I realize it’s <a href="https://www.javaworld.com/article/2886368/java-vs-nodejs-an-epic-battle-for-developer-mindshare.html">epic battle</a> between Java and JavaScript. And while I haven’t fallen in love (Python, you still have my heart), I had lots of “oh, that’s neat!” moments. I also recognized that my learning curve was not dissimilar to that of experienced – but JavaScript-naïve – developers.</p>

<p>Which brings me to my main point:</p>

<h3 id="we-should-all-design-for-the-junior-developer">We should all design for the junior developer</h3>

<p>Creating experiences with a junior developer in mind forces you to discard your comfy assumption that everyone’s drunk your product Kool-aid. If you assume you’re writing for someone who’s technically savvy and can learn quickly, but who knows nothing about your world, you’re positioning yourself to vastly decrease your developer onboarding friction. And if you assume that your “junior developer” is super impatient because they have, like, 10 other things on the docket to learn about, then you’ll learn to answer up front the question: “why should I care? Why should I do this work?”</p>

<p>It’s a fine line to tread, assuming not too much about technical knowledge, but also not coming across as condescending or silly (like, at the level of “open a terminal by taking the following steps…”). Still, I think it’s actually quite achievable. For example, it’s quite low effort to provide high-level context for coding instructions. Even something as simple as “Clone this repository and open a terminal at the local directory location” is a direction that often gets left out in GitHub readmes…but it really shouldn’t be left out.  And it never hurts to link to frameworks’ getting started guides, even if you don’t want to provide the details yourself. At the very least, no one is likely to roll their eyes at it, and it helps your reader understand what level of granularity your instructions will provide.</p>

<p>When I look for inspiration, I think the <a href="https://reactjs.org/tutorial/tutorial.html">React newbie tutorials</a> do an outstanding job of introducing junior developers to React, helping them understand why they should care, and explicitly stating their audience. I also really love (who doesn’t) the <a href="https://dashboard.stripe.com/register">Stripe developer onboarding</a> experience.</p>

<p>Ultimately, I think I came away from the coding bootcamp more confident that I <em>am</em> a junior developer. And while I’d never make the classic UX mistake of thinking I am the user, still – my confusions, my pain points in learning about a product– these are things that other developers likely share.</p>

<h3 id="postscript-fun-with-javascript">Postscript: Fun with Javascript!</h3>

<p>I’ll end on another personal note. The coding bootcamp turned out to be quite serendipitous, because I took on contracting work that immediately benefited from my new knowledge. I’d just learned about Express, and now here I was, entering a pull request to change the authentication method for an Express server. I’d just learned about React, and now here I was, wading into a web UI to change some text. It’s always nice when you can put what you’ve learned to immediate use.</p>


        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833142</guid>
            <pubDate>Tue, 20 Oct 2020 01:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assorted Thoughts on Zig (and Rust)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24832844">thread link</a>) | @todsacerdoti
<br/>
October 19, 2020 | https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I've been using <a href="https://ziglang.org/">zig</a> for ~4 months worth of side projects, including a <a href="https://git.sr.ht/%7Ejamii/focus/tree">toy text editor</a> and an <a href="https://git.sr.ht/%7Ejamii/imp">interpreter for a relational language</a>. I've written ~10kloc.</p>
<p>That's not nearly enough time to form a coherent informed opinion. So instead here is an incoherent assortment of thoughts and experiences, in no particular order :)</p>
<p>This is not meant to be an introduction to zig - check out the excellent <a href="https://ziglang.org/documentation/master/">language docs</a> or the new <a href="https://ziglearn.org/">ziglearn.org</a> instead. I'll try to focus instead on things that are not immediately obvious from reading intro material.</p>
<p>The obvious point of comparison is to rust. For context, I've been using rust <a href="https://scattered-thoughts.net/writing/three-months-of-rust/">since 2015</a>. Mostly in research positions writing throwaway code, but also ~14 months working on <a href="https://materialize.io/">a commercial database</a> which is ~100kloc.</p>
<hr>
<p>Zig is dramatically simpler than rust. It took a few days before I felt proficient vs a month or more for rust.</p>
<p>Most of this difference is <strong>not</strong> related to lifetimes. Rust has patterns, traits, dyn, modules, declarative macros, procedural macros, derive, associated types, annotations, cfg, cargo features, turbofish, autoderefencing, deref coercion etc. I encountered most of these in the first week. Just understanding how they all work is a significant time investment, let alone learning when to use each and how they affect the available design space.</p>
<p>I still haven't internalized the full rule-set of rust enough to be able predict whether a design in my head will successfully compile. I don't remember the order in which methods are resolved during autoderefencing, or how module visibility works, or how the type system determines if one impl might <a href="https://github.com/Ixrec/rust-orphan-rules#what-are-the-orphan-rules">overlap another or be an orphan</a>. There are frequent moments where I know what I want the machine to do but struggle to encode it into traits and lifetimes.</p>
<p>Zig manages to provide many of the same features with a single mechanism - compile-time execution of regular zig code. This comes will all kinds of pros and cons, but one large and important pro is that I already know how to write regular code so it's easy for me to just write down the thing that I want to happen.</p>
<hr>
<p>One of the key differences between zig and rust is that when writing a generic function, rust will prove that the function is type-safe for every possible value of the generic parameters. Zig will prove that the function is type-safe only for each parameter that you actually call the function with.</p>
<p>On the one hand, this allows zig to make use of arbitrary compile-time logic where rust has to restrict itself to structured systems (traits etc) about which it can form general proofs. This in turn allows zig a great deal of expressive power and also massively simplifies the language.</p>
<p>On the other hand, we can't type-check zig libraries which contain generics. We can only type-check specific uses of those libraries.</p>
<pre><span>// This function is typesafe if there exist no odd perfect numbers
// https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers
fn foo(comptime n: comptime_int, i: usize) usize {
  const j = if (comptime is_odd_perfect_number(n)) "surprise!" else 1;
  return i + j;
}
</span></pre>
<p>This means zig also doesn't get the automatic, machine-checked documentation of type constraints that rust benefits from and may face more challenges providing IDE support.</p>
<p>This might harm the zig ecosystem by making it harder to compose various libraries. But <a href="https://julialang.org/">julia</a> has a similar model and in practice it has worked very well (<a href="https://youtu.be/dmWQtI3DFFo?t=1710">eg</a>, <a href="https://www.oxinabox.net/2020/02/09/whycompositionaljulia.html">eg</a>).</p>
<hr>
<p>Zig's comptime allows expressing <a href="https://scattered-thoughts.net/writing/open-multiple-dispatch-in-zig/">open multiple dispatch</a> as a library.</p>
<p>It should be relatively trivial to implement specialization the same way, which has been a <a href="https://github.com/rust-lang/rust/issues/31844">work in progress</a> in rust for years and is critical to many optimizations in julia's math libraries.</p>
<p>Julia chose dynamic typing because it's very difficult to encode the types of various mathematical operations into a general schema (eg fortress <a href="https://youtu.be/EZD3Scuv02g?t=3011">struggled with this</a>). Zig's approach of not requiring general schemas but still type-checking individual cases may be an interesting sweet spot.</p>
<hr>
<p>I used the <a href="https://cwe.mitre.org/data/definitions/1350.html">2020 CWE Top 25 Most Dangerous Software Weaknesses</a> to get a sense of the relative frequency of different causes of memory unsafety.</p>
<p>(I'm assuming that the zig programmer is using release-safe mode instead of the unfortunately named release-fast mode which disables all runtime safety checks.)</p>
<ul>
<li>Out-of-bounds Write (787/1350)</li>
<li>Out-of-bounds Read (125/1350)</li>
<li>Improper Restriction of Operations within the Bounds of a Memory Buffer (119/1350)</li>
</ul>
<p>Both languages primarily use bounds-checked slices and relegate pointer arithmetic to a separate type (<code>*T</code> in rust, <code>[*]T</code> in zig).</p>
<ul>
<li>NULL Pointer Dereference (476/1350)</li>
</ul>
<p>Both languages require explicit annotations for nulls (<code>Option&lt;T&gt;</code> in rust, <code>?T</code> in zig) and require code to either handle the null case or safely crash on null (<code>x.unwrap()</code> in rust, <code>x.?</code> in zig).</p>
<p>Dereferencing/casting a null c pointer is undefined behavior in both languages, but is checked at runtime in zig.</p>
<ul>
<li>Integer Overflow or Wraparound (190/1350)</li>
</ul>
<p>Rust catches overflow in debug and wraps in release. Zig catches overflow in debug/release-safe and leaves behavior undefined in release-fast.</p>
<p>Both languages allow explicitly asking for wraparound (<code>x.wrapping_add(1)</code> in rust, <code>x +% 1</code> in zig).</p>
<ul>
<li>Use After Free (416/1350)</li>
</ul>
<p>As long as all unsafe code obeys the aliasing and lifetime rules, rust protects completely against UAF.</p>
<p>Zig has little protection. The recently merged
<a href="https://github.com/ziglang/zig/blob/575fbd5e3592cff70cbfc5153884d919e6bed89f/lib/std/heap/general_purpose_allocator.zig">GeneralPurposeAllocator</a> avoids reusing memory regions (which prevents freed data from being overwritten) and reusing pages (which means that UAF will eventually result in a page fault). But this comes at the cost of fragmentation and lower performance and it also won't provide protection for child allocators using the GPA as a backing allocator.</p>
<hr>
<p>Both languages will insert implicit casts between primitive types and pointers whenever it is safe to do so, and require explicit casts otherwise. (With the odd exception that rust will not implicitly upcast numbers).</p>
<p>Both languages support generics which almost entirely avoids the need to cast void pointers.</p>
<hr>
<p>In rust the Send/Sync traits flag types which are safe to move/share across threads. In the absence of unsafe code it should be impossible to cause data races.</p>
<p>Zig has no comparable protection. It's possible to implement the same logic as Send/Sync in comptime zig, but without the ability to track ownership the rules would have to be much more restrictive.</p>
<hr>
<p>Rust prevents having multiple mutable references to the same memory region at the same time.</p>
<p>This means that eg iterator invalidation is prevented at compile time, because the borrow checker won't allow mutating a data-structure while an iterator is holding a reference to the data-structure. Similarly for resizing a data-structure while holding a reference to the old allocation. Both examples are easy sources of UAF in zig.</p>
<hr>
<p>Neither language is able to produce stack traces for stack overflows at the moment (<a href="https://github.com/rust-lang/rust/issues/51405">rust</a>, <a href="https://github.com/ziglang/zig/issues/1616">zig</a>)</p>
<p>In the future zig is <a href="https://github.com/ziglang/zig/issues/1006">intended</a> to statically check the maximum stack usage of your program and force recursive code to explicitly allocate space on the heap, so that stack overflows produce a recoverable OutOfMemory error rather than a crash.</p>
<p>This is not an academic problem - I've seen real-world crashes from recursive tree transformations in compilers (<a href="https://github.com/MaterializeInc/materialize/pull/3996">eg</a>) and it's often painful to write the same logic without recursion.</p>
<hr>
<p>Undefined behavior in rust is defined <a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">here</a>. It's worth noting that breaking the aliasing rules in unsafe rust can cause undefined behavior but these rules are not yet well-defined. So far this hasn't caused me any problems but it is a little unnerving.</p>
<p><a href="https://github.com/rust-lang/miri">Miri</a> is an interpreter for rusts Mid-level Intermediate Representation which will detect many (but not all) cases of undefined behavior in unsafe rust. It's far too slow to use for the whole materialize test suite but was useful for unit-testing an unsafe module.</p>
<p>Undefined behavior in zig is defined <a href="https://ziglang.org/documentation/master/#Undefined-Behavior">here</a>. This list is <a href="https://github.com/ziglang/zig/issues/1966">probably incomplete</a> given that the core language is still under development.</p>
<p>Zig <a href="https://github.com/ziglang/zig/issues/2301">aspires</a> to insert runtime checks for almost all undefined behavior when compiling in debug mode. So far all the easy cases are handled, which is already a dramatic improvement over c.</p>
<p>Zigs compile-time partial evaluation is done by an IR interpreter - it seems plausible that this could also be used as a miri-like tool in the future.</p>
<hr>
<p><code>@import</code> takes a path to a file and turns the whole file into a struct. So modules are just structs. And vice-versa - if you have a large struct declaration you can move it into a file to reduce the indentation.</p>
<p>Zig doesn't care at all where you put files on the filesystem.</p>
<p><code>@import</code> is part of the compile-time execution system so things like platform-specific modules and configurable features can be specified in regular code rather than rust's limited set of <code>#[cfg(...)]</code> macros.</p>
<hr>
<p>Array, struct, enum and union literals can be anonymous - <code>.{.Constant = 1.0}</code> is an anonymous union with it's own type, but can be implicitly cast to any union with a <code>Constant: f64</code> field because they share the same structure.</p>
<p>In rust my code is littered with <code>use Expr::*</code> and I'm careful to avoid name collisions between different enums that I might want to import in the same functions. In zig I just use anonymous literals everywhere and don't worry about it.</p>
<hr>
<p>Anonymous literals are also nice when using structs to simulate keyword arguments. No need to find and import the correct type:</p>
<pre><span>fn do_things(config: struct {
  max_things: usize = 1000, // default value
  flavor: Flavor,
}) void {
  ...
}

do_things(.{.flavor = .Strawberry});
</span></pre>
<hr>
<p>There is a pattern that shows up a lot in the materialize codebase:</p>
<pre><span>let</span><span> constant </span><span>= </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(constant) </span><span>=</span><span> expr { constant } </span><span>else </span><span>{ </span><span>panic!</span><span>() }</span><span>;
</span></pre>
<p>It's common enough that many types have methods like <code>expr.unwrap_constant()</code>.</p>
<p>In zig:</p>
<pre><span>const constant = expr.Constant;
</span></pre>
<p>A similar pattern is:</p>
<pre><span>if</span><span> some_condition {
    </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(</span><span>_</span><span>) </span><span>=</span><span> expr {
        </span><span>...
    </span><span>}
}
</span></pre>
<p>Again, many types get methods like <code>expr.is_constant()</code>.</p>
<pre><span>if</span><span> some_condition </span><span>&amp;&amp;</span><span> expr</span><span>.</span><span>is_constant</span><span>(…</span></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</a></em></p>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24832844</guid>
            <pubDate>Tue, 20 Oct 2020 00:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Arguing Constructively]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24831852">thread link</a>) | @liamrosen
<br/>
October 19, 2020 | http://liamrosen.com/arguments.html | <a href="https://web.archive.org/web/*/http://liamrosen.com/arguments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div><p><span>First published September 2020</span></p><p>

<em>Questions? Suggestions? E-mail me:</em>&nbsp;<img alt="" height="22" src="http://liamrosen.com/liamrosen.png" title="" width="164"></p></div>

<h2>CONTENTS</h2>

<p><a href="#intro">PART I: INTRO</a><br>
<a href="#mindset">PART II: MINDSET</a><br>
<a href="#prework">PART III: PRE-WORK</a><br>
<a href="#debatebreakdown">PART IV: BREAKING DOWN A DEBATE</a><br>
<a href="#strategies">PART V: STRATEGIES</a><br>
<a href="#tips">PART VI: TIPS</a><br>
<a href="#thanks">PART VII: CONCLUSION</a></p>

<h2><a id="intro" name="intro">INTRO</a></h2>

<p>The vast majority of people on earth argue in a <em>destructive </em>fashion. Debates, especially in online spaces, are viewed as a battle of the wits in which egos are put on display and there can be only one "winner".</p>

<p>Instead, we should be arguing in a <em>constructive </em>fashion: treating arguments as an opportunity to expand knowledge, finding points of disagreement, and collaborating towards a common truth.</p>

<p>I have a confession to make: I used to be a destructive arguer. When I was younger, my goal in any argument was not to learn something new, but rather to assure my superiority over what I felt to be the clear stupidity of the other side. I even used to save screenshots of debates I had on various forums and social media platforms, returning periodically to reminisce about past skirmishes in which I "<a href="https://knowyourmeme.com/memes/trigger-the-libs">owned the conservatives</a>".</p>

<p>Luckily, several years spent abroad gave me a different perspective. I realized that in the small-sided debates I used to engage in back home, my positions lacked the nuance and context of the greater world. For the first time, I began to do deep research on how to think — and argue — &nbsp;more clearly, drawing from concepts from philosophy, psychology, and behavioral economics.</p>

<p>This widened outlook led me to see arguments as a chance to build value, rather than destroy it. Instead of going through the mental anguish of battle, I now follow a collaborative approach to debate that I'd like to share in this guide in hopes that it will inspire others to argue more constructively.</p>

<p>Note that the content in this guide will focus on arguments about public issues, like politics and religion, as opposed to personal issues, like "you need to communicate more" or "you haven't done the dishes in weeks". Though there is overlap between the two, interpersonal arguments are much more complex and require more nuance than this guide can provide, plus there are already a ton of great resources out there that explore these topics more thoroughly.</p>

<h2><a id="mindset" name="mindset">MINDSET</a></h2>

<blockquote>
<p><strong><span><em>&nbsp;"An argument should be a collaboration between two people to find the truth."</em></span></strong></p>
</blockquote>

<p>If I had to distill this guide down to one sentence, it would be the above. Even if you forget the individual tenets and strategies this guide has to offer, as long as you are treating any given argument as a collaboration in search of truth, you can't go wrong.</p>

<p>Arguing more effectively requires detaching yourself from the idea of "winning" in the traditional sense. Instead, you should declare victory when you have argued in good faith and kept an open mind.</p>

<p>True collaboration requires that both parties open an investigation into why they may be wrong and consider changing their beliefs. Which brings us to the three core tenets of a constructive debate mindset:</p>

<h3>Acknowledge You May Be Wrong, and Be Willing to Change Your Mind <a href="#Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" id="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" name="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Was there ever a time in which you had a deeply-held belief about something, but slowly came to realize that you were wrong? Maybe you thought a past partner was "the one", or you were devoted to a religious faith. Or perhaps something as simple as believing in Santa Claus.</p>

<p>What's to say that couldn't happen with the other deeply-held beliefs, given enough evidence?</p>

<p>Go into every debate with the mindset that you may not know everything about the topic at hand, and in fact <em>may be wrong</em>.</p>

<p>If you successfully acknowledge that you may be wrong, it follows that you must then be willing to change your mind. Having the humility to admit that your mind has been changed is one of the most honorable positions in a good faith debate.</p>

<h3>Arguments Are Not Soldiers <a href="#Arguments Are Not Soldiers" id="Arguments Are Not Soldiers" name="Arguments Are Not Soldiers"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In a war, all soldiers take an oath to fight for their own side, no matter what amount they agree with its principles. <a href="https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer">Eliezer Yudkowsky once observed</a> that in political debates, arguments were treated like soldiers: "<em>Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back.</em>"</p>

<p>Because most people go into debate with a war-like mentality, they feel they must fly the flag for all points that <em>their</em><em> side</em> supports, regardless of how much they actually agree with them.</p>

<p>The red state gun-owner must be pro-religion, anti-abortion, anti-drugs, anti-tax, and skeptical of gender issues.</p>

<p>The blue state Subaru-owner must be anti-religion, pro-abortion, pro-drugs, pro-tax(ing-the-rich), and concerned about gender issues.</p>

<p>Most annoying is that given the societal expectations for this divide, being for or against one issue immediately assigns you to a "side" in the views of everyone involved. Breaking out of this Arguments as Soldiers mindset involves two steps:</p>

<p>1. Do not be afraid to agree with the arguments of the other side when they strike you as reasonable, and critique the arguments of your own side when they strike you as unreasonable (better yet, try not to have a side).</p>

<p>2. On the flip side, avoid stereotyping your debate partner based on one opinion. If you are engaging with someone in debate for the first time, assume that they agree with you on every other position than the one they are defending, until proven otherwise.</p>

<h3>There's Always Someone Who Thinks the Jedi Are Evil <a href="#There's Always Someone Who Thinks the Jedi Are Evil" id="There's Always Someone Who Thinks the Jedi Are Evil" name="There's Always Someone Who Thinks the Jedi Are Evil"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p><em>Brace yourself, Star Wars references incoming:</em></p>

<p>In a given debate, almost everyone thinks they are a member of the Jedi order, fighting for all that is virtuous and good in the universe. Yet for every Jedi, there's a Sith out there <a href="http://www.youtube.com/watch?v=llLKar19XhA">who thinks that the Jedi are evil</a> and wrong and that <em>they</em> are actually the ones fighting for virtue and good. Remember that this person might even be <em>you</em>.</p>

<p>Of course, you are not a full agent of good, and your debate partner is not an agent of evil, or vice versa. You are simply citizens of the galaxy who happen to be operating with different sets of information. Look at the situation from a different perspective: if you were raised with Sith beliefs from childhood, don't you think you might believe the exact same things a Sith would?</p>

<p>In debate, your goal should not be to <a href="https://www.youtube.com/watch?v=rMNKwZTv1d0">strike down the side of evil with all your hatred</a>, but rather work together with them to uncover the true facts about the universe, and in doing so perhaps change both your perspectives.</p>

<h2><a id="mindset" name="prework">PRE-WORK</a></h2>

<p>It would be great if choosing to pursue the path of arguing constructively was just a matter of changing your mindset overnight, but as Carl Sagan once said: <a href="https://youtu.be/BkHCO8f2TWs?t=9">"If you wish to bake an apple pie from scratch, you must first invent the universe."</a></p>

<p>In the same vein, if you wish to improve the constructiveness of the debates you engage in, you must first spend time re-inventing your entire mind.</p>

<p>This is because our mind is constantly working against us, plagued by ancient errors from the times in which we lived in caves and hunted woolly mammoths. These errors work against us in the form of cognitive biases and logical fallacies, which hinder our ability to clearly see reality and engage in sound debate.</p>

<h3>Recognize and Avoid Cognitive Biases <a href="#Recognize and Avoid Cognitive Biases" id="Recognize and Avoid Cognitive Biases" name="Recognize and Avoid Cognitive Biases"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Cognitive biases are limits and mistakes in human judgement that prevent someone from acting rationally. They are present in every aspect of human life, and in tense situations like arguments, they tend to appear more often as emotions are heightened and the brain gets overloaded.</p>

<p>Common examples that relate to debates are <em>confirmation bias</em>, or the tendency of humans to seek out information that confirms existing beliefs, and <em>ingroup bias</em>, or the tendency to agree more strongly with people that appear to be part of our "tribe", but there are over 100 identified biases, and it's worth reading through the Wikipedia article on the <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">most common cognitive biases</a> so you can recognize when they might be clouding your thinking.</p>

<h3>Recognize and Avoid Logical Fallacies <a href="#Recognize and Avoid Logical Fallacies" id="Recognize and Avoid Logical Fallacies" name="Recognize and Avoid Logical Fallacies"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In part caused by cognitive biases, logical fallacies are errors in argument that give off an air of decisiveness, despite making points that don't hold up to logical scrutiny. While these are often used unintentionally, due to bias, carelessness, or ignorance, unfortunately, they can also be wielded intentionally by a shrewd debate partner.</p>

<p>Common examples in debate include the <em>false dilemma fallacy</em>: "you're either with us or against us", and the <em>slippery slope fallacy</em>: "if we allow the gays to marry, what's next: plants?" Just like cognitive biases, there are a large number of identified logical fallacies, and it's worth it to review the <a href="https://en.wikipedia.org/wiki/List_of_fallacies">entire list</a>, so you can spot them in your own arguments and in those of others.</p>

<h2><a id="debatebreakdown" name="debatebreakdown">BREAKING DOWN A DEBATE</a></h2>

<p>To the untrained eye, a debate might look like two or more parties trading argumentative points back and forth. But interestingly, these points can almost perfectly be classified into a few categories. Understanding these categories, and why some types of arguments are better than others, is crucial for learning how we and those whom we engage with in debate might shape their points. In a brilliant post called <em><a href="https://slatestarcodex.com/2018/05/08/varieties-of-argumentative-experience/">Varieties of Argumentative Experience</a></em>, Scott Alexander does just this, illuminating and labeling practically every part of a debate. The post itself is basically required reading, but is long-ish<em>,</em> so I will summarize here.</p>

<p>Think of a debate as a pyramid: <a href="#debatepyramid" id="debatepyramid" name="debatepyramid"><img alt="" src="http://liamrosen.com/anchor.png"></a></p>

<p><img alt="" height="548" src="http://liamrosen.com/Pyramid%20of%20Argumentative%20Experience.svg" width="978"></p>

<p>In general, the lower on the pyramid you are, the worse debate you're having. The goal should be to start as high as possible and continue to work your way towards the top.</p>

<p>Debates on twitter and other forms of social media are almost guaranteed to never rise above the lower dotted line, as these platform don't allow for more nuanced debate. Everything above the higher dotted line is our gold standard: two intelligent, charitable, and versed debaters can successfully maintain a debate at this level until some form of resolution.</p>

<p>The blue side represents the discussion …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://liamrosen.com/arguments.html">http://liamrosen.com/arguments.html</a></em></p>]]>
            </description>
            <link>http://liamrosen.com/arguments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831852</guid>
            <pubDate>Mon, 19 Oct 2020 22:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to better calculate churn rates]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24831637">thread link</a>) | @cmogni1
<br/>
October 19, 2020 | https://catchjs.com/Blog/Churn | <a href="https://web.archive.org/web/*/https://catchjs.com/Blog/Churn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
<ol>
    <li><a href="https://catchjs.com/Docs">Blog</a></li>
    <li>You're all calculating churn rates wrong</li>
</ol>

        

        
        <p>
            Many smart people will tell you to obsess over your churn rate.
        </p>
        <p>
            <img src="https://catchjs.com/Blog//images/blog/churn/churn_rate_formula2.png" alt="churn rate=(customers lost in month)/(customers at start of month)">
        </p>
        <p>
            According to Andreessen Horowitz, this number is <a href="https://a16z.com/2015/08/21/16-metrics/">one of the top 16 metrics</a>
            to measure a SaaS startup by. Well, sorry Andreessen, and sorry Horowitz, but this just isn't right.
        </p><p>
            It's counterintuitive, but it's a statistical fact: This number actually <b>tells you nothing useful about churn</b>,
            but really relates to the age of the subscriptions you have.
            It will in most cases go down on it's own, and, absurdly, the only way to keep it from going down is to have very
            high growth. So the number will literally <b>only look <i>bad</i> if your business is doing extremely <i>well</i></b>,
            and optimizing for it will be directly counter-productive.
            The error here is a simple statistical mistake that is easy to make, and luckily also easy to understand and avoid.
        </p><p>
            If you run a subscription based SaaS business, you're likely very concerned with how long you can keep your
            customers. We're a JavaScript exception tracking service, and the health of this business is fully determined by how many
            customers we bring in, and how long we can keep them. On the surface, <i>churn rate</i> may seem like a natural proxy for changes
            in <i>customer lifetimes</i>. Let's dig into why that is not true.
        </p>
        <h2>
            The false assumption
        </h2>
        <p>
            Computing a churn rate <b>assumes that a customer is equally likely to leave at any time</b>, no matter how long they've
            been subscribed to you. This is almost certainly not true. In fact, as we will see, having a constant churn probability over time
            essentially implies that you'll <i>never have long term customers</i>.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/expon.png" alt="Hazard function (churn) and the implied survival function (from an Exponential distribution)">
            <figcaption>If a user has a constant churn probability over time, this implies that customer lifetimes come from an Exponential distribution.</figcaption>
        </figure>
        <p>
            If you have a constant churn of <code>c</code> per month, the probability that a customer stays subscribed for <code>n</code> months is <code>(1-c)^n</code>. This implies that customer lifetimes come from the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>. If customers can quit the subscription at any time, we have continuous time and should use the continuous time analogue, the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution</a>.
        </p>
        <h2>
            What your churn is actually like, with help from K. S. Lomax
        </h2>
        <p>
            The problem is, your customer is not equally likely to cancel their subscription at any time. Most likely, you have a situation where the drop-off in customers is higher in the first few days than it is later. This is even more so if you have a free trial period for your product.
        </p><p>
            If the churn probability gets lower the longer the customer has been subscribed, you could model that as <code>c/(t+1)</code>, where
            <code>t</code> is the timestep (e.g. number of days the customer has been subscribed), and <code>c</code> is some constant.
            In this case, this implies that customer lifetimes comes from a <a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution</a>.
            This is equivalent to a Pareto distribution shifted to start at 0.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/lomax.png" alt="Hazard function (churn) and the implied survival function (from a Lomax distribution)">
            <figcaption>The Lomax distribution can express churn probabilities that get lower with time.</figcaption>
        </figure>
        <h2>
            What your churn is actually like, with help from Waloddi Weibull
        </h2>
        <p>
            If you suspect that churn probability per day may <i>increase</i> the longer a user has been subscribed, the Lomax distribution won't
            work for you. Instead you could enlist the help of Swedish statistician Waloddi Weibull.
            The <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> can express both decreasing,
            flat, and increasing probabilities of a customer quitting. This makes it a popular choice for modeling customer lifetimes.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/weibull.png" alt="Hazard function (churn) and the implied survival function (from two Weibull distributions)">
            <figcaption>The Weibull distribution can express both growing and shrinking churn probabilities.</figcaption>
        </figure>

        <h2>
            Optimizing for a falsehood will lead you astray
        </h2>
        <p>
            Now let's see why properly modeling this is important.
        </p><p>
            Let's measure churn the wrong way, and see where it takes us.
            Let's say customer lifetimes come from a Lomax distribution. Let's also say you have a business that is in terrible shape, where
            the number of new sign ups per day is falling by one per day. How will this look on the churn rate? We can simulate it and find out.
        </p>
        <p>
            Keep in mind, in each of the examples below we simulate lifetimes from the same customer lifetime distribution,
            and this distribution <b>does not change</b> over time.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/shrinking_business.png" alt="Shrinking business, churn appears to fall">
            <figcaption>With a shrinking business, churn appears to improve because subscriptions are getting fewer and older.</figcaption>
        </figure>
        <p>
            This is clearly a dying business, yet the churn rate graph is looking great! <b>
                The churn rate per day is falling steadily,
                even if we know that there is no change in customer lifetimes in our model.
            </b>
        </p><p>
            So what's going on? This sharp fall in churn rate is a consequence of the fact that we're not getting new customers.
            Because we're not growing, a bigger share of our customers have been around for a long time, which
            means they're less likely to churn, which means our daily churn graph goes down more than it would otherwise.
            This change on the population level happens despite there being no change in underlying individual customer lifetimes.
        </p><p>
            Let's change this into a scenario where your business is experiencing insane growth. We'll keep the customer lifetimes exactly the same,
            but change it so that the number of new sign ups per day is growing superlinearly.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/growing_business.png" alt="Growing business, churn appears to be flat">
            <figcaption>With a growing business, churn rate appears to not change, only because most subscriptions are new.</figcaption>
        </figure>
        <p>
            Even if the customer lifetimes are unchanged from before, the churn rate graph here is flat. An investor would frown and say
            we're doing nothing to improve how well we retain our customers. In reality, the only reason the graph looks "bad" has nothing to
            do with churn, it is because we're doing insanely well at getting new sign ups.
        </p><p>
            <b>
                If you are steering yourself and your team on the basis of this metric, you're rewarding yourself for stifling growth
                and punishing yourself for growing.
            </b> Obviously, this is 100% counterproductive.
        </p>
        <h2>
            How the h*** do we measure churn then?
        </h2>
        <p>
            As you might have guessed from the previous paragraphs, we should model the <i>distribution of customer lifetimes</i>,
            and we should do it in a <i>statistically sound way</i>. Lomax and Weibull distributions are good choices of model.
        </p><p>
            The part where this gets tricky is that we'll have two types of data: The customers that have quit, and the customers
            that are still subscribed. It's only our ex-customers that give us a total lifetime to work with. For our still-subscribed
            customers, we only know that their subscription has lasted up until now, and we don't know how much longer it will last
            into the future. In statistical lingo, we have what is called <i>right-censored data</i>.
        </p><p>
            Luckily there's a way to use all our data, even from our still-subscribed customers.
        </p>


        <h2>
            Weibull or Lomax?
        </h2>
        <p>
            Choosing between Weibull or Lomax (or any other distribution) has no simple answer. Weibull is more flexible
            in that it can express growing, shrinking and flat churn probabilities. However, this expressive power will
            not help you if your data is fundamentally Lomax-like. First and foremost, base your choice
            on your knowledge of the business that you're in. If you have any prior knowledge about how churn probabilities
            will develop, base your choice of distribution on that. There are also various
            <a href="https://www.weibull.com/hotwire/issue71/relbasics71.htm">goodness of fit</a> tests you could use to
            inform this decision. The truth is, any choice of distribution will be wrong to some degree, so you need to make
            a judgment call as to what fits your situation the best, based both on both your data and your prior knowledge.
            For the purposes of the rest of this post, we'll just fit both distributions and disregard the question of
            which suits us the best.
        </p>

        <h2>
            Let's do some proper statistics
        </h2>
        <p>
            The probability distributions we'll model are defined by their parameters.
            We want to find the parameters that fit the data best. To start, we want to make a guess at these parameters,
            and have a way to tell how good our guess was. Luckily, we have a statistically sound way of knowing how good a guess
            is given the data we have. Extra luckily, this is also true when we have censored data.
            This function that tells us how likely our parameters are given the data we have is called the Likelihood function.
            We get it by looking up the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>
            value for the uncensored data points and the <a href="https://en.wikipedia.org/wiki/Survival_function">survival function</a> value
            for each of the censored data points, and multiplying all these values together.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/likelihood.png" alt="Likelihood formula with right-censored data">
            <figcaption>
                Likelihood function L for right-censored data. <code>f(.)</code> is the probability distribution function, <code>S(.)</code> is the survival function,
                <code>D</code> is the set of uncensored lifetimes and <code>R</code> …</figcaption></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catchjs.com/Blog/Churn">https://catchjs.com/Blog/Churn</a></em></p>]]>
            </description>
            <link>https://catchjs.com/Blog/Churn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831637</guid>
            <pubDate>Mon, 19 Oct 2020 22:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a computer in Conway's game of life]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24831268">thread link</a>) | @ctlachance
<br/>
October 19, 2020 | https://www.nicolasloizeau.com/gol-computer | <a href="https://web.archive.org/web/*/https://www.nicolasloizeau.com/gol-computer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.p_DQq05oqSU0NY"></section><section id="h.p_iiV-AQqiVP7B"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_SXN-ydRPVP6s"><div><div><p id="h.p_iRskbwwxVP67">The purpose of this page is to describe the functioning of a computer built in Conwayâ€™s game of life. An in-detail explanation of all the mechanisms and all the components of the computer would be too long to describe here. Only the fundamental principles and main components are explained here. I think this is enough to permit anyone to recreate a similar computer or reuse it's ideas and components for any other project.</p><p id="h.p_44-lKvosVSR_">The idea here is to illustrate the Turing completeness of game of life with a more impressive example, closer to our computers and easier to program than a basic Turing machine.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p_aGh9TBjrsjnj"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_QecS9arclkic"><div><div><div jscontroller="VYKRW" jsaction="rcuQ6b:rcuQ6b;"><div><iframe jsname="L5Fo6c" sandbox="allow-scripts allow-popups allow-forms allow-same-origin allow-popups-to-escape-sandbox allow-downloads" frameborder="0" aria-label="YouTube Video, Game of life: programmable computer" src="https://www.youtube.com/embed/8unMqSp0bFY" allowfullscreen=""></iframe></div></div></div></div></div></div></div></div></div></div></div></section><section id="h.p_MUkfONu1Vy1J"></section><section id="h.p_Lqr87QKQZ7Ph"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_99zwWdVGZ7PS"><div><div><h2 id="h.p_dZFApvvPZ7Pc" tabindex="-1"></h2><p id="h.p_lvY7r7XEZ7br">The fact that two orthogonal glider beams can annihilate each other or form an eater if they intersect with the good phase shift is used to make basic logic gates.</p><p id="h.p_9XtX79ckZ7bx">This allows us to modify a glider beam with another.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p_odLc-Ig6aUwc"></section><section id="h.p_Xj-uRksRarVA"></section><section id="h.p_xIogGmHYa9ph"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_HG45lQcXbAP1"><div><div><p><img src="https://lh3.googleusercontent.com/JFxydILLeVhkpykUpiysZNuqphQ3TqvioggCQyzdHDLikp0mtcbhWN3-tusIBWyi0KNLrpwG=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_hrirjNxUbBgT"><div><div><p><img src="https://lh6.googleusercontent.com/gbAznAPpQlYYa40HwCe3L7QFqFN8kg76L6wyktO4k4IjqVzu2NlS7HED8Rq_lMSOQP-oSn5Qew=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_2tgYrbMutYVl"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_k26e1YUKtYVe"><div><div><h2 id="h.p_BF-X_8nVtYVj" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>3 Logic gates assembly, adaptators</p></div></h2><p id="h.p__rI_inRGtkdp">The assembly of logic gates is possible only if the glider beams are in phase and if the gap between the beams is right. While making the components out of multiple logic gates, I used the following conventions: </p><p id="h.p_SSA7xz3atkhv">- use a 30*30 grid </p><p id="h.p_W3Uxqe5otkhw">- each glider beam has to match the corners of the grid</p><p id="h.p_xymga8iXtkhw">- main glider beams come from the high left corner.</p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_sRRZp-fXsY3v"><div><div><p><img src="https://lh5.googleusercontent.com/g2L0EnyywPdiuzGTBU-p12r8CD0LEdE3LX-IXDiOtyRsB07051arnV_1BymDHF5sYCdgCL3nmbnCumJDVe1j8TadKk-0pYVL0nleKNeqDXlVIcKM7Q=w1280" role="img"></p></div></div></div></div><div><div id="h.p_w97cwfq5s_Mt"><div><p id="h.p_Q5ji4R90s_Mx">According to these rules, these glider beams are well in phase.</p></div></div></div></div></div></div></div></div></section><section id="h.p_p-FkrspwsSxh"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_WGORwOtzsSxU"><div><p id="h.p_YekmpiZjsSxe">A series of 3 reflectors called an adaptator is used to shift the phase or the position of a beam. The folder tools contains two Python scripts to make such adaptators. The scripts <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Ftools%2Fdecamaker.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEiQAlLT1GgHvNvqWM3gTz5xQMI_g" target="_blank">decamaker.py</a> is used to translate horizontally a well phased beam by a multiple of 1 pixel. The script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Ftools%2Fdelaymaker.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNE9PUiQEu2epUYnDRoPrX0fgWPaDA" target="_blank">delamaker.py</a> makes an adaptator of 3 dimensions D1,D2,D3 :</p></div></div></div></div></div></div></div></div></section><section id="h.p_1sZECb-FsY3o"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_lt4ZbqDrs1p4"><div><div><p><img src="https://lh5.googleusercontent.com/Nin2ZYBF4eAK84_f2Xpfu_Tw5r0rGqWGkfosGr5cJ0VJef21q4xLLA4zCD7P7sgLZ_UpdG7hDa5cFNetUmJkmuQuQYBsdFBLjsZ63brre_n2WQADDFc=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_3D7rgWqxsfmY"><div><div><p><img src="https://lh4.googleusercontent.com/ph87MAmGwmo3-ZpIM7HhFvlM0SjMq1bOk1jeZcvjrD9LG1B8bGYoHP8gXlL2fEDRJ0FKqdGOoQ=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_ameLef-vtZEs"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_lQMVu9K3tZEi"><div><p id="h.p_Tx2PYsK-tZEp">Adaptators are already included at the inputs and outputs of the logic gates from the folder Â« <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Ftree%2Fmaster%2Flogic%2520gates&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHnlKCciw5DxzWOHqg3_ld3X4_aAQ" target="_blank">logic gates</a> Â». All their inputs and outputs are well in phase and it is just required to use the decamaker script to assemble them. I made the main components using these logic gates.</p></div></div></div></div></div></div></div></div></section><section id="h.p_TkFrs9eQb-d1"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_8VsxyFB8b-dY"><div><div><h2 id="h.p_qYGHe3p4b-ds" tabindex="-1"></h2><p id="h.p_XCROTP1VcUCp">The implementation of the logic gates allows the making of any asynchronous logic circuit</p><p id="h.p_gpghndKXcZqN"><em>A,B : inputs</em></p><p id="h.p_BhzuWXcvcZt7"><em>Cin : carry input</em></p><p id="h.p_C9gmXOO9cZt9"><em>Cout : carry output</em></p><p id="h.p_tNXfsgiHcZt-"><em>S : output</em></p><p id="h.p_K2Niv_17cZt_">A ripple-carry-adder can be made by juxtaposing n full adders.</p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_CXtRrYuVcEff"><div><div><p><img src="https://lh3.googleusercontent.com/tKo3JPaQF31lrDWYmieJQBrpd7KFn_dnuKIeJ392-b3ZFPs4efwb9jy3BSx4J_qSbDIddXveTla20-eTNWqVt8gKuDAkIq1oJqp4NPFQA7OpUz244X0=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_0PNL2Bjcco5_"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_AkNt6t6cco51"><div><div><h2 id="h.p_UbbR_NuRco57" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>5 Arithmetic and logic unit (ALU)</p></div></h2><p id="h.p_Zx_DYURQcs0I">The ALU is composed of some logic functions and a unit which is composed of AND gates that select the result. The inputs are 8 bit each, the instruction is made of 8 independent bits. The instruction flat returns 11111111 if Bâ‰&nbsp;00000000, the instruction sign selects the most significant bit of B. The most significant bit is at the high left corner. The arrow from the select module to the adder represents the increment instruction.</p><p id="h.p_72CXS9I7fG-P">Instruction codes:</p><div><pre id="h.p_APcDULGQetQk"><code>+          00000001</code></pre><pre id="h.p_15CYbaBQetU2"><code>or         00000010</code></pre><pre id="h.p_WAQj6cNVetU6"><code>and        00000100</code></pre><pre id="h.p_venItL9vetU9"><code>xor        00001000</code></pre><pre id="h.p_7164prNZetVA"><code>not        00010000</code></pre><pre id="h.p_FMvwK-hnetVD"><code>flat       00100000</code></pre><pre id="h.p_8DIPmNCeetVF"><code>sign       01000000</code></pre><pre id="h.p_ooyX0MlGe8Yb"><code>increment  10000000</code></pre></div></div></div></div></div><div><div id="h.p_tFHU6M1BeOVn"><div><div><p id="h.p_KI124814eOVv"><em>A, B : inputs</em></p><p id="h.p_-Zlpu12dih6B"><em>I : instruction</em></p><p id="h.p_bcNnihNfiiLt"><em>S : output</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_EuNde33Ndr2H"><div><div><p><img src="https://lh6.googleusercontent.com/g-otSAcs-te5sDq6liB3sVazggHv67NiurLN-Gd3iOCfTuch77fJ5ZbaU8RoKIn_WrdLaz-TdbYEAGZuDxde17NFG_WOu2GAufoE9FLaRZeyZE3h5lQ=w1280" role="img"></p></div></div></div></div><div><div id="h.p_5pKa8Ic5eENS"><div><div><p><img src="https://lh4.googleusercontent.com/fbkdpCW1hGV9Phs3W15HJA34et0TS21R2sY56dZ_B_ERYlYsCz6W9_UpyLsuJLMX7CSE7bYa5Tn_2nUL3O2LdI6IWHgk621dO3IJDjslazmq5SODiw=w1280" role="img" alt="A, BÂ&nbsp;: inputs IÂ&nbsp;: instruction SÂ&nbsp;: output"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_jHes96Wtc8fQ"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_BKo62TzUc8fH"><div><div><h2 id="h.p_vYkEPbjvc8fO" tabindex="-1"></h2><h3 id="h.p_RJbO663DhlFw" tabindex="-1"></h3><p id="h.p_J5cxzD94glif">A memory unit is composed of an RS latch and logic gates AND to manage reading and writing tasks. The memory is an assembly of 64 memory units in 8 lines and 8 columns thus forming an 8x8 bytes memory.</p></div></div></div></div><div><div id="h.p_eCvk1p35gonU"><div><div><p id="h.p_P3fNdtgKgonX"><em>W : write 1 if set=1 0 if reset=1</em></p><p id="h.p_dfj4HZr1gptO"><em>R1 : read the state of the memory to the S1 output </em></p><p id="h.p_EMY4WO82gptO"><em>R1 : read the state of the memory to the S2 output</em> </p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_GQ_D4n5jhHfp"><div><div><p><img src="https://lh3.googleusercontent.com/Jr45jIX4g4t9oxpNDuATSK278tSkoPH2-FMQpyYc3LsVA6aolDn5gjsWoR5zXkW_f9kLwgpCwxJ33ba0m5bsdq2aNHw699vkD_zFHf8INtCxlJJFYQWH=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_EaOInrvcfyFS"><div><div><p><img src="https://lh6.googleusercontent.com/4rX9LliRJDwnzpUbDWDdcncDHX16YY2Jo9SpEWYAt67FoiAKFCzWZ5DGOtNSHqT43FerLnM0JxjBOULRPy7gsrURltKhoPAv9woDdQNKY_cXkk8WIA4=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_KUUiaKkXhrud"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_Fxjpj-lqhruZ"><div><div><h3 id="h.p_O689rlGChrub" tabindex="-1"></h3><p id="h.p_9JPre3onht49">The 3 modules at the left of the memory are decoders from 3 bit to 8 for decoding addresses. This memory allows us to read data from two addresses a1 and a2 at the same time. The output is made of 16 bit alternated between S1 and S2.</p><p id="h.p_LCsn7eBkh9rP"><em>A : data to write, 1 byte </em></p><p id="h.p_fHO0POG9h-BA"><em>a0 : address for writing, 3 bits</em></p><p id="h.p_ltfqpzgNh-BB"><em>a1 : address for reading, 3 bits</em></p><p id="h.p_WjJwr5Muh-BB"><em>a2 : address for reading, 3 bits</em></p><p id="h.p_nH4jURGYh-BC"><em>S : output, 2 bytes </em></p><p id="h.p_3jfHFLL-h-BC"><em>W : writes A to address a0 if W=1</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_OJ8hOGCiguUw"><div><div><p><img src="https://lh4.googleusercontent.com/FWVk_Q2EPlnCBmelo-x7ngHHY-dUL5M4XqdtZGcMpFzCH_mpIRWa7moAfzy32Y2r5kReiyG2BejH9k1Tl69V3pXqwlJIIZ9J1U1NoF4QZLHxkMHbU5s=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_xrHTkqo4dAQk"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_Z3g-lThLdAQd"><div><div><h2 id="h.p_E1XIJpRSdAQi" tabindex="-1"></h2><p id="h.p_Gfx0enzfi2bC">The program is of a static memory form. The big rectangular module is a decoder from 5 bit to 32 which is used to select a line of the program given the input address. </p><p id="h.p_lVjX0pHCi2fB">Each line is made of 21 bits distributed as follow from the high right corner:</p><p id="h.p_5YBVlSYLi2fC">- 8 bits for data</p><p id="h.p_kqeXBpHei2fC">- 3 bits for reading address</p><p id="h.p_gcYz7S9ui2fD">- 3 bits for reading address</p><p id="h.p_iI6szhGYi2fD">- 3 bits for writing address</p><p id="h.p_RbF8D0CFi2fD">The script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Fassembly.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEvSddxq7Y0FTnkWZJkBLqGTDnspw" target="_blank">assembly.py</a> contains more information on computer programming.</p><p id="h.p_idxG0XgBi2fE"><em>A : address of the line to be read: 5 bits</em></p><p id="h.p_OOX77ZdYjPJ_"><em>S : output: 21 bits</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_zozhh_nnjE17"><div><div><p><img src="https://lh6.googleusercontent.com/qmURREgmITiZN1uTzDSxRhCzP5Ne8B8JUlfUdINIuz6IcoiwopZFZ5xoREi2YOhyfnWV1M7Iok_9R8rHhisMp7PHnD6_YjQQG4KcwzuhCd8iOaIyx5g=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p__hCJiXtvjdpP"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_hqpO9gy2jdpM"><div><div><h2 id="h.p_797YSJ2BjdpO" tabindex="-1"></h2><p id="h.p_WmzCYEQBlNzw">Diagram of the computer architecture. Only the main information channels are represented. The module â€œlineâ€� is a 5 bit memory for writing the address of the line which is running (PC). The module â€œcontrolâ€� is principally a decoder which takes as input an instruction code of 4 bits, decodes it into 16 independent bits and communicates with all the other modules to execute the instruction.</p><p id="h.p_XcW1bSfulN46">Elements which are not represented in this diagram:</p><p id="h.p_N3qxDVHFlN46">- the control channels from the control module to other modules</p><p id="h.p_ZhFjawdelN47">- the clock</p><p id="h.p_39_5GK1ilN47">- the control channels from the clock to the other modules</p><p id="h.p_wEaE1tRJlN48"><em>Color code:</em></p><p id="h.p_6wdWXJ6slN48"><em>Green: 8bit data bus </em></p><p id="h.p_DYEi5V_dlN49"><em>Red: 3bits address</em></p><p id="h.p_dN0UhRcmlN49"><em>Yellow: 4bits instruction</em></p><p id="h.p_nF0hM-LnlN4-"><em>Pink: 5bits address</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_M3Aa7YeslFnO"><div><div><p><img src="https://lh6.googleusercontent.com/dGVgXdBgH4xmRPFaqIjNeTQITdeovLZegs7BJ3ON6OZxYEqnV5n9ctDGAOFQH6N9_LWh9Q0TRdvgtX9H4EQTFjZz51L-VGM0PT7gY9jIDlVG4PBaE5yI=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_iatMj5Mom9_B"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_XJCPKyEwoEID"><div><div><h2 id="h.p_0xltGO10oEIG" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>9 Detail of a clock cycle</p></div></h2><p id="h.p_akxX-ZM1oGgX">The clock is constituted of 4 loops, formed by glider reflectors in which glider beams rotate. In each loop, a glider duplicator is placed on the glider beam path. This makes it possible to extract the signal from the clock. The 4 loops give rhythm to: the execution of an instruction, the writing in the memory, the incrementation of PC, the writing of PC in the memory.</p><p id="h.p_t1CmuX1joGin">PC is stored in memory at address 000, however, it is needed to read it all along the execution of an instruction. It is therefore copied into the Line module on each cycle. The following table summarizes a clock cycle.</p></div></div></div></div><div><div id="h.p_JVam50uBm9-3"><div><div><div><pre id="h.p_l5Bvpg0xm9--"><code><strong>Generation  Clock loop  Signal edge  Action</strong></code></pre><pre id="h.p__2oUC2gPn53Z"><br></pre><pre id="h.p_6ZQ7UNDLm-Mp"><code>0           0           Rising       Reading of an instruction, </code></pre><pre id="h.p_Sv1HYSQtnsKA"><code>                                     execution of it by the ALU without writing on the memory</code></pre><pre id="h.p_YK3_r7RHm-Mr"><code>590 000     1           Rising       Writing of the ALUâ€™s output on the memory</code></pre><pre id="h.p_tfhVMyQYm-Mu"><code>650 000     1           Falling      End of the writing on the memory</code></pre><pre id="h.p_ygXdUEOXm-Mx"><code>860 000     0           Falling      End of the reading of the instruction</code></pre><pre id="h.p_RlwORZMom-My"><code>1 100 000   2           Rising       Reading PC from address 000 to the ALU for incrementation </code></pre><pre id="h.p_VjI3TS5Hny6C"><code>                                     Copy of PC from 000 to the Line module</code></pre><pre id="h.p_SEdE98RKm-M1"><code>1 440 000   3           Rising       Writing of the ALUâ€™s output (PC+1) to the address 000</code></pre><pre id="h.p_omeA5Huam-M3"><code>1 480 000   3           Falling      End of the writing of PC+1 to the address 000</code></pre><pre id="h.p_vAI6RZ7om-M5"><code>1 600 000   2           Falling      End of reading from the address 000 and end of copying from 000 to the Line module </code></pre><pre id="h.p_D181OqNhn33k"><code>                                     At this time, PC+1 is written at 000 and on the module Line</code></pre></div></div></div></div></div><div><div id="h.p_6uVtrglpoOly"><div><div><p id="h.p_H3AbL1XZoOl0">The column â€œclock loopâ€� gives he position of the clock loop which generates the signal. The index rises from the high left corner. Generation gives the time at which the signal leaves the clock loop. Each cycle is made of two parts: the execution of the instruction (loops 0 and 1) ant the incrementation of PC (loops 2 and 3). Each cycle has a period of 2,003,880 generations.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p__7h5dMoWoWOG"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_E5Cu7xouoWOE"><div><div><h2 id="h.p_eiDdjwjWoWOG" tabindex="-1"></h2><p id="h.p_ZfBRIcwDoZn9">The Golly Python script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Fassembly.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEvSddxq7Y0FTnkWZJkBLqGTDnspw" target="_blank">assembly.py</a> helps to program the computer. 8 variables can be used: a,b,c,d,e,f,g,h. h is at the address 000 and is used for storing PC.</p><div><pre id="h.p_ar30iTXdo1HX"><code><strong>Instruction    Effect</strong></code></pre><pre id="h.p_VXWYwsQ8o1Mz"><code>write a n      Write the number n in to the variable a</code></pre><pre id="h.p_nUD9ePRPo1M0"><code>goto n         Go to line n</code></pre><pre id="h.p_q0l3SJwCo1M1"><code>move a b       b=a</code></pre><pre id="h.p_EZ1mwWONo1M1"><code>jumpif a       Jump the next line if a!=0</code></pre><pre id="h.p_l-rCsKzpo1M2"><code>print a        Display a</code></pre><pre id="h.p_CBxpEJLKo1M3"><code>add a b c      c=a+b</code></pre><pre id="h.p_bfag-7ZAo1M4"><code>or a b c       c=(a or b)</code></pre><pre id="h.p__Fy1TYwTo1M5"><code>and a b c      c=(a and b)</code></pre><pre id="h.p_OQcg0eRIo1M6"><code>xor a b c      c=(a xor b)</code></pre><pre id="h.p_HVXrkzoho1M7"><code>not a b        b=not(a)</code></pre><pre id="h.p_B7QjGUiqo1M8"><code>flat a b       B=0 if a=0 ; b=11111111 else</code></pre><pre id="h.p_LZxRjcG6o1M9"><code>sign a b       Write the most significant bit of a to b </code></pre><pre id="h.p_k7oiaST4pLkr"><code>               (sign of a if a is written in 2â€™s complement)</code></pre><pre id="h.p_Tc9FaJOxo1M9"><code>increment a    a=a+1</code></pre><pre id="h.p_JTRSCPpEpftU"><br></pre></div><h3 id="h.p_0RIdrgYYqaDF" tabindex="-1"></h3><div><pre id="h.p_1k_9G6N4pgFC"><code><strong>Display a modulo b</strong></code></pre><pre id="h.p_UqV_FtofqYtT"><br></pre><pre id="h.p_PRhE8OwXqVsj"><code><strong>Line    Instruction    Pseudo-code</strong></code></pre><pre id="h.p_CGA2uabjpgFD"><code>0       write a 8      a = 8 </code></pre><pre id="h.p_lpw-3PODpgFF"><code>1       write b 3      b = 3 </code></pre><pre id="h.p_Ry8dLB3ZpgFG"><code>2       write e 1      d = -b</code></pre><pre id="h.p_LEkpXlKIpgFH"><code>3       not b d         |</code></pre><pre id="h.p_hwAKdadSpgFJ"><code>4       add d e d       |</code></pre><pre id="h.p_ijNnpg8YpgFK"><code>5       add a d a      a = a+d</code></pre><pre id="h.p_k402xubXpgFL"><code>6       sign a c       if a&gt;=0</code></pre><pre id="h.p_XAH8PlHfpgFO"><code>7       jumpif c        |</code></pre><pre id="h.p_6OVX0K86pgFP"><code>8       goto 5         go to line 5</code></pre><pre id="h.p_muhLQdv9pgFQ"><code>9       add a b        a a = a+b</code></pre><pre id="h.p_p_F6YavnpgFS"><code>10      print a        print a</code></pre><pre id="h.p_Pke5SZqQpgFT"><code>11      goto 11        end</code></pre></div><div><pre id="h.p_nD1hHtITrogs"><code><strong>Display GCD(a,b) (Euclid's algorithm)</strong></code></pre><pre id="h.p_lxqiep7_ronV"><br></pre><pre id="h.p_gMCLSmrlronW"><code><strong>Line    Instruction    Pseudo-code</strong></code></pre><pre id="h.p_UoKuhjHPronW"><code>0       write a 8      a = 8 </code></pre><pre id="h.p_UfmcCRBRronX"><code>1       write b 6      b = 6</code></pre><pre id="h.p_JpIQn7o3ronX"><code>2       write e 1      c = a modulo b</code></pre><pre id="h.p_11Xpy03cronY"><code>3       not b d           |</code></pre><pre id="h.p_sTpDaV1JronY"><code>4       add d e d         |</code></pre><pre id="h.p_RL8BEDFeronZ"><code>5       add a d a         |</code></pre><pre id="h.p_OFwIDDuoronZ"><code>6       sign a f          | </code></pre><pre id="h.p_akSliUkOronZ"><code>7       jumpif f          |</code></pre><pre id="h.p_vM6j-KkMrona"><code>8       goto 5            |</code></pre><pre id="h.p_aIlt3SfRrona"><code>9       add a b c         |</code></pre><pre id="h.p_zlehb0Moronb"><code>10      jumpif c       if c = 0</code></pre><pre id="h.p_LoCcUlePronb"><code>11      goto 15        go to line 15</code></pre><pre id="h.p_lULgjjRzronc"><code>12      move b a       a = b</code></pre><pre id="h.p_ONpwMA9sronc"><code>13      move c b       b = c</code></pre><pre id="h.p_erU6mkLGrond"><code>14      goto 3         go to line 3</code></pre><pre id="h.p_GdClsddMrond"><code>15      print b        print b</code></pre><pre id="h.p_84t--rPSrone"><code>16      goto 16        end</code></pre></div></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.nicolasloizeau.com/gol-computer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831268</guid>
            <pubDate>Mon, 19 Oct 2020 21:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clusters rule everything around me]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24830588">thread link</a>) | @nickswhitaker
<br/>
October 19, 2020 | https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/ | <a href="https://web.archive.org/web/*/https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<blockquote><p><span>“</span><i><span>When an industry has thus chosen a locality for itself, it is likely to stay there long: so great are the advantages which people following the same skilled trade get from near neighbourhood to one another. The mysteries of the trade become no mysteries; but are as it were in the air, and children learn many of them unconsciously.</span></i><span>” – Alfred Marshall</span></p></blockquote>
<p><span>As technological advances continue to build out the digital economy it is perhaps ironic that physical locations still seem to matter so much. Slack and Twitter and Zoom and a host of various collaboration software products have facilitated our ability to communicate with people from all around the world. And yet, up-and-coming founders will still pay 3x the national average in rent so that they can live in Silicon Valley or Manhattan. Despite our ever-improving virtual tools, the triumph of the city is not reversing anytime soon. And the countries with the most vibrant tech clusters will get to decide the pace and the direction of the future. We need both a better understanding of how tech clusters form and how we can maximize their benefits.</span></p>
<h3><b>Why and how do tech clusters form?&nbsp;</b></h3>
<p><span>Economists and urbanists talk a lot about the significance of clustered networks of individuals and firms working and living together in a shared environment. All else equal, having more smart people interacting leads to more ideas which leads to more innovation which leads to more growth. The whole ecosystem of product designers, scientists, engineers, supply chain managers, investors, and academics ends up creating more than the sum of their parts. These </span><a href="https://www.agglomerations.tech/"><span>agglomeration effects</span></a><span> occur in cities across the world, but the US has had a unique geopolitical advantage in having the premier industrial clusters for essential technologies like software development and machine learning.</span></p>
<p><span>Defined </span><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.34.3.50"><span>formally</span></a><span>, we could say that an industrial or tech cluster is a geographic region with a disproportionate share of economic activity, high-skilled technical employment, granted patents, and R&amp;D funding when compared to their share of the national population. Less formally, we could say that tech clusters are in the cities where the most interesting conversations and cutting-edge applications in a particular field are happening.</span></p>

<table id="tablepress-3">
<thead>
<tr>
	<th>Consolidated<br>
metro area</th><th>Venture<br>
capital<br>
investment</th><th>Granted<br>
patents</th><th>Employment<br>
in top 10<br>
R&amp;D<br>
industries,<br>
high-skilled</th><th>Population</th>
</tr>
</thead>
<tbody>
<tr>
	<td>San Francisco</td><td>48.1%</td><td>18.4%</td><td>11.7%</td><td>2.5%</td>
</tr>
<tr>
	<td>New York</td><td>15.3%</td><td>6.0%</td><td>6.3%</td><td>6.4%</td>
</tr>
<tr>
	<td>Boston</td><td>10.5%</td><td>4.5%</td><td>5.5%</td><td>1.6%</td>
</tr>
<tr>
	<td>Los Angeles</td><td>6.5%</td><td>5.3%</td><td>5.6%</td><td>5.8%</td>
</tr>
<tr>
	<td>Seattle</td><td>2.1%</td><td>4.0%</td><td>4.2%</td><td>1.2%</td>
</tr>
</tbody>
</table>
<!-- #tablepress-3 from cache -->
<p><span>San Francisco is the archetypal example, but Boston, Seattle, Austin, and Denver all meet this threshold as well. Larger cities like New York and Los Angeles are more ambiguous, as their share compared to population size is not disproportionate, but narrowing the analysis to a subregion like Manhattan or Santa Monica would likely turn up a traditional tech cluster.&nbsp;</span></p>
<p><span>Historically, clusters have been pivotal in driving long-term US growth and for creating innovations that improve the lives of billions of people around the globe. As economists </span><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.34.3.50"><span>William Kerr and Frederic Robert-Nicoud</span></a><span> summarize, there has been a continual movement of leading tech clusters over time in the US. In the 1800s, Lowell, Massachusetts was the center for textile mills relying on water power. By the early 1900s, Cleveland, Ohio was instrumental in pushing forward the frontier on electricity and steel. Detroit, Michigan, of course, developed into the powerhouse for automobile manufacturing in the mid-1900s.&nbsp;</span></p>
<p><span>Currently, US tech clusters are the envy of the world. There are only four </span><a href="https://howmuch.net/articles/companies-trillion-dollar-club"><span>trillion dollar companies</span></a><span> in the world. Two of them are based near San Francisco (Apple and Alphabet), and two near Seattle (Amazon and Microsoft). Of the </span><a href="https://www.bondcap.com/report/itr19/#view/12"><span>global top 30</span></a><span> Internet firms, 14 are based in SF alone.</span></p>
<p><span>The effects that these clusters have on innovation and productivity growth are quite impressive, even on the individual level. Enrico Moretti </span><a href="https://www.nber.org/papers/w26270"><span>models their impact</span></a><span>: “a computer scientist moving from the median cluster in computer science (Gainesville, FL) to the cluster at the 75th percentile of size (Richmond, VA) would experience a 12.0% increase in productivity, holding constant the inventor and the firm. In biology and chemistry, a move from the median cluster—Boise, ID—to the 75th percentile cluster—State College, PA—is associated with a productivity gain of 8.4%, holding constant the inventor and the firm.” And as the clusters get larger and more specialized, the productivity boosts also get larger.&nbsp;</span></p>
<p><span>While the benefits and significance of tech clusters are fairly well established, what is less well known is precisely how tech clusters originate and why they end up in the specific places they do. That software clustered near San Francisco was not inevitable, that auto manufacturing clustered in Detroit was not fate, that semiconductor fabrication today clusters in Taiwan is not preordained. So how do clusters arise?&nbsp;</span></p>
<p><span>In the past, clusters would frequently populate around a specific natural resource that was necessary for the operation of the tech in question, i.e. natural harbors, coal and iron deposits, fast-flowing streams. But the ultimate resources for technology development today are the human minds that can come up with and then implement new ideas. So tech clusters today are mostly about attracting and organizing talented humans in cities they would actually want to live in.&nbsp;</span></p>
<p><span>More formally, to become a tech cluster today, a location needs:</span></p>
<ol>
<li><span>An anchor organization as a first-mover in getting high-skilled talent in a particular field to come to a region (usually a firm or a university)&nbsp;</span></li>
<li><span>An urban environment in which firms and workers in adjacent sectors can benefit from large knowledge spillovers as new advances and technical approaches diffuse across the region quickly</span></li>
<li><span>The development of high-velocity labor markets where workers with deep technical expertise can quickly start, join, or leave various firms</span></li>
<li><span>A social scene that is animated by a particular industry or technology area such that the conversations happening in local bars are some of the best in the world for that subfield</span></li>
<li><span>A sufficient supply of industry-specific resources (venture capitalists, relevant scientific or manufacturing infrastructure, government contracts)&nbsp;&nbsp;</span></li>
<li><span>A good bit of luck</span></li>
</ol>
<p><span>It’s worth emphasizing that the development of a cluster is a process rather than a flip that is switched at a specific moment in time. A location may not have all of these elements right at the very beginning but will need to quickly develop them if it wants to have staying power beyond an initial flash in the pan. Also complicating things, some of these factors suffer from a chicken-or-the-egg problem as it is much easier to attract specialized capital and interested young people to a region once the cluster already exists.</span></p>
<p><span>The historical accidents of particular government policies can sometimes serve as a tiebreaker among competing destinations. One reason that Silicon Valley may have become the primary driver for software development rather than the Boston area is California’s decision to </span><a href="https://www.vox.com/new-money/2017/2/13/14580874/google-self-driving-noncompetes"><span>not enforce non-compete agreements</span></a><span>. While not necessarily the intention, this accelerated both the degree of knowledge spillovers and the velocity of labor markets in the region. Today, top developers at large tech companies frequently leave to start competitors and help cutting-edge practices and the more promising technical approaches diffuse quickly throughout the region. This may be frustrating for the particular firms losing out, but it makes the larger tech cluster more vibrant and dynamic. And by increasing the number of approaches attempted to solve an issue, it increases the odds of a breakthrough innovation happening.</span></p>
<p><span>But tech clusters don’t necessarily last forever. As an industry matures and becomes more established it tends to be less reliant on the kind of rapid experimentation and ideation that is facilitated so well by tech clusters. As that happens, an industry may disperse over a larger set of regions, or be subsumed into a more traditional urban agglomeration.&nbsp;</span></p>
<p><span>Unsurprisingly, it seems to be the case that the development of a new </span><a href="https://www.nber.org/papers/w11093"><span>general-purpose technology</span></a><span> is usually a prime candidate for allowing new tech clusters to form. But interestingly, there may be a bias towards slightly smaller cities that can operate as more a blank slate for the fledgling industry than can a large, established city.&nbsp;</span></p>
<p><span>Looking at the emergence of auto manufacturing as an example, despite having fewer initial entrants and a smaller population, activity started to concentrate in smaller cities like St. Louis, Cleveland, Indianapolis, and in the ultimate winner, Detroit. According to </span><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.34.3.50"><span>Kerr and Robert-Nicoud</span></a><span>, this smaller city advantage may have been due to the higher physical proximity of engineers, production line managers, and funders as it was easier to share prototypes, run experiments, and circulate ideas between the relevant stakeholders. These smaller regional hubs may have been able to provide more attention and financial resources to these new firms because there was simply less competition.</span></p>
<p><span>This should not be all too surprising when we consider the softer, cultural aspects that make up an attractive tech cluster. It seems likely that the culture of a city made up disproportionately of geneticists and CRISPR scientists might differ from that of petroleum engineers and fracking specialists. Having a separate city is useful for establishing a different culture and offers a type of specialization that can attract a separate set of weird, ambitious young people that will form the backbone of a cluster.&nbsp;</span></p>
<p><span>The conversations in the bars and social scenes of San Francisco feel </span><i><span>very different</span></i><span> from those in the financial district of NYC because the types of people attracted to those cities are very different. To truly become a cluster for a particular field, a city essentially has to reach some critical density of conversations in the social scene to be …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/">https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/</a></em></p>]]>
            </description>
            <link>https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24830588</guid>
            <pubDate>Mon, 19 Oct 2020 20:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From fluffy to valuable: How the brain recognises objects]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24830431">thread link</a>) | @pelt
<br/>
October 19, 2020 | https://www.mpg.de/15916063/1016-nepf-113272-from-fluffy-to-valuable-how-the-brain-recognises-objects | <a href="https://web.archive.org/web/*/https://www.mpg.de/15916063/1016-nepf-113272-from-fluffy-to-valuable-how-the-brain-recognises-objects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  
  

  

  <p>To recognise a chair or a dog, our brain separates objects into their individual properties and then puts them back together. Until recently, it has remained unclear what these properties are. Scientists at the Max Planck Institute for Human Cognitive and Brain Sciences in Leipzig have now identified them - from "fluffy” to “valuable” - and found that all it takes is 49 properties to recognise almost any object.</p>
  
  
<figure data-description="The human brain breaks down the environment into a total of 49 properties, which are sufficient to categorise all objects. Depending on how similar the observed object is to a known category, it is then recognised as a dog or, for instance, a piece of furniture." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          The human brain breaks down the environment into a total of 49 properties, which are sufficient to categorise all objects. Depending on how similar the observed object is to a known category, it is then recognised as a dog or, for instance, a piece of furniture.
        </p>
        <p>
          © shutterstock
        </p>
    </figcaption>
</figure>



<p>We live in a world full of things that we have to identify and classify into different categories. Only when you are able to identify the things around you, you can communicate with others about them and act in a meaningful way. If we see something in front of us that we recognise as a chair, we can sit on it. Once we have identified an object as a cup, we can lift it up and drink from it.</p>
<p>In order to carry out this mapping and make sense of our environment, we have to constantly compare the input to our senses with the information we have already learned. To do this, the brain breaks down an object into its individual properties, compares them with those that are already known, and puts these properties back together. Depending on how similar the observed object is to a known category, it is then recognised as a piece of furniture or a vessel. So far, however, it has remained unclear how we consider things to be similar or less similar. In other words, what are the characteristics that make us recognise objects?</p>
<p>Scientists at the Max Planck Institute for Human Cognitive and Brain Sciences in Leipzig, in collaboration with the National Institute of Mental Health in Bethesda, USA, have now identified a set of 49 properties that allow us to determine almost all objects, i.e. the properties underlying their so-called mental representation. This representation reflects the format into which the brain translates a stimulus. In the case of an object, it is composed of, for example, colour, shape and size, but perhaps also of the fact that it "is natural", "can move", "is valuable" or "is animal-related". The researchers had been looking for the set of dimensions that were interpretable and minimally sufficient, i.e. that contained as few properties as possible and yet were enough to describe everything.</p>

<figure data-description="The scientists identified a set of 49 properties (here only as an excerpt) that allow us to determine almost all objects, i.e. the properties underlying their so-called mental representation. This representation reflects the format into which the brain translates a stimulus. In the case of an object, it is composed of, for example, colour, shape and size, but perhaps also of the fact that it &quot;is natural&quot;, &quot;can move&quot;, &quot;is valuable&quot; or &quot;is animal-related&quot;." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          The scientists identified a set of 49 properties (here only as an excerpt) that allow us to determine almost all objects, i.e. the properties underlying their so-called mental representation. This representation reflects the format into which the brain translates a stimulus. In the case of an object, it is composed of, for example, colour, shape and size, but perhaps also of the fact that it "is natural", "can move", "is valuable" or "is animal-related".
        </p>
        <p>
          © Hebart/ MPI CBS
        </p>
    </figcaption>
</figure>



<p>"Our results show that it actually takes surprisingly few dimensions to characterise all objects in our environment," says Martin Hebart, first author of the <a href="https://www.nature.com/articles/s41562-020-00951-3" target="_blank">article describing these results</a>. The human brain breaks down the environment into a total of 49 properties, which are sufficient to categorise all objects. "From these dimensions we can also infer what is perceived as particularly similar or what is perceived as particularly typical for a category," the neuroscientist continues. Whether, for example, a mussel or a dog is perceived as a more typical animal. "Fundamentally, this explains the basic principles of our thinking about objects."</p>
<p>However, the results could also be used for medical purposes. Until now, it was believed that patients who cannot identify certain animals because of brain damage would not be able to recognise animals as a whole. But it is possible that the patient has a deficit in recognising the characteristic "fluffy" that is a property of many animals. This may then lead to other forms of therapy.</p>
<p>The scientists investigated these relationships with the help of almost 2,000 pictures of objects representative of most things encountered in our environment.&nbsp; They then showed study participants three of the pictures at a time, for example, koala, dog and fish, but also koala, doormat and pretzel. From each of these, the participants were asked to choose the “odd one out”, the one that they perceived to be most different from the other two. In the case of koala, doormat, and pretzel, for some this might have been the koala, because, unlike the other two, it is a living creature or is considered "not flat". For others, it might have been the pretzel, because doormats and koalas are fluffy or you can only eat the pretzel. Yet for others, it might be the doormat, because it is made of inorganic material. This means that the answers are not always clear, but they highlight the relevant properties to find out all the core dimensions of objects.</p>
<p>The researchers tested almost 1.5 million combinations of three objects with the help of nearly 5,500 participants. From this, they developed a computational model which they used to calculate which object was most likely to be chosen to be the odd one out. The more often two objects are left in, the more similar they are. It turned out that their model enabled the scientists to predict the similarity of two objects very precisely. But it also provided the 49 core dimensions that enable us to categorise our world according to simple criteria.</p>
  
</div></div>]]>
            </description>
            <link>https://www.mpg.de/15916063/1016-nepf-113272-from-fluffy-to-valuable-how-the-brain-recognises-objects</link>
            <guid isPermaLink="false">hacker-news-small-sites-24830431</guid>
            <pubDate>Mon, 19 Oct 2020 20:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interdimensional Cable Box]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24829947">thread link</a>) | @catacombs
<br/>
October 19, 2020 | https://nimaid.github.io/tv/ | <a href="https://web.archive.org/web/*/https://nimaid.github.io/tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nimaid.github.io/tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829947</guid>
            <pubDate>Mon, 19 Oct 2020 19:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build a $4b insurtech company: Interview with Kin Insurance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24829791">thread link</a>) | @jhannon
<br/>
October 19, 2020 | https://radicleinsights.com/posts/breaking-through-kin-insurance-sean-harper | <a href="https://web.archive.org/web/*/https://radicleinsights.com/posts/breaking-through-kin-insurance-sean-harper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p><img src="https://images.prismic.io/radiclewebsite/645464ae-9b6b-4b69-af6e-011dde85ae27_Harper-Sean.jpg?auto=compress,format&amp;rect=0,0,600,600&amp;w=200&amp;h=200" alt=""></p><p><em>“At the core, every insurance company actually is a software company. What determines how successful you are is how quickly you're able to react to what happens in the world.”</em></p><p>Sean Harper is the CEO and co-founder of Kin Insurance, a Chicago-based home insurance start-up focused on using technology to offer homeowners the lowest rates as quickly as possible. He does so in an industry known for moving slowly. “We believe in creating meaningful change for homeowners who need our solution the most,” Harper says of Kin. Prior to founding Kin in 2016, Harper founded Fee Fighters, later sold to Groupon, and TSS-Radio, an e-commerce company. Prior to Kin, both Harper and co-founder Lucas Ward consulted for top financial companies, including several for PNC.&nbsp;</p><p>Kin offers home insurance in Florida and California, both states known for their catastrophe exposure. Kin recently closed a $35 million Series B funding round led by Commerce Ventures, which brings its total funding to date to $90 million.&nbsp;</p><p>In this interview:</p><ul><li>How Harper moved from consulting to start-ups to founding Kin</li><li>The 3 criteria Harper wanted in creating a start-up</li><li>How Kin innovates compared to legacy insurance companies</li><li>Kin’s entry into catastrophe insurance coverage</li><li>Why Kin is better at underwriting insurance than legacy companies</li><li>The future of insurance online and the value of real customer service</li><li>Kin’s culture, early experiments and what Kin is focusing on next&nbsp;</li></ul><p><strong>I would love to hear about your background and how you came about founding Kin.</strong></p><p>My co-founder Lucas and I have been doing online financial services for a long time. We just sort of fell into the start-up thing and realized we liked it a lot. The great thing about consulting gigs is you get to see a lot of stuff that big companies aren't doing very well. We really enjoy doing start-ups because you can start with a blank sheet of paper and do it the right way. If you're a software geek, which we both are, you look around for problems that are easy for you to solve. Financial services are easy to solve because it's all online. There's no physical product to worry about. And we're good at online stuff. And really I think if you look at the core of a bank or an insurance company or stock trading company, they're actually software companies, but they're not very good at software. We’re a few companies in now. We’re good at it now, building financial companies from scratch.</p><p><strong>Were you in or around the insurance area at all?</strong></p><p>Almost all the consulting I did was in financial services and the same for Lucas. We worked at, between the two of us, probably three of the five top P&amp;C financial companies. Basically, Lucas and I had come out of selling our companies and we were kicking around for two and a half years trying to come up with our big idea. In the meantime, we were doing interim gigs for private equity backed companies. We didn't want to sell technology to big financial institutions because their adoption cycles are so slow. We wanted to go direct to the consumer and beyond that, we were looking for three criteria.&nbsp;</p><p>First, I wanted to be in a large and homogenous market. Second, I wanted it to be a market where it was very inefficient. I didn't want to have to win on underwriting at the onset, because it's really hard to win on underwriting until you have data. Now we have a bunch of data. And we have a huge underwriting advantage over our competitors, but on day one, I didn't want to have to do that because it's a good way to get blown up. The third thing I wanted was for there to be new data sources available for pricing and underwriting.&nbsp;</p><p>We didn't just look at insurance. We looked at all financial services. We found catastrophe-exposed homeowners insurance. It fits all those criteria. It's a $40 billion market and growing fast to extraordinarily inefficient expense ratios. The amount of money that's wasted is about 40% of every dollar they collect. And there's just a ton of data out there – the weather that's around the home, geography, the neighborhood, the construction.&nbsp;</p><p>Most insurance companies are underwriting on the same 20 to 40 fields of data that's all self reported or agent reported. They're basically doing it the same way they've been doing it for 100 years. The business model has changed and the main way it's changed since we've climbed our way up the stack is we started as a digital broker, similar to a company like Zebra or Gabi, and then we became an MGA, which is sort of a virtual insurance company. And then last year, we actually formed our own insurance entity. We did that because it's really hard to raise enough money to start an insurance company on day one. We had to build our way to it. We learned a lot at each stage that made us know we were ready to go to the next stage.</p><p><strong>You operate on this specific segment of the home insurance market: catastrophe-prone homes.</strong></p><p>In the United States, there's about 100 billion dollars of premium spent every year on homeowners insurance. It's growing 3% to 4% a year, and of that 100 billion, 40 billion of it is catastrophe exposed. It's a huge niche and it is clear that the weather is getting worse. Let’s hope we can reverse that, but it's not going to happen overnight. We're going to need to deal with it by having good insurance that allows us to spread the risk out, ready to deal with it by investing and hardening our homes to make them more weather resilient. So, we find our work meaningful because we're working on insurance for people who need it. And I think it's only a matter of time. Here in Chicago, we're pretty sheltered from extreme weather, but it is affecting more and more places. And so even more of the market will end up being catastrophe exposed next year and year after year.</p><p><strong>Why are you guys better at underwriting your home insurance than someone else?</strong></p><p>We are much more efficient at administering and servicing. We talked about the cost structure before. About 60% goes to pay claims and about 40% goes to other stuff. For us, that 40% is more like 8%, so we're just very efficient. We don't pay brokers. Brokers occupy about 17% of that 40%. We're very efficient at marketing and we have a very good tech system. Your average insurance company spends about 5% of premiums for their IT on an ongoing basis. Yet, their biggest problem is their tech doesn't work. We’re also really good now at understanding the physical properties of the home and the micro environment around it. We know the difference in risk between being the second house off the water and the fourth house off the water in California. Are you right next to the brush land or is there a road between you and the brush land? Because it makes a huge difference. And we're able to ingest all this data and understand on a micro basis which homes are more or less risky. Then we're able to price it properly.</p><p><strong>What’s stopping a legacy insurer from utilizing the same types of data that you do?</strong></p><p>In theory, nothing. In fact, four years ago, the way we came up with this idea was by going around and talking to a lot of people from the industry and finding all the smart things that they wish they could do but couldn't. At the core, every insurance company actually is a software company. We have a really cutting edge policy administration system, our core processing system. It's leaps and bounds better than what any of our competitors have. It does exactly what we need it to do and it's really easy to change. So if we want to launch a new product or add a new data source, these are the kinds of things that might take us hours and take our competitors years. What determines how successful you are is how quickly you're able to react to what happens in the world. Our competitors are not able to react quickly.</p><p><strong>You said that you're able to issue new products at a faster rate. What are some examples?</strong></p><p>We saw an opportunity to do insurance for manufactured homes, a very underserved market, in Florida, which is also underserved because of its catastrophe exposure. We actually launched that product in less than a month, including regulatory approval, and that&nbsp;doesn't happen in insurance.</p><p><strong>A surprising amount of insurance is still being sold through physical agents, not online. How do you view that? Is the wind ultimately blowing in your direction for insurance being purchased online?</strong></p><p>I just turned 40 so I'm sort of borderline millennial and I was sure I was building this for people my age and younger. Amazingly – we realized this three months after we launched and it's still true – our average customer is in their mid 50s. It shouldn't be that surprising. The average age of a homeowner is late 40s, and in Florida, it's higher. But then you start talking to these people and the thing is, they all bank online. Their retirement accounts are all online; they all have the Capital One or Amex credit card. Even they think it's weird to buy insurance at a store.&nbsp;</p><p>We do a lot of customer support on the phone and via email with a real human. Being techie does not mean that you need to be inhuman. If you think about our name, it's Kin. That's family. I don't send automated messages to my children. I talk to them in person. That's how families act with each other. So it doesn't need to be impersonal just because it's tech-based. That's a really big part of who we are. We like having this human element. A home is somebody's biggest asset for the most part. It's nice to be able to ask a person a question like, “Hey, I saw this on the website. Can you explain that to me?” So that actually is a huge role in our customer experience.</p><p><strong>How’s business been in the past five or six months, given that most of the current climate has changed?</strong></p><p>There's been no impact on consumer demand. Probably the biggest impact for us has been operationally. We've been operating remotely. We're located in Tampa and Chicago and we like our office. We like hanging out with each other. We like going for drinks after work. We like playing ping pong. We like working on the …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://radicleinsights.com/posts/breaking-through-kin-insurance-sean-harper">https://radicleinsights.com/posts/breaking-through-kin-insurance-sean-harper</a></em></p>]]>
            </description>
            <link>https://radicleinsights.com/posts/breaking-through-kin-insurance-sean-harper</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829791</guid>
            <pubDate>Mon, 19 Oct 2020 19:14:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Turing Pi 2 – a compact ARM cluster with 32 GB RAM]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24829768">thread link</a>) | @nsky-world
<br/>
October 19, 2020 | https://turingpi.com/turing-pi-2/ | <a href="https://web.archive.org/web/*/https://turingpi.com/turing-pi-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><p><strong>32 GB</strong> <span>of RAM</span></p><p><strong>SATA III</strong> <span>interface</span></p><p><strong>CM4</strong> <span>support</span></p></div></div><p><img src="https://turingpi.com/wp-content/themes/turing/assets/img/turing-2/hero-3.png" data-src="https://turingpi.com/wp-content/themes/turing/assets/img/turing-2/hero-3.png" alt=""></p></div></div></section><section><div><div><div><h3> Reliable, scalable, cloud-native infrastructure for the edge</h3><p> Turing Pi is a compact ARM cluster that provides a secure and scalable compute in the edge. It is designed to make web-scale edge computing easier for developers. Turing Pi cluster architecture allows you to migrate and sync web apps with minimal friction. It provides you with complete control of the edge infrastructure and improves reliability.</p></div><div><div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/1.svg" alt="Layer 2 Managed Switch"></p><p> Layer 2 Managed Switch</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/2.svg" alt="2 x Mini PCI Express"></p><p> 2 x Mini PCI Express</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/3.svg" alt="2 x SATA III 6 Gbps"></p><p> 2 x SATA III 6 Gbps</p></div></div><div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/4.svg" alt="12 Gbps Backplane Bandwidth"></p><p> 12 Gbps Backplane Bandwidth</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/5.svg" alt="Cluster Management Bus (I2C)"></p><p> Cluster Management Bus (I2C)</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/6.svg" alt="VLAN Support"></p><p> VLAN Support</p></div></div></div></div></div></section><section><div><h3> Use Cases</h3><div><div><div><p>Self-hosted</p><p>Host cloud applications locally or at the edge</p></div><div><p>Learning</p><p>Learn Kubernetes, Docker, Serverless</p></div><div><p>Development</p><p>Build cloud-native and CI/CD for ARM edge infrastructure</p></div><div><p>Network-Attached Storage</p><p>Connect up to 2 x 2.5″ SSD storage</p></div></div></div></div></section><div><p><img width="804" height="872" src="https://turingpi.com/wp-content/uploads/2020/10/scheme.png" data-src="https://turingpi.com/wp-content/uploads/2020/10/scheme.png" alt="" data-srcset="https://turingpi.com/wp-content/uploads/2020/10/scheme.png 804w, https://turingpi.com/wp-content/uploads/2020/10/scheme-277x300.png 277w, https://turingpi.com/wp-content/uploads/2020/10/scheme-768x833.png 768w, https://turingpi.com/wp-content/uploads/2020/10/scheme-600x651.png 600w" data-sizes="(max-width: 804px) 100vw, 804px" srcset="https://turingpi.com/wp-content/uploads/2020/10/scheme.png 804w, https://turingpi.com/wp-content/uploads/2020/10/scheme-277x300.png 277w, https://turingpi.com/wp-content/uploads/2020/10/scheme-768x833.png 768w, https://turingpi.com/wp-content/uploads/2020/10/scheme-600x651.png 600w"></p></div><section></section><section></section><div id="modal-success"><div><h3>Check your inbox!</h3><p> You should receive a confirmation email soon</p> </div></div><div id="modal-error"><div><h3>Error</h3><p>Contact already exist</p> </div></div></div></div>]]>
            </description>
            <link>https://turingpi.com/turing-pi-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829768</guid>
            <pubDate>Mon, 19 Oct 2020 19:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Discord Won]]>
            </title>
            <description>
<![CDATA[
Score 523 | Comments 522 (<a href="https://news.ycombinator.com/item?id=24829635">thread link</a>) | @ivanagas
<br/>
October 19, 2020 | https://ianvanagas.com/2020/10/19/how-discord-won/ | <a href="https://web.archive.org/web/*/https://ianvanagas.com/2020/10/19/how-discord-won/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-478">

	

	
			<figure>
				<img width="1280" height="720" src="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=1280" alt="" loading="lazy" srcset="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg 1280w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=150 150w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=300 300w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=768 768w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=1024 1024w" sizes="(max-width: 1280px) 100vw, 1280px" data-attachment-id="494" data-permalink="https://ianvanagas.com/2020/10/19/how-discord-won/kingdiscord/" data-orig-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KingDiscord" data-image-description="" data-medium-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=300" data-large-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>It has been a big year for realizing the limits of technology for interacting with people. Gamers have known this for a long time. Lag, disconnections, and coordination issues were problems in gaming since the start. There is a platform that has gone a long way in solving those problems: Discord.</p>



<p>Discord allows people to talk and chat online. Servers are created by anybody to talk about anything, usually, it is a friend group or a shared interest. They contain chat channels (kind of like Slack) and voice channels that are always on and allow people to join and leave whenever they want.</p>



<p>The competition between internet communication platforms is fierce. Discord wasn’t early to voice channels or group chats. They weren’t unique for targeting their offering to gamers. Other platforms have the same features as them. Yet they are a multi-billion dollar business. How? To borrow an idea from <a rel="noreferrer noopener" href="https://medium.com/@sarahtavel/how-to-build-an-enduring-multi-billion-dollar-business-hint-create-a-10x-product-recast-3527df2b8fcb" target="_blank">Sarah Tavel</a>, they built a 10x better product AND capture more value from it.</p>



<h2>10x Better</h2>



<p>Voice chat sucked for a long time. Skype, which was long the most popular option, was a mess. It forced you to call people. Servers went down often. The application crashed. Chats were all over the place. There is a good reason people do not use Skype and it is because it sucks.</p>



<p>There were other competitors like IRC, TeamSpeak, Mumble, Ventrilo. All had basically the same features, voice calls, and chat. Each suffered from a combination of problems like:</p>



<ul><li>Complicated setup process. Any new member must also go through a setup process.</li><li>Paid hosting. No one wanted to pay when there were free options. Especially true as servers grow.</li><li>Unclear benefits. Convincing one person was not enough, you needed to convince your whole group of the benefits of switching.</li><li>Weird ideological reasons. Your platform was your tribal affiliation, switching means abandoning your tribe. Everyone looked down on people who didn’t use the same platform as them (even if it was jokingly).</li></ul>



<p>Discord launched in May 2015, long after the competitors listed above. They are now more successful than those same competitors. They did so by making the experience 10x better:</p>



<ul><li>Discord requires nearly no setup. Starting a server on Discord takes two clicks. Creating channels is two clicks. It works instantly and all the time.</li><li>Discord is free.</li><li>It is easy to switch to Discord. Inviting people is two clicks and a paste. Joining a server (once you have an account) is two clicks. It is so simple you don’t even think about it.</li><li>Non-core features like emoji support, reactions, bots, integrations, video calls, and screen-sharing all work as well as you could ask.</li><li>Big community servers for games, fanbases, organizations, hobbies, and more.</li></ul>



<p>Improvements in each of these areas add up to a 10x better experience than other platforms. I complain about Discord way less than I complain about Skype. There are benefits for everyone on Discord, which makes it a 10x experience both for groups and individuals.</p>



<p>On top of being 10x better, the core features are free. This causes an obvious business problem, how do you make money? There isn’t an obvious place to put ads. Competitors often charge by the member, but that incentivizes against growth. Discord figured out a way to incentivize growth while capturing value from large and small groups. </p>



<h2>Sell Status to Capture Value</h2>



<p>It took Discord a long time to figure out monetization (and they still are figuring it out). Venture capital allowed them to experiment with ideas such as selling games and membership. Neither worked perfectly, but they pointed in the right direction. <a rel="noreferrer noopener" href="https://www.forbes.com/sites/abrambrown/2020/06/30/discord-was-once-the-alt-rights-favorite-chat-app-now-its-gone-mainstream-and-scored-a-new-35-billion-valuation/#article-0-topx-1:~:text=Discord%20is%20on%20track%20to%20top,Discord%20groups%20that%20they%20belong%20to." target="_blank">Forbes estimated</a> they are “on track to top $120 million in sales this year (2020)… up from around $70 million last year.”</p>



<p>To understand Discord’s monetization, look at their history. The founders previously started game companies and were <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Discord_(software)#cite_ref-vb_2015_funding_9-0:~:text=%5D%20Their%20first%20product%20was%20Fates,and%20based%20on%20more%20modern%20technology.%5B" target="_blank">inspired by free-to-play games like League of Legends.</a> Games like League of Legends sell status. It is free-to-play but you can buy “skins” to make your character look different. If you have a cool or expensive skin, it means you care more about the game. It raises your status. Discord does the same.</p>



<p>Discord allows users to raise their status through a subscription called Nitro. It provides quality improvements (file size and video quality), special profile upgrades (more emojis, animated profile photos, custom tags), and most importantly, the ability to “boost” a server.</p>



<p>Boosts raise a user’s status in both small and large servers. They allow you to either improve your friend’s online hangout and your communities’ experience by unlocking custom emotes, cosmetic features, and quality improvements. For users, it puts an icon next to their name saying they contribute and gives them a special booster role on the server. In short, it is a way for someone to pay to stand out.</p>



<figure><img data-attachment-id="493" data-permalink="https://ianvanagas.com/serverboosts/" data-orig-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png" data-orig-size="1163,333" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="serverboosts" data-image-description="" data-medium-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=300" data-large-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=750" src="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=1024" alt="" srcset="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=1024 1024w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=150 150w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=300 300w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=768 768w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png 1163w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Server Boost Perks</figcaption></figure>



<p>You can buy boosts separately from Nitro at $5 per month or $50 per year. Perks come in uneven tiers: Level 1 is 2 boosts, Level 2 is 15 boosts, Level 3 is 30 boosts. It is unlikely “friend group sized” servers get past two boosts, but large servers often pass thirty. Some examples:</p>



<figure><table><thead><tr><th data-align="left">Name</th><th data-align="left">Boosts</th><th data-align="left">MRR (@ $5 per boost)</th></tr></thead><tbody><tr><td data-align="left">Minecraft</td><td data-align="left">165</td><td data-align="left">$825</td></tr><tr><td data-align="left">Kanye</td><td data-align="left">75</td><td data-align="left">$375</td></tr><tr><td data-align="left">Fortnite</td><td data-align="left">165</td><td data-align="left">$825</td></tr><tr><td data-align="left">r/LeagueOfLegends</td><td data-align="left">201</td><td data-align="left">$1005</td></tr><tr><td data-align="left">Animal Crossing: New Horizons</td><td data-align="left">412</td><td data-align="left">$2060</td></tr><tr><td data-align="left">r/Overwatch</td><td data-align="left">85</td><td data-align="left">$425</td></tr><tr><td data-align="left">Rocket League</td><td data-align="left">116</td><td data-align="left">$580</td></tr><tr><td data-align="left">Fall Guys</td><td data-align="left">215</td><td data-align="left">$1075</td></tr><tr><td data-align="left">Anime Soul Discord</td><td data-align="left">323</td><td data-align="left">$1615</td></tr><tr><td data-align="left">Kenny Beats</td><td data-align="left">50</td><td data-align="left">$250</td></tr><tr><td data-align="left">Musicians (Turkish)</td><td data-align="left">730</td><td data-align="left">$3650</td></tr><tr><td data-align="left">English</td><td data-align="left">94</td><td data-align="left">$470</td></tr><tr><td data-align="left">Python</td><td data-align="left">44</td><td data-align="left">$220</td></tr><tr><td data-align="left">CallMeCarson Discord Cult</td><td data-align="left">1153</td><td data-align="left">$5765</td></tr></tbody></table></figure>



<p>Here are 14 popular servers accounting for nearly $250,000 in revenue per year. There are tons more, all with varying amounts of boosts. People are willing to pay to stand out, even when there is no obvious benefit. This is universal.</p>



<p>Every community needs a place to communicate online. Discord has the best offering, and it is free. Other platforms either force you to pay by the member or have a flat rate paid by the community host. Discord doesn’t require either. Servers can grow as large as they want for free, moderators and admins don’t have to pay, and Discord still makes money.</p>



<p>As communities continue to grow on Discord, the money Discord makes from those communities goes up as well. Flat rates and tiers limit this. Communities want to grow, Discord provides them with an easy and effective way to do that. Users want status, Discord gives them a shortcut. This aligns incentives better than advertising or paid memberships do.</p>



<hr>



<p>Discord won by building 10x better spaces for communities. By selling status, they have also managed to capture more value from those communities than other platforms.</p>



<p>Discord won the competition for the gaming chat platform of choice, and now it wants to be the platform for all internet communities. This means they will be competing with the “big dogs” like Slack, Reddit, Twitter, Facebook, Microsoft, and Epic. Their free-to-play, pay-for-status monetization model is a competitive advantage.</p>



<p>Discord is a successful company. The question becomes how successful can they become? The key is the number of internet communities who choose Discord as their home. By creating a better product than competitors and being free for growth, Discord puts itself in an excellent position to continue to succeed moving forward.</p>



<p>Follow me <a rel="noreferrer noopener" href="http://twitter.com/ianvanagas/" target="_blank"><strong>on Twitter</strong></a> or sign up for <a rel="noreferrer noopener" href="https://adept-teacher-7152.ck.page/55b2205587" target="_blank"><strong>my monthly newsletter</strong></a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://ianvanagas.com/2020/10/19/how-discord-won/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829635</guid>
            <pubDate>Mon, 19 Oct 2020 18:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Git diff output for Ruby, Python, Elixir, Go]]>
            </title>
            <description>
<![CDATA[
Score 278 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24828509">thread link</a>) | @Lammy
<br/>
October 19, 2020 | https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more | <a href="https://web.archive.org/web/*/https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>The regular Git users amongst you will be familiar with the diff output that breaks down into “hunks” like so:</p>

<div><div><pre><code><span>@@ -24,7 +24,7 @@</span> class TicketPdf
     ApplicationController.render(
       "tickets/index.html.haml",
       layout: "tickets",
<span>-      assigns: { tickets: tickets }
</span><span>+      assigns: { tickets: tickets, event_name: event_name }
</span>     )
   end
</code></pre></div></div>

<p>The first line (starting <code>@@</code>) is known as the hunk header, and is there to help orientate the change. It gives us the line numbers for the change (the numbers between the <code>@@..@@</code>), but also a textual description for the enclosing context where the change happened, in this example <code>"class TicketPdf"</code>. Git tries to figure out this enclosing context, whether it’s a function, module or class definition. For C-like languages it’s pretty good at this. But for the Ruby example above it’s failed to show us the immediate context, which is actually a method called <code>tickets_as_html</code>. That’s because out of the box Git isn’t able to recognise the Ruby syntax for a method definition, which would be <code>def ticket_as_html</code>.</p>

<p>What would be more useful is to see:</p>

<div><div><pre><code><span>@@ -24,7 +24,7 @@</span> def tickets_as_html
     ApplicationController.render(
       "tickets/index.html.haml",
       layout: "tickets",
<span>-      assigns: { tickets: tickets }
</span><span>+      assigns: { tickets: tickets, event_name: event_name }
</span>     )
   end
</code></pre></div></div>

<p>And it’s not just Ruby where Git struggles to figure out the correct enclosing context. Many other programming languages and file formats also get short-changed when it comes to the hunk header context.</p>

<p>Thankfully, it’s not only possible to configure a custom regex specific to your language to help Git better orient itself, there’s even a pre-defined set of <a href="https://github.com/git/git/blob/master/userdiff.c">patterns for many languages and formats right there in Git</a>. All we have to do is tell Git which patterns to use for our file extensions.</p>

<p>We can do this by defining a <a href="https://git-scm.com/docs/gitattributes"><code>.gitattributes</code></a> file inside our repo that maps the Ruby file extensions to the diff pattern for Ruby:</p>

<div><div><pre><code><span>*</span>.rb <span>diff</span><span>=</span>ruby
<span>*</span>.rake <span>diff</span><span>=</span>ruby
</code></pre></div></div>

<p>Some open source projects define their own <code>.gitattributes</code> file. There’s <a href="https://github.com/rails/rails/blob/master/.gitattributes">one in Rails</a>. There’s even <a href="https://github.com/git/git/blob/master/.gitattributes">one in the Git source</a> that enables the diff patterns for Perl and Python.</p>

<h2 id="configure-a-global-gitattributes-file">Configure a global .gitattributes file</h2>

<p>Instead of adding a <code>.gitattributes</code> file to every repo we can configure a global <code>.gitattributes</code> file. Just create a <code>.gitattributes</code> file in your home directory, fill it with all the file formats you are interested in and point Git at it:</p>

<pre><code>  <strong>$ git config --global core.attributesfile ~/.gitattributes</strong>
</code></pre>

<p>I’ve put together an <a href="https://gist.github.com/tekin/12500956bd56784728e490d8cef9cb81">example .gitattributes file</a> with some common file formats to get you started.</p>

<p>I have no idea why Git doesn’t have these file format patterns configured by default. Thanks to Tom whose <a href="https://twitter.com/tomstuart/status/1304401459069452290">exasperated tweet</a> brought this non-obvious feature to my attention.</p>


  </section></div>]]>
            </description>
            <link>https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more</link>
            <guid isPermaLink="false">hacker-news-small-sites-24828509</guid>
            <pubDate>Mon, 19 Oct 2020 17:16:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Persuasion for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24827766">thread link</a>) | @laybak
<br/>
October 19, 2020 | https://informedpm.com/posts/persuasion-product-manager | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/persuasion-product-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>The core of a product manager's job is to make change happen by influencing stakeholders without exerting power over them. It is not an easy task. But it is much more approachable with the right tools. </span></p> <p><span>Here I have curated some powerful principles and practical tips from the field of psychology as well as experts trained in persuasion so that you can rally support behind your ideas. </span></p> <p><span>Persuasion is the focus of this post. Other topics such as building the right product and making robust decisions are out of scope (to be covered in future posts). </span></p> <p><span>It should go without saying, but use these techniques wisely. Always do what's right for the product and for your customers.</span></p>  <p><h3><span>Facts Are Overrated</span></h3></p> <p><span>We like to think we are perfectly logical and rational beings. But we are not. Humans tend to make decisions based on (often hidden) biases and emotions. </span></p> <p><span>By all means, bring facts and data to the table wherever possible. But don't expect facts alone to change people's minds. </span></p>  <p><h3><span>Reciprocation</span></h3></p> <p><span>We are hardwired to reciprocate favours. If you want a partner's cooperation tomorrow, do that person a favour today. But offer real value, not just as a means to get what you want.</span></p> <p><span>Another way in which reciprocation can work to your advantage is starting with a bigger (exaggerated) ask that is likely to get rejected. Then concede to a smaller request. It is more likely to work than when presented on its own.</span></p>  <p><h3><span>Persuasion Still Works Even if the Person Recognizes the Technique</span></h3></p> <p><span>In a way, this is similar to optical or audio illusions. Even if you know certain psychological effects are at play, it is hard to resist. </span></p>  <p><h3><span>What you Think More About Becomes More Important</span></h3></p> <p><span>When you devote mental energy to an idea, you remember it better. In your mind, it becomes more important. For this reason, intentional "errors" in your message (such as a typo in your email) can make the message rise in importance, even as the errors attract criticism (which is a form of attention). </span></p>  <p><h3><span>Repetition is Persuasion</span></h3></p> <p><span>Repetition is persuasion.</span></p> <p><span>Repetition is persuasion.</span></p> <p><span>Repetition is persuasion.</span></p>  <p><h3><span>Commitment and Consistency</span></h3></p> <p><span>The moment we make a decision, there is a tendency to justify the wisdom of our choice and find reasons to dismiss the other options. From this point, cognitive dissonance and confirmation bias are at play. </span></p> <p><span>Trivial requests increase the likelihood of compliance to larger requests. In the book Influence, Robert Cialdini noted that once a small commitment has been made, people tend to add justification to further commitments. </span></p>  <p><h3><span>Visual Persuasion</span></h3></p> <p><span>All else being equal, visual persuasion is more powerful than non-visual persuasion. Humans are generally visual creatures. Using visual language and visual imagery is persuasive. What's more, if you can make someone imagine the scene, you don't even need a physical picture.</span></p> <p><span>Try using the whiteboard in a meeting and drawing out ideas as you go, or attaching simple illustrations in your emails/messages to convey your ideas.</span></p>  <p><h3><span>Thinking Past the Sale</span></h3></p> <p><span>Related to the above points about visualization and the importance we tend to assign to what we think about more, getting your stakeholder to "imagine" a future where your proposal will have manifested is powerful. </span></p> <p><span>As they think about your proposed future more, they are more likely to see opportunities to make that future a reality. In persuasion writer Scott Adams' observations, people tend to gravitate to the future they are imagining most vividly, even if they don’t want that future.</span></p>  <p><h3><span>Social Proof</span></h3></p> <p><span>If you already have buy-in from some other stakeholders, you are more likely to gain support for your idea. </span></p> <p><span>You know that restaurant in town that is popular </span> <em>because</em> <span> it is popular? Or the TV show that everyone is talking about </span> <em>because</em> <span> everyone is talking about it? Your feature idea can be like that too.</span></p>  <p><h3><span>Don't Feel Their Pain. Label It.</span></h3></p> <p><span>We all like to be heard. When we talk to people who ignore us, resentment and frustration build up. We talk past each other. Conversations break down.</span></p> <p><span>Pay close attention to the subtle changes in people when they respond to your words. One way to validate and acknowledge the other person's feelings is by labeling. Give their emotion a name. Then lead with words such as "it seems like...", "it sounds like...", or "it looks like...". </span></p> <p><span>And once you have used a label, be quiet and listen. Give the person a chance to share and reveal.</span></p>  <p><h3><span>"That's Right"</span></h3></p> <p><span>According to FBI hostage negotiator Chris Voss, the sweetest two words in any negotiation are "that’s right." If you are arguing with your stakeholder, you want to lead the conversation to a "that's right". </span></p> <p><span>It is at the point that they feel heard and become ready to listen to what you have to say. They are signaling that they believe you understand their perspective. You are now on the same page. You are now ready to move the discussion forward.</span></p>  <p><h3><span>Further Readings</span></h3></p>             


          
          
          <p><em>Each week, I send out a newsletter with the latest product learnings and insights.</em></p>
          <p><em>Enter your email below to subscribe.</em></p>

          
        </div></div>]]>
            </description>
            <link>https://informedpm.com/posts/persuasion-product-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-24827766</guid>
            <pubDate>Mon, 19 Oct 2020 16:16:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Many of the root certificates on Windows are not needed]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24827509">thread link</a>) | @svenfaw
<br/>
October 19, 2020 | https://hexatomium.github.io/2020/10/17/001.html | <a href="https://web.archive.org/web/*/https://hexatomium.github.io/2020/10/17/001.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>As of today, Windows trusts 322 root certificates issued by 122 different organizations from 47 countries. This number is quite high, and has been steadily growing over the last few years. And it turns out many of those certificates are not needed at all by the vast majority of Windows users, can be distrusted with no ill effects of any sort.</p>

<p>Each of these CAs is given tremendous power over your Internet traffic, so it makes great sense to minimize the number of CAs your computer trusts. 
One simple way to achieve this goal is to replace the default Windows list of root CAs with the much stricter Mozilla trust list, which includes 142 roots (52 organizations - 21 countries). An even stricter option is using the Google CTL, which currently includes just 127 root certificates (48 organizations - 21 countries). For the vast majority of users, applying either set is a great way to reduce your exposure to unnecessary CAs, with no negative impact whatsoever.</p>

<p>Replacing the default Windows list of root CAs with the Mozilla or Google trust lists can be done manually, but is extremely time-consuming and error prone. 
The free version of RootIQ(*) offers a much simpler way to perform this system change:</p>

<div><div><pre><code>1. Use the Quick select dropdown to select the Mozilla trust set
2. Right-click the selection and click Invert selection
3. Right-click the selection and click Distrust
   Click Yes on the confirmation dialog
   This will distrust all roots that are not part of the Mozilla trust set, except for any Microsoft OS-critical roots.
4. Use the Quick select dropdown to select the Mozilla trust set (again)
5. Right-click the selection and Trust
</code></pre></div></div>

<p><img src="https://nsa40.casimages.com/img/2020/10/17/201017023914436079.png" alt="img123"></p>

<p>As of this writing, on a standard Windows 10 system, you will end up with 145 trusted roots (rather than 322 roots for the default Microsoft CTL)</p>

<p>(*) RootIQ, our own root certificate manager for Windows, is now <a href="https://www.metasudo.com/">available</a>. A free version of RootIQ is available for home and evaluation use.</p>

  </div></div>]]>
            </description>
            <link>https://hexatomium.github.io/2020/10/17/001.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24827509</guid>
            <pubDate>Mon, 19 Oct 2020 15:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A case for using punctuation in Slack]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 242 (<a href="https://news.ycombinator.com/item?id=24827295">thread link</a>) | @dontmitch
<br/>
October 19, 2020 | https://blog.mitchjlee.com/2020/your-writing-style-is-costly | <a href="https://web.archive.org/web/*/https://blog.mitchjlee.com/2020/your-writing-style-is-costly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>
          <p><strong>You should use punctuation in Slack.</strong> You should also use complete sentences and proper grammar. You should expand acronyms<sup>[1]</sup> and — when communicating emotion — even mix in some emoji for effect. You should do that not just in Slack, but in all of your professional communication.</p>

<hr>

<p>Written communication is hard, but in the digital world we work in it’s also vital. Sadly, the style of communication that services like Slack incentivize is awful.</p>

<p>To voice an opinion before the conversation moves on, you type fast and use abbreviations and hit send even with misspellings. You think one message at a time. You bounce between different threads and become easily distracted.</p>

<p>There are some obvious downsides to this fast and loose style. Most notably, it interrupts more productive work and deters deep thinking. But one large and often overlooked downside is the impact it has on others.</p>

<h2 id="externalities">Externalities</h2>

<p>When you use an obscure initialism or take shortcuts on grammar and spelling, it may save you a couple seconds. The problem is those small savings are often outweighed by the cost born by your audience.</p>

<p>Every person who reads your message spends some finite period of time interpreting what you’re saying. Setting aside the possibility that a sloppy message might lead the reader to an incorrect interpretation, it’s harder to parse messages written hastily — messages with poor grammar, misspellings, minimal punctuation, obscure acronyms, or delivered a few words at a time.</p>

<p>As an example, assume you send the following message to a Slack channel with 10 other people in it.</p>

<div><div><pre><code>anyone know the latest on cai
</code></pre></div></div>

<p>And further assume that “cai” refers to an internal project: <strong>C</strong>rusade <strong>A</strong>gainst <strong>I</strong>nitialisms. By writing in all lower case, using an initialism to refer to the project, and omitting the question mark, you’ve saved yourself two words and a handful of extra keystrokes. Under the most generous assumptions, say that translates to five seconds in savings. That’s a lot!</p>

<p>But let’s now examine the impact the shortcuts have on your 10-person audience.</p>

<ul>
  <li>Two people thought “cai” was a typo and spent several moments trying to guess what you actually meant to type before realizing you were referring to the internal project. <em>Cost: 20 seconds</em></li>
  <li>Two people didn’t know what “cai” stood for. One spent three minutes tracking it down on the internal wiki, and the other sent a private message to another team member to ask. <em>Cost: 4 minutes</em></li>
  <li>One person ignored your ask because they didn’t realize it was a question when scanning the channel. <em>Cost: Priceless</em></li>
  <li>Five people understood what you meant but still had to mentally expand the initialism before internalizing your ask. <em>Cost: 5 seconds</em></li>
</ul>

<p>Your 5 seconds of savings amounted to roughly 4.5 <em>minutes</em> of cost spread across your audience. Sure, this is a contrived example and sure there are cases where the cost is lower, but the point stands: <strong>your communication shortcuts are costly</strong>.</p>

<p>In economics, this phenomena is referred to as a negative externality.</p>

<blockquote>
  <p>A negative externality is the cost that affects a third party who did not choose to incur that cost.</p>
</blockquote>

<p>Every time you take a communication shortcut, you are inflicting a micro-externality on your audience. The more egregious the shortcut, the larger the externality; the larger your audience, the more times the externality is multiplied and the larger the overall cost.</p>

<h2 id="so-what">So what?</h2>

<p>If you’re communicating with a close friend and choose to use shorthand, you’re probably fine. Not only will your friend probably be accustomed to it (i.e. the externality will be small), but the audience is also small (i.e. the total cost will be small). In this case, it’s entirely possible your shorthand saves you more time than it costs your friend.</p>

<p>However, when you’re communicating in a one-to-many setting such as email or Slack, and particularly in a professional setting, sloppy writing<sup>[2]</sup> has real consequences. It prioritizes your time above the time of <em>every other person</em> that will be reading that message and might misinterpret your intent or tone. In aggregate, it is a net drain on productivity at your company.</p>

<p>So use proper spelling and grammar. Write out your entire thought before hitting send. Expand acronyms. Use punctuation.</p>

<p>A period, even at the end of “Do it,” communicates, “I’ve said everything I wanted to say.”</p>

<hr>

<p>[1] For the sticklers out there, this includes initialisms as well as acronyms.</p>
<p>[2] The term "sloppy" might sound harsh, but I chose it deliberately. Not everyone speaks the company language (e.g. English) natively, and for them using proper spelling or grammar might be challenging to say the least. The argument here is scoped to people who have some degree of mastery over the language but are being <em>sloppy</em> with their written communication, which is to say "careless and unsystematic; excessively casual".</p>

        </section>
      </div></div>]]>
            </description>
            <link>https://blog.mitchjlee.com/2020/your-writing-style-is-costly</link>
            <guid isPermaLink="false">hacker-news-small-sites-24827295</guid>
            <pubDate>Mon, 19 Oct 2020 15:35:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Azure DevOps vs. GitHub: which toolstack is better for software teams?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24826940">thread link</a>) | @KaiserSanchez
<br/>
October 19, 2020 | https://www.7pace.com/blog/azure-devops-vs-github | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/azure-devops-vs-github">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>As software teams, we know how important it is to have the right tool for any given job. After all, we’re the people who actually <em>build</em> the tools used for all kinds of jobs.</p>



<p>And now, as more companies make digital transformations, there’s mounting pressure to build better apps, faster. Software teams are expected to get more and more agile, which requires teamwork from development and operations teams to increase their build velocity and deliver new, better solutions —&nbsp;faster than ever before.</p>



<p>You already know that’s where DevOps practices come in. Agile methodologies are the key to delivering the constantly increasing speed and quality that’s now expected. But what DevOps tool is right for the job? When software teams have so many choices, how do they know they’re using the best tool for the job?</p>



<p>Two of the biggest names in the game are Azure DevOps and GitHub, so let’s take a look at both, their similarities and differences, pros and cons, and see which one is actually the better tool for developers.</p>



<h2>Azure DevOps vs GitHub: What are the differences?</h2>



<p>When you get down to the bare basics of each of them, Azure DevOps and GitHub Projects are both project management tools for development teams.&nbsp;</p>



<p><strong>Azure DevOps</strong> is a collection of services for teams to share their code, track their work, and deploy and ship software. Some of the products included in Azure DevOps are:</p>



<ul><li>Azure Boards</li><li>Azure Pipelines</li><li>Azure Repos</li><li>Azure Artifacts</li></ul>



<p>What sets Azure DevOps apart from the many tools available to developers and software teams is its extended features for supporting continuous delivery/integration (CI/CD). Azure DevOps comes with a pretty robust set of features, including:</p>



<ul><li>Agile tools, like kanban boards, backlogs, and scrum boards</li><li>Reporting via dashboards, widgets, and Power BI</li><li>Git, which is a free repository with unlimited private hosting and pull requests</li></ul>



<p>Azure DevOps has also long supported other Microsoft products, and offered cloud-specific development services like cloud build and cloud testing.</p>



<p>On the other hand, <strong>GitHub </strong>is a massive, open-source code repository that has long been a favorite for sharing and collaboration among teams. It features some of the best source control management the internet has to offer, along with cloud-based code sharing and social networking among an expansive community of developers all over the world.</p>



<p>While Microsoft has spent the last few years making moves to make Azure DevOps more open-source friendly, GitHub has always been designed that way. Think of it like “social coding” —&nbsp;users can work together on projects, share projects for experimentation and specialization, and use the platform to share ideas and find new collaborators.&nbsp;</p>



<p>GitHub’s list of features is also pretty stacked, including:</p>



<ul><li>Cod management in both private and public repositories</li><li>Code workflow via GitHub Actions, GitHub Packages, code reviews, pull requests, and protected branches</li><li>Excellent security and compliance tools, from customizable security alerts and automated code scanning to audit logs and LDAP</li><li>A marketplace for finding integrations like build tools, issue trackers, and more</li></ul>



<p>Both Azure DevOps and GitHub are Microsoft products, and when Microsoft acquired GitHub in 2018, it went straight to work at adding integration features that would allow Azure DevOps users to use GitHub as well. Despite how seamlessly the two toolsets can integrate now, though, there are still users who prefer one or the other. To fully understand how to choose between Azure DevOps, GitHub, or both, you need to understand the pros and cons of each.</p>



<h2>Azure Devops vs GitHub: Pros and Cons</h2>



<p>According to <a href="https://stackshare.io/stackups/azure-devops-vs-github-enterprise">reviews</a> from users, there are plenty of pros and cons to consider with both Azure DevOps and GitHub tools.&nbsp;</p>



<h3>Azure DevOps Pros and Cons</h3>



<p>Let’s start with Azure DevOps.</p>



<figure><table><tbody><tr><td><strong>Azure DevOps Pros and Cons</strong></td></tr><tr><td><strong>Pros</strong></td><td><strong>Cons</strong></td></tr><tr><td>– Complete, flexible, and powerful set of tools<br>– Huge ecosystem of extensions<br>– One-stop-shop for all tools teams need for agile methodology and DevOps<br>– Constantly improving<br>– Free for five or fewer users<br>– Supports open source</td><td>– Some users describe it as a “Jack of all trades, master of none”<br>– Expensive for large teams</td></tr></tbody></table></figure>



<h3>GitHub Pros and Cons</h3>



<p>And now for GitHub’s pros and cons.</p>



<figure><table><tbody><tr><td><strong>GitHub Pros and Cons</strong></td></tr><tr><td><strong>Pros</strong></td><td><strong>Cons</strong></td></tr><tr><td>– Constant new features useful for developers<br>– Brings social aspects into programming<br>– Fast and easy version control<br>– Industry standard for open source projects<br>– Extremely affordable</td><td>– The UI is not as simple as some other tools, meaning there can be a learning curve to use</td></tr></tbody></table></figure>



<p>As you can see, real users think both these tools have a lot of pros, and not too many cons. So which one is actually better? Let’s take a look at how they stack up in different areas.</p>



<h2>How Do Azure DevOps and GitHub Compare?&nbsp;</h2>



<p>Choosing the right tool for your team means evaluating both Azure DevOps and GitHub in a number of important areas. Here’s how they stack up against one another.</p>



<h3>Azure DevOps vs GitHub: Included Features</h3>



<p><em>Azure DevOps</em></p>



<figure><img loading="lazy" width="303" height="72" src="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p><em>GitHub</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p>When it comes to their features and capabilities, both Azure DevOps and GitHub are powerful, stacked toolsets. Both are comprehensive and feature-rich, allowing teams to share and track their projects and code, opening doors for collaboration across teams, and creating an environment for quickly building software with CI/CD in mind.</p>



<p>We’ve already discussed a lot of the features that make both Azure DevOps and GitHub stand out in a sea of tools developers can choose from, so we’ll just say this: These are both pretty comprehensive and formidable sets of tools for teams of all sizes that come with useful integrations, collaboration support, and other features that make them powerful and attractive to all software teams.</p>



<h3>Azure DevOps vs GitHub: Ease of Use</h3>



<p><em>Azure DevOps</em></p>



<figure><img loading="lazy" width="303" height="72" src="https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p><em>GitHub</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p>Both Azure DevOps and GitHub should be reasonably simple for the average software team to learn and use. They both have attractive, elegant interfaces as well as simple integrations with tools that should already be familiar to many developers.</p>



<p>It all depends on your team, though, and for some types of development, there may be a learning curve involved with either Azure DevOps or GitHub. While neither tool is <em>difficult</em> to use, they’re also not perfectly intuitive. However, to help combat this, both tools offer tutorials and courses, like GitHub’s fun <a href="https://lab.github.com/">Learning Lab</a>.</p>



<h3>Azure DevOps vs GitHub: Community Support</h3>



<p><em>Azure DevOps</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p><em>GitHub</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p>When it comes to community support, GitHub almost has to come out on top just because of the way it was designed: As a social, collaborative platform. Simply because of that, GitHub has some of the best community support there is in this industry.</p>



<p>But Azure DevOps users aren’t on their own by any means. While Azure DevOps products don’t quite have the same social support, Microsoft does have Azure DevOps virtual assistants who are available to help customers with questions. And if you need more support, you can purchase an Azure Support Plan.</p>



<h3>Azure DevOps vs GitHub: Release Rate</h3>



<p><em>Azure DevOps</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p><em>GitHub: 5/5</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p>Azure DevOps is a tool that’s been around (in many different iterations) for some time. Formerly known as Team Foundation Server (TFS) and Visual Studio Team System, Azure DevOps sees regular releases and feature additions as users’ needs shift.&nbsp;</p>



<p>Similarly, GitHub has evolved over its lifespan. It started as an online, social code repository, and has since grown into the suite of tools it contains today. Still, GitHub sees multiple new releases each month, including essentials like security updates, and new features as needed.</p>



<h3>Azure DevOps vs GitHub: Pricing</h3>



<p><em>Azure DevOps</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p><em>GitHub</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p>For many teams, the cost is a major consideration when it comes to choosing the tools you’ll use in the long-term. Both Azure DevOps and GitHub offer different pricing plans and models depending on what a team might need.</p>



<p>Azure DevOps has per-user licenses available for purchase, and also sells bundles of services or individual units of usage. The Basic Plan costs $6 per user per month, and gives your users access to Pipelines, Boards, Repos, and Artifacts. Adding Azure’s Test Plans service increases the price pretty significantly, up to $52 per user per month.</p>



<p>GitHub, on the other hand, is widely viewed to be a more affordable option. All public, open-source projects can be hosted for free, and private repository plans start at $7 per month for personal use, up to $21 per user per month for enterprise plans.</p>



<h3>Azure DevOps vs GitHub: API, Extensibility, and Third-Party Integrations</h3>



<p><em>Azure DevOps</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p><em>GitHub</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating5-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p>Both Azure DevOps and GitHub allow for interfacing with their platforms via API very seamlessly. They also both offer extensive marketplaces of third-party integrations, from your favorite chat tools like Slack and HipChat to CI/CD tools like Semaphore and Travis CI.</p>



<p>There is a wide range of outside tools that communicate well with Azure DevOps, including REST APIs, command-line tools, web-based tools, desktop client developers, and more.</p>



<p>And GitHub Apps and Actions is where users can find a similarly wide variety of tools and solutions that integrate seamlessly with GitHub.</p>



<h3>Azure DevOps vs GitHub: Security</h3>



<p><em>Azure DevOps</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p><em>GitHub: 4/5</em></p>



<figure><img loading="lazy" width="303" height="72" src="http://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png" alt="" srcset="https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs.png 303w, https://www.7pace.com/wp-content/uploads/2020/10/rating4-blog-vs-300x71.png 300w" sizes="(max-width: 303px) 100vw, 303px"></figure>



<p>And finally, there’s the question of security — a pretty important consideration for most software teams. For this, we’ll turn to some security experts: UpGuard, which <a href="https://www.upguard.com/blog/what-are-security-ratings">creates objective, data-driven security ratings</a> for online companies.&nbsp;</p>



<p>UpGuard rates Microsoft’s Azure website at <a href="https://www.upguard.com/instant-security-score/report?c=azure.microsoft.com">751 points out of 950</a>, which is a B rating.</p>



<p>GitHub is rated slightly higher at <a href="https://www.upguard.com/instant-security-score/report?c=github.com">789 points out of 950</a>, which is also a B rating.</p>



<h2>Azure DevOps vs GitHub: Which Tool Is Better?</h2>



<p>So which is better? They’re both powerful toolsets with different pros, cons, and value to add to your team. Because of that, we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.7pace.com/blog/azure-devops-vs-github">https://www.7pace.com/blog/azure-devops-vs-github</a></em></p>]]>
            </description>
            <link>https://www.7pace.com/blog/azure-devops-vs-github</link>
            <guid isPermaLink="false">hacker-news-small-sites-24826940</guid>
            <pubDate>Mon, 19 Oct 2020 14:58:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python For Feature Film]]>
            </title>
            <description>
<![CDATA[
Score 238 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24826873">thread link</a>) | @dagmx
<br/>
October 19, 2020 | https://www.gfx.dev/python-for-feature-film | <a href="https://web.archive.org/web/*/https://www.gfx.dev/python-for-feature-film">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><section><p>This post was originally part of my series on <span>Python for Feature Film</span> on <a href="http://www.dgovil.com/">my personal site</a>, but is being ported here with minor changes. The dates have been adjusted to match release dates for the projects.</p></section><p>Python is a programming language that has become integral to the movie making process over the last few years. There’s rarely an animated feature or visual effects film, if any, that hasn’t had Python play a large part in getting it to the screen</p><p>When people think about movies, even programmers often think about the artistry involved in bringing those images to life. However, the technical side of the film industry is something that often goes unnoticed outside a small group of people.</p><p>To that end, I’ve written a few blog posts about how I’ve used Python on several major films that I’ve been lucky enough to work on. Hopefully this shows how much it contributes to the entire life of a movie.</p><p>I’ve also recently released a course on <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Udemy</a> to teach artists how to learn Python For Maya since it’s becoming an increasingly valuable skill in the industry. These blog posts serve as companion material to the course as well.</p><p>With that intro out of the way let’s continue…</p><section></section><hr><h2 id="what-is-python">What is Python?</h2><p>Some of you may not be familiar with Python.</p><p>Python is a programming language designed to be very easy to read and write. It’s incredibly popular in the feature film industry as well as other groups, like mathematics, science and machine learning.</p><p>You can learn more about Python on <a href="https://www.python.org/" target="_blank" rel="noreferrer">the official website</a>.</p><p>It’s important to note that today, the film industry is largely still tied to Python 2.7. There is a concerted effort in 2020 to move over to Python 3, and
we should start seeing larger Python 3 adoption starting in 2021 and moving forward.</p><hr><h2 id="the-feature-film-pipeline">The Feature Film Pipeline</h2><p>The biggest use of Python is in our feature film pipeline.</p><p>This is an image that describes the pipeline at most major studios.
The Pipeline is the arrows that link each department together. It’s responsible for making sure that data flows between each department and that everyone can play well together.
It’s also responsible for the toolsets in each department so that the artists themselves can work efficiently, but for now lets focus on the inter-department flow.</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/a3bc4/pipeline-flow.webp 2500w,https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/39db6/pipeline-flow.webp 4098w" sizes="(max-width: 4098px) 100vw, 4098px" type="image/webp">
        <source srcset="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/412e4/pipeline-flow.png 2500w,https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/e3fe0/pipeline-flow.png 4098w" sizes="(max-width: 4098px) 100vw, 4098px" type="image/png">
        <p><img src="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/e3fe0/pipeline-flow.png" alt="A diagram illustrating the flow of a shot between departments on a feature film pipeline"></p>
      </picture>
    </span></p><figcaption>An overview of the Film Production Pipeline</figcaption></div><p>Here you can see the various stages of a visual effects film or animated feature. Studios may differ slightly from this, but it’s the general workflow.</p><p>The storyboards/footage/previs represent the data we get, and Compositing/Lighting are the last stages of the film for us.
Visual Effects Films differ slightly from animated films because you have to deal with the extra added element of film footage in the form of plates.</p><div><figcaption>A more visual demonstration of this graph is in this video of the making of Ratatouille by Pixar</figcaption></div><p>The Pipeline is responsible for getting the data between departments. Here’s the gist of how it works (though it is more organic a process than the one described):</p><ul><li>We get data from the client or story artists in form of plates, previsualization (previs) or storyboards that tell us what is happening in the scene.</li><li>Modeling look at all of this and generate 3D models of all the assets that will be required.</li><li>Rigging take the modelled assets for characters and apply a virtual skeleton to make it animatable.</li><li>Matchmove are in charge of creating virtual cameras that match the ones used to shoot the film as well as any standin characters or geometry</li><li>Layout take the rigs, and either create their own cameras or take matchmoves cameras and set up the scene. They’re the equivalent of a virtual director of photography.</li><li>The scene is then handed off to Animation, who are the equivalent of the actors. They are in charge of the movement of the characters, and bring the inanimate skeletons to life.</li><li>CharacterFX are in charge of all the technical parts of animation. Muscle simulations, making cloth move realistically, the hair, grass etc… all comes from CharacterFX.</li><li>FX then handle the non animation related effects. Whether it be destruction, fire, voxelization, etc… there’s a lot that FX is in charge of.</li><li>While this is happening, Texturing are in charge of giving color to the 3D Assets so they aren’t just grey objects.</li><li>Shading then takes these textures and gives the assets a material that tells it how light should interact with it.</li><li>Matte Painting are the department we use when it is not logical or feasible to build an environment. We realistically can only build so much, and past that point it’s more efficient to have someone make a very high quality painting instead.</li><li>This all gets funnelled into Lighting who are in charge of adding lights to the shot and rendering the image out. They also do a little bit of compositing to sweeten the image. On an animated feature this may be the end of the show.</li><li>On a visual effects show, we have to prepare the plates by either removing unwanted elements, removing noise or removing the lens warp. This is handled by Plate Prep,also known as RotoPaint.</li><li>Finally everything goes to Compositing who take all the images and integrate our CG renders into the actual film plate. On a visual effects show, this will be the last stage.</li></ul><p>We use Python to tie all these bits together.
In the next section I’ll go over publishing before moving onto describing how Python is used for the individual departments.</p><h3 id="publishing-and-asset-management">Publishing and Asset Management</h3><p>This is pretty much the core of traditional pipeline, to make sure assets can be shared between departments and be tracked.</p><p>The first part of this is Asset Publishing.</p><p>When a department deems it’s work ready, it decides to publish it so the next department in the chain can consume it. For example modeling exports models, but does animation export animation? Well that depends on who is consuming it. This is dependent on whether it needs to be interactive past this point or not.</p><p>For geometry  we often just publish as a geometry cache using Alembic  which is a industry standard developed by Imageworks and ILM so that we can have a consistent cache format.
For point cloud data, we either use Alembic or OpenVDB, for images we tend to use tiff’s or OpenEXR.
Soon the industry will probably also standardize on a universal scene format from Pixar called OpenUSD.</p><p>Anyway  the idea is to generally keep the data in the most efficient format possible, while allowing for easy interchange. Cache data is often best because you really only take an IO hit, which is cheap, versus a deformation hit, which can be very expensive.</p><p>This all gets really complex though. Artists don’t need to know where their data is coming from or going to, or even how it gets there. They just need to be able to load it in and publish it out.</p><p>This is the pipeline. We develop the UI’s and the tools to do this in a very user friendly manner.</p><div>
  <p><img src="https://www.gfx.dev/e49c8aaf611022c8415419e9f49e3d71/pyblish.gif" alt="Pyblish is a similar but open soruce frontend that is featured here for reference"></p>
    <figcaption><a href="https://github.com/pyblish/pyblish-qml">Pyblish</a> is a tool by Marcus Ottosson that is similar to many publishing tools in studios</figcaption></div><p>To publish data, the user just has to open a publish UI that will validate their assets against some tests, and then send it off to the machine farms where the conversion to one of the open formats happens.</p><p>To ingest the published data, we similarly just have an asset browser that lets the artist pick which asset they want. Often they just see a thumbnail and description. The details are irrelevant to most artists.</p><p>Because these publishing and asset management systems need to be common to multiple apps, we develop them in Python and Qt (PyQt or PySide) , which allows us to reuse our code without recompiling for each application and makes it easy to rapidly add functionality where needed.</p><p>This is common to pretty much every department, so I figure it warrants its own section here rather than repeating for each.</p><hr><h3 id="modeling">Modeling</h3><p>Modeling is the department in charge of creating the 3D source geometry used by every other department.
Often there are quite a few repetitive tasks involved in regards to placing or editing geometry, or even just managing the scene.</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/9fd6b/wireframe.webp 598w" sizes="(max-width: 598px) 100vw, 598px" type="image/webp">
        <source srcset="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/79ee7/wireframe.png 598w" sizes="(max-width: 598px) 100vw, 598px" type="image/png">
        <p><img src="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/79ee7/wireframe.png" alt="An image of the Blender susan model (a monkeys head) with a wireframe overlay to show its polygons"></p>
      </picture>
    </span></p><figcaption>A wireframe of a 3D model. This is Blender's Susan mesh.</figcaption></div><p>This is where Python comes in handy. Most 3D packages have a Python API that lets you do program everything that you would do manually.</p><p>So instead of spending 10minutes creating a simple asset, you can script it up and then just click a button when you need it next time. That 10 minutes saved really adds up, and over the course of a project you may be saving hundreds of hours that could be better focused on building more complex assets that require artistic input.</p><p>For example, in  my course  <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Python For Maya</a> I go over creating a simple gear using Python as well as creating a simple UI so that you can specify how many teeth the gear has and how long they will be.</p><p>This can get more complex though with using Python to create custom deformers or interactive tools, like this demo from Hans Godard demonstrates.</p><div><figcaption>Hans Godard has made some really interesting Python based modeling utilities.</figcaption></div><hr><h3 id="rigging">Rigging</h3><p>Rigging’s job is to create a skeleton for the character geometry so that it can deform, just like a real human would.</p><p>Of course that’s an over simplification.
Rigging is also essentially creating the interface that animators use to bring these creatures to life, but they also have to make sure that any movement happens convincingly.
If an animator moves the arm, the rigger must make sure that the shoulders deform properly.</p><p>Python plays an integral role in Rigging. Here are just some of the uses:</p><ul><li>Creating automated builds of rigs. Rather than doing everything manually, rigs can be composed using code which makes them easy to reuse.</li><li>Developing custom deformers or nodes to perform operations not native to the application.</li><li>Develop supporting scripts for animators to switch between modes or controls etc..</li></ul><p>In  my course  <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Python For Maya</a> I go over creating a controller library.
Controllers are, as the name suggests, the objects animators use to control the rig. Instead of using the geometry directly, they use controls, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gfx.dev/python-for-feature-film">https://www.gfx.dev/python-for-feature-film</a></em></p>]]>
            </description>
            <link>https://www.gfx.dev/python-for-feature-film</link>
            <guid isPermaLink="false">hacker-news-small-sites-24826873</guid>
            <pubDate>Mon, 19 Oct 2020 14:50:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I've stopped saying 'hey guys' (as a male in tech)]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24825887">thread link</a>) | @tomquirk
<br/>
October 19, 2020 | https://blog.allybot.io/post/why-i-stopped-saying-hey-guys/ | <a href="https://web.archive.org/web/*/https://blog.allybot.io/post/why-i-stopped-saying-hey-guys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p><a href="https://allybot.io/"><img src="https://allybot.io/assets/images/image02.png" alt="AllyBot logo">
</a></p></div></section><section><section id="articleHero"><div><header><div><div>
<p>October 17, 2020
• 6 min read</p></div></div></header><p><img src="https://blog.allybot.io/images/why-i-stopped-saying-hey-guys-hero.png"></p></div></section><article id="articleContent"><p>I’ll be the first to admit that I’m not an expert in diversity, equity or inclusion. I’m a white, straight, cis-gendered male software engineer from Australia. I build products, fix bugs, and enjoy a good coffee.</p><p>And I say the word ‘guys’. A lot.</p><p>So when I was told that saying ‘hey guys’ might make some people (women, in this case) feel excluded, frankly, I didn’t understand. “I say ‘guys’ all the time. How could it be an issue?” I told myself. People telling me what I can and can’t say? That doesn’t feel right. For years, I held the view that inclusive language was a threat to free speech.</p><p>But all it took was one podcast episode to change my perspective on inclusive language.</p><h2 id="free-speech-vs-inclusive-language">Free speech vs inclusive language</h2><p>My late teens and early 20’s were influenced by the so-called Intellectual Dark Web - Jordan Peterson, Joe Rogan, Sam Harris and the like. For the most part, I respect them a lot and still listen to their content to this day.</p><p>Universally, this group is not in favor of “language policing”, to put it lightly. Famously, Jordan Peterson was outspoken in his opposition to Canada’s C-16 bill, which he believed to be a threat to free speech. Peterson was specifically against the idea that he would have to address people by their preferred gender pronoun (e.g. he, her, zir, etc.). In other words, he didn’t want the government forcing him to use inclusive language. Whether or not this&nbsp;<a href="https://torontoist.com/2016/12/are-jordan-petersons-claims-about-bill-c-16-correct/">was an accurate characterization of C-16</a> is another question. But the premise that one’s choice of words could be criminalized in such a way is one that I am not in favor of.</p><p>In the years following the C-16 controversy, the world appeared to split into two camps: one that was supportive of inclusive language, and one that, passionately, was not. I mostly found myself in the second camp.</p><p>That was until a few months ago when I was listening to an&nbsp;<a href="https://frontendhappyhour.com/episodes/bartending-to-everyone-inclusive-language/">episode of the Front End Happy Hour podcast</a>&nbsp;about inclusive language. One of the hosts said something so simple, yet so incredibly insightful, that changed my mind in an instant:</p><p><em>“I question people who have asked me, “Why are we doing [inclusive language]? Like, aren’t there bigger issues to solve?”. Yes, there’s always a bigger issue to solve. But this one’s pretty easy. And it’s not that offensive.&nbsp;<strong>All you have to do is stop doing something.</strong>"</em></p><p>I am not easily offended. And so inclusive language as a concept was initially hard to comprehend. But the reality is this: it’s not up to me to tell someone what’s offensive and what’s not. All I can tell someone is what is offensive&nbsp;<em>to me.</em>&nbsp;Inclusive language is not language policing. It’s not telling someone what they can and can’t say. It’s not a violation of free speech. Inclusive language is about&nbsp;<strong><em>empathy</em>.</strong></p><h2 id="inclusive-language-in-the-remote-workplace">Inclusive language in the remote workplace</h2><p>What is often overlooked about Jordan Peterson’s views on the subject is that he is totally on board with using inclusive language in a private context. He just doesn’t want it to be legally enforced. This is an important distinction.</p><p>If you are talking to someone, and they are uncomfortable by the words you’re using, the resultant conversation is unsatisfactory. They walk away from the encounter at best annoyed, and at worst upset. If all it took to improve your relationship with this person was more inclusive language, wouldn’t it make sense to do that?</p><p>Whether you agree or not, you cannot escape the fact that <strong>inclusion is incredibly important in the workplace</strong>. Making your team feel included at work is better for everyone and everything, including your bottom line.</p><p>Inclusion becomes even harder to cultivate in a remote environment. When you’re working from home, you communicate with your team members primarily via text chat. Slack, email and Jira tickets. Text communication is notoriously hard, something that we all now appreciate in 2020. Your words can be interpreted in wildly different ways, to the point where a productive professional relationship can collapse in a matter of seconds.</p><p>Non-inclusive language generally seems to cause a more subtle, more gradual decay of workplace relationships. If I’m the only man in a team of women, and someone in our Slack channel addresses the group with ‘hey, ladies’, I’ll probably think, “Hmm, that’s odd. Doesn’t she realize I’m in this team?”. I’ll then go about my day as normal. But if this happens every day, maybe I would start to feel like I’m invisible. Like I’m not even a part of the team. Like My work is not impressive enough to be noticed. And so on.</p><p>And the worst part is, without the person reaching out to you directly, it’s impossible to know that you’ve upset someone until it’s too late. The value of their contributions declines. They stop proposing ideas in meetings. And then, they quit their job altogether.</p><p>Additionally, Slack channels are different from physical meeting rooms. You often don’t know who is actually in a given Slack channel. You might think the channel is only comprised of males and so saying ‘hey guys’ isn’t an issue. But what if you’re mistaken? Yet another challenge for inclusion in the remote workplace.</p><p><strong>The bottom line is this: inclusive language matters</strong>. When everyone on the team truly feels a part of the team, everybody wins. Conversations improve, productivity increases, and most importantly, people enjoy coming to work. And as more and more of our office communication moves to chat platforms like Slack, the importance of inclusive language has never been greater.</p><h2 id="wrapping-up">Wrapping up</h2><p>And so, I’ve stopped saying ‘hey guys’ for these reasons. And a bunch of other words and phrases. Blacklist, whitelist, psycho, crazy, disabled, the list goes on. If there’s a chance someone will feel excluded by the words I’m about to type, then I’ll choose different words.</p><p>The question then becomes, “Well, how do I know what’s inclusive or not?”. You might argue that there are so many ways someone could be offended, that it’s not a practical problem to solve. I built a <a href="https://allybot.io/">Slack app</a> to help. AllyBot will suggest inclusive alternatives to over 400 non-inclusive phrases to team members. The suggestions are private to you, giving you the opportunity to edit your message at your discretion. AllyBot is <a href="https://allybot.io/#community">free for public Slack communities and educators</a> (reach out to me at&nbsp;<a href="mailto:tom@allybot.io">tom@allybot.io</a>).</p><p>If you’re still not convinced about inclusive language, that’s okay. Thanks for reading my ramblings regardless. But next time you’re chatting on Slack, I’d ask you to stop and think, “Is someone being excluded by my choice of language?”.</p></article><section id="articleNext"></section></section></div></div>]]>
            </description>
            <link>https://blog.allybot.io/post/why-i-stopped-saying-hey-guys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825887</guid>
            <pubDate>Mon, 19 Oct 2020 12:57:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple blocks widow from honouring husband's dying wish]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24825279">thread link</a>) | @pseudolus
<br/>
October 19, 2020 | https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825279</guid>
            <pubDate>Mon, 19 Oct 2020 11:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Euler's Formula: A Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24825065">thread link</a>) | @ColinWright
<br/>
October 19, 2020 | https://mathvault.ca/euler-formula/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/euler-formula/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mathvault.ca/euler-formula/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825065</guid>
            <pubDate>Mon, 19 Oct 2020 10:49:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This page is a truly naked, brutalist HTML quine]]>
            </title>
            <description>
<![CDATA[
Score 899 | Comments 166 (<a href="https://news.ycombinator.com/item?id=24824977">thread link</a>) | @Symmetry
<br/>
October 19, 2020 | https://secretgeek.github.io/html_wysiwyg/html.html | <a href="https://web.archive.org/web/*/https://secretgeek.github.io/html_wysiwyg/html.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>One of my favorite things is to misuse technology in creative ways. Breaking the rules without breaking the rules.</p>

<p>For example, a hobby project I built long ago was <a href="https://github.com/secretGeek/dod">DOS-on-dope</a>, a working Ruby-on-rails parody, billed as <em>the last batch-file based MVC framework you'll ever need</em>. And there was <a href="http://www.secretgeek.net/console_log">a console.log() adventure</a> in which you played an old school console-adventure-game from inside the chrome developer tools.</p>

<p>The world of esoteric programming is filled with examples of people stretching the rules to breaking point, and misusing technology in creative ways. In particular (for example) I love <a href="http://wiki.secretgeek.net/quine">quines</a>. Quines are programs which output their own source code. Life is a Quine.</p>

<p>A different but somehow related topic I like is <a href="https://en.wikipedia.org/wiki/Brutalist_architecture">brutalism</a>, in particular, this often overlooked aspect:</p>

<blockquote>Another common theme in Brutalist designs is the exposure of the building's functions.</blockquote>

<p>...the tendency to <strong>make the internal external</strong>, and reveal the secrets of the building, in a somehow.... <em>brutaful</em> way. ;-).</p>

<p>A similarly intriguing idea which has fallen into disuse is the idea of <a href="https://en.wikipedia.org/wiki/Naked_objects">naked objects</a>, wherein:</p>

<blockquote>The user interface should be a direct representation of the domain objects.</blockquote>

<p>Putting all this together I decided to make a truly naked, brutalist html page, that is itself a quine. And this page is it.</p>

<p>Viewing <a href="https://raw.githubusercontent.com/secretGeek/html_wysiwyg/master/html.html">the source</a> of this page should reveal a page identical to the page you are now seeing. Nothing is hidden. It's a true "What you see is what you get."</p>

<h2>How it works.</h2>

<p>Did you know that the rules of html and css allow you to make <strong>every</strong> element visible, even elements like 'title' or 'style' or 'script', that are normally hidden from view? Those are just elements like any other. You can expose them <strong>all</strong> like so:</p>



<p>With that snippet of code (which is <strong>not</strong> a snippet of code, but an <strong>actual</strong> style block itself!) you can now see every element of this page, including that style block, the html and title tags, etc.</p>

<p>It does have one downside: every element on the page is now a "block" element, even some which should be "inline", such as "code" and "anchor" elements. We can correct this like so:</p>



<p>To give the code a more 'view source' feel, I've also applied <code>monospace</code> fonts, and a generally simple and consistent style to all elements, using a "*" selector, like so:</p>



<p>So far I've put style declarations all on one line, because ordinary html refuses to treat line breaks as "br" tags. But there is a way to make line-breaks display as line-breaks, and that is with this piece of styling:</p>



<h2>Make the internal external.</h2>

<p>The next trick is to make the internal external. We can start by ensuring that the tags themselves, such as paragraph tags, are exposed in their stark, brutal, beauty:</p>



<p>That works for "p" elements, but do we need to have custom styling for <strong>every</strong> element? If there was a way to output the "name" of a tag in html, then we could reduce all of the necessary style rules above to something like:</p>

<blockquote>
*::before {
 '&lt;' name() '&gt;'
}
</blockquote>

<p>And...

</p><blockquote>
*::after {
 '&lt;\/' name() '&gt;'
}
</blockquote>


<p>But alas there is no "name()" function (yet!). So we are forced to generate a chunk of style information like this (via <a href="https://nimbletext.com/Live/1105905186/">NimbleText</a> of course)</p>

<p>Please scroll happily past the next 28 offensively repetitive lines...</p>



<p>Some elements are a little trickier because they have attributes. Consider for example the "anchor" which often has a <code>href</code> attribute. We <em>need</em> that attribute to be visible, including its value. This is done like so:</p>



<p>The <code>attr()</code> function, see <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/attr">mozilla docs</a> is a nifty trick, "supported" since CSS 2.</p>


<p>The only other style that is special is "style" itself, which has to include an escape character to avoid being taken literally.</p>







<p>Finally to reduce the visual weight of the before and after pseudo elements we can give them a soft purple color and a low weight font:</p>





<p>Finally, because I believe brutalist design, even when applied to truly naked brutal html quines, is about function, not about deliberate ugliness, I'd like to apply these humble styles that improve the readability of this brutiful missive.</p>



<p>...they're derived from <a href="https://jrl.ninja/etc/1/">"58 bytes of css to look great nearly everywhere"</a>.</p>

<p>One last thing. Although this idea has bounced around in my head for a decade, the thing that reminded me to pipe it into a file was seeing this piece of "Code as Art" from Geoff Huntley: <a href="https://noyaml.com/">no yaml</a>. Bring back the world weird web.</p>

<p>Kind regards</p>
<p><a href="http://secretgeek.net/">Leon</a></p>

<p>p.s. <a href="https://github.com/secretGeek/html_wysiwyg/">source code here</a></p>



</div>]]>
            </description>
            <link>https://secretgeek.github.io/html_wysiwyg/html.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24824977</guid>
            <pubDate>Mon, 19 Oct 2020 10:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Film-strip A custom element for the web that shows the frames of a video file]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24823888">thread link</a>) | @plurby
<br/>
October 18, 2020 | https://pshihn.github.io/film-strip/ | <a href="https://web.archive.org/web/*/https://pshihn.github.io/film-strip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>A custom element for the web that shows the frames of a video file. Once can choose the cell size of each frame
      and the frame rate to sample the video at.</p>
    <p>
      In HTML simply add:
      <label>&lt;film-strip
        src="./sample.mp4"&gt;&lt;/film-strip&gt;</label>
    </p>
    <p>It's less than 3KB in size when gzipped. The code and documentation is available <a href="https://github.com/pshihn/film-strip">on Github</a>.</p>
  </div></div>]]>
            </description>
            <link>https://pshihn.github.io/film-strip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24823888</guid>
            <pubDate>Mon, 19 Oct 2020 06:54:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I learned to Shut Up when Learning]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24823795">thread link</a>) | @docuru
<br/>
October 18, 2020 | https://hieunc.com/posts/Injmpe77TRe-i-learned-to-shut-up-when-learning | <a href="https://web.archive.org/web/*/https://hieunc.com/posts/Injmpe77TRe-i-learned-to-shut-up-when-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="str-vOKpYe5nW" data-connect-field="content"><p>In 2014, I participated in a national Web Design and Development contest. As a developer student, a design teacher volunteered to help me with the design aspect. When I first met her, she offered to review one of my designs in class.</p><p>My taste of design was influenced by flashy drafts online, especially from Dribbble. Not understand much of its effectiveness, I thought having a huge footer was solid and cool.</p><p>But the teacher pointed out it wasn't suitable for my design. Since it was an app, with the page's max height is the browser's height. A big element tells the viewers "this is important", while in fact, the content was the important part.</p><p>I didn't understand the point at the time, and persistently explaining why I used a huge footer. It was the last time I saw her. She quit helping me.&nbsp;</p><p>A few years later, when thinking back, I realized it was a mistake.</p><p>Paul Graham — a founder of Y Combinator, mentioned when giving advice, good startups' try not to confront it. Their responses are "we already tried it", or "from speaking to our users that isn't what they'd like" ¹</p><p>There is a thin line between explaining and talking back. It's different from each person's perspective and often misunderstands. When giving advice, people might feel unappreciated receiving a talkback. Some will respond to the stubborn, or they might not. Some will eventually quit.</p><p>Later on, unless when not looking for advice, I try to shut up and listen more.</p><hr><p>Cover photo by <a href="https://unsplash.com/@linkedinsalesnavigator">LinkedIn Sales Navigator</a></p><p>[1] — <a href="http://www.paulgraham.com/word.html">Paul Graham - A Word to the Resourceful (see footnote)</a></p></div></div>]]>
            </description>
            <link>https://hieunc.com/posts/Injmpe77TRe-i-learned-to-shut-up-when-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-24823795</guid>
            <pubDate>Mon, 19 Oct 2020 06:32:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with Lambda Calculus]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24823602">thread link</a>) | @mmphosis
<br/>
October 18, 2020 | https://stopa.io/post/263 | <a href="https://web.archive.org/web/*/https://stopa.io/post/263">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p>In 1935, a gentleman called Alonzo Church came up with a simple scheme that could compute…just about anything. His scheme was called Lambda Calculus. It was a phenomenal innovation, given that there weren’t even computers for him to test out his ideas. Even cooler is that those very ideas affect us today: anytime you use a function, you owe a hat tip to Mr. Church. </p><p>Lambda Calculus is so cool that many hackers use it as their secret handshake — a “discreet signal” if you will. The most famous, of course, is PG’s Y Combinator. In this essay, we’ll find out what it’s all about, and do things with functions that we’d never have imagined. In the end you’ll have built just about every programming concept: numbers, booleans, you name it…just with functions.</p><p>City dwellers who drive SUVs rarely consider their cars as ferocious machines that traverse rocky deserts and flooded rivers. It’s the same with programmers and functions. Here’s what we <em>think</em> functions do:</p><pre><code><span>(</span><span>def</span><span> square (</span><span>fn</span><span> [x] (</span><span>*</span><span> x x)))</span></code></pre><p>Safe, clean, and useful. We’re so accustomed that it would surprise us to find the myriad of ways we can bend functions to do just about anything. </p><p>Let’s step out into the wilderness a bit. Say you wanted to make a data structure for pairs: </p><pre><code><span>(</span><span>def</span><span> pair (</span><span>make-pair</span><span> </span><span>0</span><span> </span><span>1</span><span>))</span>
<span>(</span><span>first</span><span> pair) </span><span>; =&gt; 0</span>
<span>(</span><span>second</span><span> pair) </span><span>; =&gt; 1</span></code></pre><p>How would you do it? It’s sensible to use a map or a class or a record to represent a pair. But…you could use functions too.</p><p>Here’s one way we can make a pair:</p><pre><code><span>(</span><span>def</span><span> church-pair (</span><span>fn</span><span> [a b]</span>
<span>                   (</span><span>fn</span><span> [selector]</span>
<span>                     (</span><span>selector</span><span> a b))))</span></code></pre><p>No maps or classes…it just returns a function! </p><pre><code><span>(</span><span>def</span><span> ex-pair (</span><span>church-pair</span><span> </span><span>0</span><span> </span><span>1</span><span>))</span>
<span>ex-pair</span>
<span>; =&gt; #object[church_factorial$church_pair...</span></code></pre><p>Now  our <code>ex-pair</code> takes a <code>selector</code> argument. What if we ran ex-pair with this selector:</p><pre><code><span>(</span><span>ex-pair</span><span> (</span><span>fn</span><span> [a b] a))</span></code></pre><p>Well, <code>(ex-pair (fn [a b] a))</code> would expand too: </p><pre><code><span>((</span><span>fn</span><span> [a b] a) a b)</span></code></pre><p>Which would return… <code>a</code>! </p><p>That just gave us the <code>first</code> value of our pair! We can use that to write a <code>church-first</code> function:</p><pre><code><span>(</span><span>def</span><span> take-first-arg (</span><span>fn</span><span> [a b] a))</span>
<span>(</span><span>def</span><span> church-first (</span><span>fn</span><span> [pair]</span>
<span>                    (</span><span>pair</span><span> take-first-arg)))</span></code></pre><pre><code><span>(</span><span>church-first</span><span> ex-pair)</span>
<span>; =&gt; 0</span></code></pre><p>And do something similar for second: </p><pre><code><span>(</span><span>def</span><span> take-second-arg (</span><span>fn</span><span> [a b] b))</span>
<span>(</span><span>def</span><span> church-second (</span><span>fn</span><span> [pair]</span>
<span>                     (</span><span>pair</span><span> take-second-arg)))</span></code></pre><pre><code><span>(</span><span>church-second</span><span> ex-pair)</span>
<span>; =&gt; 1</span></code></pre><p>We just used functions to represent pairs. Now, since the grammar for Lisp is just a bunch of pairs plopped together, that also means we can represent the grammar of Lisp…with just functions!</p><p>What we just did was analogous to a city dweller driving their SUV…on a snowy day. It gets a <em>lot</em> crazier. </p><p>We said we could represent <em>everything</em>. Let’s go ahead and try it! </p><p>Here’s what can do. Let’s take a function we know and love, and implement it from top-to-bottom in Lambda Calculus.</p><p>Here’s factorial: </p><pre><code><span>(</span><span>defn</span><span> factorial-clj [n]</span>
<span>  (</span><span>if</span><span> (</span><span>zero?</span><span> n)</span>
<span>    </span><span>1</span><span> </span>
<span>    (</span><span>*</span><span> n (</span><span>factorial-clj</span><span> (</span><span>dec</span><span> n)))))</span></code></pre><pre><code><span>(</span><span>factorial-clj</span><span> </span><span>5</span><span>)</span>
<span>; =&gt; 120</span></code></pre><p>By the end of this essay, we’ll have built factorial, only with functions.</p><p>To do this, I want to come up front and say I am cheating a little bit. In Church’s Lambda Calculus, there is no <code>def</code>, and all functions take one argument. Here’s all he says: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk2Mzc4MjA4LTc0M2VkMDgwLTExNTgtMTFlYi05YTI2LTFlMGUyOWFmNDQ0MC5wbmc" alt="image"></span></p><p>In his rules, you define anonymous functions by popping a little <code>λ</code> in front. What follows is the argument, following by a  <code>.</code> .After the <code>.</code> is the application.</p><p>This is very much akin to a single-argument anonymous function in Clojure: <code>λ x. x</code> =&gt; <code>(fn [x] x)</code></p><p>We could follow those rules, but writing factorial like that is going to get hard to reason about very quickly. Let’s tweak the rules just a little bit. The changes won’t affect the essence of Lambda Calculus but will make it easier for us to think about our code. Here it goes:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk2Mzc4MjE3LTc5OWMxYjAwLTExNTgtMTFlYi05N2U5LWY0ZDIxZGE2YmJkOC5wbmc" alt="image"></span></p><p>1<!-- -->)<!-- --> for a single argument function, <code>(fn [x] x)</code> maps pretty well to Church’s encoding. We can go ahead and use it as is.</p><p>2<!-- -->)<!-- --> Since Church’s lambdas only take one argument, For him to express a function with two arguments, he has to write <em>two</em> anonymous functions: </p><pre><code><span>(</span><span>λ</span><span> f. λ x. f x)</span></code></pre><p>This would map to:</p><pre><code><span>(</span><span>fn</span><span> [f] (</span><span>fn</span><span> [x] (</span><span>f</span><span> x))</span></code></pre><p>But, nesting our functions like this can get annoying in Clojure <sup>1</sup>. To make life easier for us, we’ll allow for multi-argument functions:</p><pre><code><span>(</span><span>fn</span><span> [f x] (</span><span>f</span><span> x))</span></code></pre><p>3<!-- -->)<!-- --> Finally, Church has no concepts of variables outside of what’s provided by a function definition. </p><p>For him to express </p><pre><code><span>(</span><span>make-pair</span><span> a b)</span></code></pre><p>He would have to “unwrap” <code>make-pair</code></p><pre><code><span>((</span><span>λ</span><span> a. λ b. λ selector . selector a b)</span>
<span> a b)</span></code></pre><p>To keep our code sane, we’ll allow for <code>def</code>, but with one rule: </p><p><strong>You can use</strong> <strong><code>def</code></strong> <strong>, as long as you can “replace” it with an anonymous function and nothing breaks.</strong> </p><p>For example, imagine if <code>make-pair</code> <em>referenced itself</em>:</p><pre><code><span>(</span><span>def</span><span> make-pair (</span><span>fn</span><span> [a b]</span>
<span>                 (</span><span>make-pair</span><span> ...)))</span></code></pre><p>This would break because if we replaced <code>(def make-pair …)</code> with an anonymous function, there would be no variable called <code>make-pair</code> anymore! </p><p>That’s it, these are our rules. With that, we’re ready to make factorial! </p><p>The first thing we need is the concept of a number. How can we do that? </p><p>Church thought of a pretty cool idea. What if “numbers”, where higher-order functions with two arguments:  a function <code>f</code>, and a value <code>v</code>.</p><pre><code><span>(</span><span>def</span><span> zero (</span><span>fn</span><span> [f v] v))</span>
<!-- -->
<span>(</span><span>def</span><span> one (</span><span>fn</span><span> [f v]</span>
<span>           (</span><span>f</span><span> (</span><span>zero</span><span> f v))))</span>
<!-- -->
<span>(</span><span>def</span><span> two (</span><span>fn</span><span> [f v]</span>
<span>           (</span><span>f</span><span> (</span><span>one</span><span> f v))))</span></code></pre><p><strong>We can figure out what number each function represents by “counting” the number of times</strong> <strong><code>f</code></strong> <strong>was composed.</strong> </p><p>For example, 0 would compose <code>f</code> zero times: it would just return <code>v</code>.  1, would compose f once: <code>(f v)</code>. 2 would compose twice: <code>(f (f v))</code>, and so on. </p><p>To help us see these numbers in our REPL, let’s create a quick converter function: </p><pre><code><span>(</span><span>defn</span><span> church-numeral-&gt;int [church-numeral]</span>
<span>  (</span><span>church-numeral</span><span> inc </span><span>0</span><span>))</span></code></pre><p>Since a church numeral composes <code>f</code> the number of times it is called with <code>v</code> as the first argument, all we need to see what number it is in Clojure, is to provide <code>inc</code> as <code>f</code> and <code>0</code> as <code>v</code>! Now <code>2</code> would do <code>(inc (inc 0))</code> for example, and get us the corresponding Clojure number.</p><pre><code><span>(</span><span>map</span><span> church-numeral-&gt;int [zero one two])</span>
<span>; =&gt; (0 1 2)</span></code></pre><p>Cool! </p><p>Take a look at how we wrote two: </p><pre><code><span>(</span><span>def</span><span> two (</span><span>fn</span><span> [f v]</span>
<span>           (</span><span>f</span><span> (</span><span>one</span><span> f v))))</span></code></pre><p>What we did here,  is <em>delegate</em> f’s composition to the numeral before (in this case <code>one</code> ), and then just called <code>f</code> <em>one more time.</em> </p><p>What if we abstracted the <code>one</code> out?</p><pre><code><span>(</span><span>def</span><span> church-inc</span>
<span>  (</span><span>fn</span><span> [church-numeral]</span>
<span>    (</span><span>fn</span><span> [f v]</span>
<span>      (</span><span>f</span><span> (</span><span>church-numeral</span><span> f v))))) </span></code></pre><p>Voila. Give this function a numeral, and it will return a new numeral that calls <code>f</code> <em>one more time</em>. We’ve just discovered <code>inc</code>! </p><pre><code><span>(</span><span>church-numeral-&gt;int</span><span> (</span><span>church-inc</span><span> (</span><span>church-inc</span><span> one)))</span>
<span>=&gt; </span><span>3</span></code></pre><p>Cool.</p><p>Now that we have this function, we can also write a quick helper to translate Clojure numbers to these numbers:</p><pre><code><span>(</span><span>def</span><span> int-&gt;church-numeral</span>
<span>  (</span><span>fn</span><span> [clojure-int]</span>
<span>    (</span><span>if</span><span> (</span><span>zero?</span><span> clojure-int)</span>
<span>      zero</span>
<span>      (</span><span>church-inc</span><span> (</span><span>int-&gt;church-numeral</span><span> (</span><span>dec</span><span> clojure-int))))))</span></code></pre><pre><code><span>(</span><span>church-numeral-&gt;int</span><span> (</span><span>int-&gt;church-numeral</span><span> </span><span>5</span><span>))</span>
<span>=&gt; </span><span>5</span></code></pre><p>That’ll come in handy for our REPL.</p><p>Next up, we need a way to “decrement” a number. Well, with <code>inc</code> we create a numeral that composes <code>f</code> <em>one more time</em>. If we can make some kind of function that composes <code>f</code> <em>one less time,</em> then we’d have <code>dec</code>! </p><p>To do that, we’ll need to go on a short diversion.</p><p>Remember our <code>pair</code> data structure? Let’s create a function for it (we’ll use this in just a moment below): <code>shift-and-inc</code>.  All it would do, is take pair of numbers, and “shift” the pair forward by one:</p><p>For example, applying <code>shift-and-inc</code> to <code>(0 1)</code>,  would produce <code>(1 2)</code>. One more time, it would produce <code>(2 3)</code>, and so on. </p><p>Sounds simple enough: </p><pre><code><span>(</span><span>def</span><span> shift-and-inc (</span><span>fn</span><span> [pair]</span>
<span>                     (</span><span>church-pair</span>
<span>                       (</span><span>church-second</span><span> pair)</span>
<span>                       (</span><span>church-inc</span><span> (</span><span>church-second</span><span> pair)))))</span></code></pre><p>Bam, we take a pair. The second item is shifted over to the first positions and is replaced with its <code>inc</code>ed friend. Let’s try it out:</p><pre><code><span>(</span><span>let</span><span> [p (</span><span>shift-and-inc</span><span> (</span><span>church-pair</span><span> one two))]</span>
<span>  (</span><span>map</span><span> church-numeral-&gt;int [(</span><span>church-first</span><span> p) (</span><span>church-second</span><span> p)]))</span>
<span>; =&gt; (2 3)</span></code></pre><p>Works like a charm!</p><p>Now that we have <code>shift-and-inc</code>, what if we did this: </p><pre><code><span>(</span><span>def</span><span> church-dec</span>
<span>  (</span><span>fn</span><span> [church-numeral]</span>
<span>    (</span><span>church-first</span>
<span>      (</span><span>church-numeral</span><span> shift-and-inc</span>
<span>                      (</span><span>church-pair</span><span> zero zero)))))</span></code></pre><p>Remember that our <code>church-numeral</code> would call <code>shift-and-inc</code> N times, representing its numeral value. If we started with a pair <code>(0, 0)</code>, then what would the result b, if we composed <code>shift-and-inc</code> <code>N</code> times?</p><p>Our result would be the pair <code>(N-1, N)</code>. This means that if we take the first part of our pair, we have <code>dec</code>! </p><pre><code><span>(</span><span>church-numeral-&gt;int</span><span> (</span><span>church-dec</span><span> (</span><span>int-&gt;church-numeral</span><span> </span><span>10</span><span>)))</span>
<span>; =&gt; 9</span></code></pre><p>Nice.</p><p>Next up, multiplication. Say we multiply <code>a</code> by <code>b</code>. We’d need to produce a church numeral that composes <code>f</code>, <code>a * b</code> times. To do that, we can leverage the following idea:</p><p>Say we made a function <code>g</code>, which composes <code>f</code> <em>b</em> times. If we fed that function to <code>a</code>, it would call <code>g</code>, <em>a</em> times.  </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk2Mzc4MjI2LTdmOTFmYzAwLTExNTgtMTFlYi05MmY2LTVlZDdhNzA0YWE1MC5wbmc" alt="image"></span></p><p>If <code>a</code> was “2” and “b” was 3, how many times would <code>f</code> get composed? Well, <code>g</code> would be composed twice. Each time <code>g</code> is composed, <code>f</code> is composed 3 times. That comes out to a total of 6 times!</p><p>Bam, if we did that, it would represent multiplication.</p><pre><code><span>(</span><span>def</span><span> church-*</span>
<span>  (</span><span>fn</span><span> [num-a num-b]</span>
<span>    (</span><span>fn</span><span> [f v]</span>
<span>      (</span><span>num-a</span><span> (</span><span>partial</span><span> num-b f) v))))</span></code></pre><p>Here, <code>(partial num-b f)</code> represents our <code>g</code> function. </p><pre><code><span>(</span><span>church-numeral-&gt;int</span>
<span>    (</span><span>church-*</span><span> (</span><span>int-&gt;church-numeral</span><span> </span><span>5</span><span>) (</span><span>int-&gt;church-numeral</span><span> </span><span>5</span><span>)))</span>
<span>=&gt; </span><span>25</span></code></pre><p>Works like a charm! </p><p>We’ve got numbers, we’ve got <code>*</code> and we’ve got <code>dec</code>. Next up…booleans! </p><p>To do this, we need to be creative about what <code>true</code> and <code>false</code> is. </p><p>Let’s say this. Booleans are two argument functions: </p><pre><code><span>(</span><span>def</span><span> church-true (</span><span>fn</span><span> [</span><span>when-true</span><span> </span><span>when-false</span><span>]</span>
<span>                   </span><span>when-true</span><span>))</span>
<!-- -->
<span>(</span><span>def</span><span> church-false (</span><span>fn</span><span> [</span><span>when-true</span><span> </span><span>when-false</span><span>]</span>
<span>                    </span><span>when-false</span><span>))</span></code></pre><p>They take a “true” case and a “false” case. Our <code>church-true</code> function would return the true case, and <code>church-false</code> function would return the false case. </p><p>That’s it. Surprisingly this is enough to handle booleans. Here’s how we could convert them to Clojure bools.</p><pre><code><span>(</span><span>defn</span><span> church-bool-&gt;bool [church-bool]</span>
<span>  (</span><span>church-bool</span><span> </span><span>true</span><span> </span><span>false</span><span>))</span></code></pre><p>Our <code>church-true</code> would return the first argument (true), and our <code>church-false</code> would return the second one! </p><pre><code><span>(</span><span>church-bool-&gt;bool</span><span> church-true)</span>
<span>; =&gt; true</span>
<span>(</span><span>church-bool-&gt;bool</span><span> church-false)</span>
<span>; =&gt; false</span></code></pre><p>Do they look familiar? …</p></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/263">https://stopa.io/post/263</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/263</link>
            <guid isPermaLink="false">hacker-news-small-sites-24823602</guid>
            <pubDate>Mon, 19 Oct 2020 05:41:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing a Wing]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24823550">thread link</a>) | @hardmaru
<br/>
October 18, 2020 | https://greydanus.github.io/2020/10/14/optimizing-a-wing/ | <a href="https://web.archive.org/web/*/https://greydanus.github.io/2020/10/14/optimizing-a-wing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <div>

  

  <article>
  <p><i>(My last post in a series about human flight; <a target="_blank" href="https://greydanus.github.io/2020/10/12/story-of-flight/">post 1</a>, <a target="_blank" href="https://greydanus.github.io/2020/10/13/stepping-stones/">post 2</a>).</i></p>



<div>
    <p><img alt="" src="https://greydanus.github.io/assets/optimizing-a-wing/wing_shape.png" onclick="toggleWingShape()" id="wingShapeImage">
    <img alt="" src="https://greydanus.github.io/assets/optimizing-a-wing/wing_flow.png" onclick="toggleWingFlow()" id="wingFlowImage"></p><div><p><b>Figure 1:</b> In this post, we'll simulate a wind tunnel, place a rectangular occlusion in it, and then use gradient descent to turn it into a wing. </p><p>[The images above are videos. Click them to pause or play.]</p></div>
</div>



<p>Legos are an excellent meta-toy in that they represent the potential for a near-infinite number of toys depending on how you assemble them. Each brick has structure. But each brick is only interesting to the extent that it can combine with other bricks, forming new and more complex structures. So in order to enjoy Legos, you have to figure out how they fit together and come up with a clever way of making the particular toy you have in mind. Once you have mastered a few simple rules, the open-ended design of Lego bricks lets you build anything you can imagine.</p>

<p>Our universe has the same versatile structure. It seems to run according to just a few simple forces, but as those forces interact, they give rise to intricate patterns across many scales of space and time. You see this everywhere you look in nature – in the fractal design of a seashell or the intricate polities of a coral. In the convection of a teacup or the circulation of the atmosphere. And this simple structure even determines the shape and behavior of man’s most complicated flying machines.</p>

<p>To see this more clearly, we are going to start from the basic physical laws of airflow and use them to derive the shape of a wing.<sup id="fnref:fn18" role="doc-noteref"><a href="#fn:fn18">1</a></sup> Since we are using so few assumptions, the wing shape we come up with will be as fundamental as the physics of the air that swirls around it. This is pretty fundamental. In fact, if an alien species started building flying machines on another planet, they would probably converge on a similar shape.</p>

<h3 id="navier-stokes">Navier-Stokes</h3>

<p>We will begin this journey with the <a href="https://www.britannica.com/science/Navier-Stokes-equation">Navier-Stokes equation</a>, which sums up pretty much everything we know about fluid dynamics. It describes how tiny fluid parcels interact with their neighbors. The process of solving fluid dynamics problems comes down to writing out this equation and then deciding which terms we can safely ignore. In our case, we would like to simulate the flow of air through a wind tunnel and then use it to evaluate various wing shapes.</p>

<p>Since the pressure differences across a wind tunnel are small, one of the first assumptions we can make is that air is incompressible. This lets us use the <a href="https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equations#Incompressible_flow">incompressible form</a> of the Navier-Stokes equation:</p>

<p><span id="longEqnWithSmallScript_A">
\(\underbrace{\frac{\partial \mathbf{u}}{\partial t}}_{\text{velocity update}} ~=~ - \underbrace{(\mathbf{u} \cdot \nabla)\mathbf{u}}_{\text{self-advection}} ~+~ \underbrace{\nu \nabla^2 \mathbf{u}}_{\text{viscous diffusion}} \\
~+~ \underbrace{f}_{\text{velocity $\uparrow$ due to forces}}\)
</span>
<span id="longEqnWithLargeScript_A">
\(\underbrace{\frac{\partial \mathbf{u}}{\partial t}}_{\text{velocity update}} ~=~ - \underbrace{(\mathbf{u} \cdot \nabla)\mathbf{u}}_{\text{self-advection}} ~+~ \underbrace{\nu \nabla^2 \mathbf{u}}_{\text{viscous diffusion}} ~+~ \underbrace{f}_{\text{velocity $\uparrow$ due to forces}}\)
</span></p>

<p>Another term we can ignore is viscous diffusion. Viscous diffusion describes how fluid parcels distribute their momenta due to sticky interactions with their neighbors. We would say that a fluid with high viscosity is “thick”: common examples include molasses and motor oil. Even though air is much thinner, viscous interactions still cause a layer of slow-moving air to form along the surface of an airplane wing. However, we can ignore this boundary layer because its contribution to the aerodynamics of the wing is small compared to that of self-advection.</p>

<p>The final term we can ignore is the forces term, as there will be no forces on the air once it enters the wind tunnel. And so we are left with but a hair of the original Navier-Stokes hairball:</p>

\[\underbrace{\frac{\partial \mathbf{u}}{\partial t}}_{\text{velocity update}} = \underbrace{- (\mathbf{u} \cdot \nabla)\mathbf{u}}_{\text{self-advection ("velocity follows itself")}}\]

<p>This simple expression describes the effects that really dominate wind tunnel physics. It says, intuitively, that “the change in velocity over time is due to the fact that velocity follows itself.” So the entire simulation comes down to two simple rules:</p>

<ul>
	<li>
		• Rule 1: Velocity follows itself <p>(+)</p>
		<ul>
		
		</ul>
	</li>
	<li>
		<!-- <b>Rule 1: Velocity follows itself</b> -->
		• Rule 2: Volume is conserved <p>(+)</p>
		<ul>
		
		</ul>
	</li>
</ul>

<p>By alternating between these two rules, we can iteratively 1) move the system forward in time and 2) enforce conservation of volume and mass. In practice, we implement each rule as a separate function and then apply both functions to the system at every time step. This allows us to simulate, say, a gust of wind passing through the wind tunnel. But before we can direct this wind over a wing, we need to decide how to represent the wing itself.</p>

<h3 id="representing-the-wing">Representing the Wing</h3>

<div>
<p>The wing is an internal boundary, or occlusion, of the flow. A good way to represent an occlusion is with a mask of zeros and ones. But since the goal of our wind tunnel is to try out different wing shapes, we need our wing to be continuously deformable. So we will allow the mask to take on continuous values between zero and one, making it semi-permeable in proportion to its mask values. This lets us add semi-permeable obstructions to the wind tunnel as shown:</p> <p>(+)</p>
</div>



<div>
  <div>
    <p><img src="https://greydanus.github.io/assets/optimizing-a-wing/mask/mask_0.00.png"></p><p>Mask = 0.0</p>
  </div>
    <div>
    <p><img src="https://greydanus.github.io/assets/optimizing-a-wing/mask/mask_0.05.png"></p><p>Mask = 0.05</p>
  </div>
    <div>
    <p><img src="https://greydanus.github.io/assets/optimizing-a-wing/mask/mask_0.12.png"></p><p>Mask = 0.12</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/optimizing-a-wing/mask/mask_0.50.png"></p><p>Mask = 0.5</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/optimizing-a-wing/mask/mask_1.00.png"></p><p>Mask = 1.0</p>
  </div>
</div>

<h3 id="choosing-an-objective">Choosing an Objective</h3>

<p>Now we are at the point where we can simulate how air flows over arbitrary, semi-permeable shapes. But in order to determine which of these shapes makes a better wing, we still need to define a measure of performance. There are many qualities that one could look for in a good wing, but we will begin with the most obvious: it should convert horizontal air velocity into upward force as efficiently as possible. We can measure this ability using something called the lift-drag ratio where “lift” measures the upward force generated by the wing and “drag” measures the frictional forces between the air and the wing. Since “change in downward airflow” in the tunnel is proportional to the upward force on the wing, we can use it as a proxy for lift. Likewise, “change in rightward airflow” is a good proxy for the drag forces on the wing. With this in mind, we can write out the objective function as</p>

\[\max_{\theta} L/D\]

<p>where \(\theta\) represents some tunable parameters associated with the shape of the wing mask and \(L/D\) can be obtained using the initial and final wind velocities of the simulation according to</p>

\[\begin{align}
     L/D &amp;= \frac{\text{lift}}{\text{drag}}\\
    &amp;= \frac{\text{change in downward airflow}}{-\text{change in rightward airflow}}\\
    &amp;= \frac{ -\big ( v_y(t)-v_y(0) \big )}{-\big ( v_x(t)-v_x(0) \big )}\\
    &amp;= \frac{ v_y(t)-v_y(0) }{ v_x(t)-v_x(0)}
\end{align}\]

<p>Solving this optimization problem will give us a wing shape that generates the most efficient lift possible. In other words, we new have the correct problem setup; what remains is to figure out how to solve it.</p>

<h3 id="optimization">Optimization</h3>

<div>
<p>We are going to solve this problem with gradient ascent. Gradient ascent is simple and easy to implement, but there is one important caveat: we need a way to efficiently compute the gradient of the objective function with respect to the wing mask parameters. This involves differentiating through each step of the fluid simulation in turn – all of the way back to the initial conditions. This would be difficult to implement by hand, but fortunately there is a tool called <a href="https://github.com/HIPS/autograd">Autograd</a> which can perform this back-propagation of gradients automatically. We will use Autograd to compute the gradients of the mask parameters, move the mask parameters in that direction, and then repeat this process until the lift-drag ratio reaches a local maximum.</p> <p>(+)</p>
</div>



<p>So let’s review. Our goal is to simulate a wind tunnel and use it to derive a wing shape. We began by writing down the general Navier-Stokes equation and eliminating irrelevant terms: all of them but self-advection. Next, we figured out how to represent a wing shape in the tunnel using a continuously-deformable occlusion. Finally, we wrote down an equation for what a good wing should do and discussed how to optimize it. Now it is time to put everything together in about two hundred lines of code and see what happens when we run it…</p>

<p><img alt="" src="https://greydanus.github.io/assets/optimizing-a-wing/optimize_wing.png">
</p>

<div>
	<p>Final result</p> <p>[Click image to pause or play.]</p>
	<p><img alt="" src="https://greydanus.github.io/assets/optimizing-a-wing/wing.png" onclick="toggleBasicWing()" id="basicWing">
</p></div>

<p>Sure enough, we get a beautiful little wing. Of all possible shapes, this is the very best one for creating efficient lift in our wind tunnel. This wing is definitely a toy solution since our simulation is coarse and not especially accurate. However, after making a few simple improvements we would be able to design real airplane wings this way. We would just need to:</p>

<ol>
  <li>Simulate in 3D instead of 2D</li>
  <li>Use a mesh parameterization instead of a grid</li>
  <li>Make the flow laminar and compressible</li>
</ol>

<p>Aside from these improvements, the overall principle is much the same. In both cases, we write down some words and symbols, turn them into code, and then use the code to shape our wing.<sup id="fnref:fn14" role="doc-noteref"><a href="#fn:fn14">2</a></sup> The fact that we can do all of this without ever building a physical wing makes it feel a bit like magic. But this process really works, for when we <a href="http://aero-comlab.stanford.edu/Papers/jameson-cincin-pm.pdf#page=36">put these wings on airplanes</a> and trust them with our lives, they carry us safely to our destinations.<sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3">3</a></sup> <sup id="fnref:fn17" role="doc-noteref"><a href="#fn:fn17">4</a></sup></p>

<p>Just like the real wind tunnels of the twentieth century, these simulated wind tunnels need to go through lots of debugging before we can trust them. In fact, while building this demo we discovered a number of ways that things can go wrong. Here are some of the most amusing failure cases:</p>

<p><img src="https://greydanus.github.io/assets/optimizing-a-wing/sim_bloopers.png">
</p>

<p>Several of these wings are just plain dreadful. But others seem reasonable, if unexpected. The two-wing solution is particularly amusing. We did not intend for this “biplane” solution to occur, and yet it is a completely viable way of solving the objective we wrote down. One advantage to keeping the problem setup so …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greydanus.github.io/2020/10/14/optimizing-a-wing/">https://greydanus.github.io/2020/10/14/optimizing-a-wing/</a></em></p>]]>
            </description>
            <link>https://greydanus.github.io/2020/10/14/optimizing-a-wing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24823550</guid>
            <pubDate>Mon, 19 Oct 2020 05:27:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Online Commenting]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24823541">thread link</a>) | @Rohitha_Perera
<br/>
October 18, 2020 | https://talk.hyvor.com/blog/future-of-online-commenting/ | <a href="https://web.archive.org/web/*/https://talk.hyvor.com/blog/future-of-online-commenting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span></span>
<span>154</span>
</p>
<p>Technology has become as pervasive as the air we breathe today. While our reliance on technology keeps on increasing, there are a myriad of problems that complement the acceptance of these solutions for inconvenience. For instance, social media may have started as a force for good, but it possibly has <a href="https://www.theguardian.com/commentisfree/2020/sep/19/the-social-dilemma-a-wake-up-call-for-a-world-drunk-on-dopamine">devolved into a state of dysfunction</a>, one that is all about <a href="https://www.theguardian.com/technology/2019/jan/20/shoshana-zuboff-age-of-surveillance-capitalism-google-facebook">surveillance capitalism</a>. Likewise, online commenting may have built a degree of community and credibility over the years, but it has also led to a vast array of problems like online toxicity, <a href="https://www.salon.com/2017/08/05/why-facebooks-racism-problem-might-never-be-solved/">online disinhibition</a> and misogyny.&nbsp;</p>
<p>I believe it was Albert Einstein who adroitly stated that — <em>It has become appallingly obvious that our technology has exceeded our humanity</em>. Possible, but this is why checks and balances need to be put in effect to ensure that there is more than just a modicum of control. As more and more people are converted to a digitalized life, there are sure to be more issues that come to the forefront. If there are problems created by technology then technology will create solutions to those problems as well.</p>
<p>The focus of this post is — <em>The Future of</em> <em>Online Commenting</em>. At this particular juncture, let’s dissect the current state of online commenting, and its future. But before we do, let’s have a basic look at its history.&nbsp;</p>
<h2>A Brief Look at the History of Online Commenting&nbsp;</h2>
<p>We hear of the whole concept of letters to the editor, and even letters that were sent to authors by readers. This was the type of commenting that was present; commenting is reminiscent of the older practice of publishing&nbsp;<a href="https://en.wikipedia.org/wiki/Letter_to_the_editor">letters to the editor.</a>&nbsp;With the advent of technology and online platforms plus the death of penmanship, the whole concept of —<em> letters to the editor</em> — have taken on the form of online commentary via enabling comments. </p>
<p>The first online website to offer a comments section was <a href="https://www.opendiary.com/">Open Diary</a>, which added reader comments shortly after its launch in October 1998. As the concept of analytics came to the fore, and a larger audience created greater brand value, which resulted in more sales, more and more companies embraced online commenting.</p>
<figure><img loading="lazy" src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/reasons-people-comment-on-blogs-stats.png" alt="" width="474" height="493" srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/reasons-people-comment-on-blogs-stats.png 700w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/reasons-people-comment-on-blogs-stats-288x300.png 288w" sizes="(max-width: 474px) 100vw, 474px" data-srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/reasons-people-comment-on-blogs-stats.png 700w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/reasons-people-comment-on-blogs-stats-288x300.png 288w" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/reasons-people-comment-on-blogs-stats.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><a href="https://brandongaille.com/10-great-ways-to-increase-blog-comments/"><em>People comment for a myriad of reasons.</em></a></figcaption></figure>
<p>Towards the late 2000s, comments sections were quickly added to news sites. And, it was <a href="https://www.tandfonline.com/doi/abs/10.1080/17512786.2016.1205954?journalCode=rjop20">between 2007 and 2008 that there was a 42% growth</a> in the number of popular news sites with comments sections. In 2008, 75% of the top 100 most popular newspapers in terms of circulation had commenting systems in place. However, towards 2010, The American Journalism Review posited that newspapers offer <a href="https://www.monsterinsights.com/what-is-gated-content-and-how-to-use-it-to-get-more-leads/">gated comments</a> or do away with comments.&nbsp;</p>
<p>This evolution of commenting is the sign of the times. Many have agonized over the value of the conversations taking place online, but we see with the influx of social media platforms and blogging really taking off that online commenting is here to stay.</p>
<p>Building a commenting system where people would have to comment as their real selves, or moderating a commenting system where people were allowed to continue commenting under a different identity, has become an issue concerning the allocation of resources for many.</p>
<h2>The Future of Online Commenting has to Deal with Current Issues</h2>
<p>Online commenting and those who are privy to the world of such interactions are well aware of the <a href="https://www.theatlantic.com/technology/archive/2018/03/10-years-of-comment-moderation/553136/">mental toll that it could have</a>. While most commenting systems do offer the facility of pre-moderation, where all incoming comments are queued to await approval, this seems to be effective only to a certain degree.</p>
<p><a href="https://www.engadget.com/amp/2019-05-03-turn-off-comments-wont-fix-internet.html">Dr. Gina Masullo Chen</a>, assistant professor in the School of Journalism at the University of Texas at Austin, states, <em>“I would rather use techniques that will improve the comment stream…and some of the things that improve them are really strong moderation and pre-moderation.”</em> That said there is no doubt that moderators face a serious mental toll in embracing this as a full-time job. &nbsp;<a href="https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona">The Trauma Floor</a>&nbsp;showcases the issues faced by Facebook moderators, and it is harrowing.&nbsp;</p>
<p>Besides the mental toll that moderating online comments has on its gatekeepers, there is also the <a href="https://www.theatlantic.com/ideas/archive/2020/09/future-propaganda-will-be-computer-generated/616400/?utm_source=pocket&amp;utm_medium=email&amp;utm_campaign=pockethits">specter of misinformation</a> that is looming large and terrifying. We have all heard of <a href="https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html">the Cambridge Analytica debacle</a>, and now we are faced with so much of disinformation spreading via online comments.</p>
<p>In a world that is teeming with so much of <a href="https://api-nationalgeographic-com.cdn.ampproject.org/v/s/api.nationalgeographic.com/distribution/public/amp/science/2020/09/coronavirus-origins-misinformation-yan-report-fact-check-cvd?amp_js_v=a2&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16005082450055&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s">fake news, like, for instance, regarding Covid-19</a>, it comes as no surprise that organizations desire to one-up their competitors. With a sea chockfull of content, <a href="https://neilpatel.com/blog/is-facebook-organic-reach-dead/">organic reach appears to be dying</a>; this is certainly the case with Facebook. This is precisely why aspects like influencer marketing works where brands piggyback on the followers of influencers. </p>
<p>We hear of entities like <a href="https://interestingengineering.com/microsofts-ai-team-release-a-bot-that-can-generate-fake-comments-the-internet-asks-why">Bizarrely</a>, which is a team at Microsoft that has released work on an AI bot, called DeepCom. This initiative used to generate fake comments about news articles. This is the other side of the coin: While technology serves to solve certain problems, there are companies that will utilize technology to generate money. The intention is what counts at the end of the day.</p>
<figure><img loading="lazy" src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Picture1.png" alt="" width="652" height="447" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Picture1.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em> <a href="https://slouchingtowardsthatcham.com/2019/07/10/social-media-for-influencers-organic-reach/">Organic reach in social media is going down and will continue to do so.</a></em></figcaption></figure>
<p>Considering the various online facts regarding the aspect of commenting, you will realize that there are many issues concerning comments so much so that companies like <a href="https://mediabiasfactcheck.com/the-verge/">Verge has done away with online comments</a>. News sites are known to be a nefarious cesspit of human thoughts. Yet, the question remains: Does getting rid of comments affect a site’s engagement and followership? It does, and yet there are outliers like the <a href="https://amp-theatlantic-com.cdn.ampproject.org/v/s/amp.theatlantic.com/amp/article/371862/?usqp=mq331AQHKAFQCrABIA%3D%3D&amp;amp_js_v=0.1#aoh=16023963115219&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.theatlantic.com%2Ftechnology%2Farchive%2F2014%2F06%2Finternet-comments-and-perceptions-of-quality%2F371862%2F">National Journal</a> that saw page views increase.</p>
<p>Instead of doing away with online commenting, why not have real-time automated feedback as a solution? Instead of focusing on that age-old advice of <strong>Never Read The Comments</strong>, let’s focus on a solution. Commenting platforms aim to keep toxic conversations stifled with a combination of human guardians and up-to-date technology.</p>
<h2>Is the Future of Online Commenting Driven by AI? </h2>
<p>The future is here. <a href="https://micky.com.au/instagram-ai-automatically-hides-offensive-comments/?amp">Instagram is already on the way to using AI</a> to identify and block offensive comments. AI will also remind users that they are typing something offensive. AI tools work to flag and categorize harmful comments before a human can review them, thus helping to manage the workload and decrease toxic content. While there’s a possibility to dance around the edges of algorithmic detection, the fact is that this is better than nothing.&nbsp;</p>
<p>The question of impartiality needs to be answered. Esther Berg’s opines that Instagram has <a href="https://nypost.com/article/social-media-censorship-conservatives/">unfairly silenced conservative thoughts</a>. Although this factor is not addressed in the article, one wonders whether this particular intervention was human or non-human. There is something known as <strong>adaptive behavior</strong>, which ultimately is one of the main concerns in designing AI-focused commenting systems. Basically, commenters can ultimately amend the word. For example, if <strong>chocolate</strong> is a banned word, it could be written as <strong>c h o c o l a t e</strong>.</p>
<p>Either way, the fact here is that AI is the future, and <a href="https://techjury.net/blog/ai-statistics/#gref">there are plenty of statistics to prove this</a>. By 2025, the global AI market is expected to be almost&nbsp;<a href="https://medium.com/hackernoon/top-industries-getting-revolutionised-by-artificial-intelligence-686a440857c0">$60 billion</a>. Moreover, the number of AI startups grew&nbsp;14 times over the last two decades. A comfortable prediction would be that commenting systems will be powered by AI yet with a human overseer. </p>
<p>Just like any technology that is used, the main stakeholders of that particular technology is human. Catering to humans is only possible with humans. AI has come a long way for sure, yet what is missing is the gap between the understanding that lies between both AI and man.&nbsp;</p>
<p>Humans are still the best when it comes to reading, understanding, interpreting and moderating content. Because of this, businesses that are focused on making their mark in the world will make use of both AI and humans when creating an online presence and moderating content online.</p>
<h2>Privacy is a BIG Issue </h2>
<figure><img loading="lazy" src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Screen-Shot-2020-10-16-at-7.47.28-AM.png" alt="" width="595" height="517" srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Screen-Shot-2020-10-16-at-7.47.28-AM.png 552w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Screen-Shot-2020-10-16-at-7.47.28-AM-300x261.png 300w" sizes="(max-width: 595px) 100vw, 595px" data-srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Screen-Shot-2020-10-16-at-7.47.28-AM.png 552w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Screen-Shot-2020-10-16-at-7.47.28-AM-300x261.png 300w" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/Screen-Shot-2020-10-16-at-7.47.28-AM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><a href="https://www.datanyze.com/market-share/comment-systems--15"><em>Disqus and Facebook Comments lead the way, but at what cost to user privacy?</em></a></figcaption></figure>
<p>Many news sites and blogs have chosen to go on a digital dieting strategy with regard to the endeavor of online commenting. This is because while there are too many issues with toxic commentary, there’s also the <a href="https://www.itworldcanada.com/blog/the-endless-story-of-wordpress-plugins-security-issues/431784">issue of </a><strong><a href="https://www.itworldcanada.com/blog/the-endless-story-of-wordpress-plugins-security-issues/431784">Privacy</a></strong><a href="https://www.itworldcanada.com/blog/the-endless-story-of-wordpress-plugins-security-issues/431784"> that needs to be considered</a>.</p>
<p>Most websites and blogs use a third party commenting system. Suffice to say, the focus of a commenting system is to initiate better conversations. However, the issue here is that systems like <a href="https://talk.hyvor.com/blog/move-away-from-disqus/">Disqus and Facebook Comments track visitors</a>, and harvest their data for advertising purposes. Adding insult to injury, these systems even have the <a href="https://www.perl.com/article/104/2014/7/29/Your-users-deserve-better-than-Disqus/">indiscrete ability to know what sites users have visited</a>. What is ironic here is that <a href="https://www.perl.com/article/104/2014/7/29/Your-users-deserve-better-than-Disqus/">many companies blindly use these systems</a> at the expense of privacy. Therefore, choosing a GDPR-compliant system is key. </p>
<p>Data that is tracked by Disqus, which may be revealed to third parties, includes pseudonymous analytics data, which inclides a user’s IP address, their web browser version and installed add-ons, and their referring pages and exit links.</p>
<p>Disqus has also been criticized for <a href="http://www.baekdal.com/insights/the-first-rule-of-privacy">publishing its registered users’ entire commenting history</a>, along with a list of connected blogs and services, on the publicly viewable user profile pages. Of course, there are other issues, too, like the fact that such a system is heavy and can lead to a decrease in page load speed. </p>
<p>Exactly why is data privacy important? It is important to consumers because a breach of personal information can damage an individual’s fundamental rights and freedoms, including the risk of identity theft and other types of fraud.</p>
<p>To maintain customer trust today, a company must demonstrate that&nbsp;<a href="https://blog.netwrix.com/2019/08/08/data-privacy/">data privacy</a>&nbsp;is one of its core values. Indeed, while many businesses still view privacy policies as a forgettable legal routine, there is a change in the consumer’s attitude. <a href="https://blog.netwrix.com/2019/11/05/data-privacy-trends-issues-and-concerns-for-2020/">Worryingly, as per a PwC research, only 25%</a> of consumers believe most companies handle their personal data responsibly.</p>
<h2>There Are Other Concerns</h2>
<p>One of the most …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://talk.hyvor.com/blog/future-of-online-commenting/">https://talk.hyvor.com/blog/future-of-online-commenting/</a></em></p>]]>
            </description>
            <link>https://talk.hyvor.com/blog/future-of-online-commenting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24823541</guid>
            <pubDate>Mon, 19 Oct 2020 05:24:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Living in the Wrong Neighborhood in Japan – This Japanese Life]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24822865">thread link</a>) | @ycombonator
<br/>
October 18, 2020 | https://thisjapaneselife.org/2013/07/03/burakumin-japan/ | <a href="https://web.archive.org/web/*/https://thisjapaneselife.org/2013/07/03/burakumin-japan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://owwls.files.wordpress.com/2013/07/hamlet.png"><img data-attachment-id="1690" data-permalink="https://thisjapaneselife.org/2013/07/03/burakumin-japan/hamlet/" data-orig-file="https://owwls.files.wordpress.com/2013/07/hamlet.png" data-orig-size="600,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="hamlet" data-image-description="" data-medium-file="https://owwls.files.wordpress.com/2013/07/hamlet.png?w=300" data-large-file="https://owwls.files.wordpress.com/2013/07/hamlet.png?w=600" alt="hamlet" src="https://owwls.files.wordpress.com/2013/07/hamlet.png?w=640" srcset="https://owwls.files.wordpress.com/2013/07/hamlet.png 600w, https://owwls.files.wordpress.com/2013/07/hamlet.png?w=150 150w, https://owwls.files.wordpress.com/2013/07/hamlet.png?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>Imagine moving to a neighborhood and finding that suddenly, your friends and family are ashamed of you. Employers turn you down when you tell them your address, your fiancee tells you her family is threatening to disown her if she marries you.</p>
<p>It sounds like a literary allegory for racism, but for 2-3 million people known as <em>burakujyumin</em> in Japan, it’s a historic precedent. <em>Burakumin</em> were once part of a broader despised caste, but now refers increasingly to sections of cities where that caste once lived, and the jobs that caste once had.</p>

<p>Particularly, leather tanning and butchering. An American researcher in Japan took a job in a leather working factory, and tells this story:</p>
<blockquote><p>“On the evening before I was to head off to my first day at the factory, I had received an olfactory warning from my 82-year-old neighbor, friend, and frequent dinner companion. The stench of leather, Nakajo-san explained, was atrocious. More than that, the smell of leather stuck – it clung to your clothes, to your hands, to your hair. While the odor might wash off initially, after time, after daily contact with the scent, the smell became part of you. I needed to be prepared to stink – and stink permanently – if I were really going to work in the factory. I also, and here Nakajo-san grew a bit more serious, needed to be prepared to eat dinner alone. He explained that he could not&nbsp;abide the smell of leather and that our shared evening meals would have to end.”</p></blockquote>
<p>Some employees of banks have reported managers holding up maps of <em>burakumin</em>&nbsp;(“hamlet”) neighborhoods, warning the agents not to discriminate against people from those areas. One former clerk tells the story of a manager who delivered this speech, saying it was useful to know these neighborhoods so the agents could brace themselves to hide their disgust when they saw them. The intent was clear: “This is the map of people we don’t want to give loans to… but don’t discriminate… but check this map. You know, to <em>make sure you don’t discriminate</em> against the disgusting people who live there.”</p>
<p><strong>Defining Japan<br>
</strong>Japanese people are essentially identical to Koreans in origin, but a history of nationalism, represented by a divine emperor, has placed an imaginary sense of distinction into the blood of many Japanese. The cultural identities of some Japanese are distinct from this “pure blood” of the mainland: <em>Ainu</em> of Hokkaido and the Okinawan people have historically been considered Pseudo-Japanese, just above foreign residents of Japan. (Even multi-generational Korean migrant families are considered pseudo-Japanese). The Ainu have their own religion and ceremonies, deemed barbaric by their occupiers, while the Okinawans were seen as half-Chinese, owing to a history as a vassal state.</p>
<p>But even being “pure” Japanese didn’t keep you from full integration. There was a caste difference. Burakumin doesn’t refer to a national identity, but to “the hamlet people” who lived in ghettos on the outskirts of the cities. Essentially, outsiders.</p>
<p><a href="https://owwls.files.wordpress.com/2013/07/burakumin.jpg"><img loading="lazy" data-attachment-id="1691" data-permalink="https://thisjapaneselife.org/2013/07/03/burakumin-japan/burakumin/" data-orig-file="https://owwls.files.wordpress.com/2013/07/burakumin.jpg" data-orig-size="500,465" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="burakumin" data-image-description="" data-medium-file="https://owwls.files.wordpress.com/2013/07/burakumin.jpg?w=300" data-large-file="https://owwls.files.wordpress.com/2013/07/burakumin.jpg?w=500" alt="burakumin" src="https://owwls.files.wordpress.com/2013/07/burakumin.jpg?w=240&amp;h=223" width="240" height="223" srcset="https://owwls.files.wordpress.com/2013/07/burakumin.jpg?w=240&amp;h=223 240w, https://owwls.files.wordpress.com/2013/07/burakumin.jpg?w=480&amp;h=446 480w, https://owwls.files.wordpress.com/2013/07/burakumin.jpg?w=150&amp;h=140 150w, https://owwls.files.wordpress.com/2013/07/burakumin.jpg?w=300&amp;h=279 300w" sizes="(max-width: 240px) 100vw, 240px"></a>It started even before the Meiji restoration. During the Tokugawa Shogunate, society was deliberately stratified into classes. We imagine the peasants to be the lowest class in a country where samurai literally had the right to kill them for any perceived insult, but there were worse people to be than the farmers toiling for a feudal lord, and one of them is the person responsible for clearing away the bodies of humans and animals or slaughtering animals for meat or leather. They were called <em>Eta</em> – “Filthy People,” or <em>Hinen</em> – “Non-People.”</p>
<p>Eta came first, long before the Tokugawa era, and Hinen came after, a term applied to everyone on Tokugawa Ieyasu’s shit list:</p>
<blockquote><p>The term came to include beggars, panhandlers, lepers, and Eta and later evolved into an all-encompassing name for occupations such as cleaners, gardeners, falcon hackers, butchers, harbingers, comedians, gravediggers and prison guards.</p></blockquote>
<p>These jobs were considered filthy for a handful of reasons. Cleaners and gardeners were not the artisans designing the gardens, they were the ones cleaning outhouses or carrying fertilizer for the gardens. Falcon Hackers and Butchers were similar, a falcon hacker cut meat into bite-sized pieces for Imperial falcons while they are hatchlings. Notably, many of these – with the absence of comedians, who basically were accused of “working blue” – worked in proximity to the royal court. Most were considered below peasants, who were elevated above merchants (taxes were based on rice, not income) and merchants remained one step above the “outcasts.”</p>
<p>Popular stories about them circulated widely. They had dog bones in their bodies but were missing a rib. That their necks didn’t cast shadows, their sexual and excretory organs were deformed. They were subhuman in the hierarchy of Tokugawa, a distinction that lasted nearly 300 years.</p>
<p>They were banned from leaving their ghettos after sunset, banned from wearing shoes, often had to wear identifying marks on their clothing. If they spoke to anyone – usually for matters of trade – they had to get on their hands and knees. Certain haircuts were forbidden, and if they wore them, a samurai could execute them on sight.</p>
<p><strong>Common People&nbsp;</strong><br>
Tokugawa-era rules said that once you took one of these jobs, all of your descendants belonged to the same caste. So why would anyone take these jobs?</p>
<p>Desperation and tradition, as best as I can tell, but no one seems to know for certain. Horses and cows were being killed in Japan before Buddhist law banned it in the 8th century; once that law was passed an entire class of worker was legally and religiously tainted. (The further away you were from the capital, Kyoto, the more likely you were to ignore these laws: Hence, concentrations today are still focused in Kyushu and Tokyo, then the outskirts of the country).</p>
<p>One important factor was the weird (to Westerners) distinction between wealth and class. Lots of samurai were poor, despite being near the top of the social hierarchy. Hide workers were paid by<em> daimyo</em> and merchants for armor, saddles, and other leather goods, even if they weren’t respected for making them, and as with any organization in Japan, they formed their own hierarchies and fiefdoms on the outskirts of towns (hamlets) with the other undesirables: Lepers, comedians, prostitutes, beggars, all of which eventually became <em>burakumin</em>.</p>
<p>Eventually, of course, they had no choice: They could <em>only</em> work in the professions allowed to their class, a distinction useful to Tokugawa’s policies of strict social control. Everyone still got leather, and the stigma reminded riot-prone farmers that things could be worse.</p>
<p>By the last year of the Tokugawa period, 1867, we hear rumblings of a rebellion amongst the burakumin. Only 9 years earlier, a court had decided that only the unwarranted murder of <em>seven</em> Eta people could earn the death penalty, because Eta were only 1/7th human in the eyes of the court. And yet, a struggling shogun seeking new sources of revenue decided to tax them (already a questionable proposition, as of course most of them were quite poor). The Eta people near Osaka refused to pay, and responded with a letter:</p>
<blockquote><p>We are considered unclean because we dispose of animals and eat their flesh. Yet, we have heard that Westerners eat the flesh of animals as part of their daily meals, and they are treated politely here. Even here, in our own country after the ports have been opened, high-ranking people are said to have developed a taste for eating meat. Hence, we would like discrimination against us to cease by abolishing the use of the word “Eta” to describe us. If that were done, we would willingly donate the requested money even if we must dispose of all our possessions.</p></blockquote>
<p>A few years later, after the Meiji Restoration – a few years after the American Civil War – they got what they wanted. The government of Japan issued what some call “The Emancipation Proclamation” for Eta, giving them equal status and forbidding the acknowledgment of their history. It did not go well; riots in Okayama lead to Burakumin being burned in the streets. Even with their new legal status, the government was considering plans to round up Eta and force them to work in Hokkaido as farmers.</p>
<p>The name Eta eliminated, a few new ones emerged: “The New Commoners,” the “Special Kind,” which soon took on the meaning of “Different Kind,” even, briefly, “The Village People.” A surprisingly familiar attempt to govern attitudes through suggestion lead to another name, “Model Hamlet People,” and from there <em>burakumin</em> was born. Though still considered discriminatory, the word continues to be used by activists and academics, so I’m using it here.</p>
<p>Burakumin continued to work immersed in the smell of meat and hides, in abattoirs and tanneries isolated from the communities they served. These regions smelled like death. The workers smelled like death, and had for centuries. The religious stigma shifted to a social one, and then to a reflection of the neighborhoods they worked in. The idea of sub-humans remained.</p>
<p>Emancipation had a cost: Without legal distinctions, they became just another merchant class, now thrown into the same race and competition as everyone else. Socially, they couldn’t mingle with “proper” townspeople, could not marry out of their class. The only difference is that the government wasn’t involved in their repression – other people were doing it for them.</p>
<p>Burakumin could not find other work. They could not marry outside their closed impoverished communities, could not improve their social standing, despite the egalitarian meritocracy espoused in the Meiji period. This state of affairs lasted without government action for another 70 years – where the whole class of impoverished outcasts lived in forbidden and ignored neighborhoods marked by social exclusion.</p>
<p><strong>Eta Redux</strong></p>
<p><em>“Die eta filth.” “Burakumin maggots.” “Drop atomic bombs on buraku neighborhoods.”</em></p>
<p>These are some examples of the graffiti documented by Kiwi researcher …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thisjapaneselife.org/2013/07/03/burakumin-japan/">https://thisjapaneselife.org/2013/07/03/burakumin-japan/</a></em></p>]]>
            </description>
            <link>https://thisjapaneselife.org/2013/07/03/burakumin-japan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24822865</guid>
            <pubDate>Mon, 19 Oct 2020 02:29:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discord Desktop App RCE]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24822755">thread link</a>) | @Wingy
<br/>
October 18, 2020 | https://mksben.l0.cm/2020/10/discord-desktop-rce.html | <a href="https://web.archive.org/web/*/https://mksben.l0.cm/2020/10/discord-desktop-rce.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6054437144226106686" itemprop="description articleBody">
<p>A few months ago, I discovered a remote code execution issue in the <a href="https://discord.com/">Discord</a> desktop application and I reported it via their <a href="https://discord.com/security">Bug Bounty Program</a>.</p><p>The RCE I found was an interesting one because it is achieved by combining multiple bugs. In this article, I'd like to share the details.</p><h3>Why I chose Discord for the target</h3><p>I kind of felt like finding for vulnerabilities of the Electron app, so I was looking for a bug bounty program which pays the bounty for an Electron app and I found Discord. Also, I am a Discord user and simply wanted to check if the app I'm using is secure, so I decided to investigate.</p><h3>Bugs I found</h3><p>Basically I found the following three bugs and achieved RCE&nbsp;by combining them.</p><ol><li>Missing contextIsolation</li><li>XSS in iframe embeds</li><li>Navigation restriction bypass (CVE-2020-15174)</li></ol><p>I'll explain these bugs one by one.</p><h3>Missing contextIsolation</h3><p>When I test Electron app, first I always check the options of the <a href="https://www.electronjs.org/docs/api/browser-window">BrowserWindow API</a>, which is used to create a browser window. By checking it, I think about how RCE can be achieved when arbitrary JavaScript execution on the renderer is possible.</p><p>The Discord's Electron app is not an open source project but the Electron's JavaScript code is saved locally with the asar format and I was able to read it just by extracting it.</p><p>In the main window, the following options are used:&nbsp;</p><blockquote>const mainWindowOptions = {<br>&nbsp;&nbsp;title: 'Discord',<br>&nbsp;&nbsp;backgroundColor: getBackgroundColor(),<br>&nbsp;&nbsp;width: DEFAULT_WIDTH,<br>&nbsp;&nbsp;height: DEFAULT_HEIGHT,<br>&nbsp;&nbsp;minWidth: MIN_WIDTH,<br>&nbsp;&nbsp;minHeight: MIN_HEIGHT,<br>&nbsp;&nbsp;transparent: false,<br>&nbsp;&nbsp;frame: false,<br>&nbsp;&nbsp;resizable: true,<br>&nbsp;&nbsp;show: isVisible,<br>&nbsp;&nbsp;webPreferences: {<br>&nbsp;&nbsp;&nbsp;&nbsp;blinkFeatures: 'EnumerateDevices,AudioOutputDevices',<br>&nbsp;&nbsp;&nbsp;&nbsp;<span><b>nodeIntegration: false</b></span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;preload: _path2.default.join(__dirname, 'mainScreenPreload.js'),<br>&nbsp;&nbsp;&nbsp;&nbsp;nativeWindowOpen: true,<br>&nbsp;&nbsp;&nbsp;&nbsp;enableRemoteModule: false,<br>&nbsp;&nbsp;&nbsp;&nbsp;spellcheck: true<br>&nbsp;&nbsp;}<br>};</blockquote><p>The important options which we should check here are especially <i>nodeIntegration</i> and <i>contextIsolation</i>. From the above code, I found that the <i>nodeIntegration</i> option is set to false and the <i>contextIsolation</i> option is set to false (the default of the used version) in the Discord's main window.</p><p>If the nodeIntegration is set to true, a web page's JavaScript can use Node.js features easily just by calling the <code>require()</code>. For example, the way to execute the calc application on Windows is:</p><blockquote>&lt;script&gt;<br>&nbsp; require('child_process').exec('calc');<br>&lt;/script&gt;</blockquote><p>In this time, the <i>nodeIntegration</i> was set to false, so I couldn't use Node.js features by calling the <code>require()</code> directly.</p><p>However, there is still a possibility of access to Node.js features. The <i>contextIsolation</i>, another important option, was set to false. This option should not be set to false if you want to eliminate the possibility of RCE on your app.</p><p>If the <i>contextIsolation</i> is disabled, a web page's JavaScript can affect the execution of the <a href="https://github.com/electron/electron/tree/83bb065b4f6ed512d545c46389a7fdc114c94a54/lib/renderer">Electron's internal JavaScript code on the renderer</a>, and preload scripts (In the following, these JavaScript will be referred to as the JavaScript code outside web pages).&nbsp;For example, if you override&nbsp; <code>Array.prototype.join</code>, one of the JavaScript built-in methods, with another function from a web page's JavaScript, the JavaScript code outside web pages also will use the overridden function when the <code>join</code> is called.</p><p>This behavior is dangerous because Electron allows the JavaScript code outside web pages to use the Node.js features regardless the <i>nodeIntegration</i> option and by interfering with them from the function overridden in the web page, it could be possible to achieve RCE even if the <i>nodeIntegration</i> is set to false.</p><p>By the way, a such trick was previously not known. It was first discovered in a pentest by Cure53, which I also joined in, in 2016. After that, we reported it to Electron team and the <i>contextIsolation</i> was introduced.</p><p>Recently, that pentest report was published. If you are interested, you can read it from the following link:</p><p>Pentest-Report Ethereum Mist 11.2016 - 10.2017<br><a href="https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view">https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view</a></p><p>You can also read the slides which I used at a CureCon event:</p><p>The <i>contextIsolation</i> introduces the separated contexts between the web page and the JavaScript code outside web pages so that the JavaScript execution of each code does not affect each. This is a necessary faeture to eliminate the possibility of RCE, but this time it was disabled in Discord.</p><p>Now I found that the <i>contextIsolation</i> is disabled, so I started looking for a place where I could execute arbitrary code by interfering with the JavaScript code outside web pages.</p><p>Usually, when I create a PoC for RCE in the Electron's pentests, I first try to achieve RCE by using the Electron's internal JavaScript code on the renderer. This is because the Electron's internal JavaScript code on the renderer can be executed in any Electron app, so basically I can reuse the same code to achieve RCE and it's easy.</p><p>In my slides, <a href="https://speakerdeck.com/masatokinugawa/electron-abusing-the-lack-of-context-isolation-curecon-en?slide=41">I introduced</a> that RCE can be achieved by using the code which Electron executes at the navigation timing. It's not only possible from that code but there are such code in some places. (I'd like to publish examples of the PoC in the future.)</p><p>However, depending on the version of Electron used, or the <i>BrowserWindow</i> option which is set, because the code has been changed or the affected code can't be reached correctly, sometimes PoC via the Electron's code does not work well. In this time, it did not work, so I decided to change the target to the preload scripts.</p><div><p>When checking the preload scripts, I found that Discord exposes the function, which allows some allowed modules to be called via <code>DiscordNative.nativeModules.requireModule('MODULE-NAME')</code>, into the web page.</p></div><p>Here, I couldn't use modules that can be used for RCE directly, such as <i>child_process</i> module, but I found a code where RCE can be achieved by overriding the JavaScript built-in methods and interfering with the execution of the exposed module.</p><p>The following is the PoC. I was able to confirm that the calc application is popped up when I call the <code>getGPUDriverVersions</code> function which is defined in the module called "<i>discord_utils</i>" from devTools, while overriding the <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>.</p><blockquote>RegExp.prototype.test=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return false;<br>}<br>Array.prototype.join=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return "calc";<br>}<br>DiscordNative.nativeModules.requireModule('discord_utils').getGPUDriverVersions();</blockquote><p>The <code>getGPUDriverVersions</code> function tries to execute the program by using the "<i>execa</i>" library, like the following:</p><blockquote>module.exports.getGPUDriverVersions = async () =&gt; {<br>&nbsp;&nbsp;if (process.platform !== 'win32') {<br>&nbsp;&nbsp;&nbsp;&nbsp;return {};<br>&nbsp;&nbsp;}<p>&nbsp;&nbsp;const result = {};<br>&nbsp;&nbsp;const nvidiaSmiPath = `${process.env['ProgramW6432']}/NVIDIA Corporation/NVSMI/nvidia-smi.exe`;</p><p>&nbsp;&nbsp;try {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = parseNvidiaSmiOutput(await execa(nvidiaSmiPath, []));<br>&nbsp;&nbsp;} catch (e) {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = {error: e.toString()};<br>&nbsp;&nbsp;}</p><p>&nbsp;&nbsp;return result;<br>};</p></blockquote><p>Usually the <i>execa</i> tries to execute "<i>nvidia-smi.exe</i>", which is specified in the <code>nvidiaSmiPath</code> variable, however, due to the overridden <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>, the argument is replaced to "<i>calc</i>" in the <i>execa</i>'s internal processing.</p><p>Specifically, the argument is replaced by changing the following two parts.</p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36</a></p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55</a></p><p>The remaining work is to find a way to execute JavaScript on the application. If I can find it, it leads to actual RCE.</p><h3>XSS in iframe embeds</h3><p>As explained above, I found that RCE could happen from arbitrary JavaScript execution, so I was trying to find an XSS vulnerability. The app supports the autolink or Markdown feature, but looked like it is good. So I turned my attention to the iframe embeds feature. The iframe embeds is the feature which automatically displays the video player on the chat when the YouTube URL is posted, for example.</p><p>When the URL is posted, Discord tries to get the <a href="https://ogp.me/">OGP</a> information of that URL and if there is the OGP information, it displays the page's title, description, thumbnail image, associated video and so on in the chat.</p><p>The Discord extracts the video URL from the OGP and only if the video URL is allowed domain and the URL has actually the URL format of the embeds page, the URL is embedded in the iframe.</p><p>I couldn't find the documentation about which services can be embedded in the iframe, so I tried to get a hint by checking the CSP's <i>frame-src</i> directive. At that time, the following CSP was used:</p><blockquote>Content-Security-Policy: [...] ; frame-src https://*.youtube.com https://*.twitch.tv https://open.spotify.com https://w.soundcloud.com https://sketchfab.com https://player.vimeo.com https://www.funimation.com https://twitter.com https://www.google.com/recaptcha/ https://recaptcha.net/recaptcha/ https://js.stripe.com https://assets.braintreegateway.com https://checkout.paypal.com https://*.watchanimeattheoffice.com</blockquote><p>Obviously, some of them are listed to allow iframe embeds (e.g. YouTube, Twitch, Spotify).&nbsp;I tried to check if the URL can be embeded in the iframe by specifying the domain into the OGP information one by one and tried to find XSS on the embedded domains. After some attempts, I found that the&nbsp;<a href="https://sketchfab.com/">sketchfab.com</a>, which is one of the domains listed in the CSP, can be embedded in the iframe and found XSS on the embeds page.&nbsp;I didn't know about Sketchfab at that time, but it seems that it is a platform in which users can publish, buy and sell 3D models. There was a simple DOM-based XSS in the footnote of the 3D model.</p><p>The following is the PoC, which has the crafted OGP. When I posted this URL to the chat, the Sketchfab was embedded into the iframe on the chat, and after a few clicks on the iframe, arbitrary JavaScript was executed.</p><p><a href="https://l0.cm/discord_rce_og.html">https://l0.cm/discord_rce_og.html</a></p><blockquote>&lt;head&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta charset="utf-8"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="og:title" content="RCE DEMO"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;[...]<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="<span><b>og:video:url</b></span>" content="https://<span><b>sketchfab.com</b></span>/models/2b198209466d43328169d2d14a4392bb/embed"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta …</blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mksben.l0.cm/2020/10/discord-desktop-rce.html">https://mksben.l0.cm/2020/10/discord-desktop-rce.html</a></em></p>]]>
            </description>
            <link>https://mksben.l0.cm/2020/10/discord-desktop-rce.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24822755</guid>
            <pubDate>Mon, 19 Oct 2020 02:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp: Instruction encoding interlude]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24822534">thread link</a>) | @azhenley
<br/>
October 18, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-10/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-10/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><span data-nosnippet="">
<em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-9/">previous</a></em>
</span></p>

<p>Welcome back to the Compiling a Lisp series. In this thrilling new update, we
will learn a little bit more about x86-64 instruction encoding instead of
allocating more interesting things on the heap or adding procedure calls.</p>

<p>I am writing this interlude because I changed one register in my compiler code
(<code>kRbp</code> to <code>kRsp</code>) and all hell broke loose — the resulting program was
crashing, <code>rasm2</code>/Cutter were decoding wacky instructions when fed my binary,
etc. Over the span of two very interesting but very frustrating hours, I
learned why I had these problems and how to resolve them. You should learn,
too.</p>

<h3 id="state-of-the-instruction-encoder">State of the instruction encoder</h3>

<p>Recall that I introduced at least 10 functions that looked vaguely like this:</p>

<div><div><pre><code><span>void</span> <span>Emit_mov_reg_imm32</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>Register</span> <span>dst</span><span>,</span> <span>int32_t</span> <span>src</span><span>)</span> <span>{</span>
  <span>Buffer_write8</span><span>(</span><span>buf</span><span>,</span> <span>kRexPrefix</span><span>);</span>
  <span>Buffer_write8</span><span>(</span><span>buf</span><span>,</span> <span>0xc7</span><span>);</span>
  <span>Buffer_write8</span><span>(</span><span>buf</span><span>,</span> <span>0xc0</span> <span>+</span> <span>dst</span><span>);</span>
  <span>Buffer_write32</span><span>(</span><span>buf</span><span>,</span> <span>src</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>These functions all purport to encode x86-64 instructions. They do, most of the
time, but they do not tell the whole story. This function is supposed to encode
an instruction of the form <code>mov reg64, imm32</code>. How does it do it? I don’t know!</p>

<p>They have all these magic numbers in them! What is a <code>kRexPrefix</code>? Well, it’s
<code>0x48</code>. Does that mean anything to us? No! It gets worse. What are <code>0xc7</code> and
<code>0xc0</code> doing there? Why are we adding <code>dst</code> to <code>0xc0</code>? Before this debugging
and reading extravaganza, I could not have told you. Remember how somewhere in
a previous post I mentioned I was getting these hex bytes from reading the
compiled output on the Compiler Explorer? Yeah.</p>

<p>As it turns out, this is not a robust development strategy, at least with
x86-64. It might be okay for some more regular or predictable instruction sets,
but not this one.</p>

<h3 id="big-scary-documentation">Big scary documentation</h3>

<p>So where do we go from here? How do we find out how to take these mystical
hexes and incantations to something that better maps to the hardware? Well, we
once again drag <a href="https://tchebb.me/">Tom</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> into a debugging session and pull
out the big ol’ Intel <a href="https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html">Software Developer Manual</a>.</p>

<p>This is an enormous 26MB, 5000 page manual comprised of four volumes. It’s
<em>very intimidating</em>. This is exactly why I didn’t want to pull it out earlier
and do this properly from the beginning… but here we are, eventually needing
to do it properly.</p>

<p>I will not pretend to understand all of this manual, nor will this post be a
guide to the manual. I will just explain what sections and diagrams I found
useful in understanding how this stuff works.</p>

<p>I only ever opened Volume 2, the instruction set reference. In that honking
2300 page volume are descriptions of every Intel x86-64 instruction and how
they are encoded. The instructions are listed alphabetically and split into
sections based on the first letter of each instruction name.</p>

<p>Let’s take a look at Chapter 3, specifically at the MOV instruction on page
&nbsp; 1209. For those following along who do not want to download a massive
PDF, this <a href="https://www.felixcloutier.com/x86/index.html">website</a> has a bunch
of the same data in HTML form. Here’s the <a href="https://www.felixcloutier.com/x86/mov">page for
MOV</a>.</p>

<p>This page has every variant of MOV instruction. There are other instructions
begin with MOV, like MOVAPD, MOVAPS, etc, but they are different enough that
they are different instructions.</p>

<p>It has six columns:</p>

<ul>
  <li><em>Opcode</em>, which describes the layout of the bytes in the instruction stream.
This describes how we’ll encode instructions.</li>
  <li><em>Instruction</em>, which gives a text-assembly-esque representation of the
instruction. This is useful for figuring out which one we actually want to
encode.</li>
  <li><em>Op/En</em>, which stands for “Operand Encoding” and as far as I can tell
describes the operand order with a symbol that is explained further in the
“Instruction Operand Encoding” table on the following page.</li>
  <li><em>64-Bit Mode</em>, which tells you if the instruction can be used in 64-bit mode
(“Valid”) or not (something else, I guess).</li>
  <li><em>Compat/Leg Mode</em>, which tells you if the instruction can be used in some
other mode, which I imagine is 32-bit mode or 16-bit mode. I don’t know. But
it’s not relevant for us.</li>
  <li><em>Description</em>, which provides a “plain English” description of the opcode,
for some definition of the words “plain” and “English”.</li>
</ul>

<p>Other instructions have slightly different table layouts, so you’ll have to
work out what the other columns mean.</p>

<p>Here’s a preview of some rows from the table, with HTML courtesy of Felix
Cloutier’s aforementioned web docs:</p>

<table>
<tbody><tr>
<th>Opcode</th>
<th>Instruction</th>
<th>Op/En</th>
<th>64-Bit Mode</th>
<th>Compat/Leg Mode</th>
<th>Description</th></tr>
<tr>
<td>88 /<em>r</em></td>
<td>MOV <em>r/m8,r8</em></td>
<td>MR</td>
<td>Valid</td>
<td>Valid</td>
<td>Move <em>r8</em> to <em>r/m8.</em></td></tr>
<tr>
<td>REX + 88 /<em>r</em></td>
<td>MOV <em>r/m8</em><sup>***,</sup><em>r8</em><sup>***</sup></td>
<td>MR</td>
<td>Valid</td>
<td>N.E.</td>
<td>Move <em>r8</em> to <em>r/m8.</em></td></tr>
<tr>
<td>89 /<em>r</em></td>
<td>MOV <em>r/m16,r16</em></td>
<td>MR</td>
<td>Valid</td>
<td>Valid</td>
<td>Move <em>r16</em> to <em>r/m16.</em></td></tr>
<tr>
<td>89 /<em>r</em></td>
<td>MOV <em>r/m32,r32</em></td>
<td>MR</td>
<td>Valid</td>
<td>Valid</td>
<td>Move <em>r32</em> to <em>r/m32.</em></td></tr>
<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>
<tr>
<td>C7 /<em>0 id</em></td>
<td>MOV <em>r/m32, imm32</em></td>
<td>MI</td>
<td>Valid</td>
<td>Valid</td>
<td>Move <em>imm32</em> to <em>r/m32.</em></td></tr>
<tr>
<td>REX.W + C7 /<em>0 id</em></td>
<td>MOV <em>r/m64, imm32</em></td>
<td>MI</td>
<td>Valid</td>
<td>N.E.</td>
<td>Move <em>imm32 sign extended to 64-bits</em> to <em>r/m64.</em></td></tr>
</tbody></table>

<p>If you take a look at the last entry in the table, you’ll see <code>REX.W + C7 /0
id</code>. Does that look familiar? Maybe, if you squint a little?</p>

<p>It turns out, that’s the description for encoding the instruction we originally
wanted, and had a bad encoder for. Let’s try and figure out how to use this to
make our encoder better. In order to do that, we’ll need to first understand a
general layout for Intel instructions.</p>

<h3 id="instruction-encoding-big-picture">Instruction encoding, big picture</h3>

<p>All Intel x86-64 instructions follow this general format:</p>

<ul>
  <li><em>optional</em> instruction prefix (1 byte)</li>
  <li>opcode (1, 2, or 3 bytes)</li>
  <li><em>if required,</em> Mod-Reg/Opcode-R/M, also known as ModR/M (1 byte)</li>
  <li><em>if required,</em> Scale-Index-Base, also known as SIB (1 byte)</li>
  <li>displacement (1, 2, or 4 bytes, or none)</li>
  <li>immediate data (1, 2, or 4 bytes, or none)</li>
</ul>

<p>I found this information at the very beginning of Volume 2, Chapter 2 (page
527) in a section called “Instruction format for protected mode, real-address
mode, and virtual-8086 mode”.</p>

<p>You, like me, may be wondering about the difference between “optional”, “if
required”, and “…, or none”. I have no explanation, sorry.</p>

<p>I’m going to briefly explain each component here, followed up with a
piece-by-piece dissection of the particular MOV instruction we want, so we get
some hands-on practice.</p>

<h4 id="instruction-prefixes">Instruction prefixes</h4>

<p>There are a couple kind of instruction prefixes, like REX (Section 2.2.1) and
VEX (Section 2.3). We’re going to focus on REX prefixes, since they are needed
for many (most?) x86-64 instructions, and we’re not emitting vector
instructions.</p>

<p>The REX prefixes are used to indicate that an instruction, which might normally
refer to a 32-bit register, should instead refer to a 64-bit register. Also
some other things but we’re mostly concerned with register sizes.</p>

<h4 id="opcode">Opcode</h4>

<p>Take a look at Section 2.1.2 (page 529) for a brief explanation of opcodes. The
gist is that the opcode is the <em>meat</em> of the instruction. It’s what makes a MOV
a MOV and not a HALT. The other fields all modify the meaning given by this
field.</p>

<h4 id="modrm-and-sib">ModR/M and SIB</h4>

<p>Take a look at Section 2.1.3 (page 529) for a brief explanation of ModR/M and
SIB bytes. The gist is that they encode what register sources and destinations
to use.</p>

<h4 id="displacement-and-immediates">Displacement and immediates</h4>

<p>Take a look at Section 2.1.4 (page 529) for a brief explanation of displacement
and immediate bytes. The gist is that they encode literal numbers used in the
instructions that don’t encode registers or anything.</p>

<p>If you’re confused, that’s okay. It should maybe get clearer once we get our
hands dirty. Reading all of this information in a vacuum is moderately useless
if it’s your first time dealing with assembly like this, but I included this
section first to help explain how to use the reference.</p>

<h3 id="encoding-piece-by-piece">Encoding, piece by piece</h3>

<p>Got all that? Maybe? No? Yeah, me neither. But let’s forge ahead anyway. Here’s
the instruction we’re going to encode: <code>REX.W + C7 /0 id</code>.</p>

<h4 id="rexw">REX.W</h4>

<p>First, let’s figure out <code>REX.W</code>. According to Section 2.2.1, which explains REX
prefixes in some detail, there are a couple of different prefixes. There’s a
helpful table (Table 2-4, page 535) documenting them. Here’s a bit diagram with
the same information:</p>

<svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 626.0000000000003 128.05555555555554">
  <!-- svg-source:excalidraw -->
  
  <defs>
    
  </defs>
  <rect x="0" y="0" width="626.0000000000003" height="128.05555555555554" fill="#ffffff"></rect><g transform="translate(274.27777777777794 59.16666666666663) rotate(0 30 28.888888888888886)"><path d="M0.282781258225441 -1.8658841997385025 C21.524194687604904 0.3263779416680336, 43.51525716483593 0.5620313420891762, 59.49974836409092 0.35328303277492523 M-0.23636383563280106 0.48129016906023026 C22.33357594162226 1.3931672364473342, 43.38550271838904 -0.1093220919370651, 60.771481804549694 0.198187418282032 M59.07265104353428 -0.06147755682468414 C60.808595448732376 23.39022936589188, 61.79160812497139 43.80102747513188, 58.67354454100132 56.44631645248995 M60.97932367771864 0.9332471564412117 C61.0181736709343 19.376891723109615, 60.627089238332374 39.6501947980788, 59.43717389553785 57.598889285491566 M60.95579780638218 59.09368965195284 C37.140545189380646 56.58890948610173, 13.368886932730675 58.918221333788495, -1.9358471482992172 56.500082226263146 M59.70537953823805 58.153468066619496 C41.87183416634798 56.3581919895278, 22.80299063771963 58.02151992188559, -0.5461894944310188 58.66469209806786 M-1.2606495469808578 56.96349546478854 C1.3280181778801812 39.56183260182539, 0.8311419381035698 20.12219061288568, 1.4943272024393082 0.6683889478445053 M0.8468330428004265 57.25558679716454 C-1.2163042907913526 40.90151360051499, -0.6621219997604688 25.07094656841622, 0.5936084315180779 0.07259780913591385" stroke="#000000" stroke-width="1" fill="none"></path></g><g transform="translate(355.388888888889 59.16666666666663) rotate(0 30 28.888888888888886)"><path d="M0.9892207235097885 -1.3264554589986801 C17.91910222172737 0.6104068741202354, 39.34811396896839 0.4834799751639366, 61.95864735543728 1.8664943128824234 M-0.9697036072611809 -0.5628261044621468 C22.46204295009375 0.6441463679075241, 44.28936598449946 -1.0473149567842484, 60.47789890319109 0.6579559370875359 M61.63116703927517 -1.9358471482992172 C58.5206181704998 18.79514794051647, 58.401413172483444 35.087803795933716, 59.4107590764761 58.52915835546122 M60.77967006713152 -0.5461894944310188 C60.3763564426038 23.039876867499615, 60.26906975093815 45.00270561956697, 59.36967522650957 57.370636621283154 M59.79775629937649 59.27210498021708 C37.3329798579216 57.9651572169529, 15.18276335299015 56.39642733948098, 1.693666085600853 56.73339581655131 M60.82104355841875 58.37138620929585 C46.157548896968365 58.07063684331045, 32.67722836881876 56.84446177350149, -0.18946855515241623 57.94115201549397 M-0.07595290243625641 59.45522427724467 C-0.11518774032592771 39.320549128784066, -1.4454217910766602 20.885230059425034, -1.0231980234384537 1.208210602402687 M0.44079381972551346 57.336249748037915 C-0.7576514596740405 36.01054775963227, -0.35927714059750243 14.172448005113338, -0.15534298866987228 -0.5614060834050179" stroke="#000000" stroke-width="1" fill="none"></path></g><g transform="translate(438.72222222222206 60.277777777777715) rotate(0 30 28.888888888888886)"><path d="M-1.3264554589986801 -1.331461325287819 C24.98334500193596 0.5502206578850746, 48.80939607322216 1.6618811383843421, 61.86649431288242 1.5469771474599838 M-0.5628261044621468 -0.1788884922862053 C13.275243975222113 -0.41067473590373993, 23.98543777316809 1.0597210675477982, 60.657955937087536 0.19103915244340897 M58.06415285170078 -1.2776955515146255 C60.315263751480316 13.919570003946623, 58.170804503891205 30.04370018343131, 60.75138057768345 59.669643135534386 M59.45381050556898 0.8869143202900887 C60.790729816920226 13.007382185094885, 59.95483642435736 23.825184339450463, 59.59285884350538 58.667012626098256 M61.49432720243931 58.44616672562228 C40.2707217335701 59.57068620042668, 19.169812187552452 59.41077075319157, -1.0443819612264633 56.416127415166955 M60.59360843151808 57.850375586913685 C43.042805559933186 58.77773010598288, 24.490591250360012 58.08093535767661, 0.16337423771619797 58.01560657636986 M1.677446499466896 57.797753544317345 C0.039253393809000725 37.78255109157827, 0.3113896052042644 19.384642950362625, 1.208210602402687 1.533988580107689 M-0.4415280297398567 56.77825420515404 C-0.3269432589411735 42.26201632039414, -0.4001871153712272 27.793210381435017, -0.5614060834050179 0.3669479563832283" stroke="#000000" stroke-width="1" fill="none"></path></g><g transform="translate(516.5000000000003 60.277777777777715) rotate(0 30 28.888888888888886)"><path d="M-0.22465358674526215 -0.2532857805490494 C24.72308537364006 1.5957119718194008, 46.307192131876945 1.1461847081780434, 61.014652386307716 -1.7146605402231216 M0.2339368388056755 0.3651459887623787 C16.825212217867374 0.6960259705781937, 33.73636522144079 -0.017583963274955705, 59.34487085789442 0.26118142157793045 M59.162750378251076 1.123508557677269 C61.230626257922914 13.494371872809198, 58.34999147322443 28.750107624464565, 58.79770149290562 57.626541824804406 M60.944802574813366 0.5650888159871101 C59.07786855449279 15.794553389979733, 60.25044378985961 33.609535847273136, 59.28113179653883 57.290728503631215 M58.186400070786476 57.495594711767296 C42.87429457902908 58.84347834901676, 27.24250219762325 56.97979703264103, 1.2155314832925797 56.6980077938901 M60.425802282989025 57.679779941009144 C46.277098067104816 57.59357712136374, 32.85598631948233 58.612190698252775, 0.8906028792262077 58.06936090605126 M-1.471575602889061 59.35185071991549 C-2.1352061059739853 48.008055119050866, 1.3870826933119034 32.80206164220968, 0.965896263718605 0.7785459607839584 M0.14446526020765305 57.26035326139794 C-0.18164619786871805 36.869497058292225, 0.18228951113091574 15.633006394737286, 0.5080009028315544 -0.2884194180369377" stroke="#000000" stroke-width="1" fill="none"></path></g><g transform="translate(106.50000000000023 56.94444444444446) rotate(0 74.99999999999994 30.555555555555543)"><path d="M-0.004748240113258362 -1.2022985070943832 C51.46067134290932 1.1885993815958493, 102.10100242495534 2.2331812717020503, 151.88960514962668 1.1301776319742203 M0.7379437163472176 -0.7188682034611702 C35.54649843275546 -1.2177299521863458, 71.13148900121449 -1.5193597339093683, 149.09320003539318 -0.14109153300523758 M149.59630452096457 1.2155314832925797 C149.36633679974403 12.91017072813378, 152.28070113766518 30.678189489576543, 150.851604565978 60.91511543757383 M150.3231938555836 0.8906028792262077 C149.8666044096979 14.570648643705574, 149.9388221125635 30.15284742332166, 149.2642121985554 61.898147582179945 M148.24153147637838 62.07700737482969 C120.21612148731943 63.50114316037957, 87.43105268478391 62.236734571970146, 0.2889305204153061 60.07626207835142 M149.4094281867146 61.61911201394264 C113.6940331459045 60.465041357196014, 77.41767161339519 61.249791580355804, 0.1307886317372322 60.40915369904701 M1.4909912198781967 60.74828585154478 C-2.010100583649344 45.67236099226605, -1.8145777984625764 26.55751096208889, -0.5039833933115005 0.21762146055698395 M-0.2794763371348381 60.508841275340956 C0.02256062254309643 39.35567450357806, 0.16684558615088452 19.340500590701886, 0.17461878806352615 -0.9764813855290413" stroke="#000000" stroke-width="1" fill="none"></path></g><g transform="translate(147.05555555555566 72.38888888888891) rotate(0 35 18)"><text x="35" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">0100</text></g><g transform="translate(292.77777777777794 70.05555555555554) rotate(0 11.5 18)"><text x="11.5" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">W</text></g><g transform="translate(376.388888888889 70.05555555555554) rotate(0 9 18)"><text x="9" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">R</text></g><g transform="translate(460.22222222222206 71.16666666666663) rotate(0 8.5 18)"><text x="8.5" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">X</text></g><g transform="translate(536.5000000000003 71.16666666666663) rotate(0 10 18)"><text x="10" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">B</text></g><g transform="translate(53.666666666666856 10) rotate(0 49.5 18)"><text x="49.5" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">High bit</text></g><g transform="translate(517.0000000000003 12.277777777777715) rotate(0 49.5 18)"><text x="49.5" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">Low bit</text></g><g transform="translate(10 67.77777777777777) rotate(0 26.5 18)"><text x="26.5" y="25" font-family="Virgil, Segoe UI Emoji" font-size="28px" fill="#000000" text-anchor="middle" style="white-space: pre;" direction="ltr">REX</text></g></svg>

<p>In English, and zero-indexed:</p>

<ul>
  <li>Bits 7-4 are always <code>0b0100</code>.</li>
  <li>Bit 3 is the W prefix. If it’s 1, it means the operands are 64 bits. If it’s
0, “operand size [is] determined by CS.D”. Not sure what that means.</li>
  <li>Bits 2, 1, and 0 are other types of REX prefixes that we may not end up
using, so I am omitting them here. Please read further in the manual if you
are curious!</li>
</ul>

<p>This MOV instruction calls for REX.W, which means this byte will look like
<code>0b01001000</code>, also known as our friend <code>0x48</code>. Mystery number one, solved!</p>

<h4 id="c7">C7</h4>

<p>This is a hexadecimal literal <code>0xc7</code>. It is the <em>opcode</em>. There are a couple of
other entries with the opcode <code>C7</code>, modified by other bytes in the instruction
(ModR/M, SIB, REX, …). Write it to the instruction stream. Mystery number
two, solved!</p>

<h4 id="0">/0</h4>

<p>There’s a snippet in Section 2.1.5 that explains this notation:</p>

<blockquote>
  <p>If the instruction does not require a second operand, then the Reg/Opcode
field may be used as an opcode extension. This use is represented by the
sixth row in the tables (labeled “/digit (Opcode)”). Note that values in row
six are represented in decimal form.</p>
</blockquote>

<p>This is a little confusing because this operation clearly <em>does</em> have a second
operand, denoted by the “MI” in the table, which shows Operand 1 being
<code>ModRM:r/m (w)</code> and Operand 2 being <code>imm8/16/32/64</code>. I think it’s because it
doesn’t have a second <em>register</em> operand that this space is free — the
immediate is in a different place in the instruction.</p>

<p>In any case, this means that we have to make sure to put decimal <code>0</code> in the
<code>reg</code> part of the ModR/M byte. We’ll see what the ModR/M byte looks like in
greater detail shortly.</p>

<h4 id="id">id</h4>

<p><em>id</em> refers to an immediate <em>double word</em> (32 bits). It’s called a <em>double</em>
word because, a word (<em>iw</em>) is 16 bits. In increasing order of size, we have:</p>

<ul>
  <li><em>ib</em>, byte (1 byte)</li>
  <li><em>iw</em>, word (2 bytes)</li>
  <li><em>id</em>, double word (4 bytes)</li>
  <li><em>io</em>, quad word (8 bytes)</li>
</ul>

<p>This means we have to write our 32-bit value out to the instruction stream.
These notations and encodings are explained further in Section 3.1.1.1 (page
596).</p>

<p>Overall, that means that this instruction will have the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-10/">https://bernsteinbear.com/blog/compiling-a-lisp-10/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-10/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24822534</guid>
            <pubDate>Mon, 19 Oct 2020 01:11:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Learn Programming: A Roadmap for Becoming a Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24822175">thread link</a>) | @luthfur
<br/>
October 18, 2020 | https://makingsmallercircles.com/articles/how-to-learn-programming-a-roadmap-for-success/ | <a href="https://web.archive.org/web/*/https://makingsmallercircles.com/articles/how-to-learn-programming-a-roadmap-for-success/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I come across questions on how to get started in programming often. People are hungry to learn, but don’t know where to start or which path to take. This is made even more difficult these days due to a lot of different areas that exist, such as web development, mobile software development, game development etc.&nbsp;</p>



<p>Although we live at a time when tutorials and lessons are abundant, a lot of it can feel overwhelming. What you need is a roadmap to navigate the topics. You want a structure to guide you in your learning. A lot of coding bootcamps follow an approach similar to a college curriculum. Working through these curriculums is frustrating because you don’t feel like you are learning anything substantial quickly enough. College curriculum is great if your goal is to get a certificate or a degree. They are not great if your goal is to learn the practical skills of software engineering.</p>



<p>Following is a roadmap that I have put together to help you guide yourself in learning how to program. Your mileage with this will depend on your current experience with coding. These days though, I expect a lot of people to have had some exposure to very basic coding concepts such as loops, if statements etc. Spending any more time on these concepts may not be worthwhile. What you want is a road map that gets you on your way to building things.&nbsp;</p>



<p>Here it is, my recommended roadmap for learning how to build software:</p>



<h2>1. Start with Web Development</h2>



<p>As I had mentioned, there are many different areas of software development that you could focus on. I recommend starting with Web Development because it has the quickest feedback loop. This will help you improve fast and learn various concepts quickly. Principles learnt here can then be applied to other areas that you may be interested in such as mobile app development or game development.</p>



<p>When learning web app programming, you will be required to pick up HTML, CSS and Javascript. These are core languages for building web apps. But what you want to spend more time and focus on is the backend server system. The backend systems are responsible for providing the data APIs that support your application. Principles that you learn building good backend systems will provide you with a strong software engineering foundation.</p>



<p>For the backend, you will primarily work with either PHP, Python, Java or Ruby. Pick any one that you feel comfortable with. I recommend Python or Ruby to start.&nbsp;</p>



<h2><strong>2. Prioritize building an end-to-end application first</strong></h2>



<p>One of the key principles for effective learning is to focus on depth first. Instead of learning a lot of concepts across the breadth of the topics, I recommend going deep into one specific area. In this case, I suggest focusing on building a simple end-to-end application first.&nbsp;</p>



<p>You will get a general idea of what it is like to build something from scratch. More importantly, you will feel great having a built a working app. The feeling of satisfaction from the progress will motivate and propel you forward.&nbsp;</p>



<p>At this point you are ready to unpack and dive deeper into various aspects of what you have built. </p>











<h2><strong>3. Dive deep into the principles of software architecture</strong></h2>



<p>Once you have built an end-to-end app you will find that learning a couple of frameworks and libraries will be enough to keep you going. Most coding bootcamps stop here. But this stops short of diving into the richer and more rewarding world of software engineering. </p>



<p>I recommend spending time learning software design principles, object oriented programming and various systems architecture patterns. You will learn the details of how to cleanly and effectively work with databases, how to structure your code to enable more complex systems, different design patterns and architectures. </p>



<p>Software architecture&nbsp;principles&nbsp;are timeless and will support you throughout your entire career. </p>



<p>Some great books I can recommend here are:&nbsp;</p>



<p><a href="https://www.amazon.com/gp/product/0321127420/ref=as_li_tl?ie=UTF8&amp;tag=mkngsmlrcrcls-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0321127420&amp;linkId=4962a37ba12a94696993ef4f54eca9fa" target="_blank" rel="noopener">Patterns of Enterprise Application Architecture</a><br><a href="https://www.amazon.com/gp/product/0132350882/ref=as_li_tl?ie=UTF8&amp;tag=mkngsmlrcrcls-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0132350882&amp;linkId=20953e9f7d1dd550a5b402f355cfc2a1" target="_blank" rel="noopener">Clean Code</a></p>



<h2><strong>4. Data structure and&nbsp;algorithms are super important</strong></h2>



<p>The importance of algorithms in software engineering can be surprisingly controversial. This is perhaps due to Silicon Valley tech companies relying on them in the interview process. It’s true that many professional software developers never look back at the algorithms that they vaguely learn in college.&nbsp;</p>



<p>That’s unfortunate. The reality is that deep knowledge of algorithms, just like software architecture are foundational requirements if you want to excel as a software engineer at the highest level.&nbsp;</p>



<p>(Check out the book <a href="https://www.amazon.com/gp/product/0201657880/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0201657880&amp;linkCode=as2&amp;tag=mkngsmlrcrcls-20&amp;linkId=0eb37d6439098ac088b44d65937d4143" target="_blank" rel="noopener">Programming Pearls</a> for some great practical thinking on this).<br></p>



<hr>



<p><strong><br></strong>I hope this roadmap gives you some sense of the various aspects that you can focus on to learn programming and launch a career in software engineering. I have not provided a time estimate here since your progress will vary. Learning something new and complex takes time. If you stick with it, a rewarding career is waiting for you on the other side.</p>



<h2>Subscribe to keep learning more</h2>



<p>Sign up to receive exclusive updates and thoughts on learning how to become a Software Engineer.</p>


<div data-blog-id="164954495">
		<div>
			
			
				<p>
					Processing…				</p>
				<p>
					Success! You’re on the list.				</p>
				<p>
					Whoops! There was an error and we couldn’t process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>	</div></div>]]>
            </description>
            <link>https://makingsmallercircles.com/articles/how-to-learn-programming-a-roadmap-for-success/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24822175</guid>
            <pubDate>Mon, 19 Oct 2020 00:03:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Chose Emacs as My New Text Editor]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24821312">thread link</a>) | @todsacerdoti
<br/>
October 18, 2020 | https://takeonrules.com/2020/10/18/why-i-chose-emacs-as-my-new-text-editor/ | <a href="https://web.archive.org/web/*/https://takeonrules.com/2020/10/18/why-i-chose-emacs-as-my-new-text-editor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody" aria-label="Content">
					<p>About <time datetime="2005-08">15 or so years ago</time>, I was changing jobs.  I was leaving the walled garden of an <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q13741" title="Integrated Development Environment">IDE</abbr> <sup><a aria-label="Other references of Integrated Development Environment" href="https://takeonrules.com/more/glossary/#abbr-dfn-IDE">↑</a></sup>
						for a proprietary language that deployed to an <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q433406" title="IBM System i">AS/400</abbr> <sup><a aria-label="Other references of IBM System i" href="https://takeonrules.com/more/glossary/#abbr-dfn-AS400">↑</a></sup>
						.<span><ins role="note">
								We wrote in <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q840543" title="Report Program Generator programming language from IBM">IBM RPG</abbr> <sup><a aria-label="Other references of Report Program Generator programming language from IBM" href="https://takeonrules.com/more/glossary/#abbr-dfn-RPGP">↑</a></sup>
								and Cool Plex, which looked a lot of meta-code and what I now know to be <a href="https://www.wikidata.org/wiki/Q7839826">RDF Triples</a>
							</ins></span>
					</p>
					<p>At my new job, I was writing web-facing applications using open source technology and deploying to Linux.  I needed to find an editor to help me with the task.</p>
					<p>I spent a bit of time exploring my options.  During that exploration, I learned of <a href="https://www.gnu.org/software/emacs/">Emacs</a> from <a href="https://www.oddbird.net/authors/carl/">Carl Meyer</a>.<span><ins role="note">
								Carl is a friend of mine from high school, and has contributed a lot to the world.
							</ins></span>
					</p>
					<p>At the time I had three young children, I had just changed jobs, changed programming languages, and couldn’t wrap my head around Emacs.  I wanted my editor to behave like other <abbr title="Graphical User Interface">GUI</abbr> <sup><a aria-label="Other references of Graphical User Interface" href="https://takeonrules.com/more/glossary/#abbr-dfn-GUI">↑</a></sup>
						applications.</p>
					<p>I didn’t take the time to walk through the Emacs tutorial, and left Emacs behind.</p>
					<p>A few months into my new job, I switched languages and paradigms again.  In <time datetime="2005-12-03">December 2005</time>, my company hopped in a van and drove to Chicago to learn about <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q842014" title="Django: Python Web Framework">Django</abbr> <sup><a aria-label="Other references of Django: Python Web Framework" href="https://takeonrules.com/more/glossary/#abbr-dfn-DJANGO">↑</a></sup>
						and <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q190478" title="Ruby on Rails: Open Source Web Application Framework">Ruby on Rails</abbr> <sup><a aria-label="Other references of Ruby on Rails: Open Source Web Application Framework" href="https://takeonrules.com/more/glossary/#abbr-dfn-ROR">↑</a></sup>
						.  Within a week, our organization adopted Ruby on Rails.</p>
					<p>At that time, I adopted <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q2297533" title="Textmate">Textmate</abbr> <sup><a aria-label="Other references of Textmate" href="https://takeonrules.com/more/glossary/#abbr-dfn-TEXTMATE">↑</a></sup>
						as my editor.  It had a beautiful user-interface and required little effort to learn.<span><ins role="note">
								I wasn’t aware of how useful a shell environment could be; In the years I’d learn more.  I had, during my professional life, often relied on GUI views into files, systems, and processes.  So I didn’t have a mental model that would have further nudged me towards an integrated text editor.  And in my hubris, I didn’t step through the Emacs tutorial.
							</ins></span>
					</p>
					<p>At the time Textmate was closed source. I used it and loved it, but it began to lag.<span><ins role="note">
								The search a project function started misbehaving and gridning projects to a halt.
							</ins></span>
						I found <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q267193" title="Sublime Text: A sophisticated text editor for code, markup and prose">Sublime Text</abbr> <sup><a aria-label="Other references of Sublime Text: A sophisticated text editor for code, markup and prose" href="https://takeonrules.com/more/glossary/#abbr-dfn-SUBLIME">↑</a></sup>
						and switched.  At the time, Sublime was positioning as a Textmate replacement.</p>
					<p>Then, as I engaged more and more in open source projects, I started wanting an open source text editor.  I learned about Atom in 2015.  It was open source and acted enough like Sublime, that I switched.<span><ins role="note">
								During this time, I dabbled with <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q131382" title="Improved version of the Vi keyboard-oriented text editor">vim</abbr> <sup><a aria-label="Other references of Improved version of the Vi keyboard-oriented text editor" href="https://takeonrules.com/more/glossary/#abbr-dfn-VIM">↑</a></sup>
								.  However, the modal nature of editing felt foreign.  At times, I’d try out a tutorial, but it never stuck.  I also thought about revising Textmate as the owner later released it as open source.
							</ins></span>
					</p>
					<p>Forward to <time datetime="2020-03">earlier this year</time>.  I had begun noticing more and more bugs and breaks in Atom.  Not one to fear changing editors, I started looking.</p>
					<p>I also gave <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q19841877" title="Visual Studio Code">VS Code</abbr> <sup><a aria-label="Other references of Visual Studio Code" href="https://takeonrules.com/more/glossary/#abbr-dfn-VSC">↑</a></sup>
						a spin, and found it disconcerting.  First, it felt constraining and off-putting. The configuration ecosystem felt clunky. The plugins felt like an App Store. Everything felt like VS Code was trying to obfuscate it’s underlying systems.</p>
					
					<p>The proverbial last straw was the <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q186055" title="Git: Free and open source revision control software">git</abbr> <sup><a aria-label="Other references of Git: Free and open source revision control software" href="https://takeonrules.com/more/glossary/#abbr-dfn-GIT">↑</a></sup>
						prompt for commit messages.  The prompt was a small input box; It didn’t encourage meaningful commit messages. Instead it encouraged terse commits. That feature alone told me that people using it will be encouraged to write bad commit messages. I didn’t want to be that guy with my text editor.</p>
					<p>So, I spent a bit of time again testing <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q131382" title="Improved version of the Vi keyboard-oriented text editor">vim</abbr> <sup><a aria-label="Other references of Improved version of the Vi keyboard-oriented text editor" href="https://takeonrules.com/more/glossary/#abbr-dfn-VIM">↑</a></sup>
						and Emacs.</p>
					<p>I again tried <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q131382" title="Improved version of the Vi keyboard-oriented text editor">vim</abbr> <sup><a aria-label="Other references of Improved version of the Vi keyboard-oriented text editor" href="https://takeonrules.com/more/glossary/#abbr-dfn-VIM">↑</a></sup>
						but it felt off.<span><ins role="note">
								I use Vim when I shell out to a server.  I haven’t done it much recently, because I’d likely use Emacs’s <a href="https://www.emacswiki.org/emacs/TrampMode">Tramp mode</a>.
							</ins></span>
					</p>
					<p>I tried Emacs, and worked my way through the Tutorial.  It was the strong commitment to the Tutorial and honestly the writing of that tutorial that nudged me to dive further in.  I spent some time fiddling with Doom or Spacemacs, but in the end settled on bare metal Emacs.</p>
					<p>This proved crucial.  As someone that’s used text editors for 15+ years, I know the features I’ve used. What I chose to do in Emacs was to complete the tutorial and start coding.</p>
					<p>If I found myself wanting a feature, I took note of it.  Then, I went and found the package or packages that implemented the feature.<span><ins role="note">
								I spent quite a bit of time reading through <a href="https://melpa.org/">Melpa</a>, looking for a package. What happened is that I have built up my own editor that meets my needs.
							</ins></span>
					</p>
					<p>Now, 5 months or so in, I’m fully loving the experience. The community of Emacs developers seem to have a higher commitment to writing documentation.<span><ins role="note">
								Many Emacs developers write their configuration files using the paradigm of <a href="https://www.wikidata.org/wiki/Q607703">Literate Programming</a>.  In other words, they first write down their intentions for the software, then write the software.
							</ins></span>
					</p>
					<h2 id="org-mode">Org Mode</h2>
					<p><a href="https://orgmode.org/">Org Mode</a> is the missing piece for my past text editors. <a href="https://www.wikidata.org/wiki/Q93149769">Carstin Dominik</a> took the time to build out functionality for organizing the non-coding tasks of software development, research, and writing.<span><ins role="note">
								Were I to begin my blog anew, I’d leverage <code>org-mode</code> and <a href="https://ox-hugo.scripter.co/">ox-hugo</a> for blogging.
							</ins></span>
					</p>
					<p>Org Mode layers meaningful tools on top of plain text files; The syntax is close to Markdown, but different enough. The simplicity of structure makes the world of difference. With the plain text, I can run low-level Unix commands (e.g. <code>grep</code>, <code>sed</code>, etc.) but also have higher level programmatic access to the data.</p>
					<h2 id="magit">Magit</h2>
					<p>Prior to <a href="https://magit.vc/">magit</a>, I almost always used command line tools for <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://www.wikidata.org/wiki/Q186055" title="Git: Free and open source revision control software">git</abbr> <sup><a aria-label="Other references of Git: Free and open source revision control software" href="https://takeonrules.com/more/glossary/#abbr-dfn-GIT">↑</a></sup>
						. My previous workflow would be to use Terminal to state my git commits, and then my text editor to write commit messages.<span><ins role="note">
								Atom’s slowness to open as a commit message editor was another reason I left Atom.  I don’t want to wait multiple seconds to start writing a commit message.
							</ins></span>
					</p>
					<p>Except for reading git logs, I now do most all git tasks with Magit.  That includes an <strong>amazing</strong> interactive <code>git rebase</code> environment.</p>
					<h2 id="fill-paragraph">Fill Paragraph</h2>
					<p>I must mention this lowly command.</p>
					<p>When Carl introduced me to Emacs, he showed me <code>fill-paragraph</code>. That functionality stuck with me. It’s nothing fancy, but it shows that Emacs treats column-width as a first class citizen.</p>
					<p>And why is column width important?  First, <a href="https://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html">re-read the note about commit message</a>.</p>
					<p>Conforming to that structure helps ensure that your <code>git log</code> excursions are not unduly messy.  It also helps if you’re going to interact with the command-line.  In other words, automatic word-wrapping is nice, but its not universal, nor does it work in all contexts.</p>
					<p>I have used this command to quickly wrap documentation so as to not have it flow off the screen.<span><ins role="note">
								For coding buffers, I disable word wrapping.  I also aspire to 120 character line width for code and 80 character line width for comments.  Why the variance?  Comments should read more like prose, and long running lines make the paragraphs harder to read.
							</ins></span>
					</p>
					<p>It ain’t much of a command, but I’ve held a candle for it since I learned about Emacs.</p>
					<h2 id="swiper">Swiper</h2>
					<p>I never knew I wanted Swiper until I stumbled onto it.  I now use it <em>all of the time</em>; It’s even replaced my default Find behavior in Emacs.</p>
					<p>What does it do? I type Control+S<span><ins role="note">
								In Emacs parlance, that’s <code>C-s</code>
							</ins></span>
						and start typing a word.  In a mini-buffer at the bottom of the current buffer, I see the lines that include that word.  It’s a bit like a find with context.  Importantly, this doesn’t move my cursor in the main buffer.</p>
					<p>So I end up quickly referencing something and get back to typing.  Or, I can navigate through the mini-buffer and jump to that location in the main buffer.  Quite slick.</p>
					<h2 id="wgrep-ag">WGrep-Ag</h2>
					<p>The <a href="https://github.com/mhayashi1120/Emacs-wgrep/blob/master/wgrep-ag.el">wgrep-ag</a> package sort of blew my mind. It allows you to use <abbr itemprop="mentions" itemscope="" itemtype="https://schema.org/Thing" itemid="https://github.com/ggreer/the_silver_searcher" title="The Silver Search (ag)">ag</abbr> <sup><a aria-label="Other references of The Silver Search (ag)" href="https://takeonrules.com/more/glossary/#abbr-dfn-AG">↑</a></sup>
						with <a href="https://github.com/mhayashi1120/Emacs-wgrep">wgrep</a> to edit search results</p>
					<p>Follow along carefully:</p>
					<p>In Emacs, I search a project using <code>ag</code>.  Emacs renders the search results in a mini-buffer. In this case, the mini-buffer is a small set of rows at the bottom of Emacs that show a subset of the results.</p>
					<p>With the mini-buffer active (e.g. I’ve been typing results there), I invoke <code>ivy-occur</code>.  That function opens all of the search results in a read-only buffer.<span><ins role="note">
								While I was writing this example, I thought to myself “I wonder if I can use <code>ivy-occur</code> from Swiper results?  Yes I can.  So I learned something while explaining something.
							</ins></span>
					</p>
					<p>With this new buffer, I invoke the function <code>wgrep-change-to-wgrep-mode</code>.  This toggles <code>ivy-occur</code> buffer into an edit mode.  I begin editing the search results as though it were it’s own file.</p>
					<p>Then I save the edits, and <code>wgrep-ag</code> writes all of those changes back to the found results.</p>
					<p>Another way to think of it, <code>wgrep-ag</code> loads a semi-structured buffer. Each row has three fields: file name, line number, and line text.  I can use <code>wgrep-ag</code> to write those changes back to the originating file.</p>
					<p>Seriously, this functionality amazes me.</p>
					<h2 id="multiple-cursors">Multiple Cursors</h2>
					<p>Textmate first introduced me to this powerful concept.  Since then, this functionality has been a mandatory feature of my editors.</p>
					<p>Two packages help deliver on this:</p>
					<ol>
						<li>
							<a href="https://github.com/victorhge/iedit">iedit</a> - by default, if I type Control+<code>;</code> (e.g. <code>C-;</code>), the iedit package highlights each occurence of the word. I can now type and iedit updates all occurrences.</li>
						<li>
							<a href="https://github.com/magnars/multiple-cursors.el">multiple-cursors</a> - this package provides finer grain control, and allows me to set a cursor on ten contiguous lines and start typing.</li>
					</ol>
					<h2 id="expand-region">Expand Region</h2>
					<p>I didn’t know what I was missing until I installed <a href="https://github.com/magnars/expand-region.el">expand-region</a>.  Now with Control+<code>=</code> (e.g. <code>C-=</code>) my cursor  expands to the smallest logical region (e.g. highlighting a word), typing it again expands that region (e.g. highlighting the sentence), etc.  And Control+Shift+<code>=</code> (e.g. <code>C-+</code>) contracts the region.</p>
					<h2 id="org-roam">Org Roam</h2>
					<p>Building on <code>org-mode</code>, <a href="https://orgroam.com/">org roam</a> incorporates note taking paradigms inspired by <a href="https://en.wikipedia.org/wiki/Zettelkasten">Zettelkasten</a>.</p>
					<p>I’ve used this to write up campaign notes for my <a href="https://takeonrules.com/series/new-vistas-in-the-thel-sector/">New Vistas in the Thel Sector campaign</a>.  The bi-directional link and quick note capture tools make for a dream in information management.</p>
					<p>In …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://takeonrules.com/2020/10/18/why-i-chose-emacs-as-my-new-text-editor/">https://takeonrules.com/2020/10/18/why-i-chose-emacs-as-my-new-text-editor/</a></em></p>]]>
            </description>
            <link>https://takeonrules.com/2020/10/18/why-i-chose-emacs-as-my-new-text-editor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24821312</guid>
            <pubDate>Sun, 18 Oct 2020 21:37:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gravity is not a force – free-fall parabolas are straight lines in spacetime]]>
            </title>
            <description>
<![CDATA[
Score 774 | Comments 408 (<a href="https://news.ycombinator.com/item?id=24821141">thread link</a>) | @tim_hutton
<br/>
October 18, 2020 | https://timhutton.github.io/GravityIsNotAForce/ | <a href="https://web.archive.org/web/*/https://timhutton.github.io/GravityIsNotAForce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>For full functionality of this site it is necessary to enable JavaScript.
    Here are the <a href="http://www.enable-javascript.com/" target="_blank">
    instructions how to enable JavaScript in your web browser</a>.
    </p>



    <p>
    <canvas id="canvas" width="1360" height="480">(Canvas drawing not supported by your browser.)</canvas>
    </p><p>
      Change the frame acceleration: 
    </p>
    <p>
      Move the time window: 
    </p>
    

    <h4>Description:</h4>
    <p>
    Under general relativity, gravity is not a force. Instead it is a distortion of spacetime. Objects in free-fall move along geodesics (straight lines) in spacetime, as seen in the inertial frame of reference on the right. When standing on Earth we experience a frame of reference that is accelerating upwards, causing objects in free-fall to move along parabolas, as seen on the left.
    </p>

    <p>
    In this system there is only one space dimension, shown on the vertical axis and labeled in meters. The time dimension is the horizontal axis and labeled in seconds. The gravitational field is constant within the area of interest. 
    </p>

    <p>
    Use the first slider to change the acceleration of the frame of reference in the middle. When the frame has zero acceleration it is said to be an inertial frame of reference.
    </p>

    <p>
    Use the second slider to move the time window. Note that all the trajectories remain as straight lines in the inertial frame of reference.
    </p>

    <p>
    You can drag the start and end position of each object to change their trajectories. All free-fall trajectories in the inertial frame of reference are straight lines.
    </p>

    <p>
    Code, more details, feedback: <a href="https://github.com/timhutton/GravityIsNotAForce">https://github.com/timhutton/GravityIsNotAForce</a>
    </p>

    <p>
    More on these concepts: <a href="https://youtu.be/XRr1kaXKBsU">https://youtu.be/XRr1kaXKBsU</a>
    </p>





</div>]]>
            </description>
            <link>https://timhutton.github.io/GravityIsNotAForce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24821141</guid>
            <pubDate>Sun, 18 Oct 2020 21:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container Networking Is Simple]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24820990">thread link</a>) | @iximiuz
<br/>
October 18, 2020 | https://iximiuz.com/en/posts/container-networking-is-simple/ | <a href="https://web.archive.org/web/*/https://iximiuz.com/en/posts/container-networking-is-simple/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a name="cut"></a>
Working with containers always feels like magic. In a good way for those who understand the internals and in a terrifying - for those who don't. Luckily, we've been looking under the hood of the containerization technology for quite some time already and even managed to uncover that <a href="https://iximiuz.com/en/posts/not-every-container-has-an-operating-system-inside/#container-is-just-a-processes">containers are just isolated and restricted Linux processes</a>, that <a href="https://iximiuz.com/en/posts/you-dont-need-an-image-to-run-a-container/">images aren't really needed to run containers</a>, and on the contrary - <a href="https://iximiuz.com/en/posts/you-need-containers-to-build-an-image/">to build an image we need to run some containers</a>.</p>
<p>Now comes a time to tackle the container networking problem. Or, more precisely, a single-host container networking problem. In this article, we are going to answer the following questions:</p>
<ul>
<li>How to virtualize network resources to make containers think each of them has a dedicated network stack?</li>
<li>How to turn containers into friendly neighbors, prevent them from interfering, and teach to communicate well?</li>
<li>How to reach the outside world (e.g. the Internet) from inside the container?</li>
<li>How to reach containers running on a machine from the outside world (<em>aka</em> port publishing)?</li>
</ul>
<p>As a result, it'll become apparent that the single-host container networking is nothing more than a simple combination of the well-known Linux facilities:</p>
<ul>
<li>network namespaces;</li>
<li>virtual Ethernet devices (veth);</li>
<li>virtual network switches (bridge);</li>
<li>IP routing and network address translation (NAT).</li>
</ul>
<p>And for better or worse, no code is required to make the networking magic happen...
<a name="eofcut"></a></p>
<h2 id="prerequisites">Prerequisites</h2>
<p>Any decent Linux distribution would probably suffice. All the examples in the article have been made on a fresh <em>vagrant</em> CentOS 8 virtual machine:</p>
<pre><code>$ vagrant init centos/8
$ vagrant up
$ vagrant ssh

[vagrant@localhost ~]$ uname -a
Linux localhost.localdomain 4.18.0-147.3.1.el8_1.x86_64</code></pre>
<p>For the sake of simplicity of the examples, in this article, we are not going to rely on any fully-fledged containerization solution (e.g. <em>docker</em> or <em>podman</em>). Instead, we'll focus on the basic concepts and use the bare minimum tooling to achieve our learning goals.</p>
<h2 id="a-namenetnsaisolating-containers-with-network-namespaces"><a name="netns"></a>Isolating containers with network namespaces</h2>
<p>What constitutes a Linux network stack? Well, obviously, the set of network devices. What else? Probably, the set of routing rules. And not to forget, the set of netfilter hooks, including defined by iptables rules.</p>
<p>We can quickly forge a non-comprehensive <code>inspect-net-stack.sh</code> script:</p>
<pre><code>#!/usr/bin/env bash

echo "&gt; Network devices"
ip link

echo -e "\n&gt; Route table"
ip route

echo -e "\n&gt; Iptables rules"
iptables --list-rules</code></pre>
<p>Before running it, let's taint the iptables rules a bit to make them recognizable:</p>
<pre><code>$ sudo iptables -N ROOT_NS</code></pre>
<p>After that, execution of the inspect script on my machine produces the following output:</p>
<pre><code>$ sudo ./inspect-net-stack.sh
&gt; Network devices
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff

&gt; Route table
default via 10.0.2.2 dev eth0 proto dhcp metric 100
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100

&gt; Iptables rules
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT
-N ROOT_NS</code></pre>
<p>We are interested in that output because we want to make sure that each of the containers we are going to create soon will get a separate network stack.</p>
<p>Well, you might have heard already, that one of the Linux namespaces used for containers isolation is called <em>network namespace</em>. From <a href="https://man7.org/linux/man-pages/man8/ip-netns.8.html"><code>man ip-netns</code></a>, <em>"network namespace is logically another copy of the network stack, with its own routes, firewall rules, and network devices."</em> For the sake of simplicity, this is the only namespace we're going to use in this article. Instead of creating fully-isolated containers, we'd rather restrict the scope to only the network stack.</p>
<p>One of the ways to create a network namespace is the <code>ip</code> tool - part of the de facto standard <a href="https://en.wikipedia.org/wiki/Iproute2">iproute2</a> collection:</p>
<pre><code>$ sudo ip netns add netns0
$ ip netns
netns0</code></pre>
<p>How to start using the just created namespace? There is a lovely Linux command called <code>nsenter</code>. It enters one or more of the specified namespaces and then executes the given program:</p>
<pre><code>$ sudo nsenter --net=/var/run/netns/netns0 bash
# The newly created bash process lives in netns0

$ sudo ./inspect-net-stack.sh
&gt; Network devices
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00

&gt; Route table

&gt; Iptables rules
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT</code></pre>
<p>From the output above it's clear that the <em>bash</em> process running inside <code>netns0</code> namespace sees a totally different network stack. There is no routing rules at all, no custom iptables chain, and only one loopback network device. So far, so good...</p>
<div>
    <p><img src="https://iximiuz.com/container-networking-is-simple/network-namespace.png" width="80%"></p><p><i>Network namespace visualized.</i></p>
</div>


<h2 id="a-namevethaconnecting-containers-to-host-with-virtual-ethernet-devices-veth"><a name="veth"></a>Connecting containers to host with virtual Ethernet devices (veth)</h2>
<p>A dedicated network stack would be not so useful if we could not communicate with it. Luckily, Linux provides a suitable facility for that - a virtual Ethernet device! From <a href="https://man7.org/linux/man-pages/man4/veth.4.html"><code>man veth</code></a>, <em>"veth devices are virtual Ethernet devices. They can act as tunnels between network namespaces to create a bridge to a physical network device in another namespace, but can also be used as standalone network devices."</em></p>
<p>Virtual Ethernet devices always go in pairs. No worries, it'll be clear when we take a look at the creation command:</p>
<pre><code>$ sudo ip link add veth0 type veth peer name ceth0</code></pre>
<p>With this single command, we just created a pair of <em>interconnected</em> virtual Ethernet devices. The names <code>veth0</code> and <code>ceth0</code> have been chosen arbitrarily:</p>
<pre><code>$ ip link
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
5: ceth0@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 66:2d:24:e3:49:3f brd ff:ff:ff:ff:ff:ff
6: veth0@ceth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 96:e8:de:1d:22:e0 brd ff:ff:ff:ff:ff:ff</code></pre>
<p>Both <code>veth0</code> and <code>ceth0</code> after creation resides on the host's network stack (also called root network namespace). To connect the root namespace with the <code>netns0</code> namespace, we need to keep one of the devices in the root namespace and move another one into the <code>netns0</code>:</p>
<pre><code>$ sudo ip link set ceth0 netns netns0

# List all the devices to make sure one of them disappeared from the root stack
$ ip link
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
6: veth0@if5: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 96:e8:de:1d:22:e0 brd ff:ff:ff:ff:ff:ff link-netns netns0</code></pre>
<p>Once we turn the devices on and assign proper IP addresses, any packet occurring on one of the devices will immediately pop up on its peer device connecting two namespaces. Let's start from the root namespace:</p>
<pre><code>$ sudo ip link set veth0 up
$ sudo ip addr add 172.18.0.11/16 dev veth0</code></pre>
<p>And continue with the <code>netns0</code>:</p>
<pre><code>$ sudo nsenter --net=/var/run/netns/netns0
$ ip link set lo up  # whoops
$ ip link set ceth0 up
$ ip addr add 172.18.0.10/16 dev ceth0
$ ip link
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
5: ceth0@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
    link/ether 66:2d:24:e3:49:3f brd ff:ff:ff:ff:ff:ff link-netnsid 0</code></pre>
<div>
    <p><img src="https://iximiuz.com/container-networking-is-simple/veth.png" width="100%"></p><p><i>Connecting network namespaces via veth device.</i></p>
</div>

<p>We are ready to check the connectivity:</p>
<pre><code># From `netns0`, ping root's veth0
$ ping -c 2 172.18.0.11
PING 172.18.0.11 (172.18.0.11) 56(84) bytes of data.
64 bytes from 172.18.0.11: icmp_seq=1 ttl=64 time=0.038 ms
64 bytes from 172.18.0.11: icmp_seq=2 ttl=64 time=0.040 ms

--- 172.18.0.11 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 58ms
rtt min/avg/max/mdev = 0.038/0.039/0.040/0.001 ms

# Leave `netns0`
$ exit

# From root namespace, ping ceth0
$ ping -c 2 172.18.0.10
PING 172.18.0.10 (172.18.0.10) 56(84) bytes of data.
64 bytes from 172.18.0.10: icmp_seq=1 ttl=64 time=0.073 ms
64 bytes from 172.18.0.10: icmp_seq=2 ttl=64 time=0.046 ms

--- 172.18.0.10 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 3ms
rtt min/avg/max/mdev = 0.046/0.059/0.073/0.015 ms</code></pre>
<p>At the same time, if we try to reach any other addresses from the <code>netns0</code> namespace, we are not going to succeed:</p>
<pre><code># Inside root namespace
$ ip addr show dev eth0
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 52:54:00:e3:27:77 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic noprefixroute eth0
       valid_lft 84057sec preferred_lft 84057sec
    inet6 fe80::5054:ff:fee3:2777/64 scope link
       valid_lft forever preferred_lft forever

# Remember this 10.0.2.15

$ sudo nsenter --net=/var/run/netns/netns0

# Try host's eth0
$ ping 10.0.2.15
connect: Network is unreachable

# Try something from the Internet
$ ping 8.8.8.8
connect: Network is unreachable</code></pre>
<p>That's easy to explain, though. There is simply no route in the <code>netns0</code> routing table for such packets. The only entry there shows how to reach <code>172.18.0.0/16</code> network:</p>
<pre><code># From `netns0` namespace:
$ ip route
172.18.0.0/16 dev ceth0 proto kernel scope link src 172.18.0.10</code></pre>
<p>Linux has a bunch of ways to populate the routing table. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iximiuz.com/en/posts/container-networking-is-simple/">https://iximiuz.com/en/posts/container-networking-is-simple/</a></em></p>]]>
            </description>
            <link>https://iximiuz.com/en/posts/container-networking-is-simple/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24820990</guid>
            <pubDate>Sun, 18 Oct 2020 20:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unforced Management Errors]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24820465">thread link</a>) | @hackitup7
<br/>
October 18, 2020 | https://staysaasy.com/management/2020/10/05/unforced-errors.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/10/05/unforced-errors.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the more helpful frameworks that I’ve found in my career has been to aggressively avoid unforced errors in management. In tennis, unforced errors are cases where a player missed a shot due to their own mistake, rather than due to their opponent. In management, unforced errors are problems where the source is <em>you</em>, rather than an objective business need or external circumstance.</p>

<p>I define unforced errors as problems caused by taking action, when doing absolutely <strong>nothing</strong> would have worked just fine: cases when you mess with something that wasn’t broken in the first place. In addition to being annoying, unforced errors distract from existing priorities and open up new fronts in any battles that you’re currently engaged in. And since the solution is so easy – just do nothing – learning how to identify them can pay dividends.</p>

<h2 id="common-types-of-unforced-errors">Common Types of Unforced Errors</h2>

<p>Unforced errors generally come in a few easy to identify forms.</p>

<p>The most common is deciding to “fix” a problem that doesn’t matter, or that doesn’t exist at all. One of the prototypical examples is the decision to migrate to a new technology stack because it seems cool, or because your current technology choice is no longer in vogue. Maybe you’re running Ruby or PHP but really want to try out Rust, despite the fact that your product is otherwise working fine and you’re not having trouble finding and retaining engineers. This invention of a problem can lead to Tech Debt Science Projects in which your team rebuilds otherwise working technology. If anything breaks (it likely will), you’ve caused an unforced error.</p>

<p>Another class of unforced errors comes from deciding to standardize or regulate a system that’s working fine. For example, imagine a case where your engineering teams are all running agile processes differently. Some teams aren’t disciplined about retrospectives, some teams are highly regimented about story sizing while others wing it, and some teams occasionally insert “break” weeks in between sprints so that schedules never quite align. To a certain kind of person, this type of inconsistency feels deeply wrong – like a house in which all of the walls were a very slightly different color.</p>

<p>But your business doesn’t require consistency for aesthetic purposes, or for its own sake. In some situations, you can tolerate somewhat haphazard team processes for a surprisingly long time – dodging the upfront effort of standardization, the ongoing effort of maintaining it, and the overall risk of standardizing on a system that doesn’t actually help everyone on balance. (of course, if there are real upsides to enforcing consistency then you should go for it)</p>

<h2 id="catching-unforced-errors-before-they-happen">Catching Unforced Errors Before They Happen</h2>

<p>In my experience unforced errors often stem from a yearning for control. When times are tough it can be tempting to latch onto areas where you already have mastery and look for ways to optimize them, and this optimization feels like productive work. Ironically, this means that you’re more likely to cause unforced errors, as these familiar domains are areas where you’re probably doing well – focus is needed in the areas of the business that you rarely think about, where your existing decisions are the least battle-tested.</p>

<p>The general solution to unforced errors is to ruthlessly prioritize. Focus on the problems that are truly existential threats to your business and team, or represent transformational opportunities.</p>

<p>My simple heuristic for avoiding unforced errors is to always imagine the worst thing that can happen if you just skip a new project – what would happen if you had never thought about this initiative at all? This is especially true when you’re talking about changing something rather than doing something new. If the worst that happens is that you miss a chance for a 5-10% optimization of a non-essential part of your business, alarm bells should be gently ringing.</p>

<p>Unforced errors are a pain – not only do they distract, but the optics can be pretty bad when a lot of hard work backfires. By avoiding these hiccups, you can keep your team happier and focus on getting the wins that are most important to your business.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/10/05/unforced-errors.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24820465</guid>
            <pubDate>Sun, 18 Oct 2020 19:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The local timeline is the key to enjoying Mastodon]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 113 (<a href="https://news.ycombinator.com/item?id=24819387">thread link</a>) | @carlesfe
<br/>
October 18, 2020 | https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html | <a href="https://web.archive.org/web/*/https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="divbodyholder">

<div id="divbody"><div>
<!-- entry begin -->
<h3><a href="https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html">
You may be using Mastodon wrong
</a></h3>
<!-- bashblog_timestamp: #202010181913.37# -->
<p>October 18, 2020 — 
Carlos Fenollosa
</p>
<!-- text begin -->

<p>I'm sure you have already heard about <a href="https://joinmastodon.org/">Mastodon</a>,
typically marketed as <em>a Twitter alternative</em>.</p>

<p>I will try to convince you that the word <em>alternative</em> doesn't mean here what you think it means,
and why you may be using Mastodon wrong if you find it boring.</p>

<h4>An alternative community</h4>

<p>You should not expect to "migrate from Twitter to Mastodon."</p>

<p>Forget about the privacy angle for now. Mastodon is an alternative community, where people behave
differently.</p>

<p><strong>It's your chance to make new internet friends.</strong></p>

<p>There may be some people for whom Mastodon is a safe haven. Yes, some users really do migrate
there to avoid censorship or bullying but, for most of us, that will not be the case.</p>

<p>Let's put it this way: Mastodon is to Twitter what Linux is to Windows.</p>

<p>Linux is libre software. But that's not why most people use it. Linux users mostly want 
to get their work done, and Linux is an excellent platform.
There is no Microsoft Word, no Adobe Photoshop, no Starcraft. If you need to use these tools, honestly,
you'd better stick with Windows. You can use emulation, in the same way that there are
utilities to post to Twitter from Mastodon, but that would miss the point.</p>

<p>The bottom line is, you can perform the same tasks, but the process will be different.
You can post <em>toots</em> on Mastodon, upload gifs, send DMs... but it's not Twitter, and that is fine.</p>

<h4>The Local Timeline is Mastodon's greatest invention</h4>

<p>The problem most people have with Mastodon is that they "get bored" with it quickly. I've seen it a lot, and
it means one thing: <strong>the person created their account on the wrong server</strong>.</p>

<p>"But," they say, "isn't Mastodon federated? Can't I chat with everybody, regardless of their server?"
Yes, of course. But discoverability works differently on Mastodon.</p>

<p>Twitter has only two discoverability layers: your network and the whole world. Either a small group of
contacts, or everybody in the whole world. That's crazy.</p>

<p>They try very hard to show you tweets from outside your network so you can discover new people.
And, at the same time, they show your tweets to third parties, so you can get new followers.
This is the way that
they try to keep you engaged once your network is more or less stable and starts getting stale.</p>

<p>Mastodon, instead, has an extra layer between your network and the whole world:
messages from <em>people on your server</em>. This is called the <em>local timeline</em>.</p>

<p><strong>The local timeline is the key to enjoying Mastodon.</strong></p>

<h4>How long it's been since you made a new internet friend?</h4>

<p>If you're of a certain age you may remember BBSs, Usenet, the IRC, or early internet forums.
Do you recall how exciting it was to log into the unknown and realize that there were people
all around the world who shared your interests?</p>

<p>It was an amazing feeling which got lost on the modern internet. Now you have a chance to relive it.</p>

<p>The local timeline dynamics are very different. There is a lot of respectful interactions among total strangers,
because there is this feeling of community, of being in a neighborhood. Twitter is just the opposite, strangers
shouting at each other.</p>

<p>Furthermore, since the local timeline is more or less limited in the amount of users, you have the chance
to recognize usernames, and being recognized. You start interacting with strangers, mentioning them, sending them
links they may like. You discover new websites, rabbit holes, new approaches to your hobbies.</p>

<p>I've made quite a few new <em>internet friends</em> on my Mastodon server, and I don't mean followers or contacts.
I'm talking about human beings who I have never met in person but feel close to.</p>

<p>People are humble and respectful. And, for less nice users, admins enforce codes of conduct and, 
on extreme cases, users may get kicked off a server. But they are not being banned by a faceless corporation
due to mass reports, everybody is given a chance.</p>

<h4>How to choose the right server</h4>

<p>The problem with "generalist" Mastodon servers like <a href="https://mastodon.social/">mastodon.social</a>
is that users have just too diverse interests and backgrounds.
Therefore, there is no community feeling. For some people, that may be exactly what they're looking for. But, 
for most of us, there is more value on the smaller servers.</p>

<p>So, how can you choose the right server? Fortunately, you can do a bit of research. 
There is an official <a href="https://joinmastodon.org/communities">directory of Mastodon servers</a> categorized by
interests and regions. </p>

<p>Since you're reading my blog, start by taking a look at these:</p>

<ul>
<li><a href="http://bsd.network/">bsd.network</a>, for fans of BSD systems</li>
<li><a href="http://linuxrocks.online/">linuxrocks.online</a>, for Linux fans</li>
<li><a href="http://fosstodon.org/">fosstodon.org</a>, for free software in general</li>
<li><a href="http://tilde.zone/">tilde.zone</a>, for oldschool internet users</li>
<li><a href="https://merveilles.town/">merveilles.town</a>, with a very particular mixture of art and technology</li>
<li><a href="https://metalhead.club/">metalhead.club</a>, to enjoy those classic riffs</li>
</ul>

<p>And the regionals</p>

<ul>
<li><a href="https://mastodont.cat/">mastodont.cat</a> for catalans</li>
<li><a href="https://mastodon.madrid/">mastodon.madrid</a> for madrileños</li>
</ul>

<p>There are many more. Simply search online for "mastodon server MY_FAVORITE_HOBBY." And believe me, servers
between 500 and 5,000 people are the best.</p>

<h4>Final tips</h4>

<p>Before clicking on "sign up", always browse the local timeline,
the about page, and the most active users list. You will get a pretty good idea of the kind of people
who chat there.
Once you feel right at home you can continue your adventure and start following users from other servers.</p>

<p>Mastodon has an option to only display toots in specific languages. It can be very useful to avoid being
flooded by toots that you just have no chance of understanding or even getting what they're about.</p>

<p>You can also filter your notifications by types: replies, mentions, favorites, reposts, and more.
This makes catching up much more manageable than on Twitter.</p>

<p>Finally, Mastodon has a built-in "Content Warning" feature. It allows you to hide
text behind a short explanation, in case you want to talk about sensible topics or just about spoiling
a recent movie.</p>

<p>Good luck with your search, and see you on the Fediverse! I'm at
<a href="https://mastodon.sdf.org/@cfenollosa">@cfenollosa@mastodon.sdf.org</a></p>

<p>Tags: <a href="https://cfenollosa.com/blog/tag_internet.html">internet</a></p>
<!-- text end -->
<p id="twitter"><a href="http://twitter.com/intent/tweet?url=http://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html&amp;text=%3CType%20your%20comment%20here%20but%20please%20leave%20the%20URL%20so%20that%20other%20people%20can%20follow%20the%20comments%3E&amp;via=cfenollosa">Comments? Tweet</a> 
<a href="https://twitter.com/search?q=http://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html"><span id="count-18287"></span></a>&nbsp;</p>
<!-- entry end -->
</div>

</div></div></div>]]>
            </description>
            <link>https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24819387</guid>
            <pubDate>Sun, 18 Oct 2020 17:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Avoid Overengineering]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24818966">thread link</a>) | @Mongoose
<br/>
October 18, 2020 | https://evanm.website/2020/10/how-to-avoid-overengineering/ | <a href="https://web.archive.org/web/*/https://evanm.website/2020/10/how-to-avoid-overengineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <div>
  <p>Published October 01, 2020</p>
  <a href="https://evanm.website/2020/10/how-to-avoid-overengineering/"></a>
  
  <p>This article considers the conditions that lead teams to produce overengineered software and describes how you can avoid falling prey to such conditions.</p>

<h2 id="what-do-we-mean-by-overengineering">What do we mean by “overengineering”?</h2>

<p>When a software developer says that a piece of software is <em>overengineered</em>, they are saying that they think it has too many moving parts, too much abstraction, or an excessive emphasis on performance. The number of concepts required to understand the thing feels unreasonable.</p>

<p>It’s a fundamentally subjective call, but you know it when you see it. Like a Ferrari at a go kart race, an overengineered system is out of scale with its operating environment and intended usage.</p>

<p>But how does it happen? Are there certain conditions that lead teams to produce systems that observers would perceive as overengineered?</p>

<p>To determine this, let’s consider two stereotypical software
engineering phenomena: cargo culting and a related pattern that I’ve
started to call “the Xoogler effect”.</p>

<p>From there, we can characterize certain cognitive biases that drive a team towards overengineering.</p>

<h2 id="cargo-culting">​​Cargo culting</h2>
<p><img src="https://evanm.website/images/overengineering/cloudnativelandscape.jpg" alt="The Trillion Dollar Homepage"><span>Fig. 1. <a href="https://landscape.cncf.io/">The Trillion Dollar Homepage</a>.</span></p>

<p>A <a href="https://en.wikipedia.org/wiki/Cargo_cult">cargo cult</a> is a cultural phenomenon in which technologically-advanced artifacts become objects of obsessive ritual to a group of people outside of the artifact-producing society. While the term has fallen out of favor within the field of anthropology (in acknowledgement of its reductive and colonialist overtones), it’s fairly common in software circles.</p>

<p>To a software engineer, “cargo culting” is used pejoratively to refer to the adoption of a technology or practice based solely on its origin or popularity. Loosely, the thinking goes that if a tool, language, or convention was developed at or inspired by ideas from a large, successful company, then that tool must have contributed to the company’s success. Thus, in adopting it, you increase your odds of also succeeding.</p>

<p>Examples:</p>

<ul>
  <li>“Era-defining companies like Intel and Google used OKRs, so we should too.”</li>
  <li>“The SRE book talks about how Google relies on service level objectives, so using them will help our services become more reliable.”</li>
  <li>“Most successful companies end up needing advanced load balancing and request-proxying systems to scale their microservices architectures. Our 10-person startup should adopt these systems in order to help us scale.”</li>
</ul>

<p>Like incorporating in Delaware or only hiring graduates of name-brand universities, a particular practice correlating with notable instances of company growth doesn’t imply causation. Just because a <a href="https://en.wikipedia.org/wiki/Authority_bias">popular or successful</a> company uses a technology doesn’t mean that it’s appropriate or worthwhile for your situation.</p>

<h2 id="the-xoogler-effect">The Xoogler effect</h2>

<p>When people leave engineering jobs at big, successful tech companies, they take their former employer’s engineering culture with them. This tends to be highly valuable, for both the technical acumen of the new company and the incoming engineer’s compensation package.</p>

<p>But this tendency can be taken too far. The incoming employee, believing that they have a direct line to the state of the art, may go on to recreate systems in their former employer’s image to an unreasonable degree.</p>

<p>Not to pick on Googlers, but something about that company’s culture really brings this out. There are many notable examples of Xooglers replicating Google-internal systems and practices in the outside world, either as independent startups or efforts within existing companies. I don’t find this terribly surprising, given the tone that’s set within Google—you spend your time there constantly being told that you’re among the best software engineers to walk the face of the Earth, using technologies unmatched in their power, quality, and scalability. It makes sense that former employees feel compelled to emulate things that worked at Google<sup><a id="fn1ref" href="#fn1">1</a></sup>.</p>

<p>But this generalizes to other large and/or successful companies. Many people leave the productivity bubble of a “FAANG and friends” company and end up building tools and systems that they miss. To name but a few, this is how we got Thrift, Envoy, and <a href="https://bazel.build/">three</a> <a href="https://www.pantsbuild.org/">different</a> <a href="https://buck.build/">tools</a> based on Google’s build system.</p>

<h2 id="cognitive-biases">Cognitive biases</h2>

<p>I think these two phenomena can be linked to a handful of widely-known cognitive biases. Cargo culting is a clear manifestation of <a href="https://en.wikipedia.org/wiki/Authority_bias">authority bias</a>. And the Xoogler effect seems related to <a href="https://en.wikipedia.org/wiki/Law_of_the_instrument">the law of the instrument</a>.</p>

<p>It’s rational to want to stay within your <a href="https://fs.blog/2013/12/circle-of-competence/">circle of competence</a>, but it can be counterproductive in excess. When you’ve been inculcated in the expert use of hammers, every problem looks like a nail. Your thinking in new environments is <a href="https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)">anchored</a> by prior experience in old environments, which can impede learning and the development of new skills.</p>

<p>And it turns out that these two patterns can feed on each other. Cargo culting is <em>catalyzed by</em> the Xoogler effect in cases when a former big company employee’s experience is uncritically venerated by new colleagues.</p>

<h2 id="how-to-resist-the-urge-to-overengineer">How to resist the urge to overengineer</h2>

<p>Resisting the temptation to overengineer requires one to be honest with themselves about the context in which they’re operating.</p>

<p>You should always design systems to address problems that are in front of you instead of falling for solutions to problems faced by big companies in the past. You shouldn’t base your company’s infrastructure on GitHub stars. And as wistful as you may be for your last company’s tools, they may not be as applicable to your current situation as you think.</p>

<h3 id="assessing-cargo-without-becoming-a-cultist">Assessing cargo without becoming a cultist</h3>

<p>When evaluating a popular tool, language, or convention, it’s worthwhile to take the time to understand the underlying forces that motivated its invention<sup><a id="fn2ref" href="#fn2">2</a></sup>. Before making any decisions, try to contextualize a technology within the environment that formed it. From there, you can pattern match that environment to your own in order to determine if the technology is appropriate.</p>

<p>As an example, let’s consider everyone’s favorite overengineering punching bag: Kubernetes.</p>

<p>Kubernetes traces its conceptual lineage to Borg<sup><a id="fn3ref" href="#fn3">3</a></sup>, the cluster-management system that’s run Google’s production workloads for over a dozen years. The main value that Borg provides to Alphabet is its ability to maximize the capital efficiency of their datacenters. The technology that we now call “container orchestration” allowed them to get more computing oomph out of their fleet by maximizing utilization and making more efficient use of machines they’d already paid for.</p>

<p>Is maximizing capital efficiency of your datacenter or cloud environment a concern for your company? If you believe Kubernetes offers other benefits<sup><a id="fn4ref" href="#fn4">4</a></sup>, are you confident that they outweigh the complexity and maintenance overhead?</p>

<p>I find this thought process helpful when evaluating new tools, patterns, frameworks, or management practices. Conventional wisdom advocates that you fully understand a problem before applying a solution to it. It’s also important to understand the conditions that led to a solution and how those conditions align with those you find yourself in.</p>

<p>Regardless of the decision you end up making, this process is likely to make you a better engineer. The job is fundamentally about building systems to solve problems at reasonable cost. That cost is measured not only as upfront capital expenditure, but in the ongoing drag associated with maintenance and cognitive load. More often than we realize, engineering is about right-sizing a solution in light of these ongoing costs.</p>

<h2 id="further-reading">Further reading</h2>

<p>A few links to other reading material on related topics:</p>

<ul>
  <li><a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail">Reality has a surprising amount of detail</a>, by John Salvatier</li>
  <li><a href="https://lethain.com/learn-to-never-be-wrong/">Learn to never be wrong</a>, by Will Larson</li>
  <li><a href="http://boringtechnology.club/">Choose Boring Technology</a>, by Dan McKinley</li>
  <li><a href="https://evanm.website/2016/03/synthesis-over-invention/">Synthesis over invention</a>, by yours truly</li>
  <li>The concept of “integrative thinking”, as described in Roger Martin’s book, <a href="https://www.goodreads.com/book/show/2001132.The_Opposable_Mind">The Opposable Mind</a></li>
</ul>

<hr>

<p><em>Thanks to
<a href="https://www.linkedin.com/in/paupadhyay/">Parth Upadhyay</a>,
<a href="https://thisisehsan.com/">Ehsan Noursalehi</a>,
<a href="https://twitter.com/wil">Wilhelm Bierbaum</a> for reading
and providing feedback on drafts of this essay.</em></p>

<hr>

<section>
  <ol>
    <li id="fn1">Not to be that guy, but for full disclosure, I've had two stints at Google/Alphabet in my career, first as a lowly intern in 2010 and more recently leading a software team on an early-stage project at X. <a href="#fn1ref">↩</a></li>
    <li id="fn2">This research can often be done by reading blog posts or conference papers related to the technologies in question (major plug for <a href="https://blog.acolyer.org/">The Morning Paper</a>'s digestible summaries of papers). Recorded conference talks can be good sources, too. If you are networking-inclined, nothing beats being able to hear from experienced people directly. <a href="#fn2ref">↩</a></li>
    <li id="fn3">Or really, <a href="https://research.google/pubs/pub41684/">Omega</a>. Long story. <a href="#fn3ref">↩</a></li>
    <li id="fn4">Container orchestration tools are marketed as solutions for developer productivity and software scalability, which has always felt like revisionist history to me. In my understanding, these were not the primary concerns this technology was invented to address. <a href="#fn4ref">↩</a></li>
  </ol>
</section>


  <!-- Sharingbutton Twitter -->
  <a href="https://twitter.com/intent/tweet/?text=&amp;url=https://evanm.website/2020/10/how-to-avoid-overengineering/" target="_blank" aria-label="">
    
  </a>

  <!-- Sharingbutton Facebook -->
  <a href="https://facebook.com/sharer/sharer.php?u=https://evanm.website/2020/10/how-to-avoid-overengineering/" target="_blank" aria-label="">
    
  </a>

  <!-- Sharingbutton LinkedIn -->
  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://evanm.website/2020/10/how-to-avoid-overengineering/&amp;title=&amp;summary=&amp;source=https://evanm.website/2020/10/how-to-avoid-overengineering/" target="_blank" aria-label="">
    
  </a>

  <!-- Sharingbutton E-Mail -->
  <a href="mailto:?subject=&amp;body=https://evanm.website/2020/10/how-to-avoid-overengineering/" target="_self" aria-label="">
    
  </a>

</div>

      </div></div>]]>
            </description>
            <link>https://evanm.website/2020/10/how-to-avoid-overengineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24818966</guid>
            <pubDate>Sun, 18 Oct 2020 16:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cursed Elixir]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24818706">thread link</a>) | @udfalkso
<br/>
October 18, 2020 | https://evuez.github.io/posts/cursed-elixir.html | <a href="https://web.archive.org/web/*/https://evuez.github.io/posts/cursed-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
        <time datetime="2020-08-12">2020-08-12</time>
      <p>Let's write some Elixir.</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    if a &lt; 0 do
      bar(a, -1)
    else
      bar(a, 1)
    end
  end

  defp bar(a, b) do
    IO.inspect(a * b)
  end
end
</code></pre>
<p>Not very useful, but that's good enough for our purpose.</p>
<p>I like Elixir, but I think most of the time it just looks like functional Ruby. I want to make this code look like Elixir.</p>
<p>First, this code is lacking every Elixir developer's best friend: <code>|&gt;</code>. Let's add some <code>|&gt;</code>s.</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    if a &lt; 0 do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    (a * b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>Meh. It's definitely better, but I mean, that's only 3 <code>|&gt;</code>s. I want more <code>|&gt;</code>s.</p>
<p>We have an <code>if</code> in there, so maybe we can do something with it?</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    (a &lt; 0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    (a * b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>We sure can! That's one more <code>|&gt;</code>. Can we do better than this?</p>
<p>Well... <code>&gt;</code> and <code>*</code> are <code>Kernel</code> functions, so maybe...</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>This is great, can we keep going?</p>
<p>The Elixir docs say <code>defmodule</code> is just a macro. Does that mean I can just <code>|&gt;</code> into <code>defmodule</code>?</p>
<pre><code>FooBar |&gt; defmodule do
  def foo(a) do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>Yes you can!</p>
<p><code>def</code> and <code>defp</code> are macros too right?</p>
<pre><code>FooBar |&gt; defmodule do
  a |&gt; foo() |&gt; def do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  a |&gt; bar(b) |&gt; defp do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>So many pipes! 😍</p>
<p>We're getting somewhere, but something still doesn't feel right. This module really isn't doing much, so maybe it should not be that long? Also, I think we need more <code>:</code>. Atoms are very Elixir-y, so let's do more of that:</p>
<pre><code>FooBar |&gt; defmodule(do: (
  a |&gt; foo() |&gt; def(do: a |&gt; Kernel.&lt;(0) |&gt; if(do: a |&gt; bar(-1), else: a |&gt; bar(1)))

  a |&gt; bar(b) |&gt; defp(do: a |&gt; Kernel.*(b) |&gt; IO.inspect())
))
</code></pre>
<p>We're <code>:do</code>ing great!</p>
<p>You know what's also very Elixir-y? Lists. Lists and tuples.</p>
<pre><code>FooBar |&gt; defmodule([{:do, (
  a
  |&gt; foo()
  |&gt; def([{:do, a |&gt; Kernel.&lt;(0) |&gt; if([{:do, a |&gt; bar(-1)}, {:else, a |&gt; bar(1)}])}])

  a |&gt; bar(b) |&gt; defp([{:do, a |&gt; Kernel.*(b) |&gt; IO.inspect()}])
)}])
</code></pre>
<p>Who's going to say this looks like Ruby now? ⚗️</p>
<hr>
<p><a href="https://news.ycombinator.com/item?id=24818706">discussion on hackernews</a> /
<a href="https://www.reddit.com/r/elixir/comments/jd2hr4/cursed_elixir/">discussion on reddit</a></p>

    </article></div>]]>
            </description>
            <link>https://evuez.github.io/posts/cursed-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24818706</guid>
            <pubDate>Sun, 18 Oct 2020 15:49:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calliope: Automatic Visual Data Story Generation from a Spreadsheet [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24818571">thread link</a>) | @rbanffy
<br/>
October 18, 2020 | https://datacalliope.github.io/2020_VIS_Calliope_Camera.pdf | <a href="https://web.archive.org/web/*/https://datacalliope.github.io/2020_VIS_Calliope_Camera.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>] &gt;&gt;
stream
xœcbd`àg`b``8	"Y3ÁìZÉh&amp;ïI¦=×Al¦C R(D²ü‘‚s€$£Lˆ­Í"¥ë@¤šˆüÍÀÄø×æØLÆQr”¤œò
endstream
endobj
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
430 0 obj
&lt;&lt; /Names 329 0 R /OpenAction 373 0 R /Outlines 299 0 R /PageMode /UseNone /Pages 298 0 R /Type /Catalog &gt;&gt;
endobj
431 0 obj
&lt;&lt; /Filter /FlateDecode /S 164 /O 241 /Length 220 &gt;&gt;
stream
xœc```b``ÝÇÀÂÀÀÇÍ Ê`6+�É²@ÉDI�A~÷Wö}Q–=MBñŒ%93�Íó8h°ú900°ï&gt;»fŠAbJ•fŽö|NY“&nbsp;á‡Ô}µ–nXWÃSriU´T¸�à”—¡ºK+/Ì
õÎŒg^h¼4dÛÔç@%S^E†lÀk8¨1h¤si ‹Üeb`Ð^¿€yŠàD†ã¿?äMÑÒgËp
ûèPáz›©�¡ÖÑ%!¿…mýÁ�&gt;Ü?øž6ºñ›ƒæÿh°ÇÅŸ'gJ
endstream
endobj
432 0 obj
&lt;&lt; /Annots [ 375 0 R 376 0 R 377 0 R 378 0 R 379 0 R 380 0 R 381 0 R 382 0 R 383 0 R 384 0 R ] /Contents 435 0 R /Group 374 0 R /MediaBox [ 0 0 612 792 ] /Parent 271 0 R /Resources 385 0 R /Type /Page &gt;&gt;
endobj
433 0 obj
&lt;&lt; /BitsPerComponent 8 /ColorSpace /DeviceRGB /Filter /FlateDecode /Height 548 /SMask 436 0 R /Subtype /Image /Type /XObject /Width 1549 /Length 178969 &gt;&gt;
stream
xÚì½œÕ•ïÏî{Ï»ïÙ¬wßg×^/û¤Qa‚5`Œ1Ø$�–Á6`‘œ0iacl¯‰&amp;Œ‰HBirèœsÏtÏLOç0Óir¨êêTõ?·k¦ÕS]Ý3£8áü&gt;Wút×Ü{ëÔ¹n}ûÜ{Ó�Æ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	&amp;L˜0aÂ„	¦Ê)“a²™4&amp;L‹4eÒ©£x9dñrÀ´˜ÓÑ|4¤SèOL‹91x9`Â„=%L˜ðrÀ„éð^r¹,‡B-ZeÒGó]€ÍçÑ¥¨E*–ÍÝ÷b¨½ŠZ¤Êç²GõE �.E-^e³GóG|q@-î‡¾8&nbsp;Pü‹‹w{ÔRîü~È¤ñn�Â»}¾p-¤¡Pù\ö(^ˆ‰P‹Z¹\ú(^øâ€ZÜ/Ù£y9à‹j1¿8°Õ¯¼Û£ñ‹@&gt;ïóyºœ�¿÷¨Üðñn�Z¼b˜”«§»ËéˆEûŽür@L„ZÔ‚‹.‡±Ñá#¿¡µ¢Ñ&gt;è)õºz&amp;'ÆŽürÀÔ¢~qðû}ü‹b"Ô2W:�†÷¸ú"!Ñ¡úx·G-ê»½ÍjQ«”NG'b"Ô2EQz�.‡`À‡˜µÌ‹E5j\Cƒˆ‰PË\�[¥T˜MÆ‰ñQÄD¨å¬\.×a·Ãåàtt &amp;B-s¥R)�V�%¿Ïƒ˜µÄ”Ïçí6+œÞ]Nb"Ô2EQ½.‡PÐ�˜µÌ�Ç´5\ˆ‰P(¯×£V)-fb"Ô2W.—ëìè€Ë¡ËÙ‰˜µÌ•J¥ô:-t–~/b"Ôb"ª(ÄD(TQˆ‰P¨¢¡P¼¡PE!&amp;B-a!&amp;B¡ŠBL„B…˜…*
1
Å1
Ub"Ôb"ª(ÄD(TQˆ‰P¨¢¡P¼¡PE!&amp;B-a!&amp;B¡ŠBL„B…˜…*
1
Å1
Ub"Ôb"ª(ÄD(TQˆ‰P¨¢¡P¼¡PE!&amp;B-a!&amp;B¡ŠBL„B…˜…*
1
Å1
Ub"Ôb"ª(ÄD(TQˆ‰P¨¢¡P¼¡PE!&amp;B-a!&amp;B¡ŠBL„B…˜…*
1
Å1
Ub"Ôb"ª(ÄD(TQK±¹›£æu²ù››dóóèÚ± ØKŽ™§m4Ió³-Mlcóó±-_8œyøŸ�¶mž‡Ã'Ìç¦N.Ø–™ÏápW§¡Pˆ‰P(ÄD}}}6›Í:-·Û]ü|ýä“O,¶
1
…˜…BLÊ$ÚS÷ÒúïÐºoÑ–[Ó¡¿²Ù‰êE²c]©ž'hÃÕ)í·hãf¦÷·¹Iÿ,ÏPf(íÿmº‰ìEEÊñóÌ&nbsp;z66’KGÒ¶;hÝe´îÛ´õ¶tä“Y¹GvØ’êzˆÖ�ìÈ´…ñ¼˜££³¼ÍÑQÈ™¶}ŠC%³¡ž&amp;ÃÀ&lt;Û™èA0xWªáÀáð¶Ý·ÌbÛ¤ÜN&amp;®‡÷&lt;‘ëžÅÕ™ñtð]hJZw)­¿&lt;ÕqO&amp;ÑvÜn±ˆ‰P(ÄD(ÔÄDÛ¶mûÒ—¾´ª&nbsp;ššš›o¾™ßþÄO|ùË_&gt;ÿüóÿõ_ÿõ?ÿó?±±Pˆ‰P(ÄD(ÔrÆDlŽaº§¤«ii
-[KËÖÑÒÕ”dmÚ’›T*•Žì¢iÈ&amp;[CŠÀÿ’”òÜL¼¥"ºuRºïŠ¬.Y{¤dëSîçX6W�uŒÑ?¥$5´tÕ´m«(ÉJÚz{.•¨´#Æÿ6%;�–®œ*ÂÛ¦¹8;¨«hÛ&nbsp;2”Ø¶*�ª*¾ý¥`1†ØÆYELíø)˜-îj6‡|ÈÕà
°M÷]pNE¬oÇ
]­ØMP+(ãÒˆÒWK×¤ºŸob"
1
µd0Ñ¦M›Þzë-š¦†�ø
Ãç?ÿy…BŸµZí¾ð•J…í…BL„B!&amp;B¡–-&amp;b&lt;ÏQ’Siy--ß0#IVÒ¦DcŠ2I%Û@øƒ&nbsp;ˆl-¥Ø˜±‹&lt;=™$¥½œAy-%YÉÞ£*yÚù0MlÛPfÛ
Úv—èÐ°tÿ&gt;Jº†–¯/³m5¥:?7áƒ*~ø!6Â­‡ª&nbsp;B1ÓÒ`1CÄ¶SÁlNl¤&amp;ÁJå®–®ç€‹DøÕˆ�à8ÙÚ²ÃYM
!âêìe¼�P²2WƒÁ)÷³ˆ‰P(ÄD(Ô2ÄDÙlö´ÓN“Éd±XÌçóÁW~û¯~õ«K.¹¤˜íŠ+®¸ÿþû±½Pˆ‰P(ÄD(ÔòÄD¹	¥8Cª%Y‘$BHL7‘0±"´´&amp;eÿI9$a¼/‰C•ñ&nbsp;UçåS1awnØHoÊ¡Ê”m«2ñ&amp;¡m™qZ÷o#º#ÉŠT÷c"×îÇ*Û¶*„j…&nbsp;,Þˆ‘×‚Ù`¼°ÿ�ŠÁaŠ°µiÛÀE"&nbsp;Ìþz$îêÕÐå¬,þ�ªt8òõÐÜ¹	7b"
1
µÜ0ÑèèèŠ+.ºè¢3Î8ãÔSO…ÿ­V+l¿òÊ+ñ‹_³=úè£—]v¶
1
…˜…Zž˜(üKEBRˆrIYog¹fv¬›’µ½! Bù9ºOH–×T¤7„ùÔ¤£û…dÉýûª¶Õ¤œéÍ&nbsp;Š’®­XD¶ŽÖ|3Ÿ�ñXÏŒÂÆŠôl“®…j…}]çé
Ï|Ü¿º:ºŸI«hÛp‘€ù€Á™• áQò¯
&amp;)bY–Ì•T	â‚Ä˜à;ˆ‰P(ÄD(ÔrÃDÑh´¦¦æ‰'ž€Ï×_ýÆ�³Ùì¥—^úØc‡~Ezæ™g.¸à‚9Ö999¹ÿþ={ö|V¢]»võôô”g†}555íÞ½[�Ùd2‰V.—Ëá¯‚Ì2™L43T"È;‚Ýƒ¦Jår¹&gt;ýôÓÒÌpp p8å™ûúú5ó•'“"QÐÃÃÃŸ•	Šûý~ÑS¢®®®Ü{���¢¦­­­Ü{Z­1
…˜µTO±ñ‚WLäz’.«È.Ö¦ô—sù³Ùä¤Õ(„¼––ÕæFgŒ;c3Ã´úZ¶¾
WÉø_b¢ÎûÄ©Š¥IYnžEý»¨*‡¶)ÎÌS¡�u*+S¯
P!T+ìØXn®æé*0^ˆ°ü¯U£^àõà¨®µƒ3«Ø6@sˆ\J…È µL”v=…˜…BL„B-7LDžÅ™L)*9ùä“ý~ÿ–-[JG™=øàƒW\qÅÜß†<xw¢ýû÷—®¡vÚ×moo?pà€ 3Ôt.�fdv«Å×þ°Ùl‚Ì°#Ø�(&óöíÛwšg¯="" jæ+,Ï<22rw&(="" Ë33="" ÓÜÜ\î½®®®òÌ,ËÊd²rï�fÄdÇøi6ÉŽ;Ø‰.±+j˜·çúwä"ïæ‡tl*Œ7:b"Ô‘Ÿ?ñxÜëõÂsm§Ó+”j•j-‘hô«³÷ïªb¢5´ájÁ="" ìÙauaòŸÊ(f~zn¼k&&§5w‰Ø!ì"(œ,šqþ²zÄŽtuÊz›ðau="blSþGžîŸñX§ûi±SÕdÊ&quot;�RÕ#v¤5`¼�Èß®êêuà&quot;Áè6p#8³šmÒ5Ù™KÅ±ù,4Y•À-MTé„˜…BL„B-yLär¹ž|òÉ&quot;6q»Ý_üâ#‘È¯ýësÏ=·˜í¢‹.zðÁ±½Pˆ‰HÇ’‰¥-7¤RŠÓÙ‰™ì£ÆvkJyútÿ¿–±Ü”‹îgàù€¯ùˆ‰P‡¡ÉÉI¥RÙÞ.Ù±c‡Ùbíq¹|þ@8Ò×�A2™Í" …žÚ½½½¢±¯ˆ‰Ž¢2±ºj\eº2åö”rt?¥üzÅ‘p²u”öÁÀ.–ÍÓÖu="" *="" ìÒ”q•w«…ß��]™e@œl="" mÜÌæfø¾ÂÆÊ\ed`w¯ý¡ºm`¼ÐÕƒšjâÀ9Ö±3çt7‚3+ãµõÐ¹™Ô‹ôÃ�¿›¿ºt|ßaÄd(b"j¹a"¿ßÿw÷wÏ="÷ÜÄÄD,Û¼yó7¾ñ" x»ïîî="">ùä“¡S
¯6»wïþÂ¾`·Û±½Pˆ‰¸•é~�G@)å×JŠØ1kJ{áÔŸ´›Rª³¦&gt;«¿‘ëûÏÄDˆ‰P‡ÑIho—t÷¸’ƒmmíV›=‹Gúú‹	¾úü™L®Ñê ÃÈÈb¢cøPËŒÑºËiñè&nbsp;ÂTÌCz‘Fìª&lt;ç³dãyQŒG5æ|®'$¦ËjÏÓý…ÈÖŠÑ¢gæÆ]ÂÝ°9Ú¾½$¡$+Ó¡Êmƒ�‡ªAUöíP­ð±9îÄ‡ÑÉÖ‚Ùù2z‡Y�•Õ’¹c�å¶�3«¸¢¼4%]/Îñ¤«)Ýåˆ‡˜…BL„B-LÚ»wïÚµk7lØ°bÅŠsÏ=·84ìí·ß&gt;å”S`;üÿÆo`c¡‘·„àŸSŠÓE0Qžfì?"Uÿ‘ñ=ËR^–ög¯§ä·Ú´ýv}†˜1j^Êd2r¹¢»Ç‹'zÝžºúú`(Ü×-ÅD�`K,yÜo»D�F;e$G0„J¶®|žñ¡c´þª¾¨¬·N›o¥,›Ku=VX�k½p-xå×³#6Ñ‘Õíeë…¡&gt;²µ”t5S®3u8^JóÍ²ÑjëÉ:õö{À
Ûr)øÉ ´­ªÊMxEw€BŠ%[ƒÙâ¶�ØH –�­§
À‡esbOèQp©¸«õWACˆwÅÝÏð%C’­¦ä_Ë$åÇá¤BL„B!&amp;B¡ &amp;MLLX­ÖÎÎNÁÐÛ4ýýýØR(ÄDäˆÚRšóÉp3Ý%Ð�,ÅDìX­ ³"¤m·@ïöPßØ¼™°#ÝÅâ¡!&amp;BUÐÈÈÈ�ÔjM(Ù½gO§ÃÙ×õùüýÑ˜€#‹::z½1Ñ±%EƒJÚp%%]E&amp;Ï‘¬$„Aun:ø–(¸˜z÷¡"´};a8…"¤”ì´”ã�&lt;3P©›cRž(åYT±ˆt
mÜ’¶T±-k&nbsp;µ—–ØVC«7¥Ã;«Î¸‹¶l£dkÙ&amp;ÿZªç©|¦âéð'ÈÙÙÅ-Û²åK¥¶…w‚1Ä¤©ÃY¦‚ÁÕl¶À!“/ºZy¸¥&lt;˜ê�mÌ8–’ŸVâêõà|h‚Š®†êoQªsKl[Mé¿—PŸ3
1
…˜…Z˜˜…BL4«XÊÃ˜¯¡åÒŽ{3î§ÑD¹èn&gt;Ä(xuFÇØqo!Äèìü¨O	ÄDˆ‰Pó¸çÀëk.§R©œ]Ý&amp;³¥¡¡±¥¥u×®]§³&lt;¦¨Y$“Ëþ
h‹‘¦ÉNfmißËiïóé¾Ýù™+ÚWjÍì°9x+ã}.|7;ê˜ÓKÓ¤?ÞAöâ-“”WÁ#‡ž¼é‘L¬&gt;íûcÚûbº_&gt;•˜Ý¶|6;¨MûßHƒm¡÷sã½s²m¼2“"þ7&nbsp;8T2»m©˜DóýŒSg·-ÇÀ�Ãá'„w€Cæ„òFàdâêÀ[àvvwKhÄtß®´÷…´ï•L¼5Ÿ9~3}!&amp;B¡¡Pˆ‰Pˆ‰åÝ&gt;;’îÜN¦¤6_ËÒþŒû7L”lÏô&lt;œéz€-ÅA™á”þ2RÊ¥xJ &amp;BL„š¯‚Á&nbsp;V§K:œ]*µ¦×íÙ¿ÿ€(#‚Ô�Ù;:+­þ‰˜…Z€BL„B!&amp;B¡¡-¾»=›ÉxOÆši/ÈI	þ)ÃDbÇOgº˜
1r?	_ñ”@L„˜5_Ùív«ÍÎ¯k�'‚¡pcc“( âCŒ|þb"
1
…˜1
1
…˜è&gt;¶b»hÕÙ)åéÙÐ›ÇÎ±L4í¼?¥ØP@ºŽ¥<x> &amp;BL„š—X–µX,j�¶tˆY4ÞÚÚÖãê-ÝŸ»º»Á¿Q&amp;—Ãù†˜…BL„B!&amp;B¡¡Pˆ‰Žþ›Ú˜…Ñ›Du?Äå¦Þ¼ªb"6?$cLWóqDŒå†ü¨Ob"Ô|‹ÅärE,žÌSm0µ:}&lt;‘CüF“Ù²ç³Ïš›["ýQ~Ü1
…˜…BL„B!&amp;B¡uMÍA­ûv6ôV.º‹OLçO
+��žõ¿_9fzþR6�ñ¿œRŸ[øë™ž1Ž…˜uxÒjµn·G0[5YìÌ8pð`sKKCccSss]}}}CƒßÐjuJ•:‹ûÁO&gt;ù:ˆ‰P(ÄD(b"
1
…˜èèŠé¸��ª’rá¿Q&amp;í¸?¥øj+}3~�Ë�ãi€BL„:
Êäòþh\t93 ÐÕÕ
ŸÁ�?ŒÆâ}…8¢ú††®îøÜÒÒJÓw&gt;´ÅŽ‰rt:ôÓõ0ãü%ã});bŸµ›¥3±¦çIÆñSÆõt6ÙÎæ3³–ÊÏsŒóçL÷#™ÈÎ&lt;38»m“&amp;ðÓõ ã|€ñ½–ï™ýa�ÍôÆt?NvÔû»Ì€ŠegyÚBÈ™¶=Å¡’Ùmï“ˆa`^à-0uvÛ˜�tdÓý(ãüã~.;d˜õÆÇæÓ™D8™ØÖód&amp;VÏfgƒ	�MI´ëah\hbÄD(b"
1
…˜HuÞÉ¿+H)ÝÅ„)6�Ï†ËH@t2CïL
43]��â	€BL„:léõzÁDRTò§Cy]½îh,n³wØíö{t‹¥ûvSªó(ÉJZZC’d%%?-Õóë*,"7æ&nbsp;M×S…ÌSE¤«S–m¹I_et3’r&gt;HÉÖÓ%;¢µßÌ$Z*£–	ü…Rþ%Y1]d¥8ƒñ¼TIeµ´î
Jù‹¶­¡íÛót¬¢mt2�lS¶­$ÅuW@U•ÑMÌcèiÛÀH0®²Z}&amp;ÞBi¾YêpHÊñ«|z¤¢«'|´ùûàÞW×ÐÆë²£ŽÊ�‚æƒF,îš1
…˜…BLt¬4éæú&gt;äüÏqÁ×¸A)—Ãõž-ª»}vŒeb‚”q?ÅÏM”³ÂWèe²© £ÿÙ¨&gt;'íüy.º{Fêßõà)�˜1jŽ}©TV‰UGn�·¹¹%›
@’+ÐåFLt”Qÿ&gt;Jº––­¥åJR-%95å|D4'7é§ÕÐÒU3‹l PBwy&gt;•ƒ*é”ý'´äÔÂO%Edk(Ù†ì€\Ô6Âˆ$5´lÝÌ­§$+RîgÅŸoÃ6Jq6-]]fÛ
Ú´5ŸãWcð'’APDºª‚
ÅOi÷³^É×Ï&lt;œu`0˜-Îˆ’2JöU8d�«É®mÛÙ#b[*Né¾Kx—Ð¶J}anÂ+ÆÖòÐp”ˆ«×BCCs#&amp;B¡¡Pˆ‰Ž²Ø,y—³ÞÀ™¯âÌ×pæ«Iêþ7‰³µ &amp;ZÜwûò)¬sñý%ÃÐ6”§ü�O	ÄDˆ‰Ps‘ÍfÓEà3—™å
¥Á`äKÁw™\&gt;&gt;¾@Ç½.RL”g’”úÂ2F4MŠ¤«3‰ör‘êü)!BbÏZ²‚qýZäÓ·«béjÚð=6;!|½šðQŠ³ÊÑ´m²
ÙaKŒÊÐ–[EøU!Q`›ïuå{�*gDS¶­¢Í·–G.Á®Áñ‡£l˜
Æ—Á¨	Zÿ=Z¶º‚m+Ó‘OE:Õ=OÑ•l“¬„†(¿mB“‘Ð#qÛÖBsC£#&amp;B¡¡Pˆ‰Ž¦ú&gt;äLWrÖ-„“ùÎñ.=€­�˜hc"×£…Ag§1QÆýt%@Ä÷Òóƒ8
1b"ÔìbYÖl6ë§�ÏC‰œ]ÝMMÍýÑ¿&gt;X¬6…B�˜è(*Ý·‹ªDo
!+©Îû„o=TˆÐAM	$¡5›òé!¾Iz³ºÒŽ�J
(ŒÿO	I’”ó¨ìˆ­"½)D.Ñúï±3#Àák�Þ¬©ô¤#<jdp»¦«øm²Œ>d“Rª²ˆsÌ·²ln&amp;Ä¤Ô›*€²BT•bcn2(ì‡wÞGšUrµd%4:b"
1
…˜èè[˜³Ý"dDS¤è*.òl}ÄD‹ønŸcÇEFthKåD‚ëPˆ‰¡Êº¥CÃ‚Á&nbsp;L&amp;Sk´ÁPx^¡Dmmí]Ý=ELÛ¼&gt;¿N§CLt41Qï3Õp‡l-m¸RK“TTÃòZZ¶!7Ö9ÅdFiÍ…•qa&gt;éÀBãøyÜAKW§¬Û„(&amp;º—R«b›ò¬&lt;™ñX§#°±Êo"P!T+&lt;É­ÛèjÌ§Œº:ðçª®^Gk.bgNšM&amp;€’o¨f›tMvP9Èe&nbsp;É*„‡M»º÷ÄD(b"
1ÑÑë$CÌÊ$Ëu\×ý\žÁ1ÞíQˆ‰-ç›d{{»T*õx&lt;“““‹E¡T‚¡y
7ã¡PcS,Ý
G$RiÿøØØB[õlÑb¢§«c¢”þ»l~†1ÙY5BBJÕæFí31Ñ­¹€–­¯~“¼^†‰î¯4|l
Ynb¢þÝ³`"ÅÆ&lt;ž‰‰Â°qLÔ/œù¹zp˜
Æ—a¢ªÁQàÍ&amp;pÔLLÔÎ¬Ö+]-˜Ö‰Ì¥ÿîl˜èiÄD(b"j™c"†aJ—œ€^«ßïŸ˜˜8œº"ïVÄDÖë¹ŽÛ¹Ì0žˆ‰ðn�BL„˜hÙ*‰h´ºp¤Ïh2·¶µY¬¶ù¢b4QsK‹Çë+�õ&gt;Ã¨_­ÑJe2—Ë3™ÌB8ðÅŠ‰ÂVÃDÒU´ýNá[Ï„‡R|­òÀ®õ´ê‚Y¬Ù|6eº¡òÀ®
”tU&amp;Þ$ì¿y_¬&gt;è,Õõ¨&nbsp;HvÈ@U‰Y’­¥µßÎÏœ	¾ÂÆ*\*„j…}Ý®Ggtæ}Qˆ°âMTêÎ1ÝŽša[*N©¾Qq|Ÿ¼–’
šC°#h²jxM²1
…˜…ZÎ˜èí·ß&gt;ãŒ3âñ8ÿuß¾}ëÖ­«©©Y»víîÝó_4¶»Z4‘s;—£ð@L„w{b¢eŽ‰X–I&amp;“ve®c$•Jåõùûú£ýÑŸƒñãËöîÝçrõ
Gƒ¯ÑX|0M
¥R«Õ.'/RL”£Â”òë•†ƒQ’‘…±Ø\ÊöÃŠÃÁ$+SÎ_‰ð¨à;™¡7—äÓÂÚrcJþÕ
�¤–’®Í(ËL£iÃµã|$+˜Þß—Û+ÚU¯eË´…]“åáÄYÙz0ŒöÒÃ´æ›y‰§z§ü^’r<pyêïÚúcÁtf¿t]¥�*Ù:hnhtÄd(b"jÙb"£Ñxra‘‡î÷ûÿéŸþé¥—^Šf£¯¿þú¿øÅÞÞÞùÕ8éâ¬7v˜›èjÎÿ"¶>b"¼Û£!&amp;‚§Lss‹Õf;XWŸ—Ï)‘L&amp;Jåá…	—íß@¯7À‡*ÙHÈQ"	~Öëtp6žXX´H1�$�w
Ta½È
ò¶;EWiÏ�vPŠ3E¢ƒ¤«hõùùI¿;ÍNÐ¦EhŒl™¿:*¾Jûô¢óµe+ÈŸšr&gt;Ì²"ÐÂ¢óDhŒ´†Ò]žOÅEžìdÑùËEÀ—l-TŠYtþaº|Ñyy-f‹Nº/%]#å¤+)ã�ùŒÈ*~d¹7õ"ÑA²5”â¬ò¹µ¬Œ�†_ë¡¡…˜…BL„B-L488xúé§?òÈ#+W®‡Éï&amp;¿ýíoÏ&lt;óÌb†sÎ9ç‰'ž˜çK‘‡³Ý$†‰®çìÛ8Ê‹­�˜ïö(ÄDˆ‰|&gt;ŸÍfOêô»Ý¾|N	½^ßSÿsÃÍ\½îv‰$‘˜c~«Õ¶k×n�Çƒ˜è0Ä²yÆ÷%?�D­HWR
™¤Ú~wž¬TŠÌP¤¹˜0é*Zºþ'Ÿu—g‡Í&nbsp;t„¶l£¤5È�"«	ÊPlL‡?¨h[.�rý–’Õ–Ø¶’’®I9Œ›IcPªsé¶­¤�×åÆ\_åÆ\��d›.Å¡¨ªâád'À‚}¤Ó¶IV‚©`0˜]Ê…&gt;&nbsp;¶­.ì¨†8Ä²-GE*ºzØŽ¸šÒ\$Ê¯¦lc¡ù¨BS²M~:4´([CL„B!&amp;B¡–&amp;bYöúë¯¿çž{"‘È¿ÿû¿ó˜èºë®»ûî»‹y~ùË_^yå•ó«wÆÜD[8Û–’ù«Ê±l}ÄDx·G!&amp;ZÎ˜hhhÈãõªTªâª^-­­Ëä|�Éå‡7Ê¬”ùtuu765Œ¦¹G%ÅI�V«˜—Éd&nbsp;266–?6wÝÅ‹‰¦XÄh'ãz&amp;eÝ–²Üœrþ*ofó³DgåSñtà­”ýŽ”ùÆTÇötøý|zd–îY&gt;�‰H9~ž2ß”²ÞÆxžËM¸g·mÈ�êy"e¹5e¹%Õõhf@1ë­"7d¼/§l?JYnJuÜ›Ž|R+±dƒÌ¤ˆíGP¼|­ù²Þ&amp;Æ€IÄ00¯ç‰òYŒDlïeÜÏÂá§,[S�?ÏD÷‹†lÍ°-=”½—²o'~³ÝÁÞÌ§b³¹:�MIÔº
šø¸�Nˆ‰P(ÄD(ÔÄDÏ=÷Ü×¿þuš¦ý~ÿ)§œÂc¢K.¹ä±Ç+æyæ™g6mÚ4çƒb¬&amp;uÖ~	*&nbsp;¡´q+¥¿u:²hgÛÊÑ¡â
Áb±h4m‰Ôju¥:�N§ 3|u8¢™¡¨J�v'lß××'È2ÐFå™fð•C§º&lt;óÄÄ„¶L°¯â4P¥J§ÓF£±&lt;³h—žeY»Ý^î=—Ë…˜èø(=¨ÊxŸÍø_œJ¾²Ç~b¢%€‰B¡°J­qvuQ”ŸH'©Ôêå@Š"‘qOæš;8‚²v{Çž=Ÿ½úÚk®^÷¼¢’ÀÏR™LôQ,«Õ
¶íÙ³G*•f³Ç¤²Ø1
…˜…BL„B-aL$“ÉV®\év»Ï)ï)§œÒßßŸ¿ûÝï&gt;ðÀÅl�?þø¥—^:Ç:GF'Û?{Žµ\7&gt;d¿®³õ¿¤û_&lt;Pd¾†”ò™3™Ì§Ÿ~úÎ;ï¼[¢·ÞzK¡PˆVÞÐÐðöÛo—f†¯õõõ¢™•J%TUšv»]êÅn·¿ùæ›¥™ÿò—¿|ðÁãã"ãß�€À¾rÑ‰5à•çÝ2�a¢0Þ%?þøcØµ ³Ñhå0{÷î-÷^[[b¢ã£ñÞ?Ð­ÿJBâ‰jÿ©A-ÞÙPˆ‰f½9He²p¤_@Eúú£A‚�È/ápx�,Ëu,Nxlùü8üx!#qAÝ=:½Þfï˜c‘ÉdnhhwµK$Åp¬9&amp;¯Ï/—Ë½³ÙUI¥2gW·?„VÈ³[.b"
1
…˜…Z°˜èöÛoÿÇüÇ/¼ð¼óÎ;óÌ3?÷¹ÏmÜ¸qçÎ�&gt;øàW\QÌvíµ×Þu×]s¬Þ]r�?O�8ÛÂÙnÌŒ¹ÓT’ë¸m*&nbsp;þ~«˜?�N3“.|­ô&amp;¼5”g®ô*•”g†ÿ+Ýš™y±bïbÐy.Ï[D;ÕPCyµ�Yô—ÜJ™çå�côû/b¢rMx^,]W…’­K
éñÎ†BL4Ûc‚Õh´áHŸèº]¡pÄj³óa’�@€]*³0•ÞU*•No�ÉJ¥Ñd†-ápØn·ËärpB•è&nbsp;h,®Óë[ZZÁ�¼»cq4…B™H$&nbsp;299122"W(ÀçÜD–]óz}zƒáØy1
…˜…BL„B-XLäóùär¹¤&nbsp;÷ßÿŸÿùŸ?þøã`0¨P(¾ð…/tv’¡Ù===ÿðÿÐÜÜ&lt;çpšëþgÙ\…</pyêïúúcátf¿t]¥�*ù:hnhtäd(b"jùb"£ñxra‘‡î÷ûÿéÿþé¥—^šf£¯¿þú¿øåþþþùõ8éâ¬7v˜›èjîÿ"¶></jdp»¦«øm²œ></x></xw¢ýû÷—®¡vú×moo?pà€></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datacalliope.github.io/2020_VIS_Calliope_Camera.pdf">https://datacalliope.github.io/2020_VIS_Calliope_Camera.pdf</a></em></p>]]>
            </description>
            <link>https://datacalliope.github.io/2020_VIS_Calliope_Camera.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24818571</guid>
            <pubDate>Sun, 18 Oct 2020 15:32:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I've never met my cofounder]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24818314">thread link</a>) | @boomahora
<br/>
October 18, 2020 | https://accordably.com/blog/starting-saas-business-remote-cofounders | <a href="https://web.archive.org/web/*/https://accordably.com/blog/starting-saas-business-remote-cofounders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The most fundamental core of any business relationship is trust. Traditionally this was built through multiple interactions, which included at least in-person meeting.</p><p>It seemed that something about meeting in person helped solidify what was discussed. Whether this is through body language or both parties being able to lower their guards and speak somewhat informally.</p><p>These in-person meetings have been a staple for long-lasting business relationships. However, the ability for these type of interactions has been put on hold thanks to the current pandemic. The startup community has had to adapt to these restrictions and in my opinion, the perfect environment for entrepreneurship was created.</p><p>People with extra time on their hands and nothing to do.</p><p>While I recognize and have experienced the downsides of this pandemic from a business perspective, I try to look at the positives. This motivation is what led to my most recent startup, <a href="https://accordably.com/" target="_blank" rel="noopener noreferrer">Accordably, which is a competitor monitoring solution</a>.</p><h2><strong>How do you find a cofounder?</strong></h2><p>Alright, great, you want to start a business, but how do you actually find a cofounder?</p><p>I wish I could tell you that this was the easy part, but it’s actually probably the hardest.</p><p>It’s going to be a lot of trial and error.</p><p>We are in more restricted social times, so it becomes even more difficult. A good place to start is with previous colleagues that you’ve worked with. You know them from a professional perspective, you’ve seen how they act with colleagues and their work ethic.</p><p>Remember, the stakes are much higher when it’s your own business, so these favourable employee working traits don’t always translate into a good cofounder.</p><p>Personally, I would recommend checking out different digital communities, you’d be surprised who you’ll meet and might find someone that has very similar goals to you.</p><p>My personal favourite community is Indie Hackers. They have a specific group called <a href="https://www.indiehackers.com/group/looking-to-partner-up" target="_blank" rel="noopener noreferrer">“Looking to partner up”</a> and you will find a wide variety of people looking to start a business.</p><p>I am biased as that’s where I met the cofounder of Accordably.</p><h2><strong><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279,h_356/https://accordably.com/wp-content/uploads/2020/10/Version-1.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279,h_356/https://accordably.com/wp-content/uploads/2020/10/Version-1.png" alt="Remote cofounders of Accordably" width="1279" height="356" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279/https://accordably.com/wp-content/uploads/2020/10/Version-1.png 1279w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://accordably.com/wp-content/uploads/2020/10/Version-1-300x84.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://accordably.com/wp-content/uploads/2020/10/Version-1-1024x285.png 1024w" data-sizes="(max-width: 1279px) 100vw, 1279px" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279/https://accordably.com/wp-content/uploads/2020/10/Version-1.png 1279w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://accordably.com/wp-content/uploads/2020/10/Version-1-300x84.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://accordably.com/wp-content/uploads/2020/10/Version-1-1024x285.png 1024w"></strong></h2><h2><strong>What to look for when choosing a cofounder?</strong></h2><p>The ideal match is someone who is the complete opposite of your skillset. Think of it like an ice hockey team. If your team was all goalies, you’d get nowhere. You need balance and different strengths to help push your product over the top.</p><p>Now one thing that shouldn’t be the complete opposite is your motivation. Finding someone who has the same drive is important or else there could be a growing resentment in your near future.</p><p>No two situations are the same and this is why it’s difficult to find a cofounder. There needs to be the right mix of similar professional goals and differing skillsets to build a strong tandem.</p><p>Another important attribute is whether you can see yourself getting along with this person from a social perspective. Face it, you’re going to have to spend a lot of time speaking with this person and planning out the future of your business.</p><p>There are some personality types that just don’t mix. Even if your skillsets are the perfect match, your mental health could be at risk if find yourself in a toxic work relationship.</p><p>For me, building a startup isn’t necessarily about the money (I mean it helps of course!) but it’s an outlet where my voice has a direct impact on the future of the business. I can test out crazy ideas and not worry about angry investors or upsetting management.</p><h2><strong>How to build trust when you’ve never met?</strong></h2><p>Just because you meet somebody in person doesn’t automatically create trust. Everyone has their own problems and you’ll never truly understand all the factors that go into their decisions.</p><p>So how do you build trust?</p><p>Time.</p><p>It takes time to build trust, you need to learn each others working habits, personalities and goals. After 2 weeks of working together, you should have a good understanding of the other person.</p><p>Of course, 2 weeks isn’t enough to jump into anything long term, but it will give you a good idea of direction and at that point, you can choose whether or not to continue.</p><p>While you should protect yourself, there’s no need to waste money on lawyers right at the start. Just write up a basic agreement that lays out your agreed upon terms and that you will revisit at a later stage.</p><p>Even with an agreement created by lawyers, you can get screwed over, so don’t worry about this too much at the start.</p><h2><strong>Finding the right idea</strong></h2><p>You’ve assembled a strong team, your skills match perfectly and you’re ready to go, but you’re missing one thing.</p><p>The idea!</p><p>This is difficult because whatever you choose you will be committing a large chunk of time to it, so you don’t want to make the wrong choice and get startup remorse.</p><p>Now I can’t stress this enough, no matter what you choose, make sure that it genuinely interests you. I’ve been in many situations that after the initial sparkle of an idea wears off, I’m stuck with a product that I find soul-crushingly boring.</p><p>The product may make money, but if you don’t enjoy it, it’s not worth it.</p><p>The approach that we took was rather than getting stuck in analysis paralysis, we just started with something.</p><p>We started working on a server-side web analytics solution and testing the market on this idea. We focused on building the infrastructure and easily transferable parts that we could use for other ideas.</p><p>After about a month of building, two things happened:</p><ol><li>We had enough time to see if our working styles meshed, which they did.</li><li>An idea popped up from a client request that we both believed in.</li></ol><p>Long story short, instead of beating your head against a wall trying to find the perfect idea, <strong>just start! </strong></p><p>Start with anything, inspiration will come, staying stagnant will just make you another wantrepreneur.</p><h2><strong>Maintaining communication</strong></h2><p>When it comes to remote cofounders the importance of communication is multiplied. Setting up the proper channels and maintaining a clear schedule is critical for success.</p><p>Keeping your teammate informed of your daily/weekly goals helps motivate and set accountability.</p><p>It’s very easy to procrastinate when you’re “the boss” but when you see your cofounder working their ass off and you’re doing nothing, that guilt should set in. Unless of course, you’re a prick.</p><p>Our main communication hub is Slack and we have integrated all of our tools to send notifications to this platform. This is our main dashboard and it helps keeps us on the same page for the health of the business.</p><p>Figure out what works for your duo and run with it. For us, we will have one or two calls a week and then for the smaller topics, just send each other audios clips.</p><p>This style has worked for us because when a thought is fresh, you can send a quick audio snippet and the other can listen to it when they have time.</p><p>Getting sidetracked is a big problem, so try to stay on goal and not overcommunicate with long phone calls every day.</p><p>One piece of advice that I can share when it comes to communication is that tone is not conveyed properly over text. I can’t count the number of times I’ve seen people get upset over an email or Slack message from a misunderstanding in tone.</p><p>In this digital world, don’t forget how to communicate. Jumping to conclusions or negatives will just set your team back. Clarify before making an unnecessary enemy.</p><h2><strong>Trust your gut</strong></h2><p>There is no one size fits all formula to finding a cofounder. People aren’t predictable. It takes time to find the right fit.</p><p>The one constant is your gut because no matter who you choose, you’re going to have to take a chance.</p><p>You could get burned or feel like you’re doing all the work, that’s just collateral damage in the life of an entrepreneur.</p><p>All that you can do is work with the information you’re given and decide if you believe in your cofounder. When it works, it works and you’ll eventually see success.</p><p>That’s what we’re working towards with Accordably and we’re excited to see what’s next for this project.</p></div></div></div>]]>
            </description>
            <link>https://accordably.com/blog/starting-saas-business-remote-cofounders</link>
            <guid isPermaLink="false">hacker-news-small-sites-24818314</guid>
            <pubDate>Sun, 18 Oct 2020 15:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JuliaMono – a monospaced font for scientific and technical computing]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24817902">thread link</a>) | @ig0r0
<br/>
October 18, 2020 | https://cormullion.github.io/pages/2020-07-26-JuliaMono/ | <a href="https://web.archive.org/web/*/https://cormullion.github.io/pages/2020-07-26-JuliaMono/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>JuliaMono is a monospaced typeface designed for programming in the <a href="https://julialang.org/">Julia</a> Programming Language and in other text editing environments that require a wide range of specialist and technical Unicode characters. It was intended as a fun experiment to be presented at the 2020 JuliaCon conference in Lisbon, Portugal (which of course didn’t physically happen in Lisbon, but online).</p><p>The original temporary website used JuliaMono everywhere, so let's try to make the rest of this page do the same.</p><div><p>To download and install JuliaMono, see the instructions <a href="#download_and_install">here</a>.</p>

<p>Editing code in <a href="https://github.com/JunoLab/Juno.jl">Juno</a>.</p>

<p><img src="https://cormullion.github.io/assets/images/juliamono/juno-example.png" alt="screenshot of Juno editor"></p><p>And in <a href="https://www.julia-vscode.org/">VS Code</a>.</p>

<p><img src="https://cormullion.github.io/assets/images/juliamono/vscode-example.png" alt="screenshot of VS code editor"></p><p>And in <a href="https://www.vim.org/">Vim</a>:</p>

<p><img src="https://cormullion.github.io/assets/images/juliamono/vim-example.png" alt="screenshot of VIM editor"></p><p>And in <a href="https://www.gnu.org/software/emacs/">Emacs</a>:</p>

<p><img src="https://cormullion.github.io/assets/images/juliamono/emacs-example.png" alt="screenshot of emacs editor"></p>
<pre><code>using Zygote: @adjoint
function ignore(f)
  try return f()
        catch e; return 0; end
end
@adjoint function ignore(f)
  try Zygote._pullback(__context__, f)
  catch e
    0, ȳ -&gt; nothing
  end
end</code></pre>
<p>There are different weights of JuliaMono, so you can control the amount of contrast you have in your highlighted code: <span>JuliaMono-Light</span>, JuliaMono-Regular, <span>JuliaMono-Medium</span>, <span>JuliaMono-Bold</span>, <span>JuliaMono-ExtraBold</span>, and <span>JuliaMono-Black</span>. <sup id="fnref:masters"><a href="#fndef:masters">[3]</a></sup></p>
<p>(There are also versions of two of the fonts with “Latin” in the name: these are stripped down versions supporting just the basic MacRoman/Windows1252 “Latin” character sets, intended for use as place-holders, of interest mainly if you want to have more control over font loading times in web browser-based applications.)</p>
<p>In the hands of a virtuoso (such as Dr Zygmunt Szpak, the author of the following Julia code fragment<sup id="fnref:zscode"><a href="#fndef:zscode">[4]</a></sup>), the range of available Unicode characters can be quite expressive:</p>
<pre><code>function T(𝛉::AbstractArray,
           𝒞::Tuple{AbstractArray,
           Vararg{AbstractArray}},
           𝒟::Tuple{AbstractArray, Vararg{AbstractArray}})
    ⊗ = kron
    l = length(𝛉)
    𝐈ₗ = SMatrix{l,l}(1.0I)
    𝐈ₘ = SMatrix{1,1}(1.0I)
    𝐓 = @SMatrix zeros(l,l)
    N = length(𝒟[1])
    ℳ, ℳʹ = 𝒟
    Λ₁, Λ₂ = 𝒞
    𝚲ₙ = @MMatrix zeros(4,4)
    𝐞₁ = @SMatrix [1.0; 0.0; 0.0]
    𝐞₂ = @SMatrix [0.0; 1.0; 0.0]
    for n = 1:N
        index = SVector(1,2)
        𝚲ₙ[1:2,1:2] .=  Λ₁[n][index,index]
        𝚲ₙ[3:4,3:4] .=  Λ₂[n][index,index]
        𝐦    = hom(ℳ[n])
        𝐦ʹ   = hom(ℳʹ[n])
        𝐔ₙ   = (𝐦 ⊗ 𝐦ʹ)
        ∂ₓ𝐮ₙ = [(𝐞₁ ⊗ 𝐦ʹ) (𝐞₂ ⊗ 𝐦ʹ) (𝐦 ⊗ 𝐞₁) (𝐦 ⊗ 𝐞₂)]
        𝐁ₙ   = ∂ₓ𝐮ₙ * 𝚲ₙ * ∂ₓ𝐮ₙ'
        𝚺ₙ   = 𝛉' * 𝐁ₙ * 𝛉
        𝚺ₙ⁻¹ = inv(𝚺ₙ)
        𝐓₁   = @SMatrix zeros(Float64,l,l)
        for k = 1:l
            𝐞ₖ = 𝐈ₗ[:,k]
            ∂𝐞ₖ𝚺ₙ = (𝐈ₘ ⊗ 𝐞ₖ') * 𝐁ₙ * (𝐈ₘ ⊗ 𝛉) + (𝐈ₘ ⊗ 𝛉') * 𝐁ₙ * (𝐈ₘ ⊗ 𝐞ₖ)
            # Accumulating the result in 𝐓₁ allocates memory,
            # even though the two terms in the
            # summation are both SArrays.
            𝐓₁ = 𝐓₁ + 𝐔ₙ * 𝚺ₙ⁻¹ * (∂𝐞ₖ𝚺ₙ) * 𝚺ₙ⁻¹ * 𝐔ₙ' * 𝛉 * 𝐞ₖ'
        end
        𝐓 = 𝐓 + 𝐓₁
    end
    𝐓
end</code></pre>

<p>Here are some samples of various languages<sup id="fnref:languages"><a href="#fndef:languages">[5]</a></sup> :</p>

<table>
	<tbody><tr>
		<td>Ancient Greek</td>
		<td>Ἄδμηθ’, ὁρᾷς γὰρ τἀμὰ πράγμαθ’ ὡς ἔχει, λέξαι θέλω σοι πρὶν θανεῖν ἃ βούλομαι.</td>
	</tr>
	<tr>
		<td>Bulgarian</td>
		<td>Я, пазачът Вальо уж бди, а скришом хапва кюфтенца зад щайгите.</td>
	</tr>
	<tr>
		<td>Catalan</td>
		<td>«Dóna amor que seràs feliç!». Això, il·lús company geniüt, ja és un lluït rètol blavís d’onze kWh.</td>
	</tr>
	<tr>
		<td>Czech</td>
		<td>Zvlášť zákeřný učeň s ďolíčky běží podél zóny úlů</td>
	</tr>
	<tr>
		<td>Danish</td>
		<td>Quizdeltagerne spiste jordbær med fløde, mens cirkusklovnen Walther spillede på xylofon.</td>
	</tr>
	<tr>
		<td>English</td>
		<td>Sphinx of black quartz, judge my vow.</td>
	</tr>
	<tr>
		<td>Estonian</td>
		<td>Põdur Zagrebi tšellomängija-följetonist Ciqo külmetas kehvas garaažis</td>
	</tr>
	<tr>
		<td>Finnish</td>
		<td>Charles Darwin jammaili Åken hevixylofonilla Qatarin yöpub Zeligissä.</td>
	</tr>
	<tr>
		<td>French</td>
		<td>Voix ambiguë d’un cœur qui au zéphyr préfère les jattes de kiwi.</td>
	</tr>
	<tr>
		<td>German</td>
		<td>Victor jagt zwölf Boxkämpfer quer über den großen Sylter Deich.</td>
	</tr>
	<tr>
		<td>Greek</td>
		<td>Ταχίστη αλώπηξ βαφής ψημένη γη, δρασκελίζει υπέρ νωθρού κυνός.</td>
	</tr>
	<tr>
		<td>Guarani</td>
		<td>Hĩlandiagua kuñanguéra oho peteĩ saʼyju ypaʼũme Gavõme omboʼe hag̃ua ingyleñeʼẽ mitãnguérare neʼẽndyʼỹ.</td>
	</tr>
	<tr>
		<td>Hungarian</td>
		<td>Jó foxim és don Quijote húszwattos lámpánál ülve egy pár bűvös cipőt készít.</td>
	</tr>
	<tr>
		<td>IPA</td>
		<td>[ɢʷɯʔ.nas.doːŋ.kʰlja] [ŋan.ȵʑi̯wo.ɕi̯uĕn.ɣwa]</td>
	</tr>
	<tr>
		<td>Icelandic</td>
		<td>Kæmi ný öxi hér, ykist þjófum nú bæði víl og ádrepa.</td>
	</tr>
	<tr>
		<td>Irish</td>
		<td>Ċuaiġ bé ṁórṡáċ le dlúṫspád fíorḟinn trí hata mo ḋea-ṗorcáin ḃig.</td>
	</tr>
	<tr>
		<td>Latvian</td>
		<td>Muļķa hipiji mēģina brīvi nogaršot celofāna žņaudzējčūsku.</td>
	</tr>
	<tr>
		<td>Lithuanian</td>
		<td>Įlinkdama fechtuotojo špaga sublykčiojusi pragręžė apvalų arbūzą.</td>
	</tr>
	<tr>
		<td>Macedonian</td>
		<td>Ѕидарски пејзаж: шугав билмез со чудење џвака ќофте и кељ на туѓ цех.</td>
	</tr>
	<tr>
		<td>Norwegian</td>
		<td>Jeg begynte å fortære en sandwich mens jeg kjørte taxi på vei til quiz</td>
	</tr>
	<tr>
		<td>Polish</td>
		<td>Pchnąć w tę łódź jeża lub ośm skrzyń fig.</td>
	</tr>
	<tr>
		<td>Portuguese</td>
		<td>Luís argüia à Júlia que «brações, fé, chá, óxido, pôr, zângão» eram palavras do português.</td>
	</tr>
	<tr>
		<td>Romanian</td>
		<td>Înjurând pițigăiat, zoofobul comandă vexat whisky și tequila.</td>
	</tr>
	<tr>
		<td>Russian</td>
		<td>Широкая электрификация южных губерний даст мощный толчок подъёму сельского хозяйства.</td>
	</tr>
	<tr>
		<td>Scottish</td>
		<td>Mus d’fhàg Cèit-Ùna ròp Ì le ob.</td>
	</tr>
	<tr>
		<td>Serbian</td>
		<td>Ајшо, лепото и чежњо, за љубав срца мога дођи у Хаџиће на кафу.</td>
	</tr>
	<tr>
		<td>Spanish</td>
		<td>Benjamín pidió una bebida de kiwi y fresa; Noé, sin vergüenza, la más champaña del menú.</td>
	</tr>
	<tr>
		<td>Swedish</td>
		<td>Flygande bäckasiner söka hwila på mjuka tuvor.</td>
	</tr>
	<tr>
		<td>Turkish</td>
		<td>Pijamalı hasta yağız şoföre çabucak güvendi.</td>
	</tr>
	<tr>
		<td>Ukrainian</td>
		<td>Чуєш їх, доцю, га? Кумедна ж ти, прощайся без ґольфів!</td>
	</tr>
</tbody></table>



<p>One of the goals of JuliaMono is to include most of the characters that a typical programmer would reasonably expect to find. (Except for all those emojis - they are best handled by the operating system.) Here’s a thousand or so chosen at random:</p>
<p><img src="https://cormullion.github.io/assets/images/juliamono/unicode-sample.svg" width="100%" alt="Unicode sampler"></p><p>In JuliaMono, every character is the same width, because this is a <a href="https://en.wikipedia.org/wiki/Monospaced_font">monospaced</a> typeface. Usually, typefaces with a lot of Unicode mathematical symbols are not monospaced, because they’re intended for use in prose and \( \LaTeX \) applications, rather than in programming code.</p>
<p>From a design perspective, forcing every character into the same size box is a problem. It’s like fitting every human being of whatever shape or size into identical airplane seats - some characters are bound to look uncomfortable. There’s never quite enough room for a nice-looking “m” or “w”.</p>
<p><a href="https://github.com/Evizero/UnicodePlots.jl">UnicodePlots.jl</a> uses various Unicode characters to plot figures directly in a terminal window. <sup id="fnref:linespacing"><a href="#fndef:linespacing">[6]</a></sup></p>

<p><img src="https://cormullion.github.io/assets/images/juliamono/unicodeplots.png" alt="UnicodePlots in action"></p><p><a href="https://github.com/JuliaImages/ImageInTerminal.jl">ImageInTerminal.jl</a> is similarly awesome, conjuring images from Unicode characters:</p>

<p><img src="https://cormullion.github.io/assets/images/juliamono/imageinterminal.png" alt="ImageInTerminal"></p><p>JuliaMono is quite greedy<sup id="fnref:greedy"><a href="#fndef:greedy">[7]</a></sup>, and contains a lot of Unicode glyphs.</p>
<p><img src="https://cormullion.github.io/assets/images/juliamono/barchart.svg" width="100%" alt="silly barchart"></p><p>(Of course, size isn’t everything - quality can beat quantity, and other fonts will offer different experiences<sup id="fnref:otherfonts"><a href="#fndef:otherfonts">[8]</a></sup>).</p>
<p>It’s also a good idea to support box-drawing characters and DataFrames.jl output (terminal permitting):</p>
<pre><code>julia&gt; df = DataFrame(A=samples, B=glyphs)
df = 10×2 DataFrame
│ Row │ A              │ B                   │
│     │ String         │ String              │
├─────┼────────────────┼─────────────────────┤
│ 1   │ sample 1       │ ▁▂▁▁▂▄▅▁▄▁▁▅▆▂▇▅▂▇  │
│ 2   │ sample 2       │ ▁▂▄▁▁▃▁▆▂▆▃▁▂▃▂▇▄   │
│ 3   │ sample 3       │ ▁▆▇▁▃▇▇▆▅▅▄▇▇▅▅▇▄▂  │
│ 4   │ sample 4       │ ▅▁▄▁▆▃▁▃▇▂▂▇▅▇▃▆▃▁  │
│ 5   │ sample 5       │ ▆▂▁▂▇▆▃▅▅▄▆▇▄▇▆▁▇   │
│ 6   │ sample 6       │ ▁▁▇▂▂▇▃▅▂▂▆▂▄▄▁▄▂▇▆ │
│ 7   │ sample 7       │ ▂▃▂▁▁▇▁▂▆▂▁▇▁▄▃▂▁▄  │
│ 8   │ sample 8       │ ▄▄▁▂▄▁▅▁▅▁▂▂▇▂▁▃▄▄  │
│ 9   │ sample 9       │ ▁▁▁▂▁▆▃▄▄▁▂▂▃▂▁▅▁▆▃ │
│ 10  │ sample 10      │ ▁▇▄▂▅▃▇▁▇▇▆▄▇▅▄▂▄▅▄ │</code></pre>
<p>(Can you spot the little used and sadly mathematically-unsupported "times" character?)</p>
<p>If you want to know whether you can use a Unicode character as an identifier in your Julia code, use the undocumented function <code>Base.isidentifier()</code>. So, for example, if you have the urge to use a dingbat (one of the classic <a href="https://en.wikipedia.org/wiki/Zapf_Dingbats">Herman Zapf dingbat</a> designs), you could look for something suitable in the output of this:</p>
<pre><code>julia&gt; for n in 0x2700:0x27bf
			Base.isidentifier(string(Char(n))) &amp;&amp; print(Char(n))
	   end
✀✁✂✃✄✅✆✇✈✉✊✋✌✍✎✏✐✑✒✓✔✕✖✗✘✙✚✛✜✝✞✟✠✡✢✣✤✥✦✧✨✩✪✫✬✭✮✯✰✱✲✳✴✵✶✷✸✹✺
✻✼✽✾✿❀❁❂❃❄❅❆❇❈❉❊❋❌❍❎❏❐❑❒❓❔❕❖❗❘❙❚❛❜❝❞❟❠❡❢❣❤❥❦❧➔➕➖➗➘➙➚➛➜➝➞➟➠➡
➢➣➤➥➦➧➨➩➪➫➬➭➮➯➰➱➲➳➴➵➶➷➸➹➺➻➼➽➾➿

julia&gt; ❤(s) = println("I ❤ $(s)")
❤ (generic function with 1 method)

julia&gt; ❤("Julia")
I ❤ Julia</code></pre>

<p>JuliaMono is an <a href="https://en.wikipedia.org/wiki/OpenType">OpenType</a> typeface. OpenType technology provides powerful text positioning, pattern matching, and glyph substitution features, which are essential for languages such as Arabic and Urdu. In English, OpenType features are often seen when letter pairs such as <span>fi</span> in certain fonts are replaced by a single glyph such as <span>ﬁ</span>. These <a href="https://en.wikipedia.org/wiki/Orthographic_ligature">ligatures</a> have been used ever since printing with moveable type was invented, replacing the occasional awkward character combination with a better-looking alternative.</p>
<p>To be honest, I’m not a big fan of their use in coding fonts (and I’m not the only one<sup id="fnref:nottheonlyone"><a href="#fndef:nottheonlyone">[9]</a></sup>). I like to see exactly what I’ve typed, rather than what the font has decided to replace it with. But, there are a few places in Julia where suitable Unicode alternatives are not accepted by the language, and where I feel that the ASCII-art confections currently used can be gently enhanced by the judicious use of alternate glyphs. There are also a few places where some subtle tweaks can enhance the readability of the language without introducing ambiguity.</p>
<p>In JuliaMono, the following substitutions are applied when the <strong>contextual alternates</strong> feature is active:</p>

<table>
    <tbody><tr>
    <th><p>typed</p></th>
    <th><p>displayed</p></th>
    </tr>
    <tr>
    <td>-&gt;</td>
    <td>-&gt;</td>
    </tr>

    <tr>
    <td>=&gt;</td>
    <td>=&gt;</td>
    </tr>
    <tr>
    <td>|&gt;</td>
    <td>|&gt;</td>
    </tr>
    <tr>
    <td>&lt;|</td>
    <td>&lt;|</td>
    </tr>
    <tr>
    <td>::</td>
    <td>::</td>
    </tr>

</tbody></table>

<p>You can see these in action in the following code fragment:<sup id="fnref:width"><a href="#fndef:width">[10]</a></sup></p>
<pre><code>julialang = true # (!= 0)
(x, y) -&gt; (x + y)
f(p::Int) = p * p
@inbounds if f in (Base.:+, Base.:-)
    if any(x -&gt; x &lt;: AbstractArray{&lt;:Number})
         nouns = Dict(
            Base.:+ =&gt; "addition",
            Base.:- =&gt; "subtraction",
        )
    end
end
df2 = df |&gt;
    @groupby(_.a) |&gt;
    @map({a = key(_), b = mean(_.b)}) |&gt;
    DataFrame # &lt;|</code></pre>
<p>OpenType fonts also offer you the ability to choose different designs for certain characters. These are stored as a ‘stylistic set’.</p>
<p>All the options are stored in the font, and are often referred to by their internal four letter code (not the best user-oriented design, really). For example, the contextual alternates listed above are collectively stored in the <strong>calt</strong> feature.</p>
<p>Sometimes, an application will show the options more visually in a Typography panel<sup id="fnref:typographypanel"><a href="#fndef:typographypanel">[11]</a></sup>, usually tucked away somewhere on a Font chooser dialog.</p>
<p>Here’s a list of the stylistic sets currently available in JuliaMono.</p>

<table>
    <tbody><tr>
    <th><p>feature code</p></th>
    <th><p>off</p></th>
    <th><p>on</p></th>
    <th><p>description</p></th>
    </tr>

    <tr>
    <td>zero</td>
    <td>0</td>
    <td>0</td>
    <td><p>slashed zero</p></td>
    </tr>

    <tr>
    <td>ss01</td>
    <td>g</td>
    <td>g</td>
    <td><p>alternate g</p></td>
    </tr>

    <tr>
    <td>ss02</td>
    <td>@</td>
    <td>@</td>
    <td><p>alternate @</p></td>
    </tr>

    <tr>
    <td>ss03</td>
    <td>j</td>
    <td>j</td>
    <td><p>alt…</p></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cormullion.github.io/pages/2020-07-26-JuliaMono/">https://cormullion.github.io/pages/2020-07-26-JuliaMono/</a></em></p>]]>
            </description>
            <link>https://cormullion.github.io/pages/2020-07-26-JuliaMono/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817902</guid>
            <pubDate>Sun, 18 Oct 2020 13:56:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the PDP-11 instruction set?]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24817321">thread link</a>) | @elvis70
<br/>
October 18, 2020 | http://ftp.dbit.com/pub/pdp11/faq/faq.pages/PDPinst.html | <a href="https://web.archive.org/web/*/http://ftp.dbit.com/pub/pdp11/faq/faq.pages/PDPinst.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>
     The instruction set of the PDP-11 was designed towards a clean,
     general, symmetric instruction set.  It can be used as a
     register-based, stack-based, or memory-based machine, depending
     on the programmer's preferences.  Interrupt responsiveness is
     also important, supported with multiple interrupt levels for
     real-time computing as well as allowing for a separate interrupt
     handler for each device that generates interrupts.
</p><p>
     Word length is 16 bits with the leftmost, most significant bit
     (MSB) being bit 15.  There are eight general registers of 16 bits
     each.  Register 7 is the program counter (PC) and, by convention,
     Register 6 is the stack pointer (SP).  There is also a Processor
     Status Register/Word (PSW) which indicates the 4 condition code
     bits (N, Z, V, C), the Trace Trap bit, processor interrupt
     priority, and 4 bits for current and previous operating modes.
     Addressing on the -11 is linear from memory address 0 through
     177777.  Memory management allows access to physical memory with
     addresses of up to 22 bits (17777777).  All I/O devices,
     registers etc are addressed as if they were part of memory.
     These live in the 4KW of reserved memory space at the top of the
     addressing range.  Additionally, on most implementations of the
     PDP-11 architecture, the processor's registers are memory-mapped
     to the range 17777700-17777717 (there are many control registers
     beyond just the general registers, the specifics vary between
     implementations).  Thus Register 2 (R2) has an address of
     17777702.  All word memory addresses are even, except for registers.
     In byte operations, an even address specifies the least-significant
     byte and an odd address specifies the most-significant byte.
     Specifying an odd byte in a word operation will return an odd
     address trap.  Memory addresses from 0 to 400 octal are reserved
     for various exception traps such as timeouts, reserved
     instructions, parity, etc., and device interrupts.
</p><p>
     Addressing for the Single Operand, Double Operand and
     Jump instructions is achieved via six bits:
</p><pre>                          _ _ _ _ _ _
                         |x|x|x|_|_|_|
                         |Mode |Reg  |
</pre><p>
     where the modes are as follows: (Reg = Register, Def = Deferred)
</p><pre>     Mode 0  Reg           Direct addressing of the register
     Mode 1  Reg Def       Contents of Reg is the address
     Mode 2  AutoIncr      Contents of Reg is the address, then Reg incremented
     Mode 3  AutoIncrDef   Content of Reg is addr of addr, then Reg Incremented
     Mode 4  AutoDecr      Reg is decremented then contents is address
     Mode 5  AutoDecrDef   Reg is decremented then contents is addr of addr
     Mode 6  Index         Contents of Reg + Following word is address
     Mode 7  IndexDef      Contents of Reg + Following word is addr of addr
</pre><p>
     Note that the right-most bit of the mode is an indirection bit.
</p><p>
     Although not special cases, when dealing with R7 (aka the PC), some of
     these operations are called different things:
</p><pre>                          _ _ _ _ _ _
                         |x|x|x|1|1|1|
                         |Mode |  R7 |

     Mode 2  Immediate     Operand follows the instruction
     Mode 3  Absolute      Address of Operand follows the instruction
     Mode 6  Relative      Instr address+4+Next word is Address
     Mode 7  RelativeDef   Instr address+4+Next word is Address of address
</pre><p>
     Mainstream instructions are broken into Single operand and Double
     operand instructions, which in turn can be word or byte instructions.
</p>
<h2>Double Operand Instructions</h2>
<pre>                      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
                     |b|i|i|i|s|s|s|s|s|s|d|d|d|d|d|d|
                     | |     |     :     |     :     |
                     | | Op  | Source    |  Dest     |
</pre><p>
     Bit 15, b, generally selects between word-sized (b=0) and
     byte-sized (b=1) operands.  In the table below, the mnemonics and
     names are given in the order b=0/b=1.
</p><p>
     The double operand instructions are:
</p><dl>
          <dt>b 000 ssssss dddddd
              </dt><dd>Non-double-operand instructions.
</dd><dt>b 001 ssssss dddddd -- MOV/MOVB  <i>Move Word/Byte</i>
              </dt><dd>Moves a value from source to destination.
</dd><dt>b 010 ssssss dddddd -- CMP/CMPB  <i>Compare Word/Byte</i>
              </dt><dd>Compares values by subtracting the destination
              from the source, setting the condition codes, and
              then discarding the result of the subtraction.
</dd><dt>b 011 ssssss dddddd -- BIT/BITB  <i>Bit Test Word/Byte</i>
              </dt><dd>Performs a bit-wise AND of the source and the
              destination, sets the condition codes, and then
              discards the result of the AND.
</dd><dt>b 100 ssssss dddddd -- BIC/BICB  <i>Bit Clear Word/Byte</i>
              </dt><dd>For each bit set in the source, that bit is cleared
              in the destination.  This is accomplished by taking the
              ones-complement of the source and ANDing it with the
              destination.  The result of the AND is stored in the
              destination.
</dd><dt>b 101 ssssss dddddd -- BIS/BISB  <i>Bit Set Word/Byte</i>
              </dt><dd>For each bit set in the source, that bit is set in
              the destination.  This is accomplished by ORing the
              source and destination, and storing the result in the
              destination.
</dd><dt>b 110 ssssss dddddd -- ADD/SUB   <i>Add/Subtract Word</i>
              </dt><dd>Adds the source and destination, storing the results
              in the destination.
<p>
              Subtracts the source from the destination, storing
              the results in the destination.
</p><p>
              Note that this is a special case for b=1, in that
              it does not indicate that byte-wide operands are
              used.
</p></dd><dt>b 111 xxxxxx xxxxxx
              </dt><dd>Arithmetic functions not supported by all implementations
              of the PDP-11 architecture.
</dd></dl>
<h2>Single Operand Instructions</h2>
<pre>                      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
                     |b|0|0|0|i|i|i|i|i|i|d|d|d|d|d|d|
                     | |     |     :     |     :     |
                     | |     |Instruction|  Dest     |
</pre><p>
     Bit 15, b, generally selects between word-sized (b=0) and
     byte-sized (b=1) operands.  In the table below, the mnemonics and
     names are given in the order b=0/b=1.  Unless otherwise stated,
     the operand is read for the data to operate on, and the result is
     then written over that data.
</p><p>
     The single operand instructions are:
</p><dl>
          <dt>b 000 000 011 dddddd -- SWAB/BPL   <i>Swap Bytes/Branch Plus</i>
              </dt><dd>Swap bytes exchanges the two bytes found in the
              destination, writing the result back to it.
<p>
              The branch (b=1) is described in the section on
              branches, below.
</p><p>
              Note that SWAB is actually a bit pattern from the
              range reserved for branches.  This particular
              pattern is otherwise unused, as it would be a
              modification of BR, Branch Always, which has no
              obvious semantics.
</p></dd><dt>b 000 101 000 dddddd -- CLR/CLRB   <i>Clear Word/Byte</i>
              </dt><dd>Sets all the bits in destination to zero.
</dd><dt>b 000 101 001 dddddd -- COM/COMB   <i>Complement Word/Byte</i>
              </dt><dd>Calculates the ones-complement of the operand,
              and stores it.  The ones-complement is formed by
              inverting each bit (0-&gt;1, 1-&gt;0) independently.
</dd><dt>b 000 101 010 dddddd -- INC/INCB   <i>Increment Word/Byte</i>
              </dt><dd>Adds one to the destination.
</dd><dt>b 000 101 011 dddddd -- DEC/DECB   <i>Decrement Word/Byte</i>
              </dt><dd>Subtracts one from the destination.
</dd><dt>b 000 101 100 dddddd -- NEG/NEGB   <i>Negate Word/Byte</i>
              </dt><dd>Calculates the twos-complement of the operand,
              and stores it.  The twos-complement is formed by
              adding one to the ones-complement.  The effect is
              the same as subtracting the operand from zero.
</dd><dt>b 000 101 101 dddddd -- ADC/ADCB   <i>Add Carry Word/Byte</i>
              </dt><dd>Adds the current value of the carry flag to the
              destination.  This is useful for implementing
              arithmetic subroutines with more than word-sized
              operands.
</dd><dt>b 000 101 110 dddddd -- SBC/SBCB   <i>Subtract Carry Word/Byte</i>
              </dt><dd>Subtracts the current value of the carry flag from
              the destination.  This is useful for implementing
              arithmetic subroutines with more than word-sized
              operands.
</dd><dt>b 000 101 111 dddddd -- TST/TSTB   <i>Test Word/Byte</i>
              </dt><dd>Sets the N (negative) and Z (zero) condition codes
              based on the value of the operand.
</dd><dt>b 000 110 000 dddddd -- ROR/RORB   <i>Rotate Right Word/Byte</i>
              </dt><dd>Rotates the bits of the operand one position to
              the right.  The right-most bit is placed in the
              carry flag, and the carry flag is copied to the
              left-most bit (bit 15) of the operand.
</dd><dt>b 000 110 001 dddddd -- ROL/ROLB   <i>Rotate Left Word/Byte</i>
              </dt><dd>Rotates the bits of the operand one position to
              the left.  The left-most bit is placed in the
              carry flag, and the carry flag is copied to the
              right-most bit (bit 0) of the operand.
</dd><dt>b 000 110 010 dddddd -- ASR/ASRB   <i>Arithmetic Shift Right Word/Byte</i>
              </dt><dd>Shifts the bits of the operand one position to
              the right.  The left-most bit is duplicated.  The
              effect is to perform a signed division by 2.
</dd><dt>b 000 110 011 dddddd -- ASL/ASLB   <i>Arithmetic Shift Left Word/Byte</i>
              </dt><dd>Shifts the bits of the operand one position to
              the left.  The right-most bit is set to zero.  The
              effect is to perform a signed multiplication by 2.
</dd><dt>b 000 110 100 dddddd -- MARK/MTPS   <i>Mark/Move To Processor Status</i>
              </dt><dd>MARK is used as part of one of the subroutine call/
              return sequences.  The operand is the number of parameters.
          …</dd></dl></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://ftp.dbit.com/pub/pdp11/faq/faq.pages/PDPinst.html">http://ftp.dbit.com/pub/pdp11/faq/faq.pages/PDPinst.html</a></em></p>]]>
            </description>
            <link>http://ftp.dbit.com/pub/pdp11/faq/faq.pages/PDPinst.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817321</guid>
            <pubDate>Sun, 18 Oct 2020 12:28:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU shoots for €10B ‘industrial cloud’ to rival US]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 331 (<a href="https://news.ycombinator.com/item?id=24817290">thread link</a>) | @colinjoy
<br/>
October 18, 2020 | https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>BERLIN — The European Union aims to spend up to €10 billion over the next seven years to help build up a homegrown cloud computing sector that could rival foreign corporations such as Amazon, Google and Alibaba.</p>
<p>Twenty-five EU countries signed a <a href="https://ec.europa.eu/digital-single-market/en/news/towards-next-generation-cloud-europe" target="_blank">joint declaration</a> Thursday pledging public money to power up the cloud sector and establishing the "European Alliance on Industrial Data and Cloud," a partnership geared toward facilitating such projects.</p>
<p>The alliance — whose funding is to be drawn from existing EU programs and hoped-for pledges from industry and national capitals — will be launched by the end of the year. Cyprus and Denmark were the only EU member countries not to sign the declaration due to “technical reasons.”</p>
<p>The declaration “is a foundation stone for the establishment of European cloud technology, which will be very high performing,” said Internal Market Commissioner Thierry Breton, following a meeting of European telecoms ministers organized by the German government, which currently holds the EU’s rotating Council presidency.</p>
<p>“Contrary to the prejudices, we are not late [on cloud development]. We are the first to get involved in the industrial cloud,” he added.</p>
<blockquote><p>“EU governments and the public sector need to be fully committed to the initiative by fully shifting to cloud services” — <em>Lise Fuhr, ETNO’s director general</em></p></blockquote>
<p>The cloud alliance is a key part of the European Commission’s data strategy, which aims to create a single market for industrial data. Commissioner Breton in particular has lobbied hard to make the EU a worldwide data hub, and to develop data processing capabilities that would give Europe an edge over foreign rivals that currently dominate the cloud business.</p>
<p>It also fits in with broader efforts by European policymakers to make the Continent less dependent on foreign technology. Currently, U.S. technology firms dominate the global market for cloud storage.</p>
<p>In the same vein, the bloc is set to unveil by December a rulebook for platforms dubbed the “Digital Services Act," as well as binding laws for artificial intelligence that are set to be released early next year.</p>
<p>The new alliance will have the mandate to develop business, investment and implementation plans for European cloud technologies in the public and private sectors.</p>
<p>Signatories also pledge to create common European standards and policy norms to create pan-European cloud services, and help small and medium-sized businesses, startups and the public sector embrace cloud technology.</p>
<p>“In order to achieve digital sovereignty, we need to start approaching data processing the way major American and Chinese companies — the hyper-scalers — approach it,” said German Economy Minister Peter Altmaier.</p>
<p>“This is an area where we’re far from being equals,” he added.</p>
<h3>Money, money, money</h3>
<p>The Commission’s plan is to invest up to €10 billion to develop Europe's cloud and data infrastructures.</p>
<p>The EU’s executive arm would invest €2 billion from programs in its long-term budget such as the Digital Europe Programme, Connecting Europe Facility 2 and InvestEU.</p>
<p>The rest of the money will come from both industry and member countries. National governments will be able to fund these projects through the EU’s coronavirus recovery plan, which has earmarked 20 percent toward digital projects.</p>
<p>The joint cloud declaration also issues demands to non-European cloud companies.</p>
<p>Cloud providers must “guarantee European standards in terms of security, data protection, consumer protection, data portability and energy efficiency and contribute to European digital sovereignty.”</p>
<p>The companies must offer “adequate assurance” that the EU will maintain control over its strategic and sensitive data.</p>
<p>“While all cloud providers are welcome in European cloud federation, the resulting cloud capacities should not be subject to laws of foreign jurisdictions,” the declaration read.</p>
<p>One of the first initiatives to come out of Europe’s cloud push is Gaia-X, a much-hyped European effort spearheaded by Germany and France to build up a European platform that sets common standards for cloud technology. Gaia-X has <a href="https://www.politico.eu/?p=1449266">limited</a> the voting rights of non-European cloud computing companies, and they cannot become directors of the association.</p>
<p>ETNO, the association representing Europe’s leading telecom operators, applauded the move.</p>
<p>“EU governments and the public sector need to be fully committed to the initiative by fully shifting to cloud services. We call for EU targets and commitments that reflect the demand side of the cloud investment story,” said Lise Fuhr, ETNO’s director general.</p>
<p>Tech lobby DigitalEurope was equally supportive, and announced it was applying for membership in Gaia-X.</p>
<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#166664795666797a7f627f7579387363" target="_blank"><span data-cfemail="29595b4669594645405d404a46074c5c">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
 <div> <h3>  Also On POLITICO  </h3>   <div data-block-attributes="[]" data-page="0"> <div> <div> <p><a href="https://www.politico.eu/article/eu-cloud-new-front-with-us-tech-giants/"> <img src="https://www.politico.eu/wp-content/uploads/2020/09/iStock-1160479733-765x540.jpg" sizes="(max-width: 765px) 100vw, 765px" alt="EU cloud regulation opens new front with US tech giants" width="765" height="540" data-thumbnail-size="ev-pro-lead" loading="lazy"></a> </p>   </div><div> <p><a href="https://www.politico.eu/article/beyond-tiktok-us-chinese-app-crackdown/"> <img src="https://www.politico.eu/wp-content/uploads/2020/08/GettyImages-1068921922-1-765x540.jpg" sizes="(max-width: 765px) 100vw, 765px" alt="Beyond TikTok, US eyes Chinese apps and cloud for crackdown" width="765" height="540" data-thumbnail-size="ev-pro-lead" loading="lazy"></a> </p>   </div> </div> </div>    </div> 								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817290</guid>
            <pubDate>Sun, 18 Oct 2020 12:20:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Detection at 1840 FPS with TorchScript, TensorRT and DeepStream]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24817173">thread link</a>) | @briggers
<br/>
October 18, 2020 | https://paulbridger.com/posts/video-analytics-deepstream-pipeline/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/video-analytics-deepstream-pipeline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>October 17, 2020</h5>



  
  
  

  


  <h2 id="intro">
  Intro
  <a href="#intro">#</a>
</h2>
<p>Previously, we took a <a href="https://paulbridger.com/posts/video-analytics-pytorch-pipeline/">simple video pipeline</a> and made it as fast as we could without sacrificing the flexibility of the Python runtime. It’s amazing how far you can go — <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/">9 FPS to 650 FPS</a> — but we did not reach full hardware utilization and the pipeline did not scale linearly beyond a single GPU. There is evidence (measured using <a href="https://github.com/chrisjbillington/gil_load">gil_load</a>) that we were throttled by a fundamental Python limitation with multiple threads fighting over the <a href="https://wiki.python.org/moin/GlobalInterpreterLock">Global Interpreter Lock</a> (GIL).</p>
<p>In this article we’ll take performance of the same <a href="https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/">SSD300 model</a> even further, leaving Python behind and moving towards true production deployment technologies:</p>
<ul>
<li>
<p><a href="https://pytorch.org/docs/stable/jit.html"><strong>TorchScript.</strong></a> Instead of running directly in the Pytorch runtime, we’ll export our model using TorchScript tracing into a form that can be executed portably using the <code>libtorch</code> C++ runtime.</p>
</li>
<li>
<p><a href="https://developer.nvidia.com/tensorrt"><strong>TensorRT.</strong></a> This toolset from Nvidia includes a “deep learning inference optimizer” — a compiler for optimizing CUDA-based computational graphs. We’ll use this to squeeze out every drop of inference efficiency.</p>
</li>
<li>
<p><a href="https://developer.nvidia.com/deepstream-sdk"><strong>DeepStream.</strong></a> While <a href="https://gstreamer.freedesktop.org/">Gstreamer</a> gives us an extensive library of elements to build media pipelines with, DeepStream expands this library with a set of GPU-accelerated elements specialized for machine learning.</p>
</li>
</ul>
<p>These technologies fit together like this:</p>
<p><img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/deepstream_hybrid.svg" alt="DeepStream Hybrid Architecture"></p>
<p>This article will not be a step-by-step tutorial with code examples, but will show what is possible when these technologies are combined. The associated repository is here: <a href="https://github.com/pbridger/deepstream-video-pipeline">github.com/pbridger/deepstream-video-pipeline</a>.</p>
<h3 id="torchscript-vs-tensorrt">
  🔥TorchScript vs TensorRT🔥
  <a href="#torchscript-vs-tensorrt">#</a>
</h3>
<p>Both TorchScript and TensorRT can produce a deployment-ready form of our model, so why do we need both? These great tools may eventually be competitors but in 2020 they are complementary — they each have weaknesses that are compensated for by the other.</p>
<p><strong>TorchScript.</strong> With a few lines of <code>torch.jit</code> code we can generate a deployment-ready asset from essentially any Pytorch model that will run anywhere libtorch runs. It’s not inherently faster (it is submitting approximately the same sequence of kernels) but the libtorch runtime will perform better under high concurrency. However, without care TorchScript output may have performance and portability surprises (I’ll cover some of these in a later article).</p>
<p><strong>TensorRT.</strong> An unparalleled model compiler for Nvidia hardware, but for Pytorch or <a href="https://onnx.ai/">ONNX</a>-based models it has incomplete support and suffers from poor portability. There is a plugin system to add arbitrary layers and postprocessing, but this low-level work is out of reach for groups without specialized deployment teams. TensorRT also doesn’t support cross-compilation so models must be optimized directly on the target hardware — not great for embedded platforms or highly diverse compute ecosystems.</p>
<p>Let’s begin with a baseline from the previous post in this series — <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/">Object Detection from 9 FPS to 650 FPS in 6 Steps</a>.</p>
<h2 id="stage-0-python-baseline">
  Stage 0: Python Baseline
  <a href="#stage-0-python-baseline">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/pytorch-video-pipeline/blob/master/tuning_postprocess_2.py">tuning_postprocess_2.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/logs/tuning_postprocess_2.qdrep">tuning_postprocess_2.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/logs/tuning_postprocess_2.pipeline.dot.png">tuning_postprocess_2.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>The <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/#stage-2-postprocessing-on-gpu">Postprocessing on GPU</a> stage from my previous post is logically closest to our first DeepStream pipeline. This was a fairly slow, early stage in the Python-based optimization journey but limitations in DeepStream around batching and memory transfer make this the best comparison.</p>
<p>This Python-based pipeline runs at around 80 FPS:</p>








<p>After we get a basic DeepStream pipeline up and running we’ll empirically understand and then remove the limitations we see.</p>
<h2 id="stage-1-normal-deepstream-mdash-100-torchscript">
  Stage 1: Normal DeepStream — 100% TorchScript
  <a href="#stage-1-normal-deepstream-mdash-100-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_1.py">ds_trt_1.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_1.py">ds_tsc_1.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_1.py">ds_ssd300_1.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_1_1gpu_batch16_host.qdrep">ds_1_1gpu_batch16_host.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_1_1gpu_batch16_host.pipeline.dot.png">ds_1_1gpu_batch16_host.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>Our approach to using TorchScript and TensorRT together in a DeepStream pipeline will be to construct a hybrid model with two sequential components — a TensorRT frontend passing results to a TorchScript backend which completes the calculation.</p>
<h3 id="hybrid-deepstream-pipeline">
  Hybrid DeepStream Pipeline
  <a href="#hybrid-deepstream-pipeline">#</a>
</h3>
<p>Our hybrid pipeline will eventually use the <code>nvinfer</code> element of DeepStream to serve a TensorRT-compiled form of the SSD300 model directly in the media pipeline. Since TensorRT cannot compile the entire model (due to unsupported <a href="https://onnx.ai/">ONNX</a> ops) we’ll run the remaining operations as a TorchScript module (via <a href="https://docs.nvidia.com/metropolis/deepstream/plugin-manual/index.html#page/DeepStream%20Plugins%20Development%20Guide/deepstream_plugin_details.html#wwpID0E0TDB0HA">the <code>parse-bbox-func-name</code> hook</a>).</p>
<p>However, the first pipeline will be the simplest possible while still following the hybrid pattern. The TensorRT model does no processing and simply passes frames to the TorchScript model, which does all preprocessing, inference, and postprocessing. 0% TensorRT, 100% TorchScript.</p>
<p>This pipeline runs at 110 FPS without tracing overhead. However, this TorchScript model has already been converted to <code>fp16</code> precision so a direct comparison to the Python-based pipeline is a bit misleading.</p>








<p>Let’s drill into the trace with <a href="https://developer.nvidia.com/nsight-systems">Nvidia’s Nsight Systems</a> to understand the patterns of execution. I have zoomed in to the processing for two 16-frame batches:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_batch.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_batch_hu85cb8d526cf1fda403db89df3e60bf80_432723_896x520_fill_box_top_2.png" width="896" height="520">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>Looking at the red NVTX ranges on the <code>GstNvInfer</code> line we can see overlapping ranges where batches of 16 frames are being processed. However, the pattern of processing on the GPU is quite clear from the 16 utilisation spikes — it is processing frame-by-frame.  We also see constant memory transfers between device and host.</p>
<p>Drilling in to see just two frames of processing, the pattern is even more clear:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_frame.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_frame_hudc758a7e69d7157937e6a1d7caab6946_421239_896x540_fill_box_top_2.png" width="896" height="540">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>With a little knowledge of how DeepStream works the problem is clear:</p>
<ul>
<li><code>nvinfer</code> sends batches of frames to the configured model engine (our empty TensorRT component) — great.</li>
<li><code>nvinfer</code> then sends the model output <em>frame by frame</em> to the postprocessing hook (our TorchScript component).</li>
</ul>
<p>Since we have put our entire model into a TorchScript postprocessing hook we are now processing frame by frame with no batching, and this is causing very low GPU utilisation. (This is why we are comparing against a Python pipeline with no batching).</p>
<p><strong>We are using DeepStream contrary to the design</strong>, but to build a truly hybrid TensorRT and TorchScript pipeline we need batched postprocessing.</p>
<blockquote>
  <p><strong>DeepStream Limitation: Postprocessing Hooks are Frame-by-Frame</strong></p>
<p>The design of <code>nvinfer</code> assumes model output will be postprocessed frame-by-frame. This makes writing postprocessing code a tiny bit easier but is inefficient by default. Preprocessing, inference and postprocessing logic should always assume a batch dimension is present.</p>

</blockquote>

<p>The Nsight Systems view above also shows a pointless sequence of device-to-host then host-to-device transfers. The purple device-to-host memory transfer is due to <code>nvinfer</code> sending tensors to system memory, ready for the postprocessing code to use it. The green host-to-device transfers are me putting this memory back on the GPU where it belongs.</p>
<blockquote>
  <p><strong>DeepStream Limitation: Postprocessing is Assumed to Happen on Host</strong></p>
<p>This is a legacy of early machine learning approaches. Modern deep learning pipelines keep data on the GPU end-to-end, including data augmentation and postprocessing. See Nvidia’s <a href="https://developer.nvidia.com/DALI">DALI library</a> for an example of this.</p>

</blockquote>

<p>Okay, time to hack DeepStream and remove these limitations.</p>
<h2 id="stage-2-hacked-deepstream-mdash-100-torchscript">
  Stage 2: Hacked DeepStream — 100% TorchScript
  <a href="#stage-2-hacked-deepstream-mdash-100-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_2.py">ds_trt_2.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_2.py">ds_tsc_2.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_2.py">ds_ssd300_2.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_2_1gpu_batch16_device.qdrep">ds_2_1gpu_batch16_device.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_2_1gpu_batch16_device.pipeline.dot.png">ds_2_1gpu_batch16_device.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>Thankfully, Nvidia have provided source for the <code>nvinfer</code> pipeline element. I’ve made two changes to better support our approach of doing significant work in the postprocessing hook and fix the above limitations:</p>
<ul>
<li><code>nvinfer</code> model engine output is now sent in a single batch to the postprocessing hook.</li>
<li>Model output tensors are no-longer copied to host, but are left on the device.</li>
</ul>
<blockquote>
  These <code>nvinfer</code> changes are unreleased and are not present in the companion repository (<a href="https://github.com/pbridger/deepstream-video-pipeline">github.com/pbridger/deepstream-video-pipeline</a>) because they are clearly derivative of <code>nvinfer</code> and I’m unsure of the licensing. Nvidia people, feel free to get in touch: <a href="mailto:paul@paulbridger.com">paul@paulbridger.com</a>.
</blockquote>

<p>With hacked DeepStream and no model changes at all this pipeline now hits 350 FPS when measured with no tracing overhead. This is up from 110 FPS with regular DeepStream. I think we deserve a chart:</p>








<p>The <code>Concurrency 1x2080Ti</code> stage from the Python pipeline is now the closest comparison both in terms of FPS and optimizations applied. Both pipelines have batched inference, video frames decoded and processed on GPU end-to-end, and concurrency at the batch level (note the overlapping NVTX ranges below). One additional level of concurrency in the Python pipeline is multiple overlapping CUDA streams.</p>
<p>The Nsight Systems view shows processing for several 16-frame batches:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_hacked_ds_two_batch.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_hacked_ds_two_batch_hudc758a7e69d7157937e6a1d7caab6946_445767_896x520_fill_box_top_2.png" width="896" height="520">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>We now have good GPU utilization and very few needless memory transfers, so the path forward is to optimize the TorchScript model. Until now the TensorRT component has been entirely pass-through and everything from preprocessing, inference and postprocessing has been in TorchScript.</p>
<p>It’s time to start using the TensorRT optimizer, so get ready for some excitement.</p>
<h2 id="stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">
  Stage 3: Hacked DeepStream — 80% TensorRT, 20% TorchScript
  <a href="#stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_3.py">ds_trt_3.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_3.py">ds_tsc_3.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_3.py">ds_ssd300_3.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_3_1gpu_batch16_device.qdrep">ds_3_1gpu_batch16_device.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_3_1gpu_batch16_device.pipeline.dot.png">ds_3_1gpu_batch16_device.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>According to Nvidia, TensorRT <a href="https://developer.nvidia.com/tensorrt">“dramatically accelerates deep learning inference performance”</a> so why not compile 100% of our model with TensorRT?</p>
<p>The Pytorch export to TensorRT consists of a couple of steps, and both provide an opportunity for incomplete support:</p>
<ol>
<li>Export the Pytorch model to the <a href="https://onnx.ai/">ONNX</a> interchange representation via <a href="https://pytorch.org/docs/stable/onnx.html#tracing-vs-scripting">tracing or scripting</a>.</li>
<li>Compile the ONNX representation into a TensorRT engine, the optimized form of the model.</li>
</ol>
<p>If you try to create an optimized TensorRT engine for this entire model (SSD300 including postprocessing), the first problem you will run into is the export to ONNX of the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/">https://paulbridger.com/posts/video-analytics-deepstream-pipeline/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/video-analytics-deepstream-pipeline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817173</guid>
            <pubDate>Sun, 18 Oct 2020 11:54:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Samsung phones force Mainland China DNS service upon Hong Kong WiFi users]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24816764">thread link</a>) | @signa11
<br/>
October 18, 2020 | http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/ | <a href="https://web.archive.org/web/*/http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1387">

	
<!-- .entry-header -->

	<div>

		<div>

			<p>This is a technical write up of the author’s investigation on how users of Samsung phones in Hong Kong (and Macau), using firmware released in September 2020, would be forced to use a public DNS service in Mainland China, which caused unease and privacy concerns among some of its users.</p>
<p>While this was investigated on a variant of a Galaxy Note 10+ phone targetting the Hong Kong market, it was reported that the issue exists for a wide range of recent Samsung phones, including those sold in other places when used in Hong Kong.</p>
<p>(Update: The firmware update released in Mid-October 2020 has fixed the DNS issue discussed in this Part, but the issue of DNS queries for <code>qq.com</code> discussed in <a href="http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/">Part 2</a> remained unchanged.)</p>

<blockquote><p>Shameless plug (for Hong Kong users): The author is the developer of Headuck Call blocker (useful only in Hong Kong). Earlier it got mistakenly flagged as malware by Google and lost many of its users, but the appeal was successful and the App is <a href="https://play.google.com/store/apps/details?id=com.headuck.headuckblocker.dev">on Google Play</a> again. Please re-consider the App if you got scared by the earlier Google Play malware warning.</p></blockquote>
<h3>Background</h3>
<p>In early October 2020, a Samsung phone user in Hong Kong, local forum (HKEPC) user dingwinslow209, <a href="https://www.hkepc.com/forum/viewthread.php?fid=168&amp;tid=2586830">reported that (link to forum post in Chinese)</a> an extra DNS server entry, <code>114.114.114.114</code> was added to the DNS setting of his Samsung mobile phone, which was updated with the latest firmware, whenever he was using a WiFi connection.&nbsp; This happened both when the DNS setting is static, or dynamic using DHCP (but not when VPN / mobile network was used).&nbsp; Even when both DNS1 and DNS2 were set to valid DNS servers (e.g. Google public DNS service using <code>DNS1 = 8.8.8.8</code> and <code>DNS2 = 8.8.4.4</code>), a new DNS3 entry pointing to <code>114.114.114.114</code> would appear in some utility app.</p>
<p>This immediately raised privacy concerns among some Samsung users in Hong Kong, as the public DNS server <code>114.114.114.114</code> is owned by Cogent Communications, under <a href="https://www.whois.com/whois/114.114.114.114">Nanjing XinFeng Information Technologies Inc</a>, in Mainland China.</p>
<p>Subsequently, in another local forum (lihkg), users captured DNS requests to <code>114.114.114.114</code>, and observed queries for “<code>qq.com</code>”&nbsp; (domain owned by Chinese tech giant Tencent), even when no software from Tencent is installed in the devices.&nbsp; There were reports that these DNS queries were sent once per minute, so long as the phone screen remained on.</p>
<p>There are further reports that when DNS queries to qq.com were blocked, the phone would report no internet connectivity via the WiFi connection.</p>
<p>The observation of the extra DNS entry was later independently confirmed by other forum users and the local media, using recent Samsung phones which have been updated in recent months.&nbsp; (See the links in the HKPEC post above, in Chinese).&nbsp; The issue persisted even when users reset their Samsung phone to factory settings. This showed that the issue originates from Samsung firmware instead of some third-party software malware.</p>
<p>The following documents the technical investigation and verification of the issue directly from analysing the code from firmware.&nbsp; The information should be sufficient for the issue and its extent to be independently verified.</p>
<h3>Getting and extracting the firmware</h3>
<p>To confirm the issue, a recent Samsung Galaxy Note 10+ firmware (SM-N9750 TGY, Hong Kong version), at Security Patch level 2020-09-01 was downloaded from one of the Samsung firmware download sites. Galaxy Note 10+ is one of the Samsung models reportedly&nbsp;affected.</p>
<p>After unzipping the downloaded firmware (in zip format), expanding the tar file beginning with “<code>AP_N9750ZSU3CTH1</code>“, decompressing the file <code>system.img.ext4.lz4</code> using <code>lz4</code>, converting it to ext4 format using <code>simg2img</code>, and mounting it as ext4 volume under Linux, one has access to the system image which would be installed when Note 10+ users update their phone to that patch level. (The same is accessible if a Note 10+ phone is rooted).</p>
<p>After some research, the culprit was found – a vendor specific service level component, added by Samsung to the Android framework, located at <code>/system/framework/wifi-service.jar</code>. This seems to work at the android system service level, supplementing the usual <code>services.jar</code>.</p>
<p>The decompiled source of the jar file (using <a href="http://www.javadecompilers.com/apk">this site</a>, with Jadx decompiler) has been uploaded to <a href="https://github.com/headuck/SM-N9750-TGY">https://github.com/headuck/SM-N9750-TGY</a>.&nbsp; The following is a walkthrough of the relevant code when a user connects to a WiFi network, showing how the DNS entries were modified.</p>
<h3>Relevant flow of DNS entry addition</h3>
<p>The main culprit is the class <code>com.android.server.wifi.WifiConnectivityMonitor</code>, located in the file <a href="https://github.com/headuck/SM-N9750-TGY/blob/main/com/android/server/wifi/WifiConnectivityMonitor.java">WifiConnectivityMonitor.java</a>. The decompiled code contains the following:</p>
<p>line 129: the hardcoded address <code>114.114.114.114</code></p>
<pre>private static final String CHN_PUBLIC_DNS_IP = "114.114.114.114";</pre>
<p>line 878: addresses used for DNS probe (to be covered in next part).</p>
<pre>public final String DEFAULT_URL = "http://www.google.com";
public final String DEFAULT_URL_CHINA = "http://www.qq.com";
public String DEFAULT_URL_STRING = "www.google.com";
public final String DEFAULT_URL_STRING_CHINA = "www.qq.com";</pre>
<p>This large class is mainly a state machine of the various WiFi states. The state hierarchy are defined, and initial state set, at lines 1185-1197.</p>
<pre>addState(this.mDefaultState);
addState(this.mNotConnectedState, this.mDefaultState);
addState(this.mConnectedState, this.mDefaultState);
addState(this.mCaptivePortalState, this.mConnectedState);
addState(this.mEvaluatedState, this.mConnectedState);
....
setInitialState(this.mNotConnectedState);</pre>
<p>The base class for the StateMachine can be found under AOSP source (<a href="https://cs.android.com/android/platform/superproject/+/master:frameworks/base/core/java/com/android/internal/util/StateMachine.java?q=StateMachine.java&amp;ss=android%2Fplatform%2Fsuperproject">StateMachine.java</a>).</p>
<p>When the device is connected to WiFi, it would enter <code>ConnectedState</code>.</p>
<p>line 1976 (under <code>processMessage()</code> of the initial <code>NotConnectedState</code>) would be invoked when a new WiFi connection is detected.</p>
<pre>wifiConnectivityMonitor.transitionTo(wifiConnectivityMonitor.mConnectedState);</pre>
<p>The <code>mConnectedState</code> variable is of class <code>ConnectedState</code>, defined from line 1988. The <code>enter()</code> method of <code>ConnectedState</code> contains the following code (from line 2090), which uses <code>CHN_PUBLIC_DNS_IP</code> (i.e. the Mainland Chinese controlled DNS server):</p>
<pre>if (WifiConnectivityMonitor.this.mWifiManager != null &amp;&amp; WifiConnectivityMonitor.this.inChinaNetwork()) {
    Message msg = new Message();
    msg.what = 330;
    Bundle args = new Bundle();
    args.putString("publicDnsServer", WifiConnectivityMonitor.CHN_PUBLIC_DNS_IP);
    msg.obj = args;
    WifiConnectivityMonitor.this.mWifiManager.callSECApi(msg);
}
</pre>
<p>From the code it seems to add the Mainland Chinese DNS service to the user’s list of DNS server automatically, when the device is connected to Chinese mobile network. There seems no option to disable the behaviour.</p>
<p><code>WifiConnectivityMonitor.inChinaNetwork()</code> is at line 11199.&nbsp; As suggested by its name, it should obtain the ISO code and return true only if the device is connected to a mobile network in China:</p>
<pre>public boolean inChinaNetwork() {
    String str = this.mCountryIso;
    if (str == null || str.length() != 2) {
        updateCountryIsoCode();
    }
    if (!isChineseIso(this.mCountryIso)) {
        return false;
    }
    if (!DBG) {
        return true;
    }
    Log.d(TAG, "Need to skip captive portal check. CISO: " + this.mCountryIso);
    return true;
}
</pre>
<p>Digging deeper, this is how the ISO code (<code>mCountryIso</code>) is obtained, under <code>updateCountryIsoCode()</code> at line 11219 (fallback skipped).</p>
<pre>public void updateCountryIsoCode() {
    if (this.mTelephonyManager == null) {
        try {
            this.mTelephonyManager = (TelephonyManager) this.mContext.getSystemService("phone");
        } catch (Exception e) {
            Log.e(TAG, "Exception occured at updateCountryIsoCode(), while retrieving Context.TELEPHONY_SERVICE");
        }
    }
    TelephonyManager telephonyManager = this.mTelephonyManager;
    if (telephonyManager != null) {
        this.mCountryIso = telephonyManager.getNetworkCountryIso();
        Log.i(TAG, "updateCountryIsoCode() via TelephonyManager : mCountryIso: " + this.mCountryIso);
    }
    /* fallback when there is no mobile network skipped. The fallback is to read the CountryISO setting from a Samsung config file (cscfeature.xml) */
    ....
}
</pre>
<p>(While not shown here, this code is also invoked when initializing and when change in ISO code of telephone network is detected, so it need not be called during each check.) The country code is get from <code>TelephonyManager.getNetworkCountryIso()</code> which is a standard Android API, documented <a href="https://developer.android.com/reference/android/telephony/TelephonyManager#getNetworkCountryIso()">here</a>. It returns the ISO-3166-1 alpha-2 country code equivalent of the MCC (Mobile Country Code) of the mobile operator. In Hong Kong, this is “HK”, and in Mainland China this is “CN”.</p>
<p>As one might suspect at this point, the problem lies in <code>isChineseIso()</code>, at line 11214:</p>
<pre>private boolean isChineseIso(String countryIso) {
    return "cn".equalsIgnoreCase(countryIso) || "hk".equalsIgnoreCase(countryIso) || "mo".equalsIgnoreCase(countryIso);
}</pre>
<p>This means that you are treated as being connected to a Chinese mobile network if you are connected to a Hong Kong mobile network for the purpose of adding the 114 DNS service.&nbsp; (BTW, “MO” is the ISO-3166-1 code for Macau.) Perhaps Samsung might want to address cases when people travel to Mainland China while forgetting to reset their hardcoded DNS settings, and kindly “add” a DNS service which works within the Great Firewall of China. But they seemed to forget that both Hong Kong and Macau are outside the Great Firewall, at least so far.</p>
<p>Back to the DNS setting code above (line 2090). It makes a binder call to <code>WifiManager.callSECApi()</code>, with message code = 330, with a <code>Bundle</code> setting <code>publicDnsServer</code> to our friend <code>114.114.114.114</code>. While <code>WifiManager</code> is a standard Android class the method <code>callSECApi()</code>, as suggested by its name, is Samsung specific.</p>
<p>The remote call to <code>WifiManager</code> would end up in the service class implementation at <code>com.android.server.wifi.WifiServiceImpl</code>, implementing WifiService, at <a href="https://github.com/headuck/SM-N9750-TGY/blob/main/com/android/server/wifi/WifiServiceImpl.java">WifiServiceImpl.java</a>. (The class is Samsung’s extension to the AOSP service class of the same …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/</a></em></p>]]>
            </description>
            <link>http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816764</guid>
            <pubDate>Sun, 18 Oct 2020 10:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build products that are hard to live without]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24816608">thread link</a>) | @rjyoungling
<br/>
October 18, 2020 | https://www.younglingfeynman.com/essays/livewithout | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/livewithout">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-6668c42b763b213dbe56"><div><p>That should be your aspiration in your company. To create something that’s hard for your customer to live without. For me, my AirPods Pro, my Dyson vacuum, Audible, and Spotify are the first to come to mind.</p><p>You don’t want to be one of many. Having to resort to bribing people to use you instead of another company. Sure, you can make money but your company will be very sensitive.</p><p><em>A tiny ‘’push’’ by a competitor or a changing market will displace you out of equilibrium.&nbsp;</em></p><p>Think of delicately balancing a marble on a flipped bowl. If you can balance it, the tiniest force will displace it out of its meta-stable equilibrium.&nbsp;</p><p>If you have a startup that’s susceptible to being cloned (Groupon) and succumbing to consumer surplus (Lime, Bird, Spin, etc.) it’ll be more fragile. The ultimate example is dropshipping or any other get rich quick/commodity scheme.&nbsp;</p><p><em>This incidentally, is also why those things don’t work. As soon as you have a formula, the more people will implement it, the less effective it’ll be.&nbsp;</em></p><p><em>Read: </em><a href="https://www.younglingfeynman.com/essays/antinetworkeffects" target="_blank"><em>Network Effects, Neutral Network Effects, and Anti-Network Effects</em></a></p><p><em>The very existence of an easy formula makes that particular business model meta-stable.</em></p><p><em>Check </em><a href="https://www.younglingfeynman.com/essays/ten" target="_blank"><em>Ten</em></a><em> and </em><a href="https://www.younglingfeynman.com/essays/deeplove" target="_blank"><em>Do You Have Customers Who Deeply Love You?</em></a></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602502923408_28311"><div><p><em>I took these pictures for y’all when I was in Germany for business. As you can see, there’s Lime, Bird, Spin, Tier, and Dott. All fighting for market share and competing away profits. This creates a consumer surplus environment where the consumer would be willing to pay more but they don’t have to. That’s good for the consumer but dangerous for you as a startup.</em></p><p>If you can find a way to create a product that 1 person finds hard to live without, you can probably find 10. If you can find 10, you can probably find 100. And so on.</p><p>As a matter of fact, that 1 person most likely has 1 or 2 friends who they’ll bring into your tribe without you having to do any work. Having a product that people love so much it’s hard to live without makes your company more resilient.</p><p>Getting 1 person to feel that way is both harder and easier than people think. It’s hard because it’ll take a lot of effort and iteration before people truly feel like they would rather not live without your product.&nbsp;</p><p>It’s easier because virtually none of your competitors are even trying. They’re too focussed on the bottom line to even think about it. If they do, it’s mostly lip service or an afterthought.</p><p><em>It’s very difficult to push the business out of its equilibrium.&nbsp;</em></p><p>A business is in stable equilibrium if when it’s displaced it experiences a force pulling it back toward its equilibrium. Craigslist still lives on despite many competitors having improved a subset of it.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602502923408_24853"><div><p>Think of a marble in a bowl. If you displace it, it’ll experience a restoring force that’s trying to get it back into its stable equilibrium position. It actually takes a force to keep that marble away from its equilibrium position. That is until you put so much force on it, that it flies out of the bowl. The equivalence of this would be the iPhone vs. Nokia and Blackberry phones.</p><p>Suppose some law was passed that bans Google’s search engine until 2M people sign a petition on change.org to reinstate it. How long until that’d be done?</p><p>Probably not that long. Google is highly stable.</p><p>Now imagine the same thing with Instagram. A lot of people love Instagram but it’s probably not quite as stable as Google. One can imagine a lot of users moving on to TikTok and all of the other social platforms. It also wouldn’t be too long for someone to create a better IG from scratch without all the feature creep. IG would probably still be back though but it would likely take longer than the Google example.</p><p>Now imagine Facebook. Again, seems less stable than IG.</p><p>Now imagine TV. It might not even get back on its feet at all. If it would, it would take significantly longer than any of the previous examples.</p><p>This is essentially what happened during the pandemic. It exposed businesses that were meta-stable and businesses that thrived under this particular pressure. (Anti-fragile. Things that improve when stress is placed upon them.)</p><p>Zoom was anti-fragile because the pandemic made the product better.</p><p>This is why we often hear the following aphorism: ‘’Hard startups are easier than easy startups.’’ That’s because they’re more stable. It’s harder to disrupt a SpaceX or a Stripe than a <a href="https://techcrunch.com/2017/05/26/on-demand-food-startup-sprig-is-shutting-down-today/" target="_blank">Sprig</a>, <a href="https://www.theverge.com/2019/12/7/21000094/unicorn-electric-scooter-shut-down-refund-tile" target="_blank">Unicorn Scooters</a>, or a <a href="https://www.theverge.com/2019/9/19/20872984/moviepass-shutdown-subscription-movies-helios-matheson-ted-farnsworth-explainer" target="_blank">MoviePass</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/livewithout</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816608</guid>
            <pubDate>Sun, 18 Oct 2020 09:37:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing the Timing of Brainwork]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24816412">thread link</a>) | @rajlego
<br/>
October 18, 2020 | https://supermemo.guru/wiki/Optimizing_the_timing_of_brainwork | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Optimizing_the_timing_of_brainwork">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">Science of sleep</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>


<h2><span id="Optimizing_the_timing_of_brainwork">Optimizing the timing of brainwork</span></h2>
<p>Twice a day, we peak in intellectual performance. We can improve our productivity by understanding the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a></p>
<h3><span id="Circadian_graph_and_brainwork">Circadian graph and brainwork</span></h3>
<p>Charting the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a> makes it possible to find the best windows of time for brainwork. The <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> graph below was generated with <a href="https://supermemo.guru/wiki/SleepChart" title="SleepChart">SleepChart</a> using a log of <a href="https://supermemo.guru/wiki/Free_running_sleep" title="Free running sleep">free running sleep</a>. In the graph, two yellow bands indicate the optimum time for brainwork. The exact timing may differ for each individual. However, the blocks can be easily determined:
</p>
<ol><li> <b>Morning block</b>: soon after waking, after morning coffee, or after breakfast. The best brain slot may last 2-4 hours. If you are sleepy in the morning see: <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">Natural creativity cycle</a></li>
<li> <b>Evening block</b>: soon after <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a>. The second best brain slot may last 2-4 hours as well. If you do not nap, you may not fully benefit from that block (see: <a href="https://supermemo.guru/wiki/Power_nap" title="Power nap">Power nap</a>). If you are sleepy during this slot see: <a href="https://supermemo.guru/wiki/Best_time_for_napping" title="Best time for napping">Best time for napping</a></li></ol>
<p>The graph explains the reasons for which the two brainwork blocks emerge:
</p>
<div><p><a href="https://supermemo.guru/wiki/File:Circadian_graph_and_brainwork.gif" title="Optimizing the timing of brainwork with respect to the circadian cycle"><img alt="Optimizing the timing of brainwork with respect to the circadian cycle" src="https://supermemo.guru/images/thumb/e/ef/Circadian_graph_and_brainwork.gif/600px-Circadian_graph_and_brainwork.gif" width="600" height="454" srcset="https://supermemo.guru/images/e/ef/Circadian_graph_and_brainwork.gif 1.5x"></a></p></div>
<blockquote><i><b>Figure:</b> <b>Optimizing the timing of brainwork with respect to the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a></b>. This graph was generated with the help of <a href="https://supermemo.guru/wiki/SleepChart" title="SleepChart">SleepChart</a> on the basis of 3-year-long daily measurements of a <a href="https://supermemo.guru/wiki/Free-running_sleep" title="Free-running sleep">free-running sleep</a> rhythm. The horizontal axis expresses the <a href="https://supermemo.guru/wiki/Circadian_phase" title="Circadian phase">number of hours from awakening</a> (note that the <a href="https://supermemo.guru/wiki/Free-running_sleep" title="Free-running sleep">free-running sleep</a> cycle period may be longer than 24 hours). <span>Light blue dots</span> are actual sleep episode measurements with timing on the horizontal, and the length on the left vertical axis. <b><a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">Homeostatic</a></b> sleepiness can roughly be expressed as the <b>ability to initiate sleep</b>. Percent of the initiated sleep episodes is painted as a thick <span>blue line</span> (right-side calibrations of the vertical axis). Adenosine-related <a href="https://supermemo.guru/wiki/Homeostatic_sleep_propensity" title="Homeostatic sleep propensity">homeostatic sleep propensity</a> increases in proportion to mental effort and can be partially cleared by caffeine, stress, etc. <b><a href="https://supermemo.guru/wiki/Circadian" title="Circadian">Circadian</a></b> sleepiness can roughly be expressed as <b>the ability to maintain sleep</b>. Average length of the initiated sleep episodes is painted as a thick <span>red line</span> (left-side calibrations of the vertical axis). Mid-day slump in alertness is also circadian, but is biologically different and results in short sleep that does not register as a red peak. <b>Sleep maintenance</b> circadian component correlates (1) negatively with core body temperature, <a href="https://en.wikipedia.org/wiki/ACTH">ACTH</a>, <a href="https://en.wikipedia.org/wiki/Cortisol">cortisol</a>, <a href="https://en.wikipedia.org/wiki/Catecholamine">catecholamines</a>, and (2) positively with: <a href="https://supermemo.guru/wiki/Melatonin" title="Melatonin">melatonin</a> and <a href="https://supermemo.guru/wiki/REM_sleep" title="REM sleep">REM sleep</a> propensity. <b>Optimum timing of brainwork</b> requires both (1) low <a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">homeostatic</a> sleepiness, and (2) low <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> sleepiness. There are two high quality alertness blocks during the day: the first after the awakening, and the second after the <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a>. Both blocks are marked as <span>yellow</span> bands below the graph. For best learning, and for best <a href="https://supermemo.guru/wiki/Creativity" title="Creativity">creativity</a>, use these two <span>yellow blocks</span> of time. <a href="https://supermemo.guru/wiki/Caffeine" title="Caffeine">Caffeine</a> can only be used to enhance alertness early in the optimum brainwork window (<span>brown</span>). Later use will affect sleep (caffeine half-life is about six hours). Optimum timing of exercise is not marked as it may vary depending on the optimum timing of <a href="https://supermemo.guru/wiki/Zeitgeber" title="Zeitgeber">zeitgebers</a> (e.g. early morning for <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a> people and evening for ASPS people). For more details see: <a href="https://supermemo.guru/wiki/Biphasic_life" title="Biphasic life">Biphasic nature of human sleep</a></i></blockquote>
<h3><span id="Best_brainwork_time">Best brainwork time</span></h3>
<p>The optimum timing of brainwork requires both high <a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">homeostatic</a> alertness and high <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> alertness. There are two quality alertness blocks during the day: the first occurs after awakening and the second after the <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a> period. Both are marked as <span>yellow blocks</span> in the graph (above). For best learning and best creative results, use these yellow blocks for brainwork. <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Caffeine" title="Factors that affect sleep"><span>Caffeine</span></a> can only be used to enhance alertness early in this optimum window. Later use will affect sleep (the half-life of caffeine is about six hours). The optimum timing of exercise may vary depending on your <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Exercise" title="Factors that affect sleep">exercise</a> goals and the optimum timing of zeitgebers (e.g. early morning for <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a> people and evening for <a href="https://supermemo.guru/wiki/Advanced_Sleep_Phase_Syndrome_(ASPS)" title="Advanced Sleep Phase Syndrome (ASPS)">ASPS</a> people). In this example, the <span>stress block</span> is followed by the <span>exercise block</span> to counterbalance the hormonal and neural effects of <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Stress" title="Factors that affect sleep">stress</a> before the <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a> (see: <a href="https://supermemo.guru/wiki/Stress_valve" title="Stress valve">Stress valves</a>). Unmarked white areas can be used for the lunch (before siesta) and fun time unrelated to work in the evening at a time when the ascending <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> sleepiness makes creative work ineffective. That white evening protective zone should be free from stress, <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Alcohol" title="Factors that affect sleep">alcohol</a>, <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Caffeine" title="Factors that affect sleep">caffeine</a>, etc. Recommended activities might include fun games, relaxation, TV, reading, family-time, DIY, housework, etc. For inveterate workaholics, less challenging and stress-free jobs might also work ok. 
</p>
<p><b>The best test for a well designed day is that all activities <a href="https://supermemo.guru/wiki/Pleasure_of_learning" title="Pleasure of learning">should be fun</a>!</b></p> 
<p>Brainwork is fun only if your brain is ready. Sleep is fun if you are ready. Rest and entertainment feel right only after a productive day. Even a bit of <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">stress</a> can be fun if it is properly dosed and timed. You do not need to be an adrenaline junkie to enjoy your stress and exercise slots. There is little exaggeration in saying that <b>a good understanding of the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a> is the key to a happy and productive day!</b> (see: <a href="https://supermemo.guru/wiki/Formula_for_happy_life" title="Formula for happy life">Formula for happy life</a>).
</p>
<p>Happy and productive life is best achieved by adhering to the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a></p>
<h3><span id="Natural_creativity_cycle">Natural creativity cycle</span></h3>
<p>In addition to the variables of the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a>, the <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">natural creativity cycle</a> employs the fact that the neocortex operates in several modes determined by local fatigue, <a href="https://supermemo.guru/wiki/Creativity" title="Creativity">creative meandering</a>, and <a href="https://supermemo.guru/wiki/Neural_optimization_in_sleep" title="Neural optimization in sleep">neural optimization in sleep</a>. During the day, natural transitions from high focus to distraction, to high creativity, and to rest will occur in proportion to the engagement of individual areas of the cortex. It will depend on the <a href="https://supermemo.guru/wiki/Concept_map" title="Concept map">concept maps</a> involved in the <a href="https://supermemo.guru/wiki/Mental_computation" title="Mental computation">mental computation</a>, and the overall neural activation. At night, the brain will proceed with natural <a href="https://supermemo.guru/wiki/Memory_optimization" title="Memory optimization">memory optimization</a> by sequentially switching between <a href="https://supermemo.guru/wiki/NREM" title="NREM">NREM</a> and <a href="https://supermemo.guru/wiki/REM" title="REM">REM</a> sleep modes.
</p>
<p>All brainwork should be based on self-regulation and natural transitions to high <a href="https://supermemo.guru/wiki/Creativity" title="Creativity">creativity</a> and/or rest. All forms of artificial control will increase the fatigue and reduce the productivity</p>
<p>For details see: <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">Natural creativity cycle</a>
</p>
<h3><span id="Balanced_24_hour_cycle">Balanced 24 hour cycle</span></h3>
<p>The <span>slanting green line</span> separates the graph into the areas of phase advanced (right) and phase delays (left). The line is determined by points in the graph where the waking time (horizontal axis) added to the sleep time (left vertical axis) equals to 24.0 hours. The place where the <span>green breakeven line</span> crosses the <span>red sleep length line</span> determines the optimum balanced sleep cycle of 24 hours. In the presented example, 17.35 hours of waking, added to the expected 6.65 hours of sleep time complete a balanced full 24 hours sleep-wake cycle. The greater the angle between the <span>green</span> and <span>red</span> lines, the harder it is to balance sleep and fit it into the 24h cycle of the rotating earth. In the example, adding waking hours does not shorten sleep much enough to make the balance easy. This implies that a religious adherence to a 17.35 day may be necessary to balance the cycle. However, this shortened waking day may increase <a href="https://supermemo.guru/wiki/Sleep_latency" title="Sleep latency">sleep latency</a> and increase the probability of premature awakening, which can also tip the balance towards the phase delay. The <span>vertical aqua line</span> shows where the expected sleep time added to the waking time equals to 24 hours (crossover with the <span>green line</span> representing a perfect 24-hour day). In <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a> or <a href="https://supermemo.guru/wiki/Advanced_Sleep_Phase_Syndrome_(ASPS)" title="Advanced Sleep Phase Syndrome (ASPS)">ASPS</a> that 24h balance may be hard to accomplish. For example, without medical intervention, only a large protective zone in the evening, early nap (or no nap), and intense morning exercise can help balance the day in <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a>.
</p><p><b>Important!</b> This graph is based on data that is true solely for a free running sleep condition. If you use an alarm clock to regulate the timing of your sleep, these measurements and recommendations may not apply! In addition, the timing and amplitude of changes differ vastly between individuals!
</p>
<h2><span id="Sleeping_against_your_natural_rhythm">Sleeping against your natural rhythm</span></h2>
<p>If you sleep against your natural rhythm you will often experience tiredness or drowsiness that can be resolved by adjusting the sleeping hours. In healthy individuals, the daytime alertness is primarily determined by:
</p>
<ol><li> <a href="https://supermemo.guru/wiki/Two_components_of_sleep" title="Two components of sleep">circadian phase and homeostatic sleepiness</a></li>
<li> total sleep time the night before</li>
<li> <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep#NREM_and_memory" title="Memory optimization in sleep">amount of slow-wave sleep the night before</a></li>
<li> regular adherence to the sleep-wake schedule in preceding days</li>
<li> sleep deficits accumulated in the preceding days (e.g. <a href="https://supermemo.guru/wiki/How_do_we_fall_asleep%3F#REM_rebound_hypothesis" title="How do we fall asleep?">REM deficit</a>, SWA deficit, etc.)</li></ol>
<p>All those factors are closely associated with the sleep phase. <a href="https://supermemo.guru/wiki/Formula_for_good_sleep:_free_running_sleep" title="Formula for good sleep: free running sleep">Free running sleep</a> provides the best way to maximize alertness throughout a waking day. Free running sleep is likely to shift the minimum temperature point from the early morning closer towards the middle of the <a href="https://supermemo.guru/wiki/Subjective_night" title="Subjective night">subjective night</a>. You should notice <a href="https://supermemo.guru/wiki/Insomnia" title="Insomnia">increased sleepiness before going to sleep</a> and no <a href="https://supermemo.guru/wiki/Sleep_inertia" title="Sleep inertia">sleep inertia</a> upon awakening! If you cannot free-run your sleep, it is very important to understand the relationship between your <a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">homeostatic</a> and <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> sleep drives as compiled in the table below. In the course of the day, you should move in sync between the yellow areas of the table, i.e. <a href="https://supermemo.guru/wiki/How_do_we_fall_asleep%3F#Sleep-wake_flip-flop" title="How do we fall asleep?">from perfect alertness to maximum sleepiness, and then back to perfect alertness</a>. The gray areas illustrate when your sleep falls out of sync:
</p>
<table>
<tbody><tr>
<td>
</td>
<td>High circadian sleepiness
</td>
<td>Low circadian sleepiness
</td></tr>
<tr>
<td>High homeostatic sleepiness
</td>
<td><b>Peak of the night</b>: You are very drowsy and fall into refreshing sleep with latency of less than five minutes
</td>
<td><b>Insomnia</b>: You are tossing and turning in bed. You are very tired but you cannot fall asleep. Your temperature, blood pressure and pulse are raised. Your thoughts are racing
<p><b>Solution</b>: Wait for the arrival of the <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> phase. Delay going to sleep by 3-6 hours
</p>
</td>
</tr></tbody><caption>
</caption>
<tbody><tr><td>Low homeostatic sleepiness
</td>
<td><b>Hypersomnia</b>: You are drowsy throughout the day despite long sleep hours. Napping does not help. You show minimum energy levels. Your muscles are weak and atonic
<p><b>Solution</b>: Adjust your sleep phase to your <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> (e.g. try to go to sleep 3-6 hours later)
</p>
</td>
<td><b>Peak of the day</b>: You are alert, energetic, and full of new ideas
</td></tr></tbody></table>

<!-- 
NewPP limit report
Cached time: 20201021203041
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.122 seconds
Real time usage: 0.132 seconds
Preprocessor visited node count: 107/1000000
Preprocessor generated node count: 243/1000000
Post‐expand include size: 10085/2097152 bytes
Template argument size: 3318/2097152 bytes
Highest expansion depth: 5/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   23.554      1 - -total
 40.05%    9.434      1 - File:Circadian_graph_and_brainwork.gif
 36.41%    8.576      1 - ArticleSleep
 26.12%    6.153      1 - Template:Fig
 16.65%    3.922      4 - Template:Important_note
 10.43%    2.456      6 - Template:=
-->

<!-- Saved in parser cache with key supermem_kool_kids:pcache:idhash:401-0!*!0!!en!5!* and timestamp 20201021203041 and revision id 21364
 -->
</div></div>]]>
            </description>
            <link>https://supermemo.guru/wiki/Optimizing_the_timing_of_brainwork</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816412</guid>
            <pubDate>Sun, 18 Oct 2020 08:52:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Certified Associate Exam Preparation Guide]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24816115">thread link</a>) | @pjmlp
<br/>
October 18, 2020 | https://evalle.github.io/DCA/ | <a href="https://web.archive.org/web/*/https://evalle.github.io/DCA/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>This guide is intended to be a point of knowledge for everyone who wants to pass <a href="https://blog.docker.com/2017/09/introducing-docker-global-professional-certification-program/">Docker Certified Associate Exam</a>. The main idea is to provide links to every topic in each domain. Preference will always be the official documentation, but feel free to add useful links.</p>

<h2 id="table-of-contents">Table of Contents:</h2>
<ol>
  <li>Orchestration</li>
  <li>Image Creation, Management, and Registry</li>
  <li>Installation and Configuration</li>
  <li>Networking</li>
  <li>Security</li>
  <li>Storage and Volumes</li>
  <li>Links</li>
</ol>

<h2 id="content">Content</h2>

<h3 id="domain-1-orchestration-25-of-exam">Domain 1: Orchestration (25% of exam)</h3>
<ul>
  <li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/">Complete the setup of a swarm mode cluster, with managers and worker nodes</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/">Describe and demonstrate how to extend the instructions to run individual containers into running services under swarm</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/raft/">Describe the importance of quorum in a swarm cluster.</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#services-tasks-and-containers">Describe the difference between running a container and running a service.</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/">Interpret the output of “docker inspect” commands</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/stack-deploy/">Convert an application deployment into a stack file using a YAML compose file with “docker stack deploy”</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/stack_services/#related-commands">Manipulate a running stack of services</a></li>
  <li><a href="https://docs.docker.com/get-started/orchestration/">Describe and demonstrate orchestration activities</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/service_scale/">Increase number of replicas</a></li>
  <li><a href="https://docs.docker.com/network/">Add networks, publish ports</a></li>
  <li><a href="https://docs.docker.com/storage/volumes/">Mount volumes</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#replicated-and-global-services">Describe and demonstrate how to run replicated and global services</a></li>
  <li><a href="https://success.docker.com/article/using-contraints-and-labels-to-control-the-placement-of-containers">Apply node labels to demonstrate placement of tasks</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/service_create/#create-services-using-templates">Describe and demonstrate how to use templates with “docker service create”</a></li>
  <li><a href="https://success.docker.com/article/swarm-troubleshooting-methodology">Identify the steps needed to troubleshoot a service not deploying</a></li>
  <li><a href="https://docs.docker.com/config/containers/container-networking/">Describe how a Dockerized application communicates with legacy systems</a></li>
  <li><a href="https://docs.docker.com/get-started/kube-deploy/">Describe how to deploy containerized workloads as Kubernetes pods and deployments</a></li>
  <li><a href="https://opensource.com/article/19/6/introduction-kubernetes-secrets-and-configmaps">Describe how to provide configuration to Kubernetes pods using configMaps and secrets</a></li>
</ul>

<h3 id="domain-2-image-creation-management-and-registry-20-of-exam">Domain 2: Image Creation, Management, and Registry (20% of exam)</h3>
<ul>
  <li><a href="https://docs.docker.com/engine/reference/builder/">Describe the use of Dockerfile</a></li>
  <li><a href="https://docs.docker.com/engine/reference/builder/#from">Describe options, such as add, copy, volumes, expose, entry point</a></li>
  <li><a href="https://docs.docker.com/engine/reference/builder/#dockerfile-examples">Identify and display the main parts of a Dockerfile</a></li>
  <li><a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/">Describe and demonstrate how to create an efficient image via a Dockerfile</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/image/#usage">Describe and demonstrate how to use CLI commands to manage images, such as list, delete, prune, rmi</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/images/#filtering">Describe and demonstrate how to inspect images and report specific attributes using filter and format</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/tag/">Describe and demonstrate how to tag an image.</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/image_load/">Describe and demonstrate how to apply a file to create a Docker image</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/image_inspect/">Describe and demonstrate how to display layers of a Docker image</a></li>
  <li>Describe and demonstrate how to modify an image to a single layer (<a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#minimize-the-number-of-layers">multi-stage build</a>, <a href="https://stackoverflow.com/questions/39695031/how-make-docker-layer-to-single-layer">single layer</a>)</li>
  <li><a href="https://docs.docker.com/registry/">Describe and demonstrate registry functions</a></li>
  <li><a href="https://docs.docker.com/registry/deploying/">Deploy a registry</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/login/">Log into a registry</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/search/">Utilize search in a registry</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/push/">Push an image to a registry</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/trust_sign/">Sign an image in a registry</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/pull/">Pull</a> and <a href="https://docs.docker.com/registry/spec/api/#deleting-an-image">delete</a> images from a registry</li>
</ul>

<h3 id="domain-3-installation-and-configuration-15-of-exam">Domain 3: Installation and Configuration (15% of exam)</h3>
<ul>
  <li><a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/#upgrade-docker-engine---community">Demonstrate the ability to upgrade the Docker engine</a></li>
  <li><a href="https://docs.docker.com/install/">Complete setup of repo, select a storage driver, and complete installation of Docker
engine on multiple platforms</a></li>
  <li><a href="https://docs.docker.com/config/containers/logging/configure/">Configure logging drivers (splunk, journald, etc)</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/admin_guide/">Setup swarm, configure managers, add nodes, and setup backup schedule</a></li>
  <li><a href="https://docs.docker.com/datacenter/dtr/2.4/guides/admin/manage-users/create-and-manage-teams/">Create and manage user and teams</a></li>
  <li><a href="https://docs.docker.com/config/daemon/#troubleshoot-the-daemon">Interpret errors to troubleshoot installation issues without assistance</a></li>
  <li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/admin/install/system-requirements/#hardware-and-software-requirements">Outline the sizing requirements prior to installation</a></li>
  <li><a href="https://docs.docker.com/engine/docker-overview/#namespaces">Understand namespaces, cgroups, and configuration of certificates</a></li>
  <li><a href="https://docs.docker.com/engine/security/certificates/">Use certificate-based client-server authentication to ensure a Docker daemon has the
rights to access images on a registry</a></li>
  <li>Consistently repeat steps to deploy Docker engine, UCP, and DTR on AWS and on
premises in an HA config. <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/">Docker,</a> <a href="https://docs.docker.com/datacenter/dtr/2.3/guides/admin/install/">DTR,</a> <a href="https://docs.docker.com/ee/ucp/">UCP,</a>, <a href="https://docs.docker.com/docker-for-aws/">Docker on AWS</a> and possibly <a href="https://docs.docker.com/engine/swarm/admin_guide/#add-manager-nodes-for-fault-tolerance">on premises HA config</a></li>
  <li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/admin/backups-and-disaster-recovery/">Complete configuration of backups for UCP and DTR</a></li>
  <li><a href="https://docs.docker.com/install/linux/linux-postinstall/">Configure the Docker daemon to start on boot</a></li>
</ul>

<h3 id="domain-4-networking-15-of-exam">Domain 4: Networking (15% of exam)</h3>
<ul>
  <li><a href="https://docs.docker.com/network/network-tutorial-standalone/">Create a Docker bridge network for a developer to use for their containers</a></li>
  <li><a href="https://success.docker.com/article/troubleshooting-container-networking">Troubleshoot container and engine logs to understand a connectivity issue between
containers</a></li>
  <li><a href="https://github.com/wsargent/docker-cheat-sheet#exposing-ports">Publish a port so that an application is accessible externally</a></li>
  <li><a href="https://docs.docker.com/engine/reference/commandline/port/#examples">Identify which IP and port a container is externally accessible on</a></li>
  <li><a href="https://blog.docker.com/2016/12/understanding-docker-networking-drivers-use-cases/">Describe the different types and use cases for the built-in network drivers</a></li>
  <li><a href="https://success.docker.com/article/networking/">Understand the Container Network Model and how it interfaces with the Docker engine
and network and IPAM drivers</a></li>
  <li><a href="https://gist.github.com/Evalle/7b21e0357c137875a03480428a7d6bf6">Configure Docker to use external DNS</a></li>
  <li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/admin/configure/use-a-load-balancer/#configuration-examples">Use Docker to load balance HTTP/HTTPs traffic to an application (Configure L7 load
balancing with Docker EE)</a></li>
  <li><a href="https://success.docker.com/article/networking/">Understand and describe the types of traffic that flow between the Docker engine,
registry, and UCP controllers</a></li>
  <li><a href="https://docs.docker.com/network/overlay/">Deploy a service on a Docker overlay network</a></li>
  <li>Describe the difference between “host” and “ingress” port publishing mode (<a href="https://docs.docker.com/engine/swarm/services/#publish-a-services-ports-directly-on-the-swarm-node">Host</a>, <a href="https://docs.docker.com/engine/swarm/ingress/">Ingress</a>)</li>
</ul>

<h3 id="domain-5-security-15-of-exam">Domain 5: Security (15% of exam)</h3>
<ul>
  <li><a href="https://docs.docker.com/engine/security/trust/content_trust/#push-trusted-content">Describe the process of signing an image</a></li>
  <li><a href="https://docs.docker.com/datacenter/dtr/2.5/guides/admin/configure/set-up-vulnerability-scans/">Demonstrate that an image passes a security scan</a></li>
  <li><a href="https://docs.docker.com/engine/security/trust/content_trust/">Enable Docker Content Trust</a></li>
  <li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/access-control/">Configure RBAC in UCP</a></li>
  <li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/admin/configure/external-auth/">Integrate UCP with LDAP/AD</a></li>
  <li><a href="https://blog.docker.com/2017/09/get-familiar-docker-enterprise-edition-client-bundles/">Demonstrate creation of UCP client bundles</a></li>
  <li><a href="https://docs.docker.com/engine/security/security/">Describe default engine security</a></li>
  <li><a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/">Describe swarm default security</a></li>
  <li><a href="https://diogomonica.com/2017/01/11/hitless-tls-certificate-rotation-in-go/">Describe MTLS</a></li>
  <li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/access-control/permission-levels/#roles">Identity roles</a></li>
  <li><a href="https://docs.docker.com/datacenter/ucp/2.2/guides/architecture/">Describe the difference between UCP workers and managers</a></li>
  <li>Describe process to use external certificates with UCP and DTR (<strong>UCP</strong> <a href="https://success.docker.com/article/how-do-i-provide-an-externally-generated-security-certificate-during-the-ucp-command-line-installation">from cli</a>, <a href="https://docs.docker.com/ee/ucp/admin/configure/use-your-own-tls-certificates/#configure-ucp-to-use-your-own-tls-certificates-and-keys">from GUI</a>, <a href="https://docs.docker.com/datacenter/ucp/3.0/reference/cli/dump-certs/">print the public certificates</a>), <a href="https://docs.docker.com/ee/dtr/admin/configure/use-your-own-tls-certificates/"><strong>DTR</strong></a>)</li>
</ul>

<h3 id="domain-6-storage-and-volumes-10-of-exam">Domain 6: Storage and Volumes (10% of exam)</h3>
<ul>
  <li><a href="https://docs.docker.com/storage/storagedriver/select-storage-driver/">State which graph driver should be used on which OS</a></li>
  <li><a href="https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-docker-with-the-devicemapper-storage-driver">Demonstrate how to configure devicemapper</a></li>
  <li><a href="https://rancher.com/block-object-file-storage-containers/">Compare object storage to block storage, and explain which one is preferable when
available</a></li>
  <li><a href="https://docs.docker.com/storage/storagedriver/#images-and-layers">Summarize how an application is composed of layers and where those layers reside on
the filesystem</a></li>
  <li><a href="https://docs.docker.com/storage/volumes/">Describe how volumes are used with Docker for persistent storage</a></li>
  <li>Identify the steps you would take to clean up unused images on a filesystem, also on DTR.
(<a href="https://docs.docker.com/engine/reference/commandline/image_prune/">image prune</a>, <a href="https://docs.docker.com/engine/reference/commandline/system_prune/">system prune</a> and <a href="https://docs.docker.com/ee/dtr/user/manage-images/delete-images/">from DTR</a>)</li>
  <li><a href="https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins">Demonstrate how storage can be used across cluster nodes</a></li>
</ul>

<h2 id="quick-facts-about-the-exam">Quick facts about the exam</h2>

<h3 id="summary">Summary</h3>
<p>These are the most relevant quick facts of the exam:</p>

<ul>
  <li>The exam is online, using Google Chrome browser on <b>Windows</b> or <b>MacOS</b> ONLY. <b>Linux</b> support IS NOT available at this time;</li>
  <li>55 questions to be answered within 90 minutes. Which give you almost one minute and a half to spend on each question;</li>
  <li>It costs 195 USD or 175 EUR;</li>
  <li>Lasts for 2 years after the day you got certified;</li>
  <li>Docker does not publish exam passing scores because exam questions and passing scores are subject to change without notice;</li>
  <li>Results comes instantly.</li>
</ul>

<h3 id="question-format">Question format</h3>

<p>All the questions follow this strucuture:</p>

<p>There are THREE TYPES of giving answers:</p>
<ul>
  <li>ONE RIGHT ANSWER: The answer options will be a clickable spot and you must select ONE CHOICE. This can be either select a valid answer in a true/false statement or a fill in blank example.</li>
  <li>MULTIPLE ANSWERS: The answer option will be a square-type and accepts MULTIPLE CHOICES. Before checking the answers, please refer to the question to ensure HOW MANY VALID CHOICES ARE.</li>
  <li>Discrete Option Multiple Choice (DOMC) : Options are randomly presented, one at a time. For each presented option, the examinee chooses YES or NO to indicate if the option is correct. <a href="https://sei.caveon.com/launchpad/docker-domc-practice-exam-world-geography/domc-practice">Sample DOMC Questions</a>.</li>
</ul>

<h2 id="links">Links</h2>

<ul>
  <li><a href="https://success.docker.com/Certification">About the exam</a></li>
  <li><a href="https://docker.cdn.prismic.io/docker/4a619747-6889-48cd-8420-60f24a6a13ac_DCA_study+Guide_v1.3.pdf">Official study guide (PDF)</a></li>
</ul>

<h2 id="contributors">Contributors</h2>

<p>Thanks to all <a href="https://github.com/Evalle/DCA/graphs/contributors">contributors!</a></p>


      </section>
    </div></div>]]>
            </description>
            <link>https://evalle.github.io/DCA/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816115</guid>
            <pubDate>Sun, 18 Oct 2020 07:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Voting and Governance by Smart Contract]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24816044">thread link</a>) | @EGreg
<br/>
October 18, 2020 | https://community.intercoin.org/t/intercoin-defi-votingcontract-and-governance | <a href="https://web.archive.org/web/*/https://community.intercoin.org/t/intercoin-defi-votingcontract-and-governance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p><strong>Where we are</strong></p>
<p>Earlier this year, we <a href="https://www.coindesk.com/in-defense-of-blockchain-voting">published an article in CoinDesk</a> about using crypto to secure our elections. You can read and discuss more on this forum in <a href="https://forum.intercoin.org/t/can-crypto-save-our-elections/885">part 1</a> and <a href="https://forum.intercoin.org/t/how-to-safeguard-elections-with-crypto/886">part 2</a> that go into some detail about how crypto-powered voting would work, and why it would solve many problems that we face today.</p>
<p>A few months ago, Intercoin started building <a href="https://community.intercoin.org/c/applications/14">applications and smart contracts on the Ethereum platform</a>. While it’s not scalable enough to power <a href="https://community.intercoin.org/t/crypto-not-scalable-enough-to-be-money-cointelegraph">everyday money</a> or <a href="https://community.intercoin.org/t/ethereum-scalability-viability">massive elections</a>, perhaps Ethereum 2.0 (<a href="https://medium.com/swlh/a-comprehensive-view-of-ethereum-2-0-serenity-5865ad8b7c62">Serenity</a>) will one day become scalable enough that these smart contracts can see wider adoption, even without having to migrate to the Intercoin back-end platform.</p>
<p>In the meantime, Intercoin is planning to release its own Intercoin App in the app stores, and turn <a href="http://intercoin.org/">intercoin.org</a> into a web-based portal that will let anyone with a <a href="https://metamask.io/">Chrome Extension</a> to deploy the smart contracts we developed, invite friends from their contact list, and manage their community together. We also plan to roll out the Intercoin Crypto Show to teach people more about crypto and smart contracts. In the meantime, if you have questions, feel free to ask them in this forum.</p>
<p><strong>Start of the Art in Crypto Voting</strong></p>
<p>For every technology we use today, there was a time it was laughably inadequate as a replacement for what came before. For decades, chess engines were a mere curiosity, but now a smart phone can beat any grandmaster. The same is now true of voting technology. There have been early experiments in Russia running elections on <a href="https://www.zdnet.com/article/moscows-blockchain-voting-system-cracked-a-month-before-election/">Ethereum</a> as well as proprietary platforms like <a href="https://www.coindesk.com/russia-vote-blockchain">Waves</a>. It’s still early, but we will see tremendous growth in the coming years.</p>
<p>What if people could vote securely online? Then they would be able to make decisions collectively about a variety of things. Technology can lower the cost of running a secure election, and make it available to any organization, large or small. But who can vote, and when? How do we know that it will be secure? Below, we explore exactly these issues.</p>
<p><strong>Who Can Vote?</strong></p>
<p>The first step in democratic elections is determining who can vote, and ensuring that everyone has an equal amount of say. There needs to be some process in place to make sure people don’t create <a href="https://en.wikipedia.org/wiki/Sybil_attack#:~:text=In%20a%20Sybil%20attack%2C%20the,diagnosed%20with%20dissociative%20identity%20disorder.">multiple identities</a> to cheat the system. This is accomplished by voter registration, which itself has controversial issues like purging <a href="https://www.americanbar.org/groups/crsj/publications/human_rights_magazine_home/voting-rights/-use-it-or-lose-it---the-problem-of-purges-from-the-registration0/">inactive voters</a> and <a>disadvantaged voters</a> and other ways of <a href="https://en.wikipedia.org/wiki/Voter_ID_laws_in_the_United_States#Disparate_impact">disenfranchising voters</a> from even having their voice heard in the election.</p>
<p>Perhaps one day we will come up with better solutions for voter registration, but – for now – this step will have to be done via some established process that a community has. We have deployed the <a href="https://community.intercoin.org/t/intercoin-defi-communitycontract/1159/2">CommunityContract</a> specifically to give communities the ability to determine who can vote, and who can’t.</p>
<p><strong>When Can They Vote?</strong></p>
<p>In the USA, voting normally takes place on <a href="https://en.wikipedia.org/wiki/Election_Day_(United_States)">Election Day</a>, the Tuesday after the first Monday in November. Some states allow early voting, so people can cast ballots before Election Day.</p>
<p>Five years ago, I wrote about <a href="http://magarshak.com/blog/?p=212">how polling is better than elections</a>. What I meant is that, expecting the entire population to turn out for an election on a specific day will lead to problems with voter turnout. Having a referendum where only 20% of people vote can cast doubt on the legitimacy of whether the outcome faithfully represents the will of the overall population, or just those who bothered to show up. For example, Puerto Rico <a href="https://en.wikipedia.org/wiki/2017_Puerto_Rican_status_referendum#:~:text=A%20referendum%20on%20the%20political,overwhelmingly%20chose%20statehood%20by%2097%25.">voted in 2017 to join the United States</a> by an overwhelming 97%, but that is partly due to a boycott by the opposition, who didn’t show up to vote, resulting in a 22.93% turnout. Opinion polls, on the other hand, show 52% support for joining the United States – a majority to be sure, but nowhere near as overwhelming, and possibly within a margin of error.</p>
<p>Polling vs Elections is less about who can vote, but rather about <em>when</em>. You can have a poll take place over a 5 year period, and in any given window of time, a certain small, random representative sample is able to vote. Any given participant can vote at most once in that rolling window, before it moves on to others. Participants can also fail to cast a vote, which is similar to sitting out an election, but at least timing of the eligibility window would be randomized for everyone, and can be lengthened to several days, removing major impediments to voting. Of course, all these parameters are customizable, and letting 100% of the people vote 100% of the time throughout the poll is just like a regular election.</p>
<p>People without a phone or active notifications would be underrepresented, but presumably, those who opted into elections and polls conducted with digital technology, especially about smart contract issues, would take care to have them turned on.</p>
<p><strong>Selecting Voters</strong></p>
<p>Each block in Ethereum has a hash of all transactions it contains, and it is pretty much impossible to control this hash without controlling a majority of mining power on the network. Moreover, controlling this hash would only allow one to possibly control the outcome of a tiny window in a single given election. A lot of effort resulting in almost no vandalism.</p>
<p>It is possible for smart contracts to use the <a href="https://ethereum.stackexchange.com/questions/11455/inside-a-smart-contract-is-it-possible-to-get-latest-mined-blocks-number-and-i">hashes from previously mined blocks</a> as a “random” seed (better to call “uncontrolled” seed). Based on this seed, we can select <a href="https://community.intercoin.org/t/intercoin-defi-communitycontract/1159/2">members of the voting community</a> who are eligible to vote in any given block, by calling:</p>
<pre>eligible(address, blockNumber)
</pre>
<p>Blocks can go by pretty fast, and someone eligible to vote in block M could be eligible to vote in blocks M+1, M+2, …, M+N. Actually, rather than base it on block number, we use <em>timestamps</em>. That’s because we can’t rely on how quickly blocks will be mined, especially <a href="https://ethereum.stackexchange.com/a/200/19734">after Ethereum Serenity 2.0 rolls out</a>. Timestamps may sometimes be off by 2 hours or so (if miners are malicious) but this shouldn’t seriously affect the window in a biased way if we’re talking about random samples and polling windows that last several days.</p>
<p>Periodically, the Intercoin app (or another dapp) running on one or more servers somewhere can watch the <code>VotingContract</code> on the blockchain and find out if the user has recently become eligible to vote in the poll. It then sends a notification, sms or email to the user, with a link to the poll. Upon receiving it, the user would typically have a bunch of time to visit the link and cast their vote. Rather than having the smart contract waste gas looping through a ton of previous block hashes and execute the <code>eligible()</code> function, the client dapp interface helpfully submits the <code>blockNumber</code> together with the vote. The smart contract them simply verifies the eligibility before allowing the vote to proceed.</p>
<p>The <code>eligible()</code> function takes into account <code>blockNumber</code>, but also the <code>memberCount</code> from <code>CommunityContract</code> and <code>fraction</code> of them that can vote in any given window. The <code>eligible()</code> function must be continuous in the latter two variables, since e.g. <code>memberCount</code> of a community can change between the time the user learns they can vote, and then when their transaction is finally mined.</p>
<p><strong>What Can They Vote For?</strong></p>
<p>Our <code>VotingContract</code> is designed to be a general-purpose smart contract, to work with many types of elections, referendums, and polls. Those who are eligible to vote will call:</p>
<pre><code>contract VotingContract {
   address externalContract;
   address externalMethod;
   uint fraction; // eligible people to vote in any given window, out of 1e10
   uint minimum; // minimum number of eligible people in any window

   function vote(VotingData data, uint eligibleBlock) {
     if (eligible(msg.sender)
     &amp;&amp; !hasVotedSince(msg.sender, eligibleBlock)) {
        // valid vote as far as eligibility and voting once
        // but external contract might roll back this transaction
        // if the vote contains invalid data, for instance
        externalContract.call(
          abi.encodeWithSignature(
             concat(externalMethod, "(uint256,uint256)"), 
             data
          )
        );
     }
   }
}
</code></pre>
<p>Here, the <code>VotingData</code> is a <code>struct</code> that can contain arbitrary properties, which are interpreted by the <code>externalMethod</code> of the <code>externalContract</code>, which may choose to <code>rollback()</code> the transaction. It is not the business of <code>VotingContract</code> about <em><strong>how</strong></em> the vote is interpreted. It may be tallied in various ways (First past the post, <a href="https://electionscience.org/library/approval-voting-versus-irv/">ranked choice, approval vote</a>) and it may be a vote among two or more candidates (although for more than two, keep in mind <a href="https://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem">Arrow’s Impossibility Theorem</a>). For example, the <code>IncomeContract</code> can use the <code>VotingContract</code> and <code>CommunityContract</code> to allow a community to vote on whether the level of UBI should go up or down by 1%.</p>
<p><strong>Threat Profiles</strong></p>
<p>The set of threat profiles for an election or poll differs from, say, a banking app. Although both require security, in the banking app:</p>
<ol>
<li>people are managing relatively large amounts of money which are dear to them, and therefore take care to make sure their transaction was properly executed</li>
<li>people use the app that the bank releases, cryptographically signs and distributes on the app store or the web through https</li>
<li>people trust the bank and the bank is prepared to reverse individual transactions through chargebacks and fraud investigations</li>
</ol>
<p>On the other hand, with a voting app:</p>
<ol>
<li>people are casting one vote in a sea of votes, and it won’t harm them much if only their transaction was executed incorrectly, so most won’t check</li>
<li>if everyone used a particular app to cast their vote, the creator of the app could be compromised, and no one voter would be incentivized to check</li>
<li>people trust a system consisting of multiple actors, which is not prepared to let only some people recast their votes and not others</li>
</ol>
<p>The combination of 1 and 2 with voting means that most people won’t bother to check that their vote was properly recorded, and even if they do, they won’t know about everyone else whose vote may have been recorded incorrectly. A malicious actor could create a voting app that a large portion of the community ends up using, and this voting app might <a href="https://www.youtube.com/watch?v=EV_c1-YTk8M">switch the …</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://community.intercoin.org/t/intercoin-defi-votingcontract-and-governance">https://community.intercoin.org/t/intercoin-defi-votingcontract-and-governance</a></em></p>]]>
            </description>
            <link>https://community.intercoin.org/t/intercoin-defi-votingcontract-and-governance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816044</guid>
            <pubDate>Sun, 18 Oct 2020 07:04:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5 Hidden Python Features You Probably Never Heard Of]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24816027">thread link</a>) | @miguendes
<br/>
October 17, 2020 | https://miguendes.me/5-hidden-python-features-you-probably-never-heard-of | <a href="https://web.archive.org/web/*/https://miguendes.me/5-hidden-python-features-you-probably-never-heard-of">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this article, I’m going to show you the top 5 unusual features you can find in Python. Experienced Python developers might recognize some of them. However, others will still be unknown. Regardless, I find all of them very cool.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><code>...</code></li>
<li><a href="#an-elegant-unpacking">An Elegant Unpacking</a> </li>
<li><a href="#can-you-flat-this-list">Can You Flat This List?</a> </li>
<li><a href="#what-else">What <code>else</code>?</a></li>
<li><a href="#comparing-things-like-a-boss">Comparing Things Like a Boss</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="yc4ulma"><code>...</code></h2>
<p>Yes, you’re reading it right, <code>...</code> is a valid construct in Python. <code>...</code> is a singleton object called <code>Ellipsis</code>. If you type it into the Python interpreter, you can actually see it:</p>
<pre><code><span>&gt;&gt;&gt; </span>...
<span>Ellipsis</span>
</code></pre>
<p>According to the <a target="_blank" href="https://docs.python.org/3/library/constants.html#Ellipsis">official docs</a> , <code>Ellipsis</code> is a "special value used mostly in conjunction with extended slicing syntax for user-defined container data types.". There’s two major use cases for it. One is to serve as a placeholder body in an empty function. The other is on <code>Numpy</code>, as a slice item, just as described in the docs.</p>
<h3 id="function-placeholder">Function Placeholder</h3>
<pre><code><span><span>def</span> <span>my_awesome_function</span>():</span>
    ...
</code></pre>
<p>This is equivalent to:</p>
<pre><code><span><span>def</span> <span>my_awesome_function</span>():</span>
    <span>Ellipsis</span>
</code></pre>
<p>And this:</p>
<pre><code><span><span>def</span> <span>my_awesome_function</span>():</span>
    <span>pass</span>
</code></pre>
<p>Beware, I'm not saying that <code>pass</code> == <code>...</code>, I'm just saying that as a function body, the outcome is the same. In fact, you can use anything as placeholder.</p>
<pre><code><span><span>def</span> <span>my_awesome_function</span>():</span>
    <span>"An empty, but also awesome function"</span>
</code></pre>
<h3 id="numpy">Numpy</h3>
<p>The code below basically means create an array of matrices. Each matrix is 3x3. Then get the second column (numpy arrays are 0-based) of all innermost matrix.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>import</span> numpy <span>as</span> np
<span>&gt;&gt;&gt; </span>array = np.arange(<span>27</span>).reshape(<span>3</span>, <span>3</span>, <span>3</span>)
<span>&gt;&gt;&gt; </span>array
array([[[ <span>0</span>,  <span>1</span>,  <span>2</span>],
        [ <span>3</span>,  <span>4</span>,  <span>5</span>],
        [ <span>6</span>,  <span>7</span>,  <span>8</span>]],

       [[ <span>9</span>, <span>10</span>, <span>11</span>],
        [<span>12</span>, <span>13</span>, <span>14</span>],
        [<span>15</span>, <span>16</span>, <span>17</span>]],

       [[<span>18</span>, <span>19</span>, <span>20</span>],
        [<span>21</span>, <span>22</span>, <span>23</span>],
        [<span>24</span>, <span>25</span>, <span>26</span>]]])
<span>&gt;&gt;&gt; </span>array[..., <span>1</span>] 
array([[ <span>1</span>,  <span>4</span>,  <span>7</span>],
       [<span>10</span>, <span>13</span>, <span>16</span>],
       [<span>19</span>, <span>22</span>, <span>25</span>]])
<span>&gt;&gt;&gt; </span>
<span>&gt;&gt;&gt; </span>array[:, :, <span>1</span>] 
array([[ <span>1</span>,  <span>4</span>,  <span>7</span>],
       [<span>10</span>, <span>13</span>, <span>16</span>],
       [<span>19</span>, <span>22</span>, <span>25</span>]])
</code></pre>
<p>Beware: Python's list doesn't work with <code>...</code>. </p>
<h2 id="an-elegant-unpacking">An Elegant Unpacking</h2>
<p>Iterable unpacking is a remarkably convenient feature and has been there for a while. Most people use it to unpack iterables with multiple items. As example, consider the following use cases.</p>
<pre><code><span>&gt;&gt;&gt; </span>a, *b, c = range(<span>1</span>, <span>11</span>)
<span>&gt;&gt;&gt; </span>a
<span>1</span>
<span>&gt;&gt;&gt; </span>c
<span>10</span>
<span>&gt;&gt;&gt; </span>b
[<span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]
</code></pre>
<p>Or just:</p>
<pre><code><span>&gt;&gt;&gt; </span>a, b, c = range(<span>3</span>)
<span>&gt;&gt;&gt; </span>a
<span>0</span>
<span>&gt;&gt;&gt; </span>b
<span>1</span>
<span>&gt;&gt;&gt; </span>c
<span>2</span>
</code></pre>
<p>But one nice use case that many people do not take advantage of is unpacking a single iterable. Why this is useful? It makes the code a little bit more elegant, IMHO.</p>
<p>Instead of doing this:</p>
<pre><code><span>&gt;&gt;&gt; </span>lst = [<span>1</span>]
<span>&gt;&gt;&gt; </span>a = lst[<span>0</span>]
<span>&gt;&gt;&gt; </span>a
<span>1</span>
<span>&gt;&gt;&gt; </span>(a, ) = lst
<span>&gt;&gt;&gt; </span>a
<span>1</span>
</code></pre>
<p>You can do this:</p>
<pre><code><span>&gt;&gt;&gt; </span>lst = [<span>1</span>]
<span>&gt;&gt;&gt; </span>[a] = lst
<span>&gt;&gt;&gt; </span>a
<span>1</span>
</code></pre>
<p>I know that it may seem silly, but at least to me, it looks more elegant.</p>
<h2 id="can-you-flat-this-list">Can You Flat This List?</h2>
<p>Flattening a list can be done in several ways. The simplest one is using list comprehension. </p>
<pre><code><span>&gt;&gt;&gt; </span>l = [[<span>1</span>, <span>2</span>, <span>3</span>], [<span>4</span>, <span>5</span>, <span>6</span>], [<span>7</span>, <span>8</span>, <span>9</span>]]
<span>&gt;&gt;&gt; </span>flattened = [elem <span>for</span> sublist <span>in</span> l <span>for</span> elem <span>in</span> sublist]
<span>&gt;&gt;&gt; </span>flattened
[<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]
</code></pre>
<p>If you're more inclined to functional programming, you can use a reducer.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>from</span> functools <span>import</span> reduce
<span>&gt;&gt;&gt; </span>reduce(<span>lambda</span> x,y: x+y,l)
[<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]
</code></pre>
<p>However, there's yet another way. You can use the <code>sum</code> function!</p>
<pre><code><span>&gt;&gt;&gt; </span>sum(l, [])
[<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]
</code></pre>
<p>This works because the <code>sum</code> function iterates through each element in the list and concatenates them with the default value you pass as the second argument. Since lists in Python can be concatenated with <code>+</code> operator, then you get something like this:</p>
<pre><code><span>&gt;&gt;&gt; </span>sum(l, []) ==&gt; [] + [<span>1</span>, <span>2</span>, <span>3</span>] + [<span>4</span>, <span>5</span>, <span>6</span>] + [<span>7</span>, <span>8</span>, <span>9</span>]
[<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>]
</code></pre>
<p>Even though this trick is brilliant, it’s by no means readable. Also, it has a terrible performance.</p>
<blockquote>
<p>Can we do this with string?</p>
</blockquote>
<p>No, Python forbids doing the same with strings, even though you can concatenated strings with <code>+</code> operator.</p>
<pre><code><span>&gt;&gt;&gt; </span>s = [<span>"abc"</span>, <span>"def"</span>, <span>"ghf"</span>]

<span>&gt;&gt;&gt; </span>sum(s, <span>""</span>)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input<span>-3</span>-f60d89b81305&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> sum(s, <span>""</span>)

TypeError: sum() can<span>'t sum strings [use '</span><span>'.join(seq) instead]</span>
</code></pre>
<p>If we dig intro CPython source code, we can find where this happens:</p>
<pre><code><span><span>static</span> PyObject *
<span>builtin_sum_impl</span><span>(PyObject *<span>module</span>, PyObject *iterable, PyObject *start)</span>

</span>{
    PyObject *result = start;
    PyObject *temp, *item, *iter;

    iter = PyObject_GetIter(iterable);
    <span>if</span> (iter == <span>NULL</span>)
        <span>return</span> <span>NULL</span>;

    <span>if</span> (result == <span>NULL</span>) {
        result = PyLong_FromLong(<span>0</span>);
        <span>if</span> (result == <span>NULL</span>) {
            Py_DECREF(iter);
            <span>return</span> <span>NULL</span>;
        }
    } <span>else</span> {
        
        <span>if</span> (PyUnicode_Check(result)) {
            PyErr_SetString(PyExc_TypeError,
                <span>"sum() can't sum strings [use ''.join(seq) instead]"</span>);
            Py_DECREF(iter);
            <span>return</span> <span>NULL</span>;
        }
        <span>if</span> (PyBytes_Check(result)) {
            PyErr_SetString(PyExc_TypeError,
                <span>"sum() can't sum bytes [use b''.join(seq) instead]"</span>);
            Py_DECREF(iter);
            <span>return</span> <span>NULL</span>;
        }
        <span>if</span> (PyByteArray_Check(result)) {
            PyErr_SetString(PyExc_TypeError,
                <span>"sum() can't sum bytearray [use b''.join(seq) instead]"</span>);
            Py_DECREF(iter);
            <span>return</span> <span>NULL</span>;
        }
        Py_INCREF(result);
    }
</code></pre>
<p><a href="https://github.com/python/cpython/blob/c96d00e88ead8f99bb6aa1357928ac4545d9287c/Python/bltinmodule.c#L2310-L2315" target="_blank">github.com/python/cpython/blob/c96d00e88ead..</a></p>
<h2 id="the">The <code>_</code></h2>
<p>This one is really interesting and very handy when working with the REPL. It not only works with the default Python interpreter, but with IPython as well.</p>
<p>Whenever you run an expression in the REPL, Python binds the output to the <code>_</code> variable. </p>
<pre><code><span>&gt;&gt;&gt; </span>nums = [<span>1</span>, <span>3</span>, <span>7</span>]
<span>&gt;&gt;&gt; </span>sum(nums)
<span>11</span>
<span>&gt;&gt;&gt; </span>_
<span>11</span>
&gt;&gt;&gt;
</code></pre>
<p>Since <code>_</code> is a variable like any other, you can re-bind it, or do anything else with it.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>9</span> + _
<span>20</span>
<span>&gt;&gt;&gt; </span>a = _
<span>&gt;&gt;&gt; </span>a
<span>20</span>
</code></pre>
<h2 id="what-else">What <code>else</code>?</h2>
<p>The <code>else</code> statement in can serve several purposes. Few people know, but you can use it outside the classical ‘if else` block. Python allow it to be used on loops and also on exception blocks.</p>
<h3 id="loops">Loops</h3>
<p>Python has two different loops, <code>for</code> and <code>while</code>. Both of them can be "broken". That is, if a certain condition is met, we can break out of the loop. For example:</p>
<pre><code>In [<span>7</span>]: <span>while</span> a &lt; <span>10</span>:
   ...:     <span>if</span> a == <span>3</span>:
   ...:         print(<span>"a == 3. exiting loop."</span>)
   ...:         <span>break</span>
   ...:     a += <span>1</span>
   ...: 
a == <span>3.</span> exiting loop.
</code></pre>
<p>Now, let's say that we are looking for a particular condition. If that condition is satisfied, we save the result in a flag called <code>found</code>. Then, if we don't find it, we print a message.</p>
<pre><code>found = <span>False</span>
a = <span>0</span>

<span>while</span> a &lt; <span>10</span>:
    <span>if</span> a == <span>12</span>:
        found = <span>True</span>
    a += <span>1</span>
<span>if</span> <span>not</span> found:
    print(<span>"a was never found"</span>)
</code></pre>
<p>Since <code>a</code> never becomes 12, the program outputs <code>a was never found</code>.</p>
<blockquote>
<p>Ok, but how can we use <code>else</code> in this context?</p>
</blockquote>
<p>The <code>else</code> can be used to replace the flag. Basically, what we actually want is to run the loop and, if not found, then print a message. This is how it looks like with <code>else</code>:</p>
<pre><code>a = <span>0</span>

<span>while</span> a &lt; <span>10</span>:
    <span>if</span> a == <span>12</span>:
        <span>break</span>
    a += <span>1</span>
<span>else</span>:
    print(<span>"a was never found"</span>)
</code></pre>
<p>And since it works with any loop, you can use a <code>for</code> instead of <code>while</code>.</p>
<pre><code><span>for</span> a <span>in</span> range(<span>10</span>):
    <span>if</span> a == <span>12</span>:
        <span>break</span>
    a += <span>1</span>
<span>else</span>:
    print(<span>"a was never found"</span>)
</code></pre>
<h3 id="exceptions">Exceptions</h3>
<p>The <code>else</code> in Python is so versatile that you can even use it in a <code>try ... except</code> block. The idea here is to capture a nonoccurrence of an exception. </p>
<pre><code>In [<span>13</span>]: <span>try</span>:
    ...:     {}[<span>'lala'</span>]
    ...: <span>except</span> KeyError:
    ...:     print(<span>"Key is missing"</span>)
    ...: <span>else</span>:
    ...:     print(<span>"Else here"</span>)
    ...: 
Key <span>is</span> missing
</code></pre>
<p>In this example, we try looking up a key named “lala” in an empty dictionary. Since “lala” is not there, the code will raise an <code>KeyError</code> exception. When I run this snippet in <code>IPython</code>, I got an expected result.</p>
<p>What about a case where the program raises no exception?</p>
<pre><code>In [<span>14</span>]: <span>try</span>:
    ...:     {<span>'lala'</span>: <span>'bla'</span>}[<span>'lala'</span>]
    ...: <span>except</span> KeyError:
    ...:     print(<span>"Key is missing"</span>)
    ...: <span>else</span>:
    ...:     print(<span>"Else here"</span>)
    ...: 
Else here
</code></pre>
<p>Now we can see it in action. The <code>{’lala’: ‘bla’}[‘lala’]</code> block won’t raise <code>KeyError</code>, so the <code>else</code> comes into play. </p>
<p>Remember, few people know this, so I personally avoid using this feature to not confuse other developers working in the same code base. It’s nice to impress friends, though!</p>
<h2 id="comparing-things-like-a-boss">Comparing Things Like a Boss</h2>
<p>This is one of my favorites and not so hidden, to be honest. Unlike many programming languages, like <code>Java</code>, <code>C</code> or <code>C++</code>, Python allows you to chain comparison operators. Let's imagine that you have a variable <code>x</code> that holds the value of <code>10</code>. Now, let's say that you want to assert that <code>x</code> is within a range, like 5..20, inclusive. You could do something like this:</p>
<pre><code>In [<span>16</span>]: x = <span>10</span>
In [<span>17</span>]: <span>if</span> x &gt;= <span>5</span> <span>and</span> x &lt;= <span>20</span>:
    ...:     print(<span>"x is within range"</span>)
    ...: <span>else</span>:
    ...:     print(<span>"x is outside range"</span>)
    ...: 
<span>is</span> within range
</code></pre>
<p>It turns out, this can be simplified by chaining the operators. So, we can refactor the code to this:</p>
<pre><code>In [<span>18</span>]: <span>if</span> <span>5</span> &lt;= x &lt;= <span>20</span>:
    ...:     print(<span>"is within range"</span>)
    ...: <span>else</span>:
    ...:     print(<span>"x is outside range"</span>)
    ...: 
<span>is</span> within range
</code></pre>
<p>This code achieves the exact same result, but it's much more elegant. You can chain using any kind of comparison operator.</p>
<pre><code><span>&gt;&gt;&gt; </span>x = <span>10</span>
<span>&gt;&gt;&gt; </span><span>20</span> == x &gt; <span>1</span>
<span>False</span>
<span>&gt;&gt;&gt; </span><span>25</span> &gt; x &lt;= <span>15</span>
<span>True</span>
<span>&gt;&gt;&gt; </span>x &lt; <span>20</span> &lt; x*<span>10</span> &lt; <span>1000</span>
<span>True</span>
</code></pre>
<p>Very cool!</p>
<h2 id="conclusion">Conclusion</h2>
<p>That’s the end of this post. Python is a very friendly language and has some nice, but not well-known, features. In this post, I showed you my favorites and I hope you’ve learned something new. See you next time!</p>
<blockquote>
<p>If you liked this post, consider sharing it with your friends! Also, feel free to follow me <a href="https://miguendes.me/" target="_blank">miguendes.me</a>. </p>
</blockquote>
</div></div>]]>
            </description>
            <link>https://miguendes.me/5-hidden-python-features-you-probably-never-heard-of</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816027</guid>
            <pubDate>Sun, 18 Oct 2020 06:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finite of Sense and Infinite of Thought]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24815943">thread link</a>) | @hudon
<br/>
October 17, 2020 | https://pron.github.io/posts/computation-logic-algebra-pt1 | <a href="https://web.archive.org/web/*/https://pron.github.io/posts/computation-logic-algebra-pt1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p><a href="https://pron.github.io/computation-logic-algebra">Table of Contents</a></p>

<div>

  <div>

    <blockquote>
      <p>God invented and gave us sight to the end that we might behold the courses of intelligence in the heaven, and apply them to the courses of our own intelligence which are akin to them, the unperturbed to the perturbed; and that we, learning them and partaking of the natural truth of reason, might imitate the absolutely unerring courses of God and regulate our own vagaries. The same may be affirmed of speech and hearing: they have been given by the gods to the same end and for a like reason. For this is the principal end of speech, whereto it most contributes.</p>

      
    </blockquote>

    <blockquote>
      <p>By <em>ratiocination</em>, I mean <em>computation</em>.</p>

      
    </blockquote>

  </div>

  <h2 id="prologue">Prologue</h2>

  <p>An encouraging development in the education of programmers in recent years has been a renewed interest in the relationship between programming, logic and abstract algebra. Recent enthusiasm over functional programming is no doubt the main motivation behind this happy development.</p>

  <p>However, this interest is at times accompanied by a kind of awed appreciation of this relationship, perhaps among practitioner enthusiasts, who consider it almost miraculous, more than among academics. Some researchers notable for popularizing the interest in this relationship encourage this view with talk of “computational trinitarianism” and statements like, “this is further proof that mathematics is discovered rather than invented,” one <a href="http://archive.is/3wgAM">going so far</a> as to call the relationship “a manifestation of the divine” and to say that “all three have ontological force; they codify what is, not how to describe what is already given to us. In this sense they are foundational; if we suppose that they are merely <em>descriptive</em>, we would be left with the question of where these previously given concepts arise, leading us back again to foundations”. Another has <a href="https://vimeo.com/242784236">said</a>,<sup id="fnref:milewski"><a href="#fn:milewski">1</a></sup> “Have you heard of the Curry-Howard-Lambek isomorphism? … These three different theories … were developed separately — constructive logic, typed lambda calculus, and category theory — and the isomorphism says that these are actually <em>identical</em>. Why do these three completely separate theories have the same structure? Because all three of them are about composability.” While he is not too far off the mark when he later says, “Maybe we are just discovering the way our brains work. … [I]f mathematics is all about composition, then composition is something that our brains came up with in order to deal with complexity,” the truth is far simpler yet more interesting, even if less mysterious.</p>

  <p>Awed wonder is a powerful marketing tool, but it mystifies rather than clarifies, and fosters a kind of magical thinking in a field that strives to be most at odds with it (although, as we’ll see in part 2, it sometimes fails). The goal of mathematics is to simplify, not to wow. This attitude towards that — quite obvious, as we’ll see — relationship also distracts from the actual, less obvious, discoveries made. The existence of this relationship was not among them; it was not the denouement — it was the setup. Confusing the two muddles the very essence of any story.</p>

  <p>I also believe that it is this very attitude that puts the focus on the chosen mathematical abstractions rather than on the things they describe creates an atmosphere where there can only be one True interpretation — even one with three personas. I call this absolutist view that confuses the peculiarities of a method of observation with those of the observed system and so denies alternative interpretations the “Protestant” view, and it is a hindrance to understanding logic, where truth is, almost by definition, always relative to a specific system. As Alonzo Church wrote in the very paper he first introduced the λ-calculus<sup id="fnref:church0"><a href="#fn:church0">2</a></sup>:</p>

  <blockquote>
    <p>We do not attach any character of uniqueness or absolute truth to any particular system of logic. The entities of formal logic are abstractions, invented because of their use in describing and systematizing facts of experience or observation, and their properties, determined in rough outline by this intended use, depend for their exact character on the arbitrary choice of the inventor… [T]here exist, undoubtedly, more than one formal system whose use as a logic is feasible, and of these systems one may be more pleasing or more convenient than another, but it cannot be said that one is right and the other wrong.</p>
  </blockquote>

  <p>The following text will attempt to demistify this relationship between computation, logic and abstract algebra. Category theory is a generalization of the last, but programming languages are sometimes interchangeably assigned to both the second, logic, and the first, computation, thus adding to the confusion. In my view, programming languages (at least when studied in a theoretical context) strictly belong to the second persona of logic, and not at all to the first, computation, other than by virtue of the ordinary relationship between the three; programming languages are no more related to computation than formal logic is. I <a href="https://pron.github.io/posts/what-we-talk-about-when-we-talk-about-computation">have previously written</a> about the distinction between programming and computation and the misunderstanding caused by confusing the two, and I hope that this text will clarify the matter further.</p>

  <p>While I will not opine on whether or not mathematical objects have “an ontological force”, as the Platonic ontology of mathematics is a matter of debate in the philosophy of mathematics — a fascinating field, but not a focus of this discussion — I will show that they are not only very much descriptive, but that <em>what</em> they attempt to describe, and therefore how they arise, has been explicitly stated by the originators of those ideas. There is nothing incidental, miraculous, surprising or “divine” in the relationship between computation, logic and algebra; rather, nothing is more creatively human than the process that led to their correlation, and while some things in mathematics are perhaps discovered, logic and algebra were <em>invented</em>, and rather than carrying an independent “foundational ontological force”, they were devised to <em>describe</em> a physical phenomenon (although I do not claim that the mathematical systems invented may not <em>also</em> correspond to some Truth). In particular, I will show that computation, logic and algebra were studied as a single subject for most of their relevant history, related in the following way: human reason works by computation, logic is a description of the process of reasoning, and algebra is the mathematical modeling of logic. The three began to separate into different disciplines only towards the end of the nineteenth century and the beginning of the twentieth. Logic was separated from algebra by Gottlob Frege, immediately triggering the criticism that the correspondence between the two is an argument for having only one. Frege responded that there would <em>obviously</em> be a correspondence between the two because he had invented one to describe the same thing as the other, but that one can translate between two modes of expression does not mean that one of them is redundant. Computation separated from logic some decades later as a more foundational or primitive concept, while exposing the fact that the basic principles of how logic supposedly described human reason — which Gottfried Leibniz called the “Art of Combination” — hadn’t changed for literally millennia, and while logicians/algebraists declared themselves to be studying the computation in the human mind, they were actually just modeling a very particular, and ancient, <em>view</em> of human reason that they had taken on unquestionable faith. The systems were in such harmonious correspondence not just because they described the same physical phenomenon, but because they all <em>re</em>-described the <em>same ancient description</em> of that phenomenon.</p>

  <p>While researching the topic — not being a logician or a historian, but rather a programmer and an amateur interested in the history of mathematics — I was surprised how explicit this connection was made from the very beginning of the disciplines. Quite the opposite of accidental or miraculous, calling this relationship obvious is an <em>understatement</em>. That there is some relationship between a house cat and a leopard can be said to be obvious; the one between the original Star Wars trilogy and its many prequels and sequels is much more than just obvious. If you think that it is in any way accidental or miraculous, or that it is proof that Darth Vader was discovered rather than invented, you are clearly missing something very important in understanding the meta-theory of stories — meaning, how they come to be. I delight at the opportunity to use the history of science — or of logic and mathematics in this case — to clarify the development of mathematical concepts by tracing their evolution and the creative process of their originators.</p>

  <p>This book-length text — and not a short book — is published as a three-part blog post series, but I personally wrote very little of it. While the text is not different in content or conclusions from books about the history of logic and computation (or the wonderful recent Atlantic article, <a href="https://www.theatlantic.com/technology/archive/2017/03/aristotle-computer/518697/"><em>How Aristotle Created the Computer</em></a>), it is certainly different in style, being comprised mostly of original sources. I chose to compose the text in this way for several reasons, listed here in no particular order: 1. I am not a professional historian and do not have sufficient knowledge to provide insight on historical trends. 2. I find reading (carefully selected) primary sources a lot more fun than sweeping descriptions. 3. As most mathematicians and programmers do not make good historians, a lot of inaccuracies and downright mistakes are perpetrated because few have seen the actual sources. 4. As my goal is to demystify logic and mathematics, I think it is especially enlightening to read how the originators of the ideas describe their process of arriving at their insight. My text is also different in focus; it attempts to emphasize the evolution of the connection …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pron.github.io/posts/computation-logic-algebra-pt1">https://pron.github.io/posts/computation-logic-algebra-pt1</a></em></p>]]>
            </description>
            <link>https://pron.github.io/posts/computation-logic-algebra-pt1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815943</guid>
            <pubDate>Sun, 18 Oct 2020 06:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio’s opportunity and who will capture it]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24815888">thread link</a>) | @hunglee2
<br/>
October 17, 2020 | https://www.matthewball.vc/all/audiotech | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/audiotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5d8e94500fa50d2aaaa7c406" id="sections">
  
    <section data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
  &quot;playbackSpeed&quot;: 0.5,
  &quot;filter&quot;: 1,
  &quot;filterStrength&quot;: 0,
  &quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f88a99f19d4cd6d64631928"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1602791840799_3755"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1602792859307-U0J0NC5X6RECD3KT88YX/ke17ZwdGBToddI8pDm48kM4_kVKk9l_w74w-snZK7Fx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0sfmLVeynSYYXBTMYB-wzcE4Rlu1L95vgCX6mg-kkKYPXXkbScjoF_1N2dt8jg_pvQ/Edison.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1602792859307-U0J0NC5X6RECD3KT88YX/ke17ZwdGBToddI8pDm48kM4_kVKk9l_w74w-snZK7Fx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0sfmLVeynSYYXBTMYB-wzcE4Rlu1L95vgCX6mg-kkKYPXXkbScjoF_1N2dt8jg_pvQ/Edison.png" data-image-dimensions="2500x1456" data-image-focal-point="0.5,0.5" alt="Edison.png" data-load="false" data-image-id="5f88ad99ea51f67834f2495a" data-type="image" src="https://www.matthewball.vc/all/Edison.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-ff1f1677bf36496f03d8"><div><p>As most of the major media categories — music, video and video games — have existed for decades, we tend to forget that media is technology. Instead, we think of technology as being used to express media, rather than media itself. Spotify, for example, is an <em>internet</em> <em>streaming </em>music service, while iTunes is a <em>download </em>music service, SiriusXM is <em>satellite</em> <em>broadcast</em> music service, and radio is a <em>terrestrial broadcast</em> technology. This focus on delivery ignores the classic definition of media: “<span>outlets</span> or <span>tools</span> used to <span>store</span> and <span>deliver</span> information or data.”</p><p>While the above might seem preoccupied with theory and philosophy, all analysis of the past and future of a given media category must start from the fact that media is technology. This is because technology not only enables content categories, it defines their business models and shapes the content, too. And as we know, technology is in a constant process of change. </p><p><strong>Chapter 1: How Technology Created Recorded Media, Then Continually Redefined It</strong></p><p>Music offers a great view into the interplay between technology, business model and content. Consider the following triptych, which covers seven decades, two decades and one year, respectively.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602797899091_5458"><div><p>&nbsp;When the flat record first emerged in the 1850s, it standardized around the 78. The 78 (as in 78 rotations per minute) came in a 10-inch version that held three minutes of music and a 12-inch version that held four. This meant that after centuries of variability, music suddenly had a defined run-time.&nbsp;</p><p>This length was reaffirmed by the first mass market standard for consumer media: the 45 RPM vinyl single, which launched in 1948 and held roughly three minutes. The music industry coalesced around this format (and its runtime) for a variety of tech-based reasons. The 45 was far cheaper for consumers than a 78 album, which was important given the high cost of record players and the ubiquity of free (singles-focused) radio. The 45’s cost advantage also meant it was the primary way labels delivered singles to thousands of radio stations across the country for local airplay. In addition, RCA quickly figured out how to make a stackable version of 45s, which was important to jukebox manufacturers. The rise of the 45 naturally led the length of the average song to decline; a four-minute song simply couldn’t fit on the most important audio format in the world.</p><p>As the physical and financial limitations of the 78 and 45 were relieved, and the far more flexible cassette and CD emerged, the length of the average single grew rapidly, adding nearly two minutes (or 78%) from 1959 to 1992. Still, almost all tracks conformed to the three-to-four minute standard. After decades, the West had become used to the idea that a song was roughly between three minutes and 20 seconds and four minutes and 10 seconds long.</p><p>On its surface, the shift to digital audio should have led to further increases in song length. After all, there was no longer any limitation to run-time. However, the reverse occurred. Technology might have relaxed its grip on music’s length, but it had strengthened its hold on business models.</p><p>As is well known, iTunes unbundled the physical album in individually downloadable (and bought) tracks. But in doing so, it penalized artists for bundling a multi-part song into a single track. Pink Floyd’s decision to split the 26-minute and nine-part Shine on You Crazy Diamond into two discrete tracks didn’t matter in 1975; all nine parts fit on a single record and no one wanted to buy just a single half let alone a single part. But in 2005, such a move could mean missing out on 75% of revenues — why sell two things when you could sell nine? And why would a consumer buy an entire $10 album if all they wanted was two $1 portions of Shine on You Crazy Diamond? These incentives naturally led to artists that were publishing new music to split their longer/multi-section songs into separate — and shorter — preludes, interludes and segments.</p><p>This behaviour has been greatly exacerbated by the advent of a new and even more disruptive digital music technology: on-demand streaming. While iTunes was technically innovative, its business model was not. Consumers, after all, primarily owned copies of individual tracks in the 1950s and 1960s. Spotify and Apple Music, meanwhile, meant consumers adopted not just a new music technology, but also bought an entirely different product: ongoing access to all music ever created.</p><p>But as technology has shifted consumers away from discrete and attributable transactions (buying record A on date B) to ongoing and general ones (subscribing to service C in perpetuity), musical talent needed a new compensation model. Spotify, therefore, decided to pay talent as and to the degree consumers listened to their works. Matching revenue with usage is intuitive, but it was never before possible in music. There was no way to track at-home record spins or CD plays, let alone charge for them. Nor was it practical for iTunes to ask users to download an individual song to their devices and pay several pennies per play when they later synched their iPod to iTunes. (This would have been rife with abuse, too.)</p><p>Engagement-based monetization is arguably more fair. Consider, for example, that the Beatles’ <em>Yesterday </em>and Psy’s <em>Gangnam Style</em> would each generate $1 when sold on iTunes, even if the former was played 2,000 times over ten years and the latter 30 times in the month it was bought and then never again. But the more that business models change, the more that incentives and content change, too.</p><p>To support engagement-based monetization, Spotify and its label suppliers had to define engagement. And they chose to do this on a per stream basis with a minimum stream time of 30 seconds (to avoid accidental plays, track skipping, etc.). However, this meant that a 10-minute track, five-minute track and 31-second track generated the same royalties.&nbsp;</p><p>So as the music industry has transitioned the majority of its revenues from CDs and downloads to streaming, major artists have relentlessly shortened and split their tracks. Why release a five-minute song if you can make it a two and a half-minute song that’s played twice? Or two different two and a half-minute songs? This meant artists had yet another reason to reduce track lengths</p><p>All of this helps to explain the extraordinary success of the 2019’s top track, <em>Old Town Road </em>by Lil Nas X, which is also Billboard’s longest running #1 ever, at 19 consecutive weeks. While the song is awesome, it’s also only one minute and 53 seconds — roughly half of 2019’s average song length. This means that four minutes of listening generated two times the average revenue and charting lift of every other hit song that year.</p><p><em>Old Town Road </em>isn’t an exception, either. Up until 2017, Billboard’s Hot 100 Chart has never had a year with more than 2% of its charting tracks shorter than two minutes and 30 seconds (most years had none). In the past three years, this sum has skyrocketed to over 12%, or roughly one in every eight tracks.</p><p>Notably, labels are also encouraging artists to simplify the name of their songs and albums in order to ensure they’re optimized for voice-controlled speakers and touchscreen-based searches. A track with five words is more likely to be misunderstood or suffer from autocorrect than one with two. Similarly, voice assistants are known to struggle with <a href="https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/">accents</a>, such as Irish or even Texan. Being hard to say means you might not get played.</p><p><em>Old Town Road </em>isn’t the first time technology made a hit. In fact, the modern day dominance of rap and R&amp;B comes from how changes in technology – not for delivery, but sales recognition –&nbsp; afforded Lil Nas X the opportunity to top the charts in the first place.</p><p>Prior to the 1990s, Black artists and music fans had spent decades arguing the record industry conspired against “urban contemporary” music by refusing it radio play and ignoring its sales. It took only five weeks after Billboard adopted SoundScan, a computerized sales database, to prove this theory right.</p><p>Until 1991, Billboard charts weren’t based on actual unit sales or radio play. Instead, it was assembled using (white) retail clerk estimates of what was selling best and what (white) DJs considered to be “<a href="https://www.washingtonpost.com/archive/lifestyle/1991/06/19/charting-soundscans-shake-up/3b8187fb-2332-4096-95e9-1f8db7b66b2e/">hottest</a>” each week. According to <em>The Atlantic</em>, both groups had<a href="https://www.washingtonpost.com/archive/lifestyle/1991/06/19/charting-soundscans-shake-up/3b8187fb-2332-4096-95e9-1f8db7b66b2e/"> reasons to lie</a>. For example, labels would pressure radio stations to favour “hand-picked hits” if they wanted to keep receiving the newest single on time (stations sometimes<a href="https://en.wikipedia.org/wiki/Payola"> received bribes to play specific tracks</a>, too). Meanwhile, labels would force inventory on their retailers, who would then overreport sales to convince music fans to buy excess inventory.</p><p>Naturally, those who ran the music industry saw little need to overhaul how it worked. And thus while the book and film industries had shifted to computerized sales databases in the 1980s, not one of the top six record distributors signed onto SoundScan before its release in June 1991. But this resistance didn’t stop N.W.A.’s <em>N***az4life</em> from debuting #2 on the Billboard Top 100 the very next month under SoundScan. This was the highest charting performance in rap history – and happened without any radio airplay, music video airings on MTV, or a concert tour. The failings of the old honour system were further demonstrated by the fact that N.W.A. debuted at only #21 on Billboard’s R&amp;B chart, which wasn’t yet on SoundScan. Somehow it was possible that <em>N***az4life</em> was the second biggest album in the country by units purchased, but 21st in its own genre when it came to what was “selling” and “hottest.” One week after it’s release, the album hit #1 on the Billboard chart (displacing R.E.M) as hundreds …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/audiotech">https://www.matthewball.vc/all/audiotech</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/audiotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815888</guid>
            <pubDate>Sun, 18 Oct 2020 06:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with Combinators]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24815859">thread link</a>) | @headalgorithm
<br/>
October 17, 2020 | https://doisinkidney.com/posts/2020-10-17-ski.html | <a href="https://web.archive.org/web/*/https://doisinkidney.com/posts/2020-10-17-ski.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <h2>Fun with Combinators</h2>

            <p>
    Posted on October 17, 2020
</p>





<p>There are a bunch of “minimal” computational models out there: Turing machines, lambda calculus, PowerPoint <span data-cites="wildenhainTuringCompletenessMS2017">(Wildenhain <a href="#ref-wildenhainTuringCompletenessMS2017" role="doc-biblioref">2017</a>)</span>, etc. These are radically simple languages which are nonetheless Turing complete, so theoretically “as powerful” as each other. Of those, lambda calculus is without question my favourite to actually write programs in: it’s the one which is closest to crawling out of the <a href="https://en.wikipedia.org/wiki/Turing_tarpit">Turing tarpit</a>.</p>
<p>In terms of implementation, though, it is <em>far</em> from simple. Lambda calculus has <em>variables</em>, which introduce huge complexity into the interpreter: especially if you want to do any kind of formal reasoning about programs, this complexity is a problem. We might want to reach for something even lower-level than lambda calculus: this is where combinator calculi come in.</p>
<p>You may have heard of SKI combinator calculus: it’s the “simplest” of the calculi, but it’s not actually very easy to understand, and it’s absolute murder to try use. So we’re going to start with <code>BCKW</code>, a more obscure calculus, actually invented by Haskell Curry.</p>
<p>There are 4 combinators in <code>BCKW</code>: <code>B</code>, <code>C</code>, <code>K</code>, and <code>W</code> (shocking, I know). You can think about these combinators as functions which manipulate the beginning of strings:</p>
<pre><code>Bxyz ~&gt; x(yz)
Cxyz ~&gt; xzy
Kxy  ~&gt; x
Wxy  ~&gt; xyy</code></pre>
<p>Let’s work with some examples to get a sense for how these combinators work.</p>
<p>Upper case letters are combinators, lower-case are variables. Yes, yes, I know I said that combinator calculi didn’t need variables, and it doesn’t! I’m just using them here to explain how each of the combinators work. If you really want to be pedantic you can think of the lower case letters as notational placeholders meaning “any given combinator”. They won’t exist in any actual programs we write.</p>
<p>The simplest combinator is <code>K</code>: it’s actually equivalent to the <code>const</code> function from Haskell. It discards its second argument, and returns the first. If you give a combinator more arguments than it usually accepts, you just keep the extra arguments in the output:</p>
<pre><code>Kxyz ~&gt; xz</code></pre>
<p><code>W</code> is the next combinator: it <em>duplicates</em> its second argument.</p>
<pre><code>Wxy ~&gt; xyy</code></pre>
<p>We always start from the <em>left</em>, applying the rule for the left-most combinator first.</p>
<pre><code>WKxyz ~&gt; Kxxyz ~&gt; xyz
KWxyz ~&gt; Wyz   ~&gt; yzz</code></pre>
<p>Next we have <code>C</code>: this is equivalent to the Haskell function <code>flip</code>. It swaps the second and third arguments:</p>
<pre><code>Cxyz ~&gt; xzy</code></pre>
<p>Here’s a small little evaluator for expressions which use <code>C</code>, <code>K</code>, and <code>W</code>. You can edit the expression, and press enter to step through it.</p>



<p>The last combinator introduces parentheses, and it’s equivalent to function composition.</p>
<pre><code>Bxyz ~&gt; x(yz)</code></pre>
<p>You can write parentheses yourself: implicitly, all expressions are left-associative. That means that the following are all equal:</p>
<pre><code>xyz = (xy)z = (x)yz = ((x)y)z</code></pre>
<p>But <code>xyz</code> is <em>not</em> equal to, say, <code>x(yz)</code>.</p>
<p>And here’s a puzzle to start flexing your combinator skills: one of the combinators in SKI combinator calculus is <code>I</code>, which is the identity function.</p>
<pre><code>Ix ~&gt; x</code></pre>
<p>Try write an expression which functions the same way as <code>I</code>, using only the <code>BCKW</code> combinators. Use the following evaluator to try and figure out how to do it: write an expression after <code>λ&gt;</code> which functions the same as <code>I</code>.</p>



<details>
<summary>Answer</summary> <code>CK</code> followed by any combinator will do the trick. So <code>CKB</code>, <code>CKK</code>, <code>CKC</code>, etc.
<pre><code>I = CKC</code></pre>
Update 19/10/2020: A few people have pointed out (<a href="https://www.joachim-breitner.de/">Joachim Breitner</a> was the first) that there is a shorter solution to this problem: <code>WK</code>. I tend to prefer solutions that don’t include <code>W</code>, since then we’re working in a subset of the language that is both terminating and affine; although in this case the reason I didn’t mention <code>WK</code> is that I just didn’t find it myself.
</details>

<p>Each of the combinators we’ve defined so far work a little weird: they seem to skip over their first argument, and work on their second. Indeed, there is another, equivalent combinator calculus which doesn’t have this peculiarity:</p>
<pre><code>Bxyz ~&gt; x(yz)
Axy  ~&gt; y
Mx   ~&gt; xx
Txy  ~&gt; yx</code></pre>
<p><code>B</code> stays the same in this calculus, but the rest of the combinators get switched out for seemingly simpler versions. <code>K</code> goes to <code>A</code><a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<pre><code>Axy ~&gt; y
Kxy ~&gt; x</code></pre>
<p>Which isn’t a huge change. It’s the other two where we see the real difference. <code>W</code> has been swapped out for <code>M</code>:</p>
<pre><code>Wxy ~&gt; xyy
Mx  ~&gt; xx</code></pre>
<p>As you can see <code>W</code> basically does the same thing as <code>M</code>, but while passing through its first argument. The difference between <code>T</code> and <code>C</code> is similar:</p>
<pre><code>Cxyz ~&gt; xzy
Txy  ~&gt; yx</code></pre>
<p>So, first of all, it is pretty simple to show that <code>BCKW</code> contains all of the <code>BAMT</code> combinators. Try find a way to write <code>T</code> using only <code>BCKW</code> combinators (hint: you might want to use your previous answer for writing <code>I</code> using <code>BCKW</code>).</p>



<details>
<summary>Answer</summary> So in fact all of the changed <code>BAMT</code> combinators can be encoded using <code>BCKW</code> by putting <code>I</code> (or <code>CKC</code> or what have you) after the corresponding <code>BCKW</code> combinator. In other words:
<pre><code>T = CI = C(CKC)
A = KI = K(CKC)
M = WI = W(CKC)</code></pre>
</details>
<p>It’s pretty easy to go from <code>BCKW</code> to <code>BAMT</code>, then. However, it’s <em>extremely</em> difficult to go the other way. Here, try to write <code>K</code> in terms of <code>BAMT</code> (this is quite difficult, do not expect to get it!):</p>



<details>
<summary>Answer</summary> Either of the following would work:
<pre><code>B(TA)(BBT)
B(B(TA)B)T</code></pre>
</details>
<p>So this is why we will stick to <code>BCKW</code> for the time being: <code>BAMT</code> is just too painful to use.</p>

<p>One of the things <code>BCKW</code> has over <code>SKI</code> is that each combinator represents a concrete capability. <code>K</code> and <code>W</code> especially: without these combinators, we can neither duplicate nor discard variables. This makes the languages without one or both of these interesting (albeit not Turing-complete).</p>
<p>If we say that we can’t use <code>W</code>, we know that the will not duplicate any input. In fact, encoded appropriately, we know that the program can only decrease its size through execution. The <code>BCK</code> system is in fact an encoding of <em>affine</em> logic, which is all the rage nowadays. Rust uses affine types to guarantee memory safety: by preventing duplication of references, you can know that whenever you’re looking at a variable you’re free to modify it, or destroy it if necessary (obviously Rust is a bit more complex than what I’ve described here, but <code>BCK</code> is indeed the fundamental basis for the system in the same way that <code>SK</code> can be the basis for any programming language).</p>
<p>If we remove <code>K</code> as well we have a <em>linear</em> language. This is even more restrictive, but is also quite actively researched at the moment: linear types have been used to construct languages for differential privacy, for instance.</p>
<p>There’s one small issue with <code>BC</code>: it doesn’t (strictly speaking) have an equivalent to <code>I</code>. You can write an expression which is <em>close</em>, but it will only actually compute when applied to at least 3 arguments. See if you can find it.</p>



<details>
<summary>Answer</summary>
<pre><code>BCC</code></pre>
</details>
<p>Usually we add <code>I</code>, though, to give us <code>BCI</code>.</p>

<p><code>S</code> is the only combinator we haven’t seen yet. It’s kind of a combination of <code>B</code>, <code>C</code>, and <code>W</code>:</p>
<pre><code>Sxyz ~&gt; xz(yz)</code></pre>
<p>It does parenthesising, reordering, <em>and</em> duplication. This allows it to be powerful to be Turing complete only with the addition of <code>K</code>. Try first to construct <code>I</code> given only <code>S</code> and <code>K</code>:</p>



<details>
<summary>Answer</summary> <code>SK</code> followed by any combinator will suffice.
<pre><code>I = SKK = SKS</code></pre>
</details>
<p>And now construct <code>S</code> from <code>BCKW</code>:</p>



<details>
<summary>Answer</summary>
<pre><code>S = B(BW)(BBC) = B(B(BW)C)(BB)</code></pre>
</details>
<p>Of course, to show that <code>SK</code> is universal we’d need to show that it contains one of the other universal systems. We won’t do that exhaustively here, but first just try to figure out <code>B</code> and <code>W</code>:</p>



<details>
<summary>Answer</summary>
<pre><code>B = S(KS)K</code></pre>
</details>



<details>
<summary>Answer</summary>
<pre><code>S = SS(SK) = SS(KI)</code></pre>
</details>

<p>The next task is to encode the <code>Y</code> combinator. This is a combinator that evaluates to the following:</p>
<pre><code>Yf ~&gt; f(Yf)</code></pre>
<p>As you can see, it encodes <em>recursion</em>. Like the <code>fix</code> function in Haskell, this combinator allows us to do recursion without explicit self-reference. And, of course, we can define this combinator using the combinators we’ve seen before, since our language is Turing complete. One encoding is <code>BM(CBM)</code>:</p>



<p>As you can see, <code>BM(CBM)</code>, when applied to <code>f</code>, yields <code>f(M(CBMf))</code>, which is equivalent to <code>f(BM(CBM)f)</code> (the <code>B</code> just hasn’t been applied inside the <code>f</code>). So this is indeed a proper recursion combinator.</p>

<p>Let’s try doing a little bit of programming with these combinators now.</p>
<p>In the lambada calculus, to encode numbers we often use the <em>church</em> numerals: that’s what we’re going to do here, too. A church numeral representing some number <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> is a function which takes two arguments, and applies the first argument to the second <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> times. Here are some church numerals in Haskell:</p>
<pre><code>zero :: (a -&gt; a) -&gt; a -&gt; a
zero f x = x

one :: (a -&gt; a) -&gt; a -&gt; a
one f x = f x

two :: (a -&gt; a) -&gt; a -&gt; a
two f x = f (f x)

three :: (a -&gt; a) -&gt; a -&gt; a
three f x = f (f (f x))</code></pre>
<p>Encoding these numerals in combinators is a little more difficult. Zero and one are obvious: they are <code>A</code> and <code>I</code>, respectively. Try to figure out two and three:</p>



<details>
<summary>Answer</summary><code>WB</code>
</details>



<details>
<summary>Answer</summary><code>SB(WB)</code>
</details>
<p>It turns out that it’s pretty easy to encode numbers in a relatively small amount of space, using a binary encoding. First, multiplication on Church numerals is simply composition: so that’s <code>B</code> on our combinators. We already have 2 defined, so the next thing we need for a binary encoding is a successor function. And we know what <em>that</em> is, from the answer to 3!</p>
<p>This means we can encode normal number in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mo>log</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(\log n)</annotation></semantics></math> space (although it still takes linear time to evaluate). The following repl allows for numbers:</p>


<p>We could take up even less space if we allowed for non-normal forms. 4, for instance, could be encoded like so:</p>
<pre><code>M(WB)</code></pre>
<p>But we generally prefer to keep our encodings in normal form: otherwise there’s some extra evaluation we have to pay for when we go to use them.</p>

<p>Once upon a time SKI combinators were used as a target for functional compilers: Miranda, Haskell’s precursor, compiled down to a set of combinators which included <code>SKI</code>. Nowadays, Haskell is compiled to the “spineless tagless G-machine”: its compilation technique took over from combinators in the late 80s, and has been the dominant form since. Apparently the reason is that, on the current architecture of most computers, combinator-based compilation targets just aren’t fast enough. They generate too much garbage: as a result, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doisinkidney.com/posts/2020-10-17-ski.html">https://doisinkidney.com/posts/2020-10-17-ski.html</a></em></p>]]>
            </description>
            <link>https://doisinkidney.com/posts/2020-10-17-ski.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815859</guid>
            <pubDate>Sun, 18 Oct 2020 06:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Samsung phones force Mainland China DNS service upon Hong Kong users(Part 2)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24815765">thread link</a>) | @3np
<br/>
October 17, 2020 | http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/ | <a href="https://web.archive.org/web/*/http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1397">

	
<!-- .entry-header -->

	<div>

		<div>

			<p>Following <a href="http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">Part 1</a> on forcing Mainland China DNS service upon Hong Kong WiFi users, this part analyzes how the periodic DNS queries on <code>qq.com</code>, as seen by users capturing the DNS queries, are generated from the recent Samsung phones firmware (as at Sept 2020) when WiFi is used.</p>

<blockquote><p>tl;dr: These queries are sent simultaneously to all DNS servers registered for the WiFi connection, including <code>114.114.114.114</code> when it is added under circumstances as examined in <a href="http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">Part 1</a>. They are generated every 20 to 60 seconds (depending on settings and link conditions) when the following pre-conditions are satisfied, i.e. WiFi is connected (except with some known devices) with <code>mCurrentMode</code> not equals 0 (elaborated at the bottom of this article), and when screen is on.&nbsp; The queries are sent directly using the WiFi connection link, without going through the VPN / private DNS configured, presumably as they are intended for testing the WiFi network.&nbsp; The IP addresses returned by the queries are not further used, except for checking if they are in a private IP range (in which case the checking is deemed failed).</p></blockquote>
<p>The following is a technical (read: very boring) account of the findings. Jump to the end for hints to disable the DNS query for your home WiFi.</p>
<p>For better illustration of the source, a new Github repository showing the decompiled version of the same <code>wifi-service.jar</code> as in Part I has been created. It uses a different mode of the decompiler (JADX) to attempt to decompile more code to Java, even when there are issues in correctness. The repository is at <a href="https://github.com/headuck/SM-N9750-TGY-1">SM-N9750-TGY-1</a>.</p>
<h3>The main players</h3>
<p>The main controlling class for the logic is again under <code>com.android.server.wifi.WifiConnectivityMonitor</code>, in the file <a href="https://github.com/headuck/SM-N9750-TGY-1/blob/main/com/android/server/wifi/WifiConnectivityMonitor.java">WifiConnectivityMonitor.java</a>.</p>
<p>As briefly mentioned in the last part, this class implements a state machine which represents the status of the WiFi connection being monitored. The states accept messages and respond to them by taking actions and / or transition into another state.</p>
<p>Separately, a subclass, <code>NetworkStatsAnalyzer</code>, is responsible for the monitoring of the connectivity and signal strength. The analyzer is an Android <code>Handler</code> which consumes messages in an event loop. These messages can be sent by the parent state machine, from within the analyzer itself, or from other subclasses, to control the activities of the analyzer.</p>
<p>The most relevant messages in our context are defined as follows (unless otherwise specified, the line numbers are those of the <a href="https://github.com/headuck/SM-N9750-TGY-1/blob/main/com/android/server/wifi/WifiConnectivityMonitor.java">WifiConnectivityMonitor.java</a> file in the decompiled code):</p>
<p>Messages sent to the Analyzer to control the lifecycle of the checking loop (lines 115-117, 254):</p>
<pre>    private static final int ACTIVITY_CHECK_POLL = 135221;
    private static final int ACTIVITY_CHECK_START = 135219;
    private static final int ACTIVITY_CHECK_STOP = 135220;
     ...
    private static final int NETWORK_STAT_CHECK_DNS = 135223;
</pre>
<p>Messages representing external events sent to the <code>WifiConnectivityMonitor</code> state machine (lines 205-206).</p>
<pre>    private static final int EVENT_SCREEN_OFF = 135177;
    private static final int EVENT_SCREEN_ON = 135176;
</pre>
<h3>Let the query loop start</h3>
<p>When the phone screen is turned on, Android will send the <code>android.intent.action.SCREEN_ON</code> intent to the network receiver of this class (line 1149), which will in turn send <code>EVENT_SCREEN_ON</code> to the <code>WifiConnectivityMonitor</code> state machine. If the state is under <code>EvaluatedState</code> [Note 1], the <code>processMessage()</code> method, around line 2138, handles the message (for brevity, some reference to <code>WifiConnectivityMonitor</code> in the code is omitted):</p>
<pre>    
case EVENT_SCREEN_ON:  //135176 
...
if (mCurrentMode != 0) {
    sendMessage(obtainMessage(135188 /* CMD_RSSI_FETCH */, mRssiFetchToken, 0) ;
    if (isValidState() &amp;&amp; getCurrentState() != mLevel2State) {
        if (mNetworkStatsAnalyzer != null) {
            mNetworkStatsAnalyzer.sendEmptyMessage(ACTIVITY_CHECK_START); // 135219
        }
        startEleCheck();
    }
    if (mCurrentMode == 1 || mLinkDetectMode == 1) {
        sendMessage(obtainMessage(CMD_TRAFFIC_POLL/*135193*/, mTrafficPollToken, 0);
    }
}
...
</pre>
<p>This means that, when <code>mCurrentMode</code> is non-zero, WiFi is connected, and the connection is not with some known devices, it will send the <code>ACTIVITY_CHECK_START</code> message to the <code>NetworkStatsAnalyzer</code>. (It will also perform other actions, like calling <code>startEleCheck()</code> to discover devices, but these are not relevant to our context.)</p>
<p>The message <code>ACTIVITY_CHECK_START</code> is also sent to the <code>NetworkStatsAnalyzer</code> from a few other places. Here is an extract of the <code>enter()</code> method of the <code>Valid</code> state, triggered when <code>WifiConnectivityMonitor</code> enters <code>Valid</code> state (i.e. upon WiFi connection) (line 3077-).</p>
<pre>if (mCurrentMode != 0) {
    ...
    mNetworkStatsAnalyzer.sendEmptyMessage(ACTIVITY_CHECK_START);
    mNetworkStatsAnalyzer.sendEmptyMessage(NETWORK_STAT_CHECK_DNS);
}</pre>
<p><code>ACTIVITY_CHECK_START</code> is also sent when <code>mCurrentMode</code> switches from 0 to other values under <code>Valid</code> state (line 3112).&nbsp; Together, it is ensured that all paths arriving at the status, i.e. Wifi is connected, screen is on, and <code>mCurrentMode</code> is non-zero, will trigger <code>ACTIVITY_CHECK_START</code>.</p>
<p>Note that upon entering the <code>Valid</code> state, <code>NETWORK_STAT_CHECK_DNS</code> is also sent to the <code>NetworkStatsAnalyzer</code>. Let’s look at what this message does first.</p>
<h3>The NetworkStatsAnalyzer</h3>
<h4>The “loop” structure</h4>
<p>The below shows a skeleton of the <code>NetworkStatsAnalyzer</code> handler loop handling the above messages, with bodies of <code>ACTIVITY_CHECK_POLL</code> and <code>ACTIVITY_CHECK_STOP</code> omitted for the moment. (lines 4157-, 4477-, 5107-)</p>
<pre>private class NetworkStatsAnalyzer extends Handler
{
    ...
    private boolean mDnsInterrupted = false;
    private boolean mDnsQueried = false;
    private long mLastDnsCheckTime = 0;
    private boolean mPollingStarted = false;
    private boolean mPublicDnsCheckProcess = false;
    private boolean mSkipRemainingDnsResults = false;
    
    ...
    public void handleMessage(Message string) {
        long now = SystemClock.elapsedRealtime();
        final long elapsedRealtime = SystemClock.elapsedRealtime();
        final WifiInfo wifiInfo = WifiConnectivityMonitor.this.syncGetCurrentWifiInfo();
        final int what = string.what;
        switch (what) {
        ...
            case ACTIVITY_CHECK_START:
                if (this.mPollingStarted) break;
                if (WifiConnectivityMonitor.this.isMobileHotspot()) break;
                if (this.isBackhaulDetectionEnabled()) {
                    this.sendEmptyMessage(TCP_BACKHAUL_DETECTION_START); // 135226
                }
                this.sendEmptyMessage(ACTIVITY_CHECK_POLL);
                WifiConnectivityMonitor.this.initNetworkStatHistory();
                this.mLastRssi = wifiInfo.getRssi();
                this.mPollingStarted = true;
                break;
            case ACTIVITY_CHECK_POLL:
                ...
                break;
            case ACTIVITY_CHECK_STOP:
                ...
                break;
            case NETWORK_STAT_CHECK_DNS:
                if (!WifiConnectivityMonitor.this.isMobileHotspot()) {
                    checkPublicDns();
                }
                break;
        }
    }
}
</pre>
<p>The message <code>NETWORK_STAT_CHECK_DNS</code>, sent upon WiFi connection, will invoke the method <code>checkPublicDns()</code> if the WiFi is not a mobile hotspot. The method is as follows (line 4262-).</p>
<pre>public void checkPublicDns() {
    if (WifiConnectivityMonitor.this.inChinaNetwork()) {
        mPublicDnsCheckProcess = false;
        return;
    }
    mPublicDnsCheckProcess = true;
    mNsaQcStep = 1;
    WifiConnectivityMonitor wifiConnectivityMonitor = WifiConnectivityMonitor.this;
    String str = wifiConnectivityMonitor.mParam.DEFAULT_URL_STRING;
    DnsThread mDnsThread = new DnsThread(true, str, this, 10000);
    mDnsThread.start();
    WifiConnectivityMonitor.this.mDnsThreadID = mDnsThread.getId();
    if (WifiConnectivityMonitor.DBG) {
        Log.d(TAG, "wait publicDnsThread results [" + WifiConnectivityMonitor.this.mDnsThreadID + "]");
    }
}</pre>
<p>We see the problematic <code>inChinaNetwork()</code> method as discussed in Part I being used. It can be seen that the above code handles the “normal” case outside China. Upon WiFi connection, it will start an asynchronous DNS query in a separate thread called <code>DnsThread</code>, using the address in the constant <code>DEFAULT_URL_STRING</code> (hardcoded to “www.google.com” as shown in Part I). This is done once at the start of every WiFi connection. However, if <code>inChinaNetwork()</code> returns true, e.g. in the case of a phone in Hong Kong, it would just set the flag <code>mPublicDnsCheckProcess</code> to false and return, skipping the DNS query for google.</p>
<p>Then we look at <code>ACTIVITY_CHECK_START</code>. On receipt of <code>ACTIVITY_CHECK_START</code>, the <code>NetworkStatsAnalyzer</code>, among other actions, sends the <code>ACTIVITY_CHECK_POLL</code> message to itself, and sets the flag <code>mPollingStarted</code> to true. This would kick start the checking loop, as to be explained below. Before taking these actions, it would ensure that the loop is not already started by checking <code>mPollingStarted</code>, and that the WiFi connection is not acting as a hotspot.</p>
<p>The main flow controlling logic of the body of <code>ACTIVITY_CHECK_POLL</code> polling loop is as follows (line 4509-).</p>
<pre>case ACTIVITY_CHECK_POLL:
if (WifiConnectivityMonitor.this.SMARTCM_DBG) {
    Log.i(TAG, "mPollingStarted : " + mPollingStarted);    
}
if (!mPollingStarted) {
    break;
}
if ((WifiConnectivityMonitor.this.mCurrentBssid != null) &amp;&amp;
    (WifiConnectivityMonitor.this.mCurrentBssid != WifiConnectivityMonitor.this.mEmptyBssid)) {
    WifiConnectivityMonitor.this.mIWCChannel.sendMessage(CMD_IWC_ACTIVITY_CHECK_POLL); // 135376
    int rssi2 = wifiInfo.getRssi();
    if (rssi2 &lt; -90) {
        if (!WifiConnectivityMonitor.this.mClientModeImpl.isConnected()) {
            Log.i(TAG, "already disconnected : " + rssi2);
            removeMessages(ACTIVITY_CHECK_POLL);
            sendEmptyMessage(ACTIVITY_CHECK_STOP);
            break;
        }
        if (rssi2 &lt; -95) {
            if (rssi2 == -127) break;
           …</pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/">http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/</a></em></p>]]>
            </description>
            <link>http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815765</guid>
            <pubDate>Sun, 18 Oct 2020 05:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Set data structure saved me from a world of pain]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24815618">thread link</a>) | @root993
<br/>
October 17, 2020 | https://www.sankalpjonna.com/posts/the-set-data-structure-saved-me-from-a-world-of-pain | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/the-set-data-structure-saved-me-from-a-world-of-pain">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When we were taught the Set theory at school, I wondered why they dedicated an entire chapter in math to teach us about how to group items into categories. Isn’t it obvious that entities that have similar properties get clubbed together?<br></p><p>More than a decade later I realised that when they teach you something, maybe the entire topic is not as important as that one small nugget of information about this topic that might come in handy down the line.<br></p><p>For me, this nugget of information about Set theory was this.<br></p><figure id="w-node-9bd5380d78e6-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f89ba9979e92b0e781ddd42_LfDXNcBl9XXlc_zSVncWIpmdoJD04pJhaLJimLGvE8O2j9cX6z2wpEYXfmE6XX3JwYbQ0JvFSOU7DOdSMxjhcI219Ksul3dSqhNYRhNfXipgHZAtf_IIXj6HMelTmUbhVbCIiu-7.png" alt=""></p><figcaption>Most important aspect of a Set.</figcaption></figure><p>‍</p><p>Why did this seemingly insignificant fact become the key to my mental sanity? And more importantly how did it help me prevent my codebase from turning into spaghetti? <strong>‍</strong></p><h3><strong>The problem</strong><br></h3><p>I am building a <a href="https://www.delightchat.io/" target="_blank">customer support tool</a> where the CS agent can solve customer queries raised from multiple channels of communication. <br></p><p>So by its very design we required a UI element which indicated how many conversations are left unattended for each of the channels.<br></p><figure id="w-node-27c4f9faeadc-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f89bae0425ec7344afac63a_YAjgaMGj963ZtjICveHP_c9Sgiyzrw1YyiN09vNE9ArwLj-jZRSRIIhjSkcS-3dXlERcyErMht4mKnJ-fbxuH1llqLC2NIn31zCsD0Nzheu4RWJ4sOIEykUZjjzQXEVj9_VvsQIL.png" alt=""></p><figcaption>Open conversations in every support channel</figcaption></figure><p>‍<br></p><p>As you may have guessed, this information is being retrieved on every refresh of the browser page and therefore running a count query through the conversation database for each support channel on every refresh is not very efficient. <br></p><p>Sure, it may not be a big deal at first but if we scale to even half of what we plan to hit with this product, a query like this will bite me in the rear sooner than I would want it to.<br></p><h3><strong>The obvious solution</strong><br></h3><p>The solution that occurred to me was to cache the count of open conversations for each support channel. This made sense at first but it quickly turned into a nightmare when I gave it a little more thought.<br></p><p>Okay so I plan to save a count of the open conversations in the cache, which means every time a conversation is opened I increment the count and every time a conversation is closed, I decrement the count? <br></p><p>Alright that doesn’t sound so bad but how do I trigger this increment/decrement operation? I suppose I could do it whenever a conversation gets updated in the database.</p><p><strong>And the problems begin</strong><br></p><p>But wait, I can’t trigger it every single time a conversation is updated, what if a conversation is open but some other data in the conversation gets updated while the status is still open? <br></p><p>Do I have to write an if-else condition to run the increment/decrement operation only when status changes from open to closed or from closed to open? <br></p><p>What happens if a conversation update finished running but the increment/decrement operation failed for some reason or vice versa? How do I re-run an update without corrupting the data?<br></p><p>In case you haven’t guessed where I was heading with this, here is a nice visual aid.<br></p><figure id="w-node-8acd9e28438e-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f89bb0e233bae24f8426a98_4bpq9EhUO8t33FNJqWPsuFDUSKjgAkCndQBpK2Jp7vpODzh6eHAOGqskq5yJvkAE8LOMREF-CxlbpE-pvimw4nHMM-hR5H4s6nbxjxsx-X1mLFRykaGlaJqzQomxlq0IGL9dNF6j.png" alt=""></p><figcaption>This is not how a codebase should look</figcaption></figure><h3><strong>The elegant solution</strong><br></h3><p>So how did Set theory get me out of this mess? What if I maintained a Set of IDs that belong to open conversations for each support channel? <br></p><p>All I have to do now is this: On every conversation update, if status is open, I add that conversation ID to the Set and I remove it from the Set if status is closed.<br></p><p>This Set would be stored on the RAM of course and yes it would take up more memory than storing just a single count for every support channel but all we are doing is storing IDs and not the entire data object so it would hardly cost much in terms of memory.<br></p><p>How does this help with the problem? Well, if you want the count of open conversations just get the number of elements in the Set, the cardinal number of the Set if you will. <br></p><p><strong>Why is this elegant? </strong></p><p>Because a Set cannot have duplicates. It does not matter how many times I add an item to a Set, a unique conversation ID can be added to it only once and similarly once a remove operation is performed, subsequent remove operations on the same conversation ID won’t have an affect on the data. The data has become idempotent.<br></p><p>This means that I don’t need an if-else condition when a conversation update operation is performed. All I need to do is perform an add/remove operation based on the status of the conversation post update. <br></p><p>It doesn’t matter if there is an explicit status update or not. Every update can trigger this logic and the data remains incorrupt. If any of the operations fail midway, the conversation update can just be re-run.<br></p><p>The code now looks like this</p><figure id="w-node-2d277519589a-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f89bb36be27e6c99c326654_oWQzIzHYO33Ha-W8vdEpTLGwdR7nKhkY8uILJGhi3ZAblDClNkJunvOEY924v0u7r1ifijiRdBMkLccDknHuDPcqlSCp3N2wcwP1-xCXIW_P4SzsERz1-WtEfa-2r1XA-QhL4vSW.png" alt=""></p><figcaption>This is how a codebase should look</figcaption></figure><h3>‍<br><strong>How to implement a Set data structure in your application</strong><br></h3><p>The most obvious way to do this is to use a JSON dictionary data structure like this for every support channel.</p><figure id="w-node-a0c1c2ac391e-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f89bd048b9f4952f3ada401_s9ykghBfc4x32sr5cNPo-eOKI5lEI__XDz9HLD6WEGjw-EKesvHt8nc1wAV5JWX412TWIvLOMvE4oLB8xXrJMmQrdoAcoIxlozV1fWJpA0tQZU85OnJol_Mweheo2JKrLENl1aBM.png" alt=""></p><figcaption>A Set data structure using JSON</figcaption></figure><p>If a conversation needs to be added to the Set, update the dictionary with the key as the conversation id and value as true or 1. For remove operations first check if the conversation id is already in the dictionary and remove It from the dictionary. Do nothing if it’s not already present. <br></p><p>This dictionary can now be stored in a variable in memory and used throughout the application. To get the count of open conversations for a support channel, just get the number of keys present in the dictionary.<br></p><h3><strong>Skip the trouble and use Redis instead</strong><br></h3><p>Clearly somebody else figured out the importance of a Set as a data structure way before I did, because <a href="https://redis.io/" target="_blank">Redis</a> - an elegant In memory database used for caching data already offers the Set data structure along with operations that let you add, remove and find number of items in a Set. <br></p><p>I would highly recommend using this in your application instead of maintaining a dictionary in a variable because the good folks at Redis already solve a host of other problems that might occur as a result of maintaining an in-memory cache. <br></p><figure id="w-node-6542e37d9ac4-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f89c17824a1dd7eb0b270cd_MLAse7rDGCwNyfvu57U6jsKkIhElVm5CVv2VFGw40wVqTRgeC7ask0Pk54wni7F785D-5h1p-EH_Cn2kO6Dl2EBRPYOsJf586yIAyQDQ5aeJzFXglgG4ws7mLatx90ZyPaGORstQ.png" alt=""></p><figcaption>Set data structure in Redis</figcaption></figure><p>‍<br></p><h3><strong>Conclusion</strong><br></h3><p>Perhaps there is some merit in revisiting some of the concepts we learnt as children and see if they are still relevant and can somehow be applied to the real world.<br></p><p>At the very least this would give us closure and instil hope that maybe everything we were taught that seemed useless at the time has a certain aspect to it that might come in handy at some point or the other in our lives and we just have to keep our eyes, ears and most importantly our minds open.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/the-set-data-structure-saved-me-from-a-world-of-pain</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815618</guid>
            <pubDate>Sun, 18 Oct 2020 04:51:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create automated AWS billing reports]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24815311">thread link</a>) | @aray07
<br/>
October 17, 2020 | https://www.learnaws.org/2020/10/17/how-to-create-billing-alerts/ | <a href="https://web.archive.org/web/*/https://www.learnaws.org/2020/10/17/how-to-create-billing-alerts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<hr>
<p><img src="https://www.learnaws.org/assets/img/serverless-cost-alerts/twitter-image.png" alt="twitter-image" title="Create a serverless billing pipeline"></p>
<h2 id="introduction">Introduction</h2>
<p>Amazon provides the ability to create <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/monitor_estimated_charges_with_cloudwatch.html">Billing Alarms</a> that can be used to alert whenever your AWS bill exceeds a certain threshold. However, this approach has a few shortcomings:</p>
<ul>
<li>
<p>You need to set a predefined threshold. When you are first starting to use AWS, it’s hard to know what your AWS bill will look like. A lot of people set this threshold pretty low to be safe.</p>
</li>
<li>
<p>An alert like this tends to be reactive instead of proactive. The alarm gets triggered once the threshold has already crossed. For example, I had forgotten to turn off an EC2 instance I was no longer using but I only found out about a week later once my billing threshold crossed the limit.</p>
</li>
</ul>
<p><a href="https://aws.amazon.com/aws-cost-management/aws-cost-explorer/">Cost Explorer</a> does provide an easy-to-use interface that can help keep you on top of your billing data. However, this requires one to use the tool regularly to ensure we don’t miss anything.</p>
<p>In this article, we will look at how to build a simple pipeline to send us billing reports over email. The generated report will look like this:</p>
<p><img src="https://www.learnaws.org/assets/img/serverless-cost-alerts/billing-email.png" alt="billing-alert-email" title="Billing Alert Email"></p>
<p>The tools we will use are:</p>
<ul>
<li>AWS Lambda</li>
<li>Simple Email Service</li>
<li>Cost Explorer API</li>
</ul>

<h2 id="getting-started">Getting Started</h2>
<p>The source code for the project is available at <a href="https://github.com/abhishekray07/serverless-cost-alerts">this repository</a>.</p>
<h3 id="project-setup">Project Setup</h3>
<h4 id="create-a-new-directory-for-the-application">Create a new directory for the application</h4>
<div><div><pre><code><span>mkdir </span>serverless-cost-alerts
<span>cd </span>serverless-cost-alerts
</code></pre></div></div>
<h4 id="setup-a-virtualenv-for-the-application">Setup a virtualenv for the application</h4>
<div><div><pre><code>virtualenv <span>env
source env</span>/bin/activate
</code></pre></div></div>
<h4 id="create-requirementstxt-with-all-the-dependencies">Create requirements.txt with all the dependencies</h4>

<h4 id="install-the-dependencies">Install the dependencies</h4>
<p>Run the following command in the shell to install all the dependencies.</p>
<div><div><pre><code>pip <span>install</span> <span>-r</span> requirements.txt
</code></pre></div></div>
<section>
<p>Become An AWS Expert</p>
<p>Receive a weekly newsletter with in-depth articles and tutorials about AWS. No spam ever.</p>
<p>Subscribers get <a href="https://learn-aws-blog.s3-us-west-2.amazonaws.com/choose-aws-tools.png" target="_blank">cheatsheets and guides</a>.</p>



</section>

<h4 id="create-scaffolding">Create scaffolding</h4>
<p>We will create a new folder called <code>app</code> which will store the application logic for the Cost Explorer API as well as using SES.</p>
<div><div><pre><code><span>mkdir </span>app
<span>touch </span>app/__init__.py app/cost_explorer.py app/email.py
</code></pre></div></div>
<p>We will also create a file called <code>handler.py</code> in the root directory. This file will contain the logic used to generate billing reports.</p>

<h2 id="cost-explorer-api">Cost Explorer API</h2>
<p>We will be using the <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ce.html#CostExplorer.Client.get_cost_and_usage">Cost And Usage</a> endpoint from Cost Explorer to get the billing data we need.</p>
<p>Replace the contents of the <code>cost_explorer.py</code> file we created earlier with this:</p>
<div><div><pre><code>
<span>import</span> <span>boto3</span>
<span>from</span> <span>datetime</span> <span>import</span> <span>date</span><span>,</span> <span>datetime</span><span>,</span> <span>timedelta</span>
<span>from</span> <span>dateutil.relativedelta</span> <span>import</span> <span>relativedelta</span>


<span>class</span> <span>CostExplorer</span><span>:</span>
    <span>TODAY_DATE</span> <span>=</span> <span>datetime</span><span>.</span><span>utcnow</span><span>().</span><span>date</span><span>()</span>
    <span>CUR_MONTH_DATE</span> <span>=</span> <span>TODAY_DATE</span><span>.</span><span>replace</span><span>(</span><span>day</span><span>=</span><span>1</span><span>)</span>
    <span>PREV_MONTH_DATE</span><span>:</span> <span>date</span> <span>=</span> <span>CUR_MONTH_DATE</span> <span>-</span> <span>relativedelta</span><span>(</span><span>months</span><span>=+</span><span>1</span><span>)</span>

    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>client</span> <span>=</span> <span>boto3</span><span>.</span><span>client</span><span>(</span><span>"ce"</span><span>)</span>
        <span>self</span><span>.</span><span>metrics</span> <span>=</span> <span>[</span><span>"UNBLENDED_COST"</span><span>]</span>
        <span>self</span><span>.</span><span>currency</span><span>:</span><span>str</span> <span>=</span> <span>"USD"</span>

        <span>self</span><span>.</span><span>daily_report_kwargs</span> <span>=</span> <span>{</span>
            <span>"TimePeriod"</span><span>:</span> <span>self</span><span>.</span><span>_get_timeperiod</span><span>(</span>
                <span>start</span><span>=</span><span>self</span><span>.</span><span>TODAY_DATE</span> <span>-</span> <span>timedelta</span><span>(</span><span>days</span><span>=</span><span>2</span><span>),</span> <span># start_dt is inclusive
</span>                <span>end</span><span>=</span><span>self</span><span>.</span><span>TODAY_DATE</span><span>,</span> <span># end_dt is exclusive
</span>            <span>),</span>
            <span>"Metrics"</span><span>:</span> <span>self</span><span>.</span><span>metrics</span><span>,</span>
            <span>"Granularity"</span><span>:</span> <span>"DAILY"</span>
        <span>}</span>

        <span>self</span><span>.</span><span>monthly_report_kwargs</span> <span>=</span> <span>{</span>
            <span>"TimePeriod"</span><span>:</span> <span>self</span><span>.</span><span>_get_timeperiod</span><span>(</span>
                <span>start</span><span>=</span><span>self</span><span>.</span><span>PREV_MONTH_DATE</span><span>,</span> <span># start_dt is inclusive
</span>                <span>end</span><span>=</span><span>self</span><span>.</span><span>TODAY_DATE</span><span>,</span> <span># end_dt is exclusive
</span>            <span>),</span>
            <span>"Metrics"</span><span>:</span> <span>self</span><span>.</span><span>metrics</span><span>,</span>
            <span>"Granularity"</span><span>:</span> <span>"MONTHLY"</span>
        <span>}</span>

    <span>def</span> <span>_get_timeperiod</span><span>(</span><span>self</span><span>,</span> <span>start</span><span>:</span> <span>date</span><span>,</span> <span>end</span><span>:</span> <span>date</span><span>):</span>
        <span>return</span> <span>{</span>
            <span>"Start"</span><span>:</span> <span>start</span><span>.</span><span>isoformat</span><span>(),</span>
            <span>"End"</span><span>:</span> <span>end</span><span>.</span><span>isoformat</span><span>(),</span>
        <span>}</span>

    <span>def</span> <span>_get_data</span><span>(</span><span>self</span><span>,</span> <span>results</span><span>):</span>
        <span>"""
        Retrieves the individual billing rows from cost explorer data.
        """</span>
        <span>rows</span> <span>=</span> <span>[]</span>
        <span>for</span> <span>v</span> <span>in</span> <span>results</span><span>:</span>
            <span>row</span> <span>=</span> <span>{</span><span>"date"</span><span>:</span><span>v</span><span>[</span><span>"TimePeriod"</span><span>][</span><span>"Start"</span><span>]}</span>
            <span>for</span> <span>i</span> <span>in</span> <span>v</span><span>[</span><span>"Groups"</span><span>]:</span>
                <span>key</span> <span>=</span> <span>i</span><span>[</span><span>"Keys"</span><span>][</span><span>0</span><span>]</span>
                <span>row</span><span>.</span><span>update</span><span>({</span><span>key</span><span>:</span><span>float</span><span>(</span><span>i</span><span>[</span><span>"Metrics"</span><span>][</span><span>"UnblendedCost"</span><span>][</span><span>"Amount"</span><span>])})</span>
            <span>row</span><span>.</span><span>update</span><span>({</span><span>"Total"</span><span>:</span><span>float</span><span>(</span><span>v</span><span>[</span><span>"Total"</span><span>][</span><span>"UnblendedCost"</span><span>][</span><span>"Amount"</span><span>])})</span>
            <span>rows</span><span>.</span><span>append</span><span>(</span><span>row</span><span>)</span>

        <span>return</span> <span>[</span><span>f"</span><span>{</span><span>row</span><span>[</span><span>'date'</span><span>]</span><span>}</span><span>: </span><span>{</span><span>round</span><span>(</span><span>row</span><span>[</span><span>'Total'</span><span>],</span> <span>2</span><span>)</span><span>}</span><span>"</span> <span>for</span> <span>row</span> <span>in</span> <span>rows</span><span>]</span>

    <span>def</span> <span>generate_report</span><span>(</span><span>self</span><span>,</span> <span>report_kwargs</span><span>):</span>
        <span>"""
        Get cost data based on the granularity, start date and end date.
        """</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>get_cost_and_usage</span><span>(</span><span>**</span><span>report_kwargs</span><span>)</span>
        <span>return</span> <span>"</span><span>\n</span><span>"</span><span>.</span><span>join</span><span>(</span><span>self</span><span>.</span><span>_get_data</span><span>(</span><span>response</span><span>[</span><span>"ResultsByTime"</span><span>]))</span>
</code></pre></div></div>
<h3 id="key-points">Key Points</h3>
<ul>
<li>
<p>We want to generate two reports, one for the last 2 days (daily granularity) and one to compare the spend last month vs the current month (monthly granularity).</p>
</li>
<li>
<p>We used <code>Unblended costs</code> to represent our billing data. More information about this can be found <a href="https://aws.amazon.com/blogs/aws-cost-management/understanding-your-aws-cost-datasets-a-cheat-sheet/">here</a>.</p>
</li>
</ul>
<h2 id="simple-email-service-ses">Simple Email Service (SES)</h2>
<p>We will be using SES to send the billing reports to ourselves via email.</p>
<h3 id="prerequisites">Prerequisites</h3>
<p>SES requires a verified email address before it can be used. Verification can be done via the AWS console.</p>
<h3 id="using-ses">Using SES</h3>
<p>Replace the contents of <code>email.py</code> with the code snippet below:</p>
<div><div><pre><code>
<span>import</span> <span>boto3</span>


<span>class</span> <span>EmailClient</span><span>:</span>
    <span>SENDER</span> <span>=</span> <span>"AWS Cost Alert &lt;<a href="https://www.learnaws.org/cdn-cgi/l/email-protection" data-cfemail="2e4f4c46475d464b456e424b4f5c404f595d00415c49">[email&nbsp;protected]</a>&gt;"</span>
    <span>SUBJECT</span> <span>=</span> <span>"Daily AWS Billing Report"</span>
    <span># The email body for recipients with non-HTML email clients.
</span>    <span>BODY_TEXT</span> <span>=</span> <span>"""AWS Billing Alerts </span><span>\r\n</span><span>
    Daily billing report</span><span>\r\n</span><span>
    {daily_billing_report}</span><span>\r\n</span><span>
    Monthly billing report</span><span>\r\n</span><span>
    {monthly_billing_report}</span><span>\r\n</span><span>
    """</span>

    <span># The HTML body of the email.
</span>    <span>BODY_HTML</span> <span>=</span> <span>"""&lt;html&gt;
    &lt;head&gt;&lt;/head&gt;
    &lt;body&gt;
    &lt;h1&gt;AWS Billing Alert&lt;/h1&gt;
    &lt;hr/&gt;
    &lt;h3&gt;Daily Billing&lt;/h3&gt;
    &lt;p&gt;{daily_billing_report}&lt;/p&gt;
    &lt;hr/&gt;
    &lt;h3&gt;Monthly Billing&lt;/h3&gt;
    &lt;p&gt;{monthly_billing_report}&lt;/p&gt;
    &lt;/body&gt;
    &lt;/html&gt;
    """</span>
    <span># The character encoding for the email.
</span>    <span>CHARSET</span> <span>=</span> <span>"UTF-8"</span>

    <span># recipient email address
</span>    <span>RECIPIENT</span> <span>=</span> <span>"<a href="https://www.learnaws.org/cdn-cgi/l/email-protection" data-cfemail="60010208091308050b200c0501120e0117134e0f1207">[email&nbsp;protected]</a>"</span>

    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>client</span> <span>=</span> <span>boto3</span><span>.</span><span>client</span><span>(</span><span>"ses"</span><span>)</span>

    <span>def</span> <span>send</span><span>(</span><span>self</span><span>,</span> <span>daily_billing_report</span><span>,</span> <span>monthly_billing_report</span><span>):</span>
        <span>"""Send an email which contains AWS billing data"""</span>
        <span>email_text</span> <span>=</span> <span>self</span><span>.</span><span>BODY_TEXT</span><span>.</span><span>format</span><span>(</span>
            <span>daily_billing_report</span><span>=</span><span>daily_billing_report</span><span>,</span>
            <span>monthly_billing_report</span><span>=</span><span>monthly_billing_report</span>
        <span>)</span>

        <span>email_html</span> <span>=</span> <span>self</span><span>.</span><span>BODY_HTML</span><span>.</span><span>format</span><span>(</span>
            <span>daily_billing_report</span><span>=</span><span>daily_billing_report</span><span>,</span>
            <span>monthly_billing_report</span><span>=</span><span>monthly_billing_report</span>
        <span>)</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>send_email</span><span>(</span>
            <span>Destination</span><span>=</span><span>{</span>
                <span>"ToAddresses"</span><span>:</span> <span>[</span>
                    <span>self</span><span>.</span><span>RECIPIENT</span><span>,</span>
                <span>],</span>
            <span>},</span>
            <span>Message</span><span>=</span><span>{</span>
                <span>"Body"</span><span>:</span> <span>{</span>
                    <span>"Html"</span><span>:</span> <span>{</span>
                        <span>"Charset"</span><span>:</span> <span>self</span><span>.</span><span>CHARSET</span><span>,</span>
                        <span>"Data"</span><span>:</span> <span>email_html</span>
                    <span>},</span>
                    <span>"Text"</span><span>:</span> <span>{</span>
                        <span>"Charset"</span><span>:</span> <span>self</span><span>.</span><span>CHARSET</span><span>,</span>
                        <span>"Data"</span><span>:</span> <span>email_text</span><span>,</span>
                    <span>},</span>
                <span>},</span>
                <span>"Subject"</span><span>:</span> <span>{</span>
                    <span>"Charset"</span><span>:</span> <span>self</span><span>.</span><span>CHARSET</span><span>,</span>
                    <span>"Data"</span><span>:</span> <span>self</span><span>.</span><span>SUBJECT</span><span>,</span>
                <span>},</span>
            <span>},</span>
            <span>Source</span><span>=</span><span>self</span><span>.</span><span>SENDER</span><span>,</span>
        <span>)</span>

</code></pre></div></div>
<h3 id="key-points-1">Key points:</h3>
<ul>
<li>Replace <code>SENDER</code> and <code>RECEPIENT</code> with the email address you verified with SES.</li>
</ul>
<h2 id="generating-a-billing-report">Generating a billing report</h2>
<p>We will now generate a report using Cost Explorer and SES. Replace the contents of <code>handler.py</code> with the code snippet below:</p>
<div><div><pre><code><span>from</span> <span>app.cost_explorer</span> <span>import</span> <span>CostExplorer</span>
<span>from</span> <span>app.email</span> <span>import</span> <span>EmailClient</span>


<span>def</span> <span>main</span><span>():</span>
    <span>ce</span> <span>=</span> <span>CostExplorer</span><span>()</span>
    <span>daily_report</span> <span>=</span> <span>ce</span><span>.</span><span>generate_report</span><span>(</span><span>ce</span><span>.</span><span>daily_report_kwargs</span><span>)</span>
    <span>monthly_report</span> <span>=</span> <span>ce</span><span>.</span><span>generate_report</span><span>(</span><span>ce</span><span>.</span><span>monthly_report_kwargs</span><span>)</span>

    <span>email_client</span> <span>=</span> <span>EmailClient</span><span>()</span>
    <span>email_client</span><span>.</span><span>send</span><span>(</span>
        <span>daily_billing_report</span><span>=</span><span>daily_report</span><span>,</span>
        <span>monthly_billing_report</span><span>=</span><span>monthly_report</span>
    <span>)</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>main</span><span>()</span>
</code></pre></div></div>
<p>Next, run the script from your terminal using the following command:</p>

<p>If your AWS profile is setup with the appropriate permissions, you should receive an email with your billing data. This what the email should look like:</p>
<p><img src="https://www.learnaws.org/assets/img/serverless-cost-alerts/billing-email.png" alt="billing-alert-email" title="Billing Alert Email"></p>
<h2 id="integrating-aws-lambda">Integrating AWS Lambda</h2>
<p>Now that we have generated the billing report locally, we will make use of the <a href="https://www.serverless.com/">Serverless Framework</a> to create a serverless pipeline using AWS Lambda.</p>
<h3 id="prerequisites-1">Prerequisites</h3>
<ol>
<li>
<p>Setup serverless framework by following the instructions listed <a href="https://www.serverless.com/framework/docs/getting-started/">here</a>.</p>
</li>
<li>
<p>Run the following commands after installing the serverless framework.</p>
<div><div><pre><code>npm init <span>-f</span>
npm <span>install</span> <span>--save-dev</span> serverless-python-requirements
</code></pre></div> </div>
</li>
</ol>
<p>The <code>serverless-python-requirements</code> plugin automatically bundles dependencies from <code>requirements.txt</code> and makes them available to your Lambda function.</p>
<h3 id="setting-up-the-serverless-project">Setting up the serverless project</h3>
<p>Next, create the file <code>serverless.yml</code> in your root directory and copy the following content:</p>
<div><div><pre><code>
<span>service</span><span>:</span> <span>serverless-cost-alerts</span>

<span>plugins</span><span>:</span>
  <span>-</span> <span>serverless-python-requirements</span>

<span>package</span><span>:</span>
  <span>excludeDevDependencies</span><span>:</span> <span>true</span>
  <span>exclude</span><span>:</span>
    <span>-</span> <span>node_modules/**</span>

<span>custom</span><span>:</span>
  <span>pythonRequirements</span><span>:</span>
    <span>slim</span><span>:</span> <span>true</span>
    <span>strip</span><span>:</span> <span>false</span>
    <span>slimPatternsAppendDefaults</span><span>:</span> <span>true</span>
    <span>slimPatterns</span><span>:</span>
      <span>-</span> <span>"</span><span>**/*.egg-info*"</span>
      <span>-</span> <span>"</span><span>**/*.dist-info*"</span>
    <span>dockerizePip</span><span>:</span> <span>true</span>

<span>provider</span><span>:</span>
  <span>name</span><span>:</span> <span>aws</span>
  <span>runtime</span><span>:</span> <span>python3.7</span>
  <span>stage</span><span>:</span> <span>dev</span>
  <span>region</span><span>:</span> <span>us-west-2</span>
  <span>iamRoleStatements</span><span>:</span>
    <span>-</span> <span>Effect</span><span>:</span> <span>Allow</span>
      <span>Action</span><span>:</span>
        <span>-</span> <span>ses:SendEmail</span>
      <span>Resource</span><span>:</span>
        <span>-</span> <span>"</span><span>*"</span>
    <span>-</span> <span>Effect</span><span>:</span> <span>Allow</span>
      <span>Action</span><span>:</span>
        <span>-</span> <span>ce:GetCostAndUsage</span>
      <span>Resource</span><span>:</span>
        <span>-</span> <span>"</span><span>*"</span>

<span>functions</span><span>:</span>
  <span>send_daily_cost_report</span><span>:</span>
    <span>handler</span><span>:</span> <span>handler.generate_report</span>
    <span>events</span><span>:</span>
      <span>-</span> <span>http</span><span>:</span> <span>GET hello</span>
</code></pre></div></div>
<h4 id="key-points-2">Key points</h4>
<ul>
<li>The lambda function will have the permission to query the <code>CostAndUsage</code> function in Cost Explorer and <code>SendEmail</code> in SES.</li>
<li>To test our Lambda function, we will create a temporary HTTP endpoint called <code>hello</code>.</li>
</ul>
<h3 id="lambda-handler">Lambda Handler</h3>
<p>Before we deploy the Lambda function to AWS, we need to update the Lambda function so that it can respond to an HTTP request. Update the contents of your <code>handler.py</code> with the following code snippet:</p>
<div><div><pre><code><span>from</span> <span>app.cost_explorer</span> <span>import</span> <span>CostExplorer</span>
<span>from</span> <span>app.email</span> <span>import</span> <span>EmailClient</span>


<span>def</span> <span>generate_report</span><span>(</span><span>event</span><span>,</span> <span>context</span><span>):</span>
    <span>ce</span> <span>=</span> <span>CostExplorer</span><span>()</span>
    <span>daily_report</span> <span>=</span> <span>ce</span><span>.</span><span>generate_report</span><span>(</span><span>ce</span><span>.</span><span>daily_report_kwargs</span><span>)</span>
    <span>monthly_report</span> <span>=</span> <span>ce</span><span>.</span><span>generate_report</span><span>(</span><span>ce</span><span>.</span><span>monthly_report_kwargs</span><span>)</span>

    <span>email_client</span> <span>=</span> <span>EmailClient</span><span>()</span>
    <span>email_client</span><span>.</span><span>sen…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.learnaws.org/2020/10/17/how-to-create-billing-alerts/">https://www.learnaws.org/2020/10/17/how-to-create-billing-alerts/</a></em></p>]]>
            </description>
            <link>https://www.learnaws.org/2020/10/17/how-to-create-billing-alerts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815311</guid>
            <pubDate>Sun, 18 Oct 2020 03:27:31 GMT</pubDate>
        </item>
    </channel>
</rss>
