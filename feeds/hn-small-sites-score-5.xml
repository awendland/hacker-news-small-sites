<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 04 Mar 2021 08:39:41 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 04 Mar 2021 08:39:41 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Proposal for an Internet Service: The Eternal Home Page (1996)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26313569">thread link</a>) | @jstrieb
<br/>
March 2, 2021 | http://neilsloane.com/doc/eternal.html | <a href="https://web.archive.org/web/*/http://neilsloane.com/doc/eternal.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<center><h2>Proposal for an Internet Service: The Eternal Home Page</h2></center><center>
<a href="http://neilsloane.com/index.html"> N. J. A. Sloane</a>
</center>
<center>
Information Sciences Research Center,
</center>
<center>
AT&amp;T Labs - Research, Florham Park, New Jersey 07932, U.S.A.
</center>
<center>
Email address: njasloane@gmail.com.
</center>
<center>
December 13, 1996. Revised November 11, 1997.
</center>
<center>
<h2><strong>Abstract</strong></h2>
</center>
<p>
This paper describes a possible Internet service that
some major organization such as
Harvard University, AT&amp;T,
the Institute of Electrical and Electronic Engineers,
the American Mathematical Society, the American Medical Association,
or even the Vatican, might offer: a home page "in perpetuity".
Such a "perpetual page" or "eternity page" or
"e-memorial page" would be a home page that the organization would
help the customer set up, with a guarantee that it would
last for (say) 500 years, or until the organization no
longer exists.
It would list all the things that the customer would like to
be remembered for (accomplishments, family, etc.).
As the population of the U.S. ages,
such a service should prove very popular.
After all, almost everyone wants to be remembered by posterity.
</p><center><h2> Details </h2></center>
<ul>
<li>
The name for this service needs to be chosen with care, and
of course registered. "Eternity service",
"Perpetual page", "Eternity page", "E-memorial page",
"Everlasting page"
are a few possibilities. I will use "Perpetual page"
in this paper.

</li>
<li>
The first version of this paper was written in
December 1996, although the idea for the "Perpetual home page"
first occurred to me in January 1996.
Not surprisingly,
it turns out that other people have had similar ideas, and there may be some
commercial services that provide electronic gravestones available even now.
But my vision is that
this service would be offered by a major organization or institute,
that has already existed for a long time and
has some chance of existing 500 years from now.
And I'm not thinking of tombstones, but home-pages.

</li>
<li>
The "Perpetual page" could include such things as:
<ul>
<li>
photographs of houses, boats, paintings, other precious possessions
</li>
<li>
lists of awards, accomplishments
</li>
<li>
writings, drawings, songs, even unpublished novels
(disk space is cheap)
</li>
<li>
links to perpetual pages of one's family (including ancestors!) and friends
</li>
</ul>

</li>
<li>
This is the customer's chance to write their own
<em>New York Times</em> obituary page, or "time capsule".
(Many people do not realize that except for a handful of major obituaries,
every obituary item in the <em>New York Times</em> has to be
purchased at about $40 per line -- this can be a humiliating
experience for the next-of-kin.
Setting up a "Perpetual page" in advance for the sick
and elderly could be both therapeutic and comforting for the family.)

</li>
<li>
There should be a generous amount of disk
space available for each page - a minimum of ten megabytes,
to allow a number of photographs to be included. (Most Internet
providers at present do not allow nearly enough disk space.)
As my colleague 
Andrew Odlyzko has pointed out in his
<a href="http://www.research.att.com/~amo/doc/tragic.loss.txt">
discussion of the future of scholarly journals</a>,
the cost of disk space is dropping so rapidly that it is likely that 
the cost of providing a service
in perpetuity will be not much more than that of providing it for
one year.

</li>
<li>
The organization would help the customer set up the initial page, and would
provide instructions on how to maintain it.
A "help desk" would be part of the service.

</li>
<li>
One way to structure the offer might be to tell customers:
For a one-time fee of $X, we will provide you with Y MB of
storage, and as long as you pay a small monthly fee,
you can keep modifying it.  Once you stop paying the monthly fee
(say because you die, or switch to a different
provider) we will keep the latest version <em>forever</em>.

</li>
<li>
Part of the offer would be a guarantee that when the Internet is replaced
by some other service in a few years, all the "Perpetual pages"
would be automatically converted to the new medium.

</li>
<li>
It is important that the organization offering the servce
should have been in existence for a long time, and have a good chance of
still existing 500 hundred years from now.
The organizations mentioned in the Abstract certainly
satisfy these conditions, and it is easy to think of others. 
Such a service would not carry much conviction
if offered by some tiny local Internet service provider.

</li>
<li>
This is the first time in history that such a thing is possible.

</li>
<li>
Incidentally,
the <em>New York Times</em>} for Saturday Dec. 7 1996 describes (on page D2)
a patent, US 5,517,791, for a new tombstone design that can
incorporate a person's life story - including photographs.
So ideas like the one I am proposing are "in the air".

</li>
<li>
As one may verify by visiting cemeteries in New Jersey, tombstones are rarely
legible after a hundred years have passed.  One of the advertisements for the
proposed service could show a family searching through a
cemetery full of grave stones that have been worn smooth,
looking for the lost grave of an ancestor.  Furthermore,
as the world population continues to explode,
cemeteries will become increasingly irrelevant.

</li>
<li>
The "perpetual page" service would especially appeal to mature customers.
There are several ways in which advertisements could point out the futility
of earlier attempts to be remembered, even by world leaders.
For example, one advertisement could show a replica of the original
Mausoleum at Halicarnassus,
after which all later mausoleums are named.
(See <em>The Oxford History of the Classical World</em>,
ed. J. Boardman et al., Oxford, 1993, p. 150.)
<center> <img src="http://neilsloane.com/doc/maus1.jpg"> </center>
<p>
One of the Seven Wonders of the World, it was
built in the year 353 for King Mausolus of Caria by his wife.
It no longer exists.
"But if King Mausolus had had a perpetual page, we could still read
about his victories today ...".

</p></li>
<li>
An alternative way in which the "perpetual page" could be used is
by family and friends after the death of a loved one, by setting up a
permanent memorial for the deceased.  The Page would need to have an
authorized keeper, to screen out inappropriate material.
A certain amount of permanent space would be purchased, to which
interested parties could contribute in any way they wished.


</li>
<li>
Another advertisement could have a voice reading P. B. Shelley's
poem <strong>Ozymandias</strong>,
while the picture shows dust blowing around an appropriate ruin:

<pre>     I met a traveller from an antique land 
     Who said: Two vast and trunkless legs of stone 
     Stand in the desert ... Near them, on the sand,
     Half sunk, a shattered visage lies, whose frown,
     And wrinkled lip, and sneer of cold command,
     Tell that its sculptor well those passions read
     Which yet survive, stamped on these lifeless things,
     The hand that mocked them, and the heart that fed:
     And on the pedestal these words appear: 
     `My name is Ozymandias, king of kings: 
     Look on my works, ye Mighty, and despair!' 
     Nothing beside remains. Round the decay 
     Of that colossal wreck, boundless and bare
     The lone and level sands stretch far away.
</pre>
<center><img src="http://neilsloane.com/doc/ozy4.jpg"> </center>
</li>
<li>
It will also give all the unpublished poets and writers,
the unrecognized painters and musicians, the scientists
whose theories are rejected, the opportunity to have their
work immortalized.

</li>
<li>
Yet another advertisement could have Jessye Norman singing the moving
and unforgettable aria "Remember Me"
from Henry Purcell's "Dido and Aeneas".
(The formal title
is "Thy hand Belinda - when I am laid in Earth"
[Philips CD 434 161-2].)

</li>
</ul>
<p>
<strong>Acknowledgements</strong>:  I am grateful to Colin Mallows, Andrew Odlyzko,
Susanna Cuyler Sloane and Nambi Seshadri for a number of helpful comments.

</p><center>
<img src="http://neilsloane.com/banners/bline.gif" alt=" ">
</center>
<p><strong>See also:</strong> <a href="http://neilsloane.com/index.html"> <strong>My home page</strong></a> | 
<a href="http://neilsloane.com/doc/links.html#ET"><strong>Related links</strong></a>





</p></div>]]>
            </description>
            <link>http://neilsloane.com/doc/eternal.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26313569</guid>
            <pubDate>Tue, 02 Mar 2021 09:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A network of weather stations to help prevent pesticide spray drift]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26313216">thread link</a>) | @Damon_Mesonet
<br/>
March 2, 2021 | https://cotl.com.au/launch.html | <a href="https://web.archive.org/web/*/https://cotl.com.au/launch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <a name="intro"></a>


              <figure>
                <a href="https://riverlandmalleemesonet.com.au/"><img alt="Screenshot of the Riverland Mesonet during the beginning of an inversion" src="https://cotl.com.au/assets/app-screenshot-riverland-inversion-e97e8509021dc60e59f9013061552f9c5589719e56dbf50e5420a2d2ffc36e1a.png"></a>
                <figcaption>Screenshot of the Riverland Mesonet during the beginning of an inversion</figcaption>
              </figure>


              <p>Hi from the team who built the "mesonet" weather station networks in the state of South Australia!</p>
              <p>A <a href="https://en.wikipedia.org/wiki/Mesonet">mesonet</a> is a term for a network of automated weather stations designed to monitor meteorological phenomena at high geographic density and updated frequently.</p>
              <p>We built these networks to help prevent pesticide <a href="#spraydrift">spray drift</a> - the phenomenon in which pesticide spray that is applied to a crop ends up drifting to other crops, sometimes many kilometres away.</p>
              <p>Spray drift can be a huge problem, as it can lead to damage or even destruction of highly valuable crops, and can also cause pollution to waterways and harm to native ecosystems.</p>
              <p>The biggest factor in spray drift the presence of a <a href="#thermalinversions">thermal inversion</a>, a state in which temperature increases with increasing altitude, which usually happens in the evening and overnight when the earth is cooling, but can happen at other times. However other meteorological phenomena also affect the likelihood of spray drift, and different types of spray respond differently.</p>
              <p>So we designed a <a href="#ourweatherstations">weather station</a> to measure all the relevant meteorological phenomena, and in particular to detect thermal inversions, and a custom <a href="#webapp">web app</a> to display the data in format that is very fast and simple to access and understand.</p>
              <p>We've now deployed 70 of these stations across two of the major agricultural regions of South Australia, and so far it seems to be making a difference: no damage due to spray drift has been reported in these regions since the networks were rolled out.</p>


              

              <a name="background"><h2>Background</h2></a>

              <p>A group of stakeholders in the <a href="https://en.wikipedia.org/wiki/Mid_North">Mid North region of South Australia</a> had identified spray drift as a major issue.</p>
              <p>The region, to the north of <a href="https://en.wikipedia.org/wiki/South_Australia">South Australia</a>'s capital of <a href="https://en.wikipedia.org/wiki/Adelaide">Adelaide</a>, has a thriving agricultural sector, producing wheat, barley, wine grapes, pulses, livestock and other produce.</p>
              <p>The total annual output from the region is valued at nearly AUD $2 billion. It has been estimated that the potential loss in production from spray drift could be as high as $178M/year, and potential harm to waterways and native ecosystems is significant.</p>
              <p>The local stakeholders worked with meteorologists and researchers to develop a solution, then sought funding from the South Australia state government to fund the project.</p>
              <p>In 2018, a $1.4M grant was provided, and a pilot rollout of 40 weather stations was undertaken.  It was named the Mid North Mesonet.</p>
              <p>The pilot was deemed successful, and in 2019, another grant was provided by the state government for a network in the <a href="https://en.wikipedia.org/wiki/Riverland">Riverland</a> and <a href="https://en.wikipedia.org/wiki/Murray_Mallee">Mallee</a> region to the north-east of Adelaide.</p>

              <p>In the two years since the Mid North Mesonet was rolled out, there have been no reported instances of crop damage due spray drift.</p>

              <a name="spraydrift"><h2>The Problem of Spray Drift</h2></a>
              <p>Farmers spray pesticides on their crops to manage pests. It is an important feature of modern farming. Herbicide may be applied to target broad-leaf plants, other times to target summer weeds.</p>
              <p>Spray drift occurs when pesticide spray 'drifts' across into non-target areas.</p>
              <p>Spray drift is a problem because:</p>
              <div>
                <ul>
                    <li>The affected non-target area may be particularly susceptible to pesticides (i.e. broad-leaf crops such as grapevines are especially vulnerable)</li>
                    <li>Some markets are highly sensitive to the amount of pesticide residues detectable in the end products (i.e. wine exports to China; organic farms; etc)</li>
                    <li>The affected non-target area might be a sensitive natural ecosystem (i.e. local waterways)</li>
                    <li>The affected non-target area might include rain water tanks used for drinking water</li>
                    <li>It is a waste of pesticide product and labour time costs</li>
                </ul>
              </div>

              <a name="causesofspraydrift"><h2>Causes of Spray Drift</h2></a>
              <p>A combination of conditions can lead to spray drift.</p>
              <h3>Wind Speed</h3>
              <p>Wind speed that is very low or very high.</p>
              <h3>Temperature</h3>
              <p>A temperature over about 28Â°C (83Â°F).</p>
              <h3>Humidity</h3>
              <p>The effect of humidity varies depending on the type of spray. The spray manufacturer's instructions should provide guidance.</p>
              <h3>Atmospheric Stability</h3>
              <p><i>Unstable</i> or <i>stable</i> conditions can lead to spray drift. Conditions should be <i>neutral.</i></p>
              <h3>Thermal Inversions</h3>
              <p>A thermal inversion, in which temperature increases with increasing altitude, is a major risk factor for spray drift.</p>
              <p>Inversions generally happen in the evening and overnight as the earth cools, but they can happen at other times.</p>

              <a name="thermalinversions"><h2>Thermal Inversions</h2></a>
              <p>For current farming practices, long-distance spray drift generally occurs during very stable weather conditions (i.e. little to no air turbulence).</p>
              <p>A thermal inversion occurs when a warm layer of air sits above a cooler layer of air near the ground.</p>
              <p>This reduces air turbulence and can act as a â€˜lidâ€™ for an airborne pollutant source. The lack of air turbulence means the smaller spray droplets float without settling on the target crops.</p>
              <p>A very slight breeze can then carry these floating droplets large distances before they eventually descend into a non-target area.</p>
              <p>It is illegal to spray during a thermal inversion.</p>

              <p><strong>The problem: it is very difficult for farmers to tell if a thermal inversion is underway.</strong></p>

              <figure>
                <img alt="Diagram of an inversion" src="https://cotl.com.au/assets/inversion-diagram-4620f5e78853d307f3eda98282034a2f31990112210498b118a7f7209d362393.png">
                <figcaption>Diagram of an inversion</figcaption>
              </figure>

              <figure>
                <img alt="Photograph of an inversion with smoke" src="https://cotl.com.au/assets/inversion-smoke-photograph-37a8df015d3d946abce8f157b9088b23458cf7be098822bc24c5ccc5c98ac6ac.png">
                <figcaption>Photograph of an inversion with smoke</figcaption>
              </figure>

              <a name="ourweatherstations"><h2>Our Weather Stations</h2></a>

              <p>Our weather stations were designed to:</p>
              <div>
                <ul>
                    <li>Measure temperature at 1.2m and 10m, in order to detect inversions</li>
                    <li>Measure all weather metrics that are relevant in determining whether it is safe to spray</li>
                    <li>Update data every 10 minutes, so farmers have access to the most recent readings</li>
                </ul>
              </div>

              <p>They consist of:</p>
              <div>
                <ul>
                    <li>Temperature sensors at 1.2m</li>
                    <li>Temperature difference between 10m and 1.2m</li>
                    <li>Wind speed and direction sensors at 2m and 10m</li>
                    <li>Tipping bucket rain-gauge</li>
                    <li>Solar radiation sensor</li>
                    <li>Pressure sensor</li>
                    <li>Relative Humidity sensor</li>
                    <li>Antenna</li>
                    <li>DataLogger which takes readings every 10 minutes, does some calculations locally, and uploads over cellular data (3G/4G) to the web server for processing and display</li>
                </ul>
              </div>
              <p>Each tower is self-powered by a solar panel and battery.</p>

              <figure>
                <img alt="Weather Station at Walker Flat, SA" src="https://cotl.com.au/assets/aws-walkerflat-700x400px-4c79a337af8e7993aa961117c4d7ce0714a59cf0d23192272858e23c0c7e8a6f.jpg">
                <figcaption>Weather Station at Walker Flat, SA</figcaption>
              </figure>

              <figure>
                <img alt="Weather Station at Pinkerton Plains, SA" src="https://cotl.com.au/assets/aws_pinkerton_550px-e67cf8f7ec5c635d25d6fd2855bd4144e8209d78f17d71c9443a3b5e924419ce.jpg">
                <figcaption>Weather Station at Pinkerton Plains, SA</figcaption>
              </figure>


              <a name="webapp"><h2>The Web Application</h2></a>

              <p>We initially used an off-the-shelf web application for displaying meteorological data, but soon realised we needed something tailored to our needs. We found a company that was already in the business of building web-applications to display environmental data for farmers, and they were willing to build a customised version for us.</p>

              <p>The key requirements for the application were:</p>
              <div>
                <ul>
                    <li>Each of the monitored metrics displayed on a map, with fast/simple switching between each metric</li>
                    <li>A dashboard of all the current key metrics and recent historical graphs</li>
                    <li>Long-term graphs of all the key metrics also available, and as well as the past 48 hours of data in tabular format</li>
                    <li>The site must display well and be easy to use on a mobile device, and be fast to use even in areas with low cellular signal strength, given that much of the usage will be by farmers out in the field in remote areas.</li>
                </ul>
              </div>

              <p>The key technologies are:</p>
              <div>
                <ul>
                    <li>Ruby on Rails</li>
                    <li>PostgreSQL</li>
                    <li>Redis</li>
                    <li>Sidekiq for queue processing</li>
                    <li>React</li>
                </ul>
              </div>

              <p>Data is uploaded from the data logger via FTP (which may seem primitive, but the world of meteorological data still relies heavily on FTP).</p>

              <p>On detection of new data, the application first takes the most recent readings, and updates the data structures for the map and dashboard views.</p>

              <p>The historical data is then placed in a queue, for updating of historical graphs.</p>

              <p>All the data for the map view, dashboards and historical graphs are formatted into a JSON hash then serialized and stored in the Redis cache. That way, when the React web interface makes a request, the pre-formatted data can be retrieved and sent very quickly, as no querying, processing or formatting of data is required at request time.</p>

              <figure>
                <a href="https://midnorthmesonet.com.au/"><img alt="Screenshot of the Mid North Mesonet Map View with wind speeds shown" src="https://cotl.com.au/assets/app-screenshot-mid-north-mesonet-e2dc04bb613cc2a2607527fb6973e8fd78f938152818a84f184d0f8aeba497d5.png"></a>
                <figcaption>Screenshot of the Mid North Mesonet Map View with wind speeds shown</figcaption>
              </figure>

              <figure>
                <a href="https://riverlandmalleemesonet.com.au/"><img alt="Screenshot of the Riverland Mallee Mesonet Map View with temperatures shown" src="https://cotl.com.au/assets/app-screenshot-riverland-mallee-mesonet-61fdac0ba62e4974f33b61ae5b121162a7078d7320f4be951f2eb55052a59ce2.png"></a>
                <figcaption>Screenshot of the Riverland Mallee Mesonet Map View with temperatures shown</figcaption>
              </figure>

              <a name="results"><h2>Results so far</h2></a>

              <p>In the two years since the Mid North Mesonet was deployed, there have been no reported cases of crop damage due to spray drift.</p>

              <p>Damage and loss had been reported in most of the previous years - though not all. So it is too early to tell if the problem has been completely solved, but indications are promising.</p>

              <p>Other government bodies and NGOs are expressing interest in establishing their own mesonets.</p>


              <a name="contacts"><h2>Contacts</h2></a>
              <p>
                Damon Grace<br>
                Project Engineer<br>
                damon.grace@cotl.com.au<br>
              </p>
              <p>
                Warwick Grace<br>
                Meteorologist<br>
                warwick@graceresearch.com<br>
              </p>
              <p>
                Tom Howard<br>
  â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cotl.com.au/launch.html">https://cotl.com.au/launch.html</a></em></p>]]>
            </description>
            <link>https://cotl.com.au/launch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26313216</guid>
            <pubDate>Tue, 02 Mar 2021 08:42:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DDD Is Overrated]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 70 (<a href="https://news.ycombinator.com/item?id=26312652">thread link</a>) | @mcp_
<br/>
March 1, 2021 | https://tilkov.com/post/2021/03/01/ddd-is-overrated/ | <a href="https://web.archive.org/web/*/https://tilkov.com/post/2021/03/01/ddd-is-overrated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Update: Thereâ€™s a <a href="https://www.innoq.com/en/blog/is-domain-driven-design-overrated/">slightly extended version of this post</a> over at the INNOQ company blog.</em></p>
<p>There, I said it. Now that I have your attention: Domain Driven Design (DDD) has recently gained additional popularity, as evidenced by new books, conference talks (and even complete conferences dedicated to it), and lots of trainings â€“ including some by our very own colleagues at <a href="https://www.innoq.com/">INNOQ</a>. And in contrast to my click-bait headline, Iâ€™m actually a fan. <a href="https://www.dddcommunity.org/book/evans_2003/">Eric Evansâ€™s book</a>, the additional work writing and evangelizing it done by <a href="https://vaughnvernon.com/">Vaughn Vernon</a> (e.g. in <a href="https://www.case-podcast.org/15-domain-driven-design-with-vaughn-vernon">this very good podcast</a> with my colleague Joy) and many others, are all very good additions to our industryâ€™s body of knowledge. In the best sense of pattern languages, DDD gives clear names to things that many developers and designers know how to do, but cannot reliably and compatibly communicate about.</p>
<p>But Iâ€™m annoyed by the fact that recently, it seems that any time somebody talks about how to architect system or service boundaries, or even just mentions non-technical design, everybody feels compelled to bring in the DDD experts â€“ as if they were the only superheroes who could possibly design anything at all. This is just as bad as any other situation where you blindly apply the solution thatâ€™s currently en vogue, just because it is the thing everyone talks about, and not because it is the right solution for the job. DDD is great, but itâ€™s just one of many tools and techniques you should be aware of.</p>
<p>I think there is a more important aspect that people miss, especially when they get into DDD as their introduction to design in general. DDD emphasizes the importance of naming, and it suggests you should strive for a common, ubiquitous language, in the context youâ€™re designing for. But it also uses its own language â€“ concepts like bounded context, aggregates, entities, value objects, etc. â€“ for our domain, the domain of designing systems. And while these are all well and good, theyâ€™re only one possible language. Thereâ€™s value in calling a value object a value object, if this is a term many people understand, to facilitate communication. But the existing, common DDD concepts are not the only concepts you should consider â€“ they are just examples of a very common trait of designing and architecting systems: Coming up with and recognizing patterns, giving them good names, and using them to give the system structure and integrity. If in your architecture, thereâ€™s a common pattern that you use a Filter to route requests to a Handler, or a concept of a Document that is handled by an Agent, then these things may occur again and again, on the same level as Services or Repositories, and end up being way more important to you. This is fine! This concept, that we can and should invent our own languages, is to me way more important than many naÃ¯ve DDD practitioners think. I like to believe that DDD experts know this very well, and view any DDD material as a starting point, not an end result â€“ but if all youâ€™re doing is applying the by-the-book definition of existing DDD terms, and trying to shoe-horn any problem into this existing structure, yours is a very sad designerâ€™s life.</p>
<p>There is a life beyond DDD. Not every good design needs to be Domain-Driven (though I can accept it should always be driven by the domain, just not necessarily in the DDD sense). You can design good systems even if youâ€™re not a DDD expert.</p>

</div></div>]]>
            </description>
            <link>https://tilkov.com/post/2021/03/01/ddd-is-overrated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312652</guid>
            <pubDate>Tue, 02 Mar 2021 07:08:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed Is the Killer Feature]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 51 (<a href="https://news.ycombinator.com/item?id=26312516">thread link</a>) | @bdickason
<br/>
March 1, 2021 | https://bdickason.com/posts/speed-is-the-killer-feature/ | <a href="https://web.archive.org/web/*/https://bdickason.com/posts/speed-is-the-killer-feature/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		        
<p>Do you remember your first time using a modern smartphone? A vibrant screen that responded instantly when you tapped replaced cramped keyboards. You could sign your name, drag and drop apps around the screen, and even spin the giant Price is Right wheel to set your alarm. In 2007, this felt like a the future. There's a reason it was called 'the Jesus phone.'</p>
<p>At that same time, The Motorola Razr (<a href="https://www.youtube.com/watch?v=4_IK295sfxQ">video</a>) was the top phone on the market. It was a flip phone with the ability to take photos, play videos, browse the web, and play music. Sound familiar?</p>
<p>Phones in 2007 had the same features as the iPhone. The Palm Treo (<a href="https://www.youtube.com/watch?v=nK7FvGz4Jkc">video</a>) even had a touch screen.</p>
<img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/smartphones-2007.png">
<p>The difference was <em>speed</em>.</p>
<p>When you touched a Razr or a Palm phone, there was a delay. It felt sluggish and slow. Apple removed the delay between your finger tapping the screen and something happening. Your finger could finally manipulate the UI in realtime, just like in the real world. It felt magical. If there was even a slight delay, the whole experience fell apart.</p>
<p><strong>Speed is a killer feature. Speed is a differentiator.</strong></p>
<p>Yet teams consistently overlook speed. Instead, they add more features (which ironically make things slower). Products bloat over time and performance goes downhill.</p>
<p>New features might help your users accomplish something extra in your product.
<strong>Latency stops your users from doing the job they already hire your product for.</strong></p>
<p>Slow ui acts like tiny papercuts. Every time we have to wait, we get impatient, frustrated, and lose our flow.</p>
<h2>Honestly assess your speed</h2>
<p>I want you to take a moment and approach your product with a fresh set of eyes: Eyes for speed  ðŸ‘€</p>
<p>Go through your onboarding flow and try your core product features. Take mental note of how long each step takes to appear on the page then to be interactive.</p>
<p>How slow is it?
Be honest.
Itâ€™s ok, Iâ€™ve been there too.</p>
<p>Does your checkout page take 10+ seconds to load? Did you have to wait for a loading indicator multiple times along the way? Did things look interactive but werenâ€™t loaded yet?</p>
<p>Every one of these is an opportunity. The great thing about speed (also called â€˜performanceâ€™) is that you can stack rank it and burn it down.</p>
<p>Imagine what your product would feel like if everything happened in real time.</p>
<p><img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/speed-keanu-sandra.png"></p><p>Be like Keanu and fix every slowdown in your product. Your users will thank you.</p>
<h2>Places where speed matters</h2>
<ul>
<li>Speed during Checkout - Every second of page load time kills conversion rates. A 1 second delay <a href="https://neilpatel.com/blog/loading-time/">reduces conversion rate by 7%</a>.</li>
<li>Framerate in Virtual Reality - The early days of Virtual Reality caused intense nausea akin to motion sickness <a href="https://link.medium.com/QyheLe9rbeb">when framerates dropped below 60fps</a>.</li>
<li>Design Tools - Users are consistently frustrated when Sketch or Figma are slow. <a href="https://quizlet.com/blog/everything-i-know-about-design">Designers have high APM</a> (actions per minute) and a small slowdown can occur 5-10 times per minute.</li>
<li>The core interaction of your product - Your product exists to save people time or help them solve a problem. Introducing friction or delay during the most important flow of your product will drive people crazy. Notion has developed a reputation for being a sluggish product:</li>
</ul>
<img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/reddit-notion.png">
<h2>Perception vs. Reality</h2>
<p>If you canâ€™t speed up a specific action, you can often fake it. Perceived speed is just as important as actual speed. Even if you canâ€™t be fast, you should appear to be fast.</p>
<p><strong>Large content</strong> - Render the screen while content loads so the user knows whatâ€™s coming.
<strong>Long load times</strong> - Make the screen interactive, even if everything hasnâ€™t loaded.
<strong>Waiting for an action</strong> - Allow the user to take the action and keep moving but post the action in the background.
<strong>Very long actions</strong> - If you have an action that will take 30s or more, offer to notify the user (e.g. via email) when the action is available.</p>
<p>Here are some examples of products that fake being fast:</p>
<ul>
<li>Facebookâ€™s app pioneered loading images that look like actual content. The structure and UI of the page loads but the content does not. As a result, you can still use the product and prepare to take actions, even if the content hasnâ€™t loaded.</li>
<li>Games have a rule to never block the input thread. You can slow down the visuals but the controls should always feel responsive so the user feels in control.</li>
<li>Robinhood has you swipe up to trade, but runs your transaction in the background and notifies you via email when your trade is complete.</li>
</ul>
<h2>When is it ok to be slow?</h2>
<ul>
<li>When there is a physical constraint that causes things to take a while (e.g. dispensing money from an ATM)</li>
<li>When you want to give people a chance to correct a mistake (e.g. Gmail's "undo" feature)</li>
<li>When a human has to keep up with a machine (e.g. we slow down video game framerates, otherwise the game would run at 60x speed and overwhelm you).</li>
</ul>
<h2>Bonus Fun: What would it be like to live with lag?</h2>
<p>Imagine making breakfast with a 1 second latency added to every action you take. Even something as simple as moving your hands so that an egg rests over a bowl becomes incredibly challenging.</p>
<p><strong>Here's a real life experiment where 0.5-3s of latency was added to everyone's action via a VR headset:</strong></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/_fNp37zFn9Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>This is what we're forcing on people when we ship laggy software. We're making them spend their time waiting for us.</p>
<p><strong>Do you struggle to prioritize speed for your product? I'd love to hear more: <a href="http://twitter.com/bdickason">@bdickason</a></strong></p>
<p><strong>Get my newsletter.</strong>  It features simple improvements you can make to improve your day-to-day PM life. From Product Vision/Strategy to Goals and Metrics to Roadmaps and everything in between.</p>


<center></center>


<p>Soundtrack: <a href="https://www.youtube.com/watch?v=MviNwNKYLN4">Mega Ran &amp; Futurecop! - Slow Down</a></p>

<p> <a href="https://open.spotify.com/playlist/1sjamnHIeKEKqkYVwFtXo9?si=NAShg2i5TzetT69GKQ9Irw">See all songs featured on my site.</a></p>
<p>Post last updated: Feb 25, 2021
</p><h2 id="posts">Posts</h2>
<div>
<ul>
<li>
<p><a href="https://bdickason.com/posts/speed-is-the-killer-feature/">Speed is the killer feature</a> <span>Feb 25, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/manage-your-manager/">How to manage your manager</a> <span>Feb 19, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/social-thinkers-solo-thinkers/">Social thinkers vs. Solo thinkers</a> <span>Feb 11, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/pm-lead-massive-projects-writer-editor/">How top silicon valley PM's lead massive projects</a> <span>Feb 4, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/hardware-release-software-release/">How great hardware and software teams ship</a> <span>Jan 21, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/most-pms-dont-use-their-product/">Most PM's don't use their own product</a> <span>Jan 15, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/the-best-product-management-books-articles/">The Best Product Management books, articles, and videos</a> <span>Jan 8, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/gather-great-feedback-from-power-users/">How to gather great feedback from your power users</a> <span>Jan 4, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/biggest-pm-learning-2020-set-an-intention/">Set an intention for the year (and tell everyone)</a> <span>Dec 27, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/strategy-write-great-prereads/">Write great pre-reads and land your strategy</a> <span>Dec 21, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/write-things-down/">Write Things Down</a> <span>Dec 2, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/strategy-101-unpack-your-assumptions/">Strategy 101: Unpack your assumptions</a> <span>Nov 19, 2020</span></p>
</li>
</ul>
</div>

		


	  </div></div>]]>
            </description>
            <link>https://bdickason.com/posts/speed-is-the-killer-feature/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312516</guid>
            <pubDate>Tue, 02 Mar 2021 06:40:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element Matrix Services Announces Element Home]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 43 (<a href="https://news.ycombinator.com/item?id=26311801">thread link</a>) | @decrypt
<br/>
March 1, 2021 | https://element.io/blog/element-home/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-home/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>Weâ€™ve launched a brand new version of Element, called <a href="https://element.io/element-home">Element Home</a>!<br></p><p>Itâ€™s the Element app, but faster, personalised and under your control - all packaged up so you donâ€™t have to worry about how it works! You can just enjoy the fact you know you chose someone you trust (us!) with your data.<br></p><p>So that you know, hereâ€™s whatâ€™s going on behind the scenes with Element Home; in practice youâ€™re getting your own fully managed, dedicated server alongside your Element app. It means you have a notably faster service than when using a typical free public server - youâ€™re saved the hassle of self-hosting and itâ€™s guaranteed to be kept updated with the very latest and greatest Matrix hosting best practices.<br></p><div><p>On top of faster messaging, Element Home comes with five user accounts. Itâ€™s the ideal way for a family, or groups of friends, to get a super-quick professionally hosted version of Element.</p><p><strong>A new type of messenger</strong></p></div><p>As you know, Element is completely different to most messaging apps. <br></p><p>Because Element is <strong>decentralised</strong>, the app itself (what you see) is separate from the Matrix hosting service behind it (what you donâ€™t see; the movement of messages and where they are stored).<br></p><p>Thatâ€™s important because it lets users decide where their messages and data are kept. In owning that choice, you also get to own your data and messages rather than having them sucked up into the likes of Facebook Messenger, Signal, Telegram or WhatsApp.<br></p><p>Some people choose to host themselves, and thatâ€™s great. As it requires some technical knowledge, many others choose to use a free public hosting service such as Matrix.org to get up and running.<br></p><p>Element Home is a third option; the ability to pay for a fully managed, dedicated server (aka a â€˜homeserverâ€™). Being a dedicated server, it devotes itself to just a handful of users; and thatâ€™s why itâ€™s so much quicker than a typical free public server that constantly juggles thousands of users.</p><p><strong>There are many messaging apps, but surprisingly little choice.</strong></p><figure><img src="https://element.io/blog/content/images/2021/02/Comparison-table-8--1-.png" alt="" srcset="https://element.io/blog/content/images/size/w600/2021/02/Comparison-table-8--1-.png 600w, https://element.io/blog/content/images/size/w1000/2021/02/Comparison-table-8--1-.png 1000w, https://element.io/blog/content/images/size/w1600/2021/02/Comparison-table-8--1-.png 1600w, https://element.io/blog/content/images/2021/02/Comparison-table-8--1-.png 2108w" sizes="(min-width: 720px) 720px"><figcaption>Element compared with centralised messaging apps.</figcaption></figure><p><br><strong>Free vs $10 per month</strong><br></p><p>As you know, Element and Matrix is all about giving you choice. If you want to use the free version, thatâ€™s completely fine by us!<br></p><p>But hereâ€™s the extra you get in return for a few bucks a month:<br></p><ol><li>Element Home means youâ€™re <strong>hosted by Element Matrix Services</strong> - our Matrix-based hosting platform used by big companies and public sector organisations. You have a <strong>dedicated server</strong> (so youâ€™re sharing minimal infrastructure with anyone else), fully managed and maintained by the most Matrix-savvy team in the world.<br></li><li>Professional-hosting means the service is <strong>notably faster</strong> than when hosted by a typical free public server, and <strong>always fully updated</strong> and maintained.<br></li><li>An Element domain that you can name, so you can make <strong>memorable Matrix IDs</strong> such as @yourfirstname:yoursurname.ems.host. Use your surname as the domain, and itâ€™s perfect for family sharing!<br></li><li><strong>Five Element accounts</strong> - so after using one yourself, youâ€™ll have four more for family or friends - so thatâ€™s <strong>just $2 per user per month</strong> for a super-quick data sovereign messaging service (you can add more users if you wish).</li></ol><figure><img src="https://element.io/blog/content/images/2021/02/Element-Home-custom-IDs.png" alt="" srcset="https://element.io/blog/content/images/size/w600/2021/02/Element-Home-custom-IDs.png 600w, https://element.io/blog/content/images/2021/02/Element-Home-custom-IDs.png 848w" sizes="(min-width: 720px) 720px"><figcaption>Matching IDs for all the family!</figcaption></figure><p><strong>Wishing you could turn back time?!</strong></p><p>If youâ€™re an Element user and youâ€™re self-hosting, or using a typical free public server (such as Matrix.org), you can simply copy your existing account over to Element Home. Currently, you can only do this in the Element web app (weâ€™re working on an equally simple upgrade from within Android and iOS). Once youâ€™ve upgraded your â€˜oldâ€™ account will still be live, so feel free to keep it or delete it as you see fit.<br></p><p>For those not already up and running on Element, just <a href="https://element.io/element-home">sign up for Element Home</a> from here.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-home/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311801</guid>
            <pubDate>Tue, 02 Mar 2021 04:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Assembly Language]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 17 (<a href="https://news.ycombinator.com/item?id=26311722">thread link</a>) | @sidcool
<br/>
March 1, 2021 | https://wolchok.org/posts/how-to-read-assembly-language/ | <a href="https://web.archive.org/web/*/https://wolchok.org/posts/how-to-read-assembly-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why, in 2021, does anyone need to learn about assembly language?
First, reading assembly language is the way to know <em>exactly</em> what
your program is doing. Why, <em>exactly</em>, is that C++ program 1 MiB (say)
instead of 100 KiB? Is it possible to squeeze some more performance
out of that function that gets called all the time?</p><p>For C++ in particular, it is easy to forget or just not notice some
operation (e.g., an implicit conversion or a call to a copy
constructor or destructor) that is implied by the source code and
language semantics, but not spelled out explicitly. Looking at the
assembly generated by the compiler puts everything in plain sight.</p><p>Second, the more practical reason: so far, posts on this blog havenâ€™t
required an understanding of assembly language, despite constant
links to <a href="https://godbolt.org/">Compiler Explorer</a>. By <a href="https://twitter.com/ScottWolchok/status/1361022423399755776">popular
demand</a>,
however, our next topic will be parameter passing, and for that, we
will need a basic understanding of assembly language. We will focus
only on <em>reading</em> assembly language, not writing it.</p><p>The basic unit of assembly language is the <strong>instruction</strong>. Each
machine instruction is a small operation, like adding two numbers,
loading some data from memory, jumping to another memory location
(like the dreaded <a href="https://en.wikipedia.org/wiki/Goto">goto</a>
statement), or calling or returning from a function. (The x86
architecture has <a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">lots of not-so-small
instructions</a>
as well. Some of these are <a href="https://stackoverflow.com/questions/5959890/enter-vs-push-ebp-mov-ebp-esp-sub-esp-imm-and-leave-vs-mov-esp-ebp">legacy
cruft</a>
built up over the 40-odd years of the architectureâ€™s existence, and
others are <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">newfangled
additions</a>. )</p><p>Our first toy example will get us acquainted with simple
instructions. It just calculates the square of the
<a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">norm</a>
of a 2D vector:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and here is the resulting x86_64 assembly from clang 11, <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tQVvQAZPLUwA5YwCNMxEADZSAB1QLC62nsMTQS8fNTorG3sjJxd3JRUw2gYCZmICAONTTkVlTFU/ZNSCCLtHZzdFFLSMoOyFKuLrUujy1wBKRVQDYmQOAHIpAGZrZEMsAGpxQZ1kevx6KexxAAYAQRXV%2BuIDVXGANTzJSYB2WTXxi/HrAlduAH0CcYAPKbPVy6v6W4fxgE9XjbiY4AEQBaw212%2Bj1oJCMDAAjgZUph0BADsgjgA3NonN4fYiYAjdWjjTEAOie4wAVKSKZMZLTftTGWD1iC%2Bh1WCA%2BgBWPqkUx9Zb81DcnRyOTjBRdHqYemDTj8gjc4VtDoAaxAg0GZO1ev1BvcXL63H5guFpFFfX5ChAy1IyqFHNIcFgSDQRg8eHYZAoEA9Xp9KGEok4nGW2So3oIzltEAcKv5DmsqV%2B3MVpA9Ri0BAA8rRWGmnaQsEYRMB2ImS3gCflMZhbcXME88gYY%2Bn%2BddlB2hHgHMRU3osD2CMQ8EYOx0aPQmGwODx%2BIIQ2IJTJew5bZAOqgPIlGwBaXODcb7uZTYESGRySQW%2BJ5RKabQ1LKkcwlKIxYLeXx0Z9f0J%2BO%2BZQuHUuT5HQhTVPomSCHe4FJA0QEtCBlRFH%2BdSIU0H7lJwHTSt0vRcJy3J8gKVZWk8AAcrj7rc4yjOW4xhmSyxkpw4wQLghAkPK2TjHonres4vE4uKV4yEqiZqqQmrarqBoKdqRrcqaZHFlaNp2g6UkujAiAoKggk%2BuQlABkJLgMaG4aRtGsaUAmxbJrQqY9lmOb5oWValuWlbFvgtZqPWjYWs2rbtn0GZdsaFqsH2A7EL8Q79Bao7jpOpDTowLCVguAiSEI5YoKu8ixRu8DbrufgHkeJ5noMF7FTeNpgQ%2BEDmOhr7aEhn7ZCEP7%2BNBtSeN%2BiTdThOQJAUDQdXBiSQY0kTAbB02DS%2B9RFGNIF4TKhG4UIJFmuR3JUTRdGWcATGcCxbEcVxRDELxpD8YZgbCUMkiicVklOtJsk6opin7Sah3qdymn2o6qrEX0kggxaGnaT9HT1sQPgaNwQA%3D%3D">via Compiler Explorer</a>:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><div><pre><code data-lang="asm">        <span>imulq</span>   %rdi, %rdi
        <span>imulq</span>   %rsi, %rsi
        <span>leaq</span>    (%rsi,%rdi), %rax
        <span>retq</span>
</code></pre></div><p>Letâ€™s talk about that first instruction: <code>imulq %rdi, %rdi</code>. This
instruction <a href="https://www.felixcloutier.com/x86/imul">performs signed integer
multiplication</a>. The <code>q</code>
suffix tells us that it is operating on 64-bit quantities. (In
contrast, <code>l</code>, <code>w</code>, and <code>b</code> would denote 32-bit, 16-bit, and 8-bit,
respectively.) It multiplies the value in the first given register
(<code>rdi</code>; register names are prefixed with a <code>%</code> sign) by the value in
the second register and stores the result in that second
register. This is squaring <code>v.x</code> in our example C++ code.</p><p>The second instruction does the same with the value in <code>%rsi</code>, which
squares <code>v.y</code>.</p><p>Next, we have an odd instruction: <code>leaq (%rsi,%rdi), %rax</code>. <code>lea</code>
stands for â€œload effective addressâ€, and it stores the address of the
first operand into the second operand. <code>(%rsi, %rdi)</code> means â€œthe
memory location pointed to by <code>%rsi + %rdi</code>â€, so this is just adding
<code>%rsi</code> and <code>%rdi</code> and storing the result in <code>%rax</code>. <code>lea</code> is a quirky
x86-specific instruction; on a more
<a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC</a>-y
architecture like ARM64, we would expect to see a plain old <code>add</code>
instruction.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><p>Finally, <code>retq</code> returns from the <code>normSquared</code> function.</p><p>Letâ€™s take a brief detour to explain what the registers we saw in our
example are. Registers are the â€œvariablesâ€ of assembly
langauge. Unlike your favorite programming language (probably), there
are a finite number of them, they have standardized names, and the
ones weâ€™ll be talking about are at most 64 bits in size. Some of them
have specific uses that weâ€™ll see later. I wouldnâ€™t be able to rattle
this off from memory, but <a href="https://en.wikipedia.org/wiki/X86-64#Architectural_features">per
Wikipedia</a>,
the full list<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> of 16 registers on x86_64 is <code>rax</code>, <code>rcx</code>, <code>rdx</code>, <code>rbx</code>,
<code>rsp</code>, <code>rbp</code>, <code>rsi</code>, <code>rdi</code>, <code>r8</code>, <code>r9</code>, <code>r10</code>, <code>r11</code>, <code>r12</code>, <code>r13</code>,
<code>r14</code>, and <code>r15</code>.</p><p>Now, letâ€™s extend our example to debug print the <code>Vec2</code> in <code>normSquared</code>:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
<span>    <span>void</span> <span>debugPrint</span>() <span>const</span>;
</span>};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
<span>    v.debugPrint();
</span>    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and, again, letâ€™s see <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEJICcpLegAyeWpgByxgEaZiIAGykADqgWE6rR6hiaCfgFqdHYOzkZuHt5KKlG0DATMxAQhxqYWisqYqkHpmQQxTq7uXooZWTlhnLVlFXEJXgCUiqgGxMgcAORSAMz2yIZYANTiwzrICgT49DPY4gAMAILrGwvEBqqTAGpFktMA7LKbk9eT9gSe3AD6BJMAHjOXGze39A/PkwBPD7bb4AN1QeHQkywLgMwAACsQ7hAOpM0LQFsDNuIzgARLFbTZ3P4vWgkIwMACOBkymHQEGOyFOoNROM%2BYIAdDC4YjkR0Cd9iJgCL1aJNQRzXpMAFTiyXTGRygEypUEnG4gZdVggAYAVgGpFMAzWBtQOp0cjkkwUPT6mAVw04BoIOpNHS6AGsQMNhhyff6A4HvNqBtwDUaTaQzQMDQoQGtSC7jZrSHBYEg0EYfHh2GQKBBM9ncyhhKJOJw1k0qDmCO44xAXK6DS57JkATqnaRM0YtAQAPK0Vjt5OkLBGETAdhN0d4IXFUGYOMjzCvIoGWsdg13ZSboR4FzENt6LC7ghIoybro0ehMNgcHj8QSlsSWmR7lxxyBdVA%2BVJLgC0fbDJM/4LOgMy4hIMhyJIkbJEUqSaNoDSmE01itFUHhNBEgR0Ch4T%2BLhtAYfE1RNPBxR0KU9T6LkggUak1HlPYlSkVhzQ0aEqEccxsSYVwXQ2r0/QCUIOr6oa07Rq8AAcnj/g8aLPpM5YcmsHKcJMEC4IQJAOk0kx6FmObuPpqIWtBMjOk27qkF6Pp%2BoGTk%2BsGOphpJI7RrG8aJjZqYwIgKCoMZubkJQhYmR44wTuWlakNWrC1sQ9aNiOLa0G2u7dr2A5DtOY4TlOI74HOagLkukYrmuG4DJ224hpGrD7oexAAsegyRmeeAXrVKbXowLBTg%2BAiSEIE4oK%2B8hNR%2B8Dfr%2BQQAUBIFgRBUGyDIsGxoUlGmBA1j4Zwo3oSxbRkcMviEakB2jThqQke0nDnQxJR1NktGNKNz1Ua991nTx108b9WHDIJtoiZwWrieGUk6rJ8mKdFogqZwakaVpOlEMQ%2BmkIZwVFqZIySOZk3Wcmtn2b6znOWJobQ55OreQmSZupDAySHTkZeb5ZNdAuyVBCA3BAA">the generated assembly</a>:</p><div><pre><code data-lang="asm">        <span>subq</span>    <span>$24</span>, %rsp
        <span>movq</span>    %rdi, <span>8</span>(%rsp)
        <span>movq</span>    %rsi, <span>16</span>(%rsp)
        <span>leaq</span>    <span>8</span>(%rsp), %rdi
        <span>callq</span>   <span>Vec2</span>::<span>debugPrint</span>() <span>const</span>
        <span>movq</span>    <span>8</span>(%rsp), %rcx
        <span>movq</span>    <span>16</span>(%rsp), %rax
        <span>imulq</span>   %rcx, %rcx
        <span>imulq</span>   %rax, %rax
        <span>addq</span>    %rcx, %rax
        <span>addq</span>    <span>$24</span>, %rsp
        <span>retq</span>
</code></pre></div><p>In addition to the obvious call to <code>Vec2::debugPrint() const</code>, we have
some other new instructions and registers! <code>%rsp</code> is special: it is
the â€œstack pointerâ€, used to maintain the <a href="https://en.wikipedia.org/wiki/Call_stack">function call
stack</a>. It points to the
bottom of the stack, which grows â€œdownâ€ (toward lower addresses) on
x86. So, our <code>subq $24, %rsp</code> instruction is making space for three
64-bit integers on the stack. (In general, setting up the stack and
registers at the start of your function is called the <a href="https://en.wikipedia.org/wiki/Function_prologue">function
prologue</a>.) Then, the
following two <code>mov</code> instructions store the first and second arguments
to <code>normSquared</code>, which are <code>v.x</code> and <code>v.y</code> (more about how parameter
passing words in the next blog post!) to the stack, effectively
creating a copy of <code>v</code> in memory at the address <code>%rsp + 8</code>. Next, we
load the address of our copy of <code>v</code> into <code>%rdi</code> with <code>leaq 8(%rsp), %rdi</code> and then call <code>Vec2::debugPrint() const</code>.</p><p>After <code>debugPrint</code> has returned, we load <code>v.x</code> and <code>v.y</code> back into
<code>%rcx</code> and <code>%rax</code>. We have the same <code>imulq</code> and <code>addq</code> instructions as
before. Finally, we <code>addq $24, %rsp</code> to clean up the 24
bytes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> of stack space we allocated at the start of
our function (called the <a href="https://en.wikipedia.org/wiki/Function_prologue#Epilogue">function
epilogue</a>),
and then return to our caller with <code>retq</code>.</p><p>Now, letâ€™s look at a different example. Suppose that we want to print
an uppercased C string and weâ€™d like to avoid heap allocations for
smallish strings.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> We might write something like
the following:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdio&gt;</span><span>
</span><span>#include</span> <span>&lt;cstring&gt;</span><span>
</span><span>#include</span> <span>&lt;memory&gt;</span><span>
</span><span></span>
<span>void</span> <span>copyUppercase</span>(<span>char</span> <span>*</span>dest, <span>const</span> <span>char</span> <span>*</span>src);

<span>constexpr</span> size_t MAX_STACK_ARRAY_SIZE <span>=</span> <span>1024</span>;

<span>void</span> <span>printUpperCase</span>(<span>const</span> <span>char</span> <span>*</span>s) {
    <span>auto</span> sSize <span>=</span> strlen(s);
    <span>if</span> (sSize <span>&lt;=</span> MAX_STACK_ARRAY_SIZE) {
        <span>char</span> temp[sSize <span>+</span> <span>1</span>];
        copyUppercase(temp, s);
        puts(temp);
    } <span>else</span> {
        <span>// std::make_unique_for_overwrite is missing on Godbolt.
</span><span></span>        std<span>::</span>unique_ptr<span>&lt;</span><span>char</span>[]<span>&gt;</span> temp(<span>new</span> <span>char</span>[sSize <span>+</span> <span>1</span>]);
        copyUppercase(temp.get(), s);
        puts(temp.get());
    }
}
</code></pre></div><p>Here is <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEAHZeW9ABk8tTADljAI0zEuANlIAHVAsLqtHqGJua8vv5qdLb2Tkau7pxeSipRtAwEzMQEwcamForKmKqBGVkEMY4ubp6Kmdm5oQUK9RV2VfE1SQCUiqgGxMgcAORSAMx2yIZYANTiYzrILfio89jiAAwAguOT05hzC0sExHbAa5s7khO0Uwaz8zpGmEYkAJ4X25cAbqh46DM0N43gBVbzeNwsJQQZAILIzABUWBapEBdBagLhxERCkG3Xmsi%2B2zQtBamAAHt5sf4AF6YAD6BBmAFktgANekMAAqWx0AGl6VsAEpCrYATU5AEkAFrYQ4AERmnA2km4BMuPz%2BAKpdgIYIhxB0zGhJIxsPhCIU3TmZkJWxmDpmzAMRBmCgYeDpCrdJ3YtAgVvV20dMzwVBmAY9Xse80VrI53N5AuFoolDBl2Gt4ltlxDIfN2IIL284gArNJ3Z6DnIlWX5UH7XmHUDQeDIcbMBAi0ZvKjA2M7U2Hd4XQou8X8QPc47s4rlEobYOhwB6Zc%2B9AgEBGZgAawZBloeAAjgYGTRiPTUN83AB3U5F0MKGZGPAKfyiGZ0GZ6Ht4djY7BKVYEg3AAOmnJtlk3A9j1PelvBOR4CzLWRS3rMY5W7bwIHsG9MSyFDK2jGRazQyclybFt9XbaEsNA4BMAICBejdciILzEcCDHOiGKY7o2ODGczHrL5hOGXpWBAYZS2GUhTGGDZZNQKSdDkGsFH6QZq2uThZIIKTFP40gdxAbgxlAsZlTGABOMxS1LMZSySAAOSQhCk7hZPkxTSGU4ZZIUEANlIfSFPE0g4FgJA0F/f9yEoGLvD/GophEYBOGVThSCoP8i2IQKIGcAzZOcOwsjeKTdNIGLnnoAB5WhWAqsLSCwbdRHYYrWrwYhijUa9ApailihdEYqt1ZRKtk1g8GcYhyr0LAppC04jCm3oaHoJg2A4Hh%2BEEYRRBQNSZCEWbAsgXpUAQwJBoAWjqsYZju5ZYwkGQ5EkDZnqoWhUDu69VBIKsfr%2Bu6D2IfRWDu4DrqfO7fv%2Bikhhu9EAqKEoNAgKxGlMLKrEqOIEkECIAjoXGSb8MnaEJ6pEkKVJSlaCmspSPqmfKWnOnplpyhZupOfaImul6DSBiGLgJKkmS5K6vzyWcjw7o8bhAUO4AlU4UCNlAzgI1wQgSDmHTUR/JL/2NyzrVUj6ZD04qjJMsZzMkUszNLMxrI2MxnIc653OGTzZZavyAqCkKHYimBEBQVBYrceKYTj82UvVjKNiynLWDygqipa0raHK5aaq0AgGqarq2rSzqWvwXqSgGrrhuQUblomySWpmuaFowEYfJOPA1uGXSNroRgWE6vaBDc9Xjtt%2BQu4u5jfNR0kpIep6XoIdA3pO6QvtB/7AaIU4vQRsGIahmHUDhw%2B7uRzBV4UdHGaxnH9DyQQCaFunKciQJ%2BakzSFzYmrMMZpDKA0D%2BoQwGv3SK0EBXQBZQJCHjZBbRYi/04KLTSEtsEBxlt5JSUkFZKxVmrNKmtta631vgE%2BlssrfmTslbE4xJDWz3vbMKjsQDXFAu7VU3AHKK0kNZaypYZ4eS8nLKSYdgqhUMlLYYkhpEh1kRHbhvRrz5UCKZIAA%3D">the generated assembly</a>:<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p><div><pre><code data-lang="asm"><span>printUpperCase</span>(<span>char</span> <span>const</span>*):                  <span># @printUpperCase(char const*)
</span><span></span>        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
        <span>callq</span>   <span>strlen</span>
        <span>leaq</span>    <span>1</span>(%rax), %rdi
        <span>cmpq</span>    <span>$1024</span>, %rax                     <span># imm = 0x400
</span><span></span>        <span>ja</span>      <span>.LBB0_2</span>
        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
.LBB0_2:
        <span>callq</span>   <span>operator</span> <span>new</span>[](<span>unsigned</span> <span>long</span>)
        <span>movq</span>    %rax, %rbx
        <span>movq</span>    %rax, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %rbx, %rdi
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>jmp</span>     <span>operator</span> <span>delete</span>[](<span>void</span>*)                          <span># TAILCALL
</span></code></pre></div><p>Our function prologue has gotten a lot longer, and we have some new
control flow instructions as well. Letâ€™s take a closer look at the
prologue:</p><div><pre><code data-lang="asm">        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
</code></pre></div><p>The <code>pushq %rbp; movq %rsp, %rbp</code> sequence is very common: it pushes
the <a href="https://en.wikipedia.org/wiki/Call_stack#FRAME-POINTER">frame
pointer</a>
stored in <code>%rbp</code> to the stack and saves the old stack pointer
(which is the new frame pointer) in <code>%rbp</code>. The following four
<code>pushq</code> instructions store registers that <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#System_V_AMD64_ABI">we need to save before
using</a>.<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>
Finally, we save our first argument (<code>%rdi</code>) in <code>%r14</code>.</p><p>On to the function body. We call <code>strlen(s)</code> with <code>callq strlen</code> and
store <code>sSize + 1</code> in <code>%rdi</code> with <code>lea 1(%rax), %rdi</code>.</p><p>Next, we finally see our first <code>if</code> statement! <code>cmpq $1024, %rax</code> sets
the <a href="https://en.wikipedia.org/wiki/FLAGS_register">flags register</a>
according to the result of <code>%rax - $1024</code>, and then <code>ja .LBB0_2</code>
(â€œjump if aboveâ€) transfers control to the location labeled <code>.LBB0_2</code>
if the flags indicate that <code>%rax &gt; 1024</code>. In general, higher-level
control-flow primitives like <code>if</code>/<code>else</code> statements and loops are
implemented in assembly using conditional jump instructions.</p><p>Letâ€™s first look at the path where <code>%rax &lt;= 1024</code> and thus the branch
to <code>.LBB0_2</code> was not taken. We have a blob of instructions to create
<code>char temp[sSize + 1]</code> on the stack:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
</code></pre></div><p>We save <code>%rsp</code> to <code>%r15</code> and <code>%rbx</code> for later
use.<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> Then, we add 15 to <code>%rdi</code> (which,
remember, contains the size of our array), mask off the lower 4 bits
with <code>andq $-16, %rdi</code>, and subtract the result from <code>%rbx</code>, which we
then put back into <code>%rsp</code>. In short, this rounds the array size up to
the next multiple of 16 bytes and makes space for it on the stack.</p><p>The following block simply calls <code>copyUppercase</code> and <code>puts</code> as written in the code:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
</code></pre></div><p>Finally, we have our function epilogue:</p><div><pre><code data-lang="asm">        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
</code></pre></div><p>We restore the stack pointer to deallocate our variable-length array
using <code>leaq</code>. Then, we <code>popq</code> the registers we saved during the
function prologue and return control to our caller, and we are done.</p><p>Next, letâ€™s look at the path when <code>%rax &gt; 1024</code> and we branch to
<code>.LBB0_2</code>. This path is more â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolchok.org/posts/how-to-read-assembly-language/">https://wolchok.org/posts/how-to-read-assembly-language/</a></em></p>]]>
            </description>
            <link>https://wolchok.org/posts/how-to-read-assembly-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311722</guid>
            <pubDate>Tue, 02 Mar 2021 03:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National Security Commission on Artificial Intelligence's Final Report]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 43 (<a href="https://news.ycombinator.com/item?id=26311616">thread link</a>) | @AndrewKemendo
<br/>
March 1, 2021 | https://www.nscai.gov/2021-final-report/ | <a href="https://web.archive.org/web/*/https://www.nscai.gov/2021-final-report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><div data-elementor-type="wp-page" data-elementor-id="419" data-elementor-settings="[]"><div><div><section data-id="234355d" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="d8c7098" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><section data-id="deac5bd" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="8ba7a06" data-element_type="column"><div><div><div data-id="d57a85d" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg" data-elementor-open-lightbox="yes" data-elementor-lightbox-title="final-repor__screenshot-1"> <img width="732" height="412" src="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg" alt="" loading="lazy" srcset="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg 732w, https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1-300x169.jpg 300w" sizes="(max-width: 732px) 100vw, 732px"> </a></p></div></div><div data-id="cd4d96d" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg" data-elementor-open-lightbox="yes" data-elementor-lightbox-title="final-repor__screenshot-3"> <img width="732" height="412" src="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg" alt="" loading="lazy" srcset="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg 732w, https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3-300x169.jpg 300w" sizes="(max-width: 732px) 100vw, 732px"> </a></p></div></div></div></div></div><div data-id="4cf2c23" data-element_type="column"><div><div><div data-id="0d42a7d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The mandate of the National Security Commission on Artificial Intelligenceâ€™s (NSCAI) is to make recommendations to the President and Congress to â€œadvance the development of artificial intelligence, machine learning, and associated technologies to comprehensively address the national security and defense needs of the United States.â€</p><p>This Final Report presents the NSCAIâ€™s strategy for winning the artificial intelligence era. The 16 chapters in the Main Report provide topline conclusions and recommendations. The accompanying Blueprints for Action outline more detailed steps that the U.S. Government should take to implement the recommendations.</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="06674a1" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="5e2210f" data-element_type="column"><div><div><div data-id="dc57494" data-element_type="widget" data-widget_type="text-editor.default"><div><p>From quick bites to in depth interviews, hear from leading artificial intelligence and United States defense experts, including insights on how to move recommendations to crucial actions. New podcasts from our latest series, Highlights from 2020 Quarterly Recommendations, will be shared weekly.</p></div></div></div></div></div><div data-id="848e99b" data-element_type="column"><div><div><div data-id="222fe7f" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Read our COVID white paper series, including:</p><ul><li><span>The Role of AI Technology in Pandemic Response and Preparedness: Recommended Investments and Initiatives</span></li><li><span>Mitigating Economic Impacts of the COVID-19 Pandemic and Preserving U.S. Strategic Competitiveness in AI</span></li><li><p><span>Privacy and Ethics Recommendations for Computing Applications Developed to Mitigate COVID-19</span></p></li></ul></div></div></div></div></div></div></div></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://www.nscai.gov/2021-final-report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311616</guid>
            <pubDate>Tue, 02 Mar 2021 03:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract Tables from PDF/Images]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26311562">thread link</a>) | @nishparadox
<br/>
March 1, 2021 | https://docsumo.com/free-tools/extract-tables-from-pdf-images | <a href="https://web.archive.org/web/*/https://docsumo.com/free-tools/extract-tables-from-pdf-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-tool"><div><div><p>Automated table extraction from pdf &amp; images</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>It doesn't support in mobile view. <br>You can copy the link and view it in your desktop.</p></div><div id="rating-section"><div id="rating-block"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div><div><p>How it works?</p><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa7831743ca77a6aa3ee11_Choose%20File.png" loading="lazy" width="93" alt=""></p><div><p>1. Choose File</p><p>Select or drop the files you want to convert.<br></p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa628aeb96926ffa789a4f_edit%20%20and%20review.png" loading="lazy" width="101" alt=""></p><div><p>2. Edit &amp; Review</p><p>Review the extracted information in the review panel and make changes if needed.</p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa629ae8714b4bf57f0719_Convert%20%26%20Download.png" loading="lazy" width="101" alt=""></p><div><p>3. Convert &amp; Download</p><p>Download the converted file. Right after that, the input file is removed from our server.</p></div></div></div></div><div><p>Extract tables from PDF/Images</p><p>Save your crucial time and prevent any error from occurring with Docsumo's free table extraction from a PDF/Image tool. With this tool, extract tables from PDF documents and images in real-time with 100% accuracy.</p></div><div><p>Questions we often hear</p><p>Let's look at the answers</p><div><div role="list"><div role="listitem"><div><div><div><h4>Why do I need to extract tables from a PDF document?</h4></div><p>Tables are cleaner data format, and often you need only the data from tables embedded in a pdf document. That's why, businesses find it useful to extract tables from pdf documents and process the data.</p></div></div></div><div role="listitem"><div><div><div><h4>Do I need to train this free table extractor from pdf tool?</h4></div><p>The efficiency of Artificial Intelligence and Machine Learning technology improves with number of sample documents processed. So, it is highly recommended to have at least couple of sample documents ready for training.</p></div></div></div><div role="listitem"><div><div><div><h4>What fields does it capture?</h4></div><p>The tool lets you capture any text based field. The tool allows you to review the extracted data before downloading the output.</p></div></div></div><div role="listitem"><div><div><div><h4>Can I convert my document without installing the software?</h4></div><p>Documo's free online OCR tool is capable of processing any document online with complete accuracy. So, there is no need to install the tool on your system.</p></div></div></div><div role="listitem"><div><div><div><h4>Is my data secure with Docsumo?</h4></div><p>Docsumo doesn't sell or share your data to any third-party person or organization. Your data is completely secure and confidential.</p></div></div></div><div role="listitem"><div><div><div><h4>Is there any limit on using the tool?</h4></div><p>There's no usage limit on our free tool. No payment required and no credit card details needed. Sign up with us to get access to more of our resources.</p></div></div></div></div></div></div><div><h2>What Our Customers Are Saying</h2><div><div data-animation="slide" data-nav-spacing="4" data-duration="500" data-infinite="1"><div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1ba58812799fe2bd13_paysense.svg" loading="lazy" height="" alt=""></p><p>â€œWe are using Docsumoâ€™s APIs for automating data capture from bank statements and identity cards while on-boarding customers. It has reduced the time our operations team spends on data entry by manifolds while providing a much better customer experience.â€</p><p>Prashanth Ranganathan</p><p>CEO, Paysense.com</p></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1b531b085edc6c1cbf_Onez.jpeg" loading="lazy" height="" width="25" alt=""></p><p>Since the very beginning everything was fine, they always say â€œAsk anything even if you need support from our developers. The support for initial user was exceptional, even for small users like me.</p><div><p>Dario G</p><p>Operations Manager, Onerz</p></div></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1bf817cf304f90e758_dhanwise.svg" loading="lazy" height="" alt=""></p><p>"With Docsumo we were able to automate invoice processing completely. It has reduced invoice processing time from hours to minutes. Since there is no data entry required, our data extraction accuracy has improved. We highly recommend Docsumo to everyone. "</p><p>Subodh Malgonde</p><p>CEO, DhanWise.com</p></div></div></div></div></div><a href="https://docsumo.com/case-studies"><p>View more Customers Stories</p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f62f7ab382b1fa34db4108a_arrow.svg" loading="lazy" height="" alt=""></a></div><div id="free-trial-form"><div><div><div><h2>Start your free trial</h2><p>Weâ€™d love to show you how you can increase your productivity, process your documents faster and save operations cost!</p></div></div><div><div><div id="formId"><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://docsumo.com/free-tools/extract-tables-from-pdf-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311562</guid>
            <pubDate>Tue, 02 Mar 2021 03:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Literate: A Flexible Literate Programming System]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26311089">thread link</a>) | @cableclasper
<br/>
March 1, 2021 | https://zyedidia.github.io/literate/index.html | <a href="https://web.archive.org/web/*/https://zyedidia.github.io/literate/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- This adds the top navigation bar -->
            


            <!-- Jumbotron -->
            <div>
                
                <p>A Flexible Literate Programming System</p>
            </div>

            <!-- What is Literate Programming -->
            <p>View the literate <a href="https://zyedidia.github.io/literate/literate-source">source code</a> for Literate!
            </p><p>View the literate <a href="https://zyedidia.github.io/literate/website-source">source code</a> for this website!
            </p><p>See the <a href="https://github.com/zyedidia/Literate">Github page</a>.</p>
            
            <h2>What is Literate Programming?</h2>
            <p>Literate programming is a style of programming invented by Donald Knuth, where the main idea is
            that a program's source code is made primarily to be read and understood by other people, and
            secondarily to be executed by the computer.</p>
            
            <p>This frees the programmer from the structure of a program imposed by the computer and means that
            the programmer can develop programs in the order of the flow of their thoughts.</p>
            
            <p>A Literate program consists of explanation of the code in a natural language such as English, interspersed
            with snippets of code to be executed. This means that Literate programs are very easy to understand and share,
            as all the code is well explained.</p>
            
            <p>Literate, a tool for literate programming, will allow you to take a literate source file (<code>*.lit</code>) and
            either <em>tangle</em> the source file which will create a file with executable code, or <em>weave</em> the
            source file, which will generate an HTML document to be read as formatted documentation.</p>

            <!-- What are the features of lit -->
            <h2>Features of this tool</h2><p>
            Literate works with any programming language, generates HTML as output (<a href="https://wkhtmltopdf.org/">which can be converted to pdf</a>),
            and generates readable code. The code that is generated is indented properly and is automatically commented using the titles you have written
            for the code blocks.</p><p>
            Here is the full list of features:</p><ul>
                <li>Supports any language including syntax highlighting and pretty printing in HTML</li>
                <li>Generates HTML as output</li>
                <li>Generates readable code and commented in the target language</li>
                <li>Reports syntax errors back from the compiler to the right line in the literate source</li>
                <li>Runs fast -- wc.lit compiled for me in 7ms for both code and html output</li>
                <li>Markdown based -- very easy to read and write Literate source.</li>
                <li>Automatically generates hyperlinks between code sections</li>
                <li>Formatted output similar to CWEB</li>
                <li>Creates an index with identifiers used (you need to have exuberant or universal ctags installed to use this feature)</li>
                <li>Supports TeX equations with <code>$</code> notation</li>
                <li>Compatible with Vim (<a href="https://github.com/zyedidia/literate.vim" target="_blank">literate.vim</a>)</li>
                <li>Highly customizable</li>
            </ul><p>
            
            You can get started by taking a look at the <a href="https://zyedidia.github.io/literate/manual.html">manual</a>.
            In addition, this website is made with Literate, and the source can be viewed
            <a href="https://github.com/zyedidia/literate-website">here</a>.

        </p></div></div>]]>
            </description>
            <link>https://zyedidia.github.io/literate/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311089</guid>
            <pubDate>Tue, 02 Mar 2021 02:05:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CIAâ€™s Plot to Have Climbers Plant Nuclear-Powered Sensors in the Himalayas]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310527">thread link</a>) | @vinnyglennon
<br/>
March 1, 2021 | https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/ | <a href="https://web.archive.org/web/*/https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico"><p>The year is 1964. The United States and the Soviet Union have narrowly avoided full-scale nuclear destruction and resolved the Cuban Missile Crisis, the Vietnam War looms on the horizon, and Mao Zedongâ€™s Chinaâ€”fresh off a split with the Sovietsâ€”has just successfully blown up its first atomic bomb in a dry lakebed in southeastern Xinjiang, near what is now the <a href="https://www.wildcamels.com/what-we-do/lop-nur-nature-reserve/" target="_blank" rel="noreferrer noopener">worldâ€™s largest reserve for Bactrian camels</a>. </p><p>Chinaâ€™s nuclear test announced the country as the worldâ€™s fifth nuclear-armed nation, though unlike France, the USSR, and the United Kingdom, the Chinese nuclear program was a black box for American intelligence. <a href="http://www2.gwu.edu/~nsarchiv/nukevault/ebb488/docs/Doc%2028%2011-2-64%20inr%20on%20chinese%20test.pdf" target="_blank" rel="noreferrer noopener">Recently declassified government files show</a>, for example, that the U.S. was shocked to learn that the bomb was fueled by uranium, not plutonium. Military-industrial honchos were left scratching their heads as to how to gather intelligence, until a chance meeting between General Curtis LeMay and mountaineer Barry Bishop at a Washington D.C. cocktail party led to one of the most quixotic, unsuccessful operations in the CIAâ€™s long history of screwups.</p><figure><img loading="lazy" width="792" height="612" src="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg" alt="" srcset="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg 792w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=300,232 300w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=768,593 768w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=62,48 62w" sizes="(max-width: 792px) 100vw, 792px"><figcaption><a href="https://nsarchive2.gwu.edu/nukevault/ebb488/docs/doc%2033%201-0-65%20circa%20AFtAC%20report.pdf" target="_blank" rel="noreferrer noopener">An Air Force analysis</a> of nuclear debris scatter, which confirmed the use of enriched uranium. The lower of the two large arrows flows from the Xinjiang test site.</figcaption></figure><p>Bishop was part of the first American team to summit Mt. Everest the year prior, and according to <a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">Pete Takedaâ€™s fascinating 2007 <em>Rock And Ice</em> story</a>, he gushed about the unobstructed views he enjoyed from the worldâ€™s (<a href="https://defector.com/a-geologist-rocks-my-world-on-why-earths-tallest-mountain-isnt-so-obvious/" target="_blank" rel="noreferrer noopener">arguably</a>) tallest mountain. Takeda writes that LeMay put the pieces together and, â€œFrom this casual exchange emerged an unlikely inspiration: Recruit Americaâ€™s best high-altitude climbers to place a nuclear powered observation device atop the worldâ€™s greatest mountain range.â€ The hope was that a transceiver could pick up radio communications between Chinese nuclear personnel, remaining functional for years off of the heat from decaying plutonium isotopes. Per Takeda, the CIAâ€™s device was an â€œoven-sized metal bin with five radiating finsâ€ that weighed 125 pounds and was topped by a six-foot long antenna. If this sounds like a crude product of â€™60s nuclear frenzy, consider that <a href="https://mars.nasa.gov/mars2020/spacecraft/rover/electrical-power/" target="_blank" rel="noreferrer noopener">NASAâ€™s Perseverance rover</a> is scooting around on Mars thanks to this exact sort of battery. </p><p>Bishop could no longer climb high alpine peaks after <a href="https://www.nationalgeographic.com/magazine/article/first-successful-us-everest-summit-took-a-toll-on-barry-bishops-boots" target="_blank" rel="noreferrer noopener">losing all of his toes in the Everest expedition</a>, but by 1965, the CIA started putting together a team, picked a name (Operation Hat), and chose a mountain. Everest straddled Chinaâ€™s border, so it was out of contention. CIA officials eventually chose Nanda Devi, the tallest peak entirely within Indiaâ€™s borders. Nanda Devi offered two advantages to the Americans: long sightlines into Western China and the help of an Indian state that the U.S. had just supported in its 1962 border skirmish with China. </p><p>At this point in history, Nanda Devi had only been summited by six people, with three others dying in the process, so the CIA recruited a dream team of famous American climbers. The corps included pioneering El Capitan big-waller <a href="https://www.nytimes.com/2018/09/12/obituaries/tom-frost-dead.html" target="_blank" rel="noreferrer noopener">Tom Frost</a>, <a href="https://www.nytimes.com/1998/11/07/us/luther-jerstad-61-alpinist-who-scaled-everest-in-1963.html" target="_blank" rel="noreferrer noopener">1963 Everest</a> veteran Lute Jerstad, <em>Sports Illustrated</em> cover darling <a href="https://gripped.com/profiles/jim-mccarthy-was-first-climber-on-sports-illustrated/" target="_blank" rel="noreferrer noopener">Jim McCarthy</a>, and the unsung alpinist <a href="https://www.americanjournalofsurgery.com/article/S0002-9610(16)31088-1/pdf" target="_blank" rel="noreferrer noopener">Robert Schaller</a>. They <a href="https://wikileaks.org/plusd/cables/1978STATE094511_d.html" target="_blank" rel="noreferrer noopener">underwent a training course</a> on nuclear technology and â€œthe Asian mentalityâ€ at a South Carolina military base, though the climbers say they mostly spent time â€œplaying volleyball and doing some serious drinking.â€ <a href="https://wikileaks.org/plusd/cables/1978STATE094511_d.html" target="_blank" rel="noreferrer noopener">The full team undertook a training mission on Mount McKinley</a> in June with their Indian counterparts, and even though â€œdistressing weather and other difficulties kept them from the summit,â€ the CIA â€œchose to ignoreâ€ the omens and the American-Indian team set out for Nanda Devi in October 1965. </p><p>The CIA has not yet declassified files from the expedition, including apparently extensive photographs and journal records made by Schaller, so we do not have a detailed account of what happened on the mountain. But we do know how the mission ended: catastrophic failure. A storm pinned several climbers and the device down while they were roughly 1,800 feet from the summit. Indian intelligence lead Capt. M.S. Kohli was forced to call a retreat, and the team stashed the device in a crevice and attempted to anchor it in place, so it would stay put until they could come and retrieve it on the other side of winter.</p><p>McCarthy spoke at length with Takeda <a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">for the <em>Rock And Ice</em> story</a>â€”which really is great, Takeda makes his own attempt on Nanda Devi and narrowly escapes death by avalancheâ€”and he recalled his fury at the expeditionâ€™s failure:</p><blockquote><p>When I realize that theyâ€™re dumping the fucking generator and going down the mountain, Iâ€™m like, â€˜What the fuck are you doing? Have them bring it down! Are you crazy?â€™ Iâ€™m yelling at the top of my lungs.â€ According to McCarthy, the CIA case officer nearly had to pull him off Kohli. â€œHe says to me,â€ McCarthy says, â€˜You are creating an international incident!â€™â€</p><p>â€œBut,â€ McCarthy adds, â€œI had a vision of absolute clarity. Weâ€™re going to lose a SNAP generator, powered by plutonium, in the headwaters of the Ganges!â€</p><cite><a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">Rock And Ice</a></cite></blockquote><p>That might be what wound up happening. Nobody knows where the device ended up, since it disappeared from Nanda Devi at some point in the winter. The CIA ran a total of eight field operations in the region between 1965 and 1968, aimed at both finding the first device and getting another one up and running. Though they eventually implanted a plutonium device on nearby Nanda Kot, they have never been able to find their lost transceiver. The successfully placed device was also quickly buried under the snow and stopped working months later, after producing no useful intelligence.</p><p>The grim failure of Operation Hat resurfaced this month after violent floods killed over 50 people in the Indian state of Uttarakhand. The floods <a href="https://www.nytimes.com/2021/02/07/world/asia/india-glacier-flood-uttarakhand.html" target="_blank" rel="noreferrer noopener">most likely began</a> when a chunk of the Nanda Devi glacier broke off and trapped flowing water, forming a lake that eventually burst through and swept through nearby valleys. The undeniable oddness of a glacial breaking apart during the winter has <a href="https://www.bbc.com/news/world-asia-india-56102459" target="_blank" rel="noreferrer noopener">led some locals to speculate</a> that perhaps the plutonium generator, which is still likely producing heat, led to the deadly floods.</p><p>Thereâ€™s no evidence for the hypothesis, though even after years of reconnaissance missions and rigorous chemical assays of the surrounding area, nobody knows where the CIAâ€™s lost nuclear-powered spy oven is. </p></div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310527</guid>
            <pubDate>Tue, 02 Mar 2021 00:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. asks Google for detailed search data in antitrust case]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 83 (<a href="https://news.ycombinator.com/item?id=26310292">thread link</a>) | @johncena33
<br/>
March 1, 2021 | https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The U.S. government has asked Google to fork over granular data on how its search engine works and is monetized, seeking to prove that the internet giant is a monopoly.</p>

<p>The U.S. Department of Justice and several state attorneys general are seeking comparable data on U.S. search results and related ad from Feb. 2, 2015 to Feb. 8, 2015 and from Feb. 3, 2020 to Feb. 9, 2020, according to a legal filing Monday.</p>

<p>The Alphabet Inc. unit is being asked to share data on how and where users searched in those periods, the quantity of different types of ads, revenue from those ads and what the underlying bids were for them, among other details. The government told the company it wants the information within 30 days.</p>

<p>The Justice Department under former U.S. President Donald Trump and 11 Republican attorneys general originally filed the suit. Three other states have since joined, including California, the site of GoogleÃ¢â‚¬â„¢s headquarters. The latest data request shows the government is pressing ahead under a new administration led by Democrat Joe Biden.</p>

<p>The U.S. government alleges GoogleÃ¢â‚¬â„¢s exclusive deals to distribute its search engine on browsers and phones, including Apple Inc.Ã¢â‚¬â„¢s iPhones, violates the Sherman ActÃ¢â‚¬â„¢s prohibition on monopolization. ItÃ¢â‚¬â„¢s the most significant U.S. monopoly case since the one against Microsoft Corp. more than 20 years ago.</p>

<p>Google has said its deals donÃ¢â‚¬â„¢t prevent consumers from switching to other search providers. The company argues its success rests on superior technology.</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310292</guid>
            <pubDate>Tue, 02 Mar 2021 00:10:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gradients on grids of pixels/voxels â€“ forward, central, and diagonal differences]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26309398">thread link</a>) | @bartwr
<br/>
March 1, 2021 | https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<div><figure><img src="https://lh3.googleusercontent.com/BWwSXvV4LN0Ta6HG1XenEDTm5TnwsPcdWZnJbaNH0aYWJRogW-V7D0BujuJwuDa4c6TcfNzLklDJFzeHNl4jNSXiCjr19Qq8scpGCZrnktYSP6Ns_3x1yMI10rKXZyzghqoySdCt" alt=""></figure></div>



<p>In this post, I will focus on <strong>gradients of image signals defined on grids</strong> in computer graphics and image processing. Specifically, gradients / derivatives of images, height fields, distance fields, when they are represented as discrete, uniform grids of pixels or voxels.</p>



<p>Iâ€™ll start with the very basics â€“ what do we typically mean by gradients (as itâ€™s not always â€œstandardizedâ€), what are they used for, what are the ypical methods (forward or central differences), their cons and problems, and then proceed to discuss an interesting alternative with very nice properties â€“ <strong>diagonal gradients</strong>.</p>



<p>My post will conclude with advice on how to use them in practice in a simple useful scheme, how to extend it with a little bit of computations to a super useful concept of a <strong>structure tensor</strong> that can characterize dominating direction of any gradient field, and finish with some signal processing fun â€“ <strong>frequency domain analysis </strong>of forward and central differences.</p>



<h2>Image gradients</h2>



<p>What are image gradients or derivatives? How do you define gradients on a grid?</p>



<p>Itâ€™s not very well defined problem on discrete signals, but the most common and useful way to think about it is inspired by signal processing and the idea of sampling:</p>



<p><strong>Assuming there was some continuous signal that got discretized, what would be the partial derivative with regards to the spatial dimension of this continuous signal at gradient evaluation points?</strong></p>



<p>This interpretation is useful both for computer graphics (where we might have discretized descriptions of continuous surfaces; like voxel fields, heightmaps, or distance fields), as well as in image processing (where we often assume that images are â€œnatural imagesâ€ that got photographed).</p>



<p>Continuous gradients and derivatives used for things like normals of procedural SDFs are also interesting, but a different story. I will not cover those here, and instead recommend you check out <a href="https://www.iquilezles.org/www/articles/normalsSDF/normalsSDF.htm">this cool post</a> by Inigo Quilez with lots of practical tricks (re-reading it I learned about the tetrahedron trick) and advice. I am sure that no matter your level of familiarity with the topic, you will learn something new.</p>



<p>In my post, I will focus on computer graphics, image processing, and basic signal processing takes on the problem. There are two much deeper connections that I havenâ€™t personally worked too much with. So I leave it as something that I wish I can expand my knowledge in the future, but also encourage my readers to explore it:</p>



<p><strong>Further reading one:</strong> The first connection is with <a href="https://en.wikipedia.org/wiki/Partial_differential_equation">Partial Differential Equations</a> and their discretization. Solving PDEs and solving discretized PDEs is something that many specialized scientific domains deal with, and computing gradients is an inherent part of numerical discretized PDE solutions. I donâ€™t know too much about those, but Iâ€™m sure literature covers this in much detail.</p>



<p><strong>Further reading two:</strong> The second connection is <a href="https://en.wikipedia.org/wiki/Wavelet">wavelets</a>, filter banks, and the frequency precision / localization trade-off. This is something used in communication theory, electrical engineering, radar systems, audio systems, and many more. While I read and am familiar with <em>some </em>theory, I havenâ€™t found too many practical uses of wavelets (other than the simplest Gabor ones or in use for image pyramids) in my work, so again Iâ€™ll just recommend you some more specialized reading.&nbsp;</p>



<h2>Applications</h2>



<p>Ok, why would we want to compute gradients? Two common uses:</p>



<p><strong>Compute surface normals </strong>â€“ when we have something like a scalar field â€“ whether distance field describing an underlying implicit surface, or simply a height field, we might want to compute its gradients to compute normals of the surface, or of the heightfield for normal mapping, evaluating BRDFs and lighting etc. Maybe even for physical simulation, collision, or animation on terrain!</p>



<div><figure><img src="https://lh5.googleusercontent.com/u5cS-rFvdRrpN6iFTGYqDYyF8wMLCtB5-5ir2gQVMaQo8DmURyVdqF8Fyedcx9VW5boiVP8QuQZkL8zAEqG8_TYrkqx6b0bkWajLS-8IJykhlmhtxTH_YEXw_xivXSbd_2rPVLcX" alt=""><figcaption><strong>Left: </strong>an example heightmap image, <strong>right:</strong> partial derivatives (exaggerated for demonstration) that can be used for generating normal maps for lighting, collision, and many other uses in a 3D environment.</figcaption></figure></div>



<p><strong>Find edges, discontinuities, corners, and image features</strong> â€“ the other application that I will focus much more on is simply finding image features like edges, corners, regions of â€œdetailâ€ or texture; areas where signal changes and becomes more â€œinterestingâ€. The human visual system is actually built from many <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1350218/">edge detectors and local differentiators</a> and can be thought of as a <strong>multi-scale spatiotemporal gradient analyzer</strong>! This is biologically motivated â€“ when signal changes in space or time, it means itâ€™s a potential point of interest or a threat.</p>



<p>The bonus use-case of just computing the gradients is finding the orientation and description of those features. This is bread and butter of any image processing, but also very common in computer graphics â€“ from morphological anti-aliasing, selectively super-sampling only edges, or special effects. I will go back to it in the description of local features in the <strong>Structure Tensor</strong> section, but for now letâ€™s use the most common application â€“ just using the gradient vector magnitude, used for example in the <strong>Sobel operator</strong>: <img width="131" height="55" src="https://lh4.googleusercontent.com/XNZ1Arqp0sBJFnwkaJY9qxwOnn75NM57llXbo-aLmwwwPLxv93Sr8qWfaOswcKcWnvc1Hy-HGWKrsW9KHj10G-UkqOICr3SYO_Q6cXWvYBIZu5EALhRiSfp-mqrHpg6rjRFXJpAP">.</p>



<div><figure><img src="https://lh6.googleusercontent.com/B3C3hX34jil9a3GVJJY8e051jxZV-K2v2k0UqMIi9MkajBeYnB8LhKFLMlhRph-8Oe8-R5WyPzWyA9W6X6FISmSwvJ4hPf_adGwpA1Niwpn4qCNkLKYVUTk3ZK5rdLb1guiQu5rN" alt=""><figcaption>Gradient magnitude can be used for simple edge detection in an image, but also many more (described later in the post!).</figcaption></figure></div>



<h3>Test signals</h3>



<p>I will be testing gradients on three test images:</p>



<ul><li><strong>Siemens star</strong> â€“ a test pattern useful to test different â€œanglesâ€ and different frequencies,</li><li>A simple <strong>box</strong> â€“ has corners that can immediately show problems,</li><li>1 0 1 0 <strong>stripe</strong> pattern â€“ frequencies exactly at Nyquist.</li></ul>



<div><figure><img src="https://lh5.googleusercontent.com/y4CZ84at7ie-Rg3S_l1OQLy0qhoBmxHJXkZukiypUwb55r4dQWIPwGwG1qsdNyKCYqlhkG1TBsaYxOFTXhOFNsCIh47xyYCF5tvX6EhCAXAqORWSOOcWuxs0dF2nSyjyk_4NQan_" alt=""><figcaption>Test patterns / images</figcaption></figure></div>



<p>The Siemens star was rendered at 16x resolution and downsampled with a <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">sharp antialiasing filter </a>(windowed sinc). There is some aliasing in the center, but itâ€™s ok for our use-case (we want to see a sharp signal change there and then detect it).</p>



<h2>Forward differences</h2>



<p>The first, most intuitive approach is computing <strong>forward difference</strong>.</p>



<p>This is an approximation of <img src="https://lh5.googleusercontent.com/hPi-mgITwovkqTtAMg1LBk4GVXtKJqG15oSJn0MgJqljSZYk1CiM-mHoGYsW36452xxG3f2X9-72nQ2XVrTknF9v0IanFpTiRHsoGzPk-L_uVBComQrtujBayBlq_uDvpnF5HNVF" width="22" height="39"> by computing f(x+1) â€“ f(x).</p>



<p>What I love about this solution is that it is both intuitive, naive, as well as theoretically motivated! I donâ€™t want to rephrase the wikipedia and most of readers of my blog donâ€™t care so much for formal proofs, so feel free to <a href="https://en.wikipedia.org/wiki/Finite_difference">have a look there</a>, or in specialized courses (<strong>side note</strong>: 2010s+ are amazing, with so many best professors sharing their course slides openly on the internetâ€¦). Itâ€™s basically built around the <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor expansion</a> of the f(x+1) â€“ f(x).</p>



<p>This difference operator is the same as <strong>convolving the image with a [-1, 1] filter</strong>.</p>



<p>Itâ€™s easy, works reasonably well, is useful. But there are two bigger problems.</p>



<h3>Problem 1 â€“ even-shift</h3>



<p>If you have <a href="https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/">read my previous blog post</a> â€“ on bilinear down/upsampling â€“ one of challenges might be visible right away. Convolving with an <strong>even-sized filter</strong>, <strong>shifts the whole image </strong>by a half a pixel.</p>



<p>Itâ€™s easily visible as well:</p>



<div><figure><img src="https://lh5.googleusercontent.com/Mep5NBimKpkG1wHi1JFZ64tEeZH-Bavx8qZ9abnfIG8f_-vAvZERVKQs84hUSbPSiYkjVmBzyjWbTgL2oSWWyQTwuO1z2xv98LOjHp4pHsD4C09msAmnU9Z5U5Q4VO1rdAIgI24Q" alt=""><figcaption>Images vs image gradient magnitude. Notice the shift to left/top.</figcaption></figure></div>



<p>Depending on the application, this can be a problem or not. â€œA solutionâ€ is simple â€“ undo it with another even sized filter. Perfect solution would be resampling, but resampling by a half pixel is surprisingly challenging (see my <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">another blog post</a>), so instead we can blur it with a symmetric filter. Blurring the gradient magnitude fixes it (at the cost of blur):</p>



<div><figure><img src="https://lh4.googleusercontent.com/Ki309swxJtWYakp2nypvE4UjcgYC0uHBduyuyWzr_pamfzXFHjSlctrfAx1XPJYjk8LIECMlbRkvumjbT1TJkM225HiIggoy3lnu508mDUyDlHfRB2tog1VY82GLMcP61LK6GOO9" alt=""></figure></div>



<p>Blurring with an even sized filter fixes the even sized shift. But one other problem might have became much more visible right now.</p>



<p>Note: You might wonder, what would happen if we would <strong>blur just the partial differences</strong> instead? We will see in a second.</p>



<p>But letâ€™s focus on another, more serious problem.</p>



<h3>Problem 2 â€“ different gradient positions for partial differences</h3>



<p><strong>Second problem</strong> is more severe; what happens if we compute <strong>multiple partial derivatives</strong>; like df/dx and df/dy this way?</p>



<p><strong>Partial derivatives are approximated at different positions!</strong></p>



<div><figure><img src="https://lh6.googleusercontent.com/l11K2D7VeRoitc_dAIwMoC5WB4RPBdcKcdDtq4ysm9z-0LzJICmias8fhGIZQWvdEzJElkTp2xCMRxn1z5EbbYH5xb7Le2AlPFhr4ynlultytNqtm98b1n9d6f_Etu3mMTxpjUiF" alt=""><figcaption>Notice how gradient being defined between pixels means that two partial forward derivatives are defined at different points! This is a big problem.</figcaption></figure></div>



<p>Now letâ€™s have a look at the same plot again, this time focusing on â€œsymmetryâ€. This shows why itâ€™s a real, not just theoretical issue. If we look at gradients of a Siemens star and the box, we can see some <strong>asymmetry</strong>:</p>



<div><figure><img src="https://lh4.googleusercontent.com/DxZNozMlWMM6xr2c3NejQXpHB9xbiwfs1GyRBeUBQIMoksEisVz5n3jGZs5zWrPZU6xeUvnBaalc3IPTIV8LDoYevY-ZirN-Gsc-XOLwBiGSRzUCuvqIqio3AcmvU5_b1eKzj2aS" alt="" width="507" height="502"><figcaption>Notice left-top gradients being stronger for Siemens star, and producing a â€œholeâ€ on the box corner. Oops.</figcaption></figure></div>



<p>This is definitely not good and will cause problems in image processing or computing normals, but itâ€™s even worse if we look at the gradient magnitude of a simple â€œsquareâ€ in the center of the image â€“ notice what happens to the image corners, <strong>one corner is cut off, and another one 2x too intense</strong>!</p>



<p>This is a big problem for any real application. We need to look at better approximations.</p>



<h2>Central differences</h2>



<p>I mentioned that â€œblurringâ€ partial derivatives can â€œrecenterâ€ them, right? What if I told you that it is also <strong>numerically more accurate</strong>? This is the so-called <strong>central difference</strong>.</p>



<p>It is evaluated by <img data-attachment-id="4275" data-permalink="https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/gif/" data-orig-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif" data-orig-size="155,39" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gif" data-image-description="" data-medium-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif?w=155" data-large-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif?w=155" src="https://bartwronski.files.wordpress.com/2021/02/gif.gif" alt="">. The division by two is important and intuitively can be understood as dividing by the distance between the pixels, or the differential dx, where dx is 2x larger.</p>



<p>When forward difference was an approximation accurate to the O(h), this one is more accurate, to O(h^2). I wonâ€™t explain those terms here, but <a href="https://en.wikipedia.org/wiki/Finite_difference#Relation_with_derivatives">the wikipedia has some basic intro</a>, and in numerical methods literature you can find a more detailed explanation.</p>



<p>It is also <strong>equivalent to â€œblurringâ€ the forward difference with a [0.5, 0.5] filter</strong>! [0.5, 0.5] o [-1, 1] leads to [-0.5, 0, 0.5]. I was initially very surprised by this connection â€“ of a more accurate, theoretically motivated Taylor expansion, and just â€œsome random ad-hoc practical blurâ€. This is even sized blur, so this also fixes the half pixel shift problem and centers both partial derivatives correctly:</p>



<div><figure><img src="https://lh6.googleusercontent.com/QawQ4QcbqusIHhs7S0h2kekS4VQDqHCS_WizBd7dgstoHaLu5Lwj9bx_SbJImHNZnlc_aSs7FCzdYF0RW7oYjTTF3qzfoKiNENFh4yzTiYYt_GSO6lkFe-7lP2GpDs0G9XNYS52O" alt="" width="424" height="420"><figcaption>Central difference leads to perfectly symmetric (though not isotropic) results!</figcaption></figure></div>



<p>Problem â€“ missing centerâ€¦</p>



<p>However, there is another problem. Notice how the â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/">https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309398</guid>
            <pubDate>Mon, 01 Mar 2021 22:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why does an A note sound different across instruments?]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 90 (<a href="https://news.ycombinator.com/item?id=26308241">thread link</a>) | @OmarShehata
<br/>
March 1, 2021 | https://omarshehata.me/notebook/exploring_sound | <a href="https://web.archive.org/web/*/https://omarshehata.me/notebook/exploring_sound">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="notebook">
	
	<p>From <a href="https://omarshehata.me/notebook">Omar's notebook</a>.</p>
	<hr>
	
	
	<p>
		If you pull up a tuner app on your phone and play an A note on a piano, the tuner will say ~440 hz. Do the same thing on a violin's A note and you'll also get 440 hz.  
	</p>
	<p>
		This seemed impossible based on my understanding of sound, which was: 
	</p>
	<ol>
		<li>Our ears perceive sound by picking up on the frequency of the air vibrating around us.</li>
		<li>Two sounds are different if they have different frequencies, in the same way two colors appear different if they emit light of different wavelengths.</li>
		<li>When we say a sound is 440 hz, that means a point vibrating along that sound wave makes a complete cycle 440 times per second.</li>
	</ol>
	<p>
		So if two sound waves have exactly the same frequency, according to my tuner app, they cannot possibly sound different. But they do! Does that mean there's something else, something <i>more</i> than frequency that can differentiate sound? 
	</p>
	<p>
		There isn't! That's all sound is - vibrations in the air of some specific frequency. 
	</p>
	<p>
		Was the tuner lying? Yes, kind of: when we say a sound is 440 hz, that's not actually a complete description of the sound. It's kind of like telling you a shape has 4 points - you might assume it's a square. But it could be a rectangle, or some completely wacky irregular polygon. 
	</p>
	<h2>Visualizing a couple notes</h2>
	<p>
		Here's an A note from a piano and a violin that I recorded from online virtual instruments. 
	</p>
	<p>
		Click "Play" to hear them. Below each is a small slice of the audio. 
	</p>
	
	<p>Drag and drop your own sound file in these diagrams to use it throughout the article.</p>
	<p>
		They look structurally similar, but they're <i>not</i> the same sound wave. They both have a pattern that repeats ~3 times in 9 milliseconds (or ~440 times per second). So that's what makes them both 440 hz.
	</p>
	<p>
		But that pattern itself that repeats is different. This is why saying "A sound is 440 hz" isn't a complete description, so assumption (3) for me was a misunderstanding.
	</p>
	<p>
		Here is what the sound would look like if the speaker vibrated exactly 440 times per second in a continuous, regular, motion.
	</p>
	
	<p>
		The fact that all 3 of these sound different, even though they are all made of a pattern that repeats at 440 hz, tells me I need to tweak assumption (1). Our ears don't pick up on just a single frequency in the air. If they did, these sounds would be indistinguishable (which I think actually happens for our eyes, see <a href="https://en.wikipedia.org/wiki/Metamerism_(color)">metamerism</a>.)
	</p>
	<p>
		So our ears can detect the internal structure of these patterns. To decompose this structure on a computer, we'll use the Fourier transform.
	</p>
	<h3>
		Performing the Fourier Transform
	</h3>
	<p>
		The Fast Fourier Transform (FFT) algorithm allows you to extract frequencies in a signal.
	</p>
	<p>
		Our signal in this case is a list of amplitudes, how loud the sound is at every sample.
	</p>
	<p>
		When you run the signal through like <code>FFT(signal)</code> you get a list numbers that correspond to a list of frequencies. For example, if the FFT output looks like this:
	</p>
	<p><code>
		[0.001, 0.1, 0.7, 0, 12, 0, 2, 1]
	</code></p><p>
		You'll also have a corresponding list of frequencies:
	</p>
	<p><code>
		[0, 55, 110, 220, 440, 880, 1320, 1760]
	</code></p><p>
		We interpret this to mean 440 is the most significant frequency in this signal, because its FFT coefficient is 12 (the largest), and it's the 5th number. And the 5th frequency in our list is 440. 
	</p>
	<p>
		I've found it easiest to interpret the results of FFT by putting it in a table in terms of the original sound frequency and the relative weights (so I divide all of them by the largest number).
	</p>
	<p>
		Below are the FFT results running on our two 9 ms slices. <a id="compute-fft" href="#">Click to expand</a> the chosen slices. You can also scroll back up to change the slices by hand.
	</p>
	<div id="fft-table-container">
		<div id="fft-table-A-container">
			<h4>Piano A note</h4>
			<p>(<span id="piano-fft-slice-number">10</span> ms slice)</p>
			<table id="fft-table-A">
			  <thead>
			    <tr>
			      <th>Freq. (hz)</th>
			      <th>Weight (%)</th>
			    </tr>
			  </thead>
			  <tbody>
				<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
			</tbody>
			</table>
		</div>
		<div id="fft-table-B-container">
			<h4>Violin A note</h4>
			<p>(<span id="violin-fft-slice-number">10</span> ms slice)</p>
			<table id="fft-table-B">
			  <thead>
			    <tr>
			      <th>Freq. (hz)</th>
			      <th>Weight (%)</th>
			    </tr>
			  </thead>
			  <tbody>
			  	<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
			</tbody>
			</table>
		</div>
	</div>
	<p>Frequencies below 1% weight are omitted from this table.</p>
	<p>
		These tables tell us that both sounds do have ~440 hz as the strongest frequency, but there's other frequencies inside too! The violin one appears a lot more complex, in that it seems to contain a lot more frequencies that contribute significantly.
	</p>
	<p>
		The last step is reconstructing the sound from this table. Representing sound this way is really powerful. This is the basis for a lot of sound analysis/transformations like:
	</p>
	<ul>
		<li><b>Compression?</b> Remove the highest frequencies that our ears can't hear as easily. </li>
		<li><b>Noise filtering?</b> Remove specific known frequencies, that's how you can remove the sound of car horns but keep your voice in a recording.</li>
		<li><b>Auto tune?</b> Check which musical note is closest to the list of frequencies in the sound, and alter/remove/add frequencies to make it sound closer to the note.</li>
		<li><b>Voice recognition?</b> You can think of the frequencies you can create by talking as a unique pattern a software can search for. Like how the letter "E" appears ~11% of the time in most English text. We all have a few frequencies in our voices that appear with predictable probability.</li>
	</ul>
	<p>
		Below is a sandbox for you to explore these ideas of sound reconstruction.
	</p> 
	<p>
		The code returns a <code>outputMultipliers</code> array that scales the original frequencies. A new sound is reconstructed from those new frequencies/weights. You can try <a href="#" id="zero-out">zero-ing out all the high frequencies</a>, or isolate <a href="#" id="single-frequency">a single frequency</a>.
	</p>
	<div id="sandbox">
		
		<p><a href="#" id="run-code">Run</a> <span>(shortcut: CTRL+ENTER)</span><br>
		<a href="#" id="reset-code">Reset code</a></p><div id="note-visualization">
			<div id="output-fft-table">
				<h4>Filtered note</h4>
				<table id="fft-table-output">
				  <thead>
				    <tr>
				      <th>Freq. (hz)</th>
				      <th>Weight (%)</th>
				    </tr>
				  </thead>
				  <tbody>
				  	<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
				</tbody>
				</table>
				<p>Frequencies below 1% weight are omitted from this table.</p>
			</div>
			
		</div>	
	</div>
	<h3>
		Takeaways
	</h3>
	<p>
		So the correct version of assumption (3) is: When we say a sound is 440 hz, we mean that's the frequency with the most weight in the signal. To give a complete description of the sound you need to know (1) all the frequencies it's made of and (2) how much of each frequency to use.  
	</p>
	<p>
		I created this to learn how FFT works. This is the end-to-end demonstration I was looking for to help me understand it. It's best used to test your understanding while reading other materials. I don't have the source code up yet but if you'd like to extend this or use it as a teaching tool just let me know! 
	</p>
	<p>
	 	You can drag and drop any sound file in the very first two figures and all figures will update to use it, including the FFT tables and the code sandbox. Here's a few notes from <a href="https://philharmonia.co.uk/resources/sound-samples/">Philharmonia</a> you can try dragging in:
	</p>
	<ul>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/banjo_a4.mp3" download="">Banjo A note</a></li>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/flute_a4.mp3" download="">Flute A note</a></li>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/saxophone_a4.mp3" download="">Saxophone A note</a></li>
	</ul>
	<p>
		A few key points I needed for a correct implementation:
	</p>
	<ul>
		<li>
			<b>How to retrieve the original frequencies from the FFT output.</b> The FFT only tells you the frequency in terms of how often it repeats in the list of samples. So you need to multiple by the sample rate (like 44100 for most sound) to get frequency per second (Hz). Most FFT libraries in JS do NOT give you a list of the frequencies (just the coefficients). The formula for figuring out what frequency corresponds to what coefficient <a href="https://stackoverflow.com/questions/4364823/how-do-i-obtain-the-frequencies-of-each-value-in-an-fft/4371627#4371627" target="_blank">is described here</a>.
		</li>
		<li>
			<b>You have to take a small slice of the audio.</b> Given that the frequency of the sound changes over time, even when playing a single note, you won't get accurate/expected frequencies if you FFT the entire thing. For example, a piano note has an "attack" and a "decay", you want to take a slice from the middle. 
			<ul>
				<li>See the <a href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform">Short Time Fourier Transform (STFT)</a>. This is computing FFT for a small slice of audio as we just did, but do this for all slices of the audio. You'll get a list of frequencies over time. This is often visualized as a <a href="https://en.wikipedia.org/wiki/Spectrogram">spectrogram</a>.</li>
			</ul>
		</li>
		<li>
			<b>You have to sample an integer number of cycles.</b> If you take an arbitrary slice of a pure A note, you likely will get a lot more than 440 in your FFT table, unless you happen to pick a start and an end that matches a multiple of the cycle length. This article automatically shortens any slice to the nearest cycle (we figure that out by finding the nearest sample where the signal crosses the Y axis). This is also important when playing the reconstructed sound on loop (otherwise you hear a popping sound).
		</li>
		<li>
			<b>The discrete fourier transform (DFT) doesn't include all possible frequencies.</b> In theory, FFT is a continuous sum (AKA an integral) of all possible frequencies in the audio. What we have implemented here is a discrete version, where we sum a finite list of frequencies. In a small slice you may not get 440 exactly as an output, only because it wasn't included as a frequency the algorithm was looking for. I <i>think</i> in principle you could have an implementation that allows you to specify what frequencies must be included (if you know what you're looking for) but I haven't seen such an implementation.
		</li>
		<li>
			<b>FFT isn't magic.</b> A popular analogy is that FFT can take a smoothie and extract all the component that went into it. But this seems impossible??? The trick is the FFT comes in with an assumption of what frequencies might be in there. We go through each possible frequency and ask "How much 440 hz is in this sound?" and "How much 880 hz is in this sound?" and so on. So it's closer to having an unknown substance and figuring out what it is by checking if it reacts to known chemicals/substances.
		</li>
	</ul>
	<p>A few insights I learned from exploring the code sandbox:</p>
	<ul>
		<li><b>The sum of all the frequencies &lt; 1% weight have a big effect.</b> I had these hidden in the FFT tables thinking they weren't significant, and any one of them isn't, but removing them altogether does have a very noticeable effect. Here's a <a href="#" id="remove-low-weight">code snippet</a> (scroll up) that removes all frequencies with weight less than 1%. Or try the opposite, listen to only weights less than 1%.</li>
		<li><b>The high frequencies are a big part of the violin sound.</b> Removing anything at 5000 hz and up makes it no longer really sound like a violin (or just sound really muted). This isn't true for the piano.</li>
		<li><b>A string tuned to 440 hz will never emit frequencies any lower than that</b>. This is true because of the physics of standing waves, but it was really cool to learn about this in theory, and then go back to this interface and see that this was indeed true for all the recordings of notes I had! Without having known this before I â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://omarshehata.me/notebook/exploring_sound">https://omarshehata.me/notebook/exploring_sound</a></em></p>]]>
            </description>
            <link>https://omarshehata.me/notebook/exploring_sound</link>
            <guid isPermaLink="false">hacker-news-small-sites-26308241</guid>
            <pubDate>Mon, 01 Mar 2021 20:52:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teslaâ€™s market share in Europe keeps crumbling, as China reclaims top spot]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26307192">thread link</a>) | @remote_phone
<br/>
March 1, 2021 | http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/ | <a href="https://web.archive.org/web/*/http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Teslaâ€™s share of the critical European battery-electric-vehicle market crumbled in the first month of 2021, and China has taken the top spot from Europe in the EV race, according to new research.</p><p>Teslaâ€™s<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNAS/TSLA" href="http://www.marketwatch.com/investing/stock/TSLA?mod=MW_story_quote" target="_blank" rel="noopener">TSLA,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/203558040/composite">+5.48%</bg-quote></a><br>
       trajectory in Europe is in decline. The U.S. car maker delivered 1,619 battery-electric vehicles to 18 key European markets in January, representing 3.5% of all battery-electric vehicles registered that month, according to a report based on public data by automotive analyst <a href="https://twitter.com/auto_schmidt" target="_blank" rel="noopener">Matthias Schmidt</a>. In 2020, Tesla delivered 1,977 vehicles in January â€” more than a 5% market share.</p><div>
<p>Those 18 markets include the European Union states â€” minus 13 countries in Central and Eastern Europe â€” as well as the U.K., Norway, Iceland, and Switzerland.</p>
<p>Schmidt called Teslaâ€™s January performance â€œconsistently low,â€ noting that the companyâ€™s European delivery schedule sees volumes peak at the end of each quarter. However, the analyst noted that Teslaâ€™s 12-month rolling volumes have now fallen behind Hyundai<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/KR/XKRX/005380" href="http://www.marketwatch.com/investing/stock/005380?countryCode=KR&amp;mod=MW_story_quote" target="_blank" rel="noopener">005380,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206684590/delayed">-3.27%</bg-quote></a><br>
       and Kia<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/KR/XKRX/000270" href="http://www.marketwatch.com/investing/stock/000270?countryCode=KR&amp;mod=MW_story_quote" target="_blank" rel="noopener">000270,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206019389/delayed">+3.12%</bg-quote></a><span>,</span><br>
       which are now the third-most popular EV group in Europe.</p>
<p>Tesla comfortably topped the European EV charts in 2019. It delivered more than 109,000 vehicles that year, making up 31% of the regionâ€™s battery-electric-vehicle market. But the tide turned in 2020, with Tesla dropping behind both the brands of Volkswagen Group<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/XE/XETR/VOW" href="http://www.marketwatch.com/investing/stock/VOW?countryCode=XE&amp;mod=MW_story_quote" target="_blank" rel="noopener">VOW,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206919008/delayed">+0.67%</bg-quote></a><br>
       and the alliance between Renault<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/FR/XPAR/RNO" href="http://www.marketwatch.com/investing/stock/RNO?countryCode=FR&amp;mod=MW_story_quote" target="_blank" rel="noopener">RNO,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/200919924/delayed">+1.37%</bg-quote></a><span>,</span><br>
       Nissan<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/JP/XTKS/7201" href="http://www.marketwatch.com/investing/stock/7201?countryCode=JP&amp;mod=MW_story_quote" target="_blank" rel="noopener">7201,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/208298710/delayed">+1.43%</bg-quote></a><span>,</span><br>
       and Mitsubishi<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/JP/XTKS/8058" href="http://www.marketwatch.com/investing/stock/8058?countryCode=JP&amp;mod=MW_story_quote" target="_blank" rel="noopener">8058,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/208582984/delayed">+0.47%</bg-quote></a><span>.</span><br>
      &nbsp;</p>
<p>Last year, Tesla made up just 13% of the European market despite a smaller proportional decline in the number of vehicles it delivered â€” around 10% â€” from 109,000 in 2019 to nearly 98,000 in 2020.&nbsp;</p>
<p>According to Schmidt, who publishes the <a href="https://www.schmidtmatthias.de/electriccarreports" target="_blank" rel="noopener">European Electric Car Report</a>, it was the introduction of emissions targets, and the specter of massive fines, that accelerated the European car makersâ€™ battle against Tesla for dominance.</p>
<p><strong>Must read:</strong> <a href="https://www.marketwatch.com/story/tesla-is-in-decline-suvs-are-king-and-more-insights-from-the-worlds-largest-electric-vehicle-market-11612201675" target="_blank" rel="noopener">Tesla is in decline, SUVs are king, and more insights from the worldâ€™s largest electric-vehicle market</a></p>
<p>More broadly in January, China raced past Europe to reclaim its crown as the worldâ€™s largest market for electric vehicles. There were 179,000 battery-electric and plug-in hybrid electric vehicles registered in China in January, compared with 110,000 in Europe.&nbsp;</p>
<p>The boost in China comes after a standout year for Europe. There were 1.33 million electric-vehicle registrations in Europe in 2020, topping 1.25 million in China, amid a pedal-to-the-metal push to increase EV adoption from European governments and supercharged demand from consumers.</p>
<p>China is home to a strong domestic electric-vehicle sector, including manufacturers Nio<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNYS/NIO" href="http://www.marketwatch.com/investing/stock/NIO?mod=MW_story_quote" target="_blank" rel="noopener">NIO,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/204905836/composite">+8.61%</bg-quote></a><span>,</span><br>
       Xpeng<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNYS/XPEV" href="http://www.marketwatch.com/investing/stock/XPEV?mod=MW_story_quote" target="_blank" rel="noopener">XPEV,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/219982686/composite">+3.61%</bg-quote></a><span>,</span><br>
       and BYD<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/HK/XHKG/1211" href="http://www.marketwatch.com/investing/stock/1211?countryCode=HK&amp;mod=MW_story_quote" target="_blank" rel="noopener">1211,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/206867707/delayed">+8.01%</bg-quote></a><span>.</span>
      </p>
<p>Schmidtâ€™s report shows that Volkswagen Group, which manufactures VW, Audi, Skoda, Seat, and Porsche, remains the most popular battery-electric vehicle group in Europe, with more than 22% of the market share after delivering 10,193 vehicles.</p>
<p><strong>Plus:</strong> <a href="https://www.marketwatch.com/story/audi-is-betting-on-the-chinese-luxury-electric-vehicle-market-in-a-joint-venture-with-the-countrys-oldest-car-maker-11611146679" target="_blank" rel="noopener">Audi is betting on the luxury market in a new electric-vehicle venture with Chinaâ€™s oldest car maker</a></p>
<p>It is closely followed by Stellantis<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/US/XNYS/STLA" href="http://www.marketwatch.com/investing/stock/STLA?mod=MW_story_quote" target="_blank" rel="noopener">STLA,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/204248628/composite">+2.26%</bg-quote></a><span>,</span><br>
       a group formed earlier this year through the merger of PSA â€” which included Peugeot and CitroÃ«n â€” and Fiat Chrysler. Stellantis delivered 9,005 vehicles.</p>
<p>Behind Stellantis is Hyundai and Kia, increasingly popular in Europe, which delivered more than 7,087 vehicles. That puts the Korean group ahead of the Renault-Nissan-Mitsubishi Alliance, which delivered 6,018 cars, though Renaultâ€™s Zoe remained the most popular battery-electric vehicle in Europe in January.</p>
<p>Then comes Mercedes-owner Daimler<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/XE/XETR/DAI" href="http://www.marketwatch.com/investing/stock/DAI?countryCode=XE&amp;mod=MW_story_quote" target="_blank" rel="noopener">DAI,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/201850364/delayed">+0.54%</bg-quote></a><span>,</span><br>
       BMW<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/XE/XETR/BMW" href="http://www.marketwatch.com/investing/stock/BMW?countryCode=XE&amp;mod=MW_story_quote" target="_blank" rel="noopener">BMW,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/202432319/delayed">+0.84%</bg-quote></a><span>,</span><br>
       and Volvo<br>
        <a data-track-hover="QuotePeek" data-charting-symbol="STOCK/SE/XSTO/VOLV.B" href="http://www.marketwatch.com/investing/stock/VOLV.B?countryCode=SE&amp;mod=MW_story_quote" target="_blank" rel="noopener">VOLV.B,<br>
        <bg-quote field="percentchange" format="0,000.00%" channel="/zigman2/quotes/208939564/delayed">+1.90%</bg-quote></a><span>,</span><br>
       which all delivered more battery-electric vehicles than Tesla in the first month of the year.</p>
<p>Germany remained the single largest market within Europe for electric vehicles. The 16,315 battery-electric vehicles registered in the country in January were more than the totals of the next-two largest markets, France and the U.K., combined.</p>
</div></div>]]>
            </description>
            <link>http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26307192</guid>
            <pubDate>Mon, 01 Mar 2021 19:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing dbt + Materialize]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 22 (<a href="https://news.ycombinator.com/item?id=26306861">thread link</a>) | @jldlaughlin
<br/>
March 1, 2021 | https://materialize.com/introducing-dbt-materialize/ | <a href="https://web.archive.org/web/*/https://materialize.com/introducing-dbt-materialize/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Managing data is hard. Managing data pipelines is even harder. The meaning of individual tables or values in your data warehouse gets lost in translation across organizations. Another teamâ€™s refactor breaks your teamâ€™s pipeline. And, itâ€™s normally very difficult to tell who made what change and when.</p>
<p><a href="https://www.getdbt.com/">dbt</a>, data build tool, alleviates these frustrations by taking over the transformation step in your ETL pipelines. <a href="https://blog.getdbt.com/what--exactly--is-dbt-/">dbt is not itself a data processor</a>, but instead sits on top of your data warehouse that contains your already extracted and loaded data. dbt allows teams to easily test, document, and version-control their data transformations.</p>
<p>While dbt is a great tool for transforming batch data, it cannot currently transform streaming data in real time. (The dbt team explicitly warns users about this in a <a href="https://blog.getdbt.com/is-dbt-the-right-tool-for-my-data-transformations/">few</a> <a href="https://discourse.getdbt.com/t/how-to-create-near-real-time-models-with-just-dbt-sql/1457">places</a>.) Here at <a href="https://materialize.com/">Materialize</a>, we want to help the world stop batching and start streaming. So we* built a dbt adapter that will allow you to transform your streaming data in real time using Materialize as your data warehouse.</p>
<p>The rest of this post will explore why dbt works best with batch data and how using Materialize unlocks streaming transformations. If youâ€™re eager to get started, the <a href="https://github.com/MaterializeInc/materialize/tree/main/misc/dbt-materialize">dbt-materialize adapter is here</a>, and our <a href="https://github.com/MaterializeInc/materialize/tree/main/play/wikirecent-dbt">sample streaming project is here</a>. Note: The dbt-materialize adapter is an <a href="https://github.com/MaterializeInc/materialize/issues/5462">active work in progress</a> and not yet suitable for production use-cases. Please file issues or submit PRs as you see fit, we love feedback!</p>
<p>*The dbt-materialize adapter was originally created by Josh Wills and actively shaped by Jeremy Cohen. Thank you for all of your work and support!</p>
<h2>dbt and batch data</h2>
<p>dbt is great at transforming batch data, but it cannot transform streaming data efficiently in real time. To understand why, letâ€™s take a look at how dbt transforms data under the hood.</p>
<p>dbt users define their desired transformations using <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/">dbt â€œmodelsâ€</a>. dbt models are SQL files that contain:</p>
<ul>
<li>A SELECT statement that performs the desired transformation</li>
<li>A <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/materializations/">â€œmaterializationâ€</a> parameter</li>
</ul>
<p>dbt transforms your data each time you <a href="https://docs.getdbt.com/reference/commands/run/">â€œrunâ€</a> a model. Each time a model is run, dbt queries the underlying data warehouse using that modelâ€™s SELECT statement. The result set of the query (the transformed data) is then either returned directly to the user or persisted into your data warehouse, depending on the modelâ€™s materialization parameter.</p>
<p>Currently, dbt supports four types of materializations: <em>table</em>, <em>view</em>, <em>incremental</em>, and <em>ephemeral</em>. The <em>table</em> and <em>incremental</em> materializations persist a table, the <em>view</em> materialization creates a view, and the <em>ephemeral</em> materialization, instead of persisting anything, returns results directly using a common table expression (CTE). The good news is that these database objects are totally sufficient to transform batch data. The bad news is that none of these database objects transform streaming data efficiently.</p>
<p>First, what do I mean by batch and streaming data? Batch data, as the name suggests, is any type of data that arrives in discrete batches. This can be once a minute, once an hour, or once a day. The important thing is that no new data arrives between batches. Streaming data, on the other hand, arrives continually and at no particular schedule.</p>
<p>So, why are these database objects sufficient to transform batch data, but not able to efficiently transform streaming data?</p>
<p>Views and CTEs do not physically persist data to your data warehouse. This means that each time you query a model that uses a view or CTE, your data warehouse must re-transform the underlying source data. And, each time you transform your source data, you are paying some cost. While views and CTEs always return up-to-date transformations of your batch and streaming data, they do not do so efficiently.</p>
<p>Tables, on the other hand, do physically persist data. More specifically, tables persist the result set of the last time their model â€œdbt run.â€ Unlike views and CTEs, this means that you wonâ€™t pay the price of transforming data each time your table is queried. But, this means that your transformed data can quickly become stale as new data arrives. This is not an issue with batch data because you can simply â€œdbt runâ€ your table each time a new batch arrives. Unfortunately, things arenâ€™t so simple with streaming data.</p>
<p>Because streaming data does not arrive on a schedule, there is no longer a right time to re-run your models to keep them up-to-date. Instead, youâ€™re forced to choose between maximizing data freshness and minimizing transformation costs. You can minimize your costs by limiting how often you recreate your tables, effectively turning your streaming data into batch data. Or, you can maximize your data freshness by continually recreating your tables. But, this approach will cost you time and money, leave you vulnerable to bugs, and still wonâ€™t maintain truly up-to-date results.</p>
<p>So, what should you do if you want to transform streaming data with dbt?</p>
<h2>dbt and streaming data</h2>
<p>dbt currently has one official and one unofficial way to approximate transforming streaming data. Neither of these methods truly transforms streaming data in real-time, and both come at a cost.</p>
<p>The first method to approximate transforming streaming data is to create models with an incremental materialization. The first time you run an incremental model, dbt persists your transformationâ€™s result set into a table in your data warehouse. For subsequent runs, dbt only transforms the subset of source data indicated by your modelâ€™s filter predicate. (For example, you might have a filter predicate that will only transform data with a timestamp greater than your last modelâ€™s run.)</p>
<p>While incremental models reduce the severity of the tradeoff that users face when persisting their transformations in tables (data freshness vs cost), they do not eliminate the tradeoff entirely. By design, you will probably be paying a lesser cost each time you â€œdbt runâ€ an incremental model. (I say â€œprobablyâ€ here because even though youâ€™re only transforming a few rows of data with each run, unless youâ€™re filtering cleverly, your modelâ€™s SELECT statement will still have to scan the entire underlying source table or view to discover these rows). While these lesser costs may free you up to run your incremental models more frequently, you still will not be able to run them continuously. By definition, you are still transforming your streaming data with a batch process.</p>
<p>The second way to approximate transforming streaming data is the <a href="https://discourse.getdbt.com/t/how-to-create-near-real-time-models-with-just-dbt-sql/1457">unofficial â€œlambda viewâ€ approach</a>. This method simulates transformations over â€œnear real-time modelsâ€ by querying a combined historical table and a current view. This approach incurs the cost of querying both of the underlying database objects using some filter, similar to the incremental materialization. The current view of your data returns up-to-date results, but must re-transform the recent data each time.</p>
<p>Neither of these methods can efficiently transform data in real time. (And, they come with <a href="https://discourse.getdbt.com/t/on-the-limits-of-incrementality/303">hairy problems</a> if, say, you have streaming data that might arrive late.) In order to efficiently perform worry-free, real-time transformations of streaming data, dbt would need to persist a database object that updates as new data arrives upstream. Luckily, there is a database object that can do this for us: materialized views.</p>
<h2>dbt and Materialize</h2>
<p>Materialized views in traditional databases behave a bit like dbtâ€™s incremental materialization. When a materialized view is first created, the result set of its query is physically persisted in the database. Then, at some interval or when manually triggered, the stored result set is updated with recent data. Like the incremental materialization, maintaining these materialized views incurs a variety of costs.</p>
<p>This is the exact problem Materialize was created to solve. Unlike traditional materialized views, <a href="https://materialize.com/why-use-a-materialized-view/">our materialized views</a> continually update as new data arrivesâ€“no refreshes needed. Better yet, we provide up-to-date results with millisecond latency. (For more information about Materialize and our materialized views, check out <a href="https://materialize.com/docs/">our documentation</a>.)</p>
<p>So, what does this mean for dbt and streaming data? This means that the first time you run a dbt model on top of Materialize, dbt persists a materialized view. <strong>Then, you never have to run your model again.</strong> No matter how much or how frequently your data arrives, your model will stay up to date. No matter when you query your view, it will return a fresh answer. Just by creating your model with our materialized views, you can confidently and efficiently transform streaming data in real time.</p>
<h2>Try it out!</h2>
<p>Excited? Skeptical? Cautiously optimistic? Try it out for yourself! As mentioned before, we have a <a href="https://github.com/MaterializeInc/materialize/tree/main/misc/dbt-materialize">beta dbt-adapter</a> and a <a href="https://github.com/MaterializeInc/materialize/tree/main/play/wikirecent-dbt">demo streaming project</a>. If you have any thoughts, questions, or concerns, please feel free to contact us in our community Slack or in our dbt repos. (Or, when youâ€™re up and running, tell us what youâ€™re transforming in real time!)</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/introducing-dbt-materialize/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306861</guid>
            <pubDate>Mon, 01 Mar 2021 19:13:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Screenplay Format Reference]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26306809">thread link</a>) | @jstrieb
<br/>
March 1, 2021 | http://www.trilane.com/ref/index.html | <a href="https://web.archive.org/web/*/http://www.trilane.com/ref/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="915" nof="ly">
  <tbody><tr>
   <td>
    <p><img id="Picture3" height="93" width="90" src="http://www.trilane.com/ref/a_reels.jpg" alt="reels" title="reels"></p>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="12" height="1" alt=""></td>
      <td></td>
     </tr>
     <tr>
      <td></td>
      <td nof="NB_BYVTNN000">[Top]</td>
     </tr>
    </tbody></table>
   </td>
   <td>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="15" height="1" alt=""></td>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="559" height="1" alt=""></td>
     </tr>
     <tr>
      <td></td>
      <td>
       <p><b><span>The Ultimate Screenplay Format Reference</span></b></p>
      </td>
     </tr>
    </tbody></table>
    
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="389" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>FADE IN:</span></p>
          <p><b><span>Table of Contents</span></b></p>
          <p><b><span>measurements</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">typeface</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">margins and tabs</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">page numbers</a></span></li>
          </ul>
          <p><b><span>scenes</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html">master scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html#SecHeadings">secondary scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">montage</a>, <a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">series of shots</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashback">flashbacks</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashseq">flashback sequences</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#quickflashes">quick flashes</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html">dreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#daydream">daydreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#imagining">imaginings</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#vision">visions</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#animation">animation</a> and sequences thereof</span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html">establishing shots</a></span></li>
           <li><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingScenes"><span>spacing between scenes</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingLines">spacing between lines</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#transitions">scene transitions<span>, </span><span>MATCH CUT</span></a></span></li>
          </ul>
          <p><b><span>characters</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/chars/chars.html#names"><span>character names</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html#cues">character cues</a></span></li>
          </ul>
          <p><b><span>narrative and action</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/action/action.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/action/action4/action4.html#SUPER"><span>SUPER</span><span>, </span><span>SCROLL</span><span><span>, </span></span></a><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><span>words on TV</span></a></li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV">
           </a><li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><b><span></span></b></a><b><a href="http://www.trilane.com/ref/action/action4/action4.html#insert"><span>INSERT</span></a></b></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#sounds">sounds, MOS</a></span></li><a href="http://www.trilane.com/ref/action/action.html#sounds">
           </a><li><a href="http://www.trilane.com/ref/action/action.html#sounds"><span></span></a><a href="http://www.trilane.com/ref/action/action.html#spfx">special effects (<span>FX</span>, <span>SPFX</span>, <span>SFX</span>)</a></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#POVs"><span>POV</span>, <span>CLOSE UP</span>, <span>PULL BACK</span></a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html">slow motion</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#music">music</a>, <a href="http://www.trilane.com/ref/action/action2/action2.html#lyrics">music lyrics</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#clips">movie clips</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action3/action3.html">unseen characters</a>, <a href="http://www.trilane.com/ref/action/action3/action3.html#phantom">phantom POV</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action4/action4.html#stacking">action stacking</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action5/action5.html">then we see ...</a></span></li>
          </ul>
          <p><b><span>dialog </span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#wrylies">actorâ€™s instructions</a> (a.k.a. wrylies)</span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#os"><span>(O.S.)</span></a> and <a href="http://www.trilane.com/ref/dlg/dlg.html#vo"><span>(V.O.)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg.html#more"><span><span>MORE</span> <span>and</span> </span><span>CONTâ€™D / CONTINUED</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html">telephone conversations</a></span></li>
           <ul>
            <li><span><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span>INTERCUT</span></a></span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a></span></li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a></ul><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a><li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html">overlapping dialog</a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html#computer">computer conversations</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html#foreign">foreign languages</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html">telepathic dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html">mute dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#beat"><span>(beat)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>-- </span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>...</span></a></span></li>
          </ul>
          <p><b><span>miscellaneous</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html">the title page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#firstPage">the first page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#credits">credits and titles</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#lastPage">the last page</a></span></li>
           <li><span>authorâ€™s intrusions</span></li>
           <li><span><a href="http://www.trilane.com/ref/misc/misc.html"><span>notes</span></a></span></li>
          </ul>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <div>
             <p><span>Writing a screenplay is difficult.</span></p>
             <p><span>Formatting should be the least of all problems. Actually itâ€™s the most easiest to master, if you follow a set of simple rules.</span></p>
             <p><span><a href="http://astore.amazon.com/trilane-20/detail/1879505843/105-1611443-6684411">Trottierâ€™s Screenwriterâ€™s Bible</a> is currently considered the final authority on formatting issues. I recommend you read it. It will save you a lot of pain.</span></p>
             <p><span>Here you find a reference to those rules. Follow them and your screenplay will be well formatted.</span></p>
            </div>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="122" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="344" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>If you donâ€™t believe me then take this from a pro:</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="47" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="343" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>â€œReaders in Hollywood do a great deal of inductive reasoning, which goes something like this: â€œI just read 99 screenplays, they were all horrible, and they were all written in improper format. Therefore, if screenplay number 100 is also in improper format, it must be horrible, too.â€</span></p>
          <p><span><span>Michael Hauge, Collins 2007, Writing Screenplays That Sell </span></span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="49" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="340" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>â€˜Writing Screenplays That Sellâ€™ is another good book to read.</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="262" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="80" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="311" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>At the bottom of this page you find a few books that are real helpful in addressing important issues beyond formatting.</span></p>
          <p><span>... all the best for your own screenwriting.</span></p>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
      <td>
       
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="27" height="1" alt=""></td>
         <td>
          <div>
             <p><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture22" height="125" width="83" src="http://www.trilane.com/ref/a_Writer_s_Journey_Vogler.jpg" alt="Writer's Journey_Vogler" title="Writer's Journey_Vogler"></a><br><span><b><br>The Writerâ€™s Journey<br></b>Christopher Vogler</span></p><p>Paperback <br>300 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture16" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          <div>
             <div><p><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture23" height="125" width="79" src="http://www.trilane.com/ref/a_Screenwriter_s_Problem_Solver_Field.jpg" alt="Screenwriter's Problem Solver_Field" title="Screenwriter's Problem Solver_Field"></a></p><p><span><b>The Screenwriterâ€™s Problem Solver<br></b>Syd Field</span></p><p>Paperback <br>384 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture18" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p></div>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
   </td>
  </tr>
 </tbody></div></div>]]>
            </description>
            <link>http://www.trilane.com/ref/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306809</guid>
            <pubDate>Mon, 01 Mar 2021 19:10:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ten seconds to ponder if a thread is worth it]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 44 (<a href="https://news.ycombinator.com/item?id=26306478">thread link</a>) | @eat_veggies
<br/>
March 1, 2021 | https://blog.jse.li/posts/ten-seconds/ | <a href="https://web.archive.org/web/*/https://blog.jse.li/posts/ten-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<p>A userstyle that makes you wait ten seconds before entering a Hacker News thread. I use <a href="https://github.com/openstyles/stylus">stylus</a> to manage mine.</p>
<div><pre><code data-lang="css"><span>.</span><span>subtext</span> <span>{</span>
  <span>--bar-color</span><span>:</span> <span>#f60</span><span>;</span>
  <span>--animation-delay</span><span>:</span> <span>0.5</span><span>s</span><span>;</span>
  <span>--animation-duration</span><span>:</span> <span>9.5</span><span>s</span><span>;</span>

  <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span><span>to</span> <span>left</span><span>,</span> <span>transparent</span> <span>50</span><span>%</span><span>,</span> <span>var</span><span>(</span><span>--</span><span>bar</span><span>-</span><span>color</span><span>)</span> <span>50</span><span>%</span><span>);</span>
  <span>background-position</span><span>:</span> <span>right</span><span>;</span>
  <span>background-size</span><span>:</span> <span>201</span><span>%</span><span>;</span>
  <span>display</span><span>:</span> <span>inline</span><span>-</span><span>block</span><span>;</span>
  <span>transition</span><span>:</span> <span>background</span><span>-</span><span>position</span> <span>0.2</span><span>s</span><span>;</span>
<span>}</span>

<span>.</span><span>subtext</span><span>:</span><span>hover</span> <span>{</span>
  <span>background-position</span><span>:</span> <span>left</span><span>;</span>
  <span>transition</span><span>:</span> <span>background</span><span>-</span><span>position</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>duration</span><span>)</span> <span>linear</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>delay</span><span>);</span>
<span>}</span>

<span>.</span><span>subtext</span> <span>a</span><span>[</span><span>href</span><span>^=</span><span>"item"</span><span>]</span> <span>{</span>
  <span>pointer-events</span><span>:</span> <span>none</span><span>;</span>
<span>}</span>

<span>.</span><span>subtext</span><span>:</span><span>hover</span> <span>a</span><span>[</span><span>href</span><span>^=</span><span>"item"</span><span>]</span> <span>{</span>
  <span>animation</span><span>:</span> <span>enable-click</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>duration</span><span>)</span> <span>forwards</span> <span>step-end</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>delay</span><span>);</span>
<span>}</span>

<span>@</span><span>keyframes</span> <span>enable-click</span> <span>{</span>
  <span>to</span> <span>{</span>
    <span>pointer-events</span><span>:</span> <span>auto</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>Special thanks to Martino di Filippo (<a href="https://github.com/MartinodF">@MartinodF</a>) for showing me the <code>animation-timing-function: step-end</code> CSS property!</p>

    </section></div>]]>
            </description>
            <link>https://blog.jse.li/posts/ten-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306478</guid>
            <pubDate>Mon, 01 Mar 2021 18:46:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Won't Save Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26306372">thread link</a>) | @hackitup7
<br/>
March 1, 2021 | https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A common situation: Things are going fine, but not great at your SaaS business. Your sales teamâ€™s win rates arenâ€™t quite high enough. Your marketing pipeline isnâ€™t quite as full as youâ€™d like. Your customers are happy but some are considering other solutions. Overall, your product doesnâ€™t quite feel differentiated enough.</p>

<p>A natural temptation that Iâ€™ve seen in this situation is to look to machine learning as the solution to your differentiation woes. If we just sprinkle a dash of the olâ€™ ML on this bad boy, the thinking goes, weâ€™ll have a product that stands out in the market and that everyone will love. In general, this strategy just doesnâ€™t work.</p>

<h2 id="machine-learning-is-not-unique">Machine Learning Is Not Unique</h2>

<p>First â€“ at this point in time, everybody vaguely knows what machine learning is and has a rough sense for its capabilities. Youâ€™re not getting a jump on the market by declaring that youâ€™re going to make your product â€œpowered by AI.â€ Every Gartner report has some checkbox about building intelligent or predictive features, and itâ€™s no longer a secret that there appears to be some magical pixie dust out there that you can drizzle on your product to make it special.</p>

<p>Using machine learning to differentiate your product is like driving a fancy sports car to stand out when picking someone up for a date. It can be cool, it might even fit your persona, and <em>some</em> people will be impressed. But ultimately it isnâ€™t revolutionary or inherently game changing.</p>

<p><img src="https://staysaasy.com/assets/ml-wont-save/russ.jpg" alt="Tres comas">
We have an ML product, now are you interested?</p>

<p>ML is a buzzword of the moment â€“ and investing in buzzwords is not the route to enduring differentiation. Thereâ€™s always some technology thatâ€™s gotten enough mindshare that everyone is sharing blog posts, frantic manifestos are being written, and investors are hot and bothered. 2 decades ago it was cloud, itâ€™s currently (roughly speaking) machine learning and crypto, and who knows what it will be next.</p>

<p>This doesnâ€™t mean that ML features are useless â€“ if itâ€™s useful, people will pay. But there is essentially no novelty left in the ML play. Even if the underlying trend is meaningful (for example, cloud transformation was and continues to be a big deal!), the biggest trends rapidly become table stakes.</p>

<h2 id="a-lot-needs-to-go-right-for-ml-to-work">A Lot Needs to Go Right for ML to Work</h2>

<p>The barrier to building a profitable, differentiating ML-driven product is high â€“ not only in a technical sense, but also in terms of the role that it solves for your business. It canâ€™t just be slapped on top of your product like salad dressing:</p>

<ul>
  <li>You need to have an ML application that fits your business model â€“ for example, if ConvertKit (which Stay SaaSy uses for our newsletter) adds a crazy send-time-optimization product, that might simply not matter for sites like us that use them to email out blog content</li>
  <li>You need a problem that <em>you</em> can solve but <em>others</em> canâ€™t. In reality, you are probably not orders of magnitude smarter than your competition</li>
  <li>You need to solve a problem that has a tangible business impact â€“ only the most frivolous buyers will purchase something just because itâ€™s cool technology</li>
  <li>You need to actually prove that whatever ML magic youâ€™ve built actually solves a key problem better than anyone else can, or for that matter solves a real problem at all</li>
</ul>

<p><img src="https://staysaasy.com/assets/ml-wont-save/emeril.png" alt="Bam!">
Letâ€™s just slap some machine learning on there, and Bam!</p>

<p>A situation that checks all of the boxes above is the holy grail, but you need to be honest about whether thatâ€™s the case. Itâ€™s very possible that youâ€™d be better off trying to differentiate your SaaS product by <a href="https://staysaasy.com/product/2020/11/04/selling-to-the-enterprise-expand-playing-field.html">creating a suite of functionality</a> or investing heavily in UX â€“ both strategies that many companies have used to construct defensible product moats.</p>

<p>The concept of provable value is one of the most unknown or unappreciated elements of building a sellable ML product. The more that you can prove that youâ€™re adding revenue or reducing costs, the stickier your revenue will be. When the rubber hits the road and something needs to get cut, the products that add value in a provable and (ideally) deterministic way are the ones who survive.</p>

<p>Many customers want to verify the results of anything that theyâ€™re paying for, and black boxes understandably scare them. Hype has created a litany of startups peddling ML snake oil and buyers are rightfully skeptical. This increases the barrier to entry and means that itâ€™s much harder to build an enduring ML product. Not only does your product need to work, but you often need to build significant reporting functionality that allows customers to dissect your product and verify the advantage that you claim to provide. And keep in mind that many customers will approach the problem of analyzing whether your algorithms add value adversarially â€“ teams that wanted to build ML products in-house rather than buying yours will be especially aggressive critics and naysayers.</p>

<h2 id="the-promise-of-machine-learning-as-a-silver-bullet-is-distracting">The Promise of Machine Learning as a Silver Bullet is Distracting</h2>

<p>Perhaps the worst part of hoping that you can dust magical machine learning on top of your product is that it trains you to look for silver bullets. ML feels like a new, magical solution that will solve all of your problems. In reality magic solutions are near-mythical and itâ€™s dangerous to believe in them.</p>

<p>The earlier your startup, the worse the optics of saying that youâ€™re going to dominate your market by sprinkling machine learning on your product. If you have terabytes of unique data and claim that it will unlock the portal to Machine Learning Narnia, or if you have a unique approach and track record that indicates true expertise, reasonable listeners will hear you out and not immediately assume that youâ€™re full of it. But if your non-specialized team is trying to raise some kind of seed fundraising on the back of a machine learning story (â€œWeâ€™re just going to do X, but with MLâ€), then it should be obvious that you donâ€™t have anything vaguely proprietary. At best, you look overly optimistic; at worst, you look like you have no idea what ML actually entails. Unfortunately, some people will pump you up and make you believe that this strategy is viable â€“&nbsp;the rest will roll their eyes at your â€œ.aiâ€ domain once you leave the room.</p>

<p>Why does this happen? I think itâ€™s because the talk track â€œweâ€™re going to do X but with AIâ€ does work on a certain kind of unsophisticated observer. If boasting about ML products is like driving a McLaren, there are indeed investors / buyers who are the equivalent of someone who is really, really captivated by a fancy car. You canâ€™t count on this to be an enduring advantage.</p>

<h2 id="where-machine-learning-matters">Where Machine Learning Matters</h2>

<p>Where Iâ€™ve seen machine learning make the biggest difference is in extending a lead that youâ€™ve already earned. An example of where ML can really set a product apart is Photoshopâ€™s ability to do <a href="https://blog.adobe.com/en/publish/2020/10/20/photoshop-the-worlds-most-advanced-ai-application-for-creatives.html#gs.mqvj9d">automatic skin smoothing and sky replacement</a>. This is some hardcore stuff, and Adobe has checked the box on the narrow domain where ML products can make a huge difference:</p>

<ul>
  <li>They have the data and team to solve this problem well</li>
  <li>They have a platform (Photoshop itself!) where automatic image manipulation software can be plugged in to add significant value</li>
  <li>You can actually observe that their technology works.</li>
  <li>Photoshop already exists as the most sophisticated graphics editing software, so adding more sophisticated features on top of it extends their advantage on the market</li>
</ul>

<p>Due to the technical moats that it can create machine learning functionality can be a great accelerant when it works well. But you simply canâ€™t rely on it to be the singular differentiator for your business.</p>

<p><img src="https://thumbs.gfycat.com/AdmiredLawfulBunny-size_restricted.gif" alt="These are not the doors of a billionnaire, Richard!"></p>


    

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306372</guid>
            <pubDate>Mon, 01 Mar 2021 18:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Frictionless habit-tracking on iOS (pokeable from your text editor too)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26306018">thread link</a>) | @xenodium
<br/>
March 1, 2021 | http://xenodium.com/frictionless-org-habits-on-ios | <a href="https://web.archive.org/web/*/http://xenodium.com/frictionless-org-habits-on-ios">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-frictionless-org-habits-on-ios">

<p><img src="http://xenodium.com/images/frictionless-org-habits-on-ios/flat_habits.gif" alt="flat_habits.gif" width="80%" height="80%">
</p>

<p>
I've been wanting org to keep track of my daily habits for a little while. The catalist: reading James Clear's wonderful <a href="https://jamesclear.com/atomic-habits">Atomic Habits</a> (along with plenty of lock-down inspiration).
</p>

<p>
As much as I live in Emacs and org mode, it just wasn't practical enough to rely on my laptop for tracking habits. I wanted less friction, so I've been experimenting with building a toy app for my needs. Naturally, org support was a strict requirement, so I could always poke at it from my beloved editor.
</p>

<p>
I've been using the app every day with success. The habits seem to be sticking, but equally important, it's been really fun to join the fabulous world of Emacs/Org with iOS/SwiftUI.
</p>

<p>
This is all very experimental<sup><a id="fnr.1" href="#fn.1">1</a></sup> and as mentioned on <a href="https://www.reddit.com/r/emacs/comments/ljurwx/org_habits_ios_app_want_to_try_it/">reddit</a> (follow-up <a href="https://www.reddit.com/r/emacs/comments/lp62vn/org_habits_ios_app_followup_twoway_edit/">here</a>) and <a href="https://twitter.com/xenodium/status/1361034010047176705">twitter</a>, the app isn't available on the App Store. I may consider publishing if there's enough interest, but in the mean time, you can reach out and install via <a href="https://testflight.apple.com/">TestFlight</a>.
</p>

<p>
Send me an email address to <i>flathabits*at*xenodium.com</i> for a TestFlight invite.
</p>
</div></div>]]>
            </description>
            <link>http://xenodium.com/frictionless-org-habits-on-ios</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306018</guid>
            <pubDate>Mon, 01 Mar 2021 18:18:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doing the impossible, monetising Chrome Extensions]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26305789">thread link</a>) | @thomasisaac
<br/>
March 1, 2021 | https://tillypay.com/blog/how-to-monetise-a-chrome-extension/ | <a href="https://web.archive.org/web/*/https://tillypay.com/blog/how-to-monetise-a-chrome-extension/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>So here you are, youâ€™ve built a tool for the Chrome Web Store and suddenly youâ€™ve been bestowed with a<strong> couple of thousand users across the globe</strong>.</p><p>One question, would be how to monetise such an impressive piece of tech youâ€™ve created.</p><p>If youâ€™ve spent your time on an Android or iOS, the path to monetisation are far easy &amp; a lot simplier. Somehow, however, <strong>Chrome Extensions donâ€™t carry the same weight</strong> in the mind of the user. They are much more inclined to pay for an app or an ongoing service but Chrome Extensions wind up in the realm of â€œshould be free.â€</p><p>A lot of chrome extensions are the child of a large product or a global product itself, cases such as Honey, the coupon finder &amp; Grammerly are super giants that donâ€™t really fall into the realm of developer accidently making a tool valuable to thousands.</p><p>There seems to be a vat of extensions floating around the 20k to 50k mark, not been updated since 2015. What do to?</p><p>Rather than give you a list of things<strong> untried or untested with affiliate links attached, letâ€™s run through stories that I know.</strong></p><p>There's a new platform called <a href="https://monetise.so/">Monetise.so</a>, they have built a Chrome Extension billing platform as a direct replacement for the upcoming sunset of the Chrome Web Store Payments.</p><p>Check them out : <a href="https://monetise.so/">https://monetise.so</a></p><p>Itâ€™s no secret that Adblock Plus with their ~100 Million global users have profited from the blockage of adverts existing on internet.</p><p>The business model is unique &amp; simple, they allowed certain whitelisted ads through, non-intrusive and Google paid them an undisclosed amount.</p><p>They are not the only ones who do what they do, but theyâ€™re very good at it.<br>They aggregate affiliate schemes across the internet and put them into a single JS file for you to plugin to your site. They also built something for Chrome Extensions, after you include in your code, they will start including logos on Google Search Results, like so:</p><figure><img src="https://tillypay.com/blog/content/images/2020/02/1-tf0Kx1jGsc5mmRHPo7VYXA.png"></figure><p>The DJI link is now monetised and everyone is happy, the user who is paying somewhat for the extension, the extension developer but not Google Chrome, understandably.</p><p>This is malvertising, itâ€™s advertising in a malware way of including unwanted code. Even with itâ€™s horrid name, if privacy is not your thing, then thereâ€™s very little impacting the end user. The issue comes when you are allowing a third party with that much access to your google searches, maybe not.</p><p>Actually, I do have access to the maths on this:</p><ul><li><strong>50,000 Weekly Users resulted in about â‚¬2.2k a month.</strong></li><li>Thatâ€™s about <strong>4.4 cent per user,</strong> mostly from Tier 1 GEOs (US, UK, FR, DE)</li></ul><p>Google will kick you out if they find this.<br>It's happened time &amp; time again.</p><p>Revolution, is what they called it.<br>A new way to monetise the internet.</p><p>Yes, but no. Firstly, the UX for your end-user sucks balls.<br>Their brand new computer is down to itâ€™s last leg trying to get the you (the developer), $0.0002 per minute of agony.</p><p>Also, Iâ€™ve tried this.<br>I had 10k Weekly Users, that turned into about 30 concurrent users on average at any one time.</p><p>I made $16 a month from Coinhive at 25% of his userâ€™s CPU.</p><p>Back to the drawing board.</p><p><em>Freemium</em><br>Popular topic on the lips of SaaS models, provide something a bit more &amp; users are willing to pay for it. The problem you may have is that you product just isnâ€™t worth a cup of coffee a month. On a popular VPN Chrome extension, they managed to get 50k users a month to pay for their premium product out of a user base of 4 million MAU. Their premium product was pretty damn great too.</p><p>Here are some great stories of Chrome Extensions being monetised in this way:</p><ul><li><a href="https://www.indiehackers.com/interview/how-sharing-helpful-knowledge-helped-me-grow-to-2-500-month-ad9b94660e">Weather App</a> - $2.5k MRR</li><li><a href="https://beebs.io/">Beebs</a> - <a href="https://www.indiehackers.com/interview/from-no-coding-skills-to-50k-downloads-in-two-years-eca7ea8587">$5K MRR</a></li><li>Nighteye, nightmode - <a href="https://www.indiehackers.com/product/night-eye">$2.3k MRR</a></li></ul><p><em>Paid-Only</em><br>Yes, this works well if your product is good enough for the switch.<br>Might be fairly difficult to encourage users to pay for the simple RSS extension you created.</p><p><em>Paywall or not to Paywall</em><br>Paywalling your current userbase guarantees the maximum number of conversions in that time period, everything else is bad news. Chrome extensions have review mechanisms that mean youâ€™ll paywall your userbase &amp; they turn to the review board for revenge. <a href="https://chrome.google.com/webstore/detail/media-hint/akipcefbjlmpbcejgdaopmmidpnjlhnb" rel="noopener nofollow">See here</a>.</p><p>I decided to paywall all the new users but keep the old users free. This way I had 50,000 people who loved &amp; would recommend the extension and a steady stream of newcomers who some (5%) of them would pay a monthly subscription for it.</p><p><strong>The best way to start paywalling is to use <a href="https://monetise.so/">Monetise.so</a>, they are a direct replacement of the Chrome Web Store.</strong></p><p>This could be a possibility for you, I know of a few examples this works well:</p><p><a href="https://chrome.google.com/webstore/detail/tab-for-a-cause/gibkoahgjfhphbmeiphbcnhehbfdlcgo?hl=en" rel="noopener nofollow">Tab for a Cause</a><br>They have a new tab page with an advert on it, they donate roughly ~30% of their Gross Revenue to charities.</p><p>Total Q1 2019 Revenue: <strong>$139,395.93.</strong><br>$0.25 per user per month, not bad at all.</p><p>They have, what you probably donâ€™t is a lot of coverage being at the new tab page of every single user.</p><p><a href="http://ecosia.org/" rel="noopener nofollow"><strong>Ecosi</strong></a>a is the tree planting search engine, uses its advert revenue into planting trees across the planet. Itâ€™s difficult to quantify as they have many platforms.<br>However, diverting your user-base to a search engine is quite a profitable business, the difficulty is getting them there in the first place.</p><p>Unsure on the user numbers, but they made â‚¬2.5M in the last reported month with 10 million users. &nbsp;</p><p><a href="https://chrome.google.com/webstore/detail/norton-safe-search/gkjahlcnbjiangkneanonnndppicobbd?hl=en" rel="noopener nofollow"><strong>Norton Safe Search</strong></a> is an example of a company forcefully changing your search engine for monetary gain, there is absolutely zero benefit to an anti-virus search engine, none.</p><p>You have to be a position where changing search or implementing adverts seems legitimate. Google will quickly remove your extension if you do that.</p><p>Thee value of switching user for these Bing-copycat search engines is about â‚¬0.80 per weekly user for a tier 1 geo; really not bad going.</p><p><a href="https://chrome.google.com/webstore/detail/panda-5-your-favorite-web/haafibkemckmbknhfkiiniobjpgkebko?hl=de&amp;" rel="noopener nofollow"><strong>Panda</strong></a> offer chrome extension, 60K weekly users that probably wittles down to 10k MAU. Squarespace reportedly pay $4k a month for a spot.</p><p>Donâ€™t do this.<br>Like <a href="https://9to5google.com/2019/12/17/chrome-avast-extensions-removed/" rel="noopener nofollow">Avast have done</a>, they collected clickstream data to feed their other suspicously data rich company, <a href="https://www.jumpshot.com/" rel="noopener nofollow">Jumpshot</a>.<br>Like <a href="https://www.businessinsider.com/evidon-sells-ghostery-data-to-advertisers-2013-6?r=DE&amp;IR=T" rel="noopener nofollow">Ghostery</a> have done.</p><p>Both Firefox &amp; Chrome will kick you out even at a whiff of this.<br>Good money, undoubtedly but I have no numbers.<br>I was recently told of a 6 digit figure for access to search data with Jumpshot.</p><p>Hola Unblocker allow for users to access geo-blocked content, but at a cost.<br>Your computer becomes a part of the appropriately named, <a href="https://luminati.io/" rel="noopener nofollow">Luminati</a> network.<br>They then sell your connection to the highest bidder and all sorts can run through the computer. It makes unblocking a doddle. With access to apparently 40M residential IPs, itâ€™s pretty massive and <a href="https://luminati.io/static/IPPN-analysis-2019.pdf?md5=3109015-85e418b7" rel="noopener nofollow">making $40M a year.</a></p><p>If you don't understand residential proxies, here's a<a href="https://proxyscraper.io/what-is-a-residential-proxy/"> little guide.</a></p><p>Lastly, donations. I only really have non-quantitative information on donations for Chrome Extensions.</p><p>They donâ€™t work as well as they should, you might gather bits &amp; pieces of cash here and there but itâ€™s the lowest form of per user donation, you are not wikipedia or the Guardian, remember that.</p><p>If youâ€™ve gathered enough mass and provide a valuable time/money/effort savings product, then Iâ€™d opt for the Premium tier.<br>If you can place adverts or have an opportunity to, try that out.<br>Ultimately, get to know your users and get a feel for what fits well.</p><p>Anything untoward is unsustainable.<br>Good luck.</p>
    </section></div>]]>
            </description>
            <link>https://tillypay.com/blog/how-to-monetise-a-chrome-extension/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26305789</guid>
            <pubDate>Mon, 01 Mar 2021 18:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The small web is beautiful]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26305585">thread link</a>) | @benhoyt
<br/>
March 1, 2021 | https://benhoyt.com/writings/the-small-web-is-beautiful/ | <a href="https://web.archive.org/web/*/https://benhoyt.com/writings/the-small-web-is-beautiful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">



<div id="content">

<p>March 2021</p>

<blockquote>
  <p>Summary: I believe that small websites are compelling aesthetically, but are also important to help us resist selling our souls to large tech companies. In this essay I present a vision for the â€œsmall webâ€ as well as the small software and architectures that power it. Also, a bonus rant about microservices.</p>

  <p><strong>Go to:</strong> <a href="#small-software">Software</a> | <a href="#small-websites">Web</a> | <a href="#emphasize-server-side-not-javascript">Server-side</a> | <a href="#static-sites-and-site-generators">Static sites</a> | <a href="#fewer-dependencies">Dependencies</a> | <a href="#small-analytics">Analytics</a> | <a href="#small-architectures-not-microservices">Microservices</a></p>
</blockquote>

<p>About fifteen years ago, I read E. F. Schumacherâ€™s <em>Small is Beautiful</em> and, despite not being interested in economics, I was moved by its message. Perhaps even more, I loved the terse poetry of the bookâ€™s title â€“ it resonated with my frugal upbringing and my own aesthetic.</p>

<p>I think itâ€™s time for a version of that book about technology, with a chapter on web development: <em>The Small Web is Beautiful: A Study of Web Development as if People Mattered.</em> Until someone writes that, this essay will have to do.</p>

<p>There are two aspects of this: first, <strong>small teams and companies</strong>. Iâ€™m not going to talk much about that here, but <a href="https://basecamp.com/books">Basecamp</a> and many others have. What Iâ€™m going to focus on in this essay is <strong>small websites and architectures</strong>.</p>

<p>Iâ€™m not the first to talk about the â€œsmall webâ€, but, somewhat surprisingly, only a few people have discussed it using that term. Here are the main web pages I can find that do:</p>

<ul>
  <li><a href="https://neustadt.fr/essays/the-small-web/">Rediscovering the Small Web</a> by Parimal Satyal: a fabulous article about the joy of small, independent (and sometimes retro) websites in contrast to the â€œcommercial webâ€.</li>
  <li><a href="https://ar.al/2020/08/07/what-is-the-small-web/">What is the Small Web?</a>, by Aral Balkan of the Small Technology Foundation: more of a manifesto against the surveillance of Big Tech than something concrete, but still interesting.</li>
</ul>

<p>Why aim small in this era of fast computers with plenty of RAM? A number of reasons, but the ones that are most important to me are:</p>

<ul>
  <li>Fewer moving parts. Itâ€™s easier to create more robust systems and to fix things when they do go wrong.</li>
  <li>Small software is faster. Fewer bits to download and clog your computerâ€™s memory.</li>
  <li>Reduced power consumption. This is important on a â€œsave the planetâ€ scale, but also on the very local scale of increasing the battery life of your phone and laptop.</li>
  <li>The light, frugal aesthetic. Thatâ€™s personal, I know, but as youâ€™ll see, Iâ€™m not alone.</li>
</ul>

<p>So letâ€™s dive in. I want to cover a bunch of different angles, each with its own subheading.</p>

<h2 id="small-software">Small software</h2>

<p>If weâ€™re going to talk about a small web, we need to start with small <em>software</em>.</p>

<p>As a teen, I learned to program using x86 assembly and <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a> â€“ perhaps odd choices, but my dad was heavily into Forth, and I loved how the language was so simple I could write <a href="https://github.com/benhoyt/third">my own bootstrapped compiler</a>.</p>

<p>In terms of career, I started as an embedded programmer â€“ not as in â€œembedded Linuxâ€ but as in microcontrollers where 16KB of RAM was generous. My current laptop has 16GB of RAM, and thatâ€™s not a lot by todayâ€™s standards. We were building IP-networked products with <em>one millionth</em> the amount of RAM. Those kinds of micros are as cheap as chips (ahem), and still widely used for small electronic devices, sensors, internet-of-things products, and so on.</p>

<p>You have to think about every byte, compile with size optimizations enabled, and reuse buffers. Itâ€™s a very different thing from modern web development, where a JavaScript app compiles â€œdownâ€ to a 1MB bundle, or a single Python object header is 16 bytes before youâ€™ve even got any data, or a Go hello-world binary is 2MB even before youâ€™ve added any real code.</p>

<p>How do you create small programs? I think the main thing is that you have to <em>care about size</em>, and most of us donâ€™t think we have time for that. Apart from embedded development, thereâ€™s an entire programming subculture called the <a href="https://en.wikipedia.org/wiki/Demoscene">demoscene</a> that cares about this. They have competitions for the smallest 4KB demos: who can pack the most graphical punch into 4096 bytes of executable. Thatâ€™s smaller than many favicons! (<a href="https://www.youtube.com/watch?v=jB0vBmiTr6o">Elevated</a> and <a href="https://www.youtube.com/watch?v=RCh3Q08HMfs">cdak</a> are two of the highest-rated 4K demos.) Many demosceners go on to become game developers.</p>

<p>Itâ€™s not just about executable size â€¦ when youâ€™re developing your next command line tool, if you use Go or Rust or even C, your program will be much faster, smaller, and use less memory than a Python or Java equivalent. And easier to install. If you donâ€™t understand why, please do learn. (Itâ€™s out of scope for this essay, but to summarize: Go, Rust, and C compile to ready-to-execute machine code, donâ€™t carry around a virtual machine, and donâ€™t have memory overhead for objects like integers.)</p>

<p>But why not apply some of the same principles to web development? In the web world, I think the main trick is to be careful what dependencies you include, and also what dependencies <em>they</em> pull in. In short, know <code>node_modules</code> â€“ or maybe better, <em>no</em> <code>node_modules</code>. More about this <a href="#fewer-dependencies">below</a>.</p>

<p>Niklaus Wirth of Pascal fame wrote a famous paper in 1995 called <a href="https://cr.yp.to/bib/1995/wirth.pdf">A Plea for Lean Software [PDF]</a>. His take is that â€œa primary cause for the complexity is that software vendors uncritically adopt almost any feature that users wantâ€, and â€œwhen a systemâ€™s power is measured by the number of its features, quantity becomes more important than qualityâ€. He goes on to describe Oberon, a computer language (which reminds me of Go in several ways) and an operating system that he believes helps solve the complexity problem. Definitely wirth a read!</p>

<p>Iâ€™ve been mulling over this for a number of years â€“ back in 2008 I wrote a sarcastic dig at how bloated Adobe Reader had become: <a href="https://blog.brush.co.nz/2008/07/adobe-reader-9/">Thank you, Adobe Reader 9!</a> It was a 33MB download and required 220MB of hard drive space even in 2008 (itâ€™s now a 150MB download, and I donâ€™t know how much hard drive space it requires, because I donâ€™t install it these days).</p>

<p>But instead of just complaining, how do we actually solve this problem? Concretely, I think we need to start doing the following:</p>

<ul>
  <li>Care about size: this sounds obvious, but things only change when people think theyâ€™re important.</li>
  <li>Measure: both your executableâ€™s size, and your programâ€™s memory usage. You may want to measure over time, and make it a blocking issue if the measurements grow more than <em>x</em>% in a release. Or you could hold a memory-reduction sprint every so often.</li>
  <li>Language: choose a backend language that has a chance, for example Rust, C or C++, or for servers, Go. These languages arenâ€™t right for everything (like data transformation scripts), but they produce small executables, and theyâ€™re good for CLIs and desktop apps.</li>
  <li>Remove: cut down your feature set. Aim for a small number of high-quality features. My car canâ€™t fly or float, and thatâ€™s okay â€“ it drives well.</li>
  <li>Say no to new features: unless they really fit your philosophy, or add more than they cost over the lifetime of your project.</li>
  <li>Dependencies: understand the size and complexity of each dependency you pull in. Use only built-in libraries if you can.</li>
</ul>

<h2 id="small-websites">Small websites</h2>

<p>Iâ€™m glad thereâ€™s a growing number of people interested in small websites.</p>

<p>A few months ago there was a sequence of posts to Hacker News about various â€œclubsâ€ you could post your small website on: the <a href="https://1mb.club/">1MB Club</a> (<a href="https://news.ycombinator.com/item?id=25151773">comments</a>), <a href="https://512kb.club/">512KB Club</a> (<a href="https://news.ycombinator.com/item?id=25450451">comments</a>), <a href="https://250kb.club/">250KB Club</a> (<a href="https://news.ycombinator.com/item?id=25176663">comments</a>), and even the <a href="https://10kbclub.com/">10KB Club</a> (<a href="https://news.ycombinator.com/item?id=25556860">comments</a>). I think those are a fun indicator of renewed interested in minimalism, but I will say that raw size isnâ€™t enough â€“ a 2KB site with no real content isnâ€™t much good, and a page with 512KB of very slow JavaScript is worse than a snappy site with 4MB of well-chosen images.</p>

<p>Some of my favourite small websites are:</p>

<p><a href="https://news.ycombinator.com/news">Hacker News</a>: I personally like the minimalist, almost brutalist design, but I love its lightness even more. I just downloaded the home page, and loading all resources transfers only 21KB (61KB uncompressed). Even pages with huge comment threads only transfer about 100KB of compressed data, and load quickly. Reddit has become such a bloated mess in comparison. Hacker News, never change!</p>

<p><a href="https://lobste.rs/">Lobsters</a>: a similar news-and-voting site, with slightly more â€œmodernâ€ styling. It uses some JavaScript and profile icons, but itâ€™s still clean and fast, and the total transfer size for the homepage is only 102KB. You just donâ€™t need megabytes to make a good website.</p>

<p><a href="https://sourcehut.org/">Sourcehut</a>: I like the concept behind Drew DeVaultâ€™s business, but I love how small and anti-fluff the website is. He has set up a mini-site called the <a href="https://forgeperf.org/">Software Forge Performance Index</a> that tracks size and browser performance of the prominent source code websites â€“ Sourcehut is far and away the lightest and fastest. Even his homepage is only 81KB, including several screenshot thumbnails.</p>

<p><a href="https://sqlite.org/">SQLite</a>: not only is SQLite a small, powerful SQL database engine, the website is fantastically small and content-rich. Even their 7000-word <a href="https://sqlite.org/testing.html">page about testing</a> is only 70KB. How do they do this? Itâ€™s not magic: focus on high-quality textual content, minimal CSS, no JavaScript, and very few images (a small logo and some SVGs).</p>

<p><a href="https://lwn.net/">LWN</a>: Iâ€™m a little biased, because Iâ€™ve written <a href="https://lwn.net/Archives/GuestIndex/#Hoyt_Ben">articles</a> for them, but theyâ€™re an excellent website for Linux and programming news. Extremely high-quality technical content (and a high bar for authors). Theyâ€™re definitely niche, and have a â€œwe focus on quality content, not updating our CSS every yearâ€ kind of look â€“ theyâ€™ve been putting out great content for 23 years! Their homepage only downloads 44KB (90KB uncompressed).</p>

<p><a href="https://danluu.com/">Dan Luuâ€™s blog</a>: this is one of the more hardcore examples. His inline CSS is only about 200 bytes (the pages are basically unstyled), and his HTML source code doesnâ€™t use any linefeed characters. Kind of a fun point, although then he goes on to load 20KB of Google Analytics JavaScriptâ€¦</p>

<p>As a friend pointed out, those websites have something of an â€œanti-aesthetic aestheticâ€. I confess to not minding that at all, but on the other hand, small doesnâ€™t have to mean ugly. More and more personal blogs and websites have adopted a small web approach but are more typographically appealing:</p>

<ul>
  <li><a href="https://lucumr.pocoo.org/">Armin Ronacherâ€™s Thoughts and Writings</a></li>
  <li><a href="https://nullprogram.com/">Chris Wellonsâ€™ â€œNull programâ€ blog</a></li>
  <li><a href="http://eradman.com/">Eric Radmanâ€™s BSD and SQL blog</a></li>
  <li><a href="https://hugotunius.se/">Hugo Tuniusâ€™ programming blog</a></li>
  <li><a href="https://prog21.dadgum.com/">James Hagueâ€™s â€œProgramming in the â€¦</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benhoyt.com/writings/the-small-web-is-beautiful/">https://benhoyt.com/writings/the-small-web-is-beautiful/</a></em></p>]]>
            </description>
            <link>https://benhoyt.com/writings/the-small-web-is-beautiful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26305585</guid>
            <pubDate>Mon, 01 Mar 2021 17:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presenting the first condensed database]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26304202">thread link</a>) | @Malexik
<br/>
March 1, 2021 | https://condensationdb.com/white-paper/ | <a href="https://web.archive.org/web/*/https://condensationdb.com/white-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

          <div>
            <div>
              
              <p>Inspired by the blockchain system, the email system, and git versioning, Condensation is a unique solution to develop scalable and modern applications while providing the features to protect digital rights. Having a system that doesn't need to trust the Cloud enables to ensure the security and the ownership of data.</p>
            </div>

            <figure>
              <video poster="https://condensationdb.com/assets/img/overview-video-poster.png" autoplay="autoplay">
                  <source src="https://condensationdb.com/assets/img/overview-video.mp4" type="video/mp4">
              </video>
              <figcaption>Condensation extends the Cloud with distributed storage servers</figcaption>
            </figure>

          </div>
          
        </section><section>
        <div>
          <div>
            <div>
              <article>
                <h2>The emergence of condensed systems</h2>

                <p>
                While being entirely distributed, Condensation can store and retrieve data like a database or a file system, send data to other users or devices like a messaging system, and share and synchronize data like cloud services. Thereby, Condensation follows a distributed actor-message-passing approach and encrypts all data end-to-end.
                </p>

                <p>
                Condensation builds the bridge between the simplicity of immutable data and the easiness of implementation of mutable documents. On the client, documents are split efficiently into smaller immutable units that can be transferred freely across the network. Then, they can be condensed back when they arrive on the receiver's device. Condensed systems are free from trusting a third-party server and many new features come by design to create trust between clients such as data certification.
                </p>

                <p>
                This shift from merging data on the server to doing it on the client side, opens many new possibilities for application design. Furthermore, it is significantly more efficient if compared to existing solutions which need to build several application layers on top of existing systems to achieve the same functionalities. Before to start explaining the mechanics, this section explains the history of databases and what makes Condensation the next step in the evolution of databases.
                </p>

                <h3>Bridging the gap between mutable and immutable data structures</h3>
                    <p>
                    The structure of today's file and database systems dates back to the 1970s, when storage space was extremely scarce and computers were few. These systems were designed to run on a single machine, and mostly on a single disk.
                    </p>
                    <p>
                    While both databases and file systems have greatly evolved over time, their main structure has hardly changed. Database systems are based on tables with mutable records (rows), while file systems use a hierarchy of folders with mutable files inside. In both systems, data can be modified with little effort, and at any time. It also has the advantage of being very efficient with regards to storage space needs. Data synchronization, however, is notoriously difficult and error prone.
                    </p>
                    <p>
                    In todays' connected world, data is used on different devices, or is shared with other people. And, for most applications, storage space is not a limiting factor any more. Hence, efficient data synchronization is key.
                    </p>

                    <figure>

                      <img src="https://condensationdb.com/assets/img/historic-evolution.png" alt="Image">

                      <figcaption>A historical evolution of data systems</figcaption>
                    </figure>

                    <p>
                    Aside of file and database systems, revision control systems have been developed and used since the 1980s. Some of them, such as git or hq, are fully distributed and do not require any central server whatsoever. Each user has their own version of the data and can merge changes from other users. Such systems allow for efficient and provably correct data synchronization.
                    </p>
                    <p>
                    While they are great for source code management, current version control systems are not suited as general purpose data systems. In order to benefit from such systems, the user needs to have a certain understanding of branches, merging, and conflict resolution, which is far beyond the knowledge of an average computer user. In addition, occasional merge conflicts are inevitable, and prevent such systems from being used in a transparent way.
                    </p>
                    <p>
                    Condensation has been designed from the ground up to address this. The result is a general-purpose data system with lightweight transactions and efficient data synchronization in a completely distributed setting. Merge conflicts are impossible by design, hence no user intervention is required during the synchronization process. The data itself is end-to-end encrypted and may be spread across multiple storage systems.
                    </p>

                    <h3>The evolution of architectures from online to offline and serverless systems.</h3>

                    <p>
                    The structure of the data has a direct influence on the dependency from and the role of a server. With SQL and noSQL databases, the centralized server is needed to synchronize data. Accordingly, it is the place where the application logic occurs. As a result, the system only works when being online. Also, as the data is read and processes by the server, it is vulnerable to data breaches.
                    </p>
                    <p>
                    Working offline became possible later, by storing documents in the application and defining schemas for synchronization when the application is turned back to online mode. However, this process is complex and requires a handling logic on both the client and the server side. Moreover, scaling a central database was a major issue. Many systems developed distributed systems for horizontal scaling but in a controlled data center setup where all servers are entrusted and available.
                    </p>
                    <p>
                    As described previously, Condensation only transfer immutable data on the network, which allows to build fully distributed but yet very simple systems. The following scheme summarizes the comparison between existing systems types.
                    </p>

                    <figure>
                        <img src="https://condensationdb.com/assets/img/cn-architectures.png" alt="Architectures">
                        <figcaption>Condensation shifts intelligence to the client-side and makes servers a simple encrypted storageâ€‹</figcaption>
                    </figure>

                    <figure>

                                <table id="table1">
                                  <thead>
                                    <tr>
                                      <th scope="col-3"></th>
                                      <th scope="col-3">
                                        <b>Online-only</b><br>
                                        2000-2015
                                      </th>
                                      <th scope="col-3">
                                        <b>Offline-first</b><br>
                                        2015-2020
                                      </th>
                                      <th scope="col-3">
                                        <b>Condensated</b><br>
                                        2021
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <th scope="row">
                                        <span>Code base</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Small
                                      </td>
                                      <td>
                                          Large
                                      </td>
                                      <td>
                                          Small
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Architecture</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Simple architecture, easy to understand
                                      </td>
                                      <td>
                                          Relatively complex architecture
                                      </td>
                                      <td>
                                          Simple architecture but requires "distributed mindset"
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Structure</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Centralized with full trust in cloud
                                      </td>
                                      <td>
                                          Centralized with full trust in cloud
                                      </td>
                                      <td>
                                          Distributed/Federated
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Synchronization</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          No synchronization necessary
                                      </td>
                                      <td>
                                          Correct data synchronization (two-way) is hard. Potentially different database schemas on client and server.
                                      </td>
                                      <td>
                                          Based on synchronization<br>
                                          Direct device-to-device sync possible
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Security</span>
                                        <span></span>
                                      </th>
                                      <td>
                                        Transport encryption only
                                      </td>
                                      <td>
                                        Transport encryption and SPOF engineered mitigation
                                      </td>
                                      <td>
                                        End-to-end encryption
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Authentication</span>
                                        <span></span>
                                      </th>
                                      <td>
                                        Login required
                                      </td>
                                      <td>
                                        Login required
                                      </td>
                                      <td>
                                        Login not necessary (but sometimes desired)
                                      </td>
                                    </tr>

                                  </tbody>
                                </table>
                    </figure>

                <p>
                Condensation leverage the advantages of immutable objects. You never have to lock them, which extremely improves concurrency also it improves simplicity as persistance to certify the data isn't compromised and exactly the same as the source. Furthermore, it allows to reduce the memory usage as objects can be reused to create new trees.
                </p>
                <p>
                Developers can benefit from features available by design such as: data certification with user signature, versionning with transaction history, and conflict free merge based on CRDTs.
                </p>
                <p>
                So, Condensation has a hybrid data structure, it merge data into mutable documents stored locally and transfers immutable objects through stores. The stores can be managed in a single server or in a purely distributed manner without introducing complexities.
                </p>
                <p>
                In the following sections, first the data structure is technically described to explain how Condensation transform a document into an immutable merkle tree. Next, to better understand how Condensation manage securely data on the network, the flow of the data through a â€¦</p></article></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://condensationdb.com/white-paper/">https://condensationdb.com/white-paper/</a></em></p>]]>
            </description>
            <link>https://condensationdb.com/white-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304202</guid>
            <pubDate>Mon, 01 Mar 2021 16:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A case for funding Open Source Software]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26303592">thread link</a>) | @jackyzhao
<br/>
March 1, 2021 | https://blog.jzhao.xyz/posts/paid-open-source/ | <a href="https://web.archive.org/web/*/https://blog.jzhao.xyz/posts/paid-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainText"><h2 id="making-of-open-source-software">Making of Open Source software</h2><p>Iâ€™ve recently made my way through <em>Working in Public: The Making and Maintenance of Open Source Software</em> by Nadia Eghbal. Not only does it have some absolutely stunning cover art, it also touches on some thoughts that have been marinating in my head about the intersection of open source and funding. So much so, that Iâ€™ve started experiencing the Baader-Meinhof effect, seeing something to do with open source and funding everywhere I look in tweets, conversations, and blogs.</p><p>This blog post is an exploration of processes in open source, the value it provides, and how money fits into the picture.</p><p><img src="https://blog.jzhao.xyz/img/oss_book.jpg" alt="Working in Public: The Making and Maintenance of Open Source Software"><em>Working in Public: The Making and Maintenance of Open Source Software</em></p><h3 id="how-its-made">How itâ€™s made</h3><blockquote><p>â€œOpen source developers were frequently characterized as â€˜hobbyâ€™ developers, because the assumption was that only companies could make â€˜realâ€™ software."<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p></blockquote><p>As it stands, there are two primary schools of thought about how open source software is created.</p><ol><li><p><strong>Firm-based</strong> production involves companies, organizations, governments, or any institution with centralized resources. Their driving thesis is that only companies make software because, from a coordination standpoint, centralized firms are the most efficient way to manage resources. Most development done this way is motivated extrinsically by means of monetary compensation.</p></li><li><p><strong>Commons-based</strong> production is a more vague concept that involves a distributed group of developers that work on a resource that is used, owned, and governed by its own community - free of employer affiliations. Most development done this way is motivated intrinsically, people do work because they want to do it.</p></li></ol><p>Traditionally, software has been seen as a product of firms. Open source developers were often treated as hobbyists and the projects they made trivialized as toys. The assumption was that only companies could make â€˜realâ€™ software. However, the rise of Internet computing and collaboration tools like Git have decreased the barrier to entry enough that producing software through a commons is now feasible and very much alive. The success of projects like Apache, Linux, and FreeBSD proved just how successful a commons-based method of production could be.</p><p>Surprisingly, this may also help to explain why some developers view open source and money as completely separate. If the commons-based method of production is rooted in intrinsic motivation, then money, an extrinsic motivator, will be seen as opposite to core ideals that open source stands for.</p><h2 id="creation-vs-maintenance">Creation vs Maintenance</h2><blockquote><p>â€œCreation is an intrinsic motivator, maintenance usually requires extrinsic motivationâ€</p><p>@balupton, isaacs/github <a href="https://github.com/isaacs/github/issues/167">#167</a></p></blockquote><p>When an artist finishes a painting, or a runner finishes a marathon, that usually signifies the end of said responsibility. There is no such finish line for an open source project, even after pushing out an initial product.</p><p>Creating a project is fun. Itâ€™s a wild exploration into a new idea, a frivolous journey to create something useful or to learn something new. As cloud platforms continue to eat the world, the costs of distributing and sharing a project are almost completely nullified.</p><p>Just a few clicks and a few taps of your keyboard and your project is readily available to any of the 4.66 billion people around the world with internet access. This adrenaline rush of finally releasing the labour of your work onto the world is the moment developers are constantly chasing. For most developers, the process of creation and distribution is intrinsically motivated; itâ€™s an enjoyable process.</p><p>Maintenance is less so. This is akin to a writer thatâ€™s been asked to edit and revise the same book day in and day out, long after theyâ€™ve reaped the initial financial and reputational rewards from its creation. Even when the creator wants to leave the project to work on something else, they canâ€™t. Theyâ€™re tightly shackled by the fact that hundreds of thousands of other organizations, companies, and tools rely on their code to keep their operations running. Bringing on additional developers may not help either, as they still require onboarding, code reviews, and general guidance.</p><p>Code may be nearly free to create and distribute, but maintenance is still expensive.</p><h2 id="types-of-code">Types of code</h2><h3 id="code-as-an-artifact">Code as an artifact</h3><p>There are two main ways we can look at code. The first of which is <em>static</em> code. Code that, on its own, does nothing but exists as an archive. Others can copy and download the code without incurring any additional costs to the author. For the maintainers, it should make no difference in regards to cost whether 10 or 10,000 people use it.</p><p>This type of code is a pool resource, it is</p><ol><li><strong>Non-rivalry.</strong> My ability to copy the code doesnâ€™t affect your ability to copy it. (This isnâ€™t exactly true due to some marginal costs but Iâ€™ll discuss this later)</li><li><strong>Non-excludable.</strong> If someone has a copy of the code, it is very difficult to prevent them from sharing that code with others.</li></ol><p>Any code that is in this state is easy to share, copy, and distribute. This is the type of code that lives dormant on Github, on StackOverflow answers, and in GitHubâ€™s Arctic Vault<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. However, the main purpose of consuming code is not to simply read and study it, but to actually use it and to let it interact with other code.
In doing so, we bring it to life.</p><h3 id="code-as-an-organism">Code as an organism</h3><blockquote><p>â€œOpen source code derives its value not from its static qualities but from its living ones."<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p></blockquote><p>As soon as you hit CTRL-V on that snippet of code, as soon as that static code is inserted into your own, that code comes to life. It might surface ridiculous amounts of red squigglies, break other code, or force you to rewrite your previous code just to make it work. When code transitions from a resting static state to an active living state, it starts to incur a set of hidden costs.</p><p>Like a living organism in a symbiotic relationship, there is a mutual interdependence between it and others in the software â€˜ecosystemâ€™ in order to survive. As a result, this ecosystem requires constant upkeep to ensure that components donâ€™t fall out of balance: dependency bumps, documentation updates, and infrastructure changes.</p><h2 id="free-as-in-speech-not-as-in-beer">Free as in speech, not as in beer</h2><p>â€˜Freeâ€™ software doesnâ€™t refer to its price. In fact, â€˜freeâ€™ software is often extremely expensive. As Richard Stallman first described free software, itâ€™s â€œfree as in speech, not free as in beer.â€ The point Stallman was trying to make was that â€˜freeâ€™ refers to what one could do with the software, rather than the price tag.</p><h3 id="latent-cost-of-software">Latent cost of software</h3><p>In reality, code in its alive state is more like a free puppy. In the beginning, itâ€™s a great and wonderful thing! Super fun and super cute. As it grows and gets older, you realize â€œgeez, it actually takes a lot of my own time to take care of this thing.â€ Unlike a piece of inanimate furniture, bringing a living creature into oneâ€™s home comes with bringing in a new set of responsibilities too.</p><p><strong>Marginal costs</strong> are costs increase on a per-user basis. I mentioned earlier that these costs mean that software is actually rivalrous, meaning that at some point, the project wonâ€™t be able to support the n+1th user. Some of this cost comes from physical infrastructure like code hosting and infrastructure. However, the majority of the cost comes from user support. Say you have a billion users and only 0.1% of them require support. If it takes you roughly 10 minutes to resolve each issue, you would still need 20,833 people working 8-hour shifts a day just to be able to keep up with the support volume. Maintainers are constantly wrestling with keeping their issue volume low and questions answered. Eventually, it just becomes a hindrance preventing them from working on the core product.</p><p><strong>Temporal costs</strong> are those which build up and compound over time. Most of it comes from technical debt, choices that are easier today at the expense of time and money in the future. This is the eternal battle against entropy: the inevitable decay of systems over time. When code changes, all the supporting knowledge that surrounds it must be updated too. Documentation, tutorials, programming books, videos, and more slowly become obsolete.</p><p>Paying off these latent costs is seldom intrinsically motivated. When people talk about how fun making new projects is or contributing to open source, itâ€™s never referring to writing documentation or refactoring code. This isnâ€™t the â€˜funâ€™ part of writing software. This is the nasty upkeep that goes into maintaining a building from the 1850s thatâ€™s had new rooms, plumbing, and electric wiring frankenstein-ed into it over the years.</p><h2 id="funding-open-source">Funding Open Source</h2><p>I first started on BentoML<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> as a casual contributor last summer, submitting a few decently sized PRs. It was almost all intrinsically motivated; I found issues that I enjoyed working on and that I knew I would learn lots from. Satisfied with my experience, I decided to join the team as a paid contractor expecting to just continue the type of work I was doing in the summer. As issue after issue piled on, I slowly started to realize just how much extra work being a maintainer meant and why it was a paid position. Making proposals, triaging issues, adding tests, and writing documentation took up the majority of my time. While I recognized it was important work, it was not work I was intrinsically motivated to do. Thus, to motivate people like me to get that work done, an extrinsic motivator â€“ in this case, money â€“ needed to be applied.</p><p>How do we best incentivize maintainers to work tasks stripped of the very excitement and promise of creation that initially drew them to the project in the first place? There is a jarring disconnect between work that is needed versus work that is intrinsically motivated. This is where I believe open source funding should play a role. There are two main potential avenues to go about this.</p><h3 id="funding-projects">Funding projects</h3><p>One possibility is to fund projects directly. This route builds a brand around the project. The status of the project then transcends any single personâ€™s contributions and becomes a tangible entity â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jzhao.xyz/posts/paid-open-source/">https://blog.jzhao.xyz/posts/paid-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.jzhao.xyz/posts/paid-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303592</guid>
            <pubDate>Mon, 01 Mar 2021 15:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Simple decentralized web hosting on Peergos]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26303144">thread link</a>) | @ianopolous
<br/>
March 1, 2021 | https://peergos.org/posts/p2p-web-hosting | <a href="https://web.archive.org/web/*/https://peergos.org/posts/p2p-web-hosting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You already know that Peergos lets you store and share files securely and privately. Now, you can also host your own website on it!</p>
<p>We always thought getting a website up and running should be one of the easiest things to do on the web. There are plenty of options available for website hosting, but with Peergos there's no need to buy a domain name, arrange TLS certificates, or run a server to host the content. You also don't need any cryptocurrency to post or update your website, so you can get free instantaneous updates and peer-to-peer authenticated delivery. You can sign up to <a href="https://beta.peergos.net/?signup=true">our beta</a> today and get started right away in just two easy steps:</p>
<ol>
<li>
Upload your website files to a directory in Peergos.
</li>
<li>
Go to your profile, set that directory as your website and click publish.
</li>
</ol>

<p>Your personal website will now be available at <tt>https://&lt;your-user-name&gt;.peergos.me</tt>. It doesn't get any simpler than that. Let's see this in action!</p>
<center>
<img alt="www" id="id" src="https://peergos.org/theme/img/blog/p2p-webhosting.gif" width="90%">
<br>
Host your decentralized website directly from Peergos.
</center>
<p>Any changes made to your website files are automatically and instantly reflected in your website. When we say instantaneous, we mean it. Check it out below!</p>
<center>
<img alt="www-update" id="id" src="https://peergos.org/theme/img/blog/p2p-web-update.gif" width="90%">
<br>
Instantaneous and free updates to your decentralized website.
</center>
<p>When you publish a website from Peergos, you can view it through any Peergos gateway. We're running one at <tt>peergos.me</tt>, so your website will be available at <tt>https://&lt;your-user-name&gt;.peergos.me</tt>, and viewable in any browser today. Bear in mind that viewing through a public gateway like that still relies on DNS and the TLS certificate authorities, which are both single points of failure that are vulnerable to attack. However, we can actually get around both of these by viewing someone's site through a local Peergos gateway. To visit someone's site in this way, you just run a local Peergos instance and browse to <tt>http://&lt;username&gt;.peergos.localhost:9000</tt>. The gateway looks up the public key of the username provided in the localhost subdomain via the Peergos PKI, then retrieves the website and serves it. All this is done without relying on DNS or TLS certificates anywhere. We are thus able to use localhost subdomains to achieve isolation and security between different sites served from one local gateway. </p>
<p>Websites hosted on Peergos benefit from our resilient and reliable decentralized architecture. Most of the heavy lifting is done by <a href="https://ipfs.io/">IPFS</a> through content addressing and public key based routing. With our architecture, we add fast mutable pointers and human-readable names. Therefore, you can trust that the content of your website will be readily available without having to rely on a single-point-of-failure-server anywhere. </p>
<p>In the future, we will enable viewing such websites directly inside the Peergos web interface. At that point, Peergos will really start to look like a new web.</p>
<p>There are still a few free accounts available on <a href="https://beta.peergos.net/?signup=true">our beta</a>. Let us know what you think. We're always looking for feedback, so either <a href="mailto://peergos@peergos.org">drop us a line</a> or come say hi in our <a href="https://app.element.io/#/room/#peergos-chat:matrix.org">Matrix chatroom</a>.</p>
<p>Stay tuned for introductions to a few other new features and apps we're building as part of our <a href="https://peergos.org/posts/next-generation-internet">grant</a> from the Next Generation Internet program (<a href="https://pointer.ngi.eu/">NGI POINTER</a>).</p>

<hr>
<center>
<img alt="NGI Pointer" height="65px" id="id" src="https://peergos.org/theme/img/ngi-logo.png">
<img alt="NGI Pointer" height="65" id="id" src="https://peergos.org/theme/img/eu.png">
</center>
<p>
This project has received funding from the European Unionâ€™s Horizon 2020 research and innovation programme within the framework of the NGI-POINTER Project funded under grant agreement No 871528</p>

<h4>RECENT POSTS</h4>
    </div></div>]]>
            </description>
            <link>https://peergos.org/posts/p2p-web-hosting</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303144</guid>
            <pubDate>Mon, 01 Mar 2021 14:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MKBHD TLDR: Summarizing YouTube Video Reviews with AI]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26302959">thread link</a>) | @tlochhead
<br/>
March 1, 2021 | https://tavis.cc/mkbhd-tldr/ | <a href="https://web.archive.org/web/*/https://tavis.cc/mkbhd-tldr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>YouTube is the fastest-growing platform for all sorts of content. Video reviews being one of them. I love the quality that goes into these reviews.</p>
<p>But what if there was a way to quickly grab consensus of these videos without spending hours watching them all?</p>
<p>TLDR: Yes. With AI.</p>
<p>See the results ðŸ‘‰&nbsp;<a href="https://twitter.com/MKBHDtldr" target="_blank" rel="nofollow noreferrer noopener">twitter.com/MKBHDtldr</a></p>
<p>
  <span>
    <span>
      <img alt="tw1" title="tw1" src="https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/07484/tw1.png" srcset="https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/d76be/tw1.png 135w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/01bf6/tw1.png 270w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/07484/tw1.png 540w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/d7542/tw1.png 810w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/302a4/tw1.png 1080w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/51800/tw1.png 1196w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<h2>Evolution of AI</h2>
<p>Alongside the rapid growth of YouTubeâ€™s popularity is AI innovation. One particular company that is gaining a lot of attention is Elon Musk-backed <a href="https://openai.com/" target="_blank" rel="nofollow noreferrer noopener">OpenAI</a>.</p>
<p>Last week, I was fortunate enough to join their private beta program. So very quickly, I decided to try something I have wanted to do with <a href="https://recorank.com/" target="_blank" rel="noopener">RecoRank</a> for some time: automated YouTube video review analysis using AI.</p>
<p>Iâ€™m a huge MKBHD fan. And as one of the top YouTube video reviewers, I tried using OpenAI to summarize his video review transcripts.</p>
<p><a href="https://twitter.com/MKBHDtldr" target="_blank" rel="nofollow noreferrer noopener">The results have been amazing so far.</a></p>
<p>
  <span>
    <span>
      <img alt="tw2" title="tw2" src="https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/07484/tw2.png" srcset="https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/d76be/tw2.png 135w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/01bf6/tw2.png 270w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/07484/tw2.png 540w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/d7542/tw2.png 810w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/302a4/tw2.png 1080w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/51800/tw2.png 1196w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<h2>Achieving These Results</h2>
<p><strong>Step 1: Extract Transcripts</strong></p>
<div data-language="text"><pre><code>from youtube_transcript_api import YouTubeTranscriptApi

subtitles = YouTubeTranscriptApi.get_transcript("dhAmMXCBIcg")

sub_list = []

for subtitle in subtitles:
    sub_list.append(subtitle['text'])

txt = " ".join(sub_list)

print(txt)</code></pre></div>
<p>This simple Python script using <a href="https://pypi.org/project/youtube-transcript-api/" target="_blank" rel="nofollow noreferrer noopener">YouTubeTranscriptApi</a> quickly gets you the transcript of any YouTube video - given that the video has a transcript. The API will produce an error if one does not exist.</p>
<p><strong>Step 2: Summarize with OpenAI</strong></p>
<p>
  <span>
    <span>
      <img alt="openai" title="openai" src="https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/07484/openai.png" srcset="https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d76be/openai.png 135w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/01bf6/openai.png 270w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/07484/openai.png 540w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d7542/openai.png 810w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/302a4/openai.png 1080w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d9ed5/openai.png 2880w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<p>I used OpenAIâ€™s <code>tl;dr:</code> (too long; didnâ€™t read) function to achieve AI-generated transcript summaries.</p>
<p>On top of the default settings, I also:</p>
<ul>
<li>Set temperature to <code>0</code> to exclude any improvisation of the results and get the summary with no guesswork</li>
<li>Added <code>The [product name]</code> right after <code>tl;dr:</code> to guide OpenAI on what I wanted (i.e. <code>The iPhone 12 is a great phone, but it's not a huge leap forward.</code> - I didnâ€™t do this for all summaries, but I did find that this method delivered the most consistent results than just using <code>tl;dr</code> on its own)</li>
<li>Deleted enough of the start of the transcript to fit within the 2048 token limit (in the case with most reviews, more of the meat is at the end than the beginning, particularly final thoughts)</li>
<li>Added a return break <code>âŽ</code> as a Stop Sequence to limit the results to one paragraph</li>
</ul>
<h2>Whatâ€™s Next?</h2>
<p>These are just the results of one week of experimentation with OpenAI. Pros and cons are other areas to explore.</p>
<p>These are the pros and cons results for MKBHDâ€™s Samsung Galaxy S21 review:</p>
<div data-language="text"><pre><code>Pros:
â€“ Great display
â€“ Great performance
â€“ Great cameras
â€“ Great battery life
â€“ Great design
â€“ Great value

Cons:
â€“ No expandable storage
â€“ No MST
â€“ No S Pen
â€“ No wireless charging</code></pre></div>
<p>Iâ€™m hoping to add these insights to <a href="https://recorank.com/" target="_blank" rel="noopener">RecoRank</a> soon.</p>
<p>My friend Adrian Krebs has a <a href="https://www.buyforlife.com/blog/548RijnkRdPwn1cAI5RDjw/make-better-and-faster-purchasing-decisions-with-ai" target="_blank" rel="noopener">blog post</a> about his trials in this area for his business, <a href="https://buyforlife.com/" target="_blank" rel="noopener">BuyForLife.com</a>. Definitely worth a read.</p>
<p>Have an idea of how OpenAI could be applied for review analysis and summarization? Iâ€™d love to hear from you. Hit me up on <a href="https://twitter.com/tavislochhead" target="_blank" rel="nofollow noreferrer noopener">Twitter</a> or send me an email @ tavislochhead [ at ] gmail [ dot ] com.</p></div><p><img src="https://tavis.cc/static/headshot-37e68c3c90409f03180397ce570be16e.jpeg" alt="profile pic"><strong><a href="https://tavis.cc/about">Tavis Lochhead</a></strong> <!-- -->is a seasoned marketer who loves tech and data. Tavis is the founder of<!-- --> <a href="https://recorank.com/" target=" _blank">RecoRank</a> <!-- -->and also consults as a marketer, programmer, and data analyst.</p></div>]]>
            </description>
            <link>https://tavis.cc/mkbhd-tldr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302959</guid>
            <pubDate>Mon, 01 Mar 2021 14:18:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving ADA a Chance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26302344">thread link</a>) | @jayp1418
<br/>
March 1, 2021 | https://ajxs.me/blog/Giving_Ada_a_chance.html | <a href="https://web.archive.org/web/*/https://ajxs.me/blog/Giving_Ada_a_chance.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<header>
				<a id="header-link" href="https://ajxs.me/">
					
				</a>
			</header>
			<section id="blog-entry">
	
	<div>
		<p><span>TL;DR:</span> Ada is an extremely interesting and robust programming language that has a lot to offer modern developers of system 
	and bare-metal software. At very least, Ada presents many interesting ideas that designers of modern programming languages could stand to learn much from. If you want a 30 second version of this article, check out the 
	<a href="#practical_example">practical example</a> that I provide for a comparison of Ada with C.</p>

<p>
	Much of the technical material presented in this article is available as part of <a href="https://wiki.osdev.org/User:Ajxs">my contributions</a> to <a href="https://wiki.osdev.org/Main_Page">osdev.org</a>
</p>
<p>
	I consider myself a rational man. While I may believe in an entirely deterministic model of the universe, I certainly
	do not believe it to be guided by any conscious process.
	I do not believe in destiny. This absence of guidance makes such fortuitous occurrences as the one I will discuss all
	the more extraordinary, and for this I am all the more grateful.
</p>

<h2>A Chance Collision</h2>
<p>
	By no deliberate design of my own, I happen to live close to a university. Not in the kind of â€˜University townâ€™ common
	to much of Europe or the United States, but in the densely packed suburban sprawl of the inner-city. My regular walk
	to and from the local shopping centre takes me past several of the buildings belonging to the highly regarded
	engineering faculty of the aforementioned University.
</p>
<p>
	Making my way home one serendipitous afternoon, I happened across a sizeable stack of books sitting on the curb
	outside one of the Universityâ€™s engineering buildings. The university was ostensibly in the process of liquidating its stockpile
	of old engineering books, and had left them in a pile for the local council to collect. Amongst material covering a
	wide variety of academic disciplines, two books in particular caught my eye: <i>Building Parallel, Embedded, and
	Real-Time Applications with Ada</i>, and <i>Concurrent and Real-Time Programming in Ada</i>.
</p>
<p>
	I had heard of Ada before. I understood that it came from a pedigree of languages developed for the United States
	military, and that it still occupied a niche in the development of safety-critical applications, nothing more.
	Curious, I threw the books in my bag and off I went.
</p>


<h2>Exceeding My Expectations</h2>
<p>Admittedly, I had pictured Adaâ€™s syntax resembling the uncompromising verbosity and rigid construction of COBOL, or
	perhaps the Lovecraftian hieroglyphics of Fortranâ€™s various eldritch incarnations. Turning the pages, I was pleasantly
	surprised by modern constructs associated with modern high-level languages such as ranges, slicing and
	exception-handling. The syntax â€” Admittedly verbose by modern standards<sup><a href="#footnote_3">3</a></sup> â€” seemed deliberately and purposefully
	constructed to make the language comprehensible at a glance.</p>
<p>The fact that Ada was designed with embedded-software in mind was of particular interest to me. I already had some
	limited experience with bare-metal development on the x86 and ARM platforms using C and assembly, so the prospect of
	using higher-level constructs on bare-metal seemed promising to me.</p>

<h2>Not the Camel You Expected</h2>
<p>A common pejorative refrain directed at Ada by its many detractors is that it is a language â€œdesigned by committeeâ€,
	or even worse, a language â€œdesigned by committee <i>for the military</i>â€<sup><a href="#footnote_1">1</a></sup>. The implication of which being that (so-called)
	design by committee precludes it from any real-world practicality. I contend that it is better to design a language to fit an
	existing problem domain than to pick your weapon of choice and set out in search of new problem domains to apply it
	to<sup><a href="#footnote_2">2</a></sup>. I will spare readers a detailed retelling of Adaâ€™s conception within the Department of Defenceâ€™s <a href="http://archive.adaic.com/pol-hist/history/holwg-93/holwg-93.htm">â€˜High Order
	Language Working Groupâ€™</a>, save to say that the Ada programming language was born of the need for single, unified
	higher-level language suitable for use in the multitude of Real-Time Embedded systems developed by the DoD<sup><a href="#footnote_4">4</a></sup>. In the
	wise words of the working-groupâ€™s chair, Colonel William A. Whitaker: â€œIt was concluded that no existing language
	could be adopted as a single common high order language for the DoD, but that a single language meeting essentially
	all the requirements was both feasible and desirable.â€. If such a thing was indeed feasible, the DoDâ€™s deep pockets
	would help it bring it into existence. Ironically, given its status as the de-facto standard language of modern embedded-system development, the C language was considered unsuitable for this purpose: â€œWhen Bell Labs were
	invited to evaluate C against the DoD requirements, they said that there was no chance of C meeting the requirements
	of readability, safety, etc.â€ (Whitaker, 1993). After its successful implementation, in what would prove a controversial decision, the DoD would go so far as to mandate 
	the use of Ada for all in-house software engineering.</p>

<h2>So What Makes It Special?</h2>
<p>
	Ada has many useful features that are of particular interest for low-level programming and operating-system development. One
	feature in particular that impressed me greatly was Adaâ€™s <i>representation clauses</i> (see below). They provide a highly granular way to define the
	in-memory representation of low-level data structures. I was very quickly able to adapt my own long suffering operating-system development project to Ada, improving the
	quality of my codebase greatly in the process. The following section details some of Adaâ€™s features:
</p>

<h3>Custom Types</h3>
<p>
	In addition to being a strongly typed language, Ada allows for the definition of new scalar, enumerated and record types.
	Custom primitive types can also be constrained to a predefined range of values.
	The example below demonstrates the definition of a new integer type based upon Adaâ€™s native <code>Natural</code> type, restricted
	to a predefined range.
	The use of the subtype directive informs the compiler that other variables of the <code>Natural</code> type are compatible with
	the newly defined subtype.
</p>

<div><pre><span></span><span>VGA_COL_COUNT</span> <span>:</span> <span>constant</span> <span>:=</span> <span>80</span><span>;</span>
<span>VGA_ROW_COUNT</span> <span>:</span> <span>constant</span> <span>:=</span> <span>24</span><span>;</span>

<span>subtype</span> <span>Col</span> <span>is</span> <span>Natural</span> <span>range</span> <span>0</span> <span>..</span> <span>VGA_COL_COUNT</span> <span>-</span> <span>1</span><span>;</span>
<span>subtype</span> <span>Row</span> <span>is</span> <span>Natural</span> <span>range</span> <span>0</span> <span>..</span> <span>VGA_ROW_COUNT</span> <span>-</span> <span>1</span><span>;</span>
</pre></div>

<p>
	The below example illustrates the creation of incompatible custom integer types. While their base type and range
	constraints are identical, Ada treats both as separate, incompatible types. An assignment of a variable of one type
	to the value of another is illegal, and will trigger a compile-time error.
</p>

<div><pre><span></span><span>type</span> <span>Integer_1</span> <span>is</span> <span>range</span> <span>1</span> <span>..</span> <span>10</span><span>;</span>
<span>type</span> <span>Integer_2</span> <span>is</span> <span>range</span> <span>1</span> <span>..</span> <span>10</span><span>;</span>
<span>A</span> <span>:</span> <span>Integer_1</span> <span>:=</span> <span>8</span><span>;</span>
<span>B</span> <span>:</span> <span>Integer_2</span> <span>:=</span> <span>A</span><span>;</span> <span>-- illegal!</span>
</pre></div>

<p>
	The following example demonstrates the creation of a custom enumerated type. It also demonstrates a subtype of an enumerated type with a constrained range of values.
</p>

<div><pre><span></span><span>type</span> <span>Day_Of_Week</span> <span>is</span> <span>(</span><span>Monday</span><span>,</span> <span>Tuesday</span><span>,</span>
  <span>Wednesday</span><span>,</span> <span>Thursday</span><span>,</span> <span>Friday</span><span>,</span> <span>Saturday</span><span>,</span> <span>Sunday</span><span>);</span>

<span>subtype</span> <span>Work_Day</span> <span>is</span> <span>Day_Of_Week</span> <span>range</span> <span>Monday</span> <span>..</span> <span>Friday</span><span>;</span>
</pre></div>


<p>
	A variable with the type of <code>Work_Day</code> is restricted to its constrained range. Any attempt to assign a value outside
	of this range to a variable of this type will raise a <code>Constraint_Error</code> exception at runtime.
</p>

<h2>Representation Clauses</h2>
<p>
	Ada allows for explicitly defining the in-memory representation of scalar and compound types. The following example
	demonstrates the definition of a record type (equivalent to structures in C), as well as its associated
	representation in memory.
</p>

<div><pre><span></span><span>----------------------------------------------------------------------------</span>
<span>--  The format of the System Table Descriptor pointer used by the processor</span>
<span>--  to load descriptor tables like the GDT and IDT.</span>
<span>----------------------------------------------------------------------------</span>
<span>type</span> <span>System_Table_Descriptor</span> <span>is</span>
   <span>record</span>
      <span>Size</span>   <span>:</span> <span>Unsigned_16</span><span>;</span>
      <span>Offset</span> <span>:</span> <span>System</span><span>.</span><span>Address</span><span>;</span>
   <span>end record</span>
<span>with</span> <span>Size</span> <span>=&gt;</span> <span>48</span><span>;</span>
<span>for</span> <span>System_Table_Descriptor</span> <span>use</span>
   <span>record</span>
      <span>Size</span>   <span>at</span> <span>0</span> <span>range</span> <span>0</span>  <span>..</span> <span>15</span><span>;</span>
      <span>Offset</span> <span>at</span> <span>0</span> <span>range</span> <span>16</span> <span>..</span> <span>47</span><span>;</span>
   <span>end</span> <span>record</span><span>;</span>
</pre></div>

<p>
	The <code>Size</code> aspect specifier instructs the compiler that the <code>System_Table_Descriptor</code> type must be 48 bits in size. The
	record representation clause instructs the compiler as to the required layout of this record type in memory. This
	example specifies that the <code>Size</code> member should occupy bits 0 to 15, and the <code>Offset</code> member should occupy bits 16 to
	47. This feature is analogous to Câ€™s bit-fields. The following example demonstrates defining the in-memory
	representation of an enumerated type.
</p>

<div><pre><span></span><span>----------------------------------------------------------------------------</span>
<span>--  The privilege level for a particular descriptor.</span>
<span>--  These correspond to the 'protection ring' that this descriptor is</span>
<span>--  accessible from.</span>
<span>----------------------------------------------------------------------------</span>
<span>type</span> <span>Descriptor_Privilege_Level</span> <span>is</span> <span>(</span>
   <span>Ring_0</span><span>,</span>
   <span>Ring_1</span><span>,</span>
   <span>Ring_2</span><span>,</span>
   <span>Ring_3</span>
<span>)</span>
<span>with</span> <span>Size</span> <span>=&gt;</span> <span>2</span><span>;</span>
<span>for</span> <span>Descriptor_Privilege_Level</span> <span>use</span> <span>(</span>
   <span>Ring_0</span> <span>=&gt;</span> <span>0</span><span>,</span>
   <span>Ring_1</span> <span>=&gt;</span> <span>1</span><span>,</span>
   <span>Ring_2</span> <span>=&gt;</span> <span>2</span><span>,</span>
   <span>Ring_3</span> <span>=&gt;</span> <span>3</span>
<span>);</span>
</pre></div>


<p>
	The <code>Size</code> aspect specifier instructs the compiler that the <code>Descriptor_Privilege_Level</code> type must be 2 bits in size.
	The representation clause instructs the compiler as to required representation of each possible value of the
	enumerated type in memory. In this example the value of <code>Ring_0</code> will be represented by a value of <code>0x0</code> in memory, the
	value of <code>Ring_1</code> will be represented by <code>0x1</code>, and so on.
</p>

<h2 id="practical_example">A Practical Example</h2>

<p>
	The following example, and accompanying comparison with C, demonstrates the configuration of a hypothetical UART device by interfacing with an 8-bit memory-mapped configuration register. 
	This example has been adapted from a presentation by AdaCore viewable <a href="https://www.youtube.com/watch?v=qvmDqbuQe-M">here</a>.
</p>

<div><pre><span></span><span>with</span> <span>System.Storage_Elements</span><span>;</span> <span>use</span> <span>System.Storage_Elements</span><span>;</span>

<span>-------------------------------------------------------------------------------</span>
<span>--  Main</span>
<span>-------------------------------------------------------------------------------</span>
<span>procedure</span> <span>Main</span> <span>is</span>
   <span>----------------------------------------------------------------------------</span>
   <span>--  Baud rate type.</span>
   <span>----------------------------------------------------------------------------</span>
   <span>type</span> <span>Baud_Rate_T</span> <span>is</span> <span>(</span><span>b_9600</span><span>,</span> <span>b_14400</span><span>,</span> <span>b_115200</span><span>);</span></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ajxs.me/blog/Giving_Ada_a_chance.html">https://ajxs.me/blog/Giving_Ada_a_chance.html</a></em></p>]]>
            </description>
            <link>https://ajxs.me/blog/Giving_Ada_a_chance.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302344</guid>
            <pubDate>Mon, 01 Mar 2021 13:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolidRun 1U 2 node Arm Server]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26302237">thread link</a>) | @cameron_b
<br/>
March 1, 2021 | https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg" data-caption="SolidRun Honeycomb LX2 Server"><img width="696" height="448" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-652x420.jpg 652w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="SolidRun Honeycomb LX2 Server" title="SolidRun Honeycomb LX2 Server"></a><figcaption>SolidRun Honeycomb LX2 Server</figcaption></figure></div>
            <!-- content --><p>SolidRun has a new development in their NXP Layerscape LX2160A based systems this week. The new SolidRun HoneyComb LX2 Server packages two of their familiar HoneyComb LX2K boards into a single chassis. This includes a power supply and accommodations for 2.5â€³ or 3.5â€³ SATA storage. While the board at the core of this system is not a new part this does mark a milestone for deploy-ability of Arm systems at a tier that does not have a lot of other attention.<span id="more-51095"></span></p>
<h2>SolidRun HoneyComb LX2 Server Background</h2>
<p>To take a step back and look at where this system lands, the Arm ecosystem currently has a lot of activity at the top and bottom of the price and performance spectrum, with not a lot of options in the middle. That is where SolidRunâ€™s new dual-node server aims to compete.</p>
<figure id="attachment_51102" aria-describedby="caption-attachment-51102"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-server-front/" rel="attachment wp-att-51102"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front.jpg" alt="SolidRun Honeycomb LX2 Server Front" width="1110" height="722" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front.jpg 1110w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-400x260.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-800x520.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-696x453.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-1068x695.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-646x420.jpg 646w" sizes="(max-width: 1110px) 100vw, 1110px"></a><figcaption id="caption-attachment-51102">SolidRun HoneyComb LX2 Server Front</figcaption></figure>
<p>Raspberry Pi systems between $5 and $100 have shipped over 30 million units. Developer kits such as these have earned a level of ubiquity in learning and DIY spaces for making it really easy to try out new concepts in programming or â€œphysical computing.â€ While the Raspberry Pi Foundation has demonstrated using the Raspberry Pi 4 in production, including running Raspberry Pi 4s to serve their website for the launch of the Pi 4, that is not quite what they are designed for. In that example, the Foundation included their own hardware between more performant load balancers and database machines as a demonstration of their very capable new devices, not quite as a shot across the bow to the Xeons they may have replaced.</p>
<figure id="attachment_49430" aria-describedby="caption-attachment-49430"><a href="https://www.servethehome.com/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-review/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-4/" rel="attachment wp-att-49430"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4.jpg" alt="MyElectronics.nl Apple Mac Mini And Raspberry Pi Rack 4" width="800" height="534" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-629x420.jpg 629w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-49430">MyElectronics.nl Apple Mac Mini And Raspberry Pi Rack</figcaption></figure>
<p>On the other end of the spectrum, several orders of magnitude away, Ampere Altra is making a case for permanently replacing some of those Xeons for certain customers. Ampereâ€™s price-to-performance numbers are impressive, as are figures like 160 cores for a 2 socket server and 128 lanes of PCIe Gen4 per socket. This underscores that this is a platform designed for cloud providers and hyperscalers. You can check out STHâ€™s <a href="https://www.servethehome.com/ampere-altra-wiwynn-mt-jade-server-review-the-most-significant-arm-server/">Ampere Altra Wiwynn Mt. Jade Server Review</a> to learn more.</p>
<figure id="attachment_49505" aria-describedby="caption-attachment-49505"><a href="https://www.servethehome.com/ampere-altra-wiwynn-mt-jade-server-review-the-most-significant-arm-server/amd-epyc-ampere-altra-intel-xeon-cascade-lake-small-2/" rel="attachment wp-att-49505"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1.jpg" alt="AMD EPYC Ampere Altra Intel Xeon Cascade Lake Small" width="800" height="487" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-400x244.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-696x424.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-690x420.jpg 690w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-49505">AMD EPYC Ampere Altra Intel Xeon Cascade Lake Small</figcaption></figure>
<p>There is enough intrigue over the top-of-line Arm servers that developers wonder if there is not a better workstation-level/ or entry/mid-range server system. A prospective Arm developer would want something between $100 for a dev board and $4000 per socket for a screaming 2U. (Apologies to the $800 32-core 1.7GHz SKU at the other end of the Ampere Altra line.)</p>
<p>SolidRun has been positioning itself in this space for several years. Its LX2 products continue in active development. HoneyCombâ€™s maturity dovetails with the work SolidRun has been doing on two fronts. It is servicing its niche and driving specific development (for example their high bandwidth networking) but return their development work to benefit the ease of adoption from mainline Linux.</p>
<figure id="attachment_51103" aria-describedby="caption-attachment-51103"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-board-with-annotations/" rel="attachment wp-att-51103"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations.jpg" alt="SolidRun HoneyComb LX2 Board With Annotations" width="1030" height="789" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations.jpg 1030w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-392x300.jpg 392w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-800x613.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-696x533.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-548x420.jpg 548w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-80x60.jpg 80w" sizes="(max-width: 1030px) 100vw, 1030px"></a><figcaption id="caption-attachment-51103">SolidRun HoneyComb LX2 Board With Annotations</figcaption></figure>
<p>The HoneyComb LX2K is a COM Express Type 7 carrier for an NXP Layerscape LX2160A System-on-Chip with 16x Arm A72 cores running up to 2GHz. The COM Express Type 7 module has dual-channel DDR4 in SODIMMs for up to 64GB total. The carrier board exposes 4x SATA, one M.2 and one Micro SD slot for storage, four SFP+ (directly from the SoC) and one RJ45 at 1Gb for networking, dual USB 3.0 ports, and an open-ended PCIe x8 slot on a standard mini ITX form factor using standard ATX power. There is even the ATX standard power indicator and reset button header. The goal seems to be to create a platform that is easy to integrate into existing chassis and systems.</p>
<figure id="attachment_51101" aria-describedby="caption-attachment-51101"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-server/" rel="attachment wp-att-51101"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg" alt="SolidRun Honeycomb LX2 Server" width="800" height="515" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-652x420.jpg 652w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-51101">SolidRun HoneyComb LX2 Server</figcaption></figure>
<p>In the context of running highly deployable servers to replace Xeons, this may not be quite the same level of hardware maturity. On the other hand, having a dual-node 1U platform that one can deploy in racks and do Arm development is a big step forward. Not only do we get a bigger CPU, but we also get the ability to use a lot of standard components which will help boost the ecosystem as well. Adding a chassis with cooling and power may not seem like a big deal, but there is a large segment of the market that does not want to search for or cobble together these solutions. Instead, if the nodes are already in a 1U chassis, that lowers the friction and barriers to entry for development. This is still not a $400-500 PC or Atom server. Still, it is an important step in the right direction.</p>
<h2>Final Words</h2>
<p>SolidRunâ€™s HoneyComb LX2K is a platform that is accessible and capable for development on 64-bit Arm architecture as a workstation. It is also becoming more deployment-ready for appliance-type power-conscious edge applications with the 1U chassis. Developers interested in using the HoneyComb board in production have faced the challenge of trying to rack-mount an ITX board. Bamboo Systems in the UK have an answer for developers ready to deploy an 8-node 1U, but that raises the bar back up the scale of Ampere Altra. The challenge with small server nodes is that as one scales, it tends to be more efficient having larger nodes. AWS Gravition2 is an important product for the industry, but it is also tied to the AWS ecosystem. The new availability to deploy two nodes in 1U targets the intersection of accessibility and capability for those interested to kick the tires on Arm in the wild.</p>
<p>We look forward to getting our hands on the dual sled system and doing an in-depth review. We will also pair that with approaching the HoneyComb Board as a workstation for daily-driver use. Leave a comment if you would like to see specific applications explored for either system.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302237</guid>
            <pubDate>Mon, 01 Mar 2021 12:46:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts Around Naming Variables]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26301622">thread link</a>) | @todsacerdoti
<br/>
March 1, 2021 | https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1 | <a href="https://web.archive.org/web/*/https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        
<blockquote>
<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
</blockquote>
<p>I don't remember when I heard that, but it stuck. When a quip "clicks" for me, I can't rest until I find a framing in which it's disproved. But it's been 6 years now, and I'm still unable to muster a reply to the above other than "Yeah, yeah, it seems so".</p>
<p>I'm pretty sure cache invalidation is the harder of the two, because of some underlying OCD most of us have about picking two arbitrary constants that dictate sweep frequency and TTL. I'd even go as far as to speculate most of the evolution of programming has been a weird spiritual exercise around trying not to pick those two arbitrary numbers. Functional programming as a whole can even be understood as a set of taboos around this, because what good is shared OCD if it doesn't lead to religion.</p>
<p>I digress, I'm neither old, wise nor crazy enough to talk about cache invalidation, so I'll talk about the second hardest thing in programming instead, naming things.</p>
<h2>i - Naming necessity</h2>
<p>Maybe I'm being vague here, but please bear with me, I am trying to introduce the practice that leads to the creation of civilization and distinguishes us from apes</p>
<p>Naming helps one make sense of code.</p>
<p>That's not quite right... naming <em>gives</em> sense to code.</p>
<p>In theory, names could be arbitrary, at the ASM level it's more than reasonable to replace names with addresses. Yet names are so useful, that they persist even when code is compiled, presumably because they help preserve sanity when one is forced to look at the generate ASM.</p>
<p>In so far as names help make sense of code, they operate at different levels.</p>
<p>Names help connect the developer with the end goal of the software. I think the main reason OO became popular as a paradigm for teaching was a culture of example programs that used names referencing the "real world". Using words like "Shop" and "Transaction" and "buy" and "transfer_to", that give the student's bored brain some bit of reality to hang on to.</p>
<p>Names help in building a mental map of software. In this regard, names function much like <a href="https://slatestarcodex.com/2014/11/21/the-categories-were-made-for-man-not-man-for-the-categories/">any other arbitrary category we instil upon the world</a>, be it those that we use to refer to animals, other people, the night's sky or, to make the similarity to code more obvious, the content of one's bowel movement. In this sense, names should optimize for a map of the code that makes sense to the one writing it, you.</p>
<p>I'm just kidding though, the "you" here is really "a team" and the "a team" here is really "a team with people coming and going, people which have imperfect memory and ever-changing minds with which they read that map".</p>
<p>We can already see some tradeoffs here. Names that will help you now are not necessarily ones that will help the team 5 years from now. Maybe <code>let IHateThisFingLoop</code> is a useful outlet for one's anger or <code>val steves_moms = FAT32()</code> provided some much needed comedic relief. But naming for the moment can often backfire. Not only when naming for catharsis. We have such a good map of the code we're working on <strong>now</strong> that an "obvious" name can be a horrible choice in hindsight. Depending on our mental context, the name <code>trx</code> might be a much-welcomed shorthand for <code>write_new_credentials_transaction</code>, or it might be the cause of a security error that makes the news.</p>
<p>Names aren't there just to express the concepts we already have, once a name is chosen, if encountered often enough, it becomes its own concept. One need only looks at the old sciences to see arbitrary variable names that are now rooted in people's mindsdb as describing the fundamental nature of reality in an irreducible way. <code>pi</code> and <code>e</code> as representations of the circle, <code>x</code> as describing the concept of unkown, <code>c</code> as describing the maximum speed an object can travel with if Maxwell's equations are to hold... etc).</p>
<p>If a perfectly-named codebase were to exist, it would provide the reader with an amazing understanding of the things it's used for, in addition to being easy to grok. The sad thing is that "perfectly-named" is something that varies between people and even within people (over time).</p>
<p>I also think that the "experience" people have with names might vary greatly based on the codebases they worked on. Working in a large codebase with loads of existing names and naming standards provides a completely different naming-experience from building something from scratch.</p>
<p>Indeed, understanding a codebase or even a language can probably be boiled down to being familiar with all of its names and naming convention.</p>
<p>There might be a type of person that can remember all the names of the functions in a stdlib and yet know nothing about a language. But, in spite of our education system trying to optimize for the psychiatric illness which would allow this, for the vast majority of people understanding a language still boils down to knowing the vocabulary.</p>
<h2>ii - Naming convention</h2>
<p>The foreplay to naming things is coming up with conventions about naming things. A convention dictates the boundaries of what names one can give in various situations. For example, the conventions I usually impose are:</p>
<ul>
<li>class and struct names should be CammelCase</li>
<li>function and variable names should be snake_case</li>
<li>constants (in the constexpr sense), enum members and global aliases should be ALL_CAPS_SANKE_CASE</li>
<li>function only used inside the file they are in have names starting with <code>_</code></li>
<li>names should be &gt;1 and &lt;20 letters, &gt;0 and &lt;5 words, exceptions are allowed</li>
<li>If the type of a variable is not obvious from usage, have a name that implies the type (e.g. <code>customer_arr</code>, <code>equation_dict</code>)</li>
</ul>
<p>None of it is written down in our coding guidelines, people just sort of "catch onto it", even first-time contributors, I find this fascinating.</p>
<p>There are many things new people seem to miss that I have to re-iterate time and time again, but naming is never one of them. Nor was it ever a problem for me when joining a new team to pick up on their conventions.</p>
<p>Though maybe this ease of adoption would disappear if the conventions were too niche or too many?</p>
<p>Conventions are useful for two major reasons:</p>
<ol>
<li>They reduce the thought space when searching for a good name.</li>
<li>They add meaning to existing names without making them longer.</li>
</ol>
<p>If you want to understand naming go digging for conventions, but due to the above issue (people catch onto them instinctively), good conventions are hard to find. Some conventions were so good they got codified into language syntax.</p>
<p>Did you know <code>const</code> (i.e. immutability) wasn't a thing in any popular programming language until the early 80s when C++ came along? People (presumably) used to write it as part of variable names and hope that it would be respected by convention.</p>
<p>The idea of objects and classes are essentially a mix of naming and file-placement conventions that got mixed, at least in imperative land.</p>
<p>Even more so, one suspects that "types" were originally a mere naming convention, though the asteroid destroyed most of the evidence that could be used to conclude that with certainty. But nowadays "types" seem to be used as part of names in language lacking a type system.</p>
<h2>iii - Naming history</h2>
<p>But, asks the reader of 2050, I heard that back in your days there as a field called "mathematics", a thing humans did before computers, where they tried (and often failed miserably) to <a href="https://blog.cerebralab.com/Neural_networks_as_non-leaky_mathematical_abstraction">use their brains to execute formal logic</a>.</p>
<p>You are quite perceptive in remaking that, and I agree we can't understand naming in programming while ignoring 3000 years of naming in mathematics. The most basic names in programming, those shared between most languages, those of the operators (+,-,*,/,^,&amp; ...etc) are pulled out or inspired from math.</p>
<p>In my arbitrarily chosen view of the world, mathematics was an imperfect tool with imperfect creators built in a time before modern brains and modern machines, thus it's riddled with <a href="https://cerebralab.com/Named_Distributions_as_Artifacts">flaws and limitations</a>. One of the most obvious flaws in the way things were named.</p>
<p>When using "math notation" people tended to prefer very short names, namely 1 symbol long. A programmer might write something akin to:</p>
<pre><code>function calc_quarterly_interest(principal, rate, quarters):
    return principal*rate*time
</code></pre>
<p>Though the most obsessive might go all the way to writing:</p>
<pre><code>function calculate_quarterly_interest(principal, rate, quarters):
    quarterly_returns = multiply(principal, rate)
    return multiply(quarterly_returns, time)
</code></pre>
<p>However, in math notation, it would be considered bad form to write anything longer or more expressive than</p>
<pre><code>i(p,r,q)=p*r*q

</code></pre>
<p>The reason for this, I presume, boils down to two things:</p>
<ol>
<li>Saving paper, which could often be quite expensive and impossible to erase.</li>
<li>Reducing the amount of writing in materials like sand or clay, which are cheap and easy to erase, but difficult to write in.</li>
</ol>
<p>This didn't cause many issues because our brains are not very good at executing formal logic. So a given mathematical construct might have included 2, 3, 5 maybe 10 entities playing around. But to postulate an equation with thousands of variable probably seemed like madness even to a genius like Euler or grand curator like Euclid.</p>
<p>Of course, we live in an age where a mildly talented 8-year-old can pick up a toy language like Scratch and construct such an equation incidentally while writing a web app. Nowadays we need only write the equations, historically our brains were also responsible for executing them. This restricted the realm of possibilities to one so tiny I shudders to think about the lamentable condition of the poor souls that helped us get to where we could build computers.</p>
<p>Still, the reason why the previously mentioned interest computing function would work is that the writer could simply specify beforehand: "p stands for principal, r for rate, q for number of quarters".</p>
<p>This is a practice that remained with us until the 80s in a weird way, the name of variables used to be declared at the beginning of a file before they were initialized. Though it may seem crazy to you, C and C++ allow you to compile the following code:</p>
<pre><code>int a;</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1">https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301622</guid>
            <pubDate>Mon, 01 Mar 2021 11:12:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applicative Parsing]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26301543">thread link</a>) | @gbrown_
<br/>
March 1, 2021 | https://jobjo.github.io/2019/05/19/applicative-parsing.html | <a href="https://web.archive.org/web/*/https://jobjo.github.io/2019/05/19/applicative-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p><a href="https://en.wikipedia.org/wiki/Parser_combinator">Parser combinators</a> are
sets of functions for building parsers in a composable fashion. Haskellâ€™s
<a href="http://hackage.haskell.org/package/parsec">Parsec library</a> and OCamlâ€™s
<a href="https://github.com/inhabitedtype/angstrom">Angstrom</a> are two examples.
Both of these libraries expose <em>monadic</em> interfaces for
describing context-sensitive grammars. This post looks at implementing a more
restricted parsing library, structured around <a href="https://en.wikipedia.org/wiki/Applicative_functor">applicative
functors</a> rather
than monads.</p>

<p>What could justify giving up on monads? Depending on the design, one may get
a few things in return. In this exercise, the aim is for an API with the following
features:</p>

<ol>
  <li>The ability to extract all valid symbols from a parser.</li>
  <li>Allow some form of pretty printing.</li>
  <li>Support multiple evaluation strategies (e.g. backtracking and non-backtracking).</li>
</ol>

<p>To see why (1) is not possible to accomplish with monads, consider a parser
constructed using the monadic <em>bind-operator</em>:</p>



<p>Here, <code>f</code> is a function of the form <code>'a -&gt; 'b parser</code>; that means we donâ€™t
know what sort of parser it produces until itâ€™s provided with a value. Therefore,
we cannot infer all possible symbols consumed by those parsers. The same
reasoning applies to pretty printing.</p>

<h3 id="designing-a-parser-type">Designing a parser type</h3>

<p>The essence of a parser is a function with a type analogous to:</p>

<div><div><pre><code><span>char</span> <span>list</span> <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>*</span> <span>char</span> <span>list</span><span>)</span> <span>option</span>
</code></pre></div></div>

<p>A parser takes a list of characters as input, and, when successful, returns a
parsed value along with the remaining input.</p>

<p>This representation, however, falls short of supporting symbol
extraction, pretty printing, or allowing for multiple evaluation strategies.
To accommodate for those weâ€™d have to embellish the type with more context.
The problem is we donâ€™t necessarily know the complete feature set upfront.
Every time a request for some new capability comes in â€“ be it error reporting,
logging or something else â€“ we would have to go back and change the definition
to accommodate for the new functionality.</p>

<p>Rather than trying to anticipate all use cases upfront, an alternative
approach is to choose a representation that preserves as much structure as
possible, so that alternative interpreters may be added later on. To do that,
weâ€™re effectively going to enumerate the set of parsers, and ways of
combining them, by defining a type for representing an abstract syntax tree
(AST). To this purpose, weâ€™ll use a
<a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>, that
also expresses that different parsers are indexed by different types. The
initial constructors are split into two sets â€“ primitive ones (the
leaf nodes of the tree), and combinators for composing parsers:</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>(* Primitive parsers *)</span>
  <span>|</span> <span>Fail</span>      <span>:</span> <span>string</span>            <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
  <span>|</span> <span>Empty</span>     <span>:</span>                       <span>unit</span> <span>t</span>
  <span>|</span> <span>Return</span>    <span>:</span> <span>'</span><span>a</span>                <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
  <span>|</span> <span>Symbol</span>    <span>:</span> <span>char</span>              <span>-&gt;</span> <span>char</span> <span>t</span>
  <span>(* Composition - applicative *)</span>
  <span>|</span> <span>Map</span>       <span>:</span> <span>(</span><span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span><span>)</span> <span>*</span> <span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>'</span><span>b</span> <span>t</span>
  <span>|</span> <span>Product</span>   <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>*</span> <span>'</span><span>b</span> <span>t</span>       <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>*</span> <span>'</span><span>b</span><span>)</span> <span>t</span>
  <span>(* Composition - alternative *)</span>
  <span>|</span> <span>Either</span>    <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>*</span> <span>'</span><span>a</span> <span>t</span>       <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
</code></pre></div></div>

<p>The primitive parsers are:</p>

<ul>
  <li><code>Fail msg</code> - a parser that always fails.</li>
  <li><code>Empty</code> - a parser that succeeds when given empty input.</li>
  <li><code>Return x</code> - a parser that does not consume any input and always returns <code>x</code>.</li>
  <li><code>Symbol c</code> - a parser that matches input when the first character is <code>c</code>.</li>
</ul>

<p>The applicative interface is what provides sequential composition, as in:
first parse <code>x</code> with parser <code>p1</code>, then parse <code>y</code> with parser <code>p2</code> and combine
their results.</p>

<p>The <code>Either</code> constructor makes it possible to provide alternative execution
paths, i.e. parsers that succeed on different types of input.</p>

<p>As we donâ€™t want to give users direct access to the type, weâ€™ll mechanically
add some smart constructors:</p>

<div><div><pre><code><span>let</span> <span>empty</span> <span>=</span> <span>Empty</span>

<span>let</span> <span>fail</span> <span>m</span> <span>=</span> <span>Fail</span> <span>m</span>

<span>let</span> <span>return</span> <span>x</span> <span>=</span> <span>Return</span> <span>x</span>

<span>let</span> <span>symbol</span> <span>c</span> <span>=</span> <span>Symbol</span> <span>c</span>

<span>let</span> <span>map</span> <span>f</span> <span>x</span> <span>=</span> <span>Map</span> <span>(</span><span>f</span><span>,</span> <span>x</span><span>)</span>

<span>let</span> <span>product</span> <span>p</span> <span>q</span> <span>=</span> <span>Product</span> <span>(</span><span>p</span><span>,</span><span>q</span><span>)</span>

<span>let</span> <span>either</span> <span>p</span> <span>q</span> <span>=</span> <span>Either</span> <span>(</span><span>p</span><span>,</span><span>q</span><span>)</span>
</code></pre></div></div>

<p>Having an applicative interface means that it is also possible to leverage
the new syntax extension â€“ the <code>let+ .. and+</code> notation â€“ which Iâ€™ve described
<a href="http://jobjo.github.io//2019/04/24/ocaml-has-some-new-shiny-syntax.html">here</a>.
Assuming OCaml 4.08 or the dune
<a href="https://discuss.ocaml.org/t/let-syntax-backported-to-ocaml-4-02/3447">future_syntax stanza</a>
, we can add a syntax module, like so:</p>

<div><div><pre><code><span>module</span> <span>Syntax</span> <span>=</span> <span>struct</span>
  <span>let</span> <span>(</span><span>let</span><span>+</span><span>)</span> <span>p</span> <span>f</span> <span>=</span> <span>map</span> <span>f</span> <span>p</span>
  <span>let</span> <span>(</span><span>and</span><span>+</span><span>)</span> <span>p</span> <span>q</span> <span>=</span> <span>product</span> <span>p</span> <span>q</span>
<span>end</span>
</code></pre></div></div>

<p>In addition to these, weâ€™ll include an <code>Ops</code> module with infix versions
and some derived combinators:</p>

<div><div><pre><code><span>module</span> <span>Ops</span> <span>=</span> <span>struct</span>
  <span>open</span> <span>Syntax</span>
  <span>let</span> <span>(</span> <span>&lt;$&gt;</span> <span>)</span> <span>f</span> <span>p</span>   <span>=</span> <span>map</span> <span>f</span> <span>p</span>
  <span>let</span> <span>(</span> <span>&lt;|&gt;</span> <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>either</span> <span>p</span> <span>q</span>
  <span>let</span> <span>(</span> <span>&lt;*&gt;</span> <span>)</span> <span>pf</span> <span>px</span> <span>=</span> <span>let</span><span>+</span> <span>f</span> <span>=</span> <span>pf</span> <span>and</span><span>+</span> <span>x</span> <span>=</span> <span>px</span> <span>in</span> <span>f</span> <span>x</span>
  <span>let</span> <span>(</span> <span>*&gt;</span>  <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>(</span><span>fun</span> <span>_</span> <span>x</span> <span>-&gt;</span> <span>x</span><span>)</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>q</span>
  <span>let</span> <span>(</span> <span>&lt;*</span>  <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>const</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>q</span>
<span>end</span>
</code></pre></div></div>

<p>Before moving on, some of the code examples also assume a few general
utility functions:</p>

<div><div><pre><code><span>(* Identity *)</span>
<span>val</span> <span>id</span> <span>:</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>a</span>

<span>(* Const *)</span>
<span>val</span> <span>const</span> <span>:</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span> <span>-&gt;</span> <span>'</span><span>a</span>

<span>(* Forward composition *)</span>
<span>val</span> <span>(</span> <span>&gt;&gt;</span> <span>)</span> <span>:</span> <span>(</span><span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span><span>)</span> <span>-&gt;</span> <span>(</span><span>'</span><span>b</span> <span>-&gt;</span> <span>'</span><span>c</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>c</span>

<span>(* Converting a char list to a string *)</span>
<span>val</span> <span>string_of_list</span> <span>:</span> <span>char</span> <span>list</span> <span>-&gt;</span> <span>string</span>

<span>(* And back again *)</span>
<span>val</span> <span>list_of_string</span> <span>:</span> <span>string</span> <span>-&gt;</span> <span>char</span> <span>list</span>
</code></pre></div></div>

<p>Their implementation, along with the complete code is available
<a href="https://gist.github.com/jobjo/13376aaea1151100dd7915dedb35d9d7">here</a>.</p>

<h3 id="building-simple-parsers">Building simple parsers</h3>

<p>How can we use the API to build actual parsers? Letâ€™s consider a few simple
examples. First, a parser that parses a specific string, i.e. a function:</p>

<div><div><pre><code><span>val</span> <span>string</span> <span>:</span> <span>string</span> <span>-&gt;</span> <span>string</span> <span>t</span>
</code></pre></div></div>

<p>To implement the <code>string</code> parser, we can use the <code>symbol</code> primitive and fold over the
given string to combine the parsers using applicative (<code>let+ .. and+)</code> syntax:</p>

<div><div><pre><code><span>let</span> <span>string</span> <span>s</span> <span>=</span>
  <span>let</span> <span>accum</span> <span>c</span> <span>p</span> <span>=</span>
    <span>(* Parse 'x' using the 'symbol c' parser *)</span>
    <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>symbol</span> <span>c</span>
    <span>(* Then parse 'xs' using the 'p' parser *)</span>
    <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>p</span> <span>in</span>
    <span>(* Combine 'x' and 'xs' in a string *)</span>
    <span>Printf</span><span>.</span><span>sprintf</span> <span>"%c%s"</span> <span>x</span> <span>xs</span>
  <span>in</span>
  <span>List</span><span>.</span><span>fold_right</span> <span>accum</span> <span>(</span><span>list_of_string</span> <span>s</span><span>)</span> <span>(</span><span>return</span> <span>""</span><span>)</span>
</code></pre></div></div>

<p>Next, letâ€™s attempt a parser for parsing digits. A version that
detects a single digit may be defined as:</p>

<div><div><pre><code><span>let</span> <span>digit</span> <span>=</span>
  <span>list_of_string</span> <span>"0123456789"</span>
  <span>|&gt;</span> <span>List</span><span>.</span><span>map</span> <span>symbol</span>
  <span>|&gt;</span> <span>List</span><span>.</span><span>fold_left</span> <span>either</span> <span>fail</span>
</code></pre></div></div>

<p>Choosing between a list of parsers is a natural generalization of the binary <code>either</code>
combinator, and deserves its own version:</p>

<div><div><pre><code><span>let</span> <span>choose</span> <span>xs</span> <span>=</span> <span>List</span><span>.</span><span>fold_left</span> <span>either</span> <span>fail</span>
</code></pre></div></div>

<p>We may also generalize the <code>digit</code> definition to take a list of symbols as an argument:</p>

<div><div><pre><code><span>let</span> <span>one_of</span> <span>cs</span> <span>=</span> <span>choose</span> <span>@@</span> <span>List</span><span>.</span><span>map</span> <span>symbol</span> <span>cs</span>
</code></pre></div></div>

<p>Now, <code>digit</code> is achieved by:</p>

<div><div><pre><code><span>let</span> <span>digit</span> <span>=</span> <span>one_of</span> <span>"0123456789"</span>
</code></pre></div></div>

<h3 id="hitting-the-boundaries">Hitting the boundaries</h3>

<p>Next, consider a parser that recognizes arbitrary integers? An integer
consists of at least one digit but we donâ€™t know exactly how many. How can we
define a parser that captures this semantics? As a first try:</p>

<div><div><pre><code><span>let</span> <span>int</span> <span>=</span>
  <span>let</span> <span>rec</span> <span>digits</span> <span>()</span> <span>=</span>
    <span>let</span><span>+</span> <span>d</span>  <span>=</span> <span>digit</span>
    <span>and</span><span>+</span> <span>ds</span> <span>=</span> <span>either</span> <span>(</span><span>digits</span> <span>()</span><span>)</span> <span>(</span><span>return</span> <span>[]</span><span>)</span> <span>in</span>
    <span>d</span> <span>::</span> <span>ds</span>
  <span>in</span>
  <span>map</span> <span>(</span><span>string_of_list</span> <span>&gt;&gt;</span> <span>int_of_string</span><span>)</span> <span>@@</span> <span>digits</span> <span>()</span>
</code></pre></div></div>

<p>Can you spot the problem with the above definition? If not, just try running
it and youâ€™ll find it throwing a <em>stack-overflow</em> exception. The problem is
that the recursive call is never conditional on any base case and is always
eagerly evaluated. We need a way to describe parsers that may consume
arbitrarily large inputs without constructing infinite parsing expressions!
To generalize from the <code>int</code> example, weâ€™re aiming for a combinator with the
following signature:</p>

<div><div><pre><code><span>val</span> <span>many</span> <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>t</span><span>)</span> <span>list</span>
</code></pre></div></div>

<p>One solution would be to introduce a constructor, say <code>Delay</code>,
for representing lazy parsers:</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>...</span>
  <span>|</span> <span>Delay</span> <span>:</span> <span>(</span><span>unit</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>

<span>let</span> <span>delay</span> <span>f</span> <span>=</span> <span>Delay</span> <span>f</span>
</code></pre></div></div>

<p>That is a parser with delayed construction. We may use <code>delay</code> to define
<code>many</code>, as in:</p>

<div><div><pre><code><span>let</span> <span>rec</span> <span>many</span> <span>p</span> <span>=</span>
  <span>let</span> <span>many_one</span> <span>=</span>
    <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>p</span>
    <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>delay</span> <span>@@</span> <span>fun</span> <span>_</span> <span>-&gt;</span> <span>many</span> <span>p</span><span>)</span> <span>in</span>
    <span>x</span> <span>::</span> <span>xs</span>
  <span>in</span>
  <span>either</span> <span>many_one</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>
</code></pre></div></div>

<p>Now, each step of the recursion is evaluated on demand rather than upfront.
This solution would work well if it werenâ€™t for the more ambitious set of constraints
having to do with pretty printing and symbol extraction. The problem is that
in order to extract all possible symbols of a delayed parser, weâ€™d need to evaluate
it; this would unroll the infinite recursion expressed in the <code>many</code> definition, and
once again kill the stack.</p>

<h3 id="fixing-the-parser-definition"><em>Fixing</em> the parser definition</h3>

<p>Is there any fix for the problem of simultaneously having a finite
traversable representation, and providing sufficient expressive power for
describing infinite parsers? The clue is in the question. A way of expressing
recursive structures without recursion is exactly what is offered by the <a href="https://en.wikipedia.org/wiki/Fixed-point_combinator">fixed-point
combinator</a>.</p>

<p>Letâ€™s extend the parser type with a fixed-point constructor (and also get rid of <code>Delay</code>):</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>...</span>
  <span>|</span> <span>Fix</span> <span>:</span> <span>(</span><span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>

<span>let</span> <span>fix</span> <span>f</span> <span>=</span> <span>Fix</span> <span>f</span>
</code></pre></div></div>

<p>We can then use <code>fix</code> as a remedy for the recursiveness of the definition of <code>many</code>,
from above:</p>

<div><div><pre><code><span>let</span> <span>many</span> <span>p</span> <span>=</span>
  <span>fix</span> <span>@@</span> <span>fun</span> <span>many</span> <span>-&gt;</span>
    <span>let</span> <span>many_one</span> <span>=</span>
      <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>p</span>
      <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>many</span> <span>in</span>
      <span>x</span> <span>::</span> <span>xs</span>
    <span>in</span>
    <span>either</span> <span>many_one</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>
</code></pre></div></div>

<p>Note that there is <em>no</em> <code>rec</code> keyword in sight. The function <code>fix</code> is just a
handy tool for allowing us to mimic recursive functions. You may be left
wondering how exactly this solves the problem of symbol extraction, given
that we still end up with <code>Fix</code> nodes â€“ functions of type <code>('a t -&gt; 'a t)</code>
â€“ that need to be evaluated. Hopefully, the next sections on interpreting
parsers will bring some clarity on that matter.</p>

<p>Coming back to the example of integer-parsing, hereâ€™s how <code>int</code> may be defined
in terms of <code>many</code>:</p>

<div><div><pre><code><span>let</span> <span>int</span> <span>=</span>
  <span>let</span><span>+</span> <span>d</span>  <span>=</span> <span>digit</span>
  <span>and</span><span>+</span> <span>ds</span> <span>=</span> <span>many</span> <span>digit</span> <span>in</span>
  <span>int_of_string</span> <span>@@</span> <span>string_of_list</span> <span>(</span><span>d</span> <span>::</span> <span>ds</span><span>)</span>
</code></pre></div></div>

<p>Again, we may extract the common pattern of parsing one or more times using the same
parser (one or more digits in the example above) by adding a new combinator, as in:</p>

<div><div><pre><code><span>let</span> <span>many_one</span> <span>p</span> <span>=</span>
  <span>let</span><span>+</span> <span>x</span> <span>=</span> <span>p</span>
  <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>many</span> <span>p</span>
  <span>x</span> <span>::</span> <span>xs</span>
</code></pre></div></div>

<p>Given a parser <code>p</code>, the parser <code>many p</code> succeeds if it can apply <code>p</code> <em>at least</em> one
time on its input.</p>

<p>As a side note, the code generously makes use of the new applicative syntax to
demonstrate how it may be used to write declarative code that also avoids
infix operators. As an alternative, we can define the same functions
without relying on the syntax extension; for instance:</p>

<div><div><pre><code><span>(* Requires Ops module to be open *)</span>

<span>let</span> <span>many</span> <span>p</span> <span>=</span> <span>fix</span> <span>@@</span> <span>fun</span> <span>many</span> <span>-&gt;</span>
  <span>either</span> <span>(</span><span>List</span><span>.</span><span>cons</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>many</span><span>)</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>

<span>let</span> <span>many_one</span> <span>p</span> <span>=</span> <span>List</span><span>.</span><span>cons</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>many</span>â€¦</code></pre></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jobjo.github.io/2019/05/19/applicative-parsing.html">https://jobjo.github.io/2019/05/19/applicative-parsing.html</a></em></p>]]>
            </description>
            <link>https://jobjo.github.io/2019/05/19/applicative-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301543</guid>
            <pubDate>Mon, 01 Mar 2021 10:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DataOps: How to develop, maintain and scale data intensive projects]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26301474">thread link</a>) | @javisantana
<br/>
March 1, 2021 | https://blog.tinybird.co/2021/02/27/dataops/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/02/27/dataops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>As we build Tinybird, we work hand in hand with many data and engineering teams. In the process we are discovering new ways to develop, maintain and scale data intensive projects.</p> <h2 id="anatomy-of-a-modern-data-team"> Anatomy of a modern Data Team <a href="#anatomy-of-a-modern-data-team">Â¶</a> </h2> <p>If you are into development you have probably heard of the <strong>DevOps</strong> culture: a set of practices and tools that allow development teams to improve their productivity and collaboration when building high quality software products.</p> <p>DevOps is also key for teams that need to <strong>iterate faster</strong> on their quest to find the right thing to build.</p> <p>Things like automated testing, continuous integration and deployment, monitoring, configuration and change managementâ€¦ enable the development and operations teams to work as a single team, with end-to-end ownership of the product they are building.</p> <p>When it comes to data teams things are starting to change. There have been typically three groups in a data team:</p> <ul> <li><em>Data scientists</em>: which most of the time work locally running experiments and analyses, or machine learning models that may later need be productised.</li> <li><em>Data engineers</em>: which write and maintain data pipelines.</li> <li><em>Infrastructure engineers</em>: which are in charge of the â€œ<em>big data</em>â€ infrastructure.</li> </ul> <p>They used to be siloed groups, with long development cycles and most of the time their outputs are cascaded to the next group. Even more, their final product needed to be integrated by a separate team of developers which built the data product for the end users.</p> <blockquote> <p>The technology and tools that support data intensive applications are only good if they are applied such that it is possible for several people in an organization to collaborate around the same context (the data and the business), iterate on the problem, and continuously deliver high quality solutions.</p> </blockquote> <h2 id="dataops-working-with-data-as-if-it-were-code"> DataOps: working with Data as if it were Code <a href="#dataops-working-with-data-as-if-it-were-code">Â¶</a> </h2> <p><strong>A similar culture to DevOps can be applied to data teams</strong>: itâ€™s known as DataOps.</p> <p>DataOps is a set of practices and tools that allow data scientists, data engineers, infrastructure engineers and <strong>also developers</strong> to collaborate together having full autonomy, ownership and accountability of the data product.</p> <p>The goal is enabling data teams to handle requirements, develop, deploy and support the data product. With tools that allow them to measure performance, latencies or control SLAs.</p> <p>In the end, making data teams <strong>work with data as if it was source code</strong>, so they can iterate faster towards high quality data products.</p> <p>Continue reading to learn about <a href="https://blog.tinybird.co/2021/02/27/dataops-principles/">10 principles of DataOps we make available for data teams</a>.</p> <p><strong><em>What are your main challenges when dealing with large quantities of data?</em></strong> <a href="https://www.tinybird.co/survey">Tell us about them</a> and get started solving them with Tinybird right away.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/02/27/dataops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301474</guid>
            <pubDate>Mon, 01 Mar 2021 10:46:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spectre exploits in the "wild"]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26301326">thread link</a>) | @todsacerdoti
<br/>
March 1, 2021 | https://dustri.org/b/spectre-exploits-in-the-wild.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/spectre-exploits-in-the-wild.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Someone was silly enough to upload a
<a href="https://www.virustotal.com/gui/file/6461d0988c835e91eb534757a9fa3ab35afe010bec7d5406d4dfb30ea767a62c">working spectre (CVE-2017-5753) exploit</a>
for Linux (there is also a
<a href="https://www.virustotal.com/gui/file/ecc0f2aa29b102bf8d67b7d7173e8698c0341ddfdf9757be17595460fbf1791a">Windows one</a> with symbols that I didn't look at.)
on VirusTotal last month, so here is my quick Sunday afternoon lazy analysis.</p>
<p>The binary has its <code>-h</code> option stripped, likely behind a <code>#define</code> to avoid
detection, but some of its parameters are obvious, like specifying
what file to leak, or the kernel base address. The authors didn't check (or care)
that the logging function hasn't been entirely optimized out, leaving a bunch
of strings helping in the reversing process.</p>
<p>The exploit works in four stages:</p>
<ol>
<li>Find the <a href="https://www.halolinux.us/kernel-reference/inode-objects.html">superblock</a>,</li>
<li>Find the <a href="https://en.wikipedia.org/wiki/Inode">inode</a> of the file to dump</li>
<li>Find the corresponding page address</li>
<li>Dumps the content of the file.</li>
</ol>
<p>In the case of <code>/etc/shadow</code>, the default option, the content of the
file is shoved in memory by running the following command in the
background: <code>return system("echo \"whatever\n\" | su - 2&gt; /dev/null")</code>.
In my lab, on a vulnerable Fedora, the exploit is successfully dumping <code>/etc/shadow</code> in a couple of minutes.
Interestingly, there are checks to detect <a href="https://en.wikipedia.org/wiki/Supervisor_Mode_Access_Prevention">SMAP</a>
and abort if it's present. I didn't manage to understand why the exploit was
failing in its presence.</p>
<p>The crux of the exploit is at <code>0x4092f0</code>, using <code>cpuid</code> as a serializing
instruction, <code>rdtsc</code> for timing, and <code>mfence</code>/<code>lfence</code> as barrier, as
documented in the paper. It's also using some tricks to minimize the amount of
readings, like type-specific functions, for example a kernel address has a
specific <em>format</em>.
Thanks to <a href="https://twitter.com/spendergrsec">spender</a> for confirming that the gadget used is likely <code>get_user()</code> in the <code>FIOASYNC ioctl</code>,
which was <a href="https://patchwork.kernel.org/project/kernel-hardening/patch/20180209133935.811950747@linuxfoundation.org/">fixed in 2018</a></p>
<p><a href="https://en.wikipedia.org/wiki/KASLR">KASLR</a> is bypassed when present either by
looking at <code>/proc/kallsyms</code> when available to unprivileged users like it used
to be the case on Fedora until ~recently, or by using the generic
bypass from the <a href="https://gruss.cc/files/prefetch.pdf">prefetch side-channel</a> by Gruss and al.
originating from a library called <code>libkaslr</code>. Amusingly, this method is still
working on an up to date Linux, proving again that <a href="https://grsecurity.net/kaslr_an_exercise_in_cargo_cult_security">KASLR is useless at
best</a>.
For systems that don't have the <code>/proc/kallsym</code> file accessible, the exploit
relies on hardcoded offsets, and while only Fedora, ArchLinux and Ubuntu are currently
supported, there are functions to check for Debian and CentOS. It's a bit
surprising to see hardcoded offsets in an exploit with arbitrary read in
2021.</p>
<p>Unsurprisingly, it had a 
<a href="https://www.virustotal.com/gui/file/6461d0988c835e91eb534757a9fa3ab35afe010bec7d5406d4dfb30ea767a62c/detection">0 detection</a>
rate before I published this blogpost.</p>
<p>Attribution is trivial and left as an exercise to the reader.</p>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/spectre-exploits-in-the-wild.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301326</guid>
            <pubDate>Mon, 01 Mar 2021 10:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Business, Not an Audience]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26301030">thread link</a>) | @jakobgreenfeld
<br/>
March 1, 2021 | https://jakobgreenfeld.com/build_an_audience | <a href="https://web.archive.org/web/*/https://jakobgreenfeld.com/build_an_audience">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If youâ€™re reading this, Iâ€™m pretty sure youâ€™ve seen the following pattern over and over again:</p>

<ul>
  <li>Creative nonfiction pioneer John McPhee distilled decades of experience and first-hand learnings in a series of essays. (The best of them are now available in a book called â€œDraft No. 4â€.)</li>
  <li>A savvy entrepreneur repackages the advice in a $1000+ cohort-based course.</li>
  <li>Someone takes the course and summarizes what he learned.</li>
  <li>People on Twitter start creating threads summarizing the studentâ€™s summaries.</li>
  <li>At some point, the guy who summarized the studentâ€™s summaries will get invited to a podcast to summarize his summary of the studentâ€™s summary.</li>
</ul>

<p>I wish I was kidding.</p>

<p>This is a picture-perfect example of what Sean Blanda calls the <a href="https://99u.adobe.com/articles/55974/the-creative-worlds-bullshit-industrial-complex">Creative Worldâ€™s Bullshit Industrial Complex</a>. But my goal here is not to dunk on anyone. Instead I want to focus on something far more important.</p>

<p>The Bullshit Complex is just a symptom. Whatâ€™s the underlying cause?</p>

<p>First, let me clarify one thing. While Iâ€™m convinced that remixed content is largely a waste of time for writers and readers, itâ€™s a free world out there. Do whatever makes you happy. If you focus on remixed or â€œcuratedâ€ content Iâ€™ll probably not follow you on Twitter or read your blog, but thereâ€™s no reason why you should care about that. Ultimately, itâ€™s your own responsibility to decide how you spend your time and what kind of content you consume.</p>

<p>With that out of the way, letâ€™s talk about entrepreneurship.</p>

<p>In recent years one of the most common pieces of advice for aspiring entrepreneurs has become that you should focus on building an audience. Everyone is screaming it from the rooftops.</p>

<p>So when I started to get into entrepreneurship a few months ago, thatâ€™s exactly what I did. I spent a lot of time researching what kind of tweets get attention and set the goal for myself to post at least two tweets per week and two blog posts per month. After all, churning out content regularly is key if you want to build an audience, <a href="https://www.youtube.com/watch?t=67&amp;v=cubPiuD7_dA&amp;feature=youtu.be">right</a>?</p>

<p>If you need any evidence how serious I was about the whole building an audience thing, here it is: I created a <a href="https://whattotweet.com/">What to Tweet</a> tool because I was struggling to stick to my Twitter schedule.</p>

<p>Looking back at it now I think I largely wasted my time. And more importantly I see so many people falling into the exact same trap.</p>

<p>Their goal is to become entrepreneurs. But instead of building products, they create content. Or even worse, they do research and take courses on how to create content.</p>

<p>But this doesnâ€™t bring them one inch closer to their goal. Itâ€™s just a form of procrastination.</p>

<p>While charging money for something you created is <a href="https://jakobgreenfeld.com/free">scary</a>, there is almost zero risk in putting out free content. And if youâ€™re just remixing other peopleâ€™s content, the intellectual risk is effectively zero. After all, you can always reply â€œhey, donâ€™t shoot the messengerâ€.</p>

<p>This trap is particularly dangerous because it feels like youâ€™re making progress while really you donâ€™t.</p>

<p>Aspiring entrepreneurs are not just wasting a lot of time but also lots of money this way. They spend thousands of dollars on courses that teach them how to remix other peopleâ€™s content more effectively. They buy the latest hyped-up courses that teach them how to craft more effective tweets, blog posts and Youtube videos.</p>

<p>But donâ€™t get me wrong. <em>Having</em> an audience is awesome and I love great content.</p>

<p>What Iâ€™m saying is that too many beginners have their priorities backwards and fall into the â€œbuild an audience!â€ trap.</p>

<p>An exemplary plan looks as follows: â€œI donâ€™t know what product I should create. So Iâ€™m planning to create articles or carousels on Linkedin to find my voice and build an audience.â€ Thatâ€™s almost verbatim a paragraph from an email I received two days ago.</p>

<p>You can certainly get a lot of followers by churning out remixed content and feel-good platitudes. But everyone seems to forget that not all audiences are alike.</p>

<p>Letâ€™s say you have 2000 followers that you got by posting feel-good platitudes, whereas I only have two followers called Elon Musk and Paul Graham. Would you swap accounts?</p>

<p>With feel-good platitudes and remixed content youâ€™ll only attract fellow beginners. Everyone else recognizes the content immediately for what it is. Hence, the primary value of your much larger audience is that youâ€™re able to sell them a â€œHow to grow your Twitter followingâ€ Gumroad course for $47.</p>

<p>A high-quality audience is an endless source of opportunities. A low quality one is at most a Ponzi scheme.</p>

<p>Many people <a href="https://twitter.com/m_ashcroft/status/1364334719970721793">learn</a> this the hard way. They get lured by the promise that theyâ€™ll be able to create content effortlessly and build an audience this way. This is exactly what beginners want to hear and hence what gurus are preaching. â€œEverything is a remixâ€. So just progressively summarize a bunch of books and then start sharing pieces you remixed from your summaries.</p>

<p>Students of these courses spent months recording videos and writing thousands of words only to discover that they never said anything meaningful.</p>

<p>Valuable content that truly advances the conversation and gets the attention of people you really want to connect with is never effortless. Itâ€™s painful. And Iâ€™m not talking about some kind of sophisticated editing process, but the writing itself.</p>

<p>In fact, this is how you know that youâ€™re creating valuable content. You should at least be a little scared before you hit the publish button.</p>

<p>Publishing content online is the best way to become visible so that opportunities can find you. But please donâ€™t try to improve your ability to come up with interesting things by reading and connecting ideas just so that you have something to write about.</p>

<p>If you ever notice that youâ€™re trying to â€œsay something interestingâ€, stop. Youâ€™re just going to feed the Creative Worldâ€™s Bullshit Industrial Complex.</p>

<p>Your main priority always should be to <em>do</em> meaningful things, to solve real-world problems, to be the man in the arena. And if you share what you learn along the way, people will start to listen. Write when you have something meaningful to say, and not to stick to some self-imposed writing schedule.</p>

<p>A hidden benefit of this strategy is that your writing skills become largely irrelevant. Itâ€™s certainly true that great writers like John McPhee can make a topic as boring as <a href="https://www.goodreads.com/book/show/54983.Oranges">Oranges</a> exciting. But if you have a great story to tell or learned something important, people will pay attention no matter how bad your writing is. Not convinced? Just look at the essay youâ€™re reading right now.</p>

<p>Save yourself thousands of dollars. Hereâ€™s all the writing advice you need:</p>

<ul>
  <li>Share meaningful first-hand experiences.</li>
  <li>Write as if you were emailing a friend, not to impress an imaginary teacher.</li>
</ul>

<p>Now Iâ€™m definitely scared to publish this essay. This is exactly why Iâ€™ll do it.</p>

  </div></div>]]>
            </description>
            <link>https://jakobgreenfeld.com/build_an_audience</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301030</guid>
            <pubDate>Mon, 01 Mar 2021 09:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gerald Weinberg]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300409">thread link</a>) | @ingve
<br/>
February 28, 2021 | https://deprogrammaticaipsum.com/gerald-weinberg/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/gerald-weinberg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Some books are like mirrors. By that I mean that reading them involves a great deal of looking at oneself, both for praise and loathing. Taking a look back in time, reflecting on all those times we thought we were right and we were wrong, bringing back memories of times long gone, some of them painful, most hopefully fun and joyful.</p>
<p>â€œThe Psychology of Computer Programmingâ€ is one of those. In every one of its chapters, Dr. Weinberg reflects on the human aspects of programming. It is, most probably, the first book ever written on the subject of the personality, the interactions and the characteristics of software developers. Let me be clear: this book has been written in 1971, and it has been continuously in print until at least the end of the twentieth century, for almost 30 years. This is the stuff of classics.</p>
<p>There has even been a reviewed â€œanniversaryâ€ edition published in 1999, but I bought a copy of the first edition of the book, and besides the delightful look and feel of the pages, representatives of the typography and design of the seventies, the structure, the flow and the discussion of this book make it stand in a class of its own, and represent a hallmark in our field.</p>
<p>Dr.&nbsp;Weinberg analyzes programming from both individual and collective points of view, including the issues of education, human resources management, and even programming language design. The author actually devotes a section of his book to explain how the design of a programming language impacts the readability and the subsequent maintainability (or lack thereof) of the programs written in it.</p>
<p>Sounds familiar?</p>
<p>Regarding team interactions, the author highlights the issues brought from scaling up programming teams: do small teams face the same issues as larger ones? How do communication patterns emerge and evolve? The author takes pleasure in debunking common myths and misconceptions, some of them still held today by managers all over the world: what are the factors that can cause a project to break down in pieces? The answers will surprise you, and you will wonder why nobody had ever told you to read this book first.</p>
<p>Dr. Weinberg also pays close attention to the individual characteristics of programmers. What defines a good programmer? Why do they take pride in their jobs? What kind of incentives should a company offer to their developers? Nice offices or challenging problems? (I think you can guess the answer to that last question.)</p>
<p>In the humble opinion of the author of these lines, software is primarily a social process, and only later a technical feat. Software is no more a technical product than a book is just a printed object. Software is the result of interactions among people, and as such it will reflect all the contradictions, the failures, the wonders and the joy of the people involved in it. Every single piece of software ever written by humans reflects the underlying moods, psyche and interactions of a group of people. As such, studying the psychology of a programmer yields naturally in a process in which, invariably, the software will be better at the end.</p>
<p>I once saw a joke on Twitter, saying that managing programmers was subject to Heisenbergâ€™s Principle, in that observing programmers changes their behavior. I do not think it is a joke, for I believe that all social systems are, actually, quantum-like systems subject to this principle; the actions of the observer will invariably alter the behavior of the observed. And that is OK, as far as I am concerned. If managers are conscious of this fact, and if they can use this to their advantage, they will be able to build sustainable teams.</p>
<p>Maybe Dr. Weinberg took some inspiration from Melvin Conway, who <a href="https://en.wikipedia.org/wiki/Conway%27s_law" target="_blank" rel="noopener">in 1967 stated</a> that â€œorganizations design systems mirroring their own communication structuresâ€. Now you start to understand why your microservice architecture is a mess, and no, neither Istio nor Prometheus is going to help you with that.</p>
<p>Finally, regarding recruiting: we all know how hard it is to find and recruit software developers, yet I am appalled to see how many companies do as much as they can to destroy the teams they spent so much time and money to build. Why is this? I can only recommend all human resources managers, all project managers, and all developers as well, to get a copy of this book and, as I said at the beginning of this chapter, to take a good look at ourselves in the mirror. We all need a little bit of introspection, and Dr. Weinberg can help.</p>
<p>Legacy buzzword warning: this book is mostly accessible to general audiences, but there are a few sections where the author assumes a certain experience with programming languages, compilers, hardware design or even project management; and in some cases, with the 1971 versions of those.</p>
<p>Cover photo by the author.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/gerald-weinberg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300409</guid>
            <pubDate>Mon, 01 Mar 2021 07:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Message Sent on AIM]]>
            </title>
            <description>
<![CDATA[
Score 392 | Comments 204 (<a href="https://news.ycombinator.com/item?id=26300266">thread link</a>) | @luu
<br/>
February 28, 2021 | https://justanman.org/posts/the-last-message-sent-on-aim/ | <a href="https://web.archive.org/web/*/https://justanman.org/posts/the-last-message-sent-on-aim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://justanman.org/images/aol-instant-messenger-shuts-down.png" alt="AOL Instant Messenger â€˜Running Manâ€™ waving goodbye"></p>
<p>In the early 2000s social media sites like Facebook and Twitter werenâ€™t commonplace yet. Even text messages, at ten cents each, were something to be rationed. For many teenagers the primary means of communication outside school was AOL Instant Messenger (AIM). So when it was announced in October that they were shutting down AIM after 20 years, I felt a wave of nostalgia for the messaging app of my youth.</p>
<p>It wasnâ€™t clear when they would be pulling the plug for good, but a high school friend and I planned to be online for the occasion. Their website indicated that AIM would continue to work until the morning of December 15, 2017. Assuming this meant UTC time, that put it going offline sometime after 7:00 PM EST on the 14th.</p>
<p>I wondered: Could I be the last person to sign off? The last person to send a message? Would I have anything profound to say?</p>
<p><strong>Research</strong></p>
<p>I decided to research famous last words. First stop: the Book of Revelation. Final chapter, final verse.</p>
<blockquote>
<p>â€œThe grace of our Lord Jesus Christ be with you all. Amen.â€</p>
</blockquote>
<p>Not quite what I was looking for.</p>
<blockquote>
<p>â€œLast words are for fools who havenâ€™t said enough!â€</p>
</blockquote>
<p>Too cantankerous. And as a somewhat libertarian leaning person, I wasnâ€™t going to let Karl Marx have the last word.</p>
<p>Iâ€™d figure out what to say later and in the meantime started reading about the technology behind AIM. I learned about OSCAR, the proprietary protocol used by AIM and ICQ. Parts of the protocol were documented by AOL in an official SDK. This is what made third-party AIM clients possible. I had used Gaim (now Pidgin) on Linux machines before and indeed, there was even BSFlite, an AIM client for the command line.</p>
<p>AOLâ€™s desktop client no longer worked for me. They had already pulled the iOS app from the App Store. Ditto for Android. Fortunately browser sign on still worked. I was greeted by a familiar interface that supported new features like embedded media and SMS.</p>
<p>I sent a couple test messages from the browser to my phone. Monitoring outbound activity in the Chrome network panel revealed the structure of a request: a simple HTTP POST to a url, with what appeared to be a session ID in the query string and a message body. I tried to send a message using <code>curl</code> and it worked. As long as I was signed on in the browser the request was accepted.</p>
<p>There were several paths to automating this but given the time constraint, something quick and easy would probably suffice. All I had to do was keep sending messages until the server stopped responding.</p>
<p><strong>December 14, 2017: The final countdown</strong></p>
<p>It was almost midnight UTC time. It would be the 15th soon and I didnâ€™t want to miss the shutdown, so I set up a Bash script to run the <code>curl</code> command at one second intervals. Every now and then I had to manually reauthenticate in the browser. It wasnâ€™t elegant but it worked. Now I had to waitâ€¦</p>
<p>To pass time I searched Twitter for mentions of AIMâ€™s last day. Plenty of people were reminiscing about their old screen names, but only a handful were actually signing on one last time. I added them to my buddy list and we talked for a bit. One lived in DC, one in Toledo. Another somewhere in Maryland. Two were engineers, one was a wrestling announcer! I made dinner and watched <em>The Office</em> while occasionally checking on the script.</p>
<p>It ran for another six hours until 1:21 AM EST. I witnessed the drama play out in HTTP status codes:</p>
<pre><code>200 OK
200 OK
200 OK
408 Request Timeout
408 Request Timeout
401 Unauthorized
</code></pre><p>And like that, AIM was gone. Requests to aim.com returned an Invalid URL status page. <code>curl</code> returned nothing but 401s.</p>
<p><strong>Epitaph</strong></p>
<p>I examined the script logs and found it â€“ the last message sent on AIM. [1] It was timestamped Fri Dec 15 01:21:42 EST 2017. From me, to me. (I didnâ€™t want to spam anyone.)</p>
<p>I had borrowed the words from Leonard Nimoyâ€™s final tweet:</p>
<blockquote>
<p>â€œA life is like a garden. Perfect moments can be had, but not preserved, except in memory. LLAPâ€</p>
</blockquote>
<p>ðŸ––</p>
<p><strong>Notes</strong></p>
<p>[1] At least in my server region.</p>
<p><strong>Thanks</strong> to behind2greeneyes, dalilmoo, croftonworldwide, nuklermuleburger, and sirmatthew84.</p>
<p>If you enjoyed reading this, please consider a donation to the <a href="https://archive.org/donate/">Internet Archive</a>.</p>
<p>You can also read Kat Timpfâ€™s brilliant <a href="https://www.nationalreview.com/2017/10/aol-instant-messenger-eulogy-aim-social-media-millennials/">eulogy for AIM</a>.</p>

      <hr>
      <p>
        For more frequent updates, follow me on Twitter.
      </p>
      <p>
        <a href="https://twitter.com/jtangofx?ref_src=twsrc%5Etfw" data-show-count="false">Follow @jtangofx</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://justanman.org/posts/the-last-message-sent-on-aim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300266</guid>
            <pubDate>Mon, 01 Mar 2021 06:40:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The curious case of CVE-2020-14381]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300234">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://blog.frizn.fr/linux-kernel/cve-2020-14381 | <a href="https://web.archive.org/web/*/https://blog.frizn.fr/linux-kernel/cve-2020-14381">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://blog.frizn.fr/linux-kernel/">Kernel Linux</a> &gt; <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">The curious case of CVE-2020-14381</a></p>

                    <h3>The curious case of CVE-2020-14381</h3>                    
                    <p>Today is the one-year anniversary of this interesting kernel bug I worked
on last year with <a href="https://twitter.com/bluec0re" target="_blank">@bluec0re</a>,
and as it turns out I wrote something about it during one of these lockdown
weekends so I thought I'd release it. <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2015" target="_blank" title="CVE-2020-14381 get_futex_key use-after-free">The bug itself</a>
was discovered by <a href="https://twitter.com/tehjh" target="_blank">Jann Horn</a>
of Project Zero. While I touch most of the elements required to exploit the
bug, I stay superficial here since the exploit itself is not particularly
exciting. What makes this bug interesting to me is its lifecycle, in particular
how unevenly the patch was applied to the various distributions. I also talk
briefly about hardware side-channels since it was the first time I had ever
used one.</p>

<p><strong>The bug</strong></p><p>Itâ€™s already well-described in the bug tracker, but here is another summary.
The <span>futex</span> syscall's main parameter is a userland address, and this address
may belong to a file-backed mapping. In that case, the futex key kernel object
<a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L707" target="_blank">held</a>
and <a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L724" target="_blank">kept</a>
a reference to the inode object, but didnâ€™t hold a reference to the fileâ€™s mountpoint.
If the mountpoint were to go away, its associated kernel structures would be
freed, but the inode wouldnâ€™t. Thatâ€™s an issue because the inode itself has
fields that point to some of these structures, such as its <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L641" target="_blank">super_block</a>
struct.</p>

<p>Further use of the inode by <span>futex</span> code paths may therefore trigger
use-after-frees. One particular code path highlighted by Jann in the bug happens
when the <span>futex</span> is destroyed: the last reference to the inode is released
and the inode needs to be freed. This is done in <span>iput</span> which then calls
<span>iput_final</span>. <span>iput_final</span> and its subcalls will then call inode
management functions stored in the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L1942" target="_blank">super_operations</a>
struct accessed <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1533" target="_blank">from the super_block</a>
object. The first instance happens right at the beginning of <span>iput_final</span> with
a call to the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1539" target="_blank">drop_inode</a>
function.</p>

<p>Exploiting this bug requires being able to:
</p><ul>
  <li>Successfully <span>umount</span> a mountpoint. A no-go a few years ago, but
  possible nowadays with the normalization of unprivileged user namespaces.
  Itâ€™s a good example that this feature was never a trivial security tradeoff
  (unprivileged sandboxes v. augmented kernel attack surface) which in turn
  makes it somewhat surprising that all mainstream distributions enabled them by default
  without much debate</li>
  <li>Survive the <span>op-&gt;drop_inode()</span> execution (non-SMEP or a KASLR bypass)</li>
  <li>Survive the <span>op-&gt;drop_inode</span> indirection just before that (non-SMAP
  or a stack/heap leak)</li>
  <li>Do everything in one call, because with an incorrect inode state, a corrupted
  super_block and some linked lists unlinks to do in the remainder of <span>iput_final</span>,
  itâ€™s doubtful we can even get as far as the second <span>super_operations</span>
  function pointer call (<span>evict_inode</span>)</li>
</ul>


<p><strong>Exploitation</strong></p><p>The first exploitation pathway that comes to mind goes as follows:
</p><ul>
  <li>wait for the <span>super_block</span> to be freed. Itâ€™s done in <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/super.c#L299" target="_blank">an RCU callback</a>
  so one way or another you need to wait for the end of the RCU grace period
  after <span>umount</span> returns, e.g. with <span>membarrier</span>. For a PoC, spraying
  allocs for the duration of the expedited grace period works well enough since
  the <span>super_block</span> slab, <span>kmalloc-2k</span>, is not super busy.</li>
  <li>overwrite the freed <span>super_block</span> via a dynamic heap allocation primitive
  (e.g. <a href="https://elixir.bootlin.com/linux/v5.4.7/source/net/socket.c#L2264" target="_blank">sendmsg ancillary data</a>).</li>
  <li>point <span>s_op</span> to an attacker-controlled buffer</li>
  <li>point <span>drop_inode</span> to a chain of gadgets that pivot the stack to
  either the <span>super_block</span> or <span>super_operations</span> bufffers (which
  are both necessarily in registers and almost fully controlled). Example of
  common gadgets that would work in this situation would be <span>push reg; jmp/call [reg+x]</span>
  that can then be chained with a <span>pop rsp; ret</span> gadget placed at <span>[reg+x]</span></li>
  <li>do whatever with your unconstrained ROP, fixup the stack and return</li>
</ul>


<p>This would be a sucky exploit to maintain as it relies on precise knowledge
of the kernel image, but thatâ€™s as good as it gets for a raw function pointer
execution without a read primitive in kernel space. The portability issues
for exploits like this are in themselves a significant bonus of SMEP: it rarely
prevents exploitation but makes many candidates much less appealing for weaponization.</p>

<p>We can take SMEP for granted. Itâ€™s only one CPU generation / 2 years older
than SMAP, but not having it is getting really rare. Plus if your exploit does
rely on no-SMEP but your target ends up having software SMEP enabled, which
you sometimes can't really tell at runtime, you've just turned a privesc attempt into
a lost foothold. No-SMAP however is still a thing for the time being. As a
random example the <a href="https://aws.amazon.com/intel/" target="_blank" title="AWS EC2 intel CPUs">AWS EC2 CPU roster</a>
shows some CPUs that do not support SMAP.</p>

<p><strong>On infoleak bugs</strong></p><p>In any case, to exploit this bug one needs at least one infoleak. The most
important is to get kernel base for gadgets, and then we could use a heap leak
or similar to support SMAP-capable CPUs (to have our "attacker-controlled
buffer" in point 3 above in kernel space). A heap/stack leak can often yield
a .text address as well so having one would kill two birds with one stone.
But, not everyone has the right infoleak in their stash ready to go, contrary
to a common anti-KASLR argument. And even when you do have an infoleak bug,
it doesn't mean that it will help with your current exploit.</p>

<p>For instance, a good infoleak candidate which was released around the same
time last year would be the one with uninitialized memory in coredumps, <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-10732" target="_blank">CVE-2020-10732</a>.
But short of a public proof-of-concept, one needs to understand the coredump
generation code, then find an object in that slab that allows us to get
.text, and another one to deduce a heap address you control. In short, at least
as much work as the rest of the exploit we are looking at. And that's without
considering that using two bugs in one exploit also means that you need to
take into account both bugs limitations. Unprivileged user namespaces for the
main bug we are looking at (not a thing on e.g. RHEL 7), and for the coredump,
well the ability to retrieve the core files, i.e. not running in a container.
Luckily for our project, we already knew we were targeting non-SMAP containers
so we were able to avoid spending all that effort on an infoleak bug that
would have ended up being worthless; a luxury that real exploit developpers
preparing capabilities ahead of time do not have. But if we were targeting
SMAP containers, well that would have been it since more effort would have
exceeded our resource budget for this project.</p>

<p><strong>Hardware side-channels</strong></p><p>For kernel .text however, the situation is different since there are generic,
publicly-documented ways to obtain kernel base: hardware vulns. I personally
hadnâ€™t ever used any and even saw them as a niche exploitation technique
relying on opaque CPU heuristics that donâ€™t hold across models - not something
to be considered for resilient exploits. I was simply wrong, but thankfully
had access to many specialists (<a href="https://twitter.com/tehjh" target="_blank">@tehjh</a>,
<a href="https://twitter.com/_fel1x" target="_blank">@_fel1x</a>, <a href="https://twitter.com/_tsuro" target="_blank">@_tsuro</a>)
who knew better.</p>

<p>While side-channels that allow leaking memory across security boundaries
are hopefully bound to be mitigated, there are many side-channels that leak
addresses and which we havenâ€™t heard much about since Spectre and friends.
These ones are probably here to stay even longer. For this project I used <a href="https://github.com/tpn/pdfs/blob/master/Jump%20Over%20ASLR%20-%20Attacking%20Branch%20Predictors%20to%20Bypass%20ASLR%20-%202016%20(micro16).pdf" target="_blank" title="jump over aslr paper">Jump Over ASLR</a>,
which was published before Spectre in 2016. Itâ€™s simple to understand (especially
with access to the aforementioned people) and there are PoCs that are just
waiting to be adjusted to your own scenario (e.g. <a href="https://github.com/felixwilhelm/mario_baslr" target="_blank" title="mario_baslr jump over aslr">mario_baslr</a>
from @_fel1x). Jump Over ASLR relies on the inner workings of the Branch Target
Buffer where user and kernel branches may collide. When that happens, the CPU
has more work to do and that can be observed. This allows leaking kernel base 
as long as you have offsets of branches hit during a short kernel path you
can trigger at will: you can then leverage the low entropy of KASLR to try
all possible base addresses and find the one where the branches are hit.</p>

<p>For the parameters (the branches to measure) you can really use whatever
you want. I only tried the <span>creat</span> syscall with arguments that cause a
fast return to userland, and then measured whether the <span>sys_creat</span> and
<span>do_sys_open</span> offsets had been hit. The offsets need to be fairly precise
but not to the byte since there seems to be some aliasing going on in the branch
predictor: I originally used <span>__fentry__</span> as an additional branch target
at a +5 offset for both symbols which still worked even though I later learned
these calls get <a href="https://lwn.net/Articles/747256/" target="_blank">dynamically patched out</a>.
</p>

<p>With proper filtering of both false negatives and false positives (essentially
double checking each address) this works like a charm on recent Intel CPUs,
and itâ€™s one of many such techniques that have been published in the past
6 years or so. That makes it something we should be able to rely on as exploit
developers for the foreseeable future. So for a known kernel image at least,
we are essentially back to pre-KASLR times - and keep in mind that itâ€™s a
field I know fairly poorly so other side-channels are probably even better.</p>

<p><strong>Patch gap</strong></p><p>Ok here is what I personally found really interesting because I had never
looked into kernel bug timelines before. This bug was initially reported on
February 28 2020, and fixed in tip on March 3. At this point itâ€™s essentially
public for anyone keeping an eye out for interesting kernel patches - even
if you donâ€™t spend too much time on it, a <span>reported-by</span> Jann Horn is
worth looking into. The main kernel lines were fixed either on March 25 or
April 2. If youâ€™re thinking â€œoh wow one whole monthâ€, please be seated for
whatâ€™s coming.</p>

<p>Some distros applied the patch almost immediately:
</p><ul>
  <li>Arch Linux: Mar 25</li>
  <li>Gentoo: Mar 25</li>
  <li>Fedora: Mar 26</li>
</ul>


<p>I know they are not supposed to target workstations specifically but outside
of personal servers I don't think I have ever seen them used otherwise. The
2nd batch of distributions that fixed the bug is arguably more server-ready:
</p><ul>
  <li>Ubuntu 18.04 LTS: Apr 7</li>
  <li>Ubuntu 16.04 LTS: Apr 24</li>
  <li>Debian Buster â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">https://blog.frizn.fr/linux-kernel/cve-2020-14381</a></em></p>]]>
            </description>
            <link>https://blog.frizn.fr/linux-kernel/cve-2020-14381</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300234</guid>
            <pubDate>Mon, 01 Mar 2021 06:31:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Paying Me]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300165">thread link</a>) | @hiphipjorge
<br/>
February 28, 2021 | https://www.spakhm.com/p/please-stop-paying-me | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/please-stop-paying-me">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few days ago I realized something. I donâ€™t like writing.</p><p>I realized it because I found creative energy to work on programming projects again, and I experience writing programs differently from how I experience having to write. Even the turn of phrase â€œhaving to writeâ€ betrays my disposition toward the craft.</p><p>When Iâ€™m very excited to build products or just program computers for the joy of programming, I dread going to sleep and every part of me <em>cannot wait</em> to wake up and write code again. Iâ€™ve never felt that about writing. Writing has always been a chore. I think Iâ€™ve known this all along, but have never been able to admit this to myself until now.</p><p>When you read anything about anything anywhere, it tells you what great [INSERT CALLING HERE] do. Great startup founders and engineers write well and write a lot because without clear writing there is no clear thinking. I think I bought into that too much for my own good. So it feels liberating to say: <strong>I hate writing.</strong> Itâ€™s painful and laborious and every good piece of writing I make feels like delivering a baby. A rewarding experience for sure, but I think even the most loving of mothers would stop being so loving if she had to deliver a new baby every week.</p><p>One thing that duped me is a lot of positive reenforcement. My best pieces of writing get tens, sometimes hundreds of thousands of readers, and that gives me an addicting sense of elation. I certainly never expected to make money doing it, but enough of you find my writing sufficiently interesting to offer the ultimate seal of approvalâ€” you transfer money from your wallet into mine. I deeply appreciate it, and deeply appreciate you spending time on reading my essays, but unfortunately this isnâ€™t sufficient impetus for me to produce good work. When Iâ€™m forced to write on a schedule, my writing sucks and my life is miserable.</p><p>Which is a good reminder why some of my writing is good. Itâ€™s good when I have something important to say. Important things are hard to say by definitionâ€” if they were easy people would have already talked them out and they probably would have lost their importance. At least theyâ€™re hard to say for me. So when I do it itâ€™s always very slow and painful, and it turns out good because I say something that matters to me in a way that nobody else bothered or managed to say. With my particular idiosyncrasies the intersection of that and the business of running a newsletter is an empty set.</p><p>So please stop paying me. For the folks that have prepaid, Iâ€™m not exactly sure how Substack tooling handles this situation, but shoot me an email and Iâ€™ll figure out how to return a prorated amount.</p><p>I will continue writing. When I have something important to say, Iâ€™ll go through the pain necessary for me to say it. Iâ€™ll also write about my observations as I pursue my product and programming workâ€” technical, anthropological, and simply keeping you up to do date on what Iâ€™m up to. I donâ€™t expect youâ€™ll be hearing from me less often. In fact, Iâ€™m hoping this will allow me to write more. But owing people weekly essays as a matter of business isnâ€™t my tao. For all the reasons above, and primarily because it makes the essays suck, and I donâ€™t like producing bad work.</p><p>Until next week, hopefully. Slava.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/please-stop-paying-me</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300165</guid>
            <pubDate>Mon, 01 Mar 2021 06:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Random effects and penalized splines are the same thing]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300028">thread link</a>) | @whoisnnamdi
<br/>
February 28, 2021 | https://www.tjmahr.com/random-effects-penalized-splines-same-thing/ | <a href="https://web.archive.org/web/*/https://www.tjmahr.com/random-effects-penalized-splines-same-thing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        
        <p>For a long time, Iâ€™ve been curious about something. It is a truth Iâ€™ve
seen casually dropped in textbooks, package documentation, and tweets:
<strong>random effects and penalized smoothing splines are the same thing</strong>. 
It sounds so profound and enlightened. What does it mean? How are they
the same? What deep statistical <em>gnosis</em> was I missing out on?</p>

<p>I have spent months, off and on, trying to understand this equivalence.
I canâ€™t give you the full mathematical treatment, but I have the gist of
it and I can point you to the equations. In this post, I will try to 
highlight the connections between the two.</p>

<p>Here are the main takeaways:</p>

<ul>
  <li>Mixed effects models (a.k.a. hierarchical models or multilevel
models) use partial pooling to strike a balance between a grand
population mean (complete pooling) and individual group means (no
pooling).</li>
  <li>Smoothing splines work by penalizing model coefficients to reduce
the model degrees of freedom.</li>
  <li>You can use the computational machinery of one framework to estimate
the other.</li>
</ul>

<blockquote data-conversation="none" data-lang="en" data-dnt="true" data-theme="light">
  <p lang="en" dir="ltr">Sadly, I feel like my career has peaked with the creation of this meme <a href="https://t.co/5ilRFonsy7">pic.twitter.com/5ilRFonsy7</a></p>

  <img src="https://www.tjmahr.com/assets/images/spider-smooth.jpg" alt="Spiderman (Penalized smooths) pointing at (and being pointed at) by Spiderman (Random effects)">
  <br>
  â€” Eric Pedersen (@ericJpedersen) <a href="https://twitter.com/ericJpedersen/status/1293508069016637440?ref_src=twsrc%5Etfw">August 12, 2020</a>
</blockquote>

<h2 id="mixed-model-review">Mixed model review</h2>

<p>Letâ€™s review what these things means. Mixed effects models,
<a href="https://www.tjmahr.com/another-mixed-effects-model-visualization/">apparently</a> the <a href="https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/">main
focus</a> of <a href="https://www.tjmahr.com/iccbot-comes-online/">this
blog</a> over the years, are used to estimate
â€œrandomâ€ or â€œvaryingâ€ effects. Here is the classic equation set up:</p>

\[\mathbf{y} = \mathbf{X\beta} + \mathbf{Zb} + \mathbf{\epsilon} \\
\mathbf{b} \sim \textsf{Normal}(0, \sigma_b) \\
\mathbf{\epsilon} \sim \textsf{Normal}(0, \sigma_y) \\
\mathbf{X}: \textrm{fixed effects model matrix} \\
\mathbf{Z}: \textrm{random effects model matrix} \\
\sigma_b, \sigma_y : \textrm{variance components} \\
\sigma_b : \textrm{where the magic happens} \\\]

<p>The magic here is the <em>Ïƒ</em><sub><em>b</em></sub>, as it ties all of the
individual effects in <strong>b</strong> under a common distribution. If
<em>Ïƒ</em><sub><em>b</em></sub> were replaced with a fixed number like 10, then all
of the effects in <strong>b</strong> would be independent and unaware of each other:
There would be <em>no pooling</em> of information between the groups. If we
remove it from the modelâ€”replace <em>Ïƒ</em><sub><em>b</em></sub> with 0, so to
speakâ€”then all the group variability is ignored, and there is
<em>complete pooling</em> of information into a single mean effect. With 
<em>Ïƒ</em><sub><em>b</em></sub> all the groups can contribute information about the 
distribution of plausible effects, and so, there can be 
<em>partial pooling</em> of information between groups.</p>

<p>Consider the <a href="https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html" title="Documentation on the radon dataset"><code>radon</code> dataset</a> example from <a href="https://amzn.to/3aVa9tB" title="An Amazon Affliate link to Gelman and Hill">Gelman and Hill
(2007)</a>. Radon measurements were taken in Minnesota
counties. We would like to estimate the average radon measurement for
each county. We have a repeated measures situation, and some counties
have more observations than others. We use a Bayesian mixed effects
model with <a href="https://github.com/paul-buerkner/brms">brms</a> to estimate a
population distribution of county estimates, and the county-level
estimates are randomly varying effects. They are drawn from a random
distribution, the scale of which we estimate from the data.</p>

<div><div><pre><code><span>library</span><span>(</span><span>tidyverse</span><span>)</span><span>
</span><span>theme_set</span><span>(</span><span>theme_grey</span><span>(</span><span>base_size</span><span> </span><span>=</span><span> </span><span>14</span><span>))</span><span>
</span><span>library</span><span>(</span><span>brms</span><span>)</span><span>
</span><span>radon</span><span> </span><span>&lt;-</span><span> </span><span>rstanarm</span><span>::</span><span>radon</span><span>

</span><span>b_radon</span><span> </span><span>&lt;-</span><span> </span><span>brm</span><span>(</span><span>
  </span><span>log_radon</span><span> </span><span>~</span><span> </span><span>1</span><span> </span><span>+</span><span> </span><span>(</span><span>1</span><span> </span><span>|</span><span> </span><span>county</span><span>),</span><span> 
  </span><span>radon</span><span>,</span><span> 
  </span><span>family</span><span> </span><span>=</span><span> </span><span>gaussian</span><span>,</span><span> 
  </span><span>file</span><span> </span><span>=</span><span> </span><span>"radon"</span><span>
</span><span>)</span><span>
</span><span>b_radon</span><span>
</span><span>#&gt;  Family: gaussian </span><span>
</span><span>#&gt;   Links: mu = identity; sigma = identity </span><span>
</span><span>#&gt; Formula: log_radon ~ 1 + (1 | county) </span><span>
</span><span>#&gt;    Data: radon (Number of observations: 919) </span><span>
</span><span>#&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span><span>
</span><span>#&gt;          total post-warmup samples = 4000</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Group-Level Effects: </span><span>
</span><span>#&gt; ~county (Number of levels: 85) </span><span>
</span><span>#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; sd(Intercept)     0.30      0.05     0.22     0.40 1.00     1782     2894</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Population-Level Effects: </span><span>
</span><span>#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; Intercept     1.35      0.05     1.26     1.45 1.00     2749     3198</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Family Specific Parameters: </span><span>
</span><span>#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; sigma     0.77      0.02     0.73     0.80 1.00     7374     3105</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS</span><span>
</span><span>#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span><span>
</span><span>#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span><span>
</span></code></pre></div></div>

<p>Here <code>sd(Intercept)</code> corresponds to <em>Ïƒ</em><sub><em>b</em></sub>.</p>

<p>We can plot the observed county means alongside the model estimated
ones. First, I do some wrangling so that the difference between observed
means and estimated means are computed for use later on.</p>

<div><div><pre><code><span>radon_aug</span><span> </span><span>&lt;-</span><span> </span><span>radon</span><span> </span><span>%&gt;%</span><span>
  </span><span># add ns and means</span><span>
  </span><span>group_by</span><span>(</span><span>county</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>mutate</span><span>(</span><span>
    </span><span>observed_mean</span><span> </span><span>=</span><span> </span><span>mean</span><span>(</span><span>log_radon</span><span>),</span><span>
    </span><span>county_n</span><span> </span><span>=</span><span> </span><span>n</span><span>()</span><span>
  </span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span> 
  </span><span># add fitted values</span><span>
  </span><span>tidybayes</span><span>::</span><span>add_fitted_draws</span><span>(</span><span>b_radon</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>mutate</span><span>(</span><span>
    </span><span>observed_minus_model</span><span> </span><span>=</span><span> </span><span>observed_mean</span><span> </span><span>-</span><span> </span><span>.value</span><span> 
  </span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span># summarize fitted values</span><span>
  </span><span>ggdist</span><span>::</span><span>median_qi</span><span>(</span><span>.value</span><span>,</span><span> </span><span>observed_minus_model</span><span>)</span><span> 

</span><span>radon_aug</span><span>$</span><span>type</span><span> </span><span>&lt;-</span><span> </span><span>"mixed model estimates"</span><span>
</span><span>radon</span><span>$</span><span>type</span><span> </span><span>&lt;-</span><span> </span><span>"observed means"</span><span>

</span><span>ggplot</span><span>(</span><span>radon_aug</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>aes</span><span>(</span><span>
    </span><span>x</span><span> </span><span>=</span><span> </span><span>fct_rev</span><span>(</span><span>fct_infreq</span><span>(</span><span>county</span><span>)),</span><span> 
    </span><span>y</span><span> </span><span>=</span><span> </span><span>log_radon</span><span>,</span><span> 
    </span><span>color</span><span> </span><span>=</span><span> </span><span>type</span><span>,</span><span> 
    </span><span>shape</span><span> </span><span>=</span><span> </span><span>type</span><span>
  </span><span>)</span><span> </span><span>+</span><span>
  </span><span>stat_summary</span><span>(</span><span>data</span><span> </span><span>=</span><span> </span><span>radon</span><span>,</span><span> </span><span>fun</span><span> </span><span>=</span><span> </span><span>mean</span><span>,</span><span> </span><span>geom</span><span> </span><span>=</span><span> </span><span>"point"</span><span>)</span><span> </span><span>+</span><span>
  </span><span>geom_point</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>.value</span><span>))</span><span> </span><span>+</span><span> 
  </span><span># Want to include y = 0 in the figure</span><span>
  </span><span>geom_blank</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>0</span><span>))</span><span> </span><span>+</span><span>
  </span><span>labs</span><span>(</span><span>
    </span><span>x</span><span> </span><span>=</span><span> </span><span>"county (in increasing order by sample size)"</span><span>,</span><span> 
    </span><span>y</span><span> </span><span>=</span><span> </span><span>"log(radon)"</span><span>
  </span><span>)</span><span> </span><span>+</span><span>
  </span><span>geom_hline</span><span>(</span><span>yintercept</span><span> </span><span>=</span><span> </span><span>fixef</span><span>(</span><span>b_radon</span><span>)[</span><span>1</span><span>])</span><span> </span><span>+</span><span>
  </span><span>scale_color_manual</span><span>(</span><span>values</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>"blue"</span><span>,</span><span> </span><span>"grey40"</span><span>))</span><span> </span><span>+</span><span>
  </span><span>labs</span><span>(</span><span>color</span><span> </span><span>=</span><span> </span><span>NULL</span><span>,</span><span> </span><span>shape</span><span> </span><span>=</span><span> </span><span>NULL</span><span>)</span><span> </span><span>+</span><span>
  </span><span>theme</span><span>(</span><span>
    </span><span>axis.text.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>axis.ticks.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>panel.grid.major.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>panel.grid.minor.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>legend.title</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>legend.position</span><span> </span><span>=</span><span> </span><span>"top"</span><span>,</span><span> 
    </span><span>legend.direction</span><span> </span><span>=</span><span> </span><span>"horizontal"</span><span>,</span><span>
    </span><span>legend.justification</span><span> </span><span>=</span><span> </span><span>"left"</span><span>,</span><span>
  </span><span>)</span><span> 
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/county-means-1.png" title="A plot showing log radon on the y axis and county on the x asis. There are two sets of overlapping points. There are the observed means in each country and the model estimated means. There is much less variability in the modeled means." alt="A plot showing log radon on the y axis and county on the x asis. There are two sets of overlapping points. There are the observed means in each country and the model estimated means. There is much less variability in the modeled means." width="80%"></p>

<p>We see a classic example of partial pooling. First note that model
estimates (blue circles) are less variable: None go above <em>y</em> = 2 and
only four go below <em>y</em> = 1. For counties with many observations (right
side), the estimated mean is hardly adjusted. There is less of a visual
gap between the observed mean and estimated mean. For counties with less
data (left side), the estimate is pulled towards the population mean
(<code>Intercept</code> in the summary above).</p>

<p>The following plot shows difference between the observed means and
the estimated means, subtracting the grey triangles from the blue squares
in the plot above.</p>

<div><div><pre><code><span>radon_aug</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span> 
  </span><span>distinct</span><span>(</span><span>county</span><span>,</span><span> </span><span>county_n</span><span>,</span><span> </span><span>observed_minus_model</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ggplot</span><span>()</span><span> </span><span>+</span><span> 
    </span><span>aes</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>county_n</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>observed_minus_model</span><span>)</span><span> </span><span>+</span><span> 
    </span><span>geom_point</span><span>(</span><span>alpha</span><span> </span><span>=</span><span> </span><span>.5</span><span>)</span><span> </span><span>+</span><span>
    </span><span>labs</span><span>(</span><span>
      </span><span>x</span><span> </span><span>=</span><span> </span><span>"Number of observations in county"</span><span>,</span><span>
      </span><span>y</span><span> </span><span>=</span><span> </span><span>"Observed mean - estimated mean"</span><span>
    </span><span>)</span><span> 
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/shrinkage-by-n-1.png" title="Plot with number of observations on the x axis and the difference between the observed and estimated means on the y axis. There is a smaller difference for counties with more data." alt="Plot with number of observations on the x axis and the difference between the observed and estimated means on the y axis. There is a smaller difference for counties with more data." width="66%"></p>

<p>The contention behind the <em>smooths = random effects</em> claim is that what we
just did is a case of <em>smoothing</em>. These random effects are, in a way, 
smoothed fixed effects.</p>

<blockquote>
  <p>The function <code>random()</code> can be seen as a smoother for use with factors
in <code>gamlss()</code>. It allows the fitted values for a factor predictor to
be shrunk towards the overall mean [â€¦]</p>

  <p>â€” <a href="https://rdrr.io/cran/gamlss/man/random.html" title="random: Specify a random intercept model in a GAMLSS formula">GAMLSS documentation</a> describing a random intercept as a smoother</p>
</blockquote>

<h2 id="but-whats-smoothing">But whatâ€™s smoothing?</h2>

<p>Now letâ€™s walk through a generalized additive model in
<a href="https://cran.r-project.org/web/packages/mgcv/index.html">mgcv</a> to
demonstrate a penalized smoothing spline. That was a mouth full, but
basically additive models are like the smoothing expansion pack for the
standard linear model. Weâ€™re still doing regression, but we have some
new syntax and our models can do nonlinear relationships more easily
now.</p>

<p>I will walk through a basic example of how a splineâ€™s basis functions
are weighted to approximate a nonlinear trend, but this is not going to
be a full tutorial. Other people have made video introductions to
<a href="https://youtu.be/Zxokd_Eqrcg?t=506" title="Dr. Gavin Simpson - Learning When, Where, and by How Much, Things Change [Remote]">additive models</a> or the <a href="https://youtu.be/q4_t8jXcQgc" title="Noam Ross - Nonlinear Models in R: The Wonderful World of mgcv">mgcv package</a>. I first
learned them from <a href="https://arxiv.org/abs/1703.05339" title="Generalised additive mixed models for dynamic analysis in linguistics: a practical introduction">a tutorial for linguists</a> and then from
<a href="https://amzn.to/37PLa8W" title="An Amazon Affliate link to Simon Wood's GAM textbook">the mgcv textbook</a>, but there are <a href="https://github.com/noamross/gam-resources" title="Resources for Learning About and Using GAMs in R">other resources
online</a>.</p>

<p>We use the <a href="https://rdrr.io/pkg/MASS/man/mcycle.html" title="Documentation on the mcycle dataset"><code>mcycle</code></a> dataset which gives the head
acceleration in a simulated motorcycle accident. We are going to fit a
model, plot the smooth from it, and then we are going to work through
what the model did.</p>

<div><div><pre><code><span>library</span><span>(</span><span>mgcv</span><span>)</span><span>

</span><span>mcycle</span><span> </span><span>&lt;-</span><span> </span><span>MASS</span><span>::</span><span>mcycle</span><span> </span><span>%&gt;%</span><span> 
  </span><span>tibble</span><span>::</span><span>rowid_to_column</span><span>()</span><span>

</span><span># Fit the model</span><span>
</span><span>gam_20</span><span> </span><span>&lt;-</span><span> </span><span>gam</span><span>(</span><span>
  </span><span>accel</span><span> </span><span>~</span><span> </span><span>1</span><span> </span><span>+</span><span> </span><span>s</span><span>(</span><span>times</span><span>,</span><span> </span><span>bs</span><span> </span><span>=</span><span> </span><span>"cr"</span><span>,</span><span> </span><span>k</span><span> </span><span>=</span><span> </span><span>20</span><span>),</span><span> 
  </span><span>data</span><span> </span><span>=</span><span> </span><span>mcycle</span><span>,</span><span> 
  </span><span>method</span><span> </span><span>=</span><span> </span><span>"REML"</span><span>
</span><span>)</span><span>

</span><span>mcycle</span><span>$</span><span>.fitted</span><span> </span><span>&lt;-</span><span> </span><span>fitted</span><span>(</span><span>gam_20</span><span>)</span><span>

</span><span>ggplot</span><span>(</span><span>mcycle</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>aes</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>times</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>accel</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>geom_point</span><span>(</span><span>alpha</span><span> </span><span>=</span><span> </span><span>.5</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>geom_line</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>.fitted</span><span>),</span><span> </span><span>color</span><span> </span><span>=</span><span> </span><span>"blue"</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>labs</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>"time after impact [ms]"</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>"acceleration [g]"</span><span>)</span><span>
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/smooth-demo-1.png" title="Scattplot showing time on the x axis and acceleration on the y axis. The model fit is shown in blue. It makes two big turns down and then up." alt="Scattplot showing time on the x axis and acceleration on the y axis. The model fit is shown in blue. It makes two big turns down and then up." width="80%"></p>

<p>So what happened here? We will cover it visually.</p>

<h3 id="splines-are-the-sums-of-weighted-wiggles">Splines are the sums of weighted wiggles</h3>

<p>Letâ€™s look at the regression formula.</p>

<div><div><pre><code><span>formula</span><span>(</span><span>gam_20</span><span>)</span><span>
</span><span>#&gt; accel ~ 1 + s(times, bs = "cr", k = 20)</span><span>
</span></code></pre></div></div>

<p>We told <code>gam()</code> to estimate <code>accel</code> using an intercept term and a smooth
term on the time predictor (<code>s(times, ...)</code>). Specifically, we created
our smooth using a cubic regression spline basis (<code>bs = "cr"</code>) with <code>k
= 20</code> - 1 curves. Our model is
estimating a function by adding up smaller components called <em>basis
functions</em>, and the space that defines those components is the <em>basis</em>.
These basis functions are weighted and summed together to produce a
smooth trend called a <em>spline</em>. The name <em>splines</em> is inspired by
drafting splines which are flexible strips of wood that can be weighted
and anchored in place to make a nice curve.</p>

<p>To reiterate, conceptually, we are decomposing the <code>times</code> predictor
into a bunch of individual wiggly lines (basis functions), and these are
weighted and summed together to approximate some nonlinear function. My
post on <a href="https://www.tjmahr.com/polypoly-package-released/">orthogonal polynomials</a>
illustrates the same principle but with polynomial basis functions.
Richard McElreath provides <a href="https://youtu.be/ENxTrFf9a7c?t=2226" title="Statistical Rethinking Winter 2019 Lecture 04">a friendly 30-minute introduction
splines</a> in a Bayesian model in his Statistical
Rethinking course. One line I appreciate from his description is that
with splines, we replace a predictor variable, like <code>times</code>, with a set
of â€œsyntheticâ€ predictor variables.</p>

<figure>
  <img src="https://www.tjmahr.com/assets/images/2021-02-spline.png" alt="An illustration of a drafting spline."><figcaption>
      A drafting spline is a flexible strip of wood that is anchored at a few points so that one can create smooth curves. â€¦</figcaption></figure></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tjmahr.com/random-effects-penalized-splines-same-thing/">https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</a></em></p>]]>
            </description>
            <link>https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300028</guid>
            <pubDate>Mon, 01 Mar 2021 05:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animated PNG vs. Animated Webp vs. GIF]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300015">thread link</a>) | @panabee
<br/>
February 28, 2021 | https://corydowdy.com/blog/apng-vs-webp-vs-gif | <a href="https://web.archive.org/web/*/https://corydowdy.com/blog/apng-vs-webp-vs-gif">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>With Chrome now supporting Animated PNG as of Chrome 59 we have two image formats that can supplant the old and tired GIF format. Varying posts and sites have different conclusions on when to use APNG versus an animated Webp. In all my findings (linked below where the source Gif comes from) animated webp beats apng in filesize each and every time. Sometimes by not very much. This of course is anecdotal and I'm not as familiar with apng as the creators and others may be so they may be able to squeeze more out of an apng than I can.</p>

<p>All that being said I've heard and read people say "APNG might be bigger but webp takes longer to decode in the browser". That assumes the larger APNG will load faster than the smaller webp. Is that the case though? I assume the smaller webp gets downloaded to the client faster then it'll start decoding faster. Thus animating faster. So lets actually test that instead of me spouting off haha. On to the source GIF.</p>

<p>The GIF I'm using for this post comes from my post on <a href="https://corydowdy.com/blog/converting-mp4-to-webm">Converting MP4 To Webm <span>&nbsp;</span></a>. That was a 1080p video stripped down to about 5 seconds and resized to a width of 800.</p>

<p>Here are the relevant details of the unoptimized GIF:</p>

<ul>
<li>Dimensions: 800x450</li>
    <li>Length: 5s</li>
    <li>Size: â‰ˆ37.9MB</li>
</ul>
<h2>Setup</h2>

<p>Before we can even embark on this trip we have to convert the GIF above to an APNG and an Animated Webp. Maybe you can convert the GIF on this page to an APNG and get better results. Please try I don't want to dismiss APNG as much as I think I'm probably coming off as.</p>

<h3>Converting to an Animated PNG (apng)</h3>

<p>Gif2apng offers three different options for converting a GIF to an animated PNG. We have zlib, 7zip and Zopfli compression. Each compression option besides zlib allows you to set an iteration amount which defaults to 15.</p>

<p>I'm using gif2apng version 1.9 <a href="#footnotes-apng">[ 1 ] [ 2 ]</a>. For both 7zip and zopfli I'll use the "default" iterations of 15 and a more aggressive version of 100. Be warned if you want to do this. Depending on your server specs or locally on your own computer and it's specs Zopfli will take a long time. Increasing the iterations for either of the compression algorithms will also increase how long it takes to convert your image to an APNG. Be prepared to set aside a pretty big chunk of time if you do this on your computer :).</p>

<p>After converting the GIF to an Animated PNG I'll also run it through APNGOPT. This should "optimize" the Animated PNG. This too offers differing amount of iterations. I'll use the "default" of 15 for each apng that was converted with the defaults above and 100 for all the 100 iterations.</p>

<h4>APNG Filesize Results</h4>



<p>We can see that Zopfli compression saves the most before running these through apngopt. It's very CPU intensive though. After running these through apngopt things didn't change much or at all.</p>

<div>
<table>
<caption>Filesize of APNG after using APNGOPT</caption>
    <thead><tr>
<th>Compression Type</th>
            <th>Original Size in MB</th>
            <th>APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th>Unoptimized Gif</th>
            <td>â‰ˆ37.9MB</td>
            <td></td>
        </tr>
<tr>
<th>Animated PNG with Zlib</th>
            <td>â‰ˆ33.01MB</td>
            <td>â‰ˆ33.04MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 15 iterations</th>
            <td>â‰ˆ31.22MB</td>
            <td>â‰ˆ31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 100 iterations</th>
            <td>â‰ˆ31.22MB</td>
            <td>â‰ˆ31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 15 iterations</th>
            <td>â‰ˆ30.92MB</td>
            <td>â‰ˆ30.91MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 100 iterations</th>
            <td>â‰ˆ30.87MB</td>
            <td>â‰ˆ30.86MB</td>
        </tr>
</tbody>
</table>
</div>

<h5 id="apng-footnote-label">APNG Footnotes</h5>

<ol id="footnotes-apng">
<li>On a windows machine just use the GUI they package from sourceforge. It seems to be the most up to date. I haven't had the time to see if the GUI and CLI differ in anyway so that'll be up to you unless you're ok with the output of the GUI then keep on keepin on!</li>
    <li>If you install gif2apng through your OS's package manager (ie: apt-get/apt) depending on your OS's you'll more than likely get version 1.7.</li>
    <li>Depending on your OS again if you use the CLI version of apngopt you'll get versions ranging from 1.1 to 1.4.</li>
</ol>
<h2>Animated Webp</h2>

<p>The same reference gif was converted to a webp using three different options and WebP Encoder version: 0.6.0 (WebP Mux version: 0.4.0).</p>

<p>I didn't dive into the different CLI options available for gif2webp. Things such has <code> -kmin </code> , <code> -kmax </code> â€” which specify the minimum and maximum distance between consecutive key frames and can improve decoding performance â€” or adjust the deblocking filter <code> -f </code> from the docs suggested 50. These could with adjustments and tweaking produce smaller or in some instances bigger files. You'll have to test those out for specific images, or use the defaults such as I have.</p>

<ul>
<li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.default.webp">It's default settings (quality 75) <span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.webp">quality of 70 and 6 (-m 6) for the compression mode. It's highest.<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.webp">A quality of 70 with default compression of 4 (lossless)<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.mixed.webp">an unfair mixed mode (lossless and lossy compression) with a quality of 70<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.mixed.webp">another unfair Quality 70 with Commpression of 6 &amp; Mixed compression (lossy and lossles)<span>&nbsp;</span></a></li>
</ul>
<p>Webp at it's default settings beats (barely) each of the converted APNG's, 30.86MB for the Webp compared to 33.01MB using default APNG settings (zlib) and 30.87MB using zopfli compression @ 100 iterations.</p>

<div>
<table>
<caption>Filesize of Webp &amp; Optimized APNG</caption>
    <thead><tr>
<th>File</th>
            <th>Quality</th>
            <th>Compression Mode</th>
            <th>Webp Size in MB</th>
            <th>Best APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th rowspan="5">Animated Webp</th>
            <td>Default (75)</td>
            <td>Default (4)</td>
            <td>â‰ˆ30.82MB</td>
            <td rowspan="5">â‰ˆ30.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>6 highest</td>
            <td>â‰ˆ31.80MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Default (4)</td>
            <td>â‰ˆ30.82MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed</td>
            <td>â‰ˆ5.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed &amp; 6 (highest)</td>
            <td>â‰ˆ5.32MB</td>
        </tr>
</tbody>
</table>
</div>

<p>Ok cool all the file size mumbo jumbo is out of the way. Does a few kb/mb matter when they are so close? The default webp settings gives us the same size file of an apng using apngout and zopfli @ 100 iterations.</p>

<p>Yep. The larger apng will in fact decode faster. But does that matter? Kind of.</p>
<!-- /#setup --><h2>Summoning the WebPageTest Gods!</h2>

<p>Typically in a situation like this I would use <a href="http://www.webpagetest.org/video/">Webpagetest's "visual comparison" <span>&nbsp;</span></a> option that way we could see the pages load side by side. I'd run a desktop test and then I'd run a mobile test using the "emerging markets" settings. I can't right now since as mentioned above APNG support is in Chrome 59+. The visual comparison tool uses the current stable release of Chrome (which just happened to be updated while I was testing these out. Still to be sure I ran with the Canary version). What most everyone using a non dev/beta version of Chrome uses.</p>

<p>So I'm running these tests on Chrome Canary and will use the median from the first view as the comparison. I'll run each image option/type three (3) times on Chrome desktop using a cable connection â€” 5Mbps 28ms Latency â€” and three times using a Fourth Generation Moto G and their "Mobile 3g" connection â€” 768 Kbps 3G connection with 300ms of latency.</p>
<h3>Webp Defaults vs. Best Animated PNG</h3>

<p>The first comparison I ran is the default settings of gif2webp. As mentioned above this defaults to a quality of 75, compression mode of 4 and is lossless like APNG. You can download these animated images and run them yourself. You'll see which actually loads faster without even having to read haha.</p>

<p>Webp at it's default settings might in fact be smaller in file size (for this particular animation) than the APNG. It helps in the fact that we are sending less bytes down the wire but as for over all page load performance you can see below it's not helping much or if any at all.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Desktop Cable Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>3108</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>44.7s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>53.341s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.984s</td>
        </tr>
</tbody>
</table>
</div>

<p>Here we can see the visual differences between both of these formats.</p>



<p>These are large files. You're doing yourself and your users a disservice if you send these big honking things down the wire to them.</p>

<h3>Webp and APNG on Mobile 3g Connection</h3>

<p>Webp's defaults will help you out on a a slow 3g connection because it's sending less data. APNG gets frames faster to the screen since it decodes faster, hence the better speed index below.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Mobile 3g Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-mobile.png" title="Webp Defaults Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-mobile-3g.png" title="APNG Zopfli 100 Iterations Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>5157</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>41.014s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>4.485s</td>
            <td>3.327s</td>
        </tr>
</tbody>
</table>
</div>



<p>So don't use APNG nor the Webp Defaults on a slow connection in my opinion. They are big files.</p>

<h2>Your Best Bet</h2>

<p>So is there a solution for smaller file size than gif and that actually helps your page performance? Yes if you don't mind a possible lossy compressed image.</p>

<p>We can take the Webp image converted with the defaults, the mixed compression (lossy &amp; lossless), the lossy converted webp, and a lossy compressed and filtered webp image and compare those to the "best" file size wise APNG and an unoptimized GIF.</p>

<p>Before I show you those here are the numbers from those runs on a desktop.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Desktop Cable Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>962</td>
            <td>785</td>
            <td>882</td>
            <td>3108</td>
            <td>2282</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>1.200s</td>
            <td>4.400s</td>
            <td>4.200s</td>
            <td>44.7s</td>
            <td>45.100s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>11.600s</td>
            <td>11.446s</td>
            <td>9.734s</td>
            <td>53.341s</td>
            <td>66.486s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.879s</td>
            <td>0.681s</td>
            <td>0.783s</td>
            <td>0.984s</td>
            <td>0.778s</td>
        </tr>
<tr>
<th></th>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-desktop.png" title="Webp Lossy Desktop Cable Connection">test screenshot </a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-filtered-desktop.png" title="Webp Lossy &amp; Filtered Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-mixed-desktop.png" title="Webp Mixed Compression Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/gif-desktop.png" title="Unoptimized GIF Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
        </tr>
</tbody>
</table>
</div>

<p>Here is the visual comparison.</p>



<p>What I was most surprised by was how close a default settings animated webp and an unoptimized gif page load times and speed index were.</p>

<p>These aren't fair comparision to APNG either since there is lossy compression. There's also high variance in the load times. Much like you'd have in a real world scenario. So take these results with a grain of salt. I didn't put much effort into making them all variable free.</p>

<h3>APNG and Webp Mobile 3g</h3>

<p>Where you'll get the most benefit with this animated webp is on a slow 3g connection.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Mobile 3g Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>37.631s</td>
            <td>37.408s</td>
            <td>31.839s</td>
            <td>146.060s</td>
            <td>124.712s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>3811</td>
            <td>3964</td>
            <td>3858</td>
            <td>5157</td>
            <td>29382</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>6.871s</td>
            <td>34.057s</td>
            <td>30.033s</td>
            <td>41.014s</td>
            <td>106.860s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td></tr></tbody></table></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corydowdy.com/blog/apng-vs-webp-vs-gif">https://corydowdy.com/blog/apng-vs-webp-vs-gif</a></em></p>]]>
            </description>
            <link>https://corydowdy.com/blog/apng-vs-webp-vs-gif</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300015</guid>
            <pubDate>Mon, 01 Mar 2021 05:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[7 Reasons not to join a startup and 1 reason to]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299940">thread link</a>) | @czhu0217
<br/>
February 28, 2021 | https://huyenchip.com/2021/02/27/why-not-join-a-startup.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In 2018, I wrote <a href="https://huyenchip.com/2018/10/08/career-advice-recent-cs-graduates.html">Career advice for recent Computer Science graduates</a> about joining a big company instead of a startup after college.</p>

<p>In 2019, when I left NVIDIA, I wrote <a href="https://huyenchip.com/2019/12/23/leaving-nvidia-lessons.html">Lessons learned after my first full-time job</a> about leaving a big company for a startup.</p>

<p>Now that Iâ€™ve left my first full-time job at a startup, I want to revisit the topic. This is based on some personal experience, but most come from friendsâ€™ experiences, including the intensive note on startups from a friend who had worked at 3 startups before and who would like to remain anonymous. I hope that itâ€™ll give some pointers to those trying to decide whether to take the leap.</p>

<p>Some asked if this post is about Snorkel. Itâ€™s not. Snorkel is an exception. Itâ€™s a great startup, which is a reason why I joined in the first place, and I recommend it to all my friends who are looking to join a startup.</p>

<p><strong>Disclaimer</strong>:</p>
<ol>
  <li>Each of the points below is true for many startups, but not for all startups, and itâ€™s more true for early-stage startups (e.g. before series B). There are always exceptions, extreme exceptions, unreasonable exceptions, which make the startup world so exciting.</li>
  <li>A friend told me that these points are only true for bad startups. Most startups are, unfortunately, bad startups.</li>
</ol>

<hr>
<p><b>Table of contents</b><br>
â€¦. <a href="#why_not_join_a_startup">7 reasons not to join a startup</a><br>
â€¦â€¦.. <a href="#1_work_life_balance">Reason 1. Goodbye work-life balance</a><br>
â€¦â€¦.. <a href="#2_bad_engineering">Reason 2. Youâ€™ll pick up bad engineering practices</a><br>
â€¦â€¦.. <a href="#3_mentorship">Reason 3. Less mentorship</a><br>
â€¦â€¦.. <a href="#4_equity">Reason 4. You wonâ€™t get rich</a><br>
â€¦â€¦.. <a href="#5_management">Reason 5. Bad management</a><br>
â€¦â€¦.. <a href="#6_enjoyment">Reason 6. You might have to do a lot of things you donâ€™t want to do</a><br>
â€¦â€¦.. <a href="#7_career_growth">Reason 7. No clear career growth trajectory</a><br>
â€¦. <a href="#why_join_a_startup">One reason to join a startup</a><br>
â€¦. <a href="#next">Whatâ€™s next for me?</a><br></p>

<hr>

<h2 id="why_not_join_a_startup">7 reasons not to join a startup</h2>

<h3 id="1_work_life_balance">Reason 1. Goodbye work-life balance</h3>

<p>A friend at a tech giant told me that he and his co-workers once mused about how long they could go on not working until someone noticed. The answers were between a week and two months. At an early-stage startup, the answer is likely a couple of hours.</p>

<p>My transition from NVIDIA to Snorkel was a culture shock. At NVIDIA, you can have a predictable schedule, e.g. coming in at 9am and leaving at 6pm every day. If you donâ€™t finish something by Friday afternoon, just push the deadline to next week and go to happy hour. Itâ€™s okay, even expected, to not check emails or Slack for the entire weekend.</p>

<p>On my first day at Snorkel, when I left at 7pm, I was the first one to leave.</p>

<p>Nobody told me how to spend my time, but when everyone else worked over the weekend and responded to my Slack messages any time of the night, I wanted to do the same. Nobody forced me to take on a hefty task that would require me to cancel plans with friends, but I also knew that everybody else had their hands full and if I didnâ€™t do it, we wouldnâ€™t be able to finish this feature on time and the company would lose a contract or even die.</p>

<p>By the time that I left, the work-life balance had got a lot more balanced. Snorkel had hired a ton more people to share the workload and we had worked out processes to speed things up.</p>

<p>In general, Iâ€™ve observed that the bigger the startup, the better the work-life balance. Possible explanations:</p>

<ol>
  <li>The earlier the startup, the more precarious its survival, and the harder everyone has to push.</li>
  <li>In very early-stage startups, the working culture is dominated by those with high ownership in the company (the founding team), who are incentivized to work harder. Later on, the working culture is dominated by people with much lower ownership in the company (e.g. 0.1% over 4 years for the 20th engineer vs. 20% for the founder), who are more incentivized to keep a work-life balance.</li>
</ol>

<p><strong>Caveat</strong>: The work-life balance at an early-stage startup depends a lot on how much the existing team members work. When interviewing at a startup, donâ€™t ask the founders how much they value work-life balance (theyâ€™ll say â€œA lotâ€), but ask every team member you can talk to how much they work. If all of them work during evenings and weekends, you might likely feel pressured to do the same.</p>

<h3 id="2_bad_engineering">Reason 2. Youâ€™ll pick up bad engineering practices</h3>

<p>Consider the following scenario. A customer requires a new feature and you have to deliver it in a week. This feature is similar to one of your existing features, so the best solution is to refactor the existing code to allow some of it to be reused.</p>

<p>However, refactoring alone would require a week. Your tech lead decides that you should just duplicate the existing code and turn it into a new feature. Now you have two massive code structures that are similar but not quite. When making changes to one structure, you have to remember to change the other too.</p>

<p>Then, somebody forgets and a wild bug appears. The person assigned to fix it isnâ€™t given a lot of time, so instead of investigating the duplicate code, they write a hacky function on top.</p>

<p>Startups build 1 from 0, something from nothing. <em>Adding new things fast</em> takes precedence over both <em>adding good things slow</em> and <em>fixing existing things</em>. You might get used to writing quick and dirty code, <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">cargo cult programming</a>, merging code that has no tests, merging before tests complete, committing without comments, spaghetti code, magic numbers.</p>

<p>Bad practices might be a mere dissatisfaction at first, but can gradually become a habit, then become the only way you know how to work.</p>

<h3 id="3_mentorship">Reason 3. Less mentorship</h3>

<p>The thing I missed the most when leaving NVIDIA was mentorship. Large companies, by virtue of having a lot of employees, tend to have many people whose diverse life experience can provide you invaluable advice. At NVIDIA, I could come to my mentors for questions from general career dilemmas to obscure engineering knowledge. Once in a while, I browsed the org chart of tens of thousands of employees, identified people I want to learn from, and asked them to meet at the coffee machine, which they usually accepted.</p>

<p>Startups donâ€™t have that many people for you to reach out to in the first place. Your handful of coworkers might have backgrounds and experiences similar to yours (cue founders who say they prefer hiring from their existing networks) and are unlikely to give you dramatically different perspectives. Even if there are people who could mentor you, given the pace at which startups move, they might not have the time for it.</p>

<p>To be clear, you can still learn a lot from your coworkers at startups, just a different kind of learning.</p>

<h3 id="4_equity">Reason 4. You wonâ€™t get rich</h3>

<p>Despite a plethora of articles warning people that joining startups is a bad way to get rich (<a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/">1</a>, <a href="https://danluu.com/startup-tradeoffs/">2</a>, <a href="https://hunterwalk.medium.com/sorry-startup-employee-100-your-equity-probably-won-t-make-you-rich-d6549ece71bd">3</a>), many people still think joining a startup is a get-rich-quick scheme. Hereâ€™s the gist of the math. Imagine youâ€™re an <strong>engineer with 2-3 years of experience</strong>.</p>

<p>If you join a startup as the <strong>15th engineer</strong> (not executive), your compensation might look like the following.</p>

<ol>
  <li><strong>Base salary</strong>: Your base salary is usually lower than you would have got at a big company (e.g. <strong>$120K instead of $160K</strong>) because at startups, equity makes a large chunk of your compensation.</li>
  <li><strong>Equity</strong>: You might get <strong>0.05% - 0.25%</strong> equity vested over <strong>4 years</strong>. After subsequent fundraising rounds, this amount of equity is diluted to <strong>0.02% - 0.1% for 4 years</strong>.</li>
</ol>

<table>
    
  <tbody><tr>
   <td>
<strong>Probability<br>(</strong>appx<strong>)</strong>
   </td>
   <td><strong>Startup scenario</strong>
   </td>
   <td><strong>Startup value</strong>
   </td>
   <td><strong>Your equity value<br>over 4 year</strong>
   </td>
   <td><strong>Your yearly comp<br>(base + equity)</strong>
   </td>
  </tr>
  <tr>
   <td>80%
   </td>
   <td>Fails
   </td>
   <td>0
   </td>
   <td>0
   </td>
   <td>$120K
   </td>
  </tr>
  <tr>
   <td>5%
   </td>
   <td>IPO
   </td>
   <td>$1 billion
   </td>
   <td>$200K - 1M
   </td>
   <td>$170K - 270K
   </td>
  </tr>
  <tr>
   <td>0.5%
   </td>
   <td>IPO
   </td>
   <td>$10 billion
   </td>
   <td>$2M - 10M
   </td>
   <td>$620K - 2.62M
   </td>
  </tr>
  <tr>
   <td>0.05%
   </td>
   <td>IPO
   </td>
   <td>$100 billion
   </td>
   <td>$20M - 100M
   </td>
   <td>$5M - 25M
   </td>
  </tr>
  <tr>
   <td>14.45%
   </td>
   <td>Acquired
   </td>
   <td>$$$
   </td>
   <td>$0 - 8M
   </td>
   <td>$120K - 2.12M
   </td>
  </tr>
</tbody></table>

<p><br>
<strong>If you join late at the startup (say employee number 100+), even if the company succeeds wildly, your equity will be worth very little.</strong></p>

<p>If you want to get rich, join a big company and climb their rank. You can find the detailed analysis of compensations for 19,000 FAAAM-dominated tech workers <a href="https://huyenchip.com/2020/01/18/tech-workers-19k-compensation-details.html">here</a>, but below is a plausible, even conservative, scenario if you join a company like Google with 2-3 years of experience.</p>

<ul>
  <li>1st year, L4 $250K/year.</li>
  <li>2nd year, L4, $280K/year.</li>
  <li>3rd year, L4, $320K/year.</li>
  <li>4th year, L5, $360K/year.</li>
</ul>

<p>After the first 4 years at Google, youâ€™ve already made over $1 million, not counting â€œperksâ€ like work-life balance.</p>

<h3 id="5_management">Reason 5. Bad management</h3>

<p>Thereâ€™s a trend among startups to not fixate on titles until they have to. Some avoid â€œmanagerâ€ to not endanger the â€œeveryone is equalâ€ mindset (protip: everyone isnâ€™t equal at startups â€“ some have much more equity than others). In the early stage of a startup (e.g. before the 20th employee), there might not be anyone with â€œmanagerâ€ in their title. If you join during that phase, youâ€™re expected to get things done with little to no guidance.</p>

<p>Even if your startup has managers, they are likely bad managers. A startupâ€™s first managers are likely its founding team who might have little to no real-world working experience, let alone managerial experience (e.g. recent dropouts, recent graduates). It doesnâ€™t mean that people without working experience canâ€™t be good managers (I know a few), itâ€™s just more rare.</p>

<p>Bad management can manifest in the lack of feedback. At startups, you might get a lot of work-specific feedback â€“ demos, design docs, even code (though it might not be good feedback) â€“ because people at startups are generally more invested in the company. However, you wonâ€™t get much you-specific feedback that can help you grow such as what skills youâ€™re lacking or what you need to do to get to the level you want to get to.</p>

<p>Even if there are processes in place for feedback, everyone might be too caught up in sprinting to think about you, what you want, or what opportunities they can give you to grow.</p>

<p>Bad management can be especially frustrating during conflicts, which will inevitably arise when you work in a high-stress environment (e.g. youâ€™re all trying to push a feature at 11pm on a Saturday, everyone is tired and snappy). When something bothers you, you might feel like thereâ€™s no one you can talk to because you either â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299940</guid>
            <pubDate>Mon, 01 Mar 2021 05:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp Machine Manual (1984)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298553">thread link</a>) | @caslon
<br/>
February 28, 2021 | https://hanshuebner.github.io/lmman/title.xml | <a href="https://web.archive.org/web/*/https://hanshuebner.github.io/lmman/title.xml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><center><heading>Lisp Machine Manual</heading></center><center>Sixth Edition, System Version 99</center><center>June 1984</center><center>Richard Stallman</center><center>Daniel Weinreb</center><center>David Moon</center><nopara></nopara>
<p>This report describes research done at the Artificial Intelligence
Laboratory of the Massachusetts Institute of Technology.  Support for the
laboratory's artificial intelligence research is provided in part by the
Advanced Research Projects Agency of the Department of Defense under Office
of Naval Research Contract number N00014-80-C-0505.
<page></page></p><center><sub-heading>Preface</sub-heading></center>

<p>The Lisp Machine manual describes both the language and the operating system
of the Lisp Machine.  The language, a dialect of Lisp called Zetalisp,
is completely documented
by this manual.  The software environment and operating-system-like parts of
the system contain many things which are still in a state of flux.
This manual confines itself primarily to the stabler parts of the
system.  It describes how to program, but not for the most part how to
operate the machine.  The window system is documented separately in
the Lisp Machine Window System manual.
</p>

<p>Any comments, suggestions, or criticisms will be welcomed.  Please send
Arpa network mail to BUG-LMMAN@MIT-MC.
</p>

<p>Those not on the Arpanet may send U.S. mail to

<lisp><standard>Richard M. Stallman
Artificial Intelligence Lab
545 Technology Square
Cambridge, Mass. 02139</standard>
</lisp></p>

<p>Portions of this manual were written by Mike McMahon and Alan Bawden.
The chapter on the LOOP iteration macro is mostly a reprint of
Laboratory for Computer Science memo TM-169, by Glenn Burke.  Sarah
Smith, Meryl Cohen and Richard Ingria of LMI, and Richard Mlynarik of
MIT, helped to correct the manual.
</p>
<nopara></nopara><center><sub-heading>Personal Note from Richard Stallman</sub-heading></center>
<p>The Lisp Machine is a product of the efforts of many people too
numerous to list here and of the former unique unbureaucratic,
free-wheeling and cooperative environment of the M.I.T. Artificial
Intelligence Laboratory.  I believe that the commercialization of
computer software has harmed the spirit which enabled such systems to
be developed.  Now I am attempting to build a software-sharing movement to
revive that spirit from near oblivion.
</p>

<p>Since January 1984 I have been working primarily on the development of
GNU, a complete Unix-compatible software system for standard hardware
architectures, to be shared freely with everyone just like EMACS.
This will enable people to use computers and be good neighbors legally
(a good neighbor allows his neighbors to copy any generally useful
software he has a copy of).  This project has inspired a growing
movement of enthusiastic supporters.  Just recently the first free
portable C compiler compiled itself.  If you would like to contribute
to GNU, write to me at the address above.  Restrain social decay--help
get programmers sharing again.
</p>
<page></page>
</div></div>]]>
            </description>
            <link>https://hanshuebner.github.io/lmman/title.xml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298553</guid>
            <pubDate>Mon, 01 Mar 2021 00:42:43 GMT</pubDate>
        </item>
    </channel>
</rss>
