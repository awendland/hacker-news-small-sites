<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 01 Sep 2020 12:29:00 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 01 Sep 2020 12:29:00 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Why I don't give .edu discounts]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24322268">thread link</a>) | @AlchemistCamp
<br/>
August 30, 2020 | https://questinglog.com/why-I-dont-give-edu-discounts/ | <a href="https://web.archive.org/web/*/https://questinglog.com/why-I-dont-give-edu-discounts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>I create an educational product and students occasionally ask for discounts. So-called "educational" discounts are very popular, but I don't give them.</p> <p>To be honest, I don't like them at all, but there is some nuance.</p> <p>Not all educational discounts bother me—primarily it's the discounts limited to students at degree-granting institutions and especially those tied to having a .edu email address.</p> <h2 id="why-might-edu-discounts-be-good"><a href="#why-might-edu-discounts-be-good">#</a> Why might .edu discounts be good?</h2> <p>Many of the arguments for student discounts are similar to those for region-based discounts, which I am a fan of. So let's look at some reasons to give discounts in general.</p> <h3 id="need"><a href="#need">#</a> Need</h3> <p>The idea behind student discounts, at least as it was first explained to me, sounds great. Students are often broke so it's only fair to give them a price break!</p> <p>I totally get that. As a student myself, I worked as a waiter, a calculus tutor, a bar tender and even started a house painting franchise in order not to get buried in debt. I went to a cheap state school, back when it was only about 70% of what it costs now, and I was <em>still</em> broke.</p> <p>I have a great deal of sympathy for anyone trying to pay their way through school in the US now. I have even more sympathy for anyone taking out debts they likely won't repay for many, many years.</p> <h3 id="price-discrimination"><a href="#price-discrimination">#</a> Price discrimination</h3> <p>In economics, <a href="https://www.economicshelp.org/microessays/pd/price-discrimination/" target="_blank" rel="noopener noreferrer">price discrimination</a> refers to the idea of charging some customers more than others in order to maximize revenue.</p> <p>In the extreme form, it would mean charging each customer the absolute maximum price they're willing to pay and completely eliminating <a href="https://www.economicshelp.org/blog/188/concepts/definition-of-consumer-surplus/" target="_blank" rel="noopener noreferrer">consumer surplus</a>. This isn't practical or possible in most cases, but less extreme forms are very common.</p> <p>Sometimes customers are segmented by their actions, such as spending time clipping coupons or watching movies during typical work hours. Other times, customers are segmented simply by who they are. Senior discounts or higher prices for foreign tourists are both common examples.</p> <p>A less direct form of price discrimination is to create a slightly different product that would only appeal to customers with more money. In software, we see this often with features revolving around team management, accounting and compliance. This makes it possible to both sell to frugal hobbyist users and to charge large companies very high prices.</p> <h3 id="creating-habits"><a href="#creating-habits">#</a> Creating habits</h3> <p>For most, going to college is a time of major life transitions. Other than marriage, having children or serving in the military there are few times when people change as much.</p> <p>This is <strong>incredibly</strong> appealing to marketers.</p> <p>The opportunity to reach people when they're at a place where they're open to creating so many new habits that will stick with them for years or even decades is worth spending heavily on. One way to do it is through advertising. Another is by giving students a steep discount.</p> <h2 id="the-problem"><a href="#the-problem">#</a> The problem</h2> <p>In a number of ways that matter to me, educational discounts <em>as they are typically implemented</em> are radically different from region or need-based discounts.</p> <h3 id="who-has-a-edu-email-address"><a href="#who-has-a-edu-email-address">#</a> Who has a .edu email address?</h3> <p>Who has a .edu email address? Generally it's only students, faculty and alumni of accredited US colleges. This roughly translates to "many of the most priviledged people in the world".</p> <p>The vast majority of adults in the US <a href="https://data.census.gov/cedsci/table?q=ACSST1Y2018.S1501&amp;g=0100000US&amp;tid=ACSST1Y2018.S1501&amp;hidePreview=true" target="_blank" rel="noopener noreferrer">do not have a 4-year degree</a>. There are probably a billion people in the world who would <em>love</em> to either enter a US college themselves or get their children into one.</p> <p>Competition for those slots is fierce. People spend small fortunes on English language education for a shot. I've seen it first-hand living in Asia for most my adult life.</p> <p>Obviously, not <em>everyone</em> with a .edu email address is or will be wealthy. However in aggregate, their parents are wealthier and they will be wealthier than any country in the world... by a large margin. At a minimum, getting a 4-year degree costs tens of thousands of dollars. Saving a few dollars a month on my <a href="https://alchemist.camp/episodes" target="_blank" rel="noopener noreferrer">screencasts</a> is trivial in comparison.</p> <p>In contrast, the average person in Nigeria earns 2,000 USD/year. Even the average programmer isn't making much compared to their counterparts in other countries. Nigerians are also a double digit percentage of my audience! Indians are a large percentage as well.</p> <p>I have a <em>completely</em> different reaction when someone living in poor country asks for a discount than I do when someone spending more per year on tuition than I earned until my late 20s does.</p> <h3 id="who-is-a-student"><a href="#who-is-a-student">#</a> Who is a student?</h3> <p>An even more salient question is, who counts as a student. I've spent a great deal of time as a non-credentialed student at language schools, at a programming school and even completely on my own with a self-designed curriculum.</p> <p>During those times, I wasn't very successful in asking for educational discounts since nearly all are tied to credential-offering schools. I often thought about why and settled on two answers.</p> <ol><li>They probably worry about non-students claiming to be students to get the discount.</li> <li>Their educational discounts weren't really motivated by any sense of altruism or fairness to begin with.</li></ol> <h3 id="hypocrisy"><a href="#hypocrisy">#</a> Hypocrisy</h3> <p>Perhaps the thing that <em>most</em> bothers me about student discounts I see announced is the virtue signalling.</p> <p>If you're offering a discount to get your customers hooked early in their careers or to raise prices for business users, great. But you're not doing a noble thing if you're restricting a discount to people with .edu addresses.</p> <p>What that discount model actually does is exclude all of the students in poorer parts of the world as well as anyone who couldn't stomach going $100k in debt for a credential.</p> <h3 id="what-does-the-discount-subsidize"><a href="#what-does-the-discount-subsidize">#</a> What does the discount subsidize?</h3> <p>As economists love to point out, incentives matter. When you subsidize something, you get more of it. This isn't just true of governments, but it's also true of companies and other groups.</p> <p>That leads ato the question of what educational discounts subsidize. In effect, they subsidize going to very expensive universities. Is this something we want more of?</p> <p>In what's likely a minority opinion, I think too many people pursue formalized schooling for too long. Universities are necessary for some kinds of careers and for some kinds of research. Far more often, the price is just too high. The worst part of this cost isn't dollars either—it's four years of a person's life.</p> <p>Nearly anything universities teach can be learned outside of a university, and usually faster. I've experienced this first hand with mathematics, foreign languages and programming but it's certainly a wider phenomena.</p> <p>According to George Mason economist Bryan Caplan, <a href="https://amzn.to/2YLbmNG" target="_blank" rel="noopener noreferrer">only about 10%-20% of the value in schooling is actually education</a>. The other 80%-90% is selection and signalling.</p> <h2 id="what-products-are-exceptions"><a href="#what-products-are-exceptions">#</a> What products are exceptions?</h2> <p>If I were selling very expensive tools for skilled professionals, like Adobe used to, then I'd offer student discounts. Even a person in relatively fortunate circumstances has fewer resources than a typical company.</p> <p>Dropping a few dollars a month doesn't move the needle compared to tuition, but spending thousands of dollars on a photo or video editor sure could.</p> <p>Another factor in Adobe's case was that by being <em>the</em> tool to use in the industry, students needed to learn it. Anyone trying to become a designer pretty much had to find a way, even if that meant "pirating" it. Giving students convenient affordable access to such a tool is also a great way to <em>become</em> a standard tool in the industry.</p> <p>Even Adobe didn't limit their discounts to US students, though. Doing so might have cost them billions.</p> <h2 id="the-bottom-line"><a href="#the-bottom-line">#</a> The bottom line</h2> <p>Having a .edu email address generally means being in the most expensive and desired university system in the world.</p> <br>  <br> <hr></div></div>]]>
            </description>
            <link>https://questinglog.com/why-I-dont-give-edu-discounts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24322268</guid>
            <pubDate>Sun, 30 Aug 2020 09:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Horcrux Encrypted Messaging]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24322069">thread link</a>) | @ljlolel
<br/>
August 30, 2020 | https://www.notion.so/Horcrux-Encrypted-Messaging-78af0a3f326244ebb0aedff7c298953d | <a href="https://web.archive.org/web/*/https://www.notion.so/Horcrux-Encrypted-Messaging-78af0a3f326244ebb0aedff7c298953d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Horcrux-Encrypted-Messaging-78af0a3f326244ebb0aedff7c298953d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24322069</guid>
            <pubDate>Sun, 30 Aug 2020 08:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rise and fall of the industrial R&D lab]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24321799">thread link</a>) | @npalli
<br/>
August 29, 2020 | https://worksinprogress.co/issue/the-rise-and-fall-of-the-american-rd-lab/ | <a href="https://web.archive.org/web/*/https://worksinprogress.co/issue/the-rise-and-fall-of-the-american-rd-lab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p><span>Once, small firms centred on inventors were responsible for most of our innovation. Larger firms might buy or exploit these steps forwards, but they did not typically make them. And then for a brief period, this changed: many of the best new products, tools, and ideas came from research labs within large corporations. This brief period also happened to be the era when scientific, technological, and economic productivity sped forward at its fastest ever clip. Yet almost as soon as it arrived, the fruitful period was over and we returned to a situation where small companies and small-business-like teams at universities developed innovations outside of large companies and sold them in a market for ideas. Though we might enjoy the innovation created by small flexible firms, we should not dismiss the contributions made by large corporate labs. The corporate lab may be creeping back, but aggressively prosecuting antitrust against large firms growing organically through in-house research could easily snuff this spark out.</span></p>
<h3>The USA’s first system of innovation</h3>
<p><span>When the USA began to contribute to the progress of technology, in the early 19th century, it was largely practically-minded, not based on deep scientific understanding. Rather, it largely consisted of individual inventors commercialising their own inventions. Whereas nuclear power depended on decades or centuries of progress in physics, many late 19th century innovations were more like the cotton gin, which came together through practical-minded trial and error in the field. By the late 19th century, the system had morphed into one we would find strangely familiar today: inventors invented, venture capitalists invested, and companies commercialised. The system even had </span><a href="https://www.cambridge.org/core/journals/business-history-review/article/patent-alchemy-the-market-for-technology-in-us-history/90991329A8D4A49EBF7B49D2EAD1CE7A"><span>patent lawyers</span></a><span> and </span><a href="https://www.hoover.org/sites/default/files/khan_ip2_working_paper.pdf"><span>non-practising entities</span></a>, <span>which own patents purely </span><a href="https://www.hbs.edu/businesshistory/Documents/BHR870102.pdf"><span>to litigate on their behalf</span></a><span>. There were still startups commercialising an idea and scaling it up themselves, but many inventors found that the division of labour enabled by the market ideas allowed them to </span><a href="https://www.cambridge.org/core/journals/business-history-review/article/patent-alchemy-the-market-for-technology-in-us-history/90991329A8D4A49EBF7B49D2EAD1CE7A"><span>focus on what they did best</span></a><span>.</span></p>
<p><span>Large firms were consumers of ideas created by inventors, and were sceptical of the value of doing in-house science. They believed it was easier to buy new science off the shelf. In 1885 T. D. Lockwood, head of American Bell Telephone Company’s patent department, said:&nbsp;</span></p>
<blockquote><p><span>“I am fully convinced that it has never, is not now, and never will pay commercially, to keep an establishment of professional inventors, or of men whose chief business it is to invent”</span></p></blockquote>
<p><span>Of course, Bell Labs itself later grew to be one of the marquees of commercial labs—in the late 1960s it employed 15,000 people including 1,200 PhDs, who between them made too many important inventions to list, from the transistor and the photovoltaic cell to the first digitally scrambled voice audio (in 1943) and the first complex number calculator (in 1939). Fourteen of its staff went on to win Nobel Prizes and five to win </span><a href="https://en.wikipedia.org/wiki/Turing_Award"><span>Turing Awards</span></a><span>. </span></p>
<p><span>The 1920s stock market boom was in large part driven by a huge rise in the value that investors </span><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.98.4.1370"><span>accorded to intangible capital</span></a><span> and ideas held within companies. A similar thing happened in the </span><a href="https://www.amazon.co.uk/Capitalism-Without-Capital-Intangible-Economy/dp/0691175039"><span>1990s Dot-com Bubble</span></a><span>. Between 1921 and 1927 the number of scientists and engineers in industrial labs more than doubled. When the stock market crashed and the Great Depression hit it caused a </span><a href="https://pdfs.semanticscholar.org/d71a/90cfa2d0d0d72f13724d27dd326209431974.pdf"><span>massive and persistent decline</span></a><span> in independent inventing and the startup-like activity around it. But large labs continued to boom, increasing staffing and research spending throughout the lean 1930s, and earning more patents. By 1930, most patents were issued to large firms, rather than independent innovators, and this gap only widened into the 1950s. The industrial lab had become king.</span></p>
<h3>Why labs work well</h3>
<p><span>The question of why the industrial lab works is a microcosm of the question of why the firm works in general. Economist Ronald Coase, who won the Nobel Prize in 1991 (and who lived to be 102) bookended the most productive period of his career with two insights about transaction costs. The first, published in 1937 and entitled </span><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1468-0335.1937.tb00002.x"><span>“The Nature of the Firm”</span></a><span>, tells us why firms exist. In economics, situations are typically approached from the perspective of competitive behaviour in open markets. Most of the things we buy are from open, competitive markets like these. But when we sell our labour, we are usually bound to a single “buyer”—our employer—for an extended period of time for everything we have to offer. If market competition is so efficient, why do we not set up mini-firms for every instance of cooperative work and receive pay in line with our output? Why do we instead generally sell a promise to do whatever our boss says within limits for certain hours of the day for months or years in advance?</span></p>
<p><span>The other, </span><a href="https://www.law.uchicago.edu/files/file/coase-problem.pdf"><span>“The Problem of Social Cost”</span></a><span>, reads like a reflection of the first. Published in 1960, it spawned the so-called Coase Theorem, which holds that so long as transaction costs—the costs of interacting with other individuals or institutions, such as the costs of drawing up and enforcing a contract—are low, people will contract to deal with the problems emerging from positive and negative externalities, like the benefits of a new park to a neighbourhood or the costs of pollution. Where transaction costs are too high, institutions and policies are needed to deal with the externalities instead.</span></p>
<p><span>Coase answers the question of why businesses exist as he answers the question of why people simply don’t contract away all externalities: transaction costs. If there is a cost on both sides every time one person wants to pay another for a task, then some tasks will not be worth paying for, or worth doing at the going rate. Concretely: an employer who does not negotiate contracts for each and every individual work unit can afford to offer higher wages, and an employee who does not do so can afford to accept lower wages. Companies organized in this way thus outcompete pure market organization—in cases where transaction costs are large.</span></p>
<p><span>In many ways, this general story for why firms exist also explains why large firm R&amp;D labs were so successful. The transaction costs of collaboration are extremely large, and prevent all sorts of potentially-valuable crossovers: not just the financial costs of contracting with others, but the costs of finding people you work well with, of corresponding and collaborating with people far from you, and so on. University lecturers collaborate more with those in their department than in other departments, and more with those in their university or city than elsewhere, despite all the tools and technologies the internet has brought. Chance meetings are another driver of serendipitous discovery and unexpected but fruitful collaborations.&nbsp;</span></p>
<p><span>What’s more, without great efforts in ‘translation’, many scientific ideas can be completely disconnected from practical applications. A research lab brings an array of scientific experts together from different disciplines, for collaboration and drawing on expertise at low cost. Fellow researchers bump into one another. And the firm context means the potential impact in terms of usable products is always taken into account.</span></p>
<h3>The DARPA Era</h3>
<p><span>The era of the R&amp;D lab has one particularly legendary story and paradigmatic example: PARC. Xerox’s Palo Alto Research Centre—the location in Palo Alto, now the home of companies like Tesla, Palantir, and Google, is no coincidence—developed many of the foundational building blocks of today’s technology and economy. In the 1970s, PARC researchers built the first computer with a graphical user interface, the first laser printer, the first Ethernet cable, and the first user-friendly word processor. Steve Jobs visited PARC in 1979, aged 24, and incorporated many of the ideas into Apple products. Charles Simonyi, a key developer at PARC, moved to Microsoft, where he developed the Office suite. But Xerox itself, which is still largely known for making photocopiers, did not capitalise on these inventions.</span></p>
<p><span>PARC, in turn, had hired many of its workers from Augmentation Research Centre, a publicly-funded project which pioneered the computer mouse, hyperlinks, the earliest predecessor to the internet, and many smaller innovations we take for granted in today’s computer ecosystem. ARC was funded by ARPA, the Advanced Research Projects Agency, now DARPA. Though DARPA (then ARPA) is funded by the US Department of Defence, it shares many elements with golden era R&amp;D labs. They are organised around a mission and a goal—even the most basic research is done with an end in mind—but researchers are given a lot of freedom to make their own decisions.</span></p>
<h3>A return to the market for ideas</h3>
<p><span>The scale of the change since the 1970s is huge—big businesses have retreated from research. In the 1960s, DuPont, the chemicals giant, published more in the </span><i><span>Journals of the American Chemical Society</span></i><span> than both MIT and Caltech combined. R&amp;D magazine, which awards the R&amp;D 100 to the hundred innovations it judges most innovative in a given four year period, gave 41% of its awards to Fortune 500 companies in its 1971 iteration and 47% in 1975. By 2006, 6% of the awards were going to firms in the Fortune 500. The great majority of these awards are now being won by federal labs, university teams, and spin-offs from academia. The lone inventor is back.</span></p>
<p><span>This is reflected by declines in the shares of patents going to the biggest businesses, and in the shares of scientists working there. In 1971 just over seven per cent of scientists in industry tracked by the US National Science Foundation worked in firms with under 1,000 employees; by 2004 this was 32%. In 2003 around a quarter worked at firms with fewer than ten employees. Even pharmaceuticals, the one area where large internal research labs are still significant, has been affected—around half of the drugs approved so far in the 2010s were originally discovered by small biotech startups.</span></p>
<p><span>In general, participation by large American firms in …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worksinprogress.co/issue/the-rise-and-fall-of-the-american-rd-lab/">https://worksinprogress.co/issue/the-rise-and-fall-of-the-american-rd-lab/</a></em></p>]]>
            </description>
            <link>https://worksinprogress.co/issue/the-rise-and-fall-of-the-american-rd-lab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24321799</guid>
            <pubDate>Sun, 30 Aug 2020 06:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MicroCOVID Project, Micromorts but for Covid]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24321530">thread link</a>) | @owenshen24
<br/>
August 29, 2020 | https://www.microcovid.org/calculator | <a href="https://web.archive.org/web/*/https://www.microcovid.org/calculator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.microcovid.org/calculator</link>
            <guid isPermaLink="false">hacker-news-small-sites-24321530</guid>
            <pubDate>Sun, 30 Aug 2020 05:18:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring mullender.c – A deep dive into the first IOCCC winner]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24321403">thread link</a>) | @todsacerdoti
<br/>
August 29, 2020 | https://lainsystems.com/posts/exploring-mullender-dot-c/ | <a href="https://web.archive.org/web/*/https://lainsystems.com/posts/exploring-mullender-dot-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <ul>
<li>Table of Contents
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#mullenderc">Mullender.c</a></li>
<li><a href="#running-the-thing-on-a-pdp-11">Running the thing on a PDP-11</a></li>
<li><a href="#examining-the-pdp-11-code">Examining the PDP-11 code</a></li>
<li><a href="#the-meat-of-the-code">The meat of the code</a></li>
<li><a href="#where-is-the-string">Where is the string?</a></li>
<li><a href="#looking-at-the-vax-code">Looking at the VAX code</a></li>
<li><a href="#how-the-program-happened-in-sjoerds-own-words">How the program happened in Sjoerd’s own words</a></li>
<li><a href="#the-original-source">The Original Source</a></li>
<li><a href="#extra-bits">Extra bits</a></li>
<li><a href="#documents-and-websites-i-used">Documents and Websites I used</a></li>
</ul>
</li>
</ul>

<p>A few years ago I wrote <a href="https://medium.com/@LainIwakura/deobfuscating-obfuscated-code-for-fun-and-no-profit-36ec615c8f5d">two</a> <a href="https://medium.com/@LainIwakura/deobfuscating-code-for-fun-and-no-profit-round-2-60d78b67ebce">posts</a>
on medium.com explaining the workings of some obfuscated programs. After these posts other stuff took priority and I forgot about the world of obfuscation for a while. Now though, I find myself returning to it.
For reasons I’ll explain in a different post I find studying obfuscated code to be quite valuable. So, I thought to myself ‘Well, those last programs I examined were honestly pretty simple. What would it be like to research a truly obfuscated program?’</p>
<p>This post is the story of that journey. I will discuss the code, how I got such old and obscure code to run, as well as include snippets from my conversations with
one of the original authors (who was very helpful in figuring some of this out). If all that wasn’t enough I managed to obtain the original PDP and VAX source code, it will be hosted here with permission. I want to give a huge thank you to Sjoerd Mullender and Don Libes for their assistance and permission in reproducing some of this material.</p>

<p>Because older obfuscated programs tend to be easier to dissect I decided to stay in the early years of the IOCCC (International Obfuscated C Code Contest).
Among those early programs one sticks out as truly interesting - and that is the first IOCCC winner <a href="https://www.ioccc.org/1984/mullender/mullender.c">mullender.c</a>, which I’ve also replicated below because it’s quite short.



  </p><div>
    <p>
    <label for="187453296">
      <span>c</span>
      <span>mullender.c</span>
      <span data-label-expand="△" data-label-collapse="▽"></span>
    </label></p><pre><code>
  short main[] = {
	  277, 04735, -4129, 25, 0, 477, 1019, 0xbef, 0, 12800,
	  -113, 21119, 0x52d7, -1006, -7151, 0, 0x4bc, 020004,
	  14880, 10541, 2056, 04010, 4548, 3044, -6716, 0x9,
	  4407, 6, 5568, 1, -30460, 0, 0x9, 5570, 512, -30419,
	  0x7e82, 0760, 6, 0, 4, 02400, 15, 0, 4, 1280, 4, 0,
	  4, 0, 0, 0, 0x8, 0, 4, 0, ',', 0, 12, 0, 4, 0, '#',
	  0, 020, 0, 4, 0, 30, 0, 026, 0, 0x6176, 120, 25712,
	  'p', 072163, 'r', 29303, 29801, 'e'
  };
</code></pre>
  </div>


<p>Where do you start with a program like this? Well, the <a href="https://www.ioccc.org/1984/mullender/hint.text">hint</a> provided by the IOCCC is always a good first step.
From this hint, we can learn a few things necessary to understanding how the program works:</p>
<ul>
<li>Perhaps most importantly, this program will only run on a PDP-11 or VAX-11.</li>
<li>The C startup routine - provided by crt0.o - transfers control to a location named ‘main’ - usually intended to be a function, but in this case it’s an array of shorts</li>
<li>These shorts (represented in different formats to enhance obfuscation) form a meaningful set of PDP-11 and VAX-11 instructions</li>
<li>The first instruction is a branch to the PDP code, and due to the way VAX calls the main ‘function’ it skips the first word of the program (I’ll discuss this more later).</li>
<li>The program prints a string</li>
</ul>
<p>Essentially, the program is a bunch of machine code instructions encoded in various formats. It runs because this code predates ANSI C by a half decade and old compilers seem to have had significantly less qualms about
‘main’ being a function or not (I tried to define ‘main’ as an array of shorts with a modern compiler and it did not like that one bit).</p>

<p>I admit it, the PDP-11 was before my time. I grew up in the Windows 95/98/2000 era, and until recently I didn’t even know what a PDP-11 was.
This ignorance left me kind of stuck, and a brief look on eBay confirmed that I was not going to get a working PDP-11 any time soon. Fortunately though,
an emulator exists. Enter <a href="http://simh.trailing-edge.com/">SimH</a>, it’s more of a suite of emulators for a wide range of historical computers - of which the
PDP-11 is one, and lucky for us the VAX-11 is another.</p>
<p>After a few false starts and misadventures with 2.11BSD, I realized I had no idea what I was doing so I decided I needed some help.
The two original authors of this program are Robbert van Renesse and Sjoerd Mullender, why not try to contact them? So I did.
Robbert didn’t answer my e-mail, but luckily Sjoerd got back to me and was happy to discuss the program. He told me that the
PDP-11 OS they used was Unix v7, so I proceeded on that route.</p>
<p>I managed to <a href="http://a.papnet.eu/UNIX/v7/Installation">find a guide</a> on installing Unix v7 onto this emulator that worked;
and now with my emulator running, and OS installed, I could slap it into a file, compile, and run the thing. Below is what I got.</p>

<figure>
	<img src="https://lainsystems.com/img/running_on_pdp11.gif">
	
		<figcaption>Running the program on the PDP-11 using Unix v7</figcaption>
	
</figure>


<p>The animation is a little choppy, but even still you can hopefully see that it is printing “:-)” across the screen until it is forced to exit (there is no clean way to stop it).</p>
<p>In my discussions with Sjoerd, it was revealed that the string it prints is not exactly “:-)” but instead "  :-)\b\b\b\b”
(NOTE: there should be 2 space characters at the start but my templating engine is removing one for some reason).
It is exactly 9 bytes long. The first 2 characters are whitespace, followed by the :-), finally followed by four ‘\b’
characters. The ‘\b’ characters indicate a backspace. What does the backspace accomplish? Well, if you count 4 characters back from when they begin you’ll see we’re left with a single space - it is at this point
that the program loops and prints the string again. This happens quickly enough that to our eyes it looks like the “:-)” is scrolling across the screen - a clever effect.</p>

<p>As it turns out, the C code is not very useful to examine directly. As it also turns out, the assembly isn’t much better. Below is a small sample of what the assembly looks like (from the PDP-11’s perspective):</p>
<pre><code>    .text
    .globl  _main
    .data
    .even
_main:
    .word   0425 
    .word   04735
    .word   -010041
    .word   031
    .word   0
    .word   0735
    .word   01773
    .word   05757
</code></pre><p>So, what to do? Well, you can actually set up a cross compiler for the PDP-11 and if you go through that effort you can use the objdump program targeted at PDP-11 binaries.</p>
<p>Below is the relevant portion of the objdump - the whole thing is <a href="https://lainsystems.com/mull_objdump.txt">here</a>, but not all of it is useful. Sjoerd confirmed that the PDP code is
from _main+0x2c to _main+0x4a (inclusive). Of course, the first word is also a PDP-11 instruction. Everything I’ve ommitted is related to the VAX portion of
the program which we will get back to. (It’s also not proper VAX code since the disassembler thinks everything is PDP-11).</p>
<pre><code>   0:   0115            br  0x2c
  2c:   11c4            mov pc, r4
  2e:   0be4            tst -(r4)
  30:   e5c4 0009       sub $11, r4
  34:   1137 0006       mov r4, $0x3e
  38:   15c0 0001       mov $1, r0
  3c:   8904            sys 4
  3e:   0000            halt
  40:   0009            .word   11
  42:   15c2 0200       mov $1000, r2
  46:   892d            sys 55
  48:   7e82            sob r2, 0x46
  4a:   01f0            br  0x2c
</code></pre><p>Before going further there are 2 important things to know about PDP-11 assembly code:</p>
<ul>
<li>The PDP-11 works primarily with octal. All the addresses and instructions are encoded in octal.</li>
<li>In an instruction like <code>mov pc, r4</code>, you are moving pc INTO r4, not r4 into pc. Personally, I got used to this pretty quickly.</li>
</ul>
<p>The first number in the original program is 277, put that into a hex converter and you’ll get 115 like we see in the objdump. More interesting though is what you get translating it into octal - 425.
How does 0425 get you br 0x2c though? Well for that you need to grab some <em>manuals</em>. I got my hands on a lot of old manuals for these computers but the most useful one was the PDP-11/45 Handbook from 1973.
It would helpfully describe the instruction format, and exactly what it did. Below is an example of the page for the unconditional branch instruction.</p>

<figure>
	<img src="https://lainsystems.com/img/pdp11-branch.png">
	
		<figcaption>PDP-11/45 Handbook Describing the Branch instruction</figcaption>
	
</figure>


<p>As you can see, it sets the program counter to pc + 2x the offset - which is 25 (octal) in our case. Since the program counter at the start of our program is 2 (because it points to the next word to execute),
we get 2 + (25 x 2), or 2 + 52 = 54, which translating back into hex gives us 2c. Cool!</p>

<p>Now that we know how the branch works we can examine the main stuff - I won’t go into huge depth with the manuals for each little instruction but doing so is fun if you’re bored and enjoy that sort of thing.</p>
<p>The next relevant portion of code is this:</p>
<pre><code>  mov pc, r4
  tst -(r4)
  sub $11, r4
  mov r4, $0x3e
  mov $1, r0
  sys 4
  halt
  .word   11
</code></pre><p>We move the program counter into the r4 register and then use the ‘test’ (tst) instruction. This has the effect of clearing the some flags in the PSW (processor status word), and because
the register is using ‘Autodecrement mode’ it will subtract 2 from the value stored at r4. When using autoincrement / decrement, it will go by 1 in byte instructions or 2 in word instructions.
After this we subtract 11 from r4, but 11 is actually 9 (used to octal yet?). Then we store r4 into…0x3e? Well, if you look back at the objdump you’ll see that 0x3e is ‘halt’ or 0000. This
mov instruction overwrites that value with the contents of r4. We move 1 into r0 (1 indicating STDOUT), and call ‘sys 4’. The next line will be the value of r4 as just mentioned, and <code>.word 11</code>
simply inserts octal 11 directly into that spot. If you’re wondering what exactly is in r4 and why we’re doing all this stuff, be patient - we’re getting there.</p>
<p>If you’re familiar with system calls, you probably know what’s going on. If not, all of this is to setup the <a href="https://en.wikipedia.org/wiki/Write_(system_call)">write</a> system call. I
actually made a <a href="https://retrocomputing.stackexchange.com/questions/15590/trying-to-understand-some-assembly-syntax-in-the-unix-v7-write-system-call">post on the retro-computing stackexchange</a>
asking about the workings of this call internally - I recommend checking it out if you want further clarity on how this works.</p>
<p>After this we have the final 3 lines of PDP code which are:</p>
<pre><code>  mov $1000, r2
  sys 55
  sob r2, 0x46
</code></pre><p>We put 1000 into r2, and call system call 55. After this, we use the ‘sob’ instruction - which is ‘subtract one and branch’ and not an invitation to cry - to see if r2 is 0 yet. If it isn’t, we branch
to the previous line and call system call 55 again. loop until r2 is 0. Syscall 55 eh? Which …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lainsystems.com/posts/exploring-mullender-dot-c/">https://lainsystems.com/posts/exploring-mullender-dot-c/</a></em></p>]]>
            </description>
            <link>https://lainsystems.com/posts/exploring-mullender-dot-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24321403</guid>
            <pubDate>Sun, 30 Aug 2020 04:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Longevity FAQ: A beginner's guide to longevity research]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 90 (<a href="https://news.ycombinator.com/item?id=24320846">thread link</a>) | @apsec112
<br/>
August 29, 2020 | https://www.ldeming.com/longevityfaq | <a href="https://web.archive.org/web/*/https://www.ldeming.com/longevityfaq">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<tr>
					<td data-title="Intervention">Senescent cell removal</td>
					<td data-title="Median lifespan increase (treated/control)">135%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Does not affect rotarod performance, object discrimination. Slight delay in wound closure.</td>
					<td data-title="Reference">1</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Rapamycin</td>
					<td data-title="Median lifespan increase (treated/control)">110%</td>
					<td data-title="Year Published">2009</td>
					<td data-title="Notes">Late-life rapamyicn treatment extends lifespan (pooled females from multiple-site NIA study)</td>
					<td data-title="Reference">2</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">NR</td>
					<td data-title="Median lifespan increase (treated/control)">105%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Claim an increase in running distance</td>
					<td data-title="Reference">3</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Catalase</td>
					<td data-title="Median lifespan increase (treated/control)">117%</td>
					<td data-title="Year Published">2005</td>
					<td data-title="Notes">Mitochondrially-targeted catalase expression extended mouse lifespan compared to control</td>
					<td data-title="Reference">4</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Sirt6 overexpression</td>
					<td data-title="Median lifespan increase (treated/control)">115%</td>
					<td data-title="Year Published">2012</td>
					<td data-title="Notes">Sirt6-overexpression increases male mouse lifespan</td>
					<td data-title="Reference">5</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Metformin</td>
					<td data-title="Median lifespan increase (treated/control)">106%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">In males, small but significant lifespan extension after metformin application</td>
					<td data-title="Reference">6</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">DN-IκBα</td>
					<td data-title="Median lifespan increase (treated/control)">110%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">Dominant negative to downregulate IKK-beta activity, delivered to hypothalamus of middle-aged mice</td>
					<td data-title="Reference">7</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Klotho</td>
					<td data-title="Median lifespan increase (treated/control)">120%</td>
					<td data-title="Year Published">2005</td>
					<td data-title="Notes">Overexpression under human elongation factor 1α promoter increases lifespan, slight fertility loss</td>
					<td data-title="Reference">8</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">S6K1</td>
					<td data-title="Median lifespan increase (treated/control)">118%</td>
					<td data-title="Year Published">2009</td>
					<td data-title="Notes">KO of S6K1 extends lifspan compared to wildtype mice</td>
					<td data-title="Reference">9</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">p66</td>
					<td data-title="Median lifespan increase (treated/control)">128%</td>
					<td data-title="Year Published">1999</td>
					<td data-title="Notes">Mutation of a p66shc, member of proto-oncogene locus SHC, extends lifespan. May be just due to cancer effect.</td>
					<td data-title="Reference">10</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Lowering protein:carbohydrate ratio</td>
					<td data-title="Median lifespan increase (treated/control)">128%</td>
					<td data-title="Year Published">2014</td>
					<td data-title="Notes">Varied protein, carbohydrate, and total energy levels.</td>
					<td data-title="Reference">11</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Fat-specific insulin receptor knockout mice</td>
					<td data-title="Median lifespan increase (treated/control)">111%</td>
					<td data-title="Year Published">2003</td>
					<td data-title="Notes">Fat-specific insulin receptor knockout mice show a significant increase in lifespan</td>
					<td data-title="Reference">12</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">C57BL/6 mice with NZB/OlaHsd mitochondrial mutations</td>
					<td data-title="Median lifespan increase (treated/control)">120%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Same nuclear, different mitochondrial DNA.</td>
					<td data-title="Reference">13</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Fasting mimicking diet</td>
					<td data-title="Median lifespan increase (treated/control)">112%</td>
					<td data-title="Year Published">2015</td>
					<td data-title="Notes">FMD followed by 10 days of normal, then repeat</td>
					<td data-title="Reference">14</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Rapamycin</td>
					<td data-title="Median lifespan increase (treated/control)">127%</td>
					<td data-title="Year Published">2014</td>
					<td data-title="Notes">Rapamycin from 9 months of age, weight decreased ~30% at highest dose</td>
					<td data-title="Reference">15</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Brain-specific Sirt1 expression</td>
					<td data-title="Median lifespan increase (treated/control)">116%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">Brain-specific Sirt1 expression in female mice increases lifespan over wildtype</td>
					<td data-title="Reference">16</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">SRT1720</td>
					<td data-title="Median lifespan increase (treated/control)">104%</td>
					<td data-title="Year Published">2014</td>
					<td data-title="Notes">Start diet at 28 weeks of age, very small increase on lifespan</td>
					<td data-title="Reference">17</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Spermidine</td>
					<td data-title="Median lifespan increase (treated/control)">111%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Polyamine, administered in drinking water</td>
					<td data-title="Reference">18</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Atg5 overexpression</td>
					<td data-title="Median lifespan increase (treated/control)">117%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">Transgenic mice ubiquitously expressing Atg5 (crucial for autophagasome confirmation) live longer.</td>
					<td data-title="Reference">19</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Telomerase</td>
					<td data-title="Median lifespan increase (treated/control)">124%</td>
					<td data-title="Year Published">2012</td>
					<td data-title="Notes">Paper showing telomerase therapy increasing life</td>
					<td data-title="Reference">20</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Insulin receptor substrate null</td>
					<td data-title="Median lifespan increase (treated/control)">132%</td>
					<td data-title="Year Published">2008</td>
					<td data-title="Notes">Insulin receptor substrate 1 null mouse lifespan extension in females</td>
					<td data-title="Reference">21</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Snell Dwarf Mice</td>
					<td data-title="Median lifespan increase (treated/control)">142%</td>
					<td data-title="Year Published">2001</td>
					<td data-title="Notes">Snell dwarf mouse paper showing life extension</td>
					<td data-title="Reference">22</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Ames Dwarf Mice</td>
					<td data-title="Median lifespan increase (treated/control)">168%</td>
					<td data-title="Year Published">1996</td>
					<td data-title="Notes">Original Ames dwarf mouse paper showing life extension</td>
					<td data-title="Reference">23</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">s-Arf/p53</td>
					<td data-title="Median lifespan increase (treated/control)">113%</td>
					<td data-title="Year Published">2007</td>
					<td data-title="Notes">An extra copy of p53 and upstream regulator Arf/p16Ink4a increases lifespan</td>
					<td data-title="Reference">24</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Slow growth during lactation</td>
					<td data-title="Median lifespan increase (treated/control)">106%</td>
					<td data-title="Year Published">2004</td>
					<td data-title="Notes">Male mice suckled by dams fed a low-protein diet lived longer than their control cohort</td>
					<td data-title="Reference">25</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Methionine restriction</td>
					<td data-title="Median lifespan increase (treated/control)">111%</td>
					<td data-title="Year Published">2005</td>
					<td data-title="Notes">Methionine restriction increases mouse lifespan, here median lifespan increase in mice that survived at least 1 yr.</td>
					<td data-title="Reference">26</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Rapamycin (3 months)</td>
					<td data-title="Median lifespan increase (treated/control)">114%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Lifespan given from time of treatment which was 23-24 mo, used 24 mo to get percentage so this is an estimate</td>
					<td data-title="Reference">27</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">GHR-BP</td>
					<td data-title="Median lifespan increase (treated/control)">138%</td>
					<td data-title="Year Published">2000</td>
					<td data-title="Notes">Mice deficient in growth hormone receptor / binding protein live longer (female mean, not median, lifespan shown here)</td>
					<td data-title="Reference">28</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">mTOR</td>
					<td data-title="Median lifespan increase (treated/control)">116%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">mTOR depletion extends lifespan</td>
					<td data-title="Reference">29</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">PTEN overexpression</td>
					<td data-title="Median lifespan increase (treated/control)">112%</td>
					<td data-title="Year Published">2012</td>
					<td data-title="Notes">Overexpression of PTEN, a tumor suppressor which counteracts PI3K, extends mouse lifespan</td>
					<td data-title="Reference">30</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Myc (+/-)</td>
					<td data-title="Median lifespan increase (treated/control)">121%</td>
					<td data-title="Year Published">2015</td>
					<td data-title="Notes">Claim no correlation between weight and lifespan</td>
					<td data-title="Reference">31</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">FGF-21</td>
					<td data-title="Median lifespan increase (treated/control)">139%</td>
					<td data-title="Year Published">2012</td>
					<td data-title="Notes">Hepatic-specific expression of FGF-21 (which suppresses growth hormone and reduces the production of IGF) increases lifespan, female lifespan shown here</td>
					<td data-title="Reference">32</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">BubR1 overexpression</td>
					<td data-title="Median lifespan increase (treated/control)">114%</td>
					<td data-title="Year Published">2012</td>
					<td data-title="Notes">Kinase which localizes to kinetochore, overexpression increases lifespan</td>
					<td data-title="Reference">33</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">AC5 KO</td>
					<td data-title="Median lifespan increase (treated/control)">132%</td>
					<td data-title="Year Published">2007</td>
					<td data-title="Notes">AC5 knockount mice lived longer than control, potentially linked to effects on cAMP production and beta-adrenergic receptor signaling.</td>
					<td data-title="Reference">34</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">17-alpha-estradiol</td>
					<td data-title="Median lifespan increase (treated/control)">112%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">17-alpha-estradiol extended lifespan in males, but not females (as expected)</td>
					<td data-title="Reference">35</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Acarbose</td>
					<td data-title="Median lifespan increase (treated/control)">122%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">Acarbose extended male more than female lifespan</td>
					<td data-title="Reference">36</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">TRPV1 -/-</td>
					<td data-title="Median lifespan increase (treated/control)">114%</td>
					<td data-title="Year Published">2014</td>
					<td data-title="Notes">Resting exchange ratio similar at 16 mo to 3 mo</td>
					<td data-title="Reference">37</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">SRT2104</td>
					<td data-title="Median lifespan increase (treated/control)">106%</td>
					<td data-title="Year Published">2014</td>
					<td data-title="Notes">Start diet at 28 weeks of age, very small increase if there</td>
					<td data-title="Reference">38</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Hcrt-UCP2</td>
					<td data-title="Median lifespan increase (treated/control)">128%</td>
					<td data-title="Year Published">2006</td>
					<td data-title="Notes">UCP2 under hypocretin promoter lowers core body temp, increases lifespan</td>
					<td data-title="Reference">39</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">G6PD overexpression</td>
					<td data-title="Median lifespan increase (treated/control)">114%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Reduces NADP+</td>
					<td data-title="Reference">40</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">IGF-1 Receptor Brain KO (+/-)</td>
					<td data-title="Median lifespan increase (treated/control)">109%</td>
					<td data-title="Year Published">2008</td>
					<td data-title="Notes">Brain-specific IGF-1 Receptor +/- mice live longer than WT</td>
					<td data-title="Reference">41</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">SURF-1 KO</td>
					<td data-title="Median lifespan increase (treated/control)">121%</td>
					<td data-title="Year Published">2007</td>
					<td data-title="Notes">Mutations in SURF1, a cytochrome c oxidase assembly factor, extend lifespan. Mitochondrial.</td>
					<td data-title="Reference">42</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Litter enlargemnet (CR)</td>
					<td data-title="Median lifespan increase (treated/control)">118%</td>
					<td data-title="Year Published">2009</td>
					<td data-title="Notes">50% enlargement of litter in first 20 days, to induce caloric restriction</td>
					<td data-title="Reference">43</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">mclk-1 heterozygous</td>
					<td data-title="Median lifespan increase (treated/control)">115%</td>
					<td data-title="Year Published">2005</td>
					<td data-title="Notes">A heterozygous knockout of mclk1 (important in mitochondrial respiration) results in mouse lifespan extension compared to wildtype</td>
					<td data-title="Reference">44</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Nordihydroguairaitic acid</td>
					<td data-title="Median lifespan increase (treated/control)">112%</td>
					<td data-title="Year Published">2008</td>
					<td data-title="Notes">NDGA and aspirin extend lifespan by a little bit. Small molecule.</td>
					<td data-title="Reference">45</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Aspirin</td>
					<td data-title="Median lifespan increase (treated/control)">108%</td>
					<td data-title="Year Published">2008</td>
					<td data-title="Notes">NDGA and aspirin extend lifespan by a little bit. Small molecule.</td>
					<td data-title="Reference">46</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">SOD mimetic carboxyfullerene</td>
					<td data-title="Median lifespan increase (treated/control)">115%</td>
					<td data-title="Year Published">2008</td>
					<td data-title="Notes">Carboxyfullerene, described as an SOD mimetic, increased the lifespan of treated mice compared to wildtype control</td>
					<td data-title="Reference">47</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Removal of visceral fat tissue</td>
					<td data-title="Median lifespan increase (treated/control)">108%</td>
					<td data-title="Year Published">2008</td>
					<td data-title="Notes">Removal of visceral fat tissue increases lifespan over control</td>
					<td data-title="Reference">48</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Low glycotoxin diet</td>
					<td data-title="Median lifespan increase (treated/control)">112%</td>
					<td data-title="Year Published">2007</td>
					<td data-title="Notes">Low glycotoxin (low levels of AGE's) shown to extend lifespan</td>
					<td data-title="Reference">49</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Per2 (-/-)</td>
					<td data-title="Median lifespan increase (treated/control)">118%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Lifespan study incomplete</td>
					<td data-title="Reference">50</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Neonatal metformin</td>
					<td data-title="Median lifespan increase (treated/control)">120%</td>
					<td data-title="Year Published">2015</td>
					<td data-title="Notes">Animals recieved on 3, 5, 7th day after birth - bad for females, good for males.</td>
					<td data-title="Reference">51</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">GHRH KO</td>
					<td data-title="Median lifespan increase (treated/control)">146%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">GHRH (Growth-Hormone Releasing Hormone) disruption extends lifespan, presumably through the insulin/IGF pathway axis</td>
					<td data-title="Reference">52</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Sod-2 overexpresion</td>
					<td data-title="Median lifespan increase (treated/control)">104%</td>
					<td data-title="Year Published">2007</td>
					<td data-title="Notes">Overexpression of SOD-2 targeted to the mitochondrion increases mouse lifespan relative to wildtype</td>
					<td data-title="Reference">53</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Metallothionein cardiac-specific expression</td>
					<td data-title="Median lifespan increase (treated/control)">114%</td>
					<td data-title="Year Published">2006</td>
					<td data-title="Notes">Cardiac-specific expression of antioxidant metallothionein extended the lifespan of wildtype mice compared to WT FVB control.</td>
					<td data-title="Reference">54</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">IGF1R(+/-)</td>
					<td data-title="Median lifespan increase (treated/control)">121%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">Tyrosine kinase receptor activated by IGF1/2</td>
					<td data-title="Reference">55</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Ink4a/Arf/Ink4b</td>
					<td data-title="Median lifespan increase (treated/control)">116%</td>
					<td data-title="Year Published">2009</td>
					<td data-title="Notes">Encodes 2 CDKs (p16 and p15), and Arf (upstream of p53)</td>
					<td data-title="Reference">56</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Adult-onset Ghr (-/-)</td>
					<td data-title="Median lifespan increase (treated/control)">100%</td>
					<td data-title="Year Published">2016</td>
					<td data-title="Notes">Male mice have &gt;2x higher insulin than female mice</td>
					<td data-title="Reference">57</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Ovary Transplantation</td>
					<td data-title="Median lifespan increase (treated/control)">117%</td>
					<td data-title="Year Published">2003</td>
					<td data-title="Notes">Original paper showing that transplantation of young ovaries into old animals could result in lifespan increase</td>
					<td data-title="Reference">58</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">UCP-1 transgenic</td>
					<td data-title="Median lifespan increase (treated/control)">111%</td>
					<td data-title="Year Published">2007</td>
					<td data-title="Notes">Transgenic mice with skeletal muscle-specific UCP1 had increased longevity. Small increase if there.</td>
					<td data-title="Reference">59</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">PAPP</td>
					<td data-title="Median lifespan increase (treated/control)">131%</td>
					<td data-title="Year Published">2010</td>
					<td data-title="Notes">Knockout of PAPP-A (which enhances IGF-1 activity by degrading the inhibitory IGF-binding protein) increases lifespan over wildtype, female lifespan shown here</td>
					<td data-title="Reference">60</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">CR diet with lard</td>
					<td data-title="Median lifespan increase (treated/control)">132%</td>
					<td data-title="Year Published">2015</td>
					<td data-title="Notes">40% decrease starting at 4 months</td>
					<td data-title="Reference">61</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">loss of function of Riib (PKA subunit)</td>
					<td data-title="Median lifespan increase (treated/control)">114%</td>
					<td data-title="Year Published">2009</td>
					<td data-title="Notes">Knockout of RIIbeta, a subunit of PKA, increased lifespan in mice compared to wildtype</td>
					<td data-title="Reference">62</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Myostatin (+/-)</td>
					<td data-title="Median lifespan increase (treated/control)">109%</td>
					<td data-title="Year Published">2015</td>
					<td data-title="Notes">Knockout induces double-muscle mice</td>
					<td data-title="Reference">63</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Akt1 +/-</td>
					<td data-title="Median lifespan increase (treated/control)">113%</td>
					<td data-title="Year Published">2013</td>
					<td data-title="Notes">Haploinsufficiency of Akt1 increases mouse lifespan relative to wildtype. Insulin/IGF-1 pathway.</td>
					<td data-title="Reference">64</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">miR-17</td>
					<td data-title="Median lifespan increase (treated/control)">117%</td>
					<td data-title="Year Published">2014</td>
					<td data-title="Notes">Not clear if there is a main function for miR-17</td>
					<td data-title="Reference">65</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">NDGA</td>
					<td data-title="Median lifespan increase (treated/control)">111%</td>
					<td data-title="Year Published">2015</td>
					<td data-title="Notes">Makes up ~12.5% of the dry weight of leaves</td>
					<td data-title="Reference">66</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">FAT10ko</td>
					<td data-title="Median lifespan increase (treated/control)">119%</td>
					<td data-title="Year Published">2014</td>
					<td data-title="Notes">Ubiquitin-like protein which can signal for protein to go to proteasome.</td>
					<td data-title="Reference">67</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">Intranasal Hsp70</td>
					<td data-title="Median lifespan increase (treated/control)">116%</td>
					<td data-title="Year Published">2015</td>
					<td data-title="Notes">Seemed to extend lifespan when started at 17 months</td>
					<td data-title="Reference">68</td>
				</tr>
			

				<tr>
					<td data-title="Intervention">RasGRF1(-/-)</td>
					<td data-title="Median lifespan increase (treated/control)">120%</td>
					<td data-title="Year Published">2011</td>
					<td data-title="Notes">Ras-guanine nucleotide exchange factor …</td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ldeming.com/longevityfaq">https://www.ldeming.com/longevityfaq</a></em></p>]]>
            </description>
            <link>https://www.ldeming.com/longevityfaq</link>
            <guid isPermaLink="false">hacker-news-small-sites-24320846</guid>
            <pubDate>Sun, 30 Aug 2020 02:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Dive into PHP 8's JIT]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24320024">thread link</a>) | @nawarian
<br/>
August 29, 2020 | https://thephp.website/en/issue/php-8-jit/ | <a href="https://web.archive.org/web/*/https://thephp.website/en/issue/php-8-jit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div>
<p><time datetime="2020-03-03">
2020-03-03
</time></p>
<p><a href="https://thephp.website/br/edicao/php-8-jit">Leia em Português</a></p>
<p>PHP has a Just In Time compiler (JIT) since its most recent major version, PHP 8.</p>
<p>Here's a demo of JIT's impact on PHP. The video was recorded by Zeev, a core
developer of the php engine, to demonstrate the performance difference between
php 7.0 and JIT when generating fractals.</p>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/dWH65pmnsrI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><iframe style="margin: auto; margin-bottom: 20px;" width="560" height="315" src="https://www.youtube-nocookie.com/embed/dWH65pmnsrI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>It is fair to expect great performance improvements after watching this video,
especially if you remember the amazing boost when migrating from php 5 to 7.
But soon you'll notice that such gains aren't for most applications (unless
you do fractals for a living 🤷🏻‍♀️).</p>
<p>So before you get too hyped or too disappointed about JIT, let me explain what
this thing is and how you can get the most out of it.</p>
<h2>What is a Just In Time compiled language and why do we need it?</h2>
<p>Let me introduce you to compilation first, I believe we will need it.</p>
<p>CPUs can't read english, you already know that. They can kind of read a series
of bits and bytes which represent addresses, values, instructions... But guess
who can't code this? That's right, us! (At least I can't 👀 (I kind of can, but... no.))</p>
<p>A solution to this problem is to translate something we, humans, can write into
something CPUs can execute. This translation can be called "compilation". So
<strong>compilation is a translation of human-readable code to machine code.</strong>
Simple, oder?</p>
<p>Translating human-readable code to machine code can happen in three different
ways: Ahead Of Time (AOT) compilation, Just In Time (JIT) compilation or, our
favorite, interpretation (or Implicit Compilation).</p>
<p><strong>Languages like C, C++ or Rust are AOT-compiled languages.</strong> You write the code,
you compile it and the output is a binary object that a CPU immediately understands
how to execute. It is called Ahead Of Time because you compile the binary object
BEFORE you run it.</p>
<p><strong>Languages like PHP, Java or JavaScript are interpreted.</strong> A code written in such
languages will be translated into an intermediate representation and another
program (a compiled one) will understand and execute such intermediate
representation. It is very common to call such programs "Virtual Machines" or
"Interpreters".</p>
<p><strong>Normally interpreted languages have less performance and freedom when compared
with AOT-compiled languages</strong> because things like memory management, CPU-targeted
instructions and funky low-level tricks are not available to the user space. So
another program (the interpreter) has to manage all of this plus be polyglot
enough to talk to different kinds of processors and operating systems.</p>
<p><strong>Languages like Java, LUA and now PHP are not only interpreted but also Just
In Time compiled!</strong> They still need a VM, but their VMs are capable of compiling
this intermediate representation of code into binary objects in runtime. These
JIT-capable VMs operate in a hybrid mode where code is partially compiled and interpreted.</p>
<p>When JIT kicks in, parts of your php code will be compiled into machine code so the
Zend VM (php's virtual machine) won't interpret these parts anymore. Your php
code will talk directly to the CPU.</p>
<p>So why can't we just compile everything, then? If the VM is a bottleneck, why
bother to run through it in the first place? We could just compile our php code
into machine code and be happy about it.</p>
<p>Well, we'd have to compile to specific CPU architectures, be prepared to talk to
different operating systems, be extremely clear about our variable types and
perform way more bare-metal operations than we should if we want to be productive.
There are decent abstractions for Golang and Rust, for example, but they aren't
very practical and require control over the environment they're deployed against.</p>
<p><strong>Interpreted languages, on the other hand, can be easily deployed to different
servers, allow rapid development and create room for dynamic typing systems.</strong></p>
<p>Just In Time compilation is potentially the best of the two worlds, combining
good speed and developer experience.</p>
<p>Dynamic typing, as you know, is one of the core features of PHP. It is very
complex and is tattooed into php's core in a way that removing the dynamic
typing is almost unthinkable.
<a href="https://thephp.website/en/issue/php-type-system/">Here’s a great summary on how php’s type system works.</a></p>
<p>And because of Dynamic Typing (and some other things you'll learn about below)
the Just In Time compiler present in PHP is not yielding big performance gains.
At least not yet.</p>
<p>Curious why? Keep reading!</p>
<h2>Let's see how PHP works with and without JIT</h2>
<p>In PHP there are three steps before executing your code: <strong>tokenizing</strong>,
<strong>parsing</strong> into an AST and <strong>compiling</strong> to an intermediate representation
known as <strong>Opcode</strong>.</p>
<p><strong>Tokenizing (or Lexing) is the process of reading php code and splitting
it into understandable units called tokens.</strong> <code>&lt;?php</code> becomes a _T_OPEN<em>TAG</em>,
<code>echo</code> becomes a _T<em>ECHO</em> and <code>"Hello, friend"</code> becomes T_CONSTANT_ENCAPSED_STRING.
<a href="https://www.php.net/manual/en/tokens.php">A complete list of PHP's tokens can be found here.</a></p>
<p>Parsing is the process of making sense out of such tokens. In PHP parsed tokens
are organized in a tree structure named AST (Abstract syntax tree).
The AST's job is to represent what operations should be. In <code>echo 1+1</code> the interpreter
should in fact understand <code>print the result of the expression 1+1</code>. Such tree would
look something like the following:</p>
<pre><code>operation =&gt; ECHO,
operand =&gt; expression (
    operation =&gt; ADD,
    operand1 =&gt; 1,
    operand2 =&gt; 1
)</code></pre>
<p>PHP is then able to <strong>compile this tree into an intermediate representation
called Opcode.</strong></p>
<p>The Opcode is what is actually executed by the virtual machine, so executing
is the final step. Here's a diagram illustrating how this process looks like.</p>
<figure>
<a href="https://thephp.website/assets/images/posts/10-php-8-jit/zendvm-no-opcache.png" target="_blank">
<img src="https://thephp.website/assets/images/posts/10-php-8-jit/zendvm-no-opcache.png" alt="The PHP's interpreting flow.">
</a>
<figcaption>A simplified overview on PHP's interpreting flow.</figcaption>
</figure>
<p>You probably realized that tokenizing, parsing and compiling code every single time
can be a big bottleneck. PHP engineers thought so too and that's why the
Opcache extension exists. Let's have a quick look at it.</p>
<h2>The Opcache extension</h2>
<p>The Opcache extension is shipped with PHP and generally there's no big reason to
deactivate it. If you use PHP, you should probably have Opcache switched on.</p>
<p>It adds an in-memory shared cache layer to store Opcodes. So tokenizing, parsing
and compiling will happen once for each file and will be shared with every request.</p>
<p>With Opcache extension enabled, the execution of PHP code looks like in the following
diagram:</p>
<figure>
<a href="https://thephp.website/assets/images/posts/10-php-8-jit/zendvm-opcache.png" target="_blank">
<img src="https://thephp.website/assets/images/posts/10-php-8-jit/zendvm-opcache.png" alt="The PHP's interpreting flow with Opcache">
</a>
<figcaption>The PHP's interpreting flow with Opcache. If a file was already parsed, php fetches the cached Opcodes for it instead of parsing all over again.</figcaption>
</figure>
<p><strong>Side note:</strong> this is where <a href="https://wiki.php.net/rfc/preload">PHP 7.4's preloading feature</a>
shines! It allows you to tell PHP FPM to parse your codebase, transform it into
Opcodes and cache them even before you execute anything.</p>
<h2>Enters the Just In Time compilation</h2>
<p>While the Opcache extension will prevent PHP from tokenizing, parsing and compiling
over and over again, the Just In Time compilation aims to skip the virtual machine's
Opcode interpretation and let it execute machine code directly.</p>
<p>PHP's JIT implementation uses a C library called
<a href="https://luajit.org/dynasm.html">DynASM (Dynamic Assembler)</a>
which maps a set of CPU instructions in one specific format into assembly code for
many different CPU types. So the Just In Time compiler transforms Opcodes into an
architecture-specific machine code using DynASM.</p>
<p>The compilation happens between fetching Opcodes from cache and executing them.
Since compiling Opcode into machine code can be very expensive, PHP has to decide
which portions of your code might make sense to be compiled or not.</p>
<p><strong>PHP then profiles Opcodes being executed by the Zend VM and checks which ones
might make sense to compile. (based on your configuration)</strong></p>
<p>When an Opcode is compiled its execution doesn't happen through the Zend VM handlers,
they are directly executed by the CPU.</p>
<figure>
<a href="https://thephp.website/assets/images/posts/10-php-8-jit/zendvm-opcache-jit.png" target="_blank">
<img src="https://thephp.website/assets/images/posts/10-php-8-jit/zendvm-opcache-jit.png" alt="The PHP's interpreting flow with JIT">
</a>
<figcaption>The PHP's interpreting flow with JIT. If compiled, Opcodes don't execute through the Zend VM.</figcaption>
</figure>
<p>When an Opcode should be compiled is decided based on your INI configurations. You'll
get more details in the next section.</p>
<h2>JIT Configuration</h2>
<p>Configuring JIT in PHP is very simple, there are two INI directives we need to set:
<code>opcache.jit_buffer_size</code> and <code>opcache.jit</code>. The first indicates how much memory
we're willing to allocate for compiled code, while the later one dictates how JIT
should behave.</p>
<p>There's also an optional directive named <code>opcache.jit_debug</code> for debugging purposes.
I will not cover this one here.</p>
<p>For example, the snippet below indicates that we're willing to give up to 100 Megabytes
of compiled code, enabling AVX instruction generation, using a global linear-scan register
allocator, profiling each request and jitting hot functions, optimizing the compiled
code based on static type inference. (👀 WUT?)</p>
<pre><code>opcache.jit_buffer_size=100M
opcache.jit=1235</code></pre>
<p>To make your life easier, I’m bringing some presets that
<a href="https://beberlei.de/2020/07/05/what_to_look_out_for_when_testing_php_jit.html">Benjamin Eberlei kindly shared in his blog</a>:</p>
<ul>
<li><code>opcache.jit=1205</code> (JIT everything)</li>
<li><code>opcache.jit=1235</code> (JIT hot code based on relative usage)</li>
<li><code>opcache.jit=1255</code> (trace hot code for JITability, the best so far)</li>
</ul>
<p>The <code>opcache.jit</code> entry is a sequence of values named "CRTO", each character can have different
behavioural effect on your application. Below I explain what each of these letters can do:</p>
<p><strong>C - CPU-specific optimization</strong></p>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>No optimization whatsoever</td>
</tr>
<tr>
<td>1</td>
<td>Enable <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX instruction</a> generation</td>
</tr>
</tbody>
</table>
<p><strong>R - Register Allocation Modes</strong></p>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Never perform <a href="https://en.wikipedia.org/wiki/Register_allocation">register allocations</a></td>
</tr>
<tr>
<td>1</td>
<td>Use local linear-scan register allocation</td>
</tr>
<tr>
<td>2</td>
<td>Use global linear-scan register allocation</td>
</tr>
</tbody>
</table>
<p><strong>T - JIT trigger</strong></p>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>JIT everything on first script load</td>
</tr>
<tr>
<td>1</td>
<td>JIT functions when they execute</td>
</tr>
<tr>
<td>2</td>
<td>Profile first request and compile hot functions on second requests</td>
</tr>
<tr>
<td>3</td>
<td>Profile and compile hot functions all the time</td>
</tr>
<tr>
<td>4</td>
<td>Compile functions with a <code>@jit</code> in doc blocks</td>
</tr>
</tbody>
</table>
<p><strong>O - Optimization level</strong></p>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Never JIT</td>
</tr>
<tr>
<td>1</td>
<td>Minimal JIT (use regular VM handlers)</td>
</tr>
<tr>
<td>2</td>
<td>Selective VM handler inlining</td>
</tr>
<tr>
<td>3</td>
<td>Optimized JIT based on static type inference of individual function</td>
</tr>
<tr>
<td>4</td>
<td>Optimized JIT based on static type inference and call tree</td>
</tr>
<tr>
<td>5</td>
<td>Optimized JIT based on static type inference and inner procedure analyses</td>
</tr>
</tbody>
</table>
<p>I don't fully understand every term there, but the main takeaway is that you should play
around with each flag and keep profiling …</p></iframe></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephp.website/en/issue/php-8-jit/">https://thephp.website/en/issue/php-8-jit/</a></em></p>]]>
            </description>
            <link>https://thephp.website/en/issue/php-8-jit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24320024</guid>
            <pubDate>Sat, 29 Aug 2020 23:00:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Quietly Ends Racial Ad Profiling – Revue]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24319700">thread link</a>) | @lladnar
<br/>
August 29, 2020 | https://www.getrevue.co/profile/themarkup/issues/facebook-quietly-ends-racial-ad-profiling-269635 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/themarkup/issues/facebook-quietly-ends-racial-ad-profiling-269635">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/themarkup/issues/facebook-quietly-ends-racial-ad-profiling-269635</link>
            <guid isPermaLink="false">hacker-news-small-sites-24319700</guid>
            <pubDate>Sat, 29 Aug 2020 21:56:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Guide: Zero to Rebase]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24319451">thread link</a>) | @elgfare
<br/>
August 29, 2020 | https://oyvn.github.io/git-zero-to-rebase | <a href="https://web.archive.org/web/*/https://oyvn.github.io/git-zero-to-rebase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The aim of this guide is to make you more comfortable with git without having to read a whole book.
I will do this by giving you more of an “inside tour” of the inner workings of git.</p>

<p>If you are curious and want to become more comfortable with git, this guide aims to satisfy your curiosity more than “traditional” git guides.</p>

<p>I hope you’ll learn enough here to use git with more confidence, and will know better where to look when you are stuck.</p>

<p><strong>Table of Contents</strong>:</p>
<ul id="markdown-toc">
  <li><a href="#act-1-backups" id="markdown-toc-act-1-backups">Act 1: Backups</a>    <ul>
      <li><a href="#first-steps" id="markdown-toc-first-steps">First steps</a></li>
      <li><a href="#the-repository" id="markdown-toc-the-repository">The repository</a></li>
      <li><a href="#the-objects---commit-tree-and-blob" id="markdown-toc-the-objects---commit-tree-and-blob">The objects - commit, tree and blob</a></li>
      <li><a href="#references-the-hash" id="markdown-toc-references-the-hash">References (the “hash”)</a></li>
      <li><a href="#intermission-index" id="markdown-toc-intermission-index">Intermission: Index</a></li>
    </ul>
  </li>
  <li><a href="#act-2-timelines" id="markdown-toc-act-2-timelines">Act 2: Timelines</a>    <ul>
      <li><a href="#branches" id="markdown-toc-branches">Branches</a></li>
      <li><a href="#refs" id="markdown-toc-refs">Refs</a></li>
      <li><a href="#merging" id="markdown-toc-merging">Merging</a></li>
      <li><a href="#cherry-pick" id="markdown-toc-cherry-pick">Cherry-pick</a></li>
      <li><a href="#rebase" id="markdown-toc-rebase">Rebase</a>        <ul>
          <li><a href="#removing-commits" id="markdown-toc-removing-commits">Removing commits</a></li>
          <li><a href="#adding-more-changes-to-an-old-commit" id="markdown-toc-adding-more-changes-to-an-old-commit">Adding more changes to an old commit</a></li>
          <li><a href="#clean-history-when-collaborating" id="markdown-toc-clean-history-when-collaborating">Clean history when collaborating</a></li>
          <li><a href="#making-the-history-linear" id="markdown-toc-making-the-history-linear">Making the history linear</a></li>
          <li><a href="#fully-reconstructing-the-history" id="markdown-toc-fully-reconstructing-the-history">Fully reconstructing the history</a></li>
        </ul>
      </li>
      <li><a href="#afterword" id="markdown-toc-afterword">Afterword</a></li>
    </ul>
  </li>
</ul>



<p>Git is a computer program that creates snapshots – essentially backups – of folders on your computer.
In git, these snapshots are called “commits”.
A commit contains everything in that folder:</p>
<ul>
  <li>The folder structure</li>
  <li>names of files</li>
  <li>contents of files</li>
  <li>metadata of files</li>
</ul>

<p>Git’s strengths come from how it organizes the commits and from all the commands it provides for manipulating, labelling, and comparing them.
Handling commits is what makes git a “Version Control System”.</p>

<p>Git tries to make it <em>very</em> easy to take backups so that you can always find a useful place to return to if needed. Also, having a detailed commit history can help answer questions about the state of things at different points in the past, and about why changes were made. Each commit has info about when it was created, and by whom, as well as a “commit message” written by the committer, which ideally contains important information about why it exists.</p>

<p>Git also has commands for collaborating with others (e.g. push/pull/fetch).
The collaboration essentially means exchanging commits and “branches” (which in git are just labels for commits).
Usually collaboration means sending them to a server where others can retrieve them, but it’s also possible to share them directly with other collaborators.<sup id="fnref:distributed"><a href="#fn:distributed">1</a></sup></p>

<h3 id="first-steps">First steps</h3>

<p>Download git: <a href="https://git-scm.com/download/">https://git-scm.com/download/</a></p>

<p>Git is usually used from the command line, but there are also other ways to use it (<code>git gui</code>, SourceTree, TortoiseGit to name a few.
<a href="https://git-scm.com/downloads/guis/">Here is a big list of graphical user interfaces for git</a>).</p>

<p>To download an existing repository (for example the one for this blog), run</p>

<div><div><pre><code>git clone https://github.com/oyvn/oyvn.github.io.git
</code></pre></div></div>

<p>To create your own repository in an existing folder, run</p>

<div><div><pre><code>git init                      # Creates the repository
git add .                     # Prepares a commit of whatever was in
                              # the folder.
git commit -m"Initial commit" # Stores the commit with the message
                              # "Initial commit"
</code></pre></div></div>

<h2 id="the-repository">The repository</h2>

<p>A “repository” (repo) is a collection of commits.
When you use <a href="https://git-scm.com/docs/git-init"><code>git init</code></a> to create a repo inside a folder, git adds a hidden folder called “.git” inside it. The .git folder is where it puts all the commits.</p>

<p>The rest of your folder is now referred to as the “working directory”.</p>

<p>When you create a commit, git stores all the files and folders as “objects” in the .git folder.
Together, the stored objects contain all the information necessary to recreate the contents of the working directory.</p>

<p>When you retrieve a repo with <a href="https://git-scm.com/docs/git-clone"><code>git clone</code></a>, git essentially retrieves the .git folder and recreates – “checks out” – the working directory from the objects.</p>

<p>There are a few different types of git objects, let’s take a closer look.</p>

<h2 id="the-objects---commit-tree-and-blob">The objects - commit, tree and blob</h2>

<p>In git, everything is files.
All objects are stored as files in the .git repo.
Objects have different types depending on what data they contain.
An object’s file name is usually a string of gibberish that serves as a unique reference to that object.</p>

<p>When you call <a href="https://git-scm.com/docs/git-commit"><code>git commit</code></a>, git creates a “commit” object, as well as “tree” objects for each folder, and “blob” objects for each file in the snapshot.
The blob is the simplest, it’s just a copy of the file, except for the name, which is a gibberish reference instead.</p>

<p>If you look in <code>.git/objects</code> you will find all commit, tree, and blob objects in your repo, all with gibberish names.</p>

<p>By not associating objects with file or folder names, the object can be reused even if the name or location of a file or folder changes, as long as the contents remain unchanged.</p>

<p>A tree object contains:</p>

<ul>
  <li>The name and a reference for every immediate sub-folder. The reference is to a tree object describing the sub-folder’s contents.</li>
  <li>The name and a reference for every file in the folder. The reference is to a blob object with the file contents.</li>
</ul>

<p>A commit object contains:</p>

<ul>
  <li>The committer and author (That’s you, if you made the commit – your name and email address as configured via <a href="https://git-scm.com/docs/git-config"><code>git config</code></a>).</li>
  <li>The current date and time.</li>
  <li>The commit message that you authored in the process of committing.</li>
  <li>A reference to the tree object for the working directory.</li>
  <li>One or more references to other commit objects (“parent commits”).</li>
</ul>

<p>At this point I want you to notice a few things:</p>

<ul>
  <li>Each commit points to a parent.
This means the commit can be understood as building on something that came before it.</li>
  <li>Even though a commit is thought of as a <em>change</em>, or <em>difference</em> (also called a “delta”), it is stored by git as a standalone snapshot.
Any information about what change it represents is computed when needed, by comparing commits.</li>
  <li>Because objects are referred to by reference, any time an object already exists git just refers to the existing object.
So when your commit only changes one file, only one new blob object (and at least one tree object) needs to be created.</li>
  <li>Retrieving any object by its reference just means finding a file with a certain name.</li>
</ul>

<p>Objects are described in depth in the <a href="https://git-scm.com/book/en/v2/Git-Internals-Git-Objects">Git Internals</a> chapter of the free Pro Git Book.
I recommend it if you are curious, it’s where I learned this.</p>

<p>Now let’s take a closer look at the unique gibberish reference (“hash”).</p>

<h2 id="references-the-hash">References (the “<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function">hash</a>”)</h2>
<p>This section might be heavy, but keep going, it gets to the heart of many of git’s quirks.</p>

<p>In git, there are hashes everywhere, displayed as long strings of numbers and letters.
All objects have hashes, but you mostly see commit hashes, for example when you run <a href="https://git-scm.com/docs/git-log"><code>git log</code></a>.</p>

<p><img src="https://oyvn.github.io/assets/git-log.png" alt="git log" title="git log output."></p>
<p>git log output from this blog’s repo.</p>

<p>The hash is calculated from the contents of a given object, and is  completely unique to that object.
It’s often called the “sha” of the commit, because the hash is of the type <a href="https://en.wikipedia.org/wiki/SHA-1">sha1</a>.</p>

<p>A hash (or “digest”) is a big number which always a certain length.
For sha1, the length is 160 bits, or 20 bytes<sup id="fnref:sha1_finite"><a href="#fn:sha1_finite">3</a></sup>.
In git, these bytes are always displayed as a text string of 40 <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal</a> characters (0-9, a-f)<sup id="fnref:sha_length"><a href="#fn:sha_length">4</a></sup>.</p>

<p>The hash is created by taking the data (the input) and doing some convoluted math on it.
The input can be any data, of any length.
In git, objects serve as inputs.</p>

<p>The convoluted math is such that the hash follows some very strict rules:</p>

<ul>
  <li>The length of the hash is the same regardless of the length of the input.</li>
  <li>The hash is always the same every time if the input is the same.</li>
  <li>The hash is always <em>completely</em> different if the input is even <em>slightly</em> different, even if a single bit is changed, added or removed.</li>
  <li>Finding an input for a given hash (i.e. calculating the hash backwards) is impossible.</li>
</ul>

<div><div><pre><code>sha1("a"):
    86f7e437faa5a7fce15d1ddcb9eaeaea377667b8
sha1("To die, to sleep - to sleep, perchance to dream - ay, there's the rub, for in this sleep of death what dreams may come"):
    0855319deffa58b0458c29edeaa8d6a120d44f35
sha1("to die, to sleep - to sleep, perchance to dream - ay, there's the rub, for in this sleep of death what dreams may come"):
    cab29b74b98c3ad638fe9c1abed72be40d69badc
</code></pre></div></div>

<p>Some example SHA1 hashes.</p>

<p>From these rules, we can realize that if <em>any</em> data in an object changes, it is no longer the same object, because the reference will be completely different.
That includes if the time changes by just one second in a commit, or a file changes by just one byte, or if a folder name changes slightly.</p>

<p>It also means that the changes must propagate.
If a file changes, its reference changes, so the tree containing the reference changes, and the commit containing the tree changes.</p>

<p>Any commits descended from the commit must also change.
In fact, looking backwards in time, a commit hash uniquely identifies not just the commit, but also, through its parents and grandparents etc., the entire git history - every tree, blob, and commit - up until that commit. If any detail in any place in the history was different, the current commit would not be the same commit since its hash would be different.</p>

<p>Phew!</p>

<p>Ok. Time for a short story about something slightly different.</p>

<h2 id="intermission-index">Intermission: Index</h2>

<p>When creating a commit, you might want to limit the difference from the previous commit.
You’ll want to group changes in a logical way, to make the commit easier to describe, and to reason about later.</p>

<p>You might have done many changes, though, since the last commit.
Git helps in this situation by allowing you to “stage” changes before commiting them.
<a href="https://git-scm.com/docs/git-add"><code>git add</code></a> adds files to the “index” i.e. stages them, i.e. marks them as “to be committed”.</p>

<p>When you create the commit, only the staged files and folders receive new objects, the rest are stored as unchanged.</p>

<p>Git creates trees and blobs from the files as you stage them, so that <code>git commit</code> just needs to create a commit object which references the tree created for the index.</p>

<p>The index often confuses people, but at this point in the guide it might be interesting to realize the similarities between the index and a commit.</p>

<p>Now for the story.</p>

<p>I once mistakenly deleted a new file I had been working on, losing several hours of work since I hadn’t committed it (commit often, people!).
But I remembered that I had staged it at one point, so I knew a blob object was created.
I managed to search the files in my .git folder for a phrase present in the lost file, and I found the file.
The blob …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oyvn.github.io/git-zero-to-rebase">https://oyvn.github.io/git-zero-to-rebase</a></em></p>]]>
            </description>
            <link>https://oyvn.github.io/git-zero-to-rebase</link>
            <guid isPermaLink="false">hacker-news-small-sites-24319451</guid>
            <pubDate>Sat, 29 Aug 2020 21:08:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easily deploy node app to the cloud]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24318885">thread link</a>) | @blakemc34
<br/>
August 29, 2020 | https://docs.kintohub.com/examples/nodejs/nodejs-example | <a href="https://web.archive.org/web/*/https://docs.kintohub.com/examples/nodejs/nodejs-example">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A sample node service for <a href="https://kintohub.com/">KintoHub</a></p><h2>🚀 Deploying on KintoHub</h2><ul><li><strong>Service Type:</strong> Web App</li><li><strong>Repo:</strong> <a href="https://github.com/kintohub/kintohub" target="_blank" rel="noopener noreferrer">https://github.com/kintohub/kintohub</a></li><li><strong>Branch:</strong> master</li><li><strong>Language:</strong> NodeJS</li><li><strong>Language version:</strong> 14</li><li><strong>Build Command:</strong> <code>npm install</code></li><li><strong>Start Command:</strong> <code>npm run prod</code></li><li><strong>Subfolder Path:</strong> <code>./docs/examples/nodejs</code></li><li><strong>Port:</strong> 80</li></ul><h2>🔨 Running locally</h2><p><strong>Pre-requisites:</strong> Nodejs v12+</p><ul><li>Clone the repository to a folder of choice.</li></ul><div><div><div tabindex="0"><div><p><span>$ git clone https://github.com/kintohub/kintohub</span></p><p><span>$ cd kintohub/examples/nodejs</span></p></div></div></div></div><ul><li>Install the dependencies</li></ul><div><div><div tabindex="0"><div><p><span>$ npm install</span></p></div></div></div></div><ul><li>To start the app</li></ul><div><div><div tabindex="0"><div><p><span>$ npm run start</span></p></div></div></div></div><h2>🚑 Support</h2><p><strong>Contact us:</strong> <a href="https://www.kintohub.com/contact-us" target="_blank" rel="noopener noreferrer">https://www.kintohub.com/contact-us</a></p><p><strong>Discord:</strong> <a href="https://discordapp.com/invite/E2CMjKP" target="_blank" rel="noopener noreferrer">https://discordapp.com/invite/E2CMjKP</a></p></div></div>]]>
            </description>
            <link>https://docs.kintohub.com/examples/nodejs/nodejs-example</link>
            <guid isPermaLink="false">hacker-news-small-sites-24318885</guid>
            <pubDate>Sat, 29 Aug 2020 19:45:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inventing Monads]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24318244">thread link</a>) | @stopachka
<br/>
August 29, 2020 | https://stopa.io/post/247 | <a href="https://web.archive.org/web/*/https://stopa.io/post/247">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>I got into a discussion about monads recently. On a search to find some resources to share, I realized that most essays explained them with type signatures and rules. A missing ingredient to grok them, I think, is to understand the intuition behind them. How could you end up <em>inventing</em> monads?</p><p>Okay, let’s try to build that intuition. We’ll avoid both types and category theory.</p><p>Say you have a few functions to get a user, a profile, and a display picture:</p><pre><code>function getUser(id) { 
  return USERS[id] 
}

function getProfile(user) { 
  return user.profile
}

function getDisplayPicture(profile) { 
  return profile.displayPicture
}</code></pre><p>Now, given an id, how would you get the profile picture?</p><p>You could write this: </p><pre><code>getDisplayPicture(getProfile(getUser(id)))</code></pre><p>Buut, this would throw an error: all these functions <em>could</em> return null. If <code>getUser</code> returned null for example, you would see: </p><pre><code>Uncaught TypeError: Cannot read property 'profile' of undefined</code></pre><p>To fix this, you may end up writing something like this:</p><pre><code>function getDisplayPictureFromId(id) { 
  const user = getUser(id)
  if (!user) return
  const profile = getProfile(user)
  if (!profile) return
  return getDisplayPicture(profile)
}</code></pre><p>But, this is getting pretty ugly. All these conditional returns distract from what you’re really trying to do. <strong>What if there was a way to get rid of these conditionals?</strong></p><p>So, that’s our challenge: let’s get rid of these conditionals. One way we can do this, is to make some kind of helper. This helper would let us chain these functions together: </p><pre><code>new Chainer(getUser(id))
  .whenExists(user =&gt; getProfile(user))
  .whenExists(profile =&gt; getDisplayPicture(profile))</code></pre><p>This looks pretty good. Let’s implement it.</p><h2>whenExists</h2><p><code>.whenExists</code> would only run the callback if the value exists. Here’s how you could write this:</p><pre><code>class Chainer {
  constructor(v) { 
      this.value = v
  }
  whenExists(f) { 
      if (!this.value) return this;
      return new Chainer(f(this.value))
  }
}</code></pre><p>And voila, with just this, we can now write</p><pre><code>function getProfilePictureFromId(id) { 
  return new Chainer(getUser(id))
    .whenExists(user =&gt; getProfile(user))
    .whenExists(profile =&gt; getDisplayPicture(profile))
}</code></pre><h2>More Problems</h2><p>Notice that <code>getDisplayPictureFromId</code> now returns a <code>Chainer</code>. </p><p>Imagine we had another function <code>resizeDisplayPicture</code>, that <em>also</em> returned a Chainer</p><pre><code>function resizeDisplayPicture(pic) { 
    return new Chainer(pic).whenExists(pic =&gt; ...
}</code></pre><p>What would happen, if we wrote:</p><pre><code>getProfilePictureFromId(id).whenExists(pic =&gt; resizeDisplayPicture(pic))</code></pre><p>Let’s look at whenExists again:</p><pre><code>whenExists(f) { 
  if (!this.value) return this;
  return new Chainer(f(this.value))
}</code></pre><p>If <code>getProfilePictureFromId(id)</code> did exist, we would run </p><pre><code>new Chainer(f(this.value))</code></pre><p>which in this case is</p><pre><code>new Chainer(resizeDisplayPicture(this.value)) </code></pre><p>Which becomes </p><pre><code>new Chainer(new Chainer(this.value)...</code></pre><p><strong>Uh oh. We now have a Chainer inside of a Chainer.</strong> Ideally, we’d want a function that somehow “merged” these chainers together.</p><h2>whenExistsMerge</h2><p>So let’s do that. We can call it <code>whenExistsMerge</code></p><pre><code>class Chainer {
  constructor(v) { 
      this.value = v
  }
  whenExists(f) { 
      if (!this.value) return this;
      return new Chainer(f(this.value))
  }
  whenExistsMerge(f) { 
      if (!this.value) return this;
      return f(this.value)
  }
}</code></pre><p>And with that, we can write </p><pre><code>getProfilePictureFromId(id)
  .whenExistsMerge(pic =&gt; resizeDisplayPicture(pic))
  .whenExists(resizedPic =&gt; ...)</code></pre><p><strong>Aand voila, you’ve just invented a specific type of monad.</strong> Kind of (1). Chainer is analogous to the <code>Maybe</code> monad. <code>whenExists</code> is analogous to its <code>fmap</code> operation, and <code>whenExistsMerge</code> is analogous to its <code>bind</code> operation. If you’re curious about the type-based technicalities now, <a href="http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html" target="_blank">see this essay</a>. </p><p>So, now we’ve found this cool <code>Chainer</code>. We can stop here, or think a bit further. What’s so special about it? </p><p>Well, it’s like a box that wraps around some information. We can interact with that box with  <code>whenExists</code> and <code>whenExistsMerge</code>.</p><p>How else can we use the idea of <code>box</code> and <code>whenExists?</code></p><p>Here’s one. Let’s say you were dealing with callback hell: </p><pre><code>fetchUser(id, (err, user) =&gt; {
  if (err) ... 
    fetchProfile(profile, (err, profile) =&gt; { 
      if (err) ...
        fetchDisplayPicture(...
    }
}</code></pre><p>What if we created something like an <code>Async Chainer</code>: it stores the result of some future computation. Then, you could use the <code>whenExists*</code> functions, which let you interact with the value <em>when</em> it is computed. We turn the callback hell into</p><pre><code> fetchUser(id).whenExistsMerge(fetchProfile).whenExistsMerge(fetchDisplayPicture)</code></pre><p>Well, replace <code>whenExistsMerge</code> with <code>then</code>, and you're on a road to discover <code>Promise</code>, which is also a monad. Kind of (2). </p><p>Now, it’s pretty cool to notice that both the nullable use case and the async use case have the same interface. The name <code>whenExists</code> may be a bit too specific. Really, what it does is give you an interface to <code>map</code> over the value. If you use the word <code>map</code>, <code>whenExistsMerge</code> really lets you <code>flatMap</code> over the value. </p><p>This begins to get us to the fundamental abstraction of a monad: a box, with an interface for <code>map</code>, and <code>flatMap</code>. As you look deeper, you’ll notice that this abstraction can handle a lot of other things. If you’re curious, research the <code>Result</code> monad for example.</p><p>And with that, you’ve invented monads : ) </p><h2>Aside: Do you <em>really</em> need this?</h2><p>As you went through this, you may have realized that there are other ways to solve the problems that monads solve. Instead of <code>Chainer</code>, your language could have a <a href="https://kotlinlang.org/docs/reference/null-safety.html#safe-calls" target="_blank">safe call</a> abstraction. Instead of <code>Promise</code>, your language could have an <code>async/await</code> abstraction. Sometimes those can be a better <a href="https://www.youtube.com/watch?v=YR5WdGrpoug" target="_blank">better choice</a>. Nevertheless, if your language doesn’t have those abstractions, you can use monads to solve them. And of course, like any powerful abstraction, you can invent new monads to simplify your business logic.</p><hr><p>(1) I cheated a bit with <code>Chainer</code>, by avoiding the subtypes <code>Just</code> and <code>Nothing</code>. This makes it so you can’t express something like <code>Just(null)</code>. Still, it gets at the essence : ) </p><p>(2) Likewise, <code>Promise</code> isn’t quite a monad, because it mixes both <code>flatMap</code> and <code>map</code> with <code>then</code>. This makes it so you can’t have a <code>Promise&lt;Promise&lt;Res&gt;&gt;</code>. Again though, it gets at the essence</p><p><em>Thanks to Joe Averbukh, Mark Shlick, Daniel Woelfel, Irakli Safareli, Jacky Wang for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/247</link>
            <guid isPermaLink="false">hacker-news-small-sites-24318244</guid>
            <pubDate>Sat, 29 Aug 2020 18:22:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand HTTP3 in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24317018">thread link</a>) | @ausjke
<br/>
August 29, 2020 | https://www.jesuisundev.com/en/understand-http3-in-5-minutes | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-http3-in-5-minutes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>You haven’t quite figured out HTTP2 yet that you’re already starting to get pissed off by people talking about HTTP3. But there’s a reason for that: HTTP3 is fast. I bet you in five minutes you’ll agree with me. </p>



<h3>Once upon a time</h3>



<p>I can’t tell you about the future without telling you about the present. <strong>Do you know about HTTP ?</strong> Defined in 1991, it’s the protocol that manages the web. It means <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol" target="_blank" rel="noreferrer noopener">HyperText Transfer Protocol</a> and it allows you to fetch resources from a web page. </p>



<p>From a web server to your browser. It’s built on a lower level protocol –<strong>TCP: it’s going to be important-</strong> and it’s stateless. It means that each request is completely independent. Each GIF present on this page is a GIF proudly independent in its life on the internet. That’s good for him and his life as a GIF. But for us it’s a bit of a broken system.</p>



<p>Because the problem is that <strong>each request will only look for one file at a time</strong>. Each time an expensive TCP connection is created for the occasion. Imagine if you had 10,000 Internet tips on your page.</p>



<p> I know a lot of people absolutely loved my pattern making skills in the previous article. So, to explain the Internets to you properly, I’m doing it again.</p>



<div><figure><img src="https://i.imgur.com/iI0MrHF.jpg" data-src="https://i.imgur.com/iI0MrHF.jpg" alt="http"></figure></div>



<p>Despite the fact that a browser can make six different requests at the same time, HTTP is still slow and full of TCP connections. Plus, we developers, usualy don’t care about that. <strong>We like to put as much crap on our pages as possible. </strong>Big jQuery lib with 300 useless CSS stylesheets ending with a big transparent 8 mega PNG. </p>



<p>When Google saw all the crap we were doing everywhere <strong>they started talking about SPDY</strong> (it’s called speedy). The point? To speed up the Internets. </p>



<p>SPDY is a specification that proposes to use HTTP as is but with a change of rules. And by <strong>compressing headers, prioritizing requests and multiplexing</strong>, it will transform all TCP requests and connections into one! </p>



<p>Concretely, when your HTML is read, your browser looks at everything you’re going to ask in your page. Then, it’s getting everything all at once. <strong>This way you avoid doing it file by file.</strong> </p>



<p>The first draft of HTTP2 is SPDY based. Very quickly HTTP2 was adopted and life on the internet has become faster. <strong>Today <a href="https://w3techs.com/technologies/details/ce-http2" target="_blank" rel="noreferrer noopener">42.7% of the internet</a> use HTTP2.</strong></p>



<div><figure><img src="https://i.imgur.com/2jePyHC.jpg" data-src="https://i.imgur.com/2jePyHC.jpg" alt="http2"></figure></div>



<h3>Great, what about HTTP3?</h3>



<p>If I piss you off with HTTP and HTTP2 when you explicitly clicked to see sexy HTTP3, there’s a good reason. HTTP2 was created by taking HTTP as a base and changing the rules.<strong> It’s the same thing with HTTP3. </strong>So by understanding the present it’s easier for me to explain the future to you.</p>



<p>Googlers are geeks, they never stop. After SPDY became HTTP2, they thought that it was still not fast enough. So they started talking about QUIC (it’s called Quick). <strong>This will be the second experimental technology developed by Google to become an official upgrade of the HTTP protocol</strong>. But what’s so special about this protocol?</p>



<p>The main big evolution of HTTP3 is the change of transport layer. No more of the heavy TCP connections I’ve been telling you about since the beginning. <strong>Now, it’s all about UDP. </strong></p>



<p>By the way QUIC means “Quick UDP Internet Connections”. This change of protocol will speed up connection establishment and data transfer times enormously. Howerver, <strong>UDP is certainly faster and simpler, but it doesn’t have the reliability and error handling of TCP.</strong></p>



<p>TCP has to make several round trips just to establish a connection in a square and stable way. <strong>Where UDP doesn’t give a damn and does it really fast without stability and risk of lost packets. </strong>However UDP can dramatically reduce latency in requests. Up to almost zero latency in repeated connections to the same server because no roundtrip is made to establish connections.</p>



<figure><img src="https://i.imgur.com/hDmNkpS.png" data-src="https://i.imgur.com/hDmNkpS.png" alt="http3"></figure>



<p>HTTP3 is the multiplexing and compression features of HTTP2 with a protocol change from TCP to UDP. The Google guys then added their layer in the protocol to guarantee stability, order in the reception of packets and of course security. </p>



<p><strong>So HTTP3 uses UDP for its high speed while keeping the stability of QUIC</strong>, without forgetting the security of TLS. Because yes, in QUIC you find TLS 1.3 which allows you to make your beautiful SSL. I’ve been talking about layers for a while, this is what it looks like under the hood.</p>



<figure><img src="https://i.imgur.com/QdNsQHL.jpg" data-src="https://i.imgur.com/QdNsQHL.jpg" alt="http3"></figure>



<p>In 2018, QUIC became HTTP3. The Internet Enginerring Task Force dudes, <a href="https://www.youtube.com/watch?v=uVf_yyMfIPQ&amp;t=4956" target="_blank" rel="noreferrer noopener"><strong>dudes in shorts who decide on Internet protocols</strong></a>, have agreed. And that’s great news because the Internets will never be fast enough for us, impatient people.</p>



<h3>Epilogue</h3>



<p>HTTP3 is the sexy future with a HTTP base that has been tuned to the maximum by google geeks. At the time of writing, <a href="https://w3techs.com/technologies/details/ce-quic" target="_blank" rel="noreferrer noopener">only 4.6% of the Internet uses HTTP3</a> but this figure is likely to grow in the coming years. We stayed on the surface today, but there are a lot of deep-dive articles everywhere that I invite you to consult if you’re more curious.</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-http3-in-5-minutes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24317018</guid>
            <pubDate>Sat, 29 Aug 2020 16:01:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[She’s Got Game]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 92 (<a href="https://news.ycombinator.com/item?id=24316556">thread link</a>) | @woldemariam
<br/>
August 29, 2020 | https://restofworld.org/2020/you-just-got-pwned-habibi/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/you-just-got-pwned-habibi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>In April 2012, three college juniors — Felwa, Tasnim, and Najla — waited anxiously on the campus of Prince Sultan University in Riyadh. For the previous six months, their lives had been consumed by the pursuit of a single, radical idea: frustrated that women, year after year, were barred from the annual Gamers’ Day convention, <a href="http://gamersday.com/en/about-us.php#:~:text=Gamers'%20Day%20is%20a%20gaming,numbers%20of%20visitors%20and%20exhibitors">the largest annual gaming convention in Saudi Arabia</a>, they had decided to launch the first-ever gamers’ convention for women in the kingdom. As the organizers hurried around counting consoles and hanging posters near stalls, they wondered whether anyone would show up.</p>



<p>Over the past decade, Saudi Arabia’s gaming scene has dramatically evolved, especially for women. In the early 2000s, the country had strict moral regulations on entertainment, and games were mostly sold in a gray market or through unofficial channels. Areej, a 23-year-old university graduate, picked up her interest in gaming from her father, who once frequented the informal neighborhood stores that sold pirated copies of popular games for 10 riyals ($2). “He played Japanese and English games, even though he didn’t even understand English back then,” she recalled. “He would keep dictionaries around while playing. That’s actually how he learned the language.” Areej hopes to become a “localizer,” a job that entails translating English-language games into Arabic. A decade ago, this wouldn’t have been possible.&nbsp;</p>



<p>After Sony’s 2007 release of the PlayStation 3 in the kingdom, the gaming industry began to take shape in Saudi Arabia. The first <a href="https://www.gamersday.com/en/">Gamers’ Day</a> took place in 2008, and it now draws upward of 60,000 male visitors over the course of four days. The convention presents video game companies with a lucrative opportunity to demo their latest equipment and products; devoted players, in turn, get to try out highly anticipated games that have not yet been released. In 2012, as the three girls were setting up Girls Con (or GCON as it would come to be known), the industry was estimated to have a global revenue stream of $70 billion.</p>



<p>In the months prior to GCON, Tasnim, the only one in the group with work experience, took the lead pitching sponsorship proposals to the all-male staffs at Nintendo and PlayStation Arabia. Without any real data on female gamers in the Middle East, and with barely any on girl gamers in North America, she had pitched on the assumption that the <a href="https://newzoo.com/insights/articles/male-and-female-gamers-how-their-similarities-and-differences-shape-the-games-market/">gender ratio for gamers in Saudi Arabia</a> was likely the same as in the United States: 47%. But there was no way to prove this. Until then, the world of female gaming in Saudi Arabia was a private one, usually set in the intimacy of people’s bedrooms.</p>



<p>“You could find girls who played video games, just for fun or on their mobile phone, but I had no idea how many girls were into hardcore gaming,” Felwa said. While mobile games like Angry Birds and Candy Crush were popular — the Kingdom boasts a <a href="https://www2.deloitte.com/content/dam/Deloitte/xe/Documents/technology-media-telecommunications/GMCS-whitepaper.pdf">90% cell phone penetration rate</a> — Felwa was curious to see how many girls had grown up like her playing Tomb Raider, Tekken, and League of Legends.</p>



<p>When the hall flooded with nearly 3,000 women, some as young as 13 and others in their 50s, it was a shock. “I definitely did not expect moms to come,” Felwa said. Back then, it was mandatory for women to wear the traditional black abaya, and often a headscarf, while in public. It was only when the women walked through the doors into the all-female space that their abayas slipped off to reveal an array of cosplay costumes.</p>



<p>Inside the hallway, girls who were expected to behave discreetly at all times rushed around trying to play as many PlayStation- and Nintendo-sponsored games as they could. On one side of the hall, first-time cosplayers shared a rare opportunity to express their fandom. On the other, 150 people stood in a rowdy line waiting their turn in a Call of Duty tournament.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>While the Middle</strong> <strong>East</strong> represents only a small portion of the international gaming industry, it is a rapidly expanding market. In 2017, the countries of the Gulf Cooperation Council accounted for around $693 million of gaming revenue, most related to esports. By 2021, that number is expected to exceed <a href="https://www.strategyand.pwc.com/m1/en/press-releases/2020/gcc-gaming-market.html">$821 million</a>, boosted in part by the pandemic-induced lockdown.&nbsp;</p>



<p>Saudi Arabia expects to be at the forefront<strong> </strong>of that expansion. In a country where roughly 50% of the population is under 30, gaming has become an emblem for a generation of young Saudis.&nbsp;</p>



<p>In recent years, Prince Faisal bin Bandar, a young member of the royal family raised on Atari consoles, set out to make Saudi Arabia the Middle East’s hub for the $160 billion gaming industry. Under his leadership, the<strong> </strong><a href="https://safeis.sa/">Saudi Arabian Federation for Electronic and Intellectual Sports (SAFEIS)</a> aims for esports revenue to amount to 1% of the country’s GDP (approximately $22 billion) by 2030.</p>



<p>While Saudi Arabia was a late arrival to esports, its male players have already made their mark. Since 2017, Prince Faisal and the federation have been scouting, coaching, and sending professional esports players to competitions across the world. Mossad Al-Dossary, then 18, made headlines in 2018 after <a href="https://www.ea.com/games/fifa/news/msdossary-triumphs-fifa-eworld-cup-grand-final-london">winning first place</a> at the FIFA eWorld Cup in London, taking home a $250,000 cash prize.&nbsp;</p>



<p>Female gamers, however, are still finding their way. Women in Felwa, Tasnim, and Najla’s generation grew up under the watch of religious police, in a time when public spaces were segregated by gender. While women still do not have the same rights as men, Crown Prince Mohammed bin Salman<strong> </strong>has relaxed male-guardianship rules and mandatory dress codes and legalized certain forms of entertainment for women. “I still struggle to convey what Saudi Arabia was like at that time to those that haven’t had that experience,” Tess said. There were no theaters, and sports facilities for girls were limited, “So, mostly, we had to stay inside and make do with what we had — and games were all that we had.”</p>



<p>Raghad, 23, currently works for a mining company, but she dreams of becoming a voice actor for video games. Although she’s never lived anywhere but Saudi Arabia, she has a distinctly squeaky American accent — a curious trait she picked up from a fifth-grade teacher who had lived in the U.S. and a torrent of YouTube videos. She is considering taking voice-acting classes online, assuming she can find any, because she’s not allowed to travel abroad alone to study until after she’s married. It’s still common to meet women who come to gaming as a result of these kinds of restrictions, as Felwa, Tasnim, and Najla did years ago. This is why going to GCON can be such a powerful experience.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1010892174-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1010892174-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1010892174-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1010892174-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1010892174-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1010892174-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Mossad Al-Dossary (right) made headlines in 2018 after winning first place at the FIFA e-World Cup in London, taking home a $250,000 cash prize.&nbsp;">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Ben Hoskins/FIFA via Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p><strong>In 2018, Felwa,</strong> Tasnim, and Najla handed GCON over to Ghada Al-Moqbel, who attended her first GCON in 2013 at the age of 18. Now she leads Saudi Arabia’s women’s gaming community. This occurred right after bin Salman took control and began dismantling the country’s gender segregation. For Ghada and the wider community of female gamers, these changes forced them to decide whether they wanted to stay on the fringes of the gaming community or take a more central role. In 2018, GCON organizers met regularly to discuss whether there was still value in creating an exclusively female space for gaming.</p>



<figure><blockquote><p>“We had to stay inside and make do with what we had — and games were all that we had.”</p></blockquote></figure>



<p>For Ghada, the answer was yes. While attitudes toward female gamers have improved, parts of Saudi society remain uncomfortable with this burgeoning culture. When GCON first launched, participants were criticized for indulging in supposedly immoral behavior, and social media accounts of female gamers were routinely hacked. Likewise, after the first Comic Con in Jeddah, in 2017, a<a href="https://twitter.com/hashtag/%D9%83%D9%88%D9%85%D9%8A%D9%83%D9%88%D9%86_%D8%AD%D9%81%D9%84_%D8%B9%D8%A8%D8%AF%D8%A9_%D8%A7%D9%84%D8%B4%D9%8A%D8%B7%D8%A7%D9%86_%D8%A8%D8%AC%D8%AF%D9%87?src=hashtag_click"> hashtag</a> accusing participants of being Satan worshippers flooded social media along with pictures of women who had dressed up for cosplay. Thanks in part to the continuing fear of societal backlash, many Saudi women still advocate for all-female events.&nbsp;</p>



<p>But like the kingdom, GCON is also evolving. “We’re not just entertainment anymore,” Ghada said. “It’s about empowering and enabling women to be serious in the gaming and esports industry.” In mid-August, Princess Nourah bint Abdulrahman University, the largest women-only university in the world, <a href="https://www.arabnews.com/node/1718151/saudi-arabia">announced</a> that it would be creating a degree program for animation.</p>



<p>Since Ghada took over, the organization has expanded, hosting regular skill-development workshops as well as the annual convention. While she has maintained GCON’s focus on female gamers, she has been open to collaborating with their male peers. In 2017, organizers from Gamer’s Day worked with GCON to arrange their first mixed-gender gaming event. While 2020 was supposed to be a big year for Ghada and GCON, Covid-19 disrupted their plans. Nonetheless, it’s unlikely that GCON — a force that arose in far more challenging terrain — will be going away anytime soon.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/you-just-got-pwned-habibi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24316556</guid>
            <pubDate>Sat, 29 Aug 2020 15:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's the programming environment, not the programming language]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24315585">thread link</a>) | @panic
<br/>
August 29, 2020 | https://thesephist.com/posts/programming-environment/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/programming-environment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>It’s common to talk about the way we build software in terms of the individual tools we compose together, like command-line utilities and deployment pipelines and containers and services, and most obviously, <em>programming languages</em>. Programming languages seem to get the highest level of scrutiny out of everything that comprises the way we write software. And in the last decade, I think we’ve seen a healthy rejuvenation of innovation in programming languages, driven by languages like Rust, Go, OCaml, Zig, and Swift that bring new ideas to the industrial programming world in practical packages.</p>
<p>But while programming languages are academically interesting, I think <strong>we more desperately need innovation in programming <em>environments</em></strong>.</p>
<p>The programming <em>environment</em> isn’t a single component of our workflow, but the total sum enabled by the tools working together harmoniously. The environment contains the programming language, but also includes the debugging experience, dependency management, how we communicate with other developers (both within source code and without), how we trace and observe code in production, and everything else in the process of designing APIs to recovering from failure.</p>
<p>The story of programming language evolution is also a story of rising ideas in what capabilities good programming <em>environments</em> should grant developers. Many languages came to popularity not necessarily based on their merits as great languages, but because they were paired with some new and powerful capability to understand software and write better implementations of it.</p>
<p>C brought practical portability to (what was at the time) high level programs. C literally elevated the programming environment out of processor-specific assembly code into a common vernacular. The legacy is so strong that most languages we use in production today are either direct descendants of C, or inherit much of their syntax, like curly brace-delineated blocks and structures, semicolon statement-terminators, and parenthesized function calls.</p>
<p>JavaScript is popular outside of the browser almost entirely on the merit of its ecosystem, its tooling, and the trivial debugging experience enabled by the repl. JavaScript’s programming environment is entirely interactive, visual, and real-time, without the need for clunky debugging apparatuses. The impact of that interactivity is obvious in the fact that many of my developer friends started programming on the Web, explicitly because it was the easiest way to write programs that produced output we could see and share.</p>
<p>One of Go’s claims to fame and primary design goals is compilation speed. Compared to its predecessor C++, Go compiles fast. And when you make something fast, people start to use it differently.</p>
<p>Erlang, with its <a href="https://www.erlang.org/">advanced, concurrent, message-passing runtime</a>, offers a better way to build high availability, highly reliable systems. It was born in the telecom industry, but has found home in many other critical services industries.</p>
<p>Thoughtfully crafted programming environments are the hidden treasures of the software industry. When we choose a language because of the “tooling” or because of the “IDE experience” or because of “the workflow,” what we are really doing is making a judgement about the programming <em>environment</em> we want to live in and grow around our work.</p>
<p>Between investments being made into new languages and the community’s willingness to experiment, there’s a lot of creative energy being poured into inventing better languages. I think it would serve us well if we invested just as deeply into rethinking the context in which we write those programs. We should be asking questions like:</p>
<ul>
<li>While professional photo editors and video games can run in the browser, why are we still using a repl that prints lines in the terminal?</li>
<li>Does the compile-time / run-time distinction make sense to have? Can we give better control to developers about when their code is executed during the software development and deployment process?</li>
<li>What does an operating system kernel designed for debugging experience look like?</li>
<li>What does a memory model or memory allocator designed for debugging experience look like?</li>
<li>Are the tools we have today good enough foundations for massive open-source communities like NPM? How can we improve the programming environment and our tools to make the most of package repositories with hundreds of millions of libraries and billions of lines of code?</li>
</ul>
<p>There are some people trying to create better programming environments. <a href="https://repl.it/">Repl.it</a> brings general purpose development to the browser. Experiments like <a href="http://lighttable.com/">Light Table</a> more closely integrate source code with its output. Jupyter notebooks are a unique way of writing and sharing code that focus on the process of iteration.</p>
<p>But these are also workflows and tools built around languages that were never designed for such interactive experiences. I think if we build a culture of thinking about programming environments as a place ripe for creative innovation, we’ll see a new class of software development tools emerge that make the most of today’s machines and networks and allow us to write new kinds of software we couldn’t before.</p>

        <hr>
        <p>
            If you enjoyed this piece, you might also enjoy
            
            my next post,
            <a href="https://thesephist.com/posts/tech-industry-change/"><em>On leading change in the tech industry</em></a>.
            
        </p>
        <p>
            I share new posts like this on my <a href="https://thesephist.com/#newsletter">newsletter.</a>
            If you liked this post, you should consider joining the list.
        </p>
        <p>Have a comment or response? You can <a href="https://thesephist.com/#contact">email me.</a></p>
    </article></div>]]>
            </description>
            <link>https://thesephist.com/posts/programming-environment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24315585</guid>
            <pubDate>Sat, 29 Aug 2020 12:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't trust default timeouts]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24315239">thread link</a>) | @kiyanwang
<br/>
August 29, 2020 | https://robertovitillo.com/default-timeouts/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/default-timeouts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>May 03, 2020</p></header><p>Modern applications don’t crash; they hang. One of the main reasons for it is the assumption that the network is reliable. It isn’t. </p><p>When you make a network call without setting a timeout, you are telling your code that you are 100% confident that the call is going to succeed. Would you really take that bet?</p><p>If you are a making synchronous network call that never returns, then to very least your thread hogs forever. Whoops. Asynchronous network calls that don’t return are not free either. Sure, you are not hogging threads, but you are leaking sockets. Any HTTP client library worth its salt uses socket pools to <a href="https://en.wikipedia.org/wiki/HTTP_persistent_connection">avoid recreating connections</a>. And those pools have a limited capacity. Like any other resource leak, it’s only a matter of time until there are no sockets left. When that happens, your application is going to get stuck waiting for a connection to free up.</p><p>If the network is not reliable, why do we keep creating APIs that have infinity as the default timeout? Some APIs don’t even have a way to set a timeout in the first place! A good API should be easy to use the right way and hard to use the wrong way. When the default timeout is infinity, it’s all too easy for a client to shoot itself in the foot. </p><p>If you remember one thing from this post, then let it be this: <strong>never use “infinity” as a default timeout</strong>.</p><p>Let’s take a look at some concrete examples.</p><p>Javascript’s XMLHttpRequest is THE web API to retrieve data from a server asynchronously. Its <a href="https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/timeout">default timeout is zero</a>, which means there is no timeout!</p><div data-language="javascript"><pre><code><span>var</span> xhr <span>=</span> <span>new</span> <span>XMLHttpRequest</span><span>(</span><span>)</span><span>;</span>
xhr<span>.</span><span>open</span><span>(</span><span>'GET'</span><span>,</span> <span>'/api'</span><span>,</span> <span>true</span><span>)</span><span>;</span>


xhr<span>.</span>timeout <span>=</span> <span>10000</span><span>;</span> 

xhr<span>.</span><span>onload</span> <span>=</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
 
<span>}</span><span>;</span>

xhr<span>.</span><span>ontimeout</span> <span>=</span> <span>function</span> <span>(</span><span>e</span><span>)</span> <span>{</span>
 
<span>}</span><span>;</span>

xhr<span>.</span><span>send</span><span>(</span><span>null</span><span>)</span><span>;</span>
</code></pre></div><p>Client-side timeouts are as crucial as server-side ones. There is a <a href="https://hpbn.co/primer-on-browser-networking/#connection-management-and-optimization">maximum number of sockets your browser</a> can open for a particular host. If you make network requests that never returns, you are going to exhaust the socket pool. When the pool is exhausted, you are no longer able to connect to the host. </p><p>The fetch web API is a modern replacement for the XMLHttpRequest API, which uses Promises. When the API was initially introduced, there was <a href="https://github.com/whatwg/fetch/issues/951">no way to set a timeout at all</a>! Browsers have recently added experimental support for the <a href="https://developer.mozilla.org/en-US/docs/Web/API/AbortController">Abort API</a> to support timeouts, though.</p><div data-language="javascript"><pre><code><span>const</span> controller <span>=</span> <span>new</span> <span>AbortController</span><span>(</span><span>)</span><span>;</span>

<span>const</span> signal <span>=</span> controller<span>.</span>signal<span>;</span>

<span>const</span> fetchPromise <span>=</span> <span>fetch</span><span>(</span>url<span>,</span> <span>{</span>signal<span>}</span><span>)</span><span>;</span>  


<span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> controller<span>.</span><span>abort</span><span>(</span><span>)</span><span>,</span> <span>10000</span><span>)</span><span>;</span> 

fetchPromise<span>.</span><span>then</span><span>(</span><span>response</span> <span>=&gt;</span> <span>{</span>
 
<span>}</span><span>)</span>
</code></pre></div><p>Things aren’t much rosier in Python-land. The requests library uses a default timeout of <a href="https://requests.readthedocs.io/en/master/user/quickstart/#timeouts">infinity</a>. </p><div data-language="python"><pre><code>
response <span>=</span> requests<span>.</span>get<span>(</span><span>'https://github.com/'</span><span>,</span> timeout<span>=</span><span>10</span><span>)</span></code></pre></div><p>What about Go? Go’s HTTP package <a href="https://github.com/golang/go/issues/24138">doesn’t use timeouts</a> by default either. </p><div data-language="go"><pre><code><span>var</span> client <span>=</span> <span>&amp;</span>http<span>.</span>Client<span>{</span>
  
  Timeout<span>:</span> time<span>.</span>Second <span>*</span> <span>10</span><span>,</span> 
<span>}</span>

response<span>,</span> <span>_</span> <span>:=</span> client <span>.</span><span>Get</span><span>(</span>url<span>)</span></code></pre></div><p>Modern HTTP clients for Java and .NET do a much better job and usually, come with default timeouts. For example, .Net Core’s HttpClient has a default timeout of <a href="https://docs.microsoft.com/en-us/dotnet/api/system.net.http.httpclient.timeout?view=netcore-3.1#remarks">100 seconds</a>. It’s lax but much better than no timeout at all. That comes as no surprise since those languages are used to build large scale distributed systems that need to be robust against network failures. Network requests without timeouts are the <a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">top silent killer</a> of distributed systems.</p><h3 id="remember-this"><a href="#remember-this" aria-label="remember this permalink"></a>Remember this</h3><p>As a rule of thumb, always set timeouts when making network calls. And if you build libraries, always set reasonable default timeouts and make them configurable for your clients.</p><p>Do you want to learn more about stability patterns and anti-patterns of distributed systems? Check out my <a href="https://systemdesignmanual.com/">upcoming book</a>.</p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/default-timeouts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24315239</guid>
            <pubDate>Sat, 29 Aug 2020 10:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Literate DevOps]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24315057">thread link</a>) | @geocar
<br/>
August 29, 2020 | http://www.howardism.org/Technical/Emacs/literate-devops.html | <a href="https://web.archive.org/web/*/http://www.howardism.org/Technical/Emacs/literate-devops.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<header>

</header><p>
((tl;dr See <a href="https://www.youtube.com/watch?v=dljNabciEGg">my video presentation/demonstration</a> of this essay))
</p>

<p>
Maintaining servers falls into two phases:
</p>

<ol>
<li>Bang head until server works</li>
<li>Capture effort into some automation tool like Puppet or Chef.</li>
</ol>

<p>
Recently, I’ve been playing around with making the first phase closer
to the second.  For lack of a better word, I’m calling it <i>literate
devops</i>.
</p>

<p>
I’ve talked about using <a href="http://www.howardism.org/Technical/LP/introduction.html">org-mode’s <i>literate programming</i> model</a> to
investigate new ideas and crystallize thoughts, and this approach
appears to work well for me since I lack those esoteric sysadmin
skills.
</p>

<div id="outline-container-orgbcbce75">
<h2 id="orgbcbce75">Tell us a Story</h2>
<div id="text-orgbcbce75">
<p>
Once upon a time, I was tasked with patching an RPM, which is not in
my comfort zone, so my initial plan of attack was:
</p>

<ol>
<li>Use Vagrant to create a disposable CentOS system</li>
<li>SSH into this virtual machine to download needed tools</li>
<li>Run various unknown commands</li>
<li>Rinse and repeat this step until successful</li>
</ol>

<p>
Of course, once I figure out the solution, I need to document it for
others on my team, and maybe create a <i>repeatedable</i> script.
</p>

<p>
First step is well documented elsewhere, but today I learned (TIL)
you can <code>ssh</code> directly to your Vagrant-based virtual machine with
this little magic (<b>Note:</b> <i>client</i> is the name of my virtual
machine I specified in the <code>Vagrantfile</code>):
</p>

<div>
<pre>vagrant ssh-config --host clientvm &gt;&gt; $<span>HOME</span>/.ssh/config
</pre>
</div>

<p>
This command appends some lovely host-connection magic so you can
issue: <code>ssh clientvm</code>
</p>
</div>
</div>

<div id="outline-container-org8dff3db">
<h2 id="org8dff3db">Literate Devops</h2>
<div id="text-org8dff3db">
<p>
Instead of opening up a terminal to my virtual machine, I pop into
Emacs and load this sprint’s <i>note file</i><sup><a id="fnr.1" href="#fn.1">1</a></sup>, create a new header,
and enter the shell and ruby commands in this text file.
</p>

<p>
What good is this? Unlike a traditional terminal, this allows me to
<i>log</i>, <i>document</i> and <i>execute</i> each command.
</p>

<p>
For instance, here is a screen-shot of a section of my Emacs buffer:
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops.png" alt="literate-devops.png">

</figure>

<p>
As an old bear with very little brains, my prose can explain the
background and purpose of each command.  Clicking the hyperlink
refreshes my memory of previous discoveries. A keychord <i>executes</i>
the code block…
</p>

<p>
Yes. I execute the commands from within Emacs.
</p>

<p>
Hitting <code>C-c C-c</code> (Control-C twice) runs the code (based on the
language).  This example runs in the shell. The results are placed
back into the file, which can be used by other code blocks (and <a href="http://orgmode.org/manual/results.html#results">many
other options</a>).
</p>

<p>
For instance, here is the first half of a section for downloading
the GPG Keys from a repository (the URL is placed in a <i>property</i>
that is shared among all code blocks in his section):
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-14.png" alt="literate-devops-14.png">

</figure>

<p>
The Shell script block (in the center of the screen-shot) uses
<code>wget</code> to download the HTML index file and parse and extract the key
file URLs.  We’ll have a Ruby script do that parsing, and since the
script may be a bit hairy, we’ll define it in another code block.
</p>

<p>
One technique from <a href="http://www.howardism.org/Technical/LP/introduction.html">literate programming</a> is the idea that one code
block can be inserted into another block (the reference is a name
within double angle brackets, <code>&lt;&lt;...&gt;&gt;</code>). Donald Knuth called this
feature WEB. Since it can accidentally conflict with some languages
(like Ruby), I have it off by default, but turn it on for this block
with the <code>noweb</code> parameter.
</p>

<p>
Here is the Ruby script. Having it in a separate Ruby-specific code
block allows me to turn on all the Ruby magic that Emacs can muster.
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-15.png" alt="literate-devops-15.png">

</figure>

<p>
The last step is to take the URLs produced by the first script and
feed them to another Shell script that will call <code>wget</code> to download
each:
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-16.png" alt="literate-devops-16.png">

</figure>

<p>
The <code>key-list</code> was the name of our original code block, as well as
the name of its results. We assign that list of results to a
variable, <code>LIST</code> that the shell script would access as <code>$LIST</code>.
</p>

<p>
This example demonstrated how literate programming can weave code
and data through different languages.
</p>
</div>
</div>

<div id="outline-container-org5d7bdd1">
<h2 id="org5d7bdd1">What about the Virtual Machine?</h2>
<p>
Normally, specifying <code>sh</code> as the code block’s <i>language</i>, tells
Emacs to run the code in my local system’s shell, but in this case,
I want it ran on my virtual machine (or on my development server in
my lab). I’ll describe two options for doing this, using <a href="http://www.emacswiki.org/TrampMode">Tramp</a> and
Babel Sessions.
</p>

<div id="outline-container-org2251b72">
<h3 id="org2251b72">Tramp to the Rescue</h3>
<div id="text-org2251b72">
<p>
Tramp is an Emacs feature that allows one to edit a file on a
remote machine using <code>ssh</code> and other protocols. For instance,
running the <code>find-file</code> function (bound to <code>C-x C-f</code>) lets you type
something like:
</p>

<pre>/ssh:howard.abrams@goblin.howardism.org:web/files/robot.txt
</pre>

<p>
If you put the following in your <code>.emacs</code> initialization file:
</p>

<div>
<pre><span>(</span><span>setq</span> tramp-default-method <span>"ssh"</span><span>)</span>
</pre>
</div>

<p>
And update your <code>~/.ssh/config</code> file to know what user account goes
with the host name, the file reference above can be shorten to:
</p>

<pre>/goblin.howardism.org:web/files/robot.txt
</pre>

<p>
Emacs looks for the <code>:</code> character to determine if Tramp should be
invoked.  Tramp uses SSH keys if available, or will prompt you for
a password if needed.
</p>


<p>
Each org-mode code block can specify a <code>:dir</code> option that specifies
where the code snippet should run, for instance, the following
blocks are equivalent:
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-9.png" alt="literate-devops-9.png">

</figure>

<p>
The <code>:dir</code> option allows full Tramp functionality, allowing me to
run a block on a different machine. Remember how I added my
<code>client</code> Vagrant virtual machine to my <code>~/.ssh/config</code> file?
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-10.png" alt="literate-devops-10.png">

</figure>

<p>
<i>But I need access to my machine behind a firewall!?</i>
</p>

<p>
My job deals with virtual machines running in a highly protected
data center, where I need to first log into jump boxes and bastion
machines. Tramp handles these sorts of hops. For instance:
</p>

<pre>/ssh:10.98.18.229|ssh:10.0.1.122|sudo:/etc/network/interfaces
</pre>

<p>
Uses my account name to log into the bastion machine, and
then uses my account name to <code>ssh</code> into a virtual machine running
in a private cloud. And then uses the <code>sudo</code> command to let me edit
a file owned by <code>root</code>.
</p>

<p>
Tramp pipe references works with the <code>:dir</code> option for <code>org-mode</code>
source blocks:
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-11.png" alt="literate-devops-11.png">

</figure>

<p>
Few tricks to keep in mind:
</p>

<ul>
<li>All but the last hop uses a pipe character, |, instead of the
colon character, :</li>
<li>If you use the pipe character, you need to specify all
protocols, like <code>ssh</code>, even if it is the default.</li>
<li>If your local machine’s operating system is different than the
machine you are connecting to, you need to fix a bug in
<code>org-mode</code>, which I can show you how to fix<sup><a id="fnr.2" href="#fn.2">2</a></sup>.</li>
</ul>
</div>
</div>

<div id="outline-container-org0d027af">
<h3 id="org0d027af">Using org-mode Sessions</h3>
<div id="text-org0d027af">
<p>
Another approach is to create a <i>session</i> that connects different
code blocks together. Each screen shot below, each code block below
has the same <code>session</code> value, <code>client</code> (which is conveniently the
same my virtual machine’s hostname, <code>client</code>):
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-2b.png" alt="literate-devops-2b.png">

</figure>

<p>
If I execute the first block, a <i>shell</i> is started in the
background, and it ssh’s into the machine. Note, to get this
working, you need to enable <i>password-less access</i> by placing your
SSH’s public key into the remote system’s <code>.ssh/authorized_keys</code>
file, or using the <code>ssh</code> Emacs package.<sup><a id="fnr.3" href="#fn.3">3</a></sup>
</p>

<p>
From this point on, each code block I execute with the <code>client</code>
session value, uses this connection, and the code is executed on the
remote machine (a virtual machine in this case, but that doesn’t
matter).
</p>

<p>
Either of these approaches works well, but the second approach,
allows me to set variables to create a particular state that other
blocks may expect.  However, this requires execution of each block in
order.
</p>

<p>
I have a third, more interactive, approach<sup><a id="fnr.4" href="#fn.4">4</a></sup> using <code>screen</code>, but
it doesn’t allow passing variables to the code, and as you’ll see
below, this is pretty important to me.
</p>


<p>
Regardless, I continue learning how to accomplish my goal, all the
while documenting and <i>validating</i> my steps. The end result can be
exported to web or wiki page.
</p>
</div>
</div>
</div>

<div id="outline-container-org39ccdca">
<h2 id="org39ccdca">What about Verbose Commands?</h2>
<div id="text-org39ccdca">
<p>
Yes, executing some commands can be quite time-consuming and
verbose, but often I need to search the results, and having the
results placed in an Emacs buffer allows better searching.
</p>

<p>
Often I use a collapsible “drawer” (which is just a way to identify
the beginning and end of the output):
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-3.png" alt="literate-devops-3.png">

</figure>

<p>
Place the cursor on this drawer and hit the <code>Tab</code> key to hide or
show the output:
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-4.png" alt="literate-devops-4.png">

</figure>
</div>
</div>

<div id="outline-container-org3721d6c">
<h2 id="org3721d6c">Can you Use the Output?</h2>
<div id="text-org3721d6c">
<p>
The results of some commands are often needed for the next command,
and I’m sure you just love using your mouse to copy and paste part
of the output, but I have a better way.
</p>

<p>
For instance, I needed a list of an RPM’s dependencies:
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-5.png" alt="literate-devops-5.png">

</figure>

<p>
Notice I <i>named</i> this source code block. Also notice how Emacs
automatically broke the results up into a table. By default, the
output from shell commands are split along newlines and
spaces.
</p>

<p>
I can feed the results of these execution to another code block.
The following source block creates a variable named <code>DEPENDS</code> that
uses rows 2 through 10 of the first column as an array.
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-6.png" alt="literate-devops-6.png">

</figure>

<p>
I then download the RPMs I want without any mouse interaction.
</p>
</div>
</div>

<div id="outline-container-orgdfa5caa">
<h2 id="orgdfa5caa">Setting Variables and Values</h2>
<div id="text-orgdfa5caa">
<p>
A key aspect of reusing devops programs (like a Chef
cookbooks) is the separation of the <i>code</i> from the <i>values</i> the code
uses…a key aspect of <i>any</i> program you reuse.
</p>

<p>
In my world, I create a new <code>org-mode</code> file for each sprint, and
each task or problem gets its own header and section. Each section
can have a <i>drawer</i> of properties, including variables shared among
all code blocks in that section.
</p>

<p>
To create a <i>section variable</i>, simply hit: <code>C-c C-x p</code>, and set the
<code>Property</code> to <code>var</code> and the value to a <i>variable=value</i>, as in:
</p>



<p>
This drawer can contain any code block values you wish, like
<code>session</code> or <code>results</code>. These values can then be overridden as
settings on the code block, as you see in this screen-shot:
</p>


<figure>
<img src="http://www.howardism.org/Technical/Emacs/literate-devops-8.png" alt="literate-devops-8.png">

</figure>

<p>
Setting variables and settings (especially the <code>session</code> setting),
ties the code blocks together.
</p>
</div>
</div>

<div id="outline-container-org874102b">
<h2 id="org874102b">Communicating with Others</h2>
<div id="text-org874102b">
<p>
While investigations in operations and administrations (as I’ve
described) are useful to oneself when understanding the problem
domain, I need to communicate the results with my team mates.
Since my <a href="https://github.com/howardabrams/dot-files/blob/master/emacs-mail.org#sending-email">Emacs configuration</a> allows me to send mail messages, I kick
off the function, <code>org-mime-org-buffer-htmlize</code>, which exports the
<code>org-mode</code> file to an HTML mail message (This function is part of
the latest <code>org-plus-contrib</code> package).
</p>

<p>
However, some times the exported results are not quite perfect.
</p>

<p>
For instance, some blocks may result in some JSON data, and since</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.howardism.org/Technical/Emacs/literate-devops.html">http://www.howardism.org/Technical/Emacs/literate-devops.html</a></em></p>]]>
            </description>
            <link>http://www.howardism.org/Technical/Emacs/literate-devops.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24315057</guid>
            <pubDate>Sat, 29 Aug 2020 10:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An overview of the science on function length]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24315032">thread link</a>) | @tziki
<br/>
August 29, 2020 | https://softwarebyscience.com/very-short-functions-are-a-code-smell-an-overview-of-the-science-on-function-length/ | <a href="https://web.archive.org/web/*/https://softwarebyscience.com/very-short-functions-are-a-code-smell-an-overview-of-the-science-on-function-length/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the first part of a blog series where I examine programming concepts from a scientific perspective. In this part I dig up every study relating to function length I could find, fill in some gaps with original research, and examine what we can learn.</p>



<p>Highlights:</p>



<ul id="block-f6ddbfdc-f37f-48df-8d67-6990d4b79de3"><li>We find that in older studies (pre-2000) short functions correlate with higher defect density</li><li>There seem to be no post-2000 studies exclusively focusing on function length, but through original research we find that modern code bases exhibit similar behavior</li><li>We also find that in empirical experiments short functions make code slower to debug, with some weaker evidence suggesting they also make it slower for adding new features but faster to modify</li></ul>



<p><strong>Introduction</strong></p>



<p>In programming lore it’s hard to find sources glorifying long functions. This is codified, for example, in the widely quoted book ‘Clean Code’ which states:</p>



<blockquote><p>The first rule of functions is that they should be small. The second rule of functions is that they should be smaller than that. Functions should not be 100 lines long. Functions should hardly ever be 20 lines long</p></blockquote>



<p>Favoring short functions isn’t by any means a new practise – a 1986 study “An Empirical Study of Software Design Practices” states “keeping modules small” as a good design practise. They also quote a book from 1974, stating “many programming standards limit module size to one page (or 50-60 source lines of code)”.</p>



<p><strong>What is a small function?</strong></p>



<p>What was meant by shorts functions in the 80s is different from small functions of today. In a study from 1991 ([1]) the line between small and large functions is drawn at 142 lines, staggeringly long by modern standards. In the same vein, a study from 1984 groups functions into buckets by increments of 50 lines ([2]).</p>



<p>However, nowadays the vast majority of functions are under 50 lines. A quick analysis of Eclipse, a popular open source IDE, reveals it averages about 8.6 lines per method in its source code. Above mentioned book “Clean Code”, published in 2008, states that functions should rarely be more than 20 lines, and the author has stated in other contexts he often prefers to use single-line functions, and that about half of the functions written by the author in Ruby are single-liners.</p>



<p>This shift in function sizes is perhaps partially due to changes in programming languages. In the 80s a Fortran “module” was commonly considered a function and some variables&nbsp; (see eg. <a href="https://www.tutorialspoint.com/fortran/fortran_modules.htm">https://www.tutorialspoint.com/fortran/fortran_modules.htm</a>) and function was the basic building block of software, whereas nowadays most Java or C++ programmers would define “module” as a class consisting of multiple functions.</p>



<p>Many studies focus on analyzing module sizes without specifying what a module is, so I’ve only included studies which specifically state they analyze functions. This, combined with the change in what we consider a basic building block of software, combined with the historical shift in function sizes, makes it hard to properly analyze and aggregate the studies, but we can certainly try.</p>



<p><strong>Function length and defect density – pre-2000</strong></p>



<p>The first studies concerning the length of functions I could find were from the early 80s. Nowadays most studies examine the code on a class and package level, whereas in the 80s object oriented programming was still quite rare and functions were the main building blocks of software, so it made a lot of sense to examine functions and their error proneness.</p>



<p>The early research on function length and defect density found that very small functions tended to have higher defect densities. This has been cited in “Code Complete”, where Steve McConnell says: “The routine should be allowed to grow organically up to 100-200 lines, decades of evidence say that routines of such length no more error prone then shorter routines.” Further, he gives a reference to a study that says routines 65 lines or longer are cheaper to develop. (see appendix for a more extensive take on the studies used in Code Complete)</p>



<p>To dive further, a study from 1984 ([2]) grouped function to buckets with increments of 50 lines and measured the error density for each bucket. They found that smaller functions contained, on average, more defects per line:</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-23-at-7.43.50-PM.png?resize=553%2C258&amp;ssl=1" alt="" width="553" height="258" srcset="https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-23-at-7.43.50-PM.png?resize=1024%2C480&amp;ssl=1 1024w, https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-23-at-7.43.50-PM.png?resize=300%2C141&amp;ssl=1 300w, https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-23-at-7.43.50-PM.png?resize=768%2C360&amp;ssl=1 768w, https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-23-at-7.43.50-PM.png?w=1382&amp;ssl=1 1382w, https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-23-at-7.43.50-PM.png?w=1280&amp;ssl=1 1280w" sizes="(max-width: 553px) 100vw, 553px" data-recalc-dims="1"><figcaption>Table outlining function length and defect density in [2]</figcaption></figure></div>



<p>A follow-up study ([3]) examined five Fortran projects, and states that “no significant relationship was found between module size and fault rate“ even though, in the same paragraph, the authors also state that “nevertheless, [small modules] exhibited the highest average fault rate because a small module with even a single fault will show a very high fault rate“. It’s not clear why the authors state that module size and fault rate has no significant relationship and then state that average fault rate is highest for small modules. Another conclusion from [3] is that larger functions are cheaper to develop.</p>



<p>A third empirical study ([1]) analyzed 450 routines and found that “small” routines (those with fewer than 143 source statements, including comments) had 23 percent more errors per line of code than larger routines but were 2.4 times less expensive to fix than larger routines. This is interesting since it contrasts with some other experimental results we’ll see later.</p>



<p>So far it appears short functions are correlated with higher defect density, but due to the large sizes of the examined functions you’d be forgiven for doubting the relevance of these studies to modern software engineering.</p>



<p><strong>Modern defect prediction literature</strong></p>



<p>Modern defect prediction approaches are characterized by large data sets and machine learning methods applied on them. They mainly concentrate on correlating features such as “average method length” and “lines of code” with defects in an attempt to create defect prediction models.</p>



<p>Several such studies have found a correlation between size of methods and defects. For example [4] found that the size of the longest method in a class correlates positively with post-relase defects. Does this mean we should refactor our long methods into short ones to avoid defects?</p>



<div><figure><img loading="lazy" width="640" height="63" src="https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?resize=640%2C63&amp;ssl=1" alt="" srcset="https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?resize=1024%2C101&amp;ssl=1 1024w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?resize=300%2C30&amp;ssl=1 300w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?resize=768%2C76&amp;ssl=1 768w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?resize=1536%2C152&amp;ssl=1 1536w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?resize=2048%2C203&amp;ssl=1 2048w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?resize=1568%2C155&amp;ssl=1 1568w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?w=1280&amp;ssl=1 1280w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.02.36-PM.png?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption>The maximum length of function correlates with defects in [4]</figcaption></figure></div>



<p>Turns out the answer is no. In those same studies, the number of methods also correlates with defects:</p>







<div><figure><img loading="lazy" src="https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?resize=640%2C61&amp;ssl=1" alt="" width="640" height="61" srcset="https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?resize=1024%2C98&amp;ssl=1 1024w, https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?resize=300%2C29&amp;ssl=1 300w, https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?resize=768%2C73&amp;ssl=1 768w, https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?resize=1536%2C146&amp;ssl=1 1536w, https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?resize=2048%2C195&amp;ssl=1 2048w, https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?resize=1568%2C149&amp;ssl=1 1568w, https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?w=1280&amp;ssl=1 1280w, https://i0.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-22-at-4.01.53-PM.png?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption>The number of functions in a class also correlates with defects. [4]</figcaption></figure></div>



<p>To put it plainly, if we have a long function and split it into smaller ones, we’re not removing a source of defects, but we would simply be switching from one to another.</p>



<p>The same effect can be seen in other defect prediction studies. For example in [5] we see that both “Weighted Methods per Class” and “Average Method Complexity” correlate with defects, where former is defined as “number of methods in the class” and latter as “the average method size for each class“.</p>



<p>In both studies both metrics have a statistically significant correlation with defects, and this appears to be the trend across many other studies in defect prediction literature.</p>



<p>The literature doesn’t provide a straightforward way to measure which feature (length or number of methods) is more significant when predicting defects. It’s quite possible that, for example, measures such as “average method complexity” and “number of methods in a class” simply act as 2nd order estimators for number of lines, in which case we’d simply be comparing which measure correlates better with the underlying metric.</p>



<p>In addition, we’re interested in examining the length of the functions on a more granular level. Finding out that the number of methods and the length of methods both correlate with defects doesn’t give us anything tangible, and doing this sort of class or module level correlation analysis doesn’t get us very far.</p>



<p>However, the datasets used in many of these studies are open and we can download them to try to examine the relationship between functions length and defects ourselves.</p>



<p><strong>Data set analysis</strong></p>



<p>Time to scare the wikipedia editors among you and do some original research. All the code and data can be found at <a href="https://github.com/softwarebyscience/function-length/">https://github.com/softwarebyscience/function-length/</a>.</p>



<p>I took two datasets which contained the features we are interested in, such as the number of methods and lines of code per class. The first dataset I worked with is simply called “Eclipse Bug Database” and it contained data from three major Eclipse releases ([7]).</p>



<p>In addition, I used the “Bug Prediction Dataset” from <a href="http://bug.inf.usi.ch/download.php">http://bug.inf.usi.ch/download.php</a> as it seemed larger than the Eclipse Bug Database. The data is collected between 2005 and 2009 from 5 different Java projects – for a more detailed explanation see [6].</p>



<p>The results from the first dataset are quite straightforward:</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.13.53-PM.png?resize=511%2C375&amp;ssl=1" alt="" width="511" height="375" srcset="https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.13.53-PM.png?resize=1024%2C752&amp;ssl=1 1024w, https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.13.53-PM.png?resize=300%2C220&amp;ssl=1 300w, https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.13.53-PM.png?resize=768%2C564&amp;ssl=1 768w, https://i2.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.13.53-PM.png?w=1174&amp;ssl=1 1174w" sizes="(max-width: 511px) 100vw, 511px" data-recalc-dims="1"></figure></div>



<p>Here smaller methods clearly have a higher defect density, with the minimum defect density roughly found in classes where the methods average around 10-15 lines. What’s perhaps hard to see from the chart is that defect density starts very slightly increasing towards the right.</p>



<p>The results from the second dataset are a bit more interesting (moving average in red):</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.15.45-PM.png?resize=502%2C367&amp;ssl=1" alt="" width="502" height="367" srcset="https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.15.45-PM.png?resize=1024%2C750&amp;ssl=1 1024w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.15.45-PM.png?resize=300%2C220&amp;ssl=1 300w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.15.45-PM.png?resize=768%2C563&amp;ssl=1 768w, https://i1.wp.com/softwarebyscience.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-24-at-9.15.45-PM.png?w=1168&amp;ssl=1 1168w" sizes="(max-width: 502px) 100vw, 502px" data-recalc-dims="1"></figure></div>



<p>Perhaps most surprisingly, the distribution is quite different compared to the first dataset, even though I would’ve expected the distributions to look very similar. I have no good theories as to why this might be the case (apart from a bug in my code, although I did check it several times).</p>



<p>There are a few other interesting details here. The average error density in the second dataset is higher, and this is likely because we consider all bugs over the ~4 year period, whereas the first dataset only considers the last 6 months and specific type of bugs (see [6] and [7] for details). In addition there are some zero-length functions. These are likely methods of abstract classes, meant to be overwritten. When analyzing post-release defects we see a roughly similar picture, if noisier (graph can be found in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://softwarebyscience.com/very-short-functions-are-a-code-smell-an-overview-of-the-science-on-function-length/">https://softwarebyscience.com/very-short-functions-are-a-code-smell-an-overview-of-the-science-on-function-length/</a></em></p>]]>
            </description>
            <link>https://softwarebyscience.com/very-short-functions-are-a-code-smell-an-overview-of-the-science-on-function-length/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24315032</guid>
            <pubDate>Sat, 29 Aug 2020 10:05:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Interactive Assembly Guide for Electronics Projects]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24314801">thread link</a>) | @kasbah
<br/>
August 29, 2020 | https://kitspace.org/interactive_bom/?github.com/mattvenn/teensy-audio-fx | <a href="https://web.archive.org/web/*/https://kitspace.org/interactive_bom/?github.com/mattvenn/teensy-audio-fx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://kitspace.org/interactive_bom/?github.com/mattvenn/teensy-audio-fx</link>
            <guid isPermaLink="false">hacker-news-small-sites-24314801</guid>
            <pubDate>Sat, 29 Aug 2020 09:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hopfield Networks Is All You Need]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24313743">thread link</a>) | @beefman
<br/>
August 28, 2020 | https://ml-jku.github.io/hopfield-layers/ | <a href="https://web.archive.org/web/*/https://ml-jku.github.io/hopfield-layers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
      <p>This blog post explains the paper <a href="https://arxiv.org/abs/2008.02217">Hopfield Networks is All You Need</a> and the corresponding new PyTorch <a href="https://github.com/ml-jku/hopfield-layers">Hopfield layer</a>.</p>

<h2 id="main-contributions">Main contributions</h2>
<p>We introduce a new energy function and a corresponding new update rule which is guaranteed to converge to a local minimum of the energy function.</p>

<p>The new energy function is a generalization (discrete states \(\Rightarrow\) continuous states) of <strong>modern Hopfield Networks</strong> aka <strong>Dense Associative Memories</strong> introduced by <a href="https://arxiv.org/abs/1606.01164">Krotov and Hopfield</a> and <a href="https://arxiv.org/abs/1702.01929">Demircigil et al.</a>
The new modern Hopfield Network with continuous states keeps the characteristics of its discrete counterparts:</p>
<ul>
  <li>exponential storage capacity</li>
  <li>extremely fast convergence</li>
</ul>

<p>Surprisingly, the new update rule is the attention mechanism of transformer networks introduced in <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>.
We use these new insights to analyze transformer models in the paper.</p>

<h2 id="what-this-blog-post-is-about">What this blog post is about</h2>

<p>This blog post is split into three parts. First, we make the transition from traditional Hopfield Networks towards <strong>modern Hopfield Networks</strong> and their generalization to continuous states through our <strong>new energy function</strong>. Second, the properties of our new energy function and the connection to the self-attention mechanism of transformer networks is shown. Finally, we introduce and explain a new PyTorch layer (<a href="https://github.com/ml-jku/hopfield-layers">Hopfield layer</a>), which is built on the insights of our work. We show several practical use cases, i.e. <a href="https://arxiv.org/abs/2007.13505">Modern Hopfield Networks and Attention for Immune Repertoire Classification</a>, Hopfield pooling, and associations of two sets.</p>

<h2 id="from-classical-hopfield-networks-to-self-attention">From classical Hopfield Networks to self-attention</h2>

<p><strong>Associative memories</strong> are one of the earliest artificial neural models dating back to the 1960s and 1970s. Best known are <a href="https://authors.library.caltech.edu/7427/1/HOPpnas82.pdf">Hopfield Networks</a>, presented by John Hopfield in 1982.
As the name suggests, the main purpose of associative memory networks is to associate an input with its most similar pattern. In other words, the purpose is to store and retrieve patterns.
We start with a review of classical Hopfield Networks.</p>

<h3 id="hopfield-networks">Hopfield Networks</h3>

<p>The simplest associative memory is just a <strong>sum of outer products</strong> of the \(N\) patterns \(\{\boldsymbol{x}_i\}_{i=1}^N\) that we want to store (Hebbian learning rule). In classical Hopfield Networks these patterns are polar (binary), i.e. \(\boldsymbol{x}_i \in \{ -1,1 \}^d\), where \(d\) is the length of the patterns. The corresponding weight matrix \(\boldsymbol{W}\) is:</p>

\[\begin{equation}
\boldsymbol{W} = \sum_i^N \boldsymbol{x}_i \boldsymbol{x}_i^T \ . \tag{1}
\end{equation}\]

<p>The weight matrix \(\boldsymbol{W}\) stores the patterns, which can be retrieved starting with a <strong>state pattern</strong> \(\boldsymbol{\xi}\).</p>

<hr>
<p><strong>Nomenclature</strong></p>

<p>From now on we denote the \(N\) <strong>stored patterns</strong> as \(\{\boldsymbol{x}_i\}_{i=1}^N\) and any <strong>state pattern</strong> or <strong>state</strong> as \(\boldsymbol{\xi}\).</p>

<hr>

<p>The basic <strong>synchronuous update rule</strong> is to repeatedly multiply the state pattern \(\boldsymbol{\xi}\) with the weight matrix \(\boldsymbol{W}\), subtract the bias and take the sign:</p>

\[\begin{equation}
\boldsymbol{\xi^{t+1}} =  \text{sgn}(\boldsymbol{W}\boldsymbol{\xi}^t - \boldsymbol{b}) \ , \tag{2}
\label{eq:restorage}
\end{equation}\]

<p>where \(\boldsymbol{b} \in \mathbb{R}^d\) is a bias vector, which can be interpreted as threshold for every component.
The <strong>asynchronous update rule</strong> performs this update only for one component of \(\boldsymbol{\xi}\) and then selects the next component for update.
Convergence is reached if \(\boldsymbol{\xi^{t+1}} = \boldsymbol{\xi^{t}}\).</p>

<p>The asynchronous version of the update rule of Eq. \eqref{eq:restorage} minimizes the <strong>energy function</strong> \(\text{E}\):</p>

\[\begin{equation}
\text{E} = -\frac{1}{2}\boldsymbol{\xi}^T \boldsymbol{W} \boldsymbol{\xi} + \boldsymbol{\xi}^T\boldsymbol{b} = -\frac{1}{2} \sum_{i=1}^d\sum_{j=1}^d w_{ij}\xi_i\xi_j + \sum_{i=1}^d b_i\xi_i \ . \tag{3}
\label{eq:energy_hopfield}
\end{equation}\]

<p>As derived in the papers of <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=58341">Bruck</a>, <a href="https://www.sciencedirect.com/science/article/pii/0166218X85900290">Goles-Chacc et al.</a> and <a href="https://authors.library.caltech.edu/7427/1/HOPpnas82.pdf">the original Hopfield paper</a>, the convergence properties are dependent on the structure of the weight matrix \(\boldsymbol{W}\) and the method by which the nodes are updated:</p>

<ul>
  <li>For asynchronous updates with \(w_{ii} \geq 0\) and \(w_{ij} = w_{ji}\), the updates converge to a stable state.</li>
  <li>For synchronous updates with \(w_{ij} = w_{ji}\), the updates converge to a stable state or a limit cycle of length 2.</li>
</ul>

<p>For the asynchronous update rule and symmetric weights, \(\text{E}(\boldsymbol{\xi}^{t+1}) \leq \text{E}(\boldsymbol{\xi}^{t})\) holds. When \(\text{E}(\boldsymbol{\xi}^{t+1}) = \text{E}(\boldsymbol{\xi}^{t})\) for the update of every component of \(\boldsymbol{\xi}^t\), a local minimum in \(\text{E}\) is reached.
All stored patterns \(\{\boldsymbol{x}_i\}_{i=1}^N\) should be fixed points of the Hopfield Network, i.e.</p>

\[\begin{equation}
\boldsymbol{x}_i = \text{sgn}(\boldsymbol{W}\boldsymbol{x}_i - \boldsymbol{b}) \ . \tag{4}
\end{equation}\]

<p>They should even be local minima of \(\text{E}\).</p>

<p>In the following example, no bias vector is used. This means that taking the inverse image, i.e. flipping all pixels at once, results in the same energy.</p>

<p>We start with an <strong>illustrative example</strong> of a Hopfield Network. <strong>One input image</strong> should first be stored and then be retrieved.
The input image is:</p>

<p><img src="https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_original.png" alt="not found" width="300px"></p>

<p>Since an associative memory has <strong>polar states and patterns</strong> (or binary states and patterns), we convert the input image to a black and white image:</p>

<p><img src="https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_bw.png" alt="not found" width="300px"></p>

<p>The <strong>weight matrix</strong> \(\boldsymbol{W}\) is the outer product of this black and white image \(\boldsymbol{x}_{\text{Homer}}\):</p>

\[\begin{equation}
\boldsymbol{W} = \boldsymbol{x}_{\text{Homer}} \boldsymbol{x}_{\text{Homer}}^T \ , \qquad \boldsymbol{x}_{\text{Homer}} \in \{ -1,1\}^d \ , \tag{5}
\label{eq:weight_matrix}
\end{equation}\]

<p>where for this example \(d = 64 \times 64\).</p>

<p>Can the original image be restored if half of the pixels are masked out? The masked image is:</p>

<p><img src="https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_bw_masked.png" alt="not found" width="300px"></p>

<p>which is our inital state \(\boldsymbol{\xi}\). This inital state is updated via multiplication with the weight matrix \(\boldsymbol{W}\).
It takes one update until the original image is restored.</p>

<p><img src="https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_bw_masked_retrieved.png" alt="not found" width="600px"></p>

<p>What happens if we store <strong>more than one pattern</strong>? The weight matrix is then built from the sum of outer products of <strong>three stored patterns</strong> (three input images):</p>

\[\begin{equation}
\boldsymbol{W} = \sum_{i=1}^3 \boldsymbol{x}_i \boldsymbol{x}_i^T \ , \qquad \boldsymbol{x}_i \in \{ -1,1\}^d \ . \tag{6}
\end{equation}\]

<p><img src="https://ml-jku.github.io/hopfield-layers/assets/multi_pat_img/experiment_6.png" alt="not found"></p>

<p><img src="https://ml-jku.github.io/hopfield-layers/assets/multi_pat_img/experiment_12.png" alt="not found"></p>

<p>In this figure, the left hand side shows the three stored patterns, and the right hand side shows masked state patterns \(\boldsymbol{\xi}\) together with the retrieved patterns \(\boldsymbol{\xi}^{\text{new}}\).</p>

<p>Looking at the upper row of images might suggest that the retrieval process is no longer perfect. But there are two interesting facts to take into account:</p>
<ul>
  <li>Masking the original images introduces many pixel values of \(-1\). We therefore have the odd behavior that the inner product \(\langle\boldsymbol{x}_{\text{Homer}}^{\text{masked}},\boldsymbol{x}_{\text{Bart}}\rangle\) is larger than the inner product \(\langle\boldsymbol{x}_{\text{Homer}}^{\text{masked}},\boldsymbol{x}_{\text{Homer}}\rangle\).</li>
  <li>As stated above, if no bias vector is used, the inverse of the pattern, i.e. flipping all pixels at once, results in the same energy.</li>
</ul>

<p>Although the retrieval of the upper image looks incorrect, it is de facto correct. However, for the lower row example, the retrieval is no longer correct.
The weights of \(2 \cdot \boldsymbol{x}_{\text{Marge}}\) have simply overwritten the weights of \(\boldsymbol{x}_{\text{Homer}}\).
For both examples, only the retrieval after the first update step is shown, but the results do not change when performing further update steps.
The next figure shows the Hopfield Network retrieval for 6 patterns.</p>

<p><img src="https://ml-jku.github.io/hopfield-layers/assets/multi_pat_img/experiment_115.png" alt="not found"></p>

<p>Clearly, retrieving the patterns is imperfect. One might suspect that the limited storage capacities of Hopfield Networks, see <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.322.3548&amp;rep=rep1&amp;type=pdf">Amit et al.</a> and <a href="https://journals.aps.org/pre/pdf/10.1103/PhysRevE.66.061910">Torres et al</a>, is the problem.
However, we show now that the storage capacity is not directly responsible for the imperfect retrieval.
The storage capacity for <strong>retrieval of patterns free of errors</strong> is:</p>

\[\begin{equation}
C \cong \frac{d}{2\log(d)} \ , \tag{7}
\label{eq:storage_hopfield}
\end{equation}\]

<p>where \(d\) is the dimension of the input.</p>

<p>The storage capacity for <strong>retrieval of patterns with a small percentage of errors</strong> is:</p>

\[\begin{equation}
C \cong 0.14 d\ . \tag{8}
\label{eq:storage_hopfield2}
\end{equation}\]

<p>In the example, the storage capacity is \(C \cong 0.14 d = 0.14 \cdot 64 \cdot 64 \sim 570\).
Thus, insufficient storage capacity is not directly responsible for the retrieval errors.
Instead, the example patterns are correlated, therefore the retrieval has errors.</p>

<p>Consequently, we need a model which <strong>allows pulling apart close patterns</strong>, such that (strongly) <strong>correlated patterns can be distinguished</strong>.</p>

<hr>
<p><strong>On storage capacity</strong></p>

<p>The storage capacities stated in Eq. \eqref{eq:storage_hopfield} and in Eq. \eqref{eq:storage_hopfield2} are derived for \(w_{ii}=0\).
Recently, <a href="https://www.frontiersin.org/articles/10.3389/fncom.2016.00144/full">Folli et al.</a> analyzed the storage capacity for Hopfield Networks with \(w_{ii}\geq 0\). Also for \(w_{ii}\geq 0\), a storage capacity of \(C \cong 0.14 d\)
for retrieval of patterns with a small percentage of errors was observed. The ratio \(C/d\) is often called <strong>load parameter</strong> and denoted by \(\alpha\). <a href="https://www.frontiersin.org/articles/10.3389/fncom.2016.00144/full">Folli et al.</a> showed that there is a second regime with very large \(\alpha\), where the storage capacity is much higher, i.e. more fixed points exist. However, <a href="https://arxiv.org/abs/1704.07741">Rocci et al.</a> and <a href="https://www.mdpi.com/1099-4300/21/8/726/htm">Gosti et al.</a> reported that these fixed points for very large \(\alpha\) are unstable and do not have an attraction basin.</p>

<hr>

<h3 id="modern-hopfield-networks-aka-dense-associative-memories">Modern Hopfield Networks (aka Dense Associative Memories)</h3>

<p>The storage capacity is a crucial characteristic of Hopfield Networks. <strong>Modern Hopfield Networks</strong> (aka Dense Associative Memories) introduce a new energy function instead of the energy in Eq. \eqref{eq:energy_hopfield} to create a higher storage capacity. <strong>Discrete</strong> modern Hopfield Networks have been introduced first by <a href="https://arxiv.org/abs/1606.01164">Krotov and Hopfield</a> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ml-jku.github.io/hopfield-layers/">https://ml-jku.github.io/hopfield-layers/</a></em></p>]]>
            </description>
            <link>https://ml-jku.github.io/hopfield-layers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24313743</guid>
            <pubDate>Sat, 29 Aug 2020 05:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ergodicity Economics: A Primer]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24313716">thread link</a>) | @ogogmad
<br/>
August 28, 2020 | https://jasoncollins.blog/2020/01/22/ergodicity-economics-a-primer/ | <a href="https://web.archive.org/web/*/https://jasoncollins.blog/2020/01/22/ergodicity-economics-a-primer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>In my previous posts on loss aversion (<a href="https://jasoncollins.blog/2019/09/10/kahneman-and-tverskys-debatable-loss-aversion-assumption/">here</a>, <a href="https://jasoncollins.blog/2019/11/06/what-can-we-infer-about-someone-who-rejects-a-5050-bet-to-win-110-or-lose-100-the-rabin-paradox-explored/">here</a> and <a href="https://jasoncollins.blog/2019/12/05/the-case-against-loss-aversion/">here</a>), I foreshadowed a post on how “ergodicity economics” might shed some light on whether we need loss aversion to explain people’s choices under uncertainty. This was to be that post, but the background material that I drafted is long enough to be a stand alone piece. I’ll turn to the application of ergodicity economics to loss aversion in a future post.</p>
<p>The below is largely drawn from presentations and papers by <a href="https://ergodicityeconomics.com/">Ole Peters</a> and <a href="http://lml.org.uk/research/economics/">friends</a>, with my own evolutionary take at the end. For a deeper dive, see the <a href="https://ergodicityeconomics.com/lecture-notes/">lecture notes by Peters and Alexander Adamou</a>, or a recent <a href="https://doi.org/10.1038/s41567-019-0732-0">Perspective by Peters in Nature Physics</a>.</p>
<p><strong>The choice</strong></p>
<p>Suppose you have $100 and are offered a gamble involving a series of coin flips. For each flip, heads will increase your wealth by 50%. Tails will decrease it by 40%. Flip 100 times.</p>
<p><strong>The expected payoff</strong></p>
<p>What will happen? For that first flip, you have a 50% chance of a $50 gain, and a 50% chance of a $40 loss. Your expected gain (each outcome weighted by its probability, 0.5*$50 + 0.5*-$40) is $5 or 5% of your wealth. The absolute size of the stake for future flips will depend on past flips, but for every flip you have the same expected gain of 5% of your wealth.</p>
<p>Should you take the bet?</p>
<p>I simulated 10,000 people who each started with $100 and flipped the coin 100 times each. This line in Figure 1 represents the mean wealth of the 10,000 people. It looks good, increasing roughly in accordance with the expected gain, despite some volatility, and finishing at a mean wealth of over $16,000.</p>
<p><em>Figure 1: Average wealth of population</em><br>
<img src="https://jasonallancollins.files.wordpress.com/2020/01/non_ergodic_figure_1.jpeg?w=1100" alt="Figure 1"></p>
<p>Yet people regularly decline gambles of this nature. Are they making a mistake?</p>
<p>One explanation for declining this gamble is risk aversion. A risk averse person will value the expected outcome of a gamble lower than the same sum with certainty.</p>
<p>Risk aversion can be represented through the concept of utility, where each level of wealth gives subjective value (utility) for the gambler. If people maximise utility instead of the value of a gamble, it is possible that a person would reject the bet.</p>
<p>For example, one common utility function to represent a risk averse individual is to take the logarithm of each level of wealth. If we apply the log utility function to the gamble above, the gambler will reject the offer of the coin flip. [The maths here is simply that the expected utility of the gamble is 0.5*<em>ln</em>(150) + 0.5*<em>ln</em>(60)=4.55, which is less than the utility of the sure $100, <em>ln</em>(100)=4.61.]</p>
<p><strong>The time average growth rate</strong></p>
<p>For a different perspective, below is the plot for the first 20 of these 10,000 people. Interestingly, only two people do better than break even (represented by the black line at $100). The richest has less than $1,000 at period 100.</p>
<p><em>Figure 2: Path of first 20 people</em><br>
<img src="https://jasonallancollins.files.wordpress.com/2020/01/non_ergodic_figure_2.jpeg?w=1100" alt="Figure 2"></p>
<p>What is happening here? The first plot shows that the average wealth across all 10,000 people is increasing. When we look at the first 20 individuals, their wealth generally declines. Even those that make money make less than the gain in aggregate wealth would suggest.</p>
<p>To show this more starkly, here is a plot of the first 20 people on a log scale, together with the average wealth for the full population. They are all below average in final wealth.</p>
<p><em>Figure 3: Plot of first 20 people against average wealth (log scale)</em><br>
<img src="https://jasonallancollins.files.wordpress.com/2020/01/non_ergodic_figure_3.jpeg?w=1100" alt="Figure 3"></p>
<p>If we examine the full population of 10,000, we see an interesting pattern. The mean wealth is over $16,000, but the median wealth after 100 periods is 51 cents, a loss of over 99% of the initial wealth. 54% of the population ends up with less than $1. 86% finishes with less than the initial wealth of $100. Yet 171 people end up with more than $10,000. The wealthiest person finishes with $117 million, which is over 70% of the total wealth of the population.</p>
<p>For most people, the series of bets is a disaster. It looks good only on average, propped up by the extreme good luck and massive wealth of a few people. The expected payoff does not match the experience of most people.</p>
<p><strong><em>Four possible outcomes</em></strong></p>
<p>One way to think about what is happening is to consider the four possible outcomes over the first two periods.</p>
<p>The first person gets two heads. They finish with $225. The second and third person get a heads and a tails (in different orders), and finish with $90. The fourth person ends up with $36.</p>
<p>The average across the four is $110.25, reflecting the compound 5% growth. That’s our positive picture. But three of the four lost money. As the number of flips increases, the proportion who lose money increases, with a rarer but more extraordinarily rich cohort propping up the average.</p>
<p><strong><em>Almost surely</em></strong></p>
<p>Over the very long-term, an individual will tend to get around half heads and half tails. As the number of flips goes to infinite, the number of heads and tails is “<a href="https://en.wikipedia.org/wiki/Almost_surely">almost surely</a>” equal.</p>
<p>This means that each person will tend to get a 50% increase half the time (or 1.5 times the initial wealth), and a 40% decrease half the time (60% of the initial wealth). A bit of maths and the time average growth in wealth for an individual is (1.5*0.6)<sup>0.5</sup> ~ 0.95, or approximately a 5% decline in wealth each period. Every individual’s wealth will tend to decay at that rate.</p>
<p>To get an intuition for this, a long run of equal numbers of heads and tails is equivalent to flipping a head and a tail every two periods. Suppose that is exactly what you did – flipped a heads and then flipped a tail. Your wealth would increase to $150 in the first round ($100*1.5), and then decline to $90 in the second ($150*0.6). You get the same result if you change the order. Effectively, you are losing 10% (or getting only 1.5*0.6=0.9) of your money every two periods.</p>
<p>A system where the time average converges to the ensemble average (our population mean) is known as an ergodic system. The system of gambles above is non-ergodic as the time average and the ensemble average diverge. And given we cannot individually experience the ensemble average, we should not be misled by it. The focus on ensemble averages, as is typically done in economics, can be misleading if the system is non-ergodic.</p>
<p><strong><em>The longer term</em></strong></p>
<p>How can we reconcile this expectation of loss when looking at the time average growth with the continued growth of the wealth of some people after 100 periods? It does not seem that everyone is “almost surely” on the path to ruin.</p>
<p>But they are. If we plot the simulation for, say, 1,000 periods rather than 100, there are few winners. Here’s a plot of the average wealth of the population for 1000 periods (the first 100 being as previously shown), plus a log plot of that same growth (Figures 4 and 5).</p>
<p><em>Figure 4: Plot of average wealth over 1000 periods</em><br>
<img src="https://jasonallancollins.files.wordpress.com/2020/01/non_ergodic_figure_4.jpeg?w=1100" alt="Figure 4"></p>
<p><em>Figure 5: Plot of average wealth over 1000 periods (log plot)</em><br>
<img src="https://jasonallancollins.files.wordpress.com/2020/01/non_ergodic_figure_5.jpeg?w=1100" alt="Figure 5"></p>
<p>We can see that despite a large peak in wealth around period 400, wealth ultimately plummets. Average wealth at period 1000 is $24, below the starting average of $100, with a median wealth of 1×10<sup>-21</sup> (rounding to the nearest cent, that is zero). The wealthiest person has $242 thousand dollars, with that being 98.5% of the total wealth. If we followed that wealthy person for another 1000 generations, I would expect them to be wiped out too. [I tested that – at 2000 periods the wealthiest person had $4×10<sup>-7</sup>.] Despite the positive expected value, the wealth of the entire population is wiped out.</p>
<p><strong>Losing wealth on a positive value bet</strong></p>
<p>The first 100 periods of bets forces us to hold a counterintuitive idea in our minds. While the population as an aggregate experiences outcomes reflecting the positive expected value of the bet, the typical person does not. The increase in wealth across the aggregate population is only due to the extreme wealth of a few lucky people.</p>
<p>However, the picture over 1000 periods appears even more confusing. The positive expected value of the bet is nowhere to be seen. How could this be the case?</p>
<p>The answer to this lies in the distribution of bets. After 100 periods, one person had 70% of the wealth. We no longer have 10,000 equally weighted independent bets as we did in the first round. Instead, the path of the wealth of the population is largely subject to the outcome of the bets by this wealthy individual. As we have already shown, the wealth path for an individual almost surely leads to a compound 5% loss of wealth. That individual’s wealth is on borrowed time. The only way for someone to maintain their wealth would be to bet a smaller portion of their wealth, or to diversify their wealth across multiple bets.</p>
<p><strong>The Kelly criterion</strong></p>
<p>On the first of these options, the portion of a person’s wealth they should enter as stakes for a positive expected value bet such as this is given by the <a href="https://en.m.wikipedia.org/wiki/Kelly_criterion">Kelly Criterion</a>. The Kelly criterion gives the bet size that would maximise the geometric growth rate in wealth.</p>
<p>The Kelly criterion formula for a simple bet is as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=f%3D%5Cfrac%7Bbp-q%7D%7Bb%7D%3D%5Cfrac%7Bp%28b%2B1%29-1%7D%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=1" alt="f=\frac{bp-q}{b}=\frac{p(b+1)-1}{b}" title="f=\frac{bp-q}{b}=\frac{p(b+1)-1}{b}"></p>
<p>where</p>
<blockquote><p>
  <em>f</em> is the fraction of the current bankroll to wager</p>
<p>  <em>b</em> is the net odds received on the wager (i.e. you receive $b back on top of the $1 wagered for the bet)</p>
<p>  <em>p</em> is the probability of winning</p>
<p>  <em>q</em> is the probability of losing (1-p)
</p></blockquote>
<p>For the bet above, we have <em>p</em>=0.5 and <img src="https://s0.wp.com/latex.php?latex=b%3D%5Cfrac%7B0.5%7D%7B0.4%7D%3D1.25&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b=\frac{0.5}{0.4}=1.25" title="b=\frac{0.5}{0.4}=1.25">. As offered, we are effectively required to bet <em>f</em>=0.4, or 40% of our wealth, for that chance to win a 50% increase.</p>
<p>However, if we apply the above formula given <em>p</em> and <em>b</em>, a person should bet <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%280.5%2A%281.25%2B1%29-1%29%7D%7B1.25%7D%3D0.1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\frac{(0.5*(1.25+1)-1)}{1.25}=0.1" title="\frac{(0.5*(1.25+1)-1)}{1.25}=0.1">, or 10%, of their wealth each round to maximise the geometric growth rate.</p>
<p>The Kelly criterion is effectively maximising the expected log utility of the bet through setting the size of the bet. The Kelly criterion will result in someone wanting to take a share of any bet with positive expected value.</p>
<p>The Kelly bet “almost surely”” leads to higher wealth than any other strategy in the long run.</p>
<p>If we simulate the above scenarios, but risking only 10% of wealth each round rather than 40% (i.e. heads wealth will increase by 12.5%, tails it will decrease by 10%), what happens? The expected value of the Kelly bet is 0.5*0.125+0.5*-0.1=0.0125 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jasoncollins.blog/2020/01/22/ergodicity-economics-a-primer/">https://jasoncollins.blog/2020/01/22/ergodicity-economics-a-primer/</a></em></p>]]>
            </description>
            <link>https://jasoncollins.blog/2020/01/22/ergodicity-economics-a-primer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24313716</guid>
            <pubDate>Sat, 29 Aug 2020 05:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Door Problem (2014)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24313607">thread link</a>) | @windsurfer
<br/>
August 28, 2020 | http://www.lizengland.com/blog/2014/04/the-door-problem/ | <a href="https://web.archive.org/web/*/http://www.lizengland.com/blog/2014/04/the-door-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-997">

    <!--  -->

     
     <!-- <div class="author-info">
        <img alt='' src='http://2.gravatar.com/avatar/523831bf9a187710b813f7755c46b6a1?s=90&#038;d=retro&#038;r=g' srcset='http://2.gravatar.com/avatar/523831bf9a187710b813f7755c46b6a1?s=180&#038;d=retro&#038;r=g 2x' class='avatar avatar-90 photo' height='90' width='90' /><a class="name" href="http://www.lizengland.com/blog/author/liz-england/" rel="author">Liz England</a>      </div> -->
    
    <div>

      

            
      <div>
        <p><span>“So what does a game designer do? Are you an artist? Do you design characters and write the story? Or no, wait, you’re a programmer?”</span></p>
<p>Game design is one of those nebulous terms to people outside the game industry that’s about as clear as the “astrophysicist” job title is to me. It’s also my job, so I find myself explaining what game design means to a lot of people from different backgrounds, some of whom don’t know anything about games.</p>
<h2>The Door Problem</h2>
<p>I like to describe my job in terms of “The Door Problem”.</p>
<p>Premise: You are making a game.</p>
<ul>
<li>Are there doors in your game?</li>
<li>Can the player open them?</li>
<li>Can the player open every door in the game?</li>
<li>Or are some doors for decoration?</li>
<li>How does the player know the difference?</li>
<li>Are doors you can open green and ones you can’t red? Is there trash piled up in front of doors you can’t use? Did you just remove the doorknobs and call it a day?</li>
<li>Can doors be locked and unlocked?</li>
<li>What tells a player a door is locked and will open, as opposed to a door that they will never open?</li>
<li>Does a player know how to unlock a door? Do they need a key? To hack a console? To solve a puzzle? To wait until a story moment passes?</li>
<li>Are there doors that can open but the player can never enter them?</li>
<li>Where do enemies come from? Do they run in from doors? Do those doors lock afterwards?</li>
<li>How does the player open a door? Do they just walk up to it and it slides open? Does it swing open? Does the player have to press a button to open it?</li>
<li>Do doors lock behind the player?</li>
<li>What happens if there are two players? Does it only lock after both players pass through the door?</li>
<li>What if the level is REALLY BIG and can’t all exist at the same time? If one player stays behind, the floor might disappear from under them. What do you do?</li>
<li>Do you stop one player from progressing any further until both are together in the same room?</li>
<li>Do you teleport the player that stayed behind?</li>
<li>What size is a door?</li>
<li>Does it have to be big enough for a player to get through?</li>
<li>What about co-op players? What if player 1 is standing in the doorway – does that block player 2?</li>
<li>What about allies following you? How many of them need to get through the door without getting stuck?</li>
<li>What about enemies? Do mini-bosses that are larger than a person also need to fit through the door?</li>
</ul>
<p>It’s a pretty classic design problem. SOMEONE has to solve The Door Problem, and that someone is a designer.</p>
<h2>The Other Door Problems</h2>
<p>To help people understand the role breakdowns at a big company, I sometimes go into how other people deal with doors.</p>
<ul>
<li><span>Creative Director</span>: “Yes, we definitely need doors in this game.”</li>
<li><strong>Project Manager</strong>: “I’ll put time on the schedule for people to make doors.”</li>
<li><span>Designer</span>: “I wrote a doc explaining what we need doors to do.”</li>
<li><span>Concept Artist</span>: “I made some gorgeous paintings of doors.”</li>
<li><span>Art Director</span>: “This third painting is exactly the style of doors we need.”</li>
<li><span>Environment Artist</span>: “I took this painting of a door and made it into an object in the game.”</li>
<li><span>Animator</span>: “I made the door open and close.”</li>
<li><strong>Sound Designer</strong>: “I made the sounds the door creates when it opens and closes.”</li>
<li><strong>Audio Engineer</strong>: “The sound of the door opening and closing will change based on where the player is and what direction they are facing.”</li>
<li><strong>Composer</strong>: “I created a theme song for the&nbsp;door.”</li>
<li><span>FX Artist</span>: “I added some cool sparks to the door when it opens.”</li>
<li><strong>Writer</strong>: “When the door opens, the player will say, ‘Hey look! The door opened!’ “</li>
<li><span>Lighter</span>: “There is a bright red light over the door when it’s locked, and a green one when it’s opened.”</li>
<li><span>Legal</span>: “The environment artist put a Starbucks logo on the door. You need to remove that if you don’t want to be sued.”</li>
<li><strong>Character Artist</strong>: “I don’t really care about this door until it can start wearing hats.”</li>
<li><span>Gameplay Programmer</span>: “This door asset now opens and closes based on proximity to the player. It can also be locked and unlocked through script.”</li>
<li><strong>AI Programmer:</strong> “Enemies and allies now know if a door is there and whether they can go through it.”</li>
<li><strong>Network&nbsp;Programmer:</strong> “Do all the players need to see the door open at the same time?”</li>
<li><strong>Release Engineer</strong>: “You need to get your doors in by 3pm if you want them on the disk.”</li>
<li><strong>Core Engine Programmer:&nbsp;</strong>“I have optimized the code to allow up to 1024 doors in the game.”</li>
<li><strong>Tools Programmer:</strong> “I made it even easier for you to place doors.”</li>
<li><span>Level Designer</span>: “I put the door in my level and locked it. After an event, I unlocked it.”</li>
<li><strong>UI Designer</strong>: “There’s now an objective marker on the door, and it has its own icon on the map.”</li>
<li><strong>Combat Designer</strong>: “Enemies will spawn behind doors, and lay cover fire as their allies enter the room. Unless the player is looking inside the door in which case they will spawn behind a different door.”</li>
<li><strong>Systems&nbsp;Designer</strong>: “A&nbsp;level 4 player&nbsp;earns 148xp for opening this door at the cost of 3 gold.”</li>
<li><strong>Monetization Designer</strong>: “We could charge the player $.99 to open the door now, or wait 24 hours for it to open automatically.”</li>
<li><span>QA Tester</span>: “I walked to the door. I ran to the door. I jumped at the door. I stood in the doorway until it closed. I saved and reloaded and walked to the door. I died and reloaded then walked to&nbsp;the door. I threw grenades at the door.”</li>
<li><strong>UX / Usability Researcher</strong>: “I found some people on Craigslist to go through the door so we could see what problems crop&nbsp;up.”</li>
<li><strong>&nbsp;Localization</strong>: “Door. Puerta. Porta. Porte.&nbsp;Tür. Dør. Deur. Drzwi. Drws.&nbsp;문”</li>
<li><strong>Producer</strong>: “Do we need to give everyone those&nbsp;doors or can we save them for a pre-order bonus?”</li>
<li><strong>Publisher</strong>: “Those doors&nbsp;are really going to help this game stand out during the fall line-up.”</li>
<li><strong>CEO:</strong> “I want you all to know how much I appreciate the time and effort put into making those doors.”</li>
<li><strong>PR</strong>: “To all our fans, you’re going to go&nbsp;crazy over our next reveal #gamedev #doors #nextgen #retweet”</li>
<li><strong>Community Manager</strong>: “I let the fans know that their concerns about doors will be addressed in the upcoming&nbsp;patch.”</li>
<li><strong>Customer Support</strong>: “A player contacted us,&nbsp;confused about doors. I gave them detailed instructions on how to use them.”</li>
<li><span>Player</span>: “I totally didn’t even notice a door there.”</li>
</ul>
<p>One of the reasons I like this example is because it’s so mundane. There’s an impression that game design is flashy and cool and about crazy ideas and fun all the time. But when I start off with, “Let me tell you about doors…” it cuts straight to the everyday practical considerations.</p>
<p><em>Recent edits:&nbsp;Added&nbsp;localization, character artist, system designer, combat designer, composer, audio engineer, monetization designer, and I think that’ll be it for now.</em></p>
      </div>

      
    </div>

</article></div>]]>
            </description>
            <link>http://www.lizengland.com/blog/2014/04/the-door-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24313607</guid>
            <pubDate>Sat, 29 Aug 2020 04:42:32 GMT</pubDate>
        </item>
    </channel>
</rss>
