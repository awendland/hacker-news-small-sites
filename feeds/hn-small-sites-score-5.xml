<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 08 Dec 2020 01:09:22 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 08 Dec 2020 01:09:22 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Perils of File Typing]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25322288">thread link</a>) | @panic
<br/>
December 6, 2020 | https://invisibleup.com/articles/34/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/34/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/34/thumb.gif" alt="The Perils of File Typing thumbnail">
	
	

	
<p>Corrections added to the Creator/Type code section thanks to user "Somebody" on Hacker News</p>

<p>Suppose you double-click on a file on your computer. You're doing this so you can open the file and work with it. But does your operating system know what that means? How does it know <em>what</em> to open the file <em>in</em>? Let's look at some solutions that have been proposed over the years to solving this issue.</p>
<p>(fun fact: this originally started as a touchup of <a href="https://invisibleup.com/articles/2/">one of my oldest articles</a> before just kinda becoming this whole <em>thing</em>, so expect a bit of retreading.)</p>
<h2>Nothing</h2>
<p><img alt="IBM 709 in use" src="https://invisibleup.com/articles/34/IBM709.jpg"></p>
<p><strong>Used in</strong>: Early mainframes such as the <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a>, etc.</p>
<p>(Image credit: <a href="https://www.computer-history.info/Page4.dir/pages/IBM.704.dir/">Lawrence Livermore National Laboratory</a>)</p>
<p>What's a "file", anyways? It's a sequence of bytes on a disk, possibly floppy. Or a tape. (Cassette or paper, your choice.) Or on stacks of cards with holes in them. Or toggled in by hand on a front panel.</p>
<p>File types weren't relevant because <em>files</em> weren't really a thing. In the mainframe era, you typically 
1. loaded a program on to your computer from punch cards or a tape
2. fed input into that program either from a teletype terminal or from a different tape/card deck
3. received output from the teletype, a line printer, or yet another tape/card deck</p>
<p>Computers weren't complicated enough where there was any confusion as to what a file on a certain medium <em>was</em>, simply because there was so little to work with. If you had a stack of punchcards, that was your "file". Hope you labeled the box you put it in!</p>
<p>Tapes are more interesting, because they hold substantially more data. (A whopping 5.76 megabytes, stored on 3/4 of a kilometer of magentic tape. How exciting!) That said, storing more than one file on a tape was a strange task. Operating systems weren't really a <em>thing</em> yet. The best that existed were programming languages such as FORTRAN or COBOL that had statements for hardware tasks such as reading from or writing to a tape or punch card. For example, <a href="http://archive.computerhistory.org/resources/text/Fortran/102649787.05.01.acc.pdf">here's the manual for FORTRAN for the IBM 704.</a> We have several commands such as <code>READ</code> (from the punch card reader), <code>READ TAPE</code>, <code>PUNCH</code> (new cards), <code>PRINT</code> (to the printer), etc.</p>
<p>On the IBM tape units of the time (ex: the <a href="https://en.wikipedia.org/wiki/IBM_727">IBM 727</a>), tapes were separated into <em>files</em> and <em>records</em>. In FORTRAN, records were created on every <code>WRITE TAPE</code> command, and could be read with <code>READ TAPE</code> later. Records could be overwritten by using the <code>BACKSPACE</code> statement and then writing again. Files were collections of records, and could be created with an <code>END FILE</code> command.</p>
<p>As an aside, later programming languages such as C still share their heritage from this era. This is why we draw text to the screen with <a href="http://www.cplusplus.com/reference/cstdio/printf/"><code>printf</code></a> which long ago would have literally printed to a <a href="https://en.wikipedia.org/wiki/Teletype_Model_33">teletype terminal</a>, why we read files using <a href="http://www.cplusplus.com/reference/cstdio/rewind/"><code>rewind</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fseek/"><code>fseek</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fread/"><code>fread</code></a>, and <a href="http://www.cplusplus.com/reference/cstdio/fwrite/"><code>fwrite</code></a> as if we were on a tape drive still. Even <a href="http://www.asciitable.com/">ASCII</a>, the encoding most commonly used for the basic Latin alphabet, has code points for file, group, record, and unit separators. (This may also be related to block terminals, something that will be discussed in a future article.)</p>
<p>As mainframes moved onto more advanced batch processing and later interactive time-share operating systems like UNIX, <a href="https://en.wikipedia.org/wiki/OS/360_and_successors">OS/360</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Terminal_System">Michigan Terminal System</a>, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System">ITS</a>, etc., they gained more sophisticated methods of dealing with files than raw tape drive access. But then came the microcomputers.</p>
<h2>Type Codes</h2>
<p><img alt="Apple DOS file listing" src="https://invisibleup.com/articles/34/appledos.gif"></p>
<p><strong>Used in</strong>: <a href="https://en.wikipedia.org/wiki/Apple_DOS">Apple DOS for Apple II</a> (1978-1980), <a href="https://www.hpmuseum.org/hp28c.htm">HP-28</a> and <a href="https://www.hpmuseum.org/hp48s.htm">HP-48</a> series, etc.</p>
<p>We have floppy disks now. They can store a lot of files, rename them, delete them, etc. without too much issue. There's this neat computer called the Apple II that just came out. It uses these new-fangled disks, so it needs to figure out how to store files on it.</p>
<p>The way that Apple DOS (the Apple II's disk operating system for most of it's life) stored files is somewhat interesting. Each file has a name (up to 30 characters) and also a <em>type code</em>. 8 of them were defined but only 4 of them mattered:</p>
<ul>
<li>I (Integer BASIC program)</li>
<li>A (Applesoft BASIC program)</li>
<li>B (Binary files; either assembled programs or data)</li>
<li>T (ASCII text files)</li>
</ul>
<p>Apple DOS had some specific commands that interacted with these types. For instance, the <code>RUN</code> command worked on both Interger BASIC and Applesoft BASIC programs, and chose which one to use. <code>BRUN</code>, <em>binary run</em>, only worked on binary files. <code>OPEN</code>, <code>READ</code>, <code>WRITE</code>, and <code>CLOSE</code> all worked only on ASCII text files.</p>
<p><strong>The types more served as a way to help the operating system more so than you.</strong> This is especially evident in the late 80's and early 90's HP calculators such as the HP-28c and the HP-48GX. These calculators didn't have disks, but they did have persistent memory that could store objects into folders much like a computer.</p>
<p>These calculators used Reverse Polish Notation. Essentially, you do math by placing objects on the stack and then executing commands, which take things from the stack and put a new thing on. An <em>object</em> in RPN is something you placed on the stack. The HP-48's Advanced User's Reference Manual lists 32 distinct types, including real numbers, complex numbers, character strings, arrays, lists, variable names, executable programs, graphics objects, directories, etc. A <em>command</em> could be, say, <code>ADD</code> or some fancy plotting calculus stuff. Whatever they were, they needed to know what types they were dealing with so that they could either reject the input or properly work with it.</p>
<p>Like the Apple II, just having an integer for a type is perfectly okay because the types don't serve the user. They're just there so the operating system knows what a given chunk of bytes on the stack <em>is</em>. There are a few reserved spots for custom types, but for the most parts new types aren't expected to ever be added, nor should they be.</p>
<h3>File Extensions</h3>
<p><img alt="CP/M disk listing as seen on an Amstrad CPC" src="https://invisibleup.com/articles/34/cpm.gif"></p>
<p><strong>Used in</strong>: AMSDOS (Amstrad CPC), CP/M, MS-DOS, etc.</p>
<p>Microcomputers really started to gain in popularity with the likes of the ZX Spectrum, the Amstrad CPC and the Commodore 64 among others. These were fairly cheap and simple computers. When first launched, these came with nothing but cassette tape inputs, as disks were too expensive.</p>
<p>On these computers, you'd attach a cassette player using a standard AUX cord (although some, like the CPC, had a cassette player built in), and the computer would instruct you when to start and stop the tape. These cassette players usually came with a little counter that rolled up as the tape progressed, to help you tell where the tape was. When you insert a tape, you reset the counter to zero. When you want to <em>make</em> a file, you'd write down what the counter read, then save the file. To <em>load a specific file</em>, you'd seek the tape until you're at the location you've written down, then start reading.</p>
<p>More advanced computers such as the Amstrad CPC instead saved <a href="http://www.cpcwiki.eu/index.php/AMSDOS_Header">a header</a> with each file containing, among other things, a file name and extension. If asked for a specific file it could just read the tape until it found it. Later these computers gained disk drives, and any ad-hoc tape fiddling was replaced with a proper file system such as <a href="https://en.wikipedia.org/wiki/File_Allocation_Table">FAT</a> or <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a> that stored <em>where</em> a file was on a given disk and <em>what is was called</em>.</p>
<p>File codes are limited. It is nigh-on impossible to add more ones. What you have is what you got. So... what if we just made the codes out of letters? A couple of them? And they could be anything. Then programmers could come up with whatever file extensions they want and that's okay.</p>
<p>Suppose, in MS-DOS, you have a file named <code>REPORT.TXT</code>. <code>REPORT</code> is the file name, <code>TXT</code> is the extension. <strong>File extensions give an easy, consistent indicator of what a file contains.</strong> A <code>TXT</code> file contains text, a <code>BMP</code> file is a bitmap, etc. </p>
<p>Some file extensions, like <code>EXE</code>, <code>BAT</code>, <code>SYS</code> and <code>COM</code> had special meaning much in the same way that the Apple DOS codes had special meanings, but other than that they're just there to help the user. <strong>The user had to manually choose which program to use.</strong> This allowed for the user to choose what view or editor to use depending on what would be the most helpful. Unfortunately, there were no default programs. If the user didn't know which program, say, a <code>VIZ</code> file is for, they're out of luck. Is it a visualization? Some manga thing? The digital manifestation of a cute internet ghost who's staying up way too late geeking out about old computers? <em>The world may never know...</em></p>
<h3>Creator Codes</h3>
<p><strong>Used in:</strong> Classic Mac OS</p>
<p><img alt="File properties dialog on Classic Mac OS" src="https://invisibleup.com/articles/34/macinfo.gif"></p>
<p>Let's hop on over to the Macintosh for a quick second. It was a newfangled thing in 1984, and it had the opportunity to reinvent the wheel and break compatibility with CP/M and mainframe traditions. And so it did.</p>
<p>The original 128K Macintosh used 400K floppy disks, a not-completely-terrible amount of space for the time. It used the <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a>, which didn't support directories but <em>did</em> support files. It was also completely graphically driven. The Finder was supposed to be the primary way of interacting with files, and the <code>File &gt; Open</code> command could launch the program that made the file. How'd it do that?</p>
<p><strong>Instead of file extensions, the Macintosh used type and creator codes</strong>. These were 4-byte identifiers, much like file extensions, but there were two of them each with a different meaning. The type code was mean to represent the format the data was stored in, used to filter files in the Finder's "Open" dialog. The creator code was meant to indicate the application that created the file, and used by the Finder to choose which specific application to launch. Now, these weren't normally visible to the user. They just saw the file name and a icon for that type.</p>
<p>To do that, the system kept a database of codes and their associated icons and programs. When ran for the first time or moved from disk to disk, <strong>the Finder would read the program data and register in a database what creator codes and file types it supported.</strong> The Finder would then save this information on the disk containing the application. Later, <strong>when the user opened a file, the OS would check its type and creator code against its stored list to determine which application to use.</strong> This worked pretty well.</p>
<p><img alt="ResEdit view" src="https://invisibleup.com/articles/34/macresedit.gif"></p>
<p>A similar system was used for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/34/">https://invisibleup.com/articles/34/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/34/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322288</guid>
            <pubDate>Sun, 06 Dec 2020 09:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VisiData in 60 Seconds]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322091">thread link</a>) | @luu
<br/>
December 6, 2020 | https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/ | <a href="https://web.archive.org/web/*/https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TL;DR? Here’s a three-step introduction to VisiData.</p><div id="step-1-use-vd-to-open-a-data-file">
<h2>Step 1: Use <code><span>vd</span></code> to open a data file<a href="#step-1-use-vd-to-open-a-data-file" title="Permalink to this headline">¶</a></h2>
<p>Download <a download="" href="https://jsvine.github.io/intro-to-visidata/_downloads/83e70cf67e909f3ac177575439e5f3c5/faa-wildlife-strikes.csv"><code><span>faa-wildlife-strikes.csv</span></code></a>, a dataset of all aircraft-wildlife collisions <a href="https://wildlife.faa.gov/database.aspx">reported to the Federal Aviation Adminsitration</a> between 2010 and mid-2016.</p>
<p>From your terminal, move into the directory where you downloaded the dataset. Then run the following command:</p>
<div><div><pre><span></span>vd faa-wildlife-strikes.csv
</pre></div>
</div>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>|</span><span></span><span> ATYPE        </span><span></span><span>|</span><span></span><span> INCIDENT_DATE     </span><span></span><span>|</span><span></span><span> STATE </span><span></span><span>|</span><span></span><span> AIRPORT            </span><span></span><span>|</span><span></span><span> PHASE_OF_FLT</span><span></span><span>&gt;</span><span> 
</span><span></span><span> BUSINESS           </span><span></span><span></span><span>| PA-28        | 05/22/15 00:00:00 | FL    | VERO BEACH MUNICIP…| APPROACH     ║
</span><span></span><span></span><span> BUSINESS           </span><span></span><span>| BE-1900</span><span>      </span><span>| 06/18/15 00:00:00 | AK    | KENAI MUNICIPAL AR…| APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| PA-46 MALIBU | 09/20/15 00:00:00 | TX    | DAVID WAYNE HOOKS …|</span><span>              </span><span>║
</span><span> DELTA AIR LINES    </span><span></span><span>| B-717-200    | 11/07/15 00:00:00 | MO    | LAMBERT-ST LOUIS I…| APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| BE-90 KING   | 12/17/15 00:00:00 | FL    | POMPANO BEACH AIRP…| LANDING ROLL ║
</span><span> DELTA AIR LINES    </span><span></span><span>| B-757</span><span>        </span><span>| 07/17/15 00:00:00 | VI    | HENRY E ROHLSEN AR…|</span><span>              </span><span>║
</span><span> DELTA AIR LINES    </span><span></span><span>| B-717-200    | 08/02/15 00:00:00 | TX    | SAN ANTONIO INTL   | APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| C-414</span><span>        </span><span>| 08/03/15 00:00:00 | TX    | LONE STAR EXECUTIV…| DEPARTURE    ║
</span><span> ALLEGIANT AIR      </span><span></span><span>| MD-80</span><span>        </span><span>| 09/02/15 00:00:00 | FL    | TAMPA INTL</span><span>         </span><span>| APPROACH     ║
</span><span> TRANS STATES AIRLI…</span><span></span><span>| EMB-145</span><span>      </span><span>| 09/07/15 00:00:00 | MO    | LAMBERT-ST LOUIS I…| APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| C-172</span><span>        </span><span>| 11/28/15 00:00:00 | FL    | OPA-LOCKA EXECUTIV…| APPROACH     ║
</span><span> GOVERNMENT         </span><span></span><span>| EC120</span><span>        </span><span>| 12/08/15 00:00:00 | CA    | NORMAN Y. MINETA S…|</span><span>              </span><span>║
</span><span> AMERICAN AIRLINES  </span><span></span><span>| A-321</span><span>        </span><span>| 05/06/15 00:00:00 | FL    | FORT LAUDERDALE/HO…| APPROACH     ║
</span><span> EXPRESSJET AIRLINES</span><span></span><span>| CRJ100/200   | 05/06/15 00:00:00 | AR    | FORT SMITH REGIONA…| CLIMB</span><span>        </span><span>║
</span><span> MESA AIRLINES      </span><span></span><span>| CRJ900</span><span>       </span><span>| 05/08/15 00:00:00 | AR    | BILL AND  HILLARY …| LANDING ROLL ║
</span><span> BUSINESS           </span><span></span><span>| HELICOPTER   | 05/06/15 00:00:00 |</span><span>       </span><span>| UNKNOWN</span><span>            </span><span>| En Route     ║
</span><span> DELTA AIR LINES    </span><span></span><span>| A-320</span><span>        </span><span>| 05/07/15 00:00:00 | CA    | METRO OAKLAND INTL |</span><span>              </span><span>║
</span><span> DELTA AIR LINES    </span><span></span><span>| A-320</span><span>        </span><span>| 05/08/15 00:00:00 | UT    | SALT LAKE CITY INTL|</span><span>              </span><span>║
</span><span> LUFTHANSA          </span><span></span><span>| A-380</span><span>        </span><span>| 05/10/15 00:00:00 | TX    | GEORGE BUSH INTERC…| CLIMB</span><span>        </span><span>║
</span><span> BUSINESS           </span><span></span><span>| C-172</span><span>        </span><span>| 05/08/15 00:00:00 | FL    | ORLANDO SANFORD IN…| APPROACH     ║
</span><span> SPIRIT AIRLINES    </span><span></span><span>| A-319</span><span>        </span><span>| 05/10/15 00:00:00 | IL    | CHICAGO O'HARE INT…| CLIMB</span><span>        </span><span>║
</span><span> EXPRESSJET AIRLINES</span><span></span><span>| EMB-145</span><span>      </span><span>| 05/11/15 00:00:00 | AL    | BIRMINGHAM-SHUTTLE…| LANDING ROLL ║
</span><span>1› faa-wildlife-strikes| saul.pw/VisiData v2.0.1 | opening datasets/faa-wildlife        73448 rows </span><span> </span>
</pre>
</div>
</div><div id="step-2-test-drive-a-frequency-table">
<h2>Step 2: Test-drive a frequency table<a href="#step-2-test-drive-a-frequency-table" title="Permalink to this headline">¶</a></h2>
<p>One of VisiData’s strengths is how quickly it lets you summarize your data. Frequency tables are a great example. To create one, press <kbd>Shift+F</kbd>.</p>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>║</span><span></span><span> count♯</span><span></span><span>|</span><span></span><span> percent%</span><span></span><span>|</span><span></span><span> histogram                                         ~</span><span></span><span>║</span><span>        
</span><span></span><span> UNKNOWN            </span><span></span><span></span><span>║ 23076 |   31.42 | ************************************************** ║</span><span>        
</span><span></span><span> SOUTHWEST AIRLINES </span><span></span><span>║  7752 |   10.55 | ****************</span><span>                                   </span><span>║</span><span>        
</span><span></span><span> BUSINESS           </span><span></span><span>║  5868 |    7.99 | ************</span><span>                                       </span><span>║</span><span>        
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>║  4337 |    5.90 | *********</span><span>                                          </span><span>║</span><span>        
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>║  2817 |    3.84 | ******</span><span>                                             </span><span>║</span><span>        
</span><span></span><span> FEDEX EXPRESS      </span><span></span><span>║  2709 |    3.69 | *****    </span><span>                                          </span><span>║</span><span>        
</span><span></span><span> UNITED AIRLINES    </span><span></span><span>║  2194 |    2.99 | ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> US AIRWAYS         </span><span></span><span>║  1885 |    2.57 | ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> UPS AIRLINES       </span><span></span><span>║  1773 |    2.41 | ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> SKYWEST AIRLINES   </span><span></span><span>║  1769 |    2.41 | ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> JETBLUE AIRWAYS    </span><span></span><span>║  1740 |    2.37 | ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>║  1347 |    1.83 | **   </span><span>                                              </span><span>║</span><span>        
</span><span></span><span> AMERICAN EAGLE AIR…</span><span></span><span>║  1041 |    1.42 | **</span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> ENVOY AIR          </span><span></span><span>║   883 |    1.20 | *   </span><span>                                               </span><span>║</span><span>        
</span><span></span><span> ALASKA AIRLINES    </span><span></span><span>║   835 |    1.14 | * </span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> REPUBLIC AIRLINES  </span><span></span><span>║   804 |    1.09 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> MESA AIRLINES      </span><span></span><span>║   693 |    0.94 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> AIR WISCONSIN AIRL…</span><span></span><span>║   623 |    0.85 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PSA AIRLINES       </span><span></span><span>║   577 |    0.79 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PRIVATELY OWNED    </span><span></span><span>║   516 |    0.70 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PHI INC            </span><span></span><span>║   491 |    0.67 | *    </span><span>                                              </span><span>║</span><span>        
</span><span></span><span> SHUTTLE AMERICA    </span><span></span><span>║   467 |    0.64 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span>2› faa-wildlife-strikes_OPERATOR_freq|</span><span>                         </span><span></span><span>                 F         282 bins </span><span> </span>
</pre>
</div>
</div><div id="step-3-read-visidata-s-manual-page">
<h2>Step 3: Read VisiData’s manual page<a href="#step-3-read-visidata-s-manual-page" title="Permalink to this headline">¶</a></h2>
<p>VisiData’s “<a href="http://visidata.org/man/">quick reference guide</a>” enumerates all of VisiData’s commands and features. You can <a href="http://visidata.org/man/">read it online</a> or access it from anywhere within VisiData by pressing the <kbd>F1</kbd> key or typing <kbd>Control-h</kbd>:</p>
<div>
<pre><span>NAME</span>                     
     <span>VisiData</span> -- a terminal utility for exploring and arranging tabular data                        
<span>SYNOPSIS</span>                 
     <span>vd</span> [<span>options</span>] [<span>input</span> ...]                     
     <span>vd</span> [<span>options</span>] <span>--play</span> <span>cmdlog</span> [<span>-w</span> <span>waitsecs</span>] [<span>--batch</span>] [<span>-o</span> <span>output</span>] [<span>field</span><span></span><span></span><span>=</span><span></span><span></span><span>value</span>]                   
     <span>vd</span> [<span>options</span>] [<span>input</span> ...] <span>+</span><span></span><span></span><span>toplevel</span>:<span>subsheet</span>:<span>col</span>:<span>row</span>                                            
<span>DESCRIPTION</span>              
     <span>VisiData</span> is an easy-to-use multipurpose tool to explore, clean, edit, and restructure          
     data. Rows can be selected, filtered, and grouped; columns can be rearranged, trans-           
     formed, and derived via regex or Python expressions; and workflows can be saved, doc-          
     umented, and replayed.                       
   <span>REPLAY</span> <span>MODE</span>           
     <span>-p</span>, <span>--play</span>=<span>cmdlog</span>       replay a saved <span>cmdlog</span> within the interface                             
     <span>-w</span>, <span>--replay-wait</span>=<span>seconds</span>                    
                             wait <span>seconds</span> between commands                                          
     <span>-b</span>, <span>--batch</span>             replay in batch mode (with no interface)                               
     <span>-o</span>, <span>--output</span>=<span>file</span>       save final visible sheet to <span>file</span> as .tsv                               
:Usage: .No normal_text ... (#659)                
Usage: .No normal_text ... (#1126)                
</pre>
</div>
<div>
<p>Note</p>
<p>If you open the manual from within VisiData it will launch in your terminal’s “pager” program —&nbsp;typically the <a href="https://en.wikipedia.org/wiki/Less_(Unix)">less program</a>. To move around:</p>
<table>
<colgroup>
<col width="55%">
<col width="45%">
</colgroup>
<thead>
<tr><th>Keystroke(s)</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr><td><kbd>Space</kbd> / <kbd>b</kbd></td>
<td>Scroll forward/backward</td>
</tr>
<tr><td><kbd>/</kbd> + <em>search term</em> + <kbd>Enter</kbd></td>
<td>Search for <em>search term</em></td>
</tr>
<tr><td><kbd>n</kbd> / <kbd>N</kbd></td>
<td>Go to next/previous search match</td>
</tr>
<tr><td><kbd>q</kbd></td>
<td>Exit and return to VisiData</td>
</tr>
</tbody>
</table>
<p>You can find additional commands <a href="https://en.wikipedia.org/wiki/Less_(Unix)#Frequently_used_commands">here</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322091</guid>
            <pubDate>Sun, 06 Dec 2020 08:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Airbnb Thanksgiving Burglary]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25321770">thread link</a>) | @dsr12
<br/>
December 5, 2020 | https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html | <a href="https://web.archive.org/web/*/https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://habrastorage.org/webt/mm/dk/wp/mmdkwpapgwobqrzcauk213qoglk.png" alt=""></p>



<p>I used <a href="https://www.airbnb.com/">Airbnb</a> for years in Russia, Germany, and the United States. All the time, the experience was great. At some point, I read a <a href="https://amzn.to/3o9JywH">book about Airbnb</a> to understand the company better.</p>

<p>For Thanksgiving week (November 21-29), five of my friends and I rented a house in Las Vegas.</p>

<p>The total price for nine days: <strong>$2543</strong>.</p>

<p>Previously people went to Vegas to spend time in casinos or walk on The Strip. This year, <a href="https://www.worldometers.info/coronavirus/">the pandemic</a> made it impossible.</p>

<p>It was not a problem for us. We did not plan to socialize; we were going rock climbing.</p>

<p><a href="https://www.mountainproject.com/area/105731932/red-rock">Red Rocks</a>, located next to Vegas, is an excellent place for traditional, sport, bouldering, multi-pitch climbing.</p>

<p>The plan was for some people to take days off and climb every day, and for others to work three days remotely and join the gang during the rest.</p>

<h2 id="incident">Incident</h2>

<p>We moved in on Saturday night. The next morning, excited, we woke up at 6am, had breakfast, verified that we closed back and front doors and at 7am drove to the Red Rocks Park.</p>

<p>We had a fantastic day of climbing, but after the sunset, we went home to realize that the window in one of the rooms was open and some of our belongings had disappeared.</p>

<ul>
  <li>Three work Macbook Pro (I do not include the price, they are replaced by our employees for free)</li>
  <li>One personal <a href="https://amzn.to/33uWB3F">Macbook Pro</a> ($1550)</li>
  <li><a href="https://amzn.to/2JCZWqE">Oculus Quest 2</a>. I just bought it. Really cool. Wanted to share the experience. ($399)</li>
  <li><a href="https://amzn.to/2VnyrUt">GoPro Hero 6</a> ($194)</li>
  <li><a href="https://amzn.to/36oMMGz">Lenovo Tab 4, 10.1in Android Tablet</a> ($190)</li>
  <li><a href="https://amzn.to/3lms9is">Sony WH1000XM3 Noise Cancelling Headphones</a> ($348)</li>
  <li><a href="https://amzn.to/3qbPNSm">Bose Quietcontrol 30 Wireless Headphones</a> ($169)</li>
  <li><a href="https://amzn.to/3fVzzIh">Bose Noise Cancelling Wireless Bluetooth Headphones 700</a> ($339)</li>
  <li><a href="https://amzn.to/37qgsSN">BlueTooth ledger</a> ($118)</li>
  <li>Two backpacks. (2 x $100)</li>
</ul>

<p><img src="https://habrastorage.org/webt/kz/an/pd/kzanpdzeno_6rkrjjgbrhbscbbs.jpeg" alt=""></p>

<p>I called the host, told her about the situation. She shared a set of images from the cameras and the next day sent the whole video.</p>

<!-- Courtesy of embedresponsively.com //-->

<p>
    <iframe src="https://www.youtube-nocookie.com/embed/cg3Z9ZxtKGw" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </p>

<p>We believe this is what happened:</p>

<p>At 8:55am, two hours after we left, someone</p>
<ol>
  <li>Openly came to the front door.</li>
  <li>Knocked in the door.</li>
  <li>Waved Lexus car keys at the camera. (We do not have Lexus.)</li>
  <li>Ringed the bell.</li>
  <li>Waited to verify that no one was at home.</li>
  <li>Got to the back of the house.</li>
  <li>Put gloves and balaclava on.</li>
  <li>Checked if the back door was open. It was not.</li>
  <li>Checked if he can open the window. And it was possible.
10 Moved the pool chair below the window.</li>
  <li>Got into the house.</li>
</ol>

<p>We called the police, and in two hours an officer came. He was polite and professional. He got the list of the stolen items, our version of the incident in the written form, and left.</p>

<p>I was curious, how did the burglar open the window? I checked, and the answer was simple: <strong>the lock on the window was not operational.</strong> No need to break anything, anyone can open the window from the outside!</p>

<p>If the weather was warmer, we would probably try to open windows the night we came. In that case we would discover the problem, but the night was cold and we did not touch the windows.</p>

<p>Till this moment, I was chill. Bad things happen. Burglars get into houses, and no one could be protected from it. We were safe in this incident, and from the money perspective, our loss was not huge.</p>

<p>But the fact that the lock on that window was not functioning is an issue (few more windows had the same problem). If the front door lock was broken it would be worse but even windows that could not be locked are sketchy.</p>

<p>In general, I prefer to blame myself for bad things that happen to me. This time I cannot figure out what was my fault. For sure, we could check all the locks in the house, but it is an overkill.</p>

<p>I am ok with making mistakes and paying for them. But this time, we paid for the host’s errors and Airbnb’s as a company.</p>

<ul>
  <li><strong>Host</strong>: the house was not ready for hosting the guests.</li>
  <li><strong>Airbnb</strong>: limitations of the onboarding policy. I believe there is a list of things that the house owner needs to mark to become a host, and either functioning window locks are not on the list, or it is not enforced.</li>
</ul>

<p>After we told the host about our discovery, she sent a person to lock all the windows completely. From now on, no one would be able to open them from inside or outside.</p>



<p>I wanted to reach out to Airbnb, tell them about the situation, and ask about the next steps.</p>

<p>Safety comes first. Hence I assumed that even if you are under stress and your brain is not functioning well, it is obvious how to contact the support team.</p>

<p>To my surprise, it is not the case.</p>

<p>I spent some time on the Airbnb website but could not figure out which phone number I should call.</p>

<p><strong>Message to AirBnb</strong>: It would be great if you simplify the design of the support page. When we talk about safety, it should be about efficiency and not about the visual appeal or cuteness level.</p>

<p>I would like it to be:</p>

<ul>
  <li>I open the Airbnb website =&gt; I see an obvious button/link to the support page.</li>
  <li>I open the support page =&gt; I see an obvious button/link to the hotline phone number.</li>
</ul>

<p>I posted the tweet about the incident and tagged Airbnb and Las Vegas police in it.</p>

<blockquote>— Vladimir Iglovikov (@viglovikov) <a href="https://twitter.com/viglovikov/status/1330741490759266304?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>


<p>A miracle happened. Airbnb contacted me and asked for my email to identify the account and to get more details.</p>

<p>My guess is that the Marketing team at Airbnb has alarms that trigger when someone mentions the company on social media.</p>

<p>Finally, after two hours, we got into the conversation about the incident, but the path to get there was not obvious at all.</p>

<p>Imagine how many people got into trouble in similar situations and did not leverage this communication channel?</p>

<p>I got an email:</p>

<blockquote>
  <p>My name is XXX, from the Airbnb claims team.</p>

  <p>I am contacting you regarding the incident that occurred during your reservation with YYY.</p>

  <p>As my colleague informed you in the previous email, we are only able to offer up to $500 for any stolen property. In order to proceed with this refund, I will need the following:</p>

  <p>*Original purchase invoice for the stolen items.</p>

  <p>This is requested as “proof of ownership”, if you don’t have the original purchase invoice, a picture of you where the item can be seen will also be accepted as proof of ownership.</p>
</blockquote>

<p>All this story is not about money. But getting compensated for the host’s and Airbnb’s mistake with cash or AirBnB credits would be nice. It does not address the issue with window locks but sweetens the situation.</p>

<p>We interpreted the email as: “We will compensate up to $500 per stolen item”. Using the numbers from the invoices, it summed to $2600.</p>

<p>We collected invoices, sent them to Airbnb, and got the reply with words: “After additional review, I’m happy to report that we have just released a payout in the amount of $500 to your Airbnb account. You can confirm in your Airbnb Transaction History.”</p>

<p>The guess about up to $500 per item was overly optimistic.</p>

<p>After the end of the stay, I got a message from the host:</p>

<blockquote>
  <p>Hi Vladimir,</p>

  <p>Thank you again for choosing our home for your vacation stay.</p>

  <p>I hope the home met (and even surpassed) your expectations. It was a sincere pleasure hosting you, and I really hope to host you again in the near future. I would be truly grateful for a 5 star review of your stay when you have a spare moment and I would definitely do the same for you.</p>

  <p>Also, please in the private comments if there is something, the home or myself can approve of please let me know.</p>
</blockquote>

<p>I understand that this is a standard template, but under the circumstances, it sounds strange and
does not fit the story and overall experience.</p>

<p>I did not plan to share the actual address of the property. The harm to the renting business could be material. But after this text, I changed my mind. It does not look like the host plans to revise the house and look for things that can and should be fixed. For example, the front door lock is barely working. The door could be open with a good push.</p>



<p>We had a great vacation. The weather was good, and the red rocks are remarkable. We had a lot of fun and plan to come back sometime soon.</p>

<p>Work laptops were replaced. We accepted the loss of personal items.</p>

<p>The Airbnb experience was not as smooth as we expected. Our things got stolen, and even on the other days, we did not feel comfortable leaving belongings in the house.</p>

<p>The host was responsive, but it is not enough. Communicating with guests and collecting money should not be the only responsibility. It is worth inspecting the house and fixing things that do not work as expected proactively, without waiting till the universe gives you feedback.</p>

<p>Overall, I believe that staying at AirBnB is safe, and such incidents are the exception rather than the rule, but, for sure, Airbnb has some work to do to improve communication and increase the guests’ safety. The compensation of $500 for all the stolen items does not look fair either.</p>

<p>I would like to end the story with some action items like: “<strong>Next time, when I rent a place, I will do XXX</strong>.” Nothing reasonable comes to my mind.</p>

<p>When I sit in front of the computer in San Francisco, the only thing that comes to my mind is to build a Face Recognition system and check the burglar’s face in it. Something similar to Clearview. Machine Learning is my expertise; creating such a system is straightforward but will take some time. Tempting. Thinking about it.</p>

<p>What would be your action item after such an experience?</p>

        
      </section></div>]]>
            </description>
            <link>https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321770</guid>
            <pubDate>Sun, 06 Dec 2020 07:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons for Early Stage Founders]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25321667">thread link</a>) | @sarathyweb
<br/>
December 5, 2020 | https://calv.info/early-stage-lessons | <a href="https://web.archive.org/web/*/https://calv.info/early-stage-lessons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In Segmentâ€™s early days, we hit countless problems as a founding team. And at the time, I thought those problems were unique to our own special snowflake of a founding journey. I chalked it up to us being new grads and first-time founders.</p><p>But as I've worked with more and more startups, I've realized just how wrong I was.</p><p>Over the past five years, I've made about 25 different seed-stage investments. In doing so, it's taught me a <em>LOT</em> about the common errors that startup founders make. Even across different industries and levels of experience, I see founders hitting the exact same set of problems we encountered in the early days of Segment!</p><p>This post shares a handful of the top lessons that benefit todayâ€™s early stage founders. Itâ€™s a list of the things I wish weâ€™d figured out earlier at Segment. [1]</p><p>This sounds incredibly boring... but the #1 mistake I see startups making is that they donâ€™t set goals. If you take one thing from this post, it's that you should set goals for where you want to be.</p><p>For the longest time at Segment, we didn't have goals. We moved ahead in various (often random) directions, and we would launch features consistently... but we never really set goals at all.</p><p>As we grew the company, we started to lose momentum. Teams were spending time on a bunch of stuff that frankly just didn't really matter to the overall business.</p><p>It wasn't until we hired our VP Eng, Tido, that we finally started setting focused and audacious product goals. Just by verbalizing where we wanted to go and then grading our results, our velocity improved by an order of magnitude.</p><p>I don't care if you call them OKRs, sprints, or something else entirely. Just set a deadline when you want to have something done and a metric you want to move or some other concrete result.</p><p>When early stage founders do attempt to set goals, I often see them agonize over what specific goals to choose. In practice, a "pretty good goal" is way better than "no goals at all". Perfect is the enemy of good.</p><p>If you don't yet have product-market fit, your goal should probably be getting your first 3-5 customers using the product. If you've hit the level where you now have dozens of users, your goal should be growing by an order of magnitude. It's better to get in the habit of setting and driving towards goals rather than being too worried about their exact semantics. Worst case, you just pick a better goal later.</p><p>A great set of goals answers the question: <em><strong>"what would have to be true in order for us to feel good about our progress at the end of the month?"</strong></em><em> [2]</em></p><p>If each teammate can independently answer "what are our goals for the month?" in the same way, you'll know you've succeeded. If youâ€™re looking for prior art, read <a href="https://www.amazon.com/Measure-What-Matters-Google-Foundation/dp/0525536221">Measure What Matters</a>. </p><p>If you strictly focus on making things true by a certain date, you are bound to make at least some progress towards your end result. </p><p>At the end of the day, every billion-dollar startup is really just the sum of many small deltas.</p><p>Let's get one thing straight: your investors won't know everything. But investors won't know <em>anything</em> if you don't keep them updated on how things are going.</p><p>For the longest time, we were fearful of our Segment investors, to the point that we wouldn't bother sending them emails unless they asked about us. I can say now with confidence that this was 100% the wrong approach.</p><p>We worried that investors would think that we were screwing up (true) and failing (true as well!). And while that might be the case, a founder-friendly investor won't think that way. Investors, especially angels, invested because they believe in <em>you</em>. If I didn't think a team would go somewhere, I wouldn't put money in.</p><p>With each investor, <strong>include the goals you're working towards, as well as the asks for them</strong>. I think monthly is about the right cadence for this in the early days, moving to quarterly around Series A/B time when you start partnering more with a few board members.</p><p>Simply writing the updates should clarify your own thinking tremendously. If it takes you more than 1-2h to put together an update on the most important things happening at the company, it's probably a sign that you should be doing more thinking about the big picture.</p><p>When asking for help, the things that our investors have been able to help us with evolved quite a bit over time. But here's a good rule of thumb for what to ask for:</p><ul><li><p><u>Seed/Pre-seed</u>: user-testing, intros to beta users, hiring</p></li><li><p><u>Series A</u>: hiring, early customers, go-to-market</p></li><li><p><u>Series B/C+</u>: comparables at other companies, senior/exec hires, specific expertise around things like management, infrastructure, systems, etc.</p></li></ul><p>Not all investors will be able to help with everything. But at the very least, sending them information will help you be top of mind. I've lost track of how many times a moment of serendipity where I'm catching up with an old friend has led to a meaningful conversation for a company I've invested in.</p><p>As an extra bonus, the strongest startups send these updates to everyone on their team. It's amazing how much putting the goals in writing helps everyone stay on the same page about what's most important.</p><p>One other note here: take pictures. I now wish we had far more pictures of Segment at every stage of the company. They help turn investor updates into cherished memories.</p><p>Okay, this lesson is taken directly from the YC playbook. And YET, I see so many founders (including YC founders) fail to launch their product. </p><p>If no one notices your launch... just ignore it and then launch again. If you're doing things right, you'll never run out of stuff to launch! [3]</p><p>Why is launching so important? Let me share a personal story...</p><p>We spent about 1.5 years building different iterations of analytics tools. For every iteration, we had a waitlist that users could sign up to use. We personally reached out to the users who we thought were the best fits, and then tried to set up time to use the product. </p><p>The result? Nobody cared. We had no users. We never launched. </p><p>When we finally launched Segment in it's current incarnation, we threw out that approach entirely. We put up a self-service flow, and let anyone who wanted to sign up for it.</p><p>That's when something strange happened... we attracted an entirely new set of developers who just were crawling out of the woodwork and excited to use the new product we'd built. They were coming from companies far outside of SV that we'd never heard of.</p><p>It floored me.</p><p><strong>Lesson learned: the people you happen to be talking to now are probably not the people who have the biggest problem in your space. Do everything you can to reach the folks with the biggest problem, and then, reduce any barriers they might encounter.</strong></p><p>I expect a bunch of you reading this post to ignore this advice, just like we did in the early days. It takes a certain confidence to launch something you've built and put it out there for the world to see. Ultimately though, the rewards are worth it. You'll see users coming from communities you've never even heard of.</p><p>Let me tell you a tale of two startups.</p><p><strong>Startup A</strong> is constantly putting up interesting content on their blog. Their founders are sharing product launches, engineering posts, and creatively brainstorming about what it takes to solve problems in their market.</p><p><strong>Startup B</strong> is operating in stealth. You can't find much about them online, but one of the founders reached out with a nice personalized email mentioning their funding by a top-tier VC. </p><p>Suppose you're looking for a job... do you pick Startup A or Startup B? In my experience, A almost always wins. Momentum is a compounding force.</p><p><strong>Unless you are working in a space that heavily depends on IP, you should probably be publishing more content about what you are doing.</strong> This could be open source, it could be a weekly newsletter, it could be a changelog. [4]</p><p>Whatever it is, it's going to help you both hire <em>and</em> attract customers. So much of the internet is merely about consuming, that just by putting ideas out there, youâ€™ll have a leg up on the competition.</p><p>In the early days of Segment, our <a href="https://segment.com/blog/show-hn-to-series-d/">user acquisition was powered by open source projects and blog posts</a>. But I've seen founders have success with Twitter, Substacks, Podcasts and a variety of different channels.</p><p>If you're looking for inspiration, the <a href="https://railway.app/changelog">Railway</a> and <a href="https://linear.app/changelog">Linear</a> changelogs are epic examples. Companies like <a href="https://baremetrics.com/blog/i-sold-baremetrics">Baremetrics</a> and <a href="https://buffer.com/resources/shareholder-update-q2-2020-and-july/">Buffer</a> differentiated themselves by just being open and honest. <a href="https://stripe.com/blog/globe">Stripe</a> and <a href="https://www.figma.com/blog/behind-the-feature-the-making-of-the-new-auto-layout/">Figma's blogs</a> not only share what they build, but how they built it.</p><p>There are three big inputs that all startups need to continue growing</p><ol><li><p>product capabilities</p></li><li><p>customers and users</p></li><li><p>hiring</p></li></ol><p>I've put them in roughly the order that most teams encounter them. </p><p>Startups begin with a small product that has a modicum of utility. It starts attracting a handful of customers organically. And as more and more customers start using the product, the founders realize that they need extra help to stay on top of all of those requests.</p><p>Remember though, the real goal here is #2. Itâ€™s not the size of your team, itâ€™s the value youâ€™re able to provide to the world. [5]</p><p>I see hiring a big team before you have product-market fit as a red flag. If the company doesn't yet have a set direction, it's going to be harder to pivot with 10 people than it is with 3.</p><p>But, I've worked with startups who have traction and runway... and just seem to be spinning their wheels under load from existing customers.</p><p>I get it. Hiring isn't the most fun, especially for an introvert. It's a lot of interviewing and feeling like there's a lot of rejection. Rejecting people sucks. Losing candidates sucks. For many of our roles at Segment, we've had to talk with 50-100 different people to make an eventual hire.</p><p><strong>If you have 24 months of runway, and a clear list of things youâ€™d do if you had more copies of yourself: you probably aren't spending time to hire the people you need.</strong></p><p>At Segment, my co-founder <a href="https://twitter.com/ivolo">Ilya</a> fulfilled this role. It was back in 2014, we were 12 people at the time, had raised a $10m Series A, and had $1m in revenue.</p><p>Thing…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calv.info/early-stage-lessons">https://calv.info/early-stage-lessons</a></em></p>]]>
            </description>
            <link>https://calv.info/early-stage-lessons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321667</guid>
            <pubDate>Sun, 06 Dec 2020 06:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic segmentation algorithms do not generalize to off-road datasets]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25321540">thread link</a>) | @srik901
<br/>
December 5, 2020 | https://unmannedlab.github.io/research/RELLIS-3D | <a href="https://web.archive.org/web/*/https://unmannedlab.github.io/research/RELLIS-3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
<a href="https://www.tamu.edu/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/tamu_logo.png" alt="Texas A&amp;M University" height="90px" width="450px"></a>    <a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="CCDC Army Research Laboratory" height="90px" width="270px"></a></p>
<p>
Peng Jiang<sup>1</sup>, Philip Osteen<sup>2</sup>, Maggie Wigness<sup>2</sup> and Srikanth Saripalli<sup>1</sup><br>
1. <a href="https://www.tamu.edu/">Texas A&amp;M University; </a> 2. <a href="https://www.arl.army.mil/">CCDC Army Research Laboratory</a><br>
<a href="https://unmannedlab.github.io/research/RELLIS-3D">[Website]</a> <a href="https://arxiv.org/abs/2011.12954">[Paper]</a> <a href="https://github.com/unmannedlab/RELLIS-3D">[Github]</a> 
</p>
<h2 id="overview">Overview</h2>
<p>Semantic scene understanding is crucial for robust and safe autonomous navigation, particularly so in off-road environments. Recent deep learning advances for 3D semantic segmentation rely heavily on large sets of training data; however, existing autonomy datasets represent urban environments or lack multimodal off-road data. We fill this gap with RELLIS-3D, a multimodal dataset collected in an off-road environment containing annotations for <strong>13,556 LiDAR scans</strong> and <strong>6,235 images</strong>. The data was collected on the Rellis Campus of Texas A\&amp;M University and presents challenges to existing algorithms related to class imbalance and environmental topography. Additionally, we evaluate the current state of the art deep learning semantic segmentation models on this dataset. Experimental results show that RELLIS-3D presents challenges for algorithms designed for segmentation in urban environments. Except for the annotated data, the dataset also provides full-stack sensor data in ROS bag format, including <strong>RGB camera images</strong>, <strong>LiDAR point clouds</strong>, <strong>a pair of stereo images</strong>, <strong>high-precision GPS measurement</strong>, and <strong>IMU data</strong>. This novel dataset provides the resources needed by researchers to develop more advanced algorithms and investigate new research directions to enhance autonomous navigation in off-road environments.</p>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/data_example.png">
</p>
<h3 id="recording-platform">Recording Platform</h3>
<ul>
  <li><a href="https://clearpathrobotics.com/warthog-unmanned-ground-vehicle-robot/">Clearpath Robobtics Warthog</a></li>
</ul>

<h3 id="sensor-setup">Sensor Setup</h3>
<ul>
  <li>64 channels Lidar: <a href="https://ouster.com/products/os1-lidar-sensor">Ouster OS1</a></li>
  <li>32 Channels Lidar: <a href="https://velodynelidar.com/vlp-32c.html">Velodyne Ultra Puck</a></li>
  <li>3D Stereo Camera: <a href="https://nerian.com/products/karmin2-3d-stereo-camera/">Nerian Karmin2</a> + <a href="https://nerian.com/products/scenescan-stereo-vision/">Nerian SceneScan</a></li>
  <li>RGB Camera: <a href="https://www.baslerweb.com/en/products/cameras/area-scan-cameras/ace/aca1920-50gc/">Basler acA1920-50gc</a> + <a href="https://www.edmundoptics.com/p/16mm-focal-length-hp-series-fixed-focal-length-lens/28990/">Edmund Optics 16mm/F1.8 86-571</a></li>
  <li>Inertial Navigation System (GPS/IMU): <a href="https://www.vectornav.com/products/vn-300">Vectornav VN-300 Dual Antenna GNSS/INS</a></li>
</ul>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/sensor_setup.png">
</p>
<h2 id="annotated-data">Annotated Data:</h2>
<h3 id="ontology">Ontology:</h3>
<p>With the goal of providing multi-modal data to enhance autonomous off-road navigation, we defined an ontology of object and terrain classes, which largely derives from <a href="http://rugd.vision/">the RUGD dataset</a> but also includes unique terrain and object classes not present in RUGD. Specifically, sequences from this dataset includes classes such as mud, man-made barriers, and rubble piles. Additionally, this dataset provides a finer-grained class structure for water sources, i.e., puddle and deep water, as these two classes present different traversability scenarios for most robotic platforms. Overall, 20 classes (including void class) are present in the data.</p>

<p><strong>Ontology Definition</strong> (<a href="https://drive.google.com/file/d/1K8Zf0ju_xI5lnx3NTDLJpVTs59wmGPI6/view?usp=sharing">Download 18KB</a>)</p>

<h3 id="images-statics">Images Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/img_dist.png">
</p>
<h3 id="image-download">Image Download:</h3>

<p><strong>Image with Annotation Examples</strong> (<a href="https://drive.google.com/file/d/1wIig-LCie571DnK72p2zNAYYWeclEz1D/view?usp=sharing">Download 3MB</a>)</p>

<p><strong>Full Images</strong> (<a href="https://drive.google.com/file/d/1F3Leu0H_m6aPVpZITragfreO_SGtL2yV/view?usp=sharing">Download 11GB</a>)</p>

<p><strong>Full Image Annotations</strong> (<a href="https://drive.google.com/file/d/16URBUQn_VOGvUqfms-0I8HHKMtjPHsu5/view?usp=sharing">Download 94MB</a>)</p>

<p><strong>Image Split File</strong> (<a href="https://drive.google.com/file/d/1zHmnVaItcYJAWat3Yti1W_5Nfux194WQ/view?usp=sharing">44KB</a>)</p>

<h3 id="lidar-scans-statics">LiDAR Scans Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/pt_dist.png">
</p>

<h3 id="lidar-download">LiDAR Download:</h3>

<ul>
  <li>
    <p>LiDAR with Annotation Examples (<a href="https://drive.google.com/file/d/1QikPnpmxneyCuwefr6m50fBOSB2ny4LC/view?usp=sharing">Download 24MB</a>)</p>
  </li>
  <li>
    <p>LiDAR with Color Annotation PLY Format (<a href="https://drive.google.com/file/d/1BZWrPOeLhbVItdN0xhzolfsABr6ymsRr/view?usp=sharing">Download 26GB</a>)</p>
  </li>
  <li>
    <p>LiDAR SemanticKITTI Format (<a href="https://drive.google.com/file/d/1lDSVRf_kZrD0zHHMsKJ0V1GN9QATR4wH/view?usp=sharing">Download 14GB</a>)</p>
  </li>
  <li>
    <p>LiDAR Annotation SemanticKITTI Format (<a href="https://drive.google.com/file/d/1LUmmO2imJ4m5uCtGv1FYusCo-bEPDbBx/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Scan Poses files (<a href="https://drive.google.com/file/d/1cyVqJEnlzO9ANOP7hU8GJk28ckPDUSGv/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Split File (<a href="https://drive.google.com/file/d/1raQJPySyqDaHpc53KPnJVl3Bln6HlcVS/view?usp=sharing">75KB</a>)</p>
  </li>
</ul>

<h3 id="calibration-download">Calibration Download:</h3>
<ul>
  <li>
    <p>Camera Instrinsic (<a href="https://drive.google.com/file/d/1NAigZTJYocRSOTfgFBddZYnDsI_CSpwK/view?usp=sharing">Download 2KB</a>)</p>
  </li>
  <li>
    <p>Camera to LiDAR (<a href="https://drive.google.com/file/d/1Xra1E8Bc4l5VwjjNm7o41nDFO29nmx-u/view?usp=sharing">Download 3KB</a>)</p>
  </li>
</ul>

<h2 id="benchmarks">Benchmarks</h2>

<h3 id="image-semantic-segmenation">Image Semantic Segmenation</h3>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vr3g6lCTKRM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h3 id="lidar-semantic-segmenation">LiDAR Semantic Segmenation</h3>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/wkm8UiVNGao" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2 id="ros-bag-raw-data">ROS Bag Raw Data</h2>

<p>Data included in raw ROS bagfiles:</p>

<table>
  <thead>
    <tr>
      <th>Topic Name</th>
      <th>Message Tpye</th>
      <th>Message Descriptison</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>/img_node/intensity_image</td>
      <td>sensor_msgs/Image</td>
      <td>Intensity image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/noise_image</td>
      <td>sensor_msgs/Image</td>
      <td>Noise image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/range_image</td>
      <td>sensor_msgs/Image</td>
      <td>Range image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/imu/data</td>
      <td>sensor_msgs/Imu</td>
      <td>Filtered imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/data_raw</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/nerian_stereo/left_image</td>
      <td>sensor_msgs/Image</td>
      <td>Left image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/nerian_stereo/right_image</td>
      <td>sensor_msgs/Image</td>
      <td>Right image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/odometry/filtered</td>
      <td>nav_msgs/Odometry</td>
      <td>A filtered local-ization estimate based on wheel odometry (en-coders) and integrated IMU from Warthog</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/imu</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>Point cloud data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/imu_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw imu data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/lidar_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw lidar data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/vectornav/GPS</td>
      <td>sensor_msgs/NavSatFix</td>
      <td>INS data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/IMU</td>
      <td>sensor_msgs/Imu</td>
      <td>Imu data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Odom</td>
      <td>nav_msgs/Odometry</td>
      <td>Odometry from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Pres</td>
      <td>sensor_msgs/FluidPressure</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/vectornav/Temp</td>
      <td>sensor_msgs/Temperature</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/velodyne_points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>PointCloud produced by the Velodyne Lidar</td>
    </tr>
  </tbody>
</table>

<h3 id="ros-bag-download">ROS Bag Download</h3>

<p><strong>ROS Bag Examples</strong> (<a href="https://drive.google.com/file/d/163pEtjMhcM1OJo36ZOi6_zDHpuPSL8us/view?usp=sharing">2GB</a>)</p>

<p><strong>Sequence 00000</strong>: Synced data: (<a href="https://drive.google.com/file/d/10dHPMCschg1dMeb_Y6pcPvC-HZQZ8_ek/view?usp=sharing">12GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1d-t4P1idWkfxDEkodBrsbd4B2nAc8rZ3/view?usp=sharing">23GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1IZ-Tn_kzkp82mNbOL_4sNAniunD7tsYU?usp=sharing">29GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qc7IepWGKr8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00001</strong>: Synced data: (<a href="https://drive.google.com/file/d/1I98lEog0xFFAVVZ_AEBvXzIEcFQ2bGRl/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1LogHRN1ElE2xryILMPU3OtnV6VCnjs52/view?usp=sharing">16GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1hf-vF5zyTKcCLqIiddIGdemzKT742T1t?usp=sharing">22GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nO5JADjDWQ0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00002</strong>: Synced data: (<a href="https://drive.google.com/file/d/1yhohyWOIIf00YLUZ1RT7ouq3B-iaOU91/view?usp=sharing">14GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1F_8yviLHcAVmBpWEyCITFd1nRgPRmkVX/view?usp=sharing">28GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1R8jP5Qo7Z6uKPoG9XUvFCStwJu6rtliu?usp=sharing">37GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aXaOmzjHmNE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00003</strong>:Synced data: (<a href="https://drive.google.com/file/d/1poY5eaKKhmjUQpF1rsoL4mm4wO7T8CJM/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1HDbtqaYhfeyLoq9UsxOhgCJl2urGVKUc/view?usp=sharing">15GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1iP0k6dbmPdAH9kkxs6ugi6-JbrkGhm5o?usp=sharing">19GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Kjo3tGDSbtU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00004</strong>:Synced data: (<a href="https://drive.google.com/file/d/1xLvai6rorpjxRZXraZK7qPsA1vYMkTHJ/view?usp=sharing">7GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1usxAjxHrw89R6rMA0GtmYQRtzIP-QGJF/view?usp=sharing">14GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1WV9pecF2beESyM7N29W-nhi-JaoKvEqc?usp=sharing">17GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/lLLYTI4TCD4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h2 id="full-data-download">Full Data Download:</h2>
<p><a href="https://drive.google.com/drive/folders/1aZ1tJ3YYcWuL3oWKnrTIC5gq46zx1bMc?usp=sharing">Access Link</a></p>

<h2 id="citation">Citation</h2>
<div><div><pre><code>@misc{jiang2020rellis3d,
      title={RELLIS-3D Dataset: Data, Benchmarks and Analysis}, 
      author={Peng Jiang and Philip Osteen and Maggie Wigness and Srikanth Saripalli},
      year={2020},
      eprint={2011.12954},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre></div></div>

<h2 id="collaborator">Collaborator</h2>
<p><a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="The DEVCOM Army Research Laboratory"></a></p>

<h2 id="license">License</h2>
<p>All datasets and code on this page are copyright by us and published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License.</p>



<p><a href="https://unmannedlab.github.io/research/SemanticUSL">SemanticUSL: A Dataset for Semantic Segmentation Domain Adatpation</a></p>

<p><a href="https://unmannedlab.github.io/research/LiDARNet">LiDARNet: A Boundary-Aware Domain Adaptation Model for Lidar Point Cloud Semantic Segmentation</a></p>

  </article></div>]]>
            </description>
            <link>https://unmannedlab.github.io/research/RELLIS-3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321540</guid>
            <pubDate>Sun, 06 Dec 2020 06:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Traits of the Financially Independent]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25320594">thread link</a>) | @adrian_monk
<br/>
December 5, 2020 | https://www.thriftythoughts.io/fire-movement/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/fire-movement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h3 id="who-makes-up-the-fi-re-movement">Who makes up the FI/RE Movement?</h3><p>Despite its relatively recent popularity, the FI/RE movement is still in many ways ambiguous. Who are these millionaires next door and what common traits are shared among them? Fortunately based off of data obtained from a survey conducted of nearly 1,400 individuals in the r/financialindependence subreddit, we can get a bit more insight into not only those who are pursuing FI/RE, but also those who have already achieved it. Special thanks to u/melonbalon for conducting the survey in the first place!</p><!--kg-card-begin: html--><!--kg-card-end: html--><figure><img src="https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--7-.png" alt="" srcset="https://www.thriftythoughts.io/content/images/size/w600/2020/12/UNCLAIMED-PROPERTY--7-.png 600w, https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--7-.png 800w" sizes="(min-width: 720px) 720px"></figure><h3 id="insights-obtained">Insights Obtained</h3><p>So much data was obtained as part of this survey and the figures reported in the above visual only scratch the surface of valuable insights that could be drawn. Of note however are a couple items:</p><ol><li><strong>Commute times are very low.</strong> Over 20% of respondents noted that it takes last than 10 minutes to get to work. Additionally, nearly 70% had a commute of less than 30 minutes. It's likely that these smaller commute times result in less transportation costs which could be a motivating factor.</li><li><strong>Individuals who have already FI/RE'd are highly educated.</strong> Not only did nearly 85% of respondents have a college degree, but an additional 7% had multiple graduate degrees. Perhaps these individuals have more time for additional schooling post-retirement. It also could be the case that this additional education helped them FI/RE in the first place. Regardless, more schooling was expected in comparison to the respondent group that had not yet FI/RE'd simply given the older average age. </li><li><strong>Respondents favored urban and suburban environments equally. </strong>Additionally this ratio remained constant in both the pursuing FI/RE and FI/RE'd populations. I would have expected far more suburban living, but perhaps the increased cost of living in an urban environment is offset enough by the reduced transportation costs to be appealing.</li></ol>
                            <section>
                                <h2>Enjoying these posts? Subscribe for more</h2>
                                
                                <br>
                                
                            </section>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.thriftythoughts.io/fire-movement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320594</guid>
            <pubDate>Sun, 06 Dec 2020 02:50:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhone Is Inferior to Android]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25320572">thread link</a>) | @technojunkie
<br/>
December 5, 2020 | https://www.arencambre.com/iphone-is-inferior-to-android/ | <a href="https://web.archive.org/web/*/https://www.arencambre.com/iphone-is-inferior-to-android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong>UPDATE: While these are valid reasons, <a href="https://www.arencambre.com/iphones-are-inferior-to-android-phones-the-value/">scoring them suggests I should still switch to the iPhone</a>.</strong></p>



<p>I am on day 10 of using an iPhone. I came from the Android world.</p>



<p>The iPhone is deficient. I am leaning towards returning it.</p>




<h2><span id="Context"></span>Context<span></span></h2>



<p>Ten days ago, I switched from a Pixel 4 XL to the iPhone 12 Pro Max. I went with this iPhone model because it’s similarly sized to the Pixel 4 XL, plus I value photography.</p>



<h3><span id="Why_I_switched"></span>Why I switched<span></span></h3>



<p>I made the switch due to intellectual curiosity, to overcome limitations of the Pixel 4 XL, and to get on board with the rest of my family.</p>



<p>I am questioning this decision. While the iPhone helps me escape two Pixel 4 XL limitations, iOS’s regressions from Android feel like a heavy burden.</p>



<p>I am inside Apple’s return window, so I can return the iPhone for a full refund. It is tempting.</p>



<h3><span id="Android_only_has_two_worthwhile_brands"></span>Android only has two worthwhile brands<span></span></h3>



<p>My analysis relies heavily on my experience with the Pixel 4 XL. Much of what I say about Android applies to to top-tier Android manufacturers. Among the requirements of top-tier manufacturers is they deliver highly vanilla Android. This includes <a href="https://store.google.com/us/magazine/compare_pixel">Pixel </a>(Google’s in-house brand), <a href="https://www.oneplus.com/">OnePlus</a>, and more.</p>



<p><strong>Samsung is not a top-tier phone manufacturer.</strong> Its hardware is decent, but it has bad software. Samsung replaces Android’s best features with <a href="https://www.samsung.com/us/support/answer/ANS00078945/">poor, fussy substitutes</a>. It also adds annoying, pointless bloat. In other words, just to differentiate its brand, it <em>devalues its brand </em>by trashing up its core software.</p>



<p>The Bixby assistant is the best example of Samsung’s stupidity. It’s awful. Samsung killing Bixby might signal that it’s ready to take Android seriously. Until then, Samsung is simply not a top-tier manufacturer.</p>



<p>The Samsung example is important because Apple is the same: <strong>great hardware, bad software</strong>.</p>



<h2><span id="A_note_about_definitions"></span>A note about definitions<span></span></h2>



<p>The article’s language is sometimes imprecise. Truly, if you’re comparing Android to something in the Apple ecosystem, it would be iOS. But that is not how people talk about their phones, so I am using loose terminology in places.</p>



<p>If you’re a True Nerd™ and find my word use upsetting, just associate my word with its parent ecosystem.</p>



<p>This is how several terms are correctly used:</p>



<figure><table><tbody><tr><td><strong>Word category</strong></td><td><strong>Android phone ecosystem</strong></td><td><strong>Apple phone ecosystem</strong></td></tr><tr><td>Operating system</td><td>Android</td><td>iOS</td></tr><tr><td>Manufacturers</td><td>Google, OnePlus, and more</td><td>Apple</td></tr><tr><td>Phone brand</td><td>Pixel (Google), OnePlus, and more</td><td>iPhone</td></tr><tr><td>Phone model (current generation)</td><td>For Pixel: Pixel 4A, Pixel 4A 5G, Pixel 5. For OnePlus: OnePlus 8T, OnePlus 8 Pro, OnePlus 8, OnePlus 7T. There are more current model from other manufacturers.</td><td>iPhone 12, iPhone 12 Mini, iPhone 12 Pro, iPhone 12 Pro Max, iPhone SE, and more</td></tr></tbody></table></figure>



<p>Also, some Android features I enjoy are Pixel-specific. While Google freely distributes Android to other manufactures, it reserves some newer features for its own Pixel phones. Sometimes I may mistakenly generalize a Pixel-specific feature as an Android feature. Since Pixel-specific features often eventually end up on other phones, associating Pixel with Android is probably correct in the long run.</p>



<h2><span id="Where_Android_is_better"></span>Where Android is better<span></span></h2>



<p>Android is well thought out. It has a great UX. I really miss its great design.</p>



<h3><span id="Call_screening_Android_wins"></span>Call screening: Android wins<span></span></h3>



<p>Android’s <a href="https://support.google.com/phoneapp/answer/9118387?hl=en">built-in call screener</a> is excellent. It blocks calls it is confident are garbage. If the caller is in a gray area, it will ask the caller first to state the reason for calling, then show that to me on the screen where I can accept the call. And even if does nothing to the call, I can still use a <strong>Screen Call </strong>button to kick the call to a digital assistant, where the caller is invited to state the reason for the call.</p>



<figure><img src="https://www.xda-developers.com/files/2019/11/call_screen_assistant.jpg" alt=""><figcaption>Example call-screen opportunity. (This image shamelessly <a href="https://www.xda-developers.com/automatic-call-screen-google-pixel-phones/">stolen</a> from XDA Developers.)</figcaption></figure>



<p><strong>NOTE:</strong> This may be mostly a Pixel feature right now. Google plans to <a href="https://www.androidpolice.com/2020/09/08/google-phone-will-soon-be-downloadable-from-play-store-verified-calls-feature-rolling-out/">extend</a> this to more Android brands. Because Samsung uses its own, poor quality dialer, it’s unclear how Samsung will get this feature.</p>



<p><strong>Why iPhone sucks:</strong> Apple only has a <a href="https://support.apple.com/en-us/HT207099">crude tool</a>: block callers not in your contacts. You can’t report calls or texts as spam.</p>



<p>If you want to be more selective than Apple’s crude tool, and instead block specific spammers, you must add the spammers to your contacts. That’s dumb; it just clutters your contacts!</p>



<p>You can also subscribe to a third party service. That’s grating, because the phone should manage that itself, given that this is a years-old problem.</p>



<h3><span id="Browser_ad_blocking_Android_wins"></span>Browser ad blocking: Android wins<span></span></h3>



<p>On Android, browser ad-blocking is easy: Switch to the free <a href="https://play.google.com/store/apps/details?id=org.mozilla.firefox&amp;hl=en_US&amp;gl=US">Mozilla Firefox browser</a>. Inside Firefox, add the free <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">uBlock Origin extension</a>. Then set Firefox as your default browser for happy browsing. Simple! (Android’s Chrome browser does not support extensions.)</p>



<p><strong>Why iPhone sucks:</strong> Install the <a href="https://apps.apple.com/us/app/adguard-adblock-privacy/id1047223162">AdGuard app</a>, jump through several fussy hoops in the <strong>Settings </strong>console’s <strong>Safari </strong>area, and get nagged about going to paid AdGuard. </p>



<p>Maybe I am fussing too much. The hassle is a one-time step, and AdGuard seems to work decently.</p>



<p>Part of the point of ad-blocking is to make YouTube worthwhile. That leads to my next point…</p>



<h3><span id="YouTube_ad_blocking_Android_wins"></span>YouTube ad blocking: Android wins<span></span></h3>



<p>To block YouTube’s ads on Android, just view all YouTube content in Firefox with the uBlock Origin extension. Easy!</p>



<p><strong>Why iPhone sucks:</strong> While Safari + AdGuard = ads blocked on YouTube, it’s still a major regression from Android:</p>



<ul><li>Video quality <a href="https://www.reddit.com/r/apple/comments/aom6ge/why_does_youtube_only_go_up_to_720p_on_mobile/">maxes out at 720p</a>.</li><li>Every YouTube video in Safari starts as low quality (360p). To change it, on <em>every video you watch</em>, you must wade through the settings menu, and it has to be done before you switch to full screen, because of the next bullet’s deficiency.</li><li>When you’re viewing a video in a browser and switch to full screen, Apple cancels the website’s native video player and forces you to use iOS’s default, bad, native video player. Want to double-tap and skip 10 seconds? Want to access the site’s in-video settings? Want any feature not supported by iOS’s dumbed down video control? Forget it! iOS nukes it in full-screen mode.</li></ul>



<p>Firefox Focus is not a solution. It doesn’t fix iOS’s deficiencies.</p>



<h3><span id="Universal_back_button_Android_wins"></span>Universal back button: Android wins<span></span></h3>



<p>For at least a decade, Android has had a back button at the bottom of all windows. This means the valuable concept of “take me back” is baked into the Android paradigm. Need to return where you were, in <em>any</em> app? Just tap the back button, on bottom left of the screen. Or use the back gesture (next section).</p>



<p><strong>Why iPhone sucks:</strong> The back button is a mess.</p>



<p>In Safari, it’s on bottom left.</p>



<p>In most other apps, top left.</p>



<p>To get to the prior app that sent you to the current app, find a tiny button between the app’s top-left back button and the clock. And good luck on that; too much of the time, iOS lists a wrong or irrelevant prior app, especially if you got to your current app from a system notification.</p>



<figure><img loading="lazy" width="1024" height="449" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-1024x449.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-1024x449.png 1024w, https://www.arencambre.com/wp-content/uploads/2020/12/image-300x132.png 300w, https://www.arencambre.com/wp-content/uploads/2020/12/image-768x337.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image.png 1225w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Even though the mini back button says otherwise, I was not sent to GroupMe by NPR One! I was sent there by a notification I tapped while NPR One was active.</figcaption></figure>



<p>Even worse, because the non-Safari back buttons are on the opposite end of the phone from where you hold it, you’re less precise with finger positioning. Therefore, when you intend to use a “back” feature, you’ll instead make the phone think you’re trying to pull down the notification area.</p>



<h3><span id="Gestures_Android_wins"></span>Gestures: Android wins<span></span></h3>



<p>Building on its native strengths, Android’s <a href="https://support.google.com/pixelphone/answer/6073614?hl=en">gestures</a> are excellent. They edge out iOS with the back gesture, which I use a lot. No matter what app you’re in, swipe in from the phone’s right to go back. Simple!</p>



<p><strong>Why iPhone sucks:</strong> Without a “back” gesture, you’re stuck fumbling with iOS’s haphazard back buttons.</p>



<h3><span id="Exiting_apps_Android_wins"></span>Exiting apps: Android wins<span></span></h3>



<p>In Android, you can exit apps with the back gesture or swiping up from the bottom. The back gesture is superior, because it can’t be confused with other gestures.</p>



<p><strong>Why iPhone sucks:</strong> Your only choice is the swipe-up gesture, which sometimes conflicts with normal swipes one does in apps.</p>



<p><strong>NOTE: </strong>I don’t literally mean app-exiting in the computer-science sense. I mean more in a common-parlance sense: you’re out of the app and back to the home screen, or in another app that may have called the current app. One an app is no longer visible, and running in the background, Android and iOS both do fine managing it.</p>



<h3><span id="Ambient_display_Android_wins"></span>Ambient display: Android wins<span></span></h3>



<p>The Pixel has a great feature: even when you’re not using the phone, it shows the current time on the screen, along with some other useful information. This takes minimal power: thanks to the OLED screen, the main power use is when it lights up the specific pixels that show the time.</p>



<figure><img loading="lazy" width="768" height="1024" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-1-768x1024.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-1-768x1024.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-225x300.png 225w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-1152x1536.png 1152w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-1536x2048.png 1536w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Ambient display. This Pixel 4 XL is not active. It’s basically in sleep mode. It uses minimal power to give me useful information on its OLED screen.</figcaption></figure>



<p><strong>Why iPhone sucks:</strong> While the iPhone also has an OLED screen, Apple has no similar feature. You have to tap the phone to see the time, which lights up the whole screen.</p>



<h3><span id="Treating_me_like_an_adult_Android_wins"></span>Treating me like an adult: Android wins<span></span></h3>



<p>Android’s UX language is simply clean. It’s intuitive, simple, and it just works.</p>



<p><strong>Why iPhone sucks:</strong> iOS’s UX feels like a cartoon spoof of a phone OS. Naturally garish colors, toddler-like corner-rounding, goofy font sizes, etc. It’s like iOS’s design semantics were intended to tussle with our innate senses. Barf!</p>



<figure><img loading="lazy" width="473" height="1024" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-2-473x1024.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-2-473x1024.png 473w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-139x300.png 139w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-768x1662.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-710x1536.png 710w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-947x2048.png 947w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2.png 1284w" sizes="(max-width: 473px) 100vw, 473px"><figcaption>When a toddler breaks out crayons and designs a phone, this is what you get.</figcaption></figure>



<h3><span id="Application_organization_Android_wins"></span>Application organization: Android wins<span></span></h3>



<p>All newly installed Android apps go into the app drawer. This is an alphabetized list of apps, accessed by swiping up from a home screen (when you’re not inside an app).</p>



<figure><img loading="lazy" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-4-485x1024.png" alt="" width="485" height="1024" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-4-485x1024.png 485w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-142x300.png 142w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-768x1621.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-728x1536.png 728w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-970x2048.png 970w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4.png 1440w" sizes="(max-width: 485px) 100vw, 485px"><figcaption>Android app drawer. Simple. Organized. Appropriate icon density.</figcaption></figure>



<p>Suppose you have 150 apps. That is 30 rows of five icons each, all in alpha sort. It’s fast to find any application.</p>



<p><strong>Why iPhone sucks:</strong> It wasn’t until <em>this year</em> that Apple delivered its poor ripoff of the app drawer. Before then, people were stuck with jumbled messes of icons on multiple home-screen pages.</p>



<p>Apple’s app-drawer ripoff …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.arencambre.com/iphone-is-inferior-to-android/">https://www.arencambre.com/iphone-is-inferior-to-android/</a></em></p>]]>
            </description>
            <link>https://www.arencambre.com/iphone-is-inferior-to-android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320572</guid>
            <pubDate>Sun, 06 Dec 2020 02:45:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Urgent appeal to Paul Graham, etc.: Please help kickstart Common Lisp revolution]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25320063">thread link</a>) | @Hexstream
<br/>
December 5, 2020 | https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham | <a href="https://web.archive.org/web/*/https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

      <nav>
        <ul>
          <li><a href="#context">Context</a></li>
        </ul>
        <ul>
          <li><a href="#lispworks-and-franz">LispWorks and Franz</a></li>
          <li><a href="#common-lisp-foundation">Common Lisp Foundation</a></li>
          <li><a href="#paul-graham">Paul Graham</a></li>
          <li><a href="#planck-ez">Planck EZ (Ergodox, ZSA)</a></li>
          <li><a href="#everyone-else">Everyone else</a></li>
        </ul>
      </nav>

      

      <section id="context">

        

        <p><a href="https://github.com/sponsors/Hexstream" target="_blank">I am trying to kickstart the Common Lisp revolution from 28 november to <strong>10 december 2020</strong></a>, and as of 5 december 2020, it did look like we were going to run out of time, so this is my last-ditch attempt at rectifying the situation before it's too late. <strong><em><a href="https://github.com/sponsors/Hexstream" target="_blank">Please support the Common Lisp Revival 2020 Fundraiser!!!</a></em></strong></p>

        <p>
          Since we are on such a tight deadline, I am soliciting donations of <strong>1000$ or more</strong> from the following organizations and people. This is the only way we can realistically make it in time.
          <br>
          I can confirm that they are all eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>.
        </p>

        <p>
          Please make sure to <a href="https://github.com/sponsors/Hexstream" target="_blank">sponsor me</a> from an account able to give out doublers, you should see a banner confirming this at the top (when logged in).
          <br>
          Also <strong>beware of prorating</strong>, which might significantly cut down your contribution if you are not careful. Any prorating will be announced on the checkout page, and you may need to sponsor at a higher tier to arrive at the amount that you intended to contribute.
        </p>

        <p>I wrote this page's core content in one day, so please excuse any sloppy writing.</p>

      </section>

      <section id="lispworks-and-franz">

        

        <p>Dear LispWorks, Dear Usha, Dear Franz, Dear Jans,</p>

        <p>
          One of the biggest divisions within the Common Lisp community remains largely unacknowledged. That is <strong>the division between <em>Open Source and Proprietary</em></strong>.
          <br>
          There is tremendous untapped, latent energy to unlock to help make Common Lisp successful, and we just need a slight paradigm shift to do so.
        </p>

        <p>
          <a href="https://twitter.com/HexstreamSoft/status/1213964177657794577" target="_blank" rel="noreferrer">We can make Common Lisp a top 5 programming language by 2040</a>, and this will be much easier to achieve if we unify our forces.
          <br>
          <strong><a href="https://cv.hexstream.expert/" target="_blank">Through my work</a>, I am working to dramatically expand the Common Lisp community, which is guaranteed to greatly benefit your business</strong>.</p>

        <p>
          <strong>You could boost my productivity almost beyond imagination just by providing me a tiny fraction of a normal salary!</strong>
          <br>
          For instance, 1000$/month would be basically infinite money in my current situation. How about you each contribute 500$/month for 6 months as a trial?
          <br>
          Of course, please consider starting with a large donation to the <a href="https://github.com/sponsors/Hexstream" target="_blank">Common Lisp Revival 2020 Fundraiser</a> before <strong>10 december 2020</strong>, as GitHub will double your contribution!
        </p>

        <p>
          I also urge you to open source more of your technology, not even necessarily out of pure generosity, but simply because it makes so much business sense!
          <br>
          For instance, you could send SHOCKWAVES throughout the world simply by open sourcing <a href="http://www.lispworks.com/products/capi.html" target="_blank">CAPI</a> and <a href="https://allegrograph.com/products/allegrograph/" target="_blank">AllegroGraph</a>!
          <br>
          Inherently, the more you open source, the more you stand to benefit from the great Open Source Marketing Machine!
        </p>

        <p>In fact, I almost wonder if you should also open source LispWorks and Allegro Common Lisp and transform yourself into a services company like Red Hat? It's really hard to compete with world-class open source implementations like <a href="http://sbcl.org/" target="_blank">SBCL</a> these days. But obviously, this would be a more long-term project, and I don't presume to understand your business better than you do or tell you what to do. I'm just suggesting ideas. We stand to greatly benefit from a healthy exchange of ideas.</p>

        <p>
          Please check out the details about <a href="https://sponsors.hexstreamsoft.com/about/" target="_blank">HexstreamSoft Sponsors</a>. I think you may find them very compelling.
          <br>
          You are obviously eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>. These grant you great visibility on <a href="" target="_blank">HexstreamSoft</a>, <a href="https://cv.hexstream.expert/#hexstreamsoft-alexa-stats" target="_blank">the #1 Common Lisp site</a>!
        </p>

      </section>

      <section id="common-lisp-foundation">

        

        <p>Dear Common Lisp Foundation, Dear Dave,</p>

        <p>Thank you for giving birth to <a href="https://twitter.com/HexstreamSoft/status/1041671580957466624" target="_blank" rel="noreferrer">one of the most important conversations in the Common Lisp community</a>!</p>

        <p>I have reason to believe that your understanding and appreciation for <a href="https://cv.hexstream.expert/" target="_blank">my crucial work within the Common Lisp community</a> has only been growing since this historic event.</p>

        <p>I believe you have the necessary knowledge and resources to be a key ally in <a href="https://github.com/sponsors/Hexstream" target="_blank">leading Common Lisp to unprecedented success</a>.</p>

        <p>You are already managing <a href="https://www.common-lisp.net/" target="_blank">common-lisp.net</a> and <a href="https://www.cliki.net/" target="_blank">cliki.net</a>, both crucial resources. It is time to unify our efforts. I <a href="https://twitter.com/HexstreamSoft/status/1250142510267224065" target="_blank" rel="noreferrer">again</a> urge you to move to GitHub, the best open source platform, and the <a href="https://github.com/sponsors/Hexstream" target="_blank">Common Lisp Revival 2020 Fundraiser</a> is a great occasion to demonstrate to the world what already ought to be quite obvious: <a href="https://github.com/" target="_blank">GitHub</a> is the best code hosting platform, and <a href="https://github.com/sponsors" target="_blank">GitHub Sponsors</a> is the best open source funding platform! Let's leave <q>avoid success at all costs</q> to Haskell!</p>

        <p>
          I am not sure if your corporate processes in any way allow for such a quick turnaround time, or if you can sanely make an exception, but if in any way possible,
          <br>
          <strong>please make a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> if you wish to help kickstart the Common Lisp revolution right now! Thank you.</strong>
        </p>

      </section>

      <section id="paul-graham">

        

        <p>Dear Paul Graham, Dear Y Combinator,</p>

        <p><a href="https://cv.hexstream.expert/" target="_blank">I have been almost entirely dedicating my life to Common Lisp since mid-2006</a> when I discovered Common Lisp, largely thanks to <a href="http://www.paulgraham.com/" target="_blank">your essays</a>, especially <a href="http://www.paulgraham.com/avg.html" target="_blank">Beating the Averages</a>. After spending 2 weeks reading your essays and researching Common Lisp, I went all-in on Common Lisp and completely abandoned Java. <strong>To this day, this has been the best and most determinant event in my life and I am deeply thanking you for it!</strong></p>

        <p>Basically, I've been running <a href="https://www.hexstreamsoft.com/" target="_blank">an unregistered Common Lisp startup</a> for 14 years. I am planning to register in 2022 at the latest. I have finally started experiencing <a href="https://cv.hexstream.expert/#hexstreamsoft-alexa-stats" target="_blank">some visible success</a> this year, as I am finally reaching the interesting point in the exponential curve. <strong>I am requesting your help to further accelerate and embolden this process.</strong></p>

        <p>
          Unfortunately, I believe the traditional Y Combinator process would not be a good fit for me, due to various reasons.
          <br>
          I am requesting a fairly insignificant amount of funding compared to your usual investments, but this would completely change my life.
        </p>

        <p><a href="https://github.com/sponsors/Hexstream" target="_blank">I am the chief architect of the looming Common Lisp revolution.</a> The revolution would still happen even if you just decided to watch it unfold from afar, but I thought I would highlight your opportunity to lend it a bit of your vast resources and influence, thereby greatly empowering it. Everyone has much to gain from this happening. This is a traditional win-win-win scenario.</p>

        <p>I trust that your world-class expertise in startups will easily detect the amazing intrinsic value and potential of me and my startup.</p>

        <p><strong>Please make a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> if you wish to help kickstart the Common Lisp revolution right now! Thank you.</strong></p>

      </section>

      <section id="planck-ez">

        

        <p>Dear Ergodox/ZSA, Dear Erez, Dear Tisha, Dear Florian,</p>

        <p>The <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is truly revolutionary and life-changing! I predict that it (or its close descendants) will remain the best keyboard on the planet for decades to come!</p>

        <p>Thank you for implementing custom labels in <a href="https://configure.ergodox-ez.com/planck-ez/layouts/ABWNG/latest/0" target="_blank">Oryx</a>, <a href="https://twitter.com/HexstreamSoft/status/1237462417577295873" target="_blank" rel="noreferrer">as I requested</a>. Your email support is truly amazing, and I was surprised to find that indeed, we have already exchanged <strong>more than 100 emails in 9 months!</strong> I greatly value our great relationship, and here is a perfect occasion to go to the next level!</p>

        <p>
          The <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is so damn great that I couldn't resist making <a href="https://status-quo.hexstream.expert/hardware/planck-ez/#my-config" target="_blank">an advanced presentation for my custom keyboard layout</a>.
          <br>
          You were so impressed with it that you quickly offered to <a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/" target="_blank">interview me</a>, and I then proceeded to really pour my soul into that article, with quite impressive results I might say!</p>

        <p>
          The kicker? <strong>I did this while I was already late to launch <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a>! <em>Oh noes!!</em></strong> 🤣
          <br>
          But seriously, I just <em>couldn't wait</em> to share my passion for the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> with the world! That's how goddamn amazing it is!!
        </p>

        <p>I had already been using the TypeMatrix 2030 (a somewhat similar keyboard) for more than a decade, and the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is at least 20x better! It's easy to infer that I'm probably going to stick to the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> or a close descendant for the next decade at least... As <a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/#alternative-to-qmk" target="_blank">previously stated</a>, I am planning to build much more powerful alternatives to <a href="https://qmk.fm/" target="_blank">QMK</a>, <a href="https://ergodox-ez.com/pages/wally" target="_blank">Wally</a> and <a href="https://configure.ergodox-ez.com/" target="_blank">Oryx</a>, all written in Common Lisp, of course. Admittedly, it would take at least a few years before I can start working on this, due to <a href="https://roadmap.hexstreamsoft.com/" target="_blank">more pressing priorities</a>. My <a href="https://status-quo.hexstream.expert/hardware/planck-ez/#my-config" target="_blank">awesome Planck EZ layout presentation</a> is already a good first step towards an Oryx alternative, although it is not yet written in Common Lisp. (I would probably only support the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a>, since that's the only keyboard I find interesting...) <strong><a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/#stenography" target="_blank">I believe the Planck EZ will be the key to unlocking 100x productivity!</a></strong></p>

        <p>
          I think there is already an inherent and fundamental link between Common Lisp and the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a>:
          <br>
          <em>It's only fair to expect that the best programmers would gravitate not only towards the best programming language, but also the <a href="https://ergodox-ez.com/pages/planck" target="_blank">best keyboard</a>!</em>
          <br>
          Thankfully, we have a tremendous opportunity to make that connection even more concrete today!
        </p>

        <p><strong>As such, I would be extremely honored if you made a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> to help kickstart the Common Lisp revolution right now! Thank you.</strong></p>

        <p>I can confirm ZSA is eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>. You can advertise your amazing products on the front page of the #1 Common Lisp site thanks to <a href="https://sponsors.hexstreamsoft.com/about/#monthly-perks" target="_blank">Monthly Perks</a>.</p>

      </section>

      <section id="everyone-else">

        

        <p>Dear everyone interested in Common Lisp and/or Open Source or …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham">https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham</a></em></p>]]>
            </description>
            <link>https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320063</guid>
            <pubDate>Sun, 06 Dec 2020 01:21:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Brown University know where you are?]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25319392">thread link</a>) | @jswrenn
<br/>
December 5, 2020 | https://jack.wrenn.fyi/blog/brown-location-surveillance | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/brown-location-surveillance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In September 2020, Brown University <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">accused students</a> of lying about their location; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/notice.png" height="auto" width="100%" alt="The University has learned that between September 14, 2020 and September 21, 2020 you were allegedly in the Providence area during which time your location of study was listed as remote. This alleged behavior is a violation of the Student Code of Conduct and the COVID-19 Campus Safety Policy. A copy of the Student Commitment to COVID-19 Community Health and Safety Requirements is attached for your review, along with this link to the COVID-19 Campus Safety Policy. failure to abide by these requirements is a violation of the Code of Student Conduct. 
Based on the details of the incident and your student conduct history, the Office of Student Conduct &amp; Community Standards has decided to allow you the opportunity to accept responsibility for the following prohibited conduct without having a COVID-19 Dean's Review Meeting:
• D.8 Failure to Comply
• D.13 Misrepresentation
"></p>
<p><strong>What was Brown's basis for these accusations?</strong></p>
<p>In an <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">interview with The Brown Daily Herald</a>, University Spokesperson Brian Clark said the University evaluated a variety of indicators, including:</p>
<ol>
<li>indications of building access,</li>
<li>indications of accessing private electronic services,</li>
<li>indications of accessing secure networks, and</li>
<li>reports from community members.</li>
</ol>
<p>The mechanics of that last indicator are pretty self-explanatory, but what about the others? <a href="https://it.brown.edu/services/type/canvas-learning-management-system">Canvas</a> <em>doesn't</em> <a href="https://knowyourmeme.com/memes/google-wants-to-know-your-location">Want To Know Your Location</a>. <strong>In this post, I'm going to break down the technical mechanisms behind each of these indicators.</strong></p>
<p>For the most part, I do not have insider knowledge on how Brown reached its decisions. Rather, I'm going to consider each of the indicators Brian Clark named, and describe the technical mechanisms to which Brown <em>could</em> have availed itself to generating location data.</p>
<h2 id="indications-of-building-access">Indications of Building Access</h2>
<p>This is an easy one. Brown's buildings are located on Brown's campus. Brown's campus is in Providence. If you are in Brown's buildings, you are on Brown's campus, in Providence. QED.</p>
<p>At Brown, building access is primarily regulated with electronic control systems (namely Software House's <a href="https://www.swhouse.com/products/software_CCURE9000.aspx"><strong>C•CURE 9000</strong></a> system), not mechanical keys.</p>
<p>Encoded on <a href="https://en.wikipedia.org/wiki/Magnetic_stripe_card#Track_2">track 2</a> of the magnetic stripe on every University ID card is a sixteen digit number that uniquely identifies the card:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-back.jpg" height="auto" width="100%" alt="Image of back of Brown ID card. A tall magnetic stripe runs across the entire width of the card."></p>
<p>Well, that's underwhelming — of <em>course</em> you can't <em>see</em> it! However, up until 2017 or 2018, this number was also <em>printed</em> on the front of ID cards, just above the card-holder's name:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-front.jpg" height="auto" width="100%" alt="Image fo the front of a Brown ID card, displaying the building access code: 6009553660926201"></p>
<p>This pseudo-random identifier (well, its last ten digits) are what uniquely identify you whenever you swipe your Brown ID card <em>anywhere</em>. And, if you lose your Brown ID card, this is the <em>only</em> thing that's changed when you're issued a replacement. Convenient! In contrast, when you lose your dorm room's mechanical key, Brown must replace (or rather, <a href="https://en.wikipedia.org/wiki/Rekeying">rekey</a>) the locks.</p>
<p>But, <em>also</em> unlike a mechanical key, <em>every</em> swipe of a Brown ID card is logged in a central database. <strong>The C•CURE 9000 lets administrators view the complete historical building access history of a person.</strong> Last Spring, Brown used this mechanism to identify and prod students who were slow to evacuate Providence.</p>
<h2 id="indicators-from-electronic-services">Indicators from Electronic Services</h2>
<p>University web services like Canvas <em>don't</em> directly ask you for your location. Nonetheless, accessing these services leaves a location finger print: your IP address.</p>
<p>Your <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> is a number that identifies your device (computer, phone, etc.) for the purposes of network routing. In principle, nobody but you and your internet provider know the <em>exact</em> mapping of your IP address to your physical address.</p>
<p>In practice, IP addresses can be used to <em>roughly</em> geolocate a device. Batches of IP addresses are associated <em>loosely</em> with geographic areas. Since every web service access leaves an IP address as a trace, there are tremendous incentives for advertisers to be able accurately identify what city or town an IP address is probably associated with.</p>
<p>Brown probably <em>isn't</em> analyzing the access logs of its <em>individual</em> web services (like Canvas). Rather, they need only to audit the access logs of its three identity access management (IAM) systems:</p>
<ul>
<li>The <a href="https://workspace.google.com/">Google Workplace</a> IAM system is used to control access to your @brown.edu email, and to the various Google Drive services. <a href="https://support.google.com/a/answer/4580120?hl=en"><strong>Google Workplace</strong> provides administrators with login audit logs that include users' IP addresses.</a></li>
<li>The <a href="https://www.shibboleth.net/">Shibboleth</a> IAM system controls access to all <em>other</em> Brown web services, such as Canvas. It's what you think of as your "Brown account". Shibboleth is <em>very</em> flexible, and can be <a href="https://wiki.shibboleth.net/confluence/display/IDP30/AuditLoggingConfiguration#AuditLoggingConfiguration-GenericFields">configured to log IP addresses</a>.</li>
<li><a href="https://duo.com/">DUO</a> is used to provide two-factor authentication for Shibboleth logins. <a href="https://help.duo.com/s/article/1023?language=en_US#docs-internal-guid-0aa3b4ce-c686-7559-8814-1377592fce4a:%7E:text=Access%20Device">It too provides administrators with detailed access logs</a>.</li>
</ul>
<p>You can partly view your Google Workplace login history for yourself by opening your Brown email and clicking "Details" in the bottom right-hand corner of the page; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/gmail-account-activity.png" height="auto" width="100%"></p>
<p>With <em>either</em> of these access logs in hand, Brown could then turn to any number of geolocation services (<a href="https://tools.keycdn.com/geo">like this one</a>) to guess your physical location.</p>
<h2 id="indicators-from-secure-networks">Indicators from Secure Networks</h2>
<p>This is another easy one. Brown's WiFI network <a href="https://jack.wrenn.fyi/blog/blog/brown-location-surveillance/Campus_Wireless_Coverage_Map_24x36_1.pdf">blankets Brown's campus</a>. Brown's campus is in Providence. If you are on Brown's WiFi network, you are on Brown's campus. QED.</p>
<p>What might surprise you is the sheer depth of surveillance that's capable with WiFi alone. This section will <em>barely</em> scratch the surface.</p>
<h3 id="identification">Identification</h3>
<p>Brown's WiFi routers each broadcast three <a href="https://en.wikipedia.org/wiki/Service_set_(802.11_network)">service sets</a>:</p>
<ol>
<li><a href="https://it.brown.edu/services/type/wireless-network-brown">Brown</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-network-eduroam">eduroam</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-access-brown-guest">Brown Guest</a></li>
</ol>
<p>The Brown and eduroam networks require that you authenticate with your Brown account credentials. Brown University is thus able to identify the owner of any device connected to these networks.</p>
<p>While Brown Guest does <em>not</em> require authentication, it still provides mechanisms of identification. Your network devices broadcast a unique identifier called a <a href="https://en.wikipedia.org/wiki/MAC_address"><strong>MAC address</strong></a>.</p>
<p><a href="https://drawings.jvns.ca/mac-address/"><img type="image/svg+xml" src="https://drawings.jvns.ca/drawings/mac-address.svg" height="auto" width="100%" alt="Comic by Julia Evans. Text: Every computer on the internet has a network card. When you make HTTP requests with Ethernet/WiFi, every packet gets sent to a MAC address. (&quot;Wait, how do I know someone else on the same network isn't reading all my packets?&quot; &quot;You don't! That's one reason we use HTTPS &amp; secure WiFi networks.&quot;) Your router has a table that maps IP addresses to MAC addresses.  (Read about ARP for more.)
"></a></p>
<p>Brown <a href="https://it.brown.edu/computing-policies/network-connection-policy#32:%7E:text=CIS%20maintains%20a%20database%20of%20unique,a%20computer%20when%20it%20is%20necessary.">maintains databases of the MAC addresses of all connected devices</a>.</p>
<p>If you have ever connected to an authenticated network, Brown will be able to de-anonymize your connections to Brown Guest — <em>unless</em> your device implements <a href="https://en.wikipedia.org/wiki/MAC_address#Randomization">MAC address randomization</a>, which (as the name suggests) randomizes your device's MAC address on a per-network basis.</p>
<h3 id="localization">Localization</h3>
<p>Brown's access points log the MAC addresses of the devices that have connected to them. As of 2015, Brown retained these logs for at least several years — possibly indefinitely. Since there are so many access points on campus, which access point you are connected to can narrow your location down to a particular room. <strong>Combined, these logs paint a <em>very</em> accurate picture of your location on campus at any time.</strong></p>
<p>You do not need to be <em>actively</em> browsing the internet for Brown to know where you are via this mechanism. As you walk through campus, your phone likely <em>automatically</em> reconnects to the nearest available access point. If you are within a literal stone's throw of campus, you should assume that Brown can (roughly) identify your location.</p>
<p>Furthermore, if you are in range of three or more of Brown's ARUBA access points, Brown can, in principle, precisely triangulate your location. This functionality is <a href="https://www.arubanetworks.com/pdf/technology/whitepapers/wp_Hybrid_WIDS.pdf">common</a> in enterprise-grade WiFi infrastructure. (If you've ever tried to run a "rogue" WiFi router in your dorm room and receive an angry knock on your door — this is the mechanism by which you were located.)</p>
<h2 id="how-do-i-find-out-more">How do I find out more?</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act"><em>Family Educational Rights and Privacy Act</em></a> empowers students to request their education records from their University.</p>
<p><iframe src="https://www.youtube.com/embed/jWzBrC8dVnw" frameborder="0" allowfullscreen=""></iframe></p>
<p>If you are a current Brown student and would like to go beyond my blog post and learn <em>exactly</em> how Brown University knows your location, <a href="https://www.brown.edu/about/administration/registrar/student-information-rightsferpa">file a FERPA request</a>. Brown University is obligated to respond within 45 days. You'll need to be specific with your request. I suggest requesting:</p>
<ul>
<li>the timestamps, MAC addresses and BSSIDs associated with your devices' connections to Brown University's wireless access points</li>
<li>the timestamps and locations associated with all building accesses conducted with your ID card</li>
<li>the login audit data associated with all Google Workplace, Shibboleth, and DUO authentications conducted by your accounts</li>
</ul>
<p>Additionally, the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation"><em>General Data Protection Regulation</em></a> gives EU citizens and residents expansive control over how their personally identifiable information (PII) is used, and the right to request a copy of or the destruction of collected data. I believe these requests should be directed to <a href="https://compliance.brown.edu/">Brown's compliance office</a>. You might be able to do this even if you're a Brown alumni.</p>
<p><strong>If you attempt either of these steps, <a href="mailto:jack@wrenn.fyi">please get in touch</a>!</strong> I'm very curious as to what Brown is <em>actually</em> doing.</p>
<h2 id="bonus-surveillance-cameras">Bonus: Surveillance Cameras</h2>
<p>As of February 2020, <a href="https://www.browndailyherald.com/2020/02/21/cameras-installed-hegeman-hall/#post-2838338:%7E:text=The%20University%20uses%20approximately%20800%20cameras,with%20high%20crime%20activity%2C%20Porter%20said."><em>eight hundred</em> surveillance cameras monitor campus 24/7</a>. Brown has as about as many surveillance cameras as it has full-time faculty! This map documents a <em>mere seven percent</em> of Brown University's total camera surveillance capacity:</p>

<p><small>This map displays data from <a href="https://www.openstreetmap.org/about">OpenStreetMap</a>. <a href="https://pietervdvn.github.io/Staging/surveillance.html?z=17&amp;lat=41.82681&amp;lon=-71.4016">Help improve its accuracy!</a></small></p><p>Brown University has a longstanding policy governing the appropriate uses of its surveillance cameras. <strong>Unfortunately, <a href="https://www.browndailyherald.com/2008/01/10/surveillance-cameras-on-campus-triple/#post-1679525:%7E:text=DPS%20would%20not%20release%20the%20University%E2%80%99s%20full%20policy%20on%20the%20surveillance%20camera%20system">this policy is secret</a>.</strong></p>
<p>While Brown probably does not <em>currently</em> have the capacity to both broadly and deeply inspect the firehose of data produced by these cameras, expect this to change in the near future. Axis Communications, Brown's primary supplier of surveillance cameras, <a href="https://www.axis.com/customer-story/3767">now touts cameras that can perform <em>on-board</em> facial recognition</a>. And Software House, the provider of the C•CURE 9000 access control system, has begun marketing the integration of facial recognition with its access control systems:</p>
<p><iframe src="https://www.youtube.com/embed/bk395D0tPRA" frameborder="0" allowfullscreen=""></iframe></p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/brown-location-surveillance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319392</guid>
            <pubDate>Sat, 05 Dec 2020 23:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Blub Studies]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318635">thread link</a>) | @edavis
<br/>
December 5, 2020 | https://www.benkuhn.net/blub/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/blub/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Sometimes people ask me what they should learn to become a better programmer. I feel like the default recommendation here is usually an obscure programming language or a textbook on some high-powered machinery like ML. So I always feel a little bit embarrassed and boring when I instead suggest going really deep on what you already know: your main programming language, web framework, object-relational mapper, UI library, version control system, database, Unix tools, etc. It’s not shiny or esoteric, but for me, building a detailed mental model of those (and how they compare to alternatives) might be the learning that’s contributed most to my effectiveness as an engineer.</p><p>A coworker coined the phrase “blub studies” to refer to this sort of mundane, ultra-specific-seeming knowledge. “Blub” comes from a Paul Graham essay, <a href="http://www.paulgraham.com/avg.html" target="_blank">Beating the Averages</a>, in which Blub is a hypothetical middlebrow language whose programmers get defensive when Graham asserts that Lisp is superior. Blub studies is the study of what goes on in the guts of these boring, everyday systems—not the kind you get tenure for inventing, but the kind people actually use.</p><p>Blub studies is a never-ending treadmill of engineering know-how. It’s the fiddly technical details of how Git stores data, or how Postgres locking semantics <a href="https://gocardless.com/blog/zero-downtime-postgres-migrations-the-hard-parts/" target="_blank">caused your migration to bring down prod</a>, or why <code>pip install</code> failed <em>this</em> time. It’s what goes on inside the boiler rooms of your computer. There’s a seemingly infinite amount of it, full of bespoke details for you to stumble over, and that makes it, often, unbelievably frustrating. Experts in shiny fields like machine learning write shiny-sounding articles like <em><a href="https://blog.acolyer.org/2018/01/31/a-theory-of-the-learnable/" target="_blank">A theory of the learnable</a></em>; experts in blub studies emit screeds like <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a> and <a href="https://www.stilldrinking.org/programming-sucks" target="_blank">Programming Sucks</a>.</p><p>In short, if you’re in search of generalizable knowledge that <a href="https://fs.blog/2019/02/compounding-knowledge/" target="_blank">compounds exponentially over time</a>, then blub studies looks like the crap you have to wade through to get to the good stuff. So it’s easy to see why people give up on understanding all the blub they’re surrounded by, except what they need to get the job done.</p><p>But for me, the opposite attitude has been more productive. <a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>—even if it’s hard and takes a while. Blub studies is more generalizable than it seems, and has its own way of compounding over time, too. That makes it a lot more useful than you’d expect.<sup><label for="sn0">✻</label><span><span><sup>✻</sup>
Of course, there are useless parts of blub studies: if this essay gets you excited to memorize a bunch of command-line flags, consider <a href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/" target="_blank">reversing this advice</a>. But in my experience, it’s more common to neglect the useful parts of blubs, than to over-index on trivia.</span></span></sup></p><hr><p>The most straightforward benefit of blub expertise is that it saves you time. <a href="https://twitter.com/geoffreylitt/status/1305214228991750144" target="_blank">“You can’t apply those brilliant insights you learned from SICP if you don’t have the knowledge base and emotional fortitude to fight through <code>pip install</code> first."</a> If you know how Git’s internal model works, you can get your repository out of its borked state without spending hours on Stack Overflow.</p><p>This effect is larger than it might seem. If you’re working with a system you don’t understand, you’re limited to debugging via guess-and-check, which can be arbitrarily slow. A more efficient method would be to <a href="https://twitter.com/b0rk/status/1265360282513281025?lang=en" target="_blank">get as much information as possible about your program’s execution</a> and then use that information to exclude most of the hypothesis space. But this requires a good understanding of both the system, and the tools available for inspecting it. If you’re tracking down, say, a networking problem, staring at some <code>tcpdump</code> output will often get you most of the way there, but only if you know how to interpret it and what to look for.</p><p>If you spend half your programming time debugging, and being a blub expert lets you debug twice as fast, then just the speed gain from blub expertise will let you increase your output by a third.<sup><label for="sn1">†</label><span><span><sup>†</sup>
If you think “half of programming time debugging” sounds high, imagine how much faster you’d be if all your code worked the first time.<p>Doubling debugging speed is probably a conservative estimate—you can save pretty much unlimited time via things like <a href="http://rachelbythebay.com/w/2020/10/14/lag/" target="_blank">“hmm, 40 milliseconds sounds like the timeout for Nagle’s algorithm, try setting <code>TCP_NODELAY</code>”</a>. I somewhat frequently debug tricky things 5x+ faster than coworkers, just because I’ve been working with our stack for a long time, so I know where to look for problems and how to quickly test hypotheses.</p></span></span></sup> That justifies a lot of time staring at <code>tcpdump</code> output! But there are also more subtle reasons I’ve gotten so much from blub studies. It’s both more general, lasts longer, and has more of a compounding effect, than I expected.</p><hr><p>Blub studies are surprisingly broadly applicable because, even if you’re learning about the details of some specific blubby system, that system’s design will contain a juicy non-blubby core of extractible general principles. Unlike many “general principles” people try to teach you, the ones you learn via blub studies are guaranteed to be important to at least one real-world system (the one you’re learning about). And you’ll see them realized in all their messy detail, which academic presentations often leave out.</p><p>Suppose your blub of choice is React. You might worry that learning the gory details will be useless if you ever move to a different part of the stack, or even a different web framework. And, yes, some of them will. But the core idea of React—writing pure render functions, using <a href="https://reactjs.org/docs/reconciliation.html" target="_blank">reconciliation</a> to make updates fast—is extremely powerful and general. In fact, it’s now been copied by the next generation of UI frameworks on both iOS (<a href="https://developer.apple.com/xcode/swiftui/https://developer.apple.com/xcode/swiftui/" target="_blank">SwiftUI</a>) and Android (<a href="https://developer.android.com/jetpack/compose" target="_blank">Jetpack Compose</a>). Learning the principles behind React makes it easier to learn those other frameworks. In fact, it can even be a useful source of ideas to “import” from one to the other. At Wave, for instance, we’ve gotten a lot of mileage out of importing ideas from <a href="https://relay.dev/" target="_blank">Relay</a> into our mobile apps.</p><p>This is a good example of an idea that, as far as I know, you can <em>only</em> learn about through blub studies. Academia didn’t give much attention to React-style UI programming. In fact, it doesn’t seem to view user-interface programming paradigms as a particularly interesting object of study at all. People do sometimes publish on it but, for instance, I couldn’t find any courses on it in MIT’s extensive course catalog.<sup><label for="sn2">‡</label><span><span><sup>‡</sup>
You could argue that this is because UI programming is “too applied” and one shouldn’t expect it to be covered in an academic curriculum. But computer science covers many other equally-“applied” areas, like networking, databases, operating systems, and graphics.</span></span></sup></p><hr><p>Blub studies also compound more than you’d naively expect, in two ways. First, knowing about one blub makes it easier to learn about alternative blubs that serve the same purpose—like the React/SwiftUI example above. Second, knowing more about one blub helps you learn blubs in <em>adjacent</em> parts of the stack more quickly.</p><p>Once, while pair programming with a more junior coworker, we were writing a complicated SQLAlchemy query. My coworker used <code>user.name</code> (the <code>name</code> field of an object stored in the <code>user</code> variable) instead of <code>User.name</code> (the <code>name</code> field of the <em>class</em> <code>User</code>) and was wondering why her query gave the wrong results. I tried to explain the “magic” by which <code>User.name</code> was an instance of <code>Column</code> while <code>user.name</code> was a simple <code>str</code>. I went around in circles for a little while until I eventually explained Python’s <a href="https://docs.python.org/3/howto/descriptor.html" target="_blank">descriptor protocol</a> to her (the language feature SQLAlchemy uses to enable the “declarative” ORM syntax). At that point, everything clicked—and I realized that Python’s <code>__dunder__</code> methods are the key to decoding quite a lot of “magical” seeming code. If you learn the Python language features well, lots of complicated libraries will become a lot easier to understand.</p><p>I had a similar experience myself with Kubernetes. The first time I tried to learn it, it was a bewildering morass of jargon—all those namespaces and containers and Pods and Deployments and Services and Ingresses just to get a simple HTTP server running! Then I read <a href="http://intronetworks.cs.luc.edu/" target="_blank">a networking textbook</a> and everything made much more sense. The (arguably) most complicated parts of Kubernetes exist to solve networking-related problems—allowing hundreds of containers to talk to each other independently while hosted on a much smaller set of computers—so the networking textbook gave me a schema onto which I could hang all my Kubernetes factoids. Once I knew how Linux’s IP routing, iptables, and network namespaces worked, it was much easier for me to understand what exactly something like “kube-proxy” was doing.</p><p>If you know enough different blubs, you can end up at the point where you don’t even need to look things up to figure out how they’re (probably) implemented. An experienced Python programmer can guess immediately how SQLAlchemy’s “declarative” ORM works under the hood. That’s the point when your blub expertise will really start compounding—almost as soon as you start working with something new, you’ll start figuring out how it works and extracting the kernel of generally-interesting ideas.</p><hr><p>Because of this compounding effect, the most important step toward becoming a blub master is to kickstart your “blub flywheel”—the virtuous cycle of blub accumulation—however you can. That means starting with whichever blubs are the easiest or most motivating to learn, and branching out from there. For me, the easiest place to start has been with blubs I’m already using at my day job. I have a couple strategies for getting the most out of those.</p><p>First, I’ll try to <em>go deeper than necessary</em>. If I really want to ship something, it’s easy to give into temptation to, say, Google an error message, copy-paste a fix from Stack Overflow, and move on with my day. But it often doesn’t take that much longer to actually read the error message, understand what it means, and try to figure out <em>why</em> that Stack Overflow answer fixed my problem. Similarly, if I’m stuck in a tricky yak shave, I’ll bias against “guess-and-check” style …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.benkuhn.net/blub/">https://www.benkuhn.net/blub/</a></em></p>]]>
            </description>
            <link>https://www.benkuhn.net/blub/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318635</guid>
            <pubDate>Sat, 05 Dec 2020 21:37:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Descartes' God has failed and Thompson's Satan rules our computers]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317557">thread link</a>) | @jrepinc
<br/>
December 5, 2020 | https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1658">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
tpms, crypto wars, monopolism, computer science, trickbot, uefi, trickboot, trusted computing, palladium, ken thompson, rene descartes, infosec, malware, apts, seth david schoen, peter biddle, ngscb

Summary:
Descartes' God has failed and Thompson's Satan rules our computers

URL:
https://pluralistic.net/2020/12/05/trusting-trust/

Title:
Pluralistic: 05 Dec 2020 trusting-trust

Bullet:
👒

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2020/12/05/trusting-trust/"><img src="https://i2.wp.com/craphound.com/images/05Dec2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/05Dec2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">Descartes' God has failed and Thompson's Satan rules our computers</a>: Computers, trust, and the knowability of the universe.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#retro">This day in history</a>: 2005, 2010, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="thompsons-devil"></a><br>
<img src="https://i1.wp.com/craphound.com/images/NGSCBWHEC03.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/NGSCBWHEC03.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Security researchers are alarmed: the already-notorious Trickbot malware has been spotted probing infected computers to find out which version of UEFI they're running. This is read as evidence that Trickbot has figured out how to pull off a really scary feat.</p>
<p>To understand why, you have to understand UEFI: a fascinating, deep, philosophical change to our view of computers, trust, and the knowability of the universe. It's a tale of hard choices, paternalism, and the race to secure the digital realm as it merges with the physical.</p>
<p>Computers were once standalone: a central processing unit that might be augmented by some co-processors for specialized processes, like a graphics card or even a math co-processor.</p>
<p>These co-pros were subordinate to the CPU though. You'd turn on the computer and it would read a very small set of hardcoded instructions telling it how to access a floppy disk or other storage medium for the rest of the boot sequence, the stuff needed to boot the system.</p>
<p>The hardwired instructions were in a ROM that had one job: wake up and feed some instructions to the "computer" telling it what to do, then go back to sleep. But there's a philosophical conundrum here.</p>
<p>Because the world of computing is adversarial and networked computing is doubly so: there are people who want your computer to do things that are antithetical to your interests, like steal your data or spy on you or encrypt all your files and demand ransom.</p>
<p>To stop this, you need to be able to examine the programs running on your computer and terminate the malicious ones. And therein lies the rub: when you instruct your computer to examine its own workings, how do you know if you can trust it?</p>
<p>In 1983, Ken Thompson (co-creator of C, Unix, etc) was awarded a Turing Award ("computer science's Nobel Prize"). He gave a fucking bombshell of an acceptance speech, called "Reflections on Trusting Trust."</p>
<p><a href="https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf">https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf</a></p>
<p>Thompson revealed that he had created a backdoor for himself that didn't just live in Unix, but in the C compiler that people made to create new Unix systems.</p>
<p>Here's what that means: when you write a program, you produce "high-level code" with instructions like "printf("Hello, World!");". Once your program is done, you turn it into machine code, a series of much shorter instructions that your CPU understands ("mov  dx, msg" etc).</p>
<p>Most programmers can't read this machine code, and even for those who can, it's a hard slog. In general, we write our code, compile it and run it, but we don't examine it. With nontrivial programs, looking at the machine code is very, very hard.</p>
<p>Compilers are treated as intrinsically trustworthy. Give 'em some source, they spit out a binary, you run the binary. Sometimes there are compiler bugs, sure, and compiler improvements can be a big deal. But compilers are infrastructure: inscrutable and forgotten.</p>
<p>Here's what Thompson did: he hid a program in his compiler that would check to see whether you were compiling an operating system or a compiler. If you were compiling an OS, it hid a secret login for him inside of it.</p>
<p>If you were compiling a compiler, it hid the program that looked for compilers or operating systems inside of it.</p>
<p>Think about what this means: every OS you compiled had an intentional security defect that the OS itself couldn't detect.</p>
<p>If you suspected that your compiler was up to no good and wrote your own compiler, it would be compromised as soon as you compiled it. What Thompson did was ask us to contemplate what we meant when we "trusted" something.</p>
<p>It was a move straight out of Rene Descartes, the reasoning that leads up to "I think therefore I am." Descartes' "Discourse on the Method" asks how we can know things about the universe.</p>
<p>He points out that sometimes he thinks he senses something but is wrong – he dreams, he hallucinates, he misapprehends.</p>
<p>If all our reasoning depends on the impressions we get from our senses, and if our senses are sometimes faulty, how can we reason at all?</p>
<p>Descartes wants a point of certainty, one thing he <em>knows</em> to be absolutely true. He makes the case that if you can be certain of one thing, you can anchor everything else to this point and build up a massive edifice of trustable knowledge that all hangs off of this anchor.</p>
<p>Thompson is basically saying, "You thought you had descartesed your way into a trustable computing universe because of the axiom that I would never poison your lowest-level, most fundamental tools.</p>
<p>"<em>Wrong</em>.</p>
<p>"Bwahahahaha."</p>
<p>(But, you know, in a nice way: an object lesson to serve as a wake-up call before computers fully merged with the physical world to form a global, species-wide digital nervous system whose untrustworthy low-level parts were foolishly, implicitly trusted).</p>
<p>But processors were expensive and computers were exploding. PCs running consumer operating systems like Windows and Mac OS (and more exotic ones like GNU/Linux and various Unices) proliferated, and they all shared this flawed security model.</p>
<p>They all relied on the operating system to be a faithful reporter of the computer's internals, and operated on the assumption that they could use programs supervised by the OS to detect and terminate malicious programs.</p>
<p>But starting in 1999, Ken Thompson's revenge was visited upon the computing world. Greg Hoglund released Ntrootkit, a proof-of-concept malware that attacked Windows itself, so that the operating system would lie to antivirus programs about what it was doing and seeing.</p>
<p>In Decartesspeak, your computer could no longer trust its senses, so it could no longer reason. The nub of trust, the piton driven into the mountainface, was made insecure and the whole thing collapsed. Security researchers at big companies like Microsoft took this to heart.</p>
<p>In 2002, Peter Biddle and his team from Microsoft came to EFF to show us a new model for computing: "Trusted Computing" (codenamed "Palladium").</p>
<p><a href="https://web.archive.org/web/20020805211111/https://www.microsoft.com/presspass/features/2002/jul02/0724palladiumwp.asp">https://web.archive.org/web/20020805211111/https://www.microsoft.com/presspass/features/2002/jul02/0724palladiumwp.asp</a></p>
<p>Palladium proposed to give computers back their nub of Descartesian certainty. It would use a co-processor, but unlike a graphics card or a math co-pro, it would run before the CPU woke up and did its thing.</p>
<p>And unlike a ROM, it wouldn't just load up the boot sequence and go back to sleep.</p>
<p>This chip – today called a "Secure Enclave" or a "Trusted Platform Module" (etc) – would have real computing power, and it would remain available to the CPU at all times.</p>
<p>Inside the chip was a bunch of cool cryptographic stuff that provided the nub of certainty. At the start of the boot, the TPM would pull the first stages of the boot-code off of the drive, along with a cryptographic signature.</p>
<p>A quick crypto aside:</p>
<p>Crypto is code that mixes a key (a secret known to the user) with text to produce a scrambled text (a "ciphertext") that can only be descrambled by the key.</p>
<p>Dual-key crypto has two keys. What one scrambles, the other descrambles (and vice-versa).</p>
<p>With dual-key crypto, you keep one key secret (the "private key") and you publish the other one (the "public key"). If you scramble something with a private key, then anyone can descramble it with your public key and know it came from you.</p>
<p>If you scramble it <em>twice</em>, first with your private key and then with your friend's public key, then they can tell it came from you (because only your private key's ciphertexts can be descrambled with your public key).</p>
<p>And <em>you</em> can be certain that only they can read it (because only their private key can descramble messages that were scrambled with their public key).</p>
<p>Code-signing uses dual-key crypto to validate who published some code.</p>
<p>Microsoft can make a shorter version of its code (like a fingerprint) and then you scramble it with its private key. The OS that came with your computer has a copy of MSFT's public key. When you get an OS update, you can descramble the fingerprint with that built-in key.</p>
<p>If it matches the update, then you know that Microsoft signed it and it hasn't been tampered with on its way to you. If you trust Microsoft, you can run the update.</p>
<p>But…What if a virus replaces Microsoft's public keys with its own?</p>
<p>That's where Palladium's TPM comes in. It's got the keys hardcoded into it. Programs running on the CPU can only ask the TPM to do very limited things like ask it to sign some text, or to check the signature on some text.</p>
<p>It's a kind of god-chip, running below the most privileged level of user-accessible operations. By design, you – the owner of the computer – can demand things of it that it is technically capable of doing, and it can refuse you, and you can't override it.</p>
<p>That way, programs running even in the most privileged mode can't compromise it.</p>
<p>Back to our boot sequence: the TPM fetches some startup code from the disk along with a signature, and checks to see whether the OS has been signed by its manufacturer.</p>
<p>If not, it halts and shows you a scary error message. Game over, Ken Thompson!</p>
<p>It is a very cool idea, but it's also very scary, because the chip doesn't take orders from Descartes' omnibenevolent God.</p>
<p>It takes orders from Microsoft, a rapacious monopolist with a history of complicity with human rights abuses. Right from that very first meeting the brilliant EFF technologist Seth Schoen spotted this (and made the Descartes comparison):</p>
<p><a href="https://web.archive.org/web/20021004125515/http://vitanuova.loyalty.org/2002-07-05.html">https://web.archive.org/web/20021004125515/http://vitanuova.loyalty.org/2002-07-05.html</a></p>
<p>Seth identified a way of having your cake and eating it too: he proposed a hypothetical thing called an "owner override" – a physical switch that, when depressed, could be used to change which public keys lived in the chip.</p>
<p>This would allow owners …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317557</guid>
            <pubDate>Sat, 05 Dec 2020 19:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Special Kind of Hell: intmax_t in C and C++]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25316933">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://thephd.github.io/intmax_t-hell-c++-c | <a href="https://web.archive.org/web/*/https://thephd.github.io/intmax_t-hell-c++-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>C and C++ as languages have a few things separating them from each other, mostly in their minute details and, occasionally, larger feature sets like designated initializers. But there is a disturbingly high amount of C++ that can simply do C’s job far better than C<!--more-->, including when it comes to solving some of the biggest problems facing the evolution of C and C++.</p>

<p>Let’s take a contemporary problem plaguing both C and C++, affecting everyone from standard library maintainers to project developers, that has been going on for the last 20 or so years: <code>intmax_t</code>.</p>



<p>The concept behind <code>intmax_t</code> is simple enough: it is the largest integer type that your implementation and its standard library support in conjunction. Here is a few things <code>intmax_t</code> controls inside the implementation:</p>

<ul>
  <li>numeric literals are preprocessed according to what <code>intmax_t</code> can handle (C and C++);</li>
  <li>it is the maximum number of bits that can be printed portably, e.g. with <code>printf("%j", (intmax_t)value)</code> (C and C++);</li>
  <li><code>intmax_t</code> is the largest type for which <code>std::numeric_limits</code> applies, including most types up to and including that type (C++ only);</li>
  <li><code>intmax_t</code> underpins <code>std::chrono</code>’s casts and similar (e.g. no information is lost during conversions out of and into the system) (C++ only);</li>
  <li>and, there are a set of integer operations provided by the standard library (like absolute value and quotient / remainder operations) that can be done with the maximum bit precision available to the implementation (C and C++).</li>
</ul>

<p>These properties forge the basis of <code>intmax_t</code>’s purpose. Lossless storage, pass-through operations, and more can all be achieved by relying on this implicit contract of the type. Since it is a type definition, the “real” integer type underneath it can be swapped out and people relying on it can be upgraded seamlessly!</p>



<p>We cannot upgrade seamlessly.</p>

<p>C has a much higher commitment to not breaking old code and keeping “developers close to the machine”. What this actually translates to for most Application Binary Interfaces is very simplistic “name mangling” schemes (i.e., none), <a href="https://twitter.com/__phantomderp/status/1329960075096694790">weak linkers</a>, and other shenanigans. The end result is that we expose C developers to platform details that become invisible dependencies for their code that must be preserved at all costs. For example, let’s take a C Standard function that uses <code>intmax_t</code>, <code>imaxabs</code>:</p>

<div><div><pre><code><span>intmax_t</span> <span>imaxabs</span><span>(</span><span>intmax_t</span> <span>j</span><span>);</span>
</code></pre></div></div>

<p>and, let’s try to figure out how we can upgrade someone off of this usage without breaking their code too badly. We will try fixing this in both C and C++.</p>



<p>Taking <code>intmax_t</code>, let’s do a no-brainer usage case: calling a function with <code>intmax_t</code> input and return types. The syntax and usage ends up looking like this:</p>

<div><div><pre><code><span>#include &lt;inttypes.h&gt;
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>original</span> <span>=</span> <span>(</span><span>intmax_t</span><span>)</span><span>-</span><span>2</span><span>;</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>imaxabs</span><span>(</span><span>original</span><span>);</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>val</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Easy enough! But, there’s also a hidden dependency here, based on how the code is compiled. While many people compile their C standard library as a static library and only generate final binary code for what they use as to have a “self-contained” binary, the vast majority of the shared ecosystem depends on shared libraries/dynamically linked libraries for the standard. This means that when a program is milled through an operating system at program startup, the “loader” runs off to find the symbol <code>imaxabs</code> inside some system library (e.g., <code>/lib/x86_64-linux-gnu/libc-2.27.so</code> for an “amd64” system). Harmless enough, right? Well, it turns out to be a bit of a problem in practice, because the name <code>imaxabs</code> is all that’s used in C to figure out what subroutine to talk with in some shared library,</p>

<p>and that name is completely inadequate.</p>

<p>Consider the following scenario:</p>

<ol>
  <li>The glibc maintainers decide they’re going to change from <code>long long</code> as their <code>intmax_t</code> and move to <code>__int256_t</code> for most platforms, because most platforms support it and they have a lot of customers asking for it.</li>
  <li>They upgrade the <code>libc</code> to its next version for various Linux distribution, and everyone links against it when they look for the default <code>libc</code>.</li>
  <li>You have an application. Your code was not changed or updated, so it was not recompiled. It calls <code>imaxabs</code>. The argument it passes is a <code>long long</code>, because that was the type at the time you last compiled and shipped your software.</li>
  <li>The <code>imaxabs</code> used to lookup the function to call finds the version that takes a <code>__int256_t</code> in the new <code>libc</code>.</li>
  <li>Different registers are used to pass and return the function value than expected by the <code>imaxabs</code> function call in the <code>libc</code> binary, because your application is in <code>long long</code> mode but glibc expects a <code>__int256_t</code>.</li>
  <li>All hell breaks loose.</li>
</ol>

<p>This is one of the manifestations of what is called an “Application Binary Interface (ABI) Break”. ABI Breaks are generally undetectable, silent breaks that occur within the runtime of a program that completely destroy any dependency your program has on that functionality for correctness. It typically happens when a subtle detail – the registers used to negotiate a large integral value between a shared library and its application, the amount of padding a structure might have on a certain build, the ordering and layout of class members, the interpretation of bits even if the layout or passing convention of a type never changes, and even more – changes.</p>

<h2 id="but-c-is-abi-stable">“But C Is ABI-Stable?!”</h2>

<p>Not necessarily. C is a simple language, and it both sells itself on and prides itself as such. So much so, that it’s even part of the <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2021.htm">language’s rolling charter</a>. There’s barely any name mangling because there’s no overloading. If you want “virtual functions” you need to hand-craft your virtual table structure and initialize it yourself. There’s barely any lookup or entity negotiation: what you write – <a href="https://twitter.com/thingskatedid/status/1328918322507706368">however scary or cursed</a> – is what you get, in a general sense. (No, it’s not “portable assembly”. Compilers tear C code apart and make it far more efficient than the code people stuff into it. It’s not even a direct model of the machine anymore: just an abstract one.)</p>

<p>Still, sometimes even C can’t get away from it. The function <code>imaxabs</code> relates to exactly one entity that, for historical reasons, was pinned to a function taking and returning a <code>long long</code>. Upgrading it means dealing with this schism between what the user expects (<code>intmax_t</code> that got upgraded and can print <code>__int128_t</code>/<code>__int256_t</code>) with old, non-recompiled code that maintains the old invariant (<code>long long</code>, a 64-bit number).</p>



<p>Okay, so symbols can be repurposed between library versions that lead to ABI breaks. What are the ways to defend against such a world, in C?</p>

<h2 id="macros">Macros?</h2>

<p>Macros! Object-like macros are fun. You could do something like this…</p>

<div><div><pre><code><span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<p>… as a way to provide the <code>imaxabs</code> function. It is a bit like artisanal, hand-crafted, free-range, and organic ABI versioning (or, as I have affectionately come to call it: personal masochism to make up for language failures). This mostly works, until… it doesn’t!</p>

<h3 id="714">§7.1.4</h3>

<p>This is the “ABI Breaks Guaranteed” section in the C Standard. It’s real name is “§7.1.4 Use of library functions”. Reproduced below is the relevant piece that condemns us, emphasis mine:</p>

<blockquote>
  <p>Any function declared in a header may be additionally implemented as a function-like macro defined in the header, so if a library function is declared explicitly when its header is included, one of the techniques shown below can be used to ensure the declaration is not affected by such a macro. <strong>Any macro definition of a function can be suppressed locally by enclosing the name of the function in parentheses</strong>, because the name is then not followed by the left parenthesis that indicates expansion of a macro function name. For the same syntactic reason, it is permitted to take the address of a library function even if it is also defined as a macro. <strong>The use of <code>#undef</code> to remove any macro definition will also ensure that an actual function is referred to</strong>.</p>
</blockquote>

<p>Not only can a user suppress a function-like macro invocation by using the same trick used on <code>&lt;windows.h&gt;</code> like <code>(max)(value0, value1)</code>, but the C Standard Library permits them to also undefine function names:</p>

<div><div><pre><code><span>// implementer code: inttypes.h</span>
<span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<div><div><pre><code><span>// user code: main.c</span>
<span>#include &lt;inttypes.h&gt;
</span>
<span>#undef imaxabs // awh geez
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
	<span>intmax_t</span> <span>absval</span> <span>=</span> <span>imaxabs</span><span>(</span><span>val</span><span>);</span> <span>// awH GEEZ</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>absval</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Mmm……</p>

<h3 id="implementation-specific-strategies">Implementation-specific strategies</h3>

<p>Alright, the C Standard basically loads a double barrel and brings our only standardized mitigation strategy out back behind the barn. What’s left? Well, implementation-specific insanity, that’s what:</p>

<div><div><pre><code><span>extern</span>
<span>intmax_t</span>
<span>__glibc228_imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>

<span>__attribute</span><span>((</span><span>symbol</span><span>(</span><span>__MANGLE</span><span>(</span><span>__glibc228_imaxabs</span><span>))))</span>
<span>extern</span>
<span>intmax_t</span>
<span>imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>
</code></pre></div></div>

<p>This is pseudo-code. But, wouldn’t you believe it, some implementations actually do things very similar to this to get around these problems! The things they do are far more involved, like actually dropping down to the level of the linker and creating symbol maps and other exceedingly painful workarounds. The sed scripts and the awk scripts and the bash starts coming out, people are doing lots of text processing to get symbol names and match them to versioned symbol names…</p>

<p>It’s a mess.</p>

<p>Still, given the mess, it does save us from the problem. In C code you get to use “the real name” <code>imaxabs</code> as Our Lord and Savior intended, the binary gets linked to <code>___glibc228_imaxabs</code>, and everyone’s happy. There’s only one problem with this kind of fix…</p>

<p>It’s Quality of Implementation (QoI).</p>

<p>QoI is great for the pure, theoretical standard. We get to write sexy narratives in the C standard and call them “Recommended Practice”, with little footnotes furtively implying a more wonderful world while waggling our eyebrows seductively at hot, young developers in our area. Just come along, it’s going to be so great, we’re going have soooooo much fun, just go with that lovely little implementation right over there, you’re making such fine progress, enjoy yourself and come back soon my …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/intmax_t-hell-c++-c">https://thephd.github.io/intmax_t-hell-c++-c</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/intmax_t-hell-c++-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316933</guid>
            <pubDate>Sat, 05 Dec 2020 18:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Distributed Systems Fail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316475">thread link</a>) | @parsecs
<br/>
December 5, 2020 | https://robertovitillo.com/how-distributed-systems-fail/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/how-distributed-systems-fail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 05, 2020</p></header><p>At scale, any failure that can happen will eventually happen. Hardware failures, software crashes, memory leaks - you name it. The more components you have, the more failures you will experience.</p><p>This nasty behavior is caused by <em>cruel math</em> - given an operation that has a certain probability of failing, as the total number of operations performed increases, so does the total number of failures. In other words, as you scale out your application to handle more load, the more failures it will experience.</p><p>To protect your application against failures, you first need to know what can go wrong. Assuming you are using a cloud provider and not maintaning your own datacenter, the most common failures you will encounter are caused by single points of failure, the network being unreliable, slow processes, and unexpected load.</p><h2 id="single-point-of-failure"><a href="#single-point-of-failure" aria-label="single point of failure permalink"></a>Single Point of Failure</h2><p>A single point of failure is the most glaring cause of failure in a distributed system - it’s that one component that when it fails brings down the entire system with it. In practice, distributed systems can have multiple single points of failure.</p><p>A service that to start up needs to read its configuration from a non-replicated database is an example of a single point of failure - if the database isn’t reachable, the service won’t be able to start. </p><p>A more subtle example is a service that exposes a HTTP API on top of TLS and uses a certificate that needs to be manually renewed. If the certificate isn’t renewed by the time it expires, then most clients trying to connect to it wouldn’t be able to open a connection with the service. </p><p>Single points of failure should be identified when the system is architected before they can cause any harm. The best way to detect them is to examine every component of the system and ask what would happen if that component were to fail. Some single points of failure can be architected away, e.g., by introducing redundancy, while others can’t. In that case, the only option left is to minimize the blast radius.</p><h2 id="unreliable-network"><a href="#unreliable-network" aria-label="unreliable network permalink"></a>Unreliable Network</h2><p>When a client make a remote network call, it sends a request to a server and expects to receive a response from it a while later. In the best case, the client receives a response shortly after sending the request. But what if the client waits and waits and still doesn’t get a response? </p><p>In that case, the client doesn’t know whether a response will eventually arrive or not. At that point it has only two options, it can either continue to wait, or fail the request with an exception or an error.</p><p>Slow network calls are the <a href="https://robertovitillo.com/default-timeouts/">silent killers</a> of distributed systems. Because the client doesn’t know whether the response is on its way or not, it can spend a long time waiting before giving up, if it gives up at all. The wait can in turn cause degradations that are extremely hard to debug. </p><h2 id="slow-processes"><a href="#slow-processes" aria-label="slow processes permalink"></a>Slow Processes</h2><p>From an observer’s point of view, a very slow process is not very different from one that isn’t running at all - neither can perform useful work. Resource leaks are one of the most common causes of slow processes.</p><p>Memory leaks are arguably the most well-known source of leaks. A memory leak manifests itself with a steady increase in memory consumption over time. Run-times with garbage collection don’t help much either - if a reference to an object that isn’t longer needed is kept somewhere, the object won’t be deleted by the garbage collector. </p><p>A memory leak keeps consuming memory until there is no more of it, at which point the operating system starts swapping memory pages to the disk constantly, all the while the garbage collector kicks in more frequently trying its best to release any shred of memory. The constant paging and the garbage collector eating up CPU cycles make the process slower. Eventually, when there is no more physical memory, and there is no more space in the swap file, the process won’t be able to allocate more memory, and most operations will fail.</p><p>Memory is just one of the many resources that can leak. For example, if you are using a thread pool, you can lose a thread when it blocks on a synchronous call that never returns. If a thread makes a synchronous, and blocking, HTTP call <a href="https://robertovitillo.com/default-timeouts/">without setting a timeout</a>, and the call never returns, the thread won’t be returned to the pool. Since the pool has a fixed size and keeps losing threads, the pool will eventually run out of threads. </p><p>You might think that making <em>asynchronous</em> calls, rather than a synchronous ones, would mitigate the problem in the previous case. But, modern HTTP clients use socket pools to avoid recreating TCP connections and pay a <a href="https://robertovitillo.com/what-every-developer-should-know-about-tcp/">hefty performance fee</a>. If a request is made without a timeout, the connection is never returned to the pool. As the pool has a limited size, eventually there won’t be any connections left to communicate with the host.</p><p>On top of all that, the code you write isn’t the only one accessing memory, threads and sockets. The libraries your application depends on access the same resources, and they can do all kinds of shady things. Without digging into their implementation, assuming it’s open in the first place, you can’t be sure whether they can wreak havoc or not.</p><h2 id="unexpected-load"><a href="#unexpected-load" aria-label="unexpected load permalink"></a>Unexpected Load</h2><p>Every system has a limit to how much load it can withstand without scaling. Depending on how the load increases, you are bound to hit that brick wall sooner or later. But one thing is an organic increase in load, which gives you the time to scale your service out accordingly, and another is a sudden and unexpected spike.</p><p>For example, consider the number of requests received by a service in a period of time. The rate and the type of incoming requests can change over time, and sometimes suddenly, for a variety of reasons:</p><ul><li>The requests might have a seasonality - depending on the hour of the day the service is going to get hit by users in different countries.</li><li>Some requests are much more expensive than others and abuse the system in ways you didn’t really anticipate for, like scrapers slurping in data from your site at super human speed.</li><li>Some requests are malicious - think of DDoS attacks which try to saturate your service’s bandwidth, denying access to the service to legitimate users.</li></ul><h2 id="cascading-failures"><a href="#cascading-failures" aria-label="cascading failures permalink"></a>Cascading Failures</h2><p>You would think that if your system has hundreds of processes, it shouldn’t make much of a difference if a small percentage are slow or unreachable. The thing about faults is that they tend to spread like cancer, propagating from one process to the other until the whole system crumbles to its knees. This effect is also referred to as a <em>cascading failure</em>, which occurs when a portion of an overall system fails, increasing the probability that other portions fail.</p><p>For example, suppose there are multiple clients querying two database replicas A and B, which are behind a load balancer. Each replica is handling about 50 transactions per second.</p><p>{width: 75%}
<span>
      <a href="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/67fe0/cascading_failure_1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cascading failure 1" title="cascading failure 1" src="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/fcda8/cascading_failure_1.png" srcset="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/12f09/cascading_failure_1.png 148w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/e4a3f/cascading_failure_1.png 295w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/fcda8/cascading_failure_1.png 590w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/efc66/cascading_failure_1.png 885w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/67fe0/cascading_failure_1.png 1101w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>Suddenly, replica B becomes unavailable because of a network fault. The load balancer detects that B is unavailable and removes it from its pool. Because of that, replica A has to pick up the slack for replica B, doubling the load it was previously under. </p><p>{width: 75%}
<span>
      <a href="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/561da/cascading_failure_2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cascading failure 2" title="cascading failure 2" src="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/fcda8/cascading_failure_2.png" srcset="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/12f09/cascading_failure_2.png 148w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/e4a3f/cascading_failure_2.png 295w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/fcda8/cascading_failure_2.png 590w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/efc66/cascading_failure_2.png 885w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/561da/cascading_failure_2.png 969w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>As replica A starts to struggle to keep up with the incoming requests, the clients experience more failures and timeouts. In turn, they retry the same failing requests several times, adding insult to injury. </p><p>Eventually, replica A is under so much load that it can no longer serve requests promptly, and becomes for all intent and purposes unavailable, causing replica A to be removed from the load balancer’s pool. In the meantime, replica B becomes available again and the load balancer puts it back in the pool, at which point it’s flooded with requests that kill the replica instantaneously. This feedback loop of doom can repeat several time.</p><p>Cascading failures are very hard to get under control once they have started. The best way to mitigate one is to not have it in the first place by stopping the cracks in your services to propagate to others.</p><h2 id="defense-mechanisms"><a href="#defense-mechanisms" aria-label="defense mechanisms permalink"></a>Defense Mechanisms</h2><p>There is a variety of best practices you can use to mitigate failures, like circuit breakers, load shedding, rate-limiting and bulkheads. I plan to blog about those in the future, but in the meantime Google is your friend. Also, I have an entire chapter dedicated to resiliency patterns in my <a href="https://distributedsystemsmanual.com/">book about distributed systems</a>. </p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/how-distributed-systems-fail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316475</guid>
            <pubDate>Sat, 05 Dec 2020 17:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Walking]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25316328">thread link</a>) | @KlimYadrintsev
<br/>
December 5, 2020 | https://klimy.co/blog/benefits-of-walking | <a href="https://web.archive.org/web/*/https://klimy.co/blog/benefits-of-walking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How long does it take to walk 1 mile?</h2>
<p>As both research and actual scientific measurements, an average adult will walk 1 mile in 15 to 18 minutes at moderate to a brisk pace. Or in other words, 3 to 4 miles per hour.</p>
<p>This is a general measure for a healthy adult between 20 and 50 years old, at dry weather, on relatively flat terrain, with no destruction from cars and other environments.</p>
<p>If you are either less healthy or subjected to any of the environmental distractions, your speed, of course, will be lower.</p>
<h2>Average walking speed by age group and gender</h2>
<p>There is little difference between male and female, with males walking on average 2% faster.</p>
<p>The table below shows the speed of walking based on age and gender:</p>
<pre><code>| Age      | Sex    | Meters per second | Miles per hour |
|----------|--------|-------------------|----------------|
| 20 to 29 | Male   | 1.36              | 3.04           |
|          | Female | 1.34              | 3.0            |
| 30 to 39 | Male   | 1.43              | 3.2            |
|          | Female | 1.34              | 3.0            |
| 40 to 49 | Male   | 1.43              | 3.2            |
|          | Female | 1.39              | 3.11           |
| 50 to 59 | Male   | 1.43              | 3.2            |
|          | Female | 1.31              | 2.93           |
| 60 to 69 | Male   | 1.34              | 3.0            |
|          | Female | 1.24              | 2.77           |
| 70 to 79 | Male   | 1.26              | 2.82           |
|          | Female | 1.13              | 2.53           |
| 80 to 89 | Male   | 0.97              | 2.17           |
|          | Female | 0.94              | 2.10           |
</code></pre>
<h2>Benefits of walking</h2>
<p>There has been a great deal of research that showed that walking brings a huge advantage to humans. To both <a href="https://journals.sagepub.com/doi/abs/10.1177/0013916518800798">physical, and mental well being.</a> The benefits are as follows:</p>
<p>Physical:</p>
<ul>
<li>Burning calories. A direct way to reduce and to control your weight.</li>
<li>Lower glucose level and blood sugar levels. <a href="https://care.diabetesjournals.org/content/early/2013/06/03/dc13-0084">Research</a> has focused on short walks, where it helped reduce glucose intolerance.</li>
<li><a href="https://bjsm.bmj.com/content/45/12/987?sid=fe62a8c5-430b-4506-b854-20b62e8a5e9e">Help deal with infection and possibly Covid.</a></li>
<li>Help boost immune function.</li>
<li>Give additional energy to do other tasks due to increased efficiency of nutrients absorption and conversion.</li>
<li>Prolonging life. There is a <a href="https://bjsm.bmj.com/content/52/12/761">research that showed</a> evidence of having a relationship between physical activity and overall life expectancy. </li>
<li>Strengthen the heart. Even 20 minutes of daily walking has shown to reduce the risk of stroke by at least 20%.</li>
</ul>
<p>Mental:</p>
<ul>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving self esteem</a> by 45%.</li>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving mood</a> by 54%.</li>
<li>Additional time on focusing on self-education with educational podcasts and books. <a href="https://digitalcommons.georgiasouthern.edu/nyar_savannah/2020/2020/90/">Research</a> has shown that it leads to better learning of the material, longer retention, better engagement in post-walk discussions, better behaviour and mood, AND improved health literacy.</li>
<li>Improving <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">goal setting</a> in other areas by targeting non-specific goals which in consequence lead to better results.</li>
<li>Walking helps you get your thoughts in order. Whenever you are alone with yourself, and you are unable to really look at the phone, you are finally able to understand what is happening with yourself with no distractions.</li>
<li>Improve the creative part of the brain. While walking, <a href="https://psycnet.apa.org/record/2014-14435-001">research showed</a>, that it is easier to come up with great ideas.</li>
<li>Save money on medications. With the amount of food, we consume and with costly medicine, walking and doing exercises can help you save money and nerves.</li>
</ul>
<h2>Covid and sitting time</h2>
<p>In the world of pandemics and covid, it has been evident that humans are sitting more and more and do less and less exercises. There is a <a href="https://www.sciencedirect.com/science/article/pii/S221133552030214X">great research</a> that shows that 2020 has caused a sharp increase in average sitting time. The data is staggering.</p>
<p><code>Overall, 42.6% of participants reported sitting for &gt; 8 h/day (95% CI: 41.2%–44.0%) and 72.5% (71.2%–73.7%) reported being either sufficiently (150–300 MVPA minutes) or highly active (&gt;300 min).</code></p>
<p>If you want to boost your health and still to be able to keep up with a busy schedule walking or running can be the best idea for spending your free time. In the world where only entertainment inside your house is minimal. If being glued to the screen is no longer an option, than being outside can boost your health and your mental capabilities immensely.</p>
<p><img alt="walking in the park grass and women leg" src="https://i.gyazo.com/ecae9926d17ad69ded99b1a445482e9a.jpg"></p>
<h2>Tips on how to start walking</h2>
<h3>How to make walking a habit?</h3>
<p>The walk starts with the first step. It would be best if you did not put huge goals onto yourself. Start somewhere small, then later you can always adjust based on how you feel.</p>
<p>Start by putting on clothes(plus a mask) and go outside. Going back to your apartment would feel bad at that point.</p>
<p>Next, you should walk around your building or up and down the street.</p>
<p>Next, you walk around the block and later you can finally go for huge walks that can be a couple of hours long.</p>
<p>Don’t try to start at the last step that would only make you quit before you get the full benefit of the habit.</p>
<p>Peg your walking habit to something else. If you go for a coffee every morning, go to a coffee house that is further away. If you are usually riding a tube to work, start the journey at the stop further away from you</p>
<h3>Identify as a walker</h3>
<p>If you would like to start walking you need to think of <strong>how do you become a walker.</strong></p>
<p>You need to make sure you identify as someone who goes on walks, then keeping up with the habit will be much easier.</p>
<p>Next time someone asks you, whatever you do any exercises or what you love doing with your free time, you need to want to say that you love walking. At that point, you will be able to keep on walking and improving your health immensely.</p>
<h2>How much walking per week is enough?</h2>
<p>I think that it is tough to give a simple number for everyone, but if you are in the age range of 18-50, then:</p>
<ul>
<li>150 to 300 minutes per week is an ideal level if you are walking with moderate speed</li>
<li>75 to 150 minutes per week if you are walking with a brisk pace.</li>
</ul>
<p>Don’t think that doing extra physical exercise will be useless. In contrast, anything above that time limit will give even higher benefits to your health, so take the timing above as a general guideline. Do as much as you want.</p>
<h2>Personal tips on walking more</h2>
<h3>Wake up earlier</h3>
<p>Right now it is very easy to blame everything on covid and health, but not many people <a href="https://klimy.co/blog/how-to-wake-up-early">wake up very early in the morning</a>, that gives people that live in the city an ability to walk as much as they want, even in usually crowded spaces.</p>
<p>Also, your excuse of not having enough time can not be reinforced if you have an extra hour in the morning.</p>
<h3>Get a pet (dog)</h3>
<p>Even though it can seem like a lousy idea, multiple research papers show a relationship between owning a dog and the number of steps you do daily. If you are struggling to make time, your favourite pet will make you find time for walks.</p>
<p><img alt="man and dog walking in forest autumn" src="https://i.gyazo.com/5e16de8c0474f84f4285df88fab28c14.jpg"></p>
<h3>Podcasts and Audiobooks</h3>
<p>I love learning and listening to books. I do it all the time even when I am at home at my desk, so a change of pace for me is always going for an extended walk where I can do the same thing.</p>
<p>What I discovered is that I understand and remember information much better when I have consumed it while walking. That makes me spend twice as little time and getting twice the result. </p>
<p>Podcasts have been my go-to method of getting new relevant news and information in my field of expertise. Since I have started a habit of walking, I have been on top of my field and able to implement solutions that I would have never thought of otherwise.</p>
<h3>Music</h3>
<p>I also love discovering new music. Sometimes when I really need to get my head around something I go for a brisk walk with my favourite songs. This helps me to unwind and later really understand the problem.</p>
<p>Most of the time while on the walk, I solve the problem that I had, and in my experience would off taken me much more time to solve.</p>
<h3>Walking groups</h3>
<p><img alt="walking groups picture" src="https://i.gyazo.com/26609ccb0d7ae90e9f746389479a32b0.jpg"></p>
<p>Sometimes socialising can be hard and especially when all of your friends are on the lockdown and all of the socialising places, such as restaurants, are closed. </p>
<p>That is where walking groups can come into play! You can find someone who is staying healthy and being diligent with their health and walk together! That will allow you to catch up and have social interaction, that we humans require.</p>
<h5>So what this means?</h5>
<p>Now you have a social responsibility in your habit, and the whole activity can let you be more motivated to do it.</p>
<p>Also, walking groups normally allow you to meet new people and to bond better with existing relationships.</p>
<p>Also, walking groups is a great way to speed up your walking pace and improve your health.</p>
<h2>How do I get better at walking?</h2>
<p>If you would like to improve the speed at which you walk, there are multiple ways to do so:</p>
<ul>
<li>As mentioned above, walking groups are amazing for giving you a speedup of pace, just make sure to not overdo it.</li>
<li>Walking poles (tracking poles) are an easy way to speed up the pace. They are especially useful for those with back or leg injury, that immensely help reduce the stress on joints and back as well as speed up the pace. There is a lot of research behind use cases and benefits of using them.</li>
<li>Treadmills. If you are unable to properly walk in the wild or in the park, get yourself a treadmill. Although they can be expensive, some are very cheap and immensely powerful alternatives provide the same result. You don’t need something overly expensive. Treadmills are great for controlling your pace as well as letting you support yourself with the rails that are at either side of the treadmill.</li>
<li>Have an open goal. Whenever you are walking, the <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">research has shown</a> that having an open goal to where you want to walk or for how long will extend the amount of walking that you will eventually do.</li>
<li>Keep track of your metrics. Understanding what your heart rate and your pace are, is vital for your well being and motivation. Seeing that you have improved over a period of time is the greatest motivator there is.</li>
<li>Strive towards a 13 minutes per mile goal. The 13 minutes per mile has been shown to be the meeting point between fast walkers and the joggers. As …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klimy.co/blog/benefits-of-walking">https://klimy.co/blog/benefits-of-walking</a></em></p>]]>
            </description>
            <link>https://klimy.co/blog/benefits-of-walking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316328</guid>
            <pubDate>Sat, 05 Dec 2020 17:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improbable Inspiration: Bayesian Networks (1996)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25315982">thread link</a>) | @1e
<br/>
December 5, 2020 | https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html | <a href="https://web.archive.org/web/*/https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td>

      <span face="Arial,Helvetica" color="#003366">

      <b>Improbable Inspiration</b><p>
      The future of software may lie in the obscure theories of an
      18th century cleric named Thomas Bayes.

      </p><p>

      By LESLIE HELM, Times Staff Writer

      </p><hr>
      <p>

      When Microsoft Senior Vice President Steve
      Ballmer first heard his company was planning to make a huge
      investment in an Internet service offering movie reviews and
      local entertainment information in major cities across the
      nation, he went to Chairman Bill Gates with his concerns.

      </p><p>

      &nbsp;&nbsp;&nbsp; After all, Ballmer has billions of dollars of
      his own money in Microsoft stock, and entertainment isn't
      exactly the company's strong point.

      </p><p>

      &nbsp;&nbsp;&nbsp; But Gates dismissed such
      reservations. Microsoft's competitive advantage, he responded,
      was its expertise in "Bayesian networks."

      </p><p>

      &nbsp;&nbsp;&nbsp; Asked recently when computers would finally
      begin to understand human speech, Gates began discussing the
      critical role of "Bayesian" systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Ask any other software executive about
      anything "Bayesian" and you're liable to get a blank
      stare.

      </p><p> 

      &nbsp;&nbsp;&nbsp; Is Gates onto something? Is this
      alien-sounding technology Microsoft's new secret weapon?

      </p><p>

      &nbsp;&nbsp;&nbsp; Quite possibly.
      
      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks are complex diagrams that
      organize the body of knowledge in any given area by mapping out
      cause-and-effect relationships among key variables and encoding
      them with numbers that represent the extent to which one
      variable is likely to affect another.

      </p><p>

      &nbsp;&nbsp;&nbsp; Programmed into computers, these systems can
      automatically generate optimal predictions or decisions even
      when key pieces of information are missing.

      </p><p>

      &nbsp;&nbsp;&nbsp; When Microsoft in 1993 hired Eric Horvitz,
      David Heckerman and Jack Breese, pioneers in the development of
      Bayesian systems, colleagues in the field were surprised. The
      field was still an obscure, largely academic enterprise.

      </p><p>
 
      &nbsp;&nbsp;&nbsp; Today the field is still obscure. But scratch
      the surface of a range of new Microsoft products and you're
      likely to find Bayesian networks embedded in the software. And
      Bayesian nets are being built into models that are used to
      predict oil and stock prices, control the space shuttle and
      diagnose disease.

      </p><p>

      &nbsp;&nbsp;&nbsp; Artificial intelligence (AI) experts, who saw
      their field discredited in the early 1980s after promising a
      wave of "thinking" computers that they ultimately
      couldn't produce, believe widening acceptance of the Bayesian
      approach could herald a renaissance in the field.

      </p><p>
      
      &nbsp;&nbsp;&nbsp; Bayesian networks provide "an
      overarching graphical framework" that brings together
      diverse elements of AI and increases the range of its likely
      application to the real world, says Michael Jordon, professor of
      brain and cognitive science at the Massachusetts Institute of
      Technology.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is unquestionably the most
      aggressive in exploiting the new approach. The company offers a
      free Web service that helps customers diagnose printing problems
      with their computers and recommends the quickest way to resolve
      them. Another Web service helps parents diagnose their
      children's health problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; The latest version of Microsoft Office
      software uses the technology to offer a user help based on past
      experience, how the mouse is being moved and what task is being
      done.

      </p><p>

      &nbsp;&nbsp;&nbsp; "If his actions show he is distracted,
      he is likely to need help," Horvitz says. "If he's
      been working on a chart, chances are he needs help formatting
      the chart."

      </p><p>

      &nbsp;&nbsp;&nbsp; "Gates likes to talk about how computers
      are now deaf, dumb, blind and clueless. The Bayesian stuff helps
      deal with the clueless part," says Daniel T.  Ling,
      director of Microsoft's research division and a former IBM
      scientist.

      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks get their name from the
      Rev. Thomas Bayes, who wrote an essay, posthumously published in
      1763, that offered a mathematical formula for calculating
      probabilities among several variables that are causally related
      but for which--unlike calculating the probability of a coin
      landing on heads or tails--the relationships can't easily be
      derived by experimentation.

      </p><p>

      &nbsp;&nbsp;&nbsp; Early students of probability applied the
      ideas to discussions about the existence of God or efforts to
      improve their odds in gambling. Much later, social scientists
      used it to help clarify the key factors influencing a particular
      event.

      </p><p>

      &nbsp;&nbsp;&nbsp; But it was the rapid progress in computer
      power and the development of key mathematical equations that
      made it possible for the first time, in the late 1980s, to
      compute Bayesian networks with enough variables that they were
      useful in practical applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; The Bayesian approach filled a void in the
      decades-long effort to add intelligence to computers.

      </p><p>

      &nbsp;&nbsp;&nbsp; In the late 1970s and '80s, reacting to the
      "brute force" approach to problem solving by early
      users of computers, proponents of the emerging field of
      artificial intelligence began developing software programs using
      rule-based, if-then propositions. But the systems took time to
      put together and didn't work well if, as was frequently the
      case, you couldn't answer all the computer's questions clearly.

      </p><p>

      &nbsp;&nbsp;&nbsp; Later companies began using a technique
      called "neural nets" in which a computer would be
      presented with huge amounts of data on a particular problem and
      programmed to pull out patterns. A computer fed with a big stack
      of X-rays and told whether or not cancer was present in each
      case would pick out patterns that would then be used to
      interpret X-rays.

      </p><p>

      &nbsp;&nbsp;&nbsp; But the neural nets won't help predict the
      unforeseen. You can't train a neural net to identify an incoming
      missile or plane because you could never get sufficient data to
      train the system.

      </p><p>

      &nbsp;&nbsp;&nbsp; In part because of these limitations, a slew
      of companies that popped up in the early 1980s to sell
      artificial intelligence systems virtually all went bankrupt.

      </p><p>

      &nbsp;&nbsp;&nbsp; Many AI techniques continued to be
      used. Credit card companies, for example, began routinely using
      neural networks to pick out transactions that don't look right
      based on a consumer's past behavior. But increasingly, AI was
      regarded as a tool with limited use.

      </p><p>

      &nbsp;&nbsp;&nbsp; Then, in the late 1980s--spurred by the early
      work of Judea Pearl, a professor of computer science at UCLA,
      and breakthrough mathematical equations by <a href="http://www.hugin.dk/">Danish researchers</a>--AI
      researchers discovered that Bayesian networks offered an
      efficient way to deal with the lack or ambiguity of information
      that has hampered previous systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz and his two Microsoft colleagues, who
      were then classmates at Stanford University, began building
      Bayesian networks to help diagnose the condition of patients
      without turning to surgery.

      </p><p>

      &nbsp;&nbsp;&nbsp; The approach was efficient, says Horvitz,
      because you could combine historical data, which had been
      meticulously gathered, with the less precise but more intuitive
      knowledge of experts on how things work to get the optimal
      answer given the information available at a given time.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz, who with two colleagues founded
      Knowledge Industries to develop tools for developing Bayesian
      networks, says he and the others left the company to join
      Microsoft in part because they wanted to see their theoretical
      work more broadly applied.

      </p><p>

      &nbsp;&nbsp;&nbsp; Although the company did important work for
      the National Aeronautics and Space Administration and on medical
      diagnostics, Horvitz says, "It's not like your grandmother
      will use it."

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft's activities in the field are now
      helping to build a groundswell of support for Bayesian ideas.

      </p><p>

      &nbsp;&nbsp;&nbsp; "People look up to Microsoft," says
      Pearl, who wrote one of the key early texts on Bayesian networks
      in 1988 and has become an unofficial spokesman for the
      field. "They've given a boost to the whole area."
                     
      </p><p>

      &nbsp;&nbsp;&nbsp; A researcher at German conglomerate Siemens
      says Microsoft's work has drawn the attention of his superiors,
      who are now looking seriously at applying Bayesian concepts to a
      range of industrial applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; Scott Musman, a computer consultant in
      Arlington, Va., recently designed a Bayesian network for the
      Navy that can identify enemy missiles, aircraft or vessels and
      recommend which weapons could be used most advantageously
      against incoming targets.

      </p><p>

      &nbsp;&nbsp;&nbsp; Musman says previous attempts using
      traditional mathematical approaches on state-of-the-art
      computers would get the right answer but would take two to three
      minutes.

      </p><p>

      &nbsp;&nbsp;&nbsp; "But you only have 30 seconds before the
      missile has hit you," says Musman.

      </p><p>

      &nbsp;&nbsp;&nbsp; General Electric is using Bayesian techniques
      to develop a system that will take information from sensors
      attached to an engine and, based on expert opinion built into
      the system as well as vast amounts of data on past engine
      performance, pinpoint emerging problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is working on techniques that will
      enable the Bayesian networks to "learn" or update
      themselves …</p></span></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</a></em></p>]]>
            </description>
            <link>https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315982</guid>
            <pubDate>Sat, 05 Dec 2020 16:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Flaws of Human Thinking]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25315667">thread link</a>) | @dandanua
<br/>
December 5, 2020 | https://dandanua.github.io/posts/major-flaws-of-human-thinking/ | <a href="https://web.archive.org/web/*/https://dandanua.github.io/posts/major-flaws-of-human-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As in the lovely child’s quote found on the internet —</p><blockquote><p>I know everything. Except anything I don’t.</p></blockquote><p>— we think that we see everything around us. But we don’t. There are so many things that greatly affect our lives, yet we don’t aware of them. One type of such things is deep inside us — the flaws of our own thinking. Here is my top list of those flaws.</p><h2 id="1-wishful-thinking-conservatism-and-conformism"><strong>1. Wishful thinking, conservatism and conformism</strong></h2><p>By <em>wishful thinking</em> I don’t mean optimism, which is rather speculation about the future. Wishful thinking is when we put more weight on the present knowledge that is pleasant to us, and at the same time ignore the knowledge that is not so nice. For example, people like to ignore the knowledge that puts them in a bad light. This is clearly seen in toxic relationships, where an abuser justifies his actions by “the care” of its victim. A dictator probably thinks that he is doing the best for its nation, while completely ignoring his incapabilities and bad doings. The same is true for groups of people or even nations. An invasion is commonly portrayed as liberation.</p><p>On the other hand, anyone who had experienced an addiction probably knows how it can alter decision-making. “Vodka is an antiseptic, didn’t you know? Let’s drink those bottles so we’ll be healthier!” Gambler thinks that he is going to make money, so his family will be happy. An ordinary gamer thinks that other real affairs are not that important, so it’s ok to spend more time on the game.</p><p>This is just few examples, but such thinking is so common that I don’t think a single book will be enough to collect all different “use cases”.</p><hr><p>Another flaw of our thinking is <em>conservatism</em> — an insufficient ability to change our common views and beliefs with the new data, new evidence. This is understandable — changing basis views leads to a reconsideration of all related knowledge. An enormous amount of rebuilding is required. Our biological brains just can’t do that in a short time, also it’s much harder with age. Because of this, we give much more weight to old knowledge rather than new evidence, thus making a conservatism bias.</p><p>In our rapidly changing world, this problem will have even more impact.</p><hr><p><em>Conformism</em> is when we weigh our knowledge in accordance with our community. The effect of this is highly underrated. An ordinary human thinks that “her thoughts are her own”, without realizing to what extent they are shaped by a community. I think that we’re all conformists to some degree. And it’s hard to imagine what’s that means not to be. This is proved by numerous experiments with a group of actors and one unsuspicious testee, where actors trick the testee to make some ridiculous statements or to do some crazy actions, like the one described <a href="https://www.youtube.com/watch?v=vjP22DpYYh8">here</a>. We are social creatures.</p><p>An extreme version of conformist thinking is the one imposed by religion. I’m not against religions in general, they can be useful, but a blind belief, an unquestioning subordination to “sacred” authorities — that’s just a disaster for a clear mind. A clear mind should have the ability to stress any dogmas.</p><h2 id="2-binary-black-and-white-thinking-overgeneralization"><strong>2. Binary (black-and-white) thinking, overgeneralization</strong></h2><p>Good-evil, smart-stupid, beautiful-ugly, tall-short, fast-slow, and so on and on. We think in binary terms. Our language reflects that. And some people are stuck very hard in such thinking. The worst case of it is <em>all-or-nothing</em> thinking, when any result other than the best is considered as a failure. It causes stress and depression in people. They don’t realize anymore why the world is so mean to them. They stop seeing how many gradients are there, and also how colorful our world is.</p><p>A similar flaw is <em>overgeneralization</em>. We put into the same category very broad types of information. Prejudice, labeling, stereotypes are all related to overgeneralization.</p><h2 id="3-self-projecting-thinking"><strong>3. Self-projecting thinking</strong></h2><p>Mind reading is an ability that everyone would like to have. It would be so easier to communicate. Also, it’s an advantage if we could read the thoughts of our rivals. While we can’t do it in reality, we’re still trying to predict other people’s thoughts, both in collaboration and confrontation.</p><p>To make such predictions we use two main assumptions:</p><ol><li>Other people see the same things as we do.</li><li>Other people are like us, thus their way of thinking is similar to ours.</li></ol><p>Based on these assumptions we use our way of thinking to deduce the thoughts of others. And this is very natural since we have to model another person’s thinking somehow. But the only model that we have is ours. It’s the only model that we can use. So, we essentially project our mind into another person’s head.</p><p>This has a fatal flaw. Because both main assumptions are only half true. While we see the same bits of the world, perception is a way more complex process. From bits we see high-order patterns, but they can be very personal. People could see different patterns and focus on different things. Also, the same bits (e.g. colors) can cause different emotions. Associations are also personal. The way we do conclusions is also very different in people because every person has its own experience, principles, beliefs, preferences, etc. We do not understand how unique the mind of every human.</p><p>And this causes a lot of trouble. People are fighting because of misunderstandings. In most situations they don’t realize, that they are fighting against their own reflection (from a distorting mirror).</p><h2 id="4-human-centric-thinking"><strong>4. Human-centric thinking</strong></h2><p>Humans are extremely focused on their own businesses. Yes, we are successful as a whole, in comparison to other creatures. But we are still part of nature. We follow its laws. Despite this, we neglect nature and the life of other species at scale.</p><p>Moreover, we value leaders, rulers and heroes amongst us much more than others. Even in fiction secondary characters usually die (who cares), while all hail goes to the main performers. We think that leaders are responsible for like 99% of the job done. Thus, we are trying to analyze them, rather than abstract patterns, situations and laws of nature. For example, from the popular culture it may look like Hitler was solely responsible for WWII and the Holocaust. Yeah, sure. How about WWI? Or any other war, genocide, mass conflict in human history? It’s silly to think that all these things were mainly because of leaders. This is just how humans work. In every moment in history there is a mix of wishes, intentions, beliefs, possibilities, thoughts of a total population. It could be that nature just picks a random guy as a leader that represents the mass.</p><p>On the other hand, we think that human is a singular, indivisible unit. That’s also not true. We are a composition of attributes, that are selected by evolution. Any child has some attributes from its mother and some attributes from its father. Human is a composable organism, the same is true for its mind. I’m sure that everyone experienced competing thoughts in his head. There is a natural selection of thoughts ongoing in the mind of every human.</p><h2 id="5-false-associations-confusion-of-causation-and-correlation"><strong>5. False associations, confusion of causation and correlation</strong></h2><p>Our thinking is associative, and we can make connections very fast based on very small data. A typical example is superstition, which is clearly seen in <a href="https://www.psychologistworld.com/superstition">pigeon experiments</a>.</p><p>Survival bias and filtering are accompanying flaws that lead to false associations. In probability theory, this is related to the fact that independent events are not necessary conditionally independent.</p><p>Even when our associations are quite objective we can make false conclusions about the causes. In fact, in probability theory and statistics the notion of a <em>cause</em> is not even defined. Events can be either correlated or independent in this theory. To deduce <em>what causes what</em> we use other tools, like common sense, physics, etc. Typically, to deduce a causation from two correlated events, we check two main things:</p><ol><li>One event is earlier in time than another one.</li><li>There is no common cause that could explain the correlation.</li></ol><p>This is hard stuff even for scientists. Because you have to exclude any possible common cause. Earlier we could use physical locality of events to exclude a lot of possible common causes. But with the advance of quantum mechanics, even locality is not a reliable factor anymore.</p><h2 id="final-words"><strong>Final words</strong></h2><p>There are a lot of other flaws, if you want to learn more you can start <a href="https://en.wikipedia.org/wiki/Cognitive_bias">here</a> and <a href="https://en.wikipedia.org/wiki/Cognitive_distortion">here</a>. But those described above I find the most impactful. I feel them myself and meet them all the time.</p></div></div>]]>
            </description>
            <link>https://dandanua.github.io/posts/major-flaws-of-human-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315667</guid>
            <pubDate>Sat, 05 Dec 2020 16:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An accessible introduction to type theory and implementing a type-checker]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25315243">thread link</a>) | @mrathi12
<br/>
December 5, 2020 | https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Demystifying Deep Learning: Part 11</h3><p><h3>September 17, 2018</h3><h3>5 min read</h3></p><nav><h2>Series: Demystifying Deep Learning</h2><ul><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li><strong>Part 11: Backpropagation through, well, anything!</strong></li></ul></nav><hr><h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h2><p>So far in this series, we have looked at the general principle of <a href="https://mukulrathi.co.uk/demystifying-deep-learning/learning-gradient-descent">gradient descent</a>, and how we computed <a href="https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-maths-intuition-derivation-neural-network/">backpropagation</a> for each layer in a feedforward neural network, then generalising to look at <a href="https://mukulrathi.co.uk/demystifying-deep-learning/conv-net-backpropagation-maths-intuition-derivation/">backprop in different types of layers in a CNN</a>.</p><p>Now we will take a step back and look at backpropagation in a more general sense - <em>through a computation graph</em>. Through this we’ll get a general intuition for how the frameworks compute their</p><p>We’ll use the LSTM cell as our motivating example - to continue the task of sentiment analysis on the IMDB review dataset - you can find the code in the accompanying <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">Jupyter notebook</a></p><h2 id="general-backpropagation-principles"><a href="#general-backpropagation-principles" aria-label="general backpropagation principles permalink"></a>General Backpropagation Principles</h2><p>Let’s look back at the principles we’ve used in this series:</p><ul><li><p><em>Partial Derivative Intuition</em>: Think of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{y}}{\partial{x}}</annotation></semantics></math></span></span> loosely as quantifying how much <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span> would change if you gave the value of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> a little “nudge” at that point.</p></li><li><p><em>Breaking down computations</em> - we can use the <strong>chain rule</strong> to aid us in our computation - rather than trying to compute the derivative in one fell swoop, we break up the computation into smaller <strong>intermediate</strong> steps.</p></li><li><p><em>Computing the chain rule</em> - when thinking about which intermediate values to include in our chain rule expression, think about the immediate outputs of equations involving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> - which other values get directly affected when we slightly nudge <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span>?</p></li><li><p><em>One element at a time</em> - rather than worrying about the entire matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>, we’ll instead look at an element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}</annotation></semantics></math></span></span>. One equation we will refer to time and time again is:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mi>A</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>B</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi>C</mi><mo>=</mo><mi>A</mi><mi mathvariant="normal">.</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">C_{ij} = \sum_k A_{ik}B_{kj} \iff  C=A.B</annotation></semantics></math></span></span></p><p>A useful tip when trying to go from one element to a matrix is to look for summations over repeated indices (here it was k) - this suggests a matrix multiplication.</p><p>Another useful equation is the element-wise product of two matrices:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>B</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi>C</mi><mo>=</mo><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C_{ij} = A_{ij}B_{ij} \iff  C=A*B</annotation></semantics></math></span></span></p></li><li><p><em>Sanity check the dimensions</em> - check the dimensions of the matrices all match (the derivative matrix should have same dimensions as the original matrix, and all matrices being multiplied together should have dimensions that align.</p></li></ul><p>A <strong>computation graph</strong> allows us to clearly break down the computations, as well as see the immediate outputs when computing our chain rule.</p><p>We will use the computation graph representation <em>(shown above</em>) of the LSTM to compute the gradients using backpropagation through time.</p><h2 id="the-lstm-computation-graph"><a href="#the-lstm-computation-graph" aria-label="the lstm computation graph permalink"></a>The LSTM Computation Graph</h2><h3 id="forward-propagation-equations"><a href="#forward-propagation-equations" aria-label="forward propagation equations permalink"></a>Forward Propagation equations</h3><p>From the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">previous post</a>, the forward propagation equations for one timestep in the LSTM are:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>i</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_i = \sigma(W_i.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_i)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>f</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>f</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_f = \sigma(W_f.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_f)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>o</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>o</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_o = \sigma(W_o.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_o)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>W</mi><mi>c</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;} =\tanh (W_c.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_c)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>+</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">{c}^{&lt; t&gt;} = \Gamma_i*\tilde{c}^{&lt; t&gt;} + \Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>∗</mo><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;} = \Gamma_o*\tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p><strong>Notation used</strong>:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span> denotes a <strong>concatenation of the two matrices</strong> to form a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a+n_x)</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> matrix. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">A.B</annotation></semantics></math></span></span> denotes matrix multiplication of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span>, whereas <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A*B</annotation></semantics></math></span></span> denotes elementwise multiplication. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> refers to the gate - see the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">previous post</a> defining the LSTM for a full breakdown of the notation used.</p><p>To backpropagate through the cell, given the gradient with respect to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t&gt;}</annotation></semantics></math></span></span> from the backprop from the next step, we need to compute the gradients for each of the weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>o</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_i, W_f, W_o, W_c</annotation></semantics></math></span></span> and biases <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>o</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">b_i, b_f, b_o, b_c</annotation></semantics></math></span></span>, and finally we will need to backpropagate to the previous timestep and compute the gradient with respect to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t-1&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t-1&gt;}</annotation></semantics></math></span></span>.</p><p>These are a <em>lot</em> of partial derivatives to compute - indeed as our neural networks get more complicated there will be more partial derivatives to calculate.</p><h3 id="how-can-we-use-our-computation-graph-to-break-this-down"><a href="#how-can-we-use-our-computation-graph-to-break-this-down" aria-label="how can we use our computation graph to break this down permalink"></a>How can we use our computation graph to break this down?</h3><p>Firstly, since the gate equations are identical, we can combine them so instead we have a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> containing the 3 gates’ outputs, and we can refer to the first third of the matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_i</annotation></semantics></math></span></span> and the other two thirds <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_f</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_o</annotation></semantics></math></span></span> respectively. Then we have one <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a + n_x)</annotation></semantics></math></span></span> matrix of weights for the gates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">W_g</annotation></semantics></math></span></span> and one <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> bias vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">b_g</annotation></semantics></math></span></span>.</p><p>Next, we want to document all intermediate stages in calculation (every node in the graph).</p><p>So, walking through the computation graph node-by-node in the forward step:</p><ul><li><p>We concatenate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t-1&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{&lt; t&gt;}</annotation></semantics></math></span></span> to form the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a + n_x)</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> concatenated input matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span>.</p></li><li><p>We calculate the weighted input matrix for the gates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> using the weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">W_g</annotation></semantics></math></span></span> and bias <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">b_g</annotation></semantics></math></span></span>.</p></li><li><p>Likewise we calculate the weighted input <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span> for the candidate memory <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> using the weight matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_c</annotation></semantics></math></span></span> and bias <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">b_c</annotation></semantics></math></span></span>.</p></li></ul><p>(<em>NB:</em> the diagram uses one weight matrix W, but it helps to think about these weights separately because of the different activation functions used)</p><ul><li><p>We apply the sigmoid activation function to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> to get the Gate matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> (denoted by <strong>f</strong>, <strong>i</strong>, <strong>o</strong> in diagram), and the tanh activation function to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span> to get <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> (denoted by <strong>g</strong> in the diagram).</p></li><li><p>Since elementwise multiplication and addition are straightforward operations, for brevity we won’t give the intermediate outputs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\Gamma_i*\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span> their own symbols.</p></li><li><p>Let us denote the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> intermediate output as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span>.</p></li></ul><p>Now we have broken down the computation graph into steps, and added our intermediate variables we have the equations:</p><ol><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub><mo>=</mo><msub><mi>W</mi><mi>g</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g = W_g.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_g</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub><mo>=</mo><msub><mi>W</mi><mi>c</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c = W_c.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_c</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>Z</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma = \sigma(Z_g)</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;} =\tanh Z_c</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>+</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">{c}^{&lt; t&gt;} = \Gamma_i*\tilde{c}^{&lt; t&gt;} + \Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{a}^{&lt; t&gt;} = \tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;} = \Gamma_o*\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span></p></li></ol><p>These equations correspond to the nodes in the graph - the left-hand-side variable is the ouput edge of the node, and the right-hand-side variables are the input edges to the node.</p><h2 id="backpropagation-in-a-computation-graph"><a href="#backpropagation-in-a-computation-graph" aria-label="backpropagation in a computation graph permalink"></a>Backpropagation in a Computation Graph:</h2><p>These equations allow us to clearly see the immediate outputs with respect to a variable when computing the chain rule - <em>e.g. for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span> the immediate outputs are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span></em>.</p><p>If we look at the equations / computation graph, we can more generally look at the type of operations, and then use the same identities:</p><ul><li><p><strong>Addition</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>+</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C = A + B</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = 1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{B}} = 1</annotation></semantics></math></span></span></p></li><li><p><strong>Elementwise multiplication</strong>:
If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C = A * B</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = B</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>=</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{B}} = A</annotation></semantics></math></span></span></p></li><li><p><strong>tanh</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">C = \tanh A</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mn>1</mn><mo>−</mo><msup><mo><mi>tanh</mi><mo>⁡</mo></mo><mn>2</mn></msup><mi>A</mi><mo>=</mo><mn>1</mn><mo>−</mo><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = 1 - \tanh^2 A = 1 - C^2</annotation></semantics></math></span></span></p></li><li><p><strong>sigmoid</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C = \sigma(A)</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>−</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = \sigma (A)- \sigma^2 (A) = C*(1-C)</annotation></semantics></math></span></span></p></li><li><p><strong>Weighted Input</strong>: this is the same equation as the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/feed-forward-neural-network/">feedforward neural network</a>. If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>W</mi><mi mathvariant="normal">.</mi><mi>X</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Z =  W.X + b</annotation></semantics></math></span></span> then:</p></li></ul><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>W</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac><mi mathvariant="normal">.</mi><msup><mi>X</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W}}=  \frac{1}{m} \frac{\partial{J}}{\partial{Z}}.X^{T}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b}} = \frac{1}{m} \sum_{i=1}^{m}\frac{\partial{J}}{\partial{Z}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>X</mi></mrow></mfrac><mo>=</mo><msup><mi>W</mi><mi>T</mi></msup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{X}} = W^{T}.\frac{\partial{J}}{\partial{Z}}</annotation></semantics></math></span></span></p><p>Armed with these general computation graph principles, we can apply <strong>chain rule</strong>. We elementwise multiply (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span>) the partial derivatives, i.e.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span></p><p>Also note we sum partial derivatives coming from each of the immediate outputs:</p><p>So if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B = f(A)</annotation></semantics></math></span></span>
and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C = g(A)</annotation></semantics></math></span></span>, i.e. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> are immediate outputs of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> in the computation graph, then we sum the partial derivatives:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}} + \frac{\partial{J}}{\partial{C}}*\frac{\partial{C}}{\partial{A}}</annotation></semantics></math></span></span></p><p>In a <strong>deep learning framework</strong> like <em>TensorFlow</em> or <em>Keras</em>, there will be identities like this for each of the differentiable operations.</p><h2 id="backpropagation-through-time-in-an-lstm-cell"><a href="#backpropagation-through-time-in-an-lstm-cell" aria-label="backpropagation through time in an lstm cell permalink"></a>Backpropagation Through Time in an LSTM Cell</h2><p>When trying to compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}}</annotation></semantics></math></span></span>, we’ll use the general equation:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span></p><p>For brevity, we’ll substitute the value of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span> using the operations’ identities above.</p><p>The equations are thus as follows:</p><p>From equation 7:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\tilde{a}^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{a^{&lt; t&gt;}}}* \Gamma_o</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_o}}= \frac{\partial{J}}{\partial{a^{&lt; t&gt;}}}*\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p>Using equation 6, and writing equation 5 as an equation for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t+1&gt;}</annotation></semantics></math></span></span> instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t&gt;}</annotation></semantics></math></span></span> (i.e. adding 1 to the timestep):</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo><mn>2</mn></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{c^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{c^{&lt; t+1&gt;}}}*\Gamma_f + \frac{\partial{J}}{\partial{\tilde{a}^{&lt; t&gt;}}} *(1-\tilde{a}^{&lt; t&gt;2})</annotation></semantics></math></span></span></p><p>Also using equation 5:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\tilde{c}^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*\Gamma_i</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_i}}= \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_f}}= \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*c^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p><p>From equations 3 and 4 respectively:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="normal">Γ</mi></mrow></mfrac><mo>∗</mo><mi mathvariant="normal">Γ</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi mathvariant="normal">Γ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{Z_g}} = \frac{\partial{J}}{\partial{\Gamma}}*\Gamma*(1-\Gamma)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><msup><mo>&gt;</mo><mn>2</mn></msup></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{Z_c}} = \frac{\partial{J}}{\partial{\tilde{c}^{&lt; t&gt;}}}*(1-\tilde{c}^{&lt; t&gt;^2})</annotation></semantics></math></span></span></p><p>Equations 1 and 2 are identical, and so are the partial derivatives, differing only in subscript.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>W</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W_g}} = \frac{1}{m} \frac{\partial{J}}{\partial{Z_g}}.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]^T</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>b</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msubsup><mi>Z</mi><mi>g</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b_g}} = \frac{1}{m}\sum_{i=1}^{m} \frac{\partial{J}}{\partial{Z_g^{(i)}}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>W</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W_c}} = \frac{1}{m} \frac{\partial{J}}{\partial{Z_c}}.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]^T</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>b</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msubsup><mi>Z</mi><mi>c</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b_c}} = \frac{1}{m}\sum_{i=1}^{m} \frac{\partial{J}}{\partial{Z_c^{(i)}}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow></mrow></mfrac><mo>=</mo><msubsup><mi>W</mi><mi>g</mi><mi>T</mi></msubsup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mo>+</mo><msubsup><mi>W</mi><mi>c</mi><mi>T</mi></msubsup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]}} =  W_g^T.\frac{\partial{J}}{\partial{Z_g}}+     W_c^T.\frac{\partial{J}}{\partial{Z_c}}</annotation></semantics></math></span></span></p><p>So by breaking the computation graph into many steps, we can break down the calculation into smaller simpler steps that just use the operations’ derivative identities mentioned above.</p><h3 id="code"><a href="#code" aria-label="code permalink"></a>Code:</h3><p>The motivating example we’ve looked at uses an <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">LSTM network</a> for sentiment analysis on a dataset of IMDB reviews</p><div><div><pre><p><span>def</span><span> </span><span>backward_step</span><span>(</span><span>dA_next</span><span>,</span><span> dC_next</span><span>,</span><span>cache</span><span>,</span><span>parameters</span><span>)</span><span>:</span><span></span></p><p><span>    </span><span>(</span><span>a_next</span><span>,</span><span> c_next</span><span>,</span><span> input_concat</span><span>,</span><span> c_prev</span><span>,</span><span> c_candidate</span><span>,</span><span>IFO_gates</span><span>)</span><span> </span><span>=</span><span> cache</span></p><p><span>    n_a</span><span>,</span><span> m </span><span>=</span><span> a_next</span><span>.</span><span>shape</span></p><p><span>    dC_next </span><span>+=</span><span> dA_next</span><span>*</span><span> </span><span>(</span><span>IFO_gates</span><span>[</span><span>2</span><span>*</span><span>n_a</span><span>:</span><span>]</span><span>*</span><span>(</span><span>1</span><span>-</span><span>np</span><span>.</span><span>tanh</span><span>(</span><span>c_next</span><span>)</span><span>**</span><span>2</span><span>)</span><span>)</span><span></span></p><p><span>    dC_prev </span><span>=</span><span> dC_next </span><span>*</span><span> IFO_gates</span><span>[</span><span>n_a</span><span>:</span><span>2</span><span>*</span><span>n_a</span><span>]</span><span></span></p><p><span>    dC_candidate </span><span>=</span><span>  dC_next </span><span>*</span><span> IFO_gates</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dIFO_gates </span><span>=</span><span> np</span><span>.</span><span>zeros_like</span><span>(</span><span>IFO_gates</span><span>)</span><span></span></p><p><span>    dIFO_gates</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span> </span><span>=</span><span> dC_next </span><span>*</span><span> c_candidate</span></p><p><span>    dIFO_gates</span><span>[</span><span>n_a</span><span>:</span><span>2</span><span>*</span><span>n_a</span><span>]</span><span>=</span><span> dC_next </span><span>*</span><span> c_prev</span></p><p><span>    dIFO_gates</span><span>[</span><span>2</span><span>*</span><span>n_a</span><span>:</span><span>]</span><span> </span><span>=</span><span> dA_next </span><span>*</span><span> np</span><span>.</span><span>tanh</span><span>(</span><span>c_next</span><span>)</span><span></span></p><p><span>    dZ_gate </span><span>=</span><span>  dIFO_gates</span><span>*</span><span> </span><span>(</span><span>IFO_gates</span><span>*</span><span>(</span><span>1</span><span>-</span><span>IFO_gates</span><span>)</span><span>)</span><span></span></p><p><span>    dA_prev </span><span>=</span><span>  </span><span>(</span><span>parameters</span><span>[</span><span>"Wg"</span><span>]</span><span>.</span><span>T</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>dZ_gate</span><span>)</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dWg </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>dZ_gate</span><span>.</span><span>dot</span><span>(</span><span>input_concat</span><span>.</span><span>T</span><span>)</span><span></span></p><p><span>    dbg </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>np</span><span>.</span><span>sum</span><span>(</span><span>dZ_gate</span><span>,</span><span>axis</span><span>=</span><span>1</span><span>,</span><span> keepdims</span><span>=</span><span>True</span><span>)</span><span></span></p><p><span>    dZ_c </span><span>=</span><span> dC_candidate </span><span>*</span><span> </span><span>(</span><span>1</span><span>-</span><span>c_candidate</span><span>**</span><span>2</span><span>)</span><span></span></p><p><span>    dA_prev </span><span>+=</span><span>  </span><span>(</span><span>parameters</span><span>[</span><span>"Wc"</span><span>]</span><span>.</span><span>T</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>dZ_c</span><span>)</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dWc </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>dZ_c</span><span>.</span><span>dot</span><span>(</span><span>input_concat</span><span>.</span><span>T</span><span>)</span><span></span></p><p><span>    dbc </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>np</span><span>.</span><span>sum</span><span>(</span><span>dZ_c</span><span>,</span><span>axis</span><span>=</span><span>1</span><span>,</span><span> keepdims</span><span>=</span><span>True</span><span>)</span><span></span></p><p><span>    </span><span>return</span><span> dA_prev</span><span>,</span><span> dC_prev</span><span>,</span><span> dWg</span><span>,</span><span> dbg</span><span>,</span><span> dWc</span><span>,</span><span> dbc</span></p></pre></div></div><div><h3>Join me on this learning journey!</h3><p>This summer I’m using my blog to teach the topics I’ve learnt this year. It’s a win-win - you get computer science tutorials and I get to share it with you!</p></div><h3 id="practical-considerations"><a href="#practical-considerations" aria-label="practical considerations permalink"></a>Practical Considerations:</h3><p>When checking the equations for the backprop, it helps to have a numerical checker - I’ve written one in the accompanying <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">Jupyter notebook</a>.</p><h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2><p>This seems like a good juncture to recap the series so far.</p><p>We started the series looking at the most commonly used termninology, followed by looking at simple machine learning algorithms in <a href="https://mukulrathi.co.uk/demystifying-deep-learning/linear-logistic-regression/">linear and logistic regression</a>, building up the intuition behind the maths behind <a href="https://mukulrathi.co.uk/demystifying-deep-learning/learning-gradient-descent/">gradient descent</a> as we built up to a <a href="https://mukulrathi.co.uk/demystifying-deep-learning/feed-forward-neural-network/">feedforward neural network</a>.</p><p>Next we looked at the learning process itself, and how we could <a href="https://mukulrathi.co.uk/demystifying-deep-learning/optimising-gradient-descent/">improve gradient descent</a> itself, as well as <a href="https://mukulrathi.co.uk/demystifying-deep-learning/debug-neural-network-learning/">debug our model</a> to see whether it was learning or not.</p><p>Finally, we moved onto more specialised neural networks - <a href="https://mukulrathi.co.uk/demystifying-deep-learning/convolutional-neural-network-from-scratch/">CNNs</a> and <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">recurrent neural nets</a>, not only looking at their theory but the motivation behind them. We also looked at the maths behind them, deriving the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/conv-net-backpropagation-maths-intuition-derivation/"> CNN backprop</a> equations from scratch.</p><p>Now that we’re at the point that we’re able to understand backprop in a general computation graph, we can use the abstractions of the deep learning frameworks in subsequent posts.</p></article></div>]]>
            </description>
            <link>https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315243</guid>
            <pubDate>Sat, 05 Dec 2020 15:31:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in Sweden]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25314732">thread link</a>) | @ComputingMonk
<br/>
December 5, 2020 | https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/ | <a href="https://web.archive.org/web/*/https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <h2 id="i">I</h2><p>When Sweden announced their laissez-faire approach to COVID-19, experts, and politicians around the world, were in disbelief. Without a lockdown and mandatory masks, this could only end in a disaster. The famous model used to justify the lockdown in the <a href="https://www.businessinsider.com/neil-ferguson-transformed-uk-covid-response-oxford-challenge-imperial-model-2020-4?r=DE&amp;IR=T">UK and many other countries</a>, predicted 100.000 deaths by June if Sweden did not follow all the other countries and institute strict measures. It is now November, and at the time of writing, 6,972 people have died in Sweden from COVID-19. So what happened?</p><h2 id="ii">II</h2><p>Let’s take a step back and look at the famous model, which was the basis for many of the government measures back in March as well as for the 100.000 death prediction: The Imperial Model. It was developed by Neil Fergusson and his team at the Imperial College London.</p><p>The involvement of Neils Fergusson should already have raised doubts about the validity of the model because his track record, and there is no other way to say this, is terrible. If you think it cannot be that bad, you are in for a surprise.</p><p>We will do what <a href="https://www.businessinsider.com/neil-ferguson-transformed-uk-covid-response-oxford-challenge-imperial-model-2020-4?r=DE&amp;IR=T">Business Insider</a> promised back in April:</p><blockquote>Here's what we know about “Professor Lockdown” and the gold standard in science that is Imperial College.</blockquote><p>Of course, they did not mention his past predictions, and the “gold standard” turned out to be fake gold, but let's not get ahead of ourselves. His past predictions:</p><ul><li><a href="https://www.nationalreview.com/wp-content/uploads/2020/05/Ferguson-Estimating-the-human-health-risk-from-possible-BSE-infection-of-the-British-sheep-flock.pdf">In 2002</a>, Ferguson predicted that up to 150,000 people could die from exposure to BSE (mad cow disease) in the U.K. There were only 177 deaths.</li><li><a href="https://www.nationalreview.com/corner/professor-lockdown-modeler-resigns-in-disgrace/">In 2009</a>, Ferguson predicted that the bird flu could kill 150 million people. 282 people died worldwide.</li><li><a href="https://www.spectator.co.uk/article/six-questions-that-neil-ferguson-should-be-asked">In 2009</a>, Ferguson predicted as a “reasonable worst-case scenario” that the swine flu would kill 65,000 people in Britain. It killed 457.</li></ul><p>I think that is enough about our “Professor Lockdown.” We want to focus more on the model and “the gold standard in science that is Imperial College.”</p><h2 id="iii">III</h2><p>One reason why nobody doubted the model was that it was secret—always a smart move. When on March 16, 2020, Neil and his team published their paper, they did not publish their code. Yes, you read that correctly. Their paper made several policy recommendations based on predictions of a model <em>they did not publish</em>. So there was no way of knowing if their claims were true or false. They were simply baseless claims without any evidence.</p><p>To me, this destroys any trustworthiness Neil Ferguson might have had left. One hallmark of science is independent verifiability. Without others being able to verify the claims and run the model themselves, it is not science; it is pseudo-science with a strong appeal to authority.</p><p>On April 27, over one month after the paper in question was published, they finally released their code on <a href="https://github.com/mrc-ide/covid-sim">GitHub</a>. However, it turns out that they did not release the original code used to generate the predictions in their paper. The released version was edited by software engineers of GitHub to make it acceptable:</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Before the GitHub team started working on the code it was a single 15k line C file that had been worked on for a decade, and some of the functions looked like they were machine translated from Fortran. There are some tropes about academic code that have grains of truth, but \</p>— John Carmack (@ID_AA_Carmack) <a href="https://twitter.com/ID_AA_Carmack/status/1254872369556074496?ref_src=twsrc%5Etfw">April 27, 2020</a></blockquote>

</figure><p>As you can read in this Tweet, the original code was “a single 15k line C file that had been worked on for a decade.” Everyone with a little bit of knowledge about software engineering should be shocked. A single 15000 line C file is beyond bad practice.</p><p>But even GitHubs’s engineers could not salvage the code. The released version is still riddled with bugs and random equations that literally nobody can explain. Moreover, even if the released code were exactly the code used in the paper, no one could have replicated the results because the input parameters used in the paper were not published. As the <a href="https://github.com/mrc-ide/covid-sim/tree/master/data">GitHub page</a> reads:</p><blockquote>IMPORTANT: The parameter files are provided as a sample only and do not necessarily reflect runs used in published papers.</blockquote><p>At this point, we are long past science, with a small s, and far into the world of Science, with a capital S. The latter is the world where the term “Believe the Science” makes sense. While science (small s) is the process of doubting everything, disregarding authority, and searching for the truth, Science (capital S) is where the truth is determined by fiat, and your job is to believe, not question it. But I digress.</p><h2 id="iv">IV</h2><p>After several issues around the non-deterministic behavior of the model were brought up on GitHub, the team responded with an <a href="https://github.com/mrc-ide/covid-sim/issues/116#issuecomment-617304550">interesting answer</a>:</p><blockquote>We are aware of some small non-determinisms when using multiple threads to set up the network of people and places. (Look for the omp critical pragmas in the code). This has historically been considered acceptable because of the general stochastic nature of the model.</blockquote><p>Non-deterministic means that given the same input, you do not always get the same output (non-deterministic behavior is not necessarily bad; only in cases like this where it is not explainable). Their answer to this problem was that it does not matter because the model is “stochastic,” which is just a fancy word for saying that they run the model multiple times and average over all the outcomes.</p><p>Every time a new issue around non-determinism came up or a different bug was discovered, the team’s answer was the <a href="https://github.com/mrc-ide/covid-sim/issues/30">same</a>:</p><blockquote>This isn’t a problem running the model in full as it is stochastic anyway.</blockquote><p>But is this really true? You do not have to worry about bugs because “it is stochastic anyway”? The answer is, obviously, no.</p><p>To understand this stochastic magic better, let’s take a look at an example: baking a cake. If we weigh flour, we might weigh it several times and then average over all these measurements—only if we are nerds and want to follow the recipe particularly closely, of course. But why does this give us a more accurate result? The answer is that if, for example, we make an error when reading from the scale (imagine an old analog scale), then an error in one direction (more) is as likely as an error in the other direction (less). In other words, if the flour weighs 100 grams, you are just as likely to mistake it for 102 g the first time, and 98 g the next. Only if we make mistakes sometimes in one direction and sometimes in another, averaging out works. Otherwise, <em>it does not</em>. If your scale is broken, and always shows five grams more, averaging does not help you.</p><p>The same is true for bugs. If, and only if, we could be sure that the bugs distort the output sometimes upwards and sometimes downwards (preferably with equal probability and magnitude), we could solve the problem by running the model “stochastically.” However, this is not the case because, by definition, we do not know how bugs affect the code; otherwise we would understand them and probably be able to fix them. The point is that nobody, including the “scientists” who produced this model, can know how those bugs affect the code.</p><p>Do not get me wrong, stochastic models are not necessarily like this. Most of the time, if the model is not too complicated (we will get to this point later), small changes in the input create small changes in the output, and the randomness in the output stems from intentionally included pseudo-randomness. However, this model is not non-deterministic in the predictable (explainable) mathematical sense. It is non-deterministic in the angry-toddler-in-a-toy-store sense: nobody knows what is going to happen, and there is no way to replicate it. <a href="https://medium.com/@allenfarrington/simple-truths-and-complex-nonsense-2e1c28ae6f29">Put differently</a>:</p><blockquote>It has nondeterministic outputs that do not follow from seeded pseudorandomness but are rather an inexplicable part of the process. I am not using “inexplicable” rhetorically here: nobody can explain this. This is one of the great issues in Complexity Science. Clearly there is a stark mathematical difference between deterministic and non-deterministic. But there is also a fuzzy, and arguably more important, difference between non-deterministic and really, really, really NON-DETERMINISTIC.</blockquote><p>Unfortunately, the Imperial Model falls into the latter category.</p><h2 id="v">V</h2><p>Alright, a summary of what we have learned so far: the code was not released with the paper; the released code is not the code used in the paper; the original code was a single 15 thousand line C file; the model is non-deterministic bordering on chaotic; the parameters released are not the parameters used in the paper; the code is riddled with bugs. An impressive list for a “scientific” model that informed government decisions on life and death.</p><h2 id="vi">VI</h2><p>But what about the model without the code? Sure, the code that implements the model is awful, but maybe they have figured out a great way to model pandemics and just need better software engineering to make it work. Sadly, this is not the case.</p><p>Do you remember the parameters that were <em>not</em> provided so nobody could replicate the results of the paper? It turns out that the model has 450 input parameters. Let me say it again: the model depends on <em>450 (!!!)</em> parameters. Nobody can understand a model with this many parameters. And it gets even worse because as it turns out, complex systems like pandemics have many interdependencies, which complicates everything. As described by Allen <a href="https://medium.com/@allenfarrington/simple-truths-and-complex-nonsense-2e1c28ae6f29">here</a>:</p><blockquote>Now I should be clear that, maybe, the virus is that complicated. But it doesn’t matter. Because we can’t possibly understand this. And actually I lowballed it by a factor of 450 (Oh, God …). Because if this system is linear, which it surely is not, what this really means is that a single set of parameters can be represented as a 450-dimensional column vector acting on a 450x450 matrix with 450² = 202k independent numbers. Because, remember, the parameters can be anything. Katya suspects they are totally made up. So it’s not just the dimensions we need to account for. The surface of the earth has 2 dimensions but more than 2 locations. Assuming every entry in this matrix has only two possible states, which it surely does not, this model maps a system with at least …</blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/">https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/</a></em></p>]]>
            </description>
            <link>https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314732</guid>
            <pubDate>Sat, 05 Dec 2020 14:21:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Wrote a Book on Data Analysis with Rust Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25314170">thread link</a>) | @DataCrayon
<br/>
December 5, 2020 | https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
    <div id="et-boc">
			
		<!-- #end wrapper --><div>
			<div>
		<div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				
				
				<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they’re implemented in practice.</p>
			</div>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				
				
				<div>
					<div data-columns="4">
	<figure>
		<p><a href="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg"><img width="480" height="679" src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" alt="" loading="lazy" title="cover_darn" data-caption="" data-src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image_width="480" data-large_image_height="679" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg 480w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-212x300.jpg 212w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-300x424.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></a></p>	</figure>
</div>

				</div>
			</div>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				<div>
					 <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_row_inner --><div>
				<div>
				
				
				<div>
				
				
				<ul>
					<li><a href="#">Description</a></li>
				</ul>
				<div>
					<div>
					<div>
						<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.</p>
<ul>
<li><strong>Discounted</strong>&nbsp;<strong>Price</strong> that will grow as the book does,</li>
<li>All code examples in <strong>Rust</strong>,</li>
<li><strong>Rust (Jupyter) Notebooks</strong> for each Section,</li>
<li>Supplementary <strong>Video Tutorials</strong>,</li>
<li>Format: <strong>PDF download</strong>,</li>
<li><strong>Unlimited</strong> downloads and access to updates.</li>
</ul>
<p>Get it now to enhance your work in Rust, NDArray, Data Science, Data Analysis, and Machine Learning.</p>

					</div><!-- .et_pb_tab_content" -->
				</div>
				</div> <!-- .et_pb_all_tabs -->
			</div> <!-- .et_pb_tabs -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row_inner -->
			</div> <!-- .et_pb_column -->
				</div> <!-- .et_pb_row -->
				
			</div> <!-- .et_pb_section --> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				 <!-- .et_pb_text --><p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/shahin_square.jpg" alt="" title="shahin_square" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square.jpg 288w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-150x150.jpg 150w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-100x100.jpg 100w" sizes="(max-width: 288px) 100vw, 288px"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><p>Dr. Shahin Rostami is a <a href="http://staffprofiles.bournemouth.ac.uk/display/srostami" target="_blank" rel="noopener noreferrer">Senior Academic (Associate Professor)</a> and <a href="https://www.linkedin.com/in/shahinrostami/" target="_blank" rel="noopener noreferrer">Consultant</a> in Data Science and Artificial Intelligence, with applications in the areas of Healthcare and Defence.</p>
<p>As a <a href="https://www.heacademy.ac.uk/system/files/downloads/UK%20Professional%20Standards%20Framework%20%28PSF%29_1.pdf">Senior Fellow</a> of the Higher Education Academy and <a href="https://shahinrostami.com/">Programme Leader</a> for many postgraduate programmes, he aims to contribute openly available learning resources through this website and his <a href="https://www.youtube.com/shahinrostami" target="_blank" rel="noopener noreferrer">YouTube channel</a>.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Dr. Rostami writes and maintains the works published and offered through this website. You can expect ongoing updates and support through the communication channels listed below.</p>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/author-icon-03-2.png" alt="" title=""></span>
			</p><div>
				
				
				<div><p>The aim is to generate everything in this book through code! This means you’ll see the code for all the figures and tables, including things like flowcharts.</p>
<p>Every section is intended to be independent and <span jsslot=""><span data-dobid="hdw">reproducible</span></span>, so you’ll find some repetition as you progress from one section to another.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h2>10% discount on books.</h2>
<p>Join the newsletter to receive book and software updates, as well as discounts and occasional freebies! Your email will only used for this newsletter.</p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_code --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column --> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
		    </div></div>]]>
            </description>
            <link>https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314170</guid>
            <pubDate>Sat, 05 Dec 2020 12:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std::visit is everything wrong with modern C++ (2017)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 206 (<a href="https://news.ycombinator.com/item?id=25314126">thread link</a>) | @xucheng
<br/>
December 5, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fiancée cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let’s talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let’s say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods—e.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on—but this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It’s called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let’s take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we’ll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn’t make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we’re given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm—<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That’s a bit better, but the standard library doesn’t provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We’ll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11’s <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don’t like any of these options, you could
use C++17’s compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about—and grok—the new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you’re an experienced C++ developer,
but several are certainly “advanced” features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn’t to disparage the folks on the ISO C++ committee
who picked this approach.
I’ve had beers with some of them,
and they’re smart, kind, hardworking people.
I’m sure that I’m missing important context since I’ve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider’s perspective, the disparity in complexity between the
problem being solved (“What’s in here?”)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other…
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn’t</em> to
make it a tool for the masses, shouldn’t it be?)
The very least C++17 could do—if the committee didn’t have the time or resources
to get pattern matching into the language—is provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I’d assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don’t flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it’s completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they’re looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I’m also not here to claim that C++ is too complicated for its own good,
but it’s certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I’m sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it’s hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There’s a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you’ll quickly realize that
metaprogramming needn’t require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you’ll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>—which themselves have been a breath of fresh air—are
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That’s a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn’t going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I’ll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they’re worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
“If you can’t program in a language with ugly warts, maybe C++ isn’t the language
you should be programming in.”</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314126</guid>
            <pubDate>Sat, 05 Dec 2020 12:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Down Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25314066">thread link</a>) | @lelf
<br/>
December 5, 2020 | https://greydanus.github.io/2020/12/01/scaling-down/ | <a href="https://web.archive.org/web/*/https://greydanus.github.io/2020/12/01/scaling-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <div>

  

  <article>
  

<div>
    <div>
    <video id="demoDisplay">
    	<source src="https://greydanus.github.io/assets/scaling-down/construction.mp4" type="video/mp4">
    </video>
    <p>Constructing the MNIST-1D dataset. As with the original MNIST dataset, the task is to learn to classify the digits 0-9. Unlike the MNIST dataset, which consists of 28x28 images, each of these examples is a one-dimensional sequence of points. To generate an example, we begin with 10 digit templates and then randomly pad, translate, add noise, and transform them as shown above.</p>
  	</div>
</div>





<p>By any scientific standard, the Human Genome Project <a href="https://deepblue.lib.umich.edu/handle/2027.42/62798">was enormous</a>: it involved billions of dollars of funding, dozens of institutions, and over a decade of accelerated research. But that was only the tip of the iceberg. Long before the project began, scientists were hard at work assembling the intricate science of human genetics. And most of the time, they were not studying humans. The foundational discoveries in genetics centered on far simpler organisms such as peas, molds, fruit flies, and mice. To this day, biologists use these simpler organisms as genetic “minimal working examples” in order to save time, energy, and money. A well-designed experiment with Drosophilia, such as <a href="https://pubmed.ncbi.nlm.nih.gov/10746727/">Feany and Bender (2000)</a>, can teach us an astonishing amount about humans.</p>

<p>The deep learning analogue of Drosophilia is the MNIST dataset. A large number of deep learning innovations including <a href="https://jmlr.org/papers/v15/srivastava14a.html">dropout</a>, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">convolutional networks</a>, <a href="https://arxiv.org/abs/1406.2661">generative adversarial networks</a>, and <a href="https://arxiv.org/abs/1312.6114">variational autoencoders</a> began life as MNIST experiments. Once these innovations proved themselves on small-scale experiments, scientists found ways to scale them to larger and more impactful applications.</p>

<p>They key advantage of Drosophilia and MNIST is that they dramatically accelerate the iteration cycle of exploratory research. In the case of Drosophilia, the fly’s life cycle is just a few days long and its nutritional needs are negligible. This makes it much easier to work with than mammals, especially humans. In the case of MNIST, training a strong classifier takes a few dozen lines of code, less than a minute of walltime, and negligible amounts of electricity. This is a stark contrast to state-of-the-art vision, text, and game-playing models which can take months and <a href="https://arxiv.org/abs/2004.08900">hundreds of thousands of dollars</a> of electricity to train.</p>

<p>Yet in spite of its historical significance, MNIST has three notable shortcomings. First, it does a poor job of differentiating between linear, nonlinear, and translation-invariant models. For example, logistic, MLP, and CNN benchmarks obtain 94, 99+, and 99+% accuracy on it. This makes it hard to measure the contribution of a CNN’s spatial priors or to judge the relative effectiveness of different regularization schemes. Second, it is somewhat large for a toy dataset. Each input example is a 784-dimensional vector and thus it takes a non-trivial amount of computation to perform hyperparameter searches or debug a metalearning loop. Third, MNIST is hard to hack. The ideal toy dataset should be procedurally generated so that researchers can smoothly vary parameters such as background noise, translation, and resolution.</p>

<p>In order to address these shortcomings, we propose the MNIST-1D dataset. It is a minimalist, low-memory, and low-compute alternative to MNIST, designed for exploratory deep learning research where rapid iteration is a priority. Training examples are 20 times smaller but they are still better at measuring the difference between 1) linear and nonlinear classifiers and 2) models with and without spatial inductive biases (eg. translation invariance). The dataset is procedurally generated but still permits analogies to real-world digit classification.</p>

<div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_a.png"></p><p>Constructing the MNIST-1D dataset. Like MNIST, the classifier's objective is to determine which digit is present in the input. Unlike MNIST, each example is a one-dimensional sequence of points. To generate an example, we begin with a digit template and then randomly pad, translate, and transform it.</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_b.png"></p><p>Visualizing the performance of common models on the MNIST-1D dataset. This dataset separates them cleanly according to whether they use nonlinear features (logistic regression vs. MLP) or whether they have spatial inductive biases (MLP vs. CNN). Humans do best of all. Best viewed with zoom.</p>
  </div>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/tsne.png">
  </p>
  <p>Visualizing the MNIST and MNIST-1D datasets with tSNE. The well-defined clusters in the MNIST plot indicate that the majority of the examples are separable via a kNN classifier in pixel space. The MNIST-1D plot, meanwhile, reveals a lack of well-defined clusters which suggests that learning a nonlinear representation of the data is much more important to achieve successful classification. Thanks to <a href="https://twitter.com/hippopedoid">Dmitry Kobak</a> for making this plot.</p>
</div>

<h2 id="example-use-cases">Example use cases</h2>

<p>In this section we will explore several examples of how MNIST-1D can be used to study core “science of deep learning” phenomena.</p>

<p><strong>Finding lottery tickets.</strong> It is not unusual for deep learning models to have ten or even a hundred times more parameters than necessary. This overparameterization helps training but increases computational overhead. One solution is to progressively prune weights from a model during training so that the final network is just a fraction of its original size. Although this approach works, conventional wisdom holds that sparse networks do not train well from scratch. Recent work by <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a> challenges this conventional wisdom. The authors report finding sparse subnetworks inside of larger networks that train to equivalent or even higher accuracies. These “lottery ticket” subnetworks can be found through a simple iterative procedure: train a network, prune the smallest weights, and then rewind the remaining weights to their original initializations and retrain.</p>

<p>Since the original paper was published, a multitude of works have sought to explain this phenomenon and then harness it on larger datasets and models. However, very few works have attempted to isolate a “minimal working example” of this effect so as to investigate it more carefully. The figure below shows that the MNIST-1D dataset not only makes this possible, but also enables us to elucidate, via carefully-controlled experiments, some of the reasons for a lottery ticket’s success. Unlike many follow-up experiments on the lottery ticket, this one took just two days of researcher time to produce. The curious reader can also <a href="https://bit.ly/3nCEIaL">reproduce these results</a> in their browser in a few minutes.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a2.png">
  </p>
  <p>Finding and analyzing lottery tickets. In <b>a-b)</b>, we isolate a "minimum viable example" of the effect. Recent work by <a href="https://arxiv.org/abs/1906.02773">Morcos et al (2019)</a> shows that lottery tickets can transfer between datasets. We wanted to determine whether spatial inductive biases played a role. So we performed a series of experiments: in <b>c)</b> we plot the asymptotic performance of a 92% sparse ticket. In <b>d)</b> we reverse all the 1D signals in the dataset, effectively preserving spatial structure but changing the location of individual datapoints. This is analogous to flipping an image upside down. Under this ablation, the lottery ticket continues to win.</p>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b2.png">
  </p>
    <p>Next, in <b>e)</b> we permute the indices of the 1D signal, effectively removing spatial structure from the dataset. This ablation hurts lottery ticket performance significantly more, suggesting that part of the lottery ticket's performance can be attributed to a spatial inductive bias. Finally, in <b>f)</b> we keep the lottery ticket sparsity structure but initialize its weights with a different random seed. Contrary to results reported in <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a>, we see that our lottery ticket continues to outperform a dense baseline, aligning well with our hypothesis that the lottery ticket mask has a spatial inductive bias. In <b>g)</b>, we verify our hypothesis by measuring how often unmasked weights are adjacent to one another in the first layer of our model. The lottery ticket has many more adjacent weights than chance would predict, implying a local connectivity structure which helps gives rise to spatial biases.</p>
</div>

<p>You can also visualize the actual masks selected via random and lottery pruning:
<br></p>





<p><strong>Observing deep double descent.</strong> Another intriguing property of neural networks is the “double descent” phenomenon. This phrase refers to a training regime where more data, model parameters, or gradient steps can actually <em>reduce</em> a model’s test accuracy<sup id="fnref:fn1" role="doc-noteref"><a href="#fn:fn1">1</a></sup> <sup id="fnref:fn2" role="doc-noteref"><a href="#fn:fn2">2</a></sup> <sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3">3</a></sup> <sup id="fnref:fn4" role="doc-noteref"><a href="#fn:fn4">4</a></sup>. The intuition is that during supervised learning there is an interpolation threshold where the learning procedure, consisting of a model and an optimization algorithm, is just barely able to fit the entire training set. At this threshold there is effectively just one model that can fit the data and this model is very sensitive to label noise and model mis-specification.</p>

<p>Several properties of this effect, such as what factors affect its width and location, are not well understood in the context of deep models. We see the MNIST-1D dataset as a good tool for exploring these properties. In fact, we were able to reproduce the double descent pattern after a few hours of researcher effort. The figure below shows our results for a fully-connected network and a convolutional model. We also observed a nuance that we had not seen mentioned in previous works: when using a mean square error loss, the interpolation threshold lies at \(n * K\) model parameters where \(n\) is the number of training examples and \(K\) is the number of model outputs. But when using a negative log likelihood loss, the interpolation threshold lies at \(n\) model parameters – it does not depend on the number of model outputs. This is an interesting empirical observation that may explain some of the advantage in using a log likelihood loss over a MSE loss on this type of task. You can reproduce these results <a href="https://bit.ly/2UBWWNu">here</a>.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_a.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_b.png">
  </p>
  <p>Observing deep double descent. MNIST-1D is a good environment for determining how to locate the interpolation threshold of deep models. This threshold is fairly easy to predict in fully-connected models but less easy to …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greydanus.github.io/2020/12/01/scaling-down/">https://greydanus.github.io/2020/12/01/scaling-down/</a></em></p>]]>
            </description>
            <link>https://greydanus.github.io/2020/12/01/scaling-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314066</guid>
            <pubDate>Sat, 05 Dec 2020 12:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Smart TV is probably ignoring your PiHole]]>
            </title>
            <description>
<![CDATA[
Score 400 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25313776">thread link</a>) | @giuliomagnifico
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313776</guid>
            <pubDate>Sat, 05 Dec 2020 11:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[72% of smart TVs and 46% of game consoles hardcode DNS settings]]>
            </title>
            <description>
<![CDATA[
Score 459 | Comments 596 (<a href="https://news.ycombinator.com/item?id=25313480">thread link</a>) | @boramalper
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313480</guid>
            <pubDate>Sat, 05 Dec 2020 10:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make slides with text, markdown, YAML, JSON or JavaScript, your call]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25313347">thread link</a>) | @abusedmedia
<br/>
December 5, 2020 | https://play.presenta.cc/v2 | <a href="https://web.archive.org/web/*/https://play.presenta.cc/v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://play.presenta.cc/v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313347</guid>
            <pubDate>Sat, 05 Dec 2020 10:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Between two Lisps]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25313311">thread link</a>) | @galfarragem
<br/>
December 5, 2020 | https://ane.github.io/2020/10/05/between-two-lisps.html | <a href="https://web.archive.org/web/*/https://ane.github.io/2020/10/05/between-two-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Out of all Lisps the ones I’ve come to appreciate the most are <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a> and <a href="https://common-lisp.net/">Common
Lisp</a>. <!--break-->These two languages are fundamentally very different: Scheme
is a minimalist language built on the foundations of <a href="https://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a>, while
Common Lisp is a multi-paradigm synthesis of many Lisps before it. Common Lisp
is a large standard with many implementations, Scheme is a collection of an
evolving but minimalistic standard with many implementations. The core of Scheme
is quite small compared to Common Lisp. The latest standard <a href="http://www.r6rs.org/final/r6rs-lib.pdf">R6RS</a> is about 65
pages, while the ANSI Common Lisp standard from 1994 is about 1100 pages. The
<a href="https://srfi.schemers.org/">Scheme Requests for Implementation</a> process aims to standardize additional
features (like <a href="https://srfi.schemers.org/srfi-64/srfi-64.html">test suites</a>) that implementations may implement.</p>

<p>Common Lisp has some wonderful features, <a href="http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html">conditions and restarts</a>, the <a href="https://lispcookbook.github.io/cl-cookbook/clos.html">Common
Lisp Object System (CLOS)</a>, <a href="http://www.paulgraham.com/onlisp.html">the macro system</a>, among many other things. The <a href="http://joaotavora.github.io/sly/">SLY
IDE for Emacs</a> is <em>amazing</em>, and the <a href="http://www.sbcl.org/">Steel Bank Common Lisp</a> compiler is really
great. It has <a href="https://www.quicklisp.org/index.html">Quicklisp</a> and <a href="https://common-lisp.net/project/asdf/">ASDF</a> for package and build management,
respectively. I find the developer experience of Common Lisp to be superior to
almost anything imaginable, and this is not an empty statement: having used all
sorts of IDEs and editors for over 25 years, I have seen <em>many</em>.</p>

<h3 id="tastes-differ">Tastes differ</h3>

<p>That said, Common Lisp is <em>weird</em>. What I find particularly jarring is that
functions and variables live in different namespaces: if you put a function into
a variable, you can’t just use it like a function, you have to <code>funcall</code> it.
Having programmed in lots of languages of the ML family this is just, well, odd;
but this is due to historical reasons and there are <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">sound technical reasons for
it</a>.  There are other
oddities, some strange things like <code>(cdr '())</code> is not an error (in Scheme it
is), <code>()</code> and <code>nil</code> are equal (in Scheme <code>#f</code> and <code>()</code> are separate things), and
so on.</p>

<p>This isn’t really a fault in Common Lisp: other languages have impacted my taste
and preferences to bias me in the direction of Scheme, but that is not to say I
cannot work with Common Lisp’s idiosyncracies. Actually, I don’t mind them, I
just <em>notice</em> them.</p>

<p>I like the naming styles of Scheme more, as well. It has <code>string?</code> vs <code>string-p</code>
for predicate functions, <code>set!</code>  for state modifying functions, <code>foo-&gt;bar</code> for
conversions, these make code quite easier to read. Scheme has hygienic macros,
Guile has the traditional <code>defmacro</code> as well.</p>

<p>Many nice Scheme features are available in Common Lisp libraries. Pattern match
is available in the <a href="https://github.com/guicho271828/trivia">trivia</a> library. Named lets are easy to implement with a macro.</p>

<p>Common Lisp aficionados are quick to point out things Scheme <em>doesn’t</em> have:
keyword arguments, docstrings, rest arguments, but my Scheme implementation of
choice Guile has these built into the language.</p>

<h3 id="productivity-matters">Productivity matters</h3>

<p>Guile is in a strange niche is that its primary <em>raison d’être</em> is to be an
extension language for the GNU project. Like Emacs Lisp is for extending Emacs,
Guile is the <em>de facto</em> language for GNU programs for extension and scripting.</p>

<p>Guile doesn’t have Quicklisp and its package manager and build system is
basically nonexistent for the first and <a href="https://www.gnu.org/software/autoconf/">Autoconf</a> for the second. There is
<a href="https://lists.gnu.org/archive/html/guile-user/2017-03/msg00168.html">sentiment</a> in the Guile community to have <a href="https://guix.gnu.org/">Guix</a> as the package manager for
Guile. This might sound a bit onerous, since Guix is also a complete package
management for many other things than Guile, but consider this: as Andy Wingo
points out in his message that Guile libraries often come with C extensions,
Guile packages need some sort of managed build system for building the C
extensions. Since it doesn’t have one, to solve the problem of building a
package manager you’d also have to build a build system that can manage C code
and packages needed by the C code bits. To do this elegantly is a gargantuan
task, for instance, <a href="https://wiki.call-cc.org/man/5/Extensions#installing-eggs-that-use-libraries">chicken-install just asks you to put compiler/linker flags
on the command line before calling it</a>, so it obviously is a hard problem.</p>

<p>Now, Guix solves all that, and more, in a manner that is quite elegant and
interesting. But it’s not as lightweight as something like Quicklisp or
<a href="https://wiki.call-cc.org/man/5/Extensions"><code>chicken-install</code></a> from <a href="http://call-cc.org/">CHICKEN Scheme</a>. What is more, Guix works only on GNU/Linux
systems really, so macOS and Windows users won’t be able to do use your library
if you plan on distributing it via Guix. Duh, it’s the GNU project, but
portability is always nice.</p>

<p>But in Common Lisp I can write <code>(ql:quickload :alexandria)</code> and voilà, it will
automatically install the <a href="http://quickdocs.org/alexandria/">Alexandria</a> library that I can use. Then again, in
Common Lisp it’s somewhat rarer to have C extensions, so I don’t know how ASDF
handles that.</p>

<p>It is unfair to compare <a href="http://joaotavora.github.io/sly/">SLY</a> to <a href="https://www.nongnu.org/geiser/">Geiser</a>, the best Emacs Scheme integration
package.  SLY is based on <a href="https://common-lisp.net/project/slime/">SLIME</a> which has <em>decades</em> of man-years of work behind
it. Geiser is able to support multiple Scheme implementations and it is quite
impressive in this regard. But SLY obviously has much more (e.g. an interactive
debugger). That said, Geiser has nice Guile support, and Guile is in general the
most Common Lisp-y of all Schemes, in fact, it has</p>

<ul>
  <li>an imitation of CLOS in the form of <a href="https://www.gnu.org/software/goops/">GOOPS</a></li>
  <li>docstrings and keyword, rest, and optional arguments for function
definitions</li>
  <li>an interactive REPL and a mutable top-level (unlike many Schemes)</li>
  <li>a nice module system</li>
  <li><a href="https://www.gnu.org/software/guile/manual/html_node/Defmacros.html"><code>defmacro</code></a> and exceptions somewhat <a href="https://www.gnu.org/software/guile/manual/html_node/Raising-and-Handling-Exceptions.html">similar to Common Lisp restarts </a></li>
</ul>

<p>and some nice things Common Lisp doesn’t have like first-class
continuations. But then again I would use those rarely.</p>

<h3 id="when-would-i-pick-one-over-the-other">When would I pick one over the other?</h3>

<p>If I were to write an extensible C/C++/Rust program that I <em>know</em> will need to use
a low-level language, I might do the low level bits using a low level language
and then write the rest in Guile. Guile makes it very easy to spin up a REPL
socket to do something like <code>myprogram --repl=12345</code> that you can connect to, and
the interop between C and Guile is fantastic, it has to be, as it’s primarily an
extension language.</p>

<p>On the other hand, if were to build a wholly standalone application, the choice is
not as obvious. I could do the whole thing in either language. Common Lisp can
build native executables, although their size will be large (who cares?) since
the binary will include the whole Lisp implementation. Guile cannot compile to
native code so you’ll have to write a script executable, but that doesn’t really
matter.</p>

<p>Scenarios where I would pick Guile:</p>

<ul>
  <li>when I’m making an extensible program that has to have some C/C++ bits but I
want to make it scriptable by users</li>
  <li>when I want to write a native binary but not write too much C/C++ code</li>
  <li>I just want to write Scheme, because Scheme is a bit more elegant</li>
  <li>the project has something to do with the <a href="https://www.gnu.org/software/autoconf/">GNU project</a></li>
</ul>

<p>On the other hand, Common Lisp makes the most sense if I just want to enjoy a
seriously rapid development experience, a large standard library and language,
and I don’t mind having 50MB binaries (again, who cares?) if I were to write
standalone programs. Guile can’t do that, but it’s easy to either write Guile
scripts or a C program that essentially bootstraps a binary to load a Scheme
runtime. This is how <a href="http://lilypond.org/">LilyPond</a> is written, for example.</p>

<p>So the answer to which one is decidedly <strong>both</strong>! Both languages are really fun to
write. At the moment I don’t do Lisp at my day job so it’s all for fun
anyway. If this were for professional purposes, I don’t know. Very often a
strict requirement for professional work is to be able to be productive. In that
regard I think Common Lisp has a significant edge, not only due to its superior
development experience, but its history as a real production language. There are
actual companies doing stuff in Common Lisp. I have not heard of any
professional (in the industrial sense) uses of Guile, notwithstanding that many
projects powered by Guile (Guix, etc.)  are <em>extremely</em> professional in the way
they are written and maintained. But Common Lisp has <em>more</em> libraries and
companies behind it.</p>

<h3 id="what-about-clojure">What about Clojure?</h3>

<p>I’ve actually had the pleasure to use Clojure for personal fun, and a little bit
of professional use. I wrote a couple of libraries (<a href="https://github.com/ane/vigil">vigil</a> and <a href="https://github.com/ane/task">task</a>) and my
experience with has always been positive and its development experience is
excellent. Clojure isn’t a true Lisp, or well, it is part of the <em>Lisp
family</em>. Its ability to interface with the JVM makes it easy to leverage the
thousands of JVM libraries out there.</p>

<p>I’d gladly do it again, though I feel that Common Lisp with CLOS and its module
system makes it somewhat easier to practice <a href="https://en.wikipedia.org/wiki/Programming_in_the_large_and_programming_in_the_small"><em>programming in the large</em></a>. Clojure
explores interesting territories with <a href="https://clojure.org/guides/spec">spec</a>, so it is interesting to see what
direction the language will take in the future.</p>

<h3 id="final-words-emacs-lisp">Final words: Emacs Lisp</h3>

<p>There’s also a parenthetical elephant in the room here: Emacs Lisp! An old
descendant of <a href="https://en.wikipedia.org/wiki/Maclisp">MacLisp</a>, it’s actually quite fun to write, and the fact that Emacs
itself is the interpreter, you have superb introspectability for any Elisp
code. Most of the Lisp I write these days is probably Emacs Lisp. It’s very
close to Common Lisp. <a href="https://www.gnu.org/software/emacs/manual/html_mono/cl.html#Overview">cl-lib</a> adds a sufficient amount of convenience from
Common Lisp to make Elisp writing quite enjoyable. <a href="https://www.gnu.org/software/emacs/manual/html_mono/eieio.html#Top">EIEIO</a> adds a subset of CLOS
that can be used seamlessly with cl-lib. The condition system is missing.</p>

<p>I’ve also done a fair bit of <a href="https://fennel-lang.org/">Fennel</a>, a Lisp that compiles to Lua. I used it to
write a <a href="https://github.com/ane/mudrally">small game</a> and it was fun to write since you could develop the game in a
REPL.</p>

<p>All in all, Lisp in all its variants is the most fun I’ve ever had while
programming a computer. Guile and Common Lisp are definitely the most fun I’ve
had programming in <em>Lisp</em>.</p>

  </div></div>]]>
            </description>
            <link>https://ane.github.io/2020/10/05/between-two-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313311</guid>
            <pubDate>Sat, 05 Dec 2020 10:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of Template Haskell and cross compilation]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313146">thread link</a>) | @fanf2
<br/>
December 5, 2020 | https://www.tweag.io/blog/2020-11-25-asterius-th/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-25-asterius-th/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Template Haskell (TH) is a widely used yet controversial language extension. You have
probably used it in your own code; with a single line of splice code, you can
achieve tasks like deriving instances and embedding files easily. And you might
also have heard the reasons why people may dislike it: it slows down
compilation, breaks encapsulation, arbitrary IO at compile time is risky, etc.</p>
<p>But it is less well known that Template Haskell also makes cross compilation
with GHC harder. In this post, we’ll show why this is a challenge, some existing
solutions developed by the community, and in particular, how this problem is
addressed by <a href="https://github.com/tweag/Asterius">Asterius</a>.</p>
<h2>Just run some code at compile time, what can go wrong?</h2>
<p>Conceptually, Template Haskell is a principled way of generating Haskell AST at
compile time, like in the simplified example below:</p>
<div data-language="haskell"><pre><code>

<span><span>import</span> Data.Char</span>
<span><span>import</span> Language.Haskell.TH.Syntax</span>
<span><span>import</span> System.Process</span>

<span>gitRev</span> <span>::</span> <span>String</span>
<span>gitRev</span> <span>=</span>
  <span>$</span><span>(</span> <span>do</span>
       <span>rev</span> <span>&lt;-</span>
         <span>runIO</span> <span>$</span>
           <span>filter</span> <span>isHexDigit</span> <span>&lt;$&gt;</span> <span>readProcess</span> <span>"git"</span> <span>[</span><span>"rev-parse"</span><span>,</span> <span>"HEAD"</span><span>]</span> <span>""</span>
       <span>liftString</span> <span>rev</span>
   <span>)</span></code></pre></div>
<p>Suppose we’d like to define a <code>gitRev</code> string that represents the current <code>git</code>
revision in the project repository. This can be done using an expression splice:
it is written using the <code>$(...)</code> syntax, and the content within <code>$()</code> is an
expression of type <code>Q Exp</code>, representing a compile-time computation that returns
an <code>Exp</code> value, which is, in this case, the current <code>git</code> revision as a string
literal.</p>
<p>Splice code lives in the <code>Q</code> monad, which manages the context for Template
Haskell and provides a rich set of interfaces. Inside <code>Q</code> we can query info
about datatypes or functions, allocate fresh identifiers, etc. Arbitrary <code>IO</code>
actions may also be run inside <code>Q</code>. Here, we run <code>git rev-parse HEAD</code> to obtain
the <code>git</code> revision and then return it. When GHC compiles this module, the splice
is replaced with a string literal, and compilation moves on.</p>
<p>So at first glance, Template Haskell is just about running user code at compile
time, what can go wrong? All is right for most developers, who compile to the
same platform they run GHC on, but there’s trouble ahead when you try to do
cross compilation…</p>
<h2>The what and why of cross compilation</h2>
<p>Suppose we’d like to write a Haskell app for an Android phone or a Raspberry
Pi. It’s possible to bootstrap a native GHC release on them and use it to
compile stuff, but given the limited hardware resources of these machines, it’s
wiser to run GHC on a proper x64 build server and emit code for these ARM
devices. When we do so, we’re performing <em>cross compilation</em>. Some terminology:</p>
<ul>
<li>The <em>host</em> platform is where we run GHC to compile stuff.</li>
<li>The <em>build</em> platform is where we compile GHC. For simplicity, we assume
build=host and only use the host term from now on.</li>
<li>The <em>target</em> platform is where we run the compiled Haskell app. When
host=target, the GHC is a <em>native</em> GHC, otherwise it’s a <em>cross</em> GHC.</li>
</ul>
<p>For a native GHC, Template Haskell isn’t a problem, since GHC can link and run its
emitted code just like native dynamic libraries. But this doesn’t work
out-of-the-box for a cross GHC.</p>
<p>Over the years, people have come up with different approaches to address the
cross compilation issue of Template Haskell, each coming with its own rough
edges; more details follow in later sections.</p>
<h2>Only run TH on the host platform</h2>
<p>If we can’t run emitted code, then how about we don’t run it at all and stay
with a cross GHC without TH support? We’ll preprocess the cross GHC input code,
strip usages of the Template Haskell extension, and replace all TH splices with
the expanded code. And the way to expand the splices would be… using a native
GHC to compile it!</p>
<p>There’s a GHC flag <code>-ddump-splices</code> which dumps the expanded splices code.
Unfortunately, the dump output has extra text decorations and isn’t proper Haskell
source code, so it takes more work to use the dumps. Here’s a list of known
implementations of the splice dump approach:</p>
<ul>
<li><a href="http://source.git-annex.branchable.com/?p=source.git;a=blob;f=Build/EvilSplicer.hs;h=e07034c5b05f47c316a1e68e6a85d54335c8e253;hb=aaa841e60a55524c3efb5e9783b8e6074d2413cc"><code>EvilSplicer</code></a> uses a <code>parsec</code>-based parser to process the dumps
for later consumption of cross GHC. It was used in the
<a href="https://git-annex.branchable.com/"><code>git-annex</code></a> project until late 2018.</li>
<li><a href="https://hackage.haskell.org/package/zeroth"><code>ZeroTH</code></a> is a tool which does something similar, and includes a CLI
and <code>Cabal</code>-related helper functions.</li>
<li><a href="https://github.com/reflex-frp/reflex-platform"><code>reflex-platform</code></a> uses a patched native GHC which dumps the
expanded splices as proper Haskell source code, and feeds into <a href="https://github.com/ghcjs/ghcjs">GHCJS</a>.</li>
</ul>
<p>However, making native/cross GHC work together is not trivial:</p>
<ul>
<li>Unlike <code>gcc</code> or <code>clang</code> which can emit code for other platforms by simply
adding relevant CLI flags, a GHC installation can only emit code for a single
target platform configured at its build time. So two different GHC
installations must be managed in isolated places.</li>
<li>Native/cross GHC must have the same version and process the same build plan to
minimize the chance of emitting wrong code. Say package <code>foo</code> includes a TH
splice that uses package <code>bar</code>, if native/cross GHC sees different versions
(or even same version but different build plan) of <code>bar</code>, the splice behavior
could potentially differ, expanding into wrong code that may be silently
consumed by cross GHC.</li>
</ul>
<p>Given the complexity of the required hacks and GHC/Cabal’s lack of cross
compilation support, it’s common to use an external build system (e.g.
<a href="https://nixos.org/">Nix</a>) to encapsulate this mechanism.</p>
<p>Other than saving dumps of expanded splices, there is another solution to only
run TH splice code on the host platform: the same GHC always compile everything
to both host/target code in one invocation! When running TH, we can just load
host code just like native GHC. This requires quite some customization of GHC
behavior and is only possible for 3rd-party compilers based on GHC API. In
fact, GHCJS used this approach in its earliest days.</p>
<h3>Pros and cons of running TH on the host platform</h3>
<p>Running TH on the host platform works for pure splices, which can only do
things like reifying info and generating ASTs. It should also work pretty well
for side-effecting splices which reads files, spawns processes or fires
missiles, since the splice behavior should be just the same as when we use a
native GHC to compile stuff.</p>
<p>But is this the end of story? Not yet. Here’s one immediate problem: the
native/cross GHC may not consume the same Haskell sources despite our best
efforts.</p>
<ul>
<li>Haskell modules may use the <code>CPP</code> extension with target-specific macros, so
when you compile for different targets, you see different top-level
definitions.</li>
<li>Cabal files may also check implementation/platform/etc, and end up with
different flags or even different modules to be consumed by GHC.</li>
</ul>
<p>The problems above will likely trigger compile-time errors. And there’s an even
stealthier problem that may lead to generating incorrect code instead of a
crash: the architecture difference of host/target, e.g. word size or endianness.
For instance, a TH splice may make use of <code>sizeOf (undefined :: Int)</code>, which is
4 on 32-bit target platforms, and if the host platform is 64-bit, then the TH
splice will see 8, which sneaks into the emitted code without a single warning.</p>
<h2>Run TH code on the target platform</h2>
<p>As explained in earlier sections, vanilla GHC can only link and run host code.
Would it be possible to teach GHC to link and run target code? The answer is
yes. The key to supporting running non-native code is RPC (Remote Procedure
Calls). GHC needs to call into target code to obtain the splice expansion
result; the target code needs to call GHC to do reification. These calls are
achieved via exchanging serialized messages between GHC and the loaded splices.
Since there is a fixed set of operations allowed in the <code>Q</code> monad (as methods of
the <code>Quasi</code> class), the operations and the results can be encoded as a
serializable <code>Message</code> datatype.</p>
<p>This RPC approach to run TH code is standardized in the <a href="https://gitlab.haskell.org/ghc/ghc/-/wikis/commentary/compiler/external-interpreter">external
interpreter</a> feature. When running TH, GHC starts an
external process calls <code>iserv</code>, pipes messages to <code>iserv</code> and tells it to load
archives, objects, etc and link code. After a splice starts running in <code>iserv</code>,
<code>iserv</code> may send queries back to GHC and get results. Finally, the splice
expansion result is sent back to GHC.</p>
<p>The external interpreter opens up the possibility of using various emulators
(e.g. <code>wine</code> for windows, <code>node</code> for js/wasm or even <code>qemu</code> for exotic
platforms) to run target code for TH. GHC itself doesn’t need to care about how
the code is actually linked and run in <code>iserv</code>, and TH should work as long as
our target-specific <code>iserv</code> can properly process the messages.</p>
<p>This approach was pioneered by GHCJS, and later made it into upstream GHC by
7.10. Other than GHCJS, known users include:</p>
<ul>
<li>GHC itself, even in native GHC! But why bother? Well, suppose we’re compiling
a profiled library with TH usage. Since profiled code follows different
runtime conventions and links with profiled runtime, in the early days, a
profiled GHC executable was needed. Now, we can simply use a profiled <code>iserv</code>
executable, and avoid the extra profiling overhead in GHC.</li>
<li><a href="https://github.com/input-output-hk/haskell.nix">haskell.nix</a>, which includes support for cross-compiling to
Windows via <code>wine</code> emulation of TH code.</li>
<li><a href="https://medium.com/@zw3rk">Mobile Haskell</a>, which are ARM-targetting GHC distributions.
They use Android/iOS emulators to set up the splice runtime environment. GHC
talks to an <code>iserv-proxy</code> process via pipes, and <code>iserv-proxy</code> merely relays
the messages to the real <code>iserv</code> program in the emulator via a socket.</li>
<li>The <a href="https://github.com/typelead/eta">Eta</a> Haskell-to-JVM compiler.</li>
<li><a href="https://github.com/tweag/Asterius">Asterius</a>, which uses <code>node</code> for running the WebAssembly &amp;
JavaScript code.</li>
</ul>
<h3>Pros and cons of running TH on the target platform</h3>
<p>Compared to running TH on the host platform, there are a few benefits to
running it on the target platform:</p>
<ul>
<li>No host/target incoherence issues, as explained in earlier sections.</li>
<li>Less hacky and more standardized. Although upstream GHC won’t likely contain
<code>iserv</code> implementations for all interesting target platforms out there,
developers can just roll their own if needed.</li>
<li>Simpler, since there isn’t a bunch of hacks to be packaged via nix anymore,
and it works with vanilla <code>cabal</code>/<code>stack</code>.</li>
</ul>
<p>It would be tempting to announce TH for cross compilation is now a solved
problem! Turns out it’s not. Recall how TH enables running …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-25-asterius-th/">https://www.tweag.io/blog/2020-11-25-asterius-th/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-25-asterius-th/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313146</guid>
            <pubDate>Sat, 05 Dec 2020 09:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maybe we shouldn't want a fully decentralized web]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 415 (<a href="https://news.ycombinator.com/item?id=25312854">thread link</a>) | @talhah
<br/>
December 5, 2020 | https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spent a large part of 2019 working with the distributed and decentralized web, especially IPFS, also known as the “Inter-Planetary File System”. I’ve written a few articles on the topic, on how you can host a web app on IPFS, one of which even ended up on the front page of HackerNews.</p><p>For about a year, I hosted my blog and other apps through an IPFS cluster. I wrote a utility for making pinning files easier on Pinata, a third-party cloud service for IPFS. I made some small contributions to the IPFS core projects. I built some projects with it, including one that I never released–nor fully completed–that used both IPFS and Ethereum. And I even gave a talk about hosting static web apps on IPFS at Node+JS Interactive last December in Montreal.</p><p>That all changed in the Spring of 2020. I called myself out of the distributed web.</p><p>My blog and other apps I built aren’t hosted on IPFS anymore. I don’t participate in those online communities anymore. I’ve stopped writing about the distributed and researching about it. I’ve shelved all my projects that were using those technologies.</p><p>I also updated my blog posts about IPFS adding a note that my blog isn’t hosted that way anymore. More than a few people asked me why, and I always gave the same answer: a mix of technical issues and mostly personal reasons. So, I think it’s time I explain the personal reasons.</p><p>First, I need to explain why I got involved with IPFS in the first place.</p><p>When I first read about IPFS, my mind immediately saw it as an exciting new platform I could build my apps for. The premise of a fully-decentralized platform included unlimited scalability, ultra-high availability and resiliency, no single points of failure, and resistance against attacks like DDoS.</p><p>Coming from a background in which I am always thinking about SLAs, number of nines of uptime, disaster recovery, etc, IPFS sounded like a dream platform that would magically solve all my concerns. And, aside from some performance issues at times, it did. Plus, the small engineer inside me was really excited about being able to play with a new, shiny toy, that had lots of hype around it!</p><p>What happened next for me was a reckoning with the reality of what many people behind the IPFS core project and the community around it saw: the dream of a radically open, unfiltered, and by-design un-censorable platform.</p><p>I have recently opened up about my experience, over a decade ago, with building an app with good intentions but that was then misused (<a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html"><em>That time I accidentally built a spying app</em></a>). I learned early on in my life and (pre-)professional career about the importance of ethics in software development, and I am now a proponent of the idea that just because something <em>can</em> be built, it doesn’t mean it <em>should</em> be built.</p><p>And that brings me back to why, after spending some time in the world of the decentralized web, I have called myself out, and why I think that should things like IPFS actually become mainstream, they might cause more harm than good in the world.</p><p><strong>I have seen, and I am seeing every day, the dangers of completely unrestricted speech, and I don’t want to be the one enabling that.</strong></p><p>I know that last sentence is a strong ideological statement; some might call it a <em>political</em> statement, but for me it’s more than just political, which is often used to describe extemporary beliefs.</p><p>Many of you reading this will not agree with me, and that’s fine. I’m not going to try and change your beliefs with this blog post. Rather, I’m looking to explain why, while I respect that others might have differing opinions, I stopped doing anything that would actively advance a technology whose ethics I question. To put it in other terms: your freedom of speech isn’t my obligation to enable you and give you a platform.</p><p>In short, I think that while the Internet has helped the world in countless of ways, it has also brought out the worst in people.</p><p>I do believe we need some filters on the Internet. It’s not just about stopping criminal activities, terrorism and child pornography: while I am obviously unsupportive of all them, I also think they’re not the biggest dangers coming from the Internet (yet they’re a very convenient pretext for politicians).</p><p>Instead, I think that regular people’s writings on the Internet is hurting the world on a bigger scale. And the collective sentiment is often manipulated by some “agitators” that are exploiting anonymous online speech for their own agendas: that includes online militias–for example sponsored by foreign governments–whose goal is to destabilize a society.</p><p>In the last few years, completely unregulated online speech has given rise to fake news and conspiracy theories that have actually killed people. It’s offered a megaphone to those promoting dangerous ideas like white supremacy, Islamophobia, anti-Semitism, homophobia and other anti-LGBTQ positions, and sometimes outright Nazism. It has tilted many democracies towards right-wing populism and fascism.</p><p>All these extreme ideas have divided societies and increased social tensions. And they’re responsible for a number of acts of terrorism which caused the death of too many people.</p><p>Given our experiences so far, there’s no sign that indicates that a fully decentralized and unrestrained web would be anything but a dangerous wild west.</p><p>In fact, despite being tightly centralized and controlled, social media companies are facing significant challenges regulating what people write on their platforms, and in fact they are usually at the center of every scandal of these years. Decentralization and less control won’t be the solution to this issue, but rather the opposite.</p><p>If you believe that I’m overthinking this, and that it’s not going to be bad <em>this time</em>, I urge you to think twice.</p><p>First, there’s no indication that a new Web would be better than the previous one just on virtue of being decentralized. The same actors that are using today’s Internet to wreak havoc around the world would not disappear in the new Internet, and actually, they could be even more unrestrained.</p><p>Second, while almost everyone in the communities supporting a distributed web are good people, with good intentions, seeing some names in there is concerning to me. Regarding IPFS, advocates (at least for a while) included people like Nick Lim of BitMitigate and VanwaNet, companies responsible for rescuing, among others, <a href="https://www.geekwire.com/2017/seattles-bitmitigate-now-protecting-pro-nazi-site-daily-stormer-web-attacks/">pro-nazi website</a> The Daily Stormer <a href="https://arstechnica.com/information-technology/2019/11/breaking-the-law-how-8chan-or-8kun-got-briefly-back-online/">and the platform</a> 8chan, a cesspool full of Nazi propaganda, child pornography, and other hate speech. Gatherings on 8chan have been <a href="https://en.wikipedia.org/wiki/8chan#2019_shootings">blamed</a> for at least three mass shootings in 2019 alone, including the one in the <a href="https://time.com/5648479/8chan-ban-new-zealand/">mosque in Christchurch</a>, all of them motivated by racial hatred.</p><p>The first real examples of the distributed web aren’t particularly encouraging either. Among some of the most popular apps (“popular” in relative terms, of course) for the distributed web is DTube, a sort of YouTube that is built on top of IPFS. As you can expect, the website is full of questionable content, including conspiracy theories, cryptocurrency scams, weapons, RT&nbsp;International’s <a href="https://www.theguardian.com/commentisfree/2019/jul/26/russia-disinformation-rt-nuanced-online-ofcom-fine">Russian propaganda</a>… and of course, porn.</p><p>In essence, if it’s true that <em>a good beginning makes a good ending</em>… with such a mixed beginning, the outlook isn’t too rosy.</p><p>I understand that my opinion is somehow a minority one, and people will continue to build IPFS and other technologies part of the distributed web. There’s also a chance they might become successful and potentially get mainstream adoption–although at this stage the barrier to entry is too high for the average user.</p><p>However, I feel that it’s my responsibility to not be helping to advance this technology and the beliefs of at least some advocates in the world of the distributed web hold. If the advancement occurs, it won’t be because of my help.</p><hr><p><em>PS: The idea that freedom of speech is an absolute right that should have (almost) no limitations is not a universal one. While that right is granted to people living in all democratic countries, outside of North America it’s accepted that such right comes <a href="https://www.nytimes.com/2019/08/06/world/europe/el-paso-shooting-freedom-of-speech.html">with limitations</a>, and usually that has roots in the history of those places.</em></p><p><em>For example, in Italy where I grew up, the same constitution that grants freedom of expression (speech, press, etc) also criminalizes “apology of fascism”, or propagating the ideas of fascism; it also sets other limits on speech that is hateful or discriminatory. Other European countries have similar laws, such as the outlawing of Nazi rhetoric and symbology in Germany.</em></p></article></div>]]>
            </description>
            <link>https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312854</guid>
            <pubDate>Sat, 05 Dec 2020 08:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Coils to Curves – A Primer on Elliptic Curve Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312733">thread link</a>) | @roberla
<br/>
December 4, 2020 | https://security.christmas/2020/5 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>It is well known that prime numbers are important for cryptography, although it has not always been true. The advent of primes came with several groundbreaking papers almost 50 years ago. Pioneers in introducing asymmetric cryptography, Whit Diffie, Martin Hellman, Ron Rivest, Adi Shamir and Leonard Adleman, used results from number theory to build key agreement, encryption, and signatures. Prime numbers hold a very special position in number theory, and this carried over to cryptography.</p>
<h2>From Primes to Crypto</h2>
<p>Cryptographic protocols are typically working <em>modulo</em> some prime <em>p</em>. This can be likened to turning the number line into a coil, such that 0, <em>p</em>, 2<em>p</em>, etc. all join at the same place. From then on, whenever we add or multiply the number such that we go beyond <em>p</em>, we can simply remove as many multiples of <em>p</em> as necessary until we come between 0 and <em>p</em> again.</p>
<p>Now, imagine that we used a composite number instead, for example 12. Then 0 and 12 are "the same" in this situation, but that also means that 3 multiplied by 4 is ... 0! One of the intuitions when working with normal numbers is that if <em>ab</em> = 0, then either <em>a</em> or <em>b</em> would have to be 0. Hence, when using composite numbers, there is simply stuff that no longer works the way we’re used to. Fortunately, this is not the case when using the primes — for instance 7 — as our so-called modulus.</p>
<p><img src="https://security.christmas/assets/curves.png"></p>
<p>Let’s make a rule, and let’s call it <em>m</em>. We take the coil we just made from the number line, and since we can always reduce numbers to below <em>p</em>, we label our points on this circle from 0 to <em>p</em>-1. Given two points <em>a</em> and <em>b</em> on the circle, we decided that the output of the rule <em>m</em>(<em>a</em>, <em>b</em>) should be the point which is represented by the product <em>ab</em>, possibly after reducing modulo <em>p</em>. It may look like a very natural rule, but it is nonetheless a rule we just agreed on. If you play around with this rule a bit, you will notice some properties:</p>
<ul>
<li>If <em>a</em> = 1, then <em>m</em>(<em>a</em>, <em>b</em>) = <em>b</em> (and the other way around).</li>
<li>For any <em>a</em>, <em>b</em> not equal to 0, <em>m</em>(<em>a</em>, <em>b</em>) is never zero. So, if we removed 0 from the circle entirely, no harm would happen — the rule would still be well-defined.</li>
<li>For any nonzero <em>a</em>, there is always some <em>b</em> such that <em>m</em>(<em>a</em>, <em>b</em>) = 1.</li>
</ul>
<p>These nice properties — together with a property called associativity — are the properties we need to be able to do cryptographic computations.</p>
<p>Now focus on a particular number on the circle, and let’s call it <em>g</em>. If we take <em>m</em>(<em>g</em>, <em>g</em>), or — to return to the more usual notation — <em>g²</em>, we will reach a new point on the circle. We can continue this process and compute <em>g</em>³, <em>g</em>⁴, etc. At some point, we will reach 1. All the points we have visited in this process are members of the set of numbers <em>generated</em> by <em>g</em>, and if the number of points on the coil is a large prime, then we have a very good candidate for doing cryptography, for example Diffie-Hellman key exchange. Let <em>h</em> be some number in this set generated by <em>g</em>. That means that <em>h</em> = <em>g</em>ᵉ for some exponent <em>e</em>. If it is easy to find this <em>e</em> from <em>g</em> and <em>h</em>, we would have trouble. Fortunately, it turns out that if we use <em>large enough</em> primes, then this <em>e</em> appears to be very difficult to find.</p>
<h2>From Coils to Curves</h2>
<p>Coiling up the number line is not the only way of finding suitable primitives for cryptography. Let’s make a new rule. Instead of using a circle like we did in the previous section, we consider the following equation:</p>
<p><em>y</em>² = <em>x</em>³ + <em>ax</em> + <em>b</em>, where <em>a</em> and <em>b</em> are fixed constants.</p>
<p>If we graph this in our usual coordinate system, it may look like this curve:</p>
<p><img src="https://security.christmas/assets/curves2.png"></p>
<p>We will now make a rule on how to combine two distinct points <em>P</em> and <em>Q</em> on this curve. The agreed upon notation is to call this rule addition, but we will have to define what we mean by that. Programming languages often include this mental concept as operation overloading. Draw the straight line between <em>P</em> and <em>Q</em>. It will intersect at a third point, say, <em>R</em>. This could have been a nice candidate for <em>P</em> + <em>Q</em>, but since we are making the rules, let’s make this a bit more interesting. Draw a vertical line through <em>R</em>. It will intersect the curve on the opposite side of the <em>x</em>-axis, and we define this point as <em>P</em> + <em>Q</em>. Just as before, this is a rule we’re deciding here and now. However, this also turns out to be a very useful rule, with the same properties as before:</p>
<ul>
<li>Instead of having the point 1 on the circle, we imagine a point infinitely far up. (Remember what you see when looking at railway tracks: parallel lines actually meet beyond the horizon, at infinity.) So, now the line intersecting <em>R</em> and <em>P</em> + <em>Q</em> is indeed also intersecting a third point: the point at infinity. This can be made precise, but requires maths from algebraic geometry, which is far beyond the scope of this blog post. This point at infinity has all the same properties as 1 had above.</li>
<li>For any point <em>S</em> on the curve, there is always a point <em>T</em> such that we get a line intersecting <em>S</em>, <em>T</em> and the point at infinity. This means that for any point <em>S</em>, we can find a point we can call -<em>S</em>.</li>
</ul>
<p>You can test this rule interactively in a simple <a href="https://www.geogebra.org/m/ukhajwzs">GeoGebra demonstration</a>.</p>
<p><img src="https://security.christmas/assets/ec_group_law.gif"></p>
<p>We just assumed that <em>P</em> and <em>Q</em> were distinct. If <em>P</em> = <em>Q</em>, then we simply use the tangent to the curve at point <em>P</em> instead, and proceed as before.</p>
<p>In particular, take a point <em>G</em>, and compute 2<em>G</em> = <em>G</em> + <em>G</em>, 3<em>G</em>, 4<em>G</em>, etc. Eventually, we reach the point at infinity, and then back to <em>G</em>. We have now spent about 1000 words of this blog post getting here, just to do the same as we did above, and what was the point? Above, we said that computing exponents are secure if the primes were large enough. It turns out that "large enough" is currently about 3072 bits, or a number with approximately 925 digits. That is somewhat strenuous even for a computer, but the elliptic curve version only requires us to work on numbers of size 256 bits, or 77 digits, which is far more efficient.</p>
<h2>Elliptic Curve Diffie-Hellman Key-Exchange</h2>
<p>The Diffie-Hellman key-exchange protocol is widely used today, and its instantiation using elliptic curves is ranked as the best choice in modern cryptographic protocols like TLS and SSH. The protocol is fairly simple. The public information is an elliptic curve <em>E</em> and a generator <em>G</em> for the points on this curve. One party, Alice, samples a random integer <em>a</em> and computes a point <em>A</em> = <em>a</em> <em>G</em>. Another party, Bob, samples a random integer <em>b</em> and computes <em>B</em> = <em>b</em> <em>G</em>. Then they exchange the values <em>A</em> and <em>B</em>, and compute the shared key <em>K</em> = <em>b</em> <em>A</em> = <em>a</em> <em>B</em> = <em>a</em> <em>b</em> <em>G</em>. As long as both <em>a</em> and <em>b</em> stay secret, even when an attacker knows <em>G</em>, <em>A</em> and <em>B</em>, then the key is secure.</p>
<p><img src="https://security.christmas/assets/dh.png"></p>
<p><em>Reference: <a href="https://asecuritysite.com/encryption/go_x3dh">https://asecuritysite.com/encryption/go_x3dh</a>. Used with permission.</em></p>
<p>To achieve long-term security, to protect previous messages in the case where someone’s secret keys are leaked after the fact, Alice and Bob can do an ephemeral key-exchange every time they communicate. If <em>a</em> and <em>A</em> is Alice’s long term key pair where <em>A</em> is public to everyone, and similar for Bob, they can run the following protocol to agree upon a one-time session-key. Alice samples a random integer <em>c</em> and computes <em>C</em> = <em>c</em> <em>G</em>, and Bob samples a random integer <em>d</em> and computes <em>D</em> = <em>d</em> <em>G</em>. Then they exchange <em>C</em> and <em>D</em>, and compute the shared key as (<em>a</em> <em>b</em> + <em>c</em> <em>d</em> )<em>G</em>.</p>
<p>The interested reader can check out this <a href="https://play.golang.org/p/qJBI0_2lsGP">simple example written in Go</a>. Are you able to extend the basic protocol to the ephemeral key-exchange on behalf of Alice and Bob?</p>
<p>We finally point out that this protocol is vulnerable to a man-in-the-middle attack, and we need to also send signatures computed on the messages to ensure that the communication is authentic. Are you able to attack the protocol as described above, when signatures are not used? If you found these problems interesting, we encourage you to check out similar challenges at <a href="https://cryptohack.org/challenges/ecc/">cryptohack.org</a>.</p>
<h2>Common Curves</h2>
<p>Not all elliptic curves are suitable for cryptography. There could also be power in choosing a curve and the distinguished base point(s). Hence, implementations tend to choose among a small number of well-known curves. The US National Institute of Standards and Technology <a href="https://csrc.nist.gov/publications/detail/fips/186/4/final">maintains a list</a> of recommended curves; P-256 is perhaps the most popular among these.&nbsp;</p>
<p>Among others, there is also the <a href="https://safecurves.cr.yp.to/">SafeCurves</a> collection proposed by Dan Bernstein and Tanja Lange. In particular, their Curve25519 has proven to be a popular choice.</p>
<p>Elliptic curve libraries will typically have tailored support for certain curves.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312733</guid>
            <pubDate>Sat, 05 Dec 2020 07:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Tire-pressure monitoring system Sensors: Let's try a DoS attack]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25312714">thread link</a>) | @pabs3
<br/>
December 4, 2020 | http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack | <a href="https://web.archive.org/web/*/http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <td>&nbsp; &nbsp;</td>

  <!-- left column -->
  <td>

<!--
   <p>
   <br />
   <b>About</b> <br />
   Dieter Spaar's blog, Dieter Spaar's personal Blosxom blog.<br /><br />
   Dieter Spaar<br />
   <a href="mailto:spaar@mirider.com">spaar@mirider.com</a> <br />
   </p>
-->

   <p>
   <a href="http://www.mirider.com/weblog/index.rss">RSS</a>
   </p>

   <p>
     <b>Dieter's Web</b> <br>
     <a href="http://www.mirider.com/">mirider.com</a><br>
   </p>

   <p>
   <b>Projects I am participating</b> <br>
    <a href="http://bb.osmocom.org/" target="_blank">OsmocomBB</a><br>
    <a href="http://openbsc.osmocom.org/" target="_blank">OpenBSC</a><br>
    
   </p>

   <p>
   <b>Categories</b> <br>
   </p>
   <ul>
<li><a href="http://www.mirider.com/weblog/index.html">Root</a> (24)
<ul>
<li><a href="http://www.mirider.com/weblog/automotive/index.html">automotive</a> (3)
</li>
<li><a href="http://www.mirider.com/weblog/gsm/index.html">gsm</a> (17)
</li>
<li><a href="http://www.mirider.com/weblog/misc/index.html">misc</a> (1)
</li>
<li><a href="http://www.mirider.com/weblog/sdr/index.html">sdr</a> (2)
</li>
</ul>
</li>
</ul>


   <p>
   <b>Archives</b> <br>
   </p>
   <ul>
	<li><a href="http://www.mirider.com/weblog/2020/">2020</a> (1)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2020/12/index.html">December</a> (1)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2018/">2018</a> (5)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2018/09/index.html">September</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/05/index.html">May</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/03/index.html">March</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/01/index.html">January</a> (2)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2013/">2013</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2012/">2012</a> (4)
	</li>
	<li><a href="http://www.mirider.com/weblog/2011/">2011</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2010/">2010</a> (8)
	</li>
</ul>


<!--
   <p>
   <b>Flavours</b> <br />
   There's more than one way to view this weblog; try these flavours on
   for size.
    <li><a href="http://www.mirider.com/weblog/index.index">index</a></li>
    <li><a href="http://www.mirider.com/weblog/index.1993">circa 1993</a></li>
    <li><a href="http://www.mirider.com/weblog/index.rss">RSS</a></li>
   </p>
-->
   <p>
   <b>Other Bloggers</b> <br>
    <a href="http://laforge.gnumonks.org/weblog/" target="_blank">Harald Welte</a><br>
    <a href="http://openbts.blogspot.com/" target="_blank">David Burgess</a><br>
   </p>

<!--
   <p>
   
   </p>
-->

   <p>
    <br>
    <a href="http://www.blosxom.com/"><img src="http://mirider.com/weblog/pb_blosxom.gif" alt="blosxom"></a>
   </p>

   <p>
    <br>
    <a href="http://www.mirider.com/#Site%20Contact">Contact/Impressum</a>
   </p>

  </td>

  <td>&nbsp; &nbsp;</td>

  <td>&nbsp; &nbsp;</td> 

  <!-- main blog entry column -->
  <td> 

   <br>

<span>Fri, 04 Dec 2020</span>
<div>
<p><a name="20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack"><b>Modern TPMS Sensors: Let's try a DoS attack</b></a></p><p>
TPMS (Tire-pressure monitoring system) sensors have been researched extensively
many years ago, they periodically transmit the tire pressure, temperature
and a unique ID which can be misused for tracking a vehicle. But there is
another aspect: modern TMPS sensors also have a receiver which is typically
used to trigger the data transmission when a new TPMS sensor is presented to
the vehicle ("learning procedure").
</p>

<p>
Here in Europe TPMS sensors usually transmit on the 433 MHz ISM band. The
receiver operates on 125 kHz, very similar to LF RFID. A simple way to make
use of the receiver is just to look for the presence of the 125 kHz carrier
and then trigger data transmission. Current sensors are usually more evolved
and use a modulated carrier which contains command packets and only if the
correct command is received data transmission is triggered.
</p>

<p>
If you already have a receiver you can do of course more than just trigger
data transmission: For example there might be support for different
commands, some sensors even allow firmware updates this way.
</p>

<p>
One such command which is typically supported is switching the sensor into
"Shipping" mode. Why would you need that? When the sensor is operating
normally it waits for motion (there is an acceleration/shock sensor inside)
and only starts periodic data transmission when the wheel is rotating. This
is used to safe battery life. When the TPMS sensor is not yet mounted in the
tire it should not react on motion, that’s why there is this "Shipping" mode.
In this mode the sensor only wakes up every few seconds and looks if there
is a 125 kHz signal, if yes it checks for a valid command, for example the
command to trigger data transmission which usually also leaves "Shipping"
mode and switches the sensor into normal operation.
</p>

<p>
This "Shipping" mode can be misused: If you can switch a TPMS sensor of a
vehicle’s wheel into "Shipping" mode the sensor will no longer transmit data
and the vehicle's tire pressure control light will go on after a while.
Just to make it clear: This warning light is annoying to the driver, it
does not affect safety of the car because the deactivated TMPS sensor has
not affected the actual tire pressure.
</p>

<p>
I have looked at a few TPMS sensors for different cars if this really works,
I choose sensors for BMW and Ford cars. Please note that most certainly
other car manufactures are affected too, mainly because there are only a
few manufactures of TPMS sensors which deliver their sensors to various
car manufactures. My choice for BMW and Ford came from the fact that I
found lots of cheap, used sensor for those cars.
</p>

<p>
Also I only looked at "OEM" sensors for BMW and Ford, which means that those
sensors are mounted by the car manufacturer. There are also so called
"Universal" sensors which are typically mounted by tire dealers, there
are some notes about them at the end of this text.
</p>

<p>
It is quite easy to build a tool for transmitting data on 125 kHz: There
is this cheap EL-50448 TMPS sensor activation tool which only transmits a
carrier without modulation. However the hardware can easily be modified
to modulate the carrier: Most of the time OOK (On-Off Keying) is used
for communication, which means that the carrier is just turned on and off.
The EL-50448 uses a power driver with an unused "enable" pin to generate
the carrier, you can use this "enable" pin to modulate the carrier. The
data rate is slow, a frequently used rate is 3900 baud.  Most of the time
Manchester encoding of the data bits is used, which means that the carrier
changes twice as much (7800 changes per second). This is nothing special
and can be done with probably any microcontroller you prefer to use. The
hardware costs for such a setup are below EUR 20, the transmission range
is about 20 centimeters.
</p>

<p>
How can you find the command to switch to Shipping" mode? Brute force by
trying all possible commands is only an option if the command is short.
The reason is that the sensor only looks for the LF 125 kHz signal every
few seconds. If the command is not longer than two bytes brute force is
possible (it takes a few days), for longer commands it is impractical.
Please note that you also have to find a way to detect if the command you
send causes a reaction of the TPMS sensor, e.g. by monitoring the power
consumption of the sensor or receiving the 433 MHz data signal (which of
course only works if the command you send causes a data transmission).
</p>

<p>
Another option is looking at those TPMS tools which tire dealers and
car repair workshops use to check TPMS sensors. Some of those tools
might support switching a TPMS sensor into "Shipping" mode.
</p>

<p>
Those are the results I found (I won't go into the details to avoid misuse):
</p>

<ul>
<li><b>BMW:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. Also if the sensor detects a
  fast pressure change (e.g. by inflating the tire) the sensor leaves
  "Shipping" mode. The command length is four bytes so brute force is no option. 

</li>

<li><b>Ford:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" (the same manufacture as above for the BMW sensor) can be switched
  into "Shipping" mode, it is the same command as used by the BMW sensor
  from above. The deactivated TPMS sensor can be activated again with a
  different command.
  
  A certain sensor used in several car models from TPMS Sensor manufacturer
  "B" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. The command in this case is
  only two bytes and I tried all combinations which resulted in several more
  "interesting" commands, a few examples:


    <ul>
<li>
      It is possible to completely turn off the TPMS sensor. In this case it
      will no longer react on anything, you have to break open the sensor
      case and apply a hardware reset or disconnect the battery to reactivate
      it again.
</li>

<li>
      It is possible to switch the sensor into continuous "carrier transmit"
      mode on 433 MHz. In this mode the sensor will continuously transmit
      the 433 MHz carrier until the battery is empty or you apply a hardware
      reset (see above), it will not react on anything else. There are two
      other similar commands which transmit on the upper and lower shifted
      frequency (the sensor uses FSK modulation, Frequency Shift Keying, when
      transmitting data).
</li>
</ul>      

  Those examples show that it is basically possible to destroy this specific
  sensor by transmitting the appropriate command. Also if the sensor is in
  "carrier transmit" mode it probably disturbs the remote control car
  key fob which usually uses the same frequency as the TPMS sensor.
</li>
</ul>

<p>
You have to be close to the sensor to send those LF 125 kHz signals but it
only takes a few seconds to send the signal. Using a larger antenna (which is
basically a coil) for the transmitter, e.g. large enough to fit in a suitcase,
might extend the transmission range to more than a meter. 
</p>

<p>
How can those problems be avoided? This is actually quite easy, the command
to switch into "Shipping" mode should not be allowed if the measured tire
pressure is above a certain limit, which means that the sensor is mounted in
the tire of a vehicle. This also applies to those other commands of the sensor
from manufacturer "B" which are probably some kind of factory test or developer
commands. Please note that during my tests the commands I described were
possible even when the measured tire pressure was in the range of a typical
vehicle wheel.
</p>

<p>
I contacted the car manufactures (BMW and Ford) before I published this
article, this is the experience I made:
</p>

<ul>
<li>
  <b>BMW:</b>
  The contact information for reporting security issues can be found on
  the BMW website. I had a phone call with the responsible person within
  a few days after reporting the issue. BMW already knew the problem, they
  found it during an internal review. Their latest TPMS sensors have fixed
  the issue by blocking certain commands if the tire pressure is above a
  certain limit.
</li>

<li>
  <b>Ford:</b>
  I wasn't able to find a security contact on the website of Ford Germany
  so I contacted the person responsible for "Public Relation". He promised
  to look for someone who takes care of the issue I reported, after several
  days I got a reply that it is possible to disturb the TPMS system due to
  the nature of radio transmission and that this is a known problem. I wasn't
  able to communicate directly with the responsible person and I then replied
  that the reported issue is not about disturbance but a "Denial of Service"
  and that it is even possible to destroy a certain TPMS sensor used in Ford
  cars. I didn't receive any further information about the security issue, I
  notified them again after several weeks that I am now going to publish
  the issue which was acknowledged.
</li>
</ul>

<p>
Some notes about those "Universal" sensors tire dealers normally use: Those
sensors are "Universal" because they can be programmed for different car
models. The main benefit for the tire dealer is that only a few different
kind of "Universal" sensors have to be on stock, it’s not necessary to have
lots of different "OEM" TPMS sensors for every possible car model lying
around. The programming of those …</p></div></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</a></em></p>]]>
            </description>
            <link>http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312714</guid>
            <pubDate>Sat, 05 Dec 2020 07:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Manpages Like a Pro (2018)]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25311867">thread link</a>) | @woodruffw
<br/>
December 4, 2020 | https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jan 22, 2018</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h3 id="preword">Preword</h3>

<p>I often reference the <a href="https://en.wikipedia.org/wiki/Man_page">manpages</a> when giving a development
presentation or talk, but I’ve only recently come to realize how few people are both <em>comfortable</em>
with the <code>man</code> interface and adept at discovering information through it.</p>

<p>This post is my attempt to share some of the tricks and techniques I’ve picked up over years of
reading manpages.</p>

<h2 id="a-quick-recap">A Quick Recap</h2>

<p>The manpages (short for “manual pages”) are the oldest and longest-running documentation collection
on *nix, stemming back to the
<a href="https://www.bell-labs.com/usr/dmr/www/1stEdman.html">first edition of the Unix Programmer’s Manual</a>
in 1971.</p>

<p>On a modern system, the <code>man</code> command is the most common way to access the manpages:</p>

<div><div><pre><code><span># access the first manpage named "time", which happens to be time(1)</span>
man <span>time</span>

<span># access a specific section's "time", in this case the C time function</span>
man 2 <span>time</span>

<span># attempt to access a nonexistent "time" in section 5</span>
man 5 <span>time</span>
</code></pre></div></div>

<p>Because the manpages were originally published on paper, they were (and continue to be) typeset with
<a href="https://en.wikipedia.org/wiki/Troff"><code>troff</code></a> on most systems. Today, the <code>man</code> command (and other
manpage readers) invoke <code>troff</code> internally and pipe the output to the user’s
<a href="https://en.wikipedia.org/wiki/Terminal_pager">pager</a> (like <code>more</code> or <code>less</code>).</p>

<p>In fact, a very simple manpage reader (which only works with section 1) can be implemented with
just three commands pipelined together:</p>

<div><div><pre><code><span>function </span>myman <span>{</span>
    <span># `-t` and `-e`: run `tbl` and `eqn` on the input, for tables and equations</span>
    <span># `-mandoc`: use a set of troff macros specifically for manpages</span>
    <span># `-Tutf8`: output UTF-8 text rather than PostScript</span>
    <span>gunzip</span> &lt; /usr/share/man/man1/<span>"</span><span>${</span><span>1</span><span>}</span><span>.1.gz"</span> | groff <span>-t</span> <span>-e</span> <span>-mandoc</span> <span>-Tutf8</span> | less
<span>}</span>

myman gcc
myman <span>ls</span>
</code></pre></div></div>

<p>Apart from their simplicity and adherence to the UNIX philosophy, <code>man</code> and the manpages serve a
number of important roles:</p>

<ul>
  <li>
    <p>They provide a categorization: section 1 is for system commands, 2 for system calls, 3 for library
functions, and so forth. This categorization is followed both by the system itself (which populates
several of the sections) and by programs installed by the user or package manager.</p>
  </li>
  <li>
    <p>They provide offline documentation: <code>man</code> doesn’t require an internet connection, and can provide
much of the documentation that an internet search would yield.</p>
  </li>
  <li>
    <p>They offer <em>canonical</em> information: searching for a command or function online might tell you
whether it exists, but won’t tell you the flags, arguments, or behavior specific to your system.
For example, <code>man ls</code> will tell you whether your system’s <code>ls</code> is BSD or GNU (and the differences
therebetween). The manpages (on Linux) will also tell you which feature macros you’ll need to define
in a C program in order to use a function (or a variant of a function).</p>
  </li>
</ul>

<p>So, let’s move on to some techniques.</p>

<h2 id="colorized-manpages">Colorized manpages</h2>

<p>One of the simplest things you can do to enhance the readability of manpages within <code>man</code> is to
colorize the pager’s output:</p>

<p><img src="https://blog.yossarian.net/assets/gcc_man.png" alt="A colorized version of `man gcc`"></p>

<p>In <code>less</code>, this is accomplished by setting the <code>LESS_TERMCAP_*</code> environment variables to your
preferred ANSI color codes. Here are the variables you can set:</p>

<div><div><pre><code>LESS_TERMCAP_mb <span># blinking mode (not common in manpages)</span>
LESS_TERMCAP_md <span># double-bright mode (used for boldface)</span>
LESS_TERMCAP_me <span># exit/reset all modes</span>
LESS_TERMCAP_so <span># enter standout mode (used by the less statusbar and search results)</span>
LESS_TERMCAP_se <span># exit standout mode</span>
LESS_TERMCAP_us <span># enter underline mode (used for underlined text)</span>
LESS_TERMCAP_ue <span># exit underline mode</span>
</code></pre></div></div>

<p>You may be able to set others corresponding to the
<a href="https://www.gnu.org/software/termutils/manual/termcap-1.3/html_chapter/termcap_5.html">termcap capability names</a>,
but the variables above should cover all of your manpage needs.</p>

<p>By way of example, here is the <code>bash</code> function I use to colorize my manpages:</p>

<div><div><pre><code>man<span>()</span> <span>{</span>
    <span>env</span> <span>\</span>
    <span>LESS_TERMCAP_mb</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_md</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_me</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_se</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_so</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;44;33m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_ue</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_us</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;32m"</span><span>)</span><span>"</span> <span>\</span>
    man <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
<span>}</span>
</code></pre></div></div>

<p>Note that you don’t need to use escape sequences as above — <code>tput</code> will work just fine.</p>

<h2 id="other-sections">Other sections</h2>

<p>I mentioned some of the big sections above: 1 for system commands, 2 for system calls, and so on.</p>

<p>90% of <code>man</code> lookups will be in those three, but there are a few lesser-known sections that can also
be useful:</p>

<ul>
  <li>
    <p><code>man 4</code> - Special files and devices</p>

    <p>On Linux, section 4 is used to document special files, usually representing some aspect of
  the machine or its peripherals. For example, <code>man 4 mem</code> will tell you how to use the
  <code>/dev/mem</code>, <code>/dev/kmem</code>, and <code>/dev/port</code> files to read from and write to the system’s main
  memory.</p>
  </li>
  <li>
    <p><code>man 5</code> - Configuration files and formats</p>

    <p>You probably know the <code>/etc/shadow</code> file, but do you know how its format is specified?
  <code>man 5 shadow</code> will tell you that. Similarly, <code>man 5 deb</code> describes the <code>.deb</code> package format,
  and <code>man 5 ppm</code> lists the spec for <a href="https://en.wikipedia.org/wiki/Netpbm_format">PPM images</a>.</p>
  </li>
  <li>
    <p><code>man Np</code> - POSIX pages</p>

    <p>These pages come in handy for contrasting POSIX behavior with the system’s behavior.</p>

    <p>Some examples:</p>

    <div><div><pre><code>  <span># compare the system ls (on Linux, GNU) to the POSIX ls behavior</span>
  man 1 <span>ls
  </span>man 1p <span>ls</span>

  <span># compare the read syscall to the POSIX read function</span>
  <span># note the categorization: POSIX read is a function, not a syscall!</span>
  man 2 <span>read
  </span>man 3p <span>read</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="searching-and-navigating">Searching and navigating</h2>

<p>Like colorization, searching is more of a general <code>less</code> feature than one specific to <code>man</code>. That
being said, <code>less</code>’s searching and navigating features can make browsing the manpages a much faster
and more pleasant experience.</p>

<p>Searches in <code>less</code> can be forwards or backwards, using the <code>/</code> and <code>?</code> commands respectively. The
search syntax is mostly POSIX ERE, but with some additions (<code>man less</code> has the details!).</p>

<p>For example, to find the first instance of “x86” in <code>man gcc</code> (watch the bottom of the screen for
the search prompt):</p>

<p><a href="https://asciinema.org/a/Wc0OiKVTrTDiP4tG9bPRWtDwM" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wc0OiKVTrTDiP4tG9bPRWtDwM.png">
</a></p>

<p>Observe that instances of the search term are highlighted with the standout colors from before.</p>

<p>Once a search term is entered, its results can be navigated via the <code>n</code> and <code>N</code> commands, which
move forwards and backwards in the results list respectively. For example, going through all
of the results for “Windows”:</p>

<p><a href="https://asciinema.org/a/n3S3wteHmbdPrtmyTSkCSVMiX" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_n3S3wteHmbdPrtmyTSkCSVMiX.png">
</a></p>

<p>When the last result has been jumped to, the statusbar changes to “Pattern not found”. Once that
happens, as in the video above, previous results can be returned to by hitting <code>N</code>.</p>

<p>Even this can be simplified: the <code>&amp;</code> command can be used to display only lines that match the given
pattern. For example, retrieving every line that contains either “ARM” or “ABI”:</p>

<p><a href="https://asciinema.org/a/Wh8QZ4eideLNmCMBmAkYExgEm" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wh8QZ4eideLNmCMBmAkYExgEm.png">
</a></p>

<p>The effect is more dramatic when searching for the definition of a flag (in this case <code>-D</code>):</p>

<p><a href="https://asciinema.org/a/17Kcnb8PBNIz8JdogOFKVeDQn" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_17Kcnb8PBNIz8JdogOFKVeDQn.png">
</a></p>

<p>These commands are just the tip of the iceberg — <code>less</code> supports searching multiple files at
once, jumping around scopes (opening and closing parentheses, braces, brackets), and marking the
current location for later return. Each of these is documented on the help screen, which you can
get to in any <code>less</code> session via the <code>h</code> command:</p>

<p><a href="https://asciinema.org/a/8i6kyFTbFttVTgDNbgnzyJvGB" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_8i6kyFTbFttVTgDNbgnzyJvGB.png">
</a></p>

<h2 id="wrapup">Wrapup</h2>

<p>Before picking up these tricks (especially searching), the manpages were an item of last resort
for me: I would search the internet or ask a friend, with mixed results. I had no real idea how to
use <code>less</code>, and would just clumsily page around until I found what I was looking for. More often
than not, I would give up entirely.</p>

<p>At the end of the day, the manpages (and the <code>man</code> interface) are not perfect — there’s no
hyperlinking or real cross-referencing, and the entire corpus is written in a 45+ year old
typesetting language designed for <em>physical</em> output, not display in a virtual terminal.</p>

<p>That being said, they’re a <em>fantastic</em> initial resource for pretty much anything concerning your
system — they remain up-to-date (unlike blogs and articles), they’re accurate and concise, and
they’re <em>very</em> UNIX-y (text files and pipelines!).</p>

<hr>

<h3 id="addendum">Addendum</h3>

<p>This post was discussed on <a href="https://news.ycombinator.com/item?id=25311867">HN</a>; a response
by <a href="https://news.ycombinator.com/item?id=25313405">‘djeiasbsbo</a> includes some additionally
useful tricks and advice.</p>


<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311867</guid>
            <pubDate>Sat, 05 Dec 2020 04:53:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Poker Hands Geometrically]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25311545">thread link</a>) | @chairmanwow1
<br/>
December 4, 2020 | https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands | <a href="https://web.archive.org/web/*/https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  
<p>An interesting way for getting an intuitive sense for why <a href="https://en.wikipedia.org/wiki/Poker_probability" title="Poker hand probabilities">certain hands</a> are rare in poker, I've laid out all the cards in a standard deck in a grid:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/blank_1024x1024.png?v=1607133617" alt="Array of Playing Cards" width="1024x1024" height="1024x1024">
</p>


<p>When I first learned to play poker, it took a while before I could get an intuitive understanding of the relationships between the various poker hands. Calculating their likelihood definitely helped get a handle on how many ways for a specific hand to actually occur there were.</p>

<p>Nonetheless, I think laying the hands out in a grid like this would have given me an intuitive understanding of the game much more quickly.&nbsp;</p>
<h2>Poker Hands shown geometrically</h2>
<p>So the lowest poker hand, high card, is the most common happening 50% of the time, but will rarely be the winning hand:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/High_Card_1024x1024.png?v=1607134813" alt="High Card" width="1023" height="1023"></p>

<p>The next highest hand is a single pair which has a geometric interpretation of one column with two dots in it:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Pair_1024x1024.png?v=1607134853" alt="Pair" width="1024x1024" height="1024x1024"></p>

<p>Two pair has a similar flair to it, except this one has 2 vertical lines:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Two_Pair_1024x1024.png?v=1607134962" width="1024x1024" height="1024x1024"></p>

<p>Three of a kind is similar in spirit, but is much rarer than the two preceding hands happening once every 50 hands:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/three_of_a_kind_1024x1024.png?v=1607135086" alt="3 of a kind" width="1024x1024" height="1024x1024"></p>

<p>For a straight, we need 5 cards that are in order without any gaps and can look kind of like a nice scatter plot:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_1024x1024.png?v=1607135179" alt="Straight" width="1024x1024" height="1024x1024"></p>

<p>A flush requires all 5 cards in the hand to be in a single horizontal row, but there can gaps between them:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/flush_84512f1f-428d-4ed7-b703-9372fc3575d6_1024x1024.png?v=1607135233" alt="Flush" width="1024x1024" height="1024x1024"></p>

<p>A full house requires that all points be split into two lines of 3 and 2 points each:</p>

<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/full_house_1024x1024.png?v=1607135454" alt="Full House" width="1024x1024" height="1024x1024"></p>

<p>Four of a Kind requires a vertical line that spans the entire grid with an extra point tucked away somewhere:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/4_of_a_kind_1024x1024.png?v=1607135655" alt="4 of a kind" width="1024x1024" height="1024x1024"></p>

<p>A straight flush is one of the tidiest hands as it requires all cards to be colinear on the same row and be immediately adjacent to each other:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_flush_1024x1024.png?v=1607135809" alt="Straight Flush" width="1024x1024" height="1024x1024"></p>

<p>The best hand that you can get is a subset of all the straight flushes that you can get. It's just a straight flush all the way against the right side of the grid with the 5 highest cards:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Royal_Flush_1024x1024.png?v=1607135877" alt="Royal Flush" width="1024x1024" height="1024x1024"></p>


<p>Looking at poker this way made me realize that there are some interesting hands that we could add to the game.&nbsp;</p>
<h2>Rectangle</h2>
<p>This hand is formed when you have 4 points that are <a href="https://mathworld.wolfram.com/Collinear.html" title="Mathematical Definition of colinearity">colinear</a> in both orthogonal axes (form a rectangle):&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Rectangle_1024x1024.png?v=1607136065" alt="Rectangle Hand" width="1024x1024" height="1024x1024"></p>

<h2>Flower</h2>
<p>This one seems like it would be complicated to spot in the wild, but in reality it's a lot like a full house. You need a Three of a Kind and the other two cards need to be the same suit as one of your 3oK cards, and just before and after it. So, maybe it is a little complicated to spot, but it certainly is an interesting idea.&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Screen_Shot_2020-12-04_at_18.42.56_1024x1024.png?v=1607136337" alt="Flower Hand" width="1024x1024" height="1024x1024"></p>

<h2>Want More?</h2>
<p>If you found this interesting, you'll probably love the 3D reconstruction we did of <a href="https://evermontbills.com/pages/walter-white-did-not-have-80m" title="Walter White's Cash Pile Counting">Walter White's cash pile</a> in order to count it.&nbsp;</p>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311545</guid>
            <pubDate>Sat, 05 Dec 2020 03:48:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Esperanto Technologies to Reveal Chip with 1000 Cores at RISC-V Summit]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310931">thread link</a>) | @FullyFunctional
<br/>
December 4, 2020 | https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/ | <a href="https://web.archive.org/web/*/https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
				
			<header>
				
				
			</header>
							
				
		
				
				
			
			

						<main id="main">
				<div>

<section id="content">
	
					<article id="post-2771">
										<span>Esperanto Technologies to Reveal Chip with 1000+ Cores at RISC-V Summit</span>
			
				
						<div>
				<div><div><div><div><div><span><img width="504" height="168" title="riscv summit" src="https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit.jpg" srcset="https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit-200x67.jpg 200w, https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit-400x133.jpg 400w, https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit.jpg 504w" sizes="(max-width: 1024px) 100vw, 504px"></span></div><div><h3><strong>Esperanto Technologies to Reveal Chip with 1000+ Cores </strong><strong>at RISC-V Summit</strong></h3>
<p><em>Art Swift, CEO of Esperanto Technologies, will present chip that accelerates Machine Learning based on RISC-V ISA</em></p>
<p><strong>MOUNTAIN VIEW, Calif., Dec. 1, 2020</strong> – <a href="https://www.esperanto.ai/">Esperanto Technologies</a>™, developer of high-performance, energy-efficient computing solutions based on RISC-V for Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL) applications, will participate in the <a href="https://tmt.knect365.com/risc-v-summit/">RISC-V Summit</a>, December 8-10, 2020. <a href="https://tmt.knect365.com/risc-v-summit/speakers/art-swift/">Art Swift, CEO of Esperanto</a>, will deliver the presentation: <a href="https://tmt.knect365.com/risc-v-summit/speakers/art-swift/#hardware-coressocs_esperanto-accelerates-machine-learning-with-risc-v">Esperanto Accelerates Machine Learning with 1000+ Low-Power RISC-V Cores on a Single Chip</a> on Tuesday, December 8.</p>
<ul>
<li><strong>What</strong>: <a href="https://tmt.knect365.com/risc-v-summit/">RISC-V Summit.</a></li>
<li><strong>Where</strong>: Virtual event, online.</li>
<li><strong>When</strong>: December 8, 2020.</li>
<li><strong>Agenda</strong>: <a href="https://tmt.knect365.com/risc-v-summit/agenda/1/">View the agenda here</a>.</li>
<li><strong>Register here</strong>: <a href="https://riscv.informatech.com/2020/registrations/Attendee">https://riscv.informatech.com/2020/registrations/Attendee</a></li>
</ul>
<p><strong>Presentation: </strong><strong>Esperanto Accelerates Machine Learning With 1000+ Low-Power RISC-V Cores on a Single Chip</strong></p>
<ul>
<li>Esperanto Technologies has developed a ground-breaking accelerator chip for large-scale machine learning applications employing over 1000 RISC-V cores.</li>
<li>In this talk, Esperanto provides an overview of the company’s new ET-SoC-1 chip, which features two kinds of general-purpose 64-bit RISC-V cores. The ET-Maxion, previewed at the RISC-V Summit in 2018, is a superscalar out-of-order core delivering high performance for modern operating systems and applications. The complementary ET-Minion core designed by Esperanto is a leaner, energy efficient, in-order multithreaded core with a vector/tensor accelerator unit at the heart of the massively parallel compute array.</li>
<li>The chip’s performance and efficiency is derived from a combination of factors, including the simplicity of the RISC-V instruction set, wide vector/tensor units on every ET-Minion core, a uniquely optimized memory hierarchy, state of the art process technology, and custom pipeline architecture and low-voltage circuits which enables more energy-efficient operation. The result is that Esperanto will deliver better performance per watt than legacy CPU and GPU solutions, as well as competing fixed-function designs without compromising generally purpose flexibility.</li>
</ul>
<p><strong>About Esperanto Technologies</strong></p>
<p>Esperanto Technologies develops high-performance, energy-efficient computing solutions for Artificial Intelligence / Machine Learning based on the open standard RISC-V instruction set architecture. Esperanto is headquartered in Mountain View, California with engineering sites in Portland, Oregon and Austin, Texas in the United States and multiple sites in Europe. Esperanto has brought together a seasoned team of experienced processor and software engineers with the goal of making RISC-V the architecture of choice for compute-intensive applications such as AI and Machine Learning. For more information, please visit <a href="https://www.esperanto.ai/">https://www.esperanto.ai/</a></p>
<p><strong>About the RISC-V Summit</strong></p>
<p>The third annual RISC-V Summit will highlight the continued rapid expansion of the RISC-V ecosystem, presenting both commercial offerings and exciting open-source developments. Newcomers to RISC-V, as well as the seasoned developers who are interested in broadening their toolsets, are invited to choose from the broad range of tutorials. The comprehensive 100% virtual event will feature keynotes from industry pioneers as well as thought-provoking panel discussions. Network with thought-leaders, technology companies, and researchers spearheading the adoption of this evolutionary change in the silicon market.</p>
<p><em>All trademarks or registered trademarks are the property of Esperanto Technologies or their respective holders.</em></p>
</div></div></div></div></div>
							</div>

												<span><span><a href="https://www.esperanto.ai/author/hstump/" title="Posts by Holly Stump" rel="author">Holly Stump</a></span></span><span>2020-12-01T08:33:52-08:00</span>													
													<section>
				
			
	
	
	
	
				<!-- fusion-carousel -->
</section><!-- related-posts -->


																	</article>
	</section>
						
					</div>  <!-- fusion-row -->
				</main>  <!-- #main -->
				
				
								
					
		 <!-- fusion-footer -->

		
					

												</div> <!-- wrapper -->
		</div> <!-- #boxed-wrapper -->
		
		
		
		<a></a>

		

			
		


</div>]]>
            </description>
            <link>https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310931</guid>
            <pubDate>Sat, 05 Dec 2020 02:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Microsoft crushed Slack]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310547">thread link</a>) | @theBashShell
<br/>
December 4, 2020 | https://www.platformer.news/p/how-microsoft-crushed-slack | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/how-microsoft-crushed-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg&quot;,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1771463,&quot;alt&quot;:&quot;Image of Slack running on a laptop. Muhammed Abiodun / Unsplash&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt="Image of Slack running on a laptop. Muhammed Abiodun / Unsplash"></a><figcaption>(Muhammed Abiodun / Unsplash)</figcaption></figure></div><p>Slack’s life as an underdog darling of Silicon Valley ended on November 2, 2016. That’s when the upstart communication startup <a href="https://www.theverge.com/2016/11/2/13497766/slack-microsoft-teams-new-york-times-ad">published an open letter to Microsoft in the </a><em><a href="https://www.theverge.com/2016/11/2/13497766/slack-microsoft-teams-new-york-times-ad">New York Times</a></em>, offering the tech giant an insincere “welcome” to the world of workplace chat software. The occasion was <a href="https://www.theverge.com/2016/10/25/13405200/microsoft-teams-slack-competitor-launch">Microsoft’s launch of Teams</a>, a Slack clone that would come bundled with the company’s popular Office 365 suite of products.</p><p>In its letter, Slack warned Microsoft that “Slack is here to stay,” adding: “we’re just getting started.” But the 4 million users it had at the time would increase to just 12 million four years later, while Microsoft — which added Teams to its 365 bundle without increasing the price — <a href="https://www.theverge.com/2020/10/27/21537286/microsoft-teams-115-million-daily-active-users-stats">took Teams from zero to 115 million users</a>. </p><p>That disparity helps to explain why <a href="https://www.nytimes.com/2020/12/01/technology/salesforce-slack-deal.html">Slack sold itself this week to Salesforce</a>. The deal, which values Slack at $27.7 billion on revenues of $833 million over the past year, has largely been greeted with cheers. (Ben Thompson <a href="https://stratechery.com/2020/salesforce-acquires-slack-salesforces-reasoning-salesforces-opportunity/">offers a typically excellent rundown of the opportunity here for both Salesforce and Slack</a>.)</p><p>But it also feels like the end of an era — one where workers gained new power to bring their own tools to the office, and decide for themselves how they wanted to get work done. Slack first succeeded with small teams who wanted to accelerate their work, and was often dragged into organizations by early adopters. But today, waves of consolidation are leaving people with fewer real choices.</p><p>The rise of smart phones in the early 2010s brought with it a new surge of workplace productivity tools that made mincemeat of everything that had come before them. Box and Dropbox brought easy file storage and sharing. Evernote introduced the idea of ubiquitous, cloud-synchronized note-taking. Sunrise created a more social calendar, while Mailbox and Acompli reimagined email for the mobile phone.</p><p>Slack tiptoed into the conversation in the middle of the decade, and almost immediately became the fastest-growing enterprise software tool of all time. In 2015, just 18 months after it launched, <a href="https://www.theverge.com/2015/6/24/8836087/slack-1-million-daily-users">Slack reported having more than 1 million daily users</a> —&nbsp;a figure then unheard-of in enterprise software.</p><p>It had a great backstory —&nbsp;a last-ditch pivot from a failed video game called Glitch —&nbsp;and, in Stewart Butterfield, one of the tech world’s most charming founders. It also had a bold pitch: it was going to “kill email” —&nbsp;or, at the very least, reduce your reliance on it. And it would do so by integrating hundreds of other services into real-time work chat, creating a kind of all-knowing command console for your organization.</p><p>The company embodied the belief, so common in Silicon Valley, that the best product would win in the end. “Building a product that allows for significant improvements in how people communicate requires a degree of thoughtfulness and craftsmanship that is not common in the development of enterprise software,” the company wrote in its open letter to Microsoft. “How far you go in helping companies truly transform to take advantage of this shift in working is even more important than the individual software features you are duplicating.”</p><p>And yet if there’s a lesson of the past four years, it’s that thoughtfulness and craftsmanship only got the company about 10 percent as far as Microsoft did by copy-pasting Slack’s basic design. In its open letter, Slack famously told Microsoft: “You’ve got to do this with love.” In 2020, looking at Slack’s size, the idea seems laughable. What’s love got to do with it?</p><p>The thing is, I <em>hate</em> that this was the outcome for Slack. I love good productivity tools, and was rooting for Slack to someday become as good as the company hyped it up to be. (And perhaps it still will: like most giants Salesforce has a mixed track record when it comes to the success of its acquisitions, but some seem to be thriving. When I asked about this on Twitter, people had <a href="https://twitter.com/caseynewton/status/1333891286185644032?s=21">a lot of good things to say about post-acquisition Heroku</a>.)</p><p>But Slack’s struggle to succeed as an independent company sadly mirrors that of many one-time innovators in enterprise productivity. Mailbox died and Acompli sold to Microsoft, where it became the mobile Outlook app. Evernote is a pale shadow of its former self. Of that early cohort, only Box and Dropbox became — and still remain —&nbsp;public companies.</p><p>Why is this the case? To get some insight, I called up Aaron Levie, Box’s affable CEO. In Levie’s telling —&nbsp;and he also wrote <a href="https://blog.box.com/salesforce-slack-and-future-work">a blog post about the Slack sale</a> — it all comes down to sales. The idea that workers would someday choose all their own tools was always a fantasy, he told me, in part because most workers don’t event want to think about their tools. In such a world, the winning app will almost always be one with a giant, er, salesforce behind it. </p><p>Microsoft had one. Slack didn’t. Enter Salesforce.</p><p>“The reality with the enterprise is that you can have the best product, but that’s not good enough,” Levie told me. “You need distribution. And what Salesforce has — they have the procurement officers, they have the finance people. They have all of the apparatus you need to interact with to sell software, and they have it for the top 100,000 corporations around the world.”</p><p>Levie is bullish on the acquisition, because it puts Slack and Salesforce on more even ground. </p><p>“The only advantage Microsoft has is distribution, and so now they’ve neutralized the advantage that Microsoft has had,” he said. “All of a sudden, they can actually fulfill the ultimate promise of the opportunity, because they have 10 times the amount of salespeople that can go distribute this thing into corporations around the world.”</p><p>Assuming Levie is right — and I wouldn’t bet against him — that means the medium-term future of work is increasingly a choice between three giants: Microsoft, Salesforce, and (in a distant third) Google. And with that, the golden age of worker choice in productivity tools seems to be coming to an end.</p><p>That’s not to say that the incumbents won’t always face new challengers. But I wonder whether the low ceiling that Slack turned out to have has implications for some of the other fast-growing productivity companies of the current moment. Should Slack’s sale diminish our expectations for Airtable, or Notion, or Coda? Don’t get me wrong — I’m confident their investors will all get their money back, and then some. But do they have a real future outside the arms of a monolith?</p><p>If not, then the productivity market will become as consolidated as any number of other spaces on the internet, from app stores to search engines to social networks. And as our government antitrust regulators begin to awaken after a long period of hibernation, I wonder if they’ll have anything to say about it.</p><h3>The Ratio</h3><p><em>Today in news that could affect public perception of the big tech companies</em></p><p>⬆️ <strong>Trending up</strong>: <strong><a href="https://techcrunch.com/2020/12/02/google-news-showcase-paywalled-stories/">Google</a></strong><a href="https://techcrunch.com/2020/12/02/google-news-showcase-paywalled-stories/">’s new paid deals with publishers mean that access to some paywalled content will now be available to readers for free</a>. Good for publishers, good for Google, good for democracy. (Anthony Ha / <em>TechCrunch</em>)</p><p>🔃 <strong>Trending sideways: <a href="https://www.geekwire.com/2020/microsoft-will-remove-user-names-productivity-score-feature-privacy-backlash/">Microsoft </a></strong><a href="https://www.geekwire.com/2020/microsoft-will-remove-user-names-productivity-score-feature-privacy-backlash/">made changes to the “productivity score” feature in its 365 platform, which gave employers fine-grained data on individual employees’ use of email, chat, and other features</a>. Critics called it “full-fledged workplace surveillance tool;” Microsoft says it will now detach the data from individual employee names.  (Todd Bishop / <em>GeekWire</em>) </p><p>🔃 <strong>Trending sideways:</strong> <strong><a href="https://www.theinformation.com/articles/amazon-drops-pandemic-test-to-track-warehouse-workers-through-wi-fi?utm_source=twitter&amp;utm_medium=page">Amazon </a></strong><a href="https://www.theinformation.com/articles/amazon-drops-pandemic-test-to-track-warehouse-workers-through-wi-fi?utm_source=twitter&amp;utm_medium=page">abandoned a test of a worker safety measure that involved tracking the location of warehouse workers through their personal cell phones</a>. Big week for pushback on worker surveillance initiatives! (Mark Di Stefano / <em>The Information</em>)</p><p>⬇️ <strong>Trending down</strong>: <strong><a href="https://www.theverge.com/2020/12/2/22047383/google-spied-workers-before-firing-labor-complaint">Google</a></strong><a href="https://www.theverge.com/2020/12/2/22047383/google-spied-workers-before-firing-labor-complaint"> illegally spied on workers before firing them, according to a new lawsuit by the National Labor Relations Board</a>. Two employees were fired for looking at their colleagues’ calendars as part of an organizing effort. Google says it didn’t do anything wrong. (Zoe Schiffer / <em>The Verge</em>)</p><h3>Governing</h3><p>⭐ <strong><a href="https://www.washingtonpost.com/technology/2020/12/01/trump-repeal-section-230-ndaa/">In a pair of late-night tweets, President Trump</a></strong><a href="https://www.washingtonpost.com/technology/2020/12/01/trump-repeal-section-230-ndaa/"> threatened to veto the defense reauthorization act if Congress does not repeal Section 230 of the Communications Decency Act</a>. But it’s <a href="https://www.protocol.com/Politics/trumps-section-230-veto-threat">not clear he has the leverage to make it happen</a>. (Tony Romm /  <em>Washington Post</em>)</p><p><a href="https://www.washingtonpost.com/politics/2020/12/02/technology-202-aclu-sues-dhs-over-purchase-cellphone-location-data-used-track-immigrants/">The ACLU sued the Department of Homeland Security over its purchase of cellphone location data to track immigrants</a>. Separately, the department’s inspector general said he would investigate the matter after Senate Democrats began asking questions. (Cat Zakrzewski / <em>Washington Post</em>)</p><p><a href="https://techcrunch.com/2020/12/01/massachusetts-votes-to-pass-statewide-police-ban-on-facial-recognition/">Massachusetts passed a statewide ban on the use of facial recognition technology by police</a>. It may be the largest US ban of facial recognition tech yet, and is part of a growing patchwork of laws regulating it around the country. (Taylor Hatmaker and Zack Whittaker / <em>TechCrunch</em>)</p><p><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">EveryAction</a></strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">, a </a><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">Salesforce</a></strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">-like platform for liberal campaigns and causes, acquired the organizing company </a><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">Mobilize</a></strong>. The move bolsters what Bloomberg calls “the central nervous system for practically all of Democratic politics.” (Joshua Green / Bloomberg)</p><p><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html">Amid rising tensions between China and Australia, </a><strong><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html">WeChat</a></strong><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html"> deleted a fabricated image sent by a Chinese foreign affairs official accusing Australian soldiers of murdering Afghan children</a>. <strong>Twitter</strong> left the post up. (Eryk Bagshaw, Anthony Galloway and Shane Wright / <em>Sydney Morning Herald</em>)</p><h3>Industry</h3><p>⭐ <strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Facebook</a></strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/"> teamed up with former employees of popular game developer </a><strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Telltale</a></strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/"> for </a><em><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Rival Peak</a></em><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">, a new reality show where viewers will influence the story</a>. It feels … maybe a little too high-concept? We’ll see. Gene Park had the details at the <em>Washington Post</em>:</p><blockquote><p><em>Rival Peak</em> is a Facebook Watch program in which artificial intelligence-driven “contestants” will live, work and exist for every minute of the day within the fictional region of Rival Peak, a mountainous forest region that emulates the Pacific Northwest. With a diverse cast of internationally-based characters, Facebook users will decide what each contestant of the show will do in the game, how …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.platformer.news/p/how-microsoft-crushed-slack">https://www.platformer.news/p/how-microsoft-crushed-slack</a></em></p>]]>
            </description>
            <link>https://www.platformer.news/p/how-microsoft-crushed-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310547</guid>
            <pubDate>Sat, 05 Dec 2020 01:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25310462">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310462</guid>
            <pubDate>Sat, 05 Dec 2020 00:52:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I accidentally built a spying app]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25310316">thread link</a>) | @akeck
<br/>
December 4, 2020 | https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In the fall of 2007, my parents gave me an unforgettable gift for my sixteenth birthday: a first-generation iPhone.</p><p>I still clearly remember watching the keynote in which Steve Jobs announced the first Apple-branded phone a few months earlier. As a teenager attending high school in my hometown of Vicenza, Italy, I tuned into the livestream just before dinner, carefully listening to every word he said. That evening, Jobs started announcing a “widescreen iPod with touch controls”, a “revolutionary mobile phone” and a “breakthrough Internet communications device”–theatrically pausing before confessing that he was actually talking about one single device: the iPhone. Thousands of miles away from me, you could hear attendees exploding cheerfully through the live feed. Jobs went on demoing this amazing invention that, a decade later, would end up changing much more than the mobile phones market: it directly or indirectly impacted our society through mobile web, app stores, changing work-life balance, and social media.</p><p>October came, and so did the day I finally got my iPhone. I was really excited as I was the first one in my social circle with one. Every other teenager (and adult!) that saw my phone reacted in awe and with lots of curiosity. More than a few were also secretly envious, something I secretly did not mind. To add to the novelty, at the time the iPhone was only available for sale in the US.</p><p>To get an iPhone for me, my father had to ask a friend traveling to New York on a business trip to bring one back on the plane with her. That was not the end of it, however, as all phones were locked to the AT&amp;T network. In order for me to be able to use my iPhone in Italy, I had to unlock it.</p><p>That process required learning a variety of tools and techniques developed by hackers in the community, then documented in various blogs and forums. The first step was to <em>jailbreak</em> the phone, which gave you full access to the system and allowed you to run third-party apps. Then you’d have add one of those “hacking” apps to your phone, which patched the bootloader to remove the lock the US carrier had put on it. Despite sounding like a mouthful, the iPhone hacking community had worked hard on the User Experience (UX), making this entire process relatively easy for most people with basic tech skills.</p><hr><p>I really loved my shiny, new iPhone, and I was so excited about it that I was willing to accept many of its original limitations. It only supported slow 2G networks, didn’t have copy/paste, couldn’t transfer files via Bluetooth to my friends, and <a href="https://www.apple.com/hotnews/thoughts-on-flash/">famously</a> didn’t support Adobe Flash, which was ubiquitous on the web at the time.</p><p>However, there was one thing I really couldn’t stand: the Messages application could only store 1,000 texts (SMS).</p><p>That was 2007 — before the days of WhatsApp, Facebook Messenger, Telegram, etc. Instant messaging was something people did on their PCs only, with things like Windows Live Messenger (née MSN Messenger) or AIM.</p><p>For a high schooler like me, text messaging was the main way I kept in touch with my friends daily (<em>what was I supposed to do, call them?</em>). With my carrier giving me a whopping 100 free texts per day (seriously, we had to pay for them), between sent and received texts it would take less than a week to reach the storage limit of 1,000.</p><p>That’s when it all started.</p><p>Because my iPhone was already “hacked” (jailbroken), as a requirement for unlocking it and use it in Italy, I had full system access already. That allowed me to c extract any document I wanted, including my phone’s text message database.</p><p>It wasn’t even a month since I got my iPhone that I had already built a small “app” running on my laptop to archive my text messages forever. I would manually extract the SMS database from my iPhone, copy it to my laptop, then use a set of scripts written in PHP (the only programming language I knew at the time) to store the messages in a local database, and finally display them using a web-based interface.</p><p>This thing I put together worked just fine for me, but I immediately realized the “business potential” of what I had just created. Just like myself, I assumed many others had the same annoyance. I could have used what I learned to help them too, and maybe make some pocket change in the process. As a matter of fact, I did consider myself an enterprising teenager.</p><p>The idea had potential, and the “app” I built for myself already provided solid foundations, so I just needed to do a bit more work to turn it into a commercially-viable project.</p><p>The biggest challenge was making the solution more accessible to others, including those who were not particularly tech-savvy. That’s when I started learning about app development for iPhone.</p><p>Famously, Apple did not want the iPhone to support third-party apps at the beginning, saying developers should build web apps instead. That policy didn’t last long, and with the iPhone OS 2 update, launched in mid-2008, the official App Store came to life: the rest, as they say, is history.</p><p>However, the hacking community had already found a way to sideload apps and had even developed an “app store” called Cydia where you could find games, apps, and even mods to enhance the capabilities of the operating system itself. Cydia came preinstalled on every <em>jailbroken</em> iPhone, which meant potentially hundreds of thousands of people had access to it.</p><p>Everyone could build apps that would be published on Cydia, as long as you knew how to–something that was not remotely as easy to do as it is with today’s tools. As an enterprising teenager with quite a bit of free time on my hand during those winter afternoons and evenings, I took on that challenge.</p><hr><p>The first version of YouArchive.It came out in January 2008.</p><p>Today, you would describe YouArchive.It as a cloud service to store iPhone text messages. You could store all your messages in there, then read and search them using a web-based application.</p><p>There’s still a video left on YouTube showing the application in action (this was the third, and last, version):</p><p><iframe src="https://www.youtube-nocookie.com/embed/ps5ohEhO3S4" allowfullscreen="" title="YouTube Video"></iframe></p><p>With YouArchive.It came an iPhone application too. Published on the Cydia app store, it allowed importing messages into the “cloud service” directly from the phone.</p><p>YouArchive.It was free to use with a limit of 80,000 text messages. Because personal communications can be sensitive, all messages were stored encrypted. With a one-time payment of just €5 (about $6), you could become a VIP, remove any limit and enjoy unlimited storage.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*vTxYRljXFl3IBXGRsXOVag.png" alt="A screenshot of iTextUploader running on a first-generation iPhone"></p><figcaption>A screenshot of iTextUploader running on a first-generation iPhone</figcaption><p>For the next year and a half, YouArchive.It continued to grow organically. A few blogs and websites dedicated to iPhone “hacking” and to the underground app stores wrote about the app. Even a small radio program in the US featured it</p><p>I continued developing the app as a side project while in high school. I was also providing tech support and maintaining the infrastructure.</p><p>Listening to users' feedback, I would periodically add new features. YouArchive.It started displaying emojis as soon as the iPhone supported that (outside of Japan, it required downloading an app to enable them). Users asked for and got the ability to restore texts in another iPhone, before iCloud was available. I also implemented other privacy features such as requiring a password to open the mobile app.</p><blockquote><h3 id="what-i-didnt-realize-at-the-time-however-is-that-i-had-unknowingly-and-unwillingly-built-a-spying-tool-and-a-really-convenient-and-efficient-one">What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</h3></blockquote><p>Enough users were paying the fee to become VIP that I could cover the costs of running the service–this was before everyone was using Amazon Web Services or Microsoft Azure, so I was renting a co-located physical server which wasn’t cheap–and keep some pocket cash. Not much, but enough to pay for some hobbies and outings with friends.</p><p>Most importantly, building YouArchive.It gave me a lot of satisfaction and the opportunity to learn a lot of things about software development, business, dealing with customers and listening to their feedback.</p><hr><p>When I finally shut the service down, in June 2010, YouArchive.It had about 32,000 registered users who stored over 76 million messages.</p><p>The first, and stated, reason for the deprecation was a technical one: YouArchive.It’s iPhone app required using private APIs, which meant it could not be published on the App Store (and it still couldn’t to this day), limiting it to <em>jailbroken</em> phones only.</p><p>The second reason however was the most important to me, even though I have not revealed it until now.</p><p>About a year before the app closed, in April 2009 I implemented a new feature that was requested by many users: the ability to upload texts automatically, in background, without user intervention. For paying “VIP” users only, the mobile app could automatically send all new text messages to YouArchive.It, as often as every 15 minutes.</p><p>Automatic upload was an incredible convenience for many users that wanted to hoard their texts like me, to keep them forever, search within them, print or export them, or just liked having a backup.</p><p>What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</p><p>Thanks to background uploads, people could install the YouArchive.It app on another person’s iPhone, set it up, maybe even hide it (something possible on a <em>jailbroken</em> iPhone), and then watch as the text messages come in, almost real-time. Jealous partners, stalkers and the likes could install this tool on an unknowing victim’s phone with relative ease.</p><p>I can’t remember how I discovered that — it might have been a support request from a user or a post in a bulletin board. I also can’t know how many people were using YouArchive.It for their own archiving rather than to spy on others. Realizing what my users were doing, however, made me feel really uncomfortable and I did not want any part of that anymore.</p><p>As a senior in high school, barely eighteen years-old, I realized for the first time how technology can have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</a></em></p>]]>
            </description>
            <link>https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310316</guid>
            <pubDate>Sat, 05 Dec 2020 00:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Down Here, They Sometimes Call It 'Boy']]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25308101">thread link</a>) | @pelt
<br/>
December 4, 2020 | https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html | <a href="https://web.archive.org/web/*/https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                            

                                                        <!-- sphereit start -->
                            <!-- startprint -->

                            <!-- end article source sponsored -->

                                                                                                                                                                                                                                                                                                    
                                                                                        
                            
                            
                            
                            
                                
                                
                                                                                        
                                                            <div>
<p><a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4"> <img src="https://assets.realclear.com/images/52/527328_5_.jpg"> </a></p>

<p>Regnery Publishing</p>


</div>
<p><em>The following is an excerpt from "<a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4">Big White Ghetto: Dead Broke, Stone-Cold Stupid, and High on Rage in the Dank Woolly Wilds of the "Real America"</a>" by Kevin D. Williamson.</em></p>
<p>"Dogfood—yeah, <em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>—because it looks like ground-up dog food.” He’s embarrassed to be talking about this. “Or sand, because it’s brown. Or diesel. Or killa or 9-1-1. That’s the influence of rap culture down here.” He is a young, clean-cut, Eagle Scout–ish white kid, hesitant about using the words “rap culture,” like he’s not sure if he’s allowed to say that. But he goes on, matter-of-factly. He’s been off heroin for only a few months, so the details are fresh in his mind, even if he remains a little hazy on parts of his autobiographical timeline. “The 9-1-1, they call it that because they want you to know it’s potent, that you’ll have to go to the emergency room.”</p>
<p>That’s a weird and perverse and nasty kind of advertising, but then dope-buying psychology isn’t very much like Volvo-buying psychology: Crashing is just another part of the ride. One spiteful dealer boasts about spiking his product with excessive amounts of fentanyl—a pharmaceutical analgesic used for burn victims and cancer patients—his plan being to intentionally send overdosed users to the hospital or the morgue . . . for <em>m</em><em>a</em><em>r</em><em>k</em><em>e</em><em>t</em><em>i</em><em>n</em><em>g</em> <em>p</em><em>u</em><em>r</em><em>p</em><em>os</em><em>e</em><em>s</em>. Once the word got out about the hideous strength of his product, that killa went right out the door ricky-tick.</p>
<p>The young man explaining the current vocabulary of opiate addiction in Birmingham is barely old enough to buy a beer, and his face and voice are soft. He describes the past several years of his life: “dope-sick and stealing,” going from job to job—eight jobs in six months—robbing his employers of everything not physically nailed to the floor, alienating his family, descending. He was an addict on a mission: “You’re always chasing that first shot of dope, that first high—and the first one for me almost killed me. I was seventeen or eighteen years old, and I met a guy who had just got out of prison, doing a thirteen-year sentence for heroin possession and distribution. He was staying at the Oak Mountain Lodge, which is a nice little classic place.” (In 2013, four police officers and a drug dog had to be treated for exposure to dangerous chemicals after raiding a suspected meth lab in that hotel; the customer reviews online are decidedly mixed.) “I was <em>snorting </em>heroin when I met up with him, and set him up with my connect. He offered to shoot me up, and I wanted to do it. And I remember him looking me in the eyes and telling me, ‘If you do this, you’ll never stop, and you’ll never go back.’ And I said, ‘Let’s do it.’”</p>
<p>He doesn’t know what happened for the next several hours. When he regained consciousness, his junkie buddy’s girlfriend was worriedly ministering to him.</p>
<p>“That was first thing in the morning,” he says. “That night, I did another one.”</p>
<p>Same results. “I’d nodded out from snorting it, but there’s nothing like shooting it.”</p>
<p>He was, he says, a “pretty good junkie” for a time.</p>
<p>This particular opiate odyssey starts off in a Walgreens, something that turns out to be absolutely appropriate. I’m headed up the south coast and then inland on the heroin highway up to Atlanta, starting from the Port of Houston, which connects that city with 1,053 ports in nearly 200 countries and which in December alone welcomed the equivalent of 63,658 20-foot cargo containers of goods into the United States. There was, the feds are pretty sure, some dope squirreled away in there. In fact, all sorts of interesting stuff comes in and out of Houston. In May, U.S. Customs seized a Fast Attack Vehicle with gun mounts headed to the Netherlands. It hadn’t been ordered by the Dutch military. (Organized crime in the Netherlands is bananas: A raid in the summer of 2020 found Dutch police opening up a shipping container expecting to find it loaded with narcotics or stolen goods, but what they found instead was a dentist’s chair bolted to the floor and handcuffs hanging overhead—it was set up as a mobile torture chamber, God knows why.) I’m at Walgreens because I’ve got a long drive ahead and I’m going to be out of pocket for a bit, and I have a prescription to fill: an honest-to-goodness Schedule II Controlled Substance, in the official nomenclature, a term that covers some pretty interesting stuff, including the oxycodone and fentanyl I’ll be hearing so much about in the next few days. Some of us are going to heaven, some of us are going to hell, but all of us have to stop at Walgreens first.</p>
<p>The clerk is on the phone with a doctor’s office: “What’s your DEA number?”</p>
<p>For working-class white guys who haven’t found their way into the good jobs in the energy economy or the related manufacturing and construction booms that have reverberated throughout the oil patch, who aren’t college-bound or in possession of the skills to pay the bills, things aren’t looking so great: While much of the rest of the world gets healthier and longer-lived, the average life expectancy for white American men without college educations is declining. Angus Deaton, the Princeton economist who won the Nobel Prize in 2015, ran the numbers and found (in a study co-authored by his Princeton colleague Anne Case) that what’s killing what used to be the white working class isn’t diabetes or heart disease or the consumption of fatty foods and Big Gulps that so terrifies Michael Bloomberg, but alcohol-induced liver failure, along with overdoses of opioid prescription painkillers and heroin: Wild Turkey and hillbilly heroin, and regular old heroin, too, the use of which has increased dramatically in recent years as medical and law-enforcement authorities crack down on the wanton overprescription of oxy and related painkillers.</p>
<p>Which is to say: While we were <em>ignoring </em>criminally negligent painkiller prescriptions, we helped create a gigantic population of opioid addicts, and then, when we started paying attention, the first thing we did was take away the legal (and quasi-legal) stuff produced to exacting clinical standards by Purdue Pharma (maker of OxyContin) and others. So: lots of opiate addicts, fewer prescription opiates.</p>
<p>What was left was diesel, sand—<em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>.</p>
<p>The clerks at this Walgreens are super friendly, but the place is set up security-wise like a bank, and that’s to be expected. This particular location was knocked over by a young white man with a gun the summer before last, an addict who had been seen earlier lurking around the CVS down the road. This is how you know you’re a pretty good junkie: The robber walked in and pointed his automatic at the clerk and demanded oxy first, then a bottle of Tusinex cough syrup, and then, almost as an afterthought, the $90 in the till. Walgreens gets robbed a lot: In January, armed men stormed the Walgreens in Edina, Minnesota, and stole $8,000 worth of drugs, mainly oxy. In October, a sneaky young white kid in an Iowa State sweatshirt made off with more than $100,000 worth of drugs—again, mainly oxy and related opioid painkillers, from a Walgreens in St. Petersburg, Florida. Other Walgreens locations—in Liberty, Kansas; East Bradford, Pennsylvania; Elk Grove, California; Kaysville, Utah; Virginia Beach; New Orleans—all have been hit by armed robbers or sneak thieves over the past year or so, and there have been many more oxy thefts.</p>
<p>It won’t make the terrified clerks feel any better, but there’s poetic justice in that: In 2013, Walgreens paid the second-largest fine ever imposed under the Controlled Substances Act for being so loosey-goosey in handling oxy at its distribution center in Jupiter, Florida, that it enabled untold quantities of the stuff to reach the black market. The typical pharmacy sells 73,000 oxycodone pills a year; six Walgreens in Florida were going through more than 1 million pills a year—each. A few years before that, Purdue was fined $634.5 million for misleading the public about the addictiveness of oxycodone. Kentucky, which has been absolutely ravaged by opiate addiction, is still pursuing litigation against Purdue, and it has threatened to take its case all the way to the Supreme Court, if it comes to that.</p>
<p>Ground Zero in the opiate epidemic isn’t some exotic Taliban-managed poppy field or some cartel boss’s fortified compound: It’s right there at Walgreens, in the middle of every city and town in the country.</p>
<p>I pick up my prescription and get on my way.</p>
<p>The next afternoon, having driven past billboards advertising boudin and strip joints with early-bird lunch specials and casino after casino after sad little casino; help-wanted signs for drilling-fluid businesses and the Tiger Truck Stop (which has a twenty-four-hour Cajun café and an actual no-kidding <em>live tiger </em>in a cage out front); past Whiskey Bay and Contraband Bayou, where the pirate Jean Lafitte once stashed his booty; around the Port of New Orleans, another <em>entrepôt </em>for heroin and cocaine—it is almost as close to Cartagena as it is to New York—I arrive at a reasonably infamous New Orleans drug corner, where I inquire as discreetly as I can about the availability of prescription …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</a></em></p>]]>
            </description>
            <link>https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308101</guid>
            <pubDate>Fri, 04 Dec 2020 21:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PHP8, from a Security Point of View]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25308078">thread link</a>) | @todsacerdoti
<br/>
December 4, 2020 | https://dustri.org/b/php8-from-a-security-point-of-view.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/php8-from-a-security-point-of-view.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    <header>
      
    </header>
    <div>
      <p>PHP8 was <a href="https://www.php.net/releases/8.0/en.php">released</a> on the
26<sup>th</sup> of November 2020. It brought a lot of interesting things,
security-wise, but also showcases a couple of (minor) missed opportunities in my
opinion.</p>
<h2 id="type-safety"><a href="#type-safety">Type safety</a></h2>
<p>I'm a big fan on relying on typing to ensure security properties,
like <a href="https://web.dev/trusted-types/">Trusted types</a> in javascript: it
shouldn't compile if it's not secure.</p>
<p>PHP8 won't try to cast string into numbers anymore, thanks to the 
<a href="https://wiki.php.net/rfc/string_to_number_comparison">Saner string to number comparisons RFC</a>,
meaning that collision with hashes starting with <code>0e</code> and the likes are finally
a thing of the past! This is a subset of Snuffleupagus' <a href="https://snuffleupagus.readthedocs.io/features.html#preventing-sloppy-comparisons">sloppy comparison
prevention</a> feature.</p>
<p>The <a href="https://wiki.php.net/rfc/consistent_type_errors">Consistent type errors for internal functions RFC</a>
will prevent things like <code>0 == strcmp($_GET['username'], $password)</code> bypasses,
since <code>strcmp</code> won't return <code>null</code> and spit a warning any longer,
but will throw a proper exception instead. This was also a <a href="https://externals.io/message/106522">nice opportunity</a>
for PHP to add annotations for functions parameters and return types.</p>
<p>The <a href="https://wiki.php.net/rfc/arithmetic_operator_type_checks">Stricter type checks for arithmetic/bitwise operators</a>
and <a href="https://wiki.php.net/rfc/engine_warnings">PHP RFC: Reclassifying engine warnings</a> RFC
are in the same spirit.</p>
<h2 id="jit"><a href="#jit">JIT</a></h2>
<p>PHP8 comes with a <a href="https://wiki.php.net/rfc/jit">JIT</a> based on
<a href="https://luajit.org/dynasm.html">DynASM</a>, bringing an RWX memory space into
PHP's memory space, into a shared allocation, meaning that its offset won't
change between different PHP8+ processes.</p>
<p>Moreover, DynASM isn't designed with processing/compilation/execution of
untrusted code in mind, and doesn't do things like constants blinding and
advanced folding to mitigate against spraying, nor random padding/nop
insertion, nor ensuring that the memory region is never both writeable <em>and</em>
executable to prevent direct code injection. This means that it's now way
easier to gain native code execution when exploiting memory corruptions,
albeit to be fair, most attackers are happy with a php code execution,
and won't push further.</p>
<p>Having a JIT comes with a lot of code complexity and maintenance burden. I'll
be without doubt a <a href="https://bugs.php.net/search.php?cmd=display&amp;order_by=ts1&amp;direction=DESC&amp;limit=30&amp;package_name[]=JIT">great source of
bugs</a>,
for a minor speed improvement on real-life workloads.</p>
<h2 id="cryptography"><a href="#cryptography">Cryptography</a></h2>
<ul>
<li><code>password_hash</code> now automatically generates a salt, accepting a
    user-provided one is deprecated.</li>
<li><code>crypt</code> will now fail instead of silently falling back to
    <a href="https://en.wikipedia.org/wiki/Crypt_(C)#Traditional_DES-based_scheme">DES</a>
    when an unknown salt format was provided. The parameter is also made
    mandatory, hashing without a salt is now unsupported.</li>
<li><a href="https://tools.ietf.org/html/rfc5652">RFC 5652</a> is now exposed via the OpenSSL extension.</li>
</ul>
<h2 id="misc"><a href="#misc">Misc</a></h2>
<ul>
<li>The <a href="https://www.php.net/manual/en/language.operators.errorcontrol.php">error control operator</a>, aka <code>@</code>
    won't silence fatal errors anymore, meaning that poorly written webshells will have more chances
    to leave traces in your logs.</li>
<li><code>libxml_disable_entity_loader</code> is now deprecated, even if it's not (yet) reflected in php's documentation.
    This is acceptable since PHP8 now requires at least libxml 2.9.0,
    which comes with external entity loading disabled by default.</li>
<li>Access to undefined constants will throw an error, instead of being silently
  interpreted as a string, no more <code>SALT</code> being silently converted to <code>"SALT"</code>.</li>
<li><code>create_function</code> was <a href="https://github.com/php/php-src/commit/ee16d99504f0014c3d292809da927fb622293f41">removed</a>, closing its infamous code injection vector.</li>
<li><code>array_key_exists</code> throws when passed an array/object, instead of silently
  doing nonsense.</li>
<li>The <code>e</code> modifier in <code>mb_ereg_replace</code> has been removed.</li>
<li>Metadata associated with a phar will
  <a href="https://wiki.php.net/rfc/phar_stop_autoloading_metadata">no longer be unserialized</a>,
    killing a low-hanging
    <a href="https://github.com/s-n-t/presentations/blob/master/us-18-Thomas-It's-A-PHP-Unserialization-Vulnerability-Jim-But-Not-As-We-Know-It.pdf">RCE vector</a>.</li>
<li><code>FILTER_SANITIZE_MAGIC_QUOTES</code>, <code>get_magic_quotes_gpc</code> and <code>get_magic_quotes_runtime</code> have been removed,
  people will now have to do proper sanitization instead.</li>
<li>As usual, a couple of memory safety issues were fixed,
    <a href="https://bugs.php.net/bug.php?id=80242">some</a>
    <a href="https://bugs.php.net/bug.php?id=76618">exploitable</a>.</li>
<li><a href="https://github.com/jvoisin/snuffleupagus">Snuffleupagus</a> is currently being
    ported to php8!</li>
</ul>
<h2 id="missed-opportunities"><a href="#missed-opportunities">Missed opportunities</a></h2>
<p><a href="https://wiki.php.net/rfc/engine_warnings#undefined_variable">Undefined
variables</a>, as
opposed to constants, are still not an error, meaning that things like <code>solt</code>
instead of <code>salt</code> might (and will) go unnoticed.</p>
<p>Converting an <code>Array</code> to a string will only yield a <code>Warning</code> instead of an
error, albeit that now that <code>__toString</code> <a href="https://wiki.php.net/rfc/tostring_exceptions">can <em>finally</em>
throw</a>, it might hopefully change
in the near future.</p>
<p>Albeit significant <a href="https://wiki.php.net/rfc/easy_userland_csprng">CSPRNG</a>
<a href="https://wiki.php.net/rfc/random-function-exceptions">improvements</a> have been
merged in PHP7, PHP8 didn't seize the opportunity to keep the momentum and to
aliases <code>rand</code> and <code>mt_rand</code> to <code>random_int</code>, like
<a href="https://snuffleupagus.readthedocs.io/features.html#weak-prng-via-rand-mt-rand">Snuffleupagus</a> is doing.</p>
<p>An other missed opportunity in my opinion is that there is <a href="https://bugs.php.net/bug.php?id=50715">still no
way</a> to disable some <a href="https://www.php.net/manual/en/wrappers.php">PHP's wrappers</a>, except via
<a href="https://www.php.net/manual/en/function.stream-wrapper-unregister.php"><code>stream_wrapper_unregister</code></a>
but this can be reversed with
<a href="https://www.php.net/manual/en/function.stream-wrapper-restore.php"><code>stream_wrapper_restore</code></a>.
Wrappers are scary: the main use I've seen for the <a href="https://www.php.net/manual/en/wrappers.php.php#wrappers.php.filter"><code>filter://</code>
one</a> is
exfiltrating data via <code>php://filter/convert.base64-encode/resource=/some/file</code>, and is a <a href="https://www.netsparker.com/blog/web-security/php-stream-wrappers/">decent
amount of</a>
<a href="https://lightless.me/archives/include-file-from-zip-or-phar.html">arcane</a>
<a href="https://gynvael.coldwind.pl/?lang=en&amp;id=671">stuff</a> lurking in the shadows.
Providing a way to reduce this attack surface (like making streams opt-in)
would be welcome.</p>
    </div>
  </article>
</section>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/php8-from-a-security-point-of-view.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308078</guid>
            <pubDate>Fri, 04 Dec 2020 21:14:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Audience Is a Marathon]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25307048">thread link</a>) | @dbustac
<br/>
December 4, 2020 | https://danielbusta.com/marathon/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/marathon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://danielbusta.com/marathon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25307048</guid>
            <pubDate>Fri, 04 Dec 2020 20:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Continuous Integration Mystery]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25306898">thread link</a>) | @basicallydan
<br/>
December 4, 2020 | https://danhough.com/blog/ci/ | <a href="https://web.archive.org/web/*/https://danhough.com/blog/ci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
			<p>
				<span>Published 03 December 2020 in Vancouver, BC, Canada</span>
				
				<span title="It took me about 5 minutes to read this blog post back to myself.">(~5min read)</span>
				
			</p>
		</header>
		<p>Yesterday I faced a version control situation I rarely face.</p>

<p>It showed me that I may rely a little too much on the green light from CI tools like CircleCI and GitHub Actions when deciding whether it’s safe to merge a branch.</p>

<p>Here’s what happened:</p>

<ol>
  <li>My colleague added new <code>expect</code> clauses to a test, plus the code to <strong>pass it</strong>.</li>
  <li>They merged this into the main branch via a PR.</li>
  <li>Later, I forked off of the main branch.</li>
  <li>I added <strong>more new clauses</strong> to the test my colleague had earlier modified.<br>I worked on it for the rest of the day.</li>
  <li>I made a <strong>pull request</strong>.</li>
  <li>Next, two colleagues reviewed my work and approved it on GitHub.<br>All the pre-merge checks on CircleCI were passing, including tests and style checks.<br>I rebased and decided to save the merge for the morning.</li>
  <li>Soon after, an error was found related to the code the first colleague had deployed.<br>They <strong>reverted</strong> the PR they had merged on Day 1.</li>
  <li>Not long after, I checked my PR again - there were no merge conflicts.<br><strong>I merged my code</strong>.</li>
</ol>

<p>An hour or so later, another colleague tells me that, according to CircleCI, a test I wrote was failing on the main branch. How could this be, they said? It appears to have been passing on the branch it came from!</p>

<p>What is the cause of this mysterious failure?</p>

<p>I’d recently touched that test, so I looked at the error and quickly worked out what it was: The test I’d added to was failing because one of it’s <code>expect</code> clauses relied on code which had been been reverted - it was no longer a valid expectation. GitHub didn’t run a new diff on my PR after the removal of the clause in question from the main branch; the reverted test code simply looks ‘unchanged’ in the diff, as if it had been and was still there.</p>

<p>I didn’t remove it, I didn’t rebase, and my PR ended up re-adding the recently-removed <code>expect</code> clause even though it didn’t appear to.</p>

<p>Is there a lesson to be learned here?</p>

<p>On one hand, the process is working. There was a merge error caused by the <code>git</code> equivalent of a race condition, we were told about it, and we were able to resolve it. Why bother running tests on the main branch before you deploy unless you are concerned that there is a chance they’ll fail?</p>

<p>Maybe the lesson is to keep on doing what we’re doing.</p>

<p>On the other hand, the process felt like it was disrupting the order of things. Something like this is often said: “if you have a reliable QA and CI process, then if something is on the main branch it should be deployable.” And yet here was an anomalous case which suggested otherwise.</p>

<p>Perhaps, then, the lesson is that our QA and CI process isn’t robust enough. Should CI create a merged branch behind-the-scenes and run tests on <em>that</em> before allowing the branch to be merged?</p>

<p>I’m not sure. In the meantime, while I try to decide what the lesson is, I think I’ll just rebase my branches more often.</p>

<p>A <a href="https://news.ycombinator.com/item?id=25306898">discussion has begun on Hacker News</a>, please share your thoughts if you have any.</p>

		<p>Heckle me on Twitter <a href="http://twitter.com/basicallydan">@basicallydan</a>.</p>
	</div></div>]]>
            </description>
            <link>https://danhough.com/blog/ci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306898</guid>
            <pubDate>Fri, 04 Dec 2020 19:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gold vs. Bitcoin is a self-defeating doom-loop]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25306259">thread link</a>) | @StuntPope
<br/>
December 4, 2020 | https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/#comments">
			2 <span></span>
		</a></p>
		
		
				<h3><img loading="lazy" src="https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med.jpg" alt="" width="800" height="600" srcset="https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med.jpg 800w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-300x225.jpg 300w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-150x113.jpg 150w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-768x576.jpg 768w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-65x49.jpg 65w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-220x165.jpg 220w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-133x100.jpg 133w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-358x269.jpg 358w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-533x400.jpg 533w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-600x450.jpg 600w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-680x510.jpg 680w" sizes="(max-width: 800px) 100vw, 800px"></h3>

<p><em>With all due respect to the people arguing this one way or the other – many of whom are super intelligent. This argument is a self-defeating doom loop that can only be resolved via an act of faith.</em></p>
<h3>Introducing your Economic Apocalypse Toolkit</h3>
<p>With both Bitcoin and gold (and stonks, for that matter) at or recently off of all time highs the age old debate of whether gold is better than Bitcoin or vice versa is everywhere. I finally sat down and mapped out the <strong>Economic Apocalypse Toolkit</strong> after listening to Grant Williams and Bill Fleckenstein’s <a href="https://podcasts.apple.com/lv/podcast/the-end-game-ep-12-fred-hickey/id1508585135?i=1000501094047">End Game podcast episode with Fred Hickey</a>, who writes <strong>The High Tech Strategist</strong>.</p>
<p>In it they hit on the perennial question of “gold vs Bitcoin” and Hickey laid out his objections to it. I’ve been a subscriber of The HTS for several years now and think it’s absolutely fantastic, and of course I also subscribe to <a href="https://ttmygh.com/">Grant Williams TTMYGH</a> and <a href="https://www.fleckensteincapital.com/home.aspx">Fleck’s newsletter</a> as well. All great stuff, well written, from extremely intelligent people. I do get the sense that Williams is somewhat open to Bitcoin and he <em>wants&nbsp;</em>to talk about it and explore the idea that it may be something more than the usual tropes: <a href="https://outofthecave.io/articles/this-time-is-different-part-i-what-bitcoin-isnt/">a ponzi, based on nothing, Tulipmania, etc</a>, but maybe he’s hesitant at prospect of taking heat for suggesting it.<span id="more-1451"></span></p>
<p>I just find the entire debate pointless because people who invest in either asset class&nbsp;<em>are doing so for the same reasons.&nbsp;</em>They are reacting to the same threat, they see the same unsustainability, they are preparing for the same End Game, if you will.</p>
<p>Given that many of the people who see the underlying issues are of a capital allocator, long term mindset, why is this being thought of in terms of either/or and not in terms of probabilities and scenarios?</p>
<p>If the job at hand is to protect one’s wealth from systemically rigged and disintegrating monetary regime, arguing for one over the other feels like trying to defend against it with only half the available toolkit. Is there a mechanic who wouldn’t be caught dead with a screwdriver in his toolbox because he can give you a list of reasons why every problem can be solved with a wrench? “Screwdrivers for suckers!”</p>
<p>The entire gold vs crypto argument goes away when one realizes that there is more overlap in the objectives of each asset than there are differences. And if you can get your own biases out of the way, then even the differences when looked at objectively seem to have uncanny parallels</p>
<blockquote><p><strong>Gold</strong> has a 5,000 year track record, and has never failed to hold its value, which is quite impressive and has to count for something….<br>
<strong>Bitcoin</strong> has broken out of nowhere and taken the world by storm in an astonishingly small amount of time, which is quite impressive and has to count for something…</p>
<p><strong>Bitcoin</strong> is backed by nothing.<br>
<strong>Gold</strong> is just a shiny rock.</p>
<p>Without electricity, Bitcoin is useless.<br>
You can’t eat gold.</p>
<p><strong>Quantum computing</strong> will eventually destroy Bitcoin’s encryption.<br>
<strong>Asteroid mining</strong> will eventually make gold abundant and cheap.</p>
<p>Bitcoin is a ponzi.<br>
What’s the definition of a gold mine? A hole in the ground with a liar standing beside it.</p></blockquote>
<p>I could go on….</p>
<p>Since the future is unknowable and certainty elusive, aligning with one aspect of the above over the other has to be a choice not a fact. It’s an act of faith. So why not embrace agnosticism and make use of both sets of tools in your financial survival toolkit?</p>
<h3>The Toolkit</h3>
<p>Let’s just step briefly through some of the items in the mindmap. We have metals on one side, cryptos on the other.</p>

<div id="attachment_1452"><p><a href="https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit.png" target="_new" rel="noopener noreferrer"><img aria-describedby="caption-attachment-1452" loading="lazy" src="https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit.png" alt="" width="800" height="492" srcset="https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit.png 2074w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-300x185.png 300w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-1024x630.png 1024w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-150x92.png 150w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-768x473.png 768w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-1536x945.png 1536w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-2048x1260.png 2048w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-65x40.png 65w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-220x135.png 220w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-163x100.png 163w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-358x220.png 358w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-650x400.png 650w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-731x450.png 731w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-829x510.png 829w" sizes="(max-width: 800px) 100vw, 800px"></a></p><p id="caption-attachment-1452">Click for large version</p></div>
<p>On the cryptos side, I just think Bitcoin is the crypto-reserve currency and will continue to be for the foreseeable future. My preferred way to accumulate BTC is to earn it via my businesses. <a href="https://easydns.com/">easyDNS</a> has been accepting Bitcoin since 2013 and we’re <a href="https://easydns.com/landers/earn-crypto/">developing a payments service for clients</a> that will be based on <a href="https://btcpayserver.org/">BTCPayserver.</a></p>
<p>I put Litecoin and alts in there to trigger the maximalists. As per the Supersuckers song, <em>“I like it all man. (All or nothin’ I’m all in even when I’m bluffin’)”.</em></p>
<p>Ethereum is different animal, I think the Bitcoin vs Ethereum schism is every bit as fucking stupid as Gold vs Bitcoin. They do different things, and while they overlap in some aspects, that doesn’t mean there should only be one path forward.</p>
<p>The way I think about it, Bitcoin is the value, Ethereum is the execution. When I hear people dismiss Bitcoin because “there is as yet no ‘killer app’ that anybody has come up with for Bitcoin” I like to ask them “what is the killer app for the money in your wallet?”. Do you want to be able to play video games on your money? Collaborate on a document with your coworkers before you spend it? Dollars or&nbsp; euros aren’t dismissed as useless because nobody has come up with a compelling use case for them. You just spend it. <em>That’s&nbsp;</em>the use case.</p>
<p>Ethereum on the other hand, well that’s a whole different ball game. Smart contracts, DeFi, even Dao’s (despite early setbacks) will completely transform our lives. Ethereum, and other projects like it (Cardano, EOS, and even Ravencoin, which is actually a Bitcoin fork)&nbsp; are going to provide ways to code parameters and instructions around value and wealth that will be guaranteed to execute and can outrun government overreach.</p>
<p>We’re now coming out of that <a href="https://outofthecave.io/articles/welcome-to-bitcoins-trough-of-disillusionment/">“Trough of Disillusionment”</a> I wrote about back in 2018 and we have actual companies, actual businesses and ways to derive income now in crypto. We can invest in miners, in crypto based publicly traded companies, we can stake our assets or lend them and earn a return on them. Multiple income streams available here so we actually have some ability to compound whatever wealth we’ve managed to port to the crypto-economy separate from any nominal gains garnered in fiat terms.</p>
<p>And of course, with crypto we have the ability to move capital, in figurative terms, simply by thinking about it. If Actual Communism comes to your habitat and the best you can manage is to get out with your skin and some pass phrases you’ve remembered in your head, you can retrieve some of your assets wherever you come up for air (read <a href="https://amzn.to/2IghIzy">“We The Living”</a>. Take it to heart. This is the fate we seek to avoid, and large chunks of the world are barreling straight at it).</p>
<p>On the precious metals side you have your physical metals which, if all goes well, you simply keep vaulted in various places and your currency never collapses and you teach your kids that they should preserve the hoard and only use it in extreme emergencies down the road. And to teach their kids the same. You have junk silver in case there <em>is&nbsp;</em>a currency crisis and you don’t want to have to carve off a piece of a Krugerrand in order to buy some food at the market.</p>
<p>You have some gold tucked away in international vaults like <a href="http://www.bullionvaultaffiliate.com/trustable">Bullionvault</a> and <a href="https://www.goldmoney.com/w/wealthnet">Goldmoney</a>. My cousins run <a href="https://www.trustablegold.com/">TrustableGold.com</a> which rates these places.</p>
<p>All of this stuff, especially on the crypto side, has to be set up in advance, and you have to know how to navigate these systems before TSHTF. When a mob of mostly peaceful democratic socialists are tearing through your town and burning down your homes and businesses, or when the government is hanging both goldbugs and HODL-ers from lamposts, you do not want to be learning how to set up a Monero wallet and frantically converting as much as you can into it, nor do you want to be just then opening your Goldmoney account and trying to wire in some funds.</p>
<p>It has to be ready <em>now</em>, so&nbsp; when the inevitable&nbsp;<em>Financial Repressions </em>intensifies, or God forbid, the <em>Financial Tyranny</em> occurs, you can focus on executing your exit plans and coming out on the other end with enough capital and wealth to rebuild.</p>
<h3>The missing link</h3>
<p>What we really need are bridges between crypto-currencies and gold. Not metaphorical “can’t we all be friends” bridges, I mean gateways, tokenized/staked storage and transfer of precious metals. Conversion into or out of crypto from metals. This is not easy.</p>
<p>There have been attempts in the past, <a href="https://theagora.libsyn.com/gold-vs-crypto">Roger Ver, in Sal the Agorist’s recent “Gold vs Bitcoin” podcast</a> mentioned e-gold. easyDNS was the only domain registrar to accept e-gold back in the day and that’s how we amassed our physical gold which remains on our balance sheet even now. But contrary to Ver’s assertion that the government’s shutdown of E-gold speaks to gold’s inferiority to Bitcoin – that’s not entirely accurate. E-gold turned a blind eye to governance and it really was a wild west of ponzi schemes and criminal activity. Contrast with other DGCs of the day, like Pecunix or Goldmoney, the latter of which still exists. Goldmoney had far more stringent KYC and governance protocols, self-enforced, and here they are – still up and running.</p>
<p>In fact it was Goldmoney who had one of the more recent attempts at Bitcoin to vaulted gold convertability under their incarnation as Bitgold. They’ve since discontinued this precisely because of the governance hurdles.</p>
<p>I won’t trivialize how hard this is, but for people droning on about the need for a ‘killer app’, this one would probably do well.</p>
<h3>It’s all about optionality</h3>
<p>Both metals and crypto tribes look at the financial system and our legacy institutions as entering some form of breakdown and decline. Because the future is inherently unknowable, what makes more sense?</p>
<p>A) Betting on one half of a toolbox that may pay off huge in some scenarios but be worthless in others, or</p>
<p>B) Having a full toolbox that can give you some good outcomes under most imaginable circumstances?</p>
<p><strong>If you’re a goldbug</strong>, would it kill you to have a&nbsp;<em>fraction&nbsp;</em>of your liquidity in Bitcoin, knowing that from past events crypto superspikes tend to 10X or 100X or more with stubborn repetitiveness and increasing magnitude?</p>
<p><strong>If you’re into Bitcoin</strong>, buying the right gold miners now with a fraction of your capital may very well set you up with an increasingly fat, cushy dividend stream in a few years that you can use for living expenses while you continue to HODL.</p>
<p>Now there are many End Gamer luminaries out there who are invested in both even though …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/">https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/</a></em></p>]]>
            </description>
            <link>https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306259</guid>
            <pubDate>Fri, 04 Dec 2020 19:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Myth of Code Coverage]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25306071">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://preslav.me/2020/12/03/the-myth-of-code-coverage/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/12/03/the-myth-of-code-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body"><p>One question I often ask potential software engineering candidates is to pinpoint the percentage of code coverage in an ideal project. Interestingly enough, many of them jump to the sky with numbers beyond 90%. They would start preaching how well-tested code is more reliable and brings more value to all stakeholders. When I ask about the current projects they work on, the reality looks a bit more down to earth.</p><p>Want to know my answer? I'd say it's <strong>around 66.7%</strong>.</p><p>The reasons for that vary, but allow me to be blunt and say that <strong>1/3 of the code every software project is irrelevant, buggy, overly complicated, or simply sucks.</strong> It has a reason to be where it is, but chances are, one year down the road, it will become a liability. Being dogmatic about tests and covering every line will only make it more difficult to get rid of it.</p><p>See, no two lines of code are equal in value and importance. Adding a new feature to an existing application affects its capabilities only marginally. However, it takes a proportionally large amount of time to develop and integrate due to the existing complexity. The bigger the complexity, the longer it takes to introduce new functionality. By the time the feature finds itself in production, it may as well be already irrelevant.</p><blockquote>The only sure-fire way to improve code coverage (and by that keep software relevant) is to identify and remove the unnecessary code.</blockquote><p>How do you identify irrelevant code? Don't search for it. Instead, let it reveal itself to you. One dimension of software that few teams make good use of, is its history. Git is a great analysis tool. Start using it not only to prevent future problems but also, to understand where and how often certain parts of the code change over time.</p><p>Chances are, you will find pieces of code that have undergone fewer changes than the rest in long periods. Those are the pillars of your application - the 2/3s that <strong>must be well-tested</strong>.</p><p>You will also find others where changes occur more or less every week. Ask yourselves whether those are still relevant, both from a technical and business perspective. Adding tests for the sake of coverage would have the opposite effect of increasing the code quality. In a perfectly-design software project, the part that is allowed to change most often is the configuration. A simple analysis of the code change frequency would show whether that is the case. If it isn't, try separating the moving parts from the core logic. If this is not feasible either, most probably those portions of the code don't belong to the codebase anyway. Turning them into interchangeable scripts (even stored in a separate repository) is one way of tackling them in their own right.</p><p>Let's not get too much into technical details. I have already alluded to the work of <a href="https://twitter.com/AdamTornhill">Adam Tornhill</a> on code analysis in a previous post of mine:</p><figure><a href="https://preslav.me/2020/03/01/use-the-git-history/"><div><p>Use the Git History to Identify Pain Points in Any Project</p><p>Have you heard of Adam Tornhill [https://twitter.com/AdamTornhill]’s work? If
not, I highly recommend that you set some time aside and check out Your Code as
a Crime Scene [https://amzn.to/32DM1G9] or Software DEsign X-Rays
[https://amzn.to/2vtbjdR…</p><p><img src="https://preslav.me/favicon.png"><span>Preslav Rachev</span></p></div><p><img src="https://www.gravatar.com/avatar/fd47e6bba1f42ecacf2e7af9e4c5fb52?s=250&amp;d=mm&amp;r=x"></p></a></figure><p>In a future post, I will discuss some of the new ideas I applied to the simple git one-liner I presented there.</p></div>
</div></div>]]>
            </description>
            <link>https://preslav.me/2020/12/03/the-myth-of-code-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306071</guid>
            <pubDate>Fri, 04 Dec 2020 18:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fable 3: F# to JavaScript compiler]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 123 (<a href="https://news.ycombinator.com/item?id=25305650">thread link</a>) | @adamnemecek
<br/>
December 4, 2020 | https://fable.io/blog/Announcing-Nagareyama-4.html | <a href="https://web.archive.org/web/*/https://fable.io/blog/Announcing-Nagareyama-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today is the day, Fable 3 Nagareyama is officially released! Does this mean the latest version is bug-free? Probably not, but at least the install command is shorter. We have also tested the release candidates in many projects and managed to fix all the outstanding issues so if you find a problem when upgrading your Fable 2 project you may even consider yourself lucky (also, please report).</p>
<p>First things first, I have to acknowledge all the people that have contributed to this release: from Don Syme himself to ncave, our mysterious contributor, and all the early-users that have helped polish this release. Very importantly, the teachers too that take care of my children in difficult times so I can focus on programming. The fact that so many people can collaborate together to put a project like Fable forward still feels like magic to me and I can only say a big THANK YOU to you all. I'm also very happy this is coincidental with the release of F# 5, as incredibly smart people are putting a lot of effort to make the development experience with the language really pleasant. Quoting Krzysztof Cieślak, what a great time to be an F# developer!</p>
<p>How can you try Fable 3, you say? This is it:</p>
<pre><code>dotnet tool install fable
dotnet fable src</code></pre><p>(Change "src" with the path to your project.) It's that easy, type <code>dotnet fable --help</code> to see more options. Of course you still need extra tooling to bundle the JS code, spin off a development server, etc. If you're upgrading an app using Webpack, please <a href="https://github.com/MangelMaxime/fulma-demo/pull/43">check this PR for reference</a>.</p>
<p>Let's quickly go through the highlights of Nagareyama:</p>
<ul>
<li>It's Fable v3. Three is bigger than two, that's already a win.</li>
<li>There are no breaking changes, your Fable 2 project should compile as is with Nagareyama (you may need to update some libraries).</li>
<li>It's a dotnet tool, following suit with most F# project. Remember when Fable, Paket and Fake had each their own way to be downloaded and version-managed? Those days are happily gone!</li>
<li>It removes the inter-process communication with JS, greatly simplifying Fable usage and development.</li>
<li>The previous point together with other fixes have improved the compilation speed by a big deal. Expect it to be at least cut in half in most cases!</li>
<li>Fable is not tightly coupled with a specific bundler anymore like Webpack so you can use any tool you like! (Webpack is still a great choice.)</li>
<li>A lot of effort has been also put to prettify the generated code, making it more readable and easier to debug if needed.</li>
<li>Nagareyama can accept plugins by library authors. Zaid is already using this feature to make it much simpler to <a href="https://youtu.be/a6Ct3CM_lj4?t=860">write React components compatible with JS tooling</a>.</li>
</ul>
<p>You can check the <a href="https://fable.io/blog/Announcing-Nagareyama-3.html">previous posts</a> for more details.</p>


<p>So what are you waiting for? Give Nagareyama a try and let the world know if it goes well... and let us know (privately) if it doesn't 😅 Have fun!</p>
</div></div>]]>
            </description>
            <link>https://fable.io/blog/Announcing-Nagareyama-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305650</guid>
            <pubDate>Fri, 04 Dec 2020 18:08:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TerminusDB 4.0 'Data and Content Management in a Box']]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25305296">thread link</a>) | @LukeEF
<br/>
December 4, 2020 | https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          

<p><strong>Version 4.0 of TerminusDB - the Star’s End Release</strong> * - is a big step forward in solidifying and extending the functionality of TerminusDB and TerminusHub.</p>

<p><a href="https://terminusdb.com/">TerminusDB</a> is an <a href="https://github.com/terminusdb/terminusdb">open source</a>, revision control graph database designed for distributed collaboration. TerminusDB allows you to push, pull, time-travel and merge data, much in the way that is possible with code in Git.</p>

<p>With this release TerminusDB takes a significant step towards our vision of a general-purpose tool for data &amp; content management and collaboration.</p>

<p>TerminusDB 4.0 extends the revision control features to allow greater visibility and reproducability by allowing you to look inside individual commits to see what changes were made. Provenance, lineage, and compliance are increasingly essential in the management of data and content.</p>

<p>The <em>major</em> additional features are:</p>

<h3 id="model-building-tool">Model Building Tool</h3>

<p>The database ships with an integrated visual schema building tool. It allows users to build complex data models using point and click tooling. This makes building models significantly quicker, more efficient, and inclusive of a broader range of people by lowering the technical bar for the application of business rules to your data.</p>

<p>It lets you visually design knowledge graphs in the same way they are presented to business users. We have tried to make the tool easy to use, while preserving the ability to model the most complex domains.</p>

<p>Like everything in TerminusDB, the models are versioned so you can make changes in testing and if it breaks your database, you can easily roll back to an earlier working version. This <strong>collaborative knowledge graph design and implementation functionality</strong> does not exist elsewhere.</p>

<p>You can currently share your models/schemas through TerminusHub - the next step is to make modelling and collaboration even easier by providing data-libraries on TerminusHub, including schema.org but also basic standard models for common domains such as CRM, accounting, and inventory. Users can then generate and share models with collaborators or the broader public.</p>

<h3 id="document-editor">Document Editor</h3>

<p>TerminusDB 4.0 has full surfability, clickability and editability of database documents through the console. It is a wiki or catalogue of all your data that you can edit in place. You don’t have to write code or execute a query, just edit the document directly. If you have a collaborative project, this is a useful approach to building and curating data assets.</p>

<p>The documents link to associated documents delivering a linked data application. You can filter documents, you can find the document you want using search, you can create a new document in the interface - it is a <strong>general-purpose tool for managing your data</strong>.</p>

<p>This is the beginning of the TerminusDB content management system, which we will be expanding over the coming months - next step is to provide web accessibility to TerminusHub databases and then a publisher API to provide the ability to publish the results of any query as a static content set.</p>

<h3 id="csv-manager">CSV Manager</h3>

<p>With a single click, you can now build a database from a CSV or a group of CSVs. You can easily use TerminusDB and TerminusHub as a place to version and collaborate when working with CSV data. This will be especially useful with fast changing data as frequently used in machine learning and data science projects.</p>

<p>We have tried to make it as simple as possible for users to interact with the CSV tooling. You can view and edit CSVs directly in the document viewer. You can also add CSVs from this interface. No need to write code.</p>

<p>The database automatically spots if the CSV is already in the database and will just add the delta. There is an append mode that just adds the data that is not there and an update mode that updates the entire CSV.</p>

<p><strong>Manage your CSVs and other data via TerminusDB and Hub.</strong></p>

<h3 id="command-line-interface">Command Line Interface</h3>

<p>We are excited to launch the TerminusDB CLI. You can connect to TerminusDB with a Git-like CLI to run queries or use the revision control features.</p>

<p>You can create databases and branches, you can list databases/branches, you can query in the command line and you can load CSVs. You also get full error reporting in the CLI. Use the CLI to import a CSV, commit changes and push the changes to TerminusHub.</p>

<p>The CLI will continue to develop and add new operations. We will make it easier to execute queries directly from the CLI. We’re also planning to launch CLIs for the JavaScript and Python clients.</p>

<p>TerminusDB is a big step towards our ambition to be a complete decentralized data and content management system that is accessible to all.</p>

<p><strong>END</strong></p>

<p>* Star’s End is a reference to the mysterious location of the Second Foundation in the Asimov series of novels. The home of the First Foundation was Terminus.</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/4.0_2.png" alt=""></p>

        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305296</guid>
            <pubDate>Fri, 04 Dec 2020 17:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Fast Is My FPGA Design? Types Will Tell Me!]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305242">thread link</a>) | @durst
<br/>
December 4, 2020 | https://davidbdurst.com/blog/how_fast.html | <a href="https://web.archive.org/web/*/https://davidbdurst.com/blog/how_fast.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="header">
                <div>
                    <div>
                        <p>
                            <h3>How Fast Is My FPGA Design? Types Will Tell Me!</h3>
                        </p>
                    </div>
                    
                </div>
            </div><div>
                <p>
                    Let's look at a type-directed approach for implementing
                    image processing applications on FPGAs. This approach will
                    enable us to statically verify a design's throughput. If you
                    like this post, check out my PLDI 2020 paper <a href="https://aetherling.org/">Aetherling</a>, which
                    provides a formal definition of the types and uses them
                    to make trade-offs automatically during the FPGA design process.
                </p>
            </div><div id="main_content">
                <div>
                    <!--target audience: someone at google who already knows its hard to make stuff fast, not hardware person, knows that apple and google are doing custom hardware (maybe), interested in design choices apple/google would have to make-->
                    <p>
                        Hardware designs on FPGAs offer a different set of
                        performance trade-offs compared to software running on a
                        CPU. Greater parallelism can be achieved on an FPGA by
                        allocating more resources, like adders and multipliers.
                        This is unlike a CPU with a fixed number of cores and
                        vector lanes per cores. However, FPGA have limited
                        resources, so trade-offs must be made between
                        parallelism (or throughput) and resource utilization. In
                        this blog post, we're going to look at the
                        throughput-resource utilization trade-offs for FPGA
                        implementations of image processing operations like
                        image blurring. There are many ways to blur images on an
                        FPGA. Some designs have higher throughput, and others
                        require fewer resources. I'm going to demonstrate a type
                        system for expressing designs with different
                        throughput-resource tradeoffs that enables you to
                        statically determine a design's throughput.
                        <a href="#types_of_resources">
                            (See below for a refresher on the types of resources
                            available on an FPGA.)
                        </a>
                    </p>

                    <h4 id="what_else">
                        <a href="#what_else">
                            FPGA designs for image blurring with different throughput-resources trade-offs
                        </a>
                    </h4>
                    <p>
                        Before we get to the type system, let's look at a few
                        different ways to blur an image on an FPGA. These
                        designs will have different throughout-resources
                        trade-offs. The below video shows one design that
                        processes one pixel per clock cycle. It does so by
                        streaming over the input pixels, accepting one at a
                        time, storing two prior input pixels in registers, and
                        computing the average of the current input and the prior
                        two.
                    </p>

                    

                    <p>
                        Design a in the image below shows the same one pixel per
                        clock design as the above animation. Designs b and c
                        show two other implementations with different
                        throughput-resource utilization trade-offs. Design b
                        processes two elements per clock, doubling the
                        throughput relative to design a and the animation above.
                        Design b requires double the adders and dividers
                        compared to design a in order to achieve this
                        throughput. Design c saves on adders but can only
                        process one pixel every third clock cycle.
                    </p>

                    <div>
                        <div id="three_blurs">
                            <figure>
                                <p>Design a</p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/1px_per_clock_no_clk.svg">
                                <p>Design b</p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/2px_per_clock_no_clk.svg">
                                <p>Design c</p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/1_3px_per_clock_no_clk.svg">
                                <figcaption>
                                    Three different implementations of a blur.
                                    The gray nodes accept and emit data every
                                    clock. The red nodes accept and emit data
                                    every third clock.  For simplicity, these
                                    designs only do a blur on a 1D image.
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        You could write up all these different designs in
                        Verilog. Assuming you wrote correct code, they would
                        synthesize to a bitstream, run on an FPGA, and provide
                        the expected throughput. But, it would be challenging to
                        statically verify that the designs achieved the correct
                        performance.
                    </p>

                    <h4 id="st_types">
                        <a href="#st_types">
                            Space-time types encode throughput
                        </a>
                    </h4>
                    <p>
                        Now that we've seen some different designs, we're ready
                        for the types that encode their throughputs. Since we're
                        building application-specific hardware, we can encode
                        the throughput of the designs down to the clock cycle
                        without complex performance issues common in software
                        like multi-threading. I'm going to introduce these types
                        using a simpler example than blur: <code>map
                        add10</code>. This code adds 10 to each element in an
                        input sequence. When implementing a map on an FPGA,
                        there are two basic implementations. The first
                        implementation, <code>map_s add10</code> (or
                        <code>map</code> in space), is fully parallel and
                        duplicates <code>add10</code>. If the <code>map_s</code>
                        is applied to a sequence of four elements, then four
                        elements arrive on one clock cycle, <code>map_s</code>
                        adds 10 to every element, and the four elements depart
                        on the same clock cycle. The second implementation,
                        <code>map_t add10</code> (or <code>map</code> in time),
                        is fully sequential and requires only one copy of the
                        <code>add10</code> circuit. The four input elements
                        arrive on four separate clocks and <code>map_t</code>
                        adds 10 to one element at a time.
                    </p>

                    <div>
                        <div id="st_maps">
                            <figure>
                                <p><code>map_s add10</code></p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/map_s_4_add10_no_arrow.svg">
                                <p><code>map_t add10</code></p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/map_t_4_0_add1_no_arrow.svg">
                                <figcaption>
                                    Two different implementations of a map
                                    on an FPGA.
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        The types of <code>map_s</code> and <code>map_t</code>
                        encode their throughputs. <code>map_s add10 :: SSeq 4
                        int -&gt; SSeq 4 int</code> is a function on two space
                        sequences. Each space sequence (<code>SSeq 4 int</code>)
                        encodes both the length of the sequence and that all the
                        elements occur on the same clock cycle. The type
                        signature of <code>map_s add10</code> encodes it's a
                        function which accepts four <code>int</code>s on one
                        clock and emits them on one clock. This is a throughput
                        of four <code>int</code>s per clock. <code>map_t add10 :: TSeq 4 0
                        int -&gt; TSeq 4 0 int</code> is a function on two time
                        sequences. Each time sequence (<code>TSeq 4 0 int</code>)
                        encodes that all the elements elements occur on different clocks, one after another. The type
                        signature of <code>map_t add10</code> encodes it's a
                        function which accepts four <code>int</code>s on separate
                        clocks and emits them on separate clocks. This is a throughput
                        of one <code>int</code> per clock. The fully sequential
                        throughput, like the fully parallel one for <code>map_s
                        add10</code>, is easily expressed using the space-time
                        types.
                    </p>

                    <h4 id="other_throughputs">
                        <a href="#other_throughputs">
                            Space-time types enable expressing more
                            complex throughputs than just fully parallel or
                            sequential
                        </a>
                    </h4>
                    <p>
                        The prior <code>map</code> examples only had fully
                        parallel or sequential throughputs. We need to support
                        other types of throughputs in order to handle all of the
                        image blur designs. We can nest and modify the
                        parameters of the space-time types to express a wider
                        range of throughputs. The two pixel per clock blur
                        design b is partially parallel: it processes more than
                        one pixel per clock but doesn't do the entire image at
                        once. We can encode partially parallel throughputs by
              …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidbdurst.com/blog/how_fast.html">https://davidbdurst.com/blog/how_fast.html</a></em></p>]]>
            </description>
            <link>https://davidbdurst.com/blog/how_fast.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305242</guid>
            <pubDate>Fri, 04 Dec 2020 17:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting a 100% local app to the web]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25304100">thread link</a>) | @jlongster
<br/>
December 4, 2020 | https://actualbudget.com/blog/porting-local-app-web | <a href="https://web.archive.org/web/*/https://actualbudget.com/blog/porting-local-app-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>While researching <a href="https://actualbudget.com/blog/cursed-caching-curious">a curious caching bug</a>, I got inspired to take another look at how Actual stores data locally on the web. There's some history I need to explain. Years ago, Actual was only going to be a desktop app. That means <em>all</em> of your data is stored locally. No server.</p><p>Then I realized how important mobile is, and that most people don't want to worry about losing their data if they drop their computer in the ocean. A syncing engine was born, and desktop and mobile apps have happily synced their data ever since. A copy is kept on a server so users can login and easily view their data, and if they worry about privacy they can enable <a href="https://actualbudget.com/docs/overview/syncing-across-devices/#end-to-end-encryption">end-to-end encryption</a>.</p><p>In the last year I grew jealous of web apps. Look at how easily they can deploy… how quickly they can drop users right into the app. No install required. Here I am asking users to download an 80MB file just to run the app. That download absolutely kills conversion rates, and makes the login flow, support, a/b testing and <em>everything</em> much harder.</p><p>I love desktop apps because you have access to much better tech (like native sqlite3), the app is super fast (no network calls), and the user owns their data. However, I can't ignore that the benefits of the web <a href="https://www.kalzumeus.com/2009/09/05/desktop-aps-versus-web-apps/">dwarfs these advantages</a>.</p><p>I started thinking about a web version of Actual. After some hacking, <a href="https://app.actualbudget.com/">I got it working</a> without changing the architecture. That means all your data is still stored locally in the browser, and there are no network calls. It's a completely 100% "local" app in the browser [0].</p><p>I haven't marketed the web version much because it hasn't been tested enough, and it needs improvements like lazy loading code to make it load faster. The biggest thing I'm worried about is the data storage layer. Since <strong>all your data is local</strong>, if something goes wrong there you could potentially lose data. And we're really stressing the browser's persistant db by storing everything in it.</p><p>To be clear: <strong>we are not deprecating the desktop version</strong>. However in the future the web version will be the primary platform, with the choice to download the desktop version if desired.</p><p>The way it works a bit unusual. Here's a high-level overview:</p><ul><li>Actual uses <a href="https://www.sqlite.org/index.html">sqlite3</a>. This is a hard requirement. The app runs tons of complex SQL queries to aggregate financial data and it's so good at doing it. Queries are easy to express and run super fast.</li><li>On desktop and mobile, native sqlite3 is used. The web does not support sqlite3, however. To get around this, Actual uses a <a href="https://github.com/sql-js/sql.js">wasm version</a> of sqlite3 and creates an in-memory db.</li><li>The obvious problem is persistence. When you make changes, we need to persist them somewhere so when the user reloads they don't lose their data. Luckily we are using <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type#State-based_CRDTs">state-based CRDT's</a> and all updates come through as a list of "messages". If you are online, these messages get synced to our server so when you reload, all your data should sync up.</li><li>It's not ideal to require a big sync every time you open the app though. Also, if you are offline there shouldn't be any chance of losing data. To solve this, Actual persists each message into IndexedDB. When the app opens, it applies all messages from the local IndexedDB to get up-to-date.</li><li>It's <em>still</em> not ideal to require applying any messages on load. It won't scale - if you use the app for months you'll accumulate tens of thousands of messages. IndexedDB would grow indefinitely and loading the app would get slower. To solve this, when the stored messages crosses a threshold it flushes the entire sqlite3 db to IndexedDB and clears all the messages.</li><li>That means both a binary representation of the sqlite3 db and a list of messages is persisted in IndexedDB. On load, the app creates the in-memory sqlite3 db from the snapshot and applies any remaining messages from IDB.</li></ul><p>Turns out this is similar to how a <a href="https://sqlite.org/wal.html">write-ahead log</a> works.</p><p>I was worried about the reliability of IndexedDB. Reading the docs it seems like browsers might delete databases as needed, but in practice this doesn't seem to happen [1]. It's probably a much bigger problem on mobile where memory is scarce, but I don't mess with the mobile web (use a native app instead). I was also worried about hitting the limit of IDB storage, but as explained next that hasn't been a problem.</p><p>This technique started as an experiment, but it has worked surprisingly well. I have 5 years worth of data in Actual, and the size of the sqlite3 db is 9.7MB. The threshold of the messages table is around 50KB, so in total I'm storing ~10MB in IndexedDB for a user who's been around for 5 years. It's not even close to hitting the IndexedDB max storage limit, which these days is at least 500MB.</p><p>While it has worked so far, I want to be 100% confident in this approach. I've been digging deep into how each browser stores IndexedDB data on disk and discovered a couple improvements I can make. I was going to write about them in this post, but I ended up writing more about the overall approach. In the next post I'll dig deep into how IndexedDB works across browsers.</p><p>[0] While I didn't talk about it in this post, this also means that the entire app runs in the browser. The "backend" runs in a background worker thread and everything happens locally.</p><p>[1] If the local data does somehow get corrupted or deleted, it's not a <em>huge</em> deal. All changes are still sent off and stored on a server (which is how all other devices get synced). If something goes wrong, the app can re-download your data from the server. The only case where you'd lose data is if you were offline and lost your local data, which is to be expected.</p></div></div></div>]]>
            </description>
            <link>https://actualbudget.com/blog/porting-local-app-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304100</guid>
            <pubDate>Fri, 04 Dec 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A World Rendered Beautifully: The Making of the BFCM 3D Data Visualization]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303999">thread link</a>) | @dmalik
<br/>
December 4, 2020 | https://shopify.engineering/bfcm-3d-data-visualization | <a href="https://web.archive.org/web/*/https://shopify.engineering/bfcm-3d-data-visualization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>
  <em><strong><a href="https://shopify-bfcm.splashthat.com/" target="_blank" title="How it's made: The Black Friday &amp; Cyber Monday Live Map" rel="nofollow noopener noreferrer">Join us on Monday, December 7</a>, for a behind the scenes look at how and why we visually bring this
      exciting data to life. Shopify’s AR/VR team will take you through the
      technical journey from idea to execution and answer your questions
      live!</strong></em>
</p>
<p>
  <strong>﻿By Mikko Haapoja and Stephan Leroux</strong>
</p>
<p>
  2020 Black Friday Cyber Monday (BFCM) is over, and another BFCM Globe has
  shipped. We’re extremely proud of the globe, it focused on realism,
  performance, and the impact our merchants have on the world.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/LPm0xjr2lzo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>The Black Friday Cyber Monday Live Map</figcaption>
</figure>
<p>
  We knew we had a tall task in front of us this year, building something that
  could represent orders from our one million merchants in just two months. Not
  only that, we wanted to ship a data visualization for our merchants so they
  could have a similar experience to the BFCM globe every day in their Live
  View.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/_r6ut_Z7pss?playlist=_r6ut_Z7pss&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>Prototypes for the 2020 BFCM Globe and Live View. **</figcaption>
</figure>
<p>
  With tight timelines and an ambitious initiative, we immediately jumped into
  prototypes with three.js and planned our architecture.
</p>

<p>
  As we planned this project, we converged architecturally on the idea of
  layers. Each layer is similar to a React component where state is minimally
  shared with the rest of the application, and each layer encapsulates its own
  functionality. This allowed for code reuse and flexibility to build both the
  Live View Globe, BFCM Globe, and beyond.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/D56O11Y46o0?playlist=D56O11Y46o0&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>A showcase of layers for the 2020 BFCM Globe. **</figcaption>
</figure>
<p>
  When realism is key, it’s always best to lean on fantastic artists, and that’s
  where
  <a href="https://twitter.com/byrondelgado" target="_blank" title="Byron Delgado on Twitter" rel="nofollow noopener noreferrer">Byron Delgado</a>
  came in. We hoped that Byron would be able to use the 3D modeling tools he’s
  used to, and then we would incorporate his 3D models into our experience. This
  is where the <code>EarthRealistic</code> layer comes in.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/N4oeDV4rNQo?playlist=N4oeDV4rNQo&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    <code>EarthRealistic</code> layer from the 2020 BFCM Globe. **
  </figcaption>
</figure>
<p>
  <code>EarthRealistic</code> uses a technique called physically based
  rendering, which most modern 3D modeling software supports. In three.js,
  physically based rendering is implemented via the
  <code>MeshPhysicalMaterial</code> or
  <code>MeshStandardMaterial</code> materials.
</p>
<p>
  To achieve realistic lighting, <code>EarthRealistic</code> is lit by a 32bit
  EXR Environment Map. By using a 32bit EXR, it means we can have smooth image
  based lighting. Image based lighting is a technique where a “360 sphere” is
  created around the 3D scene, and pixels in that image are used to calculate
  how bright Triangles on 3D models should be. This allows for complex lighting
  setups without much effort from an artist. Traditionally images on the web
  such as JPGs and PNGs have a color depth of 8bits. If we were to use these
  formats and 8bit color depth, our globe lighting would have had horrible
  gradient banding, missing realism entirely.
</p>

<p>
  Once we converged on physically based rendering and image based lighting,
  building the carbon offset layer became clearer. Literally!
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/GQ2OJCiT-wA?playlist=GQ2OJCiT-wA&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    Carbon Offset visualization layer from the 2020 BFCM Globe. **
  </figcaption>
</figure>
<p>
  Bubbles have an interesting phenomenon where they can be almost opaque at a
  certain angle and light intensity but in other areas completely transparent.
  To achieve this look, we created a custom material based on
  MeshStandardMaterial that reads in an Environment Map and simulates the bubble
  lighting phenomenon. The following is the easiest way to achieve this with
  three.js:
</p>
<ol>
  <li>
    Create a custom Material class that extends off of MeshStandardMaterial.
  </li>
  <li>
    Write a custom Vertex or Fragment Shader and define any Uniforms for that
    Shader Program.
  </li>
  <li>
    Override
    <code>onBeforeCompile(shader: Shader, _renderer: WebGLRenderer): void&nbsp;</code>on your custom Material and pass the custom Vertex or Fragment Shader and
    uniforms via the Shader instance.
  </li>
</ol>
<p>
  Here’s our implementation of the above for the Carbon Offset Shield Material:
</p>
<ul>
  <li>
    <a href="https://gist.github.com/ShopifyEng/5e8bfa0de5630779ad7350c7a73cb650" target="_blank" rel="nofollow noopener noreferrer">ShieldMaterial.ts</a>
    - Our custom Carbon Offset Visualization Material
  </li>
  <li>
    <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf" target="_blank" rel="nofollow noopener noreferrer">CustomMeshStandardMaterial.ts</a>
    - Abstraction on top of MeshStandardMaterial
  </li>
  <li>
    <a href="https://gist.github.com/ShopifyEng/cc1679cfb054f85c8689037e5d168f68" target="_blank" rel="nofollow noopener noreferrer">shield.frag</a>
    - Custom Fragment shaders that make MeshStandardMaterial look like a bubble
  </li>
</ul>
<p>
  Let’s look at the above, starting with our Fragment shader. In shield.frag
  lines 94-97
</p>
<figure>
  
</figure>
<p>
  These two lines are all that are needed to achieve a bubble effect in a
  fragment shader.
</p>
<p>
  To calculate the <code>brightness</code> of an rgb pixel, you calculate the
  length or magnitude of the pixel using the GLSL length function. In three.js
  shaders, <code>outgoingLight</code> is an RGB <code>vec3</code> representing
  the outgoing light or pixel to be rendered.
</p>
<p>
  If you remember from earlier, the bubble’s brightness determines how
  transparent or opaque it should appear.&nbsp; After calculating brightness, we can
  set the outgoing pixel’s alpha based on the brightness calculation. Here we
  use the GLSL <code>mix</code> function to go between the expected alpha of the
  pixel defined by <code>diffuseColor.a</code> and a new custom uniform defined
  as <code>maxOpacity</code>. By having the concept of min or expected opacity
  and max opacity, Byron and other artists can tweak visuals to their exact
  liking.
</p>
<p>
  If you look at our shield.frag file, it may seem daunting! What on earth is
  all of this code?&nbsp; three.js materials handle a lot of functionality, so it’s
  best to make small additions and not modify existing code. three.js materials
  all have their own shaders defined in the
  <a href="https://github.com/mrdoob/three.js/blob/dev/src/renderers/shaders/ShaderLib/" target="_blank" title="ShaderLib folder in three.js repo" rel="nofollow noopener noreferrer">ShaderLib folder</a>. To extend a three.js material, you can grab the original material shader
  code from the <code>src/renderers/shaders/ShaderLib/</code> folder in the
  three.js repo and perform any custom calculations before setting
  <code>gl_FragColor</code>. An easier option to access three.js shader code is
  to simply <code>console.log</code> the <code>shader.fragmentShader</code> or
  <code>shader.vertexShader</code> strings, which are exposed in the
  <code>onBeforeCompile</code> function:
</p>
<figure>
  
</figure>
<p>
  <code>onBeforeCompile</code> runs immediately before the Shader Program is
  created on the GPU. Here you can override shaders and uniforms.
  CustomMeshStandardMaterial.ts is an abstraction we wrote to make creating
  custom materials easier. It overrides the
  <code>onBeforeCompile</code> function and manages uniforms while your
  application runs via the
  <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf#file-custommeshstandardmaterial-ts-L51" target="_blank" title="setCustomUniform in CustomMeshStandardMaterial.ts" rel="nofollow noopener noreferrer"><code>setCustomUniform</code></a>
  and
  <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf#file-custommeshstandardmaterial-ts-L60" target="_blank" title="getCustomUniform in CustomMeshStandardMaterial.ts" rel="nofollow noopener noreferrer"><code>getCustomUniform</code></a>
  functions. You can see this in action in our custom Shield Material when
  getting and setting <code>maxOpacity</code>:
</p>
<figure>
  
</figure>
<h2>Using Particles to Display Orders</h2>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/jGUDfU1c_xE?playlist=jGUDfU1c_xE&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    Displaying orders on Shopify from across the world using particles. **
  </figcaption>
</figure>
<p>
  One of the BFCM globe’s main features is the ability to view orders happening
  in real-time from our merchants and their buyers worldwide. Given Shopify’s
  scale and amount of orders happening during BFCM, it’s challenging to visually
  represent all of the orders happening at any given time. We wanted to find a
  way to showcase the sheer volume of orders our merchants receive over this
  time in both a visually compelling and performant way.&nbsp;
</p>
<p>
  In the past, we used visual “arcs” to display the connection between a buyer’s
  and a merchant’s location.
</p>
<figure>
  <img alt="The BFCM Globe from 2018 showing orders using visual arcs." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/old-globe.jpg?v=1607052787" src="https://cdn.shopify.com/s/files/1/0779/4361/files/old-globe.jpg?v=1607052787">
  <figcaption>
    The BFCM Globe from 2018 showing orders using visual arcs.
  </figcaption>
</figure>
<p>
  With thousands of orders happening every minute, using arcs alone to represent
  every order quickly became a visual mess along with a heavy decrease in
  framerate. One solution was to cap the number of arcs we display, but this
  would only allow us to display a small fraction of the orders we were
  processing. Instead, we investigated using a particle-based solution to help
  fill the gap.
</p>
<p>With particles, we wanted to see if we could:</p>
<ul>
  <li>Handle thousands of orders at any given time on screen.</li>
  <li>Maintain 60 frames per second on low-end devices.</li>
  <li>
    Have the ability to customize style and animations per order, such as
    visualizing local and international orders.
  </li>
</ul>
<p>
  From the start, we figured that rendering geometry per an order wouldn't scale
  well if we wanted to have thousands of orders on screen. Particles appear on
  the globe as highlights, so they don’t necessarily need to have a 3D
  perspective. Rather than using triangles for each particle, we began our
  investigation using three.js <code>Points</code> as a start, which allowed us
  to draw using dots instead. Next, we needed an efficient way to store data for
  each particle we wanted to render. Using <code>BufferGeometry</code>, we
  assigned custom attributes that contained all the information we needed for
  each particle/order.
</p>
<figure>
  
</figure>
<p>
  To render the points and make use of our attributes, we created a
  <code>ShaderMaterial</code>, and custom vertex and fragment shaders. Most of
  the magic for rendering and animating the particles happens inside the vertex
  shader. Each particle defined in the attributes we pass to our
  <code>BufferGeometry</code> goes through a series of steps and
  transformations.
</p>
<p>
  First, each particle has a starting and ending location described using
  latitude and longitude. Since we want the particle to travel along the surface
  and not through it, we use a geo interpolation function on our coordinates to
  find a path that goes along the surface.
</p>
<figure>
  <img alt="A photo of a globe with an order represented as a particle traveling from New York City to London. The vertex shader uses each location’s latitude and longitude and determines the path it needs to travel." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-1.jpg?v=1607053616" src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-1.jpg?v=1607053616">
  <figcaption>
    An order represented as a particle traveling from New York City to London.
    The vertex shader uses each location’s latitude and longitude and determines
    the path it needs to travel. **
  </figcaption>
</figure>
<p>
  Next, to give the particle height along its path, we use high school geometry,
  a parabola equation based on time to alter the straight path to a curve.
</p>
<figure>
  <img alt="A photo of a globe with particles that follow a curved path away from the earth’s surface using a parabola equation to determine its height." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-2.jpg?v=1607053702" src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-2.jpg?v=1607053702">
  <figcaption>
    Particles follow a curved path away from the earth’s surface using a
    parabola equation to determine its height. **
  </figcaption>
</figure>
<p>
  To render the particle to make it look 3D in its travels, we combine our
  height and projected path data then convert it to a vector position our shader
  uses as it’s <code>gl_Position</code>. With our particle now knowing where it
  needs to go, using a <code>time</code> uniform, we drive animations for other
  changes such as size and color. At the end of the vertex shader, we pass the
  position and point size to render onto the fragment shader that combines the
  calculated color and alpha at the time for each particle.
</p>
<p>
  Once …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/bfcm-3d-data-visualization">https://shopify.engineering/bfcm-3d-data-visualization</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/bfcm-3d-data-visualization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303999</guid>
            <pubDate>Fri, 04 Dec 2020 16:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to send privacy friendly emails]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25303911">thread link</a>) | @jivings
<br/>
December 4, 2020 | https://blog.leavemealone.app/how-to-send-privacy-friendly-emails/ | <a href="https://web.archive.org/web/*/https://blog.leavemealone.app/how-to-send-privacy-friendly-emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.leavemealone.app/content/images/size/w300/2020/12/cover.png 300w,
                            https://blog.leavemealone.app/content/images/size/w600/2020/12/cover.png 600w,
                            https://blog.leavemealone.app/content/images/size/w1000/2020/12/cover.png 1000w,
                            https://blog.leavemealone.app/content/images/size/w2000/2020/12/cover.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.leavemealone.app/content/images/size/w2000/2020/12/cover.png" alt="How to send privacy friendly emails">
            </figure>

            <section>
                <div>
                    <p>As a privacy friendly company who work mainly with newsletters, we spend a lot of time thinking about the ethics of email. </p><p>We've recently been working on a sort of "code of ethics" for email senders who are interested in privacy, and after getting a lot of feedback have condensed our main points down to the following. This is still a work in progress (and in some places <em>highly</em> subjective), so if you have any feedback at all then please raise a ticket on the <a href="https://github.com/leavemealone-app/ethical-email-manifesto">GitHub repo</a>, or leave a comment on the <a href="https://news.ycombinator.com/item?id=25303911">Hacker News discussion</a>. </p><p>Let's start off with a simple one. Above all else, recurring emails should be opt-in. If I receive an email from you it <strong><em>should not be a surprise</em></strong>.</p><p>In real terms this means;</p><ul><li>For newsletter creators, if someone signed up for your monthly newsletter, then don't sometimes send them weekly without asking.</li><li>For app makers and SaaS, a welcome email is okay, but don't automatically add a new customer to your automated Drip campaign of 25 on-boarding emails.</li></ul><p>This really is a no-brainer and benefits everyone. If you send emails that people don't expect, you make them angry and more likely to mark you as spam, hurting your reputation.</p><p>I've spoken about this before, letting your recipients easily unsubscribe from emails helps to maintain a healthy mailing list. But lets go one step further...</p><p>Being granted permission to send an email to a persons inbox <strong>should be treated as a privilege</strong>, and we should respect their right to easily deny us that permission at any time and for any reason.</p><p>This means we must provide an unsubscribe link within each email that is accessible to the recipient, this link should ideally unsubscribe in <em>one-click</em> and not require any additional steps.</p><!--kg-card-begin: html--><blockquote>Being granted permission to send an email to a persons inbox should be treated as a privilege</blockquote><!--kg-card-end: html--><p>The best way to do this is to provide an "unsubscribe" link in the email body. This should be clear and purposeful by;</p><!--kg-card-begin: markdown--><ul>
<li>Using clear language
<ul>
<li>"Click here to unsubscribe" is good</li>
<li>"Manage your preferences here" is not.</li>
</ul>
</li>
<li>Being accessible
<ul>
<li>Make your unsubscribe link obvious</li>
<li>Keep the contrast ratio high - eg don't use light grey text on a white background. This is not cool.</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><p>If possible, it's also good to provide a machine-readable <code>List-Unsubscribe</code> header with every email (<a href="https://www.ietf.org/rfc/rfc2369.txt">RFC 2369</a>). This allows automated tools to help your recipients unsubscribe. The URL in the List-Unsubscribe can be the same as the one you use in your unsubscribe link in the email body.</p><!--kg-card-begin: markdown--><pre><code>List-Unsubscribe: 
    &lt;http://www.host.com/list.cgi?cmd=unsub&amp;lst=list&gt;,
    &lt;mailto:<a href="https://blog.leavemealone.app/cdn-cgi/l/email-protection" data-cfemail="036f6a70772e71667276667077436b6c70772d606c6e">[email&nbsp;protected]</a>?subject=unsubscribe&gt;
</code></pre>
<!--kg-card-end: markdown--><p>In case this doesn't go without saying, if a recipient unsubscribes from your mailing list then you should not send them any more emails from that address!</p><p>P.S. Recently I've seen more mailing lists including an unsubscribe link at the top of the email as well as at the bottom. This seems like a great idea.</p><p>There should be no doubt why someone is receiving your email, or how frequently they should expect it. It sucks to receive an email but not know why.</p><p>I understand that recipients may forget that they signed up for your service or to receive your newsletter (especially if it is not sent frequently), so make the intent of the email clear at the start. For example, by leading the content with the sentence "You are receiving this email because you signed up for an account on example.com".</p><p>Newsletter creators, if you sent emails on a schedule then let your recipient know when they will receive your next email.</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/12/image.png"><figcaption>Here's how we manage this in some of our recurring emails</figcaption></figure><!--kg-card-end: image--><p>There's also an email header for this as well, the <code>List-Help</code> header. This provides a place to discover more information about the mailing list.</p><!--kg-card-begin: markdown--><pre><code>List-Help: &lt;http://www.host.com/list/&gt;, &lt;mailto:<a href="https://blog.leavemealone.app/cdn-cgi/l/email-protection" data-cfemail="335f5a40471e5a5d555c735b5c40471d505c5e">[email&nbsp;protected]</a>&gt;
</code></pre>
<!--kg-card-end: markdown--><p>Probably the most controversial point I need to make - emails should not contain spy-pixels/pixel-trackers or any other mechanism that measures open-rates.</p><p>I know it's nice to see how many people are opening your emails, but since this tracking can be done without the consent of the recipient, it should be considered a violation of privacy. Requiring recipients to disable images in their email client in order to not be tracked is <strong>not </strong>acceptable.</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/12/image-1.png"><figcaption>Read tracking can be crazy intrusive (image courtesy of the SuperHuman exposé last year)</figcaption></figure><!--kg-card-end: image--><p>If you wish to see if recipients are engaging with your emails, then provide actionable elements for them. For example, clicking a link in the email is easily measurable, shows engagement, and is less intrusive.</p><p>Ideally, I think it would be nice to return to mainly plaintext emails, with a few embedded images here and there. Embedded images don't have to be fetched from an external server, and thus can't be used for tracking purposes. I <a href="https://twitter.com/JamesIvings/status/1334796362416877569">tweeted some info</a> on how to embed images recently if you want more info on this.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>I think these 4 points cover most shady email practices, a good start!</p><p>None of this is governed by any specific law, but a bunch of it probably falls under either CAN-SPAM or GDPR email regulations. </p><p>That said, governments have been consistently slow to react with regards to protecting online privacy and barely enforce any protections they have managed to pass. So I think the best way forward is encourage email senders to act ethically, and as consumers, point out ethical violations and not do business with those who do not meet our standards wherever possible.</p><p>There's a long way to go in this space, and I want to explore it in the open with as much feedback as possible. My first draft of an <em>Ethical Email Manifesto</em> that we will be following at my company is <a href="https://github.com/leavemealone-app/ethical-email-manifesto">public on GitHub</a> and open to contributions.</p><p>If you want to support this movement and tell the world you're an "ethical email sender", then <a href="https://github.com/leavemealone-app/ethical-email-manifesto/issues">open an issue</a> and we'll add your company as a signatory to the document ❤</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Agree (or disagree) with me about any of this? Jump on the <a href="https://news.ycombinator.com/item?id=25303911">HN thread</a>, or <a href="https://twitter.com/JamesIvings">follow me on Twitter</a>, where I post a lot about shady email practices.</p><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>

            <section>
                <h3>Subscribe to Leave Me Alone Blog</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.leavemealone.app/how-to-send-privacy-friendly-emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303911</guid>
            <pubDate>Fri, 04 Dec 2020 16:11:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gumroad vs. Amazon KDP – Which Is Better for Authors?]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303244">thread link</a>) | @tagawa
<br/>
December 4, 2020 | https://www.writerontheside.com/gumroad-vs-amazon-kdp/ | <a href="https://web.archive.org/web/*/https://www.writerontheside.com/gumroad-vs-amazon-kdp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><main id="genesis-content"><article aria-label="Gumroad vs. Amazon KDP – Which is Better for Authors?"><div>
<figure><img loading="lazy" width="1024" height="576" src="https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-1024x576.png" alt="Gumroad vs Amazon KDP - Which is better for Authors" srcset="https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-1024x576.png 1024w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-300x169.png 300w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-768x432.png 768w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-1536x864.png 1536w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-2048x1152.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For authors, deciding between Gumroad vs. Amazon KDP is not always a straightforward answer. </p>



<p>I’ve been a huge advocate of Amazon KDP (Kindle Direct Publishing) for several years now, and most of my books are published on that platform. </p>



<p>However, I decided to self publish my latest book on Gumroad, and I wanted to share my thoughts about which one I think is best for authors.</p>



<p>I have also gathered some insights from other authors who have used one or both platforms.</p>







<h2>Gumroad vs. Amazon KDP: Quick Summary</h2>



<p>This is a <em>really </em>long post (3,900+ words, which will take you around 17 minutes to read), so here’s the TL;DR version if you don’t have a lot of time:</p>



<p>Both Amazon and Gumroad have some advantages and disadvantages for authors. And what works best depends on your objective and on your current situation.</p>



<p>If you want to <strong>maximize profits</strong>, already have a <strong>fairly large audience</strong>, and <strong>have the time and energy</strong> to direct traffic to your book, then <strong>Gumroad </strong>is the best option for you.</p>



<p>If you care more about <strong>brand value</strong>, have a <strong>smaller audience</strong>, and want to <strong>rely more on organic traffic/ reach</strong> for readers to find your book, then <strong>Amazon KDP</strong> is the best option for you.</p>



<p>You can, of course, publish on both platforms at the same time, but there are some considerations that you have to factor in.</p>



<p>Here are some more details about the advantages and disadvantages of each, and which one wins in each category.</p>







<h2>Gumroad vs. Amazon KDP: Fees &amp; Royalties</h2>



<p>Let’s start with a foundational question. What are the fees you have to pay and royalties (i.e. profit margins) you get on each platform?</p>



<h3>Amazon KDP</h3>



<p>With Amazon, you can publish your book for free (i.e. there are no listing fees), and there are no monthly fees. Your royalties fall between <strong>35%</strong> and <strong>70%</strong>, depending on the book’s price point. </p>



<p>If you list your book’s price between <strong>$2.99</strong> and <strong>$9.99</strong>, then you’ll get a <strong>70%</strong> royalty (i.e., your profit is 70% of the book’s price point).</p>



<p>However, if you list your book’s price between<strong> $0.99 </strong>(lowest price allowed) and <strong>$2.99 </strong>or between<strong> $9.99</strong> and <strong>$200.00</strong> (highest price allowed), then you’ll get a <strong>35%</strong> royalty (i.e., you only get paid 35% of the book’s price point).</p>



<p>In other words, Amazon tries to incentivize you to price your book between <strong>$2.99 and $9.99</strong> because that’s a sweet spot for sales. </p>



<p><em>Note: This applies to the ebook (i.e. Kindle) version of your book’s price point. The paperback version on Amazon has a different royalty structure.</em><br></p>



<h3>Gumroad</h3>



<p>With Gumroad, you have two options to publish your book. You can do it for free (i.e. no monthly fees), or you can upgrade to a premium account that costs you $10 per month (or $108 per year).</p>



<p>Upgrading to a premium account gives you a few advantages that you can read about <a href="https://gumroad.com/features/pricing">here</a>.</p>



<p>In terms of fees, you pay an <strong>8.5% + $0.30</strong> fee per sale on the free account, and <strong>3.5% + $0.30</strong> fee per sale on the premium account.</p>



<p>In other words, your royalty will be between approximately <strong>91% and 96%</strong> of your book’s price point (which is much higher than Amazon’s <strong>35% to 70%</strong>). </p>



<p>So Gumroad definitely wins here.</p>



<p>Another important factor that plays in Gumroad’s favor is “price anchoring.” Given that Amazon persuades authors to price their book between $2.99 and $9.99, most books are listed within that range, which makes it’s very hard to justify selling a $47 Kindle ebook.</p>



<p>Gumroad doesn’t have that problem.</p>



<h4><strong>Winner</strong>: <strong>Gumroad</strong></h4>







<h2>Gumroad vs. Amazon KDP: eBook Formats</h2>



<p>When you submit your ebook to Amazon, you have to meet their specific guidelines because Amazon converts your book into their proprietary ebook file format. You can format your book using Microsoft Word or by using Amazon’s own tool called “<a href="https://www.amazon.com/Kindle-Create/b?ie=UTF8&amp;node=18292298011">Kindle Create</a>.” </p>



<p>You can also submit other formats, such as PDF, but those end up causing some formatting challenges when they’re converted to Kindle-specific files.</p>



<p>The way your readers read your Kindle book is either on a Kindle device (e.g., a Kindle Fire Tablet or a Kindle Paperwhite) or on a free Kindle app installed on any other device (e.g., iPhone, iPad, Android phone, computer, etc.). </p>



<p>When you submit your ebook to Gumroad, you basically upload whatever file format your readers will end up downloading. You can also upload multiple files of the same book.</p>



<p>For example, you might want to offer your book in PDF format only.  Or you might want to offer it in PDF, MOBI, ePUB, and HTML. Gumroad basically acts as a document repository and you can upload the same files that you want your customers to view.</p>



<p><em>Note: If you want your Gumroad customers to be able to read your book on their Kindle devices, then make sure you upload the Kindle-friendly MOBI version of your book.</em></p>



<p>Gumroad wins in this category because of the file format flexibility. </p>



<p>For example, I’m writing a new book about <a href="https://www.thecouchmanager.com/home-office-book-launch">how to design a home office</a> and because it’s picture heavy (and the layout needs tweaking) the best format that will work for me is PDF.</p>



<p>And because I wouldn’t be able to do replicate that layout in Amazon without some serious design challenges, I’ll be selling that book exclusively on Gumroad.</p>



<h4>Winner: Gumroad</h4>







<h2>Gumroad vs. Amazon KDP: Paperback Copies</h2>



<p>Most authors want to (and probably should) sell paperback copies of their book. That’s because some readers still prefer to hold physical copies of books, and it would be a mistake to ignore that potential revenue stream.</p>



<p>Here’s a recent screenshot of revenue from my books. Notice the difference between the ebook and paperback royalties.</p>



<figure><img loading="lazy" width="871" height="290" src="https://www.writerontheside.com/wp-content/uploads/2020/07/image.png" alt="Amazon ebook royalty vs. paperback royalty" srcset="https://www.writerontheside.com/wp-content/uploads/2020/07/image.png 871w, https://www.writerontheside.com/wp-content/uploads/2020/07/image-300x100.png 300w, https://www.writerontheside.com/wp-content/uploads/2020/07/image-768x256.png 768w" sizes="(max-width: 871px) 100vw, 871px"></figure>



<p>With Amazon, creating a paperback version of your book is very simple. You’ll need to convert your manuscript to a print-ready file (easy to do within Amazon KDP) and then upload a print-ready cover (that you’ll need to have designed).</p>



<p>After you publish, Amazon then simply prints your book as soon as someone orders it (called POD, which stands for print-on-demand) and ships it to them. So you don’t have to worry about inventory or paying for print copies upfront.</p>



<p>Gumroad unfortunately does not provide any of those print-on-demand capabilities, which means that you will not be able to sell any paperback copies of your book.</p>



<p>The only potential alternative is to do this manually by pre-printing copies of your book yourself and then physically sell &amp; ship them when someone makes an order (not very practical, and not very cheap). </p>



<h4>Winner: Amazon KDP</h4>







<h2>Gumroad vs. Amazon KDP: Organic Reach</h2>



<p>Organic reach is about how people find your book and how effectively each platform recommends it. </p>



<p>With Amazon, over <strong>95%</strong> of my book sales come from organic sales. In other words, it’s mostly from Amazon’s own algorithm. I don’t get a lot of sales from my own efforts of directing people to buy my books. </p>



<p><em>Note: Amazon does not disclose any data about statistics or traffic sources, so I couldn’t give you exact numbers. However, I do track my own sales channels through affiliate links to my books, and that’s why I can estimate organic sales at around 95%.</em></p>



<p>With Gumroad, it’s almost the exact opposite. For sales of my last book, only around <strong>7%</strong> of the sales came in from Gumroad’s organic reach, and <strong>93%</strong> came from my own direct efforts, so I have to do a lot more marketing to sell those books. </p>



<p>So for me, Amazon wins because of three reasons. </p>



<p>First, I can depend a bit more on sales as passive income and I don’t have to constantly market my books.</p>



<p>Second, the volume of readers and traffic on Amazon is much higher than the volume on Gumroad.</p>



<p>Third, Amazon has a sophisticated search algorithm that recommends books to readers based on recent events or on their search/ purchase history.</p>



<p>And all three factors converged for me during the COVID-19 pandemic.</p>



<p>I wrote a book around 6 years ago (called “<em><a href="https://amzn.to/2EAeP7I">Influencing Virtual Teams</a></em>“) and it was making around $200 a month. Then, during the pandemic, there was a sudden spike in interest about remote work, and the book ended up making 10X that amount in a couple of those months. </p>



<p>Although Amazon wins in this category, I do have to give Gumroad two advantages here. First, they are open about their sales sources, so I can get much better statistics. And second, I made over <a href="https://www.writerontheside.com/final-results-3294usd-in-30-days-from-the-book-part-9/">$3,294 in sales in one month</a> from one book, so the higher price-point of the book could pay off for you.</p>



<h4>Winner: Amazon KDP</h4>







<h2>Gumroad vs. Amazon KDP: Reader Emails</h2>



<p>An essential feature for authors is the ability to collect emails from their customers. There are many reasons why, but in summary, it’s to be able to stay in touch with readers and build a relationship with them so you can sell other books (or products/ services) down the line. </p>



<p>Amazon does not give authors the capability to view any of those email addresses. In fact, authors have absolutely no visibility about who their customers are. There is a workaround, where authors can offer customers a freebie in exchange for their email address, but that takes <a href="https://www.writerontheside.com/how-to-collect-email-addresses-from-readers/">a bit of effort to set up</a>, and you’ll still not capture 100% of your customers.</p>



<p>Gumroad not only gives you your customers’ information (including email addresses), but it also allows you to communicate with them through Gumroad’s email messaging system directly. You can even export those email addresses and import them into your email management system (such as <a href="https://www.writerontheside.com/aweber" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">AWeber</a>) if you’d like to. So it’s a no brainer that Gumroad wins here.</p>











<h2>Gumroad vs Amazon KDP: Listing Your Book for Free</h2>



<p>Some authors like the idea of offering one or more of their books for free to help them with branding and even making <a href="https://www.writerontheside.com/ep-025-getting-200x-more-downloads-by-offering-your-book-for-free/">money indirectly</a>. </p>



<p>With Amazon, you can list your book for free on a limited basis only (for 5 days every 90 day period if you’re enrolled in <a href="https://kdp.amazon.com/en_US/select" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">KDP Select</a>).  You can also list it as a “Permanently Free” book, but that’s not a simple process.</p>



<p>However, if you are able to list your book for free on Amazon, you’ll get the advantage of the high volume of traffic. I listed one of my books …</p></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.writerontheside.com/gumroad-vs-amazon-kdp/">https://www.writerontheside.com/gumroad-vs-amazon-kdp/</a></em></p>]]>
            </description>
            <link>https://www.writerontheside.com/gumroad-vs-amazon-kdp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303244</guid>
            <pubDate>Fri, 04 Dec 2020 15:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Indian is an Indian phone?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25303208">thread link</a>) | @coolsnakeman
<br/>
December 4, 2020 | https://restofworld.org/2020/xiaomi-made-in-india/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/xiaomi-made-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he Indiranagar 100-Feet Road is the commercial heart of India’s technology capital Bangalore, lined with international brand stores, bars, restaurants, and food courts. Owning retail space here, alongside consumer giant Reliance Digital and German footwear brand Puma, is a marker of success for brands breaking into mainstream consciousness. Chinese smartphone maker Xiaomi’s two-story, 6,000-square-foot flagship store is right at the heart of the district. Behind its saffron frontage is a showcase for its as-yet-unlaunched handsets, televisions, laptops, fitness bands, e-scooters, and water purifiers.&nbsp;</p>



<p>In June, the store had a complete facelift. A new logo was put on the front of the building that read: “Made In India.” By August, the interior had been decorated with tricolored balloons in the green, white, and orange of the Indian flag. Along the walls, a company timeline showed the history of Xiaomi’s manufacturing operations in India. Mentions of the company’s heritage — it was founded in Beijing in 2010 — disappeared. <a href="https://www.indiatoday.in/india/story/xiaomi-puts-up-made-in-india-banner-outside-stores-to-counter-boycott-china-campaign-1692633-2020-06-25">Hundreds</a> of the company’s stores across the country underwent the same transformation. “Super proud to share that majority of our TVs are #MadeInIndia! We employ thousands of team members across our India factories #ProudIndian,” <a href="https://twitter.com/manukumarjain/status/1276052185638252544?s=20">tweeted</a> Manu Kumar Jain, the India head of Xiaomi.&nbsp;</p>



<p>Anti-China sentiment had already been rising in India’s heartlands before a skirmish in June in a disputed Himalayan border region left 20 Indian soldiers dead. Nationalists started <a href="https://www.thequint.com/news/india/bharat-mata-and-chinese-tvs-a-tale-of-boycotting-goods-from-china">smashing</a> Chinese-made televisions; one minister called for shutting down <a href="https://economictimes.indiatimes.com/news/politics-and-nation/restaurants-and-hotels-that-sell-chinese-food-should-be-shut-down-union-minister-ramdas-athawale/videoshow/76442910.cms">Chinese restaurants</a>. A few weeks after the skirmish, the Indian government banned TikTok, along with hundreds of Chinese apps, and, in August, passed an <a href="https://www.ft.com/content/55642551-f6e8-4f9d-b5ba-a12d2fc26ef9">unofficial</a> order to phase out dependence on Chinese telecom equipment, including 5G networks. Prime Minister Narendra Modi made a special appearance on television encouraging Indians to be <a href="https://www.youtube.com/watch?v=0xmx92Q_kQ4">“vocal” in their support for “local” products</a>, creating the #vocalforlocal slogan.&nbsp;</p>



<p>Chinese smartphone makers like Oppo, Vivo, and Xiaomi — who made up 81% of the Indian market — were left in a precarious position after the clash. Right-wing groups gathered outside Oppo’s factory in the outskirts of Delhi and <a href="https://www.newindianexpress.com/nation/2020/jun/20/anti-china-demonstration-held-outside-oppo-factory-in-greater-noida-32-protesters-booked-2159224.html">burnt effigies of Xi Jinping</a>, as they demanded that the plant be closed. Some companies battened down the hatches, <a href="https://economictimes.indiatimes.com/industry/cons-products/electronics/chinese-brands-endorsers-may-go-slow-on-promotions-some-pull-out-ads-some-plan-to-play-up-make-in-india-credentials/articleshow/76429828.cms?from=mdr">suspending their prime-time advertising campaigns</a>. Vivo <a href="https://sports.ndtv.com/cricket/ipl-title-sponsor-vivo-pulls-out-of-tournament-this-year-amid-row-2274036">pulled out</a> as the title sponsor of the country’s biggest sporting event, the Indian Premier League cricket competition, after an aggressive campaign against it on social media. Stray protests took place outside some Xiaomi stores, as threats of vandalism loomed large and mobile shipments from China were <a href="https://telecom.economictimes.indiatimes.com/news/smartphone-makers-in-panic-mode-over-stranded-shipments/76536342">stalled for manual inspection at Indian ports</a>.</p>



<p>But while other Chinese brands retreated from the limelight, Xiaomi pursued a unique — and potentially high-risk — strategy: It presented itself as not being Chinese after all, but Indian. Jain, its figurehead in India, took to television, newspapers, and social media to talk up the company’s all-Indian local leadership team and the thousands of jobs it had created in manufacturing and retail. “We are more Indian than anyone else,” Jain told <a href="https://twitter.com/manukumarjain/status/1274316181235568645?lang=en">CNBC-TV18</a>. The company even donated money to the families of soldiers “<a href="https://www.mi.com/in/service/support/crpffund.html">martyred</a>” in Kashmir.</p>



<p>Jain has proven adept in using social media and his own personal brand to launder Xiaomi’s origins. But the company faces growing pressure in an unstable political environment. Narendra Modi’s government is once again proclaiming its desire to bring manufacturing back to India, offering <a href="https://www.bloomberg.com/news/articles/2020-09-10/india-mulls-23-billion-package-to-lure-global-manufacturers?sref=QYWxDQ1o">lavish incentives</a> for export-led manufacturers, which may help once-moribund local phone brands. Xiaomi has indeed moved some of its production onshore, but the core components of its devices are still made in China. With the country’s nationalist surge unlikely to end soon, Jain and Xiaomi will eventually have to face up to the question: How Indian is Indian enough?</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-842778188-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-842778188-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-842778188-400x285.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-600x428.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-1000x713.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-1600x1140.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-2800x1995.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Manu Jain speaks during the launch of the Xiaomi Mi A1 smartphone in New Delhi in 2017.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Sajjad Hussain/AFP/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p><strong>Jain, 39, “is</strong> the Indian middle-class dream personified,” in the words of a former colleague. As a child, he lived in Meerut in northern India, alongside 150 members of his extended family, in an isolated housing compound inside a military quarters built by his great grandfather. “I had never even been exposed to the outside world,” Jain says.</p>



<p>After studying at the prestigious Indian Institute of Technology and at the Indian Institute of Management business school, he joined the global consulting firm McKinsey.</p>



<p>Jain’s early career in technology was successful but low profile. He quit McKinsey in 2012 to launch e-commerce portal Jabong.com, which was sold to SoftBank-backed (now Walmart-owned) rival Flipkart for $70 million in 2016. By then, Jain had already moved on to <a href="https://www.thehindubusinessline.com/companies/Jabong%E2%80%99s-former-MD-switches-attention-to-wearable-smart-devices/article20718785.ece#">start a short-lived wearables company</a>. In 2014, he became Xiaomi India’s first hire, recruited by Hugo Barra, the former Android executive who had been tasked with expanding Xiaomi outside China.</p>



<p>At the time, the market was dominated by Samsung and by Indian brands, such as Micromax, Karbonn, and Lava, whose model was to import unbranded Chinese products and sell them as their own. “There was no R&amp;D team, no product team, and no product design. They would basically just buy those products and sell them here,” says Jain.</p>



<p>Xiaomi’s entry was not just about cutting out the middleman. In China, Xiaomi, along with Oppo and Vivo, had evolved beyond their origins in cheap but unreliable products and were now designing and producing higher-quality but affordable devices that were well adapted to a market like India, where disposable income was increasing in step with demand for mobile data.</p>



<p>Jain began his tenure at Xiaomi with a big gamble. In 2014, only 6% of Indian retail sales happened through e-commerce, but Jain launched Xiaomi as an online-only brand, replicating an approach that had worked in China.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-40x39.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-400x394.png 400w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-600x592.png 600w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-1000x986.png 1000w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Xiaomi dominates the Indian market.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Data: Counterpoint Research</span>
			</figcaption>
		</figure>


<p>“Most people said, You are going to fail. You are going to be a disaster,” he said during a 2017 TED Talk. “Most smartphone brands until then focused on building large distribution networks, and we didn’t do that.”&nbsp;</p>



<p>To drum up interest, the company organized flash sales and made sure the phones sold out quickly, to enhance their perceived popularity, a technique known as “hunger marketing.” They spent relatively little on advertising, instead relying on their users to become evangelists for the brand.</p>



<p>Xiaomi’s phones seemed to hit a sweet spot of pricing and specifications. “Their phones were undercutting basically every other device on the market by half,” says Harish Jonalaggada, Asia editor at mobile review portal Android Central. The company launched phones for $180, with high specs like 64GB storage and 4GB RAM that were previously seen on only devices over $400.</p>



<p>The rush of orders for the launch of the Mi 3 model crashed the Indian e-commerce website Flipkart in the summer of 2014.&nbsp;</p>



<p>But Xiaomi’s success wasn’t just about its hardware. Under Jain’s leadership, the company tailored its Android-based operating system, MIUI, to the local market. One feature, Smart SMS, identifies the cluttered text messages that Indian Railways sends to its customers and extracts booking information, turning it into a ticket-like document. Xiaomi was the first company in India to incorporate a popular “dual app” feature that allows users to run duplicate versions of the same app — such as WhatsApp — on the same phone.</p>



<p>As online channels exploded in popularity and started to become saturated, Xiaomi shifted direction. In 2017, the company dramatically expanded its physical retail presence, pushing deep into rural areas. In October 2018, it set a mark recognized by the Guinness World Records by opening <a href="https://gadgets.ndtv.com/mobiles/news/xiaomi-opens-over-500-retail-stores-in-a-single-day-in-rural-india-1950375">500 stores</a> in a day. “One of the reasons Xiaomi has done well is — from both a product perspective and channel perspective — they made decisions unique to the India market,” says a Shanghai-based financial analyst covering Xiaomi who requested to remain anonymous, citing geopolitical tensions. In September, Xiaomi piloted its unique <a href="https://gadgets.ndtv.com/mobiles/news/xiaomi-mi-store-on-wheels-mobile-stores-moving-trucks-launch-india-villages-watch-xiaomi-2298745">Mi Store on Wheels</a>, a van that sells everything from trimmers to phones throughout the hinterlands of India.&nbsp;</p>



<p>This sensitivity to the local market is in no small part due to the unusual autonomy that Jain has had in running Xiaomi in India. The Indian operations of Oppo and Vivo are both run by Chinese nationals. “Chinese companies are often very inward-looking and wouldn’t devolve the power in the same way Xiaomi has,” the analyst says.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-954020916-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-954020916-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-954020916-400x600.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-600x900.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-1000x1499.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-1600x2399.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-2800x4198.jpg 2800w, " sizes="(max-width: 640px) 100vw, 300px" alt="Lei Jun, Xiaomi’s founder and CEO.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"> Giulia Marchi/Bloomberg/Getty Images</span>
			</figcaption>
		</figure>


<p>That unusual autonomy stems from the relationship that Jain has built with Lei Jun, Xiaomi’s founder and CEO, a self-confessed acolyte of Apple founder Steve Jobs. Jain says that, when he and Jun first met, “both of us were wearing black T-shirts and denim jeans. It was cool.”</p>



<p>One former employee, who worked closely with Jain while setting up the India operations, told <em>Rest of World</em>: “Over a period of time when Xiaomi India was growing, Manu was able to earn Jun’s trust, which is actually very hard. … Manu’s bets on the Indian market proved him right. And so, after a while, the CEO decided to just let Manu make his own decisions, which is very rare.”&nbsp;</p>



<p>By 2019, Xiaomi was the largest smartphone brand in India, shifting 100 million units, according to data from the International Data Corporation. The company has expanded beyond mobile and offers everything from luggage to beard trimmers. Its rise came at the cost of Indian brands, whose market share fell from close to 50% to just 13% by the end of 2018, according to market intelligence firm Counterpoint Research.&nbsp;</p>



<p>Jun and Jain share a love of the limelight. Jun is a <a href="https://www.nytimes.com/2013/06/05/business/global/in-china-an-empire-built-by-aping-apple.html">social media celebrity</a> in China, posting mobile teasers and specifications to his 5 million …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/xiaomi-made-in-india/">https://restofworld.org/2020/xiaomi-made-in-india/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/xiaomi-made-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303208</guid>
            <pubDate>Fri, 04 Dec 2020 15:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to Power Flow]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303072">thread link</a>) | @eperim
<br/>
December 4, 2020 | https://invenia.github.io/blog/2020/12/04/pf-intro/ | <a href="https://web.archive.org/web/*/https://invenia.github.io/blog/2020/12/04/pf-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>04 Dec 2020</span></p>
  <p>Although governed by simple physical laws, power grids are among the most complex human-made systems.
The main source of the complexity is the large number of components of the power systems that interact with each other: one needs to maintain a balance between power injections and withdrawals while satisfying certain physical, economic, and environmental conditions.
For instance, a central task of daily planning and operations of electricity grid operators<sup id="fnref:Tong04" role="doc-noteref"><a href="#fn:Tong04">1</a></sup> is to dispatch generation in order to meet demand at minimum cost, while respecting reliability and security constraints.
These tasks require solving a challenging constrained optimization problem, often referred to as some form of optimal power flow (OPF).<sup id="fnref:Cain12" role="doc-noteref"><a href="#fn:Cain12">2</a></sup></p>

<div><p>In a series of two blog posts, we are going to discuss the basics of power flow and optimal power flow problems.
In this first post, we focus on the most important component of OPF: the power flow (PF) equations.
For this, first we introduce some basic definitions of power grids and AC circuits, then we define the power flow problem.
</p></div>

<p><img src="https://invenia.github.io/blog/public/images/us_power_grid.jpg" alt="us_power_grid">
Figure 1. Complexity of electricity grids: the electric power transmission grid of the United States (source: FEMA and <a href="https://en.wikipedia.org/wiki/North_American_power_transmission_grid">Wikipedia</a>).</p>


<h2 id="power-grids-as-graphs">Power grids as graphs</h2>

<p>Power grids are networks that include two main components: buses that represent important locations of the grid (e.g. generation points, load points, substations) and transmission (or distribution) lines that connect these buses.
It is pretty straightforward, therefore, to look at power grid networks as graphs: buses and transmission lines can be represented by nodes and edges of a corresponding graph.
There are two equivalent graph models that can be used to derive the basic power flow equations<sup id="fnref:Low14" role="doc-noteref"><a href="#fn:Low14">3</a></sup>:</p>
<ul>
  <li>directed graph representation (left panel of Figure 2): \(\mathbb{G}_{D}(\mathcal{N}, \mathcal{E})\);</li>
  <li>undirected graph representation (right panel of Figure 2): \(\mathbb{G}_{U}(\mathcal{N}, \mathcal{E} \cup \mathcal{E}^{R})\),</li>
</ul>

<div><p>where \(\mathcal{N}\), \(\mathcal{E} \subseteq \mathcal{N} \times \mathcal{N}\) and \(\mathcal{E}^{R} \subseteq \mathcal{N} \times \mathcal{N}\) denote the set of nodes (buses), and the forward and reverse orientations of directed edges (branches) of the graph, respectively.
</p></div>

<p><img src="https://invenia.github.io/blog/public/images/power_grid_graphs.png" alt="power_grid_graphs">
Figure 2. Directed graph representation of synthetic grid 14-ieee (left) and undirected graph representation of synthetic grid 30-ieee (right). Red and blue circles denote generator and load buses, respectively.</p>


<h2 id="complex-power-in-ac-circuits">Complex power in AC circuits</h2>

<p>Power can be transmitted more efficiently at high voltages as high <a href="https://en.wikipedia.org/wiki/Voltage">voltage</a> (or equivalently, low <a href="https://en.wikipedia.org/wiki/Electric_current">current</a>) reduces the loss of power due to its dissipation on transmission lines.
Power grids generally use <a href="https://en.wikipedia.org/wiki/Alternating_current">alternating current</a> (AC) since the AC voltage can be altered (from high to low) easily via transformers.
Therefore, we start with some notation and definitions for AC circuits.</p>

<p>The most important characteristics of AC circuits is that, unlike in <a href="https://en.wikipedia.org/wiki/Direct_current">direct current</a> (DC) circuits, the currents and voltages are not constant in time: both their <em>magnitude</em> and <em>direction</em> vary periodically.
Because of several technical reasons (like low losses and disturbances), power generators use sinusoidal alternating quantities that can be straightforwardly modeled by <a href="https://en.wikipedia.org/wiki/Complex_number%7D%7Bcomplex%20numbers">complex numbers</a>.</p>

<p>We will consistently use capital and small letters to denote complex and real-valued quantities, respectively.
For instance, let us consider two buses, \(i, j \in \mathcal{N}\), that are directly connected by a transmission line \((i, j) \in \mathcal{E}\).
The <a href="https://en.wikipedia.org/wiki/AC_power">complex power</a> flowing from bus \(i\) to bus \(j\) is denoted by \(S_{ij}\) and it can be decomposed into its active (\(p_{ij}\)) and reactive (\(q_{ij}\)) components:</p><p>

\[\begin{equation}
S_{ij} = p_{ij} + \mathrm{j}q_{ij},
\end{equation}\]

</p><p>where \(\mathrm{j} = \sqrt{-1}\).
The complex power flow can be expressed as the product of the complex voltage at bus \(i\), \(V_{i}\) and the complex conjugate of the current flowing between the buses, \(I_{ij}^{*}\):</p><p>

\[\begin{equation}
S_{ij} = V_{i}I_{ij}^{*},
\label{power_flow}
\end{equation}\]

</p><p>It is well known that transmission lines have power losses due to their <a href="https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance">resistance</a> (\(r_{ij}\)), which is a measure of the opposition to the flow of the current.
For AC-circuits, a dynamic effect caused by the line <a href="https://en.wikipedia.org/wiki/Electrical_reactance">reactance</a> (\(x_{ij}\)) also plays a role.
Unlike resistance, reactance does not cause any loss of power but has a delayed effect by storing and later returning power to the circuit.
The effect of resistance and reactance together can be represented by a single complex quantity, the <a href="https://en.wikipedia.org/wiki/Electrical_impedance">impedance</a>: \(Z_{ij} = r_{ij} + \mathrm{j}x_{ij}\). 
Another useful complex quantity is the <a href="https://en.wikipedia.org/wiki/Admittance">admittance</a>, which is the reciprocal of the impedance: \(Y_{ij} = \frac{1}{Z_{ij}}\).
Similarly to the impedance, the admittance can be also decomposed into its real, <a href="https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance">conductance</a> (\(g_{ij}\)), and imaginary, <a href="https://en.wikipedia.org/wiki/Susceptance">susceptance</a> (\(b_{ij}\)), components: \(Y_{ij} = g_{ij} + \mathrm{j}b_{ij}\).</p>

<p>Therefore, the current can be written as a function of the line voltage drop and the admittance between the two buses, which is an alternative form of <a href="https://en.wikipedia.org/wiki/Ohm%27s_law">Ohm’s law</a>:</p><p>

\[\begin{equation}
I_{ij} = Y_{ij}(V_{i} - V_{j}).
\end{equation}\]

</p><p>Replacing the above expression for the current in the power flow equation (eq. \(\ref{power_flow}\)), we get</p><p>

\[\begin{equation}
S_{ij} = Y_{ij}^{*}V_{i}V_{i}^{*} - Y_{ij}^{*}V_{i}V_{j}^{*} = Y_{ij}^{*} \left( |V_{i}|^{2} - V_{i}V_{j}^{*} \right).
\end{equation}\]

</p><p>The above power flow equation can be expressed by using the polar form of voltage, i.e. \(V_{i} = v_{i}e^{\mathrm{j} \delta_{i}} = v_{i}(\cos\delta_{i} + \mathrm{j}\sin\delta_{i})\) (where \(v_{i}\) and \(\delta_{i}\) are the voltage magnitude and angle of bus \(i\), respectively), and the admittance components:</p><p>

\[\begin{equation}
S_{ij} = \left(g_{ij} - \mathrm{j}b_{ij}\right) \left(v_{i}^{2} - v_{i}v_{j}\left(\cos\delta_{ij} + \mathrm{j}\sin\delta_{ij}\right)\right),
\end{equation}\]

</p><p>where for brevity we introduced the voltage angle difference \(\delta_{ij} = \delta_{i} - \delta_{j}\).
Similarly, using a simple algebraic identity of \(g_{ij} - \mathrm{j}b_{ij} = \frac{g_{ij}^{2} + b_{ij}^{2}}{g_{ij} + \mathrm{j}b_{ij}} = \frac{|Y_{ij}|^{2}}{Y_{ij}} = \frac{Z_{ij}}{|Z_{ij}|^{2}} = \frac{r_{ij} + \mathrm{j}x_{ij}}{r_{ij}^{2} + x_{ij}^{2}}\), the impedance components-based expression has the following form:</p><p>

\[\begin{equation}
    S_{ij} = \frac{r_{ij} + \mathrm{j}x_{ij}}{r_{ij}^{2} + x_{ij}^{2}} \left( v_{i}^{2} - v_{i}v_{j}\left(\cos\delta_{ij} + \mathrm{j}\sin\delta_{ij}\right)\right).
\end{equation}\]

</p><p>Finally, the corresponding real equations can be written as</p><p>

\[\begin{equation}
\left\{
    \begin{aligned}
        p_{ij} &amp; = g_{ij} \left( v_{i}^{2} - v_{i} v_{j} \cos\delta_{ij} \right) - b_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right) \\
        q_{ij} &amp; = b_{ij} \left( -v_{i}^{2} + v_{i} v_{j} \cos\delta_{ij} \right) - g_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right), \\
    \end{aligned}
\right.
\label{power_flow_y}
\end{equation}\]

</p><p>and</p><p>

\[\begin{equation}
\left\{
    \begin{aligned}
        p_{ij} &amp; = \frac{1}{r_{ij}^{2} + x_{ij}^{2}} \left[ r_{ij} \left( v_{i}^{2} - v_{i} v_{j} \cos\delta_{ij} \right) + x_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right) \right] \\
        q_{ij} &amp; = \frac{1}{r_{ij}^{2} + x_{ij}^{2}} \left[ x_{ij} \left( v_{i}^{2} - v_{i} v_{j} \cos\delta_{ij} \right) + r_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right) \right]. \\
    \end{aligned}
\right.
\label{power_flow_z}
\end{equation}\]

</p><h2 id="power-flow-models">Power flow models</h2>

<p>In the previous section we presented the power flow between two connected buses and established a relationship between complex power flow and complex voltages.
In power flow problems, the entire power grid is considered and the task is to calculate certain quantities based on some other specified ones.
There are two equivalent power flow models depending on the graph model used: the bus injection model (based on the undirected graph representation) and the branch flow model (based on the directed graph representation).
First, we introduce the basic formulations.
Then, we show the most widely used technique to solve power flow problems.
Finally, we extend the basic equations and derive more sophisticated models including additional components for real power grids.</p>

<h3 id="bus-injection-model">Bus injection model</h3>

<p>The bus injection model (BIM) uses the undirected graph model of the power grid, \(\mathbb{G}_{U}\).
For each bus \(i\), we denote by \(\mathcal{N}_{i} \subset \mathcal{N}\) the set of buses directly connected to bus \(i\).
Also, for each bus we introduce the following quantities<sup id="fnref:Low14:1" role="doc-noteref"><a href="#fn:Low14">3</a></sup><sup id="fnref:Wood14" role="doc-noteref"><a href="#fn:Wood14">4</a></sup> (Figure 3):</p>
<ul>
  <li>\(S_{i}^{\mathrm{gen}}\): generated power flowing into bus \(i\).</li>
  <li>\(S_{i}^{\mathrm{load}}\): demand power or load flowing out of the bus \(i\).</li>
  <li>\(S_{i}\): net power injection at bus \(i\), i.e. \(S_{i} = S_{i}^{\mathrm{gen}} - S_{i}^{\mathrm{load}}\).</li>
  <li>\(S_{i}^{\mathrm{trans}}\): transmitted power flowing between bus \(i\) and its adjacent buses.
</li>
</ul>

<p><img src="https://invenia.github.io/blog/public/images/power_quantities.png" alt="...">
Figure 3. Power balance and quantities of a bus connected to three adjacent buses and including a single generator and a single load.</p>

<p><br>
<a href="https://en.wikipedia.org/wiki/Tellegen/%27s_theorem">Tellegen’s theorem</a> establishes a simple relationship between these power quantities:</p><p>

\[\begin{equation}
S_{i} = S_{i}^{\mathrm{gen}} - S_{i}^{\mathrm{load}} = S_{i}^{\mathrm{trans}} \ \ \ \ \forall i \in \mathcal{N}.
\label{power_balance}
\end{equation}\]

</p><p>Eq. \(\ref{power_balance}\) expresses the law of conservation of power (energy): the power injected (\(S_{i}^{\mathrm{gen}}\)) to bus \(i\) must be equal to the power going out from the bus, i.e. the sum of the withdrawn (\(S_{i}^{\mathrm{load}}\)) and transmitted power (\(S_{i}^{\mathrm{trans}}\)).
In the most basic model, a bus can represent either a generator (i.e. \(S_{i} = S_{i}^{\mathrm{gen}}\)) or a load (i.e. \(S_{i} = -S_{i}^{\mathrm{load}}\)).
For a given bus, the transmitted power can be obtained simply as a sum of the powers flowing in to and out from the bus, \(S_{i}^{\mathrm{trans}} = \sum \limits_{j \in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invenia.github.io/blog/2020/12/04/pf-intro/">https://invenia.github.io/blog/2020/12/04/pf-intro/</a></em></p>]]>
            </description>
            <link>https://invenia.github.io/blog/2020/12/04/pf-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303072</guid>
            <pubDate>Fri, 04 Dec 2020 15:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mannequin.js: An Articulated Mannequin Figure Library]]>
            </title>
            <description>
<![CDATA[
Score 149 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25302602">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://boytchev.github.io/mannequin.js/ | <a href="https://web.archive.org/web/*/https://boytchev.github.io/mannequin.js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<ul>
  <li><a href="#About">About</a></li>
  <li><a href="#Initialization">Initialization</a>
    <ul>
      <li><a href="#Minimal-program">Minimal program</a></li>
      <li><a href="#Figure-types">Figure types</a></li>
    </ul>
  </li>
  <li><a href="#Body-parts">Body parts</a>
    <ul>
      <li><a href="#Central-body-parts">Central body parts</a></li>
      <li><a href="#Upper-limbs">Upper limbs</a></li>
      <li><a href="#Lower-limbs">Lower limbs</a></li>
    </ul>
  </li>
  <li><a href="#Body-posture">Body posture</a>
    <ul>
      <li><a href="#Static-posture">Static posture</a></li>
      <li><a href="#Dynamic-posture">Dynamic posture</a></li>
    </ul>
  </li>
  <li><a href="#Other-functions">Other functions</a>
    <ul>
      <li><a href="#Custom-colors">Custom colors</a></li>
      <li><a href="#Hiding-body-parts">Hiding body parts</a></li>
      <li><a href="#Custom-body-parts">Custom body parts</a></li>
      <li><a href="#Global-position">Global position</a></li>
    </ul>
  </li>
  <li><a href="#Future-plans">Future plans</a></li>
</ul>


<p><strong>Mannequin.js</strong> is a simple library of an articulated mannequin figure. The shape of the figure
and its movements are done purely in JavaScript. The graphics is implemented in
<a href="https://threejs.org/">Three.js</a>. Click on an image to open a live demo.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-custom-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-custom-body-parts.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-point.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-point.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-scene.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-scene.jpg" width="150"></a></p>

<p>This is the fourth incarnation of the mannequin figure. The first one was implemented
in Elica. The second one was implemented in C/C++ and OpenGL. The third one
was implemented in JS/Three.js and is a direct predecessor of the current mannequin.js.
Since its first incarnation, mannequin.js is used in the course <em>Fundamentals of Computer Graphics</em> for Computer Sciences undergraduate students from the
<a href="https://www.fmi.uni-sofia.bg/en">Faculty of Mathematics and Informatics</a>
at <a href="https://www.uni-sofia.bg/index.php/eng">Sofia University</a>.</p>

<p>Mannequin.js is licensed under <strong>GPL-3.0</strong>.</p>

<p>Three.js is included in this repository to safeguard against incompatibilities with future versions. Three.js is not a part of mannequin.js.</p>



<p>The <strong>mannequin.js</strong> library is provided as a JavaScript file that has to
be include along with three.js.</p>

<h3 id="minimal-program">Minimal program</h3>

<p>Here is a minimal program that creates a male figure in the browser (<a href="https://boytchev.github.io/mannequin.js/examples/example-minimal.html">live example</a>):</p>

<div><div><pre><code><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;html&gt;</span>
  <span>&lt;head&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"three.min.js"</span><span>&gt;&lt;/script&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"mannequin.min.js"</span><span>&gt;&lt;/script&gt;</span>
  <span>&lt;/head&gt;</span>
  <span>&lt;body&gt;</span>
    <span>&lt;script&gt;</span>
      createScene();
      var man = new Male();
    <span>&lt;/script&gt;</span>
  <span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<p>The helper function <code>createScene()</code> provides a default set-up of the scene and its elements, like lighting, camera, ground, etc. Another helper function, <code>animate(t)</code> is responsible for defining figures’ postures at moment <em>t</em>. If the set-up is done with a custom function, then it should also manage the animation loop by itself.</p>

<h3 id="figure-types">Figure types</h3>

<p>Mannequin figures are created as instances of classes <code>Male()</code>, <code>Female()</code> or <code>Child()</code> (<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg"></a></p>

<div><div><pre><code><span>var</span> <span>man</span> <span>=</span> <span>new</span> <span>Male</span><span>();</span>
    <span>man</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>20</span><span>,</span><span>3.5</span><span>,</span><span>0</span><span>);</span>
    <span>man</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>120</span><span>);</span>
    <span>:</span>
<span>var</span> <span>woman</span> <span>=</span> <span>new</span> <span>Female</span><span>();</span>
    <span>woman</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>-</span><span>20</span><span>,</span><span>2</span><span>,</span><span>0</span><span>);</span>
    <span>woman</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>60</span><span>);</span>
    <span>:</span>
<span>var</span> <span>kid</span> <span>=</span> <span>new</span> <span>Child</span><span>();</span>
    <span>kid</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>8</span><span>;</span>
    <span>kid</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>);</span>
    <span>:</span>
</code></pre></div></div>

<p>These three classes have a common predecessor – the class <code>Mannequin(feminine,height)</code>, where <em>feminine</em> is boolean and defines whether the shape is feminine or masculine, and the second parameter is a number for relative height (adults have height 1).</p>



<p>All types of figures have the same structure of joints. For example, the right arm of a figure is accessed by <code>r_arm</code>. Left and right body parts are in respect to the figure, not to the viewer (<a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-body-parts.jpg"></a></p>

<p>Each body part has rotation methods that turn it around a pivot point.
The first parameter <em>angle</em> of the methods is the angle of rotation in degrees,
so 180 is half turn and 360 is full turn. Negative angles are allowed and
they represent turning in the opposite direction. Some methods have an optional
second parameter for <em>direction</em> of motion, which could be the constant <code>LEFT</code> or
<code>RIGHT</code>.</p>

<h3 id="central-body-parts">Central body parts</h3>

<p>The central body parts are the ones which have single instances - <em>head</em>, <em>neck</em>, <em>torso</em>, <em>pelvis</em> and the body as a whole. To move the whole <strong>body</strong> use methods <em>bend</em>, <em>turn</em> and <em>tilt</em> of the figure (<a href="https://boytchev.github.io/mannequin.js/examples/example-body.html">live example</a>):</p>

<ul>
  <li><code>figure.bend ( angle )</code></li>
  <li><code>figure.turn ( angle )</code></li>
  <li><code>figure.turn ( angle, direction )</code></li>
  <li><code>figure.tilt ( angle )</code></li>
  <li><code>figure.tilt ( angle, direction )</code></li>
</ul>

<p>The <strong>head</strong> supports similar methods: <em>nod</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-head.html">live example</a>):</p>

<ul>
  <li><code>figure.head.nod ( angle )</code></li>
  <li><code>figure.head.turn ( angle )</code></li>
  <li><code>figure.head.turn ( angle, dir )</code></li>
  <li><code>figure.head.tilt ( angle )</code></li>
  <li><code>figure.head.tilt ( angle, dir )</code></li>
</ul>

<p>The <strong>torso</strong> has the same methods as the whole body: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-torso.html">live example</a>):</p>

<ul>
  <li><code>figure.torso.bend ( angle )</code></li>
  <li><code>figure.torso.turn ( angle )</code></li>
  <li><code>figure.torso.turn ( angle, direction )</code></li>
  <li><code>figure.torso.tilt ( angle )</code></li>
  <li><code>figure.torso.tilt ( angle, direction )</code></li>
</ul>

<p>Although the <strong>neck</strong> is a separate part of the body, it is not controlled individually. Instead, a part of the head motion is distributed over the neck. Similarly, the <strong>pelvis</strong> is not controlled individually. Instead, the whole body is controlled by bending, turning and tilting.</p>

<h3 id="upper-limbs">Upper limbs</h3>

<p>The upper limbs are symmetrical body parts: <em>arm</em>, <em>elbow</em>, <em>wrist</em> and <em>fingers</em>.</p>

<p>Both <strong>arms</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm1.html">live example</a>). The following list refers to the right arm, however, the same methods are available for the right hand:</p>

<ul>
  <li><code>figure.r_arm.raise ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle, direction )</code></li>
  <li><code>figure.r_arm.turn ( angle )</code></li>
  <li><code>figure.r_arm.turn ( angle, direction )</code></li>
</ul>

<p>If the <em>direction</em> parameter is omitted, then the default motions of <em>straddle</em> and <em>turn</em> are symmetrical. For example, the left arm is straddled to the left, while the right arm is straddled to the right (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm2.html">live example</a>).</p>

<p>The motion of the <strong>elbow</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-elbow.html">live example</a>). Negative values for <em>angle</em> result in unnatural elbow position.</p>

<ul>
  <li><code>figure.r_elbow.bend ( angle )</code></li>
</ul>

<p>The <strong>wrists</strong> have the same methods as the torso: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-wrist.html">live example</a>), but similar to the arms, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_wrist.bend ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle, direction )</code></li>
  <li><code>figure.r_wrist.tilt ( angle )</code></li>
  <li><code>figure.r_wrist.tilt ( angle, direction )</code></li>
</ul>

<p>The last body parts of the upper limbs are the <strong>fingers</strong>. They can only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-fingers.html">live example</a>), however, they are composed of two segments and the bending angle is distributed over both of them.</p>

<ul>
  <li><code>figure.r_fingers.bend ( angle )</code></li>
</ul>

<h3 id="lower-limbs">Lower limbs</h3>

<p>The lower limbs are symmetrical body parts: <em>leg</em>, <em>knee</em> and <em>ankle</em>.</p>

<p>Both <strong>legs</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-leg.html">live example</a>). Straddling and turning are symmetrical if <em>direction</em> is not set.</p>

<ul>
  <li><code>figure.r_leg.raise ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle, direction )</code></li>
  <li><code>figure.r_leg.turn ( angle )</code></li>
  <li><code>figure.r_leg.turn ( angle, direction )</code></li>
</ul>

<p>The motion of the <strong>knee</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-knee.html">live example</a>). Negative values for <em>angle</em> result in unnatural knee position.</p>

<ul>
  <li><code>figure.r_knee.bend ( angle )</code></li>
</ul>

<p>The <strong>ankles</strong> have the same methods as the wrists: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-ankle.html">live example</a>), but similar to the legs, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_ankle.bend ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle, direction )</code></li>
  <li><code>figure.r_ankle.tilt ( angle )</code></li>
  <li><code>figure.r_ankle.tilt ( angle, direction )</code></li>
</ul>



<p>The posture of a figure is defined by a setting the rotations of body parts. The order of rotations is fixed independent on the order of rotations in the user program (<a href="https://boytchev.github.io/mannequin.js/examples/example-order.html">live example</a>). For example:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>produces the same posture as:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
</code></pre></div></div>

<p>Sometimes this might lead to unexpected results, especially if the user assumes an order of rotations that is different from what mannequin.js uses. This might happen when a body part is rotated around 3 or 2 axes.</p>

<h3 id="static-posture">Static posture</h3>

<p>The static posture defines the position of body part that do not change. By default, when a figure is created, its body parts are set to the default posture. This version of mannequin.js does not provide posture editor, so all rotations has to be defined programmatically.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg"></a></p>

<p>Sometimes it is better to define the figure step by step. Tai Chi Chuan posture (<a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html">live example</a>) could start by defining the whole body position:</p>

<div><div><pre><code><span>// overall body position</span>
<span>man</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>7.7</span><span>;</span>
<span>man</span><span>.</span><span>tilt</span><span>(</span><span>5</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>bend</span><span>(</span><span>15</span><span>);</span>

<span>// torso and head</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>tilt</span><span>(</span><span>15</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>15</span><span>);</span>
<span>man</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>70</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>Then the orientation of the legs can be set:</p>

<div><div><pre><code><span>// right leg</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>raise</span><span>(</span><span>85</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>straddle</span><span>(</span><span>40</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>r_knee</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>bend</span><span>(</span><span>35</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>15</span><span>);</span>

<span>// left leg</span>
<span>man</span><span>.</span><span>l_leg</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>l_knee</span><span>.</span><span>bend</span><span>(</span><span>25</span><span>);</span>
<span>man</span><span>.</span><span>l_ankle</span><span>.</span><span>bend</span><span>(</span><span>42</span><span>);</span>
</code></pre></div></div>

<p>Finally, the arms are fixed:</p>

<div><div><pre><code><span>// left arm</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>raise</span><span>(</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>60</span><span>);</span>
<span>man</span><span>.</span><span>l_elbow</span><span>.</span><span>bend</span><span>(</span><span>155</span><span>);</span>
<span>man</span><span>.</span><span>l_wrist</span><span>.</span><span>turn</span><span>(</span><span>50</span><span>);</span>
<span>man</span><span>.</span><span>l_fingers</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>10</span><span>);</span>

<span>// right arm</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>tilt</span><span>(</span><span>70</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_elbow</span><span>.</span><span>bend</span><span>(</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>r_wrist</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>r_fingers</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
</code></pre></div></div>

<h3 id="dynamic-posture">Dynamic posture</h3>

<p>The dynamic posture – i.e. a posture that changes over time – is set with the same methods that are used for static posture. Mannequin.js defines an empty function <code>animate(t)</code>, which is called in the animation loop once for each frame. All changes of a posture should be defined inside this function (<a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html">live example</a>). The parameter <em>t</em> is the time, measured in tenths of seconds. This function is set up in <code>createScene()</code>. If <em>createScene</em> and <em>animate</em> are not used, then the animation loop should be managed manually.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-dynamic.jpg"></a></p>

<div><div><pre><code><span>function</span> <span>animate</span><span>(</span><span>t</span><span>)</span>
<span>{</span>
    <span>var</span> <span>time1</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>))</span><span>/</span><span>3</span><span>,</span>
        <span>time2</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>-</span><span>60</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>-</span><span>90</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>-</span><span>120</span><span>))</span><span>/</span><span>3</span><span>;</span>

    <span>ball</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>

    <span>child</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>
    <span>child</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>4</span><span>+</span><span>cos</span><span>(</span><span>90</span><span>*</span><span>time1</span><span>);</span>

    <span>child</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>-</span><span>20</span><span>*</span><span>time1</span><span>+</span><span>20</span><span>*</span><span>time2</span><span>);</span>
    <span>child</span><span>.</span><span>tilt</span><span>(</span><span>10</span><span>*</span><span>time1</span><span>);</span>
    <span>:</span>
	
    <span>scene</span><span>.</span><span>rotation</span><span>.</span><span>y</span> <span>=</span> <span>rad</span><span>(</span><span>30</span><span>*</span><span>time1</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>To make the animation loop faster, all constant rotations should be defined outside <em>animate</em>. Also, if a rotation changing in the loop, there is no need to set it up outside the loop.</p>



<p>Apart for moving body parts, the current version of mannequin.js provides basic functionality for additional modification or accessing the figure.</p>

<h3 id="custom-colors">Custom colors</h3>

<p>By default, all figures use a predefined set of global colors for body parts. Global colors are stored in <code>Mannequin.colors</code> array as six <a href="https://threejs.org/docs/#api/en/math/Color">Three.js colors</a> or lowercase <a href="https://www.w3schools.com/colors/colors_names.asp">HTML/CSS color names</a> in specific order – head, shoes, pelvis, joints, limbs and torso:</p>

<div><div><pre><code><span>Mannequin</span><span>.</span><span>colors</span> <span>=</span> <span>[</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// head</span>
    <span>'</span><span>gray</span><span>'</span><span>,</span>		<span>// shoes</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// pelvis</span>
    <span>'</span><span>burlywood</span><span>'</span><span>,</span>	<span>// joints</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// limbs</span>
    <span>'</span><span>bisque</span><span>'</span>		<span>// torso</span>
<span>];</span>
</code></pre></div></div>

<p>The global color of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boytchev.github.io/mannequin.js/">https://boytchev.github.io/mannequin.js/</a></em></p>]]>
            </description>
            <link>https://boytchev.github.io/mannequin.js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302602</guid>
            <pubDate>Fri, 04 Dec 2020 14:35:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has AI 'solved' protein folding?]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25302487">thread link</a>) | @stuartbman
<br/>
December 4, 2020 | https://explainthispaper.com/ai-solving-protein-folding/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/ai-solving-protein-folding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<h2><b>Has AI 'solved' protein folding? 📎</b></h2>
<div>
<p><i>article</i></p>
<div>
<p>Improved protein structure prediction using potentials from deep learning</p>
<p>Andrew W. Senior, Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre, Tim Green, Chongli Qin, Augustin Žídek, Alexander W. R. Nelson, Alex Bridgland, Hugo Penedones, Stig Petersen, Karen Simonyan, Steve Crossan...</p>
<p><a href="https://www.nature.com/articles/s41586-019-1923-7.epdf?author_access_token=Z_KaZKDqtKzbE7Wd5HtwI9RgN0jAjWel9jnR3ZoTv0MCcgAwHMgRx9mvLjNQdB2TlQQaa7l420UCtGo8vYQ39gg8lFWR9mAZtvsN_1PrccXfIbc6e-tGSgazNL_Xd">Nature</a>
</p></div>
</div>
<div>
<h3>TL;DR</h3>
<p><span><p>Predicting protein folding is a massive problem with huge potential to help us understand disease. It’s been stuck in a rut for the past 50 years, but one team of researchers has come out of nowhere and claims to have solved the problem. But have they?</p></span>
</p></div>
<h3 grey-text="" text-darken-4="">Clinical Need</h3>
<section>
<div>
<p><span>
<div><p>Proteins are made up of amino acids. Getting the amino acid sequence for a protein is pretty easy these days. But going from this sequence to the 3-dimensional shape of the protein is really hard.</p><p>For decades, researchers have worked out protein structures using slow and expensive techniques such as <sample>x-ray crystallography</sample>. So far we’ve only solved about 170,000 proteins using these approaches. Yet more than 200 million proteins have been discovered across all forms of life 😳</p><p>Being able to predict a protein’s shape based on its amino acid sequence would be a game changer. We could design drugs faster by targeting proteins more effectively. But computer-based predictions haven’t been accurate enough to be useful. Until now…</p></div>
</span>
</p>
<div>

<p>X-ray crystallography uses the diffraction of x-rays to work out the shape of a protein. The pictures are murky and there's a lot of guesswork involved!</p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>

</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">What did they do?</h3>
<div><p>The team created a deep learning pipeline for predicting protein shape from its amino acid sequence.</p><p>They entered this neural network into the “Critical Assessment of Protein Structure Prediction” (CASP) competition. Teams are given amino acids sequences for ~100 proteins with unknown structures and asked to predict protein shape. The predictions are given a score from 0-100. Slow techniques (like x-ray crystallography) score above 90.</p></div>
<h3 grey-text="" text-darken-4="">How did the model work?</h3>
<section>
<div>
<p><span>
<div><p>The first version of their model (AlphaFold) performs the following stages:</p><p>First, it looks for similar sequence fragments to the protein of interest from a large protein sequence database. This helps identify features of the protein at interest. An <sample>autoencoder</sample> predicts which protein shape the sequence fragment most likely represents.</p><p>These features are then fed into a convolutional neural network which predicts the distances between different parts of the protein sequence. Predicting distances enables it to also predict contact points.</p><p>Then, using the predicted distances and contact points, the model considers all the possible shapes of the protein and identifies the most likely one.</p></div>
</span>
</p>
<div>

<p>This is a type of neural network that compresses data into a bottleneck of it's most important features, and measures it's performance by reconstructing that bottleneck back up to size. It's an in depth topic worth <a href="https://www.jeremyjordan.me/autoencoders/#:~:text=Autoencoders%20are%20an%20unsupervised%20learning,representation%20of%20the%20original%20input.">reading more on</a></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<p>With the updated model (AlphaFold-2) they made some changes. They haven't released a paper yet (only an abstract), but from what we can tell they used an <sample>attention-based deep learning</sample> to fit over the whole shape of the protein, not just the fragments.</p>
</span>
</p>
<div>

<p>Instead of working over the whole sequence at once, this method allows the learning to 'attend' to subsections individually. This is a bit like trying to translate a long german word- instead of trying to decode the whole word, you break it into sub-words and see how they match, then put it all together.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">How did the model perform?</h3>
<div><p><img alt="Animated Protein" height="450" src="https://explainthispaper.s3.amazonaws.com/images/protein.width-800.png" width="800"></p><p>From the start of the competition in 1994 up to 2016, CASP scores had been around 40. The first time DeepMind entered, they scored up to 60. This year- AlphaFold scored an average of 92.4, smashing the threshold of 90/100!</p><p>In fact, the organisers of the competition thought that DeepMind had been cheating, so they set them a special challenge- a membrane protein from an ancient species of <i>archaea</i>. For 10 years with no success, research teams tried every trick in the book to get an x-ray crystal structure of the protein.</p><p>AlphaFold had no problem, returning an image of a three part protein with two helical arms. In hindsight, this structure fit the x-ray crystallography data perfectly, effectively going beyond the limitations of current human research.</p></div>
<h3 grey-text="" text-darken-4="">So what?</h3>
<section>
<div>
<p><span>
<div><p>This is a thorny problem that researchers and pharmaceutical companies have been working on for 50+ years. This model could predict the shape of proteins without unreliable experimental measurements. This would mean faster development of a wide range of drugs, from cancer drugs that better target proteins for cell replication, to antibiotics that target surface receptors of microbes.</p><p>What’s more, this model was cheap to train- just weeks on quite a <sample>small cluster of servers</sample></p><p>It's worth saying that this isn't the whole picture of protein folding- this still doesn't inform how proteins change shape in the presence of other molecules (like oxygen near haemoglobin). These are also the crystallised protein forms rather than the true 'in vivo' structures, so there may be some errors in translation, but that remains to be seen.</p></div>
</span>
</p>
<div>

<p>Using Google's <a href="https://cloud.google.com/tpu/pricing#pricing_calculator">pricing calculator</a> and the details from the blog post, this could be trained for around $21,000. In the grand scheme of biology and pharmaceuticals, this is pennies!<br></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>

</div>
</div><div>
<h2>The latest papers in your inbox</h2>
<p>Keep up to date with the latest research, summarised concisely and clearly.</p>



</div></div>]]>
            </description>
            <link>https://explainthispaper.com/ai-solving-protein-folding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302487</guid>
            <pubDate>Fri, 04 Dec 2020 14:25:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker’s Guide to Online Anonymity]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302389">thread link</a>) | @r4um
<br/>
December 4, 2020 | https://anonymousplanet.github.io/thgtoa/guide.html | <a href="https://web.archive.org/web/*/https://anonymousplanet.github.io/thgtoa/guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<ul>
  <li><a href="#introduction">Introduction:</a></li>
  <li><a href="#requirements">Requirements:</a></li>
  <li><a href="#understanding-some-basics-of-how-some-information-can-lead-back-to-you-and-how-to-mitigate-those">Understanding some basics of how some information can lead back to you and how to mitigate those:</a>
    <ul>
      <li><a href="#your-ip-address">Your IP address:</a></li>
      <li><a href="#your-dns-requests">Your DNS requests:</a></li>
      <li><a href="#your-imei-and-imsi-and-by-extension-your-phone-number">Your IMEI and IMSI (and by extension, your phone number):</a></li>
      <li><a href="#your-wi-fi-mac-address">Your Wi-Fi MAC address:</a></li>
      <li><a href="#your-bluetooth-mac-address">Your Bluetooth MAC address:</a></li>
      <li><a href="#your-operating-systems-and-apps-telemetry-services">Your Operating Systems and Apps telemetry services:</a></li>
      <li><a href="#the-wifis-and-bluetooth-devices-around-you">The WIFIs and Bluetooth devices around you:</a></li>
      <li><a href="#your-metadata-including-your-geo-location">Your Metadata including your Geo-Location:</a></li>
      <li><a href="#your-smart-devices-in-general">Your Smart devices in general:</a></li>
      <li><a href="#your-devices-can-be-tracked-even-when-completely-powered-off">Your Devices can be tracked even when completely powered off:</a></li>
      <li><a href="#your-rfid-enabled-devices">Your RFID enabled devices:</a></li>
      <li><a href="#your-files-propertiesmetadata">Your Files Properties/Metadata:</a></li>
      <li><a href="#your-anonymized-torvpn-traffic">Your “Anonymized” Tor/VPN traffic:</a></li>
      <li><a href="#your-crypto-transactions">Your Crypto transactions:</a></li>
      <li><a href="#exploits-in-your-apps">Exploits in your apps:</a></li>
      <li><a href="#your-cloud-backupssync-services">Your Cloud backups/sync services:</a></li>
      <li><a href="#your-digital-fingerprint-and-footprint">Your Digital Fingerprint And Footprint:</a></li>
      <li><a href="#your-real-life">Your Real Life:</a></li>
      <li><a href="#your-browser-and-device-fingerprints">Your Browser and Device Fingerprints:</a></li>
      <li><a href="#your-face-and-other-biometrics">Your Face and other Biometrics:</a></li>
      <li><a href="#phishing">Phishing:</a></li>
      <li><a href="#forensics">Forensics:</a></li>
      <li><a href="#advanced-targeted-techniques">Advanced targeted techniques:</a></li>
      <li><a href="#notes">Notes:</a></li>
    </ul>
  </li>
  <li><a href="#general-preparations">General Preparations:</a>
    <ul>
      <li><a href="#picking-your-route">Picking your route:</a>
        <ul>
          <li><a href="#budgetmaterial-limitations">Budget/Material limitations:</a></li>
          <li><a href="#skills">Skills:</a></li>
          <li><a href="#adversaries-threats">Adversaries (threats):</a></li>
        </ul>
      </li>
      <li><a href="#steps-for-all-routes">Steps for all routes:</a>
        <ul>
          <li><a href="#get-a-burner-phone">Get a burner phone:</a></li>
          <li><a href="#get-an-anonymous-pre-paid-sim-card">Get an anonymous pre-paid SIM card:</a></li>
          <li><a href="#get-an-usb-key">Get an USB key:</a></li>
          <li><a href="#find-some-safe-places-with-decent-public-wifi">Find some safe places with decent public WIFI:</a></li>
        </ul>
      </li>
      <li><a href="#the-tails-route">The TAILS route:</a></li>
      <li><a href="#steps-for-all-other-routes">Steps for all other routes:</a>
        <ul>
          <li><a href="#get-a-laptop-for-your-anonymous-activities">Get a laptop for your anonymous activities:</a></li>
          <li><a href="#a-note-for-linux-users-to-avoid-wasting-your-time-later">A note for Linux users to avoid wasting your time later:</a></li>
          <li><a href="#biosuefi-settings-of-your-laptop">Bios/UEFI Settings of your laptop:</a></li>
          <li><a href="#tamper-protect-your-laptop">Tamper protect your laptop:</a></li>
        </ul>
      </li>
      <li><a href="#the-whonix-route">The Whonix route:</a>
        <ul>
          <li><a href="#picking-your-host-os-the-os-installed-on-your-laptop">Picking your Host OS (the OS installed on your laptop):</a></li>
          <li><a href="#enable-mac-address-randomization-on-your-laptop">Enable MAC address randomization on your laptop:</a></li>
          <li><a href="#setting-up-a-safe-browser-on-your-host-os">Setting up a safe Browser on your Host OS:</a></li>
          <li><a href="#enable-some-additional-privacy-settings-on-your-host-os">Enable some additional privacy settings on your Host OS:</a></li>
          <li><a href="#windows-host-os-encryption">Windows Host OS encryption:</a></li>
          <li><a href="#virtualbox">Virtualbox:</a></li>
          <li><a href="#get-an-anonymous-cash-paid-vpn-subscription">Get an anonymous (cash-paid) VPN subscription:</a></li>
          <li><a href="#download-various-utilities">Download various utilities:</a></li>
          <li><a href="#whonix-virtual-machines">Whonix Virtual Machines:</a></li>
          <li><a href="#windows-10-virtual-machine">Windows 10 Virtual Machine:</a></li>
          <li><a href="#vpn-client-installation-cash-paid">VPN client installation (cash-paid):</a></li>
          <li><a href="#keepassxc">KeePassXC:</a></li>
        </ul>
      </li>
      <li><a href="#the-qubes-route">The Qubes Route:</a></li>
    </ul>
  </li>
  <li><a href="#creating-your-anonymous-online-identities">Creating your anonymous online identities:</a>
    <ul>
      <li><a href="#understanding-the-methods-used-to-prevent-anonymity-and-verify-identity">Understanding the methods used to prevent anonymity and verify identity:</a>
        <ul>
          <li><a href="#captchas">Captchas:</a></li>
          <li><a href="#phone-verification">Phone verification:</a></li>
          <li><a href="#e-mail-verification">E-Mail verification:</a></li>
          <li><a href="#user-details-checking">User details checking:</a></li>
          <li><a href="#proof-of-id-verification">Proof of ID verification:</a></li>
          <li><a href="#ip-filters">IP Filters:</a></li>
          <li><a href="#browser-and-device-fingerprinting">Browser and Device Fingerprinting:</a></li>
          <li><a href="#human-interaction">Human interaction:</a></li>
          <li><a href="#user-moderation">User Moderation:</a></li>
          <li><a href="#behavioral-analysis">Behavioral Analysis:</a></li>
          <li><a href="#financial-transactions">Financial transactions:</a></li>
          <li><a href="#sign-in-with-some-platform">Sign-in with some platform:</a></li>
          <li><a href="#live-face-recognition-and-biometrics-again">Live Face recognition and biometrics (again):</a></li>
          <li><a href="#manual-reviews">Manual reviews:</a></li>
        </ul>
      </li>
      <li><a href="#getting-online">Getting Online:</a></li>
      <li><a href="#creating-new-identities">Creating new identities:</a></li>
      <li><a href="#protonmail">ProtonMail:</a></li>
      <li><a href="#google">Google:</a></li>
      <li><a href="#twitter">Twitter:</a></li>
      <li><a href="#linkedin">Linkedin:</a></li>
      <li><a href="#microsoft">Microsoft:</a></li>
      <li><a href="#instagram">Instagram:</a></li>
      <li><a href="#facebook">Facebook:</a></li>
      <li><a href="#github">Github:</a></li>
      <li><a href="#discord">Discord:</a></li>
      <li><a href="#telegram">Telegram:</a></li>
      <li><a href="#reddit">Reddit:</a></li>
      <li><a href="#chan">4chan:</a></li>
      <li><a href="#crypto-wallets">Crypto Wallets:</a></li>
      <li><a href="#what-about-those-mobile-only-apps-whatsappsignal">What about those mobile only apps (Whatsapp/Signal):</a></li>
      <li><a href="#anything-else">Anything else:</a></li>
      <li><a href="#maintenance-tasks">Maintenance tasks:</a></li>
    </ul>
  </li>
  <li><a href="#backup-your-work-safely-and-anonymously">Backup your work (safely and anonymously):</a></li>
  <li><a href="#covering-your-tracks">Covering your tracks:</a>
    <ul>
      <li><a href="#protecting-yourself-against-forensics">Protecting yourself against forensics:</a></li>
      <li><a href="#tails">Tails:</a></li>
      <li><a href="#windows-1">Windows:</a>
        <ul>
          <li><a href="#diagnostic-data-and-telemetry">Diagnostic Data and Telemetry:</a></li>
          <li><a href="#eventlogs">Eventlogs:</a></li>
          <li><a href="#veracrypt-history">Veracrypt History:</a></li>
          <li><a href="#external-tool-cleaning">External Tool Cleaning:</a></li>
          <li><a href="#shellbags">Shellbags:</a></li>
          <li><a href="#wi-fi-history">Wi-Fi History:</a></li>
        </ul>
      </li>
      <li><a href="#how-to-securely-wipe-your-whole-laptop-if-you-want-to-erase-everything">How to securely wipe your whole laptop if you want to erase everything:</a>
        <ul>
          <li><a href="#linux-1">Linux:</a></li>
          <li><a href="#windows-2">Windows: </a></li>
        </ul>
      </li>
      <li><a href="#if-you-think-you-got-burned">If you think you got burned:</a>
        <ul>
          <li><a href="#if-you-have-some-time">If you have some time:</a></li>
          <li><a href="#if-you-have-no-time">If you have no time:</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#some-last-opsec-thoughts">Some last OPSEC thoughts:</a></li>
  <li><a href="#appendix-a-windows-installation">Appendix A: (Windows Installation)</a>
    <ul>
      <li><a href="#installation">Installation:</a></li>
      <li><a href="#privacy-settings">Privacy Settings:</a></li>
    </ul>
  </li>
  <li><a href="#appendix-b-windows-additional-privacy-settings">Appendix B: (Windows Additional Privacy Settings)</a></li>
  <li><a href="#appendix-c-windows-installation-media-creation">Appendix C: (Windows Installation Media Creation)</a></li>
</ul>

<p>Version 0.1.1 (draft), December 2020 (work in progress, some parts are incomplete) by AnonymousPlanet</p>

<p>This guide is open-source, licensed under Creative Commons Attribution 4.0 International (cc-by-4.0).</p>

<p>Feel free to submit issues/recommendations/ideas using Github Issues at: <a href="https://github.com/AnonymousPlanet/thgtoa/issues">https://github.com/AnonymousPlanet/thgtoa/issues</a></p>

<p>PDF version of this guide at: <a href="https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf">https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf</a></p>



<p>Making a social media account with a pseudonym or artist/brand name is easy. And it’s enough is most use cases to protect your identity as the next George Orwell. There are plenty of people using pseudonyms all over Facebook/Instagram/Twitter/Linkedin/TikTok/Snapchat/Reddit/… But the vast majority of those are anything but anonymous and can easily be traced to their real identity by your local cops, random people within the OSINT<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (Open-Source Intelligence) community and trolls<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> on 4chan<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This is a good thing as most criminals/trolls are not really tech savvy and will be identified with ease. But this is also a bad thing as most political dissidents, human rights activists and whistleblowers can also be tracked rather easily.</p>

<p>This updated guide aims to provide introduction to various tracking techniques, id verification techniques and guidance to creating and maintaining anonymous identities online including social media accounts safely.</p>

<p>Will this guide help you protect yourself from the NSA, the FSB, Mark Zuckerberg or the Mossad if they’re out to find you? Probably not … Mossad will be doing “Mossad things” <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> and will probably find you no matter how hard to try to hide<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>You have to consider your threat model<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> before going further.</p>

<p><img src="https://anonymousplanet.github.io/thgtoa/media/image1.jpeg" alt=""></p>

<p>(Illustration by xkcd.com, licensed under CC BY-NC 2.5)</p>

<p>Will this guide help you protect your privacy from OSINT researchers like Belingcat<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> , Doxing<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup> trolls on 4chan<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup> and others that have no access to the NSA toolbox? More likely. Tho I wouldn’t be so sure about 4chan.</p>

<p>It’s also important to understand this guide is the humble result of years of experience and testing from a single individual (myself) and that many of those systems that aim to prevent anonymity are opaque closed-source systems. Most of those guidelines are guessed based on experience. These experiences take a lot of time and resources and are unfortunately far from being scientific. <strong>Your mileage may vary.</strong></p>

<p>You might think this guide has no legitimate use but there are many<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">10</a></sup><sup id="fnref:11" role="doc-noteref"><a href="#fn:11">11</a></sup> such as:</p>

<ul>
  <li>
    <p>Evading Censorship</p>
  </li>
  <li>
    <p>Evading Oppression</p>
  </li>
  <li>
    <p>Evading Unlawful Government Surveillance</p>
  </li>
  <li>
    <p>Whistle Blowing</p>
  </li>
  <li>
    <p>Journalism</p>
  </li>
  <li>
    <p>Activism</p>
  </li>
</ul>

<p>This guide is written for use by those good intended individuals who might not be knowledgeable enough to consider the big picture of online anonymity.</p>

<p>This guide is not intended for:</p>

<ul>
  <li>
    <p>Creating machine accounts of any kind (bots).</p>
  </li>
  <li>
    <p>Creating impersonation accounts of existing people (identity theft).</p>
  </li>
  <li>
    <p>Helping malicious individuals conduct unlawful or unethical activities (like trolls).</p>
  </li>
  <li>
    <p>Use by minors.</p>
  </li>
</ul>

<p>Feel free to report issues or recommend improvements in this repository if you have any.</p>

<p><strong>Use at your own risk. Anything in here is not legal advice and you should verify compliance with your local law before use (IANAL</strong><sup id="fnref:12" role="doc-noteref"><a href="#fn:12">12</a></sup><strong>).</strong></p>



<ul>
  <li>
    <p><strong>Be a permanent Adult resident in Germany where the courts have upheld up the legality of not using real names on online platforms (§13 VI of the German Telemedia Act of 2007</strong> <sup id="fnref:13" role="doc-noteref"><a href="#fn:13">13</a></sup><strong>). Alternatively be resident of any other country where you can validate and verify this is legal yourself.</strong></p>
  </li>
  <li>
    <p>This guide will assume you already have access to some PC (Windows/Linux) laptop computer (not a work/shared device).</p>
  </li>
  <li>
    <p>Don’t be evil (for real this time)<sup id="fnref:14" role="doc-noteref"><a href="#fn:14">14</a></sup>.</p>
  </li>
  <li>
    <p>Have patience as this process could take several weeks to finalize.</p>
  </li>
  <li>
    <p>Have a little budget to dedicate to this process (you’ll need at least budget for an USB key).</p>
  </li>
  <li>
    <p>Have a lot of free time on your hands to dedicate to this process.</p>
  </li>
  <li>
    <p>Be prepared to read a lot of references (do read them), guides (don’t skip them) and follow a lot of how-to tutorials thoroughly (don’t skip them either).</p>
  </li>
</ul>

<p><strong>This guide will (for the moment) not recommend using MacOS due to the latest Big Sur update which forces “unblockable” telemetry</strong><sup id="fnref:15" role="doc-noteref"><a href="#fn:15">15</a></sup><sup id="fnref:16" role="doc-noteref"><a href="#fn:16">16</a></sup> <strong>and because MacOS doesn’t offer MAC address randomization.</strong></p>



<p>There are many ways you can be tracked besides browser cookies and ads, your e-mail and your phone number. And if you think only the Mossad or the NSA/FSB can find you, you would be terribly wrong.</p>

<p>Here is a non-exhaustive list of some of the many ways you can be de-anonymized:</p>

<h2 id="your-ip-address">Your IP address:</h2>

<p>Your IP address<sup id="fnref:17" role="doc-noteref"><a href="#fn:17">17</a></sup> is the most known and obvious way you can be tracked. That IP is the IP you’re using at the source. This is where you connect to the internet. That IP is usually provided by your ISP (Internet Service Provider) (xDSL, Mobile, Cable, Fiber, Cafe, Bar, Friend, Neighbor). Most countries have data retention regulations<sup id="fnref:18" role="doc-noteref"><a href="#fn:18">18</a></sup> which mandates keeping logs of who is using what IP at a certain time/date for up to several years or indefinitely. Your ISP can tell a third party that you were using a specific IP at a specific date and time, years after the fact. If that IP (the origin one) leaks at any point for any reason, it can be used to track down you directly. In many countries, you won’t be able to have internet access without providing some form of identification to the provider (address, ID, real name, e-mail …).</p>

<p>Useless to say that most platforms (such as social networks) will also keep (sometimes indefinitely) the IP addresses you used to sign-up but also those you used to sign-in.</p>

<p>For those reasons, we’ll need to not use that origin IP (the one tied to your identification) or hide it as much as we can through a combination of various means:</p>

<ul>
  <li>
    <p>Using a public WIFI service (free).</p>
  </li>
  <li>
    <p>Using an anonymous VPN service<sup id="fnref:19" role="doc-noteref"><a href="#fn:19">19</a></sup> (paid by cash).</p>
  </li>
  <li>
    <p>Using the Tor Anonymity Network<sup id="fnref:20" role="doc-noteref"><a href="#fn:20">20</a></sup> (free).</p>
  </li>
</ul>

<p>All those will be explained later in this guide.</p>

<h2 id="your-dns-requests">Your DNS requests:</h2>

<p>DNS stands for “Domain Name System”<sup id="fnref:21" role="doc-noteref"><a href="#fn:21">21</a></sup> and is a service used by your browser (and other apps) to find the IP addresses of a service. It’s pretty much a huge “contact list” (phone book for older people) that works like asking it a name and it returns the number to call. Except it returns an IP instead.</p>

<p>Every time your browser wants to access a certain service such as Google through <a href="https://www.google.com/">https://www.google.com</a>. Your Browser (Chrome or Firefox) will query a DNS service to find the IP addresses of the Google web servers.</p>

<p>Usually the DNS service is provided by your ISP and automatically configured by the network you’re connecting to. This DNS service could also be subject to data retention regulations or will just keep logs for other reasons (data collection for advertising purposes for instance). Therefore this ISP will be capable of …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anonymousplanet.github.io/thgtoa/guide.html">https://anonymousplanet.github.io/thgtoa/guide.html</a></em></p>]]>
            </description>
            <link>https://anonymousplanet.github.io/thgtoa/guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302389</guid>
            <pubDate>Fri, 04 Dec 2020 14:14:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Reading]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25302132">thread link</a>) | @accountLost
<br/>
December 4, 2020 | https://maartenvandoorn.nl/reading-guide/ | <a href="https://web.archive.org/web/*/https://maartenvandoorn.nl/reading-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1454">

	<!-- .entry-header -->



	<div>

		
<figure><img src="https://cdn-images-1.medium.com/max/2600/1*0tmBPKA1YGo82VNeMS3KhA.jpeg" alt=""><figcaption> <a rel="noreferrer noopener" href="https://unsplash.com/photos/9pw4TKvT3po?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Let’s make that magic&nbsp;happen</a> </figcaption></figure>



<p>Learning is a heavily misunderstood&nbsp;concept.</p>



<p>As a&nbsp;paradigm&nbsp;example of&nbsp;deep work,&nbsp;we understand that, when reading, directing your full attention to the material at hand is essential.&nbsp;Graspingcomplex information is hard.</p>



<p>But this is only half the battle.</p>



<p>After some string of words hits your retina and has made its way to your brain, you’re&nbsp;not done.</p>



<p>In a&nbsp;cruel&nbsp;irony,&nbsp;these hours of&nbsp;deep work&nbsp;often cause&nbsp;flow&nbsp;states&nbsp;and the feeling that ‘you’ve had a good day’ and learned a&nbsp;shitload&nbsp;of new stuff.</p>



<p>But for many reading&nbsp;episodes&nbsp;this feeling is&nbsp;deceptive.&nbsp;There is anineliminable&nbsp;aspect to learning that takes place&nbsp;<em>after&nbsp;</em>the&nbsp;glorious&nbsp;flow state.</p>



<p>The&nbsp;other half of the battle is&nbsp;to&nbsp;transfer the newly acquired intelligence from your working memory to your&nbsp;long-term&nbsp;understanding and&nbsp;integrate&nbsp;it into your standing stack of mental models.</p>



<p>If you don’t&nbsp;facilitate&nbsp;this, your learning&nbsp;gains&nbsp;are only a&nbsp;fraction&nbsp;of what they could have been.</p>



<p>In this article,&nbsp;I’m going to breakdown how to win the battle and the war — how to&nbsp;avoid&nbsp;these traps and organize your reading habit for a maximalReturn On Investment (ROI)&nbsp;on reading hours.</p>



<p>This is what we’ll cover:</p>



<pre><strong>Table of Contents</strong></pre>



<pre>1. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1b1d">Meta-Learning</a><br>2. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1d70">Learning is a two-step process</a><br>3. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9181">Remembering the right things</a><br>4. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7b89">Enter: Mental models</a><br>5. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a837">Learning = upgrading your mental models</a></pre>



<pre>6. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f0d0">How to ‘get it in there’ (macro-level)</a><br>7. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8823">How to ‘get it in there’ (micro level)</a><br>7.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#19fe">Know your why</a></pre>



<pre>8. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d988">Active reading</a><br>8.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#414f">How to make a mind map</a><br>8.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#ad79">Which Returns are you aiming for?</a><br>8.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d61e">Written active recall with bullet points</a><br>8.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a187">How to actively read a book</a><br>8.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8ead">Remember your why (yes, again)</a></pre>



<pre>9. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#4e04">Advanced active reading</a><br>9.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9782">The QEC method</a><br>9.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8dac">Keep a running tally</a><br>9.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#dc6b">Put your unconsciousness to work</a><br>9.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7a10">Pulling it all together</a><br>9.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#6b84">How to actively read a book (advanced)</a></pre>



<pre>10. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#926b">Organizing repetition and reflection</a><br>10.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f934">Setting up and using your review cycle</a><br>10.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#5182">Improved learning: engage in active recall</a></pre>



<pre><a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#fc24">Conclusion: The cycle of learning</a></pre>



<p>Warning: this is a very&nbsp;nerdy&nbsp;post.</p>



<h3 id="1b1d">Meta-Learning</h3>



<p>Meta-learning&nbsp;is knowing how to learn.&nbsp;It is one of the most important skills to learn, yet few people know how to do to it.</p>



<p>Reading and writing is what I do for a living, and, interestingly, a lot of non-imaginary&nbsp;friends have been asking me how I learn.&nbsp;This is special, becausemost of the times when people don’t know how to do something, they go&nbsp;togreat&nbsp;lengths&nbsp;<em>not&nbsp;</em>to notice their&nbsp;deficiency.</p>



<p>Could it be that many students turned ‘knowledge workers’ have the&nbsp;naggingfeeling that something is missing in their skillset because they were never taught&nbsp;meta-learning?</p>



<p>This is not their fault, but a&nbsp;<a href="https://medium.com/the-understanding-project/schools-dont-support-personal-development-they-distort-it-7e1c227eb01d" target="_blank" rel="noreferrer noopener">lack in our education system</a>.</p>



<p>As Adam Robinson observed on the&nbsp;<a href="https://fs.blog/adam-robinson-pt2/" rel="noreferrer noopener" target="_blank"><em>Farnam Street&nbsp;</em>podcast</a>:</p>



<blockquote><p>“<strong>No one ever shows us how to learn, ever</strong>.&nbsp;Nowhere in school.&nbsp;For example, imagine, Shane, [Shane is the host of the FS podcast] in French class, French 101, your first French class, your teacher said,&nbsp;“Everyone, you’re going to have to learn a lot of vocabulary in this class so before I teach you any words I’m going to teach you a way to remember vocabulary.”&nbsp;They never do that.&nbsp;They just go, “We’re going to have a quiz on these 30 words on Monday.&nbsp;Good luck.”&nbsp;But they don’t teach us how to learn actually, or remember things.”</p></blockquote>



<p>This is&nbsp;weird, because,&nbsp;in today’s high-information world,&nbsp;people need the ability to&nbsp;<em>make sense of</em>&nbsp;complexity and to&nbsp;<em>combine</em>&nbsp;many bits of data into a broad picture of the world.</p>



<p>Merely&nbsp;<em>acquiring</em>information is&nbsp;<em>not&nbsp;</em>(yet) learning.</p>



<p>Learning itself is a skill, and knowing how to do it well is an incredibly valuable advantage.</p>



<p>We take this is for granted, but how to do this is&nbsp;far from&nbsp;obvious&nbsp;and doesn’t get taught in the curriculum.</p>



<hr>



<h3 id="1d70">Learning is a&nbsp;two-step&nbsp;process</h3>



<p>So, how do we learn?</p>



<p>Before we attempt to answer the question,&nbsp;let’s get clear&nbsp;on what a&nbsp;satisfactoryanswer needs to get us.&nbsp;What does it&nbsp;<em>mean&nbsp;</em>to learn?&nbsp;When have you learned something?</p>



<p>In the introduction, I stated that&nbsp;just studying the information isn’t enough(no matter how intense your focus was).&nbsp;Learning has&nbsp;two phases — not one.</p>



<ol><li>Read/listen&nbsp;the damn thing</li><li>Process and&nbsp;recall&nbsp;what you’ve just ‘learned’</li></ol>



<p>A lot has been said about the first phase — about deep work, concentration, blocking out&nbsp;distractions, and so&nbsp;forth.&nbsp;This makes sense:&nbsp;if you’re checking Facebook all the time,&nbsp;your mind is not ‘there’, and you might as well not have spent your afternoon ’reading’ this book.</p>



<p>This is all great and I‘m a big fan, but in the&nbsp;meantime, we’re ignoring step two.</p>



<p>If you don’t spend time revisiting and grappling with the book either,&nbsp;<em>the same applies</em> — you might as well not have read it.&nbsp;In the long run, there is no difference between skipping the first or the second stage (except whether you passed that French test in high school back in 2019…).</p>



<p>After you’ve killed Cersei, you’ve still got the&nbsp;White Walkers to deal with.&nbsp;If you don’t, you lose either way.</p>



<p>That is why students who&nbsp;binge-study&nbsp;the night before the exam quite literally forget everything two days later:&nbsp;while all these&nbsp;lame&nbsp;French words were still in their short-term memory,&nbsp;allowing them to pass the test,&nbsp;the information never&nbsp;transitioned&nbsp;to their long-term understanding — and so, sooner or later, it&nbsp;evaporated.</p>



<p>To learn,&nbsp;you need to transfer the newly acquired intelligence from&nbsp;your working memory to your long-term understanding.</p>



<p><strong>The jump from short-term memory to long-term understanding doesn’t happen automatically.</strong><strong>The default mode, after you close your books for the day, is not&nbsp;</strong><strong>retainment</strong><strong>&nbsp;but&nbsp;<em>forgetting</em></strong><strong>.</strong></p>



<p>This learning guide&nbsp;is not about&nbsp;<a href="https://medium.com/the-understanding-project/why-you-dont-need-to-read-those-productivity-guides-347fe02cc196" target="_blank" rel="noreferrer noopener">how to do generic deep work</a>.&nbsp;It explains how to maximize the ROI on hours spent reading,&nbsp;<em>assuming</em>&nbsp;you did them ‘deep work style’.</p>



<h3 id="9181">Remembering the right&nbsp;things</h3>



<p>First, I need to discuss a common&nbsp;objection&nbsp;that denies phase two of learning matters.&nbsp;If you have no&nbsp;quibble&nbsp;with memorization, and doing the required effort, you can skip this section.</p>



<p>“But Mr. Maarten,” the protest goes, “you mention ‘processing’ and ‘remembering’ into my ‘long-term understanding’, but isn’t memorizing pointless?&nbsp;My Google Assistant can look everything up and also is smarter than me, says my Google Assistant.”</p>



<p>Indeed,&nbsp;Albert Einstein is&nbsp;<a href="https://medium.com/the-polymath-project/studying-history-is-more-important-than-ever-in-todays-economy-c99fde4be7d0" target="_blank" rel="noreferrer noopener">supposed</a>&nbsp;to have said:&nbsp;“Never&nbsp;memorize&nbsp;what you can look up in a book”.&nbsp;In Einstein’s days, books were&nbsp;unequaled&nbsp;as a source of information.&nbsp;We, on the other hand, live in an age where nearly everything can be accessed through the magic vehicle of internet.&nbsp;Following Einstein’s logic, then,&nbsp;<em>nothing&nbsp;</em>is worth memorizing anymore, because&nbsp;<em>everything</em>&nbsp;can be looked up.</p>



<p>But, of course, that is probably not what old Albert was getting at.</p>



<p>Most likely,&nbsp;the advice he wanted to&nbsp;dispense&nbsp;was that&nbsp;you should not waste your time by committing unimportant details to memory.&nbsp;Rather,&nbsp;your&nbsp;focus should be on understanding the bigger picture — on&nbsp;how things relate to each other.</p>



<p>This reminds me of Elon Musk’s&nbsp;approach to learning.&nbsp;He&nbsp;<a href="https://www.reddit.com/r/IAmA/comments/2rgsan/i_am_elon_musk_ceocto_of_a_rocket_company_ama/" rel="noreferrer noopener" target="_blank">recommends</a>viewing knowledge as a tree:</p>



<blockquote><p>Make sure you understand the fundamental principles, the trunk and big branches, before you get into the leaves/details or there is nothing for them to hang on to.</p></blockquote>



<p>To ‘learn’, we need to do more than merely feeding ourselves new information.&nbsp;Expanding our intelligence requires&nbsp;<em>connecting</em>&nbsp;new materials to what we already knew&nbsp;(the second phase of learning).&nbsp;That, in turn, requires something to connect&nbsp;<em>to.</em></p>



<p>There’s no adding branches without a solid trunk.</p>



<p>The very possibility of genuine insight requires a memorized base.&nbsp;Without it, data you consume will not be added to your tree of knowledge.&nbsp;Instead, they will float in the air for a couple of weeks or so, before being taken away by the wind.</p>



<p>Knowledge, gone.&nbsp;Time, wasted.</p>



<p>What I’m saying is&nbsp;<em>not&nbsp;</em>that we should&nbsp;devise&nbsp;techniques which enable us torecite&nbsp;everything we’ve learned.&nbsp;That’s why we’re not talking about, for example,&nbsp;retaining&nbsp;the date of the French revolution.</p>



<p>However,&nbsp;you&nbsp;<em>should&nbsp;</em>learn by heart the lessons it tells you about how the world works&nbsp;and update your representation of reality&nbsp;accordingly.</p>



<p>In&nbsp;other words,&nbsp;you should use it to&nbsp;inform&nbsp;your&nbsp;unconscious — the&nbsp;sum&nbsp;of your mental models.</p>



<h3 id="7b89">Enter: Mental&nbsp;models</h3>



<p>I’ve long been skeptical about mental models since (1) they’re all the rage now and (2) no one seems to be able to explain in concrete terms what they are. A dangerous combination.</p>



<p>It turned out my doubt was due to ignorance on my part.</p>



<p>A mental model,&nbsp;as&nbsp;<a href="https://en.wikipedia.org/wiki/Mental_model" rel="noreferrer noopener" target="_blank">Wikipedia</a>&nbsp;tells us, is</p>



<blockquote><p>An explanation of someone’s thought process about how something works in the real world.&nbsp;<strong>It is a representation of the surrounding world</strong>, the relationships between its various parts and a person’s intuitive perception about his or her own acts and their consequences.</p></blockquote>



<p>Every problem and situation is just another ‘one of those’ — another one of a certain type.&nbsp;Figuring out what type it is and reflecting on principles for handling that type of issue will help you do a better job.</p>



<p>On the conscious level, mental models allow us to ‘fit’ different possible interpretations onto reality to see if it is ‘one of those’.</p>



<p>For example,&nbsp;according to&nbsp;<a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor" rel="noreferrer noopener" target="_blank">Hanlon’s Razor</a>&nbsp;one should&nbsp;“never attribute tomalice&nbsp;that which is adequately explained by carelessness”.&nbsp;When your coworker hands you crappy slides for the presentation you have to give in five minutes — what’s going on here?</p>



<p>Which ‘one of those’ do we have here?</p>



<p>You can see&nbsp;how different mental models in our heads will cause us to reach different conclusions about the correct interpretation of the situation.</p>



<p>A mental model is a mental, simplified&nbsp;depiction&nbsp;of how something works.They are how we order complexity, why we consider some things more relevant than others, and how we reason.&nbsp;They help us filter, organize and understand.</p>



<p>For instance, according to&nbsp;<a href="https://en.wikipedia.org/wiki/Pareto_distribution" rel="noreferrer noopener" target="_blank">Pareto distribution</a>,&nbsp;“for many events,&nbsp;roughly 80% of the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maartenvandoorn.nl/reading-guide/">https://maartenvandoorn.nl/reading-guide/</a></em></p>]]>
            </description>
            <link>https://maartenvandoorn.nl/reading-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302132</guid>
            <pubDate>Fri, 04 Dec 2020 13:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Google Analytics without GDPR consent]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25301500">thread link</a>) | @evrimfeyyaz
<br/>
December 4, 2020 | https://evrim.io/using-google-analytics-without-gdpr-consent/ | <a href="https://web.archive.org/web/*/https://evrim.io/using-google-analytics-without-gdpr-consent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://evrim.io/using-google-analytics-without-gdpr-consent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301500</guid>
            <pubDate>Fri, 04 Dec 2020 12:23:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Hacks of 2020]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25301346">thread link</a>) | @henrikwm
<br/>
December 4, 2020 | https://security.christmas/2020/4 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today we are going to explore five big hacks that took place in 2020. First we'll cover two hacks that targeted Norwegian companies Sykehuspartner and NHH. Then we'll take a look at a hack that targeted the Danish company ISS. To wrap things up we'll cover what is probably the two most high profile hacks of 2020: the Twitter phish and the CWT ransom.</p>
</section><article><section><h2>Sykehuspartner</h2>
<p><img src="https://i.ibb.co/hyMVdWh/Skjermbilde-2020-11-20-kl-07-30-21.png" alt="Sykehuspartner logo" title="Sykehuspartner"></p>
<p>Sykehuspartner deliver IT, HR, project and logistics services to all hospitals in the Norwegian health region Helse Sør-Øst (Health South East). It manages vital IT systems for the hospitals, both clinical and administrative applications, as well as infrastructure and networks.</p>
<p>On august 22 2020 several of Sykehuspartners applications became the target of an unknown malicious actor. Only one hospital (Sykehuset Innlandet) was targeted in this attack. Not much is known by the type and scope of the attack, except for what type of data might possibly have been stolen. The potentially stolen data might include:</p>
<ul>
<li>Information about the deceased</li>
<li>Health information about patients from research projects</li>
<li>Personal information about employees</li>
<li>Name and social security number (fødselsnummer) of students</li>
</ul>
<p>From reports about the incident, we know that 25 patients and several employees have been notified of personal information having been stolen. Following the attack, the hospital has carried out a forced password change for all employees.</p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://sykehuspartner.no/nyheter/dataangrep-mot-sykehuset-innlandet-hf">Sykehuspartner announcing attack</a></li>
<li><a href="https://sykehuspartner.no/nyheter/analysearbeidet-etter-dataangrepet-mot-sykehuset-innlandet-er-avsluttet">Sykehuspartners analysis of attack</a></li>
</ul>
<h2>NHH</h2>
<p><img src="https://i.ibb.co/sjQnhNF/imageedit-10-3684463812.png" alt="NHH logo" title="NHH logo"></p>
<p>In august this year, Norges handelshøgskole (NHH, English: Norwegian School of Economics), experienced a data heist. The school is one of the leading business schools in Europe and is located in the city of Bergen. </p>
<p>Usernames and passwords of both students and employees was compromised. The break in was discovered when the stolen credentials were uploaded to a “hacker” forum. The attack targeted a known vulnerability in an old version of the VPN service called Pulse Secure. An updated version that patches this vulnerability has been available since April 2019. But NHH is decommissioning the service and has thus been neglecting to update it. All students and employees were asked to change their passwords after the incident.</p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://www.dn.no/utdannelse/nhh/datakriminalitet/nhh-oppdaterte-ikke-sikkerhetshull-kjent-siden-april-2019-na-er-handelshoyskolen-rammet-av-internasjonalt-dataangrep/2-1-853329">Norwegian news article about NHH attack</a></li>
</ul>
<h2>ISS</h2>
<p><img src="https://i.ibb.co/XDJVmgQ/imageedit-12-3910494650.png" alt="ISS logo" title="ISS logo"></p>
<p>In the middle of February this year, ISS was hit by a ransomware attack. ISS is a global facility services company, founded in Copenhagen, Denmark. The company has 450,000 employees.</p>
<p>The ransomware was a massive malware attack across IT-systems and networks. Immediately after the attack was discovered, IT-access was removed to isolate the indicent. As reported by the company. Regardless of the actions taken, the company had to write down and change big parts of the IT-infrastructure. It is estimated that the attack will cost the company between 750 and 1340 million Norwegian kroner (NOK).</p>
<p>It was reported that customer data was not stolen.</p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://www.digi.no/artikler/dansk-servicegigant-rammet-etter-skadevareangrep/485762">Norwegian news article about ISS attack</a></li>
<li><a href="https://www.digi.no/artikler/iss-venter-milliardsmell-etter-cyberangrepet-i-februar/488264">Norwegian news article about aftermath of ISS attack</a></li>
</ul>
<h2>Twitter</h2>
<p>Twitter, you know, the social media platform? Yes, that one. In July this year, it was hit with a phishing campaign that was used to target high-profile individuals, like Barack Obama, Joe Biden and Bill Gates.</p>
<p>Twitter stated that "This attack relied on a significant and concerted attempt to mislead certain employees and exploit human vulnerabilities to gain access to our internal systems".</p>
<p>The phish was used to get access to certain high-profile accounts. The compromised accounts were used to promote a bitcoin scam.</p>
<p><img src="https://i.ibb.co/sPXDZK7/external-content-duckduckgo-com.png" alt="Tweets from Joe Biden and Barack Obama promoting a bitcoin scam" title="Biden and Obamas twitter profiles were hacked to promote a bitcoin scam"></p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://edition.cnn.com/2020/07/15/tech/twitter-hack-elon-musk-bill-gates/index.html">News article about Twitter hack</a></li>
<li><a href="https://edition.cnn.com/2020/07/30/tech/twitter-hack-update/index.html">News article about Twitter hack - two weeks later</a></li>
</ul>
<h2>CWT</h2>
<p>CWT is a travel management company that manages business travel, meetings and so on. The 27 of July this year, the company was hit by a massive ransomware attack that knocked 30,000 computers offline. The hackers claimed to have stolen two terabytes of files, including financial reports, security documents and employees’ personal data. CWT paid $4.5 million to the hackers to restore their systems. </p>
<p>One of the fascinating things about this hack was that the negotiation chat, where the company and the hackers met to talk, was left open to the public after the negotiations ended. This gives us a never before seen insight into how the negotiations between hacker and hacked works. As many others have noted after the chat became public, it is rarely advised to actually pay the hackers like CWT did. This is, of course, because of the precedence it sets and that the chance of getting scamed is very high.</p>
<p><img src="https://i.ibb.co/QC7f7MJ/cwt-chat.jpg" alt="Screenshot of chat between hackers and CWT" title="Screenshot of the negotiation chat between hackers and CWT"></p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://www.reuters.com/article/us-cyber-cwt-ransom-idUSKCN24W25W">News article about CWT attack</a></li>
</ul>

<p>This is of course not a complete list of all the major hacks that were reported in 2020. It sure has been a very active year in this regard. As you can see, there are many ways of being vulnerable on the internet. If you want to better understand how to prevent some of these things happening to you, take a look at the previous three posts:</p>
<ol>
<li><a href="https://security.christmas/2020/1">Application security check list</a></li>
<li><a href="https://security.christmas/2020/2">Github Security: Getting started with Dependabot</a></li>
<li><a href="https://security.christmas/2020/3">How secure is your build pipeline?</a></li>
</ol>
<p>Also, be sure to follow this advent calendar for even more articles leading up to Christmas day!</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301346</guid>
            <pubDate>Fri, 04 Dec 2020 11:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Sea Turtles Find Their Way]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25301247">thread link</a>) | @dnetesn
<br/>
December 4, 2020 | http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>T</span>he air was warm as the skies grew dark over Diego Garcia. As the nearly full moon reached its highest point, a green sea turtle scuttled her way onto the sand. The ocean giant was more than a meter wide and nearly as long from nose to tail. Her carapace, mottled with splotches of green and black, was slick with salt water.&nbsp;</p>

<p>Turtles glide through the sea with a certain reptilian elegance, but on land their awkward, plodding movements evoke a wind-up toy in need of a few more cranks. After shuffling a suitable distance from the waterline, the turtle began to excavate a shallow hole, using her arms and legs like spades to fling pebbles and sand through the air. Nearly exhausted, she finally began to relax as she released dozens of ping-pong ball-sized eggs into the ground.</p>
<p>It was likely the first time in years sheâ€™d set flipper on dry land. Other than the moments after they hatch and crawl into the surf, sea turtles spend their entire lives in the ocean. Only when females return to lay eggs on the same beaches where they hatched do they leave the water—just briefly, for a few hours, before slipping back into the sea. They may lay several clutches of eggs during the mating season before setting off for their foraging territories. There they stay for several years, regaining energy by feasting on seagrass, before returning to their natal beach, mating just offshore, and beginning the cycle anew.</p>
<p>Having carried out the full extent of her duties as a mother, this turtle had completed a ritual thatâ€™s played out countless times on Diego Garcia, a footprint-shaped atoll in the Indian Ocean's Chagos Archipelago. Green sea turtles have used the atoll as an incubator for hundreds or thousands of generations, or perhaps longer. Each generation disperses and returns; precisely where these now-endangered reptiles go, what route they take to get there, and how they navigate, is a mystery.</p>
<p>And so on that moonlit night in October of 2017 volunteers from the U.S. military facility on Diego Garcia helped <a href="https://www.swansea.ac.uk/staff/science/biosciences/esteban-n/" target="_blank">Nicole Esteban</a>, a marine biologist and sea turtle conservationist at Swansea University, fasten a GPS transmitter to the top of the turtle's shell while she laid her eggs. The volunteers nicknamed the turtle Serenity and watched as she and the computer on her back crept back into the waves and disappeared.</p>
<p>Three months later, Serenity reached her foraging waters along a small island called Farquhar Atoll in the Seychelles archipelago. It is some four thousand kilometers west of Diego Garcia, but the GPS signals traced a circuitous route that wound through more than six thousand kilometers of open ocean. Had she had taken a more direct path, she could have accomplished the entire journey in under a month.</p>
<blockquote>Precisely where these now-endangered reptiles go, what route they take to get there, and how they navigate, is a mystery.</blockquote>
<p>It was an unusual trip in other ways, too. Typically when biologists track turtles from their nesting beaches on small islands, most wind up in coastal territory, having paddled across the open ocean until hitting a continental shelf and then turning left or right. But Serenity ended up on a flyspeck island, and many others of her cohort—Estebanâ€™s team tagged a total of 35 turtles over five years—followed suit.</p>
<p>"A number of these turtles migrated to very, very small island targets, some not more than a couple of hundred meters square,â€� says Alex Rattray, a biologist at Deakin University who was also involved in the research. A few did travel more than 5000 kilometers west to the coastlines of Somalia and Mozambique, but others pulled up short of the coast, joining Serenity elsewhere in the Seychelles archipelago; still others swam north to the Maldives islands.</p>
<p>Their destinations underscored the extraordinary nature of sea turtle migration. Itâ€™s astonishing enough that a sea turtle can navigate across thousands of miles of open ocean, with no discernible landmarks, and wind up in the correct place. Even more astonishing is when the correct place is a dot of sand with nothing but blue until the horizon in every direction.</p>
<p>It's a feat that bewildered Charles Darwin. "Even if we grant to animals a sense of the points of the compass, of which there is no evidence," he wrote, "how can we account, for instance, for the turtles which formerly congregated in multitudes, only at one season of the year, on the shores of the Isle of Ascension, finding their way to that speck of land in the midst of the great Atlantic Ocean."</p>
<p>Since Darwin wrote those words in 1873, scientists have tried to understand just how turtles make these awesome journeys. Before the invention of GPS technology, sailors crossing the globe relied on a combination of complex mechanical instruments and accurate timepieces. Much remains unknown about how turtles accomplish the same task, the only tools at their disposal resting within their own brains and bodies—but biologists have come a long way in understanding how sea turtles find their way.</p>
<center>
<iframe width="733" height="412" src="https://player.vimeo.com/video/486666840?color=ffcd05&amp;title=0&amp;byline=0&amp;portrait=0" frameborder="0" allowfullscreen=""></iframe>
</center>
<p>The animated travel tracks of 35 green sea turtle migrations tracked from nesting beaches in the Chagos archipelago. Hays et al./<em>Current Biology</em></p>

<p><span>I</span>n the first month after slipping off the beaches of Diego Garcia, Serenity had logged nearly four thousand kilometers. She was still in the open ocean, north and a little east of Madagascar. Rattray wouldn't know it yet, but when he switched his computer on to check on her progress, he would find Serenity at almost precisely the longitude of her final destination in <a href="https://en.wikipedia.org/wiki/Farquhar_Atoll" target="_blank">Farquhar Atoll</a>. There was just one problem: was she was at the wrong latitude.</p>
<p>The turtle had missed her target by some two hundred kilometers. That would be like walking from New York City to Los Angeles, but accidentally winding up in Tijuana, Mexico instead. But rather than take a right turn and swim north, she kept heading west, further and further away from her goal.</p>
<p>So how did she get back on course?</p>
<p>Whether you're a sea turtle or a ship's captain, finding your way around the planet requires two tools: a map and a compass. A map tells you where you are relative to some other location: where you started out, for example, or where you want to go. A compass helps to keep you moving in a reasonably straight line.</p>
<p>"There's all sorts of ways to set and maintain a heading," says marine biologist <a href="https://lgl.com/en/staff/staff-directory/179-putman-nathan" target="_blank">Nathan Putman</a>, who studies navigation in sea turtles and salmon. Animals who have good vision can orient based on the polarization of sun light, as some birds are thought to do, or based on the position of stars in the night sky, as in dung beetles. If animals can marry their vision to an internal clock, then they can use the sun's position as a compass, accounting for its movement across the sky throughout the day. It's thought that a time-compensated sun compass, as it is called, is one of the tools that migrating monarch butterflies use to maintain their headings.</p>
<p>Other animals might orient based on the direction that persistent winds blow or the direction waves travel through the ocean. Indeed, when loggerhead sea turtles first hatch on Florida beaches, they know to swim directly into oncoming waves, a strategy that deposits them into the Gulf Stream, part of a larger network of currents called the North Atlantic Sub-tropical Gyre. These currents, which stretch from the eastern seaboard across to southern Europe and northern Africa, encircle a region known as the Sargasso Sea. By staying within the gyre, vulnerable young sea turtles can remain relatively safe.</p>
<p>In 1989 a meteorological fluke helped Ken Lohmann, a biologist at the University of North Carolina at Chapel Hill, confirm that hatchlings use waves as a guide. That year, Hurricane Hugo temporarily caused waves to travel towards the open ocean rather than towards Florida's Atlantic coast. When Lohmann dropped newly hatched turtles into these conditions, they swam into the waves, just as their innate programming instructed them to—and as a result, they went the wrong way.</p>
<p>But what if turtles were to hatch on a calm, windless night with no waves to point the way? Lohmann brought hatchlings into a laboratory to find out. In complete darkness and with no other cues available to guide them, they swam towards the northeast, which in their natural environs would have safely launched them into the Gulf Stream. When he then induced an artificial magnetic field around the tanks, the turtles continued in what they thought was a northeasterly direction. In reality, thanks to Lohmann's magnetic misdirection, they were swimming in precisely the opposite direction. The results confirmed that they really did use Earth's magnetic field.</p>
<blockquote>Sea turtles hatch with at least two strategies for finding their way pre-programmed into their brains: the movement of waves and the Earth's magnetic field.</blockquote>

<p>Taken together, Lohmannâ€™s experiments revealed that sea turtles hatch with at least two strategies for finding their way pre-programmed into their brains: the movement of waves and the Earth's magnetic field.</p>
<p>Currents around Diego Garcia are of course different from those off the Florida coast. Turtles born in Diego Garcia are delivered into the South Equatorial Current, which is part of a larger system called the Indian Ocean Gyre. The parameters of Earth's magnetic field differ as well. But the underlying principle remains the same: turtles are born with a set of instructions that, at least most of the time, safely delivers them into the open ocean.</p>
<p>"Offshore migration is really just the first part in a longer transoceanic migration,â€� says Lohmann, one that occupies the first five to eight years of a sea turtleâ€™s life—a period sometimes called â€œthe lost years,â€� spent in the open ocean, where sea turtles were once thought to lazily drift wherever the currents took them. But Lohmann realized that this strategy could be deadly.&nbsp;</p>
<p>If turtles in Florida floated passively on the North Atlantic Sub-tropical Gyre, for example, then after they cross the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way">http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301247</guid>
            <pubDate>Fri, 04 Dec 2020 11:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wikipedia's in Trouble (2019)]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 86 (<a href="https://news.ycombinator.com/item?id=25300942">thread link</a>) | @sanqui
<br/>
December 4, 2020 | http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
I got involved in wikipedia <a href="https://en.wikipedia.org/w/index.php?title=User%3ASpencerk&amp;action=history&amp;year=2006&amp;month=-1&amp;tagfilter=">very early</a>.

It was one of the most revealing things in my life, watching it being laughed at, to become the center of, and authority of, human knowledge.

It was obvious that it was working. The lag of this was 5 years or more.

Wikipedia was an experiment that proved itself, when every graph was going up and to the right.

Some of the graphs are now going down.

</p><p>Wikipedia's Markup language:</p><p>
One of the central design decisions in wikipedia is that <span>all information</span> is stored in an editable document.
This poses a huge amount of challenges for caching and scaling wikipedia. It's not a database, that you can run a script on.

Worse though, is that all of it's content is buried in this ad-hoc, impenetrable, opaque, and mostly <i>un-parsable</i> format.

If wikipedia had used <i>markdown</i>, <i>html</i>, or some <i>standardised format</i>, any parser would flip-it into other future formats.

Wikipedia's custom language is just <a href="https://github.com/spencermountain/wtf_wikipedia/blob/master/README.md">clearly insane</a>, undocumented, hopeless.
There's a team <span>(of great people!)</span> at wikimedia <a href="https://phabricator.wikimedia.org/tag/parsoid/">constantly working on it</a>, and unable to make any backwards-incompatible changes. I imagine their lives are hard.
People are creating weird new syntax concepts all the time.

Here's the markup for the <b>first sentence</b> of the Albert Einstein wikipedia article:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/albert-einstein.jpg">

The first wikimedia parser was called <a href="https://github.com/earwig/mwparserfromhell/">mwparserfromhell</a>. DBPedia, <a href="https://upload.wikimedia.org/wikipedia/commons/a/a9/LOD_Cloud_2014-08.svg">the center of the semantic web</a>, after years of work, has only ever offered limited parsing from categories and infoboxes.
Much of the early-years at <b>Freebase</b> were spent trying, with limited-success, at parsing wikipedia.
I've spent <a href="https://github.com/spencermountain/wtf_wikipedia/graphs/commit-activity">years</a> trying to parse it myself.
I'm a shitty programmer. <i>WolframAlpha</i>, and many other serious companies are using my parser,
       which is <span>down right hilarious</span>.

<img id="rtl" src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/rtl.jpg"></p><p>yes, arabic editors must write it in right-to-left, <a href="https://youtu.be/OCQd02hORJQ">somehow</a>.</p><p>

It's hard to describe how much of a serious problem this is.
Wikipedia's content is never going to go anywhere, or be used by anything.

Wikipedia may slowly die-off - like myspace, or geocities - but it's information will not go on.

Play-around in the official wikipedia android app. Many pages are unreadable.
There is a good-deal of <i>clearfix</i>, and <span>table-span</span> logic, mushed right into the syntax.
Most developers will not touch this kind of stuff.

There will be no move to a wikipedia 2.

</p><p>Static copies of dynamic content</p><p>
The contents of the english wikipedia dump are as follows, (as of Jan 2019):
</p><p>
of the <b>14m</b> records in the wikipedia dump, only <b>5.5m</b> (40%) are public-facing articles.

   <span>Yup.</span>
This does not include deleted pages, or old versions, either.


<b>Redirects:</b>
A computer-science 101 problem is to implement a fuzzy string matching. There's usually a section in the textbook about it:
</p><div>
<p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/clr.jpg"></p><p>oh yes, right here in chapter 34.</p><p>
there are <b>8,550,441</b> redirects in wikipedia.
They are mostly typos, or case-changes, and are mostly created by hand, every day.

<span>and what happens to a redirect when a page gets deleted, or merged, or spli - <a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot">Yup</a>.</span>
</p></div>

<p><b>Talk pages:</b>
Wikipedia has 35m registered users. When a user joins, a bot will often send them a <a href="https://en.wikipedia.org/wiki/Template:Welcome">{{welcome}}</a> template.
Sometimes nice users will do it themselves. It looks <a href="https://en.wikipedia.org/wiki/User_talk:Kj_aviator">like this</a>.

   - when this happens, this creates a new user page, with <b>a copy of this text</b> each time.

There are millions of examples of this in the dump. The same text, verbatim over and over.

The same process happens with <b>'Wikiprojects'</b>. Bots go around adding templates, by creating a talk page, and adding a template to it.

The same process happens with <i>deleted pages, fair-use warnings, and some bot edits</i>. Each time an edit happens, a new page is created, and boilerplate text gets thrown into it.
Resulting in <a href="https://en.wikipedia.org/wiki/Talk:XTC_discography">this</a>:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/boilerplate.png"></p><hr><p>
So let's get things straight:
in <b>1993</b>, a small japanese game company created <a href="https://en.wikipedia.org/wiki/A-Rank_Thunder_Tanjouhen">this videogame</a>:
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/thunder.jpg">
</p><p>
• In <b>2008</b>, a wikipedia user created the article with <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">two sentences and a link</a>.

• In the past 10 years since, the page has been edited <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">26 times by bots</a>.

• this created a Talk page filled with <a href="https://en.wikipedia.org/wiki/Talk:A-Rank_Thunder_Tanjouhen">11 automated sentences</a>.

A huge bulk of the wikipedia database is this boilerplate text. See <a href="https://en.wikipedia.org/wiki/Talk:764_Gedania">this asteroid</a>, <a href="https://en.wikipedia.org/wiki/Talk:NS3_(HCV)">this virus</a>, or this <a href="https://en.wikipedia.org/wiki/Talk:Oceania_Judo_Union">judo club</a>.

... and remember, if we wanted to change this text, we'd have to go and edit each of these pages - and because this syntax is so nuts, <b>bots have a hard time</b> making even simple stylistic changes, without ruining a whole page.

oh, so what happens to these auto-generated talk pages when a page is deleted, merged, or spli- <a href="https://en.wikipedia.org/wiki/Talk:578_Happelia">yup</a>

<b id="automation">Automated articles:</b>
There is a lot of disagreement about how much of wikipedia is generated by bots, and if this matters.
There's no way of knowing. Any boring-themed article with a few sentences, a reference, and an infobox probably won't get deleted.
So nothing's stopping you from spitting-out articles from a <b>database of enzymes</b>, or <b>college rugby players</b>, or season statistics for defunct sports teams.
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/enzymes.jpg">
  <img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/subgiants.png">
</p><p>
I have nothing against bots, I have nothing against the long-tail, but I think automated article-creation is responsible for a good amount of the wikipedia's claimed growth, over the past few years.
We need to be up-front about this, if we're talking about the health of the project.

Here's the distribution of words in english wikipedia, by the size of articles:
</p>

<div>
<p><span>ok hey,</span> I don't mind that the wm developers didn't develop a fancy search index, in 2001.
That's fine.
Nobody could have predicted the success and scale of wikipedia early on.
</p><p>
What angers me though
         - <i>and it should anger you</i> -
is that these problems has not been fixed in the <b>18 years</b> since.

God damn them.

Well-meaning people are wasting their time on this <span>everyday</span>.

Any <i>startup job-interview</i> asks questions about implementing a system like this.
Any CS grad can create a lucene index, to handle typos.
Some of it is complicated. Some of it is basic competence.

<span>It's annoying to whine</span>,
     but at some point, we're right to be angry at wikipedia.

            that it cannot find 2nd gear,
     when the rest of the world is zipping-along.
</p>
</div>

<p>Wikidata</p><p>
In 2007 Danny Hillis raised $57 million dollars,<a href="https://www.crunchbase.com/organization/metawebtechnologies#section-overview">[1]</a> bought-out the <b>entire</b> MIT semantic-web group,
hired 50~ employees, (including <a href="https://www.apple.com/leadership/john-giannandrea/">this person</a>, <a href="https://www.amazon.com/Toby-Segaran/e/B001I9RQVS">this person</a>, <a href="http://davidhuynh.net/">this person</a>) and got an office in the mission.

They reconciled all of wikipedia, the entire musicbrainz database, the entire open-library database, the tvdb database, and all of wordnet.
They signed a (massive) deal to import <b>all collections of the stanford library</b>.<a href="https://www.clir.org/pubs/reports/pub152/stanford-linked-data-workshop/">[2]</a>

They hit <b>high-90%</b> classification of all <a href="https://research.google.com/pubs/archive/44818.pdf"><b>50 million</b></a> entities (wikipedia has 5m)
They were evaluated at very-high 90's accuracy by several third-parties.

Facebook, Bing, Amazon, and Google all began using its data in nearly real-time in their search products.

This was one of the largest and most ambitious software projects in history.

In 2010 freebase was bought for a whack of money, and then killed-off by google.
When google announced they would be shutting down the API, they offered to import all of this data to a new wikimedia project called <span>wikidata</span>.

Wikidata was 4-or-5 Lua developers, in Germany, on a few research grants.

</p><p>and they said no. 😐</p><p>

so they said this data didn't meet it's guidelines regarding sourced data.

    <i>... aren't you pulling information <b>from wikipedia</b> blindly?</i>

    <i>... what about your (~60%) unreferenced facts?</i>

    <i>... aren't you <b>multiplying vandalism</b> from multi-lingual wikipedias?</i>

    <i>... how do you use, or verify references?</i>

They built a tool to <b>hand-transfer each freebase fact</b>, which if you have a calculator, may seem funny.
<span>(at 10 people clicking full-time, would have taken 10 million years)</span>

8 years later, <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a> remains tiny, buggy, unused, and worse - <i>majority unreferenced</i>.
I mean, they're pulling their data from wikipedia, which gets vandalized almost every minute!

It's accomplished very-little from its 5-year plan. They write academic papers.
They still don't really offer a rest api.
       ...creating new types or properties is I think, possible? or it's supposed to be...

It's got few of the safeguards, momentum, features, and ambition that Freebase had a full decade ago.
If wikidata was a company, it would not exist anymore, and you wouldn't have heard of it.

But Wikimedia places <b>banner-ads</b> on <span>hours of eye-blistering user-created content</span>,
begging children, students, and poor-people for money.
and they choose to be this petty, pithy and behind-the-times.

</p><p>Category-system</p><p>
It's a beautiful idea, to classify information with category-scheme, <a href="https://humane.computer/review-the-science-of-managing-our-digital-stuff/">until it falls-apart</a>.

<a href="http://www.shirky.com/writings/ontology_overrated.html"><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/shirky-category.jpg"></a>
Wikipedia has many-thousands of categories. They <a href="https://en.wikipedia.org/wiki/Wikipedia:Dump_reports/Category_cycles">loop-around</a> all-over the place.

</p><p>
People:
    → Musicians
        → Singers
              → American_Idol
                  → Books_about_American_Idol
</p><p>
or worse:
</p><p><span>Albanian language</span>:
    → Albanian-speaking countries and territories
      → Kosovo (region)
        → Kosovo
          → Kosovar society
            → Languages of Kosovo
              → <span>Albanian language</span>
</p><p>
if you're ever too-cheerful, and wanting to feel depressed, have a visit <a href="https://en.wikipedia.org/wiki/Wikipedia:Categories_for_discussion/Log/Today">Categories for deletion/Today</a>,
where you'll see precious human-life spent debating whether <b>'Category:Goth'</b> should exist, if it is a genre of music, if it's is a fashion-style, etc.

Work is being ravenously deleted all the time. You'll get sad thinking about it.

</p><p>Templates</p>
<div>
  <p>what about all this stuff →</p>
  <p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/infobox.png">
</p></div><p>
You're right.

Wikipedia has good structured-data in <b>infoboxes, lists, tables, citations, etc</b>.

The issue is, as of Feb 2019, Wikipedia has <b>634,755 different kinds of templates</b> (see this <a href="https://s3-us-west-1.amazonaws.com/spencer-scratch/allTemplates-2018-10-26.tsv">21mb download</a>).

Yes, there are all different.

Yes, there are <span>templates-within-templates-with-escaping-with-escaping</span>.

Even if you parse them perfectly, how do you know that for <a href="https://en.wikipedia.org/wiki/Template:HorseDeathYear">Template:HorseDeathYear</a>, the third parameter is the <b>birth date of the horse</b>, and the fourth is the birth-month?

see, for example:

• <a href="https://en.wikipedia.org/wiki/Category:16-Team_bracket_templates">Tennis Brackets vs Table Tennis Brackets</a>

• '<a href="https://en.wikipedia.org/wiki/Template:Birth_date_and_age">Birth_date_and_age</a>' vs '<a href="https://en.wikipedia.org/wiki/Template:Birth-date_and_age">Birth-date_and_age</a>'.

• <a href="https://en.wikipedia.org/wiki/Template:Trapezoidnotation">a template for a Trapezoid unicode symbol</a>
It's just a straight-up mess.

If you're thinking, <i>gee wikipedia editors must feel exhausted and stupid</i> - you're right.

<a href="https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Template:Retired&amp;limit=500">Many</a>…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</a></em></p>]]>
            </description>
            <link>http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300942</guid>
            <pubDate>Fri, 04 Dec 2020 10:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made 24 high-quality Covid illustrations. Free for commercial and personal use]]>
            </title>
            <description>
<![CDATA[
Score 317 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25300594">thread link</a>) | @andyydao
<br/>
December 4, 2020 | https://www.pixeltrue.com/frontliner-heroes | <a href="https://web.archive.org/web/*/https://www.pixeltrue.com/frontliner-heroes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
<div data-collapse="small" data-animation="default" data-duration="400" role="banner"><div data-w-id="829bd4f8-a52c-9bed-f351-1f1c429ebfb2"><p><a href="#" id="w-node-1f1c429ebfb3-a3ea6df0"><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859794cc27d27_COVID%20Logo.svg" loading="lazy" alt=""></a></p><div id="w-node-1f1c429ebfb6-a3ea6df0"><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 1439px) 20px, (max-width: 1919px) 25px, 30px" srcset="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-500.png 500w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-800.png 800w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-1080.png 1080w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png 1214w" alt=""></p></div></div></div><div><div data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1b"><p data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1c">Frontliner Heroes</p><p>24 high-quality Covid illustrations. Free for commercial and personal use.</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c6728188179a7570d_Hero%20Illustration.svg" loading="eager" width="462" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c20" alt=""><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c672818d125a7570c_Background.svg" loading="lazy" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c21" alt=""></p></div><div><div><div><div><p>Frontliner Heroes comes with exciting scenes that are commonly used to stop the spread of COVID. In addition, we'll be continually adding new illustration to this pack!</p></div></div></div></div><div><p><h2>24 Illustrations to fight against COVID!</h2></p></div><div><div><h2>Sample Applications</h2><p>These illustrations are perfect for any type of project. Simply Drag and drop them in and you're ready to go!</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b4456b3fd49b0f42063_Sample%20Applications.svg" loading="eager" alt=""></p></div><div><p><h2>Awesome Features</h2></p><div id="benefits"><div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410cacea1ebe4_Group%2084.png" alt=""></p><div><h3>Fully Vector<br></h3><p>All illustrations are fully vector meaning you can enlarge illustrations without quality loss<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe94105ee6a1ebe8_Group%20174.svg" alt=""></p><div><h3>Customizable<br></h3><p>Easily change illustration scenes to match your brand using common programs like Sketch and Figma.<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410876ca1ebe6_Group%20148.png" alt=""></p><div><h3>Different File Formats<br></h3><p>With our Frontliners pack you'll get access to all source files - this includes SVG, PNG&nbsp;and AI&nbsp;files.<br></p></div></div></div></div></div><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->


<!-- Hotjar Tracking Code for www.pixeltrue.com -->






<!-- Memberstack --> 
 








<meta name="p:domain_verify" content="efd5329f8b1be336c6381d60a312999c">



<!-- Facebook Pixel Code -->


<!-- End Facebook Pixel Code -->


<!-- Global site tag (gtag.js) - Google Analytics -->














</div>]]>
            </description>
            <link>https://www.pixeltrue.com/frontliner-heroes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300594</guid>
            <pubDate>Fri, 04 Dec 2020 09:40:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I cannot convince Twitter that I am human]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25300445">thread link</a>) | @gregdoesit
<br/>
December 4, 2020 | https://www.swyx.io/proving-our-humanity/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/proving-our-humanity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you swung by my Twitter profile in the last week, you probably saw this:</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/olflh5jfvk5clb15p5z9.png" alt="Alt Text">
</p>
<p>I'm not sure of the precise causes of me being locked out, but I have several abnormal usage factors that probably put me on the high end of Twitter's bot risk system:</p>
<ul>
  <li>I currently live in Singapore but am primarily active during US hours and have a US Phone Number</li>
  <li>I post about 30 tweets a day, probably on the high end of most Twitter users. (30 sounds like a lot, but it's mostly replies, and I maybe post 2-3 actual top tweets a day)</li>
  <li>I switch between and manage three different accounts (<a href="https://twitter.com/Coding_Career">Coding Career</a> and <a href="https://twitter.com/SvelteSociety">Svelte Society</a>) multiple times a day</li>
  <li>As far as I know I have not been reported on, but I do have people that strongly dislike me and they may have used the report button against me. Can't rule that out as a factor.</li>
  <li>Anecdotally <a href="https://twitter.com/b2m9/status/1295748479713779712?s=20">some IPs seem more risky</a> than others - I also use a VPN for work which probably shows me jumping across multiple countries in a single day, which is certainly suspicious on the face of it</li>
  <li>I have also noticed I get verification checks more often when I use scheduled tweets.</li>
</ul>
<p>If you clicked through my scary profile you also saw this:</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/6xjg8jxiwgidwffvwsnu.png" alt="Alt Text">
</p>
<p>I swear that I haven't mass unfollowed everybody! Most people see this and assume that I used some script to mass unfollow everyone and therefore got flagged as a bot. <strong>The reality is the exact opposite</strong> - I got flagged as a bot, and by default Twitter temporarily removes all follows.</p>
<p>It will be restored once I regain my Twitter account (I've filed a support ticket and am trying to reach out to friends at Twitter for help), but this is the exact user experience I wanted to talk about for this post.</p>
<p>First, a quick detour for a personal anecdote.</p>
<section>
  <h2 id="aside-my-time-as-a-cuban-detainee"><a href="#aside-my-time-as-a-cuban-detainee">Aside: My Time As A Cuban Detainee</a></h2>
  <p>A long time ago I visited Havana with some college friends. Right after landing we headed into a restaurant, all our luggage in tow. After we were done eating, I stood up and turned around - only to find all my luggage gone! Someone had stolen it while we were eating. The restaurant staff of course swore up and down that they had not seen who had taken it.</p>
  <p>Losing all your luggage on day 1 of a weeklong trip sucks, but what is worse is that <strong>my passport was in my luggage</strong>. I needed it to head back to the US at the end of my trip.</p>
  <p>If you've never lost a passport while traveling before, it's a quick trip to bureaucratic hell. If your country has an embassy where you are traveling, you can usually get it reissued in the embassy. But we were in <em>Cuba</em> - and my country had no embassy here. We reported my case to the authorities, but they had no idea what to do. I was an edge case. Worse still, because I said I had come from the US and couldn't produce any papers to prove my identity, I was detained at the police headquarters for questioning on suspicion of being a spy. (<em>I was never really at any risk - being Asian and speaking poor Spanish, I would have made for a pretty lousy spy</em>).</p>
  <p>There was a lot to figure out over the ensuing <em>month</em> of my ordeal - money, lodging, language barriers, administrative hurdles. My family and friends hit the panic button for me and my case reached the ears of both Arlen Specter on the US Senate Foreign Relations Committee and George Yeo, the Singapore Foreign Affairs Minister. We eventually worked it out, but every night for 4 weeks I would wander up and down <a href="https://en.wikipedia.org/wiki/Malec%C3%B3n,_Havana">the Malecón</a>, listening to the crashing waves, not knowing when I could ever leave the country. If I could swim <a href="https://en.wikipedia.org/wiki/Southernmost_point_buoy">the 90 miles to Key West</a> and <a href="https://en.wikipedia.org/wiki/Wet_feet,_dry_feet_policy">dry my feet</a>, I might theoretically make it back to the US on my own.</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/3i8nh2cgaoj3jlrl9ecm.jpg" alt="Alt Text">
  </p>
  <p>But most of all, I thought a lot about <strong>the humanity of having a piece of paper be more important than the human it represents</strong>. I could be physically standing in front of the immigration officer with a lie detector test on and steadfastly stating all manner of provable personal detail, and they would not let me through unless I had a small piece of paper the size of my hand.</p>
  <p>We do this a lot - passports, voter registration cards, national ID systems, licenses, and insurance proofs - mostly because some humans are untrustworthy and try to exploit the system.</p>
  <p>But we often fail to design for people who are innocent and simply don't fit the system in some way.</p>
</section>
<section>
  <h2 id="the-consequences-of-not-being-provably-human"><a href="#the-consequences-of-not-being-provably-human">The Consequences of Not Being Provably Human</a></h2>
  <p>Twitter has a way in which they expect you to verify you are human - you should get a call or text message with a code, that you then enter to prove humanity. This is what I normally get (about once every 1-2 months), and I can receive text messages from Twitter, so I can usually prove humanity with no issue.</p>
  <p>This time, for some reason, I am on a code path that doesn't offer a text message option, and Twitter somehow doesn't make international US number calls, leading to this infinite loop that I think is a bug:</p>
  
  <p>As a result of this unfortunate design:</p>
  <ul>
    <li>My friends think I mass unfollowed them, because Twitter temporarily reduced my follow count to 0</li>
    <li>People who DM me think I am ignoring them, because Twitter doesn't inform them that I am currently locked out</li>
    <li>None of my past tweets show up at all in <a href="https://twitter.com/search?q=from%3Aswyx&amp;src=typed_query">Twitter search</a>, which is problematic because I <a href="https://twitter.com/swyx/status/1245281982797373441?lang=en">use Twitter as a Second Brain</a>. If you read any of my blogposts, you will see that the rich link density of my references mainly come from taking notes in public over an extended period of time.</li>
    <li>I was unable to engage in the normal personal and professional activity I would do during Black Friday and AWS Re:invent</li>
  </ul>
  <p>I've filed a support ticket with Twitter, but you can imagine that support for a 330 million user service isn't very responsive. People who have been through this tell me the only way to resolve it is to hit up a Twitter employee to get past the masses of unrelated and less urgent support issues.</p>
</section>
<section>
  <h2 id="humans-proving-humanity-to-machines"><a href="#humans-proving-humanity-to-machines">Humans Proving Humanity To Machines</a></h2>
  <p>In the grand scheme of things, I know this is minor. I've actually taken it as a welcome social media detox, which I usually take voluntarily in December anyways. But when it's not on my terms, I lose the ability to manage the personal and professional relationships I've painstakingly built up over the past 3-4 years.</p>
  <p>Above all, I think there's an <em>indignity</em> in humans having to prove to machines that they are human, and the error resolution mechanism is to send a ticket to a faceless and unresponsive support email, and the only real way to get around it is again to re-establish human connections.</p>
  <p>I think more about all the other ways that we as software developers and designers fail to honor the dignity of humans trying to interact with the systems we create.</p>
  <p><a href="https://www.theverge.com/2019/2/1/18205610/google-captcha-ai-robot-human-difficult-artificial-intelligence">In 2014</a>, Google pitted one of its machine learning algorithms against humans in solving the most distorted text CAPTCHAs: the computer got the test right 99.8 percent of the time, while the humans got a mere 33 percent. It doesn't impact everyone equally - if you as a sighted, able bodied user struggle with CAPTCHAs, imagine the elderly or differently abled. Most services do not offer any alternative resolution when you cannot prove you are human. This is a problem when your service has essentially killed off the offline alternative and is essential for their basic needs.</p>
  <p>In Eric Meyer's <a href="https://meyerweb.com/eric/thoughts/2016/01/25/designing-for-crisis-design-for-real-life/">Designing for Crisis</a>, he describes how an inaccessible hospital website nearly risked the life of his daughter. I shudder to think how it might be made worse by perfectly well meaning software engineers who don't think about the humanity of the failure path. Imagine if you had to log in to something to save your child's life, and it presented you with a CAPTCHA you couldn't pass.</p>
  <hr>
  <p><em>Update: <a href="https://twitter.com/swyx/status/1334901024201445376?s=20">I've been helped</a>, thank you for reaching out. In case you were wondering what it looks like from Twitter's side, this is what they emailed:</em></p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/wgdlczuq2k5ay8uhql2q.png" alt="Alt Text">
  </p>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/proving-our-humanity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300445</guid>
            <pubDate>Fri, 04 Dec 2020 09:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Elixir]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300420">thread link</a>) | @bendiksolheim
<br/>
December 4, 2020 | https://functional.christmas/2020/4 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today I want to give you an introduction to the programming language Elixir, some of its features and why you might want to check it out!</p>
</section><article><section><h2>The basics</h2>
<p>First things first: Elixir is a concurrent functional language that runs on the Erlang VM. It is inspired by many different languages where Ruby and Erlang are most obvious ones based on the syntax.</p>
<p>Elixir is a <a href="https://thinkingelixir.com/elixir-in-the-type-system-quadrant/">strong, dynamically typed language</a>. This puts it in the same category as Ruby and Python and it has optional functionality for compile time type checking as well.Elixirs data structures are immutable, but variables can be reassigned/rebound. <sup><sup id="fnref-2"><a href="#fn-2">2</a></sup></sup> This was a bit strange for me in that I got started with FP through Elm where there are no variables, just constants.</p>
<p>Elixir inherits a lot its data structures and related syntax from Erlang which in many ways is its biggest influence. <a href="https://elixir-lang.org/blog/2013/08/08/elixir-design-goals/">Elixir Design Goals</a> describes the relation to Erlang like this:</p>
<blockquote>
<p>Elixir is meant to be compatible with the Erlang VM and the existing ecosystem. When we talk about Erlang, we can break it into three parts:</p>
<ul>
<li>A functional programming language, called Erlang</li>
<li>A set of design principles, called OTP (Open Telecom Plaform)</li>
<li>The Erlang Virtual Machine, referred to as EVM or BEAM</li>
</ul>
<p>Elixir runs in the same virtual machine and is compatible with OTP. Not only that, all the tools and libraries available in the Erlang ecosystem are also available in Elixir, simply because there is no conversion cost from calling Erlang from Elixir and vice-versa.</p>
</blockquote>
<p>This is a great feature of Elixir that we will talk more about later.</p>
<p>As for other inspirations Elixir has docstrings from Python, polymorphism and protocols from Clojure, macros and meta-programming from different Lisps, just to name a few. <sup><sup id="fnref-1"><a href="#fn-1">1</a></sup></sup></p>
<h3>Hello World!</h3>
<p>As I said, Elixir is a concurrent functional programming language. For the functional part it means that Elixir mainly uses functions and modules for code structure and has other features that are associated with functional languages. We'll talk about the concurrent part later. </p>
<p>A hello world example in Elixir might look something like this:</p>
<div data-language="elixir"><pre><code><span>defmodule</span> HelloWorld
  <span>def</span> hello_world <span>do</span>
    IO<span>.</span>puts<span>(</span><span>"Hello, World!"</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>Here we define a module with a function that simply writes "Hello, World!" to the console.</p>
<h2>Killer applications</h2>
<p>Many programming languages has <a href="https://en.wikipedia.org/wiki/Killer_application">"killer apps"</a>; libraries, frameworks and use cases, that in themself are enough to justify the transition to the language or try it out. For Ruby it was the web framework Ruby on Rails and in many ways Elixir has its own Rails: Phoenix.</p>
<h3>Phoenix web framework</h3>
<p><a href="https://www.phoenixframework.org/">Phoenix</a> is inspired by Rails (the team originally behind Elixir was previously a Ruby shop) and was an early addition to the Elixir community. The creators of Phoenix has learned from years of Rails development and made their own opinions in addition to the natural changes needed when going from an object oriented language to a functional language.
Compared to Rails Phoenix has with the help of the Erlang VM great performance. Some of you might have heard about Phoenix' amazing <a href="https://www.phoenixframework.org/blog/the-road-to-2-million-websocket-connections">2 million simultaneous web sockets</a> benchmark!</p>
<h3>The Nerves Project</h3>
<p>Another interesting project in the Elixir ecosystem is the embedded/IoT project <a href="https://www.nerves-project.org/">Nerves</a>. Nerves makes it possible to use Elixir code to create embedded system where previously you would have had to use a low level language like C. This does not stop you from bringing your own code (like C, C++, Python, Rust, and more) while using Nerves as a platform for your IoT project.
The project web site says:</p>
<blockquote>
<p>Nerves is a complete IoT platform and infrastructure for you to build and deploy maintainable embedded systems.</p>
</blockquote>
<h2>The BEAM and OTP</h2>
<p>When talking about the advantages of Elixir it is hard to not talk about the advantages of Erlang and its virtual machine, the BEAM (Bogdan's Erlang Abstract Machine). It is in many ways the biggest selling point for Elixir. We are now talking about the concurrent part of Elixir. Erlang and the BEAM has shown its resiliency over many years, exemplified in giving Ericsson 9 nines (99.9999999%) availability in their AXD301 switch.<sup><sup id="fnref-3"><a href="#fn-3">3</a></sup></sup> It is known for its "let it break" philosophy and self-healing properties and by being compatible with Erlang, Elixir inherits a lot of these traits.</p>
<p>Elixirs creator, Jose Valim, attributes one of the motivational factors for the creation of Elixir to the rise of multi-core CPUs and the need to utilize these. Ruby and other languages with a global interperter lock (GIL) limits this, but the Erlang VM and the tools and design prinsiples of OTP have proven to be a great choice for creating concurrent, performant and resilient applications.</p>
<h3>Everything is a process</h3>
<p>Everything in the BEAM is a process. These are not OS processes, but lightweight processes which can be cheaply spawned and killed. In his PhD thesis the co-inventor of Erlang, Joe Armstrong, summarized Erlangs principles regarding processes:</p>
<blockquote>
<ul>
<li>Everything is a process.</li>
<li>Processes are strongly isolated.</li>
<li>Process creation and destruction is a lightweight operation.</li>
<li>Message passing is the only way for processes to interact.</li>
<li>Processes have unique names.</li>
<li>If you know the name of a process you can send it a message.</li>
<li>Processes share no resources.</li>
<li>Error handling is non-local.</li>
<li>Processes do what they are supposed to do or fail.</li>
</ul>
</blockquote>
<p>Sidenote: For some this may sound vaguely familiar. Some object oriented languages has had similar principles, but instead of processes they are applied to objects. Smalltalk is reported to be one of the inspirations to Erlang and it is fun to think about Erlang being a functional language but still be more object oriented than some object oriented languages. This is of course not the case as the definition of OOP has changed over time and Erlang is a functional language, but it is fun to ponder the similarities. 😄 Back to the main story! 😅</p>
<p>These unique principles for processes where they communicate through messages lays a great foundation for creating concurrent application, but there is one more piece to the puzzle: OTP.</p>
<h3>OTP - The Open Telecom Platform</h3>
<p>As with so many other parts of this article OTP is a big topic and could be a separate article, but I'll try make it short! Today the name is a bit strange but it was created by Ericsson for their telephone switches in the 80s and 90s so in that context in makes more sense.</p>
<p>OTP is an integral part of many Erlang applications. In essence OTP is a set of design principles and standards including tools and libraries to make it easier to create applications that adheres to them.<sup><sup id="fnref-4"><a href="#fn-4">4</a></sup></sup> </p>
<p>Since Elixir is compatible with OTP we can leverage these principles and technologies that has been battle tested in high-pressure and critical applications for decades!</p>
<h2>The take-away</h2>
<p>Luckily you don't need to understand or know much about Erlang, BEAM and OTP.
Without deep knowledge of these topics you can still reap the benefits of highly performing web applications and resilient IoT applications. It would certainly help but it is not a prerequisite. This is the great thing about Elixir: it is an approachable language with battle tested underpinnings! 💪</p>
<p>It might not be your idea of a perfect language. It is not mine either, but that does not stop me from using the great tools at my disposal. If you are all into Haskell or the likes it might not be something you would use and that is OK. Whatever your preferences are you might now know a little more about Elixir and Erlang and some more knowledge is always a good thing. 😄</p>
<p>If you would like to check Elixir out I recommend checking out <a href="https://elixir-lang.org/getting-started/introduction.html">the official Getting started guide</a> or the interactive guide <a href="https://try-elixir.herokuapp.com/">Try Elixir</a> and then trying out a project with Phoenix or Nerves. Hands-on experience is always better than something you read on the internet! 🤓</p>
<p>Psst! By the way: there are other languages that run on the BEAM. <a href="https://lfe.io/">Lisp variants</a> and lately some work on <a href="https://gleam.run/">strong statically compiled ML-like languges</a> if you are into that!</p>
</section></article></div>]]>
            </description>
            <link>https://functional.christmas/2020/4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300420</guid>
            <pubDate>Fri, 04 Dec 2020 09:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-host your fonts for better performance]]>
            </title>
            <description>
<![CDATA[
Score 592 | Comments 398 (<a href="https://news.ycombinator.com/item?id=25300396">thread link</a>) | @zwacky
<br/>
December 4, 2020 | https://wicki.io/posts/2020-11-goodbye-google-fonts/ | <a href="https://web.archive.org/web/*/https://wicki.io/posts/2020-11-goodbye-google-fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div>
  <div>
    <div>
      
      <p>
        
          November 30, 2020
        
      </p>

      <figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/goodbye-google-fonts.jpg" alt="Google Fonts"> 
</figure>

<p>I’ve used Google Fonts in prototypes and in 10M+ MAU products. It’s incredibly easy to get started with and provides an amazing font discovery. That’s also why it’s currently still used on over <a href="https://trends.builtwith.com/websitelist/Google-Font-API">42M websites</a>!</p>
<p>This convenience has its price: Performance. Many <a href="https://blog.cloudflare.com/fast-google-fonts-with-cloudflare-workers/">have</a> <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">already</a> <a href="https://www.keycdn.com/blog/web-font-performance#disadvantages-of-web-fonts">pointed</a> <a href="https://blog.logrocket.com/self-hosted-fonts-vs-google-fonts-api/">out</a> the cost of multiple requests. If you want the remaining speed boost, then you’re best off downloading your used Google Fonts and self-host them.</p>
<p>This is nothing new. In fact it’s been advocated already for years. Even Google themselves <a href="https://www.youtube.com/watch?v=Mv-l3-tJgGk&amp;feature=youtu.be&amp;t=24m58s">advised others to self-host fonts</a> in their Google I/O ‘18 talk about web performance.</p>
<h2 id="self-hosting-fonts-vs-google-fonts">Self-hosting fonts vs Google Fonts</h2>
<p>By nature Google Fonts, even with all its font and CSS optimisations, can’t be faster than self-hosted fonts.</p>
<p>Sia wrote <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">a great post</a> where she compared the performance between Google Fonts and self-hosted fonts without the impact of a CDN.</p>
<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/with-google-fonts.png" alt="Network flow with Google Fonts"> <figcaption>
            <p>Optimised Google Fonts loading with preconnect</p>
        </figcaption>
</figure>

<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/without-google-fonts.png" alt="Network flow with self-hosting fonts"> <figcaption>
            <p>Optimised self-hosting fonts with preload</p>
        </figcaption>
</figure>

<hr>
<h2 id="the-old-performance-argument">The old performance argument</h2>
<p>So if the bottom-line performance is in self-hosting fonts’ favour: What was the argument that convinced us developers that Google Fonts is at least as performing as the self-host approach?</p>
<p>Google Fonts was designed to be distributed on a global CDN and reap the caching benefits from it. Users request fonts via said CDN. Chances are that they have downloaded the font resources at an earlier point already from a different site.</p>
<blockquote>
<p>“[…] Our cross-site caching is designed so that you only need to load a font once, with any website, and we’ll use that same cached font on any other website that uses Google Fonts.”</p>
<p>— <a href="https://fonts.google.com/about">https://fonts.google.com/about</a></p>
</blockquote>
<h2 id="invalidating-the-old-performance-argument">Invalidating the old performance argument</h2>
<p>Since Chrome v86, released October 2020, cross-site resources like fonts can’t be shared on the same CDN anymore. This is due to the partitioned browser cache (Safari has had this for years already).</p>
<p>In <a href="https://developers.google.com/web/updates/2020/10/http-cache-partitioning">this Google post</a> they explain what the partitioned browser cache is. It got only introduced to prevent a possible cross-site tracking mechanism.</p>
<h2 id="cache-partitioning-in-other-browsers">Cache partitioning in other browsers</h2>
<p>Safari really cares about privacy. It circumvented this very cross-site tracking attack for years already. Then finally comes Chrome. Other browsers that are based off Chromium, still need to signal or implement the feature.</p>
<ul>
<li>✅ <strong>Chrome</strong>: since v86 (October 2020)</li>
<li>✅ <strong>Safari</strong>: since 2013</li>
<li>🚫 <strong>Firefox</strong>: planning to implement</li>
<li>🚫 <strong>Edge</strong>: most likely soon</li>
<li>🚫 <strong>Opera</strong>: most likely soon</li>
<li>🚫 <strong>Brave</strong>: most likely soon</li>
<li>🚫 <strong>Vivaldi</strong>: most likely soon</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Google Fonts resources will be redownloaded for every website, regardless it being cached on the CDN. Self-host your fonts for better performance. The old performance argument is not valid anymore.</p>
<p>Thanks for checking this post out!</p>


      
      <hr><div>
  <p><img src="https://wicki.io/images/me_huc890d15b6e9f2ce8978e9aa27127dd5e_67203_350x0_resize_q75_box.jpg" alt="Simon Wicki">
    
  </p>

  <div>
    <div>
      <p>
        <strong>Simon Wicki</strong> is a Freelance Frontend Developer in
				Berlin. Passionate and fluent in Vue, Angular, React and Ionic. Interested in 
				Tech, frontend &amp; non-fiction books
      </p>
      <p>
        <a href="https://twitter.com/zwacky" onclick="ga('send', 'event', 'clickout', 'bottom_cta', '\/posts\/2020-11-goodbye-google-fonts\/')" target="_blank">
          <img src="https://wicki.io/images/svg/twitter.svg" alt="Twitter" title="Twitter">
          Follow @zwacky
        </a>
      </p>
    </div>
  </div>
</div>

    </div>
  </div>
</div>


        </div></div>]]>
            </description>
            <link>https://wicki.io/posts/2020-11-goodbye-google-fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300396</guid>
            <pubDate>Fri, 04 Dec 2020 09:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project Loom and Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25300233">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html | <a href="https://web.archive.org/web/*/https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<h2>Why Loom?</h2>
<p>In 1998, it was amazing that the Sun Java Web Server (the precursor of Tomcat) ran each request in a separate thread, and not an OS process. It was able to serve thousands of concurrent requests this way! Nowadays, that’s not so amazing. Each thread takes up a significant amount of memory, and you can’t have millions of threads on a typical server.</p>
<p>That’s why the modern mantra of server-side programming is: “Never block!” Instead, you specify what should happen once the data is available.</p>
<p>This asynchronous programming style is great for servers, allowing them to handily support millions of concurrent requests. It isn’t so great for programmers.</p>
<p>Here is an asynchronous request with the <code>HttpClient</code> API:</p>
<pre>HttpClient.newBuilder()
   .build()
   .sendAsync(request, HttpResponse.BodyHandlers.ofString())
   .thenAccept(response -&gt; . . .);
   .thenApply(. . .);
   .exceptionally(. . .);
</pre>
<p>What we would normally achieve with statements is now encoded as method calls. If we loved this style of programming, we would not have statements in our programming language and merrily code in Lisp.</p>
<p>In JavaScript, code tagged as “async” is rewritten into method calls like the ones that you’ve just seen. But that means you can only call async methods from other async methods, and your API splits into a sync and an async part, forcing you to duplicate functionality.</p>

<p>Project Loom takes its guidance from languages such as Erlang and Go, attacking the root of the problem by making blocking very cheap. You run tasks in “virtual threads”, a nearly unlimited resource that is mapped into actual “carrier” threads. When a virtual thread blocks, it is “parked” and another virtual thread runs on the carrier thread. The name is supposed to remind you of virtual memory that is mapped to actual RAM.</p>
<p>Before you complain about the name, remember that naming is hard. The Loom team previously tried “fiber”, but it is already used elsewhere with a slightly different meaning. And “lightweight” or “new” thread might look foolish when something lighter-weight or newer comes along.</p>
<p>After experimenting with separate classes for OS threads and virtual threads, they ended up deciding to use a single class for both—the familiar <code>java.lang.Thread</code>—in order to ease migration.</p>
<p>Of course, good old <code>java.lang.Thread</code>, which has been around for 25 years, ever since Java 1.0, has its share of cruft. Awkward cancellation, thread groups, priorities, depreceated methods <code>stop</code>,<code>suspend</code>, <code>resume</code>. The Loom team felt that these liabilities were minor since most programmers never explicitly use the <code>Thread</code> API but launch tasks with an <code>ExecutorService</code>. (Of course, the same argument would support coming up with a cleaner virtual thread API instead.)</p>
<p>If you have been around for a very long time, you may remember that early versions of Java had “green threads” that were mapped to an OS thread. However, there is a crucial difference. When a green thread blocked, its carrier thread was also blocked, preventing all other green threads from making progress.</p>

<p>You can download binaries of Project Loom at <a href="http://jdk.java.net/loom/">http://jdk.java.net/loom/</a>. They are updated regularly.</p>
<p>As already mentioned, a virtual thread is an object of the <code>Thread</code> class. Here are three ways of producing fibers. First, there is a new factory method that constructs and starts a virtual thread:</p>
<pre>Thread thread = Thread.startVirtualThread(runnable);
  // <cite>Note that the thread is already started</cite></pre>
<p>This is good for demos, tutorials or quick-and-dirty experiments in JShell.</p>
<p>For more customization, there is a builder API:</p>
<pre>Thread thread = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .build();</pre>
<p>However, as you have been told for many years now, it is better to use an executor service than to manually construct <code>Thread</code> instances. The static method <code>Executors.newVirtualThreadExecutor()</code> provides one. (The existing executor services are not useful for virtual threads. It would be counterproductive to pool them!)</p>
<p>For example,</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor();
exec.submit(runnable1);
exec.submit(runnable2);
</pre>
<p>As with the other factory methods in the <code>Executors</code> class, you can optionally supply a <code>ThreadFactory</code>. And the new <code>Thread.Builder</code> class has an easy way to provide a factory, instead of a single instance:</p>
<pre>ThreadFactory factory = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .<b>factory()</b>;

ExecutorService exec = Executors.newThreadExecutor(factory);
</pre>
<p>Let’s try this out. As a first test, we just sleep in each task.</p>
<pre>import java.util.concurrent.*;

public class Test {
   public static int DELAY = 10_000;
   public static int NTASKS = 1_000_000;

   public static void run(Object obj) {
      try {
         Thread.sleep((int) (DELAY * Math.random()));
      } catch (InterruptedException ex) {
         ex.printStackTrace();
      }
      System.out.println(obj);
   }

   public static void main(String[] args) {
      ExecutorService exec = Executors.newVirtualThreadExecutor();
      for (int i = 1; i &lt;= NTASKS; i++) {
         String taskname = "task-" + i;
         exec.submit(() -&gt; run(taskname));
      }
      exec.close();
   }
}
</pre>
<p>Run the program and it just works. Then try using OS threads—change to <code>Executors.newCachedThreadPool()</code> or <code>Executors.newFixedThreadPool(NTASKS)</code>. The program will run out of memory; on my laptop, after about 25,000 threads.</p>
<p>Ok, but in practice, you don’t want to sleep, but do useful work. Consider a program adapted from one of <a href="https://www.javaspecialists.eu/about/heinz/">Heinz Kabutz</a>‘ puzzlers, The program fetches a daily image, from Dilbert or Wikimedia. It consists of classes <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> and <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageInfo.java"><code>ImageInfo</code></a>. The code is an impenetrable maze of twisty passages, all alike (i.e. helper functions yielding completable futures).</p>
<p>With virtual threads, simply read web contents synchronously. It blocks, but we don’t care. All the complexity goes away. The control flow is simple and comprehensible.</p>
<pre>exec.submit(() -&gt; {
    String pageURL = info.getUrlForDate(date);
    String page = getSync(pageURL, HttpResponse.BodyHandlers.ofString());
    String imageURL = info.findImage(page).getImagePath();
    byte[] image = getSync(imageURL, HttpResponse.BodyHandlers.ofByteArray());
    info.setImageData(image);
    process(info);
    return null;
});</pre>
<p>Here is the simplified <a href="http://horstmann.com/unblog/2020-12-05/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> code.</p>
<p><b>Pro tip: </b>The statement <code>return null;</code> makes the lambda into a <code>Callable</code> instead of a <code>Runnable</code>, so that you don’t have to catch checked exceptions 😜</p>
<p>Try this out with something you care about. Call web services and make database connections, without worrying about callbacks. When blocking is cheap, a whole lot of accidental complexity goes away. Of course, to use this in a web app framework, you’ll have to wait for your framework provider to run your code in virtual threads.</p>
<h2>Structured Concurrency</h2>
<p>In <a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">this highly recommended article</a> (from which the images below are taken), Nathaniel Smith proposes structured forms of concurrency. Here is his central argument. Launching a task in a new thread is really no better than programming with GOTO, i.e. harmful:</p>
<pre>new Thread(runnable).start();</pre>
<p><img src="http://horstmann.com/unblog/2019-12-05/sequential-and-go-to-schematic.svg" alt=".svg" width="38%"></p>
<p>When multiple threads run without coordination, it’s spaghetti code all over again. In the 1960s, structured programming replaced <code>goto</code> with branches, loops, and functions:</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/control-schematics.svg" alt=".svg" width="42%"></p>
<p>When you look at a line of code, you know how the program got there.</p>
<p>Structured concurrency does the same for concurrent tasks. We should know, from reading the program text, when they all finish.</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/nursery-schematic-unlabeled.svg" alt=".svg" width="30%"></p>
<p>That way we can control the resources that the tasks use, and we know when it is time to move on.</p>
<p>In Loom, the <code>ExecutorService</code> implements this basic construct. <code>ExecutorService</code> has a <code>close</code> method that blocks until all of its virtual threads have completed. (I used this method in the first sample program to keep <code>main</code> alive until all virtual threads are done. In the past, you had to call the <code>awaitTermination</code> method instead.)</p>
<p>Conveniently, <code>ExecutorService</code> implements the <code>AutoCloseable</code> interface, so that you can just use a <code>try</code>-with-resources statement:</p>
<pre>try (ExecutorService exec = Executor.newVirtualThreadExecutor()) {
   for (int i = 0; i &lt; NTASKS; i++) {
      exec.schedule(() -&gt; run(i));
   }
} // <cite>Blocks until all threads completed</cite>
</pre>
<p>I wrote a simple web crawler as a demonstration of virtual threads—here is the <a href="http://horstmann.com/unblog/2020-12-05/Crawler.java"><code>Crawler</code></a> class. In my first attempt, I fired off a new virtual thread for each URL in a page. If I had wanted to become Google, I could have let my crawler run forever. But I wanted to go no more than 3 hops from the starting point. With “fire and forget”, there is no way of knowing when the recursion is done.</p>
<p>Instead, for each page, I make a new executor service and wait for completion. That way, the whole program completes when all pages have been crawled.</p>
<p>This seems a lot of blocking. But in Loom, blocking is cheap, so we shouldn’t worry about that.</p>
<p>We are used to having one executor service as thread pool for all our tasks. But in Loom, you are encouraged to use a separate executor service for each task set.</p>
<h2>Deadlines</h2>
<p>When crawling the web, you are likely to encounter dead links. Reading from one should time out eventually, but it can take surprisingly long.</p>
<p>The standard remedy is, of course, to provide a timeout. Loom prefers deadlines to timeouts, so you specify</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor().withDeadline(
   Instant.now().plus(30, ChronoUnit.SECONDS))
</pre>
<p>Why deadlines? In general, timeouts compose poorly. Suppose you have to accomplish two sequential tasks with an overall timeout of 10 seconds. You don’t want to give each of the tasks a timeout of 5 seconds. After all, if one takes 6 seconds and the other 3 seconds, you still come in under the finish line. To get the timeout of the second task, you’d have to measure the duration of the first task and subtract that from the overall timeout. With deadlines, it is much simpler. Each task gets the same deadline.</p>
<p>The call <code>exec.close()</code> blocks until all virtual threads have completed or the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</a></em></p>]]>
            </description>
            <link>https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300233</guid>
            <pubDate>Fri, 04 Dec 2020 08:24:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monoliths as a Service]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25299598">thread link</a>) | @gdeglin
<br/>
December 3, 2020 | https://www.themostfamousartist.com/maas | <a href="https://web.archive.org/web/*/https://www.themostfamousartist.com/maas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a13f76d094074a98b8e4"><p><h3>PO BOX 4115</h3><h3>SANTA FE, NM 87502</h3><h3><strong>© 2020 THE MOST FAMOUS ARTIST, LLC</strong></h3></p></div></div>]]>
            </description>
            <link>https://www.themostfamousartist.com/maas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299598</guid>
            <pubDate>Fri, 04 Dec 2020 06:22:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faroe Island roundabout under the Atlantic Ocean]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25299574">thread link</a>) | @sohkamyung
<br/>
December 3, 2020 | https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/ | <a href="https://web.archive.org/web/*/https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1224" class="page">
	<!-- .entry-header -->
	<div>
		<p><img src="http://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o.jpg" alt="" width="2000" height="829" srcset="https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o.jpg 2000w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-300x124.jpg 300w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-1024x424.jpg 1024w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-768x318.jpg 768w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-1536x637.jpg 1536w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-250x104.jpg 250w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-350x145.jpg 350w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p>The Eysturoyartunnilin (or Eysturoy Tunnel, earlier known as Skálafjarðartunnilin) is a large infrastructure project which connects the island of Streymoy to the island of Eysturoy through a sub-sea road tunnel under the Tangafjørður sound in the Faroe Islands. It also crosses the southern part of Skálafjørður and connects the towns of Runavík on the eastern side and Strendur on the western side of the fjord. Altogether, the three-branch sub-sea tunnel measures 11.24 kilometres (6.8 miles) long, including an underwater roundabout. Construction costs are estimated to be around a billion DKK. It will open for traffic in December 2020.</p>
	</div><!-- .entry-content -->
</article><!-- #post-1224 -->

		</main><!-- #main -->
	</div><!-- #primary -->
</div><!-- .wrap -->


		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299574</guid>
            <pubDate>Fri, 04 Dec 2020 06:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Manage My Random Daily Notes]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 180 (<a href="https://news.ycombinator.com/item?id=25299442">thread link</a>) | @hachibu
<br/>
December 3, 2020 | https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/ | <a href="https://web.archive.org/web/*/https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/featured.png"><figcaption><p>Illustration: Hachibu</p></figcaption></figure><p>For years, I kept track of random notes by creating a text or Markdown
file on my desktop. And at the end of the day, I would delete that file and
start over again the next day. Inspired by the minimalism of <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>,
I created a similar system to manage my own notes.</p><p>Keep reading for more details or skip to the code: <a href="https://github.com/hachibu/note.sh">github.com/hachibu/note.sh</a>.</p><h4 id="introduction">Introduction</h4><p>As I mentioned before, I used to keep a single notes file on my desktop, and I
would delete it everyday. I would use this notes file to keep track of random
thoughts and details related to my work and personal life. My notes file might
contain code snippets from work, inspirational quotes, or it might have my
latest and greatest open-source software idea, or maybe even the beginning of a
new blog post. Anyway, I loved the simplicity of it, and I didn’t want any more
apps, databases or logins in my life.</p><p>But it wasn’t until I started using <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>
that I considered writing a script to manage my own notes. The brilliant part
about <code>todo-txt-cli</code> is that it’s just text files stored in my Dropbox and a
small shell script to interface with those files.</p><p>Inspired by the minimalism of <code>todo-txt-cli</code>, I built <a href="https://github.com/hachibu/note.sh">note.sh</a>.
In total, the entire project consists of 1 Bash script, 1 environment variable
to configure the notes directory and 1 symlink to install it to your
<code>/usr/local/bin</code> directory.</p><h4 id="how-it-works">How It Works</h4><p>The way it works is that every time I run the script, it opens the note for that
day in my editor of choice. For example, if today was December 2, 2020 then the
script would open a file named <code>2020-12-02.md</code> in the notes directory.</p><p>I use Vim as my editor, and I have my notes stored on Dropbox so I can access
them on all of my computers. So, my shell RC file looks like this.</p><div><pre><code data-lang="shell"><span>export</span> <span>EDITOR</span><span>=</span><span>"vim"</span>
<span>export</span> <span>NOTE_DIR</span><span>=</span><span>"</span><span>$HOME</span><span>/Dropbox/Notes"</span>
</code></pre></div><p>And my Dropbox directory looks like this.</p><p><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/dropbox-screenshot.png" alt="Dropbox Screenshot"></p><p>For searching, the script accepts a pattern and runs a recursive grep over the
notes directory. I chose grep because I use this script on both Mac and Linux,
and I wanted the script to be as portable as possible.</p><h4 id="conclusion">Conclusion</h4><p>I’ve been using this script for several months across several computers, and I
still love it. I don’t search as often as I thought I would, but it’s comforting
to know it’s all there if I need it. I also ended up creating an alias for my
script so all I need to type is the letter <code>n</code> to run the script.</p><p>In the future, I’d like to add a test suite to the code base, figure out how
to create a Homebrew formula, and add archiving for older notes.</p></div></div>]]>
            </description>
            <link>https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299442</guid>
            <pubDate>Fri, 04 Dec 2020 05:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Dothraki Horde, Part I: Barbarian Couture]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25299176">thread link</a>) | @parsecs
<br/>
December 3, 2020 | https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the first part of a three part (II, III) look at the Dothraki, the fictional horse-borne nomads of the <em>Game of Thrones</em> / <em>A Song of Ice and Fire</em> series and the degree to which George R.R. Martin’s claim that they are “an amalgam of a number of steppe and plains cultures” holds up to scrutiny.  This is something that I have been suggesting I would get to since (checks notes),<a href="https://acoup.blog/2019/05/04/new-acquisitions-that-dothraki-charge/"> May.  Of Last Year.</a>  So it is about time we actually get to it.</p>



<p>The plan is for this series to run in three parts.  Part I (this part) will discuss how the Dothraki <em>look</em> in the setting.  Part II will look at broader questions of social organization and culture (I am nearly certain this is one of those cases where there will be a IIa and a IIb, but my hope for brevity springs eternal).  Part III will look at military culture.  In all three parts I am going to use both the books and the show – noting where they diverge – in part because the heaviest characterization the Dothraki got in the show was when Martin was still significantly involved with it (meaning that large parts of it likely still reflect his vision), but also because the show is how the vast majority of people experience this particular fiction.  Both the original text and the show derived from it deserve to have their vision discussed.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>First, a <strong>content warning for this series</strong>: this is discussing <em>A Song of Ice and Fire</em> and <em>Game of Thrones</em> which features a lot of content which is not G-rated.  More to the point, it is a discussion of what – I will argue – Martin presents as one of, if not the most brutal and sexually violent society in that setting.  And that means those themes are going to come up here (less in this essay, but more in the other parts); we are going to remain serious and adult about those things of course, but they will be a part of this analysis nonetheless.  If that is not for you, by all means feel free to check out for a few weeks.</p>



<p>Before we get into the main point, <strong>I want to note that I am going to reference my series on the <a href="https://acoup.blog/2020/01/17/collections-the-fremen-mirage-part-i-war-at-the-dawn-of-civilization/">Fremen Mirage</a> <em>a lot</em> here</strong>, because there is a lot of Fremen stuff going on with how Dothraki society is depicted.  As a result, it may be useful to go back and read those, but just to recap, we may define the Fremen Mirage this way:</p>



<p><a href="https://acoup.blog/2020/02/21/collections-the-fremen-mirage-interlude-ways-of-the-fremen/"><strong>The Fremen Mirage is a literary trope, <em>unconnected to historical reality</em>, which presents societies as a contrast between unsophisticated, but morally pure, hyper-masculine and militarily effective ‘strong men’ societies honed by ‘hard times’ (that is, the Fremen of the term) and a sophisticated but effeminate and decadent ‘weak men’ societies weakened by ‘good times,’ frequently with an implicit assertion of the superior worth of the former.</strong></a></p>



<p>Next, a note on citation here from the books.  My understanding is that different printings of the books have different pagination, which seems to be why the Wiki of Ice and Fire cites by chapter numbers (except that the chapters of the books, as printed, <em>aren’t numbered</em> in the print editions I’ve seen, making this classical-style citation extremely cumbersome and inexact).  I am going to cite by the page numbers of my edition, which is the 2011 Bantam Books Trade Paperback Edition (the box set).  Hopefully that will be enough.</p>



<p>Finally, a note on my expertise here.  <strong>I am not a scholar of either the peoples of the Eurasian Steppe or the American Great Plains</strong>.  The former group does intrude into my period and study, as steppe nomads, in the form of Scythians, Sarmatians and Huns did interact (sometimes peacefully, sometimes violently) with the broader Mediterranean world.  Consequently, my knowledge of steppe peoples tend to be better that my knowledge of the Native American peoples of the Great Plains, but I have tried, within the limits of time and availability, to do my research. <strong> I actually think, in a strange sense, this is useful, because my own initial unfamiliarity with the topic has demonstrated to me just how <em>basic</em> the level of research and reading necessary to avoid the failures of this depiction are</strong>.  You do not, in turns out, need to be an experienced scholar on the topic; just a few books and a couple of emails is enough to already radically improve on what we see and read in <em>A Song of Ice and Fire</em>, much less the absolute <em>mess </em>of what we see in <em>A Game of Thrones</em>.</p>



<p>Writing this has been tricky.  I am well aware that both of these broad cultural groups (that is, Steppe peoples and Plains Native Americans) are often represented in popular culture only in the form of inaccurate and demeaning stereotypes.  I do not want to be just another link in that chain of poor understanding.  I have thus tried to root my argument here, wherever possible, in either the writings of specialist scholars (there will be more of that next week as we get into subsistence patterns, warfare, etc.) or primary evidence, particularly in terms of <em>period photographs</em>, when it comes to clothing and dress.  With luck I have not erred overmuch.</p>



<figure><img data-attachment-id="5355" data-permalink="https://acoup.blog/1024px-skythian_archer_plate_bm_e135_by_epiktetos/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg" data-orig-size="1024,991" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-skythian_archer_plate_bm_e135_by_epiktetos" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Scythians#/media/File:Skythian_archer_plate_BM_E135_by_Epiktetos.jpg">Via Wikipedia</a>, an Attic vase-painting of a Scythian archer (c. 500 BCE).  The Scythians, like the Huns and Mongols, were a Eurasian Steppe people, many of them horse-borne nomads of the same sort.  Far from being drab, their clothing was colorful and distinctive, including their particular hats, which show up not only in Greek but also in Persian artwork.</figcaption></figure>



<h2>…But, Why?</h2>



<p>But before we get into the issue proper, it is important to clear away the standard objections, both why subject <em>A Song of Ice and Fire</em> (and its spin-off properties) to critical analysis at all and also why, if we are going to do that, we are going to focus squarely in on the Dothraki.  The answer to the first is something that we’ve rehearsed a number of times, but bears restating: for most of its readers (and the watchers of <em>A Game of Thrones</em>), <em>A Song of Ice and Fire</em> will be their primary exposure to the idea of the Middle Ages.  This is particularly true because of the reputation that the series has for being ‘<a href="https://acoup.blog/2019/05/28/new-acquisitions-not-how-it-was-game-of-thrones-and-the-middle-ages-part-i/">how it really was</a>,’ a reputation that George R.R. Martin has consciously cultivated (as with his classic complaint of <a href="https://youtu.be/p-VxvKoDFIw">‘what was Aragorn’s tax policy’</a> – there is a rich irony that, had Martin understood rulership in the Middle Ages better, he would have understood why Aragorn’s tax policy was less important).  Martin has been quite open that he “<a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">draw[s] inspiration from history</a>” and that fact has long been a selling point of the series over more obviously fantastical kinds of medieval-themed high fantasy as well as a <a href="https://ew.com/article/2015/06/03/george-rr-martin-thrones-violence-women/">response to some of the series’ more controversial moments</a>.</p>



<p><strong>Naturally, that cloak of verisimilitude has tended to intensify the degree to which elements of <em>A Song of Ice and Fire</em> is taken by its readers and viewers as representative of the Middle Ages more generally.</strong>  And of course as I have noted in the (quite recent) past,<strong> <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">fiction is often how the public conceptualizes the past and that concept of the past shapes the decisions we make in the present</a></strong>.  In the case of <em>A Song of Ice and Fire</em> in particular, this vision of the past is <a href="https://acoup.blog/2019/06/12/new-acquisitions-how-it-wasnt-game-of-thrones-and-the-middle-ages-part-iii/">particularly worth interrogating</a> because it serves as the basis for a<a href="https://youtu.be/ek2O6bVAIQQ"> parable on power and violence</a>.</p>



<p>But <em>even if it didn’t</em>, it would still be worth discussing these aspects of the universe of <em>A Song of Ice and Fire</em>, because that is what we are supposed to do with cultural products, with <em>literature</em>.  <strong>I am sometimes baffled that the very fans who insist that their particular loves be treated seriously, as <em>art</em> are the same fans who react with frustration if one then sets out to interrogate those same genres the way one would interrogate serious art or literature</strong>.  This is it, after all!  This is what you (we, really) wanted!  A (quite unimpressive, I’ll grant you) ivory tower academic is taking this genre seriously and subjecting it to serious criticism!  Isn’t that what emerging genres often hope for, to be taken seriously as ‘high’ literature?</p>



<p><strong>And of course we should take it seriously.</strong>  And here I want to speak briefly to the purpose of these sorts of endeavors, <strong>because the goal here is not to force anyone to dislike <em>A Song of Ice and Fire</em></strong>.   We’re not here to ‘cancel’ <em>ASOIF</em> any more than we were going to ‘cancel’ <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/"><em>AC:Valhalla</em> two weeks ago</a> (a game I continue to play, I might add).  Instead, discussing cultural products like this is a form of inoculation against their potentially negative aspects, because once a reader knows that, for instance, the depiction of a given culture in a work of fiction has relatively little to do with any real world culture, they can compartmentalize that to the fiction itself; <strong>it loses its power to mislead</strong> <strong>and so may be enjoyed in safety, as it were</strong>.  And there are good things in <em>A Song of Ice and Fire</em> and in the first six or so seasons of <em>Game of Thrones</em>; but we also need to be honest about the failings.</p>



<p>(Of course, more broadly, doing this as a practice exercise is a key part of building up that skill – what we may term ‘critical reading’ – more generally, rendering the alert reader more resistant to this sort of thing, both in its unintended form (as, I suspect, in this case) or  in its more dangerous<em> intended form</em>.  Put another way, developing critical reading skills is one important way to make one’s self a harder target for misinformation, including historical misinformation.)</p>



<h2>A Dash of Pure Fantasy</h2>



<p>Alright, so <em>A Song of Ice and Fire</em> is worth looking at closely.  So why <em>this</em> part of the fiction?  It comes down to something <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">George R.R. Martin wrote</a>:</p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299176</guid>
            <pubDate>Fri, 04 Dec 2020 05:05:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No dog food today – the Linux Foundation annual report]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25298501">thread link</a>) | @BerkhanBerkdemi
<br/>
December 3, 2020 | https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><a href="https://daniel-lange.com/categories/17-Strategy"><img title="Strategy: Airplanes are interesting toys but of no military value. (Marechal Ferdinand Foch, Professor of Strategy, Ecole Superieure de Guerre)" alt="Strategy" src="https://daniel-lange.com/uploads/strategy.serendipityThumb.jpg"></a></p><p>The Linux Foundation has published its <a href="https://www.linuxfoundation.org/wp-content/uploads/2020/11/2020-Linux-Foundation-Annual-Report_113020.pdf">annual report</a> today. LWN <a href="https://lwn.net/Articles/838871">calls it glossy</a> and yeah, boy, it is shiny.</p>

<p>So shiny that people that work in the publishing industry immediately see this has been produced with the Adobe toolchain which - unfortunately - is one of the big suites of software not yet available for Linux.</p>

<p>Checking the PDF file metadata reveals the keywords "open source, open standards, open hardware, open data". That is what the Linux Foundation is about. Good stuff.</p>

<p><!-- s9ymdb:667 --><img width="552" height="676" src="https://daniel-lange.com/uploads/entries/Linux-Foundation-Annual-Report-2020-cover.jpg" title="Mouseovers are for xkcd!" alt="Linux Foundation annual report 2020 cover"></p>

<p>The PDF producer meta data for the annual report PDF has been set to "Linux kernel 0.12.1 for Workgroups" and the PDF creator meta data element to "Sharp Zaurus XR-5000 (Maemo5) Edition". Somebody thought to better hide the real data and had some tongue-in-cheek ideas. Kudos.</p>

<p>But nicer would have been to use Open Source software to produce the report, not?</p>

<p>Running <code>strings 2020-Linux-Foundation-Annual-Report_113020.pdf | grep Adobe | wc -l</code> gives us 1229 lines and confirms the suspicion of the toolchain.</p>

<p>A stale <code>/Title (Annual Report 2020) /Producer (macOS Version 10.15.7 \(Build 19H15\) Quartz PDFContext)</code> has been forgotten in the document to tell us about the platform.</p>

<p>So, ladies and gentlemen, the Linux Foundation 2020 annual report has been produced on a Mac.</p>

<p>Running Adobe Creative Cloud on MacOS Catalina 10.15.7.</p>

<p>Which is proprietary software. Its kernel (and some userland pieces) are based on BSD. Not Linux.</p>

<hr>

<p>The image on the front page also struck me as a bit odd ... using a ballpoint pen on the laptop screen?</p>

<p>Unbranded laptop.
Unbranded cup in the foreground.</p>

<p>Kid in the background <em>not</em> paying attention to his tablet.</p>

<p>All of that cries stock image so loud it hurts.</p>

<p>Google currently finds ~560 uses of the picture and any <a href="https://www.shutterstock.com/support/article/Do-I-need-to-credit-Shutterstock-the-artist-when-I-use-Images-or-Footage">editorial use</a> nicely tells us that it is © <a href="https://www.shutterstock.com/de/g/draganagordic">Dragana Gordic / Shutterstock</a>.</p>

<p>The image is "Smiling mom working at home with her child on the sofa while writing an email. Young woman working from home, while in quarantine isolation during the Covid-19 health crisis".</p>

<p>See the <a href="https://www.dailymail.co.uk/news/article-8683629/Staff-working-home-nearly-extra-hour-day-research-shows-send-emails.html">Daily Mail</a> for a wonderful example of the working mum in context. I hope, if her laptop had been powered on, it would have run Linux. I mean, what else would still run on an old white MacBook with an Intel "Core 2 Duo" processor from 2008?</p>

<p><!-- s9ymdb:668 --><img width="504" height="742" src="https://daniel-lange.com/uploads/entries/DailyMail-screenshot-stock-image.png" title="O.k., here you go: Shiny, too!" alt="Daily Mail screenshot of the same stock image used"></p>

                </div><div id="extended">
        <p>Bonus round:</p>

<p>The Ethernet port, the USB ports and the headset connector are on the left side of the MacBook. The Daily Mail got it right.</p>

<p>Mirroring images is usually not a good idea. To Linux Foundation's defense ... similar pictures are available <a href="https://www.shutterstock.com/de/image-photo/busy-young-woman-son-home-shot-1680921679">already mirrored on Shutterstuck</a> next to the <a href="https://www.shutterstock.com/de/image-photo/smiling-mom-working-home-her-child-1680923362">correctly oriented picture</a>.</p>

        </div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298501</guid>
            <pubDate>Fri, 04 Dec 2020 03:18:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Perfection is a process, not the result]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25298477">thread link</a>) | @phongduong
<br/>
December 3, 2020 | https://phongduong.dev/blog/perfection-is-a-process-not-the-result/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/perfection-is-a-process-not-the-result/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For me, perfection is that I don't want to have any errors in what I do. It's hard and exhausted to keep everything perfect. When I publish a piece of content, I want it to be perfect. But I always feel something was wrong and afraid someone would point out the error. After all, I just make a little modification and leave it behind because it's wasting time.</p>
<p>I have so much content I want to create. I don't want to stick with a piece of content for too long. When I start creating another piece of content, I try to avoid previous mistakes. I also try something new in it. The joy of creating content is you can try something new and see if it works.</p>
<p>This is the issue that makes me hesitate to create content. I want my content to be useful to my audiences. I also want to create as much content as possible. After trying some ways, I think I should prioritize the quantity rather than quality. Because I can improve my content by creating more. </p>
<p>Now, perfection for me is not the result of a piece of content. It's a process in which I try, modify, and improve pieces by pieces. If I satisfy with a blog post or video, I just publish it and create another. When I find a mistake, I will fix it.</p>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/perfection-is-a-process-not-the-result/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298477</guid>
            <pubDate>Fri, 04 Dec 2020 03:12:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PixelNeRF Neural Radiance Fields from One or Few Images]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25298426">thread link</a>) | @choppaface
<br/>
December 3, 2020 | https://alexyu.net/pixelnerf/ | <a href="https://web.archive.org/web/*/https://alexyu.net/pixelnerf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p id="paper-title">
            
            <h3>
                Neural Radiance Fields from One or Few Images
            </h3>
            <h3>
                <small title="Note: This is a joke">IEEE International Conference on Neural Radiance Fields (ICNeRF)</small>
            </h3>
        </p>

        
        
        <div>
            <div>
                <div id="dynamic-teaser">
                     <!-- row -->

                     <!-- row -->
                    <div id="teaser-dtu">
                        <div>
                            <p>3 Input Views</p>
                            
                            <p><strong>pixelNeRF</strong></p>
                            <p>3-view NeRF</p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_inputs.jpg">
                            </p>
                            
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_outputs_sm.gif">
                            </p>
                        </div> <!-- row -->
                    </div>
                </div> <!-- dynamic-teaser -->
                <!-- <img id="teaser" src="img/teaser.png" class="img-responsive" alt="teaser figure"> -->
                <p>
                    We propose pixelNeRF, a learning framework that predicts a continuous neural scene representation conditioned on
                    one or few input images.
                    The existing approach for
                    constructing neural radiance fields&nbsp;<a href="https://www.matthewtancik.com/nerf">[Mildenhall et al. 2020]</a>
                    involves optimizing the representation to every scene independently, requiring many calibrated views and significant compute time.
                    We take a step towards resolving these shortcomings
                    by introducing an architecture that conditions a NeRF on image inputs in a fully convolutional manner. This allows the network to be trained across multiple scenes to learn a scene prior, enabling it to perform novel view synthesis in a feed-forward manner from a sparse set of views (as few as one).
                </p>

            </div>
        </div>
        <div id="overview-video">
            <div>
                <h4>Narrated Overview</h4>
                <p>
                    <iframe src="https://www.youtube.com/embed/voebZx7f32g" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </p>
            </div>
        </div>
        <div>
            <div>
                <p>
                    Leveraging the volume rendering approach of NeRF, our model can be trained directly from images with no explicit 3D supervision.
                    We conduct extensive experiments on ShapeNet benchmarks for single image novel view synthesis tasks with held-out objects as well as entire unseen categories.
                    We further demonstrate the flexibility of pixelNeRF by demonstrating it on multi-object ShapeNet scenes and real scenes from the DTU dataset. In all cases, pixelNeRF outperforms current state-of-the-art baselines for novel view synthesis and single image 3D reconstruction.
                </p>
                <p><img src="https://alexyu.net/pixelnerf/img/pipeline.png" alt="pipeline">
            </p></div>
        </div>
        <div>
            <div>
                <h4>Feed-forward NeRF from One View</h4>
                <p>
                    Using multiview image supervision, we train a single pixelNeRF to 13 largest object categories
                    in ShapeNet in order to perform novel-view synthesis on unseen objects.
                    Our approach operates in <strong>view-space</strong>—as opposed to canonical—and requires <strong>no test-time optimization</strong>.
                    Nevertheless, in terms of image metrics, we significantly outperform existing methods quantitatively, as shown in the paper.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_000.gif" alt="shapenet results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_001.gif" alt="shapenet results animated">
                    </p></div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Scene-level Representation</h4>
                <p>
                    Since our method requires <strong>neither canonical space nor object-level information such as masks</strong>,
                    it can represent scenes with multiple objects, where a canonical space is unavailable,
                    without modification.
                    Our method can also <strong>seemlessly integrate multiple views</strong> at test-time to obtain better results.
                    SRN performs extremely poorly here due to the lack of a consistent canonical space.
                </p>
                <div>
                    <div>
                        <div>
                            <p>2 Input Views</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                    <div>
                        <div>
                            
                            <p>1 Input View</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Real-world Scenes</h4>
                <p>
                    We show that our method can also conduct wide-baseline view synthesis on more complex real scenes from the <a href="http://roboimagedata.compute.dtu.dk/?page_id=36">DTU MVS</a> dataset,
                    producing reasonable results when given only 1-3 views at inference time.
                    Moreover, it is feed-forward without requiring test-time optimization for each scene.
                </p>
                <div>
                    
                    <div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu_inputs.jpg" alt="DTU 3 input images">
                        </p>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu.gif" alt="DTU results animated">
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Generalization</h4>
                <p>
                    To demonstrate generalization capabilities,
                    we apply a model trained on ShapeNet planes, cars, and chairs to unseen ShapeNet categories.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_000.gif" alt="shapenet unseen category results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_001.gif" alt="shapenet unseen category results animated">
                    </p></div>
                </div>
                <p>
                    Separately, we apply a pretrained model on real car images after background removal.
                </p>
                
                
            </div>
        </div>
        <div>
            <div>
                <h4>Related Links</h4>
                <ul>
                    <li>
                        NeRF was introduced in <a href="https://www.matthewtancik.com/nerf">Mildenhall et al. (2020)</a>
                    </li><li>
                        Local image features were used in the related regime of implicit surfaces in
                        <a href="https://shunsukesaito.github.io/PIFu/">Saito et al. (2019)</a>
                        and
                        <a href="https://arxiv.org/abs/1905.10711">Xu et al. (2019)</a>
                    </li><li>
                        Our MLP architecture is
                        inspired by
                        <a href="https://avg.is.tuebingen.mpg.de/publications/niemeyer2020cvpr">DVR</a>
                    </li><li>
                        Parts of our
                        PyTorch NeRF implementation are taken from
                        <a href="https://github.com/kwea123/nerf_pl">kwea123</a>
                    </li><li>
                        Also see the concurrent work
                        <a href="https://arxiv.org/abs/2010.04595">GRF</a>
                        which also introduces image features for NeRF, showing image features can even improve NeRF when a large number of views are available.
                </li></ul>
            </div>
        </div>
        
        <div>
            <div>
                <h4>Acknowledgements</h4>
                <p>
                    We thank Shubham Goel and Hang Gao for comments on the text. We also thank
                    Emilien Dupont and Vincent Sitzmann for helpful discussions.
                    This website is inspired by the template of <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                </p>
                <p>
                    Please send any questions or comments to <a href="https://alexyu.net/">Alex Yu</a>.
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexyu.net/pixelnerf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298426</guid>
            <pubDate>Fri, 04 Dec 2020 03:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A terminal-based workflow for research, writing, and programming]]>
            </title>
            <description>
<![CDATA[
Score 271 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25297268">thread link</a>) | @jerodsanto
<br/>
December 3, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p><a href="https://youtu.be/2SLZQQfMF8E"><img src="http://jacobzelko.com/assets/workflow_youtube_vid.jpg" alt=""></a></p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action-boom">My Workflow in Action <img title=":boom:" alt=":boom:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a5.png" height="20" width="20">
</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="floating-terminals">Floating Terminals</h3>

<p><img src="http://jacobzelko.com/assets/float_term.gif" alt=""></p>

<p>Floating terminals are immensely powerful and I love them!
This enables me to quickly pull up a terminal and do some changes without having to split tmux panes or get out of vim.
Furthermore, what is awesome is that you can use it as a sort of <code>vim-slime</code> tool to send lines of code to the floating terminal.
This is a great feature as it uses your last used floating terminal for its target - therefore, if you switch between projects a lot, just switch your floating terminal accordingly.
No need to keep opening and closing REPL sessions and such!</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I’ll have to spend valuable time getting my workflow set back up… Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It’s nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer – works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>



<p>These are parts of my workflow that I used to use.
They have been retired for a variety of reasons but all in an effort to improve my workflow.
I have kept these around in case anyone finds it useful!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><strong>Rationale for deprecation:</strong> I used to use <code>vim-slime</code> but deprecated it from my workflow because of the flexibility of floating terminals.
Not only could I use floating terminals to send code, I could also quickly flip through terminals in one button press.</p>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297268</guid>
            <pubDate>Fri, 04 Dec 2020 00:05:02 GMT</pubDate>
        </item>
    </channel>
</rss>
