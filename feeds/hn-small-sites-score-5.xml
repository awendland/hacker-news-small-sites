<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 25 Aug 2020 08:22:37 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 25 Aug 2020 08:22:37 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Persisting as a Solo Founder]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24251403">thread link</a>) | @vishnumohandas
<br/>
August 23, 2020 | https://vishnu.tech/posts/persistence/ | <a href="https://web.archive.org/web/*/https://vishnu.tech/posts/persistence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://sa.vishnu.tech/noscript.gif" alt="">




    



  



    
    <p><time itemprop="datePublished">August 19, 2020</time>
    </p>
    

<p>I quit my job in January 2020 to build a privacy friendly photo organizer.</p>

<p>As a 30 year old whose friends are either getting married or planning
off-springs, what I had underestimated was the difficulty involved in finding a co-founder and how that would compound the difficulty involved in
finding an investor.</p>

<p>Once I accepted the loneliness and the lack of a financial cushion I had to figure out a way to keep building without burning myself out.</p>

<p>It took me a while, but I have found a rhythm that works, and with it, a steady
source of endorphins. Here are some changes that helped me to keep things
moving.</p>

<h2 id="being-patient">Being patient</h2>

<p>Life is no longer as comfortable as it used to be and things are not always
going the way I want them to. Preseverance has been key and indirectly patience
too. Naval’s <a href="https://twitter.com/naval/status/1261481752448524289" target="_blank">take on
meditation</a> (60 minutes x
60 days), was an eye opener. I’ve stuck with it since, and I now have an easier
time identifying negative thought patterns and sitting out situations that would
otherwise overwhelm me.</p>

<p>On some level, spending the last few months locked indoors with my parents, who
are not the most rational people in the world has also helped. But I wouldn’t
recommend it.</p>

<h2 id="reducing-procrastination">Reducing procrastination</h2>

<p>Over time I’ve realized that action precedes motivation and procrastination precedes guilt.</p>

<p>Breaking down tasks into chunks that seem trivial to accomplish has helped reduce the friction in getting started on unexciting grunt work.</p>

<p>Then there are tasks which I loathe from my core, like writing out applications
to VCs explaining why what I’m doing will matter. To those I attach reinforcing
personal reasons, like, “I need the $50k to hire that college junior who I love
working with, and that will give me spare bandwidth to focus on traction channels”.</p>

<h2 id="thinking-clearer">Thinking clearer</h2>

<p>It is sub-optimal to not have a coworker to bounce ideas off and rant about problems to. A lot of times it’s these conversations that help you gain clarity.</p>

<p>It’s a luxury I do not have so every time I feel stuck, I type/scribble my thoughts out, and then question everything that was written, and then document my realizations.</p>

<p>Task tracking has also helped in clearing the path. I write down unstructured
thoughts into a diary, and once I’ve clarity, I promote them to a Notion board
(that’s divided into <em>Thinking</em>, <em>Building</em>, <em>Reading</em>, <em>Writing</em> and
<em>Adulting</em>) and every Monday within an Excel sheet I track what was done, and
what is left to be done.</p>

<h2 id="reducing-distractions">Reducing distractions</h2>

<p>I’ve reduced my information consumption to free up brain cycles. I’ve disabled all notifications on my phone barring a few contacts, and I’ve more or less stopped browsing on it. As an added bonus, this has reduced the negativity with which I perceived the world.</p>

<p>To minimize the overhead of context switches, I split tasks into a tree of checkpoints. Before taking a break I note down the next simplest checkpoint so that when I get back to work there’s little friction to resume.</p>

<p>To help me zone out I keep <a href="https://www.youtube.com/watch?v=5qap5aO4i9A" target="_blank">lofi
beats</a> or
<a href="http://github.audio/" target="_blank">github.audio</a> playing in the background. Listening to the
latter gives me a strange sense of motivation and makes me feel less alone.</p>

<h2 id="staying-grounded">Staying grounded</h2>

<p>I’m lucky to have some friends who call/text every other week. I look at them as my accountability partners and I talk to them about what I’m doing on a high level. While not all of them genuinely care, some do, and these conversations force me to reflect on how well I’m doing what I’m doing.</p>

<p>While Silicon Valley wisdom suggests that if I’m not sleeping I should be
working, failing because of a burn out would be stupid. An advantage of not
having a VC onboard so far has been the freedom to dictate my pace. So I spend
days thinking, reading, fiddling with my violin or just doing nothing when I
feel like writing code is not what I want to do.</p>

<hr>

<p>It’s been 7 months of building alone, and while this is not how I pictured things to be on my last day at work, this is the happiest I have ever been. There’s a long way to go, and the grind seems inviting.</p>

<p>This list is by no means exhaustive, for I’m still learning. If you’ve
anything to share, please join <a href="https://news.ycombinator.com/item?id=24251403" target="_blank">the discussion on HackerNews</a>.</p>

<hr>

<p>If you are curious about what I’ve been building, check out
<a href="https://ente.io/" target="_blank">ente.io</a>.</p>

    <br>
    


</div>]]>
            </description>
            <link>https://vishnu.tech/posts/persistence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251403</guid>
            <pubDate>Sun, 23 Aug 2020 12:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Clean Start for the Web]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24247362">thread link</a>) | @simantel
<br/>
August 22, 2020 | https://macwright.com/2020/08/22/clean-starts-for-the-web.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/08/22/clean-starts-for-the-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The web is in need of some reinvention right now.</p><p>The web’s evolution over the last decade has mirrored the American economy. All of the essential indicators are going “up and to the right,” a steady stream of fundamental advances reassure use that there “is progress,” but the actual experience and effects for individuals stagnates or regresses.</p><p>The crisis affects platforms, creators, and consumers alike.</p><p><em>I’m going to try and dissect and diagnose this situation, a bit. You can skip forward if you just want to read my casual, unprofessional pitch for a reboot of the web. The idea is that we could choose a new lightweight markdown format to replace HTML &amp; CSS, split the web into documents and applications, and find performance, accessibility, and fun again.</em></p><details><summary>This post uses the pedantic definition of "the web"</summary>I've discussed attempts to reinvent the "Internet" a few times. Things like dat, IPFS, and arweave are all projects to reinvent an Internet, or a transport and data-sharing layer. The web is what lies on top of that, the HTML, CSS, URLs, JavaScript, browsing experience.</details><h3 id="the-platform-collapse">The platform collapse</h3><p>The platform side is what changed last week, when <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla laid off 250 employees</a> and indicated that it would affect Firefox development. Firefox wasn’t the #2 browser - that’s Safari, mainly because of the captive audience of iPhone and iPad users. But it was the most popular browser that people <em>chose</em> to use.</p><p><img alt="Chart of browser market share, with Chrome becoming the monopoly" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-chart-of-browser-market-share-with-chrome-becoming-the-monopoly.png"></p><p><em>Chart from <a href="https://gs.statcounter.com/browser-market-share#monthly-200901-202007">statcounter</a></em></p><p>The real winner is not just Chrome, but Chrome’s engine. One codebase, <a href="https://en.wikipedia.org/wiki/KHTML">KHTML</a>, split into <a href="https://en.wikipedia.org/wiki/WebKit">WebKit</a> (Safari), and <a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)">Blink</a> (Chrome, Microsoft Edge, Opera, etc.)</p><p>This a textbook monoculture. In one sense, it’s a victory for collaboration because nobody’s ‘wasting time’ on competing implementations and web developers can expect the same features and bugs across different browsers. But in a deeper way, it threatens one of the basic principles of how the web has evolved.</p><h3 id="specs--implementations">Specs &amp; implementations</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.webp" type="image/webp"><img alt="Decline" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.jpg"></picture></p><p>The web has evolved through a combination of <em>specifications</em> and <em>implementations</em>. Organizations like the <a href="https://whatwg.org/">WHATWG</a>, <a href="https://www.w3.org/">W3C</a>, and <a href="https://www.ietf.org/">IETF</a> have been collaboration spaces for independent developers, corporations, and academics to discuss potential new features of the web. Then, browsers would test those ideas out in a variety of implementations.</p><p>This was an interesting structural piece: it reassured us all that it was <em>possible</em> to follow along, and that a multi-participant web was one of our goals. It was frustrating to pull up <a href="https://caniuse.com/">caniuse</a> and see blank spots, but the idea was that different browsers may take the lead in some areas, but everyone catches up eventually. Chrome was not always the first to jump on features, or the first to optimize.</p><p>It’s slower to collaborate than to work alone, but it was beneficial in some ways that we’ve lost now. Chrome has been moving extremely fast, adding new specifications and ideas at a startling rate, and it’s becoming one of the hardest pieces of software to replicate.</p><p>Mike Healy I think <a href="https://twitter.com/mike_hasarms/status/1296575224599556097">said it best</a>:</p><blockquote><p>Do you think the web has almost ‘priced itself out of the market’ in terms of complexity if only 1-2 organisations are capable of building rendering engines for it?</p></blockquote><p>Not only is it nearly impossible to build a new browser from scratch, once you have one the ongoing cost of keeping up with standards requires a full team of experts. Read Drew DeVault’s <a href="https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html">Web browsers need to stop</a> for that point, and keep reading all of Drew’s stuff.</p><details><summary>What about Flow?</summary>Yep, there’s a <a href="https://www.ekioh.com/flow-browser/">browser called Flow</a>, which may exist and may support a full range of web standards. If it does exist, I’ll be very excited about it, but it has been teased for almost a year now without any concrete evidence, so it could equally be vaporware.</details><h3 id="the-problem-for-creators">The problem for creators</h3><p>The web has gotten much harder to develop for.</p><p>The web has had about 25 years to grow, few opportunities to shrink, and is now surrounded by an extremely short-sighted culture that is an outgrowth of economic and career short-termism. There are lots of <a href="https://frankchimero.com/blog/2018/everything-easy/">ways to do anything</a>, and some of the most popular ways of building applications on the web are - in my opinion - <a href="https://macwright.com/2020/05/10/spa-fatigue.html">usually ghoulish overkill</a>.</p><p>The best way for folks to enter <em>web development</em> in 2020 is to choose a niche, like <a href="https://vuejs.org/">Vue.js</a> or <a href="https://reactjs.org/">React</a>, and hope that there’s a CSS and accessibility expert on their team.</p><p>For folks who just want to create a web page, who don’t want to enter an industry, there’s a baffling array of techniques, but all the simplest, probably-best ones are stigmatized. It’s easier to stumble into building your resume in React with GraphQL than it is to type some HTML in Notepad.</p><h3 id="the-problem-for-consumers">The problem for consumers</h3><p>We hope that all this innovation is <em>for the user</em>, but often it isn’t. Modern websites seem to be as large, slow, and buggy as they’ve ever been. Our computers are <a href="https://macwright.com/2019/11/15/something-is-wrong-with-computers.html">barely getting faster</a> and our internet connection speeds are stagnating (don’t even <em>try</em> to mention 5G). Webpage <a href="https://www.pingdom.com/blog/webpages-are-getting-larger-every-year-and-heres-why-it-matters/">size growth</a> is outpacing it all.</p><p>The end result is that I no longer expect pages to be fast, even with <a href="https://github.com/gorhill/uBlock">uBlock</a> installed in Firefox and a good local <a href="https://sonic.net/">fiber internet provider</a>.</p><p>I don’t want to lay all of the blame at <em>those web developers</em>, though. Here’s a story from an old job that I find kind of funny. We were collecting some data from user interactions to answer simple questions like “do people click to upload or do they drag &amp; drop?” So we enabled <a href="https://segment.com/">Segment</a>, a tool that lets you add data-collection pipelines by including a single script. The problem, though, is that Segment offered a big page of on/off switches with hundreds of data providers &amp; ad-tech companies on it. And, sure, enough, some folks closer to the business side started <em>clicking all those buttons</em>.</p><p>See, the problem with ads and data tracking is that <em>you can</em>, and who is going to say no? (In that instance, I said no, and added a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a> that would block new advertiser access at the page level.)</p><h2 id="recreating-simplicity">Recreating simplicity</h2><blockquote><p>You cannot get a simple system by adding simplicity to a complex system. - <a href="http://erlang.org/pipermail/erlang-questions/2012-March/065087.html">Richard O’Keefe</a></p></blockquote><p>Where do we go from here? Some of the smartest folks out there have been <a href="https://twitter.com/_developit/status/1296628134406692865">advocating for a major version revision</a> of the web.</p><p><em>I am in no way qualified to speculate on a whole new web from scratch, but the <a href="https://www.nytimes.com/2020/08/21/us/california-wildfires.html">air quality</a> is scary so I’m skipping my run and it’s Saturday morning so here we are.</em></p><p>How do we make the web fun, participatory, and good?</p><p>My first thought is that there are two webs:</p><h3 id="the-document-web">The document web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.webp" type="image/webp"><img alt="Illustration of web pages" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.jpg"></picture></p><p>There is the “document web”, like blogs, news, Wikipedia, Twitter, Facebook. This is basically the original vision of the web, as far as I can understand it (I was 2). Basically CSS, which we now think of as a way for designers to add brand identity and tweak pixel-perfect details, was instead mostly a way of making plain documents readable and letting the <em>readers</em> of those documents customize how they looked. This attribute actually <a href="https://twitter.com/autiomaa/status/1296755641164468224">survived for a while in Chrome, in the form of user stylesheets</a>, and <a href="https://davidwalsh.name/firefox-user-stylesheet">still works in Firefox</a>. Though it’s going to be a rough ride in the current web which has basically thrown away <a href="https://en.wikipedia.org/wiki/Semantic_HTML">semantic HTML</a> as an idea.</p><h3 id="the-application-web">The “application” web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.webp" type="image/webp"><img alt="Illustration of machines" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.jpg"></picture></p><p>Then there’s the “application web”. This started as <em>server</em> applications, built with things like <a href="https://www.djangoproject.com/">Django</a> and <a href="https://rubyonrails.org/">Ruby on Rails</a> and before them a variety of technologies that will live forever in corporations, like <a href="https://en.wikipedia.org/wiki/Jakarta_Servlet">Java Servlets</a>.</p><p><a href="https://backbonejs.org/">Backbone.js</a> demonstrated that a lot of these applications could be moved into the browser, and then <a href="https://reactjs.org/">React</a> and its many SPA-style competitors established a new order for the web – highly-interactive, quite complex, client-side applications.</p><h3 id="the-war-between-the-parts-of-the-web">The war between the parts of the web</h3><p>I posit that this dual-nature is part of what gives the web its magic. But it’s also a destructive force.</p><p>The magic is that a simple blog can be creative expression, can be beautifully interactive. This one isn’t, but I’m just saying - <a href="https://www.typewolf.com/site-of-the-day">it’s possible</a>.</p><p>The problem is that the “document web” is often plagued by application characteristics - it’s the JavaScript and animations and complexity that makes your average newspaper website an unmitigated disaster. Where document websites adopt application patterns they often accidentally sacrifice <a href="https://www.a11yproject.com/">accessibility</a>, performance, and <a href="https://en.wikipedia.org/wiki/Web_scraping">machine readability</a>.</p><p>And the “application web” is plagued by the document characteristics - interactive applications are going to great lengths to avoid most of the essential characteristics of HTML &amp; CSS and just use them as raw materials - avoiding writing any HTML directly at all, avoiding <a href="https://mxstbr.com/thoughts/css-in-js">writing any CSS directly at all</a>, avoiding <a href="https://www.react-spring.io/">default animation features</a>, replacing <a href="https://reactrouter.com/">page-based navigation with something that looks like it but works completely differently</a>. The application web uses <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, not HTML, and would like that in the browser itself, or <a href="https://svelte.dev/">Svelte</a>, instead of JavaScript, and would like that too.</p><p>When I read blog posts from ‘traditional web developers’ who are mad that HTML &amp; CSS aren’t enough anymore and that everything is complicated –&nbsp;I think this is largely that the application stack for building websites has replaced the document stack in a lot of places. Where we would use Jekyll or server-side rendering, we now use React or Vue.js. There are advantages to that, but for a lot of minimally-interactive websites, it’s throwing away decades worth of knowledge in exchange for certain performance perks that might not even matter.</p><p>The appeal of social networks is partly because they let us create <em>documents</em> without thinking about web technology, and they provide guarantees around performance, accessibility, and polish that otherwise would take up our time. You don’t have to think about whether your last Facebook post will load quickly on your friend’s phone or whether your Instagram post will be correctly cropped and resized in the timeline - those things are taken care of.</p><p>To some extent, this doesn’t <em>need</em> to be something that only social networks provide, though: standards like <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> and services like <a href="https://www.instapaper.com/">Instapaper</a> show that pleasing formatting and distribution can be done at the <em>platform level</em> and be provided on top of existing vanilla websites.</p><details><summary>These are not absolutes.</summary>Yeah, I can hear it now: but these categories are not …</details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/08/22/clean-starts-for-the-web.html">https://macwright.com/2020/08/22/clean-starts-for-the-web.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/08/22/clean-starts-for-the-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247362</guid>
            <pubDate>Sat, 22 Aug 2020 21:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to update U-Boot for PostmarketOS on the Pine Phone]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24244407">thread link</a>) | @dustfinger
<br/>
August 22, 2020 | https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/ | <a href="https://web.archive.org/web/*/https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 


<!--endtoc-->

<h2 id="introduction">Introduction</h2>

<p>If you are in a hurry to update U-Boot and the SPL on your PinePhone, then please proceed directly to <a href="#write-u-boot-plus-spl-to-bootable-storage">Write U-Boot+SPL to bootable storage</a>.</p>

<p>In this article, I am going to explain what U-Boot, SoC and the SPL are. After that, I will describe the sunxi bootable storage layout as well as the PinePhone boot procedure, so you will understand what you will be updating and why. Then, I will teach you how to determine if an upgrade is required, and I will explain two different ways of upgrading U-Boot. As a special treat for the curious, I will show you the first steps to reverse engineer the U-Boot+SPL firmware blob. I hope this article peeks your curiosity and encourages you to learn more.</p>

<p>Discussed on <a href="https://news.ycombinator.com/item?id=24244407">Hacker News</a> and <a href="https://forum.pine64.org/showthread.php?tid=11099">Pine64</a>.</p>

<h2 id="what-is-u-boot">What is U-Boot?</h2>

<p>U-Boot, or rather <a href="https://en.wikipedia.org/wiki/Das%5FU-Boot">Das U-Boot</a> a.k.a <em>the Universal Boot Loader</em>, is a small program that is loaded into <em>read-only memory</em> (ROM) and is ultimately responsible for loading the Linux kernel. Designed with flexibility in mind, U-Boot now supports <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/arch">a wide variety of architectures</a> for <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/board">embedded boards</a>, each of which may support multiple boot methods. This article is only concerned with U-Boot as it is configured for the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/board/sunxi/README.sunxi64">Allwinner 64-bit boards</a>, specifically the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>.</p>

<h2 id="what-is-a-soc">What is a SoC?</h2>

<p>No, it does not refer to the stinky fabric covering your feet. <em>SoC</em> stands for <em>System on a Chip</em>. The PinePhone contains the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>, featuring a Quad-Core <a href="https://en.wikipedia.org/wiki/ARM%5FCortex-A53">ARM Cortex-A53 ARMv8-A CPU</a> and an <a href="https://linux-sunxi.org/Mali400">ARM Mali400 MP2 GPU</a>. See the <a href="https://linux-sunxi.org/A64#Documentation">Allwinner A64 documentation</a> for more details.</p>

<h2 id="what-is-the-spl">What is the SPL?</h2>

<p>The <em>Secondary Program Loader’s</em> (SPL) primary function is to load U-Boot proper, the <em>flattened device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>Arm Trusted Firmware</em> (<a href="https://www.trustedfirmware.org/about/">ATF</a>), ultimately passing execution to the ATF. In particular, execution is passed to <em>Trusted Firmware-A</em> (<a href="https://trustedfirmware-a.readthedocs.io/en/latest/index.html">TF-A</a>), which is <a href="https://github.com/ARM-software/arm-trusted-firmware">the official reference implementation</a> used by SoCs with armv8- cores, such as <a href="https://trustedfirmware-a.readthedocs.io/en/latest/plat/allwinner.html">Allwinner Armv8-A SoCs</a>.</p>

<h2 id="what-installs-the-spl">What installs the SPL?</h2>

<p>The SPL is installed via the <code>u-boot-pinephone</code> package from the <a href="http://postmarketos1.brixit.nl/postmarketos/master/aarch64/">postmarketOS aarch64 APK repository</a>. The package is built from the <a href="https://gitlab.com/pine64-org/u-boot/">pine64 u-boot fork</a> in which they added a <a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/.gitlab-ci-pine64.yml">pine64 specific GitLab CI/CD pipeline configuration</a>. By listing the contents of the package using the <a href="https://wiki.alpinelinux.org/wiki/Alpine%5FLinux%5Fpackage%5Fmanagement#apk%5Finfo">apk info</a> command we can see where the SPL binary is actually installed to the root file system.</p>
<div><pre><code data-lang="sh">second-chance:~$ apk info -L u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone-2020.04_git20200421-r1 contains:
usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>However, this is just a convenient location to deliver the binary. The SPL must be deployed to a specific location on disk so that the BootROM can load it.</p>

<h2 id="a-bit-about-bytes">A bit about bytes</h2>

<p>I suspect that not all of those reading this article are familiar with the various standards when it comes to measuring information. Allow me to digress with a brief introduction to these standards with respect to how they both measure and represent a <em>kilobyte</em>. Many of the articles that I have linked herein use the <em><a href="https://en.wikipedia.org/wiki/JEDEC%5Fmemory%5Fstandards#Unit%5Fprefixes%5Ffor%5Fsemiconductor%5Fstorage%5Fcapacity">Joint Electron Device Engineering Council</a></em> (JEDEC) memory standards in which the unit for <em>kilobyte</em> is denoted by (<code>KB</code>), in upper case letters and represents <code>1024B</code>. This is not to be confused with the kilobyte from the <em><a href="https://en.wikipedia.org/wiki/Metric%5Fprefix/">International System of Quantities</a></em> (SI) in which <em>kilo</em> is denoted with a lower case <code>k</code>, such that <code>kB</code> means <code>1000B</code>. My preference is to use the <a href="https://en.wikipedia.org/wiki/Kibibyte">kibibyte</a> (pron. KI-BEE-BYTE), which was established by the <em><a href="https://en.wikipedia.org/wiki/International%5FElectrotechnical%5FCommission">International Electrotechnical commission</a></em> (IEC) and is recognized by all major standards organizations, including those aforementioned.</p>

<table>
<thead>
<tr>
<th>Decimal</th>
<th></th>
<th>Binary</th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>Value</td>
<td>Metric</td>
<td>Value</td>
<td>IEC</td>
<td>JEDEC</td>
</tr>

<tr>
<td>1</td>
<td>B byte</td>
<td>1</td>
<td>B byte</td>
<td>B byte</td>
</tr>

<tr>
<td>1000</td>
<td>kB kilobyte</td>
<td>1024</td>
<td>KiB kibibyte</td>
<td>KB kilobyte</td>
</tr>

<tr>
<td>1000^2</td>
<td>MB megabyte</td>
<td>1024^2</td>
<td>MiB mebibyte</td>
<td>MB megabyte</td>
</tr>

<tr>
<td>1000^3</td>
<td>GB gigabyte</td>
<td>1024^3</td>
<td>GiB gibibyte</td>
<td>GB gigabyte</td>
</tr>

<tr>
<td>1000^4</td>
<td>TB terabyte</td>
<td>1024^4</td>
<td>TiB tebibyte</td>
<td>-</td>
</tr>
</tbody>
</table>

<p>The reasoning behind my preference is two fold:</p>

<ol>
<li>The JEDEC <a href="https://www.jedec.org/document%5Fsearch?search%5Fapi%5Fviews%5Ffulltext=JESD100B01">Terms, Definitions, and Letter Symbols for Microcomputers, Microprocessors, and Memory Integrated Circuits</a> only defines the first three higher order prefixes: <em>kilo</em> (K), <em>mega</em> (M), <em>giga</em> (G), referring to them for common usage. The prefix <em>tera</em> was later added to the JEDEC terms dictionary to reflect <a href="https://www.jedec.org/standards-documents/dictionary/terms/mega-m-prefix-units-semiconductor-storage-capacity">common prefix usage for modern semiconductor storage capacity</a>.</li>
<li>IEC prefixes cannot be confused with Metric prefixes.</li>
</ol>

<p>To make matters more confusing, sometimes lowercase <code>k</code> is used to mean 1024, e.g. see <a href="https://man7.org/linux/man-pages/man1/tar.1.html#OPTIONS">tar(1) OPTIONS</a> sub section <code>Size Suffixes</code> located <a href="https://man7.org/linux/man-pages/man1/tar.1.html#RETURN%5FVALUE">above the RETURN VALUE section</a>. Understanding which system of measurement is being used is essential when calculating offsets.</p>

<h2 id="layout-of-sunxi-bootable-storage">Layout of sunxi bootable storage</h2>

<p>The first 40 plus <code>KiB</code> of bootable storage for an Allwinner based board has the <a href="https://linux-sunxi.org/Bootable%5FSD%5Fcard#SD%5FCard%5FLayout">following default layout</a>:</p>

<table>
<thead>
<tr>
<th>Start</th>
<th>Size</th>
<th>Usage</th>
</tr>
</thead>

<tbody>
<tr>
<td>0KiB</td>
<td>8KiB</td>
<td>Reserved for optional MBR or GPT</td>
</tr>

<tr>
<td>8KiB</td>
<td>32KiB</td>
<td>Initial SPL</td>
</tr>

<tr>
<td>40KiB</td>
<td>-</td>
<td>U-Boot Proper</td>
</tr>
</tbody>
</table>

<p>From the layout, one can conclude that upgrading the SPL and U-Boot for the PinePhone must involve writing the <code>u-boot-sunxi-with-spl.bin</code> to bootable storage starting at <code>8192B</code>.</p>

<h2 id="pinephone-boot-procedure">PinePhone boot procedure</h2>

<p>Bootstrapping is complicated by initial memory address space limitations. The <a href="https://linux-sunxi.org/BROM#U-Boot%5FSPL%5Flimitations">SPL is limited to 32 KiB</a>, most likely because the BootROM, or BROM, loads the SPL into <a href="https://linux-sunxi.org/A64/Memory%5Fmap">SRAM A1</a>, which is a <code>32 KiB</code> subsection. If the SPL is larger than <code>32 KiB</code> the BROM will refuse to load it. After the SPL loads U-Boot proper and passes execution to the ATF, U-Boot proper in turn runs <a href="https://gitlab.com/postmarketOS/pmaports/-/blob/master/device/community/device-pine64-pinephone/uboot-script.cmd">the Pine Phone’s u-boot command script</a>. The command script sets the default bootargs for init and calls the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/cmd/booti.c">booti command</a>, which boots the Linux Kernel Image from memory given the <em>flattend device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>initial ramdisk</em> (<a href="https://en.wikipedia.org/wiki/Initrd">initrd</a>), ultimately passing execution to Linux init.</p>



<div>
  
<div><pre><code data-lang="text">+-----------------------+
|        BootROM        |
+-----------.-----------+
|
|
+-----------V-----------+
|     u-boot.itb+SPL    |
+-----------.-----------+
|
|
+-----------V-----------+
|       TF-A BL31       |
+-----------.-----------+
|
|
+-----------V-----------+
| U-Boot Proper (=BL33) |
+-----------.-----------+
|
|
+-----------V-----------+
|        Linux          |
+-----------------------+</code></pre></div>
</div>

<p>You might have noticed that <code>/usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code> is much larger than <code>32KiB</code>.</p>
<div><pre><code data-lang="text">second-chance:~$ ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin
-rw-r--r--    1 root     root      486.0K Jun 20 12:41 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>That is because the SPL binary image includes a <em>Flattened uImage Tree</em> (<a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/doc/uImage.FIT/source%5Ffile%5Fformat.txt">FIT image</a>) named <code>u-boot.itb</code> that contains the rest of the firmware.</p>

<h2 id="determine-which-bootable-storage-device-is-relevant">Determine which bootable storage device is relevant</h2>

<p>Before you can <a href="#how-to-determine-if-u-boot-needs-to-be-upgraded">determine if U-Boot needs to be upgraded</a>, you need to know which storage device your PinePhone is booting from. This can be easily determined by using the <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> command to list the running operating system’s current mount points. Below is the output of <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> run on my PinePhone booted from an <code>SD</code> card:</p>
<div><pre><code data-lang="sh">second-chance:~$ lsblk --output NAME,TYPE,MOUNTPOINT</code></pre></div><div><pre><code data-lang="text">NAME         TYPE MOUNTPOINT
mmcblk0      disk
├─mmcblk0p1  part /boot
└─mmcblk0p2  part
mmcblk2      disk
├─mmcblk2p1  part
├─mmcblk2p2  part
├─mmcblk2p1  part
└─mmcblk2p2  part
mmcblk2boot0 disk
mmcblk2boot1 disk</code></pre></div>
<p>The disk corresponding to the <code>/boot</code> mountpoint is the name of the block special device that postmarketOS is currently running form. The device path to the relevant boot storage device is therefore <code>/dev/mmcblk0</code>. We will be using this device name in the next two sections to determine if an upgrade is needed and again to perform the actual upgrade if warranted. You must be careful to use the device name that is relevant to your own running environment if you are following along.</p>

<h2 id="how-to-determine-if-u-boot-needs-to-be-upgraded">How to determine if U-Boot needs to be upgraded?</h2>

<p>You can determine if an upgrade is necessary simply by comparing the version of U-Boot installed by the <code>u-boot-pinephone</code> package with the version of U-Boot that is written to <a href="#determine-which-bootable-storage-device-is-relevant">the bootable storage device which is relevant to your running environment</a>.</p>

<p>To see which version of <code>U-Boot</code> was installed by the <code>u-boot-pinephone</code> package, simply run the <code>apk policy</code> sub command as shown below:</p>
<div><pre><code data-lang="sh">second-chance:~/$ apk policy u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone policy:
  2020.04_git20200421-r1:
    lib/apk/db/installed
    etc/apk/cache
    http://postmarketos1.brixit.nl/postmarketos/master</code></pre></div>
<p>Alternatively, you can use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>strings</code> command to search the binary’s printable strings for the regex pattern <code>U-Boot [[:digit:]]</code> by piping the output through a <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>grep</code> filter. As a side note, the PinePhone uses busybox, so when you find yourself looking up command line documentation with the intention of running the command from a PinePhone shell, always check the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> man pages first.</p>
<div><pre><code data-lang="sh">second-chance:~/packages$ strings /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin | grep -E <span>'U-Boot [[:digit:]]'</span></code></pre></div><div><pre><code data-lang="text">U-Boot 2020.04 (Jun 20 2020 - 12:41:48 +0000)</code></pre></div>
<p>Similarly, to determine the version of U-Boot that is currently written to bootable storage, you can search for the same regex pattern in the printable strings of the boot disk after the first <code>8 KiB</code>. However, since the bootable storage is significantly larger than <code>u-boot-sunxi-with-spl.bin</code>, it would not be efficient to use the <code>strings</code> command as we did previously. Instead, we will use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>dd</code> command, which will allow us to control where to begin and end the search. Since we can’t easily know the exact offset of the version string, which can very from build to build, my strategy has been to simply skip the first <code>8 KiB</code> and then read the same number of <code>KiB</code> as the size of the currently installed <code>u-boot-sunxi-with-spl.bin</code>. If my search turns up nothing, then that means that the previously installed version was larger, and I can simply increase the <code>count</code> to some reasonable number of <code>KiB</code> until I find what I am looking for.</p>

<p>First, let’s determine the size of <code>u-boot-sunxi-with-spl.bin</code>.</p>
<div><pre><code data-lang="sh">ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div><div><pre><code data-lang="text">-rw-r--r--    1 root     root      543.3K Jul 18  2020 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>The binary installed to disk is about <code>5…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</a></em></p>]]>
            </description>
            <link>https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244407</guid>
            <pubDate>Sat, 22 Aug 2020 14:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build tools around workflows, not workflows around tools]]>
            </title>
            <description>
<![CDATA[
Score 435 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24244329">thread link</a>) | @thesephist
<br/>
August 22, 2020 | https://thesephist.com/posts/tools/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><em>This March, I spent a couple of days traveling through western Iceland.</em></p>
<p><img src="https://thesephist.com/img/iceland.jpg" alt="Iceland, part 1"></p>
<p>While I was there, I thought a lot about tools – mechanical tools, software tools, tools that last, and tools that are fragile. The somber snow-covered scenery made me think about how quickly most of the tools we use today get outdated or replaced, and I thought about the kinds of tools that I’ve been building for myself for the last few years to help organize my life.</p>
<p>I took a walk around <em>Smábátahöfnin í Keflavík</em> (a small marina nearby) that night, unraveled myself into my hotel room, and started writing this post.</p>
<p>I want to share why I build my own tools and how I think we should think about building tools for life. It’s long, so here’s a roadmap. Feel free to jump around.</p>
<ol>
<li><a href="#my-tools-today">My tools, today</a></li>
<li><a href="#workflows--tools">Workflows &gt; tools</a>
<ol>
<li><a href="#tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</a></li>
<li><a href="#tools-that-grow-with-your-workflows">Tools that grow with your workflows</a></li>
</ol>
</li>
<li><a href="#own-your-load-bearing-tools-of-life">Own your load-bearing tools of life</a></li>
<li><a href="#cost-and-other-smaller-benefits">Cost and other smaller benefits</a></li>
<li><a href="#your-tools-are-an-extension-of-you">Your tools are an extension of you</a></li>
<li><a href="#appendix-the-technical-nitty-gritty">Appendix: the technical nitty-gritty</a></li>
</ol>
<hr>

<p>For the last few years, I’ve been on a journey to replace all of the essential digital tools I use for organizing my life with tools I develop, maintain, and deploy myself.</p>
<p>What started with a single-page notes app I made in high school has grown into a constellation of home-grown productivity tools I now rely on for my day-to-day work and learning. Here’s a sample.</p>
<ul>
<li>
<p><a href="https://github.com/thesephist/polyx#ligature">Ligature</a>, for long-term notes and tasks, goals, brainstorming, project planning, and other important writing.</p>
<p><img src="https://thesephist.com/img/ligature.jpg" alt="Ligature"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/pico">Pico</a>, for more ephemeral notes and tasks that change on a daily basis. I split up my notes into two apps (Ligature and Pico) because it works better for my workflow. (More on this later.)</p>
<p><img src="https://thesephist.com/img/pico.jpg" alt="Pico"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/mira">Mira</a> for keeping track of people I know, why they’re interesting, and what we’ve talked about.</p>
<p><img src="https://thesephist.com/img/mira.png" alt="Mira"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/lovecroft">Lovecroft</a> for managing and sending emails to my <a href="https://thesephist.com/#newsletter">mailing lists</a>.</p>
<p><img src="https://thesephist.com/img/lovecroft.jpg" alt="Lovecroft"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/polyx#noct">Noct</a> for backing up and syncing all my files across computers and the cloud. Noct doesn’t have a graphical UI, just a command-line tool.</p>
</li>
<li>
<p><a href="https://thesephist.com/posts/frieden/">Frieden</a> as a public availability calendar, showing when I’m free or busy.</p>
<p><img src="https://thesephist.com/img/frieden.png" alt="Frieden"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/thingboard">Thingboard</a> for more free-form Post-its-on-the-wall style brainstorming.</p>
<p><img src="https://thesephist.com/img/thingboard.jpg" alt="Thingboard"></p>
</li>
<li>
<p><a href="https://codeframe.co/">Codeframe</a> for spinning off simple JavaScript experiments like <a href="https://thesephist.com/posts/word-experiments/#word-plotter">the word plotter</a>.</p>
<p><img src="https://thesephist.com/img/codeframe.jpg" alt="Codeframe"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/draw">draw</a>, a collaborative whiteboard, best used with my iPad Pro and Apple Pencil.</p>
<p><img src="https://thesephist.com/img/draw.jpg" alt="Draw"></p>
</li>
</ul>
<p>Taken together, these apps do almost everything I need to do on my computer to keep myself organized. I don’t use any third-party notes, task management, or contacts apps, though I used to be a big fan of Simplenote and Todoist. I’ve used Notion, Dropbox Paper, Google Docs, and Airtable, but only for working in teams that centralized on them. These days, besides email and calendar, I live within a system of my own tools, and it works well for me.</p>
<p>I don’t want to imply that my tools are objectively better than the professional tools on the market like Notion and Dropbox. Those latter services have more features, and might even be more reliable today. But I think my tools fit me better for a different reason.</p>

<p>Each person’s mind works a little differently, and each person remembers and processes information a little differently. I think we all work at our best when we work with tools that fit how our minds work.</p>
<p>The Eureka moment that some of us feel when we finally find a notes app or todo system that fits our brains – that epiphany happens when the tools we use mirror the way our minds work, and how we want to move information through our lives. Good tools fit perfectly around our workflows, bad tools don’t.</p>
<p>When we resort to having other people build tools for us, the tools they build might never quite perfectly fit our workflows, because they’re not built for our individual minds. When other people build tools for us to use, they either design tools after their own workflows and mental models, or worse, they design it for a mass market of millions of people who all sort-of-but-not-really work and think in similar ways. The result is that mass-market productivity tools don’t fit the way our individual minds are predisposed to work. Instead, to use these tools, we need to bend our workflows to fit around the tools.</p>
<p>My biggest benefit from writing my own tool set is that <strong>I can build the tools that exactly conform to my workflows, rather than constructing my workflows around the tools available to me.</strong> This means the tools can truly be an extension of the way my brain thinks and organizes information about the world around me. My tools aren’t perfect yet, but as they grow and evolve, they’ll only become better reflections of my personal mental models.</p>
<p>For example, one place where my mind works differently than the tools on the market is the task/notes distinction.</p>
<h3 id="tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</h3>
<p>My workflow used to differentiate between tasks and notes. Tasks were action items that I could reference, take action on, and complete, and then erase from my list. Notes were things that were indefinitely relevant. I would take notes and then come back to reference them many times. A note by itself isn’t actionable.</p>
<p>But once I started building my own tools, I realized this distinction isn’t really the way my brain worked. For me, a huge grey area exists between actionable, completable tasks and purely encyclopedic notes. Here are some things that fall in the grey area for me, pulled from my real, actual notes I took this week.</p>
<ol>
<li>I recently learned some really useful tips about how to grow leaders within a community from the book <em><a href="https://gettogetherbook.com/">Get Together</a></em>. I definitely want to act on these learnings at some point in the communities I lead, but I don’t want them cluttering up my todo list because they’re not things I can just complete and check off quickly. I also want to remember these tips forever, even after the first time I act on them.</li>
<li>I’ve been brainstorming an idea for a side project related to <a href="https://en.wikipedia.org/wiki/Computer_algebra">symbolic mathematics</a>. I’ve been writing down my inspirations related to this project. I don’t want to tuck it away in my notes, because this is something I want to build soon, but I also don’t want to shove paragraphs of notes into a todo list item.</li>
<li>I keep a running list of ideas I have for future blog posts, but I don’t really have a “write the next blog post” task item under which I’d normally put these ideas, because I don’t write on schedule – I just write when I can. Where should these ideas go? They’re sort-of notes and sort-of tasks.</li>
</ol>
<p>You might think that these are either very clearly todo items or very clearly notes, and that’s ok. But I certainly felt differently, and I realized I was only separating things into these two buckets because my tools forced me to. Before I wrote my own tools, I had a todo app (Todoist) and I had a notes app (Simplenote), and there was nothing in between.</p>
<p>Eventually, I discovered a better mental model for my working style: I ask myself <em>how immediately</em> I need to take action on something.</p>
<p>The way that I see it, everything I learn and jot down is something for me to act on at some point in my life. If I read something that I never thought would influence the way I lived, it wouldn’t have value to me, and I simply wouldn’t write it down. Armed with this insight, these days, I have two different notes apps, and I don’t use a todo list app. These two apps are Ligature and Pico, mentioned above.</p>
<p>One is for notes that are changing often. Day-to-day tasks, things to remember for the next week, even long notes and links related to what I’m working on <em>now</em>. The other app is for notes that grow over time, like notes I take while reading books or watching talks, my annual goals, financial planning, reading list, and project outlines. <strong>My two notes apps mirror the way my brain works best – one is my short-term, working memory, the other is my long-term memory.</strong></p>
<p>I’ve had this system for a few months now, and haven’t felt any need for something better. It doesn’t have the crazy features of some notes services on the market today, but it just works the way my brain does.</p>
<p>But what if I need something different later on in life?</p>
<h3 id="tools-that-grow-with-your-workflows">Tools that grow with your workflows</h3>
<p>The other benefit of building homebrew tools is that <strong>tools you build yourself can grow and change as your workflow changes over time</strong>. So if my needs do change over time, my tools can grow to accommodate exactly what I need.</p>
<p>When I first started keeping more organized notes on the interesting people I met, I started with a document in my notes app. Over time, I noticed that these notes followed a pattern: I wrote down their name and primary contact info, how I first met them, what school they went to, and what we talked about the last time we spoke.</p>
<p>So when I built Mira, my own people-manager app, I designed it around that exact workflow I had developed. When I later realized I was also recording people’s Twitter usernames in the description field, I just added a Twitter username field to each contact.</p>
<p>This is typical of the way I <em>discover</em> my workflows. <strong>I start with a minimal, bare-bones solution, and try to pick up on patterns and tricks I create for myself. And then I encode those patterns and tricks into the tools over time.</strong></p>
<p>This way, my tools can grow organically as my workflows evolve. Neither of them gets in the way of each other most of the time, and I think that was hard to appreciate before I started relying wholly on my own tools.</p>

<p>My productivity tools, especially my notes and contacts, are the load-bearing tools of my life. If they break or disappear, it’ll take a long time and a lot of effort for me to rebuild those same workflows and tools, so it’s important that they’re reliable, and that I can depend on them working for me for a long time (measured in years and decades, not quarters).</p>
<p>I’ve written at length about <a href="https://thesephist.com/posts/ownership/">the importance of ownership</a> before. I want to own the pieces of my life that are most critical, and I want agency over how these tools change over time.</p>
<p>I want these notes and ideas and workflows to stick with me as I grow as a person through the next decades. If I had to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/tools/">https://thesephist.com/posts/tools/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244329</guid>
            <pubDate>Sat, 22 Aug 2020 14:23:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rolling your own crypto gone wrong: A look at a .NET Branca implementation]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243750">thread link</a>) | @todsacerdoti
<br/>
August 22, 2020 | https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html | <a href="https://web.archive.org/web/*/https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h3 id="introduction">Introduction</h3>

<p>Some time back, I was looking at token authentication formats to authenticate some API calls. I didn’t even attempt to look at JWT &amp; Co. for <a href="https://paragonie.com/blog/2017/03/jwt-json-web-tokens-is-bad-standard-that-everyone-should-avoid">multiple reasons</a>. I landed between <a href="https://paseto.io/">PASETO</a> and <a href="https://branca.io/">Branca</a>.</p>

<p>I chose Branca for its simplicity. I needed authenticated API calls with a shared symmetric key. Both Branca and PASETO implemented this using XChaCha20-Poly1305, but PASETO also supports asymmetric authentication, which I didn’t need. I was quite pleased by looking at how straight-forward Branca <a href="https://github.com/tuupola/branca-spec#token-format">made it</a>:</p>
<div><div><pre><code>Version (1B) || Timestamp (4B) || Nonce (24B) || Ciphertext (*B) || Tag (16B)
</code></pre></div></div>

<p>Simply construct a header and encrypt and authenticate the payload using XChaCha20-Poly1305, with the header as the AAD.</p>

<p>Back then, there was only one <a href="https://github.com/thangchung/branca-dotnet">.NET implementation</a>, which targeted .NET Core whereas I needed .NET Framework. I took a quick look: there were no test vectors and used ChaCha20-Poly1305 instead of XChaCha20-Poly1305. It was only available GitHub, so I thought it may just be a toy project for fun. I dropped it and forgot about it.</p>

<p>Fast forward a couple of days ago, I returned to find <a href="https://github.com/scottbrady91/IdentityModel">a new</a> .NET Core implementation. It was also published as a NuGet, which got my hopes up - might be a polished implementation that I could get working on .NET Framework.</p>

<p><a href="https://www.nuget.org/packages/ScottBrady.IdentityModel/">ScottBrady.IdentityModel</a> is a relatively new NuGet, with three releases in total. Its first release was at the beginning of May this year and the latest was at the beginning of this August. It uses <a href="https://www.bouncycastle.org/csharp/index.html">BouncyCastle</a> for cryptographic implementations and offers both PASETO and Branca.</p>

<p>Note: All code discussed is based on the master branch at <a href="https://github.com/scottbrady91/IdentityModel/commit/4ff8a06719bd83a4129f45d2ce92f1891a51bd01">4ff8a06</a>. I’ll also be referring to this NuGet as just IdentityModel throughout the rest of this post.</p>

<h3 id="inspection">Inspection</h3>

<h4 id="tokenssecuritytokenexception-invalid-message-authentication-code">Tokens.SecurityTokenException: Invalid message authentication code</h4>

<p>I pulled down IdentityModel in a new project and took some <a href="https://github.com/tuupola/branca-js/blob/master/test.js">test vectors</a> from the JS reference implementation, which is linked in the specification for Branca.</p>

<div><div><pre><code><span>static</span> <span>void</span> <span>TestBranca</span><span>(</span><span>string</span> <span>expectedToken</span><span>,</span> <span>string</span> <span>expectedPayload</span><span>)</span> 
<span>{</span>
    <span>var</span> <span>handler</span> <span>=</span> <span>new</span> <span>BrancaTokenHandler</span><span>();</span>
    <span>var</span> <span>key</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>"supersecretkeyyoushouldnotcommit"</span><span>);</span>

    <span>try</span>
    <span>{</span>
        <span>var</span> <span>actualToken</span> <span>=</span> <span>handler</span><span>.</span><span>CreateToken</span><span>(</span><span>expectedPayload</span><span>,</span> <span>key</span><span>);</span>
        <span>var</span> <span>actualPayload</span> <span>=</span> <span>handler</span><span>.</span><span>DecryptToken</span><span>(</span><span>expectedToken</span><span>,</span> <span>key</span><span>);</span>
    <span>}</span>
    <span>catch</span> <span>(</span><span>Exception</span> <span>e</span><span>)</span>
    <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"FAILED: \nexpectedToken: {0}\nexpectedPayload: {1}\nexception: {2}\n"</span><span>,</span> <span>expectedToken</span><span>,</span> <span>expectedPayload</span><span>,</span> <span>e</span><span>.</span><span>Message</span><span>);</span>
    <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
<span>{</span>
    <span>TestBranca</span><span>(</span><span>"870S4BYjk7NvyViEjUNsTEmGXbARAX9PamXZg0b3JyeIdGyZkFJhNsOQW6m0K9KnXt3ZUBqDB6hF4"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
    <span>TestBranca</span><span>(</span><span>"89i7YCwtsSiYfXvOKlgkCyElnGCOEYG7zLCjUp4MuDIZGbkKJgt79Sts9RdW2Yo4imonXsILmqtNb"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
    <span>TestBranca</span><span>(</span><span>"875GH234UdXU6PkYq8g7tIM80XapDQOH72bU48YJ7SK1iHiLkrqT8Mly7P59TebOxCyQeqpMJ0a7a"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Running the above tests gave me:</p>

<div><div><pre><code>FAILED: 
expectedToken: 870S4BYjk7NvyViEjUNsTEmGXbARAX9PamXZg0b3JyeIdGyZkFJhNsOQW6m0K9KnXt3ZUBqDB6hF4
expectedPayload: Hello world!
exception: Invalid message authentication code

FAILED: 
expectedToken: 89i7YCwtsSiYfXvOKlgkCyElnGCOEYG7zLCjUp4MuDIZGbkKJgt79Sts9RdW2Yo4imonXsILmqtNb
expectedPayload: Hello world!
exception: Invalid message authentication code

FAILED: 
expectedToken: 875GH234UdXU6PkYq8g7tIM80XapDQOH72bU48YJ7SK1iHiLkrqT8Mly7P59TebOxCyQeqpMJ0a7a
expectedPayload: Hello world!
exception: Invalid message authentication code
</code></pre></div></div>

<p>I was already off to a good start.</p>

<h4 id="nonce-generation">Nonce generation</h4>
<p>Starting at the top of the file containing the Branca implementation, comes <code>CreateToken()</code>. The first thing is nonce generation:</p>
<div><div><pre><code><span>var</span> <span>nonce</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>24</span><span>];</span>
<span>RandomNumberGenerator</span><span>.</span><span>Create</span><span>().</span><span>GetBytes</span><span>(</span><span>nonce</span><span>);</span>
</code></pre></div></div>

<p>It uses the <a href="https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.randomnumbergenerator.getbytes?view=netcore-3.1">System.Security.Cryptography.RandomNumberGenerator.GetBytes</a> method, which is intended for cryptographic purposes, so that checks out.</p>

<h4 id="unauthenticated-ciphertext">Unauthenticated ciphertext</h4>

<p>After the nonce is generated, the header is created according to the specification. No problem there. Then comes the encryption:</p>

<div><div><pre><code><span>keyMaterial</span> <span>=</span> <span>new</span> <span>KeyParameter</span><span>(</span><span>key</span><span>);</span>
<span>var</span> <span>parameters</span> <span>=</span> <span>new</span> <span>ParametersWithIV</span><span>(</span><span>keyMaterial</span><span>,</span> <span>nonce</span><span>);</span>

<span>var</span> <span>engine</span> <span>=</span> <span>new</span> <span>XChaChaEngine</span><span>();</span>
<span>engine</span><span>.</span><span>Init</span><span>(</span><span>true</span><span>,</span> <span>parameters</span><span>);</span>
</code></pre></div></div>

<p>I’m not familiar with BouncyCastle, so I checked its source to see what <code>KeyParameter</code> and <code>ParametersWithIV</code> were doing. They were simply wrappers for the parameters.</p>

<p><code>XChaChaEngine()</code> was not from BouncyCastle however, but implemented in IdentityModel:</p>

<div><div><pre><code><span>using</span> <span>Org.BouncyCastle.Crypto.Engines</span><span>;</span>

<span>namespace</span> <span>ScottBrady.IdentityModel.Crypto</span>
<span>{</span>
    <span>public</span> <span>class</span> <span>XChaChaEngine</span> <span>:</span> <span>ChaChaEngine</span>
    <span>{</span>
        <span>public</span> <span>XChaChaEngine</span><span>()</span> <span>:</span> <span>base</span><span>(</span><span>20</span><span>)</span> <span>{</span> <span>}</span>

        <span>public</span> <span>override</span> <span>string</span> <span>AlgorithmName</span> <span>=&gt;</span> <span>"XChaCha20"</span><span>;</span>

        <span>protected</span> <span>override</span> <span>int</span> <span>NonceSize</span> <span>=&gt;</span> <span>24</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>After initializing the <code>XChaChaEngine</code>, the payload is “encrypted and authenticated”:</p>

<div><div><pre><code><span>var</span> <span>plaintextBytes</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>payload</span><span>);</span>
<span>var</span> <span>ciphertext</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>plaintextBytes</span><span>.</span><span>Length</span> <span>+</span> <span>16</span><span>];</span>

<span>engine</span><span>.</span><span>ProcessBytes</span><span>(</span><span>plaintextBytes</span><span>,</span> <span>0</span><span>,</span> <span>plaintextBytes</span><span>.</span><span>Length</span><span>,</span> <span>ciphertext</span><span>,</span> <span>0</span><span>);</span>

<span>var</span> <span>poly</span> <span>=</span> <span>new</span> <span>Poly1305</span><span>();</span>
<span>poly</span><span>.</span><span>Init</span><span>(</span><span>keyMaterial</span><span>);</span>
<span>poly</span><span>.</span><span>BlockUpdate</span><span>(</span><span>header</span><span>,</span> <span>0</span><span>,</span> <span>header</span><span>.</span><span>Length</span><span>);</span>
<span>poly</span><span>.</span><span>DoFinal</span><span>(</span><span>ciphertext</span><span>,</span> <span>plaintextBytes</span><span>.</span><span>Length</span><span>);</span>
</code></pre></div></div>

<p>This is <strong>not a XChaCha20-Poly1305 construction</strong>. There is no padding of the AAD nor the ciphertext during authentication. Neither is there any authentication of their length. All this is specified in the <a href="https://github.com/bikeshedders/xchacha-rfc">draft RFC</a> and the <a href="https://tools.ietf.org/html/rfc8439">RFC for ChaCha20-Poly1305</a>. Actually, this does not even authenticate the ciphertext since <code>DoFinal()</code> writes the current tag into <code>ciphertext</code>. The <strong>ciphertext can be modified without invalidating the token</strong>.</p>

<div><div><pre><code><span>var</span> <span>handler</span> <span>=</span> <span>new</span> <span>BrancaTokenHandler</span><span>();</span>
<span>var</span> <span>key</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>"supersecretkeyyoushouldnotcommit"</span><span>);</span>
<span>var</span> <span>actualToken</span> <span>=</span> <span>handler</span><span>.</span><span>CreateToken</span><span>(</span><span>"Test"</span><span>,</span> <span>key</span><span>);</span>
<span>var</span> <span>decoded</span> <span>=</span> <span>Base62</span><span>.</span><span>Decode</span><span>(</span><span>actualToken</span><span>);</span>
<span>decoded</span><span>[</span><span>decoded</span><span>.</span><span>Length</span> <span>-</span> <span>17</span><span>]</span> <span>^=</span> <span>1</span><span>;</span> <span>// Last byte before the Poly1305 tag</span>
<span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"{0}"</span><span>,</span> <span>handler</span><span>.</span><span>DecryptToken</span><span>(</span><span>Base62</span><span>.</span><span>Encode</span><span>(</span><span>decoded</span><span>),</span> <span>key</span><span>).</span><span>Payload</span><span>);</span>
</code></pre></div></div>

<p>Running this will return <code>Tesu</code> instead of <code>Test</code>. Thereby, <strong>IdentityModel allows attackers to arbitrarily modify the payload of a Branca token</strong>.</p>

<p>After searching BouncyCastle, I found no XChaCha20 implementation but a ChaCha20-Poly1305, which had the following fields:</p>

<div><div><pre><code><span>private</span> <span>readonly</span> <span>ChaCha7539Engine</span> <span>mChacha20</span><span>;</span>
<span>private</span> <span>readonly</span> <span>IMac</span> <span>mPoly1305</span><span>;</span>
</code></pre></div></div>

<p>As you might have noticed, <code>ChaCha7539Engine</code> is not the same engine that is implemented by <code>XChaChaEngine</code> in IdentityModel. Turns out, IdentityModel uses the ChaCha20 variant with a 64-bit nonce, instead of the 96-bit nonce required by the IETF version of ChaCha20. Both ChaCha20-Poly1305 and XChaCha20-Poly1305 require the IETF variant of ChaCha20. Taking a look at <code>ChaChaEngine</code> from BouncyCastle, there is no HChaCha20 being used to calculate a subkey, if the nonce length is set to 24 as in <code>XChaChaEngine</code>. Therefore, all we’re left with is the original ChaCha20 from DJB, using an 8-byte nonce, meaning <code>engine.Init(true, parameters)</code> only loads 8 bytes of the 24-byte nonce that has been generated.</p>

<p>The Branca specification makes it <a href="https://github.com/tuupola/branca-spec">pretty clear</a> how to encrypt the payload:</p>
<blockquote>
  <ol>
    <li>Encrypt the user given payload with IETF XChaCha20-Poly1305 AEAD with user-provided secret key. Use the header as the additional data for AEAD.</li>
  </ol>
</blockquote>

<p>It doesn’t have to be made as complicated as the above code from IdentityModel. If one reads the draft RFC, or looks at another implementation, it eventually becomes clear that XChaCha20-Poly1305 is “just” a combination of HChaCha20 and ChaCha20-Poly1305.</p>

<h4 id="forgeable-tokens">Forgeable tokens</h4>
<p>Let’s return to the attempt of authenticating the header and ciphertext. Specifically, this line:</p>


<p><code>keyMaterial</code> is <strong>the same key</strong> that was used to initialize the <code>XChaChaEngine</code>.</p>

<blockquote>
  <p>The sender must not use crypto_onetimeauth to authenticate more than one message under the same key. Authenticators for two messages under the same key should be expected to reveal enough information to allow forgeries of authenticators on other messages.</p>
</blockquote>

<p>(From <a href="https://nacl.cr.yp.to/onetimeauth.html">NaCl</a>)</p>

<p>As NaCls documentation states, any given key used with Poly1305 may <strong>only be used once</strong> otherwise, an attacker could forge future authenticators. This is a problem since Branca might be used in contexts like authenticating API calls, where long-lived API keys are used. <strong>IdentityModel allows attackers to forge API tokens</strong>.</p>

<p>This would not be a problem in IdentityModel, had it at least used ChaCha20-Poly1305 from BouncyCastle to attempt the Branca implementation. ChaCha20-Poly1305 uses the first 32 bytes of the first keystream-block (64 bytes), of the internal ChaCha20 state, as the Poly1305 one-time key. So if a nonce is unique for every time ChaCha20-Poly1305 is used with any given key (which it <strong>MUST</strong>), the Poly1305 key will also be unique.</p>

<p>Of course, IdentityModel should use XChaCha20-Poly1305, not only because that is what the Branca specification defines, but also because it’s not safe to randomly generate nonces for ChaCha20 or ChaCha20-Poly1305 (see <a href="https://godoc.org/golang.org/x/crypto/chacha20poly1305">/x/crypto</a>). This limitation was the motivation behind XChaCha20-Poly1305 (see <a href="https://github.com/bikeshedders/xchacha-rfc/blob/master/draft-irtf-cfrg-xchacha-rfc-03.txt">draft RFC</a>).</p>

<h4 id="constant-time-mac-comparison">Constant-time MAC comparison</h4>
<p>Any decent ChaCha20-Poly1305 or XChaCha20-Poly1305 implementation will compare the Poly1305 MACs in constant-time, to not reveal information via a timing side-channel. This, unfortunately, is not the case for IdentityModel either:</p>

<div><div><pre><code><span>var</span> <span>headerMac</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>16</span><span>];</span>
<span>[..]</span>
<span>if</span> <span>(!</span><span>headerMac</span><span>.</span><span>SequenceEqual</span><span>(</span><span>tag</span><span>))</span> <span>throw</span> <span>new</span> <span>SecurityTokenException</span><span>(</span><span>"Invalid message authentication code"</span><span>);</span>
</code></pre></div></div>

<p>BouncyCastle uses constant-time comparison with ChaCha20-Poly1305 and provides the comparison function as a utility:</p>

<div><div><pre><code><span>if</span> <span>(!</span><span>Arrays</span><span>.</span><span>ConstantTimeAreEqual</span><span>(</span><span>MacSize</span><span>,</span> <span>mMac</span><span>,</span> <span>0</span><span>,</span> <span>mBuf</span><span>,</span> <span>resultLen</span><span>))</span>
<span>{</span>
    <span>throw</span> <span>new</span> <span>InvalidCipherTextException</span><span>(</span><span>"mac check in ChaCha20Poly1305 failed"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<h3 id="summary">Summary</h3>

<p>I’m a big fan of “rolling your own crypto” and here I’m talking about implementing known algorithms. I do it myself. I even think making it available on GitHub or similar, to ask for feedback, is good (if users are warned that no security can be expected).</p>

<p>However, a problem arises when projects that …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html">https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html</a></em></p>]]>
            </description>
            <link>https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243750</guid>
            <pubDate>Sat, 22 Aug 2020 12:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing better Code (extension to Joel's 12 steps to better Code)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24243656">thread link</a>) | @gerlacdt
<br/>
August 22, 2020 | https://gerlacdt.github.io/posts/writing-better-software/ | <a href="https://web.archive.org/web/*/https://gerlacdt.github.io/posts/writing-better-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>I</span>n Joel Spolsky’s blog post <a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/" target="_blank" rel="noopener">“The Joel Test: 12 Steps to better
Code”</a>,
he describes a test composed of twelve simple yes-no questions. For a
<strong>yes</strong> you get one point. 10 points are acceptable and 12 are
perfect. If you have less than 10 points, you will get in trouble with
your software – sooner or later.</p>
<p>For a quick self-check, these are the original questions:</p>
<ol>
<li>Do you use source control?</li>
<li>Can you make a build in one step?</li>
<li>Do you make daily builds?</li>
<li>Do you have a bug database?</li>
<li>Do you fix bugs before writing new code?</li>
<li>Do you have an up-to-date schedule?</li>
<li>Do you have a spec?</li>
<li>Do programmers have quiet working conditions?</li>
<li>Do you use the best tools money can buy?</li>
<li>Do you have testers?</li>
<li>Do new candidates write code during their interview?</li>
<li>Do you do hallway usability testing?</li>
</ol>
<p>Although Joel’s Test is still an excellent indicator for good software
development and engineering, 20 years have past and many game changing
technologies have emerged like mobile apps, the public cloud and in
general better tooling is available. The success of
<a href="https://git-scm.com/" target="_blank" rel="noopener">git</a> and <a href="https://github.com/" target="_blank" rel="noopener">github</a> changed
how we develop software. In this article i want to extend Joel’s test
with contemporary questions:</p>
<ol start="13">
<li>Do you enforce a common code styleguide?</li>
<li>Do you write tests?</li>
<li>Do you conduct code reviews?</li>
<li>Do your developers write documentation?</li>
<li>Do you focus on code health?</li>
<li>Do you practice continuous integration?</li>
<li>Do you have a mentoring program?</li>
<li>Is your infrastructure reproducible?</li>
<li>Are you doing your best to keep your engineers?</li>
<li>Do you provide the best technology for your developers?</li>
<li>Do you focus on the four key metrics?</li>
<li>Do you empower your developers?</li>
</ol>
<p>The extended test consists of 24 yes-no questions. As with Joel’s
Test, for a <strong>yes</strong> you get one point. The ranking is:</p>
<ul>
<li>&lt;= 20 points, you must improve</li>
<li>21 points, you are ok</li>
<li>22 points, you are a high-performer</li>
<li>23 points, you are a high-performer</li>
<li>24 points, you are best-in-class</li>
</ul>
<p>Further I want to emphasis that <strong>sustainablity</strong> is my main intention
for the test. Many questions contribute directly or indirectly to a
sustainable and healthy codebase which is crucial for a successful
long-term software project and in general for a successful software
company. <a href="https://youtu.be/zW-i9eVGU_k?t=197" target="_blank" rel="noopener">Titus Winters</a> defines a
sustainable codebase as:</p>
<blockquote>
<p>Your organization’s codebase is sustainable when you are able to
change all of the things that you ought to change, safety, and can do
so for the lifetime of your codebase.</p>
</blockquote>
<h4 id="13-do-you-enforce-a-common-code-styleguide"><a href="#13-do-you-enforce-a-common-code-styleguide"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>13. Do you enforce a common code styleguide?</h4>
<p><strong>Consistency</strong> is one of the most important properties of a codebase.
It bolsters readability and maintainability which are essential for
sustainable code. A consistent codebase is easier to grasp and makes
onboarding new developers faster. New programmers are guided by the
prevailing style and can adapt quickly to it. Consistency is also an
indicator for coder’s discipline, clearly you don’t want to have dead
code, unused imports, wrong indentations, and other intricacies in
your codebase. The desired consistency can be achieved by a code
styleguide.</p>
<p>At best you enforce the rules of the styleguide via tooling like
static code analyzers, linters and autoformatting tools. Often these
tools are integrated into the build or are executed before a
commit. Further there are also manually measures like <a href="#codereview">code
reviews</a> to enforce a common code style.</p>
<p>A consistent code style increases productivity, e.g. linters prevent
sloppy programming errors, autoformatters leave no room for useless
(sometimes religious) discussions about indentation and formatting
rules. All code looks the same. Developer’s taste and ego take a back
seat.</p>
<h4 id="14-do-you-write-tests"><a href="#14-do-you-write-tests"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>14. Do you write tests?</h4>
<p>Writing automatic test is a major trait of a sustainable
codebase. There are many kind of tests but the best known
classification comes with the <a href="https://martinfowler.com/articles/practical-test-pyramid.html" target="_blank" rel="noopener">Test
Pyramid</a>.</p>
<ul>
<li>Unit Tests</li>
<li>Service Tests</li>
<li>User Interface Tests</li>
</ul>
<p>Particularly <strong>unit tests</strong> build the foundation and give developers
confidence to move fast and not to break existing functionality. Unit
testing is a major pillar of a fast feedback loop. This keeps
developers happy and the quality high. In general, tests act as a
safety net, prevent new bugs from being introduced and old bugs from
reoccurrence.</p>
<p>Without automatic tests your codebase will erode and only long-term
developers will be capable to make changes. Onboarding new developers
will take months or will never succeed at all. Over time developer
speed will slow down and finally come to a complete halt. Heavily
relying on manual testing before a release is a clear indicator of
missing automatic tests and extends the release cycle by days or
weeks. High performers deploy on a daily basis which is not possible
with manual testing phases. Therefore manual testing should be reduced
to a minimum or completely avoided.</p>
<p>Establishing a good testing culture is especially important. E.g.</p>
<ul>
<li>no code changes without a corresponding test</li>
<li>no bugfix without a test demonstrating the bug is indeed fixed</li>
<li>unit test should be fast, so developers run them continuously</li>
<li>unit test code coverage should be at a reasonable level like ~70%</li>
</ul>
<p>At Google, they practice the <a href="https://www.oreilly.com/library/view/software-engineering-at/9781492082781/" target="_blank" rel="noopener">Beyonce Rule “If you liked it, you
shoulda put a test on
it!"</a>
This rule inverts responsibility, e.g. if someone breaks a feature and
there was no test, the original author of the broken feature “shoulda
put a test on it!”.</p>
<h4 id="codereview"><a href="#codereview"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>15. Do you conduct code reviews?</h4>
<p>Code reviews are a critical step in your software engineering
process. Not only they prevent entering bugs into your mainline but
they are a major tool for knowledge transfer, learning and mentoring.
The code review process fosters a common understanding between
reviewers and author and offers a platform for discussions about
trade-offs and design decisions. Reviews are not only focused on
correctness but also on readability, performance and other
non-functional properties.</p>
<p>All of that will lead to better solutions. Further reviewers practice
their code reading skill which is as important as code
writing. Besides compiling, linting and running tests, code reviews
form a major step in a developers feedback loop. Code should never be
committed into mainline without a proper code review.</p>
<p>Because code reviews can conjure up heated discussions, reviewers
should comply to some <a href="https://google.github.io/eng-practices/review/reviewer/" target="_blank" rel="noopener">code review
guidelines</a>
in order to guarantee a flawless experience.</p>
<h4 id="16-do-developers-write-documentation"><a href="#16-do-developers-write-documentation"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>16. Do developers write documentation?</h4>
<p>Documentation starts with the code. Code comments or a good
description of a pull request are good examples. Thereby good
documentation focuses on <strong>why</strong> something was done. An extensive
<code>README.md</code> acts as the “front-page” of a project and should contain
its purpose and instructions for developers to set up their local
environment for development, e.g installing prerequisites, building
the project, running the tests.</p>
<p>Additionally a variety of documents with different purposes exist:</p>
<ul>
<li>Design Docs (showing alternative solutions, why was one approach
chosen over the others?)</li>
<li>Architecture Diagrams (System overview, showing coherence between
components)</li>
<li>Operational Playbooks for <a href="https://landing.google.com/sre/workbook/chapters/on-call/" target="_blank" rel="noopener">Software Reliability Engineers
(SREs)</a>
(operational instructions for fighting outages)</li>
</ul>
<p>All these documents should be written by developers, operators or
other technical people. Living, up-to-date documentation makes a
project more understandable and long-term project members are capable
of answering questions why things were done in the past – in the
majority of projects, the top answer is “this is historically grown”.
The only way to get real insights is conducting time consuming
face-to-face interviews. Documentation helps to keep an overview over
an ever-growing project, to facilitate the start for new developers
and to build a searchable knowledge base. Past decisions should be
transparent through good documentation and not hidden in people’s
heads.</p>
<h3 id="17-do-you-focus-on-code-health"><a href="#17-do-you-focus-on-code-health"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>17. Do you focus on code health?</h3>
<p>A healthy codebase is a major criteria for developer happiness. If
your developers working on a shitty codebase, they adapt to the poor
quality or leave. The existing codebase act as a <strong>role model</strong>. For
the purpose of high quality code, it is important to continuously
focus on code health. The best coders are repelled by bad code and
attracted by healthy code. But what is a healthy codebase?</p>
<p>A codebase is healthy when:</p>
<ul>
<li>you have fast builds</li>
<li>you have an easy development setup</li>
<li>you have fast and maintainable tests</li>
<li>you have clean, readable, loosely coupled and consistent code</li>
<li>you can easily debug the system</li>
<li>you continuously tackle technical debt</li>
</ul>
<p>You can find a much more exhaustive explanation of code health in
<a href="https://testing.googleblog.com/2016/08/hackable-projects.html" target="_blank" rel="noopener">Google’s Testing Blog about Code
Health</a>.</p>
<p>Signs of bad code are:</p>
<ul>
<li>complicated developer setup</li>
<li>hard to debug, missing monitoring, noisy garbage logs</li>
<li>long build times</li>
<li>inconsistent code (dead code, unused imports, different formatting
styles, no code styleguide)</li>
<li>large merge conflicts due to long running feature branches, broken mainline</li>
<li>no tests, flaky tests, hard-maintainable tests because of mocking overuse</li>
</ul>
<p>Never trade dirty code or workarounds due to time or release pressure
for code health. You will end up very badly in the long run. Worse
yet, you get in a vicious cycle because bad code slows you down and in
order to fulfil the next release you add more dirty workarounds. So
always prioritize code health, even when it looks counterintuitive at
first sight.</p>
<h3 id="18-do-you-practice-continuous-integration"><a href="#18-do-you-practice-continuous-integration"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>18. Do you practice continuous integration?</h3>
<p>Nowadays Continuous Integration is hopefully commonplace. At best, you
work with trunk-based development and your mainline is always
releasable, preferably with feature toggles. Highest priority is to
keep the mainline green and a broken build should be fixed
immediately. Small and frequent releases prevent bugs or even outages
which happen when large releases are done only intermittently.</p>
<p>CI helps to prevent tedious merge conflict resolutions because your
developers regularly commit into mainline. Additionally you will get
rid of time consuming integration problems at the end of your
implementation phases.</p>
<p>“Agile”’s main goal is to identify risks as early as possible and not
to postpone them till the end of a project. CI supports exactly</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gerlacdt.github.io/posts/writing-better-software/">https://gerlacdt.github.io/posts/writing-better-software/</a></em></p>]]>
            </description>
            <link>https://gerlacdt.github.io/posts/writing-better-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243656</guid>
            <pubDate>Sat, 22 Aug 2020 12:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AngelCAD: Script-based 3D solid modeller]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24243077">thread link</a>) | @app4soft
<br/>
August 22, 2020 | https://arnholm.github.io/angelcad-docs/ | <a href="https://web.archive.org/web/*/https://arnholm.github.io/angelcad-docs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>AngelCAD - user documentation</p>

        
        <p><a href="https://github.com/arnholm/angelcad-docs">View the Project on GitHub <small>arnholm/angelcad-docs</small></a></p>
        

        

        
      </header>
      <section>

      <p><strong>AngelCAD - script based 3D solid modeller</strong></p>

<p>AngelCAD is a powerful open source 3D solid modeller based on the Constructive Solid Geometry (<a href="https://en.wikipedia.org/wiki/Constructive_solid_geometry">CSG</a>) modelling technique, expressed in the <a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html">AngelScript</a> language. The software creates 3D models in STL or other file formats.</p>



<p>The csg_wikipedia.as sample</p>

<table>
  <thead>
    <tr>
      <th>AngelCAD resources</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html" target="_blank">AngelScript language</a></td>
      <td>AngelScript language reference</td>
    </tr>
    <tr>
      <td><a href="https://arnholm.github.io/angelcad-docs/docs/annotated.html" target="_blank">AngelCAD language extension</a></td>
      <td>Language extension for 3d modelling</td>
    </tr>
    <tr>
      <td><a href="https://forum.abmesh.com/" target="_blank">AngelCAD user forum</a></td>
      <td>Discuss AngelCAD topics</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad-samples" target="_blank">angelcad-samples</a></td>
      <td>Examples repository - GitHub</td>
    </tr>
    <tr>
      <td><a href="https://youtu.be/h-qDzG9bwnQ" target="_blank">Video</a></td>
      <td>script based 3D solid modeller</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad/releases" target="_blank">Downloads</a></td>
      <td>Prebuilt binaries - Windows and Linux</td>
    </tr>
  </tbody>
</table>

<p>(links above open in new tabs)</p>

<p><strong>AngelCAD IDE and Viewer</strong> - With the desktop IDE you edit/run the scripts and launch the 3d Viewer</p>

<p><img src="https://arnholm.github.io/angelcad-docs/images/angelcad_ide.png" alt="AngelCAD modeller"></p>

<p><strong>Technology</strong> - AngelCAD uses <a href="https://github.com/arnholm/xcsg" target="_blank">xcsg</a> for 3d computations. xcsg is based on the <a href="https://github.com/arnholm/carve" target="_blank">carve library</a> by Tobias Sargeant. Also used is <a href="http://angusj.com/delphi/clipper.php">Clipper</a> by Angus Johnson, qhull by C.B. Barber and libtess2 by Mikko Mononen.</p>

<p>The AngelCAD language interpreter - as_csg - is based on the <a href="http://www.angelcode.com/angelscript/" target="_blank">AngelScript language</a> by Andreas Jönsson, as_csg extends the language with 3d modelling primitives and operations for constructive solid geometry.</p>

<p>The AngelCAD IDE and Viewer applications use the <a href="https://wxwidgets.org/" target="_blank">wxWidgets cross-platform GUI library</a> to create native GUI for Windows and Linux.</p>


      </section>
      
    </div></div>]]>
            </description>
            <link>https://arnholm.github.io/angelcad-docs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243077</guid>
            <pubDate>Sat, 22 Aug 2020 10:07:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Name Classes After Patterns. Mostly]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24241886">thread link</a>) | @allending
<br/>
August 21, 2020 | https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc | <a href="https://web.archive.org/web/*/https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
													<tbody>
														<tr>
															<td><!--[if mso]>
				<table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;">
				<tr>
				<![endif]--><!--[if mso]>
				<td valign="top" width="600" style="width:600px;">
				<![endif]-->
															<div>
																		<p>Good Morning/Afternoon/Evening as the case may be.</p>

																		<p>I've been hoping you are well, and thinking about naming.</p>

																		<p><em>Estimated reading time: 7 minutes, 37 seconds.</em></p>

																		<h2>A Small Digression</h2>

																		<p>You may have heard <a href="https://sender.cloudy.email/postal/click?link=92413&amp;sid=qcdgifbdgjegdlzlgnwgp&amp;ck=77-977-9d2YSTu-_vQouSu-_ve-_vXd1Ee-_vShpBu-_ve-_ve-_ve-_vSdL77-977-977-9Jx4=" target="_blank">Phil Karlton's famous saying</a>:</p>

																		<blockquote>
																		<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
																		</blockquote>

																		<p>I first heard this as 'There are only two hard things in Computer Science: cache invalidation, naming things, and off-by-one errors.'</p>

																		<p>I passed this phrase on for many years before realizing that the 'off-by-one errors' bit was a joke.</p>

																		<p>Truth.</p>

																		<p>I am so literal that it pains me. I confess this in case it's paining you too. Puns, for example, fly right over my head, and any that I make are most likely inadvertent. I don't believe that there are any puns in the text that follows—but how would I know?</p>

																		<h2>Thoughts on Using Pattern Names in Class Names</h2>

																		<p>I've always heard that it's best to avoid using pattern names in class names. As one so often does, I've cargo-culted this rule without truly examining it. I habitually obey it myself, and teach it to folks in my OOD classes, but until recently I couldn't have articulated a convincing defense.</p>

																		<p>But then, while writing the 2nd Edition of 99 Bottles of OOP, I broke it. I created a new class whose name included the name of a pattern. I did this because it just felt right.</p>

																		<p>This put me in a pickle.</p>

																		<p>I very much believe in being guided by feelings about code, but when writing a book one can't just say, 'Okay, now do this because I, the author, <em>feel</em> like you should'. Respect for the reader requires investing sincere effort into dragging feelings about code into the light of day, and at least <em>trying</em> to justify them with convincing words.</p>

																		<p>Below I've included the excerpt from the book where I attempt just such convincing. The excerpt explains the purpose of the no-pattern-names-in-class-names rule and defends its utility.</p>

																		<p>I've built a newsletter around this rule not only because I believe that it's useful, but also because my initial attempts to explain it exposed deep holes in my understanding. This was a revelation. Had I not been writing a book, I might have hand-waved around these gaps in my knowledge forever.</p>

																		<h3>Some Context</h3>

																		<p>Before moving on to the excerpt, here's a bit of context to orient you. At this point in the book:</p>

																		<ul>
																			<li>
																			<p>The code contains a <code>CountdownSong</code> class that gets injected with a player of the <code>verse template</code> role.</p>
																			</li>
																			<li>
																			<p><code>BottleVerse</code> is the only class that plays this role. It's used as the default <code>verse template</code> in <code>CountdownSong</code>.</p>
																			</li>
																		</ul>

																		<p>So, <code>CountdownSong</code> has-a <code>verse template</code>, whose concrete implementation is supplied by <code>BottleVerse</code>.</p>

																		<ul>
																			<li>
																			<p>I'm writing tests for <code>CountdownSong</code>, and have just decided to create a new player of the <code>verse template</code> role to inject for use during these tests.</p>
																			</li>
																			<li>
																			<p>I've named this new class <code>VerseFake</code>.</p>
																			</li>
																		</ul>

																		<p>The excerpt below also mentions a <code>BottleNumber</code> class. This class wraps a number to add bottle-ish behavior.</p>

																		<h3>The Excerpt</h3>

																		<p>With that, here's a bit of chapter 9:</p>

																		<blockquote>
																		<p><em>The <code>VerseFake</code> class above is perfect for your needs, though it must be acknowledged that it unrepentantly breaks several common programming rules.</em></p>

																		<p><em>First, Chapter 8 suggested that you put domain behavior on instances. This class violates that rule; its behavior is on the class/static side.</em></p>

																		<p><em>Next, there's an as-yet-unmentioned object-oriented programming rule that prohibits the use of pattern names in class names. The word "Fake" above refers to a testing pattern, so naming this class <code>VerseFake</code> violates that rule.</em></p>

																		<p><em>Fake things first. You're probably familiar with the idea of design patterns, which are named, re-usable solutions to common software problems. Pattern names act as shortcuts to big ideas and allow programmers to communicate with speed and precision. Pattern thinking has so influenced software design that most programmers are familiar with a number of patterns. For example, you've likely heard of Decorator, Adapter, Enumerator, and so on, even if you're a bit fuzzy on the specifics of some of their definitions.</em></p>

																		<p><em>Since pattern names are so meaningful, it can be tempting to stick them in class names. For example, you might use the Decorator pattern to enclose a <code>number</code> in a new class that adds additional responsibility. Initially, <code>NumberDecorator</code> might seem like a good name for the result. The problem with including the name of a pattern in the name of a class is that this permits you the feeling of having created a useful name without actually having done so. Pattern names don't generally reflect concepts in your application. Appending them to class names pollutes your domain with programmer-y words and circumvents the search for names that add semantic meaning. Class names that include patterns are a signal that you've given up too soon on the hard problem of naming.</em></p>

																		<p><em>Class names should reflect concepts in your domain, not the patterns used to create them. Compared to <code>BottleNumber</code>, the much-richer name you gave this class in Chapter 4, <code>NumberDecorator</code> is so abstract as to be meaningless. Future readers won't care that the class was created using Decoration but they'll be grateful to know that it's a bottle-ish kind of number.</em></p>

																		<p><em>The <a href="https://sender.cloudy.email/postal/click?link=92414&amp;sid=qcdgifbdgjegdlzlgnwgp&amp;ck=77-977-977-977-9QO-_ve-_vT3vv73vv71KHllU77-9Ccqq77-9Ru-_ve-_vVEB77-9TQYZ77-977-9Eu-_vQ==" target="_blank">xUnit Test Patterns</a> book by <a href="https://sender.cloudy.email/postal/click?link=92415&amp;sid=qcdgifbdgjegdlzlgnwgp&amp;ck=77-977-977-977-977-9Mu-_ve-_ve-_ve-_vVfvv70077-977-95auh77-9anPvv70cX0Mh77-9D3EZEA==" target="_blank">Gerard Meszaros</a> standardizes the <a href="https://sender.cloudy.email/postal/click?link=92416&amp;sid=qcdgifbdgjegdlzlgnwgp&amp;ck=77-977-977-9cO-_vS0q77-9Ry_vv73vv73vv70pJO-_ve-_ve-_ve-_vWp81o8jOyBpcu-_vSAWSQ==" target="_blank">pattern names</a> of a set of objects that are used to simplify testing. <code>TestDouble</code> is his generic name for all of the patterns. Within <code>TestDouble</code> he further delineates the <code>Dummy</code>, <code>Stub</code>, <code>Spy</code>, <code>Mock</code>, <code>Fake</code>, and <code>Temporary Test Stub</code> patterns.</em></p>

																		<p><em>Meszaros defines <code>Fake</code> as a <code>TestDouble</code> that provides a lightweight implementation of a collaborator that is needed by the class you are actually unit testing. A <code>Fake</code> is a regular old object; no testing magic is involved. In this case the new <code>VerseFake</code> class is a real player of the verse template role; it's called a <code>Fake</code> because it's only used during testing. <code>BottleVerse</code> plays the role of verse template in production. <code>VerseFake</code> was created to play this role during <code>Bottles</code>' unit tests.</em></p>

																		<p><em>The upshot is that <code>Fake</code> is the name of a pattern, so <code>VerseFake</code> violates the don't-include-pattern-names-in-class-names rule.</em></p>

																		<p><em>Rules exist to save money, and the two rules that <code>VerseFake</code> breaks are primarily meant to save money in production code; they might not be so applicable in code created to simplify tests. For example, the purpose of <code>VerseFake</code> is to fake the role of verse template. In this case, <code>VerseFake</code> might be the most intention-revealing name possible. If you end up needing a number of different kinds of fakes, you might need additional qualifiers in their names (<code>SimpleVerseFake</code>, <code>ComplicatedVerseFake</code>) but the word "fake" still adds meaning in the domain of your tests.</em></p>

																		<p><em>Similarly, it's important that the shape of production code not interfere with your ability to change it. The put-domain-behavior-on-instances rule serves this goal. In tests, however, you're less concerned with preserving the fake's changeability and more interested in directly communicating its responsibilities. Putting the behavior in a class or static method simplifies the code in <code>VerseFake</code> at the expense of making it less adaptable. This is a trade-off you'll happily make in code used only by the tests.</em></p>
																		</blockquote>

																		<p>I am convinced by that explanation, and I hope you are too. Now that I comprehend it, the no-pattern-names-in-class-names rule seems both simple and inevitable.</p>

																		<p>The deeper point is that I didn't really understand this rule until I had to write an explanation—believe me, my early attempts were neither brief nor convincing. The above is the result of a few days of walking around in my office, muttering, groping for insight.</p>

																		<p>It's not necessarily bad to cargo-cult a rule. Most rules that have risen to the level of cargo-cult-ability are actually pretty reasonable, and even if you don't completely understand their subtleties, following them might improve your code.</p>

																		<p>However, you'll get more value from a rule if you comprehend its underlying purpose. And even better, understanding its true purpose allows you to justify yourself when you decide to break it.</p>

																		<p>Thanks for reading. I very much hope you are safe and well.</p>

																		<p>Best,</p>

																		<p>Sandi</p>

																		<hr>
																		<h2><a href="https://sender.cloudy.email/postal/click?link=92417&amp;sid=qcdgifbdgjegdlzlgnwgp&amp;ck=dGnvv71A77-9JFt177-977-9ewPvv73vv70Q77-9Qu-_ve-_ve-_ve-_vU_vv71q77-916zvv73vv70Dau-_vQ==" target="_blank">99 Bottles of OOP, 2nd Edition</a> is complete!</h2>

																		<h3>Use coupon code <strong><a href="https://sender.cloudy.email/postal/click?link=92418&amp;sid=qcdgifbdgjegdlzlgnwgp&amp;ck=GXDvv73vv70ENu-_vXDvv70Y77-977-9Uu-_vXDvv73vv73vv70p77-977-977-977-977-977-9fFHvv73vv71pUA==" target="_blank">2ND-IS-DONE!</a></strong> through Sept 7</h3>

																		<h3>for a <a href="https://sender.cloudy.email/postal/click?link=92418&amp;sid=qcdgifbdgjegdlzlgnwgp&amp;ck=GXDvv73vv70ENu-_vXDvv70Y77-977-9Uu-_vXDvv73vv73vv70p77-977-977-977-977-977-9fFHvv73vv71pUA==" target="_blank">25% discount</a> on the book.</h3>

																		<p>The new edition:</p>

																		<ul>
																			<li>has three new chapters (it's almost 50% longer).</li>
																			<li>comes in separate books for two programming languages (Ruby and JavaScript) and two beverages (beer and milk), with a free PHP upgrade coming this fall.</li>
																			<li>is available as an ebook only, in epub, kepub, kobi, and pdf formats.</li>
																			<li>bundles every book variant. A single purchase gets you all of the books.</li>
																		</ul>

																		<p>I am so <em>glad</em> to be done with this edition that I'm passing that good cheer on to you.</p>

																		<p><strong><em>Note:</em></strong><br>
																		<span><em>Those of you who already own the book should have recently received</em></span><span><em>your own personal upgrade coupon.</em></span></p>

							…</div></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc">https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc</a></em></p>]]>
            </description>
            <link>https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241886</guid>
            <pubDate>Sat, 22 Aug 2020 05:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stef's Free Online Smalltalk Books]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24241561">thread link</a>) | @triyambakam
<br/>
August 21, 2020 | http://stephane.ducasse.free.fr/FreeBooks.html | <a href="https://web.archive.org/web/*/http://stephane.ducasse.free.fr/FreeBooks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
	   I started to be fed up to see all the books I like to be out of print, so I started to contact authors and 
	   collect their old books. I would like to thanks them all and their publishers as well. If you
       know an author that is willing to give to the community a book, please give
       him my email. You can support me. </p><p> Thanks in advance. 




</p><p>
You can find a lot more recent and free books at <a href="http://books.pharo.org/">http://books.pharo.org</a>: Spec, Pharo by Example Updated, Pharo with Style, Learning OOD with TDD, and many more. 
In addition most the new books around Pharo are hosted at <a href="http://github.com/SquareBracketAssociates">http://github.com/SquareBracketAssociates</a> and each project has an automatic build with the latest PDF version.


</p><p>
If you have more books and you want to get them archived and listed here please contact me.

</p><div width="95%" height="174">

	<tbody><tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/DynamicWebDevInSeaside/DynWebDevInSeaside.png" width="100"></td>
	    <td>
	      <p><a href="http://book.seaside.st/">[ Dynamic Web Development with Seaside ]</a> Stephane Ducasse, Lukas Renggli, David C. Shaffer and Rick Zaccone. Square Bracket Associates, 2009.</p>
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>
	

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PBE/PharoByExample.png" width="100"></td>
	    <td>
	      <p><a href="http://books.pharo.org/">[ Pharo by Example (original version and translation) ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz, Damien Pollet with Damien Cassou and Marcus Denker. Square Bracket Associates, 2009.</p> Pay attention there is also Pharo by Example Updated (for Pharo 50) and we are working on Pharo by Example for Pharo 80.
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/GNU.png" width="100"></td>
	    <td>
	     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/computer_programming_using_gnu_smalltalk.pdf">[ Computer Programming using GNU Smalltalk ]</a> Canol Gokel, free e-book. 2009. 
	   <a href="http://www.canol.info/books/computer_programming_using_gnu_smalltalk">home page of the book to have an up to date version</a>.
		</p> 
	    </td>
	  </tr> 


  	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SBE/sbe.png" width="100"></td>
	    <td>
	      <p><a href="https://hal.inria.fr/inria-00441576/document">[ Squeak by Example ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz and Damien Pollet. Square Bracket Associates, 2007.</p> Watch out this book is old. Better read <a href="http://books.pharo.org/">Pharo by Example book</a>.
	    </td>
	  </tr>
	
	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion/coversm.gif" width="100"></td>
	    <td>
	      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion">[ Smalltalk design pattern companion book drafts ]</a> Sherman Alpert, Kyle Brown, and Bobby Woolf. Addison-Wesley,  978-02011846241998.</p>
		The chapters listed here are not in their final form but more in draft form. Buy the book it is really excellent. 
	    </td>
	  </tr>
	
	
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/byExample.gif" width="100"></td>
    <td> 
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/">[ Smalltalk by
      Example: the Developer's Guide ]</a> Alex Sharp, McGraw Hill Text; ISBN:
      0079130364, 1997.</p>
      This book covers all kinds of issues basic level, design, testing... I
      liked it a lot. The code and the book as a single file containing everything are available. Thank again
      Lukas Renggli for his effort for converting everything from Word.
       Thanks a lot Alec and thanks McGraw-Hill <a href="http://books.mcgraw-hill.com/">http://books.mcgraw-hill.com/</a>
  They were really nice with us so think about it if you hesitate to buy
  one of their books. Not all the publishers are that open-minded. 
  </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/WithStyle.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/SmalltalkWithStyle.pdf">[ Smalltalk With Style ]</a> by Edward Klimas, Suzanne Skublics and David A. Thomas. 
		ISBN: 0-13-165549-3, Publisher: Prentice Hall, Copyright: 1996. A great and 
		small book that everybody should read. Thanks Ed, Suzanne and Dave to give it for free. 
		Thanks Don for the OCR!
	   </p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV1.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalk.pdf">[ Inside Smalltalk 
       (Volume One) ]</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1.
       Thanks Don for the OCR! 
	   </p>
    </td>
  </tr>
  
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV2.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkII.pdf">[ Inside Smalltalk (Volume Two)],</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1. Thanks Don for the OCR! </p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/littleST.jpeg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/ALittleSmalltalk.pdf">[ A Little Smalltalk ] </a> by Tim Budd, Addison-Wesley 1987.  
      <br>Many thanks to Tim Budd and his  publisher. Please have a look at <a href="http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html">http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html</a>. Thanks Don for the OCR!.
		</p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Art/Art.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Art/artAdded174186187Final.pdf">[ The Art and Science of Smalltalk ]</a>  by Simon Lewis, Prentice-Hall 1995-1999.  
      <br>Many thanks to the original publishers of this book Prentice-Hall, the responsible of the HP series and Simon Lewis.</p>
    </td>
  </tr>
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/practical.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/PracticalSmalltalk.pdf">[ Practical Smalltalk: Using Smalltalk/V ]</a>  by Dan Shafer and Dean A. Ritz, Springer Verlag; (July 1991).  
      <br>Many thanks to the original publishers of this book Springer Verlag,  and Dan. Thanks</p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.pdf">[ Smalltalk An Introduction to Application Development using VisualWorks ]</a> Trevor Hopkins and Bernard Horan,  Pearson Education, 1995. The answers of the exercises are at ftp://st.cs.uiuc.edu/pub/Smalltalk/books/Book_Answers.tar.gz
      <br>Many thanks to the original publishers of this book,  Pearson Education,  for permission to distribute this work, and of course the authors! </p>
    </td>
  </tr>

<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/st-and-oo.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/Smalltalk-and-OO.pdf"> [ Smalltalk and Object Orientation: an Introduction ] </a> Springer-Verlag, ISBN 3-540-76115-2, 1997.
</p>
      <br>This book provides a good survey of Smalltalk. Some information are now obsolete 
      but it is still worth reading. Enjoy it. Thanks John to support our request. We want to thank Springer Verlag Publishing
    for allowing us to give you this book for free.
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/SmalltalkVTutorial.pdf"> [ Smalltalk V Tutorial ]</a>
	   </p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/taste.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/"> [ The Taste of Smalltalk ] </a> Ted Kaehler and Dave Patterson, W W Norton Co.; ISBN: 0393955052; (May 1986).</p>
      This book is for collectors. The quotes are really excellent. 
      <br>All the chapters are ready (except chap.2 for now)
    Enjoy it. (Scanned ... by Stef, Alex, Gabriela, and Lukas).
    Thanks Ted.
    </td>
  </tr>

 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Joy/">[ The Joy Of Smalltalk ]</a> Ivan
    Tomek (September 2000). 700 pages</p>
    Ivan wrote this book and he gave it to the community. It contains a lot of useful material. 
    Thanks again ivan and continue to write good books. 
    </td>
  </tr>
  
  
  
   <!--<tr>
    <td width="45%"><img src="FreeBooks/SmalltalkObjectAndDesign/SmalltalkObjectAndDesign.jpg" width=100></td>
    <td width="55%">
      <p><a href="http://books.iuniverse.com/viewbooks.asp?isbn=1583484906&page=fm1">Smalltalk,objects and design</a>
	  Liu, iUniverse books</p>
      
	  </font>
    </td>
  </tr>-->
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/BitsOfHistory.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/"> [ Smalltalk-80, Bits of History, Words of Advice] </a> By Glen Krasner, Editor
ISBN 0-201-11669-3. 344 pp. 1983</p>
      This book is for collectors. Thanks Glenn.
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/blueBook.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/">[ Smalltalk-80: The Language and its Implementation ]</a>
	By Adele Goldberg and DavidRobson; 		Xerox Palo Alto Research Center
	ISBN 0-201-11371-6. 344 pp. 1983</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.pdf">[ Smalltalk-80, The Interactive Programming Environment ]</a> By Adele Goldberg 
ISBN  0201113724. 560 pp. 1983</p> This book is for collectors. Thanks Adele. Thanks Don for the OCR!
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/small-bluebook-cover.jpg" width="100"></td>
    <td>
    <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/">[ DRAFTS of Squeak, Open Personal Computing and Multimedia ]</a> Mirror of <a href="http://coweb.cc.gatech.edu/squeakbook/">http://coweb.cc.gatech.edu/squeakbook/</a> Edited by Mark Guzdial and Kim Rose. Prentice-Hall 2000.  It's available from Prentice-Hall.  </p>
    <br>
    </td>
  </tr>
  
  
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/mark1.jpg" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/">[ DRAFS of Squeak: Open Personal Computing for Multimedia ]</a>
	 taken from <a href="http://www.cc.gatech.edu/~mark.guzdial/drafts/">http://www.cc.gatech.edu/~mark.guzdial/drafts/</a> 
	 Mark Guzdial, Prentice-Hall 2000. It's available from Prentice-Hall. </p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/BuchLogo.png" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/Syntax.zip">[ (In German) Syntaxbasierte
      Programmierwerkzeuge ]</a> L. Schmitz, B.G. Teubner Stuttgart 1995.  
        1996.</p>
      <p>This book presents compilation techniques in german.
	 Lothar Schmitz is still developing a free visual compiler-compiler
	 (SIC and JACCIE).  <!-- <a
	 href="http://ist.unibw-muenchen.de/Research/Tools/SIC">http://ist.unibw-muenchen.de/Research/Tools/SIC</a> 
<a href="http://ist.unibw-muenchen.de/Research/Tools/JACCIE">http://ist.unibw-muenchen.de/Research/Tools/JACCIE</a> 
-->

</p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/emptyCover.gif" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/smalltalkBuch.pdf">[ (In German) Smalltalk
      Einfuehrung in die objekt-orientierte Programmierung ]</a> Peter P. Bothner, Wolf-Michael Kaehler 1999.  
        1996.</p>
      <p>This book presents object-oriented programming in german with VisualWorks.  
<!-- <a href="http://e-books.zfn.uni-bremen.de/e-book-SMALLTALK.html</a>  
-->

</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Swedish/">[  (In Swedish) Objektorienterad programmering i Smalltalk ]</a>
	  Bjoern Eiderbaeck, Per Haegglund, and Olle Baelter</p>
      <br>Thanks Bjoern Eiderbaeck.
	  
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/Programando.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/ProgramandoConSmalltalk-BORRADORFINAL07-Febrero-2006.pdf">[ (In Spanish) Programando con Smalltalk ]</a>
	  Diego Gomez Deck</p>
      <br>Thanks Diego. This book is distributed under the Creative Commons license.
	  
    </td>
  </tr>
  
</tbody></div><p>
 I added some other material because they illustrate the philosophy behind Smalltalk.

 </p></div>]]>
            </description>
            <link>http://stephane.ducasse.free.fr/FreeBooks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241561</guid>
            <pubDate>Sat, 22 Aug 2020 04:33:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debian Janitor: 60k Lintian Issues Automatically Fixed]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24241549">thread link</a>) | @zdw
<br/>
August 21, 2020 | https://www.jelmer.uk/janitor-update-3.html | <a href="https://web.archive.org/web/*/https://www.jelmer.uk/janitor-update-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
    <div>
        <div>
            <section>
                
            </section>
            <p>The <a href="https://jelmer.uk/debian-janitor.html">Debian Janitor</a> is an automated
system that commits fixes for (minor) issues in Debian packages that can be
fixed by software. It gradually started proposing merges in early
December. The first set of changes sent out ran <a href="https://salsa.debian.org/jelmer/lintian-brush">lintian-brush</a> on sid packages maintained in
Git. This post is part of <a href="https://jelmer.uk/tag/janitor-update.html">a series</a> about the progress of the
Janitor.</p>
<div id="scheduling-lintian-fixes">
<h2>Scheduling Lintian Fixes</h2>
<p>To determine which packages to process, the  <a href="https://janitor.debian.net/">Janitor</a>  looks at the import of  <a href="https://lintian.debian.org/">lintian</a>  output across the archive that is available
in  <a href="https://wiki.debian.org/UltimateDebianDatabase/">UDD</a> <a href="#f1" id="id1">[1]</a>. It
will prioritize those packages with the most and more severe issues that it has
fixers for.</p>
<p>Once a package is selected, it will clone the packaging repository and run
<a href="https://manpages.debian.org/testing/lintian-brush/lintian-brush.1.en.html">lintian-brush</a>
on it.  Lintian-brush provides a framework for applying a set of “fixers” to a
package. It will run each of a set of “fixers” in a pristine version of the
repository, and handles most of the heavy lifting.</p>
</div>
<div id="the-inner-workings-of-a-fixer">
<h2>The Inner Workings of a Fixer</h2>
<p>Each fixer is just an executable which gets run in a clean
checkout of the package, and can make changes there. Most
of the fixers are written in Python or shell, but they
can be in any language.</p>
<p>The contract for fixers is pretty simple:</p>
<ul>
<li>If the fixer exits with non-zero, the changes are reverted and fixer is
considered to have failed</li>
<li>If exits with zero and made changes, then it should write a summary of its
changes to standard out</li>
</ul>
<p>If a fixer is uncertain about the changes it has made, it should report so on
standard output using a pseudo-header.  By default, lintian-brush will discard
any changes with uncertainty but if you are running it locally you can still
apply them by specifying <tt><span>--uncertain</span></tt>.</p>
<p>The summary message on standard out will be used for the commit message and
(possibly) the changelog message, if the package doesn’t use gbp dch.</p>
</div>
<div id="example-fixer">
<h2>Example Fixer</h2>
<p>Let’s look at an example. The package priority “extra” is deprecated since
Debian Policy 4.0.1 (released August 2 017) – see
<a href="https://www.debian.org/doc/debian-policy/ch-archive.html#priorities">Policy 2.5 "Priorities"</a>.
Instead, most packages should use the “optional” priority.</p>
<p>Lintian will warn when a package uses the deprecated “extra” value for the
“Priority”  - the associated tag is
<a href="https://lintian.debian.org/tags/priority-extra-is-replaced-by-priority-optional.html">priority-extra-is-replaced-by-priority-optional</a>.
Lintian-brush has a fixer script that can automatically replace “extra” with
“optional”.</p>
<p>On systems that have lintian-brush installed, the source for the fixer lives in
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/blob/master/fixers/priority-extra-is-replaced-by-priority-optional.py">/usr/share/lintian-brush/fixers/priority-extra-is-replaced-by-priority-optional.py</a>,
but here is a copy of it for reference:</p>
<table><tbody><tr><td><div><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td><div><pre><span></span><span>#!/usr/bin/python3</span>

<span>from</span> <span>debmutate.control</span> <span>import</span> <span>ControlEditor</span>
<span>from</span> <span>lintian_brush.fixer</span> <span>import</span> <span>report_result</span><span>,</span> <span>fixed_lintian_tag</span>

<span>with</span> <span>ControlEditor</span><span>()</span> <span>as</span> <span>updater</span><span>:</span>
    <span>for</span> <span>para</span> <span>in</span> <span>updater</span><span>.</span><span>paragraphs</span><span>:</span>
        <span>if</span> <span>para</span><span>.</span><span>get</span><span>(</span><span>"Priority"</span><span>)</span> <span>==</span> <span>"extra"</span><span>:</span>
            <span>para</span><span>[</span><span>"Priority"</span><span>]</span> <span>=</span> <span>"optional"</span>
            <span>fixed_lintian_tag</span><span>(</span>
                <span>para</span><span>,</span> <span>'priority-extra-is-replaced-by-priority-optional'</span><span>)</span>

<span>report_result</span><span>(</span><span>"Change priority extra to priority optional."</span><span>)</span>
</pre></div>
</td></tr></tbody></table><p>This fixer is written in Python and uses the  <a href="https://salsa.debian.org/jelmer/debmutate">debmutate</a>  library to easily modify
control files while preserving formatting — or back out if it is not possible
to preserve formatting.</p>
<p>All the current fixers come with tests, e.g. for this particular fixer the
tests can be found here:
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional">https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional</a>.</p>
<p>For more details on writing new fixers, see the  <a href="https://salsa.debian.org/jelmer/lintian-brush#writing-new-fixers">README</a>  for
lintian-brush.</p>
<p>For more details on debugging them, see the  <a href="https://manpages.debian.org/unstable/lintian-brush/lintian-brush.1.en.html">manual page</a>.</p>
</div>


            

            

            
            <p><a href="#">Go Top</a></p>        </div>
    </div>
</div></div>]]>
            </description>
            <link>https://www.jelmer.uk/janitor-update-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241549</guid>
            <pubDate>Sat, 22 Aug 2020 04:30:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How NAT Traversal Works]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24241105">thread link</a>) | @signa11
<br/>
August 21, 2020 | https://tailscale.com/blog/how-nat-traversal-works/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/how-nat-traversal-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>We covered a lot of ground in our post about <a href="https://tailscale.com/blog/how-tailscale-works/"><em>How Tailscale
Works</em></a>.  However, we glossed over how we can get through NATs
(Network Address Translators) and connect your devices directly to
each other, no matter what’s standing between them. Let’s talk about
that now!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-intro.png">
    
    
</figure>

<p>Let’s start with a simple problem: establishing a peer-to-peer
connection between two machines. In Tailscale’s case, we want to set
up a WireGuard® tunnel, but that doesn’t really matter. The
techniques we use are widely applicable and the work of many people
over decades. For example, <a href="https://webrtc.org/">WebRTC</a> uses this bag of tricks to
send peer-to-peer audio, video and data between web browsers. VoIP
phones and some video games use similar techniques, though not always
successfully.</p>
<p>We’ll be discussing these techniques generically, using Tailscale and
others for examples where appropriate. Let’s say you’re making your
own protocol and that you want NAT traversal. You need two things.</p>
<p>First, the protocol should be based on UDP. You <em>can</em> do NAT traversal
with TCP, but it adds another layer of complexity to an already quite
complex problem, and may even require kernel customizations depending
on how deep you want to go. We’re going to focus on UDP for the rest
of this article.</p>
<p>If you’re reaching for TCP because you want a stream-oriented
connection when the NAT traversal is done, consider using QUIC
instead. It builds on top of UDP, so we can focus on UDP for NAT
traversal and still have a nice stream protocol at the end.</p>
<p>Second, you need direct control over the network socket that’s sending
and receiving network packets. As a rule, you can’t take an existing
network library and make it traverse NATs, because you have to send
and receive extra packets that aren’t part of the “main” protocol
you’re trying to speak. Some protocols tightly integrate the NAT
traversal with the rest (e.g. WebRTC). But if you’re building your
own, it’s helpful to think of NAT traversal as a separate entity that
shares a socket with your main protocol. Both run in parallel, one
enabling the other.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-deep-integration.png">
    
    
</figure>

<p>Direct socket access may be tough depending on your situation. One
workaround is to run a local proxy. Your protocol speaks to this
proxy, and the proxy does both NAT traversal and relaying of your
packets to the peer. This layer of indirection lets you benefit from
NAT traversal without altering your original program.</p>
<p>With prerequisites out of the way, let’s go through NAT traversal from
first principles. Our goal is to get UDP packets flowing
bidirectionally between two devices, so that our other protocol
(WireGuard, QUIC, WebRTC, …) can do something cool. There are two
obstacles to having this Just Work: stateful firewalls and NAT
devices.</p>
<h3 id="figuring-out-firewalls">Figuring out firewalls</h3>
<p>Stateful firewalls are the simpler of our two problems. In fact, most
NAT devices include a stateful firewall, so we need to solve this
subset before we can tackle NATs.</p>
<p>There are many incarnations to consider. Some you might recognize are
the Windows Defender firewall, Ubuntu’s ufw (using iptables/nftables),
BSD’s pf (also used by macOS) and AWS’s Security Groups. They’re all
very configurable, but the most common configuration allows all
“outbound” connections and blocks all “inbound” connections. There
might be a few handpicked exceptions, such as allowing inbound SSH.</p>
<p>But connections and “direction” are a figment of the protocol
designer’s imagination. On the wire, every connection ends up being
bidirectional; it’s all individual packets flying back and forth. How
does the firewall know what’s inbound and what’s outbound?</p>
<p>That’s where the stateful part comes in. Stateful firewalls remember
what packets they’ve seen in the past and can use that knowledge when
deciding what to do with new packets that show up.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-1a.png">
    
    
</figure>

<p>For UDP, the rule is very simple: the firewall allows an inbound UDP
packet if it previously saw a matching outbound packet. For example,
if our laptop firewall sees a UDP packet leaving the laptop from
<code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, it’ll make a note that incoming
packets from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code> are also fine. The
trusted side of the world clearly intended to communicate with
<code>7.7.7.7:5678</code>, so we should let them talk back.</p>
<p>(As an aside, some <em>very</em> relaxed firewalls might allow traffic from
anywhere back to <code>2.2.2.2:1234</code> once <code>2.2.2.2:1234</code> has communicated
with anyone. Such firewalls make our traversal job easier, but are
increasingly rare.)</p>
<h4 id="firewall-face-off">Firewall face-off</h4>
<p>This rule for UDP traffic is only a minor problem for us, as long as
all the firewalls on the path are “facing” the same way. That’s
usually the case when you’re communicating with a server on the
internet. Our only constraint is that the machine that’s <em>behind</em> the
firewall(s) must be the one initiating all connections. Nothing can
talk to it, unless it talks first.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-2.png">
    
    
</figure>

<p>This is fine, but not very interesting: we’ve reinvented client/server
communication, where the server makes itself easily reachable to
clients. In the VPN world, this leads to a hub-and-spoke topology: the
hub has no firewalls blocking access to it and the firewalled spokes
connect to the hub.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-3.png">
    
    
</figure>

<p>The problems start when two of our “clients” want to talk
directly. Now the firewalls are facing each other. According to the
rule we established above, this means both sides must go first, but
also that neither can go first, because the other side has to go
first!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-4.png">
    
    
</figure>

<p>How do we get around this? One way would be to require users to
reconfigure one or both of the firewalls to “open a port” and allow
the other machine’s traffic. This is not very user friendly. It also
doesn’t scale to mesh networks like Tailscale, in which we expect the
peers to be moving around the internet with some regularity. And, of
course, in many cases you don’t have control over the firewalls: you
can’t reconfigure the router in your favorite coffee shop, or at the
airport. (At least, hopefully not!)</p>
<p>We need another option. One that doesn’t involve reconfiguring
firewalls.</p>
<h4 id="finessing-finicky-firewalls">Finessing finicky firewalls</h4>
<p>The trick is to carefully read the rule we established for our
stateful firewalls. For UDP, the rule is: <strong>packets must flow out
before packets can flow back in.</strong></p>
<p>However, nothing says the packets must be <em>related</em> to each other
beyond the IPs and ports lining up correctly. As long as <em>some</em> packet
flowed outwards with the right source and destination, any packet that
<em>looks like</em> a response will be allowed back in, even if the other
side never received your packet!</p>
<p>So, to traverse these multiple stateful firewalls, we need to share
some information to get underway: the peers have to know in advance
the <code>ip:port</code> their counterpart is using. One approach is to
statically configure each peer by hand, but this approach doesn’t
scale very far. To move beyond that, we built a <a href="https://tailscale.com/blog/how-tailscale-works/#the-control-plane-key-exchange-and-coordination">coordination
server</a> to keep the <code>ip:port</code> information synchronized in a
flexible, secure manner.</p>
<p>Then, the peers start sending UDP packets to each other. They must
expect some of these packets to get lost, so they can’t carry any
precious information unless you’re prepared to retransmit them. This
is generally true of UDP, but especially true here. We’re <em>going</em> to
lose some packets in this process.</p>
<p>Our laptop and workstation are now listening on fixed ports, so that
they both know exactly what <code>ip:port</code> to talk to. Let’s take a look at
what happens.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5a.png">
    
    
</figure>

<p>The laptop’s first packet, from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, goes
through the Windows Defender firewall and out to the internet. The
corporate firewall on the other end blocks the packet, since it has no
record of <code>7.7.7.7:5678</code> ever talking to <code>2.2.2.2:1234</code>. However,
Windows Defender now remembers that it should expect and allow
responses from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code>.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5b.png">
    
    
</figure>

<p>Next, the workstation’s first packet from <code>7.7.7.7:5678</code> to
<code>2.2.2.2:1234</code> goes through the corporate firewall and across the
internet. When it arrives at the laptop, Windows Defender thinks “ah,
a response to that outbound request I saw”, and lets the packet
through! Additionally, the corporate firewall now remembers that it
should expect responses from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, and
that those packets are also okay.</p>
<p>Encouraged by the receipt of a packet from the workstation, the laptop
sends another packet back. It goes through the Windows Defender
firewall, through the corporate firewall (because it’s a “response” to
a previously sent packet), and arrives at the workstation.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5c.png">
    
    
</figure>

<p>Success! We’ve established two-way communication through a pair of
firewalls that, at first glance, would have prevented it.</p>
<h4 id="creative-connectivity-caveats">Creative connectivity caveats</h4>
<p>It’s not always so easy. We’re relying on some indirect influence over
third-party systems, which requires careful handling. What do we need
to keep in mind when managing firewall-traversing connections?</p>
<p>Both endpoints must attempt communication at roughly the same time, so
that all the intermediate firewalls open up while both peers are still
around. One approach is to have the peers retry continuously, but this
is wasteful. Wouldn’t it be better if both peers knew to start
establishing a connection at the same time?</p>
<p>This may sound a little recursive: to communicate, first you need to
be able to communicate. However, this preexisting “side channel”
doesn’t need to be very fancy: it can have a few seconds of latency,
and only needs to deliver a few thousand bytes in total, so a tiny VM
can easily be a matchmaker for thousands of machines.</p>
<p>In the distant past, I used XMPP chat messages as the side channel,
with great results. As another example, WebRTC requires you to come up
with your own “signalling channel” (a name that reveals WebRTC’s IP
telephony ancestry), and plug it into the WebRTC APIs. In Tailscale,
our coordination server and fleet of DERP (Detour Encrypted Routing
Protocol) servers act as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/how-nat-traversal-works/">https://tailscale.com/blog/how-nat-traversal-works/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241105</guid>
            <pubDate>Sat, 22 Aug 2020 02:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to Zero-Knowledge Proofs with Hands-On Examples]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24240915">thread link</a>) | @mariorz
<br/>
August 21, 2020 | https://dochdoch.gitlab.io/snark_intro/snark_intro_front/ | <a href="https://web.archive.org/web/*/https://dochdoch.gitlab.io/snark_intro/snark_intro_front/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dochdoch.gitlab.io/snark_intro/snark_intro_front/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240915</guid>
            <pubDate>Sat, 22 Aug 2020 01:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bread, How Did They Make It? Part IV: Markets, Merchants and the Tax Man]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24240677">thread link</a>) | @Kednicma
<br/>
August 21, 2020 | https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>As the fourth and final part (<a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">I</a>, <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">II</a>, <a href="https://acoup.blog/2020/08/06/collections-bread-how-did-they-make-it-part-iii-actually-farming/">III</a>) of our look at the basic structure of food production in the pre-modern world (particularly farming grain to make bread), this week we’re going to look at how at least some of the delicious food we made in the last post might make its way into the hands of people who are <em>not</em> <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>or even<a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/"> farm owners</a>.</p>



<p>In the previous three posts, I have mostly just used the magic word ‘markets’ to describe how the food produced in the countryside gets to the cities and people who are not farmers.  As we’ll see in this post, that is a bit of an oversimplifying fib, both in that the phrase ‘markets’ covers a <em>lot </em>of complexity, but also (as we’ll see) some of the major drivers of moving that food from the countryside into towns doesn’t involve money <em>or</em> market interactions.  That said, we’re going to <em>start</em> with market transactions, because while they are actually the minority-type in many of these societies, they are more readily familiar and understandable, I suspect, to modern readers.  Then we’ll move to <em>extraction</em> as the other category.</p>



<p>Speaking of extraction, as always, if you like what you are reading here, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreo</a>n. And if you want updates whenever a new post appears, you can click the button below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts, as well as my occasional ancient history, foreign policy or pop-culture thoughts.</p>






<h2>Point of Sale</h2>



<p>I want to start by leaning on (with small modifications for clarity) Paul Erdkamp’s taxonomy of the various options by which food might get into the stream of commerce.  A small farmer might sell their grain (I) directly to city-dwellers, (II) indirectly, via urban middlemen and grain merchants, either in the market or (III) ‘at the gate’ (meaning selling to merchants who come out to the farm in order to buy; the difference being who transports the food to the city), (IV) to itinerant traders at periodic rural markets or (V) to other local small farmers.  As we’ll see, <em>large </em>landholders have a <em>somewhat</em> larger range of options within this taxonomy, but the fundamentals are the same.</p>



<p>While all of these sale methods certainly happened, in every society I have looked at, Option I – selling directly to city-dwellers – is fairly rare for grains and other bulk agricultural goods.  Market <em>gardeners</em>, selling fruits, vegetables (and sometimes flowers) often do sell this way, maintaining a high-intensity garden near town and a shop or stall in the town market.  Likewise, while Option V – small-scale trade between farmers – absolutely happens, it is typically non-monetary: the banqueting of neighbors discussed in the first post.  Where it is monetary, it is typically quite small scale and very short distance.  By and large, small and mid-sized farmers hadn’t the time, expertise or infrastructure to sell their goods directly.  They needed to be farming, not manning a market stall or trying to figure out how to store their goods close to the point of sale.  And of course large landowners, being rich, aren’t going to stand in the market square either (and in many cases don’t want their obvious representative doing so either,  see below).  So while I and V happen, they’re not too common or too large a portion of total trade and we may lay them aside for this discussion.</p>



<p>That leaves Options II, III and IV, all of which involve selling grain to a middle-man merchant of some sort.  The main difference is the location of sale (in town, at the gate, or at periodic rural markets).  Outside of large cities and major ports, markets were likely to be <em>periodic</em>, occurring only on certain days (typically around once per week).  In Roman Italy, these were the <em>nundinae</em> (‘ninth days,’ although it was an 8-day cycle as the Romans count inclusively); the <em>nundinae</em> were minor festivals, days of rest and merrymaking, but they were also the days when the rural markets would be open – the rest-day from agricultural labor enabled farmers to head into local towns to buy or sell whatever they needed (interestingly, at Rome, the <em>nundinae</em> were <em>dies nefasti</em> – state business couldn’t generally be conducted on them – so poor farmers hoping to use their day off to participate politically were out of luck).  Similar periodic markets are common in the Middle Ages (and even today; most ‘farmer’s markets’ in the United States are periodic, <a href="http://www.carrborofarmersmarket.com/">including my town’s</a>).  The periodic nature of these markets is an adaptation to agricultural rhythms; for a market to function there need to be a lot of people together all at once and the small towns that dotted the countryside simply didn’t have the density to do that all of the time.</p>



<figure><img data-attachment-id="4249" data-permalink="https://acoup.blog/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg" data-orig-size="2325,663" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:Fresco_from_the_House_of_Julia_Felix,_Pompeii_depicting_scenes_from_the_Forum_market.JPG">Via Wikipedia</a>, a fresco showing market activity, with merchants showing off wares of fabric (left) and goods in pots (center) from the House of Julia Felix at Pompeii, first century CE.  Please note: the importance of pottery in modern archaeology has given many students and the general public the idea that the ancients were always shipping pots around for sale, as if there was a vast market in pottery.  <strong>Generally, people were buying what was in the pot, not the pot itself</strong>.</figcaption></figure>



<p>But as noted, our farmers are unlikely to be selling their grain directly to customers.  Instead, they are likely to be using some sort of middle-man merchant, which brings us to:</p>



<h2>Merchants!</h2>



<p>Merchants are a bit of a break from the people we have so far discussed in that they, by definition, live in the realm of the <em>market</em> (in the economic sense, although often also in a physical sense).  As we’ve seen so much of the world of our farmers and even our millers and bakers was governed by <em>non-market</em> interactions: horizontal and vertical social ties that carried expectations that weren’t quite transactional and certainly not monetized.  By contrast, merchants work with transactions and tend to be the <em>first</em> group in any society to attempt to monetize their operations once money becomes available.  I find students are often quick to feel identity with the merchant class, because these folks are more likely to travel, more likely to use money, more likely to employ or be employed in wage-labor; they feel more like modern people.</p>



<p>It thus tends to come as something of a surprise that with <em>stunning</em> consistency, <strong>the merchant class tended to be at best cordially disliked and at worst <em>despised</em> by the broader community</strong> (although not typically to the point of suffering legal disability, as did some other jobs; see S. Bond, <em>Trade and Taboo: Disreputable Professions in the Roman Mediterranean</em> (2016) for this in Rome).  This often strikes students as strange, both because we tend to think rather better of our own modern merchants but also because the image they have of the merchant class certainly looks elite.</p>



<figure><img data-attachment-id="4257" data-permalink="https://acoup.blog/britlibaddms35166apocalypseunkfolio3sealblackhorse/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg" data-orig-size="1134,766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="britlibaddms35166apocalypseunkfolio3sealblackhorse" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg 1134w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:BritLibAddMS35166ApocalypseUnkFolio3SealBlackHorse.jpg">Via Wikipedia</a>, a manuscript illustration showing the Horseman of Famine depicted as a grain merchant (from Revalations 6:5-6), holding the scales he would use to measure out grain.</figcaption></figure>



<p>For the farmers who need to sell their crops (for reasons we will get to in a moment) and purchase the things they need that they cannot produce, the merchant feels like an adversary: always pushing his prices to his best advantage.  We expect this, but remember that our pre-modern farmers are just <em>not that exposed to market interactions</em>; most of their relationships are reciprocal, not transactional – the horizontal relationships we discussed before.  The merchant’s ‘money-grubbing’ feels like a betrayal of trust in a society where you banquet your neighbors in the good years so they’ll help you in the bad years.  <strong>The necessary function of a merchant is to transgress the ‘rules’ of village interactions which – and this <em>resounds</em> from the sources – the farmers tend to understand as being ‘cheated.’</strong></p>



<p>At the same time, <strong>while most merchant types are humble, the high-risk and potentially high-reward involved in trade meant that <em>some</em> merchants </strong>(again, a small number) <strong>could become <em>very</em> rich</strong>.  That, as you might imagine, <strong>did not go over well for the traditionally wealthy in these societies</strong>, the large landholders.  Again, the values here often strike modern readers as topsy-turvy compared to our own, but to the elite large landholders (who dominate the literary and political culture of their societies), the <em>morally correct</em> way to earn great wealth is to inherit it (or capture it in war).  The <em>morally correct</em> way to hold that wealth is with large landed estates.  Anything else is <em>morally</em> suspect, and so the idea that a successful merchant could – by a process that again, strikes the large landholder, just like the small farmer, as ‘cheating’ – leap-frog the social pyramid and skip to the top, without putting in the work at either having distinguished wealthy ancestors <em>or</em> tremendous military success was an open insult to elite values.  Often laws were put in place to limit the ability of wealthy non-aristocrats (likely merchants or successful artisans) from displaying their wealth (<a href="https://en.wikipedia.org/wiki/Sumptuary_law">sumptuary laws</a>) so as to keep them from competing with the aristocrats; at Rome, senators were forbidden from owning ships with much the same logic (Roman senators being clever, they still invested in trade through proxies while at the same time disapproving of the activity in public politics).</p>



<p>Such disdain appears, with varying justification, in the sources of every pre-modern agrarian society I’ve studied, to one degree or another.  One commonplace of Greek and Roman thinking – despite these being very active, maritime societies – was that the first production of ships and the first sailing was in some essential way a profanation of the divine realm of the sea, a space humans ought not have ever ventured into – and certainly not for anything as mean as profit (e.g. Euripides, <em>Medea</em> 1-6; Catullus. 64.1-20; Valerius Flaccus, <em>Argonautica</em> 627-632; Seneca, <em>Medea</em> 1-12; 301-379, <em>inter alia</em> – thanks to my old grad school pals <a href="https://www.usf.edu/arts-sciences/departments/world-languages/about-us/hedrick.aspx">Buddy Hedrick</a> and <a href="http://gdrsd.org/gdrhs/faculty/michael-hoffman/">Michael Hoffman </a>for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240677</guid>
            <pubDate>Sat, 22 Aug 2020 01:04:49 GMT</pubDate>
        </item>
    </channel>
</rss>
