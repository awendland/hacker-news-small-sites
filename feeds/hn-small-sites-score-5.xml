<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 20 Dec 2020 01:20:11 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 20 Dec 2020 01:20:11 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to find contextually relevant link opportunities]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25464356">thread link</a>) | @jbsingh
<br/>
December 17, 2020 | https://tabtimize.com/how-to-find-contextually-relevant-link-opportunities/ | <a href="https://web.archive.org/web/*/https://tabtimize.com/how-to-find-contextually-relevant-link-opportunities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<p>It’s actually quite simple.</p>



<p><strong>Just follow the list below and you’ll be well on your way:</strong></p>



<ol><li>Enter the keyword/topic into Google you want to find link opportunities for.</li><li>Open each result in a new tab.</li><li>Read through all the pages and make an educated guess where on the page it might make sense to get a link from.</li><li>Save each relevant link opportunity in a spreadsheet, with the URL, related keywords/topic, where on the page the link should be linked from, and an anchor text.</li><li>If you want to reach out to these link opportunities, then you must also find one or more relevant email addresses of the people you want to get in touch with.</li><li>To make sure you have the correct contact information, just cross-reference it on any social media platform, preferably LinkedIn, to see if it’s correct.</li></ol>







<p>Repeat steps 1-6 at least hundreds to thousands of times, to make sure that, statistically, you have high enough chances of getting any contextually relevant links.</p>



<p>There must be a better way, right?</p>



<p><strong>Thankfully yes</strong>, and that’s what we’re going to talk about in this post. But before we get into it, let’s look at the numbers behind the “traditional” way of finding RLOs (relevant link opportunities). Prepare to be surprised.</p>







<h2>How long does it take to find contextually relevant link opportunities?</h2>



<p>The “traditional” 6 step approach is an excellent way to get started building contextually relevant backlinks, but it’s definitely a time consuming and mentally draining practice. In fact, this method takes around<strong> 4 minutes on average per link opportunity</strong>, not including the time it takes to do your own keyword/topic analysis and outreach.</p>



<p>Below is a basic example where I try to find relevant link opportunities for a blog on cats. The topic is cat nutrition. Doing steps 1-6 took me <strong>3 minutes and 45 seconds</strong>.</p>







<figure><img loading="lazy" width="600" height="647" src="https://tabtimize.com/wp-content/uploads/2020/11/4-minutes-gif-of-link-opportunity.gif" alt="How long does it take to find contextually link opportunities?"></figure>







<p>With an average hit rate between 3-5% (sources <a rel="noreferrer noopener nofollow" href="https://www.robbierichards.com/seo/13-killer-link-building-strategies/" target="_blank">1</a> &amp; <a rel="noreferrer noopener nofollow" href="https://moz.com/blog/link-building-rules" data-type="URL" data-id="https://moz.com/blog/link-building-rules" target="_blank">2</a>), you will be able to <strong>get a backlink every 1 hour and 20 minutes</strong> at best, and only with the use of automated outreach software. Just think <strong>what it will take to beat the top 5 spots in SERP</strong> for your niche in terms of the number of backlinks… </p>



<p>Now I do not know your specific competitors or niche, but I would assume that it will take you a lot more time than you’d ideally like to spend.</p>



<p>For example, it will take <strong>133.33 hours to build 100 links</strong> on average.</p>



<p>Here is how its calculated:</p>



<p>(100 (number of backlinks) * 80 (the average number of minutes to build 1 backlink)) / 60 (number of minutes per hour) = 133.33 hours.</p>



<p>Want to find out how many hours getting as many backlinks as your competitors will take?</p>



<p>Try it out for yourself in the calculator below:</p>







<div>   
<p>Number of backlinks: </p>
        
<p>The average number of hours it will take to get them: </p>
        <br></div>
        







<h2>The better way to find contextually relevant link opportunities</h2>



<p>We now come to what you have been waiting for, the easiest way to find contextually relevant link opportunities.</p>



<p>Artificial intelligence is becoming a norm in almost everyone’s day to day life. Smart speakers, smart cars, and smart ‘anything’ that make our lives that much easier. So why should it be so ridiculously time-consuming to find contextually relevant link opportunities?</p>



<p>Fortunately for all of us, there is now a much (and I mean <em>much</em>) easier way to find relevant link opportunities.</p>



<p>Luckily, you also do not have to go very far to find the easy way. It’s all inside the <strong>Link Opportunity feature</strong>, which you can find under the ‘Backlink Engine’ menu on Tabtimize.</p>







<figure><img loading="lazy" width="791" height="252" src="https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature.png" alt="The Link Opportunity feature" srcset="https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature.png 791w, https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature-300x96.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/Screenshot-of-link-opportunity-feature-768x245.png 768w" sizes="(max-width: 791px) 100vw, 791px"></figure>







<p>The Link Opportunity feature does all the hard work for you.</p>



<p>It reads the main content of web pages and analyzes the content with many different NLP models. It finds various essential data about the content, such as keywords, topics, contextual understanding, semantic understanding, and more. With all that data, the machine can find a contextual connection between all pages in the database and only match the relevant ones.</p>



<p>Also, it uses a relevance metric (<a rel="noreferrer noopener" href="https://tabtimize.com/link-relevance-score/" data-type="post" data-id="44" target="_blank">Link Relevance Score or LRS</a>) that quantifies the relevance analysis between two pages so that you can understand the degree of relevance between them.</p>







<figure><img loading="lazy" src="https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-1024x421.png" alt="The Link Opportunity feature view of all the relevant link opportunities" width="580" height="238" srcset="https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-1024x421.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-300x123.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-768x316.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view-1536x632.png 1536w, https://tabtimize.com/wp-content/uploads/2020/11/screenshot-of-link-opportunity-view.png 1627w" sizes="(max-width: 580px) 100vw, 580px"></figure>







<p>This basically means that the machine will do everything for you in terms of determining if a page is relevant to yours. You can also use the LRS metric to compare and sort link opportunities by the degree of contextual relevance they have to your page.</p>







<h2>But what about the anchor text?</h2>



<p>The anchor text is usually always mentioned as an essential part of understanding what a link refers to. In other words, the anchor text must tell both the users and Google what the content of that link is about. This helps users and Google to determine if the link is relevant to follow.</p>



<p>Therefore, one of the most important tasks in finding relevant link opportunities is also deciding on an anchor text.</p>



<p>Fortunately, this is also something that the Backlink Engine takes into account in its two-page relevance match. In each link opportunity result, you can see a short snippet of a text containing one or more “links” with blue marking. It symbolizes a possible anchor text that can be used If these two pages are to be linked with each other.</p>







<figure><img loading="lazy" width="1024" height="333" src="https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-1024x333.png" alt="relevant anchor text of a link opportunity " srcset="https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-1024x333.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-300x98.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3-768x250.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/new-anchor-view-3.png 1247w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>So not only does it read and link the pages by keyword, topic, and semantic relevance, but the machine also suggests anchor texts for you. Basically, there’s nothing you have to do (manually) to analyze the relevance of the pages.</p>



<p>Okay, a text savvy machine that can link relevant pages to my page, I get that, but what about the whole personalization thing and finding the right contact information?</p>







<h2>Getting the right contact information, the AI way</h2>



<p>When you find the page or pages you want to contact to get a link from in the Link Opportunities feature, you have the possibility to simply click on the green plus icon and select the “request link” button. The machine not only handles the task of finding the right contact information, but it has actually just done the outreach for you too, and eliminating the need for a pitch.</p>







<figure><img loading="lazy" width="1024" height="494" src="https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-1024x494.png" alt="request a link from a relevant link opportunity" srcset="https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-1024x494.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-300x145.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon-768x371.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/green-plus-icon.png 1225w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Requesting a link in the Link Opportunities feature</figcaption></figure>



<figure><img loading="lazy" width="1024" height="219" src="https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-1024x219.png" alt="link building management made easy " srcset="https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-1024x219.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-300x64.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-768x164.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status-1536x329.png 1536w, https://tabtimize.com/wp-content/uploads/2020/11/my-requests-status.png 1589w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Keep track for your outreach in the Link Community feature</figcaption></figure>







<p>However, if you want to do the outreach yourself, you can always add the opportunities to a list, export them to a CSV file, and do the outreach by yourself.</p>







<figure><img loading="lazy" width="1024" height="153" src="https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-1024x153.png" alt="mass export contextually relevant link opportunities" srcset="https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-1024x153.png 1024w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-300x45.png 300w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-768x114.png 768w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view-1536x229.png 1536w, https://tabtimize.com/wp-content/uploads/2020/11/Mass-export-in-list-view.png 1564w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>How does Tabtimize know what the right contact information is? That’s a secret, but one thing is for sure, this method will save you many, <em>many</em> hours of work!</p>



<p>You can actually find out just how many hours it would take to build the same amount of backlinks as your competitors by entering the number of backlinks that you entered in the first calculator in the “number of backlinks” field below.&nbsp;</p>







<div>   
<p>Number of backlinks: </p>
        
<p>The average number of hours it will take with Tabtimize: </p>
        <br></div>
        







<p>How did we calculate it?:</p>



<p>((number of entered backlinks) * 0,5 (the average number of minutes to build 1 backlink with Tabtimize)) / 60 (number of minutes per hour) = XX hours.</p>



<p><strong>An average time-saving percentage of 99.38%</strong> compared to the “traditional” way. Neat right?</p>







<h2>Get your contextual relevant link opportunities without the hassle</h2>



<p>Whether you want to do all the link building yourself, taking on all the hassle that comes with the research, outreach, and link building management, or whether you just want to do one of the ways yourself, link building is still an ultra time-consuming process. Making the process smarter will save you a lot of time and energy, and ensure your efforts aren’t wasted.</p>



<p>For the majority of us, it’s easy to see the benefit of using the Tabtimize method to find contextually relevant link opportunities. Who wouldn’t want to save 99% of their valuable time finding relevant link opportunities, right?&nbsp; It’s all about working smarter, not necessarily harder.&nbsp;</p>



<p>Did you know, it’s completely free to sign up for Tabtimize and start building contextually relevant link opportunities right away?&nbsp;</p>



<p>Click below to check it out:</p>



<p><a href="https://tabtimize.com/link-community-waiting-list/">Get contexutally relevant link opportunities</a></p>



<h2>Final thoughts</h2>



<p>You can save a lot of time if you use the right tools and methods to find and build contextually relevant backlinks. Over 99% (99.38% to be exact) of the time you spend on traditional link building research, can be simplified by using Tabtimize’s Link Opportunities feature. If you also use a smart tool to find content gaps and other content-creating options then you will be able to further optimize your time and efficiency.</p>



<p>I’m curious about other methods to find relevant link opportunities, so if you have a method you think is worth sharing, feel free to include it in the comments below.</p>

</div></div>]]>
            </description>
            <link>https://tabtimize.com/how-to-find-contextually-relevant-link-opportunities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25464356</guid>
            <pubDate>Fri, 18 Dec 2020 06:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding Composite Video to a Famicom]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25463627">thread link</a>) | @todsacerdoti
<br/>
December 17, 2020 | https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html | <a href="https://web.archive.org/web/*/https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Since I’ve been reading <a href="https://mitpress.mit.edu/books/i-am-error"><em>I Am Error</em></a>, I’ve been getting more and more interested in the technical aspects of the Famicom. Turns out all you really need to get me interested in your console is prose explanations of how a pattern table works. Also, I get to drip some molten lead into it so I can use a modern TV! Everyone wins.</p>

<p>When I was growing up, a lot of my friends had an NES, but I first had the ColecoVision and then a “Model 2” Sega Genesis when that came out. As a result, I’ve gone the last few decades thinking the NES was full of branded shovelware, because it turns out that’s <a href="https://www.youtube.com/watch?v=MzJ0M-erXAM">the exact kind of game that eight year old boys bought a lot of and then subjected their friends to</a>.</p>

<p>Later, when I was getting interested in collecting old videogames, the NES had already started its stratospheric price rise for many games, and with it the skeeziest members of the game-price-speculator community. None of the cool modern “community” stuff existed then (NESRGB, Everdrives, FDSStick) so I gave the entire system a wide berth and decided to wait until this whole fad was over and prices returned to normal. That hasn’t happened yet… however, in Japan, stuff is still really cheap due to the massive popularity of the Famicom, and the Famicom is different enough from the NES that I’m coming at it without the same preconceptions that I had of those childhood NESes.</p>

<p>Out of the box, the original Famicom only has RF output. If you’re not familiar, <a href="https://www.youtube.com/watch?v=8sQF_K9MqpA">this video by Gravis is the best I’ve seen on how RF output works</a>, and a Nintendo is even used to make it relevant to this post.</p>

<p>Not only does the Famicom only have RF output, the Japanese channel frequencies are such that that RF output only appears on channel 95 and 96 on a Western TV, which a lot of TVs simply can’t reach. On some models, you can <a href="https://www.youtube.com/watch?v=RVyFEMg0Kpg">tweak the pots on the RF can to bring that down to US channel 6</a> to get around this. However, I wanted to play my games on a Commodore 1702 or a PVM, neither of which have an antenna tuner of any kind. Doing a composite mod seemed like the easiest way forward.</p>

<h2 id="giving-it-a-good-squint">Giving It A Good Squint</h2>
<p>The first thing I noticed is that a Famicom is a <em>lot</em> smaller than an NES. They added a bunch of empty space for the American model in order to accommodate the “toaster” mechanism, I guess.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-vs-nes.jpg" alt="A Famicom is sitting on top of an American front-loading NES, which is a spoiled Western brat and doesn't like loading cartridges."></p>

<p>I thought I would hate the hard-wired controllers, but they’re actually really nice. You’re guaranteed to always get first-party controllers when you buy a used system, which is more than I can say for basically any other machine, that NES included. It would be nice if they were in better condition, but if they work I’ll be happy.</p>

<p>There’s a “Famicom Family” logo on the front sticker that I haven’t seen on most other Famicoms; from what I can tell, this is a good way to tell what machines are later models as it ties into <a href="https://maru-chang.com/hard/hvc/english.htm">some kind of later branding</a>.</p>

<h2 id="opening-it-up">Opening It Up</h2>
<p>When mine arrived from Japan, it looked dirty and pretty beaten up, but that’s okay for a test machine. I can always get a nicer one later; another thing to hoard.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-case-damage.jpg" alt="The missing chunk of plastic near the player 1 controller slot."></p>

<p>A corner of the plastic near the player-1 controller mount was missing, and there was grit in the textured plastic. I took a few trips to the sink with the plastic and scrubbed, but the yellowing is obviously not going to come out with soap and water.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-opened.jpg" alt="The Famicom's bottom cover is opened, revealing the underside of the motherboard."></p>

<p>I opened it up - screws were tight, a good sign - and then took a look at the board. It’s a late model, as evidenced by the big power/RF module soldered to the board instead of attached by a ribbon cable.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-gross-pot.jpg" alt="There is a green potentiometer with some gunk and tree debris (seeds?) on it."></p>

<p>This console has spent some time in an old shed or something, based on how much of Mother Nature had crept inside of it, but at least I didn’t find any stray cigarettes inside it unlike the above NES. The motherboard cleaned up quickly with some spray alcohol and cotton swabs.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-1989-copyright.jpg" alt="The copyright reads © 1989 Nintendo"></p>

<p>The board is a 1989, which was a pretty good year for Nintendo. <a href="https://arstechnica.com/gaming/2013/07/time-to-feel-old-inside-the-nes-on-its-30th-birthday/3/">The Famicom apparently kept getting made until <em>2003</em></a>. It would be cool to track one of those down.</p>

<p>I wanted to deep-clean the dirty, scratched-up controllers as well - the controllers still had their protective plastic wrap on them, but they were scratched anyway! - and make sure that the silicone on the D-pads were in good shape, but I stripped one of the screws on controller 1 pretty severely in a moment of clumsiness. I’ll drill that out later and service it, but in the meantime let’s get back to the composite mod.</p>

<h2 id="motherboard-work">Motherboard Work</h2>
<p>I got sort of lucky in having a late-model board. On the later boards there’s a dedicated “video” pin that is broken out near the RF jack that I could just solder to, rather than lifting pin 21 (<a href="http://wiki.nesdev.com/w/index.php/PPU_pin_out_and_signal_description"><code>VOUT</code></a>) of the PPU. This way, you can keep both the RF and composite. Reportedly, this creates a bunch of ‘jailbar’ interference, so I’ve done what others have and lifted pin 21 of the PPU. Sometimes the hard way is the best way.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-pin21-lifted.jpg" alt="Pin 21 lifted out of the PPU. Ignore the Sharpie mark telling me which pin is 21, as if I could have forgotten"></p>

<p>This wasn’t too hard to desolder and lift, but the pin would have looked a lot less mangled if I had also desoldered R6 first to get it out of the way. I had to use a little bit too much force on my “prying tweezers” to lift it out, which could have easily broken the leg on a newer chip where the legs are much more fragile. Thanks, 80s technology!</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-decoupling-caps.jpg" alt="The axial decoupling caps are added."></p>

<p>I also added decoupling caps between 5V and GND on the CPU and PPU chips. It’s just good practice! These 0.1µF axial ceramic cuties were lying in my cap pile ever since I used a handful of them for <a href="https://www.leadedsolder.com/tag/tandy1000sx">the cursed Tandy 1000SX</a>, so I was happy to slam two more of them in. The recipe I was following used <code>/RESET</code> as the 5V source, which feels a little sketchy, but it means you don’t have to run long wires all the way to the other end of the chip. Then again, the copper pour on the back of the board <em>is</em> 5V…</p>

<p>I thought 0.1µF might be a little small, but it’s easy to change these out for a 1µF or larger cap if it doesn’t have much effect. You probably shouldn’t pick decoupling caps based on aesthetics.</p>

<h2 id="video-amplification">Video Amplification</h2>
<p>The whole idea behind the composite mod is that you’re building a simple signal amplifier to replace the one that was originally inside the RF can.</p>

<p>As the baseband video signal comes out of PPU pin 21, you need to step it up to a level that the TV can easily understand. The video chip’s output transistors are simply not designed to directly drive a television, and after the weak signal goes all the way through the AV cable into the back of the TV, there’s probably not much left to pick up anyway.</p>

<p>There are a lot of homebrew mods for this, ranging from cutting out and reusing the stock transistors on the motherboard to building a whole protoboard circuit with some new parts.</p>

<p>After doing some more research, I decided I would try a part that I’ve been meaning to try for a while, <a href="https://www.ti.com/product/THS7314">the TI THS7314 video amplifier IC</a>. It’s used a lot for <a href="https://www.retrorgb.com/thsamps.html">the amplification of analogue RGB signals</a>, and it should work really well for my one-channel signal. The part is designed specifically for this application, and should both install cleanly and produce nice-looking video.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-ths7314-board.png" alt="The prototype board as seen from KiCad. It's very simple, with only a 'video in,' 'audio in,' and 'power in' pinout which then goes to the THS7314 chip."></p>

<p>I made a quick, super-simple little board that basically just broke out the pins of the video amp chip, and sent it to fab at OSH Park. They’ve recently added free (if slow - over a month) shipping to Canada, which makes them a really desirable option for running off onesy-twosie little mod boards like this during the current shipping nightmare we find ourselves in.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-boards-osh.jpg" alt="The two variants of the board - one with the traditional &quot;homebrew amp&quot; design, and the other with the TI THS7314 video amplifier chip."></p>

<p>I made boards to do two variants, one with the original “homebrew” amplifier circuit and one with the THS7314. If the THS7314 doesn’t work out for whatever reason, I can just put in the usual circuit that the community prefers. However - spoilers - the THS7314 worked fine, so I never actually constructed the traditional design.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-v0.2-assembled.jpg" alt="The v0.2 board, assembled. A cap leg comes out of the &quot;R&quot; audio hole, and then directly around in a 180 to the &quot;L&quot; audio hole."></p>

<p>I should have added a jumper to the board to solder left and right audio together (the Famicom is monoaural.) This ugly cap leg trick should be fine for awhile. I decided on a 220µF capacitor for audio, because that’s what was on the top of the cap bin when I opened it.</p>

<h2 id="sound">Sound</h2>
<p>The Famicom supports audio coming from the cartridge, which is why Castlevania III on the Famicom has such better music than that on the NES. I definitely want to be able to hear the cartridge audio, so it’s worth pulling the audio from somewhere other than directly out of the CPU (which also contains the sound hardware – lower chip counts = more profit for Nintendo.) The “<a href="https://wiki.nesdev.com/w/index.php/Cartridge_connector">audio output</a>” pin on the cartridge contains the Famicom’s sound after it has been mixed between the expansion audio and the system audio, where it normally then travels immediately to the RF can for output. Since we’re no longer putting that audio into the RF output stream, it needs to get broken out and fed into the TV using the usual RCA jacks as well.</p>

<p>Reportedly, the GPM-02 motherboard has <a href="https://nerdlypleasures.blogspot.com/2018/01/famicom-nes-simple-tweaks-to-restore.html">a different ‘mix’ between the expansion audio and the system audio compared to the original Famicom motherboard</a>. You can revert back to the original model’s amplifier behaviour by removing the 43kΩ resistor at R7 and replacing it with a 100kΩ part.</p>

<p>I also removed the choke at FC1 on the motherboard, so that the sound didn’t go into the RF can where it might pick up other noise. To source audio, I just went from the “expansion audio” pin (#46) on the cartridge port and added a 220µF capacitor.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-gpm02-audio-mods.jpg" alt="The two audio mods done. R7 is replaced with a 100kΩ resistor that I had on hand (sorry it's so big... and backward) and FC1 is removed entirely."></p>

<p>I only had a giant 100kΩ resistor on hand, so that’s the one that went in. This bugs me more than I thought it would.</p>

<p>These changes <a href="https://www.youtube.com/watch?v=gD22orMjz48">seem to make a pretty significant impact</a>. I generally don’t have an ear for little tweaks, but this is big enough that even I can pick it out. There’s whole instruments that seem to be missing from the unmodified mix.</p>

<h2 id="getting-the-signal-out">Getting The Signal Out</h2>
<p>There’s a lot of different ways I’ve seen of actually getting the composite signal out of the Famicom and into a way that you can plug it into a TV:</p>
<ul>
  <li>Cut out the RF box’s antenna jack, and <a href="http://8bitplus.co.uk/projects/famicom-av-mod-nintendo/">replace it with a TRRS jack</a>, which carries all four signals for RCA on one jack;</li>
  <li><a href="https://www.boards.ie/vbulletin/showthread.php?t=2056561579">Drill holes in the side</a> and put in some panel-mount RCA connectors;</li>
  <li><a href="https://www.youtube.com/watch?v=ky8rFPbzGMU">Run a female or male RCA cable squid out of the case</a> (usually …</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html">https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html</a></em></p>]]>
            </description>
            <link>https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463627</guid>
            <pubDate>Fri, 18 Dec 2020 03:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin: Decentralization Deserves a Chance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25463561">thread link</a>) | @npguy
<br/>
December 17, 2020 | http://p2p.ai/2020/12/17/decentralization-deserves-a-chance/ | <a href="https://web.archive.org/web/*/http://p2p.ai/2020/12/17/decentralization-deserves-a-chance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-73">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>“In crypto, the price is the news” said a smart person on Twitter.  Today, it most definitely is. With Bitcoin blowing past 20K USD and folks in technology and finance struggling to fit narratives to price changes, it is important that in the midst of all the noise around price we don’t lose sight of a very significant and impactful paradigm shift that Bitcoin is an instance of: Decentralization.</p>



<p>The ‘Digital Gold’ narrative has given a very effective model for most of us to understand Bitcoin. But the simplicity of this model is also its curse – it mostly hides the actual promise that Bitcoin represents – that trust can indeed be decentralized, and a ‘hubless’ world is very much possible. In fact, in a digital world where we all increasingly understand that “we are the product” – a move towards such a hubless economy might be inevitable.</p>



<p>It will help to remember that Decentralization is not a discrete point in the space of how economies work, but a continuous spectrum. The most recent changes in economic models that we have witnessed (Hotel chains to AirBnB, Taxi companies to Uber) tell us that directionally, we are definitely moving towards a peer-to-peer (P2P) model for many economic functions – and while there might be attempts to decentralize most functions (very comparable to the Internet), the ones where a P2P model would be the best fit, the model will stick. Crypto (and the token model representing ownership/utility/governance) just happens to be the current transactional framework that enables such economies to function. There will be more. </p>



<p>Unfortunately, Bitcoin – the first instance of this shift – happens to address a very tricky concept: Money. The fact that many of the early cryptocurrencies that came after Bitcoin chose to just refine the concept – improving what Bitcoin did, on parameters like scalability, privacy and programmability, but still focusing on the concept of Money – brought a lot of skepticism and negative commentary to the space. Obviously, if you put anonymity and Money in the same sentence, the interpretations cannot be very positive. The 2017 ICO boom, where many players chose to ignore the regulations set by governments and organizations that oversee fundraising, added strength to the perception that decentralizing trust is not a good idea – and made many smart people both in technology and finance just stay away from Crypto.</p>



<p>So here is the one good thing that the price of Bitcoin does to the space: it brings the attention back. And while we have the attention, it is important for us to ask: If the Internet – with its promise of disintermediation – deserved a chance, if the sharing economy – with its promise of providing more economic opportunities to individuals – deserved a chance, then, with its promise of a P2P world with no hubs that might misuse our trust for profit – Decentralization Deserves a Chance?   </p>













		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>http://p2p.ai/2020/12/17/decentralization-deserves-a-chance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463561</guid>
            <pubDate>Fri, 18 Dec 2020 03:42:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur bug prevents upgrades to the next version]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25463521">thread link</a>) | @groobongithub
<br/>
December 17, 2020 | https://micromdm.io/blog/big-sur-softwareupdate/ | <a href="https://web.archive.org/web/*/https://micromdm.io/blog/big-sur-softwareupdate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><br><span>Date: Thu, Dec 17, 2020</span><br><span>Reading Time: 7 minutes</span></p><p>If you work with Apple in some capacity, you know that they’re not very likely to admit mistakes. I’m not aware of Apple publishing postmortems after outages or providing details about known issues. So it’s up to the developer and admin communities at large to help each other learn about outages and potential causes. With the release of macOS 11.1 this week I’ve been debugging a new issue with the Mac software update process, one which will affect most enterprise users. I decided I should write about it and let everyone know what the issue is, workarounds, and how to avoid it. I’ve also been paying close attention to some recent changes to the software update mechanism, so I’ll try to mention them below as well.</p><h2 id="a-macos-11-bug-prevents-upgrades-to-the-next-version">A macOS 11 bug prevents upgrades to the next version</h2><p>After macOS 11.1 was released earlier this week, many users <a href="https://twitter.com/Contains_ENG/status/1339399335298166785">started reporting</a> that they were not able to see the software update. Others reported that they saw it, but were not able to download it. I personally experienced this issue when 11.1 was in beta and filed a case with Apple about it, but then moved on to other problems. When the final release came out this week, there were widespread reports of it on the MacAdmins Slack. Reading through system logs, I as well as other admins were able to find what appears to be the root cause. <strong>Under certain conditions, macOS 11.0.1 and macOS 11.1 hosts are requesting the update server send the 11.0.1 update, instead of requesting the next available one. The server rejects this update as it’s already either installed or older.</strong> This somehow corrupts the state of the software update process, and the update is no longer visible as an option in System Preferences.</p><figure><img src="https://micromdm.io/big_sur_softwareupdate/log.jpg"></figure><h3 id="workarounds">Workarounds</h3><ul><li>The update is visible again immediately after the restart. But it’s unclear if the update can always be installed after it’s visible since the condition that made it fail to download the first time can be triggered again.</li><li>Removing the MDM enrollment profile causes the update to be seen again. I and several others tested this extensively, and it’s definitely the enrollment profile, not some other policy managed by MDM. This is obviously a terrible workaround and I’d hesitate to mention it to users as it could cause security agents to stop working, and countless approval dialogs we’re so familiar with. Not to mention some of you have the MDM enrollment profile as non-removable or users who are not administrators, so they don’t have permission to unenroll. Getting them back enrolled in the MDM might prove to be a challenge too.</li><li>Distributing the full 11.1, and eventually the 11.2 installers.</li></ul><h3 id="can-apple-fix-this-bug-without-manual-intervention">Can Apple fix this bug without manual intervention?</h3><p>Apple is well aware this is a problem now, so I am confident the issue will be addressed in 11.2. Unfortunately, it is a client-side issue affecting both 11.0.1 and 11.1 clients. So there’s not much Apple <em>can</em> do to provide a fix. One potential solution I see is for Apple to detect the wrong request and instead of rejecting the download, offer the right file archive instead. But this is a complex system and it’s unclear if the server-side changes alone are enough.</p><p>Something else Apple could try is to side load a patch through another software update. There’s background configuration and malware removal tools that are likely capable of fixing the issue on the system. But it’s an ugly hack and one I’d personally stay clear of even if the option was available.</p><p>In my opinion, the most likely outcome is that the bug will be fixed in 11.2, but clients that have already upgraded to Big Sur (or any M1 macs you might’ve bought) will have to work around the problem themselves. If we’re lucky Apple will publish a support article and that will be that.</p><h2 id="what-else-you-need-to-know">What else you need to know</h2><p>Big Sur has changed the software update mechanism entirely, especially on Apple Silicon macs. It’s a long time coming and Apple spoke about some of this at WWDC in the MDM and IT sessions, so it shouldn’t be entirely surprising. But a lot was left unsaid for us to discover on our own.</p><ul><li>Combo update packages are <a href="https://eclecticlight.co/2020/12/17/apple-has-stopped-providing-standalone-installers-for-macos-updates/">no longer published</a> on the Apple website. This might surprise many of you who rely on distributing them. The main reason is that the entire format of the updates has changed, and it’s also no longer possible to install updates without the Mac having access to the internet. The updates must come from Apple, and they must be managed by <code>softwareupdate</code> and related processes on the system.</li><li>On Apple Silicon, third party processes are no longer able to script the <code>softwareupdate</code> command. Running the software update command as a root process now prompts for the administrator password, who also needs to be a secure token user. There are only two possible options for OS updates to be applied; either the human user of the device itself or the MDM process <a href="https://support.apple.com/guide/deployment-reference-macos/using-secure-and-bootstrap-tokens-apdff2cf769b/1/web/1.0">which has special permission</a>. It might also be possible for the Mac to update itself with the auto-update mechanism, but there are too many bugs right now to observe how well that works. My personal experience is that it doesn’t and I’m greeted with a password prompt to enter the next day…</li><li>Specifying a custom URL for the <code>softwareupdate</code> process to pull updates from is no longer possible. Apple advertised this deprecation for all of last year, so it should surprise no one but it hurts. <a href="https://github.com/wdas/reposado">Reposado</a> was one of several great tools that made it possible to have unstable/beta/stable tracks within an organization.</li><li>—ignore is gone as a flag. It <a href="https://mrmacintosh.com/10-15-5-2020-003-updates-changes-to-softwareupdate-ignore/">was gone</a> in 10.15.5 briefly too, so you likely know about this one. This time it’s gone for good and never coming back. An MDM server can delay the client from seeing OS updates for up to 90 days only, but that is the absolute maximum going forward. Even for a future major release like macOS 12. If this is important to you, file feedback for Apple to provide a second deferral option, specific to major version numbers.</li></ul><p>I work with the MDM protocol a lot day-to-day and have been <a href="https://micromdm.io/blog/os_update/">testing</a> software updates for a while. I was even <a href="https://micromdm.io/blog/wwdc20-what-s-new-in-managing/">optimistic</a> about what it would look like in Big Sur back in June. Apple had promised it’s an entirely new implementation, closer to what is available on iOS and that everything would work better than before. But we’re not off to a good start, and all the concerns I had for several years now are back. The <a href="https://developer.apple.com/documentation/devicemanagement/commands_and_queries">design</a> of OS updates in MDM is brittle, requiring multiple remote procedure calls to accomplish something that was previously done by a few lines of shell scripting. And that would be bad on its own, but the bad design is coupled with a buggy implementation; there are many known issues, besides the one I described above. Unless something drastically changes, we’re likely to see many months, if not years of software update bugs that are entirely out of our control.</p><p>Apple was never particularly great at building systems for the enterprise. But, until recently, the Unix components were available for software developers and system administrators to work with. The end result ended up being that if you made an investment within your organization, macOS was a great experience for end-users. It took a lot of work, but it was all achievable. Today, Apple is no better at developing systems that are required in the enterprise. But the ball is entirely in their court. Apple still makes great tools for consumers, and there will be a demand from employees to provide them with Apple gear. But, if Apple can’t start acting on our collective feedback, the experience of using a Mac in the workplace will quickly become unbearable to most.</p></div></div></div>]]>
            </description>
            <link>https://micromdm.io/blog/big-sur-softwareupdate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463521</guid>
            <pubDate>Fri, 18 Dec 2020 03:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WeWork: How the $3.5B Flex Space Giant Is Engineering a Comeback]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25462692">thread link</a>) | @gk1
<br/>
December 17, 2020 | https://sacra.com/research/wework-engineering-a-comeback/ | <a href="https://web.archive.org/web/*/https://sacra.com/research/wework-engineering-a-comeback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="light-at-the-end-of-the-tunnel">Light at the end of the tunnel</h2><p>WeWork is inarguably one of the most controversial companies in the world. Its unsustainable growth strategy destroyed billions in shareholder value. Has WeWork finally hit rock bottom, or is it a falling knife?&nbsp;</p><p>We don’t have a crystal ball, but based on the work we have done, we believe WeWork has most of the pieces in place for a powerful turnaround.</p><p>In January 2019, WeWork was valued at $47B, making it the second-largest private company at the time, 15x the price of its closest competitor. After its failed IPO at the end of 2019, it nosedived to $7.3B. In March 2020, just as offices around the world were closing amid the coronavirus outbreak, SoftBank refused to participate in a $3B tender offer of early employee shares. The valuation of WeWork fell all the way to $2.9B, down 94% from its peak.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/d878dff8-8141-42de-9292-25cabe8af273_Screen+Shot+2020-12-17+at+14.23.03.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>WeWork’s rise from startup to $47B company took 9 years—its fall back down to $2.9B took just over 1.</em></p><p>The private markets have gone from euphoria to disillusion with WeWork. The company was downgraded again by credit rating agency Fitch in October 2020, and its cash burn through the year so far is estimated to be above $1.6B.</p><p>Our research shows that after all the recent changes, there is a light at the end of the tunnel. We aggregated public data, analyzed financial data, talked to real estate brokers, developers, industry experts and built a model.&nbsp;</p><p>We can scoff at WeWork’s one-page long community adjusted EBITDA, but the company has been undergoing a reorganization towards profitability.&nbsp;</p><p>Key decisions include rightsizing their real estate portfolio, exiting 66 unprofitable leases, effecting a favorable shift in customer mix shift with 60% revenue now coming from enterprises, reducing the size of the workforce from 14,000 to 5,000 and hiring a new management team.&nbsp;</p><p>In addition to WeWork’s internal efforts, the most unexpected tailwind is that the global experiment of remote working that we’ve seen during COVID may give rise to a structurally more flexible and distributed workforce in the near future. Ironically, the economic downturn many thought would sink WeWork may become the very cause of its survival.&nbsp;</p><p>A capital-light strategy is also on the horizon (a genuine one this time). Once the dust settles, WeWork could leverage its existing business and office management services and transform itself into a franchise provider.</p><div>
            <p>Join our list for access to an exclusive 1-hour analyst conference call on the future of WeWork's business.</p>
            
        </div>
    <h2 id="wework-s-road-to-redemption--">WeWork’s road to redemption&nbsp;&nbsp;</h2><ul><li><strong>Our DCF model gives WeWork a valuation of $3.5B.</strong> At this price, WeWork equity resembles a call option, with limited downside but asymmetric upside.</li><li><strong>The site economics behind WeWork's core business are surprisingly positive. </strong>24 months after opening, the average WeWork location can generate a 20% contribution margin, compared with economics from more stable peers. A big reason for WeWork’s cash burn was its lack of mature locations. In 2019, WeWork had the biggest flexible workspace footprint, but the lowest % of mature sites, comparing with its profit-making peers.</li><li><strong>WeWork has become much more prudent in new location openings.</strong> Mature locations are expected to grow to 50% by the end of 2020 and reach 100% in 2022.</li><li><strong>WeWork has spent 2020 stabilizing its core operations</strong> with 4 key measures.</li><li><strong>60% of WeWork's customers are now enterprises.</strong> During the pandemic, WeWork leased 3.5 million square feet to enterprise clients, including TikTok, Mastercard, Microsoft, Citigroup and Deloitte.</li><li><strong>WeWork's new CEO is a real estate veteran.</strong> The current CEO is a disciplined operator with successful turnaround experience.</li><li><strong>WeWork has rightsized its real estate portfolio.</strong> We estimate WeWork has exited 66 locations and amended about 150 leases, driving higher average occupancy and margins across their portfolio.</li><li><strong>WeWork has cut costs.</strong> WeWork has shrunk its workforce by 60% and cut many experimental growth projects, such as WeLive, WeGrow and self-driving chairs. Operating expenses are trending down significantly, from 86% of revenue in 2018 to an estimated 50% in 2019.</li><li><strong>Market dynamics are changing.</strong> Post-COVID, 80% of people want to return to the office a few days a week but keep the benefit of flexibility. Ironically, the downturn many thought would sink WeWork may become the very cause of its survival.</li><li><strong>WeWork is quietly transitioning to an integrated, tech-enabled ecosystem coordinator.</strong> Despite the large cost-cutting, WeWork continues to invest in community services, aka, the "killer app". For example, WeWork Labs is a community digital platform. It provides cross-sector incubator services to support companies to acquire skills, meet peers and experts.</li><li><strong>WeWork could reshape the real estate stack. </strong>It could leverage its physical locations and build a tech-enabled layer on top, thereby, transform into a middleware to connect people and optimize spaces.</li></ul><h2 id="valuation--wework-is-worth--3-5b">Valuation: WeWork is worth $3.5B</h2><p>Our base case discounted cash flow (“DCF”) model implies a 2021 forward equity value of $3.5B for WeWork.&nbsp;</p><p>WeWork still has the shape of a distressed company. The capital structure is heavily indebted and equity is at the bottom of the pecking order. Nevertheless, the equity resembles the asymmetric risk/reward profile of an out of the money call option.&nbsp;</p><p>In other words, given the current financial and operating dynamics of the company, for every one unit of enterprise value increase, the upside is amplified for the equity holders.&nbsp;</p><p>For anyone to stand behind WeWork now, however, they must be comfortable with a lot of macro uncertainties related to GDP, unemployment, speed of returning to the office and the opportunities around what the future of workspace would look like.&nbsp;</p><p>If WeWork can stabilize their operations in the near term through delayed capital spending, improved occupancy and regained focus, there could be a meaningful upside.</p><p>We highlight the structure of our model below.&nbsp;</p><p>Our aim with our model is to capture WeWork’s key growth and cost drivers to have a sense of the company’s profit-making potential. We used company disclosures from 2019 and turnaround guidance to form the base case assumptions. Our model calculates enterprise value by subtracting net debt and capitalized operating leases to derive equity value.&nbsp;</p><p>We can summarize our DCF into three distinct phases:</p><ul><li>Phase 1: 2020 - 2024 turnaround and stabilization.&nbsp;</li><li>Phase 2: 2025 - 2030 disciplined growth in the core business, expansion in franchise model and other business services.&nbsp;</li><li>Phase 3: 2031+ steady-state growth at 2%, with the overall occupancy to remain at 90%.&nbsp;</li></ul><p>We disaggregate revenue into total workstations, total memberships and average revenue per member (“ARPM”) to derive occupancy rates. We also build a CapEx profile based on cost per workstation to calculate location level contribution margin (WeWork defines contribution margin as membership revenue minus location operating expenses before headquarter administrative costs, growth expenses, marketing and stock-based compensation).&nbsp;</p><img src="https://images.prismic.io/sacra/40c25e89-a189-4840-9598-e31e51bb39f4_Screen+Shot+2020-12-17+at+16.39.31.png?auto=compress,format"><p><em>WeWork's revenue drivers. </em></p><p>WeWork doubled its total workstations between 2016 and 2019. As a result, mature locations accounted for only c.30% of the overall portfolio. To preserve cash and streamline operations, the pace of expansion has slowed significantly. The base case assumes total workstations to grow at 5% p.a. to reach 1.2M by 2024.&nbsp;</p><p>We illustrate our key revenue and cost assumptions below.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/651fa87a-afc1-4704-b255-af19682d60fe_Screen+Shot+2020-12-17+at+14.26.02.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Post the initial phase of “growth at all cost” prior to 2019, we model that between 2021 and 2024, WeWork would become more selective in new location openings, as well as, more prudent in the number of new openings.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/ff74c6c7-57a0-4331-973f-cb4f175995e7_Screen+Shot+2020-12-17+at+14.26.18.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Revenue: We model a slower revenue growth rate before WeWork achieves profitability.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/bc338059-f6b2-4418-a579-f4a85000e82a_Screen+Shot+2020-12-17+at+14.26.36.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Mixed shift: Enterprise memberships contribute 60% of the revenue in 2020. It is a positive trend that it almost doubled since 2017.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/bc174c16-e919-48b6-898e-94e5fb1e5aee_Screen+Shot+2020-12-17+at+14.26.48.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>We model that, …</em></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/wework-engineering-a-comeback/">https://sacra.com/research/wework-engineering-a-comeback/</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/wework-engineering-a-comeback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25462692</guid>
            <pubDate>Fri, 18 Dec 2020 01:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Hundred Different Misspellings of Schwarzenegger]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25462660">thread link</a>) | @cowllin
<br/>
December 17, 2020 | https://www.watercoolertrivia.com/blog/schwarzenegger | <a href="https://web.archive.org/web/*/https://www.watercoolertrivia.com/blog/schwarzenegger">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Arnold Alois Schwarzenegger was born in Austria on July 30, 1947. Famously, he reached stratospheric levels of notoriety and success in three wholly distinct professional fields: bodybuilding, acting, and politics, culminating in his eight years as the Governor of California.&nbsp;<br></p><p>For the past 73 years, Schwarzenegger has gone by Arnold, Ahnuld, Governator, <a href="https://en.wikipedia.org/wiki/Arnold_Schwarzenegger">Austrian Oak</a>, Terminator, Running Man, and dozens of other nicknames. In part because he’s charismatic and there’s nicknames aplomb to describe him, sure.&nbsp;<br></p><p><strong>But also because his last name is hard to spell. Like, really hard.</strong> We would know, because Water Cooler Trivia participants have spelled Schwarzenegger 255 different ways. And we’ve dug deep to explore that data.&nbsp;<br></p><p>255 different spellings. <a href="https://www.watercoolertrivia.com/blog/feature-emojis"><strong>We don’t grade responses based on spellings</strong></a>, so these are the spellings we’ve accepted as correct. We’ve got the full list of them at the end of this article, but we wanted to dig deeper into the data<br></p><h2>First things first: here’s the trivia question<br></h2><blockquote><strong>“What is the name of the Austrian bodybuilder who has been Mr. Universe three times and Mr. Olympia seven times?”</strong><br></blockquote><p>The answer, as you’ve surely guessed by now, is Arnold Schwarzenegger. We first wrote this question in April 2019, and since then…</p><ul role="list"><li><strong>3,019 different participants</strong> across 306 different groups have submitted a response</li><li><strong>2,681</strong> (89%) of folks got the question correct</li><li><strong>1,616</strong> (60%) of correct responses were spelled correctly [editor’s note: we suspect phone and browser autocorrect software lent a helping hand here]</li><li><strong>255</strong> different spellings of Schwarzenegger during that time<br></li></ul><p>And now, let’s look at the different ways in which Schwarzenegger has been spelled by Water Cooler Trivia participants.&nbsp;</p><h2>1. What are the most common misspellings?</h2><p>When you remove the correct spelling, you are left with 1,060 participants who spelled Schwarzenegger in 254 different ways.&nbsp;<br></p><p>The most common misspelling is to simply add a <strong>T </strong>after the <strong>R</strong>, a.k.a <strong>Schwartzenegger</strong>. This makes sense, as Schwartz itself is a fairly common German surname. 116 different respondents, 4% of all correct responses, spelled Arnold’s surname with that bonus <strong>T.</strong><br></p><p>Next up was <strong>Schwarzeneger</strong>, which removes a letter rather than adding one, this time removing one of the two <strong>G</strong>s. Again, this matches intuition. Double letters are hard to remember and frequently don’t add anything phonetically to a word. 88 different participants spelled it with this missing <strong>G</strong>, or 3% of all correct responses.<br></p><p>In third place was <strong>Schwarzenager</strong> with 56 people (2% of correct responses) both dropping that same <strong>G </strong>and then also swapping an <strong>E </strong>with a <strong>G. </strong>We get it, spelling is hard.<br></p><p>Below is a chart of the ten most common misspellings, and for the intrepid, here’s the <a href="https://docs.google.com/spreadsheets/d/1QqEL1IZvox3Aypi0YDStZ3QJ2_WuMTPwp7pOJ2batPE/edit#gid=756356712">full list</a> of misspellings.</p><figure id="w-node-73dd971f4f5a-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf08dd766ee0807d28_YMx1QfTHzO6c61u44T5MnhVihFk7AuJUa3aJXoUvDh8sLDYthwp4CYFclY0sUekxH3MYA1U9T9lu0OY0GBnxEtnBW-jUzNYQfk5iRSXSBP2musv3twFKBiNuMHwAPsVhEvrRVvUz.png" alt=""></p></figure><h2>2. Wait, how many letters is it?</h2><p>It’s 14 letters. S-c-h-w-a-r-z-e-n-e-g-g-e-r. But not everyone realized that.&nbsp;<br></p><p>Of the 255 total different spellings,&nbsp;</p><ul role="list"><li><strong>169</strong> (66%) had fewer than 14 letters</li><li><strong>24</strong> (9%) had more than 14 letters</li><li><strong>61</strong> (24%) correctly had 14 letters but were spelled incorrectly</li><li><strong>1</strong> (0.4%) correctly had 14 letters and was spelled correctly<br></li></ul><p>The most popular length was 13 letters with 31% of distinct spellings and 13% of all correct responses.</p><figure id="w-node-b1be6443de1a-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf088a2f4f273d8970_jDn-VaUiTJ_o9aGXBHJpAgFsSNJ4qViTLF0n0X5ZsN1kWQFbC7nS7JO88_K3BwfEaYJEkkT60LeNMN6-x7CwXgXXpJPsO7JLx7fPFXYMxPmM2bmSAaVNS0g1ttJBCkZDVdFqo_jX.png" alt=""></p></figure><h2>3. So it starts with an S... then a C… then...</h2><p>Schwarzenegger starts with the letter S. That’s fairly obvious. In fact, of the 255 distinct spellings that accepted as correct, 100% of them started with the letter <strong>S</strong>. However, once you move on to the second letter, <strong>only 58% of the spellings had C as the second letter.</strong><br></p><p>Unsurprisingly, the share of “correct” letters in terms of positions descends as you get further in the word, with a few noticeable deviations: interestingly, misspellings tend to correctly guess that the 11th letter is a <strong>G</strong> and the 14th letter is an <strong>R</strong>.<strong>&nbsp;</strong></p><figure id="w-node-3153958d4ef7-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf6ef4066cb3b8bc5a_SVo29XaQjA6jKuUkHuTPk1t2s967m2NoVPJrmpRPCGKe3Hrzg40C8kdhQvOqWkjw_BH_8noZ2ds0YGXkppq-B22DsD0PZ6auFQTHvSlEjpjzYw7r1Htdz5sFgWl7oAdN6pVAGp-6.png" alt=""></p></figure><h4>Double Letters</h4><p>On that topic, Schwarzenegger has a double letter in it: two G’s as the 11th and 12th letter. This was a common source of misspellings, as 1<strong>47 of the distinct spellings (58%) guessed that there was only one G</strong> in the politician’s surname.<br></p><h4>Edit Distance</h4><p>Known as edit distance or Levenshtein distance, this is a measure of how many changes you need to make to a word or phrase in order to translate it into another word or phrase. <strong>So “bake” has a distance of one from “cake” or “ake” or “baked”.</strong><br></p><p>When you search the internet for <strong>Girrafe</strong> and the search engine asks <strong><em>“Did you mean Giraffe?”</em></strong><em> </em>they are making that guess because your search query only had an edit distance of two from the more common query term <strong>Giraffe</strong>. One deletion (the first <strong>R</strong>) and one insertion (the second <strong>F</strong>) turns your query into the correct word.&nbsp;<br></p><p>So, basically, this is a way to see <strong><em>how bad </em></strong>certain spellings were. Or, more optimistically, how generous we at Water Cooler Trivia are as graders.&nbsp;<br></p><p>Okay, with all that prologue finished, here’s the edit distance stats for the 255 distinct spellings of Schwarzenegger. Note that we are only surfacing the 1,060 responses that were incorrectly spelled.&nbsp;</p><ul role="list"><li><strong>34% had an edit distance of only one</strong>!</li><li>And another 28% were only off by two characters!</li><li>18% of misspellings had an edit distance of at least four</li></ul><figure id="w-node-00b9f866edfc-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcfee56eb8449ae2563_Qw6LyfdHxuw1-KuhsN3NFHyHzwr-1PnjCWoBqcc6pBTMNmr1DKqO-LmCkjcwMx-wn3K4inzJcTAnSOQCLQokxfe_psFkS6F8YkA4ohbuvw5kcvg7D9ApQtGulyfaG4kXCjRYgV-r.png" alt=""></p></figure><h2>4. What does Schwarzenegger even mean?</h2><p>I was wondering that too. It turns out the name has Germanic roots, divided neatly into two terms.</p><ul role="list"><li>"schwarzen" means "black"</li><li>&nbsp;"egg" refers to a ridge<br></li></ul><p>So the Governator’s surname <strong>translates most literally into English as Black Ridge</strong>, which happens to be the name of a U.S. <a href="https://www.blackridge.us/"><strong>technology services company</strong></a>.</p><h2>Closing thoughts...</h2><p>Looking to learn about more commonly-misspelled names or commonly-mistaken knowledge? Us too! We have a dataset of 2.5 million free text trivia responses. If you want to work with us to mine for fun data-driven stories, email <a href="https://www.watercoolertrivia.com/cdn-cgi/l/email-protection#6501041104251204110017060a0a09001711170c130c044b060a08"><span data-cfemail="1d797c697c5d6a7c69786f7e727271786f696f746b747c337e7270">[email&nbsp;protected]</span></a> and we can find a way to work together.<br></p><p>Or if you just want to bring a <a href="https://www.watercoolertrivia.com/blog/how-weekly-trivia-impacts-your-mental-well-being"><strong>weekly trivia ritual</strong></a> to your team, that would make our hearts a-flutter. Get started with a four-week free trial at our <a href="http://watercoolertrivia.com/"><strong>homepage</strong></a>.<br></p></div></div>]]>
            </description>
            <link>https://www.watercoolertrivia.com/blog/schwarzenegger</link>
            <guid isPermaLink="false">hacker-news-small-sites-25462660</guid>
            <pubDate>Fri, 18 Dec 2020 01:15:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse engineering the Nest home/away API]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25459560">thread link</a>) | @emilburzo
<br/>
December 17, 2020 | https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/ | <a href="https://web.archive.org/web/*/https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
<p>A while ago I purchased a Nest camera because I liked the idea of only having to provide power and a WiFi connection to get a nice security system.</p>
<p>The fact that you could control it with <a href="https://support.google.com/googlenest/answer/9293712?hl=en">Works with Nest</a> (their open API) was a major factor in that decision.</p>
<p>Then Google bought Nest, and <a href="https://www.consumerreports.org/smart-home/things-to-know-about-works-with-nest-shutdown/">disabled access</a> for users who didn’t sign up in time (including me).</p>
<p>There were some promises that a new open API will be created “soon”.</p>
<p>Eventually, they released the <a href="https://developers.google.com/nest/device-access/api">Smart Device Management API</a>, and although you can do some things (get camera stream), you can’t set the “Home/Away” status.</p>
<p>Bummer.</p>

<p>You can read more about it <a href="https://support.google.com/googlenest/answer/9257400">here</a>, but <strong>TL;DR</strong> the Nest camera movement/sound alarms only trigger if it’s set to “Away”.</p>
<p>For reasons I don’t want to go into, the automatic Home/Away feature doesn’t work for me so I need a way to control it from code so it can be automated, as all good things.</p>

<p>Like all pros, my first try was to just open the Nest webapp with DevTools open, click the Home/Away toggle, copy as curl, run it from the CLI and… nothing.</p>
<p>Didn’t work.</p>
<p>Upon closer inspection I noticed the payload was binary, never a good sign :)</p>
<div><pre><code data-lang="bash">curl --data-binary <span>$'\nB\n\u001aSTRUCTURE_XXXXXXXXXXXXXXXX\u0012$XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\u0012\u0095\u0001\n\u000estructure_mode\u0012u\nTtype.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeRequest\u0012\u001d\u0008\u0002\u0010\u0001\u001a\u0017\n\u0015USER_XXXXXXXXXXXXXXXX\u001a\u000c\u0008ü¸Ìþ\u0005\u0010\u0080É\u0087¸\u0001'</span> <span>'https://grpc-web.production.nest.com/nestlabs.gateway.v1.ResourceApi/SendCommand'</span>  
</code></pre></div><p>(some details redacted)</p>

<p>The host endpoint at the end of the <code>curl</code> command was a very good hint that they are using <a href="https://grpc.io/">gRPC</a>, which I didn’t have any experience with so far.</p>
<p>On the gRPC website was our next clue:</p>
<blockquote>
<p>Define your service using Protocol Buffers, a powerful binary serialization toolset and language</p>
</blockquote>
<p>That matches the binary payload that we previously saw, now it’s getting exciting!</p>

<p>Since the simple payload replay didn’t do anything, I needed to figure out what’s actually in there.</p>
<p>The first (surprising) problem was actually just getting the binary payload into a text file, I guess the binary was getting messed up somewhere between the browser and the file I was pasting to.</p>
<p>The “Save all as HAR with content” feature was very helpful here, especially since there’s a base64 encoded field beneath the binary one.</p>
<p>Extracting that only took a bit of bash magic:</p>
<div><pre><code data-lang="bash">cat set-away-home.nest.com.har                           <span>\
</span><span></span>    | gron                                               <span>\
</span><span></span>    | grep <span>'json.log.entries[1].response.content.text'</span>   <span>\
</span><span></span>    | cut -d <span>'"'</span> -f <span>2</span>                                    <span>\
</span><span></span>    | base64 -d                                          <span>\
</span><span></span>    | base64 -d
</code></pre></div><p>(If you don’t know about <a href="https://github.com/tomnomnom/gron">gron</a>, you should definitely check it out, it makes JSON grep-able)</p>
<p>(No idea why it was base64-encoded twice)</p>

<p>Going through the official protobuf documentation it seemed like I needed the <code>.proto</code> files to do anything useful.</p>
<p>Which I couldn’t figure out how to extract from the Nest website, or if that’s even possible.</p>
<p>Luckily, I stumbled upon <code>protoc --decode_raw</code>, which gave the following output:</p>
<pre><code>1 {
  1 {
    1: "STRUCTURE_XXXXXXXXXXXXXXXX"
    2: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
  }
  2 {
    1 {
      1: "STRUCTURE_XXXXXXXXXXXXXXXX"
      2: "structure_mode"
      3: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
    }
    2: 4
    4 {
      1 {
        1: "type.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeResponse"
        2 {
          1: 1
        }
      }
    }
    6 {
      1 {
        1: "STRUCTURE_XXXXXXXXXXXXXXXX"
        2: "structure_mode"
        3: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
      }
      2 {
        1: "type.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeRequest"
        2 {
          1: 2
          2: 1
          3 {
            1: "USER_XXXXXXXXXXXXXXXX"
          }
        }
      }
      3 {
        1: XXXXXXXXXX
        2: XXXXXXXXX
      }
    }
  }
}
15: ""
2: ""
15: "\000\000"
</code></pre><p>Quite a heavy payload to set a flag.</p>
<p>Then I tried to manually create the <code>.proto</code> files going by the output from above.</p>
<p>Not fun.</p>
<p>By luck (aka searching GitHub for those types) I found out that somebody a lot smarter than me had actually <a href="https://github.com/derek-miller/nest-protobuf">managed to extract the proto files</a> from the Nest website, thank you stranger!</p>

<p>Time to make use of those <code>.proto</code> files.</p>
<p>Start up the IDE and follow the protobuf tutorial on how to build a payload.</p>
<p>It was a lot harder than I expected.</p>
<p>I’m sure most of the hardness came from me never using protobuf before, but it also took me a bit to realize that they serialize the command we care about (<code>StructureModeChangeRequest</code>) into a generic type (<code>ResourceCommandRequest</code>) which is then also serialized.</p>
<p>Eventually I was able to send the protobuf payload to the Nest API and oh boy, seeing that icon switch from “Home” to “Away” was like an early christmas :)</p>
<p><img src="https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/images/nest-home-away.gif" alt="Nest home to away animation"></p>
<p>Hmm, but why isn’t the HTTP connection closing? It just hangs there.</p>
<p>Comparing the headers from the original request I could see that there’s an <code>X-Accept-Response-Streaming: true</code> header, adding it caused the connection to directly close as expected.</p>
<p>Strange, especially since <code>false</code> keeps the connection open. Mystery for another day.</p>
<p>I packaged everything nicely into a <a href="https://github.com/emilburzo/nest-rest">GitHub repo</a> and moved on to the last part.</p>

<p>The standard approach here would be to install some location tracker on all the “home” phones and periodically send it to a server which then decides when to toggle the Nest status.</p>
<p>Although I actually built an <a href="https://graticule.link/">android location sharing app</a>, I didn’t like this approach due to having to make a tradeoff between battery life and responsiveness.</p>
<p>I also looked into Google Location Sharing, but it involved creating another Google Account, permanently sharing my location with it and using that as the source. Too fragile.</p>
<p>The solution I went with in the end was:</p>
<ul>
<li>assign static IPs to all the relevant phones</li>
<li>try to connect to them from the internal network</li>
</ul>
<p>If the response is <code>connection refused</code>, they are on the network/“home”.</p>
<p>Anything else, they aren’t “home”.</p>
<p>Well, maybe also <code>connection accepted</code> if you’re weird and have a server on your phone.</p>
<p>I’m still surprised how well this works, because I read a lot of “don’t do this” online with reasons like:</p>
<ul>
<li>phones will automatically switch off their WiFi overnight</li>
<li>they won’t respond when they are in deep sleep</li>
<li>etc</li>
</ul>
<p>Maybe I got lucky, but it works, and it works very well:</p>
<pre><code>2020-12-17 09:36:07 INFO     found hosts: ['192.168.0.30', '192.168.0.31']
2020-12-17 09:36:07 INFO     192.168.0.30 is home
2020-12-17 09:36:09 INFO     set status to: home (200)
2020-12-17 09:41:09 INFO     192.168.0.30 is home
2020-12-17 09:46:13 INFO     192.168.0.31 is home
2020-12-17 09:51:17 INFO     192.168.0.31 is home
[..]
2020-12-17 11:17:29 INFO     set status to: away (200)
2020-12-17 12:35:11 INFO     192.168.0.31 is home
2020-12-17 12:35:12 INFO     set status to: home (200)
2020-12-17 12:40:16 INFO     192.168.0.31 is home
</code></pre><p>The switch from Away -&gt; Home is quicker than doing it by hand :)</p>
<p>I prepared another <a href="https://github.com/emilburzo/nest-home-away">GitHub repo</a>, fired everything up, and… it works!</p>

<p>It really sucks that I had to spend a day for something that either should just work, or at least I should have access to change on my own.</p>
<p>If the camera quality wasn’t so high I would have just ditched it and gone self-hosted with a DVR/NVR.</p>
<p>It would have taken longer to build all the features, but then I have control over every part.</p>
<p>The Nest app is still annoying me to migrate to a Google account, so let’s see for how long this solution actually works.</p>
    </div></div>]]>
            </description>
            <link>https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459560</guid>
            <pubDate>Thu, 17 Dec 2020 19:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon disallows pointing out paid reviews]]>
            </title>
            <description>
<![CDATA[
Score 963 | Comments 422 (<a href="https://news.ycombinator.com/item?id=25459434">thread link</a>) | @kmod
<br/>
December 17, 2020 | http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/ | <a href="https://web.archive.org/web/*/http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-1067">
<p><span><span>17</span>Dec/20</span><span><a href="http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/#comments">11</a></span></p>

<p>I recently bought a webcam from Amazon (late to the party, I know), and when it came it was fine but not amazing.</p>
<p>When I went through the packaging I saw a little card saying "send us a screenshot of your 5-star review and we'll give you a $10 Amazon gift card":</p>
<p><img src="http://blog.kevmod.com/wp-content/uploads/2020/12/IMG_16902.jpg" alt="$10 for 5-star reviews" width="400/"></p>
<p>I thought that other Amazon shoppers would want to know that this was happening and that the reviews were less trustworthy, so I wrote up a review and submitted it to Amazon.</p>
<p>Yesterday I got a notification that my review was rejected.  I heard of Amazon being ham-fisted about this stuff but it was still shocking that it would happen to me:</p>
<p><img src="http://blog.kevmod.com/wp-content/uploads/2020/12/screenshot.png" alt="Amazon review rejection"></p>
<p>I assume they rejected this due to the first rule, "Feedback on the seller ... should be provided [elsewhere]".  I could understand this being a good policy in some cases, but here they're using it to justify silencing talk about reviews.  I suppose we don't know whether they disallow positive comments about other reviews, but I would guess that that never happens.</p>
<p>I remember that I used to use Amazon ratings as the main driver behind my purchases, so it's sad to see the review system become less helpful over time.  It's extra sad that Amazon would rather try to hide the issue and not improve it.</p>
<p>Update:<br>
My premise was that the reviews section should be helpful for making purchasing decisions.  Some people (including Amazon) are saying that the reviews should be about the product, which is coherent but I would argue makes them less useful.  For example I feel quite helped when a review for chocolate mentions that the chocolate arrived melted -- this is not a review about the product intrinsically, but is still very helpful for deciding whether or not to buy the item.  Similarly, as a purchaser I would want to see a warning that there may be paid reviews for the product, and I was very surprised to learn that Amazon disallows such warnings.</p>
<p>Update 2:<br>
I submitted feedback through the link they requested, and here's the result:</p>
<p>https://www.amazon.com/sp?_encoding=UTF8&amp;asin=B087NN41JH&amp;isAmazonFulfilled=1&amp;ref_=olp_merch_name_1&amp;seller=AD5F1I5PAE5XB</p>
<p>I don't think this serves either goal of educating future purchasers or changing the sellers behavior.</p>
<p>Update 3:<br>
I've chatted with an Amazon rep on the issue, and to their credit they seemed to take it seriously and "noted the report violation against the seller".  They said to expect an update in 2-3 business days, though it's not clear what sort of update it will be.</p>







</div></div>]]>
            </description>
            <link>http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459434</guid>
            <pubDate>Thu, 17 Dec 2020 19:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralization Deserves a Chance]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25458429">thread link</a>) | @npguy
<br/>
December 17, 2020 | https://p2p.ai/2020/12/17/decentralization-deserves-a-chance/ | <a href="https://web.archive.org/web/*/https://p2p.ai/2020/12/17/decentralization-deserves-a-chance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-73">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>“In crypto, the price is the news” said a smart person on Twitter.  Today, it most definitely is. With Bitcoin blowing past 20K USD and folks in technology and finance struggling to fit narratives to price changes, it is important that in the midst of all the noise around price we don’t lose sight of a very significant and impactful paradigm shift that Bitcoin is an instance of: Decentralization.</p>



<p>The ‘Digital Gold’ narrative has given a very effective model for most of us to understand Bitcoin. But the simplicity of this model is also its curse – it mostly hides the actual promise that Bitcoin represents – that trust can indeed be decentralized, and a ‘hubless’ world is very much possible. In fact, in a digital world where we all increasingly understand that “we are the product” – a move towards such a hubless economy might be inevitable.</p>



<p>It will help to remember that Decentralization is not a discrete point in the space of how economies work, but a continuous spectrum. The most recent changes in economic models that we have witnessed (Hotel chains to AirBnB, Taxi companies to Uber) tell us that directionally, we are definitely moving towards a peer-to-peer (P2P) model for many economic functions – and while there might be attempts to decentralize most functions (very comparable to the Internet), the ones where a P2P model would be the best fit, the model will stick. Crypto (and the token model representing ownership/utility/governance) just happens to be the current transactional framework that enables such economies to function. There will be more. </p>



<p>Unfortunately, Bitcoin – the first instance of this shift – happens to address a very tricky concept: Money. The fact that many of the early cryptocurrencies that came after Bitcoin chose to just refine the concept – improving what Bitcoin did, on parameters like scalability, privacy and programmability, but still focusing on the concept of Money – brought a lot of skepticism and negative commentary to the space. Obviously, if you put anonymity and Money in the same sentence, the interpretations cannot be very positive. The 2017 ICO boom, where many players chose to ignore the regulations set by governments and organizations that oversee fundraising, added strength to the perception that decentralizing trust is not a good idea – and made many smart people both in technology and finance just stay away from Crypto.</p>



<p>So here is the one good thing that the price of Bitcoin does to the space: it brings the attention back. And while we have the attention, it is important for us to ask: If the Internet – with its promise of disintermediation – deserved a chance, if the sharing economy – with its promise of providing more economic opportunities to individuals – deserved a chance, then, with its promise of a P2P world with no hubs that might misuse our trust for profit – Decentralization Deserves a Chance?   </p>













		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://p2p.ai/2020/12/17/decentralization-deserves-a-chance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25458429</guid>
            <pubDate>Thu, 17 Dec 2020 18:17:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring arrays in Kafka with lateral joins]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457905">thread link</a>) | @Natasha_Fll
<br/>
December 17, 2020 | https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article we are going to explore <b>lateral joins. </b></p><p><b>"What is a lateral join?"</b> you may ask. It's a new kind of <i>join</i> that allows to extract and work with the single elements found inside an array, as if the array was a normal table.</p><p>Lenses 4.1 comes with a lot of new features that make your life easier when working with arrays: we introduced <a href="https://docs.lenses.io/4.1/sql/functions/#array-functions">6 new functions to work with arrays</a>, better support for array literals, and lateral joins.</p><p>All these features are available both for our Snapshot and Streaming Engine.</p><p>You can read more about <a href="https://docs.lenses.io/4.1/sql/streaming/laterals/">this functionality in our docs</a>, as well as trying it yourself following <a href="https://help.lenses.io/sql/streaming/explode-arrays/">this self-contained tutorial</a>.</p><p>What we would like to focus on in this post, however, is how this feature came to be; designing this functionality has been an exciting journey and we thought it would be useful to share the thought process and iterations behind the implementation.</p><ul><li><p> <!-- -->We will initially explore the high-level requirements that motivated this feature;</p></li><li><p> <!-- -->Then we will explore what a possible solution could look like and the implications of each approach</p></li><li><p> <!-- -->Finally we will go through our design iterations, concluding with the final result and how it delivers all that we set out to achieve.</p></li></ul><p>Let's get cracking.</p><h2>Motivation</h2><p>Assume that you have a topic called <code>batched_readings</code> that collects readings from some kind of sensor meter.</p><p>The upstream system stores "batches" of reading per meter. That means that each single record will contain multiple readings for its meter:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[81,&nbsp;82,&nbsp;81]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[95,&nbsp;94,&nbsp;93,&nbsp;96]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[80,&nbsp;82]&nbsp;}</pre><pre></pre><pre></pre><p>
Our goal is to extract the single readings for each record, and build a new topic where each record contains only one reading:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;100&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;101&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;102&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"reading":&nbsp;81&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"reading":&nbsp;82&nbsp;},</pre><pre></pre><pre>...</pre><pre></pre><pre></pre><p>
How can we do that?</p><h2>Exploring the solution space</h2><p>Before starting to work on the feature, we did some research to see if and how this functionality was implemented in other SQL streaming systems or more traditional RDBMS systems.</p><p>We found two main different approaches to the problem:</p><h3>The "Explode" approach</h3><p>
Some systems implement the functionality introducing special functions that can be used as a normal projections, right after the <code>SELECT&nbsp;</code>clause. The idea is that a special function will "explode" the array, making the select emit a record for each item in the array.</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;EXPLODE(readings)&nbsp;AS&nbsp;reading</pre><pre></pre><pre>FROM&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading</pre><p>The syntax is quite straightforward and easy to use in this simple case, but we found it a bit more complex and less predictable in more complicated scenarios, like when multiple <code>EXPLODE</code>s are used or when multi-level arrays need to be worked with.</p><p>Another limitation of this approach is that it is hard to work with the exploded array elements outside the projection. For example, something like this is not possible in KSqlDB:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;EXPLODE(readings)&nbsp;AS&nbsp;reading</pre><pre></pre><pre>FROM&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading</pre><pre></pre><pre>WHERE&nbsp;EXPLODE(readings)&nbsp;&gt;&nbsp;100</pre><p>

In general, we soon realized that treating <code>EXPLODE</code> as a normal function (albeit one that generates more than one output per each input) was not the right choice for us. We could do better.</p><h3>The "Table Function" approach</h3><p>Not satisfied with the solution above, we considered whether moving the <code>EXPLODE</code> to the source would solve the some of the highlighted problems.</p><p>After some research, we realized that this was an approach already embraced by other classical RDBMS systems like PostgreSQL, with its <code>unnest</code> table function.</p><p>This approach is based on two concepts:</p><ol><li><p> <b>Table functions: </b>functions that transforms normal values to tables</p></li><li><p> <b>Lateral joins: </b>with lateral joins it is possible to express a relation between the value of a field on the left-hand side of a join, and its right-hand side. This contrasts with traditional joins, where you can only join tables that are completely independent of one another.</p></li></ol><p>With these concepts to hand, our first design iteration defined a new <code>EXPLODE</code> table function and a new <code>LATERAL</code> keyword, to be able to join a source to the result of a table function:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;EXPLODE(readings&nbsp;as&nbsp;reading)</pre><p>The table function <code>EXPLODE(readings&nbsp;as&nbsp;reading)</code> should be read as follows:</p><blockquote><p><i>Take the current value of the </i><i><code>readings</code></i><i> array and transform it to a table. Such table will have only one column, called </i><i><code>reading</code></i><i>, and each element of the original array will be a row in that table.</i></p></blockquote><p><code>EXPLODE(readings&nbsp;as&nbsp;reading)</code> is a table that depends on the value of the <code>readings</code> field for each single record. Every record will then produce a table.</p><p>Going back to our meter reading example, consider the first record, where <code>readings</code> is <code>[100,&nbsp;101,&nbsp;102]</code>. For that record, the expression <code>EXPLODE(readings&nbsp;as&nbsp;reading)&nbsp;</code>will produce the following table:</p><pre>|&nbsp;reading&nbsp;|</pre><pre></pre><pre>-----------</pre><pre></pre><pre>|&nbsp;100&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|&nbsp;101&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|&nbsp;102&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre></pre><p>
Since we gave the name <code>reading</code> to the elements inside <code>readings</code>, we can use it in the <code>SELECT</code> as if it were a normal field.</p><p>But not only that, we can use it wherever we want, like in a <code>WHERE</code> or in a <code>GROUP&nbsp;BY</code> !</p><p>The table expression <code>batched_reading&nbsp;LATERAL&nbsp;EXPLODE(readings&nbsp;as&nbsp;reading)</code> can at this point be read as follows:</p><blockquote><p><i>For each record in </i><i><code>batched_reading</code></i><i>, compute the table </i><i><code>EXPLODE(readings&nbsp;as&nbsp;reading)</code></i><i>, and join that table with the original record.</i></p></blockquote><p>That means that if we take again the record <code>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102]&nbsp;}</code> as an example, the above table expression will result in the following table:</p><pre>|&nbsp;meter_id&nbsp;|&nbsp;readings&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;reading&nbsp;|</pre><pre></pre><pre>|----------|----------------|---------|</pre><pre></pre><pre>|1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|[100,&nbsp;101,&nbsp;102]&nbsp;|100&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|[100,&nbsp;101,&nbsp;102]&nbsp;|101&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre><pre></pre><pre>|1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|[100,&nbsp;101,&nbsp;102]&nbsp;|102&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</pre>
<h3>Our final approach</h3><p>After exploring the table function approach, we realized that the only real concrete example of a table function would be <code>EXPLODE</code>; we then understood that we could use directly the array expression as the argument of the <code>LATERAL</code> join, without the <code>EXPLODE</code> function.</p><p>With that simplification the query becomes:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;readings&nbsp;as&nbsp;reading</pre><p>This brings a small but effective improvement to the syntax, as well as making an important aspect of our approach to lateral joins more prominent: we can treat <i>any</i> array as a valid right-hand side of a lateral join, including any expression returning an array.</p><h2>Filtering the results of a lateral join</h2><p>With the approach to lateral joins we just described, we can use the exploded item not only in the projections of a <code>SELECT</code>, but also in all the other places of the query where you can use fields coming from a source. This includes <code>WHERE</code> and <code>GROUP&nbsp;BY</code>.</p><p>Using the same example used above, this query allows you to keep only the readings greater than <code>90</code>:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_reading&nbsp;</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;readings&nbsp;as&nbsp;reading</pre><pre></pre><pre>WHERE</pre><pre></pre><pre>&nbsp;&nbsp;reading&nbsp;&gt;&nbsp;90</pre><h2>Nested lateral joins</h2><p>The result of a <code>LATERAL</code> is a table expression, so  it can be used inside the left-hand-side of a <code>LATERAL</code>. This can be useful when you want to extract elements inside a nested array.</p><p>Let's take  a slight modification of the <code>batched_readings</code> example:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"nested_readings":&nbsp;[[100,&nbsp;101],&nbsp;[102]]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"nested_readings":&nbsp;[[81],&nbsp;[82,&nbsp;81]]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"nested_readings":&nbsp;[[95,&nbsp;94],&nbsp;[93,&nbsp;96]]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"nested_readings":&nbsp;[[80,&nbsp;82]]&nbsp;}</pre><pre></pre><pre></pre><p>
Here <code>nested_readings</code> is an array of arrays. We can get the same results as before with the following query:</p><pre>SELECT&nbsp;STREAM</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_readings_nested</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;nested_readings&nbsp;as&nbsp;readings</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;readings&nbsp;as&nbsp;reading</pre><h2>Working with multiple arrays</h2><p>The <code>EXPLODE</code> function approach allowed to specify multiple arrays to be exploded at the same time. When multiple <code>EXPLODE</code>s are used, the arrays are traversed in parallel, and elements with the same index are returned together.</p><p>To achieve similar behavior with <code>LATERAL</code> join it was enough to introduce a new <code>zip</code> array function: <code>zip</code> takes two (or more) arrays, it traverses them in parallel, and it builds a single new array where the elements are objects containing values from the original arrays.</p><p>For example, the following expression:</p><pre>zip([1,&nbsp;2,&nbsp;3],&nbsp;'a',&nbsp;['x',&nbsp;'y',&nbsp;'z'],&nbsp;'b')</pre><pre></pre><pre></pre><p>
will be evaluated to the following array:</p><pre>[{"a":&nbsp;1,&nbsp;"b":&nbsp;"x"},&nbsp;{"a":&nbsp;2,&nbsp;"b":&nbsp;"y"},&nbsp;{"a":&nbsp;3,&nbsp;"b":&nbsp;"z"}]</pre><pre></pre><pre></pre><p>
Let's go back to our original example, and assume now we have a new array where the time of the reading was reported (the time is here a simple integer just to keep the code concise):</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102],&nbsp;"times":&nbsp;[1,&nbsp;2,&nbsp;3]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[81,&nbsp;82,&nbsp;81],&nbsp;"times":&nbsp;[1,&nbsp;2]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[95,&nbsp;94,&nbsp;93,&nbsp;96],&nbsp;"times":&nbsp;[4,&nbsp;5,&nbsp;6,&nbsp;7]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[80,&nbsp;82],&nbsp;"times":&nbsp;[4,&nbsp;5]&nbsp;}</pre><pre></pre><pre></pre><p>
We can use <code>zip</code> to build an intermediate array that will then be passed to the <code>LATERAL</code> join:</p><pre>SELECT</pre><pre></pre><pre>&nbsp;&nbsp;meter_id,</pre><pre></pre><pre>&nbsp;&nbsp;reading.value,</pre><pre></pre><pre>&nbsp;&nbsp;reading.time</pre><pre></pre><pre>FROM</pre><pre></pre><pre>&nbsp;&nbsp;batched_readings</pre><pre></pre><pre>&nbsp;&nbsp;LATERAL&nbsp;zip(readings,&nbsp;'value',&nbsp;times,&nbsp;'time')&nbsp;as&nbsp;reading</pre><h2>Lateral joins for streaming data</h2><p>Something that we strive to achieve with Lenses <a href="https://lenses.io/product/sql/">SQL </a>is a consistent and seamless experience over all type of user data, be it static or streaming.</p><p>It will come as little surprise then that lateral joins are fully supported in our Streaming SQL as well as in our Snapshot one.</p><p>The syntax and concepts are the same the we have been explaining throughout this post, but now are used as part of an <a href="https://docs.lenses.io/4.1/sql/streaming/">SQL Processor</a> rather than an <a href="https://docs.lenses.io/4.1/sql/snapshot/">SQL Studio</a> query.</p><p>To illustrate how this would work, let's go back to our sensor meter example, and let's assume that we have the same <code>batched_readings</code> topic as before, which will receive events as below:</p><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[81,&nbsp;82,&nbsp;81]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[95,&nbsp;94,&nbsp;93,&nbsp;96]&nbsp;},</pre><pre></pre><pre>{&nbsp;"meter_id":&nbsp;2,&nbsp;"readings":&nbsp;[80,&nbsp;82]&nbsp;},</pre><pre></pre><pre>....</pre><pre></pre><pre>....</pre><pre></pre><pre>....</pre><p>

What if we wanted to <i>split</i> our data to ensure that readings that are inside a <i>normal</i> range are sent downstream to be processed, but readings outside such …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/">https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/</a></em></p>]]>
            </description>
            <link>https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457905</guid>
            <pubDate>Thu, 17 Dec 2020 17:39:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to property-based testing with QuickCheck]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25457744">thread link</a>) | @gbrown_
<br/>
December 17, 2020 | https://jesper.sikanda.be/posts/quickcheck-intro.html | <a href="https://web.archive.org/web/*/https://jesper.sikanda.be/posts/quickcheck-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
      Posted
      
            by Jesper
       on December 17, 2020
    </p>
    <p>In February, I will be teaching a new course on Functional Programming at TU Delft. The course will mostly cover Haskell using <a href="https://www.cs.nott.ac.uk/~pszgmh/pih.html">Graham Hutton’s excellent book</a>, though there will be a part on basic usage of dependent types in Agda towards the end as well. For the exercises, we will use the Delft-grown <a href="https://weblab.tudelft.nl/">Weblab platform</a> for letting the students code and run the automated tests using QuickCheck. Unfortunately for me, the book does not talk about QuickCheck at all. Fortunately for you, that means I decided to write a tutorial myself, which you can read here.</p>
<p>Of course there are many excellent QuickCheck tutorials out there already. However I found all of them either assumed too much Haskell knowledge (since I want to introduce QuickCheck as early as possible), skipped out on interesting parts (such as conditional and quantified properties), or were just not up-to-date with the latest version of QuickCheck (such as the new approach for generating random functions using <code>Fun</code>). So I hope this post closes a gap in the current menu of tutorials for at least a few people.</p>
<p>If you spot any errors or opportunities for improvement, please let me know. The students at TU Delft will be grateful!</p>

<p>When you were first learning to program, at some point you were probably told about the importance of writing <em>unit tests</em>: small test cases that each test a small piece of functionality of your code. And while it is true that writing unit tests is important, it is also at the same time <em>boring</em> and <em>difficult</em>. It is boring because you need to write many separate unit tests for each piece of functionality, which all look more or less the same. And it is difficult because it is very easy to miss a certain combination of inputs for which the program crashes. Would it not be nice if we could just write down how the program should behave and have the test cases be generated automatically? That is precisely the approach of <strong>property-based testing</strong>.</p>
<p>In short, property-based testing is an approach to testing where you as the programmer write down properties that you expect to hold of your program. When running the tests, the test runner will generate a lot of different random input values, and then check that the property holds for all these (combinations of) input values. Compared to writing individual unit tests, property-based testing has several advantages:</p>
<ul>
<li>You spend <strong>less time writing test code</strong>: a single property can often replace many hand-written test cases.</li>
<li>You get <strong>better coverage</strong>: by randomly generating inputs, QuickCheck will test lots of combinations you’d never test by hand.</li>
<li>You spend <strong>less time on diagnosis of errors</strong>: if a property fails to hold, QuickCheck will automatically produce a minimized counterexample.</li>
</ul>
<p><strong>QuickCheck</strong> is a tool for property-based testing of Haskell code. Since its introduction for Haskell in 1999, QuickCheck has become very popular as a testing framework and has been ported to many other programming languages such as C, C++, Java, JavaScript, Python, Scala, and many others (see <a href="https://en.wikipedia.org/wiki/QuickCheck">https://en.wikipedia.org/wiki/QuickCheck</a> for a more complete list). However, QuickCheck really benefits from the fact that Haskell is a pure language, so that is where the approach continues to be the most powerful.</p>
<p>This introduction will show you the basic usage of QuickCheck for testing properties of Haskell code, as well as how to use alternative random generators. All the functions that are used come from the module <code>Test.QuickCheck</code> from the QuickCheck package. This package can be installed using the Cabal package manager for Haskell by issuing the following command:</p>
<pre><code>&gt; cabal install QuickCheck</code></pre>

<p>To write a QuickCheck test case, all you have to do is define a Haskell function that defines a <strong>property</strong> of your program that you expect to hold. In the simplest case, a property is just a value of type <code>Bool</code>. For example, suppose we have written a simple Haskell function to calculate the distance between two integers:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>distance ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb2-2">distance x y <span>=</span> <span>abs</span> (y<span>-</span>x)</span></code></pre></div>
<p>We can then express the property that the distance between <code>3</code> and <code>5</code> equals <code>2</code>:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>prop_dist35 ::</span> <span>Bool</span></span>
<span id="cb3-2">prop_dist35 <span>=</span> distance <span>3</span> <span>5</span> <span>==</span> <span>2</span></span></code></pre></div>
<p>By convention, names of QuickCheck properties always start with <code>prop_</code>. We can express more general properties by defining a function that returns a <code>Bool</code>:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>-- The distance between any number and itself is always 0</span></span>
<span id="cb4-2"><span>prop_dist_self ::</span> <span>Int</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb4-3">prop_dist_self x <span>=</span> distance x x <span>==</span> <span>0</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span>-- The distance between x and y is equal to the distance between y and x</span></span>
<span id="cb4-6"><span>prop_dist_symmetric ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb4-7">prop_dist_symmetric x y <span>=</span> distance x y <span>==</span> distance y x</span></code></pre></div>
<p>When testing a property that takes one or more inputs, QuickCheck will randomly generate several inputs (100 by default) and check that the function returns <code>True</code> for all inputs.</p>
<p>The main function used to call QuickCheck is <code>quickCheck</code>, which is defined in the module <code>Test.QuickCheck</code>. To import it, you can either add <code>import Test.QuickCheck</code> at the top of your file or import it manually if you are working from GHCi. Assuming you have installed the QuickCheck package, you can then load the file and run tests by calling <code>quickCheck</code>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>&gt;</span> ghci</span>
<span id="cb5-2"><span>GHCi</span>, version <span>8.10</span><span>.</span><span>2</span><span>:</span> https<span>://</span>www<span>.</span>haskell<span>.</span>org<span>/</span>ghc<span>/</span>  <span>:?</span> for help</span>
<span id="cb5-3"><span>Loaded</span> package environment from <span>~/.</span>ghc<span>/</span>x86_64<span>-</span>linux<span>-</span><span>8.10</span><span>.</span><span>2</span><span>/</span>environments<span>/</span>default</span>
<span id="cb5-4"><span>&gt;</span> <span>:</span>l QuickCheckExamples.hs</span>
<span id="cb5-5"><span>&gt;</span> quickCheck prop_dist35</span>
<span id="cb5-6"><span>+++</span> <span>OK</span>, passed <span>1</span> test<span>.</span></span></code></pre></div>
<p>QuickCheck tells us that everything is as it should be: it ran the test and got the result <code>True</code>. Since there are no inputs to the test, it is run only once. Let us try out some more properties!</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>&gt;</span> quickCheck prop_dist_self</span>
<span id="cb6-2"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span>
<span id="cb6-3"><span>&gt;</span> quickCheck prop_dist_symmetric</span>
<span id="cb6-4"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span></code></pre></div>
<p>Huge success! For each of the tests, QuickCheck has generated 100 random inputs and verified that for each one the property returns <code>True</code>.</p>
<p>To get more information about the test inputs that are generated by QuickCheck, you can replace the function <code>quickCheck</code> with <code>verboseCheck</code>. This will print out each individual test case as it is generated. Try it out for yourself!</p>
<h2 id="shrinking-counterexamples">Shrinking counterexamples</h2>
<p>What happens if there’s a mistake in our code? Say we forgot to write <code>abs</code> in the definition of <code>distance</code>?</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>&gt;</span> quickCheck prop_dist_symmetric</span>
<span id="cb7-2"><span>***</span> <span>Failed</span><span>!</span> <span>Falsified</span> (after <span>2</span> tests)<span>:</span>                  </span>
<span id="cb7-3"><span>0</span></span>
<span id="cb7-4"><span>1</span></span></code></pre></div>
<p>QuickCheck has found a counterexample: if the first input <code>x</code> is 0 and the second input <code>y</code> is 1, then <code>y-x</code> is not equal to <code>x-y</code>.</p>
<p>When QuickCheck finds a counterexample, it will not always return the first one it encounters. Instead, QuickCheck will look for the smallest counterexample it can find. As an example, let us try to run QuickCheck on the (false) property stating that every list is sorted.</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>sorted ::</span> <span>Ord</span> a <span>=&gt;</span> [a] <span>-&gt;</span> <span>Bool</span> </span>
<span id="cb8-2">sorted (x<span>:</span>y<span>:</span>ys) <span>=</span> x <span>&lt;=</span> y <span>&amp;&amp;</span> sorted (y<span>:</span>ys)</span>
<span id="cb8-3">sorted _        <span>=</span> <span>True</span></span>
<span id="cb8-4"></span>
<span id="cb8-5"><span>-- A (false) property stating that every list is sorted</span></span>
<span id="cb8-6"><span>prop_sorted ::</span> [<span>Int</span>] <span>-&gt;</span> <span>Bool</span></span>
<span id="cb8-7">prop_sorted xs <span>=</span> sorted xs</span></code></pre></div>
<div id="cb9"><pre><code><span id="cb9-1"><span>&gt;</span> verboseCheck prop_sorted</span>
<span id="cb9-2"><span>Passed</span><span>:</span>  </span>
<span id="cb9-3">[]</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span>Passed</span><span>:</span> </span>
<span id="cb9-6">[]</span>
<span id="cb9-7"></span>
<span id="cb9-8"><span>Passed</span><span>:</span>  </span>
<span id="cb9-9">[<span>0</span>]</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span>Failed</span><span>:</span>  </span>
<span id="cb9-12">[<span>2</span>,<span>1</span>,<span>3</span>]</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span>Passed</span><span>:</span>                                 </span>
<span id="cb9-15">[]</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span>Passed</span><span>:</span>                                                 </span>
<span id="cb9-18">[<span>1</span>,<span>3</span>]</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span>Passed</span><span>:</span>                                                 </span>
<span id="cb9-21">[<span>2</span>,<span>3</span>]</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span>Failed</span><span>:</span>                                                 </span>
<span id="cb9-24">[<span>2</span>,<span>1</span>]</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span>...</span></span>
<span id="cb9-27"></span>
<span id="cb9-28"><span>***</span> <span>Failed</span><span>!</span> <span>Falsified</span> (after <span>4</span> tests <span>and</span> <span>3</span> shrinks)<span>:</span>    </span>
<span id="cb9-29">[<span>1</span>,<span>0</span>]</span></code></pre></div>
<p>The first list that is generated that is not sorted is <code>[2,1,3]</code>. Note that this will be a different list every time we run QuickCheck since it is randomly generated. However, QuickCheck does not stop there and instead tries smaller and smaller lists until it converges to a minimal counterexample: <code>[1,0]</code>. This process is called <strong>shrinking</strong>.</p>
<p>It is worth noting that despite the inherent randomness of QuickCheck, shrinking will often converge to one of a small set of minimal counterexamples. For example, if we run <code>quickCheck</code> many times on <code>prop_sorted</code>, we always end up with either <code>[1,0]</code> or <code>[0,-1]</code> as a counterexample.</p>
<p>The precise strategy that QuickCheck uses for shrinking counterexamples depends on the type of the counterexample:</p>
<ul>
<li><p>For numeric types such as <code>Int</code>, QuickCheck will try a random number that is smaller in absolute value (i.e.&nbsp;closer to 0).</p></li>
<li><p>For booleans of type <code>Bool</code>, QuickCheck will try to replace <code>True</code> with <code>False</code>.</p></li>
<li><p>For tuple types <code>(a,b)</code>, QuickCheck will try to shrink one of the components.</p></li>
<li><p>For list types, QuickCheck will try to either delete a random element from the list, or try to shrink one of the values in the list.</p></li>
</ul>
<h2 id="testing-many-properties-at-once">Testing many properties at once</h2>
<p>Instead of running individual tests from GHCi, you can also combine all your tests in a <code>main</code> function:</p>
<div id="cb10"><pre><code><span id="cb10-1">main <span>=</span> <span>do</span></span>
<span id="cb10-2">  quickCheck prop_dist35</span>
<span id="cb10-3">  quickCheck prop_dist_self</span>
<span id="cb10-4">  quickCheck prop_dist_symmetric</span></code></pre></div>
<p>This code makes use of Haskell <code>do</code> keyword that we will study in the chapter on monads. Once you have defined this <code>main</code> function, you can invoke it by calling <code>runghc</code> from the command line:</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>&gt;</span> runghc QuickcheckExamples.hs</span>
<span id="cb11-2"><span>+++</span> <span>OK</span>, passed <span>1</span> test<span>.</span></span>
<span id="cb11-3"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span>
<span id="cb11-4"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span></code></pre></div>
<p>Note that a file may only contain a single <code>main</code> function. In a realistic project, we would instead create a separate file that just defines all QuickCheck properties and puts them together in a <code>main</code> function.</p>
<p><strong>Remark.</strong> When you are writing code in the WebLab instance for this course, you do not need to write a main function for QuickCheck tests: WebLab will automatically collect all functions in the <code>Test</code> tab whose name starts with <code>prop_</code> and run <code>quickCheck</code> on each one.</p>

<p>The biggest challenge in making effective use of QuickCheck lies in coming up with good properties to test. So let us take a look at some examples of good properties to test.</p>
<h2 id="roundtrip-properties">Roundtrip properties</h2>
<p>When one function is an inverse to another function, we can create a property test for that. For example, we can test that reversing a list is its own inverse:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>prop_reverse_reverse ::</span> [<span>Int</span>] <span>-&gt;</span> <span>Bool</span></span>
<span id="cb12-2">prop_reverse_reverse xs <span>=</span> <span>reverse</span> (<span>reverse</span> xs) <span>==</span> xs</span></code></pre></div>
<p>As another example, we can test that inserting an element into a list and then deleting it again …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesper.sikanda.be/posts/quickcheck-intro.html">https://jesper.sikanda.be/posts/quickcheck-intro.html</a></em></p>]]>
            </description>
            <link>https://jesper.sikanda.be/posts/quickcheck-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457744</guid>
            <pubDate>Thu, 17 Dec 2020 17:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Password Cracking with Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25457715">thread link</a>) | @gsvclass
<br/>
December 17, 2020 | https://42papers.com/p/generative-deep-learning-techniques-for-password-generation | <a href="https://web.archive.org/web/*/https://42papers.com/p/generative-deep-learning-techniques-for-password-generation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://42papers.com/p/generative-deep-learning-techniques-for-password-generation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457715</guid>
            <pubDate>Thu, 17 Dec 2020 17:24:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cold War II has started, and China is a bigger challenger than the USSR ever was]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25457476">thread link</a>) | @lawschool333
<br/>
December 17, 2020 | https://www.pairagraph.com/dialogue/cf3c7145934f4cb3949c3e51f4215524?hack | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/cf3c7145934f4cb3949c3e51f4215524?hack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/cf3c7145934f4cb3949c3e51f4215524?hack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457476</guid>
            <pubDate>Thu, 17 Dec 2020 17:04:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl Supports NASA]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25456369">thread link</a>) | @ddevault
<br/>
December 17, 2020 | https://daniel.haxx.se/blog/2020/12/17/curl-supports-nasa/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/17/curl-supports-nasa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Not everyone understands how open source is made. I received the following email from NASA a while ago.</p>



<h2>Subject: Curl Country of Origin and NDAA Compliance</h2>



<blockquote><p>Hello, my name is [deleted] and I am a Supply Chain Risk Management Analyst at NASA. As such, I ensure that all NASA acquisitions of Covered Articles comply with Section 208 of the Further Consolidated Appropriations Act, 2020, Public Law 116-94, enacted December 20, 2019. To do so, the Country of Origin (CoO) information must be obtained from the company that develops, produces, manufactures, or assembles the product(s). To do so, please provide an email response or a formal document (a PDF on company letterhead is preferred, but a simple statement is sufficient) specifically identifying the country, or countries, in which Curl <strong>is developed and maintained</strong></p></blockquote>



<blockquote><p>If the country of origin is outside the United States, please provide any information you may have stating that testing is performed in the United States prior to supplying products to customers. Additionally, if available, please identify all authorized resellers of the product in question.</p></blockquote>



<blockquote><p>Lastly, please confirm that Curl <strong>is not developed by, contain components developed by</strong>, or receive substantial influence from entities prohibited by Section 889 of the 2019 NDAA. These entities include the following companies and any of their subsidiaries or affiliates:</p></blockquote>



<blockquote><p>Hytera Communications Corporation<br>Huawei Technologies Company<br>ZTE Corporation<br>Dahua Technology Company<br>Hangzhou Hikvision Digital Technology Company</p><p>Finally, we have a time frame of 5 days for a response.<br>Thank you,</p></blockquote>



<h2>My answer</h2>



<p>Okay, I first considered going with strong sarcasm in my reply due to the complete lack of understanding, and the implied threat in that last line. What would happen if I wouldn’t respond in time?</p>



<p>Then it struck me that this could be my chance to once and for all get a confirmation if curl is already actually used in space or not. So I went with informative and a friendly tone.</p>



<blockquote><p>Hi [name],</p><p>I will answer to these questions below to the best of my ability, and maybe you can answer something for me?</p></blockquote>



<blockquote><p>curl (https://curl.se) is an open source project that creates two products, curl the command line tool and libcurl the library. I am the founder, lead developer and core maintainer of the project. To this date, I have done about 57% of the 26,000 changes in the source code repository. The remaining 43% have been done by 841 different volunteers and contributors from all over the world. Their names can be extracted from our git repository: https://github.com/curl/curl</p></blockquote>



<blockquote><p>You can also see that I own most, but not all, copyrights in the project.</p></blockquote>



<blockquote><p>I am a citizen of Sweden and I’ve been a citizen of Sweden during the entire time I’ve done all and any work on curl. The remaining 841 co-authors are from all over the world, but primarily from western European countries and the US. You could probably say that we live primarily “on the Internet” and not in any particular country.</p></blockquote>



<blockquote><p>We don’t have resellers. I work for an American company (wolfSSL) where we do curl support for customers world-wide.</p></blockquote>



<blockquote><p>Our testing is done universally and is not bound to any specific country or region. We test our code substantially before release.</p></blockquote>



<blockquote><p>Me knowingly, we do not have any components or code authored by people at any of the mentioned companies.</p></blockquote>



<blockquote><p>So finally my question: can you tell me anything about where or for what you use curl? Is it used in anything in space?</p></blockquote>



<blockquote><p>Regards,<br>Daniel</p></blockquote>



<h2>Used in space?</h2>



<p>Of course my attempt was completely in vain and the answer back was very brief and it just said…</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/NASA_logo.png" alt="" width="399" height="334"></figure></div>



<h5>“We are using curl to support NASA’s mission and vision.”</h5>



<h2>Credits</h2>



<p>Space ship image by <a href="https://pixabay.com/users/eliassch-3372715/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2057420">Elias Sch.</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2057420">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/17/curl-supports-nasa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456369</guid>
            <pubDate>Thu, 17 Dec 2020 15:25:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cats Make Your Life Better, According to Science]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25456357">thread link</a>) | @KaiserSanchez
<br/>
December 17, 2020 | https://www.gethuan.com/how-cats-make-your-life-better/ | <a href="https://web.archive.org/web/*/https://www.gethuan.com/how-cats-make-your-life-better/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="154261b3" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Cats rule, and dogs drool. And before you come at me, dog owners, I’m sorry — it’s just a fact.</p>



<p>OK, OK. There’s no reason to argue about which pets are the best, because we already know there are <em>so many</em>&nbsp;benefits to having <em>any</em>&nbsp;kind of animal in your life (and we already know that cats win).</p>



<p>The truth is that all pet owners know that their furry (or feathery or scaly or what have you) friends only make their lives better. But cat owners have science on their side.</p>



<p>That’s right —&nbsp;owning a cat is so good for you, there are actual, proven, scientific benefits. Ready to see exactly how your purry, biscuit-making buddy has been improving your life? Here’s what science has to say about the subject.</p>



<h2>The Scientific Benefits of Being a Cat Owner</h2>



<figure><img width="1024" height="548" src="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg" alt="The Scientific Benefits of Being a Cat Owner" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-324x173.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-416x223.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-300x161.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-768x411.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-60x32.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20548'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-324x173.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-416x223.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-300x161.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-768x411.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science-60x32.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/02-HUAN-cats-science.jpg"></figure>



<p>Anywhere between 10 and 30 percent of people call themselves “<a href="https://www.gethuan.com/3-surprising-ways-cats-love-their-owners/"><u>cat people</u></a>.” Not dog people. Not equal-opportunity lovers of all animals. Just cat people.</p>



<p>And naturally, some scientists were a little confused by that. After all, cats seem <a href="https://www.gethuan.com/3-reasons-why-cats-run-away-and-what-you-can-do/"><u>generally ungrateful for our love and affection</u></a>. They can go from enjoying a belly rub to digging sharp claws and teeth into your skin without any warning whatsoever. And then there’s all the barfing —&nbsp;seriously, what makes cats throw up so much?</p>



<p>In other words, scientists wondered what makes people love these little animals that can be <a href="https://www.gethuan.com/lost-indoor-cat-behavior/"><u>emotionally volatile</u></a>, messy, and don’t seem to appreciate a single thing their human subjects do for them.</p>



<p>And those scientists actually found out more than they bargained for. It turns out there are <em>a ton</em>&nbsp;of ways cats make our lives better. They make us happier. They make us healthier. And it’s all been proven (or at least supported) by science.</p>



<h3>Cats Can Help You Sleep Better</h3>



<figure><img width="1024" height="680" src="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg" alt="Cats Can Help You Sleep Better" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-60x40.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20680'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep-60x40.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/03-HUAN-cats-science-sleep.jpg"></figure>



<p>Most people don’t associate cats with good sleep.</p>



<p>They have a bad rap for waking their owners up at the crack of dawn for breakfast, or making noise all night with their nocturnal antics. But science actually shows that sharing your sleeping space with a cat (especially one that cuddles and purrs) can help you get better sleep. <a href="https://www.mayoclinicproceedings.org/article/S0025-6196(15)00674-6/fulltext" target="_blank" rel="noreferrer noopener"><u>In one study</u></a>, 41 percent of people reported sleeping better with their pets by their side.</p>



<h3>Cats Can Calm You Down</h3>



<p>One thing you probably never expected your cat to be is an instant anti-anxiety tool. But that’s exactly what cats can be, according to science.</p>



<p><a href="https://doi.org/10.2752/089279399787000237" target="_blank" rel="noreferrer noopener"><u>Studies have shown</u></a>&nbsp;that because cats appear less dependent on their humans than other types of pets, we tend to see them as a strongly calming presence in our lives. Cat owners <a href="https://static1.squarespace.com/static/5aa6be7de17ba3f559d28f25/t/5aa85bc7e2c4839970ff3190/1520982983501/pet_paper.pdf" target="_blank" rel="noreferrer noopener"><u>have been shown</u></a>&nbsp;to have lower blood pressure and resting heart rates, and in one study, were more likely to be able to respond to challenges without feeling threatened or overwhelmed.</p>



<h3>Cats Can Improve Your Mental Health</h3>



<p>Want to be happier overall? You need a cat, according to science.</p>



<p><a href="https://doi.org/10.2752/089279393787002385" target="_blank" rel="noreferrer noopener"><u>An Australian study</u></a>&nbsp;showed that cat owners largely were more psychologically healthy than people without pets. The people who owned cats reported being more happy, more confident, and less nervous.</p>



<p><a href="https://www.researchgate.net/profile/Gerulf_Rieger/publication/50911102_Spouses_and_cats_and_their_effects_on_human_mood/links/00b7d5326dc2cf12c8000000/Spouses-and-cats-and-their-effects-on-human-mood.pdf" target="_blank" rel="noreferrer noopener"><u>Another study</u></a>&nbsp;showed that people with cats reported fewer negative emotions than people without cats. They reported being in a bad mood less often than even people with other kinds of pets.</p>



<h3>Cats Can Reduce Loneliness</h3>



<figure><img width="1024" height="1002" src="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg" alt="Cats Can Reduce Loneliness" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-324x317.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-416x407.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-300x293.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-768x751.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-60x59.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%201002'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-324x317.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-416x407.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-300x293.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-768x751.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science-60x59.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/04-HUAN-cats-science.jpg"></figure>



<p>Who needs humans for company? Pets can make great companions, and science shows they reduce loneliness and feelings of seclusion in their owners.</p>



<p>Besides the obvious benefits —&nbsp;when you’re lonely, you can play with, talk to, or cuddle with your cat —&nbsp;<a href="https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/12764/Marsa_Sambola_2017_Quality_AHD_AAM.pdf?sequence=1" target="_blank" rel="noreferrer noopener"><u>one study</u></a>&nbsp;showed that owning a cat made kids feel less sad and lonely, and made them better enjoy time spent alone, compared to kids who didn’t have cats. We’re sure those benefits extend to grown-ups, too.</p>



<h3>Cats Can Help You Make Friends</h3>



<p>There’s a stereotype that “crazy cat ladies” are socially awkward, but according to science, that’s very far from the truth.</p>



<p>Multiple studies have shown that cat owners are <a href="http://psycnet.apa.org/record/1983-32714-001" target="_blank" rel="noreferrer noopener"><u>more socially sensitive</u></a>, <a href="http://psycnet.apa.org/record/1983-32714-001"><u>trust people more</u></a>, and <a href="https://www.tandfonline.com/doi/abs/10.1080/08927936.1998.11425085" target="_blank" rel="noreferrer noopener"><u>like people more</u></a>&nbsp;than non-pet owners. <a href="https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/12764/Marsa_Sambola_2017_Quality_AHD_AAM.pdf?sequence=1" target="_blank" rel="noreferrer noopener"><u>Yet another study</u></a>&nbsp;showed that kids who had cats as pets were better at communicating with their human friends.</p>



<p>“Pets appear to act as ‘social catalysts,’ inducing social contact between people,” that study’s author wrote. “A pet can be accepting, openly affectionate, consistent, loyal, and honest, characteristics that can fulfill a person’s basic need to feel a sense of self-worth and loved.”</p>



<h3>Cats Can Entertain You For Hours</h3>



<figure><img width="1024" height="680" src="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg" alt="Cats Can Entertain You For Hours" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-60x40.jpg 60w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20680'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-416x276.jpg 416w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-300x199.jpg 300w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-768x510.jpg 768w, https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science-60x40.jpg 60w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/05-HUAN-cats-science.jpg"></figure>



<p>Anyone who’s ever played with an energetic cat knows just how entertaining they can be.</p>



<p>Cats are natural-born hunters with fierce prey drives, and that means that a ball, a feather, or a piece of string can have them jumping, pouncing, and chasing for hours. Most cats are perfectly content to play by themselves with any object that can be batted across the floor, giving their humans plenty to watch and laugh at.</p>



<h3>Cats Can Encourage You to Get Up and Play</h3>



<p>What’s even better about how playful our feline friends can be is that they encourage their owners to get up and play, too. Sure, you’re probably not going to get as much aerobic exercise with a cat as you would with a dog. But running around the house with a toy on a string, even for just 10 or 15 minutes a day, can provide more exercise benefits than you might think.</p>



<h3>Cats Can Encourage You to Rest and Take Naps</h3>



<p>On the other hand, sometimes the best way to practice some good, old-fashioned self care is to take a nap. Studies have shown that most house cats sleep around 16 hours a day, so if you need some encouragement to slow down and get some shuteye, just look to your cat, an expert at cat naps who would love to take a snooze with you at any time of the day.</p>



<h3>Cats Have Lower Carbon Footprints Than Dogs</h3>



<p>Just another benefit to choosing a cat over a dog: It’s better for the earth. A <a href="https://www.seattletimes.com/seattle-news/dogs-eco-footprint-a-hummer-study-says/" target="_blank" rel="noreferrer noopener"><u>2009 study</u></a>&nbsp;found that the carbon footprint of owning a dog was about the equivalent of driving a Hummer. On the other hand, owning a cat was like owning a Volkswagen with reduced carbon emissions. Neither pet is perfect, but cats are contributing less to climate change than dogs.</p>



<h3>Cats Can Fight Depression</h3>



<figure><img width="1024" height="630" src="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg" alt="Cats Can Fight Depression" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-324x199.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-416x256.jpg 416w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20630'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-324x199.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science-416x256.jpg 416w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/06-HUAN-cats-science.jpg"></figure>



<p>Now for the actual medical benefits of cat ownership — and there are a lot of them. It turns out that owning a cat is exceptionally good for your overall health, both mental and physical.</p>



<p>First up: Mental health. Because they tend to increase happiness and decrease feelings of loneliness and isolation, studies have shown that cats can help alleviate some of the symptoms of clinical depression, since they’re exacerbated by those things.</p>



<h3>Cats Can Lower Your Blood Pressure</h3>



<p>Aside from their mental health benefits, cats can have a positive effect on our physical health, too.</p>



<p>Studies have shown that cat owners have lower blood pressure on average, and that stroking a cat can release hormones that tell our bodies to calm down, lower their heart rates, and lower blood pressure even more. As an added bonus, most cats find stroking to be calming and enjoyable, too.</p>



<h3>Cats Can Reduce Your Risk of a Stroke</h3>



<p>Studies have shown that people who own cats have greatly reduced risk of cardiovascular diseases, including heart attacks and strokes.</p>



<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3317329/" target="_blank" rel="noreferrer noopener"><u>A 2009 study</u></a>&nbsp;showed that people who currently own cats are at far less risk of cardiovascular problems, and that even people who owned cats in the past but don’t any longer have less risk of these kinds of diseases. The scientists who worked on that study attributed their subjects’ better health to the fact that cats reduce stress and blood pressure, putting less strain on the cardiovascular system over a lifetime and allowing it to stay healthy long term.</p>



<h3>Cats Can Lower Your Cholesterol and Triglycerides</h3>



<p>That same 2009 study showed yet another surprising cardiovascular benefit to having a cat as a pet: They lower your cholesterol and triglycerides. In fact, researchers found that in some cases, getting a cat was more effective at bringing patients’ high cholesterol into a normal range than using medication meant to lower cholesterol.</p>



<p>Scientists aren’t exactly sure why cats have this particular benefit for their owners, but there’s no question that owning a cat has positive effects on your overall health.</p>



<h3>Cats Can Help Heal Bone and Muscle Injuries</h3>



<p>If you ever injure a bone or muscle or suffer from a minor wound, add this surprising step to your treatment plan: Cuddling with a cat.</p>



<p>Cats purr at a frequency between 20 and 140 Hz, which <a href="https://www.scientificamerican.com/article/why-do-cats-purr/" target="_blank" rel="noreferrer noopener"><u>studies have shown</u></a>&nbsp;can help promote better bone density and help minor injuries heal faster. In other words, your cat’s purr has literal healing powers.</p>



<h3>Cats Can Help You Fight Off Allergies and Asthma</h3>



<p>Well, cats unfortunately can’t do much for your existing allergies. But if you want your children to avoid them, get a cat.</p>



<p>In 2002, the National Institutes of Health released a study that showed that kids who were exposed to cats regularly when they were under a year old were less likely to suffer from all kinds of allergies —&nbsp;in addition to pet dander, those kids were less likely to have dust mite, ragweed, grass, and other allergies.</p>



<h3>Cats Can Help You Live Longer</h3>



<figure><img width="1024" height="680" src="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg" alt="Cats Can Help You Live Longer" srcset="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-416x276.jpg 416w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20680'%3E%3C/svg%3E" data-lazy-srcset="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg 1024w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-324x215.jpg 324w, https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science-416x276.jpg 416w" data-lazy-src="https://www.gethuan.com/wp-content/uploads/2020/11/07-HUAN-cats-science.jpg"></figure>



<p>With all those health benefits, it’s no wonder that cat owners live longer than those who don’t have feline friends in their lives. That just means you have plenty of time to continue to enjoy all the benefits of being a cat lover.</p>



<h3>Can’t Have a Cat? Even Just Watching Cat Videos Can Be Good for You</h3>



<p>Not everyone can have a cat —&nbsp;we understand what a serious commitment any pet is, and why it’s not for everyone.</p>



<p>But if you’d like to reap some of the benefits of having a cat in your life, even if you’re not up for the task of caring for one, just queue up some cat videos online. A <a href="https://www.goodnet.org/articles/7-scientifically-proven-health-benefits-being-cat-owner" target="_blank" rel="noreferrer noopener"><u>2015 study</u></a>&nbsp;from the University of Indiana showed that watching cat videos gave people an instant mood and energy boost, and decreased their negative feelings throughout the day.</p>



<p>Now that you know all the scientific …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gethuan.com/how-cats-make-your-life-better/">https://www.gethuan.com/how-cats-make-your-life-better/</a></em></p>]]>
            </description>
            <link>https://www.gethuan.com/how-cats-make-your-life-better/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25456357</guid>
            <pubDate>Thu, 17 Dec 2020 15:24:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make comic book layouts in the browser]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455659">thread link</a>) | @TiredGuy
<br/>
December 17, 2020 | https://andrewfulrich.gitlab.io/panelle/ | <a href="https://web.archive.org/web/*/https://andrewfulrich.gitlab.io/panelle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://andrewfulrich.gitlab.io/panelle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455659</guid>
            <pubDate>Thu, 17 Dec 2020 14:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[More information on the plant disturbance at Olkiluoto 2]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455279">thread link</a>) | @ericdanielski
<br/>
December 17, 2020 | https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html | <a href="https://web.archive.org/web/*/https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455279</guid>
            <pubDate>Thu, 17 Dec 2020 13:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyberpunk 2077 Din Schachtdeckel]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25455049">thread link</a>) | @Fake4d
<br/>
December 17, 2020 | https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel | <a href="https://web.archive.org/web/*/https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Gamer diskutieren derzeit über deutsche DIN-Schachtdeckel in einem weltbekannten Computerspiel. Den RSV freut's.</strong></p>
<p>Im amerikanischen Schauplatz des Spiels "Cyberpunk 2077" kommen Schachtabdeckungen nach deutscher Bauart zum Einsatz – allerdings dort, wo es eigentlich nicht DIN-konform wäre. Nach ersten Diskussionen in sozialen Netzwerken gibt es nun sogar schon eine - nicht ganz ernst gemeinte - <a href="https://www.change.org/p/the-cyberpunk-developers-fix-the-manhole-covers-in-cyberpunk-2077" target="_blank" rel="noopener">Petition</a>, die die Entwickler zu mehr Sorgfalt auffordert.</p>
<p><strong>RSV: Endlich mehr Aufmerksamkeit für unsere Branche</strong></p>
<p>Volle Unterstützung gibt es auch vom RSV: "Wir freuen uns über die wachsende Anerkennung für diesen bisher unterbelichteten Bereich in der Öffentlichkeit und hoffen, dass die Entwickler dieses Detail der DIN-Norm zuliebe ausbessern", sagt RSV-Geschäftsführerin Reinhild Haacker dazu, nicht ohne Augenzwinkern. "Deutsche Qualität und Normen liegen uns beim RSV am Herzen. Es ist beruhigend zu wissen, dass deutsche Schachtdeckel – zumindest nach Einschätzung der Gaming-Entwickler – in 57 Jahren zum Einsatz kommen werden, und das sogar in den USA. Dennoch sehen wir uns verpflichtet, im Sinne der Qualitätssicherung darauf hinzuweisen, dass eine DIN 4271 Schachtabdeckung nicht, wie im Spiel gezeigt, auf einer Fahrbahn verbaut werden darf."</p>
<p><strong>Gamer stoßen Petition an</strong></p>
<p>In dem Computerspiel, das derzeit millionenfach gespielt wird, schlüpfen Gamer in die Rolle eines Hackers in einer fiktiven US-Metropole im Jahr 2077. Deutsche Fans des Spiels teilten auf Twitter und in Gaming-Foren Bilder des falsch verbauten DIN-Schachtdeckels, bevor sie scherzhaft eine <a href="https://www.change.org/p/the-cyberpunk-developers-fix-the-manhole-covers-in-cyberpunk-2077">Petition</a> zum Thema einleiteten.</p>
<p>Für das Spiel hatten die polnischen Entwickler übrigens sogar Stadtplaner engagiert, um möglichst realitätsnah rüberzukommen. Möglicherweise haben die vollmundigen Ankündigungen auch dazu geführt, dass Gamer - mit der gewohnten deutschen Gründlichkeit - besonders genau hinschauen.</p>
</div></div>]]>
            </description>
            <link>https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455049</guid>
            <pubDate>Thu, 17 Dec 2020 12:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to let go of a lifelong dream]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455014">thread link</a>) | @known
<br/>
December 17, 2020 | https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Emma Garber began dancing aged three. By the time she was a teenager â€“ following years of dedicated, exhausting, sometimes painful training â€“ it was her burning ambition to become a professional ballet dancer. â€˜I think around age 14, I sat my parents down and I said: <em>This is what I want to do with my life. This is what makes me happy</em>,â€™ she says.</p>
<p>All of us have dreams and hopes for our future. They are often career-focused, but not always. Some people dream of starting a family or living in another country, for instance. Our dreams form part of our identity, giving us purpose and direction. That is, until reality gets in the way, as so often happens: the change might come from within us, as our passion wanes, or the obstacles to realising the dream might become insurmountable (or a mixture of the two).</p>
<p>Garberâ€™s dream began to fade amid burnout and doubt during her freshman year at the University of Massachusetts. After a particularly terrible dance class, she recalls: â€˜I was like, <em>I donâ€™t think I want to do this for the rest of my life</em>. I stood up, I walked out, I called my mom and I was like, <em>I donâ€™t even know what I want to do with my life anymore</em>.â€™</p>
<p>You might be experiencing one of these unsettling fork-in-the-road moments yourself. Perhaps the dying breath of a fading dream is leaving you with intense feelings of regret and failure. You might fear how others will judge you. After all, in todayâ€™s culture, in many parts of the world, weâ€™re taught from a young age that success is born from stubborn perseverance.</p>
<p>â€˜To be gritty,â€™ writes the psychologist Angela Duckworth in her bestselling <a href="https://www.penguin.co.uk/books/110/1109188/grit/9781785042669.html" rel="nofollow noreferrer noopener">book</a> <em>Grit</em> (2016), â€˜is to fall down seven times, and rise eight.â€™ The gist of her advice has echoed through different eras. â€˜Many of lifeâ€™s failures are people who did not realise how close they were to success when they gave up,â€™ wrote the inventor Thomas Edison.</p>
<p>Given this dominant narrative of the virtues of perseverance, and considering how our ambitions can become a core part of our sense of self, itâ€™s understandable that you might be finding it difficult and unsettling to face the prospect of losing your dream. You can take comfort, though, in knowing that being adaptable and flexible in oneâ€™s ambitions is just as important as being gritty or determined. â€˜By definition, if you cannot achieve what you want to achieve, you will fail repeatedly if you donâ€™t stop,â€™ says Carsten Wrosch, a psychology professor at Concordia University in Montreal, who has been studying the construct of â€˜goal adjustment capacityâ€™ for more than 20 years.</p>
<p>Goal adjustment capacity â€“ which psychologists <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/jopy.12492" rel="nofollow noreferrer noopener">see</a> as a beneficial form of â€˜self-regulationâ€™ or â€˜self-managementâ€™ â€“ encapsulates two key components: the ability to disengage from fruitless goals and the ability to reengage in new, more productive goals. You could see it as knowing when and how to switch from one dream to another. Itâ€™s measured by agreement with questionnaire items such as â€˜Itâ€™s easy for me to stop thinking about the goal and let it goâ€™ and â€˜I tell myself that I have a number of other new goals to draw upon.â€™</p>
<p>Wrosch says that people who lack this capacity are inclined to â€˜bang their head against the wallâ€™ when theyâ€™re confronted by an unobtainable goal, and, long-term, theyâ€™re more prone to stress and chronic illness. In contrast, those with greater adjustment capacity â€˜have a much easier timeâ€™ â€“ they decommit to the fruitless goal and find a different ambition to pursue. The virtues of being flexible and adaptable are also recognised by careers researchers, who <a href="https://www.sciencedirect.com/science/article/abs/pii/S0001879116300604" rel="nofollow noreferrer noopener">refer</a> to â€˜career adaptabilityâ€™, aspects of which involve being curious about new opportunities and being confident in oneâ€™s ability to learn new skills. People who score highly in this trait are generally â€˜happier. They perform better. They get promoted â€¦ Just a whole range of good things,â€™ says Rajiv Amarnani, a lecturer in the University of Western Australia Business School. That youâ€™re contemplating giving up your dream suggests that you have a healthy willingness to adjust and adapt, which is to your advantage.</p>
<p>If youâ€™re nonetheless finding it difficult to look beyond the immediate sense of loss or failure, know that there are routes ahead and that other opportunities will emerge. By having the wisdom and flexibility to know when to let go, or when to redirect your passion, youâ€™ll be following in the footsteps of many who have achieved greatness. David Foster Wallace let go of his tennis-greatness dreams and became an acclaimed novelist and writer instead. Meanwhile, Roger Federerâ€™s dreams of tennis greatness came true, but only at the expense of his dream of becoming a professional footballer. And Maryam Mirzakhani let go her childhood dream of becoming a novelist but went on to be awarded the Fields Medal for mathematics in 2014 â€“ the first and only woman ever to receive the honour.</p>
<p>These are dramatic examples, but they show that the path to fulfilment isnâ€™t always smooth or direct. Once youâ€™ve come to terms with your loss, youâ€™ll find other passions. New dreams await.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>Come to terms with your decision</strong></p>
<p>As you let your dream go, you might be agonising over whether youâ€™re making a mistake. â€˜Thereâ€™s no good answer, thereâ€™s no formulaâ€™ for deciding whether to plough on or give up, says Wrosch. However, he recommends bearing in mind a phenomenon known as â€˜goal shieldingâ€™ â€“ when weâ€™re highly focused on a particular dream or ambition, we tend to filter out inconvenient information that might imperil the project. â€˜Motivational psychologists call it an â€œimplemental mindsetâ€�,â€™ says Wrosch. â€˜If you cross the Rubicon, you focus on what you want to achieve, and you donâ€™t have that balance [in how you process the situation] any more.â€™ For that reason, he says most us are, if anything, probably more at risk of stubbornly pursuing a dream for too long than giving up too early.</p>
<p>The author and entrepreneur Seth Godin agrees with Wrosch â€“ â€˜thereâ€™s no calculusâ€™ for deciding when to give up, he says. He too warns that most of us â€˜lie to ourselves all the time about whether we have the resources to get through the dipâ€™. â€˜The dipâ€™ is Godinâ€™s term â€“ taken from his 2007 <a href="https://www.penguinrandomhouse.com/books/300938/the-dip-by-seth-godin/" rel="nofollow noreferrer noopener">book</a> of the same name, and subtitled <em>A Little Book That Teaches You When to Quit (and When to Stick)</em> â€“ that he says refers to the â€˜difficult space in between the joy of starting and the benefit of getting to the other sideâ€™.</p>
<p>One way to think about this emotionally difficult moment is as a chance to be objective about your dream. Was pursuing it coming at great personal cost, in terms of your relationships and other goals in life? If so, that would suggest it was what psychologists call an â€˜obsessive passionâ€™ and youâ€™re wise to give it up (as distinct from a â€˜harmonious passionâ€™ that fits well into the rest of your life).</p>
<p>Also, try to think, if you can, more like a â€˜healthy perfectionistâ€™: recognise that letting go of your goals doesnâ€™t cast some final verdict on you as a person, and acknowledge the influence of circumstances beyond your control. Remember too that success isnâ€™t all or nothing â€“ although you might not have fulfilled your dream in its entirety, you will likely have learned much along the way, and you now have the chance to redirect your energy and passion in new ways. This is also a good time to seek the counsel of close family and friends. Theyâ€™ll be able to help you view your situation objectively and come to terms with your decision.</p>
<p><strong>Be realistic about what you just gave up</strong></p>
<p>When you decide to let go of a dream, itâ€™s almost inevitable that itâ€™s going to hurt, at least for a time, but there are ways to ease the discomfort and move on. â€˜My approach to this is starting with the tragic realism of it, that itâ€™s going to be hard, itâ€™s going to hurt,â€™ says Amarnani, who likens the experience of giving up a dream to a romantic breakup. â€˜To have an ambition is to have this vision of your future self, and to drop that is to drop a piece of you,â€™ he says.</p>
<p>That parallel with relationships offers an effective clue for how to cope. In the context of romantic relationships, Amarnani says that it can be therapeutic to be realistic, rather than idealistic, about the person youâ€™re breaking from, even to focus deliberately on their flaws. If weâ€™re honest, many of our dreams are romanticised, and itâ€™s worth remembering that what youâ€™re giving up is not that fantasy version of the future. We think of doctors as healing people, says Amarnani, or that staff at the United Nations are building peace, but then their daily reality is often far more mundane â€“ doctors are navigating the bureaucracy of their healthcare system; workers at the UN are pushing paperwork around.</p>
<p>Amarnani speaks partly from personal experience. He once harboured a dream to become a computational cognitive neuroscientist, but he suffered repeated rejections and then the financial crisis hit. He changed gears to become a management scholar â€“ â€˜I thought I was selling my soul,â€™ he says, â€˜but really what I was doing was just adjusting to the situation, being adaptable and trusting that, when you try something new, the passion will come.â€™ To help make peace with his decision, Amarnani focused on the negatives of the field he gave up â€“â€˜Decades of research on the brain has taught us next to nothing about the mindâ€™ â€“ and today he couldnâ€™t be happier that he gave up his dream. â€˜I grieved, genuinely,â€™ he says, â€˜but life does go on.â€™</p>
<p><strong>Find a new passion</strong></p>
<p>Itâ€™s a clichÃ© to say that one door closing means another opening, but itâ€™s true. By letting go of an impossible dream, youâ€™re freeing yourself to put time and effort into a potentially more rewarding project. Itâ€™s tempting to look at a high achiever such as Godin and assume that he arrived at his …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion">https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455014</guid>
            <pubDate>Thu, 17 Dec 2020 12:37:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Julia after 2 weeks]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454943">thread link</a>) | @the_origami_fox
<br/>
December 17, 2020 | https://liorsinai.github.io/coding/2020/12/15/julia-review.html | <a href="https://web.archive.org/web/*/https://liorsinai.github.io/coding/2020/12/15/julia-review.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>

        <p><em>Julia is a fast, flexible and robust language. Having used Julia for 2 weeks, and Python for 7 years, I can already say I prefer Julia. It is not as mature as Python, but I believe it has the potential to far exceed it.</em></p>



<p>It was Ars Technica’s “<a href="https://arstechnica.com/science/2020/10/the-unreasonable-effectiveness-of-the-julia-programming-language/">The unreasonable effectiveness of the Julia programming language</a>” that finally convinced me to learn the Julia programming language.
For years, I’ve heard whispers and glowing praises about Julia. 
It’s a dynamic programming language, but is said to be much faster than Python, and even as fast as C.
The terse, clean syntax is supposed to allow very generic but also robust code creation, reducing friction to collaboration. 
On top of that, it has math friendly syntax like in Matlab or R but also with real maths symbols. 
All of this has been driving adoption of Julia in academia, a highly scientific, collaborative environment with very high computational needs.
The adoption in industry has been predictably slower.</p>

<figure id="SIR model">
<img src="https://liorsinai.github.io/assets/posts/julia-review/SIR%20epidemic%20model.png" alt="SIR model">
	<figcaption>A snapshot of agents moving around a grid with an infection spreading when they touch, and the resulting infection outbreak graphs. Generated by the author using Julia.</figcaption>
</figure>

<p>So does Julia live up to the hype? I decided to find out.
To this end, I completed the recently released Julia Academy course “<a href="https://juliaacademy.com/p/computational-modeling-in-julia-with-applications-to-the-covid-19-pandemic">Computational Modeling in Julia with Applications to the COVID-19 Pandemic</a>”.
This is a 16 hour course which works with real Covid-19 pandemic data, and teaches you how to implement SIR epidemiology models as well.<sup id="fnref:SIR" role="doc-noteref"><a href="#fn:SIR">1</a></sup>
See the above picture.
After completing this course I challenged myself to rewrite my Random Forest Python <a href="https://github.com/LiorSinai/randomForests">code</a> in Julia and also my corresponding blog <a href="https://liorsinai.github.io/coding/2020/09/29/random-forests.html">post</a>.
You can see the Julia code <a href="https://github.com/LiorSinai/RandomForest-jl">here</a> and the twin blog post <a href="https://liorsinai.github.io/coding/2020/12/14/random-forests-jl.html">here</a>. 
This resulted in code of similar length, but that was 9 times faster and that felt much more robust.</p>

<p>The table below has a quick comparison of the Python and Julia Random Forests fitting times.
This was on the <a href="https://www.kaggle.com/sriharipramod/bank-loan-classification/">Universal Bank Loan</a> data, with 4000 training samples and 1000 test samples.
The random forest had 20 trees, with each tree having 40 to 120 leaves. 
Tests were run from the Anaconda CMD and Julia REPL.</p>
<table>
<caption>*after first compile run for Julia. Time to first compile was 4.6s</caption>
<thead>
  <tr>
    <th> </th>
    <th>Number of runs</th>
    <th>Scikit-learn</th>
    <th>Python</th>
    <th>Julia</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Fitting time (s)*</td>
    <td>10</td>
    <td>0.04810 ± 0.00951</td>
    <td>6.87132 ± 0.31106</td>
    <td>0.73991 ± 0.04208</td>
  </tr>
  <tr>
    <td>ratio mean times</td>
    <td>10</td>
    <td>1.00</td>
    <td>142.85</td>
    <td>15.38</td>
  </tr>
  <tr>
    <td>test accuracy (%)</td>
    <td>10</td>
    <td>98.43 ± 0.58</td>
    <td>98.56 ±  0.46</td>
    <td>98.66 ± 0.37</td>
  </tr>
</tbody>
</table>
<p>Scikit-learn (written in Cython) is still the fastest, but that code is more heavily optimised than mine, and also it use parallel processing.</p>

<p>In general, my experience with Julia was very positive. 
It is indeed fast and powerful, and the syntax is very nice.
It is not an upgrade to Python, but I am going to frame much of this article as such.
It operates under some very different paradigms - for example, Julia is very much a functional programming language, whereas Python is object-orientated.
The creators themselves tried to integrate the best of several different languages into Julia including Python, R, Matlab, Ruby, C and Lisp
(see their 2012 <a href="https://julialang.org/blog/2012/02/why-we-created-julia/">release statement</a>). But my experience is mostly with Matlab, C++ and Python. 
Of these, Julia is most likely to replace the code I write with Python.</p>

<p>C++ is a complex and powerful static typed language with memory management capabilities, and I don’t see Julia replacing mission critical software written with it.
Matlab is proprietary software which has great support for specialised scientific computing.
Its Simulink control software and image processing toolbox are the nicest of their kind that I’ve used.
Python, however, is a different story.</p>

<p>Python is easy to learn and lovely to tinker with, but as soon as your project expands that joy dissipates.
It’s noticeably slower than other languages. It has no type checking and very generous scoping rules.
This makes you think less when writing your own code, which is great, but it makes you think <em>more</em> when reviewing someone else’s.
Did they intend this variable to be an array? A string? A custom type? Have I accidently reused an identifier?
Popular packages go out of their way to <em>not</em> use Python for core processing, including Numpy, Scikit-learn and TensorFlow (they use, C, C++ and Cython).
Julia promises to fix these many issues, and it’s a relief.</p>

<p>I want to state upfront that my main frustration with Julia is that it is not as mature as Python.
The release of Julia 1.0 was just over two years ago; Python 1.0 was released 25 years ago.
The Julia community is playing catch-up with Python and has the second-mover advantage of knowing what works and what doesn’t.
But there simply are not as many packages, features, tutorials or videos as Python has. 
Fewer people ask questions on StackOverflow or Discourse.
Like many open-source projects, the documentation is often lacking.<sup id="fnref:pie" role="doc-noteref"><a href="#fn:pie">2</a></sup>
The language itself is changing fast, and some code on Julia Academy’s own online tutorials is already out of date.<sup id="fnref:out_of_date" role="doc-noteref"><a href="#fn:out_of_date">3</a></sup>
Then there is all the massive amounts of legacy code in companies and institutions.
So if you’re a beginner programmer, you can stop reading now. My advice is focus on Python. It has more resources and will get you further.
But if you can relate to my frustrations with Python or have more of your own, read on.</p>



<p>So what makes Julia special? A good summary is given by Serdar Yegulalp at <a href="https://www.infoworld.com/article/3241107/julia-vs-python-which-is-best-for-data-science.html">www.infoworld.com</a>, which I’ll briefly repeat here:</p>

<ul>
  <li>Julia is just-in-time (JIT) compiled, not interpreted. Furthermore, it is type-specific compiled for each datatype. 
For example, the same function will be compiled differently if integers are passed to it instead of floats. 
This means compiled Julia code can be heavily optimised and therefore is fast.
A downside is that the first call where JIT compiling takes place is slow.
A more detailed explanation can be found at <a href="http://www.stochasticlifestyle.com/7-julia-gotchas-handle/">ww.stochasticlifestyle.com/7-julia-gotchas-handle/</a>.</li>
  <li>Julia uses multiple dispatch to combine the benefits of dynamic typing and static typing. 
In short, multiple methods with different argument types can exist for a single function and Julia will choose the best one to use at compile time.
To facilitate  this, Julia has a comprehensive type system which can easily be extended.
This <a href="https://www.youtube.com/watch?v=kc9HwsxE1OY">video</a> by one of the founders explains this concept the best.</li>
  <li>Julia has a terse and straightforward syntax. It has 32 keywords (compared to Python’s 35 and C++’s original 63, now 97). 
Of these, 16 have a direct parallel with a Python keyword.</li>
  <li>Julia comes with expansive Base and Core modules. A further 12 of the Python keywords are provided by functions and operators in these modules.
These modules are mostly written in Julia which makes them easily accessible and extendable.</li>
  <li>Julia has full Unicode support and mathematical-like notation. The following is a fully working piece of code which can be copied directly into the Julia REPL: 
<span><code>gaussian(x, μ, σ) = 1/(σ*√(2π))*exp(-(x-μ)^2/(2σ^2))</code></span>. A disadvantage is that string indexing sometimes breaks because Unicode characters can take two or more bytes. 
So Base functions like <code>isascii()</code>, <code>nextind()</code> and <code>eachind()</code> should be used to handle strings properly.</li>
  <li>Julia supports metaprogramming, such as macros (like in C++) and creating expression objects with the keyword <code>quote</code>. So Julia programs can generate other Julia programs.</li>
  <li>Julia can call Python, C, and Fortran libraries. This is presumably to facilitate  crossover to Julia.</li>
</ul>

<p>The next three sections are <a href="#Things I like about Julia">Things I like about Julia</a>, <a href="#Neutral issues about Julia">Neutral issues about Julia</a>, 
and <a href="#Things I dislike about Julia">Things I dislike about Julia</a>.
Lastly there are small <a href="#Annoyances">Annoyances</a> I would like to vent after using it for 2 weeks.
I guess no programming language is perfect.</p>

<h2 id="things-i-like-about-julia">Things I like about Julia<a id="Things I like about Julia"></a></h2>

<p>Like all programming languages, there was a learning curve to Julia. This was made more difficult by the lack of resources. 
However generally it was easy to learn coming from a Python background and there are many things I definitely  prefer about Julia.</p>

<h4 id="the-type-system-and-multiple-dispatch">The type system and multiple dispatch</h4>
<p>This really does balance controlling types with giving the user flexibility.
For my random forest <a href="https://github.com/LiorSinai/RandomForest-jl">code</a>, it essentially provided a way to make object specific functions, even though Julia is a functional language.
For example, the <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/DecisionTree.jl#L203"><code>DecisionTreeClassifier</code></a> and <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/RandomForest.jl#L104"><code>RandomForestClassifier</code></a> have different <code>fit!()</code> methods associated with each of them.
I had no problem calling the <code>DecisionTreeClassifier</code> <code>fit!()</code> method from within the  <code>RandomForestClassifier</code> <code>fit!()</code> method.</p>

<p>A mistake I made at first is to use <code>AbstractFloat</code> inside the struct, whereas the recommendation is to always have concrete types in definitions.
This definitely slowed down my code, which is why I added the type to the struct definition: <code>DecisionTreeClassifier{T}</code>.
I also added an outer constructor to set this to <code>Float64</code> as a default.</p>

<p>Multiple dispatch can easily be abused because finding the best fit is a problem that grows exponentially with the number of different arguments.
However most functions have a very low number of methods associated with them.<sup id="fnref:exceptions" role="doc-noteref"><a href="#fn:exceptions">4</a></sup>
Another fault is that sometimes it is not fully unambiguous which method should be called, especially with <code>Union</code> data types. 
But this is being worked on and clearer rules should be published in the future.</p>

<p>A prime advantage of the type system is on display with my <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/Classifier.jl#L35"><code>score()</code></a> function. 
For my Python code, I wrote a separate score function inside the <code>DecisionTreeClassifier</code> and <a href="https://github.com/LiorSinai/randomForests/blob/1b3737097e8d80a947aa880ce20038db09016383/TreeEnsemble.py#L98"><code>RandomForestClassifier</code></a> classes.
They are however essentially identical functions.
For my Julia code, I wrote a single function which takes in a type of <code>AbstractClassifier</code>. 
Since I defined both my classifiers to be subtypes of <code>AbstractClassifier</code>, calling score on those objects dispatches to this <code>score</code> function.</p>

<p>Of course you can argue I could have made a super class in Python which implements <code>score</code>, and then have both <code>DecisionTreeClassifier</code> and <code>RandomForestClassifier</code> inherit from it.
However this adds complexity without much benefit.
In Julia, there is a robust type system and it makes sense to follow those design patterns.</p>

<p>Another use case is with my <a href="https://github.com/LiorSinai/RandomForest-jl/blob/89a948fe30c22bb92947f7016f7ca25135e1720b/Utilities.jl#L65"><code>calc_f1_s…</code></a></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://liorsinai.github.io/coding/2020/12/15/julia-review.html">https://liorsinai.github.io/coding/2020/12/15/julia-review.html</a></em></p>]]>
            </description>
            <link>https://liorsinai.github.io/coding/2020/12/15/julia-review.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454943</guid>
            <pubDate>Thu, 17 Dec 2020 12:25:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[51% of 4M Docker images have critical vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 323 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25454207">thread link</a>) | @AnnieNma
<br/>
December 17, 2020 | https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454207</guid>
            <pubDate>Thu, 17 Dec 2020 10:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25453663">thread link</a>) | @ingve
<br/>
December 17, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453663</guid>
            <pubDate>Thu, 17 Dec 2020 08:13:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deep learning tool that repairs damaged/faded photos]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25453481">thread link</a>) | @panabee
<br/>
December 16, 2020 | https://hotpot.ai/restore-picture?s=hn | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBox">

			<div>
				<p><img src="https://hotpot.ai/images/site/transparent.gif">
				</p>
			</div>

			

			<p><span>Restore</span>
			</p>

		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			Enable "Has Scratches" to explicitly remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453481</guid>
            <pubDate>Thu, 17 Dec 2020 07:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Code-Generated Art]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25453252">thread link</a>) | @dzink
<br/>
December 16, 2020 | https://www.editorx.com/shaping-design/article/creative-coding | <a href="https://web.archive.org/web/*/https://www.editorx.com/shaping-design/article/creative-coding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><p id="viewer-foo"><span><span>Have you ever experienced true novelty? Something so mind-altering that it questions your definition of what you’ve known to be true for so long. I imagine the first people to watch a film or see an airplane felt this. It’s an inexplicable energy that has the power to redefine. In many ways, artists have been at the center of challenging commonly held beliefs, and using entirely new mediums to express speculative ideas. </span></span></p><p id="viewer-fa7pc"><span><span>While never the first thing to come to mind when discussing art, creative coding is revolutionizing what art is and can be. As we enter a more digital world, creative coding may be the contemporary art movement we need in order to articulate major societal challenges we are facing as technology advances. </span></span></p><p id="viewer-gar4"><span><span>Put simply, creative coding is an emerging specialty that utilizes code and programming as a medium to create art. Programming’s versatility and ubiquitous nature makes it especially expressive, allowing it to manifest itself as digital paintings, data visualization, or even robotics. </span></span></p><p id="viewer-aesrq"><span><span>Unlike the functional focus of most uses of code - like the code lines of a navigation app - creative coding uses programming languages for a solely artistic purpose.</span></span></p><p id="viewer-bg2ev"><span><span>As artists, we generally hold a stigma regarding coding having high barriers to entry, and as engineers, we also hold a stigma surrounding the difficulties of creative expression. However, these fields no longer need to be separate entities, as they are more closely tied than people expect. </span></span></p><p id="viewer-80qt3"><span>With programming resources being incredibly open-source and <a href="https://www.editorx.com/shaping-design/article/drawing-inspiration-for-designers" target="_blank" rel="noopener"><u>creative inspiration</u></a> democratized across the internet, getting into this field is as easy as watching some coding tutorials on Youtube and making a Pinterest board. </span></p><p id="viewer-2vgh3"><span>If you haven’t already, you can <a href="https://www.editorx.com/shaping-design/article/should-designers-code" target="_blank" rel="noopener"><u>learn to code</u></a> by picking up a coding language such as HTML, CSS, and JavaScript. There are many online resources available, such as:</span></p><ul><li id="viewer-27t6d"><p><a href="https://www.w3schools.com/" target="_blank" rel="noopener"><u>W3Schools</u></a></p></li><li id="viewer-5oukm"><p><a href="https://www.youtube.com/watch?v=2qDywOS7VAc" target="_blank" rel="noopener"><u>Youtube Tutorials</u></a></p></li><li id="viewer-4rsku"><p><a href="https://www.linkedin.com/learning/" target="_blank" rel="noopener"><u>LinkedIn Learning</u></a></p></li><li id="viewer-a6fsj"><p><a href="https://www.learnpython.org/" target="_blank" rel="noopener"><u>Learnpython.org</u></a></p></li><li id="viewer-8el3i"><p><a href="https://www.codecademy.com/?g_network=g&amp;g_device=c&amp;g_adid=459321005730&amp;g_keyword=codecademy&amp;g_acctid=243-039-7011&amp;g_adtype=search&amp;g_adgroupid=70946090375&amp;g_keywordid=kwd-41065460761&amp;g_campaign=US_Brand_Core_Exact_Net+New+%28Auto+Tagging%29&amp;g_campaignid=1955172604&amp;utm_id=t_kwd-41065460761:ag_70946090375:cp_1955172604:n_g:d_c&amp;utm_term=codecademy&amp;utm_campaign=US_Brand_Core_Exact_Net%20New%20(Auto%20Tagging)&amp;utm_source=google&amp;utm_medium=paid-search&amp;utm_content=459321005730&amp;hsa_acc=2430397011&amp;hsa_cam=1955172604&amp;hsa_grp=70946090375&amp;hsa_ad=459321005730&amp;hsa_src=g&amp;hsa_tgt=kwd-41065460761&amp;hsa_kw=codecademy&amp;hsa_mt=e&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gclid=CjwKCAiAzNj9BRBDEiwAPsL0d6bnyHp-tuJuJPB6ESAc8vQsGp2os6n9SvJ_fN73bAazebYH-FcctRoCuOMQAvD_BwE" target="_blank" rel="noopener"><u>The Code Academy</u></a> </p></li><li id="viewer-6638e"><p><a href="https://processing.org/" target="_blank" rel="noopener"><u>Processing</u></a></p></li></ul><p id="viewer-cbn64"><span>From there, finding inspiration can be as simple as reading the rest of this article or exploring dedicated art-technology spaces such as <a href="https://www.artechouse.com/" target="_blank" rel="noopener"><u>Artechouse</u></a>.</span></p><p id="viewer-erafq"><span>Here are some interesting fields within creative coding that you can experiment with once you get started:</span></p><ul><li id="viewer-ehb6t"><p><span><strong>Machine learning:</strong> The development of computer algorithms that automatically learn and improve their performance through experience and data.</span>


</p></li><li id="viewer-32vc4"><p><span><strong>Projection mapping:</strong> A technique to project video on irregularly shaped surfaces, such as sculptures or buildings. </span>


</p></li><li id="viewer-f009e"><p><span><strong>Generative design:</strong> An iterative design process in which a program, usually using algorithms, generates a certain number of outputs based on a set of constraints.</span>


</p></li><li id="viewer-5n77p"><p><span><strong>Live coding:</strong> A form of performance art in which coders program in real-time. It usually involves sound, image and light design.</span></p></li></ul><p id="viewer-ep6sm"><span><span>To get some ideas flowing and inspire your own creative coding pieces, here are some examples of how expansive, stunning, and novel creative coding can be.</span></span></p><ol><li id="viewer-eeo5c"><p><span>Audience by Random International</span></p></li><li id="viewer-fha9v"><p><span>New Nature Digital Petting Zoo by Marpi Studio</span></p></li><li id="viewer-a5o8e"><p><span>Everything in Existence by fuse*</span></p></li><li id="viewer-8gq1n"><p><span>Infinite Command Team by Casey Reas </span></p></li><li id="viewer-4eu7u"><p><span>Land Lines by Zach Lieberman </span></p></li><li id="viewer-3unh"><p><span>ALGOBABEZ by Shelly Knotts</span></p></li><li id="viewer-538vu"><p><span>XYZT: Abstract Landscapes by Adrien M &amp; Claire B</span></p></li><li id="viewer-b7vhn"><p><span>Tecnicontrol by Bradley G Munkowitz (GMUNK)</span></p></li><li id="viewer-bprm6"><p><span>PEmbroider created at Frank-Ratchye STUDIO for Creative Inquiry</span></p></li><li id="viewer-akhtn"><p><span>Learning to See by Memo Akten</span></p></li></ol><p id="viewer-bahbh"><span><span>Random International is a London-based experimental art studio that has been pioneering the creative coding space for well over a decade now. Their work touches on deep social themes and has been exhibited internationally in spaces like the MoMa. </span></span></p><p id="viewer-fduu8"><span><span><em>Audience</em>, one of their earlier pieces of work from 2008, uses motion tracking software and creative coding to create an almost uncomfortable, anthropomorphic experience. As a gallery visitor steps in front of rows of individually dancing mirrors, they instantly synchronize and lock onto the viewer. With 100 mirrors now looking right back at you, you then become the focal point of your own onlooking. </span></span></p><p id="viewer-8dmeo"><span><span>Created by Marpi Studio, New Nature is a digitally interactive petting zoo that relies on gesture-based technology and programming to create virtual organisms. </span></span></p><p id="viewer-65ego"><span><span>Through machine learning, Marpi has forged a virtual terrarium of creatures and plants that rely on the physical interactions of the viewers to come alive. As viewers engage with the digital creatures, the artwork responds with real-time computer-generated motions, simulating the movement of an organic creature being pet. </span></span></p><p id="viewer-60ee9"><span><span><em>Everything in Existence</em> questions our perceptions of reality. Using real-time data processing tools and algorithmic software, fuse* creates a living piece of art that constantly evolves and adapts depending on its interactions with onlookers. </span></span></p><p id="viewer-bna5m"><span><span>The artworks are constantly generating new visuals in response to the viewers, their social networks, sound and more. This solo exhibition by fuse*, which premiered in Washington DC in 2019, creates digitally interactive experiences independently of an artist. Its self-sufficient and generative nature suggests an entirely new form of artistic expression.</span></span></p><p id="viewer-274p6"><span><span>Casey Reas’ <em>Infinite Command Team</em> investigates the relationship between particles that are encoded to construct images, and the code that forges those particles. </span></span></p><p id="viewer-c3cum"><span><span>Using pixelation of different weights and sizes, the piece creates a digital mosaic of television signals that become abstract and collage-like, reminiscent of TV channel-surfing. The piece is a celebration of art and technology that showcases the potential of combining digital fragments into a holistic piece of work. </span></span></p><p id="viewer-fhi88"><span><span>One of the most exciting aspects of creative coding is that it’s so readily available. Regardless of where you go in the world, there will always be code present guiding new innovations or digital platforms. </span></span></p><p id="viewer-8344v"><span><span>Creative coder Zach Lieberman takes advantage of how constantly present code is in our lives by using Google Maps to create art. In his proj</span>ect <a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><em><u>Land Lines</u></em></a>, Lieberm<span>an uses machine learning, optimized algorithms, and card power to harness images from Google Maps and match them with viewers’ drawings. </span></span></p><p id="viewer-ab3mh"><span><span>Lieberman asks his viewers to draw shapes and lines on the screen, which in turn are converted into real spaces on earth that resemble the line they drew. </span></span></p><div id="viewer-6292q"><a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="Land Lines by Zach Lieberman website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_1000%2Ch_715%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Land Lines by Zach Lieberman website screenshot"></p></div></div></a></div><p id="viewer-8vtqk"><span><span>Shelly Knotts takes creative coding to an entirely new plane in her live-coding pop band, ALGOBABEZ. Based in the UK, Shelly collaborates with other musicians and programmers in her pseudo-improvised live-coded music performances. Her coded music has been played to international audiences and explores themes of data, music, networks, and code.</span></span></p><p id="viewer-5b9e7"><span><span>Created by the company Adrien M &amp; Claire B, <em>XYZT</em> explores the intersection of mathematics and imaginary landscapes. </span></span></p><p id="viewer-bstnp"><span><span>Leveraging technology, programming, and lighting design, <em>XYZT</em> allows visitors to explore the four primary planes of existence: horizontal (the X axis), vertical (Y), depth (Z), and time (T). The exhibit allows for unparalleled interactivity across each of the planes, responding to visitors’ motion and creating new visuals in real time. </span></span></p><p id="viewer-3jqso"><span><span>In his creative coding work <em>Technicontrol</em>, Bradley Munkowitz, also known as GMUNK in the art community, investigates the ways in which robotics, code and screen content can result in a choreographed piece of work. </span></span></p><p id="viewer-b6arv"><span><span>Rather than using typical projection-mapped canvases, he pushed for LED-screen-wielding robots and a motion-controlled camera. The end result is a whimsical, technology-driven video piece with a truly marvelous storyline tracing the steps of a television abduction.</span></span></p><p id="viewer-178s8"><span><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><em><u>PEmbroider</u></em></a> is a<span>n open-source computational embroidery library. The goal of the creative coding library is to empower artists and craftspeople to make generative embroidery work for free. </span></span></p><p id="viewer-2ua6k"><span><span>Usually, tools such as this would be costly, and oftentimes are inaccessible to most artists or hobbyists. By creating an open-source repository, PEmbroider allows anyone to forge new, generative embroidery work through code. </span></span></p><div id="viewer-ecl5u"><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="PEmbroider creative coding website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_1000%2Ch_661%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="PEmbroider creative coding website screenshot"></p></div></div></a></div><p id="viewer-18rug"><span><span>Memo Akten is an artist and researcher who examines the nature of vision and perception through computational creativity and artificial intelligence. In his series of works, <em>Learning To See</em>, Akten has developed an artificial neural network to view and make sense of the world around us. </span></span></p><p id="viewer-bnqsf"><span><span>By comparing everyday objects with their interpretations through the eyes of neural networks, Memo Akten is able to digitally emulate the way we humans observe the world and make sense of objects.</span></span></p><p id="viewer-1q52f"><span><span>As he states, “it can only see through the filter of what it already knows. Just like us. Because we too, see things not as they are, but as we are.”</span></span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.editorx.com/shaping-design/article/creative-coding</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453252</guid>
            <pubDate>Thu, 17 Dec 2020 06:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React's UseRef Deep Dive]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25452146">thread link</a>) | @giovannibenussi
<br/>
December 16, 2020 | https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1 | <a href="https://web.archive.org/web/*/https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article"><header></header><p><code>useRef</code> allows you to keep a mutable value within a component, similar to <code>useState</code> or instance variables on a class, without triggering re-renders.</p><p>For example, this component stores the number of clicks for a button:</p><div data-language="jsx"><pre><code><span>function</span> <span>RefButton</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> clicks <span>=</span> <span>useRef</span><span>(</span><span>0</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks<span>.</span>current <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>.</span>current<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>This is how this component looks like (I added a re-render button so you can
actually test it out 😄):</p><div><h2>Interactive Example</h2><p>The example below is completely interactive, try clicking the "Clicks" button and then click on "Re-render".</p></div><p>As you can see, if you click the "Clicks" button it doesn't do anything. However, after click on "Re-render", it gets updated with the number of clicks we did previously.</p><h2>Difference with a variable</h2><p>You might wonder why not just use a simple variable as the example below:</p><div data-language="jsx"><pre><code><span>let</span> clicks <span>=</span> <span>0</span><span>;</span>

<span>function</span> <span>OutsideVariableButton</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>And here's an interactive example for it:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span></p></div><p>The button works the same way that our previous example. However, the problem arises when you have multiple instances of the same component like the example below. Try clicking just one of the buttons and then click on re-render to see the result.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span><span>outside variable</span><span>outside variable</span></p></div><p>As you were able to see, the clicks are not isolated. In fact, all the examples
from this article uses the same button component, so if you click the button
from the first example and then click on "re-render" on the second example, the count it is gonna be
incremented! What a bug 🐛.</p><p>On the other hand, <code>useRef</code> values are completely isolated between components:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>ref</span><span>ref</span><span>ref</span></p></div><h2>Difference with&nbsp;useState</h2><blockquote><p>The main difference between useState and useRef, is that useState triggers a
re-render and useRef doesn't.</p></blockquote><p>In the following example I added two buttons: one that updates its count with <code>useRef</code> and the other one with <code>useState</code>. I added some labels so you can identify them easily.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>state</span><span>ref</span></p></div><p>You'll notice that clicking on the button with <code>useRef</code> doesn't trigger a re-render and thus, the view isn't updated. On the other side, when you click on the button that uses <code>useState</code>, it will update its clicks count immediately.</p><p>To perform imperative actions on DOM nodes, React provides a way to get a
reference to them via refs. All you have to do is to assign a <code>ref</code> property to
a node with a ref object like this:</p><div data-language="jsx"><pre><code><span>function</span> <span>CustomInput</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>The way to get a DOM reference using refs works (informally 😅) as follows:</p><div><p><span>Today</span></p><div><p>React</p><p>Hey, what's up?<span>12:00</span></p></div><div><p>Could you give me a reference to this dom node?<span>12:00<svg style="color:#34B7F1" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><svg style="color:#34B7F1;margin-left:-12px" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg></span></p></div><div><p>React</p><p>Sure, I assigned it to the 'current' property of your ref.<span>12:00</span></p></div></div><p>On the first render, <code>inputRef</code>'s value will be <code>{ current: null }</code> and in the
following renders it will have its <code>current</code> property assigned to the specified DOM
node:</p><p>However, if you only reference <code>inputRef</code> inside <code>useEffect</code> then it'll always
reference the DOM node so you don't need to worry about it being undefined.</p><p>Let's update our example to get an idea of how this works:</p><div data-language="jsx"><pre><code><span>function</span> <span>AttachingToDomExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  console<span>.</span><span>log</span><span>(</span><span>"Render inputRef value:"</span><span>,</span> inputRef<span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"useEffect inputRef value:"</span><span>,</span> inputRef<span>)</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>Here's the console output when rendering this component:</p><table><thead><tr><th>Render</th><th>Location</th><th>Value</th></tr></thead><tbody><tr><td>1</td><td>Render</td><td>{ current: undefined }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>2</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>3</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr></tbody></table><p>As you can see, if you access the <code>inputRef</code> inside <code>useEffect</code> then you don't
need to worry about it being <code>undefined</code> because React will assign it
automatically for you.</p><p>Let's start with a simple real-world application for refs: <code>usePrevious</code>. This
hook stores the previous value for a given state variable.
<a href="https://reactjs.org/docs/hooks-faq.html#how-to-get-the-previous-props-or-state" target="_blank" rel="nofollow">It is even referenced on React's docs</a> as a way to "get the previous props or state". Let's see it in
action first:</p><div data-language="jsx"><pre><code><span>function</span> <span>UsePreviousExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>clicks<span>,</span> setClicks<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span>
  
  <span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span>clicks<span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setClicks</span><span>(</span>clicks <span>+</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
        Clicks: </span><span>{</span>clicks<span>}</span><span> - Before: </span><span>{</span>previousClicks<span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>Here's the output so you can play with it:</p><p>You can notice that the <code>previousClicks</code> variable stores the value for the previous render
for a given variable. Here's its implementation:</p><div data-language="jsx"><pre><code><span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    ref<span>.</span>current <span>=</span> value
  <span>}</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>Let's analyze how it works.</p><p>Let's simulate what happens on the first render. We can remove the call to
<code>useEffect</code> since it doesn't affect the return value on the first render:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>On the first render it is called with a value of <code>0</code>:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>0</span><span>)</span></code></pre></div><p>In this case, <code>usePrevious</code> will return <code>undefined</code>:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>After increase the value for count, here's how the <code>usePrevious</code> call will look:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>1</span><span>)</span></code></pre></div><p>Since <code>usePrevious</code> is called again, its effect needs to run:</p><div data-language="jsx"><pre><code><span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  ref<span>.</span>current <span>=</span> <span>0</span>
<span>}</span><span>)</span></code></pre></div><p>After this, the <code>usePrevious</code> function is called again:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>And so on. Here's the value for each render for both variables:</p><table><thead><tr><th>Render</th><th>clicks</th><th>previousClicks</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>undefined</td></tr><tr><td>2</td><td>1</td><td>0</td></tr><tr><td>3</td><td>2</td><td>1</td></tr><tr><td>4</td><td>3</td><td>2</td></tr></tbody></table><p>Callback Refs are a different way to set refs. It gives you a fine-grain control
over when refs are attached and detached because you provide a function instead
of a ref variable. This function gets called every time the component mounts and
unmounts.</p><p><a href="https://codesandbox.io/s/callback-ref-example-lqe8w?file=/src/App.js" target="_blank" rel="nofollow">Here's an example</a> that shows/hides an emoji every time you click its button.
The important thing here is the <code>ref</code> prop that we added. We use a function to log
the provided ref:</p><div data-language="jsx"><pre><code><span>const</span> <span>callback</span> <span>=</span> <span>(</span><span>ref</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"callback:"</span><span>,</span> ref<span>)</span>

<span>function</span> <span>App</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>show<span>,</span> setShow<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setShow</span><span>(</span><span>!</span>show<span>)</span><span>}</span></span><span>&gt;</span></span><span>
        </span><span>{</span>show <span>?</span> <span>"Hide"</span> <span>:</span> <span>"Show"</span><span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span>{</span>show <span>&amp;&amp;</span> <span><span><span>&lt;</span>span</span> <span>ref</span><span><span>=</span><span>{</span>callback<span>}</span></span><span>&gt;</span></span><span>👋</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div><p>Here's an interactive version of the previous code (you can check the output in
the console to see that I'm not lying 🙃):</p><p><em>Note: If you use callback refs as inline functions, it will be called
twice: one with <code>null</code> and another one with the DOM element.
This is because React needs to clear the previous ref every time the function is
created. A workaround for this is to use a class method.</em></p><div><h2>Warning</h2><p><a href="https://reactjs.org/docs/refs-and-the-dom.html#legacy-api-string-refs" target="_blank" rel="nofollow">String refs</a> are a legacy feature and they are likely to be removed in future React versions.</p></div><p>The way it works is that you provide a string as a ref value like <code>ref="exampleRef"</code> and it automatically gets assigned to <code>this.refs</code>.</p><p><em>Note: String refs can only be used with class components.</em></p><p>Here's an usage example:</p><div data-language="jsx"><pre><code><span>export</span> <span>default</span> <span>class</span> <span>App</span> <span>extends</span> <span>React<span>.</span>Component</span> <span>{</span>
  <span>render</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>this</span><span>.</span>refs<span>)</span><span>;</span>

    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span> <span>ref</span><span><span>=</span><span>"</span>exampleRef<span>"</span></span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span> dummy<span>:</span> <span>0</span> <span>}</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>Re-render</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Here's the value for <code>this.refs</code> across renders:</p><table><thead><tr><th>Render</th><th>this.refs</th></tr></thead><tbody><tr><td>1</td><td><code>{}</code></td></tr><tr><td>2</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>3</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>4</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr></tbody></table><p>As you can see, on the first render <code>this.refs.exampleRef</code> will be undefined and
on the following renders it will point out to the specified DOM node.</p><p>We saw what <code>useRef</code> is, how it differentiates with a plain old variable and
state variables, and we saw real world examples that uses it. I hope that most
of the content makes sense to you!</p><p>I'd love to hear your feedback. You can <a href="https://twitter.com/giovannibenussi" target="_blank" rel="nofollow">reach out to me on
Twitter</a> at any time :-)</p><hr></article></div></div>]]>
            </description>
            <link>https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25452146</guid>
            <pubDate>Thu, 17 Dec 2020 03:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passing of a Great Mind (1957)]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25451727">thread link</a>) | @unclefuzzy
<br/>
December 16, 2020 | https://qualiacomputing.com/2018/06/21/john-von-neumann/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/06/21/john-von-neumann/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2>Passing of a Great Mind</h2>
<h3>John von Neumann, a Brilliant, Jovial Mathematician, was a Prodigious Servant of Science and his Country</h3>
<p><em>by Clary Blair Jr</em>. –&nbsp;<em>Life Magazine</em>&nbsp;(February 25th, 1957)</p>
<p>The world lost one of its greatest scientists when Professor John von Neumann, 54, died this month of cancer in Washington, D.C. His death, like his life’s work, passed almost unnoticed by the public. But scientists throughout the free world regarded it as a tragic loss. They knew that Von Neumann’s brilliant mind had not only advanced his own special field, pure mathematics, but had also helped put the West in an immeasurably stronger position in the nuclear arms race. Before he was 30 he had established himself as one of the world’s foremost mathematicians. In World War II he was the principal discoverer of the implosion method, the secret of the atomic bomb.</p>
<p>The government officials and scientists who attended the requiem mass at the Walter Reed Hospital chapel last week were there not merely in recognition of his vast contributions to science, but also to pay personal tribute to a warm and delightful personality and a selfless servant of his country.</p>
<p>For more than a year Von Neumann had known he was going to die. But until the illness was far advanced he continued to devote himself to serving the government as a member of the Atomic Energy Commission, to which he was appointed in 1954. A telephone by his bed connected directly with his EAC office. On several occasions he was taken downtown in a limousine to attend commission meetings in a wheelchair. At Walter Reed, where he was moved early last spring, an Air Force officer, Lieut. Colonel Vincent Ford, worked full time assisting him. Eight airmen, all cleared for top secret material, were assigned to help on a 24-hour basis. His work for the Air Force and other government departments continued. Cabinet members and military officials continually came for his advice, and on one occasion Secretary of Defence Charles Wilson, Air Force Secretary Donald Quarles and most of the top Air Force brass gathered in Von Neumann’s suite to consult his judgement while there was still time. So relentlessly did Von Neumann pursue his official duties that he risked neglecting the treatise which was to form the capstone of his work on the scientific specialty, computing machines, to which he had devoted many recent years.</p>
<p><img data-attachment-id="26616" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_1_1/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1316%2C920&amp;ssl=1" data-orig-size="1316,920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_1_1" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1000%2C699&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;ssl=1" alt="von_neumann_1_1" width="1000" height="699" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>His fellow scientists, however, did not need any further evidence of Von Neumann’s rank as a scientist – or his assured place in history. They knew that during World War II at Los Alamos Von Neumann’s development of the idea of implosion speeded up the making of the atomic bomb by at least a full year. His later work with electronic computers quickened U.S. development of the H-bomb by months. The chief designer of the H-bomb, Edward Teller, once said with wry humor that Von Neumann was “one of those rare mathematicians who could descend to the level of the physicist.” Many theoretical physicists admit that they learned more from Von Neumann in methods of scientific thinking than from any of their colleagues. Hans Bethe, who was director of the theoretical physics division at Los Alamos, says, “I have sometimes wondered whether a brain like Von Neumann’s does not indicate a species superior to that of man.”</p>
<p><img data-attachment-id="26617" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_2/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" data-orig-size="226,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_2" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=223%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;ssl=1" alt="von_neumann_2" width="226" height="304" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The foremost authority on computing machines in the U.S., Von Neumann was more than anyone else responsible for the increased use of the electronic “brains” in government and industry. The machine he called MANIAC (mathematical analyzer, numerical integrator and computer), which he built at the Institute for Advanced Study in Princeton, N.J., was the prototype for most of the advanced calculating machines now in use. Another machine, NORC, which he built for the Navy, can deliver a full day’s weather prediction in a few minutes. The principal adviser to the U.S. Air Force on nuclear weapons, Von Neumann was the most influential scientific force behind the U.S. decision to embark on accelerated production of intercontinental ballistic missiles. His “theory of games,” outlined in a book which he published in 1944 in collaboration with Economist Oskar Morgenstern, opened up an entirely new branch of mathematics. Analyzing the mathematical probabilities behind games of chance, Von Neumann went on to formulate a mathematical approach to such widespread fields as economics, sociology and even military strategy. His contributions to the quantum theory, the theory which explains the emission and absorption of energy in atoms and the one on which all atomic and nuclear physics are based, were set forth in a work entitled <em>Mathematical Foundations of Quantum Mechanics</em>&nbsp;which he wrote at the age of 23. It is today one of the cornerstones of this highly specialized branch of mathematical thought.</p>
<p>For Von Neumann the road to success was a many-laned highway with little traffic and no speed limit. He was born in 1903 in Budapest and was of the same generation of <a href="http://slatestarcodex.com/2017/05/26/the-atomic-bomb-considered-as-hungarian-high-school-science-fair-project/">Hungarian physicists</a> as Edward Teller, Leo Szilard and Eugene Wigner, all of whom later worked on atomic energy development for the U.S.</p>
<p>The eldest of three sons of a well-to-do Jewish financier who had been decorated by the Emperor Franz Josef, John von Neumann grew up in a society which placed a premium on intellectual achievement. At the age of 6 he was able to divide two eight-digit numbers in his head. By the age of 8 he had mastered college calculus and as a trick could memorize on sight a column in a telephone book and repeat back the names, addresses and numbers. History was only a “hobby,” but by the outbreak of World War I, when he was 10, his photographic mind had absorbed most of the contents of the 46-volume works edited by the German historian Oncken with a sophistication that startled his elders.</p>
<p>Despite his obvious technical ability, as a young man Von Neumann wanted to follow his father’s financial career, but he was soon dissuaded. Under a kind of supertutor, a first-rank mathematician at the University of Budapest named Leopold Fejer, Von Neumann was steered into the academic world. At 21 he received two degrees – one in chemical engineering at Zurich and a PhD in mathematics from the University of Budapest. The following year, 1926, as Admiral Horthy’s rightist regime had been repressing Hungarian Jews, he moved to Göttingen, Germany, then the mathematical center of the world. It was there that he published his major work on quantum mechanics.</p>
<h4>The young professor</h4>
<p>His fame now spreading, Von Neumann at 23 qualified as a <em>Privatdozent</em>&nbsp;(lecturer) at the University of Berlin, one of the youngest in the school’s history. But the Nazis had already begun their march to power. In 1929 Von Neumann accepted a visiting lectureship at Princeton University and in 1930, at the age of 26, he took a job there as professor of mathematical physics – after a quick trip to Budapest to marry a vivacious 18-year-old named Mariette Kovesi. Three years later, when the Institute for Advanced Study was founded at Princeton, Von Neumann was appointed – as was Albert Einstein – to be one of its first full professors. “He was so young,” a member of the institute recalls, “that most people who saw him in the halls mistook him for a graduate student.”</p>
<p><img data-attachment-id="26618" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_3/" data-orig-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1210%2C1028&amp;ssl=1" data-orig-size="1210,1028" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_3" data-image-description="" data-medium-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=300%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1000%2C850&amp;ssl=1" loading="lazy" src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;ssl=1" alt="von_neumann_3" width="1000" height="850" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Although they worked near each other in the same building, Einstein and Von Neumann were not intimate, and because their approach to scientific matters was different they never formally collaborated. A member of the institute who worked side by side with both men in the early days recalls, “Einstein’s mind was slow and contemplative. He would think about something for years. Johnny’s mind was just the opposite. It was lightning quick – stunningly fast. If you gave him a problem he either solved it right away or not at all. If he had to think about it a long time and it bored him, hist interest would begin to wander. And Johnny’s mind would not shine unless whatever he was working on had his undivided attention.” But the problems he did care about, such as his “theory of games,” absorbed him for much longer periods.</p>
<h4>‘Proof by erasure’</h4>
<p>Partly because of this quicksilver quality Von Neumann was not an outstanding teacher to many of his students. But for the advanced students who could ascend to his level he was inspirational. His lectures were brilliant, although at times difficult to follow because of his way of erasing and rewriting dozens of formulae on the blackboard. In explaining mathematical problems Von Neumann would write his equations hurriedly, starting at the top of the blackboard and working down. When he reached the bottom, if the problem was unfinished, he would erase the top equations and start down again. By the time he had done this two or three times most other mathematicians would find themselves unable to keep track. On one such occasion a colleague at Princeton waited until Von Neumann had finished and said, “I see. Proof by erasure.”</p>
<p>Von Neumann himself was perpetually interested in many fields unrelated to science. Several years ago his wife gave him a 21-volume Cambridge History set, and she is sure he memorized every name and fact in the books. “He is a major expert on all the royal family trees in Europe,” a friend said once. “He can tell you who fell in love with whom, and why, what obscure cousin this or that czar married, how many illegitimate children he had and so on.” One night during the Princeton days a world-famous expert on Byzantine history came to the Von Neumann house for a party. “Johnny and the professor got into a corner and began discussing some obscure facet,” recalls a friend who was there. “Then an argument arose over a date. Johnny insisted it was this, the professor that. So Johnny said, ‘Let’s get the book.’ They looked it up and Johnny was right. A few weeks later the professor was invited to the Von Neumann house again. He called Mrs. von Neumann and said jokingly, ‘I’ll come if Johnny promises not to discuss Byzantine history. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qualiacomputing.com/2018/06/21/john-von-neumann/">https://qualiacomputing.com/2018/06/21/john-von-neumann/</a></em></p>]]>
            </description>
            <link>https://qualiacomputing.com/2018/06/21/john-von-neumann/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451727</guid>
            <pubDate>Thu, 17 Dec 2020 02:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sequoia PGP 1.0 Released: The Seedling Is a Sapling]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25448533">thread link</a>) | @dannyobrien
<br/>
December 16, 2020 | https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/ | <a href="https://web.archive.org/web/*/https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
                          <p>Version 1.0.  It’s here.  After three and a half years of development,
we are happy to announce the release of version 1.0 of Sequoia!</p>
<p>The release includes the low-level crate <a href="https://crates.io/crates/sequoia-openpgp"><code>sequoia-openpgp</code></a>, and a
program to verify detached signatures geared towards software
distribution systems called <a href="https://crates.io/crates/sequoia-sqv"><code>sqv</code></a>.</p>
<p>We will support this API with security updates for at least one year.
In 9 months, we will announce whether we will extend this commitment.
The two main criteria will be our financial situation (please
<a href="https://pep.foundation/support-pep/index.html">donate</a>, or sponsor a developer or two), and the number of users.</p>

<p>We actually <a href="https://mastodon.social/@sequoiapgp/103364362621954545">almost released</a> version 1.0 about a year ago.  All of the
features that we had planned for version 1.0 were implemented, we had
good test coverage, and we even had a few users.  But, we decided to
wait.  We decided to wait not because we thought of another feature,
or because we became aware of a significant bug, but because <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/465">we</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/466">decided</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/467">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/468">take</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/469">some</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/470">time</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/471">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/472">improve</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/473">our</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/474">documentation</a>.</p>
<p>Our goal was to make sure that every module had a helpful
introduction, and all public methods had a useful description, a link
to <a href="https://tools.ietf.org/html/rfc4880">the standard</a>, when appropriate, and a meaningful example.
Dividing the task between five people, we figured it would delay the
release by a month, perhaps two.  In the end, well, it took nearly a
year, and we had to scale our ambitions back a bit.  Nevertheless,
we’re quite happy with <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/index.html">the</a> <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html">result</a>.</p>
<p>First, the documentation is much better.  It’s of course hard to
quantify its quality.  But, we can distill a few numbers.  When we
started our documentation effort shortly after we released version
0.14, the Sequoia library had just over 11k lines of comments
including 53 documentation tests, and 37 kSLOC including 12 kSLOC of
unit tests.  The 1.0 release has over 33k lines of comments (190%
more) including 464 documentation tests (780% more), and 44 kSLOC (21%
or 7.5 kSLOC more) including 8k SLOC of additional unit tests.</p>
<p>Second, in the process of documenting our public API and writing
examples, we discovered many minor annoyances, some inconsistencies,
and more than a few bugs.  Since we hadn’t yet commited to a stable
API, we could and did fix them.</p>
<p>Finally, as the rate of change of the API had decreased, more projects
were willing to try out Sequoia.  They provided additional useful
feedback, which we integrated.</p>
<p>All in all, we feel that with version 1.0 we’ve not only checked the
<a href="https://www.tomsguide.com/news/cyberpunk-2077-is-a-disaster-on-ps4-and-xbox-one-and-it-gets-worse">right boxes</a>, but we also have a high-quality API and implementation
that we can be proud of.</p>

<p>Sequoia was started 3.5 years ago by Justus Winter, Kai Michaelis and
me, Neal Walfield.  Prior to working on Sequoia, the three of us had
worked together at <a href="http://www.g10code.de/">g10code</a> on <a href="https://gnupg.org/">GnuPG</a>.  The <a href="https://pep.foundation/">p≡p foundation</a> hired
us not only to create a new OpenPGP implementation using a new
architecture and programming language, but to improve the ecosystem
around privacy-preserving tools as a whole.</p>
<p>The Sequoia library is a first step in that direction.  But it is not
our end goal.  Indeed, over the past three years, we’ve helped other
OpenPGP implementations.  We’ve reported bugs that we’ve found (thanks
in particular to our <a href="https://tests.sequoia-pgp.org/">OpenPGP interoperability test suite</a>), and even
contributed some fixes to other OpenPGP implementations.</p>
<p>And, we’ve invested in tooling.  We developed <a href="https://gitlab.com/hagrid-keyserver/hagrid">Hagrid</a>, a new
verifying OpenPGP key server, which powers <a href="https://keys.openpgp.org/">keys.openpgp.org</a> and is
now maintained by Vincent Breitmoser.  We’ve helped <a href="https://openpgp-ca.gitlab.io/openpgp-ca/">OpenPGP CA</a>, a
tool written by Heiko Schaefer to create <em>federated</em> CAs for groups
like activists, lawyers, and journalists, but also companies, who
don’t want to trust centralized infrastructure whose primary
incentives are monetary.  OpenPGP CA significantly simplifies key
discovery and authentication for unsophisticated OpenPGP users.  We’ve
developed <a href="https://gitlab.com/koverto/koverto">Koverto</a>, an SMTP proxy, which makes it easy to sign and
encrypt mails sent by services that don’t support OpenPGP out of the
box, like most CMSes.  We developed a tool, <a href="https://gitlab.com/sequoia-pgp/keyring-linter"><code>sq-keyring-linter</code></a>
(<a href="https://packages.debian.org/sid/sq-keyring-linter">Debian</a>), to help users update their OpenPGP Certificates, so that
we can <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">finally get rid of SHA-1</a>.</p>
<p>We’re thinking big.  We’re thinking not only about mail encryption or
even encryption in general, but also about integrity and
authentication.  And, we’re thinking in particular, about <a href="https://en.wikipedia.org/wiki/Public_key_infrastructure">PKI</a>.  If
users can’t easily find the <strong>right</strong> certificate for a communication
partner, encryption and digital signatures are worthless, and possibly
even dangerous.</p>

<p>In designing Sequoia, we took a library-first approach.  Although we
have a command-line tool, <a href="https://docs.sequoia-pgp.org/sq/index.html"><code>sq</code></a>, which we are not yet releasing, we
intend for the library to always provide a richer, more expressive
interface.  We agree that there is value in process separation, but we
want to avoid the dangerous complexity of <em>safely</em> shelling out to
another program.</p>
<p>The sequoia-openpgp crate (Rust’s terminology for a library) is a
low-level, policy-free OpenPGP implementation.  Our goal was to
implement all of <a href="https://tools.ietf.org/html/rfc4880">RFC 4880</a>, and provide an API that can be used to
access and modify pretty much everything, but is simultaneously secure
by default.</p>
<p>We understand low-level to mean not only an API that provides getters
and setters, but an API that provides interfaces to parse and
serialize those fields, and can combine them in ways intended by the
standard, and needed by users.  For instance, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> data
structure encapsulates an OpenPGP certificate (casually referred to as
an OpenPGP key).  It canonicalizes the structure, and makes it easy to
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html#method.revocation_status">query its properties</a>.  But, it does so in such a way that it is
still possible for a user to inspect and modify the low-level bits
themselves without reimplementing the rest of the functionality.
Another example is the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>, which makes it easy to
parse and decrypt an OpenPGP message.</p>
<p>An example of how we make the API safe by default is that it is hard
to accidentally export secret key material.  In Sequoia, you have to
explicitly <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html#secret-keys">opt-in to export it</a>.  Similarly, when <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/packet/signature/struct.SignatureBuilder.html">updating a
signature</a>, the creation time, hash algorithm, and issuer are
automatically updated.  This is usually what the user wants, but is
easy to forget, and hard to debug when forgotten.  Critically, it is
easy to opt out when that behavior is not desired.</p>
<p>While developing Sequoia, we spent a lot of time thinking about
extremes and corner cases.  For instance, OpenPGP supports
notarizations (signatures over signatures), but as far as we know no
OpenPGP implementation supports them.  We implemented support for it
anyway, and it improved the ergonomics of the common case.</p>
<h2 id="notable-details">Notable Details</h2>
<p>The devel is in the details.  And while deviloping Sequoia, we paid
attention.  Here are a few noteworthy details:</p>
<p><a href="https://en.wikipedia.org/wiki/SHA-1">SHA-1</a> has been broken since 2005.  And, in 2011 NIST deprecated its
use.  Initially, we decided to simply reject any signature that used
SHA-1.  However, we were recently forced to <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">reevaluate</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/595">that
decision</a>: 22% of Debian developers use a certificate that relies on
SHA-1 as do 63% of Arch developers.  Even the Fedora release keys use
SHA-1.</p>
<p>We decided that we couldn’t simply reenable SHA-1.  After some
consideration, we’ve opted to <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/enum.HashAlgoSecurity.html">permit it</a> in contexts where collision
attacks similar to the one presented in <a href="https://sha-mbles.github.io/">SHA-1 is a Shambles</a> are
harder.  We also use a variant of SHA-1 called <a href="https://gitlab.com/sequoia-pgp/sha1collisiondetection">SHA1CD</a> (SHA-1
Collision Detection), which detects and neutralizes the known attacks
against SHA-1.  Among others, <a href="https://github.blog/2017-03-20-sha-1-collision-detection-on-github-com/">GitHub uses it</a>.  And, we have also
decided to <strong><a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/struct.StandardPolicy.html#method.reject_hash_at">start rejecting SHA-1 by default</a> at the beginning of
2023</strong>, i.e., in a bit more than two years.  This will hopefully give
Debian developers and others sufficient time to <a href="https://gitlab.com/sequoia-pgp/keyring-linter">fix</a> or replace their
certificates.</p>
<p>When we create a signature, we include a <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/597">salt</a>.  This makes it harder
for an attacker to predict what data a user will sign.  And, it foils
attacks where an attacker needs multiple signatures over the same
message.</p>
<p>Similar to <a href="https://www.undeadly.org/cgi?action=article;sid=20190621081455">OpenSSH</a>, we <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/mem/struct.Encrypted.html">encrypt secret key material</a> while it is in
memory.  This frustrates side-channel attacks.</p>
<p>Sequoia supports <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/serialize/stream/padding/index.html">padding messages</a> to obfuscate an encrypted
message’s length.  We include support for the <a href="https://bford.info/pub/sec/purb.pdf">padmé</a> scheme, but
other schemes can be plugged in.</p>
<p>To allow users to control the policy while still using higher-level
functionality, Sequoia uses a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/index.html">policy object</a>.  A policy object is
passed to any method that checks something for validity.  For
instance, when a method needs to determine whether a binding signature
should be used, it invokes the policy object’s <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/trait.Policy.html#method.signature"><code>signature</code> callback</a>.
Our experience suggests that this approach greatly simplifies dealing
with this <a href="https://en.wikipedia.org/wiki/Cross-cutting_concern">cross-cutting concern</a> in a highly flexible manner.</p>
<p>Policy objects can also be embedded in other objects.  For instance, a
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html"><code>ValidCert</code></a> encapsulates a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> and a policy object.  This
ensures that the application of the policy is consistent, and hard to
forget to apply.</p>
<p>In Sequoia, we prefer the use of formal grammars rather than ad-hoc
parsing when doing any non-trivial parsing.  For instance, when
verifying the structure of <a href="https://tools.ietf.org/html/rfc4880#section-11.1">OpenPGP Certificates</a> and <a href="https://tools.ietf.org/html/rfc4880#section-11.3">OpenPGP
Messages</a>, we use <a href="https://github.com/lalrpop/lalrpop">LALRPOP</a>, a parser generator, to generate the
parser.</p>
<p>Sequoia implements a streaming API.  If not careful, this can lead to
a consumer processing unauthenticated data, which was exploited by
<a href="https://efail.de/">EFAIL</a>.  To mitigate this type of failure, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>
withholds the last <code>O(1)</code> bytes of data, and only releases it if the
message can be authenticated.  This makes it harder for an attacker to
control what is released.  And for short messages, nothing is released
since the whole message is buffered.</p>
<p>We’ve tried to ensure that data structures that may be used in a
side-channel sensitive context use constant time comparisons.</p>
<p>Where possible, we use a device driver-style API so that it is
straightforward to add new backends.  For instance, our <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/trait.Signer.html"><code>Signer</code></a> and
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/struct.Decryptor.html"><code>Decryptor</code></a> traits make it easy to implement alternative signing and
decryption backends.  In addition to the in-memory implementations, we
already have implementations that use secret key material managed by
<a href="https://docs.sequoia-pgp.org/sequoia_ipc/gnupg/struct.KeyPair.html">gpg agent</a>.</p>
<p>We tried hard to provide helpful error messages.  This is particularly
difficult …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</a></em></p>]]>
            </description>
            <link>https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448533</guid>
            <pubDate>Wed, 16 Dec 2020 20:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Old New Adventure]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25448248">thread link</a>) | @Ygg2
<br/>
December 16, 2020 | https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>After two and a half years of being independent, I am returning to Google.</p>

<p>The time off was really valuable. I was still feeling residual effects from burnout on the Android team in late 2015, and also drained by family and personal things that were happening and needed more time and energy. I got that, and return recharged and with some insights that I hope will be useful. I’ll touch on a few of those in this post. Each could probably be its own blog post, but today I want to briefly note the event.</p>

<p>I am now a research software engineer on the Google Fonts team, working on a number of topics in font technology, including font design tools, GPU-accelerated font rendering, and evolution of font file formats to be more efficient and capable.</p>

<h2 id="on-open-source-sustainability">On open source sustainability</h2>

<p>Much has been written on open source sustainability, notably <a href="https://nadiaeghbal.com/">Nadia Eghbal</a>’s <em>Working in Public.</em> I won’t speak to open source more broadly (except to note how impressed I am with Blender and Krita), but for the specific task of building an ecosystem for a library, I think there is one model that actually works: being hired by a company that depends on that ecosystem.</p>

<p>To some extent, that’s an indictment of our capitalist system. In an ideal universe, there would be strong institutions dedicated to the public interest where open source developers could develop, researchers could research, and spend an absolute minimum of time and energy hustling for support. For software, in any case, universities are not that (as demonstrated by <a href="https://blog.cocalc.com/2019/04/12/should-i-resign-from-my-full-professor-job-to-work-fulltime-on-cocalc.html">William Stein’s experience with Cocalc at University of Washington</a>), otherwise I’d be quite tempted. In the actual world, working for a company like Google is about as close as you can come.</p>

<p>I remain skeptical of patronage-style platforms such as Patreon or Github Sponsors. I think it’s possible to make them work, but only for a small number of fortunate people, and even then, the incentives for creating maximum value aren’t that well aligned with the incentive structure of hustling on social media.</p>

<p>So me (re-)joining Google full time is basically a statement of confidence in this model of being employed to work on open source. Other models can work, and people should definitely find what works for them, but particularly for the projects I’m interested in, it makes sense.</p>

<h2 id="on-rust">On Rust</h2>

<p>I continue to love Rust, and believe it offers a stronger foundation for building software. I feel like I started my Rust journey in the early ’90s, when I was working on retrofitting <a href="https://theory.stanford.edu/~aiken/publications/papers/pldi95.pdf">static memory management</a> to ML, using explicit lifetime regions.</p>

<p>Rust adoption is trending up, including at Google. The language is in good shape, but the library ecosystem is still fairly immature, missing a number of critical pieces. Building up that ecosystem is an incredibly rewarding project.</p>

<p>I am particularly excited about Rust for font technology and infrastructure. Today, Python rules on the font design and production side, partly to the connection of typeface designer <a href="https://medium.com/type-thursday/learning-python-makes-you-a-better-designer-an-interview-with-just-van-rossum-8d4758c192d8">Just van Rossum</a> being Guido’s brother. The flexibility and expressiveness of Python makes it a good fit, but we’ve also gotten to a place where the <em>production</em> of fonts is done in Python, and the <em>consumption</em> is in C++.</p>

<p>Rust lets us build reliable, performant code that can also be deployed in production, and can be the basis of fluidly interactive UI tools. I’m not the only one who sees this potential; YesLogic is building their next-generation font shaper <a href="https://github.com/yeslogic/allsorts">Allsorts</a> in Rust, for many of the same reasons.</p>

<p>The Google Fonts team has been interested in adopting more Rust for a while, and part of my role is to facilitate that. I’m really looking forward to it.</p>

<h2 id="on-research">On research</h2>

<p>I have rebranded myself somewhat as a researcher, but that doesn’t <em>quite</em> capture the whole story either. I have always loved research, and that love sustained the energy to complete my <a href="https://levien.com/phd/phd.html">PhD</a>, but I also love building real things, and actually feel that many of these practical problems are more interesting than many of the abstract topics fashionable in academia. Just as much as writing papers and so on, I’m trying to build open source software and community around that. There isn’t really a word for this role, but even without such a word I’m trying to consciously create it for myself, and am grateful that Google is allowing me to try.</p>

<h2 id="on-the-work">On the work</h2>

<p>This is the most exciting part for me. I have a very long-term interest in 2D graphics, font technology, and UI, and have been doing a bunch of interesting things on all these fronts. I expect to spend most of my time continuing to advance research on all these frontiers.</p>

<p>The scope of these projects is large, and more ambitious than one person could really do. That’s one reason I’ve been consciously developing an open source community around them. That will continue.</p>

<p>Most of the day-to-day work on <a href="https://github.com/linebender/druid">Druid</a> and <a href="https://github.com/linebender/runebender">Runebender</a> will be done by Colin Rofls, though I very much enjoy getting my elbows in the code too and will be doing some of that.</p>

<p>A major focus will be building out the <a href="https://github.com/linebender/piet-gpu/blob/master/doc/vision.md">piet-gpu vision</a>. I believe a high-performance 2D rendering engine will be a great thing for the Rust ecosystem and with potential for large impact. It feels like good research; whether it goes into production at scale or not, I expect the things we learn from doing it will help inform the next generation of UI technology. That’s equally true for research into fundamental UI principles, for example the <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet</a> architecture for Druid.</p>

<p>There are also really exciting advances in <a href="https://github.com/linebender/spline">spline</a> technology in the pipeline. I think these have the potential to be a more appealing and productive basis for drawing fonts than cubic Béziers. The next big step is to validate whether they actually work as well as I’m hoping. That involves polishing the UX and integrating them into Runebender. If that turns out really well, a longer term (but more speculative) aspiration is to get them into a font format, where they could reduce binary size while increasing quality. It’s obvious the Google Fonts team is the best home for this work.</p>

<p>I have a lot of work in front of me, but am more excited than ever. On to an old new adventure, and may 2021 be a time of healing and renewed energy for all.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448248</guid>
            <pubDate>Wed, 16 Dec 2020 20:36:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Preview in macOS Big Sur is destroying PDFs]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 311 (<a href="https://news.ycombinator.com/item?id=25447830">thread link</a>) | @matrixagent
<br/>
December 16, 2020 | https://annoying.technology/posts/86f4ea27e4cd90d0/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/86f4ea27e4cd90d0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/35f98c21da204421e81bcfcb709f0b9a2563fde5/a3843/media/previeweatingpdfs.png"></p><p>This <a href="https://annoying.technology/media/previeweatingpdfs.png">image</a> has three components: On the left is an OCR’ed PDF from my ScanSnap iX500. I have selected most of the text, and on the right side you can see two copy&amp;paste results. In the upper half is the result directly after scanning, right after the bundled ABBYY FineReader that comes with the iX500 did its magic. In the lower half is the result <strong>after</strong> modifying (removed a blank page) and saving that same PDF in <em>Preview</em>.</p><p>Hard to believe, but that’s <a href="https://discourse.devontechnologies.com/t/odd-pdf-behavior/21400">not</a> <a href="http://www.documentsnap.com/ocr-text-macos-sierra-preview/">the</a> <a href="https://discussions.apple.com/thread/8010687">first</a> time Apple <a href="https://mjtsai.com/blog/2016/12/21/more-macos-preview-pdf-trouble/">messed this up</a>. Sure, even Apple can’t account for all use cases when changing complex stuff like internal PDF handling. But:</p><ul><li>The iX500 is an insanely popular and common scanner</li><li>I don’t know any OCR software that is more popular than ABBYY FineReader</li><li>macOS used to be the absolute best in class OS for dealing with PDFs by a <strong>long</strong> shot</li><li>IT HAPPENED BEFORE</li></ul><p>I wish Apple was still charging for OS updates, so I could at least refund it.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> This is such a nasty bug – if you don’t already know to expect it, you will only find out months or possibly years later. I almost missed it this time, because even after modifying and saving the file it’s still not happening. You have to completely close the file and reopen it, only then will you realize that it has been destroyed.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Yes, I blame only Apple for this. I’ll repeat what I told Philipp (noted Apple apologist!) when we argued about this last week after I discovered the problem: ABBYY says they don’t support Big Sur yet, that’s fine. But Apple didn’t tell me that I can’t upgrade to Big Sur when I use ABBYY. I’d be a lot less angry if there was a changelog or release notes <em>from Apple</em> where it says there is a known problem with OCR’ed PDFs in Preview. <em>Their</em> software is broken, <em>they</em> need to tell me. I don’t care if it only worked because they had workarounds for super shitty PDFs that ABBYY possibly produces, I just need my OS to keep working for me. This bug could hit me without even owning a scanner at all – someone sending me a PDF that I then unknowingly break before archiving it. That’s the part I’m mad about. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/86f4ea27e4cd90d0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447830</guid>
            <pubDate>Wed, 16 Dec 2020 20:07:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Killing Our Help Center Improved CSAT and Revenue over 11%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25446836">thread link</a>) | @tapneal
<br/>
December 16, 2020 | https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue | <a href="https://web.archive.org/web/*/https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/Helpcenter.png"></center>
<p>Being card game geeks, we run <a href="https://solitaired.com/">our solitaire site</a> as a fun hobby. As we gained some users though over the last year and launched a subscription service to generate some side income, we had to make sure we had reasonable customer support. </p>
<p>It was a no brainer to create a help center because we didnâ€™t want to spend time managing customer support tickets, and having a workflow where users could be self-directed and answer questions on their own was ideal. </p>
<h2 id="whenirealizedihatedhelpcenters">When I realized I hated help centers</h2>
<p>I had an issue with one of our service providers, and went to their site to figure out how to solve the problem. For 30 minutes, I hopped around their own help center with no luck finding the answer to my question. </p>
<p>I then started looking for a support line. After digging through various questions and hitting â€œNo, this did not answer my question,â€� I  found  that it was discontinued and the page redirected me back. </p>
<p>Needless to say, I wasnâ€™t happy. </p>
<p>It made me realize that instinctually, I always want to talk to someone. Whether it be over email, the phone, or chat, knowing that I was getting personalized attention would give me comfort and confidence that my issues will be resolved. </p>
<p>I decided then and there: We will get rid of our help center!</p>
<h2 id="removingourhelpcenterandimprovingourcustomersatisfactionscoreby12">Removing our help center and improving our customer satisfaction score by 12%</h2>
<p>We analyzed where users visited most in our help center. We found that three issues dominated 95% of requests:</p>
<ol>
<li>We had launched a subscription service and users wanted to understand how to cancel. Having run subscription businesses in the past, this wasnâ€™t too surprising. </li>
<li>How to report bugs in the game. Invariably, users came across some fringe bugs, especially for our <a href="https://solitaired.com/freecell">Freecell</a>, <a href="https://solitaired.com/klondike-solitaire">Klondike</a>, and <a href="https://solitaired.com/spider">Spider Solitaire</a> games, and wanted to report it. </li>
<li>Requests for more games. </li>
</ol>
<p>Addressing these questions were relatively simple, and we figured we can spend a few minutes a day responding to anything that came in. </p>
<p>We responded on average within two days and found that our customer satisfaction score (CSAT) improved from 65% to 73%. </p>
<h2 id="improvingcustomersatisfactionanother22">Improving customer satisfaction another 22%.</h2>
<p>We hypothesized that response time played a major role in improving customer satisfaction. </p>
<p>For the next week we decided to respond within 24 hours and we found that CSAT improved from 73% to 78%.</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/24hours.png"></center>
<p>Realizing that response time makes a difference, we promised and communicated on our site that weâ€™d respond within 2 hours during business hours. CAST went up 82%. </p>
<p>We didnâ€™t want to stop, and we decided to add live chat and respond immediately during business hours. CSAT shot up to 89%!</p>
<h2 id="improvingrevenueby11">Improving revenue by 11%</h2>
<p>As we started responding and talking to our customers, we learned that many users would cancel their subscription because they didnâ€™t know how to access certain games, customization features, and due to some unknown bugs. </p>
<p>Operating a help center only gave users instructions on how to cancel, and did not give us an opportunity to understand why and course correct.</p>
<p>When we started understanding all the reasons our users were canceling, we were able to address this, improving our retention. In the first month, this improved our very modest subscription revenue by 11%. If you compound the impact of retention, it will likely be more over time. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/Retention.png"></center>
<h2 id="ourcustomersupportsetuptodayandidealsolutions">Our customer support set up today, and ideal solutions</h2>
<p>Because we run the site for fun, itâ€™s difficult for us to commit to a SLA when someone responds. Today, we just have a simple contact us page. We try to get back within a day generally, but sometimes we miss that and sometimes weâ€™re able to respond earlier depending on competing priorities. </p>
<p>This has taught us though that many consumers want to talk to someone and want a response right away. With that said, some people are totally fine skipping the human interaction. We think an ideal set up is to:</p>
<ol>
<li>Have a help center that covers very simple questions, like how to use certain features. On those pages, there should be an option to quickly talk to a customer service agent. </li>
<li>Have a page on cancellation, but have a CTA talk to someone with a quick response. This will help you understand issues for paying customers and address it</li>
<li>Have a chatbot in lieu of a help center with similar works flow described above. However, set it up in a way where users understand they are talking to a bot, and at any point they can talk to someone</li>
</ol>
<p>Naturally, everyone has resource limitations. If you were to protoize KPIs like revenue, as I imagine you would, find a way to quickly talk to your paying customers or those most likely to pay to support your business goals.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25446836</guid>
            <pubDate>Wed, 16 Dec 2020 19:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risk8s Business: Risk Analysis of Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444866">thread link</a>) | @clintgibler
<br/>
December 16, 2020 | https://tldrsec.com/guides/kubernetes/ | <a href="https://web.archive.org/web/*/https://tldrsec.com/guides/kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><strong>On this page</strong>: A zero-to-hero guide for assessing the security risk of your Kubernetes cluster and hardening it.</p>

<p>Kubernetes is a container orchestrator that has seen year-after-year exponential growth in adoption.</p>

<p>While many organizations have adopted Kubernetes because of its hyped ability to
scale, extensibility, and multi-cloud support, many security teams have been
left playing catch-up.</p>

<blockquote>
  <p>This guide will help you rapidly ramp on what Kubernetes is and what it does
(and doesn’t do).</p>

  <p>You’ll learn how to understand the current state of your
Kubernetes deployment, hone in on what’s most risky, and how to mitigate that
risk.</p>

  <p>We’ll link to the best tools and other resources to learn more, and
include plenty of handy CLI one-liners to get the job done.</p>
</blockquote>

<h2 id="guide-structure">Guide Structure</h2>

<p>The structure of this guide, which you can also quickly navigate by the navbar
links on the left hand side, is the following:</p>

<h3 id="introduction">Introduction</h3>

<p>First we’ll give you an <a href="https://tldrsec.com/guides/kubernetes/overview">overview</a> of Kubernetes, discuss what it means to <a href="https://tldrsec.com/guides/kubernetes/secure-cluster-looks-like">secure a
cluster</a>, and talk about the end
goal here.</p>

<p>We’ll list a number of <a href="https://tldrsec.com/guides/kubernetes/tooling-up">solid tools</a> to get you
started, which will be used throughout this guide.</p>

<h3 id="understanding-your-environment">Understanding Your Environment</h3>

<p>You need to <a href="https://tldrsec.com/guides/kubernetes/understanding-your-environment">understand your environment</a> before you can secure it, so we start
there. We’ll quickly dive in to ways that you can collect information, and which information is relevant in the big picture.</p>

<p>We want to see what your cluster looks like, how you’re <a href="https://tldrsec.com/guides/kubernetes/how-deploying">deploying it</a> (managed vs self-hosted), what’s running
<a href="https://tldrsec.com/guides/kubernetes/whats-running-in-cluster">inside</a> and <a href="https://tldrsec.com/guides/kubernetes/whats-running-nearby-cluster">nearby</a>, and what services are at risk of being compromised throughout the cluster’s lifetime.</p>

<h3 id="understanding-your-risk">Understanding Your Risk</h3>

<p>With all this information we will run through a simple risk analysis that helps us determine how likely an exploit would occur and determine how your cluster will hold up. Finally building
an overall risk baseline for the environment.</p>

<p>We’ll examine:</p>
<ul>
  <li><a href="https://tldrsec.com/guides/kubernetes/understanding-your-risk">Access controls</a>: who can deploy and how are workloads being deployed?</li>
  <li>Which <a href="https://tldrsec.com/guides/kubernetes/services-exposed">services are exposed</a> publicly or internally?</li>
  <li>Do we have visibility into the cluster, and is our <a href="https://tldrsec.com/guides/kubernetes/how-vulnerable-is-cluster">cluster vulnerable</a> due to configuration mistakes or networking-related vulnerabilities?</li>
</ul>

<p>We’ll conclude by discussing <a href="https://tldrsec.com/guides/kubernetes/common-compromise-scenarios">common compromise
scenarios</a>: a pod being
compromised, a developer compromising a cluster, and a developer being
compromised by an attacker. And some stories of what I’ve seen in the real world
during my consulting work, for good measure 😎</p>

<h3 id="wrapping-up">Wrapping Up</h3>
<p>In the end, we’ll <a href="https://tldrsec.com/guides/kubernetes/putting-it-together">put it all together</a>,
and you will hopefully have enough information to get started reviewing your
cluster environment to identify gaps, vulnerabilities, and just questionable
areas that will need further inspection.</p>

<p>Once you have a risk assessment complete, it’ll be your job to continue onto the
risk management phase and find out what mitigations will best fit in to address
all the issues you found.</p>

<p>And of course, we conclude with a variety of <a href="https://tldrsec.com/guides/kubernetes/further-reading">further
resources</a> on Kubernetes threat modeling,
additional tools, and some of our favorite conference talks.</p>



<p>My name is Mark Manning and I’m currently a security architect at <a href="https://www.snowflake.com/">Snowflake</a>. I’ve spent years as a security consultant for a global security consulting firm where I assessed, reviewed, attacked, and sometimes, helped fix problems on a wide range of Kubernetes projects (among other types of projects). I was excited for the opportunity to collaborate with <em>tl;dr sec</em> and write about a topic I’ve dealt with repeatedly over the last 4 years, Kubernetes risk.</p>

<p>I’ve worked with customers just getting started with Kubernetes, cloud providers deploying their own Kubernetes platforms, and large organizations that have invested much of their business into embracing the “digital transformation.”</p>

<p>Today I’m working with Snowflake by focusing some of my experiences and offensive skills towards helping solve some really interesting security challenges. Part of that is Risk Management of Kubernetes clusters at scale.</p>

<p>I’ve seen how things can go right, and wrong, in the real world, in a vast variety of companies. While I don’t have all the answers, I enjoy sharing what I do know with the public, and <a href="https://www.twitter.com/antitree">on Twitter</a> or at <a href="https://www.shmoocon.org/speakers/#kubectl">hacker conferences</a>.</p>

<p>My hope is that some of us will continue to work heavily on Kubernetes security so that even if we don’t fix everything, the rest of the infosec industry can level-up to meet the challenges of securing these modern platforms.</p>










<!-- Begin MailChimp Signup Form -->



<!--End mc_embed_signup-->
        
      </section></div>]]>
            </description>
            <link>https://tldrsec.com/guides/kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444866</guid>
            <pubDate>Wed, 16 Dec 2020 16:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaSy Math: A Resource of SaaS Metrics for Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25444277">thread link</a>) | @randrews543
<br/>
December 16, 2020 | https://www.talkinsaasy.com/saasy-math | <a href="https://web.archive.org/web/*/https://www.talkinsaasy.com/saasy-math">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><h2 data-ix="fade-in-on-scroll-2">A collection of simple, easy to use SaaS metrics with formulas, sample calculations, and examples of how to find this data in your own tech stack</h2></p><div><div><p>Net Revenue Retention (NRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4ad78fde0b0a238a1870_Net%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Net Revenue Retention represents how well you are <strong>retaining</strong> and <strong>expanding</strong> your existing recurring revenue. NRR is most typically measured either annually or month-to-month, but you are always comparing a cohort (a group of customers acquired at the same time) to see how their subscription revenue fares over the given time period. Think about your Netflix subscription, when you first signed up, are you still subscribed? And are you paying the same about as before?</p><p>‍<strong>Quick and SaaSy Way To Calculate:</strong> Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month, then just divide that number by previous years MRR number and you have your annual net revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Net Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-revenue-retention" target="_blank">Net Revenue Retention</a></p></div></div></div><div><div><p>Gross Revenue Retention (GRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4aa6b26ad627a4efeb0f_Gross%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Gross Revenue Retention represents how well you are <strong>retaining</strong> your revenue and DOES NOT include how well you are expanding them. Similar to NRR, GRR measures customer cohorts aver a given time period to see how much of the initial MRR still remains over the given time period.</p><p><strong>Quick and SaaSy Way To Calculate:</strong> Similar to NRR, go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month but in the case of GRR, any customers who’s revenue expanded, you need to take out the additional revenue and just keep their original MRR. Then just divide that number by previous years MRR number and you have your annual gross revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Gross Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank">Net vs Gross Revenue Retention</a></p></div></div></div><div><div><p>Customer Churn</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca548eec3a202105d82b1e_Customer%20Churn.png" loading="lazy" alt=""></p></div><div><div><p>Customer Churn is the measure of how many customers cancel over time from a given cohort. While the goal is to always minimize churn as best possible, SaaS/Subscription will have some churn and tracking it is crucial for success. Similar to Revenue Retention</p><p><strong>Quick and SaaSy Way To Calculate: </strong>Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>, or go into your CRM such as <a href="https://www.salesforce.com/" target="_blank">Salesforce</a> or <a href="https://www.hubspot.com/" target="_blank">HubSpot</a>. From either system you want to look for the Customer/Account table from the systems API. From that table you want to look up and count all of the unique customer ID’s that where created in a given month. Then month-to-month you want to run a check on those same ID’s to see how many of them are still active customers and then divide that number by the initial number in their first month. Typically, startups will look at churn on a monthly and annual basis and we highly recommend you track the changes in churn over time (ie. If the rate of churn is decreasing or increasing over time). If you want to take this analysis to the next level shoot me us <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer churn can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/churn-isnt-always-bad" target="_blank">Churn Isn’t Always Bad</a>, <a href="#https://www.talkinsaasy.com/blog/revenue-churn-vs-customer-churn">Revenue Churn vs Customer Churn</a><br><a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank"></a></p></div></div></div><div><div><p>Customer Acquisition Cost (CAC)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca549a64abc2d9c6dfb094_Customer%20Acquisition%20Cost.png" loading="lazy" alt=""></p></div><div><div><p>Customer Acquisition Cost, or CAC, is the measure of how much a company must spend in order to acquire a new customer. Typically you look at CAC over a period of time (annually and/or month-to-month) to understand how it is trending for your business.<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>To get your expenses you will need to go into your accounting/financial system such as Quickbooks or Xero, and track down your sales and marketing expenses for a time frame. This will include salaries, tech spend, marketing spend and any other expenses that go into your customer acquisition funnel. You then want to go into your CRM or billing and subscription management system and run a count of all the unique customer ID’s that have a created date in the same time period. You then divide the cost by your new customer count and you have your average CAC. If you want to take this analysis to the next level shoot us an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer acquisition cost can differ throughout your customer base.</p><p>Related Blog&nbsp;Posts:<a href="https://www.talkinsaasy.com/blog/dont-get-fooled-by-cac"> Don't Get Fooled By CAC</a></p></div></div></div><div><div><p>Retention Margin</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fd6a337e1ad8f8787d82e4d_Retention%20Margins.png" loading="lazy" alt=""></p></div><div><div><p>Retention Margins is a measurement of the % of top-line revenue that is left over each month once you have taken out the cost of revenue (Gross Margins) and the cost of keeping (retaining) your recurring revenue customers. Think of retention margins as the the home profit on a per customer basis after you have retained them month-over-month<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>First you need to calculate your Gross Margin (Revenue-Cost of Revenue/Revenue). Then go into your accounting system like Quickbooks or Xero. You want to total up the amount of spend (payroll, overhead, etc.) for your customer service and success teams. You then want to add that number to your Cost of Revenue number and subtract that from your top-line revenue. That number is your retention profit (Take home $$$) after retaining your customers. Take your retention profit and divide it by your top-line revenue number and that will give you your retention margin.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/why-net-and-gross-revenue-retention-matter">Why Net AND&nbsp;Gross Revenue Retention Matter</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.talkinsaasy.com/saasy-math</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444277</guid>
            <pubDate>Wed, 16 Dec 2020 16:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Regret Quitting Astrophysics]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 140 (<a href="https://news.ycombinator.com/item?id=25444069">thread link</a>) | @petschge
<br/>
December 16, 2020 | http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/ | <a href="https://web.archive.org/web/*/http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-223">
	
	<!-- .entry-header -->

	<div>
		
<p>In 2013 I decided to quit my career in astrophysics, move back “home” and become a data scientist. The <a href="http://www.marcelhaas.com/index.php/2018/03/30/leaving-the-field-becoming-an-extronomer/">blog post</a> I wrote about my decision was probably my best read publication as a professional astronomer and it was moving to read all the reactions from people who were struggling with similar decisions. I meant every word in that blog post and I still agree with most of what I said. Now, 7 years after the fact, it is time to confess: I deeply regret quitting.</p>



<p>This post is meant to give my point of view. Many people who left academia are very happy that they did. Here I present some arguments why one might not want to leave, which I hope will be of help for people facing decisions like these.</p>



<p><span>I miss being motivated.</span> In the first few years after jumping ship many people asked me why I would ever wanted to <em>not</em> be a professional astronomer. I have always said that my day-to-day work wasn’t too different, except that what I did with data was about financial services or some other business I was in, rather than about galaxies and the Universe, but that the “core activities” of work were quite similar. That is kind of true. On an hour by hour basis, often I’m just writing (Python) code to figure things out or build a useful software product. The motivation to do what you do, though, is very <em>very</em> different. The duty cycle and technical depth of projects are short and shallow and the emphasis of projects is much more on getting working products than on understanding. I am doing quite well (in my own humble opinion), but it is hard to get satisfaction out of my current job.</p>



<p><img loading="lazy" width="546" height="340" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png" alt="" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png 546w, http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat-300x187.png 300w" sizes="(max-width: 546px) 100vw, 546px"></p>



<p><span>I miss academic research.</span> The seeds of astronomy were planted at very young age (8, if I remember correctly). The fascination for the wonders of the cosmos has changed somewhat in nature while growing up but hasn’t faded. Being at the forefront of figuring things out about the workings of the Universe is amazing, and unparalleled in any business setting. Having the freedom to pick up new techniques that may be useful for your research is something that happened to me only sporadically after the academic years. The freedom to learn and explore are valuable for creative and investigative minds and it doesn’t fit as well in most business settings that I have seen.</p>



<p><span>I miss working at academic institutions.</span> The vibe of being at a large research institute, surrounded by people who are intrinsically motivated to do what they do was of great value to me. Having visitors over from around the globe with interesting, perhaps related work was a big motivator. That journal clubs, coffee discussions, lunch talks, colloquiums etc. are all “part of the job” is something that even most scientists don’t always seem to fully appreciate. Teaching, at the depth of university level classes, as a part of the job is greatly rewarding (I do teach nowadays!).</p>



<p><span>I miss passion and being proud of what I do.</span> The <a href="https://www.google.nl/search?hl=nl&amp;q=sexiest+job+of+the+21st+century">internet </a>says I have ”the sexiest job of the 21<sup>st</sup> century”, but I think my previous job was more enjoyable to brag about at birthday parties. I can do astro as a hobby, but that simply doesn’t give you enough time to do something substantial enough.</p>



<p><span>I don’t miss …</span> Indeed, the academic career also had its downsides. There is strong competition and people typically experience quite some pressure to achieve. The culture wasn’t always very healthy and diversity and equality are in bad shape in academia. Success criteria of your projects and of you as a person are typically better motivated in business. The obligatory nomadic lifestyle that you are bound to have as an early career scientist were a very enjoyable and educational experience, but it can easily become a burden on your personal life. The drawbacks and benefits of any career path will balance out differently for everybody. If you get to such a point, don’t take the decision lightly.</p>



<div><figure><img loading="lazy" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png" alt="" width="89" height="89" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png 200w, http://www.marcelhaas.com/wp-content/uploads/2020/12/decision-150x150.png 150w" sizes="(max-width: 89px) 100vw, 89px"></figure></div>



<p>The people who questioned my decision to become an extronomer were right. I was wrong. It seems too late to get back in. I think I have gained skills and experience that can be very valuable to the astronomical community, but I know that that is simply not what candidates for academic positions are selected on. On top of that, being geographically bound doesn’t help. At least I will try to stay close to the field and who knows what might once cross my path.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444069</guid>
            <pubDate>Wed, 16 Dec 2020 15:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A year's worth of learnings from adopting Mob programming]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443874">thread link</a>) | @dinispeixoto
<br/>
December 16, 2020 | https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/ | <a href="https://web.archive.org/web/*/https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At FARFETCH, teams are encouraged to try new development methodologies so that they can deliver even better results while also improving productivity. As a fairly new team, we have continuously been looking for different methodologies that best fit our needs, such as avoiding knowledge silos or a slow-paced reviewing process. Although not every approach that we have tried has worked, the ones that did are now part of our daily development workflow and play a key role in the outcome of the tasks that we deliver.</p><p>A year ago, our team was first introduced to <a href="https://mobprogramming.org/" target="_blank">Mob Programming</a>, and we have been using it since then. The concept that was once hard to fathom is now the go-to approach when dealing with most of our sprint tasks. Although being able to use Mob Programming daily has come with many different types of challenges, the results have been surprisingly good.&nbsp;</p><p>When using Mob Programming, instead of having each team element working on its own task, the whole team gathers together to tackle the same task. It includes using a single workstation and only one person typing - <span>the Driver</span> - while the remaining people are describing the path that should be taken.</p><blockquote><p><span>Itâ€™s a software development approach where the whole team works on the same thing, at the same time, in the same space, and at the same computer. - Woody Zuill (2014)</span></p></blockquote><p>Mob Programming is somewhat similar to Pair Programming. While the latter consists of having two team members sharing the same workstation, Mob Programming goes a bit further and implies having the entire team focused on a single task. Even though Pair Programming is a great tool to share knowledge, improve communication and even bring better outcomes (as a consequence of having multiple people thinking about the same problem), it confines these advantages to only two elements on a team. On the other hand, Mob Programming can amplify these benefits to the whole team.</p><p>Yet, having an entire team working on the same problem brings its own challenges. It's imperative that the team establishes a set of well-defined procedures and rules. Furthermore, Mob Programming may not be suitable for all kinds of tasks or teams. Depending on the task the team is tackling, it should first be established whether Mob, Pair or Solo Programming is the appropriate methodology. None of the three is suitable for all situations. It's up to the teams to give them a try and figure out when to use them.</p><p>A typical Mob Programming setup consists of moving the team to an isolated space (e.g. a meeting room) and bringing one computer that should be connected to either a large monitor or a projector. Having a whiteboard to write down possible solutions and describe the next steps is great to empower collaborative brainstorming. Seats and tables for everyone is a must, as everyone should be comfortable during the session, this is particularly relevant as these sessions tend to be time-consuming. Since the beginning of the Covid-19 pandemic, we have adapted our ways of working to facilitate Remote Mob Programming sessions - but more to come on that later.&nbsp;</p><p><img src="https://www.farfetchtechblog.com/fotos/editor2/Dinis_Peixoto/Image_01.png" alt=""></p><p>Two key roles must be considered when using Mob Programming: the Driver and the Navigator. The Driver is the person at the keyboard, responsible for moving the codebase forward. The Navigator understands what the group has decided to aim for and provides instructions to the Driver. The Navigator shouldn't dictate the actual code that the Driver has to write down, only the expected solution. Sometimes, the Navigator role may not be needed. It is up to the Driver to opt-in or out. Nonetheless, when there's no Navigator, the Driver may get lost by having multiple people explaining what to do. These roles should rotate between all team members at regular intervals (usually monitored by a timer).</p><p>The session should be held continuously until the task is done. Quick breaks, like coffee or bathroom, are allowed and shouldn't require the session to stop. Some longer breaks like lunch must be agreed between the team so that everyone does it at the same time to prevent distractions and absences.</p><div><p>The first thing that may come to one's mind is that Mob Programming jeopardizes the team's overall productivity. After all, having an entire team working on the same task certainly means that both the team's velocity and throughput will be compromised, right?</p></div><div><p>More often than not, people tend to forget that delivering a task includes a lot more than just writing code. It's common that most of the time spent on a particular task is on coming up with the right solution or waiting for the team to review what was done. In our case, each task requires approval from 3 different people, which implies that they stop what they are doing, get up to speed, and finally review the result.</p></div><div><p>When using a development workflow like Solo Programming, once a developer puts the task up for review, the team has to understand all the requirements and review what was done, while also trying to identify what was the problem-solving process that the author took. The fact that the team has to go through someone elseâ€™s work without being completely aware of the decisions behind the proposed solution might take longer and prevent some mistakes from being identified.</p></div><p>Whereas when using Mob Programming, taking advantage of insights and knowledge from the whole team may lead to the task being delivered quicker while also with a better solution. When it comes to the review process, it will also be straightforward as everyone owns the decisions that were made and the solution path that was taken.&nbsp;</p><p>We have been using Mob Programming for over a year. Over this period, we have been trying to refine our methodology so that we can make the most out of our sessions. Some of the phases that have improved our workflow are described below.</p><ol><li><span>Task scouting:</span> each team member should, individually, check the task details prior to the session. Investing time on exploring the task beforehand will considerably shorten the time required on the next phase.</li><li><span>Purpose clarification: </span>at the beginning of the session, someone should present the problem at hand and make sure that everyone has a clear grasp of what the team is trying to achieve. Any questions about the purpose of the task should be raised at this time.</li><li><span>Work breakdown:</span> with the purpose of clarified, it's now time to identify the work blocks that have to be monitored during the session. The different tasks that result from this analysis should be prioritized and can be split into even smaller tasks if needed.</li><li><span>Execution:</span> based on the tasks identified previously, the team must try to work on each task by following the agreed order. The team should expect new tasks to surface throughout the session. If it happens, the order of the tasks can be adjusted.</li><li><span>Debriefing:</span> at the end of the session, the team will need to look at the initially defined tasks and check if everything was tackled. The solution should be carefully reviewed together before submitting it for team review. It's highly recommended to provide some time for an individual review to address groupthink problems.</li></ol><p>Equally important are the rules that our team has defined so far. Periodically, we revisit them and discuss whether or not some updates are required. Trying to make this an iterative process is extremely important to enhance the overall experience of our Mob Programming sessions over time.</p><ol><li><span>Driving/navigation time:</span> each team member will be in the Driver/Navigator role for 15 minutes. If a discussion comes up, the timer should stop so that both the Driver and Navigator can participate.</li><li><span>Complete focus on the session:</span> everyone in the room has to be focused on the session. If someone needs to work on something else, they must leave the room to avoid distracting the team.</li><li><span>Mandatory and optional breaks:</span> there are three mandatory breaks where the session must be stopped: morning coffee, lunch and afternoon coffee. Additional breaks are allowed but should be minimized to reduce the impact on focus. These sessions are very demanding on every team member so, if one cannot focus on the current tasks, taking a break is completely acceptable.</li><li><span>Research time:</span> whenever research is required, it should be done primarily by the Driver with the help of the team. Parallel research streams are allowed, as long as the team is aware of them.</li><li><span>Identify Mob Programming tasks ahead of time:</span> we always try to decide upon whether a specific task is going to be tackled through Mob Programming or not. It facilitates any coordination required during our sprint.</li></ol><p>Due to the COVID-19 global pandemic, we had a new challenge ahead of us: <a href="https://www.remotemobprogramming.org/" target="_blank">Remote Mob Programming</a>. As a consequence, we had to go through the rules above and update them as a means to adapt to the reality of having the whole team working remotely.</p><ol><li><span>Driving/navigation time:</span> this should be increased, in our case, we adjusted it to 45 minutes, due to the extra work required when changing the Driver (e.g. setting up the environment, sync with git's remote repository). It might take up to 5 minutes and wouldn't be worth it to do it every 15 minutes.</li><li><span>Video sharing:</span> everyone should keep the camera on during the session and, when possible, look directly at it. Itâ€™s as close as we can get to face-to-face interaction.</li><li><span>Driver handover:</span> every time a Driver handover is required, the current Driver has to ensure that changes made during their turn are properly committed and pushed to the remote repository. To have a better sense of the changes and their history, usually, the Driver's name is kept on the commit description.</li></ol><p>When it comes to the tools that we use during our mob sessions, it depends on if we are doing it in-person or remotely. When having in-person sessions, the only tool that we make use of is <a href="https://github.com/dillonkearns/mobster" target="_blank">Mobster</a>, which allows us to keep track of the Driver timer, the active and next up Drivers. Whereas when having remote sessions, on top of Mobster we also benefit from <a href="https://slack.com/" target="_blank">Slack</a> for video/screen sharing and live annotations (i.e. being able to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/">https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/</a></em></p>]]>
            </description>
            <link>https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443874</guid>
            <pubDate>Wed, 16 Dec 2020 15:42:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Linux and Bash for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443415">thread link</a>) | @tolstoyevsky
<br/>
December 16, 2020 | http://dagshub.com/blog/effective-linux-bash-data-scientists/ | <a href="https://web.archive.org/web/*/http://dagshub.com/blog/effective-linux-bash-data-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>In November 2020, DAGsHub gave a series of guest lectures to the excellent <a href="https://yandexdataschool.com/israel/">Y-DATA</a> course for aspiring data scientists, which we would now like to share with whoever finds it useful, in blog form!</p><h2 id="cut-to-the-chase-">Cut to the chase!</h2><ul><li><a href="#basics">Shell basics</a></li><li><a href="#the-shell">Background on shells</a></li><li><a href="#shell-variables">Shell variables</a></li><li><a href="#pipes">Pipes</a></li><li><a href="#redirects">Redirects</a></li><li><a href="#filesystem">Filesystem</a></li><li><a href="#runnable-files">Runnable files</a></li><li><a href="#package-managers">Package managers</a> (e.g. brew and apt)</li><li><a href="#shell-commands-inside-jupyter-notebooks">Shell commands inside Jupyter notebooks</a></li><li><a href="#text-editors-in-the-terminal">Text editors in the terminal</a></li><li><a href="#other-useful-commands">Other useful commands</a></li><li><a href="#ssh">SSH</a></li><li><a href="#tmux">tmux</a></li><li><a href="#running-commands-in-the-background">Running commands in the background</a></li><li><a href="#symbolic-links">Symbolic links</a></li><li><a href="#zsh-oh-my-zsh-powerlevel10k">Oh-my-zsh</a></li></ul><h2 id="intro">Intro</h2><p>The topic - system, IT, DevOps, MLOps, whatever other name you want to call it - how do you make the computer do what you want, outside the context of Python (or R or Matlab etc., we don't discriminate)? How do you get that beautiful neural network of yours to run on an actual server in the cloud, so that it can serve actual users?</p><blockquote>What to do when the bubble bursts, and you have to step outside the Jupyter notebook to fix things?</blockquote><p>Of course, this is a wide open question which requires a lot of previous knowledge to answer. In our lectures, we wanted to start by building a solid foundation for the students to stand on. So, we went to the classics - what is Linux? Why do people use it? What is Bash? How to use the terminal? How to exit vim?!</p><figure><img src="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="It's all about that base, no trouble!" srcset="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>It's all about that base, no trouble! Photo by <a href="https://unsplash.com/@arstyy?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Austin Neill</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Instead of creating yet-another-tutorial on how to move and copy files in terminals, we wanted to bring perspective: </p><ul><li>Why would you use Linux, Bash, and other system tools?</li><li>What's the smart way to do it, based on our subjective experience? </li><li>What common problems will you come across, and how to solve them?</li><li>What's the mental framework for working with these tools, to gain understanding and learn more by playing?</li></ul><p>So, this guide/cheatsheet is more about our tips and tricks, and is definitely not exhaustive. On the contrary - we wanted to make the most of students' time, and only talk about what's interesting. Other things can be learned on an as-needed basis.</p><h3 id="who-is-this-for">Who is this for?</h3><p>The curriculum and some of the tips are aimed at data scientists who want an introduction to the topics of Linux &amp; Bash. However, the data science orientation mainly comes into play in a few domain specific tips, and in the stated motivations to learn these things - if you're an aspiring web developer, there's no reason not to benefit from this guide as well!</p><h2 id="linux">Linux</h2><h3 id="what-is-linux">What is linux?</h3><ul><li>A family of open source operating systems.</li><li>Developed by Linus Torvalds, who also invented Git to manage the source code for Linux.</li><li>An operating system is a program that takes over a bit after your computer turns on.</li><li>For the first few seconds after your computer switches on, the motherboard runs a small hard-coded operating system called the BIOS, but it quickly hands control over to some operating system<em> kernel</em>, which is installed on one of the hard drives, a USB stick or CD.</li><li>From that point on, the kernel decides which programs to run when, and how to control physical devices (via drivers).</li><li>An <em>operating system</em> is a bundle of programs that come packaged together. The kernel is the most important part, but it comes with more programs which help the users communicate with the kernel.</li><li>e.g. File explorers are part of the OS, but not the kernel - they're just graphical interfaces which sit between the user and the kernel.</li><li>Operating systems normally also handle file systems, user permissions, memory management, and many other things.</li><li>The thing that unites all the different operating systems in the Linux family is they all use the same Linux kernel - other parts differ. More on that later in the section about distributions.</li></ul><figure><img src="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Penguins" srcset="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@topcools?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">topcools tee</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h3 id="what-is-linux-good-for">What is Linux good for?</h3><p>An operating system is, surprisingly, just a type of system. Systems are designed by humans, and better designs lead to better performance, stability, and flexibility. <strong>Linux is simply a better designed operating system</strong>. It's super flexible and stable - "blue screens of death" are exceedingly rare in production Linux servers, and their performance is very reliable. <strong>Which is why a vast majority of production systems run on Linux</strong>, and that's also why it's good for anyone working in tech to be Linux literate. That includes you, dear reader.</p><p>Being open source leads to high quality, as bugs have fewer dark places to hide in. Developers can peer under the covers to make sure their Linux applications will work well, rather than guessing and relying on questionable documentation from closed source operating system developers.</p><p>But with great power and flexibility comes a great ability to shoot yourself in the foot. Linux makes that easy as well.</p><h3 id="what-do-the-different-types-of-linux-mean">What do the different types of Linux mean?</h3><p>One of the confusing things when entering the Linux world is the giant jargon which is thrown in your face. It feels like the explanations expect you to already know and understand a bunch of other terms, without building understanding step by step. So, I'd like to give you a very brief summary of terms you might come across and what they mean.</p><h3 id="linux-like-systems">Linux-like systems</h3><p>Mac and Unix are very similar to, but are not Linux technically. You will have a hard time telling the difference, unless you dive deep.</p><p>Unix is older than Linux and extremely similar - In fact, Linux is an open source re-implementation of Unix (which was closed source, but very good). This is pretty much historic trivia, as Unix is rarely seen nowadays, but know that some people use the words Unix and Linux interchangeably.</p><p>In general, there’s a name for operating systems that look and feel like Unix – POSIX compliant, or *nix. When you see these words, translate them as “follows the conventions of Linux, such as basic commands for file manipulation (ls, cd, mkdir) and "/" as the root of the file system etc.”</p><p>GNU is a large set of free software which is the foundation for much of Linux – compilers, C libraries, programs to zip files, and many others. It's also the name of an independent POSIX operating system, with more hardcore ideology around free software than Linux.</p><p>All of the above systems, as well as Linux itself, are examples of POSIX compliant or *nix systems.</p><h3 id="linux-distributions-distros">Linux Distributions / Distros</h3><p>There are (too?) many flavours of “real Linux”, called distros or distributions. It can be a headache to differentiate them.</p><p>A distribution is like a "company", which invents a new operating system. They wrap the Linux Kernel with a new bundle of peripheral programs - i.e. they may use a different mix of GUI programs, support different hardware by default, etc. They release new versions occasionally.</p><p><strong>The bottom line – unless you know what you’re doing, <a href="https://ubuntu.com/download/desktop">just use Ubuntu</a></strong>. It’s the most user friendly, widely supported, and easy to install.</p><p><a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux">Red Hat Enterprise Linux</a>, or RHEL, is a different distro which is used sometimes in heavy duty production servers. <a href="https://getfedora.org/">Fedora</a> is the desktop equivalent of RHEL - usually, developers aiming to run their applications on RHEL servers will use Fedora for their development computers, to avoid compatibility issues.</p><p><a href="https://alpinelinux.org/">Alpine</a> is a super minimal distro which is used for many Docker images. <a href="https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">Read our blog post about Docker for more information</a>.</p><h2 id="interfaces">Interfaces</h2><p>When people think of Linux, they usually associate it with a scary terminal (plus attached Anonymous hacker with a hoodie 👩‍💻).</p><p>Don't Panic – it’s not so scary! Today, it’s really easy to install Linux on a computer, with a regular GUI wizard, if you pick a distro that cares about that sort of thing (for example, Ubuntu).</p><p>We'll focus on terminals / shells in this lecture, since that is always available, and generally where "real work" is done. Production servers will rarely have GUIs. Don't let that discourage you - after you get used to it, using the shell can become much more convenient than GUIs!</p><figure><img src="https://dagshub.com/blog/content/images/2020/12/image.png" alt="The Wizard will now install your software."><figcaption>The Wizard will now install your software.</figcaption></figure><h2 id="basics">Basics</h2><p>The following actions are very basic file manipulation commands - moving, copying, deleting, viewing, etc.<br>I think there are enough sources online to learn these basic commands, and so I won't be re-explaining them here. Below the list, I provide my recommended way to learn about them, so don't worry!</p><ul><li>ls</li><li>mv</li><li>cp</li><li>rm</li><li>pwd</li><li>cd</li><li>mkdir</li><li>echo</li><li>cat</li></ul><p><strong>The most convenient way I found to learn about these commands, even if you don't have a Linux terminal available, is to follow these tutorials:</strong></p><ol><li><a href="https://www.webminal.org/terminal/">https://www.webminal.org/terminal/</a><br><strong>Do up to and including lesson 3.</strong><br>Webminal includes an interactive terminal in the browser, which you can play with and use for the next tutorial (which doesn't have an interactive shell, only text and quizzes).</li><li><a href="https://linuxjourney.com/lesson/the-shell">https://linuxjourney.com/lesson/the-shell</a></li></ol><h2 id="the-shell">The Shell</h2><p>The shell (AKA terminal) is itself a program! It's in charge of things like: </p><ul><li>Taking keystrokes from the user</li><li>Displaying text output to the user.</li><li>Remembering what directory you're in currently (changed using <code>cd</code>, shown using <code>pwd</code>)</li><li>Turning your commands into <strong>new</strong> <strong>running programs &nbsp;- processes,</strong> by sending appropriate messages to the kernel</li></ul><p>For example, what does the shell do when I type <code>python hello_world.py</code> and press enter?</p><ul><li>It's in charge of knowing where the actual program called "python" is located in the file system - probably something like <code>/usr/bin/python</code>. In the end, the kernel is the only thing that can run new programs, and it expects absolute paths to files.</li><li>I can check where the shell is actually finding "python" by running <code>which python</code>. &nbsp;The <code>which</code> command outputs the full path found by the shell. How does it know? More on that later, in the section on runnable scripts.</li><li><code>which</code> is a useful command! Maybe you have several conflicting versions of python installed, and you're not sure which one is actually running and giving you problems. <code>which python</code> to the rescue!</li><li>Or maybe I have some runnable script, and I want to edit, delete or rename it, but I forgot where it's located. <code>which</code> to the rescue!</li><li>So, what actually happens is that the shell tells the kernel program: "Please take the program file located at <code>/usr/bin/python</code>, and turn that into a new running process with a single argument <code>/absolute/path/to/hello_world.py</code> , running inside the current …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://dagshub.com/blog/effective-linux-bash-data-scientists/">http://dagshub.com/blog/effective-linux-bash-data-scientists/</a></em></p>]]>
            </description>
            <link>http://dagshub.com/blog/effective-linux-bash-data-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443415</guid>
            <pubDate>Wed, 16 Dec 2020 15:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442991">thread link</a>) | @woodruffw
<br/>
December 16, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442991</guid>
            <pubDate>Wed, 16 Dec 2020 14:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gloo Mesh Enterprise Beta Release – Solo.io Service Mesh Management Plane]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442825">thread link</a>) | @ilackarms
<br/>
December 16, 2020 | https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/ | <a href="https://web.archive.org/web/*/https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png" data-src="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png" alt="" width="1781" height="397" data-srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png 1781w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1024x228.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-768x171.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1536x342.png 1536w" data-sizes="(max-width: 1781px) 100vw, 1781px" srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png 1781w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1024x228.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-768x171.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1536x342.png 1536w"></p><p><span>From day one, our mission with Gloo Mesh has been to provide a service mesh command center that will give users indispensable features to manage a “glooed” together mix of environments, and today I am excited to announce that Gloo Mesh Enterprise is now available in Beta. We are asking the Gloo community and customers to <a href="https://lp.solo.io/request-trial">request a trial</a>, <a href="https://docs.solo.io/gloo-mesh/latest/">get started</a> and provide <a href="https://slack.solo.io/">feedback</a> via Slack on this latest Gloo Mesh Enterprise Beta so that our teams can continue to improve the features for its upcoming general availability. In addition, Gloo Mesh Enterprise has released its accompanying long term support for Istio, Istio on ARM and FIPS compliant Istio in general availability today with a license.&nbsp;</span></p><p><span>Originally launched in early 2019, Gloo Mesh (previously Service Mesh Hub) aims to provide organizations with a command center for all their service mesh needs, from a single cluster with Istio to stitching together and providing consistency for multiple clusters running different service meshes.&nbsp;</span></p><p><img src="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png" data-src="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png" alt="" width="7272" height="3440" data-srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png 7272w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-300x142.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1024x484.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-768x363.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1536x727.png 1536w" data-sizes="(max-width: 7272px) 100vw, 7272px" srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png 7272w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-300x142.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1024x484.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-768x363.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1536x727.png 1536w"></p><p><span>Some of the exciting features you will find in the Enterprise Beta release includes:</span></p><ul><li><b>A Single Pane of Glass for Every Service Mesh On Every Cluster – </b><span>Gloo Mesh helps users manage similar or mixed service meshes such as Istio and Open Service Mesh (originally from Microsoft) over multiple clusters.&nbsp;&nbsp;</span></li><li><b>Ability to Create a Virtual Mesh that Connects Multiple Clusters </b><span>–&nbsp; Join similar meshes, such as Istio, together in a virtual mesh that makes services discoverable and policies easy to manage anywhere, even across clusters. With Gloo Mesh Enterprise the promise of federated workloads is finally here!&nbsp;</span></li><li><b>Enhanced Security Across Your Mesh – </b><span>Gloo Mesh includes end-to-end security across clusters and meshes and forms a virtual, zero trust, mesh.&nbsp;</span></li><li><b>WebAssembly Modules to Increase Engineer Productivity </b><span>– Extend your service mesh control plane to allow developers to declaratively initialize, build, push, and deploy Wasm filters to Istio workloads over multiple clusters.&nbsp;</span></li><li><b>Easy User Management </b><span>– No more wrangling of users with complex RBAC permissions across clusters and meshes. With Gloo Mesh Enterprise you can now define a single user policy for your service mesh or virtual mesh, and propagate that policy to all your environments.&nbsp;</span></li><li><b>Simplified Failover and Traffic Polices</b><span> – Easy to define policies for service failover and traffic limits that are effortless to migrate throughout your service mesh environments.&nbsp;</span></li></ul><p><span>Istio Support Features:</span></p><ul><li><b>Long Term Enterprise Support for Istio</b><span> – Gloo Mesh enterprise license includes support for N-3 versions of Istio. This long term support aligns Istio support with the underlying Kubernetes cluster and gives organizations the peace of mind that break fixes, security patches, and other Istio issues will be fixed with the type of enterprise support they require.&nbsp;</span></li><li><b>Istio for ARM</b><span> – With new cloud providers releasing ARM instances that boost performance while decreasing cost, organizations’ ARM portfolio has become increasingly important and Solo.io has listened with ARM build.&nbsp;</span></li><li><b>Istio with FIPS – </b><span>&nbsp;Federal government agencies and those organizations serving them often need to comply with the Federal Information Processing Standard (FIPS-2) to maintain a minimum level of security. Solo.io has the option for FIPS-2 compliant build of Istio’s data plane.&nbsp;</span></li></ul><p><span>What’s Next for Gloo Mesh? The </span><span>Gloo Mesh team is working tirelessly on the new set of features based on what our customers and the community require in an Enterprise service mesh.&nbsp;</span></p><ul><li><span>Routing locality rules for cross cluster service failover and ability to access closest geographical workload – e.g. one housed on east coast cluster vs. Asia.</span></li><li><span>Upstream enhancements for Istio</span></li><li><span>Full AWS App Mesh Support</span></li><li><span>Metrics for a single or multiple clusters</span></li><li><span>Virtual Mesh that includes AppMesh and Istio in a single logical mesh.&nbsp;</span></li><li><span>Istio lifecycle management&nbsp;</span></li></ul><p><span>To learn more about the features in the Beta release of Gloo Mesh please see the</span> <a href="https://www.solo.io/products/gloo-mesh/"><span>website</span></a><span>, </span><a href="https://docs.solo.io/gloo-mesh/main/"><span>documentation</span></a><span> and the public </span><a href="https://github.com/solo-io/gloo-mesh"><span>Github</span></a><span>.&nbsp;&nbsp;&nbsp;</span></p><p>You can also read about Making Web Assembly a first-class citizen on Gloo Mesh Enterprise Beta <span><a href="https://www.solo.io/blog/making-web-assem%E2%80%A6-enterprise-beta/">blog.</a></span></p><p><span>You can request a free trial of Gloo Mesh today <a href="https://lp.solo.io/request-trial">here</a>. To connect, join the </span><a href="https://solo-io.slack.com/archives/CJQGK5TQ8"><span>#gloo-mesh</span></a><span> channel in the Solo.io Slack.</span></p></div></div></div>]]>
            </description>
            <link>https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442825</guid>
            <pubDate>Wed, 16 Dec 2020 14:26:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolarWinds leaked FTP credentials through a public GitHub repo since 2018]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25442734">thread link</a>) | @hackerpain
<br/>
December 16, 2020 | https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/ | <a href="https://web.archive.org/web/*/https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.savebreach.com/content/images/size/w300/2020/12/ss_solar.png 300w,
                            https://www.savebreach.com/content/images/size/w600/2020/12/ss_solar.png 600w,
                            https://www.savebreach.com/content/images/size/w1000/2020/12/ss_solar.png 1000w,
                            https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png" alt="SolarWinds Leaked FTP Credentials through a Public GitHub Repo &quot;mib-importer&quot; since 2018">
            </figure>

            <section>
                <div>
                    <h2 id="what-could-go-wrong-when-your-employees-commit-internal-information-to-public-github-repos">What could go wrong when your employees commit internal information to public GitHub repos? </h2><p>While <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">we were the first to report on the SolarWinds security vulnerability that possibly could have exposed their Downloads FTP server</a> credentials letting attackers to push malicious binaries and attack the US government and <a href="https://solarwinds.com/">SolarWinds</a>' other high profile clients, some more information has surfaced regarding the SolarWinds security vulnerability since then, that gives more insight into what possibly was exposed and whether it could have led to this massive breach of the US government. While majority of security researchers are of the opinion that this wasn't the main reason of the breach, and that there was a complex and sophisticated supply chain attack targeting <a href="https://solarwinds.com/">SolarWinds</a>, we believe<strong> these small security lapses could have given the attackers a larger attack surface to carry out their attacks</strong> and eventually might have helped strengthen their foothold into the SolarWinds infrastructure, to perform reconnaissance and evade detection.</p><h3 id="plain-old-ftp-to-the-blame">Plain old FTP to the blame?</h3><p>As per the screenshot posted by Vinoth, which we wrote about in our previous <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">post</a>, SolarWinds were possibly using unencrypted plain FTP server for their Downloads server in the age of global CDN technologies. However, not a direct attack vector its very likely that the FTP server had more vulnerabilities and unencrypted communication can always be intercepted, and modified. But we don't believe this maybe something as concerning as the FTP password leak.</p><h2 id="solarwinds-credentials-were-possibly-leaking-since-2018">SolarWinds Credentials were possibly leaking since 2018</h2><p>Security researcher Vinoth Kumar, told us that "SolarWinds had been possibly exposing the FTP credentials to the Download server since at least 2018". To corroborate his claim, Vinoth shared the the following link to the Configuration file exposed that was exposed in the mib-importer GitHub repo possibly belonging to a <a href="https://github.com/xkozus00">SolarWinds employee</a>, <a href="https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config">https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config</a> and he further added that, upon supplying the <a href="https://github.com/xkozus00/mib-importer">repo base url</a> to the Web Archive, it shows Web Archive had first archived the page back in June 2018, and that was the last time the page was archived. So we concluded that the credentials to the FTP server and other potentially sensitive information in that exposed repository possibly existed for more than 1 year in the public domain until Vinoth reported it to the SolarWinds PSIRT.</p><figure><img src="https://savebreach.com/content/images/2020/12/image-3.png" alt="" srcset="https://savebreach.com/content/images/size/w600/2020/12/image-3.png 600w, https://savebreach.com/content/images/size/w1000/2020/12/image-3.png 1000w, https://savebreach.com/content/images/2020/12/image-3.png 1411w" sizes="(min-width: 720px) 720px"><figcaption>Screenshot of the SolarWinds GitHub repository archived by Web Archive</figcaption></figure><p>This shows that SolarWinds might have been exposing their sensitive internal credentials since a fairly long time before it was brought to their notice, which in turn might have given its attackers an opportunity to steal certificates and other valuable internal information about SolarWinds to carry out the large scale attack against US government and other top organizations using the backdoored SolarWinds Orion software.</p><h2 id="the-mib-importer-github-repository">The mib-importer GitHub repository</h2><p>A "mib-importer" public GitHub repository, possibly belonging to a SolarWinds employee with secrets (like FTP username and password) exposed, was found on GitHub by the security researcher in November 2019, which is said to have existed from around June 2018</p><p>Upon analyzing, the SaveBreach team found out that SolarWinds Orion lets users import MIB files into it. MIB files are used for monitoring network devices. Apparently, the mib-importer tool was developed by SolarWinds to import MIB files into Orion. We found the following data from the <strong><a href="https://support.solarwinds.com/SuccessCenter/s/article/Add-MIBs-to-the-SolarWinds-MIB-database">SolarWinds documentation pages</a> </strong>regarding importing &nbsp;MIB files (Reference – <a href="https://support.solarwinds.com/SuccessCenter/s/article/Upload-MIB-in-Orion-Universal-Device-Poller">1</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">2</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">3</a>)</p><p><a href="https://documentation.solarwinds.com/en/Success_Center/orionplatform/Content/Core-Management-Information-Base--MIB--sw1730.htm">From SolarWinds website</a> – </p><blockquote>Management Information Base (MIB) is a structure that describes all objects a device can report on, such as CPU, fan, or temperature. MIB contains the name, datatype, and the object identifier (OID). MIB is a hierarchical structure, displayed as a navigation tree. Every entry in the MIB tree is a value for a specific component on a specific device.</blockquote><blockquote>SolarWinds maintains a MIB database that serves as a repository for the OIDs used to monitor a wide variety of network devices. The MIB database is updated regularly.</blockquote><h2 id="qa-with-cybersecurity-researcher-vinoth">Q&amp;A with cybersecurity researcher Vinoth</h2><p>From our most recent conversation with Vinoth, it appears that the credentials and possibly more sensitive data about SolarWinds was lying in public domain for a long time before finally being taken down. Vinoth doubts that the data might have also included certificates and not just FTP credentials, which was alone sufficient to sign the malicious binaries and upload them to the FTP server while passing off as legitimate software.</p><p><strong>Q: Since when do you think the GitHub repo might have been exposed? Do you think the attackers could have gained persistence into their infrastructure for almost 3 years to carry out the attack?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: I’m not sure, even on June 2018, 40 commits were there (in that repo). There was only one page available on archive couldn’t find anything else.</p><p><strong>Q: The Attackers had put signed binaries on the Download server. What was the process the attackers might have followed after getting access to the file upload server to sign the binaries?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: Not sure, but I could have missed checking the repo which could have had the certificate in it.</p><p><strong>Vinoth had tweeted that the GitHub repo was open to public since 17th June, 2018</strong></p><figure><blockquote data-width="550"><p lang="en" dir="ltr">That Github repo was open to the public since 17 Jun 2018 😱 <a href="https://t.co/SHUWaPXIeK">pic.twitter.com/SHUWaPXIeK</a></p>— Vinoth Kumar (@vinodsparrow) <a href="https://twitter.com/vinodsparrow/status/1338956534147993601?ref_src=twsrc%5Etfw">December 15, 2020</a></blockquote>

<figcaption>Tweet by Vinod about the web archived GitHub repository page</figcaption></figure><h2 id="certificates-used-to-sign-malicious-binaries-exposed-through-github-repo">Certificates used to sign malicious binaries exposed through GitHub repo?</h2><p>This raises many questions. Were the certificates used to sign the binaries obtained from that public GitHub repository or, from any other information leaked publicly? &nbsp;Exposed certificate could have allowed hackers to sign their malicious SolarWinds Orion binaries and pass them off as legitimate software developed by SolarWinds, subsequently uploading them to the Downloads server with the previously found leaked FTP credentials.</p><h2 id="was-this-how-solarwinds-got-hacked">Was this How SolarWinds got hacked?</h2><p>We can come to a partial conclusion that the internal information exposed on GitHub was there for a sufficiently long time for the attackers to have already exploited them to gain their initial foothold. Although unclear at this point, as there maybe a more sophisticated and complex attack chain with evasion techniques as being claimed by FireEye and security researchers, but we do feel this might have been a precursor to the SolarWinds breach and the widespread cyber attack against the US Government.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaveBreach | Cyber Security, Bug Hunting &amp; Domain Acquisitions</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442734</guid>
            <pubDate>Wed, 16 Dec 2020 14:19:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tig – Text-mode interface for Git]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 96 (<a href="https://news.ycombinator.com/item?id=25442510">thread link</a>) | @lemonspat
<br/>
December 16, 2020 | https://jonas.github.io/tig/ | <a href="https://web.archive.org/web/*/https://jonas.github.io/tig/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tig is an ncurses-based text-mode interface for git. It functions mainly
as a Git repository browser, but can also assist in staging changes for
commit at chunk level and act as a pager for output from various Git
commands.</p>
</div></div>]]>
            </description>
            <link>https://jonas.github.io/tig/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442510</guid>
            <pubDate>Wed, 16 Dec 2020 14:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting started with C]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 101 (<a href="https://news.ycombinator.com/item?id=25442165">thread link</a>) | @hdante
<br/>
December 16, 2020 | https://not.cafe/2020/10/12/getting-started-with-c-programming.html | <a href="https://web.archive.org/web/*/https://not.cafe/2020/10/12/getting-started-with-c-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <article>
    

  <h5>Posted at <time>2020-10-13 00:32+0000</time>
  
          , <em>last edit: <time>2020-12-14 18:47+0000</time></em>
  
  </h5>

  
  

  <p><span>!☕</span> This tutorial will guide you through writing the
“Hello World” program in the C programming language. You’ll use Unix-style terminal
emulators and command-line tools to execute commands, Linux-style package managers to
install programs and libraries, the GNU nano text editor to write C code, the meson build
system to build executable programs and the Gtk+ library to write portable, cross-platform
graphical programs.</p>

<figure>
  <a href="https://commons.wikimedia.org/wiki/File:Ken_Thompson_(sitting)_and_Dennis_Ritchie_at_PDP-11_(2876612463).jpg" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg/599px-Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg" alt="Ken Thompson (sitting) and Dennis Ritchie at PDP-11">
  </a>
  <figcaption>
    <a href="https://en.wikipedia.org/wiki/Dennis_Ritchie" target="_blank">
    Dennis Ritchie
    </a> (standing), the creator of the C programming language, with
    <a href="https://en.wikipedia.org/wiki/Ken_Thompson" target="_blank">Ken Thompson</a>, the
    creator of Unix. Ken is using a
    <a href="https://en.wikipedia.org/wiki/Teleprinter" target="_blank">teletypewriter</a>
    (known as a tty on Unix) typewriter-style
    <a href="https://en.wikipedia.org/wiki/Computer_terminal" target="_blank">physical terminal</a>.
    Behind is the <a href="https://en.wikipedia.org/wiki/PDP-11" target="_blank">DEC PDP-11</a>
    minicomputer.
  </figcaption>
</figure>

<p>Instructions&nbsp;for&nbsp;three operating systems are provided: macOS, Ubuntu Linux and
Windows. The selected tools are personal favorites and were hand picked to allow the
fastest development and to allow identical development flows (and thus seamless
environment switching) on the three operating systems. All tools used in this tutorial are
<a href="https://en.wikipedia.org/wiki/Free_and_open-source_software" target="_blank">free, open source software</a>
and can be downloaded and used without any issues. No programming experience is required,
as this tutorial is for absolute beginners.</p>

<h3 id="before-we-start-terminals">Before we start: terminals</h3>

<p>There are a few notes for absolute beginners that will make our path easier and faster to
understand: to stay short, the tutorial will only guide through the setup process, but
will not teach the C language; references for next steps will be given at the end; some
program downloads may be large and take some time.</p>

<p>Programming languages and textual commands are very different from spoken languages:
programs must be written in a very strict way. Miss a comma and the program will stop
working. The most important rule for a beginner is that the C language, like most other
programming languages, is case sensitive, that is, upper case letters are considered
distinct from lower case letters and one can’t be swapped for the other. Keep this in mind
when typing the code and when in doubt copy and paste it to make sure all symbols are
correctly written.</p>

<figure>
  <a href="https://www.sydney.edu.au/science/psychology/pdp-11/terminals.html" target="_blank">
    <img src="https://not.cafe/assets/2020/terminals.jpeg" alt="PDP-11 terminals">
  </a>
  <figcaption>
    The <a href="https://en.wikipedia.org/wiki/VT52#VT55" target="_blank">DEC VT55</a>
    (display-style terminal, left side), the
    <a href="https://en.wikipedia.org/wiki/DECwriter" target="_blank">DECwriter</a>
    (dot-matrix printer-style terminal) and the
    <a href="https://en.wikipedia.org/wiki/Teletype_Model_33" target="_blank">Teletype ASR-33</a>
    (typewriter-style terminal).
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the terminal emulator application to type textual commands. I’ll
succintly explain what each command does and will show each command written after a dollar
sign. The dollar sign represents the terminal emulator’s prompt symbol, and that’s the
usual symbol that the command line input program, called the shell, displays when waiting
for a command. For example:</p>

<pre><code>$ ls -l
</code></pre>

<p>In the above example, we type after the prompt symbol: <code>ls[space][minus]l</code>, then press
<code>[enter]</code> to execute. In this example, we execute the <code>ls</code> program (list directory) with
the <code>-l</code> parameter (a specific parameter for the program, changes the output mode to long,
or more descriptive). Same example, but also showing the resulting output in my computer:</p>

<pre>$ ls -l
total 7344
-rw-r--r-- 1 hdante users    9999 set 19 19:12 coffee-34251.svg
-rw-r--r-- 1 hdante users     347 set 19 19:12 coffee-34251.svg.license
-rw-r--r-- 1 hdante users   16805 set 19 19:12 favicon.ico
-rw-r--r-- 1 hdante users    3253 set 19 19:12 favicon.svg
-rw-r--r-- 1 hdante users   11665 out  2 18:49 index.html
-rw-r--r-- 1 hdante users   17833 set 19 19:12 not-coffee.svg
-rw-r--r-- 1 hdante users 2372085 set 19 19:12 radio.caf
-rw-r--r-- 1 hdante users 2656465 set 19 19:12 radio.mka
-rw-r--r-- 1 hdante users 2401864 set 19 19:12 radio.opus
-rw-r--r-- 1 hdante users    3263 out  2 16:48 site.css
-rw-r--r-- 1 hdante users    2166 set 19 19:12 square.svg
$ </pre>

<p>So,&nbsp;after&nbsp;running the <code>ls</code> program with the <code>-l</code> parameter, it shows the long
description of current directory and another dollar symbol appears at the end, it’s
waiting for a new command. Don’t worry about understanding this example, I’ll also add
references at the end for learning more about using Unix-style command-line tools.</p>

<h3 id="installation">Installation</h3>

<figure>
  <a href="https://not.cafe/assets/2020/macos-terminal-app.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/macos-terminal-app.jpeg" alt="macOS Terminal App">
  </a>
  <figcaption>
    The
    <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)" target="_blank">
    macOS Terminal.app
    </a> is a
    <a href="https://en.wikipedia.org/wiki/Terminal_emulator" target="_blank">terminal emulator</a>.
    Modern terminals are software that emulate physical terminals.
  </figcaption>
</figure>

<p>Different&nbsp;procedures&nbsp;are required for each operating system. Pick the best one
for you. After installing, writing and running code will work the same way. We’ll write a
single cross-platform program that works on all three systems and build it using the same
cross-platform build tools.</p>

<h4 id="macos">macOS</h4>

<p>For macOS, only the terminal emulator comes installed with the operating system. The Apple
provided C compiler is the
<a href="https://en.wikipedia.org/wiki/Clang" target="_blank">LLVM clang compiler</a>,
contained in the “Xcode command line tools” package. To install it, open the Terminal
application by opening the Spotlight search input, then typing Terminal (or find it in the
Utilities folder inside Applications). In the terminal emulator, type:</p>

<pre><code>$ xcode-select --install
</code></pre>

<p>The Xcode installation program will start. Follow the instructions that will appear and in
the end, the LLVM clang C compiler will be installed. You can check if it’s working by
executing it with the <code>--version</code> parameter:</p>

<pre><code>$ clang --version
</code></pre>

<p>For installing packages like build tools, text editors and libraries, we’ll install the
<a href="https://en.wikipedia.org/wiki/Homebrew_(package_manager)" target="_blank">Homebrew package manager</a>,
which is the main Linux-style package manager for macOS. The package manager allows
single-command installing, configuring, upgrading and removing of packages from the
command line. Go to <a href="https://brew.sh/" target="_blank">brew.sh</a> and access the
instructions there, or simply execute this command to download and install it:</p>

<pre><code>$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
</code></pre>

<p>Notice that this command is already more complex than the previous ones, downloading and
executing the install script from the Homebrew source code repository, and gives a hint on
the power and efficiency of the command line. Don’t worry trying to understand it, we’re
installing Homebrew exactly to make it easy to execute complex package installations.
[<strong>edit 20201214</strong>: It might be necessary to restart the Terminal App and configure the
search path after installing <code>brew</code> to be able to use it. When in doubt, check the
<a href="https://docs.brew.sh/">Homebrew documentation</a>.]</p>

<p>Now that Homebrew is installed, you may install packages with <code>brew install</code> and search
packages with <code>brew search</code>. Search and install the GNU nano text editor with:</p>

<pre><code>$ brew search nano
$ brew install nano
</code></pre>

<h4 id="linux">Linux</h4>

<figure>
  <a href="https://not.cafe/assets/2020/gcc-on-ubuntu.png" target="_blank">
    <img src="https://not.cafe/assets/2020/gcc-on-ubuntu.png" alt="gcc on Ubuntu">
  </a>
  <figcaption>
    Installing gcc on Ubuntu Linux.
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the apt package manager available in
<a href="https://ubuntu.com/" target="_blank">Ubuntu Linux</a> from the Debian family, but
other Linux distributions using, for example,
<a href="https://www.redhat.com/sysadmin/how-manage-packages" target="_blank">yum</a>,
<a href="https://docs.fedoraproject.org/en-US/quick-docs/dnf/" target="_blank">dnf</a>,
<a href="https://wiki.archlinux.org/index.php/Pacman" target="_blank">pacman</a>,
etc. will work in pretty much the same way. On Linux the
<a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a>
usually comes preinstalled, so we’ll use it instead of clang, but they work the same way.
Open a terminal by clicking the activities menu on the top left of the screen and writing
terminal in the search input (or click on the terminal icon in the favorites bar). In the
terminal emulator, write:</p>

<pre><code>$ sudo apt-get install gcc
</code></pre>

<p>Ubuntu Linux and most other distributions require switching to administrator (root) mode
to install programs, so we use the <code>sudo</code> program to execute <code>apt-get</code> in root mode (you
may also use the <code>su</code> program, if <code>sudo</code> is not installed). Type your password and follow
the instructions. In the end, check gcc:</p>

<pre><code>$ gcc --version
</code></pre>

<p>You may install packages with <code>sudo apt-get install</code> and search packages with <code>apt-cache
search</code>:</p>

<pre><code>$ apt-cache search nano
$ sudo apt-get install nano
</code></pre>

<p>For other Linux distributions, use the appropriate package manager:</p>

<pre><code>$ yum search nano         # for RedHat Linux/CentOS
$ sudo yum install nano   # for RedHat Linux/CentOS
</code></pre>

<h4 id="windows">Windows</h4>

<figure>
  <a href="https://www.msys2.org/" target="_blank">
    <img src="https://not.cafe/assets/2020/msys2-website.jpeg" alt="MSYS2 website">
  </a>
  <figcaption>
    <a href="https://www.msys2.org/" target="_blank">MSYS2 website</a>. MSYS2 is a
    toolkit for Windows development that contains Unix-style tools.
  </figcaption>
</figure>

<p>For Windows we’ll use the
<a href="https://en.wikipedia.org/wiki/Mingw-w64#MSYS2" target="_blank">MSYS2 toolkit</a>,
which provides a terminal emulator, the pacman package manager and a complete set of
Unix-style command line tools. Download the MSYS2 installer from
<a href="https://www.msys2.org/" target="_blank">www.msys2.org</a> and follow the
instructions to install the package. When installed, MSYS2 will provide three sets of
programs, which are selected whenever opening the terminal emulator. They are called the
MSYS2 shell, the MINGW64 shell (pronounced mingwee 64) and the MINGW32 shell. The MINGW64
shell is the appropriate one to develop Windows programs. The MSYS2 is appropriate for
managing MSYS2 itself and the MINGW32 is the 32-bit version that shouldn’t be used
anymore. After installing MSYS2 it’s necessary to immediatelly upgrade it. Open the MSYS2
shell and type:</p>

<pre><code>$ pacman -Syu
</code></pre>

<p>Follow the instructions and if requested restart the terminal emulator. On Windows we’ll
use the <a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a> C
compiler (gcc):</p>

<pre><code>$ pacman -S mingw-w64-x86_64-toolchain
</code></pre>

<p>After installing, to test gcc, you must use a MINGW64 shell. If you’re running the MSYS2
shell for executing pacman, open another terminal running the MINGW64 shell and type:</p>

<pre><code>$ gcc --version
</code></pre>

<p>From now on, we’ll assume that the MINGW64 shell is being used. Notice that pacman runs
normally both on MSYS2 and MINGW64 shells. You may install packages with <code>pacman -S</code> and
search packages with <code>pacman -Ss</code>:</p>

<pre><code>$ pacman -Ss nano
$ pacman -S nano
</code></pre>

<h3 id="hello-world-">Hello, World !</h3>

<figure>
  <a href="https://not.cafe/assets/2020/nano-on-macos.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/nano-on-macos.jpeg" alt="GNU nano on macOS">
  </a>
  <figcaption>
    Writing the Hello World program using GNU nano on macOS.
  </figcaption>
</figure>

<p>After installing the compilers, remember installing the
<a href="https://en.wikipedia.org/wiki/GNU_nano" target="_blank">GNU nano</a> text editor:</p>

<pre><code>$ brew install nano    # (or apt-get, or pacman)
</code></pre>

<p>Now, let’s create a new root directory to store this project and all future code:</p>

<pre><code>$ mkdir code
$ cd code
</code></pre>

<p>The first command above creates a new directory called <code>code</code>. If it already exists, it
will complain. Change the name if you prefer something else. The second command changes
the current directory to the <code>code</code> directory (the current directory is the directory used
when file operations specify file names without …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://not.cafe/2020/10/12/getting-started-with-c-programming.html">https://not.cafe/2020/10/12/getting-started-with-c-programming.html</a></em></p>]]>
            </description>
            <link>https://not.cafe/2020/10/12/getting-started-with-c-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442165</guid>
            <pubDate>Wed, 16 Dec 2020 13:21:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiments on a $50 DIY air purifier that takes 30s to assemble]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 141 (<a href="https://news.ycombinator.com/item?id=25442097">thread link</a>) | @dyno-might
<br/>
December 16, 2020 | https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 15, 2020</strong></p>
            
            



<p>Bad air is bad for you. The air purifier market, though, is a mess. Every purifier uses incompatible proprietary filters, presumably to lock you into buying replacements. How do we know these actually work? Few seem to publish lab tests. And why does it cost $100-$300 for a big plastic box with a fan and a filter inside?</p>

<p>It’s common to build DIY air purifiers by basically strapping a filter to a fan. I like the idea of these, but again, it’s hard to be confident they really work. There’s a few experiments out there, but not enough to make me comfortable. So I decided to do some experimenting of my own. I made a purifier, generated smoke, and measured how well it removes tiny particles.</p>



<p>If you’re in a hurry, this post says that if you strap two HEPA filters to a box fan, it will clear the air of basically all the particles we can measure, and it will do it faster than a commercial filter that costs twice as much.</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="in a large room the DIY filter does slightly better than the commercial filter"></p>



<h3 id="diy-purifier">DIY purifier</h3>

<p>My DIY purifier was <em>very</em> simple. (I don’t want to promote any particular brands here. Contact me if you want the exact products.)</p>

<ul>
  <li>A standard box fan. (Cost: $19)</li>
  <li>Two HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick. (Cost: $35 for both)</li>
  <li>A bungie cord. (Cost: Free)</li>
</ul>

<p>Assembly takes about 30s. You put the filters on the intake side of the fan and strap them on with the bungie cord. Here’s a picture:</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_notape.jpg" alt="DIY purifier" max-width="60%" min-width="35%"></p>

<p>Timeless elegance and grace, it is not. I get the shakes just looking at that bit of crinkled filter.</p>

<h3 id="commercial-purifier">Commercial purifier</h3>

<p>As a comparison, I got a $100 air purifier from a well-known brand that’s intended for small rooms. It uses uses a single HEPA filter that’s about 25cm x 12cm and 4cm thick. Replacement filters currently cost around $25.</p>

<h3 id="smoke">Smoke</h3>

<p>It’s surprisingly hard to repeatedly generate a consistent amount of smoke. I tried burning various things (paper, cardboard) and found that the number of particles generated can vary by an order of magnitude, depending on the burn pattern. This is difficult to control and effectively random.</p>

<p>Ideally, I’d have liked to burn some food product like oil, since the kitchen is usually the biggest source of indoor air pollution. I couldn’t figure out a good way of doing this, either: You’d need to have the same amount of oil distributed in the same way and heated to the same temperature.</p>

<p>I finally settled on using incense. I cut sticks to the length of a standard credit card and then attached the ends horizontal to the ground. This seemed to be pretty consistent. In retrospect, I bet that burning toast in a toaster would work well. (I didn’t have one on hand.)</p>

<h3 id="measurements">Measurements</h3>

<p>I borrowed a cheap-ish ($100) air quality monitor from a friend. I think it’s made by some company in China and then re-sold by various white-label brands. I can’t figure out who the original manufacturer is. Based on data I’ve seen for the reliability of other air quality monitors, I wouldn’t trust the absolute numbers, but the I think the <em>relative</em> measurements should still be OK.</p>

<p>The typical measurement for particulate pollution is “PM 2.5” which is in units of μg/m³. This is intended to measure what you’d get if you did the following:</p>
<ul>
  <li>Take a cubic meter of air.</li>
  <li>Filter all the solid particles out of the air.</li>
  <li>Keep only the solid particles that are are 2.5 micrometers (μm) or smaller.</li>
  <li>Weigh all the particles you kept in micrograms (μg).</li>
</ul>

<p>Here are some ways to interpret these numbers:</p>
<ul>
  <li>The EPA says yearly averages should be below 12 and daily averages below 35.</li>
  <li>The average outdoor level ranges from 6 in Finland to almost 100 in Nepal. Rich countries are typically under 15. The highest levels are typically found in Asia and Africa.</li>
  <li>Cooking can easily cause PM 2.5 measurements to spike into the hundreds. I’ve observed myself that this can happen with only a small amount of visible smoke.</li>
</ul>

<h3 id="logging">Logging</h3>

<p>Since the air quality monitor doesn’t log data, I used an ultra-hacky alternative: I set the monitor next to a laptop running a stopwatch. I then aimed a tabet at both of those screens and took a timelapse video. Finally, I manually transcribed the data by going to each minute marker in the data. (This was even more tedious than it sounds.)</p>



<p>I ran a first experiment in a tiny room of around 8 ㎥. Due to worries that wind from the purifiers might change the speed the incense burned, I placed it on the opposite side of a wall, with a gap of around 20 cm near the ceiling.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_tinyroom.jpg" alt="tiny room setup"></p>

<p>I repeated the experiment once with no filter, once with a commercial filter, and once with the DIY filter. Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_linear.jpg" alt="smallroom measurements in linear space"></p>

<p>Things are a bit random around the beginning, probably due to the drifting of the smoke before it’s equalized in the room. With no filter at all, this spikes all the way to 1000 μg/m³, the maximum the instrument can show.</p>

<p>If we make the y-axis logarithmic, it becomes quite clear that the DIY filter is cleaning the air at a better rate. (This is the picture from the top of this page.)</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="smallroom measurements in log space"></p>

<p>If we take the EPA’s threshold of 12 μg/m³, the DIY filter gets there in around 15 minutes, while the commercial filter take around 25 minutes.</p>



<p>Thankfully, I don’t spend most of my time in an 8 ㎥ room. Thus, I repeated the experiment in a large room of around 100 ㎥. Here there was no wall between incense and purifier. Instead I left around a meter of distance between the incense and purifier and the purifier and the monitor.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_largeroom.jpg" alt="large room setup"></p>

<p>Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_linear.jpg" alt="large room measurements in linear space"></p>

<p>There’s even more randomness around the beginning, probably just due to how the smoke drifts around. Based on the room volume we’d expect a peak concentration with no filter of around 80 μg/m³ = 1000 μg/m³ * (8/100). Reassuringly, this is pretty close to what we see.</p>

<p>The DIY purifier looks a bit better. If we plot in log space, it’s more clear that it is indeed filtering at a better rate:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_log.jpg" alt="large room measurements in log space"></p>



<p>It’s common advice for DIY purifiers like this to seal around the edges of the filter so that all air must pass through it.  I share the intuition that this would help, but it’s hard to be sure: If you block airflow, you slow down the fan. This could be counterproductive.</p>

<p>In this case at least, experiment is easier than theory. I took packing tape and carefully sealed around the intake side.</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_tape.jpg" alt="DIY purifier with tape" max-width="60%" min-width="35%"></p>

<p>And the results are…</p>

<p><img src="https://dyno-might.github.io/img/purifier/taping.jpg" alt="taping around the filter has no effect"></p>

<p>…nothing!?</p>

<p>This was unexpected. I thought the tape would help, but I wouldn’t have been surprised if it hurt instead. Instead, there’s basically no difference at all. I don’t know enough about fluid dynamics to even speculate about what’s happening here, so I won’t try.</p>

<p>There could be some weird quirk in how I ran this experiment. This doesn’t necessarily mean that all the advice to tape around the filter is <em>wrong</em>. However, I’ve never seen any experriments that show taping helps either.</p>



<p><strong>Cost.</strong> The DIY purifier isn’t dramatically cheaper than the commercial one, but I expect the filters would need to be replaced much less often. The commercial purifier uses a single filter with an area of 300 cm², whereas the DIY purifier uses two filters with a total area of around 1400 cm², and also slightly thicker. It’s reasonable to assume the DIY filters could remove ~4 times as many particles before replacement.</p>

<p><strong>Durability.</strong> One concern is that box fans aren’t meant to be used with filters attached and could wear out. This is reasonable. However, box fans are much cheaper than commercial purifiers, and I’ve been using this particular fan with various filters attached for several years now without issue.</p>

<p><strong>Electricity.</strong> The cost of electricity is another factor. Typical box fans seem to use around 55W, whereas commercial purifiers typically use 30-45W. If electricity costs $0.13 / kWh, the box fan would cost around $62 to operate 24 hours a day for a year, while a 30-watt purifier would cost around $34. Obviously, these numbers decrease if you run the purifier less. Some (more expensive) commercial purifiers have air quality sensors built in and automatically turn on only when needed.</p>

<p><strong>MERV or HEPA?</strong> Most people who build box-fan purifiers use <a href="https://en.wikipedia.org/wiki/Minimum_efficiency_reporting_value">MERV</a>-rated filters intended for furnaces. Commercial air purifiers use <a href="https://en.wikipedia.org/wiki/HEPA">HEPA</a>-rated filters. Roughly speaking, HEPA filters are “better” in that they are rated to remove a higher percentage of particles in one pass. It’s not clear that HEPA filter will actual perform better when attached to a fan, though: A filter that catches fewer particles in one pass might still be better if it allows for faster airflow.</p>

<p><strong>That one video.</strong> If you’re reading this article after it was linked from some forum, I’d bet you that someone in the comments links to <a href="https://www.youtube.com/watch?v=kH5APw_SLUU">this video</a> from the Michigan Sinus Center. I found this inspirational, but note a couple of things: First, while the description says they use HEPA filter, the video clearly indicates a MERV filter. Again, that’s not necessarily bad! They claim that around 90% of particles sized 0.3 microns are larger are eliminated in a single pass. That’s good, but not totally reassuring. The question is, does it remove 99% in two passes? If 90% of the particles in the ambient air were large and the filter only catches large particles, then additional passes would never get rid of the most dangerous small particles. This is why I trust HEPA filters a bit more: since they remove almost all particles in one pass, I’m confident they should remove almost all particles eventually. This is also why I strongly prefer experiments that actually measure particles removed from the air in a room, rather than just the air coming out of the purifier.</p>

<p><strong>Further questions.</strong> There’s a lot of things that further experiments could look at:</p>

<ol>
  <li>Does the fan speed make a huge difference?</li>
  <li>How does the purifier compare to larger commercial purifiers?</li>
  <li>How do MERV-rated furnace-type filters compare under the same conditions?</li>
  <li>How can it not matter if there’s tape around the filters!?</li>
  <li>Does fan speed matter? (I always ran the box fan at maximum speed.)</li>
  <li>Is it better to put the filters on the intake or outtake side of the …</li></ol></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</a></em></p>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442097</guid>
            <pubDate>Wed, 16 Dec 2020 13:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For e-mobility 2020 brought significant progress, this is an extensive overview]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25441956">thread link</a>) | @Pabloemm
<br/>
December 16, 2020 | https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;The growing concept of e-Mobility as a Service
                </p>

                

                <h2 id="research-explanation">Research explanation of e-Mobility as a
                    Service</h2>

                <h3 id="emergence-of-emobility">Emergence of mobility concepts</h3>

                <p>
                    Before the digital revolution and user-centric approach, the concept of accessible, new forms of
                    transportation was the future vision of what life could be like. With the rapid growth of
                    technology, mobile devices, enhanced battery capacities, wide Internet connection, investments in
                    new unexplored forms of service delivery, and quick social adaptation in the last ten years we have
                    witnessed a great transformation.
                </p>
                <p>
                    Raising enthusiasm boosted consumption and proved that rapid adaptation is possible and widely
                    accepted. New economic models have begun to take into account sharing concepts and value the
                    tangible benefits of such solutions. In a sharing economy, not used assets such as parked cars and
                    extra bedrooms can be rented out. We transferred from owning to renting. And this concept widely
                    approved first by Uber users moved to other transport areas offering new possibilities. In the
                    Alternative Journal article,
                    <a href="https://www.alternativesjournal.ca/science-and-solutions/ours-better-yours" target="_blank" rel="nofollow">
                        ‘Ours is Better than Yours’
                    </a>
                    , Ray Tumulty (2014) the sharing economy is
                    described as a clearly urban phenomenon. To achieve economies of scale for shared economy services
                    satisfactory population density is required. Moreover, these services are seen as an extra option,
                    not a replacement for traditional sectors. Ridesharing is used along with public transportation in
                    cities.
                </p>
                <p>
                    With the growing success of rented items and services, new forms of transportation options come to
                    the market. The mobility concept grew to form a comprehensive ecosystem offering numerous moving
                    variants, such as city bikes, electric scooters, car rides, ticket purchasing options, city traffic
                    monitoring, planning the most convenient route, parking options, integrated payments, and available
                    charging options for ‘e’ users. All available in real-time from the mobile app on one’s phone. This
                    progress developed the term
                    <a href="https://solidstudio.io/blog/from-maas-to-emaas-how-e-is-taking-a-charge-over-the-markets.html" target="_blank" rel="nofollow">
                        Mobility as a service
                    </a>
                    , which covers a wide range of mobility services
                    available on the market, and its integral part becomes a shared economy providing extra value for
                    participants.
                </p>
                <p>
                    On a high-level, the MaaS ecosystem includes transport infrastructure, transportation services,
                    transport information, and payment services. Within the ecosystem, the common objective is the
                    delivery of a seamless mobility experience and transportation network improvement by utilizing the
                    benefits of each service - public and private. Besides, other participants such as local authorities
                    or data administration companies can collaborate to smooth the operation of the services and improve
                    their profitability.
                </p>
                <p>
                    MaaS as a definition is described as
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/6.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>
                <p>
                    One of the MaaS ecosystem examples was presented by the Siemens Mobility Division in 2016 for
                    Tampere City, Finland. The ecosystem is build of 4 main elements: service providers; a
                    business-to-business (B2B) platform; mobility retailers; and the users. The intention of the project
                    was to unite the existing and upcoming transport services with the operations of the local
                    paratransit services.
                </p>
                <p>
                    A similar approach on a high level was presented by König project ‘Mobility As A Service for Linking
                    Europe’. Four different levels define the public and regulatory level, the transport and logistics
                    service providers level, the mobility service level, and the end-user level. On the basis of similar
                    concepts and definitions, a framework for Mobility as a service was developed.
                </p>
                <p>
                    From a business perspective, MaaS is described by Kamargianni and Matyas in the paper ‘The Business
                    Ecosystem of Mobility-as-a-Service’[1](2017) as ‘the wider network of enterprises that influences how a
                    dominant company, in this case, the MaaS provider, creates and capture value’.
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/7.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    To support theoretical premises on shared mobility, a survey conducted by McKinsey&amp;Company (2017)
                    provides some insight into the consumer’s opinion on ride-hailing and car-sharing. Respondents were
                    asked how their usage of ride-hailing and car-sharing services will change within the next two
                    years. In both cases, over 60% responded that it will increase or increase significantly. Shared
                    mobility is mostly favored in urban areas, but seems to be less attractive for running errands or
                    multi-stop shopping trips.
                </p>

                <h3 id="what-is-e">What is ‘e’ all about?</h3>

                <p>
                    We are an integral part of the next global transformation, where alternative fuels and green energy
                    takes charge. The concept explained above has been extended with ‘e’ - a possibility to travel in an
                    eco-friendly way, where ‘e’ stands for electric solutions.
                </p>
                <p>
                    Electric Mobility as a service combines Mobility as a Service (MaaS), Electric Mobility Systems
                    (EMS), and Shared Electric Mobility Services (SEMS) [2]. As a concept eMaaS operates upon MaaS,
                    where the last one became one of the complementary components. With that defined, all MaaS
                    participants become, as a consequence, eMaaS attendees. Providing they offer electric mobility
                    solutions.
                </p>

                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/8.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    Electric Mobility System (EMS) covers technologies (batteries, charging technologies, drivetrains,
                    and EVs), infrastructure (physical and organizational of charging stations, electricity grid,
                    information and communication technology), and users (manufacturers, suppliers, end-users, service
                    providers, governments, and agents).
                </p>
                <p>
                    Shared Electric Mobility Services’ (SEMS) applies to a new economy implementation, where instead of
                    ownership there is an on-a-need basis share connected by the technology with users and providers.
                    SEMS replies to the environmental, social, financial, and transportation-related benefits that had
                    already been correlated to emobility and shared mobility practice connecting both. Five business
                    approaches are proposed:
                </p>
                <ul>
                    <li>
                        Membership-based (e.g. e-bike sharing, e-car sharing, e-ridesharing, e-ride hailing, e-scooter
                        sharing, e-bus sharing),
                    </li>
                    <li>
                        Peer-to-Peer(e.g. e-car sharing, e-bike sharing, e-scooter sharing),
                    </li>
                    <li>
                        Non-membership-based (e.g. e-car rental, elimousine rental),
                    </li>
                    <li>
                        For-hire (e.g. e-car/bike/scooter sharing, e-ridesharing e-carpooling),
                    </li>
                    <li>
                        Mass transit systems (e.g. e-Public Transport, airport autonomous shuttles).
                    </li>
                </ul>
                <p>
                    As a part of a wider concept, combined with two other components MaaS &amp; EMS, together provides
                    multiple eco-friendly transportation possibilities. Successful implementation of such a concept
                    requires multi-level support, well-designed system architecture, and an extensive network in public
                    structures.
                </p>

                <h3 id="user-centric">User-centric approach</h3>

                <p>
                    The user-centric approach will always be foreground. It applies to the development of the widely
                    recognized concept of e-mobility as a service. From accessible payment methods for single ticket
                    purchasing, subscriptions, to well-developed charging networks and various means of transport
                    access. At each stage of the proposition should be declared value.
                </p>
                <p>
                    We are still in the early stages of what could be called e-Mobility as a service. Most customer
                    journeys are under development, and achieving overall flow is still in its infancy. There is a lot
                    of research to be done, but there is room for the general necessary approaches. Each of the
                    participants, in order to achieve success and remain successful in this growing market, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</a></em></p>]]>
            </description>
            <link>https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441956</guid>
            <pubDate>Wed, 16 Dec 2020 12:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PerceptiLabs – A simple tool to build machine learning models]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25441955">thread link</a>) | @Xubeqi
<br/>
December 16, 2020 | https://perceptilabs.com/product | <a href="https://web.archive.org/web/*/https://perceptilabs.com/product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-b80770e6=""><div xs="12" data-v-b80770e6=""> <p data-v-b80770e6="">
          PerceptiLabs is a dataflow driven, visual API for TensorFlow,
          carefully designed to make machine learning (or deep learning)
          modeling as intuitive as possible.
        </p></div></div></div>]]>
            </description>
            <link>https://perceptilabs.com/product</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441955</guid>
            <pubDate>Wed, 16 Dec 2020 12:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: ThinkType – Write and Search Notes at the Same Time]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25441662">thread link</a>) | @amadeuspagel
<br/>
December 16, 2020 | https://thinktype.app/resubmit | <a href="https://web.archive.org/web/*/https://thinktype.app/resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thinktype.app/resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441662</guid>
            <pubDate>Wed, 16 Dec 2020 12:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a crate for creating interactive chord diagrams in Rust]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25440590">thread link</a>) | @DataCrayon
<br/>
December 16, 2020 | https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]</pre>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440590</guid>
            <pubDate>Wed, 16 Dec 2020 09:31:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elderly patients 23% more likely to die if surgery is on the surgeon’s birthday]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 208 (<a href="https://news.ycombinator.com/item?id=25440322">thread link</a>) | @whx23
<br/>
December 16, 2020 | https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5563" role="main"><div><div><div><p>A <a href="https://www.bmj.com/content/371/bmj.m4381" target="_blank" rel="noreferrer noopener">new study has found</a> that elderly patients who underwent emergency surgery on their surgeon’s birthday had significantly higher 30-day mortality rates than patients whose surgery took place on any other day of the year. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The 30-day mortality rate (defined as death within 30 days after surgery)&nbsp;for the “surgeon’s birthday” group was 6.9%. This was 23% higher than the 5.6% rate for the “other day” group.</p><p>The study, which appears today in the <em>British Medical Journal</em> (<a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener">BMJ</a>),&nbsp;looked at 980,876 procedures performed in US hospitals by 47,489 surgeons.&nbsp;Of those procedures, 2,064 (0.2%) took place on a surgeon’s birthday.&nbsp;The patients were all Medicare beneficiaries aged 65 to 99. They had all undergone one of 17 common emergency surgical procedures between 2011 and 2014.</p><h2>Distractions during the most common emergency surgery types</h2><p>Examples of those 17 procedures included cardiovascular surgeries, hip and femur fracture, appendectomy, and small bowel resection. The study focused on&nbsp;emergency surgery, so as to&nbsp;minimize the potential selection bias. For example, surgeons might otherwise choose patients based on their illness severity, or patients might choose their surgeon.</p><p>As the authors write, “The effect size of surgeons’ birthday observed in our analysis (1.3 percentage point increase or a 23% increase in mortality), though substantial, is comparable to the impact of other events, including holidays (e.g., Christmas and New Year) and weekends.” <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>In fact, the <a href="https://amzn.to/3m5rimG" target="_blank" rel="noreferrer noopener">history of surgery</a> has often demonstrated that external factors can influence surgical outcomes. The authors refer to a 2014 study showing that <a href="https://pubmed.ncbi.nlm.nih.gov/23345314/" target="_blank" rel="noreferrer noopener">patients admitted to Scottish emergency rooms on&nbsp;public holidays had a 27% increase</a> in 30-day mortality.&nbsp;Other research has found, for example,&nbsp;that doctors are more likely to <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1910546" target="_blank" rel="noreferrer noopener">prescribe antibiotics</a> and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2749268" target="_blank" rel="noreferrer noopener">opioids</a> — and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733171" target="_blank" rel="noreferrer noopener">less likely to order&nbsp;cancer screening tests</a> — as the workday progresses. This is most likely because the “cumulative cognitive demand” of such decisions gradually takes its toll.&nbsp;</p><p>Research on judges has yielded similar results. It has found, for example, that external factors as diverse as outdoor temperatures and sports results can influence judges’ decisions.&nbsp;</p><h2>A natural experiment: ER surgery on the doctor’s birthday</h2><p>But the authors say the “natural experiment” in the present study is more revealing than, for example, holiday-related mortality rates. That is because “those events not only affect physicians’ performance but also influence patients’ decision to seek care (i.e., patients seeking care on these special days might be sicker than those seeking care on other days), as well as hospital staffing.” Unless, of course, the patients know their surgeon’s birthday, which is unlikely (though that may change if this study becomes widely known).&nbsp;</p><p>The 1.3% effect size was the result after a very through series of controls. These included, for example, excluding those surgeons with the highest patient mortality rates. Other controls included assigning a random “pseudo-birthday” to surgeons to see whether the results still held up, or checking whether the surgeon did an above-average number of procedures on their birthday. <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>Likewise, the researchers controlled for “milestone” birthdays (such as 40 or 50). They also controlled for whether a birthday fell on a Friday, which might make after-work birthday festivities more likely.&nbsp;Their findings also held up when the analysis was restricted to procedures with the highest average mortality, or to only the most ill patients.&nbsp;In fact, without these adjustments, the 30-day mortality rate difference between the birthday and non-birthday groups (the unadjusted rate) was even higher (7.0% vs. 5.6%, or a 1.4% difference).</p><h2><strong>Why</strong> does emergency surgery suffer on surgeon’s birthday?</h2><p>The authors propose a few potential explanations for this “birthday effect.”&nbsp;</p><p>These include hurrying through an emergency surgery to be on time for after-work birthday events; <a href="https://www.psychnewsdaily.com/study-finds-users-not-notifications-initiate-89-of-smartphone-interactions/" target="_blank" rel="noreferrer noopener">distracting</a> birthday-related phone calls or text messages; more conversations with well-wishing staff members; and a decreased likelihood to go back to the hospital that evening if a patient’s condition deteriorates.</p><p>They also found that some surgeons did not work on their birthdays. While 2,144 surgeons in this study performed procedures one day before their birthday, and 2,027 did so one day after their birthday, only 1,805 surgeons carried out procedures on their actual birthday. This does not affect the results of the study’s analyses. But it does suggest “that birthdays are an important enough factor for some surgeons to choose not to operate on that day, which supports the credibility of our assumption that a birthday could be a distracting factor for those surgeons who choose to operate on that day,” the authors write.&nbsp;</p><h2><strong>Limitations</strong> <strong>and future directions</strong></h2><p>The researchers emphasized that this study focused on common procedures, and on older Medicare patients. This means that the findings may not apply to other types of patients, or to other surgical procedures.</p><p>Still, the authors write, these results may lead to “additional support for surgeons who have potentially distracting events,” such as birthdays, “to make sure that patients receive high quality surgical care regardless of when undergo surgery.”</p><hr><p><strong>Study: </strong>“<a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">Patient mortality after surgery on the surgeon’s birthday: observational study</a>“<br><strong>Authors:</strong> Hirotaka Kato, Anupam B. Jena, and Yusuke Tsugawa<br><strong>Published in:</strong> <a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener"><em>The BMJ</em></a><br><strong>Publication date: </strong>December 10, 2020<br><strong>DOI:</strong> <a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">https://dx.doi.org/10.1136/bmj.m4381</a><br><strong>Photo: </strong>by&nbsp;<a href="https://pixabay.com/users/theshiv76-1022681/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Jason Shivers</a>&nbsp;from&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440322</guid>
            <pubDate>Wed, 16 Dec 2020 08:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research in Programming Languages (2012)]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25439629">thread link</a>) | @swyx
<br/>
December 15, 2020 | http://tagide.com/blog/academia/research-in-programming-languages/ | <a href="https://web.archive.org/web/*/http://tagide.com/blog/academia/research-in-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><strong>Is there still research to be done in Programming Languages?</strong> This essay touches both on the topic of programming languages and on the nature of research work. I am mostly concerned in analyzing this question in the context of Academia, i.e. within the expectations of academic programs and research funding agencies that support research work in the STEM disciplines (<span>Science, Technology, Engineering, and Mathematics</span>). This is not the only possible perspective, but it is the one I am taking here.</p>
<p><span id="more-416"></span>PLs are dear to my heart, and a considerable chunk of my career was made in that area. As a designer, there is something fundamentally interesting in designing a language of any kind. It’s even more interesting and gratifying when people actually start exercising those languages to create non-trivial software systems. As a user, I love to use programming languages that I haven’t used before, even when the languages in question make me curse every other line.</p>
<p>But the truth of the matter is that ever since I finished <a href="ftp://ftp.ccs.neu.edu/pub/people/crista/publications/thesis/index.html">my Ph.D.</a> in the late 90s, and especially since I joined the ranks of Academia, I have been having a hard time convincing myself that research in PLs is a worthy endeavor. I feel really bad about my rational arguments against it, though. Hence this essay. Perhaps by the time I am done with it I will have come to terms with this dilemma.</p>
<p>Back in the 50s, 60s and 70s, programming languages were a BigDeal, with large investments, upfront planning, and big drama on standardization committees (Ada was the epitome of that model). Things have changed dramatically during the 80s. Since the 90s, a considerable percentage of new languages that ended up being very popular were designed by lone programmers, some of them kids with no research inclination, some as a side hobby, and without any grand goal other than either making some routine activities easier or for plain hacking fun. Examples:</p>
<ul>
<li>PHP, by Rasmus Lerdorf circa 1994, “originally used for tracking visits to his online resume, he named the suite of scripts ‘Personal Home Page Tools,’ more frequently referenced as ‘PHP Tools.’ ” [<a href="http://www.php.net/manual/en/history.php.php">1</a>] PHP is a marvel of how a horrible language can become the foundation of large numbers of applications… for a second time! <a href="http://www.dreamsongs.com/RiseOfWorseIsBetter.html">Worse is Better</a> redux. According one <a href="http://langpop.com/">informal but interesting survey</a>, PHP is now the 4th most popular programming language out there, losing only to C, Java and C++.</li>
<li>JavaScript, by Brendan Eich circa 1995, “Plus, I had to be done in ten days or something worse than JS would have happened.” [<a href="http://www.jwz.org/blog/2010/10/every-day-i-learn-something-new-and-stupid/#comment-1021">2</a>] According to that same survey, JavaScript is the 5th most popular language, and I suspect it is climbing up that rank really fast. It may be #1 by now.</li>
<li>Python, by Guido van Rossum circa 1990, “I was looking for a ‘hobby’ programming project that would keep me occupied during the week around Christmas.” [<a href="http://www.python.org/doc/essays/foreword/">3</a>] Python comes at #6, and its strong adoption by scientific computing communities is well know.</li>
<li>Ruby, by Yukihiro “Matz” Matsumoto circa 1994, “I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That’s why I decided to design my own language.” [<a href="http://linuxdevcenter.com/pub/a/linux/2001/11/29/ruby.html">4</a>] At #10 in that survey.</li>
</ul>
<p>Compare this mindset with the context in which the the older well-known programming languages emerged:</p>
<ul>
<li>Fortran, 50s, originally developed by IBM as part of their core business in computing machines.</li>
<li>Cobol, late 50s, designed by a large committee from the onset, sponsored by the DoD.</li>
<li>Lisp, late 50s, main project occupying 2 professors at MIT and their students, with the grand goal of producing an algebraic list processing language for artificial intelligence work, also funded by the DoD.</li>
<li>C, early 70s, part of the large investment that Bell Labs was doing in the development of Unix.</li>
<li>Smalltalk, early 70s, part of a large investment that Xerox did in “inventing the future” of computers.</li>
</ul>
<p>Back then, developing a language processor was, indeed, a very big deal. Computers were slow, didn’t have a lot of memory, the language processors had to be written in low-level assembly languages… it wasn’t something someone would do in their rooms as a hobby, to put it mildly. Since the 90s, however, with the emergence of PCs and of decent low-level languages like C, developing a language processor is no longer a BigDeal. Hence, languages like PHP and JavaScript.</p>
<p>There is a lot of fun in designing new languages, but this fun is not an exclusive right of researchers with, or working towards, Ph.Ds. Given all the knowledge about programming languages these days, anyone can do it. And many do. And here’s the first itchy point: <em>there appears to be no correlation between the success of a programming language and its emergence in the form of someone’s doctoral or post-doctoral work. </em>This bothers me a lot, as an academic. It appears that deep thoughts, consistency, rigor and all other things we value as scientists aren’t that important for mass adoption of programming languages. But then again, <a href="http://www.dreamsongs.com/RiseOfWorseIsBetter.html">I’m not the first to say it</a>. It’s just that this phenomenon is hard to digest, and if you really grasp it, it has tremendous consequences. If people (the potential users) don’t care about conceptual consistency, why do we keep on trying to achieve that?</p>
<p>To be fair, some of those languages designed in the 90s as side projects, as they became important, eventually became more rigorous and consistent, and attracted a fair amount of academic attention and industry investment. For example, the Netscape JavaScript hacks quickly fell on Guy Steele’s lap resulting in the <a href="http://en.wikipedia.org/wiki/ECMAScript">ECMAScript specification</a>. Python was never a hack even if it started as a Christmas hobby. Ruby is a fun language and quite elegant from the beginning. PHP… well… it’s fun for possibly the wrong reasons. But the core of the matter is that “the right thing” was not the goal. It seems that <span><em>a reliable implementation of a language that addresses an important practical need</em></span> is the key for the popularity of a programming language. But being opportunistic isn’t what research is supposed to be about… (or is it?)</p>
<p>Also to be fair, not all languages designed in the 90s and later started as side projects. For example, Java was a relatively large investment by Sun Microsystems. So was .NET later by Microsoft.</p>
<p>And, finally, all of these new languages, even when created over a week as someone’s pet project, sit on the shoulders of all things that existed before. This leads me to the second itch: <em>one striking commonality in all modern programming languages, especially the popular ones, is how little innovation there is in them</em>! Without exception, including the languages developed in research groups, they all feel like mashups of concepts that already existed in programming languages in 1979, wrapped up in their own idiosyncratic syntax. (I lied: exceptions go to aspects and monads both of which came in the 90s)</p>
<p><a href="http://tagide.com/blog/?attachment_id=544" rel="attachment wp-att-544"><img title="PLs" src="http://tagide.com/blog/wp-content/uploads/2011/09/PLs-300x225.jpg" alt="" width="300" height="225"></a>So one pertinent question is: given that not much seems to have emerged since 1979 (that’s 30+ years!), is there still anything to <em>innovate</em> in programming languages? Or have we reached the asymptotic plateau of innovation in this area?</p>
<p>I need to make an important detour here on the nature of research.</p>
<h3>&lt;Begin Detour&gt;</h3>
<p>Perhaps I’m completely off; perhaps <em>producing innovative new software</em> <em>is not a goal of [STEM] research</em>. Under this approach, any software work is dismissed from STEM pursuits, unless it is necessary for some specific goal — like if you want to study some far-off galaxy and you need an IT infrastructure to collect the data and make simulations (S for Science); or if you need some glue code for piecing existing systems together (T for Technology); or if you need to improve the performance of something that already exists (E for Engineering); or if you are a working on some Mathematical model of computation and want to make your ideas come to life in the form of a language (M for Mathematics). This is an extreme submissive view of software systems, one that places software in the back sit of STEM and that denies the existence of value in research in/by software itself. If we want to lead something on our own, let’s just… do empirical studies of technology or become biologists/physicists/chemists/mathematicians or make existing things perform better or do theoretical/statistical models of universes that already exist or that are created by others. Right?</p>
<p>I confess I have a dysfunctional relationship with this idea. Personally, I can’t be happy without creating software things, but I have been able to make my scientist-self function both as a cold-minded analyst and, at times, as an expert passenger in someone else’s research project. The design work, for me, has moved to sabbatical time, evenings and weekends; I don’t publish it [much] other than the code itself and some informal descriptions. And yet, I loathe this situation.</p>
<p>I loathe it because it’s is clear to me that software systems are something very, <em>very</em> special. Software revolutionized everything in unexpected ways, including the methods and practices that our esteemed colleagues in the “hard” sciences hold near and dear for a very long time. The evolution of information technology in the past 60 years has been _way_ off from what our colleagues thought they needed. Over and over again, software systems have been created that weren’t part of any scientific project, as such, and that ended up playing a central role in Science. Instead of trying to mimic our colleagues’ traditional practices, “computer scientists” ought to be showing the way to a new kind of science — maybe <em>that </em><a href="http://www.wolframscience.com/nksonline/page-1?firstview=1">new kind of science</a> or <a href="http://www.amazon.com/Sciences-Artificial-Herbert-Simon/dp/0262691914">that one</a> or maybe something else. I dare to suggest that the something else is related to the design of things that have software in them. It should not be called Science. It is a bit like Engineering, but it’s not it either because we’re not dealing [just] with physical things. Technology doesn’t cut it either. It needs a new name, something that denotes “the design of things with software in them.” I will call it Design for short, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tagide.com/blog/academia/research-in-programming-languages/">http://tagide.com/blog/academia/research-in-programming-languages/</a></em></p>]]>
            </description>
            <link>http://tagide.com/blog/academia/research-in-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439629</guid>
            <pubDate>Wed, 16 Dec 2020 06:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg: How my Twitter hijacks happened]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25438660">thread link</a>) | @sohkamyung
<br/>
December 15, 2020 | https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>You might recall that my Twitter account was <a href="https://daniel.haxx.se/blog/2020/11/16/i-lost-my-twitter-account/" data-type="post" data-id="15196">hijacked</a> and then <a href="https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/" data-type="post" data-id="15287">again</a> just two weeks later.</p>



<h2>The first: brute-force</h2>



<p>The  first take-over was most likely a case of brute-forcing my weak password while not having 2FA enabled. I have no excuse for either of those lapses. I had convinced myself I had 2fa enabled which made me take a (too) lax attitude to my short 8-character password that was possible to remember. Clearly, 2fa was not enabled and then the only remaining wall against the evil world was that weak password.</p>



<h2>The second time</h2>



<p>After that first hijack, I immediately changed password to a strong many-character one and I made really sure I enabled 2fa with an authenticator app and I felt safe again. Yet it would only take seventeen days until I <em><strong>again</strong></em> was locked out from my account. This second time, I could see how <em>someone had managed to change the email address</em> associated with my account (displayed when I wanted to reset my password). With the password not working and the account not having the correct email address anymore, I could not reset the password, and my 2fa status had no effect. I was locked out. Again.</p>



<p>It felt related to the first case because I’ve had my Twitter account since May 2008. I had never lost it before and then suddenly after 12+ years, within a period of three weeks, it happens twice?</p>



<h2>Why and how</h2>



<p>How this happened was a complete mystery to me. The account was restored fairly swiftly but I learned nothing from that.</p>



<p>Then someone at Twitter contacted me. After they investigated what had happened and how, I had a chat with a responsible person there and he explained for me exactly how this went down.</p>



<p>Had Twitter been hacked? Is there a way to circumvent 2FA? Were my local computer or phone compromised? No, no and no.</p>



<p>Apparently, an agent at Twitter who were going through the backlog of issues, where my previous hijack issue was still present, accidentally changed the email on my account by mistake, probably confusing it with another account in another browser tab.</p>



<p><strong>There was no outside intruder, it was just a user error.</strong></p>



<p>Okay, the cynics will say, this is what he <em>told</em> me and there is no evidence to back it up. That’s right, I’m taking his words as truth here but I also think the description matches my observations. There’s just no way for me or any outsider to verify or fact-check this.</p>



<h2>A brighter future</h2>



<p>They seem to already have identified things to improve to reduce the risk of this happening again and Michael also mentioned a few other items on their agenda that should make hijacks harder to do and help them detect suspicious behavior earlier and faster going forward. I was also happy to provide my feedback on how I think they could’ve made my lost-account experience a little better.</p>



<p>I’m relieved that the second time at least wasn’t my fault and neither of my systems are breached  or hacked (as far as I know).</p>



<p>I’ve also now properly and thoroughly gone over all my accounts on practically all online services I use and made really sure that I have 2fa enabled on them. On some of them I’ve also changed my registered email address to one with 30 random letters to make it truly impossible for any outsider to guess what I use.</p>



<p>(I’m also positively surprised by this extra level of customer care Twitter showed for me and my case.)</p>



<h2>Am I a target?</h2>



<p>I don’t think I am. I think maybe my Twitter account could be interesting to scammers since I have almost 25K followers and I have a verified account. Me personally, I work primarily with open source and most of my works is already made public. I don’t deal in business secrets. I don’t think my personal stuff attracts attackers more than anyone else does.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor.jpg" alt="" width="184" height="183" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor.jpg 471w, https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor-200x200.jpg 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor-450x448.jpg 450w" sizes="(max-width: 184px) 100vw, 184px"></figure></div>



<p>What about the risk or the temptation for bad guys in trying to backdoor curl? It is after all installed in some 10 <em>billion</em> systems world-wide. I’ve <a href="https://daniel.haxx.se/blog/2017/09/12/the-backdoor-threat/">elaborated on that before</a>. Summary: I think it is terribly hard for someone to actually manage to do it. Not because of the security of my personal systems perhaps, but because of the entire setup and all processes, signings, reviews, testing and scanning that are involved.</p>



<p>So no. I don’t think my personal systems are a valued singled out target to attackers.</p>



<p>Now, back to work!</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3319619">Gerd Altmann</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3319619">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438660</guid>
            <pubDate>Wed, 16 Dec 2020 03:19:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Far Cry: How the Fire Burns and Spreads (2012)]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25437800">thread link</a>) | @fctorial
<br/>
December 15, 2020 | https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/ | <a href="https://web.archive.org/web/*/https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
			
<h2>INTRO</h2>



<p>A few years ago, I got the opportunity to architect and code the fire propagation system in Far Cry 2. &nbsp;At that time, &nbsp;it was a gigantic task and it scared the hell out of me. Luckily, it turned out well enough.</p>



<p>With the upcoming Far Cry 3, several people recently asked me how the system worked. I realized that I never took the time to write it down. So, before I forget and also because it might be useful to somebody out there, here’s a high level overview of its inner workings. &nbsp;Pretty programmer art included as a bonus.</p>



<p><em>Disclaimer: Although Far Cry 3 uses the same system I wrote, I was not involved in the project. They may or may not have changed / adapted or modified the algorithms. What I describe below is accurate for Far Cry 2.</em></p>



<figure><p>
<iframe title="Far Cry 3 incredible fire demo video" width="640" height="360" src="https://www.youtube.com/embed/zcmbWqJjCN4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>BASE STRUCTURE</h2>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACell1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>A 2D Grid good for grass fire. &nbsp;Here, a fire cell has 50 hitpoints</figcaption></figure></div>



<p>At the core, the fire propagation system is quite simple. Since gameplay is what’s important, we&nbsp;sacrifice some of the realism for fun. The fire propagation in&nbsp;Far Cry 2 &nbsp;(and Far Cry 3) has just enough realism to maintain the player’s&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Suspension_of_disbelief">suspension of disbelief</a>,&nbsp;but certainly not enough to get published anytime soon. Because I like to&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/KISS_principle">keep things simple</a>, it doesn’t involve any complicated mathematics, physics or fluid dynamics. That has the additional advantage to be fast to simulate and easy to understand.</p>



<p>The secret sauce is an&nbsp;equally spaced grid. It is true for grass, for objects as well as for trees. The only difference is that we use a 2D grid for grass and a 3D grid for objects and trees.</p>



<p>Each cell of the grid has a position in the world, a radius and&nbsp;<strong>hitpoints</strong>. The cells have a plethora of&nbsp;properties, but these three are the bare minimum to propagate fire.</p>



<h2>LIGHT MY FIRE! HOW TO START ONE?</h2>



<p>The game engine tracks all damage done in the game, might it be bullet shots, impacts or fire damage. When a game entity is damaged, it is notified by an event. The damage event includes how much damage was done, what kind it was and what caused it.&nbsp;&nbsp;If the kind of damage was fire based and the entity is flammable, then at least two things happen:</p>



<ul><li>Firstly, the fire grid is dynamically created for the damaged entity. We create them dynamically because we don’t want those grids&nbsp;to exist in the wild for no reasons. That would take memory, disk space, etc, so we create them as we go. But, once created, it remains as long as the game entity exists.</li></ul>



<ul><li>Secondly, we figure out which cell in the grid is closest to the damage source. That cell then takes the damage and its hitpoints are reduced accordingly.</li></ul>



<p>That’s where things get interesting – When a cell has been damaged by fire and has lost all its hitpoints;&nbsp;<strong>it catches fire</strong>.</p>



<p>While burning, the cell becomes a damager itself. It deals damage to its neighbour cells on the grid; cells that share an edge with it. By doing so, it reduces their hitpoints and when in turns these cells have lost all their hitpoints, they catch fire. That’s how the propagation is created.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg 700w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1-300x220.jpg 300w" sizes="(max-width: 700px) 100vw, 700px"><figcaption>Fire propagating from left to right. The cells on the fire front are being damaged.</figcaption></figure></div>



<p>Lastly, a cell from the grid as a finite lifetime. Otherwise, it would burn forever. It can be seen as the amount of energy given by the material that is burning. &nbsp;For instance,&nbsp;a piece of paper would most likely burn faster than a wood log, so it would be given a shorter lifetime value.</p>



<p>That’s it. A fully functional fire propagation system good enough for a AAA game!</p>



<h2>TECHNICALITIES</h2>



<p><strong>Simulate wet jungle VS dry patch of grass</strong><br>How to simulate a wet jungle versus a dry patch of grass? They behave differently. Quite easily!<br>Increase the fire cell’s hitpoints and it’s difficult to set it on fire and it’s slow to propagate.&nbsp;Decrease its burning lifetime and the fire dies out quickly. There, you just simulated a wet jungle environment.</p>



<p><strong>How to create the propagation grids</strong></p>



<p><strong><em>Grass / Land</em></strong><br>For grass wildfire, &nbsp;an axis-aligned 2D grid is built in realtime and projected on a 3D terrain. For each of the cell, we take care to determine if the cell position is underwater, or under an object such as a rock or a building. In which case, we disable that cell and it can no longer catch fire. We wouldn’t want to have fire propagating under rock, would we?<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg 512w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled-300x220.jpg 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>2D grid projected on a terrain. The cells under the rock are disabled.</figcaption></figure></div>



<p><strong><em>Objects</em></strong><br>For objects, it’s a little bit more complicated. First, we create an&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Bounding_volume">AABB</a>&nbsp;that entirely surrounds the object. &nbsp;Second, we somehow&nbsp;need to detect the shape of that object. After all, it could be a chair, an oil barrel or a whole house for all we know. To accomplish that, the &nbsp;bounding box is divided in equally spaced cubes.&nbsp;The size of each cube depends of the object size, the number of fire emitter we want to have, performance, memory, etc.</p>



<p>An iterative algorithm then go through all those cubes and test their location against the collision shape of the object.&nbsp;If the test return a positive result, this cube is kept, otherwise it is discarded. At the end, we have a collection of cubes that approximately&nbsp;represent the shape of the object to be burned. That’s our propagation grid.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg 800w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-300x183.jpg 300w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-768x469.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>Detection of the shape of an object</figcaption></figure></div>



<h2><strong>WIND EFFECT</strong></h2>



<p>The wind is an important disruptive factor for a wildfire and it adds a great layer of realism for the player. &nbsp;Here it could be tempting to&nbsp;over-think&nbsp;the design and go with a very complicated system. After all, it’s an active area of research and&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S1540748912001988">several</a>&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S0378475407002030">papers</a>&nbsp;on the subject are available online.</p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S0378475407002030-gr3-300x235-1.jpg" alt=""></figure></div>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S1540748912001988-gr3.jpg" alt=""></figure></div>



<p>Luckily, with what have been explained thus far, it’s quite easy to simulate if we accept to cut corners a bit.</p>



<p>In our system, the fire propagates by damaging the&nbsp;neighbor&nbsp;cells on a grid. And it is generally accepted that a fire should spread faster in the direction of the wind than against&nbsp;the wind? Then, with that in mind, we can create a rule where a burning cell deals more damage to its&nbsp;neighbor&nbsp;cells if that neighbor is in the direction of the wind.</p>



<p>We do that by getting the&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Dot_product">dot product</a>&nbsp;between the wind direction&nbsp;vector and the direction of the&nbsp;neighbor&nbsp;cell to damage.&nbsp;If the result is greater than zero, then that node is dealt greater damage. &nbsp;Likewise, if the result is negative, &nbsp;the node is against the wind and should be dealt less damage. To be fancy, the amount of damage is interpolated with the dot product result as shown in the picture below.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>The cell on fire causes more damage to its neighbor cells if they are in the direction of the wind.</figcaption></figure></div>



<p>With that rule alone, you will get a nice bell shaped fire front that propagates in the direction of the wind. Simple, yet believable&nbsp;enough to get the player’s stamp of approval.</p>



<p>It’s worth noting that we simulate gravity the exact same way.</p>



<h2>PROPAGATING TO THINGS AROUND AND CHAIN REACTIONS</h2>



<p>When a cell burns, it sends a “I’m on fire and I burn this much in this radius” message down&nbsp;the game event pipeline. This event is caught by objects, AI and other game systems that are in that area. They react&nbsp;to this message their own specific ways. The AI freaks out, the flammable objects get damaged and eventually catch fire. And, &nbsp;it is also true for dynamic objects. &nbsp;For example, if a burning oil barrel goes flying through the map, every step of the way, &nbsp;it will send that “i’m burning” message and a lot of things around might hear it.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg 719w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone-300x284.jpg 300w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>In the absence of wind, a cell on fire damages equally all its neighbors.</figcaption></figure></div>







<p>This causes a chain reaction effect where trees, explosive items, &nbsp;objects and patches of grass set each others on fire. &nbsp;It’s completely&nbsp;systemic and it makes it much more believable. It &nbsp;also scores pretty high on the&nbsp;player’s&nbsp;fun meter because it behaves as one would expect, yet as real fire, it sometimes gets totally out of control.</p>



<h2>OPTIMISATION</h2>



<p><strong>The Hair Transplant Strategy</strong></p>



<p>In an ideal world, we would have access to enough memory to hold&nbsp;an infinite number of particle emitters and we could display an infinite number of particles on screen.&nbsp;Unfortunately, the reality is that those numbers are actually pretty low.</p>



<p>To do more with less, we have to put our emitters where it really counts. Enters the hair transplant strategy! &nbsp;In Far Cry 2, the fire emitters are constantly being teleported around, most importantly, from the back of the camera to the front. The player’s point of view is monitored at all time and emitters that are burning out of sight are moved to a better location where they are also needed.</p>



<p>In addition, the emitters’s density is higher in close proximity of the player and lower as the distance increases. A kind of fire&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Level_of_detail">LOD&nbsp;</a>if you will.&nbsp;If things are getting bad and we still need more emitters but none are available, we increase the particle sizes to give them more volume and fill more space on screen.</p>



<p>With this strategy, and some others, we can simulate a wildfire that is several meters wide with a relatively low number of particle emitters.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/farc2-300x169.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>Credits: http://www.rockpapershotgun.com</figcaption></figure></div>



<p><strong>Event Pipeline</strong><br>Since the described system tried to avoid all complicated maths, generally speaking we will be GPU bound before being&nbsp;CPU bound.</p>



<p>That being said, the event pipeline could be a bottleneck. It works well when you have just a few cells on fire. But, it’s another story when you have thousands of them burning and&nbsp;advertising&nbsp;their state to the world. That will likely clog your CPU’s arteries.</p>



<p>The trick for me was to regroup the cells that were burning into&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Axis-aligned_bounding_box#Axis-aligned_minimum_bounding_box" target="_blank" rel="noreferrer noopener">AABB</a>&nbsp;groups. These groups would constantly merge, split and&nbsp;change shape to follow the evolution of the fire. The events would then be sent per AABB instead of per cell, which saves&nbsp;a significant amount of processing power. Additionally, the events would be spread out across several frames in order to distribute the load and avoid framerate spikes.</p>



<p><strong>Keeping things under control.</strong><br>In your game, if you don’t constrain the propagation somehow, it will either</p>



<ul><li>Burn the entire map and kill all the NPCs</li><li>Fill out the …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</a></em></p>]]>
            </description>
            <link>https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437800</guid>
            <pubDate>Wed, 16 Dec 2020 01:13:40 GMT</pubDate>
        </item>
    </channel>
</rss>
