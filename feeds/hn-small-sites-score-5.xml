<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 12 Nov 2020 16:36:08 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 12 Nov 2020 16:36:08 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I’ll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I’ll call the ‘feature ID’.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (“Is a certain feature present or not”) or can be the
amount of DSP memory etc.</p>

<p>Here’s a very non-exhaustive list of codes that I’ve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It’s a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That’s the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable “Option 05 - Video Triggering”, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it’s great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called “MathPak”. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It’s now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I’m now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It’s a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It’s now clear why option 1M doesn’t get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of “D2” memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there’s a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it’s a board that’s easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they’re now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn’t be a problem.</p>

<p>They’re cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished…</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that’s wired to the board: it’s used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I’m most comfortable doing it that way.
Afterwards I Ohm’ed out most of the pins, and I’m glad I did because
there were some open connections.</p>

<p>The end result isn’t perfect, but it’s good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it’s time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it’s
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it’s really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn’t able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We made our own x86 shellcode emulator and how it works]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don’t affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn’t have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn’t even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they’re loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn’t matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies – Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exodus of Silicon Valley]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25052818">thread link</a>) | @Reedx
<br/>
November 10, 2020 | https://breakingground.us/exodus/ | <a href="https://web.archive.org/web/*/https://breakingground.us/exodus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4180">
					
					
					
					
					<div>
					<p>On the day the sun didn’t rise in San Francisco, the early warning signs came through the screen. The 6:30 a.m. Zoom always requires unnatural light, making the outlines of faces fuzzy. The natural morning light, combined with the “Touch Up My Appearance” feature on 2020’s preferred video conferencing system, hides the marks of age and sleeplessness that most of us seek to mask. But by 9:00, the fluorescent light was still dominating the screen, and the darkness outside our windows had turned to infernal orange.</p>
<p>The scientific explanation for our sunless day in September is pretty dull. The clouds of soot from the largest California wildfire in history intermixed with the Bay Area’s perennial fog, turning the usual sepia hue of dirty global cities into an apocalyptic blood-orange sky. Though Twitter blamed the hellscape on far more menacing forces, the direct cause of our Blade Runner Day was mostly carbon clinging to the blue-light hues while letting the red pierce through.</p>
<p>If we were more like ancient peoples, many joked, we would assume the gods were enraged. We’d be running for the hills to escape their wrath, or at least head straight for our prepper bunkers. That we are unlike ancient people is actually the only myth, as this is exactly the exodus that is happening in Silicon Valley right now—and will continue for the next few years as true believers deliver themselves from this promised land.</p>
<p><a href="https://breakingground.us/from-ashes/">It’s time to build</a>, yes. But it’s also time to leave.</p>
<p>The battle over tech’s supremacy has been waged and all of our premonitions came true: We wanted flying cars and got vertical take-off innovation hubs from every car maker in America. Software has not only eaten the world, but feasted on your screen-weary eyes. It has swallowed your children, your church, your bank, and your politics, and somehow it all feels inevitable. That these feats of human progress—of instant connectivity in a now homebound world—became the scapegoat of our time is another symptom of the era’s end, cueing the quiet exodus of builders who had bigger aspirations than the same-day shipping that keeps our households afloat.</p>
<p>Now, Silicon Valley is witnessing a reckoning, but it’s not the long-awaited one predicted by the New York press, or the antitrust bonanza that Washington longs for because too many people seem satisfied getting their news from Facebook. The reckoning is more of a realization that tech exceeded expectations and somehow squandered the fruit of its own garden, and that a city on a hill that could have supported so much innovation was not Florence in the Renaissance nor the Athenian Academy with MacBooks. Rather, it became a government-sponsored needle exchange, a haven for the homeless and forgotten that put government’s paralysis on display downtown on Market Street.</p>
<blockquote><p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p></blockquote>
<p>San Francisco had four times as many deaths from overdose this year as it did from the COVID-19 virus.</p>
<p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p>
<p>* * *</p>
<p>The computer revolution of the late twentieth century has yet to be named as an epoch, but we can assume that nomenclature will begin in the coming years, alongside the battle for what it all really meant.</p>
<p>What we now call our “technological age” was supposed to be a full-throated and enduring argument for the future, not unlike previous epochs in history that pushed art, science, philosophy, and religion forward in dizzying ways that run counter to ordinary time. The Enlightenment. The Renaissance. The French Revolution. These movements now sit as categories on our bookshelves with clear beginnings and ends, and more importantly, clear hubs and cities of frenetic building that drove the ethos forward. Many books assume that contemporary critics or philosophers were blissfully ignorant to the unraveling of their revolutions, but we should not assume that contemporaries did not feel the same twilight setting. The figurative orange skies always creep in before dawn.</p>


<p>Which brings us to the supposed death of Silicon Valley, a fate that has long been predicted but with data now finally catching up. San Francisco apartment rents in 2020 have deflated by 20 percent after an up-up-and-away decade that made the city truly unlivable. Home inventory has reached a fifteen-year high in a city blighted by restrictive housing policy that makes construction cranes as miraculous as stumbling upon a burning bush. The growth in online sales-tax collection, according to the <em>San Francisco Chronicle</em>, is the lowest of all counties in the state of California. And public tech companies, such as Pinterest, paid upwards of $90 million to break its lease in downtown San Francisco. Some would argue this is a clear end to Bay Area tech dominance, while others would point to the many new unicorns that popped up this year despite the once-in-a-century pandemic. No one’s living here, yet somehow the companies are still growing.</p>
<p>Silicon Valley doesn’t really have cultural critics to weigh in on whether this era is officially over, but we do have venture capitalists. And our Nostradomuses are telling us that change is afoot.</p>
<p><em>Do we really need this office? The founders all have left.</em></p>
<p><em>Their entire partnership is now living in Montana. It’s only a two-hour flight away!</em></p>
<p><em>Denver seems like a good option, but Reno has no state income tax.</em></p>
<p>The weirdness of this exodus is that it is not driven by fear. Technologists weren’t <em>really </em>driven out by plague or fire or San Francisco’s insatiable need for higher tax revenue. Those ills were always apparent, and yet people stayed to carry the torch.</p>
<p>The exodus of tech’s true believers may be that the covenant is finally fulfilled. That when America—along with the rest of the world—met their darkest hour and turned inward, the technology that was long ridiculed as frivolous or dangerous led us to relative normalcy. The Zooms. The Tiger Kings. The Signal chats. The Slack jokes. An election news cycle that plowed ruthlessly forward on Twitter. Though inconvenient, mothers and fathers set their children in front of screens to occupy them for <em>just</em> long enough to survive a terrible year. And maybe, just maybe, the same-day-shipping racket that made Jeff Bezos the richest man alive was actually a feat of human genius that held the country together when public infrastructure and the social fabric were fraying at the seams. Perhaps our lowly software revolution was actually the fruition of a long-held California dream, when the physical world forced us inside and virtual life prevailed.</p>
<blockquote><p>Silicon Valley is no longer a place, they’ll say. It’s a way of being, of building, and the latest embodiment of belief in human progress. And it’s spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p></blockquote>
<p>For that triumph, the nerds can now smell the impending scapegoating of their success. And like so many of history’s prophets and heretics, those who believe most fervently in the promise of technology are beginning their long march away from the Valley.</p>
<p>And they will substitute the virtual world for the physical space that once defined this movement. Silicon Valley is no longer a place, they’ll say. It’s a way of being, of building, and the latest embodiment of belief in human progress. And it’s spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p>
<p>Silicon Valley is over. The exodus is just beginning.</p>
					</div> <!-- .entry-content -->

				
				</article></div>]]>
            </description>
            <link>https://breakingground.us/exodus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052818</guid>
            <pubDate>Tue, 10 Nov 2020 22:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top 10 Most Important SQL Commands to Know]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052742">thread link</a>) | @jackmcclelland
<br/>
November 10, 2020 | https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <figure><img src="https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/SQL-Cheat-Sheet.png 600w, https://blog.arctype.com/content/images/size/w1000/2020/11/SQL-Cheat-Sheet.png 1000w, https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png 1440w"></figure><p>As companies and organizations find themselves dealing with rapidly increasing amounts of data, there's a growing need for developers to effectively use databases to handle this data. SQL, which stands for Structured Query Language, is a programming language that helps manage data stored in relational databases (a popular type of database).</p><p>SQL commands can help a developer create tables, add and modify data in these tables, search the database, and more. This article will cover a list of ten basic SQL commands that are essential to know for developers working with SQL. You'll find for each SQL command a code snipped and brief description of what the code runs.</p><p>Whether you're a beginner or a pro at SQL, consider trying out <a href="http://arctype.com/"><strong>Arctype</strong></a>, a redesigned SQL client for PostgreSQL and MySQL developers and teams. It's free, fast, and easy-to-use: <a href="http://arctype.com/" rel="noopener noreferrer">http://arctype.com/</a></p><p>Let's get right into it! Here are ten basic building blocks of SQL programming.</p><hr><!--kg-card-begin: markdown--><h2 id="createtable">CREATE TABLE</h2>
<pre><code>CREATE TABLE table_name (
  column_1 datatype_1, 
  column_2 datatype_2, 
  column_3 datatype_3
);
</code></pre>
<!--kg-card-end: markdown--><p>This command allows you to create a new database or table; the example above adds a new table with a title and column names.</p><!--kg-card-begin: markdown--><h2 id="altertable">ALTER TABLE</h2>
<pre><code>ALTER TABLE table_name 
ADD column_name datatype;
</code></pre>
<!--kg-card-end: markdown--><p>Run this command to modify (add, drop, rename, etc) the structure (not the data) in your database; the example above adds a new column to a table with a specified datatype.</p><!--kg-card-begin: markdown--><h2 id="delete">DELETE</h2>
<pre><code>DELETE FROM table_name
WHERE some_condition = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command can delete data from your table based on conditions specified with the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="drop">DROP</h2>
<p><code>DROP TABLE table_name;</code></p>
<!--kg-card-end: markdown--><p>Similar to the create command, DROP deletes a database or table. Be careful when using this command – the code above will delete your whole table, including all data, indexes, and more.</p><!--kg-card-begin: markdown--><p><code>ALTER TABLE table_name DROP COLUMN column_name;</code></p>
<!--kg-card-end: markdown--><p>The ALTER TABLE and DROP statement above will remove a specific column from a table.</p><!--kg-card-begin: markdown--><h2 id="insertinto">INSERT INTO</h2>
<pre><code>INSERT INTO table_name (column_1, column_2, column_3) 
VALUES (value_1, value_2, value_3);
</code></pre>
<!--kg-card-end: markdown--><p>To add new records to your table, use the INSERT INTO command. You can use this command on one or more rows.</p><!--kg-card-begin: markdown--><h2 id="select">SELECT</h2>
<pre><code>SELECT column_name 
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Every query begins with SELECT; this is how you grab data from your database. It's the most fundamental SQL query. After the SELECT command, you can use the keyword FROM to specify a table, the keyword WHERE to select with conditions, and the keyword ORDER BY to sort your results.</p><!--kg-card-begin: markdown--><h2 id="update">UPDATE</h2>
<pre><code>UPDATE table_name
SET some_column = some_value
WHERE some_column = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command lets you edit data in your table by updating data based on conditions specified after the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="as">AS</h2>
<pre><code>SELECT column_name AS 'Alias'
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>The AS keyword allows you to use a temporary alias when referring to a column or table.</p><!--kg-card-begin: markdown--><h2 id="count">COUNT</h2>
<pre><code>SELECT COUNT(column_name)
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Use the COUNT() function to add up the number of rows where the specified column is not NULL.</p><!--kg-card-begin: markdown--><h2 id="between">BETWEEN</h2>
<pre><code>SELECT column_name(s)
FROM table_name
WHERE column_name BETWEEN value_1 AND value_2;
</code></pre>
<!--kg-card-end: markdown--><p>This operator filters the results to be within a specified range (numbers, text, dates, etc).</p><hr><p>These building blocks will get you started programming with SQL, which is a great language useful and definitely worth learning in 2020. Check out the <a href="https://insights.stackoverflow.com/survey/2020">StackOverflow Developers Survey 2020</a>, where 65k developers answered questions about the programming languages and tools they run: SQL was top three in the most popular technologies question!</p><figure><img src="https://blog.arctype.com/content/images/2020/11/devdev.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/devdev.png 600w, https://blog.arctype.com/content/images/2020/11/devdev.png 900w" sizes="(min-width: 720px) 720px"><figcaption>If you're curious you can check out the rest of the results of the survey here at the URL here: <a href="https://insights.stackoverflow.com/survey/2020" rel="noopener noreferrer">https://insights.stackoverflow.com/survey/2020</a></figcaption></figure><p>Database programming languages are popular and have active developer communities, and are becoming increasingly important as organizations seek to process the thousands of terabytes of data generated each day. If you're working with databases in SQL or are planning on doing so, check out the newly-designed <a href="http://arctype.com/"><strong>Arctype</strong></a> SQL client. It's faster and easier-to-use than many of the clients out there right now and is designed with your needs in mind as a modern developer.</p><p>Thanks for checking out my article covering these ten basic SQL commands! Let me know if you have any questions, or would like me to write a follow-up post with more intermediate SQL commands to check out. Happy coding!</p>
            </div></div>]]>
            </description>
            <link>https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052742</guid>
            <pubDate>Tue, 10 Nov 2020 22:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flaws of “Subscription Fatigue”, “SVOD Fatigue”, and the “Streaming Wars”]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25051292">thread link</a>) | @bschne
<br/>
November 10, 2020 | https://www.matthewball.vc/all/misnomers | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/misnomers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-96dbb3b03808a860d80e"><div><p>When we consider the state of tech-media in 2020, there are a few common narratives. The most inescapable is the “Streaming Wars”. In November, I argued that <a href="https://www.matthewball.vc/all/minedmedia">this term was a misnomer</a>. Digital/streaming/OTT video is really just <em>a</em> battle in a much larger war: the “ecosystem war”. And for the most part, this war is fought asymmetrically. Apple and Amazon both sell digital media devices, third-party media content, and their own original content, for example. However, Apple isn’t an e-retailer nor a diversified enterprise cloud services provider, and Amazon doesn’t even have a smartphone, personal computer, watch or non-video app store. I’ll come back to this idea, but understanding the differences between these companies and their motivations is helpful when considering two other popular phases that are unhelpful at best and misleading at worst: “subscription fatigue” and “SVOD fatigue”.</p><p><strong>“Subscription Fatigue”</strong></p><p>The “subscription economy”, by definition, presumes that the overall “economy” – from products, to services, content, transportation, labor and more – is shifting over to “subscriptions”. Thus, to claim that consumers have “subscription fatigue” is to say that they have “spending fatigue”.</p><p>As always, most consumers will say they wish they spent less money, bought fewer things, and enjoyed lower prices. However, it makes little sense to say that the decision to buy TV subscriptions, radio subscriptions, toothbrush subscriptions, video gaming subscriptions, dog food subscriptions, car subscriptions, or productivity software subscriptions should drive “subscription fatigue” or mean each subscription competes with one another. For decades, consumers have bought TV, music, toothbrushes, video games, dog food, cars and Microsoft Office. What’s new is that they all have similar models – digitally-based, predominantly D2C subscriptions. This changes nothing about the individual value or baseline need for them.</p><p>Of course, the “subscription economy” does mean that step one of a recession will be to “re-evaluate all subscriptions”. However, this does not mean subscription <em>fatigue</em> should be considered a real “thing”, let alone a defining element of modern-day competition. Furthermore, payment model – upfront v. recurring, subscription v. á la carte, online v. offline – is irrelevant to what’s “re-evaluated” and not. Some subscriptions are “necessities”, like toilet paper, while others are concerned with discretionary spend, such as Office 365 or Netflix or Tinder. This latter group isn’t competitive because they’re “subscriptions”, but because there is, as always, finite spending money for non-essential items. </p><p>To this end, it’s important to highlight subscriptions are often a <em>preferred</em> buying path for consumers. Most would rather (or can only afford) $10 a month for a multi-year license to Microsoft Office for $300. Subscriptions also meaningfully reduce the cognitive burden of repeat decision making. No longer do you need to “track” your toothbrush for wear, risk “running out” of toilet paper and then be forced to overpay for a small-volume purchase, or need to scan and hoard coupons to ensure a great deal. Similarly, many consumers would rather marginally overpay for an all-you-can-eat subscription than optimize for specific tiers of use. In fact, most of us have caustic responses to per unit pricing, often to the point of irrationality (e.g. $40 for 35 loads of laundry detergent v. $1.00 per load). Amazon Prime is based on the <em>need</em> to get shipping fees out of the way once, versus fight them over and over and over and over, even if the effective shipping cost went up for a consumer, or the lack of shipping costs led to unnecessary purchases.</p><p>The rise of fully flexible monthly commitments also means that consumers no longer have to worry about having made a bad decision and being stuck with it. In this sense, every subscription is still á la carte, but unlike in the analog era, the default outcome of “doing nothing” is to keep getting value you enjoy rather than running out of a thing you need. </p><p><em>(Note that none of this means that a digital subscription business is a “good” one. Many sub-categories of CPGs and foodstuffs, not to mention music or fitness equipment, weren’t good business before the shift to subscription. The fact they shifted to subscriptions doesn’t inherently change this, just as it doesn’t mean they suddenly compete with all other subscriptions).</em></p><p><strong>“SVOD Fatigue”</strong></p><p>Of course, the nuances of “subscription fatigue” is separate from the question of “Subscription <em>VOD</em> fatigue”. It is obvious consumers don’t need 20 Netflixes. However, they’re not being asked to buy 20 Netflixes. It’s wrong to treat Fox Nation, Netflix, ESPN, and Twitch as competitors, let alone interchangeable “units of SVOD”. They serve very different functions and offer very different content. Just as Spotify and the <em>New York Times</em> and Amazon Prime shipping each do.</p><p>Amazon and Apple TV+, meanwhile, aren’t Netflixes – not in monetization, content volumes, or strategy. Now, if Amazon or Apple’s SVOD services can monetize so dramatically better through the Prime and iOS ecosystem than Netflix can via direct consumer spend and a singular focus, they can, in theory, “kill” Netflix – should they so choose – but that has nothing to do with SVOD fatigue nor the number of viable SVODs.</p><p>The question of SVOD fatigue isn’t about “how many SVODs will the average household have”. It’s really about “how many different roles are there to be played in video”. And the answer here is mostly path dependent – it depends on the innovation, risk taking, and discovery that happens in the marketplace, as well as timing. No one knew “live streaming video games” was an opportunity until Twitch, for example. And while Twitch likely steals <em>time</em> away from the video ecosystem, the viability of the Twitch subscription doesn’t mean that the number of viable OTT services has reduced.</p><p><strong>The Question</strong></p><p>All of which is to say what matters in SVOD is simple and not unique to SVOD: <span>A service will succeed if (1) it addresses a real, outstanding customer want/need; (2) at an appropriate price or value to the consumer; and (3) while generating sustainable economics</span>. </p><p>Quibi is a good example here. The company believes that there is an outstanding need for a new type of content, focused on a different time and place, under a different viewing behavior and focused on a specific audience. If it is right, and it can build up a defensible leadership position before other players replicate it, a new subscription will be possible and it doesn’t matter how many SVODs a customer already has (just as whether they have NYT or Spotify doesn’t matter). But of course, if you ask consumers “do you wish you had fewer subscriptions” or “fewer SVODs”, they will say yes – especially if they don’t really know what the new “thing” is. Note, too, that Pay-TV studies have been promising that 10%–30% of subscribers will cancel each year. They never do… because enough value remains. </p><p>More broadly, this three-point framework is well established (it actually has nothing to do with video). Over the past forty years, we have seen countless examples of “networks” launching into hyper-saturated marketplaces with hyper-specific but unproven (and often openly derided) theses regarding outstanding consumer wants and needs. Almost all of these have succeeded. In fact, they usually spawned several direct competitors – showing that the unmet want was even larger than originally anticipated. &nbsp;</p><p>For example…</p><ul data-rte-list="default"><li><p><em>1972: HBO launched a network focused on the most valuable TV time, Sunday night, with an unprecedented monetization model (á la carte consumer spend and no advertising), and focused only on reruns of Hollywood movies. It was ultimately bought by 25% of TV homes, became the most profitable network in the world and the market leader in quality. And this was despite the launches of Showtime (1976), Starz (1994) and Epix (2009).</em></p></li><li><p><em>1977: Nickelodeon launched 24/7 content only for kids. No longer was kids content relegated just to afternoon and Sunday morning blocks. In the 2000s, Nickelodeon became the most watched cable network, despite having spun-off several other Nick-branded channels and seen the launch of The Disney Channel in 1983.</em></p></li><li><p><em>1979: ESPN launched a 24/7 sports channel, ultimately with the highest programming budget in the world. In 2019, it brought in more than $2.5B in profits, with an annual revenue of roughly $9B. In 2009, Fox launched its own suite of 24/7 Fox-branded sports networks.</em></p></li><li><p><em>1980: CNN launched a 24/7 news channel. Today, it generates an estimated $800MM a year in cash flow on $2B in revenue, and several other 24/7 networks exist.</em></p></li><li><p><em>1981: MTV launched a 24/7 music video and culture channel that focused only on young audiences. The result was the first new Hollywood film/TV conglomerate in decades. Within years, MTV had launched several other 24/7 networks, while competitors launched even more focused versions, such as CMT.</em></p></li><li><p><em>1983: BET launched a 24/7 network focused on black American audiences. In 2001, the company was sold to Viacom for $3B. Several other black-focused networks exist today. </em></p></li><li><p><em>1996: Fox News launched a 24/7 news channel… only for half of news watchers. It now generates more than $1.5B in cash on $2.5B+ revenue</em></p></li></ul><p>Of course, this sort of logic can be used to justify faulty assumptions around what opportunity exists, where, how large it might be, how durable it is, etc. In addition, these specifics gaps were open because of technological limitations. A network like ABC could only air one thing at a time – and therefore there were structural impediments to serving “everyone”. Netflix, meanwhile, can air anything, at any time, to every viewer, and on an individual basis.</p><p>But the crucial point here is that it’s wrong to think about the “number” of subscription video services, just as it was wrong to think about how “many” networks were in the cable bundle in 1980, 1985, 1990, and so on. In fact, it’s incredibly close …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/misnomers">https://www.matthewball.vc/all/misnomers</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/misnomers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051292</guid>
            <pubDate>Tue, 10 Nov 2020 20:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-Scale Geo-Replicated Conflict-Free Replicated Data Types [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051115">thread link</a>) | @simonebrunozzi
<br/>
November 10, 2020 | https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf | <a href="https://web.archive.org/web/*/https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051115</guid>
            <pubDate>Tue, 10 Nov 2020 20:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Benefits of Being a Stoic]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25050456">thread link</a>) | @davefreiburger
<br/>
November 10, 2020 | https://gradually.co/the-benefits-of-being-a-stoic/ | <a href="https://web.archive.org/web/*/https://gradually.co/the-benefits-of-being-a-stoic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-893">
				<!-- <a href="https://gradually.co/the-benefits-of-being-a-stoic/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              																			<p>								Wisdom								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Benefits of Being a Stoic</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 10, 2020						</span>

						<img width="640" height="340" src="https://gradually.co/wp-content/uploads/2020/11/GD24-Wisdom.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://linkmix.co/1611480" target="_blank">
									[Image source: Eric Gerlach/Giphy]								</a></p><h5>
									<a href="http://nautil.us/issue/92/frontiers/the-joys-of-being-a-stoic" target="_blank">
										The Joys of Being a Stoic									</a>
									 &nbsp;by Massimo Pigliucci									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>“If there is nothing you can do about a particular situation, why beat yourself up about it?” — Massimo Pigliucci</span></li>
<li><span>Stoicism shouldn’t be about suppressing your emotions. Moreso, Stoicism is about adjusting your unhealthy emotions (anger) to a more mindful embrace of healthier ones (joy).&nbsp;</span></li>
<li><span>Stoicism receives a great deal of pushback regarding the negative effects of not acknowledging pain and the silent endurance and lack of emotion.&nbsp;</span></li>
<li><span>Massimo quotes Epictetus (Greek Philosopher), “Some things are within our power, while others are not. Within our power are opinion, motivation, desire, aversion, and, in a word, whatever is of our own doing; not within our power are our body, our property, reputation, office, and, in a word, whatever is not of our own doing.”&nbsp;</span></li>
<li><span>Massimo adds, “…the idea is to internalize our goals: Instead of focusing, as it comes natural, on outcomes, let’s pay attention to our intentions and efforts. The Stoics think that the only truly good thing for us is our own character, and that therefore the only truly bad things are whatever may undermine our character. Everything else (including health, wealth, reputation, etc.) has value, but does not define who we are.”</span></li>
<li><span>The four virtues:</span></li>
</ul>
<ol>
<li>
<ol>
<li><i><span>Practical wisdom</span></i><span> — the knowledge of what is truly good or bad for me. Will this undermine my character or not?&nbsp;</span></li>
<li><i><span>Courage</span></i><span> — doing something that frightens us.</span></li>
<li><i><span>Justice</span></i><span> — as treating other people, like my coworker, fairly and with respect.</span></li>
<li><i><span>Temperance</span></i><span> — we should do things in the right measure, neither too much nor too little.&nbsp;</span></li>
</ol>
</li>
</ol>
<ul>
<li><span>“Apply the dichotomy of control and the four virtues to everything you do and, as Epictetus promises, you will never be unhappy. You will be free, and you will live a life truly worth living.” — Massimo Pigliucci</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>Massimo mentions that the four virtues help us form a sort of moral compass. Allowing people to navigate the world and weather the storm of whatever that’s thrown at us. Moral compass or not, Stoicism or not, knowing your own virtues that help you navigate the world seems like an exercise worth doing. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!-- </a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/the-benefits-of-being-a-stoic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050456</guid>
            <pubDate>Tue, 10 Nov 2020 19:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnout can exacerbate work stress, further promoting a vicious circle]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 181 (<a href="https://news.ycombinator.com/item?id=25048455">thread link</a>) | @rustoo
<br/>
November 10, 2020 | https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php | <a href="https://web.archive.org/web/*/https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- Hier kommen Imagescroller und ZGN, sowie... -->
            <!-- Offene Universität Scroller --><!-- Default Row -->
            <!-- Spaltenlayout gemäß Einstellungen für option_schalter_linke_spalte, option_schalter_rechte_spalte -->
            <!-- Ende linke Spalte -->
            <article id="spaltemitte">
               <!-- Beginn Inhalt Spalte Mitte -->
               <!-- Indexüberschrift:  -->
               <h3>
                  Work stress and burnout are mutually reinforcing / Surprisingly, the effect of work stress on burnout is much smaller than the effect of burnout on work stress
               </h3>
               <p>
                  10 November 2020
               </p>
               <p>
                  Stress and overload in the workplace are increasing worldwide and are often considered a cause of burnout. Indeed, a new study shows that work stress and burnout are mutually reinforcing. However, contrary to popular belief, burnout has a much greater impact on work stress than vice versa. "This means that the more severe a person's burnout becomes, the more stressed they will feel at work, such as being under time pressure, for example," said Professor Christian Dormann of Johannes Gutenberg University Mainz (JGU). Employees suffering from burnout should be timely provided with adequate support in order to break the vicious circle between work stress and burnout.
               </p>
               <p>
                  Symptoms of burnout include exhaustion, cynicism, and reduced performance. "The most important burnout symptom is the feeling of total exhaustion – to the extent that it cannot be remedied by normal recovery phases of an evening, a weekend, or even a vacation," said Dormann. "To protect themselves from further exhaustion, some try to build a psychological distance to their work, that is, they alienate themselves from their work as well as the people associated with it and become more cynical," added Dr. Christina Guthier. She conducted the study as part of her doctoral thesis in Dormann's research group and was awarded with the dissertation prize of the Alfred Teves Foundation in 2020. The study has recently been published in <em>Psychological Bulletin</em>.
               </p>
               <p>
                  For the joint publication with Professor Christian Dormann and Professor Manuel Völkle of Humboldt-Universität zu Berlin, Christina Guthier evaluated 48 longitudinal studies of burnout and work stress comprising 26,319 participants. The average age in the initial survey was about 42 years, 44 percent of the respondents were men. The longitudinal studies from 1986 to 2019 came from various countries, including predominantly European countries as well as Israel, the USA, Canada, Mexico, South Africa, Australia, China, and Taiwan.
               </p>
               <h4>
                  Stopping the downward spiral and reducing the effect of burnout on work stress
               </h4>
               <p>
                  The results challenge, or at least relativize, the common perception that work stress is the driving force behind burnout. "Burnout can be triggered by a work situation, but that is not always the case," Dormann pointed out. Once burnout begins, it develops only very gradually, building up slowly over time. Ultimately it leads to work being increasingly perceived as stressful: The amount of work is too much, time is too short, and work stress is too great. "When exhausted, the ability to cope with stress usually decreases. As a result, even smaller tasks can be perceived as significantly more strenuous," explained Guthier, the first author of the article. "We expected an effect of burnout on work stress; the strength of the effect was very surprising," she noted. The effect of burnout on perceived work stress can be somewhat mitigated if employees have more control over their own work and receive support from colleagues or superiors.
               </p>
               <p>
                  According to Dormann, a new research area is emerging on the basis of this unique data because the strong boomerang effect of burnout on work stress has not yet been investigated. Key questions that need to be addressed are: how can the effects of burnout on perceived work stress be reduced and how can the development of this vicious circle be prevented? Dormann and Guthier suggest that the place to start is with management behavior. Employees should have the opportunity to give feedback on their work stress at any time and be appreciated. Last but not least, proper recovery could also help to stop the downward spiral.
               </p><!-- Ende Inhalt Spalte Mitte -->
            </article>            <!--Ende-->
                     </div></div>]]>
            </description>
            <link>https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048455</guid>
            <pubDate>Tue, 10 Nov 2020 17:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Gods on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 303 | Comments 157 (<a href="https://news.ycombinator.com/item?id=25047838">thread link</a>) | @ivm
<br/>
November 10, 2020 | https://www.riknieu.com/the-gods-on-hackernews/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/the-gods-on-hackernews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tank_ghisletti?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Francisco Ghisletti</a> on <a href="https://unsplash.com/s/photos/greek-gods?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>(This post is mostly fun and tongue-in-cheek, please contain your indignation.)</p><p>Every so often I encounter a comment on HackerNews that involuntarily makes my jaw drop, head shake and eyes water. It's usually concerning what some on HackerNews consider a 'worthwhile' amount of money you can earn as an solopreneur or maker VS being an employee. </p><p>Obviously, it's probably a small minority of the silent masses who scroll through HN daily who have these views, but comments like the following, or a variant of it comes up so often I can't help but feel that a decent part of the community is <em>ridiculously</em> out of touch with the rest of humanity. </p><p>Behold.</p><!--kg-card-begin: html--><blockquote><p lang="und" dir="ltr">😂 <a href="https://t.co/mg1UFHxp08">https://t.co/mg1UFHxp08</a></p>— Pete from No CS Degree (@petecodes) <a href="https://twitter.com/petecodes/status/1326144308706209798?ref_src=twsrc%5Etfw">November 10, 2020</a></blockquote> <!--kg-card-end: html--><p>$1000 per month from a side project is considered meh. 😳 🙃</p><p>And here's another from the same day,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/soundslikealot.png"></figure><p>And from the same user a few scrolls later,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/FANG.png"></figure><p>My god. Look, the commenter had the self awareness to bring up regional cost of living and that not everyone can work at the FAMANGs of the world, but really? Getting $3.7 million dollars for just 7 years of work is, like, a bad deal?</p><p>To consider making $500K pa as a doable, realistic salary to be taken into account when deciding between starting a company or just seeking a job... Like us millennials say, "I can't. Even." </p><p>That annual salary far outstrips what I can reasonably expect to earn in a decade, and I'm a developer working for a fintech startup with a good couple of years under my belt. For most people in the world, $500K pa is a <em><strong>preposterous</strong></em> amount of money. </p><p>I'm too lazy to go dig up more examples, but I'm sure you'll find some more gems like these if you go digging around on past threads.</p><p>This kind of poo-pooing of what most - and I'm talking 90% of the US population, never mind the rest of the world! - would consider rather large amounts of money is incredibly mind-blowing and makes my head spin.</p><p>Now I'm sure that in commenters like the above's worlds, that kind of money is indeed average and peanuts, but I wanted to write this article for myself and the rest of us to just try and deal. </p><p>I'm trying to make sense of the fact that I'm on this forum, interacting with people everyday, talking about current events and issues, that make more money per year than I can even imagine. In a way we're peers, but more realistically they're like the gods of Olympus who occasionally slum it with the rest of us.</p><p>So if you're like me, and you consider even a $1000 as lot of money, let's look at this as average mortals should.</p><h2 id="1-1000pm-is-a-flippen-lot">1) $1000pm is a flippen lot</h2><p>Let's go with the $1000 pm example, because figures like $3.6 million is, to be frank, in the realms of La-La land for me and almost everyone I know personally. </p><p>And let's - for the sake of simplicity - assume that you can take home 60% of that revenue as net earnings. And that the project doesn't take up more free time with maintenance and support issues than you can handle on your own. That's $600 per month. Extra. From a thing on the side. </p><p>I realise that I live in one of those cheap, unappealing parts of the world, but that kinda money would easily cover me and my family's rent every month, and then some. Do you realise how much of a mental weight that can take off a persons shoulders? To know rent is covered over and above your day-job earnings?</p><p>Away with your $1000-is-not-worth-it malarky!</p><h2 id="2-making-money-with-your-own-products-is-hard-">2) Making money with your own products is HARD.</h2><p>Take a look at <a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">this post</a> by <a href="https://twitter.com/mccrmx">Chris McCormick</a>, titled "<a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">Holy heck this is hard</a>". </p><p>When he last checked, 12 solo founders out of 17207 made more than $10K MRR. Only 54 products made more than $2000pm. I don't think I need to express that in ratios for you to see the probability of making a profitable project.</p><p>Starting a product and <em>actually earning money from it</em> is hard. Insanely hard. Hell, if you manage to make even $100pm from a side project you've got my respect. You've got me beat by a lot!</p><p>When I see makers on IndieHackers or Twitter celebrate $100 in sales I get genuinely excited for them. It's really an incredible feat. Bravo to them, I wish them luck and more success in the future.</p><h2 id="that-1000-per-month-can-grow">That $1000 per month can grow</h2><p>Another thing to consider is that earning a $1000 pm means your project is basically validated and ready to explode. With work, you could probably scale it to much higher multiples. </p><p>Sure, the money it makes is negligible to the higher beings in Silicon Valley, but for us regular plebs that's a <em>strong</em> signal that your project potentially has legs. It might even be a project you could sell for $3.7 million dollars in 7 years time, if you put the work in and get a little lucky.</p><h2 id="ya-but-rik-cost-of-living">Ya, but Rik, cost of living</h2><p>Sure, things cost more in the States. And more so in SanFran. But I can't just up and go live in the States. Nor pretty much anywhere else in the First World. A heck of a lot of the people frequenting HN, TW and IH on a daily basis could probably not either.</p><p>So for people like us, it's inspiring to read about some rando making a $1000 pm, on their own, independently. It gives us hope that some dude in Alabama could start a thing and sell it for more money than we could expect to earn in a lifetime as a salaried employee. Because maybe that means we could too.</p><p>Because they used the same tools we have access too(except for Stripe 😝). They had access to the same markets we could reach. </p><p>And they make the kinds of money with those tools that could buy people like us freedom. Freedom from being chained to a job, freedom from financial stress, and possibly even the freedom to move our families to better places in the world. Places that others just get born in.</p><p>So when you see smarmy comments on HackerNews new putting down the success of others, take a step back and realise, it's not meant for you. It's not personal. </p><p>These are merely the musings of a few lucky, privileged gods, reflecting on the toils of the mortals.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. 👇</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/the-gods-on-hackernews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047838</guid>
            <pubDate>Tue, 10 Nov 2020 16:34:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the youtube-dl project]]>
            </title>
            <description>
<![CDATA[
Score 492 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25047818">thread link</a>) | @rg3
<br/>
November 10, 2020 | https://rg3.name/202011071352.html | <a href="https://web.archive.org/web/*/https://rg3.name/202011071352.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<h3><a href="https://rg3.name/202011071352.html">Origins of the youtube-dl project</a></h3>
<p>Posted on <time>2020-11-07T13:52Z</time>. Updated on <time>2020-11-10T16:28Z</time>.</p>


<p>As you may know, as of the time this text is being written <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl’s repository at GitHub</a> is blocked due to a <a href="https://github.com/github/dmca/blob/master/2020/10/2020-10-23-RIAA.md">DMCA takedown letter</a> received by GitHub on behalf of the RIAA. While I cannot comment on the current maintainers' plans or ongoing discussions, in light of the claims made in that letter I thought it would be valuable to put in writing the first years of youtube-dl as the project creator and initial maintainer.</p>
<div>
<h4 id="_copper_thieves">Copper thieves</h4>
<p>All good stories need at least a villain so I have arbitrarily chosen copper thieves as the villains of the story that set in motion what youtube-dl is today. Back in 2006 I was living in a town 5 to 10 kilometers away from <a href="https://en.wikipedia.org/wiki/Avil%C3%A9s">Avilés</a>, which is itself a small city or town in northern Spain. While people in Avilés enjoyed some nice infrastructures and services, including cable and ADSL Internet access, the area I lived in lacked those advantages. I was too far away from the telephone exchange to enjoy ADSL and copper thieves had been stealing copper wires along the way to it for years, causing telephone service outages from time to time and making the telephone company replace those wires with weaker and thinner wires, knowing they would likely be stolen again. This had been going on for several years at that point.</p>
<p>This meant my only choice for home Internet access so far had been a dial-up connection and a <a href="https://en.wikipedia.org/wiki/Modem#Standardized_56k_(V.90/V.92)">56k V.90 modem</a>. In fact, connection quality was so poor I had to limit the modem to 33.6 kbps mode so the connection would be at least stable. Actual download speeds rarely surpassed 4 KB/sec. <a href="https://en.wikipedia.org/wiki/YouTube">YouTube</a> was gaining popularity then to the point it was purchased by Google at the end of that year.</p>
</div>
<div>
<h4 id="_up_all_night_to_get_some_bits">Up all night to get some bits</h4>
<p>Watching any YouTube video on the kind of connection I described above was certainly painful, as you can imagine. Any video that was moderately big would take ages to download. For example, a short 10 MB video would take, if you do the math, 40 minutes to download, making streaming impossible. A longer and higher-quality video would take several hours and render the connection unusable for other purposes while you waited for it to be available, not to mention the possibility of the connection being interrupted and having to start the download process again. Now imagine liking a specific video a lot after watching it and wanting to watch it a second or third time. Going through that process again was almost an act of masochism.</p>
<p>This situation made me interested in the possibility of downloading the videos I was trying to watch: if the video was interesting, having a copy meant I could watch it several times easily. Also, if the downloader was any good, maybe the download process could be resumed if the connection was interrupted, as it frequently was.</p>
<p>At the time, there were other solutions to download videos from YouTube, including a quite popular <a href="https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/">Greasemonkey</a> script. By pure chance, none of the few I tested were working when I did, so I decided to explore the possibility of creating my own tool. And that is, more or less, how youtube-dl was born. I made it a command-line program so it would be easy to use for me and wrote it in Python because it was easy thanks to its extensive standard library, with the nice side effect that it would be platform independent.</p>
</div>
<div>
<h4 id="_an_ethereal_start">An Ethereal start</h4>
<p>The initial version of the program only worked for YouTube videos. It had almost no internal design whatsoever because it was not needed. It did what it had to do as a simple script that proceeded straight to the point. Line count was merely 223, with only 143 being actual lines of code, 44 for comments and 36 of them blank. The name was chosen out of pure convenience: youtube-dl was an obvious name, hard to forget, and it could be intuitively typed as “Y-O-U-TAB” in my terminal.</p>
<p>Having been using Linux for several years at that point, I decided to publish the program under a free software license (MIT for those first versions) just in case someone could find it useful. Back then, GitHub did not exist and we had to “make do” with <a href="https://en.wikipedia.org/wiki/SourceForge">SourceForge</a>, which had a bit of a tedious form that you needed to fill to create a new project. So, instead of going to SourceForge, I quickly published it under <a href="https://web.archive.org/web/20060812055952/http://www.arrakis.es/~rggi3/youtube-dl/">the web space that my Internet provider gave me</a>. While not usual today, it was common for ISPs to give you an email address and some web space you could upload stuff to using FTP. That way, you could have your own personal website on the net. The first ever version made public was 2006.08.08, although I probably had been using the program for a few weeks at that point.</p>
<p>To create the program, I studied what the web browser was doing when watching a YouTube video using Firefox. If I recall correctly, Firefox didn’t yet have the development tools it has today to analyze network activity. Connections were mostly HTTP and <a href="https://en.wikipedia.org/wiki/Wireshark">Wireshark</a>, known as “Ethereal” up to that year, proved invaluable to inspect the network traffic coming in and out of my box when loading a YouTube video. I wrote youtube-dl with the specific goal of doing the same things the web browser was doing to retrieve the video. It even sent out a User-Agent string that was verbatim copied from Firefox for Linux, as a way to make sure the site would send the program the same version of video web pages that were used to study what the web browser was doing.</p>
<p>In addition, YouTube used <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a> back then for the player. Videos were served as Flash Video files (FLV), and this all meant a proprietary plugin was required to watch them on the browser (many will remember the dreaded <code>libflashplayer.so</code> library), which would have made any browser development tools useless. This proprietary plugin was a constant source of security advisories and problems. I used a Firefox extension called <a href="https://en.wikipedia.org/wiki/Flashblock">Flashblock</a> that prevented the plugin from being loaded by default and replaced embedded content using the plugin, in web pages, with placeholder elements containing a clickable icon so content would be loaded only on demand and the plugin library was not used unless requested by the user.</p>
<p>Flashblock had two nice side effects apart from making the browsing experience more secure. On the one hand, it removed a lot of noisy and obnoxious ads from many web pages, which could also be a source of security problems when served by third parties. On the other hand, it eased analyzing how videos were being downloaded by the video player. I would wait until the video page had finished downloading completely and then start logging traffic with Wireshark just before clicking on the embedded video player placeholder icon, allowing it to load. This way, the only traffic to analyze was related to the plugin downloading the video player application and the application itself downloading the video.</p>
<p>It’s also worth noting the Flash Player plugin back then <a href="https://www.nirsoft.net/articles/copy_flash_flv_temp_file.html">was already downloading a copy of those videos to your hard drive</a> (they were stored in <code>/tmp</code> under Linux) and many users relied on that functionality to keep a copy of them without using additional tools. youtube-dl was simply more convenient because it could retrieve the video title and name the file more appropriately in an automated way, for example.</p>
</div>
<div>
<h4 id="_ahh_fresh_meat">Ahh, fresh meat!</h4>
<p>The Flash Player plugin was eventually <a href="https://www.omgubuntu.co.uk/2010/09/saving-flash-videos-in-linux-tmp-no-longer-works">modified so videos wouldn’t be so easily available to grab</a>. One of the first measures was to <a href="https://en.wikipedia.org/wiki/Unlink_(Unix)">unlink</a> the video file after creating it, so the i-node would still exist and be available to the process using it (until it was closed) while keeping the file invisible from the file system point of view. It was still possible to grab the file by using the <code>/proc</code> file system to examine file descriptors used by the browser process, but with every one of those small steps youtube-dl turned to be more and more convenient.</p>
<p>As many free and open source enthusiasts back then, I used <a href="https://en.wikipedia.org/wiki/Freecode">Freshmeat</a> to subscribe to new releases of projects I was interested in. When I created youtube-dl, I also created a project entry for it in that website so users could easily get notifications of new releases and a change log listing new features, fixes and improvements. Freshmeat could also be browsed to find new and interesting projects and its front page contained the latest updates, which usually amounted to only a few dozens a day. It’s only my guess that’s the way <a href="https://en.wikipedia.org/wiki/Joe_Barr">Joe Barr</a> (rest in peace), an editor for <a href="https://en.wikipedia.org/wiki/Linux.com">linux.com</a>, found out about the program and decided to write <a href="https://www.linux.com/news/cli-magic-enhance-your-youtube-viewing-pleasure/">an article about it</a> back in 2006. Linux.com was a bit different then and I think it was one of the frequently-visited sites for Linux enthusiasts together with other classics like <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a> or <a href="https://en.wikipedia.org/wiki/LWN.net">Linux Weekly News</a>. At least, it was for me.</p>
<p>From that point on, youtube-dl’s popularity started to grow and I started getting some emails from time to time to thank me for creating and maintaining the program.</p>
</div>
<div>
<h4 id="_measuring_buckets_of_bits">Measuring buckets of bits</h4>
<p>Fast forward to the year 2008. youtube-dl’s popularity had kept growing slowly and users frequently asked me to create similar programs to download from more sites, a request I had conceded a few times. It was at that point that I decided to rewrite the program from scratch and make it support multiple video sites natively. I had some simple ideas that would separate the program internals into several pieces. To simplify the most important parts: one would be the file downloader, common for every website, and another one would be the information extractors: objects (classes) that would contain code specific to a video site. When given a URL or pseudo-URL, the information extractors would be queried to know which one could handle that type of URL and then requested to extract information about that video or list of videos, with the primary goal of obtaining the video URL or a list of video URLs with available formats, together with some other metadata like the video titles, for example.</p>
<p>I also took the chance to switch version control systems and change where the project would be hosted. …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rg3.name/202011071352.html">https://rg3.name/202011071352.html</a></em></p>]]>
            </description>
            <link>https://rg3.name/202011071352.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047818</guid>
            <pubDate>Tue, 10 Nov 2020 16:33:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jack Ma's Bund Finance Summit Speech]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25047544">thread link</a>) | @ceohockey60
<br/>
November 10, 2020 | https://interconnected.blog/jack-ma-bund-finance-summit-speech/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/jack-ma-bund-finance-summit-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!-- social share icon -->
                    

                    <p><em>I don’t normally do any translation, because Interconnected is focused on original work and thinking. But I felt compelled to provide an English version of Jack Ma’s speech on October 24 at the Bund Finance Summit in Shanghai, because mainstream media coverage of the speech and the subsequent cancellation of Ant Group’s IPO has been lacking and simplistic. The speech is worth reading in its entirety to have a deeper understanding the full picture. Below is my unofficial translation of the speech </em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>based on a Chinese transcript</em></a><em>, with minor edits for clarity and speechifying. To read my deep dive analysis on the speech and its broader context, please check out: "<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">Jack Ma, P2P Lending, Responsibility, Legacy</a>"</em></p><p><em>我通常不做任何翻译工作，因为《互联》专注于原创作品和思考。但我觉得有必要提供马云10月24日在上海外滩金融峰会上的演讲的一个英文版，尽管只是我个人非官方的翻译，因为主流媒体对演讲和随后蚂蚁集团取消上市的报道太欠缺，过于简单化。整套演讲值得一读来更深层的了解整个事情，可以在</em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>这里看全文</em></a><em>，在</em><a href="https://finance.sina.com.cn/chanjing/gsnews/2020-10-28/doc-iiznctkc8161643.shtml"><em>这里看视频</em></a><em>。想看我对这套演讲和有关大观景的深度分析，请读《<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">马云，P2P借贷，责任，留给社会的遗产</a>》</em></p><hr><p>Thank you for inviting me to this Summit. I am delighted to have this opportunity to learn, discuss, and exchange ideas together with you. In 2013, also in Shanghai, I came to the Lujiazui Finance Summit and shared some “pie in the sky” views about Internet-powered finance. Seven years later, today I'm back in Shanghai as an unofficial non-professional person here at the Bund Finance Summit, hoping to share more ideas for you to ponder.</p><p>Actually, I was quite torn about whether to speak here today. But I think there is one thing that is incumbent upon this group of people, and that is the responsibility to think about the future, because although the world has left us many opportunities for development, there are really only one or two critical opportunities. This is a most critical moment.</p><p>So I come here to share some of my own thoughts and views, which are the result of our own practical experience in the last 16 years, plus discussions and research I have had with scholars, experts, and practitioners from all over the world, during the period when I was honored to be the co-chair of the UN High-Level Panel on Digital Cooperation and an advocate for the UN Sustainable Development Goals (SDGs).</p><p>I’m basically retired at this point, so I thought I'd speak freely at this unofficial forum and share the non-professional views of a non-professional person. Fortunately, I've discovered that many professionals no longer speak about their professions anymore.</p><p>I have three points of view for you to consider. They may be immature, incorrect, or laughable. Just give them a listen, if they make no sense, just forget about them.</p><p>The first point of view is we have some inertia in our thinking, like we always feel that in order to keep pace with international standards, we must do what developed countries like Europe and the United States have done. If we don’t have something they have, the so-called “blank spot”, we must fill those blank spots domestically. Filling these spots has become the goal to pursue.</p><p>I have always felt that, given this year's situation, the phrase to “fill the blank spot” is problematic. Just because Europe and the United States have something does not mean that thing is always advanced and worth having ourselves. In fact, today, we should not be concerned about what things to align with, which country's standard to adapt to, what blank spots to fill. Today, we have to think about how to align with the future, how to adapt to the future’s standard, how to fill the future’s blank spots. We have to figure out what the future will be, and what we really want to do, and then look at how others do it. If we always repeat the language of others, discuss topics defined by others, we will not only be lost in the present, but also miss the future.</p><p>After World War II, the world needed to restore economic prosperity. The establishment of the Bretton Woods system was an enormous catalyst to the global economy. Later, after the Asian financial crisis occurred, the Basel Accords talked about risk control, which has been gaining more and more attention, to the point that it became an operational standard for risk control. Now the trend is, the world is talking more and more just about risk control, not development. Very few people talk about where the opportunities are for young people, for developing countries.</p><p>This, in fact, is the root cause of many of the world's problems today. We also see today that the Basel Accords have put great limitations on Europe’s ability to innovate as a whole, for example, in digital finance.</p><p>Basel, more like a seniors club, is about solving the problem of an aging financial system that has been operating for decades, and Europe’s aging system is extremely complex. But the problem in China is the opposite: it is not a problem of systemic financial risk, because China's financial sector basically doesn’t have a system. Its risk is actually a "lack of financial system."</p><p>China's financial sector, like other developing countries that have just grown up, is a young industry that does not have a mature ecosystem and is not fully moving. China has many big banks. They are more like big rivers or arteries in our body’s circulatory system, but today we need more lakes, ponds, streams and tributaries, all kinds of swamps. Without these parts of the ecosystem, we will die when we are flooded, and die when we are in a drought. So, today we are a country that bears the risk of lacking a healthy financial system, and we need to build a healthy financial system, not worry about financial systemic risks.</p><p>They are like two completely different diseases, like Alzheimer's disease and polio. Both look similar at first glance but are two totally different illnesses. If a child takes Alzheimer's medication, he or she will not only get the old person’s disease, but a lot of other strange diseases as well.</p><p>The Basel Accords is designed to treat the diseases of the elderly with an aging system and over-complexity, and what we have to think about is what can we learn from the elderly? You must remember, older people and younger people care about different issues. Younger people care about whether there are schools, older people care about whether there are hospitals.</p><p>So, the way the world is changing this year is fascinating and very fast. Last night in Shanghai, we decided on the pricing of Ant’s IPO. This is the largest listing ever priced in the history of the entire human race, and the pricing happened in a place other than New York City. This was unthinkable five years ago, even three years ago, but miracles happen.</p><p>Second, innovation must come at a price, and our generation must take on that responsibility.</p><p>President Xi once said, "success does not have to come from me." I understand this phrase to be about a sense of responsibility. It’s about taking responsibility for the future, for tomorrow, for the next generation. Many of the world's problems today, including China's, can only be solved by innovation. However, for real innovation to happen, no one will show you the way, and someone must shoulder that responsibility, because innovation is bound to make mistakes. But the question is not how not to make mistakes, but whether we can perfect and correct them after making mistakes and persistently innovate. To make risk-free innovation is to stifle innovation, and there is no risk-free innovation in this world. There is no such thing as risk-free innovation. Oftentimes, managing risk down to zero is the biggest risk.</p><p>When the battle of Red Cliff was fought, I believe Cao Cao’s act of connecting all the ships together was the first instance of an aircraft carrier, in China and the world, but after a fire burned it all down, for a thousand years, the Chinese people didn't dare to think about it again. Once they thought about that fire, who still wanted to make a bigger ship, who could still have this kind of system-level thinking?</p><p>Seven or eight years ago, also in Shanghai, I mentioned this concept of Internet-powered finance. We have always emphasized that Internet-powered finance must have three core elements: first, it must have rich data; second, it must have risk control technology based on rich big data; and third, it must have a credit-based system built on big data.</p><p>Using these three criteria to evaluate, we can see that P2P is not Internet-powered finance at all, but today we cannot negate the innovation that the Internet has brought to finance just because of P2P. In fact, let's think about it, how can there be thousands of Internet-powered finance companies in China within a few years? Shouldn't we examine what gave birth to thousands of “Internet-powered finance”, the so-called P2P companies?</p><p>Today, it's really difficult to regulate ourselves; it's hard to conduct regulation everywhere around the globe. Innovation mainly comes from the marketplace, innovation comes from the grassroots, innovation comes from young people. Regulatory challenges are getting bigger and bigger. In fact, <em>jian </em>[editor's note: English word is “supervision”, the first character in the word for “regulation” in Chinese] and <em>guan </em>[editor's note: English word is “management”, the second character in the word for “regulation” in Chinese] are two different things. "Supervision" means watching you as you develop and paying attention to your development. “Management” means intervening when there is a problem or when there is a foreseeable problem.</p><p>We are very good at “management”, but our “supervision” ability is sorely lacking.</p><p>Good innovation is not afraid of regulation, but is afraid of being subjected to yesterday's way to regulate. We cannot use the way to manage a railway station to manage an airport. We cannot use yesterday's way to manage the future.</p><p>"Supervision" and "management" are not the same, “policies” and “documents” are also not the same. This isn’t allowed, that isn’t allowed, those are all called “documents”. Policy …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/jack-ma-bund-finance-summit-speech/">https://interconnected.blog/jack-ma-bund-finance-summit-speech/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/jack-ma-bund-finance-summit-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047544</guid>
            <pubDate>Tue, 10 Nov 2020 16:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C source-to-source compiler enhancement from within]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25047169">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://hal.inria.fr/hal-02998412 | <a href="https://web.archive.org/web/*/https://hal.inria.fr/hal-02998412">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p><strong>Abstract</strong> : We show how locally replaceable code snippets can be used to easily
  specify and prototype compiler and language enhancements for the
  C language that work by local source-to-source
  transformation.
  A toolbox implements the feature and provides many directives that
  can be used for compile time configuration and tuning, code
  unrolling, compile time expression evaluation and program
  modularization.
  The tool is also easily extensible by simple filters that can be
  programmed with any suitable text processing framework.                    </p>
                                </div><p><small>
                https://hal.inria.fr/hal-02998412<br>
                Contributeur : <a rel="nofollow" href="https://hal.inria.fr/search/index/q/*/contributorId_i/105206" target="_blank">Jens Gustedt</a>                        &lt;<a href="" id="link5fad64a37d880"></a>&gt;
                        <br>Soumis le : mardi 10 novembre 2020 - 15:02:12<br>DerniÃ¨re modification le : mercredi 11 novembre 2020 - 03:36:16</small>
        </p></div>]]>
            </description>
            <link>https://hal.inria.fr/hal-02998412</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047169</guid>
            <pubDate>Tue, 10 Nov 2020 15:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading, Wisely – How I'm Using Readwise to Improve My Learning]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046762">thread link</a>) | @ggnall
<br/>
November 10, 2020 | https://www.grahamgnall.com/blog/2020/11/9/reading-wisely | <a href="https://web.archive.org/web/*/https://www.grahamgnall.com/blog/2020/11/9/reading-wisely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-9da5bc9359b1bdaa3cf4"><div><p>Readwise is a utility that’s changed the way I read. I'm thoroughly enjoying it and I recommend it to anyone looking to improve their learning. You can sign up for a trial here:</p>
<p><a href="https://readwise.io/">Readwise - plain link</a></p>
<p><a href="https://t.co/3y8bAXryW7?amp=1">Readwise - my referral link</a></p>
<h2 id="about">About</h2>
<p>Readwise is an app (browser extension, web app, mobile app) that organizes information from the books you read. The app relies on learning techniques like <a href="https://en.wikipedia.org/wiki/Spaced_repetition">spaced repetition</a> to train your memory on your reading highlights and annotations.</p>
<h2 id="benefits">Benefits</h2>
<p><strong>Retention</strong></p>
<p>Readwise makes it easy to retain information you’ve read and deemed important in the past. I try to read constantly, but when I look at my <a href="https://www.grahamgnall.com/books">Books</a> list, there are plenty of subjects that are blurry or shockingly, missing altogether from my memory. I’ve been a Kindle device/app enthusiast and previously built my own scripts to export and organize my highlights. It was fun, but I ended up spending more time writing the so-called automation than actually reviewing the highlights. Readwise handles all of the syncing automatically from all your ebooks and articles, and even supports input from physical books. Its Daily Readwise review feature is a daily, randomized feed of highlights that surfaces old and new content to train on.</p>
<p><strong>Making New Connections</strong></p>
<p>There is a thrilling feeling when your mind makes connections between two seemingly disparate topics. This is foundational in my belief in <a href="https://www.grahamgnall.com/blog/2014/7/9/learn-disciplines-not-skills-startups-for-liberal-arts-majors">liberal arts education</a> and it's applications. The simple act of viewing highlights from multiple, unrelated books in the Daily Readwise allows your brain to play with these concepts on the same plane. Readwise’s tagging feature allows you to group highlights about the same topic or theme, so you can build your knowledge base with more examples and perspectives. Both of these features aid in constructing, expanding, and applying mental models to the world, or what Charlie Munger called a <a href="https://fs.blog/great-talks/a-lesson-on-worldly-wisdom/">“latticework”</a> of models from different disciplines.</p>
<h2 id="how-i-use-it">How I Use It</h2>
<p><strong>Set Up</strong></p>
<p>I mostly use the core Readwise syncing sources:</p>
<ol>
<li>Kindle - automated</li>
<li>Pocket - automated</li>
<li>Non-kindle ebooks - semi-automated, requires one manual step when I finish a book</li>
<li>Physical books - manual, but with highly reliable OCR.</li>
</ol>
<p>There are also other a growing number of non-traditional sources like Twitter threads and podcast annotations. I haven’t tried them out yet, but they look promising.</p>
<p>The default settings are thoughtfully done to maximize your learning right out of the box (e.g. 5 daily items, mix of old and new highlights). You can get really granular configuring these settings, down to the book/article level. So far, I’ve only used this to filter out certain things, like definitions from a Javascript textbook I read in 2012. </p>
<p><strong>Developing a Review Habit</strong> </p>
<p>The best product experiences create new habits and rituals around them, for a positive result. Readwise has created a few distinct habits for me. I look forward to my Daily Readwise and it’s one of the few things I let myself do on my phone when waking up. This takes less than a minute and is easy to implement. I never have to schedule in time for this and I never miss it.</p>
<p>Readwise sits on my home screen and I’ve started to open it whenever I need a “feed fix”. It takes my boredom trigger and offers something more valuable than a dopamine hit. Sometimes I’ll do a few cycles of 5 items before calling it quits and going back to whatever I was supposed to be doing. </p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_44801"><div><p><strong>Developing Better Reading Habits</strong></p>
<p>Readwise has also changed the way I read. I now look for insights that I want to extract and return to later far more deliberately. I’ve found that even for books I abandon, if I was able to pull a single interesting idea out of it, I got some value out of it. This has reduced the guilt of putting down a book that can’t hold my attention. Or in the case of many business books, lets me extract the primary bits in the beginning without slogging through the filler.</p>
<p>The same applies to how I approach articles. I now view all types of text as holding information I can extract for my own purposes. I'm excited to uncover items to clip and have been delighted by the easy inputs into Readwise, including: highlighting directly in my browser, copy/pasting text from a mobile app, or taking an image of a physical book or magazine. This lets me jot things down, like book recommendations, without having to leave the text and pick them up later. </p>
<p><strong>Organizing Information</strong></p>
<p>I’ve always liked the idea of linking ideas together and this was lacking in my homegrown version of this tool. In addition to notes, you can also add freeform tags to your highlights. This makes it easy to view all your highlights that relate to theme like <code>writing</code> or <code>decision-making</code>. I use this feature to learn about a specific topic. I’m very interested in learning about the routines and processes of interesting creators, and I’ve started to aggregate tags for <code>routine</code> and <code>process</code> for instance. </p>
<p>I use the Daily Review to tag anything that fits into my ongoing areas of interest.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604956577898_10298"><p>The free-form search is also a great way to pull in notes on a specific topic. Feeling homesick recently, I typed in “new york” and saw some highlights that made me smile:</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_70588"><div><h2 id="last-word">Last Word</h2>
<p>I was happy to drop my hacky version for a simple, easy, and well-designed product. It's helping me to create better habits and reinvigorating my reading pracitce.</p>
<p>I'm training myself to spend on well-designed software products so that such things can exist. Unfortunately paid apps are still a boundary for many - and hopefully the COVID trend of increased subscription spending will change that. For me, the $8.99 / month is well worth the increased utility from books I’ve already purchased (usually for the low Amazon set price of $9.99). I’m sure this was intentional: get more out of your books for less than the already low price of a book a month. Better yet, it makes me <em>excited</em> to buy and read more books.</p>
<p>Of course, if you want to apply these lessons to a self-hosted system you can. You can scrape (pun intended) together your own version by parsing the Kindle Cloud Reader (and other reading apps) to a database (including no-code databases in Notion, Airtable, and even Google Sheets) and building out the necessary views. Or you can keep it lo-fi. I’ve heard of several non-fiction authors using a index card based version of Readwise, where they group passages from different sources by them. I wouldn’t be surprised if this tradition influenced Readwise's card ui and tag features. </p>
<p>And then you <em>could</em> always take it further. While many in the <em>organized thinking</em> movement (or <a href="https://twitter.com/cultroam?lang=en">roamcult</a>) are using Readwise’s Notion and Roam exports to develop fully mapped information on <em>everything</em>, I find the Readwise experience to be fully satisfactory on its own.</p>
</div></div></div>]]>
            </description>
            <link>https://www.grahamgnall.com/blog/2020/11/9/reading-wisely</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046762</guid>
            <pubDate>Tue, 10 Nov 2020 15:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The state of JavaScript at the end of 2020]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046293">thread link</a>) | @milo_im
<br/>
November 10, 2020 | https://www.ideamotive.co/javascript-business-guide | <a href="https://web.archive.org/web/*/https://www.ideamotive.co/javascript-business-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
           <p><span id="hs_cos_wrapper_pillarPage_content" data-hs-cos-general-type="widget_container" data-hs-cos-type="widget_container"><p id="hs_cos_wrapper_widget_1603280203415" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>00</span>
        
        
          <span>State of JavaScript in 2020 [INFOGRAPHIC]</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1603200140243" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p><img src="https://www.ideamotive.co/hs-fs/hubfs/Pillar%20JS/JavaScript%20in%202020%20C%20(4).png?width=1439&amp;quality=low" alt="JavaScript in 2020 C (4)"></p>

    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603280336294" data-hs-cos-general-type="widget" data-hs-cos-type="module">









  <div>
    <p> Share the infographic in social media </p>
    
  </div>


</div>
<p id="hs_cos_wrapper_widget_1601646578122" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>01</span>
        
        
          <span>What is JavaScript?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601646616007" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>You might have heard that “JavaScript is everywhere.” Which is where exactly?&nbsp;&nbsp;</p>
<p>According to <a href="https://w3techs.com/technologies/details/cp-javascript" rel="noopener" target="_blank">Web3Techs</a> — on over 96% of all websites. Google, LinkedIn, Yahoo, YouTube, eBay, Amazon, you name it. There’s JavaScript all over the place.&nbsp;</p>
<p>Created in 1995 by Brendan Eich, JavaScript is a scripting language used to build and manage dynamic web content, such as multimedia, interactive forms, animations, photo slideshows, calendars, autocomplete suggestions, and much more.</p>
<p>JS is one of the three core technologies of frontend web development, along with HTML and CSS. While HTML is a markup language responsible for giving the structure to a website, and CSS is a language used to apply styles to HTML content, JavaScript is responsible for creating and managing dynamic, interactive website elements.</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069795205" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        Who is the JavaScript creator?
      </h3>
    
    
      <div>
        <p>Born in 1961, <a href="https://www.linkedin.com/in/brendaneich/" rel="noopener" target="_blank"><span>Brendan Eich</span></a> is an American technologist, software engineer, and keynote speaker. After joining Netscape Communications in 1995, Eich created a language to support the browser. It was designed based on Java’s syntax and standard library, and with object names that corresponded to Java classes.&nbsp;</p>
<p>In 1998, Eich co-founded the Mozilla project, ultimately leading to the creation of the Mozilla Foundation, which later became <a href="https://www.mozilla.org/en-US/foundation/moco/" rel="noopener" target="_blank"><span>Mozilla Corporation</span></a>. After leaving Mozilla, Eich set up another company, <a href="https://brave.com/" rel="noopener" target="_blank"><span>Brave Software</span></a>, developing a privacy-oriented browser combined with a blockchain-based digital advertising platform.</p>
      </div>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601646749682" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>Is JavaScript a programming language?</h3>
<p>Yes! As the name implies — JavaScript is a <em>scripting language</em>. Traditionally, scripting languages are executed one line at a time by an interpreter, so a computer program that directly executes the written instructions. This stands in opposition to <em>compiled languages</em>, such as C++, for instance, which must run through a compiler before they can be translated into binary code.&nbsp;</p>
<p>Currently, it is possible to run JS with a just-in-time compiler, too. It compiles the code on the fly and caches the result to speed up the subsequent runs. Still, JavaScript remains a scripting language.</p>
<p>&nbsp;As a programming language, JavaScript is:</p>
<ul>
<li><strong>High-level</strong> – high-level languages resemble natural languages or mathematical notation, which helps simplify programming, including code updates and extensions.</li>
<li><strong>Dynamic </strong>– as a dynamic language, JS uses dynamically-written code to quickly implement functionality to an application, in a way that enhances programming efficiency.</li>
<li><strong>Prototype-based </strong>– JavaScript’s structure is based on prototypical objects, which can be cloned and reused as templates to build new objects. Prototypes also enable building associations between objects in JS. Copying and modifying objects are more direct than in class-based languages such as Java, which simplifies coding and reduces the programmer’s cognitive load.</li>
<li><strong>Multi-paradigm </strong>– JS supports event-driven, functional, and imperative programming styles, which makes it a multi-paradigm language. This results in its flexibility and enables different approaches to development.&nbsp;</li>
</ul>
<h3>Is JavaScript open source?</h3>
<p>Open source applies to software, and JS is a programming language, so no, JS is not open source. However, it’s an open standard that conforms to <a href="https://www.ecma-international.org/ecma-262/" rel="noopener" target="_blank"><span>ECMAScript</span></a> specification. Anyone can use it to develop their own implementations.&nbsp;</p>
<p>For JS to produce any output, we need <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)" rel="noopener" target="_blank"><span>interpreter engines</span></a>, each of which is subject to its own license agreement. For example, <a href="https://v8.dev/" rel="noopener" target="_blank"><span>Google’s V8</span></a>, <a href="https://github.com/facebook/hermes" rel="noopener" target="_blank"><span>Facebook’s Hermes</span></a>, or <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Projects/Rhino" rel="noopener" target="_blank"><span>Mozilla’s Rhino</span></a>, they are all open source. By contrast, <a href="https://jerryscript.net/" rel="noopener" target="_blank"><span>Jerryscript</span></a> is licensed under the Apache License.</p>
<h3>The difference between JavaScript library and framework</h3>
<p>While interpreters are essential to generate JS output, frameworks and libraries are optional but highly recommended. These are <strong>prewritten components that your JavaScript team can use to build robust, highly-performant code faster</strong>. They offer significant advantages to your business, too, from reducing code size and complexity to speeding up the deployment of your project.&nbsp;</p>
<p>Sometimes, e.g., in the case of React, it’s hard to categorically determine whether a given resource is a framework or a library. Nevertheless, in theory, the two notions are distinct.</p>
<p><strong><img src="https://www.ideamotive.co/hubfs/The%20difference%20between%20JavaScript%20library%20and%20framework%20(2).png" alt="The difference between JavaScript library and framework (2)"></strong></p>
<h4>Framework</h4>
<p>A <strong>framework </strong>is a software platform that lays the groundwork for programmers to develop applications. You can compare it to a house plan or blueprint that needs to be populated with input before the construction begins.&nbsp;</p>
<p>Same with a software framework; it is pre-equipped with code for predefined classes, workflows, and functions, but needs specific details to be supplied by the programmer before it can run a complete code.&nbsp;</p>
<p>Popular JS frameworks include Angular, Bootstrap, and Vue.js.</p>
<p><strong>Jump to </strong><a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener"><strong><span>this section</span></strong></a><strong> to learn more about JS frameworks.&nbsp;</strong></p>
<h4>Library</h4>
<p>A <strong>library</strong>, like a framework, refers to a reusable piece of code; however, libraries are usually focused on delivering a specific functionality/component, and give developers greater freedom over the code structure than frameworks. Coming back to the house metaphor: libraries can be compared to ready-made pieces of furniture or appliances that we choose to make our home complete.&nbsp;</p>
<p>The main difference between a library and a framework is that a library contains snippets of ready-made code that needs to be still arranged by the developer into a workflow. Frameworks, on the other hand, are in charge of running workflows. Additionally, one framework can utilize multiple libraries.</p>
<p>There are dozens of JS libraries available, with DOJO, jQuery, and React topping popularity charts.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069971226" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
    
      <p>While most JavaScript developers rely on specific frameworks and libraries, some of them also build applications using the so-called “Vanilla JavaScript,” i.e., pure JS code without any additional resources. However, this approach is infrequent.</p>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601647248048" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>How does JavaScript work?</h3>
<p>JavaScript is primarily used in the form of<strong> client-side JavaScript</strong>. This means it is typically running on client devices (laptops, smartphones, PCs, and others) communicated with the network.&nbsp;</p>
<p>In the client-side context, scripts execute directly in the browser, which results in faster processing and immediate response to the user’s requests. Because of the speed and more lightweight script processing on the client side, this model is preferred to implement dynamic, interactive web content and handle user interactions.</p>
<p>An extended version of JS allows it to be run on the server side, with backend access to files, databases, and servers. In this context, JS code is created similarly to C, Java, or any other server-side language.</p>
<p><strong>Server-side JavaScript</strong> can be applied to handle logging in, manage personal information and preferences, and fetch specific files or data as requested by the user. <a href="https://nodejs.org/" rel="noopener" target="_blank"><span>NodeJS</span></a> is commonly used as a runtime environment to execute JavaScript code outside a web browser</p>
<p><strong>See also section <a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener">The most popular JavaScript frameworks</a>.</strong></p>
<p>Currently, JS is the only commonly-recognized client-side language for browsers apart from WebAssembly, which is rather to be seen as a complementary technology. Alternative solutions like Java applets, Silverlight, or ActiveX, have all been discontinued by now.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603785890114" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        What is the difference between Java and JavaScript?
      </h3>
    
    
      <p>We’ve seen it happen too many times... A job posting for JavaScript talent with a “Java Developer” header. A few years ago, the confusion between the two languages was so common it became anecdotal. Today, it seems to be a thing of the past.The two languages could not be further from the same thing. Still, just in case you (or your HR department) need a little recap, here are the core differences between Java and JS:</p>
    
  </div>

</div>

<div id="hs_cos_wrapper_widget_1601896662232" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>What can you build with JavaScript?</h3>
<p>Originally, JavaScript was conceived to add interactivity into static browser pages. While today, it is still mostly used to enrich websites with animated, lively components, its capabilities also cover the creation of:</p>
<ul>
<li>Robust web and server applications</li>
<li>Stunning business presentations</li>
<li>Interactive gaming platforms</li>
<li>Multi-functional mobile apps</li>
<li>Smart device applications&nbsp;</li>
</ul>
<p><strong><br>For more details</strong><a href="https://www.ideamotive.co/javascript-business-guide#what-is-javascript-used-for" rel="noopener"><strong><span> jump to the next chapter</span></strong></a></p>
<h3><span>How is JavaScript different from TypeScript?</span></h3>
<p>If you already have some grasp of JavaScript, you might have stumbled upon <a href="https://www.typescriptlang.org/" rel="noopener" target="_blank"><span>TypeScript</span></a>. A superset of JS, TypeScript is a modern programming language developed and maintained by Microsoft. It was publicly released in 2012 as a tool for the development of large applications in JS (“JavaScript that scales” — states the official slogan). TypeScript simplifies JavaScript code, making it easier to read and debug, and at the same time, it expands on JS capabilities.</p>
<p><strong>See also: </strong><a href="https://www.ideamotive.co/javascript-business-guide#javascript-vs-typescript" rel="noopener"><strong><span>JavaScript vs. TypeScript</span></strong></a></p>
    </div>
  </section>

</div>
<p id="hs_cos_wrapper_widget_1601896842863" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="what-is-javascript-used-for">
    
      <h2>
        
          <span>02</span>
        
        
          <span>What is JavaScript used for?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601896857056" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>In the introduction, we have already covered some of the key JavaScript applications. Here, we will add some more details about each use of the language.</p>
<h3>Adding interactive website components</h3>
<p>JavaScript was made to create and control dynamic website content, and this task remains its primary application. A vast majority of developers use JS to enhance Internet web pages with interactive features such as:</p>
<ul>
<li>dynamic forms</li>
<li>animated graphics</li>
<li>autocomplete suggestions</li>
<li>photo slideshows</li>
</ul>
<p>If we said that everyone uses JS on their website, this wouldn’t be much of an overstatement. JS powers over 90% of all global sites, including those of …</p></div></section></div></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ideamotive.co/javascript-business-guide">https://www.ideamotive.co/javascript-business-guide</a></em></p>]]>
            </description>
            <link>https://www.ideamotive.co/javascript-business-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046293</guid>
            <pubDate>Tue, 10 Nov 2020 14:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Micro 3.0 is a platform for cloud native development]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25044604">thread link</a>) | @asim
<br/>
November 10, 2020 | https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html | <a href="https://web.archive.org/web/*/https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      
      
      

      <p>This is the official announcement for the release of Micro 3.0 better known as M3O - a platform for cloud native development. 
Our 3.0 release is a major refactor and consolidation of the existing tooling into something that addresses the entire workflow 
of build, run, manage and consume all from the developers perspective.</p>

<p>Read on to learn more or go straight to the <a href="https://github.com/micro/micro/releases/latest">latest release</a>. 
Head to <a href="https://m3o.com/">m3o.com</a> for the hosted offering.</p>

<h2 id="overview">Overview</h2>

<p>Micro focuses on developer productivity for the backend. It’s clear that the Cloud has become infinitely more complex 
over the past few years. Micro attempts to create order out of that chaos by distilling it all down to a handful of 
primitives for distributed systems development.</p>

<p>Why should you care? If you’re reading this you’ve no doubt encountered the tedious nature of infrastructure management, 
wrangling a kubernetes cluster on AWS or the thousands of things you need to do to cobble together a platform before 
starting to build a product. We think we’ve nailed the solution for that just as Android did for Mobile. Keep reading 
if you want to find out more.</p>

<h2 id="quick-flashback">Quick Flashback</h2>

<p>Micro started out as a <a href="https://micro.mu/blog/2016/03/20/micro.html">toolkit for microservices</a> development, 
incorporating an api gateway, web dashboard and cli to interact with services built using a Go RPC framework. 
Back then it felt like getting anyone to buy into PaaS again was going to be a losing battle. So we chose 
to write single purpose tools around an RPC framework thinking it might allow people to adopt it piece by piece 
until they saw the need for a platform. It was really straight forward right until it wasn’t.</p>

<p>There was a simple Go framework plus some surrounding 
components to query and interact with them, but like any long lived project, the complexity grew as we 
tried to solve for that platform experience that just couldn’t be done with a swiss army knife. The repo 
exploded with a number of independent libraries. To the creator its obvious what these are all for but to 
the user there is nothing but cognitive overload.</p>

<p>In 2019 we went through a <a href="https://micro.mu/blog/2019/06/10/the-great-consolidation.html">consolidation</a> of all those libraries 
which helped tremendously but there was still always one outstanding question. What’s the difference between 
<a href="https://github.com/micro/micro">micro</a> and <a href="https://github.com/micro/go-micro">go-micro</a>? It’s a good 
question and one we’ve covered before. We saw go-micro as a framework and micro as a toolkit but these 
words were basically empty and meaningless because multiple projects working in coordination really need a 
crisp story that makes sense and we didn’t have one.</p>

<p>In 2020 we’re looking to rectify that but let’s first let’s talk about platforms.</p>

<h2 id="paas-in-2020">PaaS in 2020</h2>

<p>5 years ago the world exploded with a proliferation of “cloud native” tooling as containers and 
container orchestration took centre stage. More specifically, Docker and Kubernetes redefined the 
technology landscape along with a more conscious move towards building software in the cloud.</p>

<p>Micro took a forward looking view even as far back as 2015. It was clear distributed systems and cloud native 
was going to become the dominant model for backend services development over the coming years but, what wasn’t clear 
is just how long we’d spend wrangling all sorts tools like docker, kubernetes, grpc, istio and everything else. 
It felt like we were rebuilding the stack and weren’t really ready to talk about development aspects of it all.</p>

<p>In fact at that time, people mostly wanted to kick the tyres on all these tools and piece something together. 
Running kubernetes yourself became all the rage and even using service mesh as the holy grail for solving 
all your distributed systems problems. Many of us have come to realise while all of this tech is fun 
it’s not actually solving development problems.</p>

<p>We’ve gotten to the point of managed kubernetes and even things like Google Cloud Run or DigitalOcean App 
Platform, but none of these things are helping with a development model for a cloud native era. Our 
frustrations with the existing developer experience have grown and Micro felt like something that 
could solve for all that, but only if we took a drastic step to overhaul it.</p>

<p>We think PaaS 3.0 is not just about running your container or even your source code but something that 
encapsulates the entire developer experience including a model for writing code for the cloud. Based on that 
Micro 3.0 aka M3O is a platform for cloud native development.</p>

<h2 id="what-even-is-cloud-native">What even is Cloud Native?</h2>

<p>What is cloud native? What does it mean to build for the cloud? What is a cloud service?</p>

<p>Cloud native is basically a descriptive term for something that was built to run in the cloud. That’s it. It’s not 
magic, it might sound like a buzzword, but the reality is it simply means, that piece of software was built 
to run in the cloud. How does that differ from the way we used to build before? Well the idea behind the cloud 
is that its ephemeral, scalable and everything can be accessed via an API.</p>

<p>Our expectation for services running in the cloud is that they’re mostly stateless, leveraging external services 
for the persistence, that they are identified by name rather than IP address and they themselves provide an 
API that can be consumed by multiple clients such as web, mobile and cli or other services.</p>

<p>Cloud native applications are horizontally scalable and operate within domain boundaries that divide them as 
separate apps which communicate over the network via their APIs rather than as one monolithic entity. 
We think cloud services require a fundamentally different approach to software creation and why Micro 3.0 
was designed with this in mind.</p>

<h2 id="micro-30-aka-m3o">Micro 3.0 aka M3O</h2>

<p>Micro 3.0 (M3O) reimagines Micro as a platform for cloud native development. What does that mean? Well we think of 
it as PaaS 3.0, a complete solution for source to running and beyond. Micro has moved from just being a Go 
framework to incorporating a standalone server and hosted platform. Our hosted offering is called 
<a href="https://m3o.com/">M3O</a>, a hat tip to Micro 3.0 or M[icr]o, whichever way you want to see it.</p>

<p>Another way to think about it. What Git is to GitHub, Micro is to the M3O platform. Let’s dig into it.</p>

<p>Micro 3.0 includes the following.</p>

<h3 id="server">Server</h3>

<p>The server is our abstraction for cloud infrastructure and underlying systems you might need for writing 
distributed systems. The server encapsulates all of these concerns as gRPC services which you can 
query via any language. The goal here is to say developers don’t really need to be thinking about infrastructure 
but what they do need is design patterns and primitives for building distributed systems.</p>

<p><img src="https://micro.mu/images/micro-3.0.png"></p>

<p>The server includes the following:</p>

<ul>
  <li>
    <p><strong>Authentication</strong>: Auth whether its authentication or authorization is part of the system. Create JWT tokens, define access rules, use one system to govern everything in a simple and straight forward manner. Whether it’s for a user or a service.</p>
  </li>
  <li>
    <p><strong>Configuration</strong>: Dynamic config management allows you to store relevant config that needs to be updated without having to restart services. Throw API keys and business logic related configuration into the secure config service and let your services pick up the changes.</p>
  </li>
  <li>
    <p><strong>Key-Value Storage</strong>: We’re focused on best practices for microservices development which means keeping services mostly stateless. To do this we’re providing persistent storage on the platform. Key-Value allows you to rapidly write code and store data in the format you care about.</p>
  </li>
  <li>
    <p><strong>Event Streaming</strong>: Distributed systems are fundamentally in need of an event driven architecture to breakdown the tight dependencies between them. Using event streaming and pubsub allows you to publish and subscribe to relevant events async.</p>
  </li>
  <li>
    <p><strong>Service Registry</strong>: Micro and M3O bake in service discovery so you can browse a directory of services to explore your service APIs and enable you to query services by name. Micro is all about microservices and multi-service development.</p>
  </li>
  <li>
    <p><strong>Service Network</strong>: Because you don’t want to have to resolve those service names to addresses and deal with the load balancing aspect, the server bakes in a “service mesh” which will handle your inter-service requests (as gRPC) and route to the 
appropriate instance.</p>
  </li>
  <li>
    <p><strong>Identity Proxy</strong>: We include a separate identity proxy for external requests using gRPC via the CLI and other means. This enables you to query from your local machine or anywhere else using valid auth credentials and have it seamlessly work as if 
you were in the platform itself.</p>
  </li>
  <li>
    <p><strong>API Gateway</strong>: Finally there’s an API gateway that automatically exposes your services to the outside world over HTTP. Internally writing service to service using gRPC makes sense, but at the end of the day we want to build APIs consumed from clients via HTTP.</p>
  </li>
</ul>

<h3 id="clients">Clients</h3>

<p>The server provides inter-service communication and two means of external communication with a HTTP API and gRPC proxy but that 
experience is made much better when there’s user experience on the client side that works. Right now we’ve got two ways of doing this.</p>

<ul>
  <li>
    <p><strong>Command Line</strong>: The CLI provides a convenient and simple way to talk to the server via gRPC requests through the proxy. 
The most convenient commands are builtin but every service you write also gets beautiful dynamic generated commands 
for each endpoint.</p>
  </li>
  <li>
    <p><strong>gRPC SDKs</strong>: Every service in the server is accessible via gRPC. We’re code generating clients for the server itself 
so you can access them from any language. What this enables is a wide array of experiences on the client side without 
having to handcraft libraries for each language.</p>
  </li>
  <li>
    <p><strong>Web Interface</strong>: Coming soon is a dynamically generated web interface that creates a simple query mechanism through a 
browser for any of your services. We’ve got a http api, gRPC proxy and command line interface but feel like the browser 
could use some love too.</p>
  </li>
</ul>

<h3 id="framework">Framework</h3>

<p>One thing we really understood from our time working on go-micro was that the developer experience …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</a></em></p>]]>
            </description>
            <link>https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044604</guid>
            <pubDate>Tue, 10 Nov 2020 11:00:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to revert HP printer’s ban on 3rd-party ink cartridges]]>
            </title>
            <description>
<![CDATA[
Score 407 | Comments 247 (<a href="https://news.ycombinator.com/item?id=25044597">thread link</a>) | @kdeldycke
<br/>
November 10, 2020 | https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/ | <a href="https://web.archive.org/web/*/https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
     <p>
      Hewlett
      <span>
       &amp;
      </span>
      Packard, the founders, had great lessons to teach us (managers in high-tech) about culture. I even
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management/commit/de3e64647c911f78a37b3e54c7e46197acb061e1">
       quoted them
      </a>
      in my
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management#readme">
       awesome list on engineering team management
      </a>
      .&nbsp;👨‍💼
     </p>
     <p>
      <span>
       HP
      </span>
      Inc., the company, sucks. At least their
      <a href="https://news.ycombinator.com/item?id=25045024">
       printer division’s business model
      </a>
      . They recently pushed a
      <strong>
       firmware update to ban third-party compatible toner cartridges
      </strong>
      .&nbsp;💔
     </p>
     <p>
      The timeline is&nbsp;straightforward:
     </p>
     <ul>
      <li>
       <p>
        2020, March: general lockdown. 🦠 I need a home office.
        <span>
         SO
        </span>
        is a scientist and spend her time printing papers for review. Got her an
        <a href="https://amzn.com/B073R2WVKB/?tag=kevideld-20">
         <span>
          HP
         </span>
         Color LaserJet M254dw
        </a>
        to keep her productive workflow (
        <a href="https://en.wikipedia.org/wiki/Publish_or_perish">
         publish or perish!
        </a>
        ).
       </p>
      </li>
      <li>
       <p>
        2020, October:
        <span>
         HP
        </span>
        release a new firmware (versioned
        <code>
         20201021
        </code>
        ).
       </p>
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20201021-firmware.jpg">
     </p>
     <ul>
      <li>
       2020, November: my printer auto-upgrade. I’m welcomed with this
       <em>
        Supply Problem
        <a href="https://en.wikipedia.org/wiki/Screen_of_death">
         Screen of Death
        </a>
       </em>
       :
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-supply-problem-screen-of-death.jpg">
     </p>
     <p>
      I can’t print anymore.&nbsp;🤯
     </p>
     <p>
      Eight months. My printer worked for only 8 months.&nbsp;😤
     </p>
     <p>
      <span>
       OK
      </span>
      . It’s my fault. I should have spent more money buying certified™ gear.&nbsp;😑
     </p>
     <p>
      <img alt="" src="https://comdoc.com/wp-content/uploads/2019/01/copier-printer-meme-03.jpg">
     </p>
     <p>
      The solution is to travel back in time when things were working just great, and downgrade to the previous&nbsp;firmware.
     </p>
     <h2 id="disable-auto-upgrade">
      Disable Auto-Upgrade
      <a href="#disable-auto-upgrade" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      We will start by stopping this madness for good, and prevent the printer from downloading a firmware behind our&nbsp;back.
     </p>
     <p>
      In the control panel, go to
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       LaserJet Update
      </code>
      &gt;
      <code>
       Manage Updates
      </code>
      :
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-manage-updates-menu.jpg">
     </p>
     <p>
      Then set these&nbsp;options:
     </p>
     <ul>
      <li>
       Allow Downgrade:
       <code>
        Yes
       </code>
      </li>
      <li>
       Check Automatically:
       <code>
        Off
       </code>
      </li>
      <li>
       Prompt Before Install:
       <code>
        Always Prompt
       </code>
      </li>
      <li>
       Allow Updates:
       <code>
        No
       </code>
      </li>
     </ul>
     <p>
      I’m quite surprised downgrades are allowed. 🤔 It seems out of character. Therefor, with my
      <em>
       Evil Product Manager
      </em>
      hat, I advise
      <span>
       HP
      </span>
      to monetize this feature under a monthly Enterprise Subscription of sort.&nbsp;😈
     </p>
     <h2 id="download-old-firmware">
      Download Old Firmware
      <a href="#download-old-firmware" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      I got lucky and found the previous
      <code>
       20200612
      </code>
      firmware referenced in
      <a href="https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf">
       <code>
        https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf
       </code>
      </a>
      .
     </p>
     <p>
      There you’ll get a direct link to the
      <code>
       .rfu
      </code>
      file (Remote Firmware Update):
      <a href="http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       <code>
        http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      And just in case it disappear from its original location, here is a
      <a href="https://kevin.deldycke.com/uploads/2020/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       copy of
       <code>
        HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      The checksum of that file&nbsp;is:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> sha256sum ./HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
<span data-linenos="2 "></span><span>91c7f51ceba2386f3b94dcb9da20c669ab10b1ee3a9b1e1f742c40091920188e</span>
</code></pre>
     </div>
     <h2 id="downgrade-firmware">
      Downgrade Firmware
      <a href="#downgrade-firmware" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      Once you get the
      <code>
       .rfu
      </code>
      file, list all your printers from a macOS&nbsp;terminal:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpstat -p -d
<span data-linenos="2 "></span><span>printer HP_Color_LaserJet_M254dw_0 is idle.  enabled since Fri Nov  6 17:47:06 2020</span>
<span data-linenos="3 "></span><span>system default destination: HP_Color_LaserJet_M254dw_0</span>
</code></pre>
     </div>
     <p>
      And run the firmware downgrade
      <span>
       CLI
      </span>
      :
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpr -P HP_Color_LaserJet_M254dw_0 /Users/kde/Downloads/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
</code></pre>
     </div>
     <p>
      Nothing gets printed to the&nbsp;console.
     </p>
     <p>
      I don’t know what happens here but it seems the
      <code>
       .rfu
      </code>
      file is pushed to the printer’s queue and then gets consumed as any other printable document. See,
      <a href="https://www.jsof-tech.com/unpacking-hp-firmware-updates-part-1/">
       the
       <span>
        RFU
       </span>
       file format is a matryoshka doll
      </a>
      embedding printing commands, encoded data and raw
      <span>
       NAND
      </span>
      code.
     </p>
     <p>
      After a minute  or two, the printers reboots and upgrades&nbsp;itself:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-firmware-updating.jpg">
     </p>
     <p>
      And we’re back in business!&nbsp;🥳
     </p>
     <p>
      A detour via
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       Firmware Datecode
      </code>
      menu confirm we’re running the the previous&nbsp;firmware:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20200612-firmware.jpg">
     </p>
     <h2 id="printer-security">
      Printer Security
      <a href="#printer-security" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      In my research for this article, I found out about
      <a href="https://github.com/RUB-NDS/PRET">
       <span>
        PRET
       </span>
       , a printer exploitation toolkit
      </a>
      . It’s a brilliant tool, in a malignant way. It allows for pen-testing and hacking, using the same vectors as the firmware update.&nbsp;🤫
     </p>
     <p>
      I’ll probably play with it in the future. For fun, but also to try enhance the security of the printer. In the mean time, I guess a password is the bare minimum. And if my printer get kidnapped by a cyber gang, I now have a way to restore my printer’s firmware!&nbsp;😬
     </p>
     <h3>
      Related content
     </h3>
     
     
    </div></div>]]>
            </description>
            <link>https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044597</guid>
            <pubDate>Tue, 10 Nov 2020 10:59:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The myriad meanings of pwd in Unix systems]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25044131">thread link</a>) | @quyleanh
<br/>
November 10, 2020 | https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Last week I ran a poll on Twitter to see what people considered with respect to the meaning of ‘pwd’ in Unix and Linux systems. The results were varied, for perhaps good reason.</em></p>

<p>At the end of Oct 2020 I ran a <a href="https://twitter.com/qmacro/status/1322567992551624705">brief poll on Twitter</a>, on which 82 people voted. Here’s that poll, and the results. They’re quite mixed, which at first might seem surprising. But there are reasons for that, as we’ll find out.</p>

<p><img src="https://qmacro.org/content/images/2020/11/twitter-poll-pwd.png" alt="Poll on Twitter: &quot;Fun Saturday afternoon shell poll. In Unix (and Linux), what do you think the P in $PWD (or pwd) stand for?&quot;"></p>

<p><strong>Print working directory</strong></p>

<p>The most popular option was “print working directory”. At first sight it seems logical: “print out the current working directory, i.e. where I am right now”. Moreover, the description in various versions of the manual for <code>pwd</code> help to drive home that notion. Typically we see sentences like “<a href="https://linux.die.net/man/1/pwd">print name of current/working directory</a>” or “<a href="https://www.mankier.com/1/pwd">print the current directory</a>”.</p>

<p>But there are lots of commands that print stuff, and are described in that way too. Take the <code>id</code> command. Here’s what one man page says: “<a href="https://man7.org/linux/man-pages/man1/id.1.html">print real and effective user and group IDs</a>”. There’s “print” again. But the command isn’t <code>pid</code>, it’s <code>id</code>. When you think about it, many, many commands in Unix send information to STDOUT, i.e. to the terminal. That’s sort of the point of many of them.</p>

<p>This time arguably only superficially definitive, it would seem, the Wikipedia entry states, on the <a href="https://en.wikipedia.org/wiki/Pwd">page for <code>pwd</code></a>: “the pwd command (print working directory) writes the full pathname of the current working directory to the standard output”. As if to underline the hopeful authority of this statement, there are five (!) footnotes that supposedly link to resources that back this up.</p>

<p>Unfortunately, the first footnote points to a Wayback Machine copy of the <a href="https://web.archive.org/web/20050520231659/http://cm.bell-labs.com/7thEdMan/v7vol1.pdf">UNIX PROGRAMMERS MANUAL - Seventh Edition, Volume 1 - January, 1979</a>, wherein there are actually zero references to <code>pwd</code> being short for “print working directory”:</p>

<p><img src="https://qmacro.org/content/images/2020/11/programmers-manual-pwd.png" alt="excerpt from UNIX PROGRAMMERS MANUAL on pwd"></p>

<p>I don’t know about you, but this historic document carries more weight for me than other sources I’ve come across, and it only serves here to undermine the credibility of the Wikipedia entry.</p>

<p>The rest of the footnote links seem dubious at best, except for the one pointing to the <a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#pwd-invocation">GNU Coreutils manual on pwd</a> which has it as “print working directory”. But everything else I’ve seen so far makes me think that this is a misunderstanding that has spread for obvious and innocent reasons. In addition, the one footnote in the Wikipedia page that is not used to back this claim up is a pointer to <a href="https://pubs.opengroup.org/onlinepubs/9699919799/utilities/pwd.html">The Open Group Base Specifications Issue 7, 2018 edition’s information on pwd</a>, which almost seems like it’s actually avoiding using the word “print” at all: “return working directory name” … “The pwd utility shall write to standard output an absolute pathname of the current working directory, which does not contain the filenames dot or dot-dot.”. Very specific, very not-print.</p>

<p>So I’m thinking that “print working directory” isn’t what <code>pwd</code> stands for. In fact, “print working directory” may be common to some man pages, but on this macOS machine, with its <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a> heritage, we have, instead: “pwd – return working directory name”. Moreover, it goes on to say “The pwd utility writes the absolute pathname of the current working directory to the standard output”.</p>

<p><strong>Pathname of working directory</strong></p>

<p>So perhaps it really is “pathname of working directory”. That would, at least to me, make more sense. Not only does it eschew the redundancy of “print”, it also is more specific about the output - if I’m in <code>/home/dja/</code> for example, then invoking pwd will tell me that, i.e. where I am, including the whole path, and not just <code>dja</code>:</p>



<p><strong>Process working directory</strong></p>

<p>As for the other options, I do favour “process working directory”, mostly because it makes a lot of sense to me; every process in Unix has the concept of a current working directory, and that’s exactly what I’m asking for when I’m in my shell process and enter <code>pwd</code> - there’s a part in the video <a href="https://youtu.be/hgFBRZmwpSM?t=165">Unix terminals and shells</a> that explains this very well.</p>

<p>I’d love to be able to point to some old Unix sources that definitively explain the answer, but unfortunately that search has come up with very little - the <code>pwd</code> source in both the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V5/usr/source/s2/pwd.c">5th</a> and <a href="https://github.com/yisooan/unix-v6/blob/master/source/s2/pwd.c">6th</a> Editions of Unix shed no light on this whatsoever.</p>

<p><strong>Present working directory</strong></p>

<p>What about “present working directory”? Well, that option seems to have legs, in the form of the Korn shell. While <a href="https://northstar-www.dartmouth.edu/doc/solaris-forte/ipe-help/dbx/dbx88cc.html">one source</a> implies that the answer might well be “pathname of current working directory”, in that <code>pwd</code> just emits the value of the <code>$PWD</code> environment variable (and a variable called “print working directory” makes no sense at all) … it would seem that in ksh-land, at least, “present working directory” is what <code>pwd</code> represents. Take, for example, the <a href="https://osr507doc.xinuos.com/en/man/html.C/ksh.C.html">ksh man page</a> which states “PWD - The present working directory set by the cd command”.</p>

<p>There’s a ton of discussion, both direct and indirect, on this very question. Take for example these two entries in the Unix &amp; Linux Stack Exchange forum: <a href="https://unix.stackexchange.com/questions/399026/etymology-of-pwd">Etymology of $PWD</a> and <a href="https://unix.stackexchange.com/questions/174990/what-is-pwd-vs-current-working-directory">What is $PWD? (vs current working directory)</a>. Of course, perhaps the definitive answer will never be found, as computing history is nothing if not varied and prone to forking.</p>

<p><strong>Multics and print_wdir</strong></p>

<p>Talking of history, we could go further back to pre-Unix roots, in the form of Multics, which indirectly gave rise to Unix (originally “Unics”). In the <a href="https://multicians.org/multics-commands.html">list of Multics Commands</a>, we see, nestled amongst other similarly named commands, something that jumps out at us:</p>

<div><div><pre><code>print_mail (pm)	display mail in a mailbox
print_messages (pm)	display interactive messages in a mailbox
print_motd (pmotd)	display message of the day (source)
print_proc_auth (ppa)	display process's sensitivity level and compartments
print_request_types (prt)	display list of I/O daemon request types
print_search_paths (psp)	display search paths
print_search_rules (psr)	display ready messages
print_wdir (pwd)	display working directory
</code></pre></div></div>

<p>There’s <code>pwd</code>, and in fact, just like its sibling <code>pmotd</code>, for example, which is short for <code>print_motd</code>, it’s short for <code>print_wdir</code>. Now, given the context of the original poll being set to Unix and Linux, perhaps we must discount this information. But as someone who is fascinated with Unix history in general - how can I?</p>

<p>I guess there are few things to conclude. The history is rich and diverse, and maybe we’ll never know for sure. Perhaps, in fact, the answer will depend on whom we ask. In the grand scheme of things, it doesn’t really matter … but to those who delight in minutiae, it’s a fun topic worth exploring.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044131</guid>
            <pubDate>Tue, 10 Nov 2020 09:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become Covid Savvy in 10 Steps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044022">thread link</a>) | @datashrimp
<br/>
November 10, 2020 | https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/ | <a href="https://web.archive.org/web/*/https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044022</guid>
            <pubDate>Tue, 10 Nov 2020 09:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I git]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 133 (<a href="https://news.ycombinator.com/item?id=25043731">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043731</guid>
            <pubDate>Tue, 10 Nov 2020 08:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AppleCrate II: A New Apple II-Based Parallel Computer (2015)]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25042551">thread link</a>) | @aresant
<br/>
November 9, 2020 | http://michaeljmahon.com/AppleCrateII.html | <a href="https://web.archive.org/web/*/http://michaeljmahon.com/AppleCrateII.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<b><span face="Arial, helvetica" size="4"><p>AppleCrate II:  A New Apple II-Based Parallel Computer</p>
</span><span face="Arial, helvetica" size="2"><p>
Michael J. Mahon – July 26, 2008<br>
Revised – September 23, 2015</p>

<p><img src="http://michaeljmahon.com/CrateII.jpg" width="500" height="612"></p>

</span><span face="Arial, helvetica"><p>Introduction</p>
</span></b><span face="Arial, helvetica" size="2"><p>
In 2004 I built the first <a href="http://michaeljmahon.com/Applecrate.html">AppleCrate</a>, an 8-board system, as an inexpensive, easy to program
vehicle for experiments in parallel programming—a kind of "blade server" for the Apple II, if
you will!  AppleCrate I (at the time I didn't realize that it was number "I" ;-) was great fun, and it
enabled some very interesting experiments, but over time I discovered some of its shortcomings.</p>

<p>First and foremost, since the boards were supported by only two edges and not clamped in place, it
was relatively fragile and hard to transport.  Second, I had come across situations in which more
than 8 slave processors would have been useful.  Third, my arrangement for collecting audio signals
synthesized by the slaves was quite makeshift and delivered sound with lots of digital "hash"
as background noise.  And finally, the original AppleCrate made no provision for plugging I/O cards
into any of its boards, so it had to be hosted by a separate Apple II, adding to the problem of
transporting it for demonstrations.</p>

<p>The AppleCrate II is designed to be significantly improved in all of the areas that were
problems for the AppleCrate I.</p>

<b></b></span><b><span face="Arial, helvetica"><p>Description</p>
</span></b><span face="Arial, helvetica" size="2">

<p>The AppleCrate II is made from 17 Enhanced Apple //e main boards.  (Fifteen of these boards were
obtained in the same eBay auction that netted the eight unenhanced boards for the original AppleCrate.)
Because they are enhanced ROMs, the original NadaNet boot ROM code would not fit and a new
boot protocol had to be developed, as described below.</p>

<p>Instead of mounting the cards vertically in a frame, as in the original, I decided to mount them
horizontally in a stack secured with standoffs—3/4" long hexagonal rods, each with a screw protruding from
one end and a tapped hole in the other.  The AppleCrate II has nine "columns" of these standoffs—six
metal columns at the back and corners of the boards and three nylon columns interior to the boards
to add stiffness, as shown in the photo below at the 2-board construction stage:</p>

<p><img src="http://michaeljmahon.com/TwoBoards.jpg" width="800" height="554"></p>

<p>This "hi-rise" construction makes the "stack" quite rigid and sturdy, while eliminating the need
for a space-consuming exoskeleton.  It also has the advantage of leaving the top board unobstructed
so that I/O cards can be plugged in, allowing it to serve as the host machine for the AppleCrate.  (In fact,
I used 17 boards so that the top board can serve as master and leave 16 slave machines for parallel
programs.)</p>

<p>The Pushbutton 1 input and Annunciator 1 output bus wires and the AN2-to-PB2 GETID daisy chain wires are connected to
machined-pin sockets inserted into the 16-pin game port connector.  These connections support <a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a>,
which is the only signal connection between the boards.  The network adapter (described below) is shown
with its mounting bracket under what will be the third board.  The power bus card is supported by a
similar angle bracket, and the standoffs immediately beneath them are filed down to accomodate the
bracket thickness.</p>

<p>The boards are powered by a PC AT power supply.  The average power consumed by an Apple //e
board is about 4.2 watts, so the whole 17-board crate consumes only about 70 watts in total,
and both the AppleCrate and the power supply run only a few degrees above ambient temperature.</p>

<p>I decided to use #12 copper bus wires
to distribute power to all boards (visible on the right side of the first photo).  I would have preferred
a connectorized approach, but I could not come up with a connector scheme with a
reasonable mating/unmating force.  As a result, I decided to go with soldered power connections.
(It's a good thing that Apple //e's are so reliable, since replacing one in the middle of the
stack would be relatively difficult!)</p>

<p>The top board is used as the "master" machine with I/O cards and an external keyboard plugged into it.
The Master boots the 16 slave Apples in the AppleCrate II and uses them to run parallel programs.
Once they have been booted and started, they can run independently of the master—though they are clearly
I/O-constrained!</p>

<b></b></span><b><span face="Arial, helvetica"><p>Indicators</p>
</span></b><span face="Arial, helvetica" size="2">

<p>It has proven useful to have some real-time indication of each board's activity.  The stock board contains a
red "power" LED (at the right) and a red "speaker" LED at the left.  Both are easily visible from the back of the
boards (the "front" of the AppleCrate).  The function of the power LED is fixed, but the speaker LED is usable
as an indicator that software running on the board can operate, just by toggling the speaker.  For example,
printing a "beep"—CHR$(07)—causes the speaker LED to flash for 0.1 second, and can be used to indicate some
condition in the software.  (The speaker LED will not light when a speaker is installed, but AppleCrate
boards have no speakers attached.)</p>

<p>Although the Applecrate network interface described below incorporates an LED to show global network activity,
it is very useful to be able to see when any particular board is sending on the network.  This need is met by
using the PDL 3 timer to "stretch" each packet send operation into a visible flash of a green rectangular LED.</p>

<p><img src="http://michaeljmahon.com/SendLED.jpg" width="762" height="263"></p>

<p>These photos show the modification made to the 558 timer chip, in which a 267-ohm resistor (just what I
had handy—any value between 220 and 560 ohms is fine) is connected
between pins 5 and 8, and the "send" signalling LED is connected between pin 8 and ground, with pin 8 going to the
anode.  The rectangular LED is carefully pressed between the cassette input and output jacks.  On some boards,
the jacks were so close together that it was necessary to "shave" the upper plastic swage on the side of the input
jack with an Exacto knife to make room for the LED to press fit between them.  (Note that in these photos the red
wire connected to the anode of the LED has not yet been soldered.)</p>

</span><b><span face="Arial, helvetica"><p>Network Boot in NadaNet 3.x</p>
</span></b><span face="Arial, helvetica" size="2">

<p>Since AppleCrate machines have no I/O capabilities other than
the network, they must be booted from the network.  This requires that the ROMs on the boards be replaced with
EPROMs containing modified RESET code to perform the network boot.</p>

<p>As with the AppleCrate I, replacement of the self-test code was the easiest path, since it is self-contained,
contiguous, and is executed upon power-on reset if no keyboard is connected.  However, the Enhanced //e ROM contains
only $200 bytes of self-test code, just half the size of the unenhanced //e self-test, requiring a new
design for the network boot.</p>

<p>The AppleCrate I used an "active" boot protocol, in which each board enabled by the "GETID daisy chain" (connected from
AN2 of the previous machine to PB2 of the current machine) continuously sent GETID requests to ID 1, until it was assigned
a permanent ID and received a NadaNet boot image.  The complexity of this protocol, requiring both sending and receiving
packets over the network, resulted in a boot ROM requirement of almost $400 bytes—which fit in an <b>Unenhanced</b> //e ROM.</p>

<p>Since the <b>Enhanced</b> //e ROM has only $200 bytes available, a new "passive" boot protocol had to be devised.
The <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">new ROM code</a> continuously monitors the network for a broadcast BOOTREQ control packet
containing  the load address and length of the immediately following boot code data.  When the boot image has been correctly
read from the network, control is passed to its starting address.  This passive boot code only needs to <b>read</b> packets from the
net, and so occupies just $190 bytes, which comfortably fits in place of the Enhanced //e ROM self-test code at $C600.</p>

<p>The new boot protocol capitalizes on the fact that boot code is sent as a broadcast transaction, so the
machines being booted do not need IDs to receive boot code.  A page of "second-stage boot" code is added at the
front of the slave machine boot image.  This code is given control immediately after the boot image is received, and,
when enabled by the "GETID daisy chain", it sends a GETID request to the machine that &amp;BOOTed it, making use of the
code in the full NadaNet boot image to do so (see the BOOT2 code in the <a href="http://michaeljmahon.com/NADA.CRATE.pdf">NADA.CRATE</a>
listing for details).</p>

<p>The GETID daisy chain functions just as it did in the AppleCrate I.  The "first" machine is permanently enabled
by connecting its PB2 to ground.  AN2 of each machine is connected
to PB2 of the "next" machine.  The second-stage boot code running in each machine initially sets its AN2.
Then it waits until it sees its PB2 go low, enabling it to send its GETID request.  When its GETID is successful
it drops its AN2, enabling the next machine.  Then it clears its video display, writes a banner showing the
machine ID, and enters its server loop.</p>

<p>This results in permanent
IDs being assigned in the fixed order of the physical daisy chain, while allowing all ROMs to be identical.
An LED on the AppleCrate II NadaNet adapter board is wired to the last machine's AN2, so that when the last
machine drops its AN2, the red LED extinguishes, signalling that all machines have booted successfully.</p>

<p>When a network-booting machine is reset, it first checks the network state.  If the network is low (ZERO),
it performs a cold start.  If the network is being held high (ONE), it checks page 3 to see if it is being cold started or warm reset.  If it is
a warm reset, it re-enters its Server loop.  If it is a cold start, it initializes and enters the ROM boot code, again waiting
for a BOOTREQ packet.  (This approach has the advantage of reliably forcing a reboot on a power cycle, while
still permitting boards to be warm reset while holding the network high.)</p>

<p>As of NadaNet 3.1, all AppleCrate boot ROMs must be <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">NadaNet 3.x capable</a>.</p>

</span><b><span face="Arial, helvetica"><p>AppleCrate II NadaNet Interface</p>
</span></b><span face="Arial, helvetica" size="2">
<p><a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a> is a TTL-level serial network in which logic high is represented by a voltage greater than +2 volts
and logic low is represented by a voltage less than +0.7 volts.  The fanout capability of a TTL annunciator output
is sufficient to  drive a dozen or so TTL pushbutton inputs if they are not otherwise …</p></span></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://michaeljmahon.com/AppleCrateII.html">http://michaeljmahon.com/AppleCrateII.html</a></em></p>]]>
            </description>
            <link>http://michaeljmahon.com/AppleCrateII.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042551</guid>
            <pubDate>Tue, 10 Nov 2020 03:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networking for Introverts]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042288">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/how-to-network-as-an-introvert/ | <a href="https://web.archive.org/web/*/https://gradually.co/how-to-network-as-an-introvert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gradually.co/how-to-network-as-an-introvert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042288</guid>
            <pubDate>Tue, 10 Nov 2020 02:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Writing Clean Interfaces in Go]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25042085">thread link</a>) | @lanecwagner
<br/>
November 9, 2020 | https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042085</guid>
            <pubDate>Tue, 10 Nov 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking an election fraud claim using open data and Dolt]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25041998">thread link</a>) | @proverbialbunny
<br/>
November 9, 2020 | https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041998</guid>
            <pubDate>Tue, 10 Nov 2020 01:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Try Design Thinking]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25041961">thread link</a>) | @gbasin
<br/>
November 9, 2020 | https://garybasin.com/try-design-thinking/ | <a href="https://web.archive.org/web/*/https://garybasin.com/try-design-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://garybasin.com/try-design-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041961</guid>
            <pubDate>Tue, 10 Nov 2020 01:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ladders of Wealth Creation]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25041361">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/roadmap-to-building-wealth/ | <a href="https://web.archive.org/web/*/https://gradually.co/roadmap-to-building-wealth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gradually.co/roadmap-to-building-wealth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041361</guid>
            <pubDate>Mon, 09 Nov 2020 23:47:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The election of the doge]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25039470">thread link</a>) | @flannery
<br/>
November 9, 2020 | https://generalist.academy/2020/11/06/the-election-of-the-doge/ | <a href="https://web.archive.org/web/*/https://generalist.academy/2020/11/06/the-election-of-the-doge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4574">
	
		<p>
By  on <a href="https://generalist.academy/2020/11/06/the-election-of-the-doge/" title="7:00 am" rel="bookmark"><time datetime="2020-11-06T07:00:00+13:00">November 6, 2020</time></a>	• 
	</p>
	<section>

<p>The ruler of Medieval Venice was chosen by an exceptionally complex ten-step process of alternating random lots and elections.</p>



<div><figure><img loading="lazy" data-attachment-id="4580" data-permalink="https://generalist.academy/kms3898/" data-orig-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg" data-orig-size="2043,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Statens Museum for Kunst&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Canaletto (1697-1768), Dogen og det store raad forsamlede i Sala del consiglio maggior i Dogepaladset, About 1763&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;Public Domain (CC0)&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;kms3898&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kms3898" data-image-description="" data-medium-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=300" data-large-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=656" src="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1024" alt="Grand Council" width="768" height="451" srcset="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1024 1024w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=768 768w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1536 1536w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=150 150w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=300 300w" sizes="(max-width: 768px) 100vw, 768px"><figcaption><a href="https://commons.wikimedia.org/wiki/File:Canaletto_-_The_Doge_and_Grand_Council_in_Sala_del_Maggior_Consiglio_-_KMS3898_-_Statens_Museum_for_Kunst.jpg">Canaletto</a>, Public domain, via Wikimedia Commons</figcaption></figure></div>



<p>A few weeks ago I wrote about modern <a href="https://generalist.academy/2020/10/17/electoral-fairness/">democratic electoral systems</a>, and a couple of days ago I wrote about the complexities of the <a href="https://generalist.academy/2020/11/04/the-unpopular-president/">American Electoral College</a>. Today I wanted to go even further back, to the Medieval Venetian Republic. There, the selection of a new leader – the doge – was one of the more complex and baffling electoral processes in history. And even so, though this be madness, yet there is method in’t.</p>



<p>The Great Council of Venice was a large legislative body made up of a relatively small number of noble families. Obviously, everyone wanted to be the doge, but the council was very keen to avoid behind-the-scenes bribery, dirty deals, intrigue, and extended and contentious campaigns. To achieve this, the election of the doge went through multiple steps, all designed to reduce power consolidation.</p>



<p>First, thirty members of the Great Council were chosen at random. Then nine of those thirty were chosen, again randomly. Those nine members picked the next set: forty people from the Great Council. And those forty? Twelve, randomly picked from their number, moved on to the next step. Those twelve chose twenty-five; those twenty-five were randomly pared down to just nine. Having fun yet?</p>



<p>This set of nine members chose forty-five more; eleven were picked – again at random – from those forty-five. The eleven chose forty-one members. Those forty-one (finally!) voted for the doge. </p>



<p>There were some additional checks against skulduggery. Each noble family couldn’t have more than one member in each group, and members couldn’t vote for their own relatives. Every time a set of members voted for the next group, more than a simple majority was required: around three quarters of the voting group had to agree. (For the final election, just 25 of the 41 had to agree.)</p>



<p>To recap, this is the process:<br>Great Council &gt; 30 &gt; 9 &lt; 40 &gt; 12 &lt; 25 &gt; 9 &lt; 45 &gt; 11 &lt; 41 &gt; 1.</p>



<p>Because of this complexity, the chances of rigging or buying the election were greatly reduced, minority concerns were not buried by the majority, but neither was the majority tyrannized by the minority. Today we only use this kind of random process in jury selection and citizen’s assemblies.</p>



<p>[Thanks to Alistair S. for suggesting this topic.]</p>



<ul><li><a href="https://en.wikipedia.org/wiki/Doge_of_Venice">Doge of Venice</a></li><li><a href="https://en.wikipedia.org/wiki/Sortition">Sortition</a></li><li><a href="https://doi.org/10.1007/s10602-019-09290-6">How the Republic of Venice chose its doge: Lot-based elections and supermajority rule</a></li></ul>
		<p>Categories: <a href="https://generalist.academy/category/places/europe/" rel="category tag">Europe</a> <a href="https://generalist.academy/category/history/" rel="category tag">History</a> <a href="https://generalist.academy/category/history/medieval-history/" rel="category tag">Medieval history</a> <a href="https://generalist.academy/category/places/" rel="category tag">Places</a> <a href="https://generalist.academy/category/politics-law/" rel="category tag">Politics &amp; law</a>		</p>
	<div>
		<p><img alt="" src="https://0.gravatar.com/avatar/f7eb82f9df252be8cad1a3993809331d?s=100&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D100&amp;r=G" height="100" width="100"></p><h3>The Generalist</h3>
		<p>I live in Auckland, New Zealand, and am curious about most things.</p>
	</div>
	</section>
</article></div>]]>
            </description>
            <link>https://generalist.academy/2020/11/06/the-election-of-the-doge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039470</guid>
            <pubDate>Mon, 09 Nov 2020 20:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Recalculate a Spreadsheet]]>
            </title>
            <description>
<![CDATA[
Score 289 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25039393">thread link</a>) | @todsacerdoti
<br/>
November 9, 2020 | https://lord.io/blog/2020/spreadsheets/ | <a href="https://web.archive.org/web/*/https://lord.io/blog/2020/spreadsheets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Let’s say I’m ordering burritos for my two friends while they quar up in Jersey City, and want to calculate the total price of my order:</p>
<p><img alt="screenshot of spreadsheet; burrito price is listed as $7, burrito price w ship as burrito price plus $3, num burritos is 2, and total is num burritos times burrito price w ship, for a total of $20" src="https://lord.io/images/2020/anchors_0.png"></p>
<p>It’s a little confusing to follow the flow of data in a spreadsheet when it’s written like that, so I hope you don’t mind this equivalent diagram that represents it as a graph:</p>
<p><img alt="the previous spreadsheet represented as a graph, with arrows from one cell to another replacing the spreadsheet cell references" src="https://lord.io/images/2020/anchors_1.png"></p>
<p>We’re rounding the cost of an El Farolito super vegi burrito to $8, so assuming the per-burrito delivery toll remains at just $2 per burrito, it looks like the total for our two burritos will be $20.</p>
<p>Oh no, I completely forgot! One of my friends loves to wolf down multiple burritos at a time, so I actually want to place an order for three burritos. If I update <code>Num Burritos</code>, a naïve spreadsheet engine might recompute the entire document, recalculating first the cells with no inputs, and then recalculating any cell whose inputs are ready until we’ve finished every cell. In this case, we’d first calculate <code>Burrito Price</code> and <code>Num Burritos</code>, then <code>Burrito Price w Ship</code>, and then a new final <code>Total</code> of $30.</p>
<p><img alt="same as previous graph, but num burritos is updated to 3, and every cell is tagged as &quot;recalc&quot;" src="https://lord.io/images/2020/anchors_2.png"></p>
<p>This simple strategy of recalculating the whole document may sound wasteful, but it’s actually already <em>better</em> than VisiCalc, the first spreadsheet software ever made, and the first so-called “killer app”, responsible for popularizing the Apple II. VisiCalc would repeatedly recalculate cells from left-to-right and top-to-bottom, sweeping over them again and again until none of them changed. Despite this “interesting” algorithm, VisiCalc remained the dominant spreadsheet software for four years. Its reign ended in 1983, when Lotus 1-2-3 swept the market with “natural-order recalculation”, <a href="https://aresluna.org/attached/computerhistory/articles/spreadsheets/tenyearsofrowsandcolumns">as described by Tracy Robnett Licklider in Byte Magazine</a>:</p>
<blockquote>
<p>Lotus 1-2-3 exploited natural-order recalculation, although it also supported VisiCalc’s row- and column-order modes. Natural-order recalculation maintained a cell dependency list and recalculated a cell before recalculating cells that depended on it.</p>
</blockquote>
<p>Lotus 1-2-3 implemented the “recalculate everything” strategy we’ve shown above, and for the first decade of spreadsheets, that was as good as it got. Yes, we recalculate every cell in the document, but at least we only recalculate every cell once.</p>
<h2>but what about “burrito price w ship”</h2>
<p>Great point, header 2. In my three burrito example there’s no reason to recompute <code>Burrito Price w Ship</code>, because changing the number of burritos we order can’t possibly influence the per-burrito price. In 1989, one of Lotus’ competitors realized this, and created SuperCalc5, presumably naming it after the theory of super burritos at the core of this algorithm. SuperCalc5 recalculated “only cells dependent on changed cells”, which would make updating the burrito count look more like this:</p>
<p><img alt="same as prior graph, with burrito count updated from 2 to 3, but now only the two affected cells &quot;num burritos&quot; and &quot;total&quot; are tagged as recalc" src="https://lord.io/images/2020/anchors_3.png"></p>
<p>By only updating a cell when one of its inputs changes, we can avoid recalculating <code>Burrito Price w Ship</code>. In this case, it saves just a single addition, but on larger spreadsheets it can save quite a bit of time! Unfortunately, we now have another problem. Let’s say my friends now want meat burritos, which cost a dollar more, and simultaneously El Farolito adds a $2 fee paid per-order, regardless of how many burritos you order. Before any formula outputs are recalculated, our graph might look like this:</p>
<p><img alt="same as prior graph (after burrito count update finished calculation), but now burrito price is being updated from $8 to $9, and simultaneously total is updated from &quot;burrito price w ship * num burritos&quot; to &quot;burrito price w ship * num burritos + $2 fee&quot;" src="https://lord.io/images/2020/anchors_4.png"></p>
<p>Since there are two updated cells here, we have a problem. Should we recalculate <code>Burrito Price</code> first, or <code>Total</code>? Ideally, we first calculate <code>Burrito Price</code>, notice that its output has changed, then recalculate <code>Burrito Price w Ship</code>, and finally recalculate <code>Total</code>. However, if we instead recalculate <code>Total</code> first, we’ll have to recalculate it a second time once the new $9 burrito price propagates down. If we don’t calculate cells in the right order, this algorithm isn’t better than recalculating the whole document. In some cases, it’s as slow as VisiCalc!</p>
<p>Clearly, it’s important for us to figure out the right order to update our cells. Broadly, there are two solutions to this problem: dirty marking and topological sorting.</p>
<p>This first solution involves marking all cells downstream from an edit as dirty. For instance, when we update <code>Burrito Price</code>, we would mark the downstream cells <code>Burrito Price w Ship</code> and <code>Total</code> as dirty, even before doing any recalculations:</p>
<p><img alt="same as prior graph with the two updates, but now three nodes are tagged as dirty: &quot;burrito price&quot;, &quot;burrito price w ship&quot;, and &quot;total&quot;. would also like to apologize for the rather confusing image alt text so far; it's really hard to write these for graph diagrams!! if you are a screen reader user and have advice on better ways to do this, would love to hear from you." src="https://lord.io/images/2020/anchors_5.png"></p>
<p>Then, in a loop, we find a dirty cell that has no dirty inputs, and recalculate it. When there are no dirty cells left, we’re done! This solves our ordering problem. There’s one downside though — if a cell is recalculated and we find its new output to be the same as its previous output, we’ll still recalculate downstream cells! A little bit of extra logic can avoid actually running the formula trouble in this case, but we unfortunately still waste time marking and unmarking a lot of cells as dirty.</p>
<p>The second solution is topological sorting. If a cell has no inputs, we mark its height as 0. If a cell has inputs, we mark its height as the maximum of the heights of its inputs, plus one. This guarantees all cells have a greater height than any of their inputs, so we just keep track of all cells with a changed input, always choosing the cell with the lowest height to recalculate first:</p>
<p><img alt="same as prior graph with the two updates, but instead of dirty tags, now every node has a height tag. &quot;burrito price&quot; and &quot;num burritos&quot;, the two cells with no in-nodes, have height 0. &quot;burrito price w ship&quot; has height 1. &quot;total&quot; has height 2." src="https://lord.io/images/2020/anchors_6.png"></p>
<p>In our double-update example, <code>Burrito Price</code> and <code>Total</code> would be initially added to the recalculation heap. <code>Burrito Price</code> has lesser height, and would be recalculated first. Since its output changes, we then would add <code>Burrito Price w Ship</code> to the recalculation heap, and since it too has less height than <code>Total</code>, it would be recalculated before we finally recalculate <code>Total</code>.</p>
<p>This has a big advantage over the first solution: no cell is ever marked dirty unless one of its inputs actually change. However, it requires we keep all cells pending recalculation in sorted order. If we use a heap, this results in an <code>O(n log n)</code> slowdown, so in the worst case, asymptotically slower than Lotus 1-2-3’s strategy of recalculating everything.</p>
<p>Modern-day Excel uses <a href="https://docs.microsoft.com/en-us/office/client-developer/excel/excel-recalculation">a combination of dirty marking and topological sorting</a>, which you can read more about in their docs.</p>
<h2>demand-driven complications</h2>
<p>We’ve now more or less reached the algorithms used in modern-day spreadsheet recalculation. Unfortunately, I suspect there is basically no business case to be made for ever improving it further. The few people with the problem “my Excel spreadsheet is too slow” have already written enough Excel formulas that migration to any other platform is impossible. Fortunately, I have no understanding of business, and so we’re going to look at further improvements anyway.</p>
<p>Beyond caching, one of the cool aspects of a spreadsheet-style computation graph is we can only calculate the cells that we’re interested in. This is sometimes called lazy computation, or demand-driven computation. As a more concrete example, here’s a slightly expanded burrito spreadsheet graph. This example is the same as before, but we’ve added what is best described as “salsa calculations”. Each burrito contains 40 grams of salsa, and we perform a quick multiplication to know how much salsa is in our entire order. In this case, since our order has three burritos, there’s a total of 120 grams of salsa in our entire order.</p>
<p><img alt="a new graph. similar structure to the old graph, but there are two new nodes: &quot;salsa per burrito&quot;, which is set to the constant &quot;40 grams&quot;, and &quot;salsa in order&quot;, which is &quot;salsa per burrito&quot; times &quot;num burritos&quot;" src="https://lord.io/images/2020/anchors_7.png"></p>
<p>Of course, astute readers will have spotted the problem here already: knowing the total weight of salsa in an order is a pretty useless measurement. Who cares that it’s 120 grams? What am I supposed to do with this information?? Unfortunately, a regular spreadsheet would waste cycles calculating <code>Salsa In Order</code>, even if we don’t want it recalculated most of the time.</p>
<p>This is where demand-driven recalculation can help. If we could somehow specify that we’re only interested in the output of <code>Total</code>, we could only recompute that cell and its dependencies, and skip touching <code>Salsa In Order</code> and <code>Salsa Per Burrito</code>. Let’s call <code>Total</code> an <em>observed</em> cell, since we’re trying to look at its output. We can also call both <code>Total</code> and its three dependencies <em>necessary</em> cells, since they’re necessary to compute some observed cell. <code>Salsa In Order</code> and <code>Salsa Per Burrito</code> would be aptly described as <em>unnecessary</em>.</p>
<p>Some folks on the Rust team created the <a href="https://github.com/salsa-rs/salsa">Salsa</a> framework to solve this problem, clearly naming it after the unnecessary salsa calculations their computers were wasting cycles on. Salsa is really cool, and I’m sure <a href="https://www.youtube.com/watch?v=i_IhACacPRY">they can explain</a> how it works better than I can. Very roughly, they use revision numbers to track whether a cell needs recalculation. Any mutation to a formula or input increments the global revision number, and every cell tracks two revisions: <code>verified_at</code> to track the revision its output was last brought up-to-date, and <code>changed_at</code> to track the revision its output last actually changed.</p>
<p><img alt="our new graph, but now there's a title of &quot;current revision: R6&quot;. each cell is tagged with a change revision and verified at revision. all change revisions are R1, except &quot;salsa per burrito&quot;, which is R6. all verified at revisions are R6, except &quot;salsa in order&quot;, which is R1." src="https://lord.io/images/2020/anchors_8.png"></p>
<p>When the user indicates they’d like a fresh value for <code>Total</code>, we’d first recursively recalculate any cell necessary to <code>Total</code>, skipping cells if their <code>last_updated</code> revision is equal to the global revision. Once the dependencies of <code>Total</code> are up-to-date, we only rerun the actual formula in <code>Total</code> if either <code>Burrito Price w Ship</code> or <code>Num Burrito</code> have a <code>changed_at</code> revision greater than the <code>verified_at</code> revision of <code>Total</code>. This is great for Salsa’s purposes in the rust-analyzer, where simplicity is important and each cell takes a significant amount of time to compute. However, we can see the disadvantages in our burrito graph above — if <code>Salsa Per Burrito</code> constantly changes, our global revision number will frequently tick up. This will make each observation of <code>Total</code> walk the three cells necessary to it, even though none of those cells have actually changed. No formulas will be recalculated, but if the graph is large, repeatedly walking all of a cell’s dependencies could get expensive.</p>
<h2>faster demand-driven solutions</h2>
<p>Instead of inventing new algorithms for demand-driven spreadsheets, what if we instead draw from the two classical spreadsheet algorithms mentioned earlier: dirty marking and topological sorting? As you might imagine, a demand-driven model complicates both of these, but both are still viable.</p>
<p>Let’s first look at dirty marking. As before, when we change a cell’s formula, we mark all downstream cells as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lord.io/blog/2020/spreadsheets/">https://lord.io/blog/2020/spreadsheets/</a></em></p>]]>
            </description>
            <link>https://lord.io/blog/2020/spreadsheets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039393</guid>
            <pubDate>Mon, 09 Nov 2020 20:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does consciousness even make sense?]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25039045">thread link</a>) | @algoholix
<br/>
November 9, 2020 | http://niklasbuehler.com/blog/consciousness.html | <a href="https://web.archive.org/web/*/http://niklasbuehler.com/blog/consciousness.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<header>

<span><a href="http://niklasbuehler.com/">Home</a> / <a href="http://niklasbuehler.com/rss.xml">RSS</a> / <a href="http://niklasbuehler.com/contact.html">Contact me</a></span>
</header>
<p><em>08.11.2020</em></p>
<!--
## How does consciousness even make sense?
<a id='1604845992' href='/log/#1604845992'>#1604845992 2020 Nov 08, 15:33</a>
-->
<p>I don’t think the current state of “artificial intelligence” really has proven that it earns the great title of <em>intelligence</em>, as I believe it’s all still just a sophisticated application of statistics on large amounts of data. I prefer the title “machine learning”, as in my opinion that describes the process of adjusting the parameters of statistical methods based on the given data adequately.</p>
<p>I’m not even sure if intelligence and consciousness can be simulated by a computer. Because if they could, then the speed of execution surely wouldn’t matter to that fact, right? And if speed didn’t matter, one could just as well represent the (deterministic!) calculations of a finite computer on a piece of paper or by arranging some stones on a large field. Granted, it’d be somewhat slower than a modern computer and the paper would have to be sufficiently large, but in the end flipping bits, drawing on paper, and moving rocks in a systematic way is just the same when it comes to representing computation. So that’d mean if we arranged a bunch of stones on a large field in a certain pattern and then used some fancy (but deterministic) rules to move them around, we’d create consciousness?! I can’t really believe that’s true.</p>
<p><em>But how is a human brain any different??</em> In the end it’s also just biological wires exchanging electricity (+ some chemistry added to the process)…<br>
I can’t really grasp that. Do my thoughts make sense? Where’s the flaw?</p>
<hr>
<h3 id="join-the-discussion-on-hacker-news">Join the discussion on Hacker News</h3>
<p>There’s an interesting discussion about this text on <a href="https://news.ycombinator.com/item?id=25039045">Hacker News</a>.</p>

<hr>

<h3>Want to leave a comment?</h3>
<p>
If you want to give me some feedback or share your opinion, please contact me via <a href="mailto:hi@niklasbuehler.com?subject=Comment%20on%20Blog:%20consciousness" target="_blank">email</a>.
</p>

<hr>

<p>
<span>© Niklas Bühler, 2020</span>
<span><a href="http://niklasbuehler.com/rss.xml">RSS</a> / <a href="http://niklasbuehler.com/contact.html">Contact me</a></span>
</p>



</div>]]>
            </description>
            <link>http://niklasbuehler.com/blog/consciousness.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039045</guid>
            <pubDate>Mon, 09 Nov 2020 19:48:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Security Maturity Roadmap [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25038422">thread link</a>) | @sciurus
<br/>
November 9, 2020 | https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf | <a href="https://web.archive.org/web/*/https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038422</guid>
            <pubDate>Mon, 09 Nov 2020 19:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A hidden gem in sound symmetry]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25037784">thread link</a>) | @gbh444g
<br/>
November 9, 2020 | https://soundshader.github.io/hn/acf/index.html | <a href="https://web.archive.org/web/*/https://soundshader.github.io/hn/acf/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<blockquote>
  <p><em><a href="https://pages.mtu.edu/~suits/autocorrelation.html">Autocorrelation</a> is used to compare a signal with a time-delayed version of itself. If a signal is periodic, then the signal will be perfectly correlated with a version of itself if the time-delay is an integer number of periods. That fact, along with related experiments, has implicated autocorrelation as a potentially important part of signal processing in human hearing.</em></p>
</blockquote>

<p>ACF is a simple method to visualize music that produces surprisingly good results. Perhaps the most unexpected property of ACF is that it accurately transfers the subjective “harmony level” from music to images. It’s almost an unreasonable property, if you think about it. Images below are ACF height maps in polar coordinates.</p>

<table>
  <thead>
    <tr>
      <th>Female vocal</th>
      <th>David Parsons</th>
      <th>Piano</th>
      <th>Bird</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/song-2.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bowl-3.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/piano-p.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bird-2.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>More examples: <a href="https://soundshader.github.io/gallery/">soundshader.github.io/gallery</a> (beware of large images).</p>

<p>Live demo: <a href="https://soundshader.github.io/">soundshader.github.io</a></p>



<p>Contrary to what you might think, our ears don’t seem to rely on an FFT-like process to extract isolated frequencies. Instead, our ears detect periodic parts in the signal, although in most cases those periodic parts closely match the FFT frequencies. There is a simple <a href="https://auditoryneuroscience.com/pitch/missing-fundamental-stimuli">experiment</a> that proves this point:</p>

<p><img src="https://auditoryneuroscience.com/sites/default/files/missingFundamental2.png" alt=""></p>

<p>As can be clearly seen on the FFT image, the A signal is a pure sinusoidal tone, while B is a mix of tones. Despite each tone in B is higher than A, our ears perceive B as a lower tone. If we plot both waveforms, we’ll see that A has about 9 peaks in a 20 ms window, while B has only 5. The definition of “peak” is moot, but it doesn’t stop our ears from counting them and using the “number of peaks per second” as a proxy to the tone height.</p>

<p>ACF detects those peaks. ACF sees that there are 5 equally spaced time shifts where <code>B[t] * B[t + shift]</code> reaches the maximum, so on the ACF output we’ll see those 5 peaks.</p>

<blockquote>
  <p>Given that I’ve shamelessly stolen the experiment’s illustration above, I feel obligated to recommend the book where the illustration came from: <a href="https://auditoryneuroscience.com/book-preview">Auditory Neuroscience</a>.</p>
</blockquote>

<p>One downside of ACF is that it drops the phase component of the input signal, and thus ACF is not reversible. This means that images that only render ACF, lose about 50% of the information from the sound and those 50% are important, e.g. dropping the phase from recorded speech makes that speech indiscernible. Real world sounds, such as voice, heavily use nuanced amplitude and phase modulation. ACF captures the former, but ignores the latter.</p>



<p>ACF of a sound sample <code>X[0..N-1]</code> can be computed with two FFTs:</p>

<div><div><pre><code>S = |FFT[X]|^2
ACF[X] = FFT[S]
</code></pre></div></div>

<p>And thus ACF contains exactly the same information as the spectral density <code>S</code> (the well known spectrogram).</p>

<blockquote>
  <p>If you’re familiar with the ACF definition, you’ll notice that I should’ve used the inverse FFT in the last step. There is no mistake. The inverse FFT can be computed as <code>FFT[X*]*</code>, where <code>X*</code> is complex conjugate, but since <code>S[i]</code> is real-valued (and positive, in fact), the conjugate has no effect on it, and since ACF is also real valued in this case, the second conjugate has no effect either.</p>
</blockquote>

<p>ACF is a periodic and even function and so it can be naturally rendered in polar coordinates. In most cases, ACF has a very elaborate structure. Below are some examples, where red = ACF &gt; 0 and blue = ACF &lt; 0.</p>

<table>
  <thead>
    <tr>
      <th>conventional music</th>
      <th>a bird song</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/acf-c-1.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/acf-c-3.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>Looking at the first example, we can tell that there are 5 prominent peaks in a 20 ms sound sample, which corresponds to 250 Hz. This means that our ears would necesserarily perceive this sound as a 250 Hz tone, regardless of what its spectrogram says. If it was a pure 250 Hz tone, we’d see perfectly round shapes of the <code>r = cos(250Hz * t)</code> line, but it’s not the case here: we see that the 5 peaks are modulated with small wavelets: there is one big wavelet in the middle (which consists of 3 smaller wavelets) and 4 smaller wavelets. Our ears would hear the big wavelet as the 2nd harmonic of the 250 Hz tone (i.e. it would be a 500 Hz tone with a smaller amplitude) and the 4 small wavelets as the 5th harmonic (1000 Hz) at barely discernible volume. In addition to that, the 500 Hz harmonic is also modulated by the 3 tiny wavelets, which means we’d hear a 1500 Hz tone, almost inaudible. We can say all this without even looking at the spectrogram or hearing the sound.</p>



<p>Music is a temporal ornament. There are many types of ornaments, e.g. the 17 types of wallpaper tesselations, but few of them look like music. However there is one particular type of ornament that resembles music a lot - I mean those “mandala” images. I don’t know how and why those are produced, but I noticed a connection between those images and music:</p>

<ul>
  <li>The 1st obvious observation is that a mandala is drawn in polar coordinates and is <code>2*PI</code> periodic. Sound is periodic too, so I thought the two facts are related.</li>
  <li>The 2nd observation is that patterns on those images evolve over the radial axis. Ans so is music is a sequence of evolving sound patterns.</li>
  <li>The 3rd observation is that a <code>2*PI</code> periodic function trivially corresponds to a set of frequencies. We usually use FFT to extract the frequencies and another FFT to restore the <code>2*PI</code> periodic function. Thus, a single radial slice of a mandala could encode a set of frequencies. If this is correct, a mandala is effectively an old school vinyl disk.</li>
</ul>

<p>Putting these observations together we naturally arrive with the ACF idea.</p>



<p>Open an issue on github or shoot me a email at ssgh@aikh.org</p>



<p>AGPLv3</p>


      
    </div></div>]]>
            </description>
            <link>https://soundshader.github.io/hn/acf/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037784</guid>
            <pubDate>Mon, 09 Nov 2020 18:19:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Illustrated Guide to Superlearning]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037740">thread link</a>) | @prostoalex
<br/>
November 9, 2020 | https://www.khstats.com/blog/sl/superlearning/ | <a href="https://web.archive.org/web/*/https://www.khstats.com/blog/sl/superlearning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      


<blockquote>
<p>Why use <em>one</em> machine learning algorithm when you could use all of them?! This post contains a step-by-step walkthrough of how to build a superlearner prediction algorithm in <code>R</code>.</p>
</blockquote>


<title>
HTML Image as link
</title>


<p><img alt="cheatsheet" src="https://www.khstats.com/img/Superlearning.jpg" width="100%&quot;"></p><figcaption>
<strong><em>A Visual Guide…</em></strong> Over the winter, I read <a href="https://www.springer.com/gp/book/9781441997814"><em>Targeted Learning</em></a> by Mark van der Laan and Sherri Rose. This “visual guide” I made for <em>Chapter 3: Superlearning</em> by Rose, van der Laan, and Eric Polley is a condensed version of the following tutorial. It is available as an <a href="https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/Superlearner.pdf">8.5x11" pdf on Github</a>, should you wish to print it out for reference (or desk decor).
</figcaption>



<div id="supercuts-of-superlearning">

<ul>
<li><p><strong>Superlearning</strong> is a technique for prediction that involves <strong>combining many individual statistical algorithms</strong> (commonly called “data-adaptive” or “machine learning” algorithms) to <strong>create a new, single prediction algorithm</strong> that is expected to <strong>perform at least as well as any of the individual algorithms</strong>.</p></li>
<li><p>The superlearner algorithm “decides” how to combine, or weight, the individual algorithms based upon how well each one <strong>minimizes a specified loss function</strong>, for example, the mean squared error (MSE). This is done using cross-validation to avoid overfitting.</p></li>
<li><p>The motivation for this type of “ensembling” is that <strong>a mix of multiple algorithms may be more optimal for a given data set than any single algorithm</strong>. For example, a tree based model averaged with a linear model (e.g.&nbsp;random forests and LASSO) could smooth some of the model’s edges to improve predictive performance.</p></li>
<li><p>Superlearning is also called stacking, stacked generalizations, and weighted ensembling by different specializations within the realms of statistics and data science.</p></li>
</ul>
<p><img src="https://www.khstats.com/img/spiderman_meme.jpg"></p>
</div>
<div id="superlearning-step-by-step">

<p>First I’ll go through the algorithm one step at a time using a simulated data set.</p>
<div id="initial-set-up-load-libraries-set-seed-simulate-data">
<h2>Initial set-up: Load libraries, set seed, simulate data</h2>
<p>For simplicity I’ll show the concept of superlearning using only four variables (AKA features or predictors) to predict a continuous outcome. Let’s first simulate a continuous outcome, <code>y</code>, and four potential predictors, <code>x1</code>, <code>x2</code>, <code>x3</code>, and <code>x4</code>.</p>
<pre><code>library(tidyverse)
library(knitr)
set.seed(7)</code></pre>
<pre><code>n &lt;- 5000
obs &lt;- tibble(
  id = 1:n,
  x1 = rnorm(n),
  x2 = rbinom(n, 1, plogis(10*x1)),
  x3 = rbinom(n, 1, plogis(x1*x2 + .5*x2)),
  x4 = rnorm(n, mean=x1*x2, sd=.5*x3),
  y = x1 + x2 + x2*x3 + sin(x4)
)
kable(head(obs), digits=3, caption = "Simulated data set")</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Simulated data set</caption>
<thead>
<tr>
<th>id</th>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2.287</td>
<td>1</td>
<td>1</td>
<td>1.385</td>
<td>5.270</td>
</tr>
<tr>
<td>2</td>
<td>-1.197</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-1.197</td>
</tr>
<tr>
<td>3</td>
<td>-0.694</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-0.694</td>
</tr>
<tr>
<td>4</td>
<td>-0.412</td>
<td>0</td>
<td>1</td>
<td>-0.541</td>
<td>-0.928</td>
</tr>
<tr>
<td>5</td>
<td>-0.971</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-0.971</td>
</tr>
<tr>
<td>6</td>
<td>-0.947</td>
<td>0</td>
<td>1</td>
<td>-0.160</td>
<td>-1.107</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 1: Split data into K folds
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step1.png">
The superlearner algorithm relies on K-fold cross-validation (CV) to avoid overfitting. We will start this process by splitting the data into 10 folds. The easiest way to do this is by creating indices for each CV fold.</p>
<pre><code>k &lt;- 10 # 10 fold cv
cv_index &lt;- sample(rep(1:k, each = n/k)) # create indices for each CV fold. We need each fold K to contain n (all the rows of our data set) divided by k rows. in our example this is 5000/10 = 500 rows in each fold</code></pre>


<h2>
<strong>Step 2: Fit base learners for first CV-fold
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step2.png"></p>
<p>Recall that in K-fold CV, each fold serves as the validation set one time. In this first round of CV, we will train all of our base learners on all the CV folds (k = 1,2,…,9) <em>except</em> for the very last one: <code>cv_index == 10</code>.</p>
<p>The individual algorithms or <strong>base learners</strong> that we’ll use here are three linear regressions with differently specified parameters:</p>
<ol>
<li><p><strong>Learner A</strong>: <span>\(Y=\beta_0 + \beta_1 X_2 + \beta_2 X_4 + \epsilon\)</span></p></li>
<li><p><strong>Learner B</strong>: <span>\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_3 + \beta_4 sin(X_4) + \epsilon\)</span></p></li>
<li><p><strong>Learner C</strong>: <span>\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_1 X_2 + \beta_5 X_1 X_3 + \beta_6 X_2 X_3 + \beta_7 X_1 X_2 X_3 + \epsilon\)</span></p></li>
</ol>
<pre><code>cv_train_1 &lt;- obs[-which(cv_index == 10),] # make a data set that contains all observations except those in k=1
fit_1a &lt;- glm(y ~ x2 + x4, data=cv_train_1) # fit the first linear regression on that training data
fit_1b &lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train_1) # second LR fit on the training data
fit_1c &lt;- glm(y ~ x1*x2*x3, data=cv_train_1) # and the third LR</code></pre>
<p>I am <em>only</em> using the linear regressions so that code for running more complicated regressions does not take away from understanding the general superlearning algorithm.</p>
<p>Superlearning actually works best if you use a diverse set, or <strong>superlearner library</strong>, of base learners. For example, instead of three linear regressions, we could use a least absolute shrinkage estimator (LASSO), random forest, and multivariate adaptive splines (MARS). Any parametric or non-parametric supervised machine learning algorithm can be included as a base learner.</p>


<h2>
<strong>Step 3: Obtain predictions for first CV-fold
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step3.png"></p>
<p>We can then get use our validation data, <code>cv_index == 10</code>, to obtain our first set of cross-validated predictions.</p>
<pre><code>cv_valid_1 &lt;- obs[which(cv_index == 10),] # make a data set that only contains observations except in k=10
pred_1a &lt;- predict(fit_1a, newdata = cv_valid_1) # use that data set as the validation for all the models in the SL library
pred_1b &lt;- predict(fit_1b, newdata = cv_valid_1) 
pred_1c &lt;- predict(fit_1c, newdata = cv_valid_1)</code></pre>
<p>Since we have 5000 <code>obs</code>ervations, that gives us three vectors of length 500: a set of predictions for each of our Learners A, B, and C.</p>
<pre><code>length(pred_1a) # double check we only have n/k predictions ...we do :-)</code></pre>
<pre><code>## [1] 500</code></pre>
<pre><code>knitr::kable(head(cbind(pred_1a, pred_1b, pred_1c)), digits= 2, caption = "First CV round of predictions") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 2: </span>First CV round of predictions</caption>
<thead>
<tr>
<th>pred_1a</th>
<th>pred_1b</th>
<th>pred_1c</th>
</tr>
</thead>
<tbody>
<tr>
<td>-1.39</td>
<td>-0.77</td>
<td>-0.40</td>
</tr>
<tr>
<td>-1.27</td>
<td>-0.34</td>
<td>-0.11</td>
</tr>
<tr>
<td>2.16</td>
<td>1.32</td>
<td>1.10</td>
</tr>
<tr>
<td>4.27</td>
<td>4.26</td>
<td>3.98</td>
</tr>
<tr>
<td>3.31</td>
<td>3.98</td>
<td>3.78</td>
</tr>
<tr>
<td>2.29</td>
<td>2.42</td>
<td>2.83</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 4: Obtain CV predictions for entire data set
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step4.png"></p>
<p>We’ll want to get those predictions for <em>every</em> fold. So, using your favorite <code>for</code> loop, <code>apply</code> statement, or <code>map</code>ping function, fit the base learners and obtain predictions for each of them, so that there are 1000 predictions – one for every point in <code>obs</code>ervations.</p>
<p>The way I chose to code this was to make a generic function that combines Step 2 (base learners fit to the training data) and Step 3 (predictions on the validation data), then use <code>map_dfr()</code> from the <code>purrr</code> package to repeat over all 10 CV folds. I saved the results in a new data frame called <code>cv_preds</code>.</p>
<pre><code>cv_folds &lt;- as.list(1:k)
names(cv_folds) &lt;- paste0("fold",1:k)

get_preds &lt;- function(fold){   # function that does the same procedure as step 2 and 3 for any CV fold
  cv_train &lt;- obs[-which(cv_index == fold),]  # make a training data set that contains all data except fold k
  fit_a &lt;- glm(y ~ x2 + x4, data=cv_train)  # fit all the base learners to that data
  fit_b &lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train)
  fit_c &lt;- glm(y ~ x1*x2*x3, data=cv_train)
  cv_valid &lt;- obs[which(cv_index == fold),]  # make a validation data set that only contains data from fold k
  pred_a &lt;- predict(fit_a, newdata = cv_valid)  # obtain predictions from all the base learners for that validation data
  pred_b &lt;- predict(fit_b, newdata = cv_valid)
  pred_c &lt;- predict(fit_c, newdata = cv_valid)
  return(data.frame("obs_id" = cv_valid$id, "cv_fold" = fold, pred_a, pred_b, pred_c))  # save the predictions and the ids of the observations in a data frame
}

cv_preds &lt;- purrr::map_dfr(cv_folds, ~get_preds(fold = .x)) # map_dfr loops through every fold (1:k) and binds the rows of the listed results together

cv_preds %&gt;% arrange(obs_id) %&gt;% head() %&gt;% kable(digits=2, caption = "All CV predictions for all three base learners") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-7">Table 3: </span>All CV predictions for all three base learners</caption>
<thead>
<tr>
<th></th>
<th>obs_id</th>
<th>cv_fold</th>
<th>pred_a</th>
<th>pred_b</th>
<th>pred_c</th>
</tr>
</thead>
<tbody>
<tr>
<td>1…1</td>
<td>1</td>
<td>4</td>
<td>3.73</td>
<td>5.42</td>
<td>5.28</td>
</tr>
<tr>
<td>1…2</td>
<td>2</td>
<td>8</td>
<td>-0.77</td>
<td>-1.19</td>
<td>-1.20</td>
</tr>
<tr>
<td>1…3</td>
<td>3</td>
<td>2</td>
<td>-0.78</td>
<td>-0.81</td>
<td>-0.69</td>
</tr>
<tr>
<td>1…4</td>
<td>4</td>
<td>10</td>
<td>-1.39</td>
<td>-0.77</td>
<td>-0.40</td>
</tr>
<tr>
<td>1…5</td>
<td>5</td>
<td>6</td>
<td>-0.78</td>
<td>-1.01</td>
<td>-0.97</td>
</tr>
<tr>
<td>1…6</td>
<td>6</td>
<td>7</td>
<td>-0.96</td>
<td>-1.04</td>
<td>-0.94</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 5: Choose and compute loss function of interest via metalearner
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step5.png"></p>
<blockquote>
<p>This is the key step of the superlearner algorithm: we will use a new learner, a <strong>metalearner</strong>, to take information from all of the base learners and create that new algorithm.</p>
</blockquote>
<p>Now that we have cross-validated predictions for every observation in the data set, we want to merge those CV predictions back into our main data set…</p>
<pre><code>obs_preds &lt;- 
  full_join(obs, cv_preds, by=c("id" = "obs_id"))</code></pre>
<p>…so that we can minimize a final loss function of interest between the true outcome and each CV prediction. This is how we’re going to optimize our overall prediction algorithm: we want to make sure we’re “losing the least” in the way we combine our base learners’ predictions to ultimately make final predictions. We can do this efficiently by choosing a new learner, a metalearner, which reflects the final loss function of interest.</p>
<p>For simplicity, we’ll use another linear regression as our metalearner. Using a linear regression as a metalearner will minimize the Cross-Validated Mean Squared Error (CV-MSE) when combining the base learner predictions. Note that we could use a variety of parametric or non-parametric regressions to minimize the CV-MSE.</p>
<p>No matter what metalearner we choose, the predictors will always be the cross-validated predictions from each base learner, and the outcome will always be the true outcome, <code>y</code>.</p>
<pre><code>sl_fit &lt;- glm(y ~ pred_a + pred_b + pred_c, data = obs_preds)
kable(broom::tidy(sl_fit), digits=3, caption = "Metalearner regression coefficients") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-9">Table 4: </span>Metalearner regression coefficients</caption>
<thead>
<tr>
<th>term</th>
<th>estimate</th>
<th>std.error</th>
<th>statistic</th>
<th>p.value</th>
</tr>
</thead>
<tbody>
<tr>
<td>(Intercept)</td>
<td>-0.003</td>
<td>0.002</td>
<td>-1.447</td>
<td>0.148</td>
</tr>
<tr>
<td>pred_a</td>
<td>-0.017</td>
<td>0.004</td>
<td>-4.739</td>
<td>0.000</td>
</tr>
<tr>
<td>pred_b</td>
<td>0.854</td>
<td>0.007</td>
<td>128.241</td>
<td>0.000</td>
</tr>
<tr>
<td>pred_c</td>
<td>0.165</td>
<td>0.005</td>
<td>30.103</td>
<td>0.000</td>
</tr>
</tbody>
</table>
<p>This metalearner provides us with the coefficients, or weights, to apply to each of the base learners. In other words, if we have a set of predictions from Learner A, B, and C, we can obtain our best possible predictions by starting with an intercept of -0.003, then adding -0.017 <span>\(\times\)</span> predictions from Learner A, 0.854 <span>\(\times\)</span> predictions from Learner B, and 0.165 <span>\(\times\)</span> predictions from Learner C.</p>
<p><em>For more information on the metalearning step, check out the <a href="#appendix">Appendix</a>.</em></p>


<h2>
<strong>Step 6: Fit base learners on entire data set
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step6.png"></p>
<p>After we fit the metalearner, we officially have our superlearner algorithm, so it’s time to input data and …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.khstats.com/blog/sl/superlearning/">https://www.khstats.com/blog/sl/superlearning/</a></em></p>]]>
            </description>
            <link>https://www.khstats.com/blog/sl/superlearning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037740</guid>
            <pubDate>Mon, 09 Nov 2020 18:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust Is the Future of Game Development]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 236 (<a href="https://news.ycombinator.com/item?id=25037147">thread link</a>) | @adamnemecek
<br/>
November 9, 2020 | https://thefuntastic.com/blog/why-rust-is-the-future-game-dev? | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-2ae295f5=""><p><em>Rust, not related to the video game also called Rust, is a promising systems programming language with novel features ideally suited for game development. Exposure and awareness within the game developer community, however, remains limited. In this post, I provide a gentle introduction to Rust and attempt to justify its place on your radar.</em></p>
<h2 id="a-short-history-lesson">A Short History Lesson</h2>
<p>What is Rust, and where did it come from? In <a href="https://www.youtube.com/watch?v=HiWkMFE8uRE" target="_blank" rel="nofollow noopener noreferrer">this fantastic talk</a>, James Munns gives us a detailed oral history. Way back around 2010, Mozilla was frustrated by the state of development in Firefox, a massive software project  written mostly in C++. Despite best practices and an abundance of engineering talent, writing high-performance, parallelised, and memory-safe code, at that scale of complexity, remained fraught and error-prone.</p>
<p>Bear in mind, this predates the advent of C++11 (aka the 2011 edition) which heralded efforts to somewhat modernise the language. Even so, manual memory manipulation is easy to get wrong, and <a href="https://msrc-blog.microsoft.com/2019/07/18/we-need-a-safer-systems-programming-language/" target="_blank" rel="nofollow noopener noreferrer">research</a> from <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/" target="_blank" rel="nofollow noopener noreferrer">multiple vendors</a> describes this category of error as responsible for 70% of security vulnerabilities. </p>
<p>Into this context steps Graydon Hoare, a Mozilla employee, introducing <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)#History" target="_blank" rel="nofollow noopener noreferrer">a potential solution</a> to the roadblock: Rust, the hobby language he'd been tinkering with since 2006. In 2012, Mozilla would formally announce Servo, an experimental research project to re-imagine a browser engine built with memory safety and concurrency as first principles. And alongside it, Rust, the companion language to make it all possible.</p>
<p>These early days of Rust are described as a Cambrian explosion of ideas and wild experimentation. Concepts were liberally stolen from other languages, from C++ to OCaml, Haskell, Erlang, ML, C#, Ruby and more, reflecting the diverse pool of engineers working on the language at the time. Still, most in the industry, while admiring the optimism in taking such an ambitious moon shot, <a href="http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/" target="_blank" rel="nofollow noopener noreferrer">remained pessimistic</a> about the prospects of success. </p>
<p>2015 saw a major milestone, with the release of Rust v1.0. Perhaps as significant as the feature list, was the number of failed experiments left behind on the cutting room floor, the team unafraid to pare down the language to its quintessential elements. This was also the first time stability guarantees would be offered, a quality notoriously absent before. </p>
<p>Soon after, in 2016, Firefox <a href="https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/" target="_blank" rel="nofollow noopener noreferrer">shipped its first production Rust code</a>. The industry and community started to take notice, and Rust began its impressive, and as yet unbroken, <del>four</del> <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank" rel="nofollow noopener noreferrer">five year streak</a> as Stack Overflow's most beloved language. [<em>Thank you James Munns for pointing out it's now actually five years</em>]. </p>
<p>Right from the outset, Rust set out with a clear focus on   building an inclusive community. They, in turn, have contributed to Rust's impressive technical aptitude, but have also fostered a sense of reverence and fondness not often witnessed in other languages. Are they crazy zealots or onto something?</p>
<h2 id="why-rust">Why Rust?</h2>
<blockquote>
<p><em>The performance of C++ with the convenience of C#</em></p>
</blockquote>
<p>This was the first time Rust hijacked my attention. C++ enjoys a long-standing ubiquity, in part, due to its ability to express zero cost abstractions. As explained by Bjarne Stroustrup, the creator of C++:</p>
<blockquote>
<p><em>What you don't use, you don't pay for. And further: What you do use, you couldn't hand code any better.</em></p>
</blockquote>
<p>It's easy to spot the relevancy to games. Making frame-rate while simulating entire worlds is a daunting performance challenge. Indeed, C++ underpins the bulk of game engines. There simply is <a href="https://www.youtube.com/watch?v=ltCgzYcpFUI" target="_blank" rel="nofollow noopener noreferrer">no other industrial language</a> that offers the same speed and low-level control, whilst writing programs in the large. </p>
<p>C++, however, suffers from the weight of its legacy. The accumulation of features over 40 years makes for a complex and intricate language. In the last decade modernisation of the standard has done well to uplift it from its C roots, but the experienced programmer must build up an arcane lore of which features are blessed, and which machinery is dangerous. As Stroustrup again describes:  </p>
<blockquote>
<p>Within C++, there is a much smaller and cleaner language struggling to get out.   </p>
</blockquote>
<p>This makes the language daunting and difficult to approach for beginners. In <a href="https://boats.gitlab.io/blog/post/zero-cost-abstractions/" target="_blank" rel="nofollow noopener noreferrer">this blog post</a>, Rust contributor <em>withoutboats</em> defines an import quality about abstraction:  </p>
<blockquote>
<p>A zero cost abstraction, like all abstractions, must actually offer a better experience than the alternative.</p>
</blockquote>
<p>So yes, of course, C++ offers a better time than your own hand wrought assembly. However, this is making the subtle point that it's competing against a secondary force: a more expensive abstraction that justifies its cost by being more comfortable and convenient.</p>
<p>We see this writ large in the rise of popular game engines that eschew the complexity of C++, the most notable being Unity. End users write code in C#, a more forgiving and ergonomic language, creating a boon in developer productivity and a reduction in iteration time.  </p>
<p><img src="https://thefuntastic.com/blog/2020-10-Unity-Interest.png" title="Unity interest over time in search trends"></p>
<p>In large codebases though, near the edge of the performance envelope, this trade-off begins to bite. The garbage collector eliminates an entire category of errors by removing responsibility for memory management from the end-user. However as its workload grows, so do periodic performance spikes antithetical to smooth gameplay.  </p>
<p><img src="https://thefuntastic.com/blog/2020-11-GC-spikes.png" title="Unity interest over time in search trends"></p>
<p>The experienced developer can still create a performant experience, however, this demands plugging the leaks in the abstraction. They must build a mental model of the machinery behind the curtain, a collection of arcane wisdom that bans many of the original conveniences, lest they disturb the garbage collector. </p>
<p>So development teams face a choice. Better resourced AAA studios generally choose Unreal or in-house engine tech built on C++, able to absorb the overhead for long term gain. Less resourced studios optimise for time to market, choosing Unity, or one of the many other accessible game making tools (Godot, Haxe, Game Maker, etc.). They often postpone performance concerns until after business eligibility is secured.   </p>
<p>Rust, however, for the first time, promises a third way. A world where it's possible to write zero cost abstractions without sacrificing higher-order elegance. </p>
<h3 id="ownership-based-memory">Ownership based memory</h3>
<p>To understand Rust's special sauce, we're going have to talk about ownership and how it handles memory. This is only a simple sketch, but <a href="http://intorust.com/tutorial/ownership/" target="_blank" rel="nofollow noopener noreferrer">in-depth resources</a> exist for the curious. </p>
<p>Writing optimised code is often about taking the way we, as humans, naturally think of an idea or algorithm, and instead expressing it in terms that favour the computer. This act often harms the legibility and understanding of a program, which makes it much harder for us, the humans, to reason about its correctness. </p>
<p>In a manually managed language, like C, the hapless programmer is left responsible for the machinations of the machine. They must take great care to ensure data is appropriately loaded into memory before operation, and then responsibly disposed of afterwards. A difficult dance in which missteps either cause dramatic crashes or else subtle and hard to detect vulnerabilities. But these are the very same tools that allow careful users to tune performance.  </p>
<p>At the other end of the spectrum, garbage collection promises the programmer it will automatically deal with the problem on their behalf. They are now free to express code naturally, but in doing so, it ties hands behind their back. They no longer have, at least not without indirection, the levers needed to wring out maximal performance.</p>
<p>Rust begins from a different premise. Rather than hiding this complexity, it accepts that computers are hard for humans, and instead tries to save us from the dangerous bits. Users can still tune the machine, but with less rope to wrap around their necks. </p>
<p>In the same way that static typing exists, very clever people have figured out how to make the compiler eliminate a whole category of memory and concurrency errors. To achieve this, Rust makes a bargain with the developer: </p>
<blockquote>
<p>"I'm going to keep track of the lifetime of every piece of memory in your program for you. This way, I can detect the moment you're no longer using it and safely free it on your behalf. But in return, I'm going to need you to follow <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html" target="_blank" rel="nofollow noopener noreferrer">strict rules</a> about the ownership of that memory. If you try to use it outside of the scope that owns it, my humourless friend here, the borrow checker, is going to make sure you don't hurt yourself."</p>
</blockquote>
<p>However, like static typing, this lunch isn't free. Rust is known to have a steep learning curve, "fighting the borrow checker" becomes a right of passage. It takes time to learn this new paradigm. Ownership makes some familiar patterns difficult or impossible and demands new ones be learnt in their place. Perhaps we should revise our earlier statement as: "The performance of C++ with the <del>convenience</del> safety of C#"</p>
<h2 id="unpacking-rusts-popularity">Unpacking Rust's Popularity</h2>
<p>Early adopters have a selfish reason to extol the virtues of their chosen technology, as widespread adoption enhances the return on their risky investment. In this respect, while interest is high but opportunities for real-world exposure are limited, is it possible that Rust is cresting a wave of unearned hype? <a href="https://matklad.github.io/2020/09/20/why-not-rust.html" target="_blank" rel="nofollow noopener noreferrer">Not every javascript or python developer</a> interested in the language, for example, has a use case that merits the additional complexity.</p>
<p>To a developer standing on the shores of 2010, <code>git</code>, a new version control system with a steep learning curve, may have seemed like a risky investment. But, in the ensuing world of Github, it's hard to argue the effort was wasted, even if some workloads (i.e. large games) still require alternatives.</p>
<p>In a similar vein, how can we qualify Rust's popularity as a meaningful signal? Ultimately, we will only know by the volume of mud we've dug through in the trenches, and admittedly, it is far too early to collect this data for games. </p>
<p>In other industries, though, early reports of Rust are effusive. <a href="https://medium.com/the-innovation/how-microsoft-is-adopting-rust-e0f8816566ba" target="_blank" rel="nofollow noopener noreferrer">Mircosoft</a>, <a href="https://developers.libra.org/docs/community/coding-guidelines" target="_blank" rel="nofollow noopener noreferrer">Facebook</a>, <a href="https://aws.amazon.com/blogs/opensource/aws-sponsorship-of-the-rust-project/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>, <a href="https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/" target="_blank" rel="nofollow noopener noreferrer">Dropbox</a>, <a href="https://blog.cloudflare.com/tag/rust/" target="_blank" rel="nofollow noopener noreferrer">Cloudflare</a> all have Rust deployed in production. The <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Rust-Path-LPC2020" target="_blank" rel="nofollow noopener noreferrer">Linux Kernel</a> and <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability" target="_blank" rel="nofollow noopener noreferrer">Chrom…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037147</guid>
            <pubDate>Mon, 09 Nov 2020 17:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian government pledges to connect 98% of Canadians via High-Speed Internet]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25037074">thread link</a>) | @aDfbrtVt
<br/>
November 9, 2020 | https://www.cbc.ca/news/politics/broadband-internet-1.5794901 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/broadband-internet-1.5794901">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The Liberal government is promising to spend more than a billion dollars to connect most Canadian to high-speed internet by 2026.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4962390.1546282434!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/broadband-expansion.jpg"></p></div><figcaption>The Liberal government has been promising to do something to approve broadband internet service in rural areas.<!-- --> <!-- -->(Toby Talbot/Associated Press)</figcaption></figure><p><span><p>After some pandemic-related delays, the Liberal government says it's now&nbsp;on track to connect 98 per cent of Canadians to high-speed internet by 2026.</p>  <p>The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.</p>  <p>Prime Minister Justin Trudeau and a handful of cabinet ministers&nbsp;held a news conference in Ottawa to launch the $1.75 billion universal broadband fund — a program unveiled in the federal government's 2019 budget and highlighted on the campaign trail and in&nbsp;September's throne speech. Most of the money&nbsp;was&nbsp;announced in last year's budget.</p>  <p>"We were ready to go&nbsp;in March&nbsp;with the new Universal Broadband Fund and then the pandemic hit,"&nbsp;Rural Economic Development Minister Maryam Monsef told reporters.</p>  <p>The prime minister said the government is now on track to connect&nbsp;98 per cent of Canadians&nbsp;to high-speed&nbsp;by 2026 — an increase over&nbsp;the previously promised 95 per cent benchmark — and to link up&nbsp;the rest by 2030.</p>  <p>"These are ambitious targets&nbsp;and we're ready to meet them,"&nbsp;Trudeau said.</p>  <p><em><strong>WATCH |&nbsp;Trudeau announces a large investment in broadband services for rural Canadians</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Trudeau announces a large investment in broadband services for rural Canadians"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/573/747/ftr%20TRUDEAU%20broadband_frame_0.jpg" alt=""></p></div></div></div><span>Prime Minister Justin Trudeau spoke with reporters during a media briefing in Ottawa on Monday.<!-- --> <!-- -->2:47</span></span></span></p>  <p>About&nbsp;$150 million from the fund will be freed up to fund projects aimed at getting communities connected by next fall.</p>  <p>Senior officials with the department of&nbsp;Innovation, Science and Economic Development&nbsp;said applications will be reviewed on an ongoing basis until Jan. 15, 2021, with a goal of having projects completed by mid-November, 2021.</p>  <p>Deciding who gets upgraded connectivity first will depend on the service providers applying, they said.</p>  <p>Josh Tabish is&nbsp;corporate communications manager at the Canadian Internet Registration Authority, the not-for-profit agency that manages the .ca internet domain. He said he's hoping&nbsp;that a&nbsp;rapid build will bring relief to many Canadians over the next year.</p>    <p>"In terms of action, I think&nbsp;this is great news for Canadians who are stuck at home suffering from slow, crappy internet," he said.&nbsp;</p>  <p>But Tabish also said he hopes the government will look at need when deciding which projects should get approval first.&nbsp;His group has been working to identify the&nbsp;communities that&nbsp;have the slowest&nbsp;rates in Canada.</p>  <p>"What we really want to see happen is communities who are suffering with slow, sluggish connectivity get those upgrades first," he said.</p>  <p>The prime minister said the government also&nbsp;has reached a $600 million agreement with Telesat for satellite capacity to improve broadband service in remote areas and in the North.</p>    <p>"Good reliable internet isn't a luxury. It's a basic service," he said.</p>  <p>"Now more than ever, a video chat cutting out during a meeting or a connection that's too slow to upload a school assignment — that's not just a hassle, that's a barrier."</p>  <h2>Tories call out timelines</h2>  <p>The Opposition Conservatives criticized the government's timelines, arguing Canadians need better access now more than ever.</p>  <p>"This is absolutely unacceptable and a slap in the face to the nearly one million Canadians who don't have internet access at home, much less a reliable cell phone signal," said MP John Nater, Conservative critic&nbsp;for rural economic development.</p>  <p>"For months, Canada's Conservatives have been demanding concrete action to connect Canadians.&nbsp;We will continue to advocate for lower cell phone prices and for real improvements to broadband internet services, so that Canadians living in rural and remote areas have consistent access to these essential services."</p>  <p>The&nbsp;CRTC <a href="https://www.cbc.ca/news/politics/crtc-internet-essential-service-1.3906664">declared</a> broadband internet a basic telecommunications service in 2016.&nbsp;But its data suggest&nbsp;just&nbsp;<a href="https://crtc.gc.ca/eng/internet/internet.htm">40.8 per cent of rural Canadian households have access to </a>download speeds of&nbsp;at least 50 megabits per second (Mbps) and upload speeds of&nbsp;10 Mbps.</p>  <p>The government said those speeds will allow Canadians to work and learn online and access telehealth services.</p>  <p><em><strong>WATCH | Rural Canadians react to today's announcement</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Liberals promise to connect 98% of Canadians by 2030"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/732/431/politics_THURTON_broadband_money_7000kbps_1280x720_1817544259879.jpg" alt=""></p></div></div></div><span>After some pandemic-related delays, the Liberal government says it's now on track to connect 98 per cent of Canadians to high-speed internet by 2026. The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.<!-- --> <!-- -->1:47</span></span></span></p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/broadband-internet-1.5794901</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037074</guid>
            <pubDate>Mon, 09 Nov 2020 17:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Converting Utzoo-Wiseman Usenet Tapes to PostgreSQL Back End Using Python]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25036780">thread link</a>) | @kxrm
<br/>
November 9, 2020 | https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/ | <a href="https://web.archive.org/web/*/https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="content" role="main" itemprop="mainEntityOfPage" itemscope="itemscope" itemtype="http://schema.org/Blog"> <article id="post-4678" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost"><div> <!-- .entry-header --><div itemprop="articleBody"><p>Recently, I came across a resource that allowed me to download the entire collection of UTZOO NetNews Archive of the earliest USENET posts. These were essentially the earliest available discussions posted to the Internet by people working at various Universities who were already connected to the Internet. There were approximately 2.1 million posts in these archives created between Feb 1981 and June of 1991. This article describes the journey of converting those tapes into fully searchable PostgreSQL database and later also into the <a href="https://usenetarchives.com/groups.php?c=utzoo" target="_blank" rel="noopener noreferrer">usenetarchives.com</a> website.</p><p>Until 2001, these early Usenet discussions were considered being lost, but miraculously <a href="https://en.wikipedia.org/wiki/Henry_Spencer" target="_blank" rel="noopener noreferrer">Henry Spencer</a> from the University of Toronto, Department of Zoology was backing it up onto magnetic tapes and kept them stored for all these years (apparently at a great cost).</p><p><a href="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png" alt="" width="325" height="259" srcset="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png 1282w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-300x239.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-768x613.png 768w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-1024x817.png 1024w" sizes="(max-width: 325px) 100vw, 325px"></a>H. Spencer had altogether 141 of these magnetic tapes, but there were of no use, so eventually, him and a couple of motivated people such as David Wiseman (who dragged 141 tapes back and forth in his a pickup truck), Lance Bailey, Bruce Jones, Bob Webber, Brewster Kahle, and Sue Thielen; embarked on a process of converting all of these tapes into the regular format, accessible to everyone.</p><p>And that’s the copy I downloaded. What a treasure, right?</p><p>Well, not so fast, once I unzipped the data, I realized that the TGZ format contains literally millions of small text files (each post in its own file). While it was certainly nice to have, it wasn’t something that I or anyone else could read. Certainly not in a forum like discussion format. It wasn’t obvious which post is the one that starts the discussion or which ones are the replies to the thread. And forget about searching through these files, that was utterly not possible. Just to put things into perspective, it took me over 5 hours to un-tar the archives.</p><p>That said, it didn’t take long for me to decide to develop a Python-based converter that would allow me to convert the entire collection from millions of flat files into a fully searchable PostgreSQL database. The following post talks about the process and also includes the Python code of the solution released as open source.</p><p>The UTZOO Usenet archive can be downloaded here:</p><ul><li>http://www.skrenta.com/rt/utzoo-usenet/</li><li>http://shiftleft.com/mirrors/utzoo-usenet/</li><li>https://ipfs.io/ipfs/QmTo7fRxpXwxv6Uw4TAAtyLWEmvugKaggrHSKNBTRHzWcA/</li><li>Or using this torrent: <a href="https://www.joe0.com/wp-content/uploads/2020/10/utzoo-wiseman-usenet-archive_archive.zip">utzoo-wiseman-usenet-archive_archive</a></li></ul><p>Once downloaded you’ll see that archive contains 161 x TAR Archive files. It looks like this:</p><p><a href="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png" alt="" width="596" height="531" srcset="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png 832w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87-300x268.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87-768x685.png 768w" sizes="(max-width: 596px) 100vw, 596px"></a></p><p>So, I grabbed a copy of the 7-Zip archiver from <a href="https://www.7-zip.org/">https://www.7-zip.org</a> and started decompressing the files.</p><p>I ended up with over <strong>2,104,828</strong>&nbsp;flat text files in <strong>56,988</strong> folders, which was the entire copy of Henry Spencer’s Usenet archive.</p><p>For those who like numbers, here is each Utzoo tape along with its size, number of files and folders:</p><p id="MLqhONH"><img loading="lazy" width="602" height="2294" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee.png 602w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-79x300.png 79w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-269x1024.png 269w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-403x1536.png 403w" sizes="(max-width: 602px) 100vw, 602px"></p><h3>File Issues</h3><p>While examining the extract, I realized that Magnetic Tape 118 is uncompressed in \utzoo-wiseman-usenet-archive\news118f1 folder, named tape118, so I had rename it to tape118.tar and extracted it manually, only to realize it’s a copy of files which I already have. Someone creating the original archive forgotten to remove that file. There are 3 files in these folders that need to have.tar extension added and decompressed as well:</p><ul><li>\utzoo-wiseman-usenet-archive\news118f1\tape118</li><li>\utzoo-wiseman-usenet-archive\news120f1\tape120</li><li>\utzoo-wiseman-usenet-archive\news121f1\tape121</li></ul><p>If you opened one of the folders and navigated down to one of the many subfolders, you’d find a file that contained the message. For example, going into&nbsp;\utzoo-wiseman-usenet-archive\news006f1\b15\net\aviation folder, I was now apparently in the <strong>net.aviation</strong> Usenet group. But the only way to find out was to open one of the files and look at the content. Here I highlighted what it looked like.&nbsp;As you can see, each file seems to consist of a header, then a single empty line and the body of the message:</p><p id="RYYsysr"><a href="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png" alt="" width="1110" height="759" srcset="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png 1110w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-300x205.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-768x525.png 768w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-1024x700.png 1024w" sizes="(max-width: 1110px) 100vw, 1110px"></a></p><p>So, I decided to build a Python parser, that went through all these files reading the header portion of each message and grouping all unique results together, giving me all the possible headers such as (From, Subject, Newsgroup, etc.). I found that there were about 79 x different types of headers. So it appeared that not all messages adhered to the same basic structure. Going through the headers, all had the standard set that was common across all posts.</p><p>Once I had the common field, I’ve created a Postgres database called ‘utzoo’</p><pre>create database utzoo;</pre><p>And a new schema called all_messages</p><pre>create schema all_messages;


</pre><p>The above database and schema were the pre-requisites. Everything else, like table creation, inserting the posts, etc. is part of the Python script and fully automated.</p><p>In terms of table creation, the script automatically creates 5 tables for each detected newsgroup:</p><ul><li>headers – parsed headers</li><li>references – references for each message</li><li>body – text of the message</li><li>from – who posted the message</li><li>subjects – list of unique subject lines</li></ul><p>This is what the script auto-creates for each unique Group name:</p><pre>create table all_messages.<strong>GroupName_headers</strong>
(
    id         bigserial not null
        constraint GroupName_headers_pk primary key,
    dateparsed timestamp,
    subj_id    bigint,
    ref        smallint,
    msg_id     text,
    msg_from   bigint,
    enc        text,
    contype    text,
    processed  timestamp default CURRENT_TIMESTAMP
);
alter table all_messages.GroupName_headers
    owner to postgres;


create table all_messages.<strong>GroupName_refs</strong>
(
    id      bigint,
    ref_msg text default null
);
alter table all_messages.GroupName_refs
    owner to postgres;

create table all_messages.<strong>GroupName_body</strong>
(
    id   bigint primary key,
    data text default null
);
alter table all_messages.GroupName_body
    owner to postgres;

create table all_messages.<strong>GroupName_from</strong>
(
    id   serial not null
        constraint GroupName_from_pk primary key,
    data text
);
alter table all_messages.GroupName_from
    owner to postgres;

create table all_messages.<strong>GroupName_subjects</strong>
(
    id      serial not null
        constraint GroupName_subjects_pk primary key,
    subject text
);
alter table all_messages.GroupName_subjects
    owner to postgres;</pre><p>Those will be the tables where the Python parser will dump all the data and make sure posts are properly lined up between tables.</p><p>The python script also creates indexes to make the inserting and later reading of the posts faster:</p><pre>create unique index GroupName_headers_uiidx on all_messages.GroupName_headers(id);
create unique index GroupName_headers_umidx on all_messages.GroupName_headers(msg_id);
create unique index GroupName_body_idx on all_messages.GroupName_body(id);; 
create unique index GroupName_from_idx on all_messages.GroupName_from(data);
create unique index GroupName_subjects_idx on all_messages.GroupName_subjects(subject);

</pre><p>Once created, the structure per group looks like this:</p><p id="kdsmyQE"><img loading="lazy" width="362" height="703" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4.png 362w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4-154x300.png 154w" sizes="(max-width: 362px) 100vw, 362px"></p><p>The following screenshot explains how it’s all wired up. I didn’t do any hardcoded relationships, but you can change the script if you want that.</p><p id="THgecCD"><img loading="lazy" width="601" height="496" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef.png 601w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef-300x248.png 300w" sizes="(max-width: 601px) 100vw, 601px"></p><p>The date is an integral part of each message and I had to do some data conversion massaging in Python to get the proper date, as dates were coming in a variety of formats. I’ve tried various libraries but dateutil.parser.parse standard date and time library for Python did the best job.</p><p>However, I still needed to account for various labelling of data fields in the headers, so if data wasn’t found in the ‘date’ header, I had to look into other header parts such as ‘NNTP-Posting-Date’, ‘X-Article-Creation-Date’,&nbsp;‘Posted’,&nbsp;or ‘Received’ fields.</p><p>Well and then it was all about creating a Python parser, start the PostgreSQL, point it to an archive directory, and wait :)</p><p>At the bottom of this article is the code of the Python solution. It’s about 1,000 lines, and it took altogether about 1 day to create and test it. The script is smart enough to keep the track of where it started, so if it needs to be interrupted, it’ll know where to continue from to get the job done.</p><p>The source code is available on GitHub as open-source under MIT license:</p><p><a href="https://github.com/JozefJarosciak/python_mbox_parser/blob/master/utzoo2postgres.py" target="_blank" rel="noopener noreferrer">https://github.com/JozefJarosciak/python_mbox_parser/blob/master/utzoo2postgres.py</a></p><p>The final solution artifact is called ‘<strong>utzoo2postgres.py</strong>‘ , and it was tested on Python 3.8.</p><p>Open the script and define the path to un-tared Utzoo archive directories.</p><p>Examples:</p><pre># for Windows
positionFilePath = "E:\\Usenet\\Utzoo\\"
# for linux:
# positionFilePath = "/Usenet/Utzoo/"</pre><p>Also, define the particulars of your PostgreSQL database:</p><pre>db_connection = psycopg2.connect(host="localhost", user="", password="", port="5432", database="utzoo")</pre><p>And then just execute the script!</p><pre>python 3 utzoo2postgres.py</pre><p><em>Note: In case you need to stop the program and run it later, the script is smart to resume from the last spot it was processing.</em></p><p>The script will process all Utzoo Archive messages in about 6 hours (depending on the speed of your machine).</p><p>Screenshot from processing:</p><p id="UwdOjId"><img loading="lazy" width="713" height="585" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827.png 713w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827-300x246.png 300w" sizes="(max-width: 713px) 100vw, 713px"></p><p>Here is a screenshot of the database after only a couple of minutes of conversion:</p><p id="JQYnVLo"><img loading="lazy" width="432" height="642" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7.png 432w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7-202x300.png 202w" sizes="(max-width: 432px) 100vw, 432px"></p><p>As you can see, the conversion utility produces a database with 5 tables per group where messages are linked to each other through auto-created indexes.</p><p id="kdsmyQE">Let’s say we want to look up all discussions in the<strong> net.physics</strong> discussions; and sort them out by the number of replies.</p><p>This is how you can do that:</p><p id="ymEaJie"><a href="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png" alt="" width="1198" height="625" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png 1198w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-300x157.png 300w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-1024x534.png 1024w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-768x401.png 768w" sizes="(max-width: 1198px) 100vw, 1198px"></a></p><p>Now, we can look up a particular discussion by the ID. For example, we want the ID: 1648 from the screenshot above, the discussion with the subject: “<strong>Question on FTL and quantum mechanics</strong>“. That’s not so hard either:</p><p id="rcwUUqq"><a href="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png" alt="" width="1697" height="847" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png 1697w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-300x150.png 300w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-1024x511.png 1024w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-768x383.png 768w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-1536x767.png 1536w" sizes="(max-width: 1697px) 100vw, 1697px"></a></p><p>It’s nice to have a database full of posts, but it’s hardly usable that way. I needed something that would allow me to easily access these posts.</p><p>So, once everything was done, I built a PHP script around this code and registered <a href="http://usenetarchives.com/" target="_blank" rel="noopener noreferrer">https://usenetarchives.com</a> to make all these archives available online, in an easy to read and search (forum-like) web site.</p><p>The PHP code is not part of this article, but you can head over to <a href="https://usenetarchives.com/groups.php?c=utzoo" target="_blank" rel="noopener noreferrer"><strong>https://usenetarchives.…</strong></a></p></div></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/">https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/</a></em></p>]]>
            </description>
            <link>https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036780</guid>
            <pubDate>Mon, 09 Nov 2020 16:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Separating User Database and Authorization from Apps with Istio and FusionAuth]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25035985">thread link</a>) | @mooreds
<br/>
November 9, 2020 | https://reachablegames.com/oidc-fusionauth-istio/ | <a href="https://web.archive.org/web/*/https://reachablegames.com/oidc-fusionauth-istio/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://reachablegames.com/content/images/size/w300/2020/11/security.jpg 300w,
                            https://reachablegames.com/content/images/size/w600/2020/11/security.jpg 600w,
                            https://reachablegames.com/content/images/size/w1000/2020/11/security.jpg 1000w,
                            https://reachablegames.com/content/images/size/w2000/2020/11/security.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://reachablegames.com/content/images/size/w2000/2020/11/security.jpg" alt="Separating your User Database and Authorization from Applications with Istio and FusionAuth">
            </figure>

            <section>
                <div>
                    <p>Kubernetes is a tremendously powerful cluster management system. &nbsp;There are many pluggable technologies to choose from that exhibit the features you desire, which is great because you have options--but also comes with the down-side that the likelihood someone else has done exactly what you are trying to do is slim. &nbsp;Eventually, there will be some consolidation as developers gather around the best solutions, but for the moment, there are lots of interesting projects to choose from (and not a ton of great examples for certain configs). Today, I'm sharing a slightly challenging setup and hoping it helps the community.</p><p>I am using Istio as my L7 ingress and routing controller, which is based on Envoy. &nbsp;It is a highly scalable L7 proxy with excellent performance characteristics and relatively mature feature set. When it came time to implement a basic <code>/admin</code> route on a project, I came up with the list of features that I wanted to achieve. &nbsp;My desired config:</p><ul><li>Applications should not have access to user passwords or necessarily email</li><li>Applications should not re-implement role-based access control (RBAC) security, as every application will need it</li><li>Users should be able to login without creating yet another username/password to remember, but support it if they prefer</li><li>Users should be able to self-register, password reset if necessary, and manage what remote authentications are associated with their account without needing support (Google keyword CIAM)</li><li>Application Admins should be able to edit the role of users, either explicitly or by group permissions, with a visual interface for non-technical people to control access</li><li>K8s Ops should be able to change what RBAC rules protect individual routes to applications without a redeploy</li><li>Fully self-hosted, to limit external dependencies and have auditable security around user data</li></ul><p>The simplest way to get started is to follow the excellent walkthrough on <a href="https://www.blog.jetstack.io/blog/istio-oidc/">Jetstack.io</a> that explains in reasonably good detail how to cover your whole ingress with JWT handling. &nbsp;I won't go over all that detail here. &nbsp;Instead, I will present the exact YAML manifests necessary to directly deploy a working config, as well as show screenshots of relevant bits in FusionAuth of exactly how to configure the application so it communicates properly with these manifests.</p><h3 id="why-fusionauth">Why FusionAuth?</h3><p>I usually try out two or three alternative technologies before settling into one I like. Although I did start with KeyCloak, it felt a little unpolished and left a lot to be desired when it came to explaining how to configure it if the terminology wasn't familiar (eg. people who aren't security professionals). &nbsp;I studied several other options and it came down to Gluu or FusionAuth. &nbsp;The main deciding factor for me in favor of FusionAuth was the amount of documentation and tutorials (with much appreciated touches of humor). &nbsp;There is also a clear effort made by the developers to provide official docker images and Kubernetes examples that show real world use. &nbsp;I have been remarkably satisfied with this decision.</p><h3 id="quick-architecture-overview">Quick Architecture Overview</h3><p>Ok, so let's talk about the architecture of how this works together. &nbsp;Like any other traffic using Istio, a request will come into an application by following the routing rules of a <code>VirtualService</code> to a <code>Service</code>, then to a Deployment's <code>Pod</code>. &nbsp;To use the Istio security features, this pod needs to have the Sidecar Proxy running, otherwise the rules don't do anything. (This is unfortunate, as it has been my experience that the sidecar can cause connectivity issues with certain workloads, so just be aware it can cause side effects and you may need to explicitly create and configure the <code>Sidecar</code> for this namespace). The easiest way to get this working is to enable automatic sidecar proxy injection on a new <code>Namespace</code> and deploy the application there. &nbsp;By declaring a <code>RequestAuthentication</code> rule, we configure Istio to refuse any traffic that doesn't have a validly signed Json Web Token (JWT). &nbsp;And by declaring an <code>AuthorizationPolicy</code> rule, we configure Istio to accept or deny traffic by matching specific HTTP paths or user roles, etc. &nbsp;That's great! &nbsp;Right?</p><p>Well, Istio isn't quite mature enough to speak Open ID Connect. &nbsp;It's only smart enough to expect a validly decoded JWT and do some simple pattern matching against its contents. &nbsp;When those rules fail, you just get <code>RBAC: access denied</code> as a response to your request. &nbsp;There's no redirection logic to send the browser to the auth server login page. &nbsp;So, let's teach it to do that with a simple <code>EnvoyFilter</code> rule that is injected on <code>SIDECAR_INBOUND</code>. This lets us target specific applications to protect only the routes we care about without impacting anything else. </p><p>A few critical details: <code>RequestAuthentication</code> only accepts a &nbsp;JWT that is signed with an RSA key, because HMAC is a symmetrical key and anyone who can decode it can also sign it. &nbsp;This means it needs to know where to get the public RSA key, which is supplied in the <code>issuer</code> field. &nbsp;Assuming this checks out, Istio then looks at any <code>AuthorizationPolicy</code> rules and either <code>ALLOW</code> or <code>DENY</code> traffic based on matching or non-matching details. &nbsp;In this case, I have provided a basic rule that allows anyone who has been verified to have an account with this application, and further restrict the <code>/admin/</code> path to accounts that have the <code>admin</code> role. &nbsp;Should anything go wrong, Istio just says <code>RBAC: access denied</code> . &nbsp;To diagnose, just delete these rules and try hitting the endpoint to see what errors pop up. &nbsp;If these rules are removed and you are still getting Unauthorized messages, it's oauth2-proxy refusing the user--check the config and logging to see why.</p><p>Here's the YAML we've all been waiting for. &nbsp;This fully describes a working config where the <code>VirtualService</code> is in the default namespace but everything else is in <code>auth</code> just to keep it away from everything else. &nbsp;The application is hosted at <code>https://auth-example.reachablegames.com</code>. &nbsp;Certain difficult and undocumented details that cause problems if not configured properly have been commented below--please pay attention before changing or simplifying things.</p><pre><code># create namespace where applications can have sidecar injection
apiVersion: v1
kind: Namespace
metadata:
  labels:
    app: auth
    istio-injection: enabled
  name: auth
---
# This rule makes sure the JWT is decoded and passed through to the web server as HTTP_PAYLOAD base64 encoded.
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: auth-example
  namespace: auth
spec:
  selector:
    matchLabels:
      app: auth-example
  jwtRules:
  - issuer: "https://fusionauth.reachablegames.com"
    # this passes the full bearer token as the "authorization" header
    forwardOriginalToken: true        
    # this passes just the decoded JWT as "payload" header
    outputPayloadToHeader: "payload"  
---
# This rule verifies the user is an authenticated user (requestPrincipals) and also authorized (request.auth.claims)
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: auth-example
  namespace: auth
spec:
  selector:
    matchLabels:
      app: auth-example
  action: ALLOW
  rules:
  - from:  # limit admin path to users with admin role
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        paths: ["/admin/*"]
    when:
    - key: request.auth.claims[roles]
      values: ["admin"]
  - from:  # allow anyone who is authorized to access the site to access anything other than /admin
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        notPaths: ["/admin/*"]
---
# This intercepts and sends the traffic directly to the oauth2-proxy if there isn't a JWT cookie in the header.
apiVersion: networking.istio.io/v1alpha3
kind: EnvoyFilter
metadata:
  name: auth-example
  namespace: auth
spec:
  workloadSelector:
    labels:
      app: auth-example
  configPatches:
  - applyTo: HTTP_FILTER
    match:
      context: SIDECAR_INBOUND
      listener:
        portNumber: 80
        filterChain:
          filter:
            name: envoy.http_connection_manager
            subFilter:
              name: envoy.filters.http.jwt_authn
    patch:
      operation: INSERT_BEFORE
      value:
        name: envoy.filters.http.ext_authz
        typed_config:
          "@type": type.googleapis.com/envoy.config.filter.http.ext_authz.v2.ExtAuthz
          http_service:
            server_uri: # Note, this absolutely must be the FQDN for the service.  Does not work as a shortname.
              uri: http://auth-example-oauthproxy.auth.svc.cluster.local:8081
              cluster: outbound|8081||auth-example-oauthproxy.auth.svc.cluster.local
              timeout: 10s
            authorizationRequest:
              allowedHeaders:
                patterns:
                - exact: cookie
            authorizationResponse:
              allowedUpstreamHeaders:
                patterns:
                - exact: authorization
---
# Critical: spell out the FQDN because this VirtualService is in "default" but the Service is in "auth"
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: auth-example
  namespace: default
  labels:
    app: auth-example
spec:
  hosts:
  - "auth-example.reachablegames.com"
  gateways:
  - istio-gw
  http:
  - route:
    - destination:
        host: auth-example.auth.svc.cluster.local  # this refers to a Service with name="auth-example"
        port:
          number: 80
---
# Sends traffic to the auth-example deployment pods, which is our application we are trying to secure
apiVersion: v1
kind: Service
metadata:
  name: auth-example
  namespace: auth
  labels:
    app: auth-example
spec:
  ports:
  - port: 80
    name: http-web
    targetPort: http-web
    protocol: TCP
  selector:
    app: auth-example  # send traffic to the auth-example pods
  sessionAffinity: None
  type: ClusterIP
---
# Sends …</code></pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reachablegames.com/oidc-fusionauth-istio/">https://reachablegames.com/oidc-fusionauth-istio/</a></em></p>]]>
            </description>
            <link>https://reachablegames.com/oidc-fusionauth-istio/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035985</guid>
            <pubDate>Mon, 09 Nov 2020 15:51:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oneapi.jl – Native Julia Support for Intel GPUs]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25035875">thread link</a>) | @KenoFischer
<br/>
November 9, 2020 | https://juliagpu.org/2020-11-05-oneapi_0.1/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-11-05-oneapi_0.1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main"><i data-feather="calendar"></i><time datetime="2020-11-05">Nov 5, 2020</time><br><i data-feather="edit-2"></i>Tim Besard<p>We’re proud to announce the first version of oneAPI.jl, a Julia package for programming
accelerators with the <a href="https://www.oneapi.com/">oneAPI programming model</a>. It is currently
available for select Intel GPUs, including common integrated ones, and offers a similar
experience to CUDA.jl.</p><p>The initial version of this package, v0.1, consists of three key components:</p><ul><li>wrappers for the oneAPI Level Zero interfaces;</li><li>a compiler for Julia source code to SPIR-V IR;</li><li>and an array interface for convenient data-parallel programming.</li></ul><p>In this post, I’ll briefly describe each of these. But first, some essentials.</p><h2 id="installation">Installation</h2><p>oneAPI.jl is currently only supported on 64-bit Linux, using a sufficiently recent kernel,
and requires Julia 1.5. Furthermore, it currently only supports a limited set of Intel GPUs:
Gen9 (Skylake, Kaby Lake, Coffee Lake), Gen11 (Ice Lake), and Gen12 (Tiger Lake).</p><p>If your Intel CPU has an integrated GPU supported by oneAPI, you can just go ahead and
install the oneAPI.jl package:</p><pre><code>pkg&gt; add oneAPI
</code></pre><p>That’s right, no additional drivers required! oneAPI.jl ships its own copy of the <a href="https://github.com/intel/compute-runtime">Intel
Compute Runtime</a>, which works out of the box on
any (sufficiently recent) Linux kernel. The initial download, powered by Julia’s artifact
subsystem, might take a while to complete. After that, you can import the package and start
using its functionality:</p><pre><code>julia&gt; using oneAPI

julia&gt; oneAPI.versioninfo()
Binary dependencies:
- NEO_jll: 20.42.18209+0
- libigc_jll: 1.0.5186+0
- gmmlib_jll: 20.3.2+0
- SPIRV_LLVM_Translator_jll: 9.0.0+1
- SPIRV_Tools_jll: 2020.2.0+1

Toolchain:
- Julia: 1.5.2
- LLVM: 9.0.1

1 driver:
- 00007fee-06cb-0a10-1642-ca9f01000000 (v1.0.0, API v1.0.0)

1 device:
- Intel(R) Graphics Gen9
</code></pre><h2 id="the-onearray-type">The <code>oneArray</code> type</h2><p>Similar to CUDA.jl’s <code>CuArray</code> type, oneAPI.jl provides an array abstraction that you can
use to easily perform data parallel operations on your GPU:</p><pre><code>julia&gt; a = oneArray(zeros(2,3))
2×3 oneArray{Float64,2}:
 0.0  0.0  0.0
 0.0  0.0  0.0

julia&gt; a .+ 1
2×3 oneArray{Float64,2}:
 1.0  1.0  1.0
 1.0  1.0  1.0

julia&gt; sum(ans; dims=2)
2×1 oneArray{Float64,2}:
 3.0
 3.0
</code></pre><p>This functionality builds on the <a href="https://github.com/JuliaGPU/GPUArrays.jl/">GPUArrays.jl</a>
package, which means that a lot of operations are supported out of the box. Some are still
missing, of course, and we haven’t carefully optimized for performance either.</p><h2 id="kernel-programming">Kernel programming</h2><p>The above array operations are made possible by a compiler that transforms Julia source code
into SPIR-V IR for use with oneAPI. Most of this work is part of
<a href="https://github.com/JuliaGPU/GPUCompiler.jl">GPUCompiler.jl</a>. In oneAPI.jl, we use this
compiler to provide a kernel programming model:</p><pre><code>julia&gt; function vadd(a, b, c)
           i = get_global_id()
           @inbounds c[i] = a[i] + b[i]
           return
       end

julia&gt; a = oneArray(rand(10));

julia&gt; b = oneArray(rand(10));

julia&gt; c = similar(a);

julia&gt; @oneapi items=10 vadd(a, b, c)

julia&gt; @test Array(a) .+ Array(b) == Array(c)
Test Passed
</code></pre><p>Again, the <code>@oneapi</code> macro resembles <code>@cuda</code> from CUDA.jl. One of the differences with the
CUDA stack is that we use OpenCL-style built-ins, like <code>get_global_id</code> instead of
<code>threadIdx</code> and <code>barrier</code> instead of <code>sync_threads</code>. Other familiar functionality, e.g. to
reflect on the compiler, is available as well:</p><pre><code>julia&gt; @device_code_spirv @oneapi vadd(a, b, c)
; CompilerJob of kernel vadd(oneDeviceArray{Float64,1,1},
;                            oneDeviceArray{Float64,1,1},
;                            oneDeviceArray{Float64,1,1})
; for GPUCompiler.SPIRVCompilerTarget

; SPIR-V
; Version: 1.0
; Generator: Khronos LLVM/SPIR-V Translator; 14
; Bound: 46
; Schema: 0
               OpCapability Addresses
               OpCapability Linkage
               OpCapability Kernel
               OpCapability Float64
               OpCapability Int64
               OpCapability Int8
          %1 = OpExtInstImport "OpenCL.std"
               OpMemoryModel Physical64 OpenCL
               OpEntryPoint Kernel
               ...
               OpReturn
               OpFunctionEnd
</code></pre><h2 id="level-zero-wrappers">Level Zero wrappers</h2><p>To interface with the oneAPI driver, we use the <a href="https://github.com/oneapi-src/level-zero">Level Zero
API</a>. Wrappers for this API is available under the
<code>oneL0</code> submodule of oneAPI.jl:</p><pre><code>julia&gt; using oneAPI.oneL0

julia&gt; drv = first(drivers())
ZeDriver(00000000-0000-0000-1642-ca9f01000000, version 1.0.0)

julia&gt; dev = first(devices(drv))
ZeDevice(GPU, vendor 0x8086, device 0x1912): Intel(R) Graphics Gen9
</code></pre><p>This is a low-level interface, and importing this submodule should not be required for the
vast majority of users. It is only useful when you want to perform very specific operations,
like submitting an certain operations to the command queue, working with events, etc. In
that case, you should refer to the <a href="https://spec.oneapi.com/level-zero/latest/index.html">upstream
specification</a>; The wrappers in the
<code>oneL0</code> module closely mimic the C APIs.</p><h2 id="status">Status</h2><p>Version 0.1 of oneAPI.jl forms a solid base for future oneAPI developments in Julia. Thanks
to the continued effort of generalizing the Julia GPU support in packages like GPUArrays.jl
and GPUCompiler.jl, this initial version is already much more usable than early versions of
CUDA.jl or AMDGPU.jl ever were.</p><p>That said, there are crucial parts missing. For one, oneAPI.jl does not integrate with any
of the vendor libraries like oneMKL or oneDNN. That means several important operations, e.g.
matrix-matrix multiplication, will be slow. Hardware support is also limited, and the
package currently only works on Linux.</p><p>If you want to contribute to oneAPI.jl, or run into problems, check out the GitHub
repository at <a href="https://github.com/JuliaGPU/oneAPI.jl">JuliaGPU/oneAPI.jl</a>. For questions,
please use the <a href="https://discourse.julialang.org/c/domain/gpu">Julia Discourse forum</a> under
the GPU domain and/or in the #gpu channel of the <a href="https://julialang.org/community/">Julia
Slack</a>.</p></main></div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-11-05-oneapi_0.1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035875</guid>
            <pubDate>Mon, 09 Nov 2020 15:42:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture Playbook]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25035752">thread link</a>) | @yarapavan
<br/>
November 9, 2020 | https://nocomplexity.com/documents/arplaybook/index.html | <a href="https://web.archive.org/web/*/https://nocomplexity.com/documents/arplaybook/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
        
          By Maikel Mardjan<br>
        
            © Copyright 2018,2019, 2020 BM-Support.org. Created by Maikel Mardjan. This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (cc-by-sa).<br>
      </p>
  </div></div>]]>
            </description>
            <link>https://nocomplexity.com/documents/arplaybook/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035752</guid>
            <pubDate>Mon, 09 Nov 2020 15:31:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I don't care what Elon Musk thinks anymore]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25035658">thread link</a>) | @avthar
<br/>
November 9, 2020 | https://avthar.com/blog/dont-outsource-thinking | <a href="https://web.archive.org/web/*/https://avthar.com/blog/dont-outsource-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-f18334b57a4385ee2a76"><div><p><em>This blog originally appeared in my </em><a href="https://avthar.substack.com/"><em>weekly newsletter</em></a><em>, where I share ideas I’m reflecting upon, experiments I’m trying and lessons I’ve learned, all to help you level up your own life. To get posts like this straight to your inbox, </em><a href="https://avthar.substack.com/"><em>subscribe here</em></a><em>.</em></p><p>—</p><p>Youtube recommended to me&nbsp;<a href="https://www.youtube.com/watch?v=vVnDE8wSrVo">what Elon Musk would work on if he was 22 years old today</a>. The video has almost 3 million views. In the past, I would’ve immediately watched the whole video, gotten inspired by what Elon thought were industries important to the future of humanity and then spent a ton of time working on that and telling everyone about it. All because Elon Musk thought it was important.&nbsp;</p><p><strong>This is outsourcing your thinking</strong>. This trick served me well in highschool and throughout college, but it’s not sustainable for long term success and happiness.&nbsp;</p><p>There are two problems with outsourcing your thinking. Continuing with the example of past me, there are things I’m already interested in, have&nbsp;<a href="https://nav.al/specific-knowledge">specific knowledge</a>&nbsp;about or possess a competitive advantage in, that won’t be mentioned on Elon’s list. Consequently, the first problem is that I will look down on those things as less meaningful and important and not pursue them, despite my better suitability and chances of success in those areas.</p><p>The second problem with outsourcing your thinking is that once the novelty of the problem fades away, I’d be faced with navigating difficulty, naysayers and the friction of creating something new, without an internal compass to guide me toward the correct paths to take. Put simply, Elon Musk isn’t there to talk me through what he thinks the path forward to be. This all stems from the issue that I pursued something, not because I had interest in that thing, actually enjoyed it or thought it was important, but because Elon Musk (or whoever else) thought it was important to work on. And I followed his thinking, rather than thinking for myself.</p><p>The reason this is important is because most success in business is having&nbsp;<strong>product-market-founder fit</strong>, not just about working on what’s world changing or hot. It’s about building a product that solves a burning problem for the right market and&nbsp;<strong>being the right person, with the right intuition</strong>&nbsp;to bring that product to market, operate that company and delight those customers. Even if you’re working on an important problem, if you don’t have conviction that comes from your own mental models, you’ll get burned when chaos hits. Just ask all the crypto ‘experts’ of 2016/17.&nbsp;<strong>It’s better to build something that’s an expression of yourself, rather than something others think is smart.</strong></p><p>Outsourcing your thinking is a manifestation of the error of trusting others more than we trust ourselves.&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a>&nbsp;talks about how this phenomenon of outsourcing your thinking happens all the time in the investing world:</p><blockquote><p>“<em>If you take investors, there might be an investment, which one from the outside we think is objectively good. But it really isn't objectively good. It has to fit into one's portfolio of investments in a way that emerges from one's own mental models. Otherwise, it is not a form of self expression. Then, when you enter volatility, you're not gonna know what to do with it.</em>” -&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a></p></blockquote><p>Elon Musk is a placeholder for anyone telling you what you should do or think. That could be entrepreneurs or VCs you idolize or maybe your parents (especially true if you’re brown). The reality is that you should not care what Elon Musk or anyone else says is important, you should decide for yourself what you should work on, based on following your own curiosity and interest.&nbsp;<strong>Do the hard work of experimenting, exploring and thinking for yourself. Don’t outsource your thinking.</strong></p><p><a href="https://avthar.substack.com/"><em>Subscribe here</em></a><em> to get posts like this straight to your inbox, </em></p></div></div></div>]]>
            </description>
            <link>https://avthar.com/blog/dont-outsource-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035658</guid>
            <pubDate>Mon, 09 Nov 2020 15:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A US Visa in 937 Days]]>
            </title>
            <description>
<![CDATA[
Score 296 | Comments 144 (<a href="https://news.ycombinator.com/item?id=25035307">thread link</a>) | @caution
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Here’s the complete timeline of events. From my first denial to travel to the US until I eventually received a tourist visa. And then I can’t go anyway.</p>



<h2>December 5-11, 2016</h2>



<p>I spent a week on Hawaii with Mozilla – my employer at the time. This was my 12th visit to the US over a period of 19 years. I went there on ESTA, the visa waiver program Swedish citizens can use. I’ve used it many times, there was nothing special this time. The typical procedure with ESTA is that we apply online: fill in a form, pay a 14 USD fee and get a confirmation within a few days that we’re good to go.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg" alt="" width="558" height="414"></a><figcaption>I took this photo at the hotel we stayed at during the Mozilla all-hands on Hawaii 2016.</figcaption></figure>



<h2>June 26, 2017</h2>



<p>In the early morning one day by the check-in counter at Arlanda airport in Sweden, I was refused to board my flight. Completely unexpected and out of the blue! I thought I was going to San Francisco via London with British Airways, but instead I had to turn around and go back home – slightly shocked. According to the lady behind the counter there was “something wrong with my ESTA”. I used the same ESTA and passport as I used just fine back in December 2016. They’re made to last two years and it had not expired.</p>



<figure><a href="https://twitter.com/bagder/status/879198063998513152"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-06-Twitter-Publish.png" alt="" width="553" height="199"></a><figcaption>Tweeted by me, minutes after being stopped at Arlanda.</figcaption></figure>



<p>People engaged by Mozilla to help us out could not figure out or get answers about what the problem was (questions and investigations were attempted both in the US and in Sweden), so we put our hopes on that it was a human mistake somewhere and decided to just try again next time.</p>



<h2>April 3, 2018</h2>



<p>I missed the following meeting (in December 2017) for other reasons but in the summer of 2018 another Mozilla all-hands meeting was coming up (in Texas, USA this time) so I went ahead and applied for a new ESTA in good time before the event – as I was a bit afraid there was going to be problems. I was right and I got denied ESTA very quickly. “Travel Not Authorized”.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/ESTA-travel-not-authorized.png" alt="" width="642" height="458"><figcaption>Rejected from the ESTA program.</figcaption></figure>



<h2>Day 0 – April 17, 2018</h2>



<p><strong>Gaaah</strong>. It meant it was no mistake last year, they actually mean this. I switched approach and instead applied for a tourist visa. I paid 160 USD, filled in a ridiculous amount of information about me and my past travels over the last 15 years and I visited the US embassy for an in-person interview and fingerprinting.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/Administrative-Processing.png" alt="" width="577" height="289"></figure>



<p>This is day 0 in the <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/" data-type="post" data-id="11076">visa process</a>, 296 days after I was first stopped at Arlanda.</p>



<h2>Day 90 – July 2018</h2>



<p>I missed the all-hands meeting in San Francisco when I didn’t get the visa in time.</p>



<h2>Day 240 – December 2018</h2>



<p>I <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/">quit Mozilla</a>, so I then had no more reasons to go to their company all-hands…</p>



<h2>Day 365 – April 2019</h2>



<p><a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/" data-type="post" data-id="12216">A year passed</a>. “someone is working on it” the embassy email person claimed when I asked about progress.</p>



<h2>Day 651- January 28, 2020</h2>



<p>I emailed the embassy to query about the process</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/651-days-email.png" alt="" width="611" height="166"><figcaption>Screenshotted email</figcaption></figure>



<p>The reply came back quickly:</p>



<blockquote><p>Dear Sir, </p><p>All applications are processed in the most expeditious manner possible. While we understand your frustration, we are required to follow immigration law regarding visa issuances. This process cannot be expedited or circumvented. Rest assured that we will contact you as soon as the administrative processing is concluded.</p></blockquote>



<h2>Day 730 – April 2020</h2>



<p><a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/" data-type="post" data-id="13456">Another year had passed</a> and I had given up all hope. Now it turned into a betting game and science project. How long can they actually drag out this process without saying either yes or no?</p>



<h2>Day 871 – September 3, 2020</h2>



<p>A friend of mine, a US citizen, contacted his Congressman – <a href="https://en.wikipedia.org/wiki/Gerry_Connolly">Gerry Connolly</a> – about my situation and asked for help. His office then subsequently sent a question to the US embassy in Stockholm asking about my case. While the response that arrived on September 17 was rather negative…</p>



<pre>your case is currently undergoing necessary administrative processing and regrettably it is not possible to predict when this processing will be completed.</pre>



<p>… I think the following turn of events indicates it had an effect. It unclogged something.</p>



<h2>Day 889 – September 22, 2020</h2>



<p>After 889 days since my interview on the embassy (only five days after the answer to the congressman), the embassy contacted me over email. <em> For the first time since that April day in 2018.</em></p>



<pre>Your visa application is still in administrative processing. However, we regret to inform you that because you have missed your travel plans, we will require updated travel plans from you.</pre>



<p>My travel plans – that had been out of date for the last 800 days or so – suddenly needed to be updated! As I was already so long into this process and since I feared that giving up now would force me back to square one if I would stop now and re-attempt this again at a later time, I decided to arrange myself some updated travel plans. After all, I work for an American company and I have a friend or two there.</p>



<h2>Day 900 – October 2, 2020</h2>



<p>I replied to the call for travel plan details with an official invitation letter attached, inviting me to go visit my colleagues at <a href="https://www.wolfssl.com/">wolfSSL</a> signed by our CEO, Larry. I really want to do this at some point, as I’ve never met most of them so it wasn’t a made up reason. I could possibly even get some other friends to invite me to get the process going but I figured this invite should be enough to keep the ball rolling.</p>



<h2>Day 910 – October 13, 2020</h2>



<p>I got another email. Now at 910 days since the interview. The embassy asked for my passport “for further processing”.</p>



<h2>Day 913 – October 16, 2020</h2>



<p>I posted my passport to the US embassy in Stockholm. I also ordered and paid for “return postage” as instructed so that they would ship it back to me in a safe way.</p>



<h2>Day 934 – November 6, 2020</h2>



<p>At 10:30 in the morning my phone lit up and showed me a text telling me that there’s an incoming parcel being delivered to me, shipped from “the Embassy of the United State” (bonus points for the typo).</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png" alt="" width="496" height="211"></a></figure>



<h2>Day 937 – November 9, 2020</h2>



<p>I received my passport. Inside, there’s a US visa that is valid for ten years, until November 2030.</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg" alt="" width="441" height="221"></a><figcaption>The upper left corner of the visa page in my passport…</figcaption></figure></div>



<p>As a bonus, the visa also comes with a NIE (National Interest<br>Exception) that allows me a single entry to the US during the PP (Presidential Proclamations) – which is restricting travels to the US from the European Schengen zone. In other words: I am actually allowed to travel right away!</p>



<p>The timing is fascinating. The last time I was in the US, Trump hadn’t taken office yet and I get the approved visa in my hands just days after Biden has been announced as the next president of the US.</p>



<h2>Will I travel?</h2>



<p>Covid-19 is still over us and there’s no end in sight of the pandemic. I will of course not travel to the US or any other country until it can be deemed safe and sensible.</p>



<p>When the pandemic is under control and traveling becomes viable, I am sure there will be opportunities. Hopefully the situation will improve before the visa expires.</p>



<h2>Thanks to</h2>



<p>All my family and friends, in the US and elsewhere who have supported me and cheered me up through this entire process. Thanks for keeping inviting me to fun things in the US even though I’ve not been able to participate. Thanks for pushing for events to get organized outside of the US! I’m sorry I’ve missed social gatherings, a friend’s marriage and several conference speaking opportunities. Thanks for all the moral support throughout this long journey of madness.</p>



<p>A special thanks go to David (you know who you are) for contacting Gerry Connolly’s office. I honestly think this was the key event that finally made things move in this process.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035307</guid>
            <pubDate>Mon, 09 Nov 2020 14:47:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Kafka – 8 things to check before going live]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25035239">thread link</a>) | @ariskk
<br/>
November 9, 2020 | https://ariskk.com/kafka-8-things | <a href="https://web.archive.org/web/*/https://ariskk.com/kafka-8-things">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="A Kafka System" title="A Kafka System" src="https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/18e3b/kafka-system.jpg" srcset="https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/46946/kafka-system.jpg 240w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/55489/kafka-system.jpg 480w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/18e3b/kafka-system.jpg 960w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/60e21/kafka-system.jpg 1440w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/198e7/kafka-system.jpg 1485w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>Apache Kafka is a beautiful system. It scales well, it is stable and it provides phenomenal system architecture flexibility.
After 5 years of running production Kafka clusters, I have collected a list of tips and pitfalls. Some of them were learnt the hard way.
If you work in a small team rolling out Kafka to production, those might prove useful.
The article assume familiarity with basic Kafka concepts, such as brokers, topics, producers and consumers.
What is more, the following points should be valid for up to Kafka 2.6.0.
Without further ado.</p><h3>1. Key all the messages!</h3><p>Kafka topics consist of a (configurable) number of partitions.
If the partition number is not provided by the user, <code>KafkaProducer</code>
chooses the partition for the message using the <code>key</code> in the <code>ProducerRecord</code> instance passed to it.</p><p>Check out the default <a href="https://github.com/apache/kafka/blob/2.6.0/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java#L65">implementation</a>:
It checks if the key is <code>null</code>, and if it isn't it, computes a <code>murmur2</code> hash modulo the number of partitions.
This is consistent; it will yield the same result for messages sharing the same key.
If the key is <code>null</code> though, it uses a <a href="https://github.com/apache/kafka/blob/2.6.0/clients/src/main/java/org/apache/kafka/clients/producer/internals/StickyPartitionCache.java#L60">sticky partitioner</a>
that chooses a partition randomly at every batch.
In practical terms, if no key is passed, the producer will choose the partition randomly.</p><p>This has important implications because <strong>Kafka only provides delivery ordering guarantees within a partition</strong>.
Messages in the same partition will be delivered in the order they were committed.
Messages in different partitions will be delivered in non-deterministic order.
If the messages have any form of <strong>causal relationship</strong> between them, and they are <strong>not</strong> in the same partition,
then any downstream consumer will have to collect all messages for a key before processing them, else causal consistency might be violated; whatever <em>all</em> means in the context of
an infinite stream.</p><p>As a simple example to illustrate the above, think of a simple event like the following:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>case class EmailSubscription(</span></p><p><span>2</span><span>  email: Email,</span></p><p><span>3</span><span>  active: Boolean,</span></p><p><span>4</span><span>  createdOn: DateTime</span></p><p><span>5</span><span>)</span></p><p><span>6</span><span></span></p><p><span>7</span><span>def storeToDB(sub: EmailSubscription) = ???</span></p><p><span>8</span><span>val events: Stream[EmailSubscription] = ???</span></p></pre></div><p>If emails arrive in causal order, then we can map the events statelessly:</p><p>If per-email causal order is not guaranteed though, we need to maintain enough state to know
if the event we see is indeed the latest. Else if the order is reversed, we might send an email to a user who
has unsubscribed.
For example:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>events</span></p><p><span>2</span><span>  .groupMapReduce(_.email)(identity)(</span></p><p><span>3</span><span>    (e1, e2) =&gt; if (e1.createdOn.isAtfer(e2.createdOn)) e1 else e2</span></p><p><span>4</span><span>  )</span></p><p><span>5</span><span>    .values</span></p><p><span>6</span><span>    .map(storeToDB)</span></p></pre></div><p>If we key messages using <code>email</code>, then Kafka will deliver all messages for a single email in the order they were inserted.
Our consumer can be completely stateless; it can fetch messages from Kafka and store them to a datastore.
If the key is <code>null</code> (none provided), our stateless consuer will happily store a message from the past.
To mitigate that, at the very minimum we need to maintain the latest <code>createdOn</code> date for every email.
Relying on wall clocks for causality <a href="https://github.com/aphyr/distsys-class#clocks">is a very bad idea</a>.</p><p>Assuming per key ordering can be guaranteed, downstream reducer bounds can be reduced from a <code>Semilattice</code> to a <code>Semigroup</code>.
In practical terms, by taking advantage of this property we can drop the commutativity requirement which unlocks easier implementations.
If designing reducers for Kafka consumers sounds interesting, let me know and I will write about it.</p><h3>2. Ensure all producers are using the same partitioner</h3><p>Providing a key is not enough. Partitioners (ie the function f: (key) =&gt; partition) are configurable.
Kafka provides a few and users can roll out their own. Do <strong>NOT</strong> assume all producers are using the same partitioner.</p><p>In a complex system where Go services, Python services, Spark and other wild animals all share the same Kafka cluster, all sorts of different implementations might exist.
If different services are pushing data to the same topics, an integration test would be very useful.
If things go wrong, delivery to consumers will be non-deterministic and debugging it can be pure hell.</p><h3>3. Topic versioning</h3><p>The beauty of Kafka is that data can be reprocessed as many times as needed.
This forgives a lot of errors. To illustrate this one, let's assume the same dummy model:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>case class EmailSubscription(</span></p><p><span>2</span><span>  email: Email,</span></p><p><span>3</span><span>  active: Boolean,</span></p><p><span>4</span><span>  createdOn: DateTime</span></p><p><span>5</span><span>)</span></p></pre></div><p>Let's now assume messages are serialized to <code>json</code> before being pushed to Kafka.
Due to a json serialization bug, the following is pushed to the <code>emailsubscriptions</code> topic:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>{</span></p><p><span>2</span><span>  "email": {</span></p><p><span>3</span><span>    "value": "aris@aris.com"</span></p><p><span>4</span><span>  },</span></p><p><span>5</span><span>  "active": false,</span></p><p><span>6</span><span>  "createdOn": 1600000000</span></p><p><span>7</span><span>}</span></p></pre></div><p>Instead of the expected:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>{</span></p><p><span>2</span><span>  "email": "aris@aris.com",</span></p><p><span>3</span><span>  "active": false,</span></p><p><span>4</span><span>  "createdOn": 1600000000</span></p><p><span>5</span><span>}</span></p></pre></div><p>Downstream consumers try to deserialize the message and fail. What can be done?</p><p>One solution would be to create a custom deserializer for those buggy instances and to add it to all the consumers.
That's non trivial and error prone code; useful just for this instance.</p><p>Another solution would be to implement a consumer that would read from <code>emailsubscriptions-1</code>, fix the issue, and write to <code>emailsubscriptions-2</code>.
Once the offsets of the two topics are identical, producers and consumers can switch from <code>emailsubscriptions-1</code> to <code>emailsubscriptions-2</code> without having to update any code.
What's great about this is that those migrations can fail with no major consequences. If <code>emailsubscriptions-2</code> is no good, we can run again and produce <code>emailsubscriptions-3</code> and so on.
This trick also works for non-trivial schema changes, migrations and other data enrichments.
Avro and Profobuf can help in some cases, but bugs will occur and requirements will evolve in unpredictable ways.
In any case, "fixing" a topic's data by reading from it and publishing to it is rarely a good idea.
Topics should be immutable and versioning them can help in many situations where a topic's content have been corrupted.</p><h3>4. Treat ZooKeeper like royalty</h3><p>Up until at least 2.6.0, Kafka relies on ZooKeeper.
Losing connection to ZooKeeper means no ISRs (In-Sync-Replicas, more on that later), no partition leader election and eventually the brokers shut down.
Thankfully <a href="https://twitter.com/fpjunqueira?lang=en">@fpjunqueira</a> and his team who created ZooKeeper are real pros, and that won't happen without reason.
In fact, ZooKeeper is one of the most reliable distributed systems (that I have seen at least).</p><p>The two following mess ups have occurred though:</p><ol><li>Due to a bug in the provisioning Ansible script, 2/3rds of a cluster ended up in the same availability zone, with sequential IPs (that usually means in the same rack on AWS).
They all disappeared at the same time. No consensus, hell broke loose.</li><li>A QA environment ran for long enough for all nodes to run out of disk space (ZooKeeper creates backup snapshots of the transaction log over time and someone/something external has to deal with deleting them).
At the same time. Bringing this env back to life required editing znodes manually, and still data was lost.</li></ol><p>To clean up older transaction log snapshots in ZooKeeper 3.4.x, ZooKeeper provides the following tool:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>java -cp zookeeper-3.4.x.jar:lib/*:conf org.apache.zookeeper.server.PurgeTxnLog \</span></p><p><span>2</span><span>  /var/lib/zookeeper /var/lib/zookeeper -n 5</span></p></pre></div><p>Ideally on a cron.</p><p>Those are just two examples. A lot more can go wrong. Because of the consequences of failure, proper JMX metric monitoring and real time log aggregation,
all hooked up to a form of PagerDuty, are very highly recommended.</p><h3>5. Unclean elections and minimum ISRs</h3><p>This is essentially a trade off between availability and durability. Let's start with unclean elections.</p><p>Let's assume we have a topic with a single partition and a single replica. Data is happily flowing in.
If the replica is "in-sync" (aka identical to the leader and in the ISR set in ZooKeeper),
then if the leader partition becomes unavailable (eg the broker crashes) then the replica can pick up, accept writes and continue with no downtime.
If the replica lags behind though, the leader will remove it from the ISRs in ZooKeeper. If then the leader goes down, there are two options:</p><ol><li>The lagging replica picks up, accepts writes and whatever excess writes the old leader had are <em>lost</em>. Essentially, the replica gets elected as leader without being in-sync. This is the "unclean" part.</li><li>The partition becomes unavailable and new writes are rejected.</li></ol><p>It entirely depends on the kind of data the topic holds. If the topic holds system metrics,
then maybe the most recent data is more valuable and thus losing some older writes might be acceptable.
If the topic contains bank transactions, going down until a human intervenes might be a better option.
This is a broker level config that can be overridden per topic.</p><p>The second part of this equation is <code>min.insync.replicas</code>, which represents the minimum number of replicas that have to be in-sync for a write to go through.
This is configurable at the broker level, topic level and even at the producer level (ie <code>acks</code>). Same considerations as above,
if the topic holds payments, having just 1 replica with all the data might be risky.</p><p>Legendary distributed systems researcher Kyle Kingsbury, aka Aphyr, did an <a href="https://aphyr.com/posts/293-call-me-maybe-kafka">excellent analysis on Kafka's replication mechanism</a> some 7 years ago.
If you wish to dig deeper into this trade off, reading Aphyr's piece is very highly recommeneded. As far as I understand, the basic trade offs discussed still hold true today.</p><h3>6. Memory Maps</h3><p>Kafka uses a LOT of those. Running out of them leads to a fatal runtime exception that will kill the broker.
If the OS defaults are used, it is extremely likely that those will be reached as soon as the cluster has a few tens of thousand segments per broker.
What's worse is that in a well balanced cluster where brokers hold similar numbers of partitions, those failures will occur roughly at the same time.
Let's look a bit closer:</p><p><code>vm.max_map_count</code>: is the maximum number of memory map areas a process can have.</p><p>From the linux kernel <a href="https://www.kernel.org/doc/html/latest/admin-guide/sysctl/vm.html?highlight=max_map_count#max-map-count">docs</a>:</p><blockquote><p>max_map_count:<br>
<!-- -->This file contains the maximum number of memory map areas a process
may have. Memory map areas are used as a side-effect of …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ariskk.com/kafka-8-things">https://ariskk.com/kafka-8-things</a></em></p>]]>
            </description>
            <link>https://ariskk.com/kafka-8-things</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035239</guid>
            <pubDate>Mon, 09 Nov 2020 14:39:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Free Features]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25034809">thread link</a>) | @alangibson
<br/>
November 9, 2020 | https://landshark.io/2020/11/09/no-free-features.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/09/no-free-features.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><a href="https://news.ycombinator.com/item?id=25032105">This thread recently hit the top of Hacker news</a>.</p>

<blockquote>
  <p>No More Free Work from Marak: Pay Me or Fork This</p>

  <p>Respectfully, I am no longer going to support Fortune 500s
( and other smaller sized companies ) with my free work.</p>
</blockquote>

<p>The gist is that Marak, who’s on the brink of homelessness after his apartment building caught fire, is no longer interested in doing unpaid work for businesses using his <a href="https://github.com/Marak/faker.js">faker.js</a> project. He seems to be getting a lot of support from the open source developer community.</p>

<h2 id="unpaid-interns">Unpaid Interns</h2>

<p>The foundational principle of open source is “fix your problem, then give the world a copy of the solution.” So let’s get one thing straight: <em>open source developers are not volunteering to fix your problem.</em> They are fixing their own problems, then letting you use the solution too because it costs them nothing. That near-zero cost of replicating software is why open source works.</p>

<p>Because of this, I don’t think developers claiming to do open source should expect compensation for features that they need for themselves. But developing a new feature that they don’t need is something different entirely. In IT we call that a Change Request, and CRs come with a fee to cover them. ‘Near-zero cost’ doesn’t apply anymore because now they’re taking on a lot of work they otherwise wouldn’t have done.</p>

<p>Not recognizing this difference has led to a situation where for-profit entities are using open-source devs as unpaid interns. Well it’s worse really: at least interns get resume filler.</p>

<h2 id="no-more-free-features">No More Free Features</h2>

<p>I look forward to a day when asking anyone to do unpaid labor is considered unethical by our industry. That goes for feature requests on open source projects, on unpaid internships, and on unpaid ‘take home’ interview assignments.</p>

<p>Requesting work in an economic context without offering compensation in some form is morally indefensible. It’s wrong because unpaid labor is wrong. It’s wrong because presuming on anyone’s helpful nature is wrong. We shouldn’t be using bounties to move our change requests to the head of the line because we shouldn’t even be making requests without a bounty attached.</p>

<p>(<a href="https://news.ycombinator.com/item?id=25034809">Official Hacker News discussion thread</a>)</p>

</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/09/no-free-features.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034809</guid>
            <pubDate>Mon, 09 Nov 2020 13:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Writing Is About Logic, Not Words]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25034706">thread link</a>) | @anacleto
<br/>
November 9, 2020 | https://pulseasync.com/operators/share-written-ideas/ | <a href="https://web.archive.org/web/*/https://pulseasync.com/operators/share-written-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article"><p>Today it's almost obvious to state that good written communication creates a business advantage.</p>
<p>I've probably read more articles on written communication in the workplace in the last two months than over the last 10 years. </p>
<p>Most of these essays gave tips on how to become better writers.</p>
<p>I couldn't help but notice that many (if not all) of them questioned the same thing: the prose.</p>
<p>Everyone advised to keep sentences short and to the point, use active voice and not passive&nbsp;voice, use fewer commas and more periods, avoid acronyms, etc.</p>
<p>Let's be clear: none of these are mistaken or wrong by any means. But this made me realize how huge the misconceptions are on what good business writing actually means.</p>
<p>In fact, what separates most people from good writing has very little to do with style, grammar, local sentences structure, word selection, or even content per se.&nbsp;</p>
<p>Most people can't write well because they don't know how to control the logical sequence in which they present their ideas.</p>
<p>And that is the single most important act necessary to clear writing.</p>
<p>In this essay we're going to dig into how you can effectively share written ideas in a way that value time and effort for others.</p>
<hr>
<h2 id="understanding-how-we-think"><a href="#understanding-how-we-think" aria-label="understanding how we think permalink"></a>Understanding How We Think</h2>
<p>Writing an idea is always the result of two macro-steps. First, decide the point that we want want to make, and then put into words.</p>
<p>To understand how we can effectively share written ideas, we need to understand first how we formulate them in the first place.</p>
<p>Deciding the point you want to make is the result of a 5-step process.</p>
<ul>
<li><em>Unbundling</em> a concept</li>
<li><em>Noticing</em> something</li>
<li><em>Articulating</em>/<em>Developing</em> an idea</li>
<li><em>Re-Bundling</em>&nbsp;</li>
<li><em>Reframing</em></li>
</ul>
<p><img src="https://pulseasync.com/assets/generate-idea-thinking-process.png" alt="State diagram to share the 5-step process one use to generate an idea."></p>
<h3 id="unbundling-a-concept"><a href="#unbundling-a-concept" aria-label="unbundling a concept permalink"></a>Unbundling A Concept</h3>
<p>Every idea begins with an unbundling process. Unbundling is an act of exploration that leads to the decoupling of all the individual items of a certain subject.</p>
<p>Unbundling something doesn't imply a deep understanding of it. It's more a perception of full awareness.</p>
<p>In fact, you might not even know how every individual piece works, but you know they all exist in separate forms. No hidden parts.</p>
<h3 id="noticing-something"><a href="#noticing-something" aria-label="noticing something permalink"></a>Noticing Something</h3>
<p>Unbundling enhances our ability to observe, and this can lead us to noticing something. This can be a pattern, an insight, a novelty, or even a minor detail.</p>
<p>If <em>unbundling</em> is the flint, <em>noticing</em> is the spark that really makes the fire.</p>
<h3 id="articulatingdeveloping-an-idea"><a href="#articulatingdeveloping-an-idea" aria-label="articulatingdeveloping an idea permalink"></a>Articulating/Developing An Idea</h3>
<p>Only when we notice something can we start developing an idea. That's where the creative part begins. That's where you try to develop your initial cue into a fully formed idea.&nbsp;</p>
<p>For instance, if you noticed that something was unnecessary or too complicated, you might run a simplification process. If you noticed something was missing, you go through an addition or reinforcement process.</p>
<h3 id="re-bundling-and-reframing"><a href="#re-bundling-and-reframing" aria-label="re bundling and reframing permalink"></a>Re-bundling And Reframing</h3>
<p>Once you finish including your idea, you go through re-bundling. This is a reconstruction process. This is where you try to recompose a world that now contemplates your newly inserted idea.&nbsp;</p>
<p>Bundling is a fundamental part because it's where you can verify if the your new world still holds up. If not, that's a signal you need to put more work in the articulation phase or what you noticed didn't lead to anything meaningful at all.</p>
<p>If at the end of the re-bundling process your world does hold up, you go through a reframing process.</p>
<p>On paper, this seems to be a very logical and clear process, but in reality it's much more complicated as you constantly repeat these steps of of unbundling, editing your idea, and re-bundling until you find a viable path.</p>
<p><img src="https://pulseasync.com/assets/generate-idea-complexity.png" alt="The complex process of idea generation"></p>
<p>Now that you have an idea, you need to decide how to put it into words that you can share with others.</p>
<h2 id="understanding-how-we-write"><a href="#understanding-how-we-write" aria-label="understanding how we write permalink"></a>Understanding How We Write</h2>
<p>From a broader point, the single goal of writing is to get some information into someone's head.</p>
<p>Think about it. It's almost a simulation act.</p>
<p>You need to reproduce your reader's thinking process using your brain. And know how to build up your information in a way that feels logical and makes sense to them.</p>
<p>This process has very little to do with what you went through when you came up with the idea in the first place. In fact, forcing the reader through the exact same original path you took will have the opposite effect and create more confusion.</p>
<p>Here's how it often goes:</p>
<ol>
<li>You have an idea <em>x</em></li>
<li>You write down a set of words <em>m</em> that lead you to <em>x</em></li>
<li>Because of the pre-existing narrative that led you to the idea, you associate <em>m -&gt; x</em></li>
<li>When you proofread it, you mentally get it. Not because <em>m -&gt; x</em> but because of all the pre-existing associations.</li>
</ol>
<p>This is how most people write. And it's exactly why most people's writing sucks.</p>
<p>Not because they use too many passive forms or weak verbs (that doesn't help either), but because they aren't able to write from the reader's perspective. Most writings lacks the basic logical order and structure.</p>
<h2 id="what-is-good-business-writing"><a href="#what-is-good-business-writing" aria-label="what is good business writing permalink"></a>What is Good Business Writing</h2>
<p>Good business writing is a combination of two things:</p>
<ul>
<li>Information Context</li>
<li>Information Resolution</li>
</ul>
<h3 id="how-to-build-context-the-scqa-framework"><a href="#how-to-build-context-the-scqa-framework" aria-label="how to build context the scqa framework permalink"></a>How to build Context: The SCQA Framework</h3>
<p>Context is the "<em>you're here</em>" red arrow that you can see on almost any maps. Good information context helps the reader set the frame to understand what they're about to read next.</p>
<p>Shared context helps the participants make judgments calls using the same pair of lenses.</p>
<p>A lack of a shared understanding on the basic principles can easily result in a partial understanding or conflict on what follows.</p>
<p>What's the best way to build information context?</p>
<p>Barbara Minto, a McKinsey consultant in the 70s, solved this problem with what she called the <em>SCQA framework</em>.</p>
<p>She named this framework the <em>Situation — Complication — Question — Answer</em> framework. You can unpack more on this topic in her book “The Pyramid Principle”.</p>
<p>According to Minto, context is the result of these four sub-ingredients:</p>
<ol>
<li>Situation,</li>
<li>A Complication,</li>
<li>A Question,</li>
<li>... and an Answer.</li>
</ol>
<p>The <strong>Situation</strong> is a non-controversial statement on a subject that you know the reader will agree because it's something he already knows. By summarizing what he already knows, the situation establishes the relevance of the questions that your document is going to answer.&nbsp;</p>
<p>The <strong>Complication</strong> describes an alteration of a stable situation. Keep in mind, this alteration is purely fact-based. The Situation-Complication combination should lead the reader to an immediate question.</p>
<p>The <strong>Question</strong> represents an intuitive response to the complication. The best Situation-Complication scenario makes the question sound totally superfluous to state. The best questions aren't posed, they emerge.</p>
<p>The <strong>Answer</strong> is the summary of your main idea. Beware, it's the solution, not the explanation of it. Good answers are typically represented by 3/4 bullet points. No more.</p>
<p>If you squint at it, you realise that the SCQA framework turned out initial schema upside down.</p>
<p>Ideas comes up in a bottom-up fashion, but they need to be told top-down.</p>
<p>This is not how we think. But it's how we should write.</p>
<p><img src="https://pulseasync.com/assets/scqa-reversed-thinking-frmework.png" alt="SCQA reversed thinking framework"></p>
<p>Another interesting benefit of building information context using the SCQA framework is that once you've gotten the initial part out of the way, you can focus all your energy on making and supporting the case for why it's true.</p>
<h3 id="how-to-increase-resolution-whyhow-dialogues"><a href="#how-to-increase-resolution-whyhow-dialogues" aria-label="how to increase resolution whyhow dialogues permalink"></a>How to increase Resolution: Why/How Dialogues</h3>
<p>Ensuring you and your reader are in the same place before you lead him through your thinking is a necessary but non-sufficient condition. </p>
<p>Once he's aware of the gist of your main idea (Answer), you need to argue and support it. That's when you need to focus on information resolution.</p>
<p>Think of <em>information resolution</em> as the density level of details that you're able to provide to the reader. The bolder the answer, the higher resolution levels it requires.</p>
<p>If you gloss over key important passages, people will not follow your thinking and might have a partial understanding of the message.</p>
<p>How do you increase information resolution?</p>
<p>You support your initial <em>Answer</em> using the form of Why/How dialogues. Making an initial statement that the reader doesn't know will automatically raise a logical question in his mind. <em>How is that possible?</em> <em>Why do you say that?</em> In your following answers, you're likely to tell him other details he doesn't know and this will raise further questions that you're going to answer. And so on.</p>
<p>The author will continue to write, raising and answering questions, until he reaches a point at which he judges the reader will have no more logical questions.</p>
<p>The vertical relationship of a why/how dialogue helps capture the reader's attention. It permits you, as an author, to establish an inner dialog that will pull him with great interest through your reasoning. The reader will be forced to respond logically to your ideas.</p>
<p>As you can see we've not made a full circle. We're now in the (previously discussed) unbundling part.</p>
<h2 id="examples-of-good-business-writing"><a href="#examples-of-good-business-writing" aria-label="examples of good business writing permalink"></a>Examples of Good Business Writing</h2>
<p>Armed with our SCQA framework and the Why/How vertical development, let's look at the skeleton of some real examples.</p>

<p>It's one of the most common examples. common examples. A salesperson, after speaking with a customers, irrupts in the #product or #engineering Slack channels requesting the implementation of a given feature.</p>
<p>If you've been in this position, here's how you can Minto-ize an internal feature request for your product:</p>
<blockquote>
<p><em>Situation:</em>
We have never allowed customers to customize XYZ in order to keep complexity low.</p>
<p><em>Complication:</em>
However, competitor X has now shipped such a customization feature, and we’ve been losing deals because of that.</p>
<p><em>Questions:</em>
We now need to decide whether we want to allow some kind of customization as well.</p>
<p><em>Answer:</em>
[...]</p>
</blockquote>

<p>Directives are the most common internal memo. Executives write them to request something of someone.</p>
<blockquote>
<p><em>Situation:</em>&nbsp;
As you know we're repositioning product <em>x</em> for mid-sized enterprise. We need to teach you how to see <em>x</em> for organizations between 100 and 200 employees.</p>
<p><em>Complication:</em>
We've never sold to this type of customer before. Hence, we need to construct a new customer profile from scratch</p>
<p><em>Questions:</em> (How can we do the profile?)</p>
<p><em>Answer:</em>
We're going to host:</p>
<ol>
<li>A …</li></ol></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pulseasync.com/operators/share-written-ideas/">https://pulseasync.com/operators/share-written-ideas/</a></em></p>]]>
            </description>
            <link>https://pulseasync.com/operators/share-written-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034706</guid>
            <pubDate>Mon, 09 Nov 2020 13:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cyrillic orthography for the Polish language]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25034182">thread link</a>) | @keiferski
<br/>
November 9, 2020 | http://steen.free.fr/cyrpol/index.html | <a href="https://web.archive.org/web/*/http://steen.free.fr/cyrpol/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<!---------------- Header ------------------->





<!---------------- Body ------------------->



<p><small><i>See also: </i> <a href="http://steen.free.fr/interslavic/index.html">Interslavic</a>, <a href="http://steen.free.fr/wenedyk/index.html">Wenedyk</a>, <a href="http://steen.free.fr/poilschi/index.html">Poilschi</a></small></p>

<a name="introduction"></a>

<h2>Ortografia cyrylicka dla języka polskiego</h2>
<h2>A Cyrillic orthography for the Polish language</h2>

<p><big>E</big>ver wondered what Polish would look like if it were written in Cyrillic? Perhaps you have. Or not. In any case, I have. That's what happens when you spend half of your life working on language projects that one way or another are related to Polish or the Slavic languages in general. Toying around with Polish, Slavic, as well as with several Slavic orthographies, it is hard not to think about the possibilities of a Cyrillic orthography for Polish.</p>

<p>Many people have argued that Cyrillic would be unsuitable for Polish. I disagree with that opinion. Granted, Polish phonology differs from that of the other Slavic languages in several ways, but these two facts remain: Polish is a completely Slavic language by any standard, and Cyrillic, unlike the Latin alphabet, was made especially to fit Cyrillic phonology, and therefore is perfectly suited for it. Therefore, I am convinced that Polish and Cyrillic are a perfect match. Much more so, in fact, than Polish and the Latin alphabet. Latin orthographies of Slavic languages always have one of the following two disadvantages: either they are full of diacritical marks, or they look horribly like English or another Western language. Slovene manages best, but still has <b>š</b>, <b>ž</b> and <b>č</b>. Other languages have more of those babies. Polish orthography has managed to avoid hačeks, but has a whole bunch of other diacritics instead: <b>ą</b>, <b>ę</b>, <b>ł</b>, <b>ż</b>, <b>ć</b>, <b>ń</b>, <b>ó</b>, <b>ś</b>, <b>ź</b>. Besides, Polish in addition tends to favour digraphs like <b>sz</b> and <b>ie</b>, so Polish words tend to be appear longer than they actually are.</p>

<p>Now, I am quite fond of Polish orthography, and therefore my Cyrillic orthography of Polish should by no means be treated as a serious proposal to replace Polish orthography. If anyone would ever make such a proposal, I would be the first to stand up against it. This project, therefore, is primarily a thought experiment, my answer to the question if such an orthography would be possible at all.</p>

<p>The idea, by the way, is not new at all. If we have to believe Wikipedia, Russia's czar Nikolay I intended to cyrillify Polish in the mid-19th century as a means for russification, although at last nothing came of his plans. Here is a sample:</p>

<table><tbody><tr><td>
<div><p>Поврóтъ Таты, <i>пр̌езъ А. Мицкевича</i></p><p>
Пóйдзьце о дзятки, пóйдзьце вшистке разэм<br>
За място, подъ слупъ на взгóрэкъ,<br>
Тамъ пр̌едъ цудовнымъ клęкнийце образэмъ,<br>
Побожне змóвце пацёрэкъ.</p><p>
Тато не враца ранки и вечоры<br>
Вэ Лзах го чекамъ и трводзэ;<br>
Розлялы р̌еки, пэлнэ звер̌а боры,<br>
И пэлно збóйцóвъ на дродзэ;-</p></div>
</td><td>
<div><p>Слышąцъ то дзятки бегнą вшистке разэмъ<br>
За място подъ слупъ на взгóрэкъ,<br>
Тамъ пр̌едъ цудовнымъ клęкая̨ образемъ,<br>
И зачиная̨ пацёрэкъ.</p><p>
Цалуя̨ земę, потэмъ въ Имę Ойца,<br>
Сына и Духа свęтэго,<br>
Бąдзь похвалёна пр̌енайсьвęтша Трóйца<br>
Тэразъ и часу вшелькего.</p><p>
(...)</p></div></td></tr></tbody></table>

<p>A few pecularities in this text deserve our attention:
</p><ul>
<li>the use of the letter <b>р̌</b> for Polish <b>rz</b>;
</li><li>the hard sign <b>ъ</b> at the end of many words (a feature common in prerevolutionary Russian);
</li><li>the fact that Polish <b>ó</b> remains untouched;
</li><li>this orthography inherits the Polish ogonek and adds it to Cyrillic letters;
</li><li>the use of <b>ць</b> and <b>дзь</b> where Polish has <b>ć</b> and <b>dź</b>, a feature also present in contemporary Belarusian.
</li></ul>

<p>My own Cyrillic orthography for Polish is largely based on the same premises, but there are a few differences as well, which I will describe below. By the way, it should be noted that the transcription quoted above is not the only attempt at a Cyrillic alphabet for Polish. Several people have played with the idea, seriously or less seriously. An interesting example is <a href="http://varpho.livejournal.com/2006/11/17/">Jusowica (Юсовица)</a>, created by Szymon Pawlas.</p>

<hr>

<p><big>T</big>he biggest problem related with the Cyrillisation of Polish are sounds that do not exist in other languages, nor do they correspond closely with anything else that exist in them: the nasal vowels <b>ą</b> and <b>ę</b>. The 19th century Russian solution is in fact a pretty funny one: it simply teleports the ogonek to Cyrillic, thus producing four characters that have never seen before in Cyrillic: <b>а̨</b>, <b>э̨</b>, <b>я̨</b> and <b>е̨</b> (the latter two representing <b>ją</b> and <b>ję</b> respectively). A funny solution indeed! And an unnecessary one to that, because Old Church Slavonic has precisely four Cyrillic characters for exactly these four sounds: <b>ѫ</b>, <b>ѧ</b>, <b>ѭ</b> and <b>ѩ</b>. True, they are uncommon, because the only living Slavic language that preserved these sounds is Polish, a language that happens to be written in Latin alphabet. But since these letters are around, why shouldn't we simply use them? After all, they exist, and are indefinitely more Cyrillic than Cyrillic letters with ogoneks beneath them. Besides, the choice for <b>а̨</b> and <b>я̨</b> is equally unlogical as the Polish letter <b>ą</b> itself, since it is pronounced as nasalised <b>o</b>; it is not for nothing that the Latin transcription of Old Church Slavonic uses <b>ǫ</b>.</p>

<p>Another specifically Polish letter is the <b>ó</b>, pronounced as [u] (its Czech equivalent is <b>ů</b>). The transcription mentioned above conveniently keeps it. But why would we? It has no pronunciation of its own; the only thing that distinguishes it from <b>u</b> is that it alternates with <b>o</b>. Incidentally, mixing up those two is the most common spelling mistake in Polish. As far as I am concerned, there is no reason to keep it. Since <i>miasto</i> alternates with <i>mieście</i> (and not with <i>miæście</i> or something), why can't <i>grud</i> alternate with <i>grodzie</i>? So let's be bold and use <b>у</b> instead.</p>

<p>The characters <b>ć</b> and <b>dź</b> could of course be rendered like Belarusian (and in a way, Polish) does, by using <b>ць</b> and <b>дзь</b>, but I'd much prefer <b>ть</b> and <b>дь</b>. Etymologically speaking, this is more correct; after all <b>ć/dź</b> are the softened equivalents of <b>t/d</b>, not of <b>c/dz</b>. Sequences like <b>ti</b> and <b>di</b> are rare in Polish and occur only in foreign words. In these rare cases, we could write <i>радио</i> and <i>тиара</i> (a Pole will know that they are to be read as <i>radio</i> and <i>tiara</i> and not like <i>radzio</i> or <i>ciara</i>). Or, if we want to be really sure that the <b>t</b> will not be softened in these cases, we could use the hard sign and write <i>радъио</i> and <i>тъиара</i>.<br>
Using <b>ть</b>/<b>дь</b> instead of <b>ць</b>/<b>дзь</b> has one more advantage: now at least will not have to worry about the sequence <b>cja</b>, which is unambiguously rendered as <b>ця</b>.</p>

<p>Same goes for the digraphy <b>rz</b>, which in Polish is pronounced like <b>ż</b>. Another common source of spelling errors. Yet, I wouldn't propose transcribing it to <b>ж</b>, for the same etymological reasons: <b>rz</b> comes from softened <b>r</b>, while <b>ż</b> comes from softened <b>g</b>. The fact that it sounds very different does not change that fact. Therefore, we simply use <b>рь</b> (and not this weird creation from the 19th century, <b>р̌</b>). Just like <b>ti</b> and <b>di</b>, <b>ri</b> is a rare sequence in Polish that occurs only in foreign words, so I propose the same solution for it as well.</p>

<p>And then we have the letter <b>e</b>. Because in Polish palatalising <b>e</b> is way more numerous than its non-palatalising equivalent, we will use Cyrillic <b>e</b> for the former (usually rendered as <b>je</b> or <b>ie</b>) and <b>э</b> for the latter. This is also what the 19th century version does.</p>

<p>The choice for other Cyrillic letters is merely a matter of picking an option. For example, how do we represent <b>i</b> and <b>y</b>? Do we follow the Russian model and pick <b>и/ы</b> or do we prefer the Ukrainian model and pick <b>і/и</b>? Both are possible, but I've decided to follow the Russian model. Also, when preceded by <b>cz</b>, <b>sz</b> or <b>ż</b> we write <b>и</b> instead of <b>ы</b> – just like Russian does. Again, a matter of etymology.</p>

<p>So, let's see now what Cyrylica Polska looks like.</p>

<a name="alphabet"><hr></a><h2>Alphabet</h2>

<p><big>C</big>yrylica Polska has 37 letters. Exactly the same as the 33 letters of the Russian alphabet, with four additional characters for the nasals:</p>

<p><p><b><span size="+1">А Б В Г Д Е Ë Ж З И Й К Л М Н О П Р С Т У Ф Х Ц Ч Ш Щ Ъ Ы Ь Э Ю Я Ѧ Ѫ Ѩ Ѭ</span></b></p></p>

<a name="vowels"><hr></a><h2>Vowels</h2>

<p><big>E</big>very vowel has a hardening and a softening version. Both can occur in two possitions: either it follows a consonant, or it doesn't (in that case it is either word-initial or after another vowel). In Polish orthography, when a softening vowel follows a consonant, it is preceded by <b>i</b>, unless the consonant in question is inherently soft. In other positions this vowel is preceded by <b>j</b>. The only exceptions are <b>i</b>, which is softening by definition, and <b>y</b>, which is never softening. <br>
Just like <b>i</b> and <b>y</b> form a pair, in Cyrillic all vowels come in pairs, as you can see in the table below:</p>

<p><table><colgroup><col><col><col><col>
</colgroup><tbody><tr><th colspan="2">Latin</th><th colspan="2">Cyrylica</th></tr>
<tr><th> <i>hard</i> </th><th> <i>soft</i> </th><th> <i>hard</i> </th><th> <i>soft</i> </th></tr>
<tr><td>	a	</td><td>	ia/ja		</td><td>	а	</td><td>	я	</td></tr>
<tr><td>	e	</td><td>	ie/je		</td><td>	э	</td><td>	е	</td></tr>
<tr><td>	y	</td><td>	i		</td><td>	ы	</td><td>	и	</td></tr>
<tr><td>	o	</td><td>	io/jo		</td><td>	о	</td><td>	ë	</td></tr>
<tr><td>	ó<br>u	</td><td>	ió/jó<br>iu/ju	</td><td>	у	</td><td>	ю	</td></tr>
<tr><td>	ą	</td><td>	ią/ją		</td><td>	ѫ	</td><td>	ѭ	</td></tr>
<tr><td>	ę	</td><td>	ię/ję		</td><td>	ѧ	</td><td>	ѩ	</td></tr>
</tbody></table></p>

<a name="consonants"><hr></a><h2>Consonants</h2>

<p><big>N</big>ow that the question of palatalised vs. non-palalalised consonant has been resolved by the vowels that follow them, the consonants have suddenly become very simple to handle. Here goes:</p>

<p><table><tbody><tr><td>
<table><colgroup><col width="40%"><col width="60%">
</colgroup><tbody><tr><th>Latin</th><th>Cyrylica</th></tr>
<tr><td>	p		</td><td>	п	</td></tr>
<tr><td>	b		</td><td>	б	</td></tr>
<tr><td>	f		</td><td>	ф	</td></tr>
<tr><td>	w		</td><td>	в	</td></tr>
<tr><td>	t, ć		</td><td>	т	</td></tr>
<tr><td>	d, dź		</td><td>	д	</td></tr>
<tr><td>	s, ś		</td><td>	с	</td></tr>
<tr><td>	z, ź		</td><td>	з	</td></tr>
<tr><td>	k		</td><td>	к	</td></tr>
<tr><td>	g		</td><td>	г	</td></tr>
<tr><td>	ch<br>h		</td><td>	х	</td></tr>
</tbody></table>
</td><td>
<table><colgroup><col width="40%"><col width="60%">
</colgroup><tbody><tr><th>Latin</th><th>Cyrylica</th></tr>
<tr><td>	sz		</td><td>	ш	</td></tr>
<tr><td>	ż		</td><td>	ж	</td></tr>
<tr><td>	cz		</td><td>	ч	</td></tr>
<tr><td>	szcz		</td><td>	щ	</td></tr>
<tr><td>	c		</td><td>	ц	</td></tr>
<tr><td>	m		</td><td>	м	</td></tr>
<tr><td>	n		</td><td>	н	</td></tr>
<tr><td>	ł, l		</td><td>	л	</td></tr>
<tr><td>	r, rz		</td><td>	р	</td></tr>
<tr><td>	j		</td><td>	й	</td></tr>
<tr><td>	ь		</td><td>	soft sign	</td></tr>
<tr><td>	ъ		</td><td>	hard sign	</td></tr>
</tbody></table>
</td></tr></tbody></table></p>

<p>A few notes:
</p><ul>
<li>Most consonants can be soft (palatalised) or hard. Whether a Cyrillic <b>д</b> should be read as <b>d</b> or <b>dź</b> is decided by the consonant that follows it: <b>дэ</b> should be read as <b>de</b>, <b>де</b> should be read as <b>dzie</b>.
</li><li>If a soft consonant is not followed by a vowel, i.e. when it is word- or syllable-final, it is followed by the soft sign: <b>bat</b> becomes <b>бат</b>, <b>bać</b> becomes <b>бать</b>.
</li><li>In reality, the soft sign will occur only after <b>т</b>, <b>д</b>, <b>н</b>, <b>л</b>, and <b>р</b>. However, in a few cases it can be placed after another consonant as well, although that wouldn't affect pronunciation. For example, take these two Polish cities: Kraków and Wrocław. When declined, the former has a hard <b>w</b>, the latter a soft <b>w</b>, and so their genitives are <i>Krakowa</i> and <i>Wrocławia</i> respectively. In Cyrillic, we could easily write <b>Вроцлавь</b> for "Wrocław", to make this fact predictable.
</li><li>Most consonant clusers as palatalised as a whole, and only in a few cases consonants in such a cluster are palatalised individually. Therefore, <b>śmiałość</b> is written <b>смялость</b>, and not <b>сьмялосьть</b>.
</li><li>The consonant clusters <b>śr</b> and <b>źr</b> (historically from <i>ser-/zer- &gt; srze-/zrze-</i>, in some dialects <i>st…</i></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://steen.free.fr/cyrpol/index.html">http://steen.free.fr/cyrpol/index.html</a></em></p>]]>
            </description>
            <link>http://steen.free.fr/cyrpol/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034182</guid>
            <pubDate>Mon, 09 Nov 2020 12:49:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When remote work doesn't cut it]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25034037">thread link</a>) | @FlyingSnake
<br/>
November 9, 2020 | https://samkhawase.com/blog/remote-work/ | <a href="https://web.archive.org/web/*/https://samkhawase.com/blog/remote-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>The COVID-19 crisis, while disrupting the global world unlike anything before, has opened up an unexpected window to remote work. Nearly all major<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>tech<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> giants<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> have<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> allowed their workers to do home office. Many people are considering this as a sign of the advent of <strong>Work 2.0</strong>, where physical offices spaces will be irrelevant, and people can work from their cozy dens. There are however significant challenges in adoption of generalized remote work and things will be back as usual once the COVID-19 ends.</p>
<p>The <strong>challenges surrounding remote work outweigh it’s promises</strong>. Not every company is a FAANG, and companies will struggle to transition given their limited resources.</p>
<h2 id="regulations">Regulations</h2>
<p>The most significant hurdle in hiring a global remote team is <strong>regulation</strong>. Labor regulations are wildly different amongst countries, and could be cumbersome for some companies. Some major hurdles include:</p>
<ul>
<li>
<p><strong>Payroll taxes</strong>, retirement bonuses: Germany has rentenversicherung, sozialversicherung whereas USA has 401k contributions. Can a German company afford to <strong>setup payroll</strong> taxes for a remote workers hired from India, Chile or US? Or will it lead to worker abuse through <strong>laissez-faire abuse</strong> through freelance contracts?</p>
</li>
<li>
<p><strong>Notice periods</strong>: Europeans (on average) have 3 months notice period while US Americans have 2 weeks. How would a US company deal with it? On top of that, several countries have <strong>protection against unlawful termination</strong>, and how can a Slovakian employee avail that benefit against a German company?</p>
</li>
<li>
<p><strong>IP protection</strong>: It’s hard to <strong>protect IP</strong> if employees are not in the same jurisdiction. A company operation from Czechia would find it hard to settle trade disputes with a remote worker from South Africa. Another example is of <strong>TISAX compliance</strong> that is required for specialized hardware projects for Automotive industries. Remote work fails to make a dent in this situation.</p>
</li>
</ul>
<h2 id="hardware-cant-remote">Hardware can’t remote</h2>
<p>Patio11’s law<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> states that the <strong>economy is much bigger than you think</strong>. There are companies which have widely different business models and they often have a hardware related product. My <a href="https://www.salonlab-server.de/en-GB/">current project</a> is an IoT device that talks to an iPad app. The <strong>hardware team</strong> needs <strong>specialized tools</strong> to work on the IoT device, and these tools can’t be moved to home office. Remote work is a strict no-no for such products.</p>
<h2 id="swim-against-the-tide">Swim against the tide</h2>
<p>The biggest hurdle employees face in remote/home offices is <strong>lack of focus and direction</strong>. Humans have evolved over thousands of years to collaborate based on interpersonal cues, and a video call simply does not have the same effect. Humans need <strong>feedback</strong> and <strong>constructive communication</strong> whereas isolation kills the spirit. People who are new to remote work often feel <strong>rudderless</strong> because <strong>self discipline is hard</strong> when there’s no structure. I’m doing remote work on-and-off since 2018, and it took me a lot of discipline to get productive. The simple fact is that remote work is not natural, and not suited for all work streams in a typical company. Add to it the fact that many <strong>families</strong> simply don’t have space to work from home, and on top of that there might be kids around.</p>
<p>Remote work might be one of the few positive outcomes of the COVID-19 crisis but unless we tend to it carefully, we’ll end up creating a unhappy and unproductive workspace.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300">https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html">https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201">https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever">https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://secondbreakfast.co/patio11-s-law">https://secondbreakfast.co/patio11-s-law</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://samkhawase.com/blog/remote-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034037</guid>
            <pubDate>Mon, 09 Nov 2020 12:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD Router Guide]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25033925">thread link</a>) | @upofadown
<br/>
November 9, 2020 | https://www.unixsheikh.com/tutorials/openbsd-router-guide/ | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/tutorials/openbsd-router-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<table>
    <tbody><tr>
        <td><img src="https://www.unixsheikh.com/includes/img/openbsd-icon.png" alt="OpenBSD icon"></td>
        <td>
            
            <h4>Network segmenting firewall, DHCP, DNS with Unbound, domain blocking and much more<br>
                <span>OpenBSD: 6.8 · Published: 2020-11-05 · Updated: 2020-11-12 · Version: 1.4.1</span>
            </h4>
        </td>
    </tr>
</tbody></table>

<h2>Introduction</h2>

<div><p>In this guide we're going to take a look at how we can use cheap and "low end" hardware to build an amazing OpenBSD router with firewalling capabilities, segmented local area networks, DNS with domain blocking, DHCP and more.</p><p>We will use a setup in which the router segments the local area network (LAN) into three separate networks, one for the grown-ups in the house, one for the children, and one for public facing servers, such as a private web server or mail server. We will also look at how we can use DNS to block out ads, porn, and other websites on the Internet. The OpenBSD router can also be used on small to mid-size offices.</p></div>

<p>Table of contents</p>
<ul>
    <li><a href="#why-a-firewall">Why a firewall?</a></li>
    <li><a href="#the-hardware">The hardware</a></li>
    <li><a href="#why-openbsd">Why OpenBSD?</a></li>
    <li><a href="#the-network">The network</a>
    <ul>
        <li><a href="#setting-up-the-network">Setting up the network</a></li>
    </ul>
    </li>
    <li><a href="#dhcp">DHCP</a></li>
    <li><a href="#a-packet-filtering-firewall">PF - A packet filtering firewall</a>
    <ul>
        <li><a href="#pf-setup">PF setup</a></li>
        <li><a href="#clarifications">Clarifications</a></li>
        <li><a href="#pf-domain-name-resolution">Domain name or hostname resolution</a></li>
        <li><a href="#the-ruleset">The ruleset</a>
            <ul>
                <li><a href="#whitelist">The children's whitelist</a>
                    <ul>
                        <li><a href="#persistent-table">Using a persistent table</a></li>
                    </ul>
                </li>
            </ul>
        </li>
        <li><a href="#loading-ruleset">Loading the rules</a></li>
        <li><a href="#logging">Logging and monitoring</a></li>
    </ul>
    </li>
    <li><a href="#domain-name-service">DNS</a>
    <ul>
        <li><a href="#unbound">I present to you, Unbound</a></li>
        <li><a href="#blocking-with-dns">Blocking with DNS</a>
            <ul>
                <li><a href="#nxdomain">NXDOMAIN vs redirecting</a></li>
            </ul>
        </li>
        <li><a href="#doh">The problem with DNS over HTTPS (DoH)</a></li>
        <li><a href="#unbound-setup">Setting up Unbound</a>
            <ul>
                <li><a href="#basic-settings">Basic settings</a></li>
                <li><a href="#lets-block-some-domains">Let's block some domains!</a></li>
            </ul>
        </li>
        <li><a href="#dns-security">DNS security</a>
            <ul>
                <li><a href="#dns-hijacking">DNS hijacking</a>
                    <ul>
                        <li><a href="#dns-hijacking-prevention">DNS hijacking prevention</a></li>
                    </ul>
                </li>
                <li><a href="#dns-spoofing">DNS spoofing</a>
                    <ul>
                        <li><a href="#dns-spoofing-prevention">DNS spoofing prevention</a></li>
                    </ul>
                </li>
            </ul>
        </li>
    </ul>
    </li>
    <li><a href="#appendix">Appendix</a>
        <ul>
            <li><a href="#inspecting-doh">Inspecting DNS over HTTPS (DoH)</a></li>
            <li><a href="#blocking-doh">Blocking DNS over HTTPS (DoH)</a></li>
            <li><a href="#dhcp-domain">Adding the domain-name option to DHCP and using a FQDM</a></li>
            <li><a href="#recommended-reading">Recommended reading</a></li>
            <li><a href="#how-to-contribute">How to contribute to the guide?</a></li>
            <li><a href="#todo">TODO</a></li>
        </ul>
    </li>
</ul>

<h2 id="why-a-firewall">Why a firewall?</h2>
<p>Almost no matter how you connect to the Internet from your home or office, you need a real firewall between you and the modem or router that your ISP has provided you with.</p>
<p>Very rarely do consumer-grade modems or routers get firmware updates and they are often vulnerable to <a href="https://en.wikipedia.org/wiki/Home_router#Security">network attacks</a> that turns these devices into <a href="https://en.wikipedia.org/wiki/Botnet">botnets</a>, such like the <a href="https://en.wikipedia.org/wiki/Mirai_(malware)">Mirai malware</a>. Many consumer-grade modems and routers is to blame for some of the largest <a href="https://en.wikipedia.org/wiki/Distributed_denial_of_service_attack">distributed denial of service (DDoS) attacks</a>.</p>
<p>A firewall between you and your ISP modem or router cannot protect your modem or router device against attacks, but it can protect your computers and devices on the inside of the network, and it can help you monitor and control the traffic that comes and goes to and from your local network.</p>
<p>Without a firewall between your local network and the ISP modem or router you could basically consider this an open door policy, like leaving the door to your house wide open, because you cannot trust the equipment from your ISP.</p>
<p>It is always a really good idea to put a real firewall between your local network and the Internet, and with OpenBSD you get an very solid solution.</p>

<p><b>NOTE:</b><br>Currently this guide only deals with IPv4 as most people still don't use IPv6 and many ISPs also still only use IPv4, but IPv6 is planned for a future update of the guide.</p>

<h2 id="the-hardware">The hardware</h2>
<p>You don't have to buy expensive hardware to get an effective router and firewall for your house or office. Even with cheap and "low end" hardware you can get a very solid solution.</p>
<p>I have build multiple solutions with the <a href="https://www.asrock.com/mb/Intel/Q1900DC-ITX/">ASRock Q1900DC-ITX</a> motherboard that comes with an Intel Quad-Core Celeron processor.</p>
<p><img src="https://www.unixsheikh.com/includes/img/asrock-q1900dc-itx.png" alt="ASRock Q1900DC-ITX motherboard"></p>
<p>I'll admit, it's a pretty "crappy" motherboard, but it gets the job done and I have several builds that have run very solid for many years on gigabit networks with full saturation and the firewall, DNS, etc. working "overtime" and the CPU hardly breaks a sweat.</p>
<p>The ASRock Q1900DC-ITX motherboard has the advantage that it comes with a DC-In Jack that is compatible with a 9~19V power adapter, making it very power saving. Unfortunately the ASRock Q1900DC-ITX motherboard is no longer made, but I'm just using it as an example, I have used several other cheap boards as well.</p>
<p><b>NOTE:</b><br>Most of the current ASRock J-series can be used. Search for any J-series board on Amazon and a list will show up on recent hardware. Such as <a href="https://www.amazon.com/ASRock-Motherboard-Mini-DDR3-Q1900B-ITX/">ASRock Q1900B-ITX</a>, <a href="https://www.amazon.com/ASRock-J5005-ITX-Quad-Core-Processor-Motherboards/">ASRock J5005-ITX</a> and <a href="https://www.amazon.com/ASRock-Motherboard-CPU-Combo-J3355M/">ASRock J3335M</a> (These are not affiliate links!). Many other low power brands from other motherboard producers can be uses as well.</p>
<p>I have also used the ASRock Q1900-ITX (it doesn't come with the DC-In Jack) combined with a PicoPSU.</p>
<p><img src="https://www.unixsheikh.com/includes/img/picopsu.png" alt="PicoPSU power supply"></p>
<p>You can find different brands and versions of the PicoPSU, some are better quality than others. I have two different brands, the original and a cheaper knockoff, both performs very well and they save quite a bit of power contrary to running with a normal power supply.</p>
<p>Last, I am using a cheap Intel knockoff quad port NIC found on Ebay like this one:</p>
<p><img src="https://www.unixsheikh.com/includes/img/intel-quad-nic.png" alt="Intel Quad NIC"></p>
<p>I know it is better to use quality hardware, especially on a network that you care about, but this tutorial is about how you can get away with using fairly cheep hardware and still get an extremely useful product that will continue to serve you well for many years - at least that is my experience.</p>
<p>I recommend that you look for a low power mini ITX board with hardware <a href="https://www.openbsd.org/amd64.html">supported by OpenBSD</a>, such as an Intel Celeron or Intel i3 processor. These boards are typically cheap, less power hungry, and they don't take up much space. I don't recommend using the Intel Atom CPU if you have a gigabit network as they usually choke because they can't handle the amount of traffic, but your mileage may vary.</p>
<p>You might also need a couple of cheap gigabit switches for the segmented local network, at least if you have more than one computer you want to connect to the same LAN :)</p>

<h2 id="why-openbsd">Why OpenBSD?</h2>
<p>In truth, you can get a similar setup with one of the other <a href="https://en.wikipedia.org/wiki/Comparison_of_BSD_operating_systems">BSD flavors</a> or one of the many different <a href="https://en.wikipedia.org/wiki/Linux_distribution">Linux distribution</a>, but <a href="https://www.openbsd.org/">OpenBSD</a> is specifically very well suited and designed for this kind of task. Not only does it come with all the needed software in the base install, but it also has significantly better security and tons of improved mitigations already build-in into the operating system. I <a href="https://www.unixsheikh.com/articles/openbsd-is-fantastic.html">highly recommend</a> OpenBSD over any other operating system for this kind of task.</p>
<p>This guide is not going to show you how to install OpenBSD. If you haven't done that before I recommend you spin up some kind of virtual machine or see if you have some unused and supported hardware laying around you can play with. OpenBSD is one of the easiest and quickest operating systems to install. Don't be afraid of the non-gui approach, once you have tried it you will really appreciate the simplicity. Use the default settings when in doubt.</p>
<p>Before you endeavor on this journey make sure to reference the OpenBSD documentation! Not only is everything very well documented, but you will most likely find all the answers you need right there. Read the <a href="https://www.openbsd.org/faq/index.html">OpenBSD FAQ</a> and take a look at the different <a href="https://man.openbsd.org/">manual pages</a> for the software we're going to use.</p>
<p>Another really useful place to find general information about OpenBSD is the <a href="https://marc.info/?l=openbsd-misc">OpenBSD mailing list archives</a>. Also make sure to stay up to date with relevant information by subscribing to the <a href="https://www.openbsd.org/mail.html">Announcements and security advisories</a> mailing list.</p>
<p>Last, but not least, please consider <a href="https://www.openbsd.org/donations.html">supporting OpenBSD</a>! Even if you don't use OpenBSD on a daily basis, but perhaps make use of <a href="https://www.openssh.com/">OpenSSH</a> on Linux, then you're really using software from the OpenBSD project. Consider making a small, but steady donation to support the further development of all the great software the OpenBSD developers make!</p>

<h2 id="the-network">The network</h2>
<p>A router is basically a device that regulate network traffic between two or more separate networks. The router will ensure that network traffic intended for the local network doesn't run out into the wild on the Internet, and traffic on the Internet, that is not intended for your local network, stays on the Internet.</p>
<p><b>NOTE:</b><br>A router is sometimes also referred to as a gateway, which generally is alright, but in truth a real gateway joins dissimilar systems, while a router joins similar networks. An example of a gateway would be a device that joins a PC network with a telecommunications network.</p>
<p>In this tutorial we're building a router and we have 4 networks of the same type to work with. One is the Internet and the other three are the internally segmented local area networks (LANs). Some people prefer to work with virtual LANs, but in this tutorial we're going to use the quad port NIC from the illustration above. You can achieve the same result by using multiple one port NICs if you prefer that, you just have to make sure that you have enough room and free PCI slots on the motherboard. You can also use the Ethernet port on the motherboard itself, but it depends on the driver and support for the device. I have had no problems using the Realtek PCI gigabit Ethernet controller that normally comes with many motherboards even though I recommend Intel over Realtek.</p>
<p>Of course you don't have to segment the network into several parts if you don't need that, and it will be very easy to change the settings from this guide, but I have decided to use this approach in order to show you how you can protect your children by segmenting their network into a separate LAN that not only gets ad and porn blocking using DNS blocking (all the segments gets that), but you can even whitelist the parts of the Internet you want them to have access to. The last part about whitelisting is difficult and generally not recommended unless your children requires only very limited access, but it is doable with some work, and the guide is going to show you one way you can do that.</p>
<p>This is an illustration of the network we're going to setup:</p>
<pre><code>
                       Internet
                          |
                    xxx.xxx.xxx.xxx
                    ISP Modem (WAN)
                      10.24.0.23
                          |
                       OpenBSD
                      10.24.0.50
                  (router/firewall)
  …</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.unixsheikh.com/tutorials/openbsd-router-guide/">https://www.unixsheikh.com/tutorials/openbsd-router-guide/</a></em></p>]]>
            </description>
            <link>https://www.unixsheikh.com/tutorials/openbsd-router-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033925</guid>
            <pubDate>Mon, 09 Nov 2020 12:13:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-drawn animated tram ride (web experiment)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033545">thread link</a>) | @parisianka
<br/>
November 9, 2020 | https://alexanderperrin.com.au/paper/shorttrip/ | <a href="https://web.archive.org/web/*/https://alexanderperrin.com.au/paper/shorttrip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="credits">
<div>
<p>
<strong>Short Trip - Alexander Perrin, 2017</strong>
</p>
<p>Hold left or right to move.</p>
<p>Read more about the project
<a href="http://alexanderperrin.com.au/portfolio/short-trip/" target="_blank">here.</a>
</p>
<p>Thank you to
<a href="https://twitter.com/domwillmott" target="_blank">Dom Willmott</a> for
<br>audio support.</p>
<p>If you would like to support Short Trip, you're welcome (but not obliged) to make a contribution
<a href="https://paypal.me/alexanderperrin">here.</a>
</p>
<p>Quality Mode:
<span id="default-button">Default</span>
<span id="eco-button">Eco</span>
</p>
<p>Sound:
<span id="mute-off">On</span>
<span id="mute-on">Off</span>
</p>
</div>
</div></div>]]>
            </description>
            <link>https://alexanderperrin.com.au/paper/shorttrip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033545</guid>
            <pubDate>Mon, 09 Nov 2020 11:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The power of HTTP headers and examples]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25033398">thread link</a>) | @loweisz
<br/>
November 9, 2020 | https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/ | <a href="https://web.archive.org/web/*/https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Almost everything in the web is sent with <strong>http</strong> and even non-developers have seen it when using the internet as keyword
inside urls or links.</p>
<p>Http stands for <strong>Hypertext Transfer Protocol</strong> and gives us the ability to transfer hypertext between a browser and a server.
This is a great technology that has been around almost since the invention of the web and is constantly evolving and
<a href="https://en.wikipedia.org/wiki/HTTP/2">offering more and more great features</a></p>

<p>As a developer you probably heard of http headers, at least in the moment you heard about the CORS policy.
This is a problem you must have heard about when developing websites.
But what exactly are http headers and what other ways are there to use them?</p>
<p>Let us first find out what they do and how you could use them. </p>
<p>When a browser requests a resource, for example a page of this blog, it asks the server with a request.
This request looks something like this: </p>
<div data-language="js"><pre><code><span>fetch</span><span>(</span><span>"https://www.lorenzweiss.de/race_conditions_explained/"</span><span>,</span> <span>{</span>
  credentials<span>:</span> <span>"include"</span><span>,</span>
  headers<span>:</span> <span>{</span>
    accept<span>:</span>
      <span>"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3"</span><span>,</span>
    <span>"accept-language"</span><span>:</span> <span>"en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7"</span><span>,</span>
    <span>"cache-control"</span><span>:</span> <span>"max-age=0"</span><span>,</span>
    <span>"sec-fetch-mode"</span><span>:</span> <span>"navigate"</span><span>,</span>
    <span>"sec-fetch-site"</span><span>:</span> <span>"same-origin"</span><span>,</span>
    <span>"sec-fetch-user"</span><span>:</span> <span>"?1"</span><span>,</span>
    <span>"upgrade-insecure-requests"</span><span>:</span> <span>"1"</span><span>,</span>
  <span>}</span><span>,</span>
  referrerPolicy<span>:</span> <span>"no-referrer-when-downgrade"</span><span>,</span>
  body<span>:</span> <span>null</span><span>,</span>
  method<span>:</span> <span>"GET"</span><span>,</span>
  mode<span>:</span> <span>"cors"</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>So you can see the URL or location of the resource, some information about the request and also a lot of headers with some information about the request.
This is how your browser tells the server some more information about the request. For example what kind of data type it accepts or
how the client is handling the cache.</p>
<p>After sending the request, the server replies, and it also sets some headers in the reply, which could look like this: </p>
<div data-language="text"><pre><code>:authority: www.lorenzweiss.de
:method: GET
:path: /race_conditions_explained/
:scheme: https
accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
accept-encoding: gzip, deflate, br
accept-language: en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7
cache-control: max-age=0
cookie: _ga=GA1.2.1173972759.1584812492; _gid=GA1.2.2076192721.1594044231
sec-fetch-mode: navigate
sec-fetch-site: same-origin
sec-fetch-user: ?1
upgrade-insecure-requests: 1
user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36</code></pre></div>
<p>There is also some information that the server wants to tell the browser what to do with the resource, for example
if there are cookies, it must be determined which encoding was used, etc</p>
<p>Basically, in the http-context the headers for the communication of the browser and the server are used to extend the simple
Requests for resources. You could see it as the sheet of paper that is added on top of a package that you oder from an online store,
giving you more information about the context and the resource that you ordered.
Most of the headers have quite good defaults which you don't need to think of, but there are some headers that
can get quite important, like CORS headers. But there are so much more headers that you might never heard of which are very useful
and good to know how to use. </p>

<p>Do not worry, this article will not deal with CORS headers. The following http headers are those that are rarely used, but
can be really powerful and helpful to significantly improve the communication between a server and the browser. </p>
<p>So let's dig into it. Here are some headers that you can set and that are very useful and practical.</p>
<h2 id="if-range"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/If-Range">If-Range</a><a href="#if-range" aria-label="if range permalink"></a></h2>
<h3>What and why?</h3>
<p>Imagine you start downloading a large resource, such as a video, an image, etc., and stop in between because of connection problems.
With <code>If-Range</code> you can tell the server if the representation is unchanged, to send the part(s) that are requested in Range.
Which means only the parts that were missing and not again the whole thing.</p>
<p>This can be very helpful when dealing with large resources and often bad connections as with mobile devices.
Because the resource can be downloaded in parts even if the connection is interrupted in between. </p>
<h4>How to use</h4>
<p>It can either be used with a date when the resources were last modified, or with an <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">ETag</a>, which is a key to help if the resources was invalidated</p>
<div data-language="text"><pre><code>If-Range: &lt;day-name&gt;, &lt;day&gt; &lt;month&gt; &lt;year&gt; &lt;hour&gt;:&lt;minute&gt;:&lt;second&gt; GMT
If-Range: &lt;etag&gt;</code></pre></div>
<h4>Example</h4>
<div data-language="text"><pre><code>If-Range: Wed, 21 Oct 2015 07:28:00 GMT </code></pre></div>
<h2 id="vary"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Vary">Vary</a><a href="#vary" aria-label="vary permalink"></a></h2>
<p><code>Vary</code> Comes from a time when the web or http was used for a variety of things and not just for web pages.<br>
It is based on the idea of using http to exchange information in many different formats.
How does it do that? Well, it tells the server in which header to find the information, how to present the information. </p>
<p>Nowadays it can be really helpful if you have different resources for different customers, for example
mobile, tablet or desktop.
Imagine three different images for the same resource are stored on the server, depending on the device.
Then you can simply use the <code>Vary</code> header to tell the server to check the device and then decide which image size to send. </p>
<h4>Example</h4>
<p>For the example with the device dependent images, you can simply pass the 'user agent' to tell the server
that it should check the user-agent for device information. </p>

<h4>How to use</h4>

<p>Just enter the header, the server must check before deciding which resource to send.</p>
<h2 id="content-disposition"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Content-Disposition">Content-Disposition</a><a href="#content-disposition" aria-label="content disposition permalink"></a></h2>
<p>If we go back to the example of a request to a server, for example to load this website, it is clear to the browser,
that it must <strong>display</strong> the resource of the answer.
But it can also be the case that the server sends a resource that the browser should automatically download to the user's computer,
like a picture or pdf etc.
A server can tell the browser what the browser should do with the attached resource via the <code>Content Disposition</code> header.</p>
<h4>Example</h4>
<p>With defining the <code>Content-disposition</code> to <code>attachment</code> the browser knows that this is a resource to download instead of just
show. </p>
<div data-language="text"><pre><code>Content-Disposition: attachment; filename="data.pdf"</code></pre></div>
<h4>How to use</h4>
<p>You can define the header as <code>inline</code> or <code>attachment</code>, where `inline is always the default.  </p>
<div data-language="text"><pre><code>Content-Disposition: &lt;inline | attachment&gt;</code></pre></div>
<h2 id="feature-policy"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy">Feature-Policy</a><a href="#feature-policy" aria-label="feature policy permalink"></a></h2>
<p>This is a fairly new header and therefore only supported by modern browsers (sorry to all IE users). However
I want to mention this anyway because I think it can be really helpful for some use cases.<br>
Basically, the <code>feature-policy tells the browser which features or apis the browser should provide to the document and its</code>iframes` to be used. </p>
<p>For example, it can ban all scripts or iframes etc. within this website to allow sensitive apis like the camera or microphone.</p>
<h4>How to use</h4>
<div data-language="text"><pre><code>Feature-Policy: &lt;directive&gt; &lt;allowlist&gt;</code></pre></div>
<p>The <code>directive</code> is the name of the feature. You can see the full <a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy#Directives">list of features here</a>
The <code>allowlist</code> defines the origins which are allowed to use the directive.</p>
<h3>Example</h3>
<p>Suppose we want our website to use neither the microphone nor the camera. With this header the
document or a contained iframe cannot access these functions.</p>
<div data-language="text"><pre><code>Feature-Policy: microphone 'none'; camera 'none'</code></pre></div>
<h3>More Headers:</h3>
<p>Here are some more headers that are worth mentioning: </p>
<ul>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Upgrade-Insecure-Requests">Upgrade-Insecure-Requests</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Age">Age</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Trailer">Trailer</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Location">Location</a></li>
</ul>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="conclusion permalink"></a></h2>
<p>Https headers are great and also very useful! But sometimes they can be quite complex, and it's really hard to get an overview of what headers are available and what benefits they bring.
Also when developing a website, especially in the frontend, you don't come in contact with them too often, except maybe with the CORS headers.
But I think that this missed some possibilities. http headers represent the communication between the server and the
customers much better, and we all know that communication is the key to a good relationship.</p>
<p>I hope I could shed some light on the darkness of http headers for you. In case I missed a good and helpful header,
please do not hesitate to send me a mail or contact me in any way.</p></div></div>]]>
            </description>
            <link>https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033398</guid>
            <pubDate>Mon, 09 Nov 2020 10:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Days in Desktop Web Browsers]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25033290">thread link</a>) | @svenfaw
<br/>
November 9, 2020 | https://www.radsix.com/dashboard1/ | <a href="https://web.archive.org/web/*/https://www.radsix.com/dashboard1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.radsix.com/dashboard1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033290</guid>
            <pubDate>Mon, 09 Nov 2020 10:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust Is the Future of Game Development]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25033247">thread link</a>) | @TheFuntastic
<br/>
November 9, 2020 | https://thefuntastic.com/blog/why-rust-is-the-future-game-dev | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/why-rust-is-the-future-game-dev">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-2ae295f5=""><p><em>Rust, not related to the video game also called Rust, is a promising systems programming language with novel features ideally suited for game development. Exposure and awareness within the game developer community, however, remains limited. In this post, I provide a gentle introduction to Rust and attempt to justify its place on your radar.</em></p>
<h2 id="a-short-history-lesson">A Short History Lesson</h2>
<p>What is Rust, and where did it come from? In <a href="https://www.youtube.com/watch?v=HiWkMFE8uRE" target="_blank" rel="nofollow noopener noreferrer">this fantastic talk</a>, James Munns gives us a detailed oral history. Way back around 2010, Mozilla was frustrated by the state of development in Firefox, a massive software project  written mostly in C++. Despite best practices and an abundance of engineering talent, writing high-performance, parallelised, and memory-safe code, at that scale of complexity, remained fraught and error-prone.</p>
<p>Bear in mind, this predates the advent of C++11 (aka the 2011 edition) which heralded efforts to somewhat modernise the language. Even so, manual memory manipulation is easy to get wrong, and <a href="https://msrc-blog.microsoft.com/2019/07/18/we-need-a-safer-systems-programming-language/" target="_blank" rel="nofollow noopener noreferrer">research</a> from <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/" target="_blank" rel="nofollow noopener noreferrer">multiple vendors</a> describes this category of error as responsible for 70% of security vulnerabilities. </p>
<p>Into this context steps Graydon Hoare, a Mozilla employee, introducing <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)#History" target="_blank" rel="nofollow noopener noreferrer">a potential solution</a> to the roadblock: Rust, the hobby language he'd been tinkering with since 2006. In 2012, Mozilla would formally announce Servo, an experimental research project to re-imagine a browser engine built with memory safety and concurrency as first principles. And alongside it, Rust, the companion language to make it all possible.</p>
<p>These early days of Rust are described as a Cambrian explosion of ideas and wild experimentation. Concepts were liberally stolen from other languages, from C++ to OCaml, Haskell, Erlang, ML, C#, Ruby and more, reflecting the diverse pool of engineers working on the language at the time. Still, most in the industry, while admiring the optimism in taking such an ambitious moon shot, <a href="http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/" target="_blank" rel="nofollow noopener noreferrer">remained pessimistic</a> about the prospects of success. </p>
<p>2015 saw a major milestone, with the release of Rust v1.0. Perhaps as significant as the feature list, was the number of failed experiments left behind on the cutting room floor, the team unafraid to pare down the language to its quintessential elements. This was also the first time stability guarantees would be offered, a quality notoriously absent before. </p>
<p>Soon after, in 2016, Firefox <a href="https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/" target="_blank" rel="nofollow noopener noreferrer">shipped its first production Rust code</a>. The industry and community started to take notice, and Rust began its impressive, and as yet unbroken, <del>four</del> <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank" rel="nofollow noopener noreferrer">five year streak</a> as Stack Overflow's most beloved language. [<em>Thank you James Munns for pointing out it's now actually five years</em>]. </p>
<p>Right from the outset, Rust set out with a clear focus on   building an inclusive community. They, in turn, have contributed to Rust's impressive technical aptitude, but have also fostered a sense of reverence and fondness not often witnessed in other languages. Are they crazy zealots or onto something?</p>
<h2 id="why-rust">Why Rust?</h2>
<blockquote>
<p><em>The performance of C++ with the convenience of C#</em></p>
</blockquote>
<p>This was the first time Rust hijacked my attention. C++ enjoys a long-standing ubiquity, in part, due to its ability to express zero cost abstractions. As explained by Bjarne Stroustrup, the creator of C++:</p>
<blockquote>
<p><em>What you don't use, you don't pay for. And further: What you do use, you couldn't hand code any better.</em></p>
</blockquote>
<p>It's easy to spot the relevancy to games. Making frame-rate while simulating entire worlds is a daunting performance challenge. Indeed, C++ underpins the bulk of game engines. There simply is <a href="https://www.youtube.com/watch?v=ltCgzYcpFUI" target="_blank" rel="nofollow noopener noreferrer">no other industrial language</a> that offers the same speed and low-level control, whilst writing programs in the large. </p>
<p>C++, however, suffers from the weight of its legacy. The accumulation of features over 40 years makes for a complex and intricate language. In the last decade modernisation of the standard has done well to uplift it from its C roots, but the experienced programmer must build up an arcane lore of which features are blessed, and which machinery is dangerous. As Stroustrup again describes:  </p>
<blockquote>
<p>Within C++, there is a much smaller and cleaner language struggling to get out.   </p>
</blockquote>
<p>This makes the language daunting and difficult to approach for beginners. In <a href="https://boats.gitlab.io/blog/post/zero-cost-abstractions/" target="_blank" rel="nofollow noopener noreferrer">this blog post</a>, Rust contributor <em>withoutboats</em> defines an import quality about abstraction:  </p>
<blockquote>
<p>A zero cost abstraction, like all abstractions, must actually offer a better experience than the alternative.</p>
</blockquote>
<p>So yes, of course, C++ offers a better time than your own hand wrought assembly. However, this is making the subtle point that it's competing against a secondary force: a more expensive abstraction that justifies its cost by being more comfortable and convenient.</p>
<p>We see this writ large in the rise of popular game engines that eschew the complexity of C++, the most notable being Unity. End users write code in C#, a more forgiving and ergonomic language, creating a boon in developer productivity and a reduction in iteration time.  </p>
<p><img src="https://thefuntastic.com/blog/2020-10-Unity-Interest.png" title="Unity interest over time in search trends"></p>
<p>In large codebases though, near the edge of the performance envelope, this trade-off begins to bite. The garbage collector eliminates an entire category of errors by removing responsibility for memory management from the end-user. However as its workload grows, so do periodic performance spikes antithetical to smooth gameplay.  </p>
<p><img src="https://thefuntastic.com/blog/2020-11-GC-spikes.png" title="Unity interest over time in search trends"></p>
<p>The experienced developer can still create a performant experience, however, this demands plugging the leaks in the abstraction. They must build a mental model of the machinery behind the curtain, a collection of arcane wisdom that bans many of the original conveniences, lest they disturb the garbage collector. </p>
<p>So development teams face a choice. Better resourced AAA studios generally choose Unreal or in-house engine tech built on C++, able to absorb the overhead for long term gain. Less resourced studios optimise for time to market, choosing Unity, or one of the many other accessible game making tools (Godot, Haxe, Game Maker, etc.). They often postpone performance concerns until after business eligibility is secured.   </p>
<p>Rust, however, for the first time, promises a third way. A world where it's possible to write zero cost abstractions without sacrificing higher-order elegance. </p>
<h3 id="ownership-based-memory">Ownership based memory</h3>
<p>To understand Rust's special sauce, we're going have to talk about ownership and how it handles memory. This is only a simple sketch, but <a href="http://intorust.com/tutorial/ownership/" target="_blank" rel="nofollow noopener noreferrer">in-depth resources</a> exist for the curious. </p>
<p>Writing optimised code is often about taking the way we, as humans, naturally think of an idea or algorithm, and instead expressing it in terms that favour the computer. This act often harms the legibility and understanding of a program, which makes it much harder for us, the humans, to reason about its correctness. </p>
<p>In a manually managed language, like C, the hapless programmer is left responsible for the machinations of the machine. They must take great care to ensure data is appropriately loaded into memory before operation, and then responsibly disposed of afterwards. A difficult dance in which missteps either cause dramatic crashes or else subtle and hard to detect vulnerabilities. But these are the very same tools that allow careful users to tune performance.  </p>
<p>At the other end of the spectrum, garbage collection promises the programmer it will automatically deal with the problem on their behalf. They are now free to express code naturally, but in doing so, it ties hands behind their back. They no longer have, at least not without indirection, the levers needed to wring out maximal performance.</p>
<p>Rust begins from a different premise. Rather than hiding this complexity, it accepts that computers are hard for humans, and instead tries to save us from the dangerous bits. Users can still tune the machine, but with less rope to wrap around their necks. </p>
<p>In the same way that static typing exists, very clever people have figured out how to make the compiler eliminate a whole category of memory and concurrency errors. To achieve this, Rust makes a bargain with the developer: </p>
<blockquote>
<p>"I'm going to keep track of the lifetime of every piece of memory in your program for you. This way, I can detect the moment you're no longer using it and safely free it on your behalf. But in return, I'm going to need you to follow <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html" target="_blank" rel="nofollow noopener noreferrer">strict rules</a> about the ownership of that memory. If you try to use it outside of the scope that owns it, my humourless friend here, the borrow checker, is going to make sure you don't hurt yourself."</p>
</blockquote>
<p>However, like static typing, this lunch isn't free. Rust is known to have a steep learning curve, "fighting the borrow checker" becomes a right of passage. It takes time to learn this new paradigm. Ownership makes some familiar patterns difficult or impossible and demands new ones be learnt in their place. Perhaps we should revise our earlier statement as: "The performance of C++ with the <del>convenience</del> safety of C#"</p>
<h2 id="unpacking-rusts-popularity">Unpacking Rust's Popularity</h2>
<p>Early adopters have a selfish reason to extol the virtues of their chosen technology, as widespread adoption enhances the return on their risky investment. In this respect, while interest is high but opportunities for real-world exposure are limited, is it possible that Rust is cresting a wave of unearned hype? <a href="https://matklad.github.io/2020/09/20/why-not-rust.html" target="_blank" rel="nofollow noopener noreferrer">Not every javascript or python developer</a> interested in the language, for example, has a use case that merits the additional complexity.</p>
<p>To a developer standing on the shores of 2010, <code>git</code>, a new version control system with a steep learning curve, may have seemed like a risky investment. But, in the ensuing world of Github, it's hard to argue the effort was wasted, even if some workloads (i.e. large games) still require alternatives.</p>
<p>In a similar vein, how can we qualify Rust's popularity as a meaningful signal? Ultimately, we will only know by the volume of mud we've dug through in the trenches, and admittedly, it is far too early to collect this data for games. </p>
<p>In other industries, though, early reports of Rust are effusive. <a href="https://medium.com/the-innovation/how-microsoft-is-adopting-rust-e0f8816566ba" target="_blank" rel="nofollow noopener noreferrer">Mircosoft</a>, <a href="https://developers.libra.org/docs/community/coding-guidelines" target="_blank" rel="nofollow noopener noreferrer">Facebook</a>, <a href="https://aws.amazon.com/blogs/opensource/aws-sponsorship-of-the-rust-project/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>, <a href="https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/" target="_blank" rel="nofollow noopener noreferrer">Dropbox</a>, <a href="https://blog.cloudflare.com/tag/rust/" target="_blank" rel="nofollow noopener noreferrer">Cloudflare</a> all have Rust deployed in production. The <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Rust-Path-LPC2020" target="_blank" rel="nofollow noopener noreferrer">Linux Kernel</a> and <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability" target="_blank" rel="nofollow noopener noreferrer">Chrom…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/why-rust-is-the-future-game-dev">https://thefuntastic.com/blog/why-rust-is-the-future-game-dev</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/why-rust-is-the-future-game-dev</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033247</guid>
            <pubDate>Mon, 09 Nov 2020 10:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Think Piece on Privacy and Big Data]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033030">thread link</a>) | @Rohitha_Perera
<br/>
November 9, 2020 | https://talk.hyvor.com/blog/privacy-and-big-data/ | <a href="https://web.archive.org/web/*/https://talk.hyvor.com/blog/privacy-and-big-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span></span>
<span>117</span>
</p>
<p>The majority of us in the present and in the immediate future <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">will face the issue of Privacy</a>. Consider this basic thought, which may sound like science fiction, but is actually quite present today: Thanks to the devices we wear now, <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">the harvesting of our biometric data</a> is a possibility. It is this thought process that led to this think piece on privacy and big data.</p>
<p>Corporations can get to know us far better than we know ourselves. They can then not just predict our feelings but also manipulate our feelings. Monitoring of our biometrics can make episodes like that of Cambridge Analytica’s data hacks prehistoric in comparison. </p>
<p>Remember that <a href="https://www.cheatsheet.com/money-career/heres-much-google-facebook-really-think-youre-worth.html/">you are worth quite a bit of money to the social channels </a>you use. The podcast detailing the <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9IY09mTE41Mg&amp;ep=14&amp;episode=MjM0YjM1OTgtZTQ1Mi00NGZhLTkzYjUtMTQxMGJjZTY1NGE4">Congressional Antitrust Investigation on Tech Monopolies: Google, Facebook, Amazon, and Apple</a> gives a serious look at how powerful these big data companies are. The scale is astronomical. Amazon captures 70% of all retails in the United States. They literally have seven times the revenue of their next largest competitor. </p>
<p>Now imagine their cloud computing capabilities. Take stock of the number of iPhones that are there. We know that what you share on social media, and the information that you surrender is a Big Data Issue; and, consider the number of search results Google controls. There’s information about you being harvested. You should know how your information is being used. </p>
<h2>Some Background</h2>
<p>We hear of how <a href="https://www.theguardian.com/us-news/2018/mar/22/steve-bannon-on-cambridge-analytica-facebook-data-is-for-sale-all-over-the-world">Steve Bannon used Facebook</a> to change politics and change culture. Facebook data, algorithms and narratives were his key weapons. These tools were used by the <a href="https://www.reuters.com/article/us-facebook-cambridge-analytica-kogan-idUSKBN1GX2F6">Cambridge Analytica team to identify the dark triad</a> — Narcissism, Machiavellianism and Psychopathy — in people. We now know about the Russian interference in American politics. We know how data had been manipulated to channel the latent proclivities of racism and anti-Semitism within America to divide it. </p>
<p>The same podcast makes mention of a great knowledge-infused book, which is Shoshana Zuboff’s <a href="https://youtu.be/QL4bz3QXWEo">The Age of Surveillance Capitalism</a>. In this book, Zuboff details the rise of a new form of power which will forever change our lives. By collecting behavioral data from their users, corporations have amassed an incomprehensibly large and detailed picture of our personal lives. They use this data to expand their corporate power and profitability. This, of course, has tremendous consequences for our privacy, but also for our political system.</p>
<figure><img src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" alt="" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Surveillance Capitalism talks of <a href="https://www.simplypsychology.org/big-five-personality.html">The Five Factor Personality Test</a>, which helps companies like Facebook infer our political proclivities and sexuality. This is based on the predictive signals based on the punctuation we use on a Facebook status. </figcaption></figure>
<p>Surveillance Capitalism is where it universally claims our private human experience as their free source of raw material. They take the rich predictive signals in our behavior and convert it into data. We hear of <a href="https://arstechnica.com/information-technology/2017/05/facebook-helped-advertisers-target-teens-who-feel-worthless/#:~:text=Leaked%202017%20document%20reveals%20FB,exploit%20teens'%20words%2C%20images.&amp;text=Facebook's%20secretive%20advertising%20practices%20became,of%20the%20company's%20Australian%20office.">Facebook executives who promote&nbsp;advertising campaigns that exploit Facebook users’ emotional states</a>. Facebook’s algorithms can determine, and&nbsp;allow&nbsp;advertisers to pinpoint, “moments when young people need a confidence boost.”&nbsp;97% of Facebook’s revenue comes from its online targeted advertising markets. These are wholly-owned and operated in this surveillance capitalist economic logic. </p>
<p>Readers of Cathy O’Neil’s Weapons of Math Destruction will be compelled to believe the potential dangers of big data. O’Neil, a mathematician, analyses how the use of big data and algorithms in a variety of fields. These include insurance, advertising, education, and policing. They can lead to decisions that harm the poor, reinforce racism, and amplify inequality. Mathematicians and statisticians were for a very long time studying our desires, movements, and spending power. This is the Big Data economy we are living in. </p>
<h2>Trust is Important </h2>
<p>Consumers are more conscious of their data privacy than ever. A recent <a href="https://tealium.com/resource/whitepaper/how-brands-can-prioritize-privacy-in-the-age-of-data/">Tealium study</a> on consumer data privacy found that 97% of consumers surveyed said they are somewhat or very concerned about protecting their data. <a href="https://www.accenture.com/t20171220T024439Z__w__/us-en/_acnmedia/PDF-68/Accenture-Global-Anthem-POV.pdf#zoom=50">Research by Accenture</a>&nbsp;shows that&nbsp;88% of<strong> </strong>consumers say companies that provide personalized experiences without compromising their trust are more appealing and can relate to their needs better than others.</p>
<p>We are focusing on Facebook on this particular blog post to quite a degree since it is the one singular social medium that is growing exponentially. One of the ways in which Facebook garners your data is with you revealing your data and your intentions via the act of publishing status updates and even commenting. You see, the act of commenting fulfills just one touchpoint in the process of these tech giants harvesting of data. Facebook built&nbsp;<a rel="noreferrer noopener" href="https://developers.facebook.com/docs/plugins/comments/" target="_blank">comments plugin</a>&nbsp;to allow users to leave comments on websites, blogs and forums through their Facebook accounts. It was expected to provide high-quality conversations over the internet but instead ended up spamming popular sites.</p>
<p>If you do use the Facebook Comments plugin, remember that your comments are a valuable content asset that shouldn’t be subject to <a href="https://ducttapemarketing.com/how-and-why-i-use-the-facebook-comments-plugin/">Facebook’s Terms of Service</a>, which basically says they can do whatever they want with them. An increasing amount of spam raises questions about how well the policy of malicious content online is going on. There are many misleading and offensive comments, usually attracting and persuading users towards a specific link to click it. These comments are often repetitive and can easily be identified as spam.</p>
<p>According to an estimation by&nbsp;<a href="https://www.similartech.com/technologies/facebook-comments">Similartech</a>&nbsp;more than 360,000 unique domains have installed Facebook Comments plugin. It is still not clear why and how the spam filters of Facebook failed to filter spam comments. <a href="https://www.similartech.com/technologies/facebook-comments">In 2015</a>, one of the security firms, Symantec reported scammers had been trying to affect the comments sections of Facebook to spread malware. </p>
<p>For more than two years now, Facebook has been working on its content-moderation efforts and the spamming in Facebook Comment boxes shows that problematic content still finds its way to escape the loopholes. Moreover, <a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">Facebook can track what </a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?usqp=mq331AQFKAGwASA%3D&amp;amp_js_v=0.1#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">you</a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html"> type</a>, even if you never post it.&nbsp;Data scientists can determine that a status or comment has been typed by tracking code in the HTML form element of each page.</p>
<h2>Read The Terms and Conditions</h2>
<p>We live in a world where the concept of privacy already seems outdated. But that is largely because we’ve decided not to inquire about what happens when we trade it for convenience. The more connected you, and billions of others, are to Facebook, the more money Facebook makes by selling your personal information, and the more powerful it becomes.</p>
<p>The terms of service state,&nbsp;<em>We use the data we have — for example, about the connections you make, the choices and settings you select, and what you share and do on and off our Products — to personalize your experience.</em></p>
<figure><img loading="lazy" width="746" height="634" src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" alt="" srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" sizes="(max-width: 746px) 100vw, 746px" data-srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><a href="https://qz.com/1266835/facebooks-terms-of-service-translated-so-you-understand-your-data-and-privacy-settings/">Be wary of nebulous terms and promises</a></figcaption></figure>
<p>Basically, this means that Facebook uses every bit of personal information it can, collected&nbsp;<a href="https://www.consumerreports.org/privacy/how-facebook-tracks-you-even-when-youre-not-on-facebook/">both on and off Facebook</a>, to entice advertisers. The better the company knows you through the personal information you share with your friends and family, the more likely they are to be able to sell you stuff you want.</p>
<h2>Choose The Right to Privacy</h2>
<p>Big data is big business and value is created from customer insight. But, where is the moral line? What happens when companies cross that line? What if consumers could flip the equation to offer their data directly to the companies they trust? The future could be customer-monetized data.</p>
<p>We are the authors of our own destruction here since we don’t choose to be aware. If you participate in Facebook, should you not have some semblance of an expectation of privacy. The former Federal Trade Commission Chairperson Jon Leibowitz publicly stated, “We all agree that consumers don’t read privacy policies.”</p>
<p><a href="https://talk.hyvor.com/docs/gdpr">Ensure you choose privacy</a> and are aware of how technology plans on using your data. The only solution is being non-participatory. The solution is choosing not to be part of a pernicious agenda that can be defined as Surveillance Capitalism. </p>
<div><div><div><h4>
Need a privacy-focused commenting platform for your website?
</h4>

</div></div></div> </div></div>]]>
            </description>
            <link>https://talk.hyvor.com/blog/privacy-and-big-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033030</guid>
            <pubDate>Mon, 09 Nov 2020 09:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul: Towards 1.0]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 107 (<a href="https://news.ycombinator.com/item?id=25032956">thread link</a>) | @lelf
<br/>
November 9, 2020 | https://pijul.org/posts/2020-11-07-towards-1.0/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2020-11-07-towards-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
                We are looking for <strong>VC funding</strong>. If you are interested in helping us build the future of collaboration (for code and other documents), shoot us an email at <a href="mailto:contact@pijul.org">contact@pijul.org</a>.
                
            </p>


<p>Saturday, November 7, 2020</p>
<p>After fixing the performance and scalability problems, we’re on our way to getting a stable Pijul. In this post, I explain what I’ve been up to in the recent months.</p>
<h2 id="context">Context</h2>
<p>Pijul has always been advertised as a research project, trying to implement a theory of patches that would be sound and fast. This is an ambitious goal, and became even more ambitious than initially envisioned.</p>
<p>One of the hardest challenges is that source code is by essence stateful, which makes it much harder to iterate over algorithm designs, like normal research projecst need to. For example, in order to get from our last published version to our current design, we have gone through many different variants, and there wasn’t much to publish.</p>
<p>Moreover, the UX aspect is what matters most in the end, and testing it on a real world project is the only way to get it there. However, unlike in a compiler, where bootstrapping is done one step at a time, and previous versions are always available to compile your current one, a version control system has the additional problem that the previous versions might not always be easily accessible if there is a bug.</p>
<p>One of the criticisms I’ve heard since I realised that better datastructures were possible is that I was “working secretely”. I certainly understand this feeling, but this is based on a misunderstanding of how research works. When I first had the idea that I’m explaining in this post, I realised that a complete rewrite would be needed. But for a very long time, almost nothing other than unusable, unreadable prototypes happened.</p>
<p>Back then, there wasn’t much to show, since it wasn’t even clear that the basic datastructure would work. And even when they started working at a large enough scale, it took me quite a bit of testing on large repositories before they started actually working.</p>
<p>This also implies that there wasn’t much to show for quite a while, since the new algorithm wasn’t usable until very recently, and any repository started before now would have become obsolete in a matter of days.</p>
<p>There were also <a href="#a-personal-note">persoprofessional reasons</a> for this silence, described at the end of this post.</p>

<p>Pijul depends on two other projects I’ve started.</p>
<h3 id="sanakirja">Sanakirja</h3>
<p>One of these projects is Sanakirja, which is “just” a key-value store, but has the extra feature that databases can be cloned efficiently. I would have loved to just use an existing library, but there just isn’t any that has this cloning feature. However, the scope of Sanakirja is still quite modest, it does one thing and does it well. Obviously, it took some time to find the memory-management bugs, but I have good confidence that this is now done.</p>
<p>In previous releases of Pijul, databases were implemented with a single mmapped file containing the binary representation of B Trees. Despite their lower writing performance (compared to alternatives such as <em>Log-structured merge-trees</em>), and the complexity of the code for deletions, B Trees are very well suited to this use case: indeed, since they are trees, reference-counting the nodes is enough to implement efficient clones.</p>
<p>One of the remaining issues was that in order to grow the database, we needed to un-mmapped the file, grow it, and mmap it again. Since applying a single change in Pijul must be an atomic operation, we needed to cancel the transaction when that happened, and restart it with a bigger file.</p>
<p>Another issue is that I wanted the next libpijul to compile on platforms that don’t have mmap, such as WASM. However, if reallocating an mmapped file has a very low complexity (even though it does have a non-zero cost in terms of system calls), reallocating a chunk of memory often requires copying everything. This completely defeats the point of the algorithms in Pijul, which rely on a particular representation of the datastructures on the disk.</p>
<p>The main innovation in Sanakirja 0.13 is to use a vector of memory blocks (either in memory or mmapped from a file), of exponentially-increasing size. The overhead is just one extra indirection, the complexity of adding items is the same (since the operation of creating an extra block is $O(1)$). The exponentially-increasing sizes mean that the allocated memory is always at least half-full.</p>
<h3 id="thrussh">Thrussh</h3>
<p>The other one is Thrussh. That library implements the SSH protocol, and tries to handle a number of key formats. The former is a surprisingly easy goal, and keeping up with Tokio versions has historically been the hardest bit, while the latter is the most horrendous hydra-like task, with new heads and legacy formats showing up every time you think you’re done.</p>
<h2 id="how-repositories-used-to-work-and-still-do-to-some-extent">How repositories used to work (and still do, to some extent)</h2>
<p>Old-style repositories represented a single file by a directed graph $G = (V, E)$ of lines, where each vertex $v\in V$ represented a line, and an edge from $u \in V$ to $v\in V$, labelled by some change (also called patch) number $c$, could be read as “according to change $c$, line $u$ comes before $v$”.</p>
<p>This means that changes could introduce vertices and lines, as in the following example, where a line $D$ is introduced between $A$ and $B$:</p>
<p><img src="https://pijul.org/img/repos-line-add.svg">
</p>
<p>Here, the thick line represents the change from the file containing the lines $A$, $B$, $C$ to the file with the new line $D$.
An important feature to note is that <strong>vertices are uniquely identified</strong>, by the hash of the change that introduced them, along with a position in that change. This means that two lines with the same content, introduced by different changes, will be different. It also means that a lines keeps its identity, even if the change is applied in a totally different context.</p>
<p>Moreover, this system is append-only, in the sense that <em>deletions</em> are handled by a more sophisticated labelling of the edges. In the example above, if we want to delete line $D$, we just need to make a change mapping the edge introduced by $c_0$ to a deleted edge, which we label by the name $c_1$ of the change that introduces it:</p>
<p><img src="https://pijul.org/img/repos-line-del.svg">
</p>
<p>From now on, we call the full edges <strong>alive</strong>, and the dashed ones <strong>dead</strong>.</p>
<p>We have just described the two basic kinds of actions in Pijul. There are no other. One kind adds vertices to the graph, along with “alive” edges around them, and the other kind maps an existing edge label onto a different one.
In order to fully described the system, I also need to mention that the edge labels are given by two parameters: their status (alive, deleted, and a few others related to multiple files and technical details explained below) and the change that introduced them.</p>
<h3 id="dependencies">Dependencies</h3>
<p>This scheme allows to defines dependencies between changes:</p>
<ul>
<li>
<p>If a change $c$ adds a vertex, we must have its <em>“context”</em>, i.e. the lines before and after it, hence the changes that introduced these lines are in the dependencies of $c$.</p>
</li>
<li>
<p>If a change $c$ deletes a vertex, or in other words maps an existing edge introduced by a change $d$, then $c$ must depend on $d$.</p>
</li>
</ul>
<p>Of course, this is just the minimal set of dependencies needed to make sense of the text edits. Hooks and scripts may add extra language-dependent dependencies based on semantics.</p>
<h3 id="are-edge-labels-minimal">Are edge labels minimal?</h3>
<p>Our goals is to find the smallest possible system, both for reasons of mathematical aesthetics (why store useless stuff?) and the other one for performance. Therefore, one immediate question comes to mind: why even keep the change number on the edges?</p>
<p>In order to answer that question, suppose we don’t keep the labels, meaning that the maps happen between statuses only. Then, consider the following two situations:</p>
<ul>
<li>
<p><strong>Change inverses</strong></p>
<p>The first issue happens when two authors delete a line in parallel, and one of the authors reverts their change. Applying these changes yields the following diagram, where the two deletions get merged into one, and the inverse applies to both:</p>
 <p><img src="https://pijul.org/img/inverse2.svg">
 </p>
<p>However, this is not what we expect, since one of the authors explicitly reverted the deletion, while the other performed the same deletion in parallel.
By keeping the labels, this is what we get instead:</p>
 <p><img src="https://pijul.org/img/inverse3.svg">
 </p>
</li>
<li>
<p><strong>Missing contexts</strong></p>
<p>For the sake of clarity, in the rest of this post, we name two users Alice (with pronouns “she/her”) and Bob (with pronouns “he/his”).</p>
<p>This situation, where Alice writes something in the middle of a paragraph $p$, while Bob deletes $p$ in parallel.
One issue here, is that the situation is not symmetric: when Bob applies Alice’s change, he can tell immediately that something is wrong, because the context of Alice’s edits is labelled as deleted in his repository.</p>
 <p><img src="https://pijul.org/img/known-vertices1.svg">
 </p>
<p>However, Alice’s situation is different: indeed, consider the case where instead of deleting $p$ <em>in parallel</em> of her changes, Bob deleted $p$ after applying Alice’s change. The edges deleted are exactly the same, but this is not a conflict, as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices2.svg">
 </p>
<p>The situation is further complicated by the fact that this system doesn’t behave symmetrically with the contexts above and below the new line. Indeed, if Bob deleted the <em>down context</em> of the line (i.e. if he deleted line $C$) instead of the <em>up context</em> (line $B$), Alice could detect the conflict, since in that case, $C$ would have both an alive and a dead edge pointing to it ($C$ is called a “zombie vertex” internally), as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices0.svg">
 </p>
<p>Keeping the change identifiers on each edge allows us to solve this. In Pijul 0.12, Bob would add the labels of all the edges around the deleted lines to the dependencies of his change. Then, Alice can tell whether Bob knows of her change before applying it. The changes are conflict if and only if Bob doesn’t know of the new lines.</p>
<p>However, this behaviour was counter-intuitive, <a href="https://discourse.pijul.org/t/why-these-patches-dont-commute/449">as noted by @tae</a>.</p>
<p>A finer analysis of what dependencies are led to a different behaviour in the new Pijul. Changes now have two different sets of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pijul.org/posts/2020-11-07-towards-1.0/">https://pijul.org/posts/2020-11-07-towards-1.0/</a></em></p>]]>
            </description>
            <link>https://pijul.org/posts/2020-11-07-towards-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032956</guid>
            <pubDate>Mon, 09 Nov 2020 09:24:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Beauty of Python's ExitStack (2015)]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25032924">thread link</a>) | @polm23
<br/>
November 9, 2020 | https://www.rath.org/on-the-beauty-of-pythons-exitstack.html | <a href="https://web.archive.org/web/*/https://www.rath.org/on-the-beauty-of-pythons-exitstack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I believe Python's <a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> feature does not get the recognition
it deserves. I think part of the reason for this is that its
documentation is somewhere deep down in the (already obscure)
<a href="http://docs.python.org/3/library/contextlib.html">contextlib</a> module because formally ExitStack is just one of many
available context managers for Python's <a href="http://docs.python.org/3/reference/compound_stmts.html#the-with-statement">with statement</a>. But
ExitStack deserves far more prominent notice than that. This post will
hopefully help with that.</p>
<p>So what makes ExitStack so important? In short, it's the best way to
handle allocation and release of external resources in Python.</p>
<div id="the-problem">
<h2>The Problem</h2>
<p>The main challenge with external resources is that you have to release
them when you don't need them anymore -- and in particular you must
not forget to do so in all the alternate execution paths that may be
entered in case of error conditions.</p>
<p>Most languages implement error conditions as "exceptions" that can be
"caught" and handled (Python, Java, C++), or as special return values
that you need to check to determine if an error occured (C, Rust,
Go). Typically, code that needs to acquire and release external
resources then looks like this:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>try</span><span>:</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>try</span><span>:</span>
        <span># do stuff with res1 and res2</span>
    <span>finally</span><span>:</span>
        <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>finally</span><span>:</span>
   <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
</pre></div>
<p>or, if the language doesn't have exceptions:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
   <span>goto</span> <span>error_out1</span><span>;</span>
<span>}</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>2</span><span>;</span>
   <span>goto</span> <span>error_out2</span><span>;</span>
<span>}</span>
<span>// do stuff with res1 and res2</span>
<span>retval</span> <span>=</span> <span>0</span><span>;</span> <span>// ok</span>

<span>error_out2</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res2</span><span>);</span>
<span>error_out1</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res1</span><span>);</span>
<span>return</span> <span>retval</span><span>;</span>
</pre></div>
<p>This approach has three big problems:</p>
<ol>
<li>The cleanup code is far away from the allocation code.</li>
<li>When the number of resources increases, indentation levels (or jump
labels) accumulate, making things hard to read.</li>
<li>Managing a dynamic number of resources this way is impossible.</li>
</ol>
<p>In Python, some of these issues can be alleviated by using the
<tt>with</tt> statement:</p>
<div><pre><span></span> <span>@contextlib.contextmanager</span>
 <span>def</span> <span>my_resource</span><span>(</span><span>id_</span><span>):</span>
     <span>res</span> <span>=</span> <span>acquire_resource</span><span>(</span><span>id_</span><span>)</span>
     <span>try</span><span>:</span>
         <span>yield</span> <span>res</span>
     <span>finally</span><span>:</span>
         <span>release_source</span><span>(</span><span>res</span><span>)</span>

<span>with</span> <span>my_resource</span><span>(</span><span>RES_ONE</span><span>)</span> <span>as</span> <span>res1</span><span>,</span> \
   <span>my_resource</span><span>(</span><span>RES_TWO</span><span>)</span> <span>as</span> <span>res2</span><span>:</span>
    <span># do stuff with res1</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>However, this solution is far from optimal: you need to implement
resource-specific context managers (note that in the above example we
silently assumed that both resources can be acquired by the same
function), you can get rid of extra indentation only if you allocate
all the resources at the same time and live with an ugly continuation
line (no parenthesis allowed in this context), and you still need to
know the number of required resources ahead of time.</p>
<p>Over in the world of exception-less programming languages (no pun
intended), <a href="http://www.golang.org/">Go</a> has developed a different remedy: the <a href="http://golang.org/ref/spec#Defer_statement">defer statement</a>
defers execution of an expression until the enclosing
function returns. Using <tt>defer</tt>, the above example can be written
as:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>1</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>2</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>// do stuff with res1 and res2</span>
<span>return</span> <span>0</span>
</pre></div>
<p>This is pretty nice: allocation and cleanup are kept close together,
no extra indentation or jump labels are required, and converting this
to a loop that dynamically acquires multiple resources would be
straightforward. But there are still some drawbacks:</p>
<ul>
<li>To control when exactly a group of resources is getting released you
have to factor out into separate functions all parts of code that
access the respective resources.</li>
<li>You cannot "cancel" a deferred expression, so there is no way to
e.g. return a resource to the caller if no error occured.</li>
<li>There is no way to handle errors from the cleanup functions.</li>
<li><tt>defer</tt> is available in Go, but not in Python.</li>
</ul>
</div>
<div id="exitstack-to-the-rescue">
<h2>ExitStack to the rescue</h2>
<p><a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> fixes all of the above issues, and adds some benefits on
top of it. An ExitStack is (as the name suggests) a stack of clean-up
functions. Adding a callback to the stack is the equivalent of calling
Go's <tt>defer</tt> statement. However, clean-up functions are not executed
when the function returns, but when execution leaves the <tt>with</tt>
block - and until then, the stack can also be emptied again.</p>
<p>Finally, clean-up functions itself may raise exceptions without
affecting execution of other clean-up functions. Even if multiple
clean-ups raise exceptions, you are will get a usable stacktrace.</p>
<p>Here's how to acquire multiple resources:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res1</span><span>)</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res2</span><span>)</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>Note that</p>
<ul>
<li>acquisition and release are close to each other</li>
<li>there's no extra indentation,</li>
<li>the pattern and it easily scales up to many resources (including a
dynamic number that's acquired in a loop)</li>
</ul>
<p>If there already is a context manager for your resource, there's also
a shortcut function:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'first_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'second_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>To open a bunch of files and return them to the caller (without
leaking already opened files if a subsequent open fails):</p>
<div><pre><span></span><span>def</span> <span>open_files</span><span>(</span><span>filelist</span><span>):</span>
    <span>fhs</span> <span>=</span> <span>[]</span>
    <span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
        <span>for</span> <span>name</span> <span>in</span> <span>filelist</span><span>:</span>
            <span>fhs</span><span>.</span><span>append</span><span>(</span><span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>name</span><span>,</span> <span>'r'</span><span>)))</span>
        <span>cm</span><span>.</span><span>pop_all</span><span>()</span>
        <span>return</span> <span>fhs</span>
</pre></div>
<p>Disclaimer: the <a href="https://bugs.python.org/issue13585">original idea for ExitStack</a> came from me.</p>
</div>
</div></div>]]>
            </description>
            <link>https://www.rath.org/on-the-beauty-of-pythons-exitstack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032924</guid>
            <pubDate>Mon, 09 Nov 2020 09:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Loop Software (2013)]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25032563">thread link</a>) | @netgusto
<br/>
November 9, 2020 | https://marak.com/blog/2013-05-13-time-loop-software | <a href="https://web.archive.org/web/*/https://marak.com/blog/2013-05-13-time-loop-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>What if it were possible to write software capable of time travel? What if we could write software that was able to retrieve results from a computation solved sometime in the near future? What would this software look like? What problems could be solved?</p>
<p><a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle#Time_loop_logic">Time loop logic</a> is a hypothetical system of computation that exploits the <a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle">Novikov self-consistency principle</a>. In this system the computer is able to send the result of a computation backwards through time and rely upon the self-consistency principle to force the sent result to be correct. This futuristic concept might seem impossible now but I'd imagine trying to explain nuclear fission to a 3rd century blacksmith would seem equally impossible.</p>
<h2 id="writing-time-loop-software">Writing time loop software</h2>
<p>Building on the concept of time loop logic we are able to implement theoretical programming constructs to help better understand the concept of time travel in software. In the following examples we demonstrate what a time loop logic program might look like.</p>
<h3 id="an-event-loop">An event loop</h3>
<p>In the follow examples we'll be using the JavaScript programing language. JavaScript provides a single thread of execution for code to run in. The JavaScript virtual machine is constantly running an event loop. Each tick of this event loop represents a single cycle of code execution. Once this cycle is completed the next tick in the event loop will occur. In the popular <a href="https://nodejs.org/">Node.js</a> framework <a href="https://nodejs.org/api/process.html#process_process_nexttick_callback">an API is provided</a> to defer the execution of a block of code until the nextTick of the event loop occurs.</p>
<h4 id="node-js-process-nexttick-example">node.js process.nextTick() example</h4>
<pre><code><span><span>function</span> <span>foo</span>(<span></span>) </span>{
  <span>console</span>.log(<span>'foo'</span>);
}

process.nextTick(foo);
<span>console</span>.log(<span>'bar'</span>);
</code></pre><p>This will output:</p>
<pre><code><span>bar
</span><span>foo</span>
</code></pre><p>The same effect of <code>process.nextTick</code> can also be achieved using JavaScript's setTimeout command</p>
<pre><code>setTimeout<span>(<span>foo</span>, <span>0</span>)</span>
</code></pre><h4 id="node-js-process-prevtick-example">node.js process.prevTick() example</h4>
<p>Now let's imagine that instead of deferring a line of code until the next tick of the event loop we could instead push that code <em>backwards</em> to the <em>previous</em> tick of the event loop.</p>
<pre><code><span><span>function</span> <span>foo</span>(<span></span>) </span>{
  <span>console</span>.log(<span>'foo'</span>);
}

<span>console</span>.log(<span>'bar'</span>);
process.prevTick(foo);
</code></pre><p>Outputs:</p>
<pre><code><span>foo</span>
bar
</code></pre><p>The same effect of <code>process.prevTick</code> can also be achieved using setTimeout with a negative value</p>
<pre><code>setTimeout<span>(<span>foo</span>, <span>-1</span>)</span>
</code></pre><p>Since all we are doing is logging a simple string to the console, this is a contrived example. However; building on the concept of <code>process.prevTick</code> we can begin to implement more complex time loop programs.</p>
<h2 id="brute-force-cracking-with-time-loops">Brute force cracking with time loops</h2>
<p>Let's assume a simple <a href="https://en.wikipedia.org/wiki/Brute-force_search">brute-force search</a> password cracking scenario. Imagine there is a login function which expects a password. We have access to a very large word dictionary in which our cracking software will sequentially attempt logins using every word in the dictionary as a password until a match is found.</p>
<p>Here is the code for our brute-force program</p>
<p><em>Note: It's important to remember that Novikov's self-consistency principle guarantees that the sequence of events generating the paradox in the following code has zero probability.</em></p>


<h2 id="prime-factors-with-time-loops">Prime Factors with time loops</h2>
<p>Using time-loop logic  prime factors can be calculated in polynomial time.</p>


<h2 id="zero-lag-instant-communication">Zero-lag / Instant Communication</h2>
<p>The theoretical application of time-loop logic is endless. Imagine a time-loop based communication protocol. This would mean zero millisecond latency. Imagine gaming, video broadcasting, and file sharing with instantaneous transfer and zero lag. Through exploiting self-consistency we know that data will be sent in the immediate future ( since the data has begun transferring from the source ) and that eventually the transmission will arrive at it's destination. As long as the data will eventually be received, we are able to send the result back from the future into the immediate present, removing the notion of latency or lag.</p>
<h2 id="time-loop-logic-and-novikov-s-self-consistency-principle">Time Loop Logic and Novikov's Self-Consistency Principle</h2>
<p>How is it actually possible to program a time loop? Based on the self-consistency principle and continuing advancements in quantum entanglement these types of mind-bending constructs are not very far away. It's very possible we'll see this type of software actively being developed within the next hundred years.</p>
<p>Time loop logic was first written about by <a href="https://en.wikipedia.org/wiki/Hans_Moravec">Hans Moravec</a> who is best known for his work in robotics and artificial intelligence at Carnegie Mellon University. You can find Hans' original paper from 1991, "Time Travel and Computing", here: <a href="https://frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html">https://frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html</a>. I recommend reading the entire paper.</p>
<p>What we know from <a href="https://en.wikipedia.org/wiki/Closed_timelike_curve#General_relativity">general relativity</a> is that at a quantum level backwards time-travel is mathematically possible in certain solutions containing <a href="https://en.wikipedia.org/wiki/Closed_timelike_curve">closed timelike curves</a>. A closed timelike curve is a <a href="https://en.wikipedia.org/wiki/World_line">world-line</a> in a <a href="https://en.wikipedia.org/wiki/Lorentzian_manifold#Lorentzian_manifold">Lorentzian manifold</a>. </p>
<p>Closed timelike curves ( CTCs ) pose a problem for physicists. The existence of CTCs introduces the notion of time travel being possible. If time travel is possible, we have now introduced the notion of <a href="https://en.wikipedia.org/wiki/Grandfather_paradox">time travel paradoxes</a> which can violate <a href="https://en.wikipedia.org/wiki/Causality_(physics)">causality</a>. Since it's generally accepted that we cannot violate causality in our universe we must be able to explain how closed time-like curves can exist.</p>
<p>In his self-consistency principle Novikov asserts that if an event exists that would give rise to a paradox, or to any "change" to the past whatsoever, then the probability of that event is zero. In short, it says that it is impossible to create time travel paradoxes. You can find the original paper here: <a href="http://authors.library.caltech.edu/3737">http://authors.library.caltech.edu/3737</a>. I recommend starting with reading the <a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle#History_of_the_principle">history of the principle</a>.</p>

<p>In order for time loop logic to return an answer instantaneously, we <em>must</em> ensure that the problem will run long enough into the future to <em>actually</em> calculate the result. If a problem takes sixty seconds to solve, the program must run for at least sixty seconds. Time-loop logic does <em>not</em> violate causality. We are able to retrieve the answer instantly because we have committed to spending sixty seconds in the future calculating the answer and sending it back.</p>
<p>This turns debugging time-loop logic into somewhat of an impossibility. Any bugs in a time loop indicate that sometime in the future a problem has occurred. <strong>This event may or may not be related to software.</strong> </p>
<p>Imagine a computer that utilized a time loop to brute force crack passwords ( as our code posted above did). I turn the machine on and request it cracks the password. The program doesn't work. Frustrated, I turn off the machine and complain to my co-worker Josh.</p>
<p>Josh turns on the machine and requests the password. The software works instantly cracking the password in under 1ms.</p>
<p>Bewildered, I ask Josh why the machine worked for him but not for me.</p>
<p>Josh replies, "It's actually quite simple. Using that computer it's going to take approximately 400 hours to brute force the password. After that 400 hours the CPU must recursively return the cracked password back in time until it reaches right now. I was able to get the answer instantly because I have decided to not turn this computer off for another 399 hours and 59 minutes. Simply put, you turned off the computer too quickly"</p>
<p><em>The consequences of unplugging the computer</em></p>
</div></div></div>]]>
            </description>
            <link>https://marak.com/blog/2013-05-13-time-loop-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032563</guid>
            <pubDate>Mon, 09 Nov 2020 08:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25032481">thread link</a>) | @jessems
<br/>
November 9, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which — crucially — includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as “<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>”. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer — the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that’s no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we’ll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from — that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn’t obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them — and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there’s a gap between the two — and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032481</guid>
            <pubDate>Mon, 09 Nov 2020 08:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25032133">thread link</a>) | @ingve
<br/>
November 8, 2020 | https://ericniebler.com/2020/11/08/structured-concurrency/ | <a href="https://web.archive.org/web/*/https://ericniebler.com/2020/11/08/structured-concurrency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>TL;DR: <strong>“Structured concurrency” refers to a way to structure async computations so that child operations are guaranteed to complete before their parents, just the way a function is guaranteed to complete before its caller.</strong> This sounds simple and boring, but in C++ it’s anything but. Structured concurrency — most notably, C++20 coroutines — has profound implications for the correctness and the simplicity of async architecture. It brings the <a href="https://docs.microsoft.com/en-us/cpp/cpp/welcome-back-to-cpp-modern-cpp?view=msvc-160">Modern C++ style</a> to our async programs by making async lifetimes correspond to ordinary C++ lexical scopes, eliminating the need for reference counting to manage object lifetime.</p>
<h2>Structured Programming and C++</h2>
<p>Back in the 1950’s, the nascent computing industry discovered structured programming: that high-level programming languages with lexical scopes, control structures, and subroutines resulted in programs that were far easier to read, write, and maintain than programming at the assembly level with test-and-jump instructions and <code>goto</code>. The advance was such a quantum leap that nobody talks about structured programming anymore; it’s just “programming”.</p>
<p>C++, more so than any other language, leverages structured programming to the hilt. The semantics of object lifetime mirror — and are tied to — the strict nesting of scopes; i.e., the <em>structure</em> of your code. Function activations nest, scopes nest, and object lifetimes nest. Objects’ lifetimes end with a scope’s closing curly brace, and objects are destroyed in the reverse order of their construction to preserve the strict nesting.</p>
<p>The Modern C++ programming style is built on this structured foundation. Objects have <em>value semantics</em> — they behave like the ints — and resources are cleaned up in destructors deterministically, which guarantees structurally that resources aren’t used after their lifetimes have ended. This is <em>very</em> important.</p>
<p>When we abandon this strict nesting of scopes and lifetimes — say, when we reference count an object on the heap, or when we use the singleton pattern — we are fighting against the strengths of the language rather than working with them.</p>
<h2>The Trouble With Threads</h2>
<p>Writing correct programs in the presence of concurrency is far more difficult than in single-threaded code. There are lots of reasons for this. One reason is that threads, like singletons and dynamically allocated objects, scoff at your puny nested scopes. Although you can use the Modern C++ style <em>within</em> a thread, when logic and lifetimes are scattered across threads, the hierarchical structure of your program is lost. The tools we use to manage complexity in single-threaded code — in particular, nested lifetimes tied to nested scopes — simply don’t translate to async code.</p>
<p>To see what I mean, let’s look at what happens when we take a simple synchronous function and make it asynchronous.</p>
<pre>void computeResult(State &amp; s);

int doThing() {
  State s;
  computeResult(s);
  return s.result;
}
</pre>
<p><code>doThing()</code> is simple enough. It declares some local state, calls a helper, then returns some result. Now imagine that we want to make both functions async, maybe because they take too long. No problem, let’s use Boost futures, which support continuation chaining:</p>
<pre>boost::future&lt;void&gt; computeResult(State &amp; s);

boost::future&lt;int&gt; doThing() {
  State s;
  auto fut = computeResult(s);
  return fut.then(
    [&amp;](auto&amp;&amp;) { return s.result; }); // OOPS
}
</pre>
<p>If you’ve programmed with futures before, you’re probably screaming, <em>“Nooooo!”</em> The <code>.then()</code> on the last line queues up some work to run after <code>computeResult()</code> completes. <code>doThing()</code> then returns the resulting future. The trouble is, when <code>doThing()</code> returns, the lifetime of the <code>State</code> object ends, <em>and the continuation is still referencing it</em>. That is now a dangling reference, and will likely cause a crash.</p>
<p>What has gone wrong? Futures let us compute with results that aren’t available yet, and the Boost flavor lets us chain continuations. But the continuation is a separate function with a separate scope. We often need to share data across those separate scopes. No more tidy nested scopes, no more nested lifetimes. We have to manage the lifetime of the state manually, something like this:</p>
<pre>boost::future&lt;void&gt;
computeResult(shared_ptr&lt;State&gt; s); // addref
                                    // the state

boost::future&lt;int&gt; doThing() {
  auto s = std::make_shared&lt;State&gt;();
  auto fut = computeResult(s);
  return fut.then(
    [s](auto&amp;&amp;) { return s.result; }); // addref
                                       // the state
}
</pre>
<p>Since both async operations refer to the state, they both need to share responsibility to keep it alive.</p>
<p>Another way to think about this is: <em>what is the lifetime of this asynchronous computation?</em> It starts when <code>doThing()</code> is called, but it doesn’t end until the continuation — the lambda passed to <code>future.then()</code> — returns. <em>There is no lexical scope that corresponds to that lifetime.</em> And that is the source of our woes.</p>
<h2>Unstructured Concurrency</h2>
<p>The story gets more complicated yet when we consider executors. Executors are handles to executions contexts that let you schedule work onto, say, a thread or thread pool. Many codebases have some notion of an executor, and some let you schedule things with a delay or with some other policy. This lets us do cool things, like move a computation from an IO thread pool to a CPU thread pool, or retry an async operation with a delay. Handy, but like <code>goto</code> it is a very low-level control structure that tends to obfuscate rather than clarify.</p>
<p>For instance, I recently came across an algorithm that uses executors and callbacks (called Listeners here) that retries the async allocation of some resource. Below is a greatly abridged version. It is described after the break.</p>
<pre>// This is a continuation that gets invoked when
// the async operation completes:
struct Manager::Listener : ListenerInterface {
  shared_ptr&lt;Manager&gt; manager_;
  executor executor_;
  size_t retriesCount_;

  void onSucceeded() override {
    /* ...yay, allocation succeeded... */
  }
  void onFailed() override {
    // When the allocation fails, post a retry
    // to the executor with a delay
    auto alloc = [manager = manager_]() {
      manager-&gt;allocate();
    };
    // Run "alloc" at some point in the future:
    executor_.execute_after(
      alloc, 10ms * (1 &lt;&lt; retriesCount_));
  }
};

// Try asynchronously allocating some resource
// with the above class as a continuation
void Manager::allocate() {
  // Have we already tried too many times?
  if (retriesCount_ &gt; kMaxRetries) {
    /* ...notify any observers that we failed */
    return;
  }

  // Try once more:
  ++retriesCount_;
  allocator_.doAllocate(
    make_shared&lt;Listener&gt;(
      shared_from_this(),
      executor_,
      retriesCount_));
}
</pre>
<p>The <code>allocate()</code> member function first checks to see if the operation has already been retried too many times. If not it calls a helper <code>doAllocate()</code> function, passing in a callback to be notified on either success or failure. On failure, the handler posts deferred work to the executor, which will call <code>allocate()</code> back, thus retrying the allocation with a delay.</p>
<p>This is a heavily stateful and rather circuitous async algorithm. The logic spans many functions and several objects, and the control and data flow is not obvious. Note the intricate ref-counting dance necessary to keep the objects alive. Posting the work to an executor makes it even harder. Executors in this code have no notion of continuations, so errors that happen during task execution have nowhere to go. The <code>allocate()</code> function can’t signal an error by throwing an exception if it wants any part of the program to be able to recover from the error. Error handling must be done manually and out-of-band. Ditto if we wanted to support cancellation.</p>
<p>This is <strong>unstructured concurrency</strong>: we queue up async operations in an <em>ad hoc</em> fashion; we chain dependent work, use continuations or “strand” executors to enforce sequential consistency; and we use strong and weak reference counts to keep data alive until we are certain it’s no longer needed. There is no formal notion of task A being a child of task B, no way to enforce that child tasks complete before their parents, and no one place in the code that we can point to and say, “Here is the algorithm.”</p>
<blockquote>
<p><strong>If you don’t mind the analogy, the hops through the executor are a bit like <code>goto</code> statements that are non-local in both time and space: “Jump to this point in the program, <em>X</em> milliseconds from now, on this particular thread.”</strong></p>
</blockquote>
<p>That non-local discontinuity makes it hard to reason about correctness and efficiency. Scale unstructured concurrency up to whole programs handling lots of concurrent real-time events, and the incidental complexity of manually handling out-of-band asynchronous control and data flow, controlling concurrent access to shared state, and managing object lifetime becomes overwhelming.</p>
<h2>Structured Concurrency</h2>
<p>Recall that in the early days of computing, unstructured programming styles rapidly gave way to structured styles. With the addition of coroutines to C++, we are seeing a similar phase shift happening today to our asynchronous code. If we were to rewrite the above retry algorithm in terms of coroutines (using Lewis Baker’s popular <a href="https://github.com/lewissbaker/cppcoro">cppcoro</a> library), it might look something like this:</p>
<pre>// Try asynchronously allocating some resource
// with retry:
cppcoro::task&lt;&gt; Manager::allocate() {
  // Retry the allocation up to kMaxRetries
  // times:
  for (int retriesCount = 1;
       retriesCount &lt;= kMaxRetries;
       ++retriesCount) {
    try {
      co_await allocator_.doAllocate();
      co_return; // success!
    } catch (...) {}

    // Oops, it failed. Yield the thread for a
    // bit and then retry:
    co_await scheduler_.schedule_after(
      10ms * (1 &lt;&lt; retriesCount));
  }

  // Error, too many retries
  throw std::runtime_error(
    "Resource allocation retry count exceeded.");
}
</pre>
<blockquote>
<p>Aside: This replaces the <code>executor_</code> with a <code>scheduler_</code> that implements cppcoro’s <a href="https://github.com/lewissbaker/cppcoro#delayedscheduler-concept">DelayedScheduler</a> concept.</p>
</blockquote>
<p>Let’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ericniebler.com/2020/11/08/structured-concurrency/">https://ericniebler.com/2020/11/08/structured-concurrency/</a></em></p>]]>
            </description>
            <link>https://ericniebler.com/2020/11/08/structured-concurrency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032133</guid>
            <pubDate>Mon, 09 Nov 2020 07:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm going to experiment by being Blind and Alone for 24 Hours]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25031774">thread link</a>) | @Osiris30
<br/>
November 8, 2020 | https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-896">

	
	<!-- .entry-header -->


			<div>

			
<figure><img data-attachment-id="901" data-permalink="https://dormin.org/bird-box/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg" data-orig-size="2000,1050" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bird-box" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=760" src="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024 1024w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300 300w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=768 768w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For 24 hours I will be blind and alone in my apartment. I eventually want to try being blind for a week, but I’ll need seven days with no other obligations, and I won’t have that for a while. For now, I’ll suffice with a smaller-scale experiments with a few extra provisions for added difficulty.</p>







<ol type="1"><li>I must leave my blindfold on for 24 hours.<ul><li>If I remove the blindfold, I have failed the experiment</li><li>If the blindfold falls off or I can get partial sight, I have failed the experiment.</li><li>I am only allowed to readjust my blindfold if I can see light.</li></ul></li><li>I must not be in contact with any other people for 24 hours.<ul><li>I cannot answer my phone or any other messaging system.</li><li>I cannot receive in-person visitors.</li><li>If someone knocks at the door, I cannot answer verbally or physically.</li></ul></li><li>I will set an alarm for 24 hours. I cannot set any other alarms or use any other means to ascertain the time.<ul><li>It is up to me to keep my phone charged so the alarm goes off.</li></ul></li><li>I cannot leave my apartment.</li></ol>











<p>I have no good reason. I just want to see if I am capable of doing it and what will happen. Some things I’m curious about:</p>



<ul><li>Do I have the willpower to get through the experiment?</li><li>Will I become disoriented from losing all sense of time?</li><li>Will I be able to stave off boredom with podcasts, audiobooks, and music on my phone?</li><li>Will I enter some sort of meditative state due to a lack of sensory input?</li><li><a href="https://www.discovermagazine.com/the-sciences/scientists-made-people-wear-blindfolds-for-4-days-the-resulting-hallucinations-were-incredible">Will I hallucinate</a>?</li><li>Will my non-sight senses heighten?</li><li>Will I hurt myself by falling or banging into something?</li><li>Will I sleep?</li><li>Will I eat? Is consuming caffeine a good idea (for entertainment) or a bad idea (energy with no direction)?</li><li>Will this experience make me more interested in being blind for a week? Or less?</li></ul>



<figure><img src="https://digitalimpact.io/wp-content/uploads/2014/08/Blind.png" alt="Modern CEOs Are Blindfolded - Digital Impact"></figure>







<p>Attempt One started at 10:30 AM and failed at 1:13 PM. I purposefully took off my blindfold because I was worried that my multiple failures to input my Iphone’s password had resulted in a permanent lock or data wipe. But the password screen was just locked for a minute and all was well.</p>



<p>Given that I failed in the early afternoon, I considered restarting the experiment on another day in the morning. But I had already carved out a 24 hour period when I wouldn’t do any work or be disturbed, and it might have been a week or two longer before I got that opportunity again.</p>



<p>So I checked my messages, briefly went on Reddit, and then restarted.</p>



<div><figure><img data-attachment-id="903" data-permalink="https://dormin.org/t86752/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg" data-orig-size="521,610" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;CSA Images \/ CSA Images&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Blindfolded Woman&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;\u00a9 CSA Images \/ CSA Images&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;T86752&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="T86752" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" src="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg 521w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=128 128w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256 256w" sizes="(max-width: 521px) 100vw, 521px"></figure></div>







<p>Attempt Two was successful. I put on my blindfold at 1:23 PM on Thursday, November 5, 2020. I removed it at 1:28 PM on Friday, November 6.</p>



<p>It was an… interesting experience. I don’t recommend it, but I’m glad I did it. I’m not sure where to begin in describing it, especially since I couldn’t take notes, and part of the challenge was being confused. But I’ll do my best to break down the experience.</p>



<div><figure><img src="https://cdn.shopify.com/s/files/1/0818/3417/products/Les_Sublimes_Cashmere_Scarf_Dark_Blue_packshot_2048x.jpg?v=1539973736" alt="Large Cashmere Scarf in Dark Blue | Les Sublimes" width="427" height="427"></figure></div>



<h2><strong><span>Blindfold</span></strong></h2>



<p>To simulate blindness, I used a dark blue scarf as a blindfold. One layer wasn’t quite dark enough, so I folded it in half for extra light defense.</p>



<p>With the blindfold securely on, my vision was the same whether my eyes were open or closed. I kept my eyes closed 99.9% of the time since it was usually more comfortable and helped limit light. I occasionally opened my eyes to check the brightness level and to… I guess you could call it <em>stretch my eyelids.</em> They don’t feel good if you leave them closed for too long.</p>



<p>I couldn’t get a perfect scarf seal around my eyes, so sometimes when I tilted my head back while sitting I noticed a little light come into the bottom of my vision. To limit this, I often pinched the scarf around my nose in that position. But many/most blind people can see some light anyway, so I don’t think this was a significant violation of the experiment.</p>



<p>My eyes got quite dry under the scarf, so I applied moisturizer to this lids and sockets four or five times. I wanted to use eyedrops too, but there was no way to do so without failing the experiment.</p>



<figure><img loading="lazy" data-attachment-id="906" data-permalink="https://dormin.org/image/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" data-large-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" src="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" alt="BLACK N BLACK - #blackouttuesday ✊🏻✊🏼✊🏽✊🏾✊🏿 | Facebook" width="786" height="786" srcset="https://dorminorg.files.wordpress.com/2020/11/image.jpeg 225w, https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=150 150w" sizes="(max-width: 786px) 100vw, 786px"></figure>



<h2><strong><span>Blindness</span></strong></h2>



<p>Initially, everything was black, but as the day went on and the sun went down, I could tell it was nighttime even through two layers of scarf and my eyelids. I’m not sure if I could tell because my eyes had adjusted to become extremely sensitive to light, or if there were other subtle signals (ie. noises, air temperature, circadian rhythms, etc.) which my body picked up on. As evidence of the latter, I could not see any difference between the tv being on or off, nor the refrigerator being opened or closed, even when I was sitting right in front of either.</p>



<p>What I saw depended on how I applied my focus. If I did focus on my vision, I’d see the typical blackness you get from closing your eyes, but it was never perfectly black nor uniform; there was always some odd movement and occasional coloring (whiteness, pale blue, or sometimes red). The most common distortions were a swirling or flowing whiteness, sort of like cream in coffee. I hoped that being blindfolded for so long would make the distortions more extreme, but for the most part it looked no different than what you’d see if you closed your eyes right now for ten minutes.</p>



<p>There was one exception. It must have been about 20+ hours into the experiment, and my eyes were itching, so I rubbed both of them at the same time over the scarf. If you rub your closed eyes and focus on your sight any time you can see some weird stuff, but this was far more extreme than usual. I remember my entire vision filling up with white bubbles which then broke and briefly returned to black. Then white lightning bolt shapes stretched across my sight, expanded to make my vision purely white, and then slowly faded back to black. The strangest thing about it was the <em>brightness</em>. I literally felt like I was staring into lights despite being blindfolded in a dark room. Unfortunately, it only lasted about 30 seconds, but my heart was racing.</p>



<p>More notable than what I saw was what I didn’t see. By default, I was lost in thought and I focused on nothing. In such a state, I didn’t even register my vision or notice the darkness. I <em>think</em> this made my imagination and mental visualization more acute. On occasion, I’d be deep in thought and I’d get the <em>brightness</em> sensation again because I’d be mentally picturing something so vividly that the inevitable return to darkness felt like shutting off the lights in my brain. I’ll explain more about this in the <strong>Three Phases</strong> section.</p>



<p>Sadly, I did not hallucinate, or at least not as far as I could tell.</p>



<figure><img src="https://i1.wp.com/www.intelligentliving.co/wp-content/uploads/2014/07/sloth-sleeping.jpg?fit=1024%2C698&amp;ssl=1" alt="Fighting Bacteria With Sloth Fur"></figure>



<h2><strong><span>Energy</span></strong></h2>



<p>This was the most surprising aspect of the experiment.</p>



<p>I read that <a href="https://abcnews.go.com/Health/story?id=117902&amp;page=1#:~:text=Without%20light%20cues%20that%20the,as%20a%20result%2C%20researchers%20say.">blind people have trouble getting to sleep</a> because they don’t access any/enough light for their circadian rhythms. I seem to have the exact opposite problem. Without light, my body always thinks it’s time to sleep and has trouble doing anything else. Throughout most of the experiment, I felt extremely lethargic, lazy, and had to fight to stay awake.</p>



<p>I started my first failed experiment attempt at 10:30 AM. I had gotten 7.5 solid hours of sleep, I hadn’t done anything tiring the previous day, and I generally felt fine. Then I put on my blindfold, and within thirty minutes I was nodding off. I semi-slept for two hours before deciding to get an energy drink to get myself out of the funk. That worked, but as soon as it wore off, I was back in semi-sleep mode.</p>



<p>Even when I was firmly awake, I generally felt weak and lethargic. Movement around the apartment was annoying of course, but made so much more difficult by my energy levels. I ended up lying perfectly still in my comfy computer chair with my feet on a table 95% of the time. That is, when I wasn’t lying in bed.</p>



<p>On the other hand, when I removed my blindfold after 24 hours, I experienced a <em>burst</em> of energy. Seriously, it was like I had downed a double shot of espresso. It was like a switch had been flicked. The haziness and cobwebs were gone in an instant, and I felt the energy coursing through my body. I guess light has a big impact on me.</p>



<div><figure><img data-attachment-id="908" data-permalink="https://dormin.org/blind-man-2/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg" data-orig-size="615,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1604789422&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="blind-man-2" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" src="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg 615w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300 300w" sizes="(max-width: 615px) 100vw, 615px"></figure></div>



<h2><strong><span>Movement</span></strong></h2>



<p>I moved exactly how you’d expect… clumsily.</p>



<p>For the most part, I slowly walked around my apartment with a hand out to feel for walls and edges. Sometimes I’d get lazy and crawl just so it was easier. I know my apartment well enough that it wasn’t hard to get around, but every once in awhile I’d lose track of where I was and would be left slowly swinging my arm around searching for anything. It’s not a pleasant sensation.</p>



<p>Before the experiment, I had planned to pace around for fun, or maybe even do some exercise with the free time. But the confusion and especially the lethargy stopped all that. I just sat in my chair and didn’t move unless I needed to get a drink, go to the bathroom, or sleep.</p>



<p>I kind of wish I had done the experiment in an unfamiliar environment to add to the movement challenge, but oh well.</p>



<div><figure><img src="https://secure.img1-fg.wfcdn.com/im/99629273/compr-r85/1167/116715839/dual-flush-elongated-one-piece-toilet-seat-included.jpg" alt="DeerValley Dual-Flush Elongated One-Piece Toilet (Seat Included) &amp; Reviews  | Wayfair" width="729" height="729"></figure></div>



<h2><strong><span>Necessities</span></strong></h2>



<p>For food, I ate a big lunch at 10 AM before the experiment and then munched on dark chocolate throughout the night. I felt the heavy lethargy well before the lack of calories was an issue. I probably should have put some prepackaged meals in my fridge to eat, but I was worried about making a mess and not being able to clean up. Do I want ants? Because that’s how I get ants.</p>



<p>For drinks, I could manage to get to the kitchen and fill a cup with water when I needed to. I never took a full cup back to my chair just in case I knocked it over (clean up would be a nightmare). I also had some diet coke to serve as entertainment and put a little caffeine in me.</p>



<p>For the bathroom, I (a man) peed sitting down. I’m not ashamed to admit it.</p>



<div><figure><img src="https://imgaz2.staticbg.com/thumb/large/oaupload/banggood/images/F2/09/b934b522-e3e3-491d-b758-d0b92c259f0c.jpg" alt="Novel surreal melting distorted wall clock surrealist salvador dali style  wall clock amazing home decoration gift Sale - Banggood.com" width="802" height="801"></figure></div>



<h2><strong><span>Time</span></strong></h2>



<p>As part of the experiment, I never knew what time it was. This was intended to confuse me throughout the 24 hours, and it did, but it may have helped too. With no sense of time, it was easy to sit back and not think about it. Time drifted by and I existed. That was that.</p>



<p>I actually did ask Siri for the time once… it was late in the experiment, and it felt like I had put on the blindfold forever ago. As you’d expect, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031774</guid>
            <pubDate>Mon, 09 Nov 2020 05:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with pen and paper]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25031483">thread link</a>) | @sethetter
<br/>
November 8, 2020 | https://sethetter.com/posts/start-with-pen-and-paper/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/start-with-pen-and-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            


<article>
    
    <section>
        <p>tl;dr — If you feel unfocused, grab a pen and paper and start writing your thoughts down.</p>
<p>Is there a question you are stuck on? A ambiguous goal you're trying to accomplish? Maybe a task you know you need to do but from which you keep getting distracted?</p>
<p><strong>Nothing will provide focus like pen and paper.</strong></p>
<p>It's all too easy these days to have a clear intention only to be sidetracked by the whirlpool of apps and services clawing for our attention on our devices.</p>
<p>It helps to take the time to groom our notification settings for importance and timeliness, but a digital device that we can use to complete nearly any task will never stand up to pen and paper in terms of it's ability to provide focus.</p>
<p>My thoughts are a constant whirlwind, I'm certainly more distractible than most, and interacting with nearly any online service only fuels that fire. So how can I get anything done if I'm unable to control my focus?</p>
<p><strong>Pen and paper.</strong> Whenever I catch myself stuck in the whirlpool, feeling not-great because I <em>know</em> I'm not doing what I want to be doing, or what I should be doing, I step away, grab pen and paper, and start writing.</p>
<p>The simple act of writing can focus my thoughts and attention in a way that nothing else can. Free from distractions, just a canvas to pour my thoughts into, and turn them into something with a sense of direction and purpose.</p>
<p>Writing is like a superpower to me. If there's any task I want to accomplish, the first step is always to write it down. Anytime I need to recenter myself on that task, I simply return to paper.</p>
<p>Throughout my life I've found that the simplest solutions are often the most powerful. So far I've found no simpler solution to start tackling any problem than to simply write it down, and then keep on writing.</p>

    </section>
</article>


        </div></div>]]>
            </description>
            <link>https://sethetter.com/posts/start-with-pen-and-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031483</guid>
            <pubDate>Mon, 09 Nov 2020 04:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cool Machine Learning Books]]>
            </title>
            <description>
<![CDATA[
Score 242 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25031455">thread link</a>) | @ridddle
<br/>
November 8, 2020 | http://matpalm.com/blog/cool_machine_learning_books/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/cool_machine_learning_books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  <p>awhile ago i posted
   <a href="http://matpalm.com/blog/2010/08/06/my-list-of-cool-machine-learning-books/">my list of cool machine learning books</a>,
   but it's been awhile so it's probably time to update it...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mml.jpg"></p>
<p><b><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a>
   by Marc Peter Deisenroth, A. Aldo Faisal &amp; Cheng Soon Ong.</b>
</p>
<p>this is my personal favorite book on the general math required for machine learning,
   the way things are described really resonate with me.
   available as a free pdf but i got a paper copy to support the authors after reading the
   first half.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/laalfd.jpg"></p>
<p><b><a href="http://math.mit.edu/~gs/learningfromdata/">Linear Algebra and Learning from Data</a>
   by Gilbert Strang.</b>
</p>
<p>this is gilbert's most recent work. it's really great, he's such a good teacher, and
   <a href="https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/">his freely available lectures</a>
   are even better. it's a shorter text than his other classic intro below with
   more of a focus on how things are connected to modern machine learning techniques.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itla.jpg"></p>
<p><b><a href="https://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra</a>
   by Gilbert Strang.</b>
</p>
<p>this was my favorite linear algebra book for a long time before his 'learning from
   data' came out. this is a larger book with a more comprehensive view of linear algebra.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ts.jpg"></p>
<p><b><a href="https://greenteapress.com/wp/think-stats-2e/">Think Stats: Probability and Statistics for Programmers</a> by Allen Downey.</b>
</p>
<p>this book focuses on practical computation methods for probability and statistics.
   i got a lot out of working through this one.
   it's all in python and available for free.
   ( exciting update! as part of writing this post i've discovered there's a new edition
   to read!)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dbda.jpg"></p>
<p><b><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>
   by John Kruscgke</b>
</p>
<p>on the bayesian side of things this is the book i've most enjoyed working through.
   i've only got the first edition which was R and
   <a href="https://en.wikipedia.org/wiki/OpenBUGS">BUGS</a> but i see
   the second edition is R,
   <a href="http://mcmc-jags.sourceforge.net/">JAGS</a> and
   <a href="https://mc-stan.org/">Stan</a>.
   it'd be fun i'm sure to work through it doing
   everything in <a href="https://github.com/pyro-ppl/numpyro">numpyro</a>. i might do that in all
   my free time. haha. "free time" hahaha. sob.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/eosl.jpg"></p>
<p><b><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a>
   by Hastie, Tibshirani and Friedman</b>
</p>
<p>this is still one of the most amazing fundamental machine learning books i've ever had.
   in fact i've purchased this book <em>twice</em> and given it away both times :/ i might buy another
   copy some time soon, even though it's been freely available to download for ages. an
   amazing piece of work.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pgm.jpg"></p>
<p><b>
   <a href="https://mitpress.mit.edu/books/probabilistic-graphical-models">Probabilistic Graphical Models</a>
   by Daphne Koller &amp; Nir Friedman</b>
</p>
<p>this is an epic textbook that i'd love to understand better. i've read a couple of sections in
   detail but not the entire tome yet.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/praml.jpg"></p>
<p><b>
   <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/">Pattern Recognition and Machine Learning</a>
   by Christopher Bishop</b>
</p>
<p>this is probably the best overall machine learning text book i've ever read. such a beautiful book
   and <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">the pdf is FREE FOR DOWNLOAD!!!</a>
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mlapp.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/machine-learning-1">Machine Learning: A Probabilistic Perspective</a> by Kevin Murphy</b>
</p>
<p>this is my second favorite general theory text on machine learning.
   i got kevin to sign my copy when he was passing my desk once but
   someone borrowed it and never gave it back :(
   so if you see a copy with my name on the spine let me know!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/homl.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</a> by Aurélien Géron</b>
</p>
<p>this is the book i point most people to when they are interested in getting up
   to speed with modern applied machine learning without too much concern for the
   theory. it's very up to date (as much as a book can be) with the latest libraries
   and, most importantly, provides a good overview of not just neural stuff but fundamental
   <a href="https://scikit-learn.org/stable/">scikit-learn</a> as well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mle.jpg"></p>
<p><b><a href="http://www.mlebook.com/wiki/doku.php">Machine Learning Engineering</a> by Andriy Burkov</b>
</p>
<p>a great book focussing on the operations side of running a machine learning system. i'm a bit
   under half way through the free online version and very likely to buy a physical copy to finish
   it and support the author. great stuff and, in many ways, a more impactful book than any of
   the theory books here.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itdm.jpg"></p>
<p><b><a href="https://www-users.cs.umn.edu/~kumar001/dmbook/index.php">Introduction to Data Mining</a>
   by Pang-Ning Tan, Michael Steinbach &amp; Vipin Kumar</b>
</p>
<p>this is another one that was also on my list from ten years ago and though it's section
   on neural networks is a bit of chuckle these days there is still a bunch of really
   great fundamental stuff in this book. very practical and easy to digest. i also see there's
   a second edition now. i reckon this would compliment the "hands on" book above very well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/salp.jpg"></p>
<p><b><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a>
   by Dan Jurafsky &amp; James Martin</b>
</p>
<p>still the best overview of NLP there is (IMHO). can't wait to read the 3rd edition which
   apparently will cover more modern stuff (e.g. transformers) but until then, for the
   love of god though, please don't be one of those "this entire book is
   irrelevant now! just fine tune BERT" people :/
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/no.jpg"></p>
<p><b><a href="https://link.springer.com/book/10.1007/978-0-387-40065-5">Numerical Optimization</a>
   by Jorge NocedalStephen J. Wright</b>
</p>
<p>this book is super hard core and maybe more an operations
   research book than machine learning. though i've not read it cover to cover the
   couple of bits i've worked through really taught me a lot. i'd love to understand
   the stuff in this text better; it's so so fundamental to machine learning (and more)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dl.jpg"></p>
<p><b><a href="https://www.deeplearningbook.org/">Deep Learning</a>
   by Ian Goodfellow</b>
</p>
<p>writing a book specifically on deep learning is very dangerous since things move so fast but
   if anyone can do it, ian can... i think ian's approach to explaining neural networks
   from the ground up is one of my favorites. i got the first edition hardback but it's free to
   download from the website.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pr.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/probabilistic-robotics">Probabilistic Robotics</a>
   by Sebastian Thrun, Wolfram Burgard and Dieter Fox</b>
</p>
<p>when i first joined a robotics group i bought a stack of ML/robotics books and this
   was by far the best. it's good intro stuff, and maybe already dated in places given
   it's age (the 2006 edition i have) but i still got a bunch from it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/tml.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/tinyml/9781492052036/">TinyML</a>
   by Pete Warden &amp; Daniel Situnayake</b>
</p>
<p>this was a super super fun book to tech review! neural networks on microcontrollers?!?
   yes please!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ec.jpg"></p>
<p><b><a href="https://www.wiley.com/en-us/Evolutionary+Computation%3A+Toward+a+New+Philosophy+of+Machine+Intelligence%2C+3rd+Edition-p-9780471669517">Evolutionary Computation</a> by David Fogel</b>
</p>
<p>this is still by favorite book on evolutionary algorithms; i've had this for a loooong
   time now. i still feel like evolutionary approaches are due for a big big comeback
   any time soon....
</p>
<hr>


<h2>in the mail...</h2>
<p>the good thing about writing a list is you get people telling you cool ones you've missed :)
</p>
<p>the top three i've chosen (that are in the mail) are...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ciis.jpg"></p>
<p><b><a href="http://bayes.cs.ucla.edu/PRIMER/">Causal Inference in Statistics</a> by
   Judea Pearl, Madelyn Glymour &amp; Nicholas P. Jewell</b>
</p>
<p>recommended by <a href="https://twitter.com/animesh_garg">animesh</a> who quite rightly points out
   the lack of causality in machine learning books in the books above.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itiala.jpg"></p>
<p><b><a href="https://www.cambridge.org/au/academic/subjects/computer-science/pattern-recognition-and-machine-learning/information-theory-inference-and-learning-algorithms?format=HB&amp;isbn=9780521642989">Information Theory, Inference and Learning Algorithms</a> by David MacKay</b>
</p>
<p>i've seen this book mentioned a number of times and was most recently recommended by
   my colleague <a href="https://twitter.com/danesherbs">dane</a> so it's time to get it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/bmlpa.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/building-machine-learning/9781492045106/">Building Machine Learning Powered Applications</a> by Emmanuel Ameisen</b>
</p>
<p>a number of people i worked with have enjoyed this. first recommended by another
   colleague <a href="https://twitter.com/davidcolls">dave</a>.
   looks to be on the practical side rather than the theory but that's ok some times :)
</p>

  </div></div>]]>
            </description>
            <link>http://matpalm.com/blog/cool_machine_learning_books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031455</guid>
            <pubDate>Mon, 09 Nov 2020 04:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does the event loop work in JavaScript? [video]]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25031384">thread link</a>) | @krayonatan
<br/>
November 8, 2020 | https://yonatankra.com/how-does-the-event-loop-work/ | <a href="https://web.archive.org/web/*/https://yonatankra.com/how-does-the-event-loop-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary"><main id="main" role="main"><article id="post-599"><div><!-- .entry-meta --><div> <p><span><span>Estimated Reading Time: </span> <span>&lt; 1</span> <span>minute</span></span></p><figure><p><span><iframe width="640" height="360" data-src="https://www.youtube.com/embed/Nqx3rtv_dko?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p><figcaption>The event loop and your code talk from WarsawJS</figcaption></figure><p>On august 2020 I spoke at <a rel="noreferrer noopener" href="https://warsawjs.com/" data-type="URL" data-id="https://warsawjs.com/" target="_blank">WarsawJS</a>, explaining about the event loop and how it works.  I hope you will enjoy this talk.</p><p>If you prefer to read – <a href="https://yonatankra.com/the-event-loop-and-your-code/" data-type="post" data-id="299">here’s the blog post this talk is based on</a>.</p><p id="jp-relatedposts"><h3><em>Related</em></h3></p></div><!-- .entry-content --><!-- .entry-footer --></div></article><!-- #post-## --><p><h3>Enjoyed the article?</h3><h4>Sign up to my newsletter to enjoy more content:</h4></p>  <nav role="navigation" aria-label="Posts"><h2>Post navigation</h2></nav><!-- #comments --></main><!-- #main --></div></div>]]>
            </description>
            <link>https://yonatankra.com/how-does-the-event-loop-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031384</guid>
            <pubDate>Mon, 09 Nov 2020 04:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fun website that simulates fluid]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25031304">thread link</a>) | @svikashk
<br/>
November 8, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/ | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031304</guid>
            <pubDate>Mon, 09 Nov 2020 03:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attention Is My Most Valuable Asset for Productivity as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 630 | Comments 246 (<a href="https://news.ycombinator.com/item?id=25030938">thread link</a>) | @zwbetz
<br/>
November 8, 2020 | https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/ | <a href="https://web.archive.org/web/*/https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
      <div>
        <div>
          <div>
            
  
  
  <p>
    
    
    
    <strong>Published: </strong>2020-11-08

    
    
      
      
        • <strong>Lastmod: </strong>2020-11-09

      
    
    
    
    
      <br>
      <span>
        <strong>Tags: </strong>
        
          
          
          
        
          
          
          
        
          
          
          
        
        <a href="https://zwbetz.com/tags/life/">life</a> • <a href="https://zwbetz.com/tags/attention/">attention</a> • <a href="https://zwbetz.com/tags/productivity/">productivity</a>
      
    </span>
  </p>
  
  
  
  

<p>Like a tightly written function, I prefer to exit early if no work should be done. So, if you disagree with these definitions and assumptions, now’s a good time to stop reading.</p>
<ul>
<li><strong>Sustainable productivity:</strong> The maximum rate of quality work output, without loss to the wellbeing of the developer</li>
<li><strong>Quality work:</strong> Software that meets requirements, is valuable to users, is maintainable, and is as bug free as possible</li>
<li><strong>Attention:</strong> The limited mental capacity to focus on a task</li>
<li>Sustainable productivity is desired</li>
<li>Attention is essential to sustainable productivity</li>
</ul>
<p>My high-level workflow looks something like this: identify the problem to solve; think on the problem and let ideas percolate; research, discuss, and experiment with these ideas; implement and test the solution; deliver and maintain the solution.</p>
<p>This cycle could repeat many times in a day. Or I could spend days stuck on a single cycle step. Every step in this cycle requires attention. The more attention I can devote, the more cycles I can complete, and the more productive I am.</p>
<p>How long you can focus on a task varies by person. Some people are very good at it out of the box, some people, not so much. Regardless of the hand you were dealt, I believe that focus (the act of devoting your attention) is a skill, and like any skill, can be improved with practice.</p>
<p>So, how can you increase your attention reserves? The most bang for your buck is to organize your outside world in such a way that it’s distraction free as possible. Once you do that, you’ll have more time to practice, and therefore more time to get better.</p>
<p><strong>Build physical strength.</strong> The damage done by sitting 8+ hours a day is underrated. You need a way to offset this damage, especially if you plan to work in this field for decades. Opinions abound on this topic, but I personally prefer deadlifts. There are few movements more primal than picking a heavy object off the ground and standing up with it. You can <a href="https://www.youtube.com/watch?v=wYREQkVtvEc">learn correct technique in little time</a>. I most like deadlifts because you can do them safely, at high weights, into old age. I also like the hand, back, and hip strength they give, to make it that much harder for sitting damage to have its way with you.</p>
<p><strong>Make your place of work boring and tidy.</strong> My office is a spare bedroom. The walls are blank. There’s no tv. There’s a desk, chair, laptop, laptop stand, keyboard, mouse, and mouse pad. There’s a window, which lets enough light in so that I don’t feel like I’m missing a beautiful day, but not too much light to cause screen glare. If I need to work with paper, it’s immediately filed somewhere when done. Like I said, boring and tidy.</p>
<p><strong>Make your smart phone dumb.</strong> My phone has all notifications disabled, except for calls and text messages. Well, and National Hurricane Center alerts, since I live in Louisiana. Unless you’re my wife, you know that I don’t respond to text messages immediately, that’s just how it is. I disabled my social media accounts some time ago. But if you have them, turning off notifications should help curve the urge to compulsively check them.</p>
<p><strong>Be an OS minimalist.</strong> Apps I use less commonly are a keypress combo away. Given this, my dock has only the apps I use on a daily basis:</p>
<ul>
<li>File system explorer</li>
<li>Internet browser</li>
<li>Terminal</li>
<li>Text editor for front-end code and notes</li>
<li>IDE for back-end code</li>
<li>IDE for database</li>
<li>Visual file differ for version control</li>
<li>Email client</li>
<li>Instant message client</li>
</ul>
<p>My desktop alternates between clean and dirty states. Files I’m currently working with live on the desktop. Then they’re filed away into sensible folders when done.</p>
<p><strong>Organize your browser bookmarks.</strong> When I read something useful that I may need to reference later, I file it under a general archive folder. Then more specific items get their own folders. Frequently accessed links are visible on my bookmarks bar under their own folder.</p>
<p><strong>Minimize meetings.</strong> Look, I know some things make sense to discuss face to face, or voice to voice. But if they don’t, then you don’t need a meeting. An email or instant message will suffice.</p>
<p><strong>Finally, use the <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a> to categorize your tasks.</strong> Imagine a grid of 4 quadrants:</p>
<ul>
<li>Important and Urgent</li>
<li>Important and Not Urgent</li>
<li>Not Important and Urgent</li>
<li>Not Important and Not Urgent</li>
</ul>
<p>Important and Urgent tasks have to be dealt with. For me, these are usually major production issues.</p>
<p>Important and Not Urgent tasks should absorb the bulk of your time. For me, this is the plain old development work of implementing features, fixing bugs, and making existing code more maintainable and performant. Also included are building relationships with others and planning ahead.</p>
<p>Not Important and Urgent tasks are nasty attention thieves. They shout out to you in immediacy, but offer little value in return. You know what these are for you. For me, these are most often lazily asked questions, where the asker did not do their due diligence, and expects a top-notch answer immediately. Also included are last-minute meetings, and over-talkative coworkers.</p>
<p>Not Important and Not Urgent tasks are usually not known to your users. Take internal documentation updates as an example. Thing is, they’re an investment in yourself, which means a more productive future “you”. So don’t forget to show them some love in your spare moments.</p>
<p><strong>Further reading.</strong> If you don’t know who Cal Newport is, you’re missing out. He has a whole blog dedicated to this type of thing, and has written books such as <em>Deep Work</em> and <em>Digital Minimalism</em>. Here are some of my favorite articles by him:</p>
<ul>
<li><a href="https://www.calnewport.com/blog/2009/02/04/have-we-lost-our-tolerance-for-a-little-boredom/">Have We Lost Our Tolerance For a Little Boredom?</a></li>
<li><a href="https://www.calnewport.com/blog/2010/06/10/is-allowing-your-child-to-study-while-on-facebook-morally-equivalent-to-drinking-while-pregnant/">Is Allowing Your Child to Study While on Facebook Morally Irresponsible?</a></li>
<li><a href="https://www.calnewport.com/blog/2008/04/07/monday-master-class-how-to-reduce-stress-and-get-more-done-by-building-an-autopilot-schedule/">Monday Master Class: How to Reduce Stress and Get More Done By Building an Autopilot Schedule</a></li>
<li><a href="https://www.calnewport.com/blog/2009/11/24/are-passions-serendipitously-discovered-or-painstakingly-constructed/">Are Passions Serendipitously Discovered or Painstakingly Constructed?</a></li>
<li><a href="https://www.calnewport.com/blog/2018/06/08/jerry-seinfelds-closed-door/">Jerry Seinfeld’s Closed Door</a></li>
</ul>



  
  
  

  
  




          </div>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030938</guid>
            <pubDate>Mon, 09 Nov 2020 02:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Windows 10 Installer Dystopia]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25030752">thread link</a>) | @brenns10
<br/>
November 8, 2020 | https://brennan.io/2020/11/08/windows-10-nightmare-edition/ | <a href="https://web.archive.org/web/*/https://brennan.io/2020/11/08/windows-10-nightmare-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan • 08 November 2020</em></p><p>A few days ago I had the displeasure of helping a friend reinstall Windows on
their laptop, which had previously contained Ubuntu. The reason for their switch
isn’t that important – although I helpfully suggested keeping Linux, it was
their machine and their decision. I didn’t expect the process to be particularly
difficult. After all, I work on operating systems for a living now, so I didn’t
expect any trouble. But to my surprise, I encountered a nearly dystopian
situation before I even got to the desktop.</p>

<p>I started the process by creating a bootable USB from the ISO downloaded from
Microsoft’s <a href="https://www.microsoft.com/en-us/software-download/windows10ISO">download page</a>. It feels weird writing that, but yes, the ISO
seems to be freely, easily downloaded. No product key was required to download,
or even install. The USB creation process was not easy (Microsoft suggests using
Windows to create the bootable USB, a chicken-and-egg problem if ever there was
one). It seems that the standard <code>dd</code> process used by every Linux vendor does
not work here – instead you need to get the correct magic incantations of
partition types and filesystems, and then copy files from the ISO file into the
USB. I ended up falling back to a tool called <a href="https://github.com/slacka/WoeUSB">WoeUSB</a> to do this process,
after three failed manual attempts.</p>

<p>The real fun started after I (finally) successfully booted from the USB and
started through the installation wizard. Cortana loudly greeted me, telling me
she’d walk me through the installation process using my voice. I must say that,
while I don’t really care to have a voice assistant guide me through OS
installation, I can see it helping a lot of folks out there, if it works
properly (I did not test it). I’m glad that Microsoft is at least trying this
out!</p>

<p>I went through the (impressively quick) installation process, and the laptop
automatically rebooted. It prompted me to connect to the Internet, which I
foolishly did. Directly after connecting to WiFi, the wizard asked me to login
with a Microsoft account!</p>

<p>I chuckled internally. “Classic Microsoft, asking for a silly cloud login just
to use Windows,” I thought. I don’t know my friend’s MS account login, and even
if I did I wouldn’t link their OS account to some cloud account!</p>

<p>I searched for the cancel button, but couldn’t find one. I tried to submit the
form with empty username and password, but that didn’t work. Realizing that I
might be trapped, I got my phone and fired up Google.  Surely, Microsoft
wouldn’t make it <em>impossible</em> to setup a new PC without linking it to their
cloud, right?</p>

<p>I found an <a href="https://helpdeskgeek.com/windows-10/how-to-setup-windows-10-without-a-microsoft-account/">article</a> which said that, by disabling the Internet connection I
had just configured, I could skip the login process. So, I hit the back button
on the installer. The wizard animated for a moment as if it was working, and
then showed me the same login screen. No matter how many times I hit the back
button, the wizard did not let me go back to the Internet configuration page!</p>

<p>“They haven’t got me yet,” I thought. I held down the power button and rebooted
the computer. Certainly on reboot I would restart the process, and could skip
the Internet configuration, right?</p>

<p>The laptop rebooted to a Microsoft Account login page.</p>

<p>So, I did what any self-respecting, conscientious friend would do for a friend:
<strong>I reinstalled Windows all over again.</strong>  This time, during the setup wizard
after the reboot, I skipped configuring an Internet connection. I was greeted
with this page:</p>

<p><img src="https://brennan.io/images/win10-nointernet.png" alt="win10-nointernet"></p>

<p>This, to me, felt kind of chilling. After all, it’s not like I asked not to use
a MS account. All I did was decide not to configure Internet on my first boot,
which has nothing to do with linking a MS account. After all, maybe I just don’t
have Internet access at the moment, or maybe I forgot the WiFi password.  Why
should the installer lecture me about the benefits of a MS account when simply I
did not configure WiFi? It felt obvious that this was a bald-faced statement:
“we know you’re avoiding our login process, and in a few years we’ll get rid of
this loophole too. Welcome to the future!”</p>

<p>I clicked the text (which wasn’t highlighted as a link or as a button) which
said “Continue with limited setup”. This was an odd phrasing, given that none of
the operating system features I’m familiar with (scheduling processes, providing
a unified interface to hardware devices, etc) requires a cloud account.</p>

<p>At this point, I was allowed to create a “local account” for my friend, and
finish the setup. I was presented with a list of preferences, all helpfully
enabled by default:</p>

<p><img src="https://brennan.io/images/win10-privacy.png" alt="win10-privacy"></p>

<p>The irony here is beautiful. Ads “may be less relevant to you”. The only entity
this harms is Microsoft, being able to avertise at you less (within your very
<em>operating system</em>, no less). Why should they bill this as a negative?</p>

<p>After disabling all of the toggles, the desktop loaded for the first time, I
noticed the following at the bottom right:</p>

<p><img src="https://brennan.io/images/win10-edge.png" alt="win10-edge"></p>

<p>I used MS Edge to install Firefox, and closed it out. On reboot, the login
screen contained two advertisements (!!!) for MS Edge. I returned the laptop to
my friend, grateful I didn’t have to use this horror show of an operating
system.</p>

<h2 id="why-does-this-even-matter">Why does this even matter?</h2>

<p>I spend my workday working on operating systems. Don’t get me wrong, I’m new to
the field, and I have a lot to learn. But as far as I know, <strong>there is no
feature in a modern operating system which requires a cloud account login.</strong> (I
would love to be educated if this claim is false, please get in touch!)</p>

<p>I used to spend my career working on machine learning and data analysis. One
thing I remember from my “past life” is that <strong>there’s nothing better than
linking different types of identifiers together.</strong> If Microsoft can track you by
your “Windows installation ID” and also by your “Microsoft Account”, then <em>of
course</em> they want to link those two identifiers together.</p>

<p>More links means more data about you. What applications you run, what sites you
visit, etc. An operating system as at the root of what you trust when you use a
computer. Do you use online banking? Your operating system can read the password
to your bank account, the balances, and more, directly out of memory! I’m not
suggesting that Windows does that – I just want to illustrate the sort of trust
you implicitly use every time you login to your bank account on Windows (or Mac
OS for that matter). But maybe Microsoft just looks at how frequently you login
to your computer, or what sites you’re interested in. What DNS queries does your
OS resolve? What IP addresses have you used in the last 90 days?</p>

<p>All of the data which is obvious to your operating system, can be linked to your
personal identity when you connect it to a cloud account. Don’t get me wrong,
even if you don’t connect it to a cloud account, you still are getting
incredible amounts of telemetry and tracking recording your every move. But why
would you voluntarily give more links and data to Microsoft?</p>

<p>I don’t think most people understand the sort of data they’re giving over to
Microsoft when they login and use Windows. These dark patterns that Microsoft
employs are sickeningly obvious, and really difficult to avoid. Why would I
trust a company that tries to manipulate its customers into such total data
collection, to be responsible with the data it receives?</p>

<p>I can’t imagine how frustrating it must be to be an operating system developer
at Microsoft. I have a lot of respect for the operating system kernel they make.
It seems to be one of the few major non-Unix like kernels out there. It seems
fascinating and I’d love to learn more about it. But it must be frustrating to
see the product of your hard work go out packaged with software capable of
collecting and tracking your users’ every move, and thrown together with an
installer intent on forcing them to submit to this data collection.</p>



<hr>



  
  

  </div></div>]]>
            </description>
            <link>https://brennan.io/2020/11/08/windows-10-nightmare-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030752</guid>
            <pubDate>Mon, 09 Nov 2020 02:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big-O]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030390">thread link</a>) | @dleskosky
<br/>
November 8, 2020 | https://www.danielleskosky.com/big-o/ | <a href="https://web.archive.org/web/*/https://www.danielleskosky.com/big-o/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Big-O"><div>
<div><figure><img loading="lazy" width="2240" height="1260" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/bigo-banner.png" alt="Big O Banner"></figure></div>


<p>Big-O is pretty important.&nbsp; It is the metric that is used to describe the efficiency of algorithms.&nbsp; Having a thorough understanding of Big-O is crucial for ensuring that algorithms are as efficient as possible.&nbsp; Let’s learn more about this fundamental computer science topic.</p>


<h2>What is Big-O?</h2>


<p>Imagine that there is a ship builder.&nbsp; Her name is Andrea.&nbsp; She makes big ships and small ships for a port city.&nbsp; She can make the small ships pretty quickly, but the bigger ships take longer.&nbsp; The amount of&nbsp;<strong>time</strong> that it takes her to build a ship is proportional to the&nbsp;<strong>size</strong> of the ship.&nbsp;&nbsp;</p>
<p>Andrea is also a pirate.&nbsp; She is known to steal other peoples’ ships.&nbsp; She usually does her pirating in a port town that is 10 days worth of travel by land and 5 days of travel back with the stolen ship, so 15 days round trip.&nbsp; The port town that she pirates from always has the ship size that she is looking for.&nbsp;</p>
<p>If a customer asks Andrea to build a ship, she has two options.&nbsp; She can either build the ship or she could put on her pirate hat and go steal a ship.&nbsp;&nbsp;</p>
<p>So if someone wants Andrea to build a ship for them, which option should Andrea choose?&nbsp; That’s right!&nbsp; It depends.</p>
<ul>
<li><strong>Build the Ship: O(s):</strong>&nbsp; where s is the size of the ship.&nbsp; This is <strong>linear</strong> time.&nbsp; The time that it takes to build the ship increases linearly depending on the size of the ship.&nbsp;</li>
<li><strong>Steal the Ship: O(1):&nbsp;&nbsp;</strong>this is <strong>constant</strong> time.&nbsp; It doesn’t matter how big or small the ship is.&nbsp; It will always take Andrea 15 days to get the ship back to the customer.&nbsp;&nbsp;</li>
</ul>
<p>So Andrea should build the ship if she can get it done in less than 15 days.&nbsp; If the ship is big enough that it would take longer than 15 days to build, then Andrea should go steal the ship.&nbsp;</p>
<p>On a side note, this blog does not condone stealing and Andrea should really rethink her life of crime.</p>
<p>Here is a graph that represents the relationship between linear O(s) and constant O(1) time:</p>


<div><figure><img loading="lazy" width="532" height="484" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/constant-linear.png" alt="Constant v linear"></figure></div>


<p>There are many more possible runtimes that can occur besides linear and constant.&nbsp; Here is a graph that shows some of the more commonly-used runtimes:</p>


<figure><img loading="lazy" width="1618" height="1130" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/complexity-chart.png" alt="Complexity Chart"></figure>


<p>The above complexity chart comes from the <a href="https://www.bigocheatsheet.com/" target="_blank" rel="noopener noreferrer">Big-O Cheatsheet</a> website.&nbsp; Definitely a useful resource!</p>


<h2>The Three Cases</h2>


<p>Let’s use quick sort as an example.&nbsp; Quick sort picks a random element as a pivot and then swaps the values so that the elements less than the pivot appear before the elements that are greater than the pivot.&nbsp; Then it uses recursion to further sort the left and right sides.&nbsp; Learn more about quick sort <a href="https://www.geeksforgeeks.org/quick-sort/" target="_blank" rel="noopener noreferrer">here</a>.</p>
<ul>
<li><strong>Best Case:</strong>&nbsp; The best case means that the algorithm is given the most ideal data.&nbsp; If all elements are equal in the array then quick sort will just have to traverse the array once.&nbsp; Traversing an array of <strong>N</strong> elements will give a runtime of&nbsp;<strong>O(N)</strong>.</li>
<li><strong>Worst Case:</strong>&nbsp; The worst case means that the algorithm is given the least ideal data.&nbsp; With quick sort, it could happen that the pivot is repeatedly the biggest element in the array.&nbsp; If this were to happen then instead of the subarray being recursively divided in half each time, the subbarray would only be reduced by one element.&nbsp; This would give a runtime of&nbsp;<strong>O(<b><i>N</i><sup>&nbsp;2</sup></b>)</strong>.</li>
<li><strong>Expected Case:</strong>&nbsp; Typically instead of having a worst case or a best case you are more likely to have an expected case.&nbsp; Sometimes the pivot will be high and sometimes the pivot will be low, but over time they will average each other out.&nbsp; This will give a runtime more close to&nbsp;<strong>O(N log N)</strong>.</li>
</ul>
<p>The best case runtime usually isn’t of too much interest when analyzing an algorithm.&nbsp; The&nbsp;<strong>worst</strong> and&nbsp;<strong>expected&nbsp;</strong>cases are the ones that need to be considered.</p>


<h2>Space Complexity</h2>


<p>Space complexity is used to describe the total amount of memory that an algorithm uses in respect to the input size of the algorithm.&nbsp;&nbsp;</p>
<p>If an algorithm requires an array of size <em>n</em>, this will require O(n) space.&nbsp; If there is a two dimensional array of size&nbsp;<em>n </em>by <em>n, </em>then O(n<sup>2</sup>) space is required.</p>


<h2>Some Useful Big-O Tips</h2>


<p>There are a couple of tips that you should keep in the back of your mind when you are working on finding the Big-O.&nbsp; Here they are:</p>
<ul>
<li><strong>No constants</strong></li>
<li><strong>No non-dominant terms</strong></li>
<li><strong>Consider multiple runtimes</strong></li>
</ul>


<h2>No Constants</h2>


<p>With Big-O time the constants are not taken into consideration.&nbsp;</p>
<blockquote>
<p>Big-O notation doesn’t care about constants because Big-O notation only describes the long-term growth rate of functions, rather than their absolute magnitudes.”&nbsp;&nbsp;</p>
</blockquote>
<p>An algorithm that might seem to be <em>O(2N)</em> is actually only <em>O(N).&nbsp; </em>Here is a <a href="https://stackoverflow.com/questions/22188851/why-is-the-constant-always-dropped-from-big-o-analysis#:~:text=Big%2DO%20notation%20doesn't,rather%20than%20their%20absolute%20magnitudes.&amp;text=A%20function%20whose%20runtime%20is%20n2%20%2F%202%20will%20be,runtime%20is%20just%20n2." target="_blank" rel="noopener noreferrer">Stack Overflow post</a> that does a pretty good job of describing it.&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>The runtime is O(array.length) or O(N).&nbsp;</p>
<p>Let’s take look at some more code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
}
for (int x : array) {
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>Your first intuition might to be assume that because there are two for loops that iterate the length of the array that the runtime must be O(2N).&nbsp; Don’t fall into this trap!&nbsp; The runtime is O(N).&nbsp; Remember to drop the constant!</p>


<h2>No Non-Dominant Terms</h2>


<p>What if you get a runtime like O(<i>N</i><sup>&nbsp;2</sup> + N)?&nbsp; What should we do then?&nbsp; Well, if you were able to deduce that we should drop the non-dominant term, then congratulations!&nbsp;&nbsp;</p>
<p>Consider the runtime O(<i>N</i><sup>&nbsp;2</sup> + <i>N</i><sup>&nbsp;2</sup>).&nbsp; This is the same as O(2<i>N</i><sup>&nbsp;2</sup>).&nbsp; We know that we should not include constants in our runtimes.&nbsp; So if one of the <i>N</i><sup>&nbsp;2</sup> terms is ignored then we can ignore the N in O(<i>N</i><sup>&nbsp;2</sup> + N) as well.&nbsp;&nbsp;</p>
<ul>
<li>O(<i>N</i><sup>&nbsp;2</sup> + N) becomes O(<i>N</i><sup> 2</sup>).</li>
<li>O(N + logN) becomes O(N).</li>
<li>O(5*2<sup>N</sup> + 1000N<sup>100</sup>) becomes O(2<sup>N</sup>).</li>
</ul>


<h2>Consider Multiple Runtimes</h2>


<p>If we had to iterate through two arrays of the same length N then we could say that the runtime was O(N) (remember to drop constants!).&nbsp; However what happens if the arrays are of different lengths?&nbsp;&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">for (int a : arrA) {
    print(a);
}

for (int b : arrB) {
    print(b);
}
</pre>

<p>We are iterating through two arrays of different lengths.&nbsp; The runtime is O(A + B).&nbsp; Both runtime lengths must be considered!</p>
<p>Let’s take a look at some more code:</p>

<pre title="">for (int a : arrA) {
    for (int b : arrB) {
        print(a + "," + b);
    }
}
</pre>

<p>If the arrays were of equal length we could say that the runtime was O(<i>N</i><sup>&nbsp;2</sup>).&nbsp; However, the arrays are different lengths.&nbsp; This means that for every element of A, arrB will be iterated through.&nbsp; This results in a runtime of <br>O(A * B).</p>


<h2>Thanks!</h2>


<p>Thanks for reading my post.&nbsp; I hope that you found it useful.&nbsp; Once you understand the material presented here, be sure to continue your learning about Big-O.</p>
<p>Here are some topics that you should explore next:</p>
<ul>
<li><a href="https://hackernoon.com/what-does-the-time-complexity-o-log-n-actually-mean-45f94bb5bfbf" target="_blank" rel="noopener noreferrer">Log N Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/time-complexity-recursive-functions/" target="_blank" rel="noopener noreferrer">Recursive Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/amortized-time-complexity-analysis/" target="_blank" rel="noopener noreferrer">Amortized Time</a></li>
</ul>
<p>Thanks again!</p><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.danielleskosky.com/big-o/"
    dc:identifier="https://www.danielleskosky.com/big-o/"
    dc:title="Big-O"
    trackback:ping="https://www.danielleskosky.com/big-o/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://www.danielleskosky.com/big-o/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030390</guid>
            <pubDate>Mon, 09 Nov 2020 00:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping the Underground: Supervised Discovery of Cybercrime Supply Chains [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25030329">thread link</a>) | @stjo
<br/>
November 8, 2020 | https://damonmccoy.com/papers/ecrime2019.pdf | <a href="https://web.archive.org/web/*/https://damonmccoy.com/papers/ecrime2019.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://damonmccoy.com/papers/ecrime2019.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030329</guid>
            <pubDate>Mon, 09 Nov 2020 00:23:34 GMT</pubDate>
        </item>
    </channel>
</rss>
