<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 06 Nov 2020 00:50:39 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 06 Nov 2020 00:50:39 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Introduction to Google Cloud Functions]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24987197">thread link</a>) | @adrianancona
<br/>
November 4, 2020 | https://ncona.com/2020/11/introduction-to-google-cloud-functions/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/11/introduction-to-google-cloud-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Cloud Functions are Google’s offering for serverless architecture (similar to AWS lambdas).</p>

<h2 id="what-is-serverless">What is serverless?</h2>

<p>Before we look into how to use Cloud Functions, we should understand some things about it.</p>

<p>Code needs servers to run, so <code>serverless</code> doesn’t mean there are no servers, it means that we don’t need to manage those servers ourselves.</p>

<p>In a usual server based architecture, we might create a service and deploy it to a machine. This service will be running in the machine all the time waiting for requests. This has the disadvantage that even if there are no requests, the machine would need to be up, and incurring cost.</p>

<p>On the other hand, if we use Cloud Functions, we write a service and register it with Google. Google will then listen to the endpoint this service cares about and will only start it when there are requests. If it detects that there haven’t been requests for some time, it will stop the service again.</p>

<!--more-->

<p>While Google Compute Engine instances are billed by time, Cloud Functions are billed by execution time. If a Cloud Function is not being executed, then it is not being billed. This sounds very attractive, but there are draw backs, namely:</p>

<ul>
  <li>Running a Compute Engine instance for a full month is most of the time cheaper than having a Cloud Function executing for one month straight. This means that if we need a service to be always doing work, it’s better to get a whole machine for it.</li>
  <li>Cloud Functions need to warm up. If a Cloud Function hasn’t been used for a while, Google will stop the server that was running it. Next time we get a new request, a new server needs to be started, which takes some time. This will make this first request take long (This time varies a lot, but usually less than 4 seconds)</li>
</ul>

<p>For these reasons, serverless shouldn’t be used in all scenarios.</p>

<h2 id="creating-a-cloud-function">Creating a Cloud Function</h2>

<p>To make it easy to work on our Cloud Function, we need a way to run the function from our development machine.</p>

<p>Let’s start by creating a module:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>mkdir test-functions
cd test-functions
go mod init test.com/functions
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now, we can create a file for our function:</p>



<p>With this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>package</span> <span>functions</span>

<span>import</span> <span>(</span>
	<span>"net/http"</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>DoYouLikeTacos</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Of course I like tacos!</span><span>\n</span><span>"</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To be able to test our functions from our development machine, we need to create a server. Let’s create a file for it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>mkdir cmd
touch cmd/main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And add this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
  <span>"log"</span>
  <span>"context"</span>
  <span>"github.com/GoogleCloudPlatform/functions-framework-go/funcframework"</span>
  <span>"test.com/functions"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>ctx</span> <span>:=</span> <span>context</span><span>.</span><span>Background</span><span>()</span>

  <span>// Our function will be executed when a request to /do-you-like-tacos is received</span>
  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>RegisterHTTPFunctionContext</span><span>(</span>
      <span>ctx</span><span>,</span> <span>"/do-you-like-tacos"</span><span>,</span> <span>functions</span><span>.</span><span>DoYouLikeTacos</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.RegisterHTTPFunctionContext: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>

  <span>// The server will run on port 8080</span>
  <span>port</span> <span>:=</span> <span>"8080"</span>
  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>Start</span><span>(</span><span>port</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.Start: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To run the server:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd cmd
go run main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Once the server is running, we can use curl to test it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl localhost:8080/do-you-like-tacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The output should be:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>Of course I like tacos!
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This example is very simple, but we can have our fucntion do whatever we want.</p>

<p>We can also add more functions by adding more files and updating our <code>main.go</code> server. Let’s create another function just to show it.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd ..
touch cerveza.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>package</span> <span>functions</span>

<span>import</span> <span>(</span>
	<span>"net/http"</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>Thirsty</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Cerveza, por favor</span><span>\n</span><span>"</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And add this to <code>cmd/main.go</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>RegisterHTTPFunctionContext</span><span>(</span>
      <span>ctx</span><span>,</span> <span>"/thirsty"</span><span>,</span> <span>functions</span><span>.</span><span>Thirsty</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.RegisterHTTPFunctionContext: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Run the server:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd cmd
go run main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And hit the new url:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl localhost:8080/thirsty
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="deploying-to-google-cloud">Deploying to Google Cloud</h2>

<p>Once we have our functions ready, we want to make them available to the public by deploying them to Google Cloud.</p>

<p>From the root of our project we can use this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gcloud functions deploy DoYouLikeTacos \
    --runtime go113 --trigger-http --allow-unauthenticated
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will spit out a bunch of information. The most important part is the URL:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>httpsTrigger:
  url: https://us-central1-proj-1234567.cloudfunctions.net/DoYouLikeTacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can curl this endpoint, the same way we did for our local endpoint:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl https://us-central1-proj-1234567.cloudfunctions.net/DoYouLikeTacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Let’s take a closer look to the command we used to deploy our function:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gcloud functions deploy DoYouLikeTacos \
    --runtime go113 --trigger-http --allow-unauthenticated
</pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li><code>DoYouLikeTacos</code> is the name of the function we are deploying. The tool will search the package for a function with that name.</li>
  <li><code>--runtime go113</code> tells google to use Golang 1.13. We can see the available runtimes in the help (<code>gcloud functions deploy --help</code>)</li>
  <li><code>--trigger-http</code> means that an http endpoint will be assigned to the function</li>
  <li><code>--allow-unauthenticated</code> means that the function will be available for everybody without authentication. Note that the function code itself could expect some kind of authentication independently of this flag</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>This was a quick introduction to Google Cloud Functions. We learned how to create a function, test it locally and deploy it to Google Cloud.</p>

<p>Complete applications can be built using Cloud Functions, so I’ll explore a little more in another article.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/11/introduction-to-google-cloud-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987197</guid>
            <pubDate>Wed, 04 Nov 2020 08:04:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clean Code – Notes]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24986604">thread link</a>) | @wheresvic3
<br/>
November 3, 2020 | https://smalldata.tech/blog/2018/09/16/clean-code-notes | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2018/09/16/clean-code-notes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  The following is a list of notes taken on writing clean code, i.e. code that is maintainable and extensible.
</p>
<h5 id="names">Names</h5>
<p>
  Naming is the <i>hardest</i> and the most important part of writing clean code. Names should clearly express intent
  and the assumption here is that everyone involved in the codebase has the same cultural background which is not
  always the case in practice. Some general tips:
  </p><ul>
    <li>Classes should be Nouns, e.g. <code>User</code></li>
    <li>Methods should be verbs, e.g. <code>getById()</code>, <code>save()</code></li>
    <li>No need for prefixes such as <code>m_</code> or <code>str</code> for strongly typed languages</li>
    <li>Pick one word per concept, e.g. <code>fetch</code>, <code>retrieve</code> and <code>get</code> are
      semantically equal</li>
  </ul>

<h5 id="functions">Functions</h5>
<p>
  Functions or methods are the fundamental building blocks of programming. In fact, the internal operation of
  programs normally consists mostly of functions pushing data onto and popping data off the stack as they call each
  other. Sometimes memory needs to be allocated on the heap for data that must survive across function calls.
</p>
<p>
  When a function is called, a <strong>stack frame</strong> is created to support the function's execution. The stack
  frame contains the function's local variables and the arguments passed to the function by its caller. The frame
  also contains housekeeping information that allows the called function (the callee) to return to the caller safely.
  The exact contents and layout of the stack vary by processor architecture and function call convention.
</p>
<div>
  <p><a href="https://smalldata.tech/img/blog/call-stack-layout.svg">
      <img alt="An example of a call stack for the DrawLine function which is called by DrawSquare" src="https://smalldata.tech/img/blog/call-stack-layout.svg">
    </a>
  </p>
  
  <p>
    An example of a call stack for the <code>DrawLine</code> function which is called by <code>DrawSquare</code>.
  </p>
</div>
<p>
  Some general tips on writing functions:
  </p><ul>
    <li>Functions should be small and they should do 1 thing only:
      <ul>
        <li>Only have 1 level of indentation - highly nested functions should be refactored into sub-routines</li>
        <li>
          <strong>No side-effects!</strong>
          <pre>public int sum(int a, int b) {
    int result = a + b;
    resetGui(); // this is untestable and introduces a hidden dependency!
    return result;
}
</pre>
        </li>
      </ul>
    </li>
    <li>Do not return <code>null</code> - caller will need to always check cluttering p code, consider using <i>special
        case</i> return values</li>
    <li>Don't pass <code>null</code> as a parameter value either</li>
    <li>Prefer exceptions for error conditions except in cases were a <code>Nullable</code> or <code>Optional</code>
      type is available</li>
    <li>Should ideally return a value, especially for monadic functions as this allows function chaining</li>
    <li>Fewer arguments are better - the more the arguments, the more the complexity and test cases that need to be
      written</li>
  </ul>

<h5 id="oop">Object Oriented Programming</h5>
<p>
  An important but suble point to note in OOP is that objects hide their data behind abstractions and expose
  functions that operate on that data whereas data structures expose their data and have no meaningful functions.
  Good OOP requires knowing when to use objects and when to use data structures. Consider the following example:
  </p><pre>public class Point {
    public double x;
    public double y;
}

public interface Point {
    double getX();
    double getY();
    void setCartesian(double x, double y);
    double getR();
    double getTheta();
    void setPolar(double r, double theta);
}
</pre>
    <p>
      In the second <code>Point</code> definition the co-ordinate system being used by the implementation is not
      known and need not necessarily be cartesian nor polar!
    </p>
    <p>
      Tips on writing clean OO code:
      </p><ul>
        <li>Classes should be small and follow the Single Responsibility Principle (SRP)</li>
        <li>Classes should have high cohesion, i.e. operate on a small number of variables</li>
        <li>Avoid using boundary interfaces, e.g. instead of returning a <code>Map</code>, wrap it in a class (<code>Sensors</code>)
          to encapsulate the implementation</li>
        <li>Comments should only be used for clarification or amplification - avoid in general and let the code
          do the talking!</li>
        <li>Prefer exceptions to error codes - error codes have the habit of spilling out into the entire
          system</li>
        <li>Use unchecked exceptions to not break encapsulation</li>
      </ul>
    
    <p>
      Finally, procedural code makes it hard to add new data structures because all the functions must change. OO
      code makes it hard to add new functions because all the classes must change. Again, writing clean code
      requires insight as to when to use which style of programming.
    </p>
    <h5 id="tdd">Test Driven Development</h5>
    <p>
      Unit Tests should follow the F.I.R.S.T principle, i.e. they should be Fast, Independent of any external
      dependencies or manual setup, Repeatable, Self-validating (no manual checking verification) and Timely (run
      just before writing production code). Some general tips on writing clean tests:
      </p><ul>
        <li>Tests should be readable above all else and this might mean relaxing certain production code
          restrictions on performance</li>
        <li>Single concept per test</li>
        <li>Create helper methods to simplify complicated setups</li>
        <li>Convert multiple asserts into a single assert via a state pattern</li>
      </ul>
    

    <p>
      The three laws of TDD:
      </p><dl>
        <dt>First law</dt>
        <dd>You may not write production code until you have written a failing test.</dd><dt>Second law</dt>
        <dd>You may not write more of a test than is sufficient to fail, and not compiling is failing.</dd>
        <dt>Third law</dt>
        <dd>You may not write more production code than is sufficient to pass the currently failing test.</dd>
      </dl>
    

    <div>
      <p><a href="https://smalldata.tech/img/blog/011-clean-code.jpg">
        <img alt="" src="https://smalldata.tech/img/blog/011-clean-code.jpg">
      </a></p><p>
        Not quite TDD.
      </p>
    </div>

    <h5 id="system-design">System Design</h5>
    <ul>
        <li>Classes should follow the open-closed principle - open for extension but closed for modification.
          Consider the following example where we write an <code>AreaCalculator</code> which calculates the
          total area of a collection of rectangles.
          <pre>public class Rectangle {
    public double width;
    public double height;
}

public class AreaCalculator {

    public double calculateArea(Collection<rectangle> rectangles) {
        double result = 0;
        for (Rectangle r : rectangles) {
            result += r.width * r.height;
        }
        return result;
    }
}
</rectangle></pre> We would now like to extend this function to calculate the area of circles as well. Our new function now looks
          as follows:
          <pre>public abstract class Shape { }

public class Rectangle extends Shape {
    public double width;
    public double height;
}

public class Circle extends Shape {
    public double radius;
}

public class AreaCalculator {

    public double calculateArea(Collection<shape> shapes) {
        double result = 0;
        for (Shape s : shapes) {
            if (s instanceof Rectangle) {
                Rectangle r = (Rectangle) s;
                result += r.width * r.height;
            } else {
                Circle c = (Circle) s;
                result += c.radius * c.radius * Math.PI;
            }
        }
        return result;
    }
}
</shape></pre> Extending this further to calculate the area of triangles now requires another modification to the <code>calculateArea</code>
          method, i.e. it is not <strong>open for extension</strong>. We can change this by introducing an
          <code>area</code> method on the <code>Shape</code> data structure. Our code now looks like the
          following:
          <pre>public abstract class Shape {
    abstract double area();
}

public class Rectangle extends Shape {
    public double width;
    public double height;

    @Override
    public double area() {
        return width * height;
    }
}

public class Circle extends Shape {
    public double radius;

    @Override
    public double area() {
        return radius * radius * Math.PI;
    }
}

public class AreaCalculator {

    public double calculateArea(Collection<shape> shapes) {
        double result = 0;
        for (Shape s : shapes) {
            result += s.area(); // note the simplicity
        }
        return result;
    }
}
</shape></pre>
        </li>
        <li>Dependency Inversion Principle - depend upon abstractions and interfaces, not concrete
          implementations</li>
        <li>When building large software systems, try to avoid doing a big design up front - use a dependency
          injection container to separate cross-cutting concers like transactions, logging, etc. from
          business logic</li>
      </ul>
    
    <h5 id="references">References</h5>
    <ul>
        <li><a href="https://smalldata.tech/api/to/f838bf36866ac96dc70a088a5d559fb0">Clean Code - A handbook on agile software
            craftmanship</a></li>
        <li><a href="https://smalldata.tech/api/to/d0ed22ebb2bd98aa226ab833705aaa85">Explanation of the stack</a></li>
        <li><a href="https://smalldata.tech/api/to/779794f2469765d811744e656c1e09e2">Simple example of the Open Closed Principle</a></li>
      </ul>
    
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2018%2F09%2F16%2Fclean-code-notes&amp;t=Clean%20Code%20-%20Notes">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2018/09/16/clean-code-notes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986604</guid>
            <pubDate>Wed, 04 Nov 2020 05:35:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All systems go for UK’s £55M fusion energy experiment]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24986528">thread link</a>) | @danboarder
<br/>
November 3, 2020 | https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/ | <a href="https://web.archive.org/web/*/https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
						
			<div>
			
			
<article id="post-14051">
  
  <div>

		<div data-hide-featured-media="0">
      
        <div><p>Clean energy from fusion is a step closer with the launch of the MAST Upgrade tokamak.</p>
<div id="attachment_14062"><p><img aria-describedby="caption-attachment-14062" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgOTYwIDY0MCIgd2lkdGg9Ijk2MCIgaGVpZ2h0PSI2NDAiIGRhdGEtdT0iaHR0cHMlM0ElMkYlMkZjY2ZlLnVrYWVhLnVrJTJGd3AtY29udGVudCUyRnVwbG9hZHMlMkYyMDIwJTJGMTAlMkZnb3YudWtfLmpwZyIgZGF0YS13PSI5NjAiIGRhdGEtaD0iNjQwIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="MAST Upgrade first plasma" width="400" height="267" sizes="(max-width: 400px) 100vw, 400px"></p><p id="caption-attachment-14062">MAST Upgrade first plasma</p></div>
<p>For the first time, after a seven-year build, UKAEA’s £55M-machine, labelled <a href="https://ccfe.ukaea.uk/research/mast-upgrade/">Mega Amp Spherical Tokamak (MAST) Upgrade</a>, has achieved “first plasma” – where all the essential components work together simultaneously.</p>
<p>The project at Culham Centre for Fusion Energy was funded by the Engineering &amp; Physical Sciences Research Council, part of UK Research &amp; Innovation and the Department for Business, Energy &amp; Industrial Strategy.</p>
<p>Fusion energy offers the potential of an abundant, inherently safe low-carbon electricity supply (the raw materials are found in seawater and the Earth’s crust). It involves fusing hydrogen particles in a hot gas known as a ‘plasma’ to unlock large amounts of energy.</p>
<p>Operating fusion technologies requires a careful balancing act of controlling extreme heat, gas and powerful magnetic fields, amongst other complex systems.</p>
<h3>Super-X factor</h3>
<p>One of the biggest challenges in fusion research has been to extract the amount of excess heat from the plasma. UKAEA’s scientists now plan to test a new exhaust system called the ‘Super-X divertor’ at MAST Upgrade.</p>
<p>This system is designed to channel plasma out of the machine at temperatures low enough for its materials to withstand – meaning that components can last much longer. The approximate tenfold reduction in heat arriving at the internal surfaces of the machine has the potential to be a game-changer for the long-term viability of future fusion power stations.</p>
<h3>A step towards fusion power</h3>
<p>MAST Upgrade will be the forerunner of the UK’s prototype fusion power plant, <a href="https://ccfe.ukaea.uk/research/step/">Spherical Tokamak for Energy Production (“STEP”)</a>, due for completion by 2040.</p>
<p>STEP – which UKAEA is designing in an initial £220 million programme funded by the UK Government – will be based on MAST Upgrade’s ‘spherical tokamak’ fusion concept. The spherical tokamak could offer a route to a compact fusion power plant. The success of MAST Upgrade is another step along the way to designing future fusion power facilities, which could have an important role as part of a future portfolio of low-carbon energy.</p>
<p>MAST Upgrade will also aid preparations for <a href="https://www.iter.org/" target="_blank" rel="noopener noreferrer">ITER</a> – the world’s largest science megaproject, now being built in the South of France, which intends to demonstrate fusion power on an industrial scale.</p>
<p><iframe title="Shaping fusion power for the future - Mega Amp Spherical Tokamak Upgrade" width="1080" height="608" src="https://www.youtube.com/embed/PVUnOZwrSx8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>UK Science Minister, Amanda Solloway, said: “We want the UK to be a world leader in fusion energy and to capitalise on its amazing potential as a clean energy source that could last for hundreds of years.</p>
<p>“Backed by £55 million of government funding, powering up the MAST Upgrade device is a landmark moment for this national fusion experiment and takes us another step closer towards our goal of building the UK’s first fusion power plant by 2040.”</p>
<p>Commenting on the achievement of first plasma, UKAEA CEO, Professor Ian Chapman, said:</p>
<p>“MAST Upgrade will take us closer to delivering sustainable, clean fusion energy. This experiment will break new ground and test technology that has never been tried before. It ensures the UK is in the premier league of countries working on fusion – and will be vital in achieving UKAEA’s goal of building the STEP fusion power plant.”</p>
<p>Video of the first plasma on MAST Upgrade:</p>

</div>        
      </div><!--/post-content-->
      
    </div><!--/inner-wrap-->
    
</article>
		</div><!--/post-area-->
			
							
		</div></div>]]>
            </description>
            <link>https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986528</guid>
            <pubDate>Wed, 04 Nov 2020 05:01:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serendipity in a Remote World]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986523">thread link</a>) | @akhilkg
<br/>
November 3, 2020 | http://akhilkg.me/blog/serendipity | <a href="https://web.archive.org/web/*/http://akhilkg.me/blog/serendipity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p><strong>serendipity</strong></p>
<p> noun <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the occurrence and development of events by chance in a happy or beneficial way.<br>&nbsp;&nbsp;&nbsp; <em>”a fortunate stroke of serendipity"</em></p></div>
<p>I hadn't even heard of the word ‘serendipity’ before COVID and true to its nature - serendipity is events happening organically - by chance or "spontaneously".</p>
<p>In real life, we almost always fail to notice serendipity to put a word on it. I only came across the word when everything went remote and random interactions came to a full stop and now suddenly, something was missing. <br>
Obviously, it was other people.
But even with video calls, meetings, standups - it didn't feel right. </p>
<p>The truth is nothing can beat a real-life conversation with someone - not chat, audio or video. Maybe not even VR or holograms.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/97962688-b401eb00-1ddb-11eb-9903-2c485567e6e6.gif" alt="Silicon Valley GIF"></p><p><em>(Silicon Valley, S1E5)</em></p>
<hr>

<p>Random interactions in a fully remote world have to be forced. That’s just how we must play it now. But trying to duplicate in-person serendipity in a remote world - as is - might not be a great way out.</p>
<p>For instance, take the Qt World Summit this year which happened about a week ago:</p>
<p><img src="https://user-images.githubusercontent.com/32199592/97961622-ab101a00-1dd9-11eb-88b4-ab044cf9da5e.png" alt="qtws"></p><p><em>Reminds me of Club Penguin. Heh</em></p>
<p>I don’t know about you but to me, that looks extraordinarily distracting and borderline unnecessary. </p>
<p>Creating organic serendipity in a totally remote set up is a tough nut to crack - props to Qt for trying something new but to pretend that ‘online’ is the new ‘offline’ might not be the way to solve it. </p>
<p>On the same note though, multiplayer games are quite effective in the right context - simple, popular ones like <a href="http://www.innersloth.com/gameAmongUs.php">'Among Us'</a> can work both as an icebreaker and as a way to create organic interactions between a group of people and games have always been a source of a spontaneous group activity.</p>
<hr>
<br>
<h3>Embracing remote</h3>
<p><strong>The case of GitLab</strong></p>
<p><a href="https://about.gitlab.com/">GitLab</a> is an all remote company - right from the beginning as an open-source project - GitLab, in its initial days, was developed from contributors around the world. The GitLab team is now over 1,200 employees strong and Gitlab recently held its Series E round with $268M raised - and all of this without even having a physical office.</p>
<p>GitLab has an <a href="https://about.gitlab.com/company/culture/all-remote/">excellent handbook</a> on remote work, some key points - </p>
<h4>Regular engagement</h4>
<p>To simulate serendipity within a team - engage regularly on a weekly basis - in form of text or video. </p>
<p>Nothing beats seeing someone in person and the closest we can get to in-person meetings are video calls. Try to have regular video calls with your team - it might require some getting used to - to discuss something other than work but once you establish a flow, video calls are super effective.</p>
<p>Even an always-on video conferencing room or dedicated time slots for video/audio chat can also work wonders.</p>
<br>
<h4>Async</h4>
<p>Regarding work - asynchronous is preferred over synchronous communication.</p>
<p>Meetings are synchronous events - they require everyone at the same time.
Asynchronous events are things like chat/etc that do not require an immediate response.</p>
<p>An all remote culture means employees from all different timezones and so - meetings are only kept for the most important things and are also most of the times, optional. </p>
<p>Record the meetings, have an agenda, maintain the minutes, allow people to asynchronously contribute and don’t waste time.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/97961918-27a2f880-1dda-11eb-9a8d-8871b55cb778.png" alt="this meeting should have been an email"></p><h4>Role of text communication</h4>
<p>Most of remote communication happens through text and texting can get quite difficult at times - mainly because of the lack of non-verbals (like the lack of your facial expressions and tone when you are trying to tell a joke in chat but no one gets it)</p>
<p>"<em>Text communication can be easily derailed, and assumptions can lead to  good-mannered communiques being viewed as a slight.</em>"</p>
<p>Assume the best - don’t be an asshole.
From experience, when things start getting heated up on a text chat, jump immediately to a video call and straighten things up. Don’t keep it for later. </p>
<p>It’s really, really easy to get angry with someone’s stupid texts but when you see their face or hear their voice, that anger starts to dissipate ;)</p>
<br>
<hr>
<p>All in all, remote is tough and we need to intentionally create situations and design systems where we can interact organically and spontaneously.</p></div></div>]]>
            </description>
            <link>http://akhilkg.me/blog/serendipity</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986523</guid>
            <pubDate>Wed, 04 Nov 2020 04:59:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Months of Go from a Haskeller’s perspective]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24986132">thread link</a>) | @amzans
<br/>
November 3, 2020 | https://memo.barrucadu.co.uk/three-months-of-go.html | <a href="https://web.archive.org/web/*/https://memo.barrucadu.co.uk/three-months-of-go.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/BlogPosting" itemprop="mainEntity">
      

      <article>
        
<header>
  
</header>

<section itemprop="articleBody">
<p>This summer I’ve been interning at <a href="https://pusher.com/">Pusher</a>, and have been writing a lot of Go. It’s been a bit of a change coming from a Haskell background, so I decided to write up my thoughts now, at the end.</p>
<h2 id="the-good">The Good</h2>
<h3 id="incredibly-easy-to-pick-up">Incredibly easy to pick up</h3>
<p>There’s not a lot to Go, it’s quite a small language. I had never written a line of it before June, and now I’ve written about 30,000. It’s very easy to get started and become productive.</p>
<p>Haskell, on the other hand, is notorious for being hard to learn (<em>cough</em> monad tutorials <em>cough</em>). People often find it really hard to take the step from evaluating pure mathematical expressions to writing actual programs. I experienced no such disconnect in Go.</p>
<h3 id="garbage-collector-keeps-getting-better-and-better">Garbage collector keeps getting better and better</h3>
<p>Pusher previously tried to use Haskell for the project I was working on, but eventually had to give up due to unpredictable latency caused by garbage collection pauses. GHC’s garbage collector is <a href="https://blog.pusher.com/latency-working-set-ghc-gc-pick-two/">designed for throughput, not latency</a>. It is a generational copying collector, which means that pause times are proportional to the amount of live data in the heap. To make matters worse, it’s also stop-the-world.</p>
<p><a href="https://blog.golang.org/go15gc">Go’s garbage collector</a> is a concurrent mark-sweep with very short stop-the-world pauses, and it just seems to <a href="https://golang.org/doc/go1.7#performance">keep getting better</a>. This is definitely a good thing for a garbage collected language. We did have some issues with unacceptable latencies, but were able to work them all out. No such luck with the Haskell project.</p>
<h3 id="style-wars-are-a-thing-of-the-past">Style wars are a thing of the past</h3>
<p>Say what you like about <code>gofmt</code>, but it makes arguments over code style almost impossible. Just run it on save, and your code will always be consistently formatted.</p>
<p>I do find it a little strange that <code>gofmt</code> has been completely accepted, whereas Python’s significant whitespace (which is there for exactly the same reason: enforcing readable code) has been much more contentious across the programming community.</p>
<h2 id="the-neutral">The Neutral</h2>
<h3 id="code-generation-seems-to-be-the-accepted-solution-to-a-lot-of-problems">Code generation seems to be the accepted solution to a lot of problems</h3>
<p>I am not a huge fan of code generation (and I say this as <a href="https://blog.pusher.com/go-interface-fuzzer/">the author of a code generation tool</a>). I think it can do good, but it can also obscure what’s actually going on. In every discussion on Go generics, someone will come along and say you can add generics with code generation: that’s true, but at the cost of introducing additional, nonstandard, syntax.</p>
<p>I suspect the strong culture of code generation is largely because it lets you work around the flaws of the language.</p>
<h3 id="strict-not-lazy-evaluation">Strict, not lazy, evaluation</h3>
<p>Strict evaluation is typically better for performance than lazy evaluation (thunks cause allocation, so you’re gambling that <a href="https://www.barrucadu.co.uk/posts/2016-02-12-strict-vs-lazy.html">the computation saved offsets the memory cost</a>), but it does make things less composable. There have been a couple of times where I’ve gone to split up a function, only to realise that doing so would require allocating a data structure in memory which before was not needed.</p>
<p>I could trust the compiler to inline things for me, and so optimise away the additional allocations, but in a lazy language you just don’t have that issue at all.</p>
<h3 id="the-standard-library-is-not-so-great">The standard library is not so great</h3>
<p>If you know me in person, it might seem a little odd that I specifically comment on this. Normally I am all for languages having a small, really well-written, stdlib and everything else provided through libraries. I am picking on Go here a bit because the standard library seems to get a lot of praise, but I was unimpressed.</p>
<p>Parts of it are good, a lot of it is mediocre, and some of it is downright bad (like the <a href="https://golang.org/pkg/go/ast/">go/ast</a> package documentation). It seems a lot of Go’s use is in webdev, so perhaps those bits of the stdlib (which I haven’t touched at all) are consistently good.</p>
<h2 id="the-bad">The Bad</h2>
<p>I also agree with this Quora answer by Tikhon Jelvis to <a href="https://www.quora.com/Do-you-feel-that-golang-is-ugly">do you feel that golang is ugly?</a>, so have a look at that once you’ve read this section.</p>
<h3 id="a-culture-of-backwards-compatibility-at-all-costs">A culture of “backwards compatibility at all costs”</h3>
<p>In Go, you import packages by URL. If the URL points to, say, GitHub, then <code>go get</code> downloads HEAD of master and uses that. There is no way to specify a version, unless you have separate URLs for each version of your library.</p>
<p>This is just insane.</p>
<p>Go has a very strong culture of backwards compatibility, which I think is largely due to this. Even if you have a flaw in the API of your library, you can’t actually <em>fix</em> it because that would break all of your reverse-dependencies, unless they do vendoring, or pin to a specific commit.</p>
<p>Coming from the Haskell world, where the attitude is far more towards correctness than compatibility, this was probably the biggest culture shock for me. Things break backwards compatibility in Haskell, and the users just update their code because they <em>know</em> the library author did it for a reason. In Go, it just doesn’t happen <em>at all</em>.</p>
<h3 id="the-type-system-is-really-weak">The type system is really weak</h3>
<p>A common mantra in Haskell is “make illegal states unrepresentable,” which is great. If you’ve never come across it before it means to <em>choose your types such that an illegal value is a static error</em>. Want to avoid nulls? Use an option type. Want to ensure a list has at least one element? Use a nonempty list type. Use proper enums, not just ints. etc etc</p>
<p>In Go you just can’t do that, the type system isn’t strong enough. So a lot of things which are (or can be) a <em>compile-time</em> error in Haskell are a <em>runtime</em> error in Go, which is just worse.</p>
<p>Let’s pick on some specifics:</p>
<ul>
<li><p><strong>No generics</strong></p>
<p>Want to write a tree where every element is statically <em>guaranteed</em> to be the same type? Well, have fun implementing a “uinttree”, an “inttree”, a “stringtree”, and so on. You can’t just implement a generic tree.</p>
<p>But Go <em>does</em> have generics, for the built-in types. Arrays, channels, maps, and slices all have generic type parameters. So it seems that the Go developers want generics, but they don’t want to bother implementing it properly, so it remains a special case for a few things in the compiler.</p></li>
<li><p><strong>No sum types</strong></p>
<p>The way in Go to handle possibly-failing functions is to have multiple return values: an actual result, and an error. If the error is <code>nil</code>, then the actual result is sensible; otherwise the actual result is meaningless.</p>
<p>This means you can forget to check the error and use a bogus result and, because there are no compiler warnings (another wtf), you will know nothing of this until things fail at runtime.</p>
<p>With a sum type, like <code>Either error result</code>, that just can’t happen.</p></li>
<li><p><strong>No separation of pure code from effectful code</strong></p>
<p>It is very nice to know, just by looking at the type of a function, that it <em>cannot</em> perform any side-effects. Go’s type system doesn’t do that.</p></li>
</ul>
<h3 id="the-tooling-is-bad">The tooling is bad</h3>
<p>Haskell gets a lot of criticism for bad tooling, but I think it’s worlds ahead of Go in some cases.</p>
<ul>
<li><p><strong>Godoc makes it really difficult to write good documentation</strong></p>
<p>Godoc groups bindings by type, and then sorts alphabetically. Code is not written like that, code is written with related functions in proximity to each other. The source order is <em>almost always</em> better than how godoc sorts things.</p>
<p>Also, <a href="https://github.com/golang/go/issues/7873">godoc doesn’t even support lists</a>:</p>
<blockquote>
<p>Previous proposals similar to this have been rejected on grounds that it’s a slippery slope from this to Markdown or worse.</p>
</blockquote>
<p>I think that comment is particularly discouraging. Because the developers don’t like Markdown (and similar languages), they refuse to add even the most basic of formatting to godoc.</p></li>
<li><p><strong>There is nothing like GHC’s heap profiling</strong></p>
<p>Go has a snapshot-based memory profiler. You can take a snapshot at a point in time, and see which functions and types are taking up the heap space. However, there is <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html#profiling-memory-usage">nothing like this</a>.</p>
<p>Being able to see not only a snapshot, but also how things have changed over time, is incredibly useful for spotting memory leaks. If all you have is a snapshot, all you can really say is “well, the number of allocated <code>Foo</code>s looks a bit high, is that right?” With a graph you can say “the number of allocated <code>Foo</code>s is increasing when it shouldn’t be.”</p></li>
<li><p><strong>There is (was?) nothing like ThreadScope</strong></p>
<p><a href="https://wiki.haskell.org/ThreadScope">ThreadScope</a> is a tool for profiling performance of concurrent Haskell programs. It shows which Haskell threads are running on which OS threads, when garbage collection happens, and a bunch of other information.</p>
<p>If things are slower than expected, it’s great: you can see <em>exactly</em> how things are executing. Go doesn’t <em>currently</em> have anything like it, although towards the end of Dave Cheney’s <strong>Seven ways to profile Go applications</strong> talk at <a href="http://golanguk.com/">GolangUK</a>, he did whip out something which looked rather like ThreadScope (sadly, a video isn’t up at the time of writing, that I can see).</p></li>
</ul>
<h3 id="zero-values-are-almost-never-what-you-want">Zero values are almost never what you want</h3>
<p>Go avoids the issue of uninitialised memory by having “zero values”. If you declare a variable of type <code>int</code>, but don’t give it a value, it gets the value 0. Simple.</p>
<p>Except that that’s almost never what you want.</p>
<p>What is a sensible default value for a type? Well, it depends on what you’re using it for! Sometimes there isn’t a sensible default, and not initialising a value should be an error. You can’t define a zero value for your own types, so you’re kind of stuck.</p>
<p>Zero values caused so many problems over the summer, because everything would <em>appear</em> to be fine, then it suddenly breaks because the zero value wasn’t sensible for its context of use. Perhaps it’s an unrelated change that causes things to break (like a struct getting an extra field).</p>
<p>I would much rather:</p>
<ol type="1">
<li>Drop the syntax for declaring a variable without giving it a value.</li>
<li>Make it an error to not initialise a struct field.</li>
</ol>
<h3 id="lots-of-boilerplate">Lots of boilerplate</h3>
<p>The cause of the lots of code generation, I feel.</p>
<ul>
<li><p>Because you have to check error values, if you want to perform a sequence of possibly-erroring computations, where the successful result of one feeds into the next, there is a lot of typing. In Haskell, you’d just use the <code>Either</code> monad.</p></li>
<li><p>If you want to sort a slice, because there are no generics, you need to wrap the slice in another type and implement three methods on that type. So that’s four lines of code to sort a slice of uints, four lines to sort a slice of uint8s, …</p></li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memo.barrucadu.co.uk/three-months-of-go.html">https://memo.barrucadu.co.uk/three-months-of-go.html</a></em></p>]]>
            </description>
            <link>https://memo.barrucadu.co.uk/three-months-of-go.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986132</guid>
            <pubDate>Wed, 04 Nov 2020 02:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Programming Glossary]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24984318">thread link</a>) | @elierotenberg
<br/>
November 3, 2020 | https://elie.rotenberg.io/b/p/modern-programming-glossary | <a href="https://web.archive.org/web/*/https://elie.rotenberg.io/b/p/modern-programming-glossary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><i>Disclaimer: I spent a LOT of time browsing Github, and read a lot of READMEs. This post is a satire, and many great repos / landing pages feature some of the following idioms. I don't mean to offend dedicated maintainers &amp; docs writers, however funny I find dev-targeted marketing tropes.</i></p><p><i><a target="_blank" rel="noopener noreferrer" href="https://github.com/elierotenberg/rotenberg.io/blob/master/posts/modern-programming-glossary.md">Suggestions welcome!</a></i></p><h2><a id="table-of-contents" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#table-of-contents">Table of contents</a></h2><ul><li><a href="#accessible">Accessible</a></li><li><a href="#battle-tested">Battle-tested</a></li><li><a href="#blazingly-fast">Blazingly fast</a></li><li><a href="#bloated">Bloated</a></li><li><a href="#bleeding-edge">Bleeding edge</a></li><li><a href="#cloud-native">Cloud-native</a></li><li><a href="#cloud-ready">Cloud-ready</a></li><li><a href="#configurable">Configurable</a></li><li><a href="#cross-plaform">Cross-plaform</a></li><li><a href="#customizable">Customizable</a></li><li><a href="#entreprise-level">Entreprise-level</a></li><li><a href="#legacy-code">Legacy code</a></li><li><a href="#lightweight">Lightweight</a></li><li><a href="#mobile-first">Mobile-first</a></li><li><a href="#modern">Modern</a></li><li><a href="#modular">Modular</a></li><li><a href="#open-standards">Open standards</a></li><li><a href="#privacy-focused">Privacy-focused</a></li><li><a href="#production-ready">Production-ready</a></li><li><a href="#progressive-web-app">Progressive web app</a></li><li><a href="#responsive">Responsive</a></li><li><a href="#robust">Robust</a></li><li><a href="#scalable">Scalable</a></li><li><a href="#secure">Secure</a></li><li><a href="#serverless">Serverless</a></li><li><a href="#tiny">Tiny</a></li><li><a href="#well-tested">Well-tested</a></li><li><a href="#unified">Unified</a></li><li><a href="#typesafe">Typesafe</a></li><li><a href="#zero-dependencies">Zero-dependencies</a></li></ul><h2><a id="accessible" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#accessible">Accessible</a></h2><p><code>alt</code> attributes on <code>img</code> are encouraged. Some of our components allow <code>aria</code> attributes.</p><p><i>See also: <a href="#responsive">responsive</a>, <a href="#mobile-first">mobile-first</a></i></p><h2><a id="battle-tested" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#battle-tested">Battle-tested</a></h2><p>We used it for the docs website of the project and we haven't received any complains except for browers other than latest Chrome.</p><p><i>See also: <a href="#production-ready">production-ready</a>, <a href="#well-tested">well-tested</a>, <a href="#modern">modern</a></i></p><h2><a id="blazingly-fast" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#blazingly-fast">Blazingly fast</a></h2><p>Fast-enough on our latest-gen Macbook Pros and on the adhoc microbenchmark we have massaged into being faster than <em>&lt;similar project&gt;</em>. We don't support edge cases though.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#lightweight">lightweight</a></i></p><h2><a id="bloated" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#bloated">Bloated</a></h2><p>Handles edge cases we don't.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#lightweight">lightweight</a>, <a href="#tiny">tiny</a></i></p><h2><a id="bleeding-edge" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#bleeding-edge">Bleeding edge</a></h2><p>Only works in latest Chrome with experimental flags enabled and a custom <code>babel</code> plugin. Expect breaking changes without notice every 1-2 months.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#legacy-code">legacy code</a></i></p><h2><a id="cloud-native" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#cloud-native">Cloud-native</a></h2><p>We have written a <code>docker-compose.yml</code> file and it works on AWS. You need to pass secrets as environment variables.</p><p><i>See also: <a href="#cloud-ready">cloud-ready</a>, <a href="#scalable">scalable</a></i></p><h2><a id="cloud-ready" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#cloud-ready">Cloud-ready</a></h2><p>We provide a <code>Dockerfile</code>.</p><p><i>See also: <a href="#cloud-native">cloud-native</a>, <a href="#scalable">scalable</a></i></p><h2><a id="configurable" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#configurable">Configurable</a></h2><p>You will need to copy/paste a subfolder from our <code>examples</code> folder to run it.</p><p><i>See also: <a href="#modular">modular</a></i></p><h2><a id="cross-plaform" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#cross-plaform">Cross-plaform</a></h2><p>Laggy on all Web, Android, iOS and Electron. All versions include 20Mb of Node API polyfills.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#progressive-web-app">progressive web app</a></i></p><h2><a id="customizable" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#customizable">Customizable</a></h2><p>Our JSON configuration interpreter is Turing-complete.</p><p><i>See also: <a href="#configurable">configurable</a>, <a href="#modular">modular</a></i></p><h2><a id="entreprise-level" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#entreprise-level">Entreprise-level</a></h2><p>We provide paid support &amp; services.</p><p><i>See also: <a href="#cloud-native">cloud-native</a></i></p><h2><a id="legacy-code" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#legacy-code">Legacy code</a></h2><p>Code not written by us less than 3 month ago.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#bleeding-edge">bleeding-edge</a></i></p><h2><a id="lightweight" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#lightweight">Lightweight</a></h2><p>With 100Gbps network speed, it takes no more than several seconds to download in NA.</p><p><i>See also: <a href="#tiny">tiny</a>, <a href="#modern">modern</a>, <a href="#blazingly-fast">blazingly-fast</a></i></p><h2><a id="mobile-first" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#mobile-first">Mobile-first</a></h2><p>We have copy-pasted <code>&lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;</code> and it works on our Macbook Pros in latest Chrome emulating iPhone X.</p><p><i>See also: <a href="#mobile-first">mobile-first</a></i></p><h2><a id="modern" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#modern">Modern</a></h2><p>Written in a language we are familiar with, using our own linting conventions. Only works on latest Chrome. Expect breaking changes every 2-3 months.</p><p><i>See also: <a href="#bleeding-edge">bleeding edge</a>, <a href="#legacy-code">legacy code</a></i></p><h2><a id="modular" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#modular">Modular</a></h2><p>Code is spread over 10 different tighly-coupled packages. We expose a <code>plugin</code> configuration option that only accepts our own plugins. Expect breaking plugin API changes every 2-3 months.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#bleeding-edge">bleeding edge</a></i></p><h2><a id="open-standards" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#open-standards">Open standards</a></h2><p>We published the source code of our parser and wrote a README file that looks like an RFC.</p><p><i>See also: <a href="#modular">modular</a></i></p><h2><a id="privacy-focused" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#privacy-focused">Privacy-focused</a></h2><p>You may opt-out of automated backdoor analytics in both your config file and environment variables, and you must do so again every time you update.</p><p><i>See also: <a href="#secure">secure</a></i></p><h2><a id="production-ready" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#production-ready">Production-ready</a></h2><p>Not yet used in production.</p><p><i>See also: <a href="#enterprise-level">entreprise-level</a>, <a href="#modern">modern</a>, <a href="#well-tested">well-tested</a>, <a href="#battle-tested">battle-tested</a></i></p><h2><a id="progressive-web-app" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#progressive-web-app">Progressive web app</a></h2><p>We display a spinner while the 10Mb bundle is downloading.</p><p><i>See also: <a href="#responsive">responsive</a>, <a href="#lightweight">lightweight</a></i></p><h2><a id="responsive" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#responsive">Responsive</a></h2><p>We use <code>display: flex</code> instead of <code>display: block</code> and we have replaced <code>16px</code> with <code>1em</code>.</p><p><i>See also: <a href="#accessible">accessible</a>, <a href="#mobile-first">mobile-first</a></i></p><h2><a id="robust" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#robust">Robust</a></h2><p>It works on our machines.</p><p><i>See also: <a href="#well-tested">well-tested</a>, <a href="#battle-tested">battled-tested</a>, <a href="#production-ready">production-ready</a>, <a href="#enterprise-level">entreprise-level</a></i></p><h2><a id="scalable" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#scalable">Scalable</a></h2><p>You need a Kubernetes cluster with at least 3 nodes to serve your blog. We also provide paid hosting, by the way.</p><p><i>See also: <a href="#enterprise-level">enterprise-level</a>, <a href="#cloud-native">cloud-native</a>, <a href="#cloud-ready">cloud-ready</a></i></p><h2><a id="secure" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#secure">Secure</a></h2><p>We only use <code>eval</code> sparingly and we embed a 10Mb third party HTML sanitizer.</p><p><i>See also: <a href="#enterprise-level">entreprise-level</a>, <a href="#typesafe">typesafe</a></i></p><h2><a id="serverless" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#serverless">Serverless</a></h2><p>You need an AWS server to run it.</p><p><i>See also: <a href="#scalable">scalable</a>, <a href="#cloud-native">cloud-native</a>, <a href="#cloud-ready">cloud-ready</a></i></p><h2><a id="tiny" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#tiny">Tiny</a></h2><p>All code is inlined in a single 1k LOC file.</p><p><i>See also: <a href="#lightweight">lightweight</a>, <a href="#zero-dependencies">zero-dependencies</a></i></p><h2><a id="well-tested" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#well-tested">Well-tested</a></h2><p>We have written some tests and have more than 50% code coverage.</p><p><i>See also: <a href="#battle-tested">battle-tested</a>, <a href="#robust">robust</a>, <a href="#production-ready">production-ready</a></i></p><h2><a id="unified" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#unified">Unified</a></h2><p><a target="_blank" rel="noopener noreferrer" href="https://xkcd.com/927"><img src="https://imgs.xkcd.com/comics/standards.png" alt="Standards"></a></p><p><i>See also: <a href="#open-standards">open standards</a></i></p><h2><a id="typesafe" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#typesafe">Typesafe</a></h2><p>We have prefixed all occurences of <code>any</code> with <code>// eslint-ignore-next-line</code>.</p><p><i>See also: <a href="#secure">secure</a></i></p><h2><a id="zero-dependencies" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#zero-dependencies">Zero-dependencies</a></h2><p>Our dependencies are embeded in a <code>vendor</code> folder, and/or we have custom implementations of common functions that don't support edge cases, most of which are copy/pasted from StackOverflow without attribution.</p><p><i>See also: <a href="#tiny">tiny</a>, <a href="#lightweight">lightweight</a>, <a href="#modular">modular</a>, <a href="#modern">modern</a></i></p></div></div>]]>
            </description>
            <link>https://elie.rotenberg.io/b/p/modern-programming-glossary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24984318</guid>
            <pubDate>Tue, 03 Nov 2020 21:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bevy 0.3: game engine built in Rust]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24983956">thread link</a>) | @_cart
<br/>
November 3, 2020 | https://bevyengine.org/news/bevy-0-3/ | <a href="https://web.archive.org/web/*/https://bevyengine.org/news/bevy-0-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://bevyengine.org/news/bevy-0-3/sheep_game.png"></p>
      
    
  </div><div><p>A little over a month after releasing Bevy 0.2, and thanks to <strong>59</strong> contributors, <strong>122</strong> pull requests, and our <a href="https://github.com/sponsors/cart"><strong>generous sponsors</strong></a>, I'm happy to announce the <strong>Bevy 0.3</strong> release on <a href="https://crates.io/crates/bevy">crates.io</a>!</p>
<p>For those who don't know, Bevy is a refreshingly simple data-driven game engine built in Rust. You can check out <a href="https://bevyengine.org/learn/book/getting-started/">Quick Start Guide</a> to get started. Bevy is also free and open source forever! You can grab the full <a href="https://github.com/bevyengine/bevy">source code</a> on GitHub.</p>
<p>Here are some of the highlights from this release:</p>
<h2 id="initial-android-support">Initial Android Support</h2>

<p>You can try out the <a href="https://github.com/bevyengine/bevy/tree/master/examples/android">Bevy Android example</a> by following the <a href="https://github.com/bevyengine/bevy/blob/master/examples/README.md#android">instructions here</a>. While many things work, please note that this is <em>very hot</em> off the presses. Some features will work and others probably won't. Now is a great time to dive in and help us close the gaps!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/android.png" alt="android"></p>
<p>This was a massive group effort that spanned multiple projects:</p>
<ul>
<li>Bevy: rewrote bevy-glsl-to-spirv to support android / static libraries (@PrototypeNM1, @enfipy)</li>
<li>Bevy: <code>bevy_asset</code> backend using Android Asset Manager (@enfipy)</li>
<li>Bevy: Touch support (@naithar)</li>
<li>Bevy: Texture format fix (@enfipy)</li>
<li>Bevy: UI touch fixes, touch force, and android example (@enfipy)</li>
<li>Cpal: android audio support (@endragor) </li>
<li>android-ndk-rs / cargo-apk: fix to support Bevy project structure (@PrototypeNM1)</li>
</ul>
<h2 id="initial-ios-support">Initial iOS Support</h2>
<p>authors: @simlay, @MichaelHills, @Dash-L, @naithar</p>
<p>Bevy can now run on iOS!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/ios.png"></p><p>You can try out the <a href="https://github.com/bevyengine/bevy/tree/master/examples/ios">Bevy iOS example</a> by following the <a href="https://github.com/bevyengine/bevy/tree/master/examples#ios">instructions here</a>. This one is also hot off the presses: some features will work and others probably won't.</p>
<p>This was another large group effort that spanned multiple projects:</p>
<ul>
<li>Bevy: XCode Project / Example (@simlay with help from @MichaelHills)</li>
<li>Bevy: Runtime shader compilation using shaderc (@MichaelHills)</li>
<li>Bevy: Rodio upgrade (@Dash-L)</li>
<li>Bevy: Touch support (@naithar)</li>
<li>Winit: Fix iOS portrait view (@MichaelHills) </li>
<li>RustAudio: iOS support (@simlay and @MichaelHills)</li>
</ul>
<p>Known issues:</p>
<ul>
<li><a href="https://github.com/RustAudio/cpal/pull/485">Audio doesn't quite work yet</a></li>
</ul>
<h2 id="wasm-asset-loading">WASM Asset Loading</h2>
<p>authors: @mrk-its (and ported to the new AssetIo by @cart)</p>
<p>@mrk-its has been hard at work on expanding Bevy's WASM support. In this release we landed WASM asset loading. You can now load assets when you publish to WASM just like you would on any other platform:</p>
<pre><code><span>asset_server</span><span>.</span><span>load</span><span>("</span><span>sprite.png</span><span>");
</span></code></pre>
<p>If the asset hasn't already been loaded, this will make a <code>fetch()</code> request to retrieve the asset over HTTP.</p>
<p>@mrk-its has also been building a custom WebGL2 <code>bevy_render</code> backend. It is already pretty usable, but its not <em>quite</em> ready yet. Expect more news on this soon!</p>
<h2 id="touch-input">Touch Input</h2>
<p>authors: @naithar</p>
<p>Bevy now has support for touches:</p>
<pre><code><span>fn </span><span>touch_system</span><span>(</span><span>touches</span><span>: </span><span>Res</span><span>&lt;</span><span>Touches</span><span>&gt;) {
    </span><span>// you can iterate all current touches and retrieve their state like this:
    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter</span><span>() {
        </span><span>println!</span><span>("</span><span>active touch: {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_pressed</span><span>() {
        </span><span>println!</span><span>("</span><span>just pressed {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_released</span><span>() {
        </span><span>println!</span><span>("</span><span>just released {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_cancelled</span><span>() {
        </span><span>println!</span><span>("</span><span>just cancelled {:?}</span><span>",</span><span> touch</span><span>);
    }
}
</span></code></pre>
<p>You can also consume raw touch events using the <code>Events&lt;TouchInput&gt;</code> resource.</p>
<h2 id="asset-system-improvements">Asset System Improvements</h2>
<p>authors: @cart</p>
<h3 id="asset-handle-reference-counting">Asset Handle Reference Counting</h3>
<p>Assets are now automatically freed when their "handle reference count" reaches zero. This means you no longer need to think about freeing assets manually:</p>
<pre><code><span>// Calling load() now returns a strong handle:
</span><span>let</span><span> handle </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>sprite.png</span><span>");

</span><span>// Note that you no longer need to unwrap() loaded handles. Ergonomics for the win!

// Cloning a handle increases the reference count by one
</span><span>let</span><span> second_handle </span><span>=</span><span> handle</span><span>.</span><span>clone</span><span>();

</span><span>// Spawn a sprite and give it our handle
</span><span>commands</span><span>.</span><span>spawn</span><span>(</span><span>SpriteComponents </span><span>{
</span><span>    material</span><span>:</span><span> materials</span><span>.</span><span>add</span><span>(</span><span>handle</span><span>.</span><span>into</span><span>()),
    ..</span><span>Default</span><span>::</span><span>default</span><span>()
});

</span><span>// Later in some other system:
</span><span>commands</span><span>.</span><span>despawn</span><span>(</span><span>sprite_entity</span><span>);

</span><span>// There are no more active handles to "sprite.png", so it will be freed before the next update
</span></code></pre><h3 id="asset-loaders-can-now-load-multiple-assets">Asset Loaders can now load multiple assets</h3>
<p>In past releases, <code>AssetLoaders</code> could only produce a single asset of a single type. In <strong>Bevy 0.3</strong>, they can now produce any number of assets for any type. The old behavior was extremely limiting when loading assets like GLTF files, which might produce many meshes, textures, and scenes. </p>
<h3 id="sub-asset-loading">Sub-Asset Loading</h3>
<p>Sometimes you only want to load a specific asset from an asset source. You can now load sub assets like this:</p>
<pre><code><span>// Mesh0/Primitive0 references the first mesh primitive in "my_scene.gltf"
</span><span>let</span><span> mesh </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>my_scene.gltf#Mesh0/Primitive0</span><span>");
</span></code></pre><h3 id="assetio-trait">AssetIo Trait</h3>
<p>The <code>AssetServer</code> is now backed by the <code>AssetIo</code> trait. This allows us to load assets from whatever storage we want. This means on desktop we now load from the filesystem, on Android we use the Android Asset Manager, and on the web we make HTTP requests using the <code>fetch()</code> api.</p>
<h3 id="asset-dependencies">Asset Dependencies</h3>
<p>Assets can now depend on other assets, which will automatically be loaded when the original asset is loaded. This is useful when loading something like a "scene" which might reference other asset sources. We utilize this in our new GLTF loader.</p>
<h3 id="removed-assetserver-load-sync">Removed AssetServer::load_sync()</h3>
<p>This might rustle some feathers, but <code>AssetServer::load_sync()</code> had to go! This api wasn't WASM friendly, encouraged users to block game execution for the sake of convenience (which causes "hitching"), and was incompatible with the new AssetLoader api. Asset loading is now always asynchronous. Users of <code>load_sync()</code> should instead <code>load()</code> their assets, check load status in their systems, and change game state accordingly. </p>
<h2 id="gltf-scene-loader">GLTF Scene Loader</h2>
<p>authors: @cart</p>
<p>Up until this point, the GLTF loader was painfully limited. It could only load the first mesh with a single texture in a GLTF file. For <strong>Bevy 0.3</strong>, we took advantage of the asset system improvements to write a new <code>GltfLoader</code> that loads GLTF files as Bevy <code>Scenes</code>, along with all meshes and textures in the files.</p>
<p>Here's Bevy loading the Khronos Flight Helmet example, which consists of multiple meshes and textures!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/flight_helmet.png" alt="flight helmet"></p>
<p>Here is the complete code for a system that loads a GLTF file and spawns it as a scene:</p>
<pre><code><span>fn </span><span>load_gltf_system</span><span>(</span><span>mut </span><span>commands</span><span>:</span><span> Commands, </span><span>asset_server</span><span>: </span><span>Res</span><span>&lt;</span><span>AssetServer</span><span>&gt;) {
    </span><span>let</span><span> scene_handle </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>models/FlightHelmet/FlightHelmet.gltf</span><span>");
</span><span>    commands</span><span>.</span><span>spawn_scene</span><span>(</span><span>scene_handle</span><span>);
}
</span></code></pre><h2 id="bevy-ecs-improvements">Bevy ECS Improvements</h2>
<p>authors: @cart</p>
<h3 id="query-ergonomics">Query Ergonomics</h3>
<p>In this release I finally was able to remove the one thing I <em>truly despised</em> in Bevy ECS. In previous versions of Bevy, iterating over the components in a <code>Query</code> looked like this:</p>
<pre><code><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in &amp;</span><span>mut</span><span> query</span><span>.</span><span>iter</span><span>() {
    </span><span>// The `&amp;mut` here just felt so unnatural
</span><span>}

</span><span>// Or if you preferred you could do this
</span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> query</span><span>.</span><span>iter</span><span>().</span><span>iter</span><span>() {
    </span><span>// query.iter().iter()? Really???
</span><span>}
</span></code></pre>
<p>Similarly, retrieving a specific entity's component's looked like this:</p>
<pre><code><span>if let </span><span>Ok</span><span>(</span><span>mut</span><span> result</span><span>) =</span><span> query</span><span>.</span><span>entity</span><span>(</span><span>entity</span><span>) {
    </span><span>if let </span><span>Some</span><span>((</span><span>a</span><span>,</span><span> b</span><span>)) =</span><span> result</span><span>.</span><span>get</span><span>() {
        </span><span>// access components here
    </span><span>}
}
</span></code></pre>
<p>In <strong>Bevy 0.3</strong> you can just do this:</p>
<pre><code><span>// iteration
</span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> query</span><span>.</span><span>iter</span><span>() {
    </span><span>// sweet ergonomic bliss
</span><span>}

</span><span>// entity lookup
</span><span>if let </span><span>Ok</span><span>((</span><span>a</span><span>,</span><span>b</span><span>)) =</span><span> query</span><span>.</span><span>get</span><span>(</span><span>entity</span><span>) {
    </span><span>// boilerplate be gone!
</span><span>}
</span></code></pre>
<p>You might naturally be thinking something like:</p>
<p><em>Why did this take so long? Why would removing a single <code>&amp;mut</code> be hard?</em></p>
<p>It's a long story! In summary:</p>
<ul>
<li>The old api looked the way it did for a reason. It was the result of good design choices that protect against unsafe memory access in a parallel environment.</li>
<li><code>query.iter()</code> didn't actually return an iterator. It returned a <em>wrapper</em> that held an atomic lock on the component storages. The same was true for the type returned by <code>query.entity()</code></li>
<li>Removing these "wrapper types" would have allowed unsafe behavior because another Query could access the same components in a way that violated Rust's mutability rules.</li>
<li>Due to the iterator implementation and quirks in the rust compiler, removing the wrapper type <em>tanked</em> iteration performance by about ~2-3x.</li>
</ul>
<p>Fortunately we finally found ways to solve all of these problems. The newly added <code>QuerySets</code> allow us to completely remove the locks (and wrapper types). And by completely rewriting <code>QueryIter</code> we were able to avoid the performance hit that removing the wrapper incurred. Read on for the details!</p>
<h3 id="100-lockless-parallel-ecs">100% Lockless Parallel ECS</h3>
<p>Bevy ECS is now completely lock free. In Bevy 0.2, we made direct <code>World</code> access and "for-each" systems lock free. This is possible because the Bevy ECS scheduler ensures that systems only run in parallel in ways that respect Rust's mutability rules. </p>
<p>We couldn't remove locks from <code>Query</code> systems because of systems like this:</p>
<pre><code><span>fn </span><span>conflicting_query_system</span><span>(</span><span>mut </span><span>q0</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> A</span><span>&gt;</span><span>, </span><span>mut </span><span>q1</span><span>: </span><span>Query</span><span>&lt;(&amp;</span><span>mut</span><span> A, </span><span>&amp;</span><span>B</span><span>)&gt;) {
    </span><span>let</span><span> a </span><span>=</span><span> q0</span><span>.</span><span>get_mut</span><span>(</span><span>some_entity</span><span>).</span><span>unwrap</span><span>();
    </span><span>let </span><span>(</span><span>another_a</span><span>,</span><span> b</span><span>) =</span><span> q1</span><span>.</span><span>get_mut</span><span>(</span><span>some_entity</span><span>).</span><span>unwrap</span><span>();
    </span><span>// Aaah!!! We have two mutable references to some_entity's A component!
    // Very unsafe!
</span><span>}
</span></code></pre>
<p>The locks ensured that the second <code>q1.get_mut(some_entity)</code> access panicked, keeping us nice and safe. In <strong>Bevy 0.3</strong>, a system like <code>conflicting_query_system</code> will fail when the schedule is constructed. By default, <em>systems cannot have conflicting queries</em>.</p>
<p>However there are some cases where a system <em>needs</em> conflicting queries to do what it needs to do. For these cases, we added <code>QuerySets</code>: </p>
<pre><code><span>fn </span><span>system</span><span>(</span><span>mut </span><span>queries</span><span>: </span><span>QuerySet</span><span>&lt;(</span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> A</span><span>&gt;</span><span>, Query</span><span>&lt;(&amp;</span><span>mut</span><span> A, </span><span>&amp;</span><span>B</span><span>)&gt;)&gt;) {
    </span><span>for</span><span> a </span><span>in</span><span> queries</span><span>.</span><span>q0_mut</span><span>().</span><span>iter_mut</span><span>() {
    }

    </span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> queries</span><span>.</span><span>q1_mut</span><span>().</span><span>iter_mut</span><span>() {
    }
}
</span></code></pre>
<p>By putting our conflicting <code>Queries</code> in a <code>QuerySet</code>, the Rust borrow checker protects us from unsafe query accesses.</p>
<p>Because of this, we were able to remove <em>all</em> safety checks from <code>query.iter()</code> and <code>query.get(entity)</code>, which means these methods are now <em>exactly</em> as fast as their <code>World</code> counterparts (which we made lock-free in Bevy 0.2). </p>
<h3 id="performance-improvements">Performance Improvements</h3>
<p>Bevy had a number of nice performance improvements this release:</p>
<ul>
<li>Removed atomic locks from Query access, making Bevy ECS 100% lock free</li>
<li>Removed archetype "safety checks" from Query access. At this point we have already verified …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bevyengine.org/news/bevy-0-3/">https://bevyengine.org/news/bevy-0-3/</a></em></p>]]>
            </description>
            <link>https://bevyengine.org/news/bevy-0-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983956</guid>
            <pubDate>Tue, 03 Nov 2020 21:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It may be possible to reverse aging. Doing so risks severe overpopulation.]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24983592">thread link</a>) | @lawschool333
<br/>
November 3, 2020 | https://www.pairagraph.com/dialogue/952f0d63098645af9ed547880fca3a20?01 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/952f0d63098645af9ed547880fca3a20?01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/952f0d63098645af9ed547880fca3a20?01</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983592</guid>
            <pubDate>Tue, 03 Nov 2020 20:25:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mind-Melting Decision Proves a Dialer Can Never Be Too Old to Be an ATDS]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24983532">thread link</a>) | @guerrilla
<br/>
November 3, 2020 | https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/ | <a href="https://web.archive.org/web/*/https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>Editor’s Note: Welcome Hackers! Not sure how Hacker News found this article but I see a ton of folks headed in from that website, which I presume is some sort of aggregator for news articles of interest to folks that like to hack stuff. Feel free to have a look around the website–<a href="https://tcpaworld.com/podcast/">check out our cool podcast</a>–and tell any friends that might like this nerdy stuff. But don’t hack anything please. Thanks.&nbsp;</em></p>
<p>Since there is absolutely nothing else going on today I figured I’d share one of the weirdest TCPA cases I’ve seen recently.</p>
<p>So apparently some guy in Nebraska named Mort who really doesn’t like a gas station called Bucky’s Gas Station. He hates it so much, in fact, that he has created a stark raving mad loony-toons (my opinion) gripes board on the internet to assail it. You can visit it, if you’d like, but be warned that your brain will melt a little: <a href="http://www.buckysgasstationsucks.com/">www.buckysgasstationsucks.com</a>.</p>
<p>I spent more time than I’d care to admit reviewing the website last night but I can’t quite figure out where the beef originated. (If you can figure it out let me know, as I am actually genuinely curious.)</p>
<p>So Bucky’s Gas Station is owned by a guy named Buchanan— who I will assume goes by Bucky whether he wants to or not—and his wife who have allegedly been subjected to years of abuse at the hands of Mort using something called a FaxTel 2000, which is something directly out of a 90s era Simpsons. Apparently Mort revs up his FaxTel 2000 and blasts Bucky and his wife with unwanted messages from time to time, just to make sure Bucky remembers how much Mort dislikes him.</p>
<p>Not stopping there, Mort also—allegedly—encourages members of the public to blast poor Bucky with calls “day and night” and to do the same with his associates and neighbors, many of whose contact information is listed on the brain-melting website. As the order tersely words it: “<em>[Mort] encourages members of the public to contact the Buchanans, their neighbors, and others they are affiliated with; and notes that the Buchanans and others will be contacted daily and nightly regarding Sullivan’s grievances</em>.”</p>
<p>Since I don’t actually know why Mort is so agitated by Bucky I can’t say that his conduct is totally inappropriate. I mean, maybe Bucky threw Mort’s puppy in a microwave or something. But either way the conduct of blasting someone’s cell phone with unwanted messages is illegal—if an ATDS is used.</p>
<p>And here’s where things finally get interesting in this yawner of a case.</p>
<p>The Plaintiff alleged that FaxTel 2000 is an autodialer because, I mean, look at the thing.</p>
<p><img data-attachment-id="9016" data-permalink="https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/faxtel-20007jpeg/" data-orig-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=350%2C267&amp;ssl=1" data-orig-size="350,267" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="FAXTEL 20007jpeg" data-image-description="" data-medium-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=300%2C229&amp;ssl=1" data-large-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=350%2C267&amp;ssl=1" loading="lazy" src="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1" alt="" width="300" height="229" srcset="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?w=350&amp;ssl=1 350w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?w=350&amp;ssl=1 350w" data-lazy-src="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>But Mort had a clever response—this device is so old and beaten up that it can no longer dial randomly and sequentially, plus no replacement parts are available so it lacks the capacity to dial that way in the future either. So it can’t possibly meet the TCPA’s ATDS definition.</p>
<p>I mean, its kind of a brilliant argument if you think about it (and your mind has melted a little.)</p>
<p>Unfortunately for Mort, however, the case was decided at the pleadings stage and the Court simply could not accept Mort’s assertions on the FaxTel’s dialing capacity as those “facts” were outside the pleadings. Instead the Court had to accept Bucky’s claim that the dialer had all the needed functionality to behave as an ATDS.</p>
<p>Undeterred, Mort also argued that the TCPA infringed on his First Amendment rights but—as <strong><a href="https://tcpaworld.com/2020/10/29/happy-halloween-tcpaworld-heres-are-the-top-10-scariest-tcpa-stories-going-to-freak-you-out-this-halloween/">readers of my Halloween column know</a></strong>—the Constitution won’t save you in TCPAWorld.</p>
<p>*Insert left-over evil laugh from Halloween bargain bin here*</p>
<p>Mort finished his motion to dismiss with a claim that the TCPA only applies to telemarketing harassment, not good-ole-fashioned harassment harassment. No dice. The Court looks at the words of the statute and cannot find the “I just want to abuse people out of spite” TCPA exemption.</p>
<p>On the other hand, and somewhat amusingly, the Court refused to enter a preliminary injunction prohibiting Mort’s conduct finding that it wanted more information and evidence before doing so. Under the circumstances of this case one might have thought ordering one party to temporarily stop blasting the other with&nbsp; robocalls would have been pretty perfunctory. But I guess the Court also wants to know about the condition of Mort’s puppies before ordering him to stop FaxTeling Bucky.</p>
<p>The case is <em>Buchanan v. Sullivan</em>, 8:20-CV-301, 2020 U.S. Dist. LEXIS 202519 (D. Ne. October 30, 2020).</p>
<p>And now you may return to your low-anxiety and worry free Tuesday.</p>
<p>Hey, look at that bird outside.</p>
<p><strong>UPDATE: 11/3/2020 at 2:24 pm pacific</strong></p>
<p>So I apparently have a new team of hackers that work for me– Czar of TCPAWorld and Czar of the Hackers?– and they think they’ve uncovered what happened here. Below is an exchange from a hacker news message board, because that’s how I roll now:</p>

	</div></div>]]>
            </description>
            <link>https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983532</guid>
            <pubDate>Tue, 03 Nov 2020 20:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decision Journal in Notion]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24983435">thread link</a>) | @saviorand
<br/>
November 3, 2020 | https://optemization.com/decision-journal-notion | <a href="https://web.archive.org/web/*/https://optemization.com/decision-journal-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="decision-journal-notion"><p><span><span>Using the Farnam Street framework to prompt you to document and reflect on important decisions. Digitally templated in Notion. </span></span></p><h2><span id="288d7840441747b18e822ebbbc8ad065"></span><span><span>"Your success will be the sum of the decisions you make over your career."</span></span></h2><p><span><span>Says Shane Parish, author, mental model expert and the founder and CEO of Farnam Street (FS), a company focused on timeless ideas for upgrading life and business. FS runs a remarkable newsletter,  podcast and community on multidisciplinary thinking and mental models. </span></span></p><p><span><span>Members include students, teachers, CEOs, coaches, athletes, artists, leaders, followers, politicians, and more. They’re not defined by gender, age, income, geography, or politics but rather by a shared passion for living a meaningful life, doing good, and avoiding problems before they happen.</span></span></p><p><span><span>I found Parrish on Twitter, where he compresses and shares FS learning into digestible fire tweets like these ones (that's why I love Twitter):</span></span></p><h2><span id="e3f5175809104bc08c044cc9a1d8622f"></span><span><span>Decision Journal</span></span></h2><p><span><span>In 2014, Parish shared the "decision journal ", a tool to "collect accurate and honest feedback on what you were thinking at the time you made a certain decision that will help you see when you were stupid and lucky as well as when you were smart and unlucky; all to make better decisions."</span></span></p><p><span><span>Read more about the thinking and structure behind this decision making framework at the link below.</span></span></p><p><span><span>Later, FS came out with a pocket-sized journal capture decisions with a pen (who uses those anymore). </span></span></p><div id="c28b706b637d401c847f6452fb722421"><div id="8911e52c145840c3b08b1b092b19e9cd"><div id="707ab5d696434b29bb032672582f06da"><picture><source srcset="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300" alt="image" loading="lazy"></picture></div></div><div id="f31dee76d0ec4c7e883d9dfddf29f1c5"><div id="b1f81624f9754bf98987069098c371d4"><picture><source srcset="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=1500" alt="image" loading="lazy"></picture></div></div></div><p><span><span>The journal invites you to break down an important decision with the following prompts:</span></span></p><ul><li id="f84732a96cb34f75b493316d75535c81"><span><span>Mental or Physical State</span></span></li><li id="1945d55968eb4cd4a32e8e840e250ee6"><span><span>Situation or context</span></span></li><li id="2b061e1623b9405d96f1c55380e1b59e"><span><span>Problem statement of frame</span></span></li><li id="0a0d150ed00c461083c613b4c1d0d793"><span><span>Variables that govern the situation</span></span></li><li id="ba1ae1514f934fefbf163d92bd3da053"><span><span>Complications or complexities as you see them</span></span></li><li id="898fd35a5232468ca0f58541946f967f"><span><span>Range of outcomes</span></span></li><li id="03fb7f6338404c9a9417a6d597e1a3b6"><span><span>Expectations and probabilities</span></span></li><li id="d860f50788f84cf2a47086cc074df8ab"><span><span>Outcome </span></span></li><li id="a450fc0f701f49d492b659d6ed75da72"><span><span>Reflection (six months after decision was made)</span></span></li></ul><p><span><span>I found this framework to be quite thought provoking and challenging. Like most, I'm not used to documenting decision-making whatsoever. But approaching decisions this way and writing even just a few lines invited me to </span><span><em>think deeper. </em></span></span></p><p><span><span>After using the journal digitally (more on that below) for a few months, I've integrated it across Optemization. I find documenting hiring and strategic decisions to be the most useful. And</span><span><em> </em></span><span>that in turn, will make me a better person and entrepreneur.</span></span></p><p><span><span>Now paper and physical journals are </span><span><em>great</em></span><span> but if you know me; you know I have an obsession with digitizing my operations and productivity in Notion.</span></span></p><h2><span id="1ee913d94f9a482499b0dcb53bd778cf"></span><span><span>Decision Journal </span><span><em>in Notion</em></span></span></h2><p><span><span>As you might know, </span><span><a target="_blank" rel="noopener noreferrer" href="http://notion.so/">Notion</a></span><span> is a incredible all-in-one software tool that works like a digital paper. Many use it for journaling, so keeping decisions alongside with notes, for example, would be a perfect use case.</span></span></p><p><span><span>Recently, I digitized FS's decision journal and integrated it into my personal life and our work at Optemization. Here's how it looks</span></span></p><div id="6be5237cecb34854b190e8980484b179"><picture><source srcset="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=1500" alt="A real decision that Shane Parrish documented and I re-created in Notion (dark mode) 🌑" loading="lazy"></picture><figcaption><span><span>A real decision that Shane Parrish documented and I re-created in Notion (dark mode) 🌑</span></span></figcaption></div><h2><span id="e24cfb65a0864da78d99c4bc119005ab"></span><span><span>How it Works</span></span></h2><p><span><span>Here's a video breakdown on YouTube (or </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.loom.com/share/b3498e89e9b2451994b0d35ee4fd30e6">Loom</a></span><span>). You can read a deeper dive below or on Optemization, which is formatted nicer.</span></span></p><h2><span id="10053c973581433e9ff2f5ebcc3e8d0c"></span><span><span>Grab the Free Template</span></span></h2><h2><span id="c28450588b8a4dee9ce9676b30ad0247"></span><span><span>How it Works (Deep Dive)</span></span></h2><p><span><span>I structured each decision to be a database entry while splitting the aforementioned decision factors into database properties (columns) and page contents. If you haven't used Notion yet, that's one of the coolest features: any content can be stored as a property or inside of a database record.  </span></span></p><div id="5d36fc34fd80465b9b23af606a8f026a"><picture><source srcset="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>To contextualize a specific decision record in the database, apply the template  that brings up the aforementioned prompts . A new decision by default will be marked as </span><span><code>undecided</code></span><span>. The rest of the properties will be left for you to fill</span></span></p><div id="bddd80415c3a48daa7f506900c691cb0"><picture><source srcset="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>One of the core tenets of decision making in this framework is reflection and feedback. It's so easy to overlook this part but reflecting on past decisions will improve your decision making 10x (don't @ me). Anyway,  I built a three properties that help with facilitating this behavior:</span></span></p><p><span><span>Firstly, </span><span><code>Review in</code></span><span>, a single choice label for the duration of weeks or months after which you want to review your decision. Parrish recommended six months as the default time frame but I thought that was too constrained, so I expanded it to one week, two weeks, one month, three month and six months. Below I will explain how you can add your own .</span></span></p><p><span><span>Secondly, I find unnecessarily annoying to add the dates and figure out where you need to set the reminder, so I wrote the </span><span><code>Review at</code></span><span> formula. It's a bunch of nested IF statements that look at </span><span><code>Review in</code></span><span> and add the corresponding timeframe to </span><span><code>Created at</code></span><span>. It looks like this:</span></span></p><pre id="2ed841786e93444cb3aeb16bcea725e5"><code><span><pre><code><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"One week"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>"weeks"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"Two weeks"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>"weeks"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"One month"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>"months"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"Three months"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>"months"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"Six months"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>6</span><span>,</span><span> </span><span>"months"</span><span>)</span><span>)</span><span>,</span><span> </span><span>"Decision has not been made yet"</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span></code></pre></span></code></pre><div id="8defbfbe696d40628a3b56bc53b88a33"><p><span><span>Right now, you can only compute one result in </span><span><code>Review at</code></span><span> that's why </span><span><code>Review in</code></span><span> is single choice. That can be changed but I didn't find it necessary.</span></span></p></div><p><span><span>There's probably a way to run this better, so let me know if you think there are better ways to write it.</span></span></p><p><span><span>Note that if the </span><span><code>Made at</code></span><span> property is empty the </span><span><code>Review at</code></span><span> will return "Decision has not been made yet" string.</span></span></p><p><span><span>If you want to add a new time segment to </span><span><code>Review in</code></span><span> do this:</span></span></p><ol><li id="20c7d79cdad34949893347e3232ef233"><span><span>Add the label. For example "Three weeks"</span></span></li><li id="ccbb98282393418794103bf03eb934de"><span><span>In the formula, after the last comma add </span><span><code>if(prop("Review in") == "Three weeks", format(dateAdd(prop("Made at"), 3, "weeks")),</code></span><span>.
There are three variables that you need to input the if condition (Three weeks), the duration (3) and the time format (weeks).</span></span></li><li id="76b8f79bad30438e93655859b9d505fd"><span><span>Add one </span><span><code>)</code></span><span> to the end of the formula and press </span><span><code>cmd+enter</code></span><span> to accept.</span></span></li></ol><p><span><span>Finally there's the </span><span><code>Remind at</code></span><span> property, which is a simple text field where you can put your actual reminder. Unfortunately the formula field cannot do that for you. To add a reminded type </span><span><code>@ remind</code></span><span> and enter the date that </span><span><code>Review in</code></span><span> gave you.</span></span></p><div id="3e0da30d538742b6a261295467ec8902"><picture><source srcset="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=1500" alt="image" loading="lazy"></picture></div><div id="c3704eda0bc443b79eb785ef40a360ae"><p><span><span>Notion reminders will default to the current year, so make sure to specify 2021 as the year for your reminder.</span></span></p></div><p><span><span>That's it! Farewell and I hope this helps you make some great decisions. Please share on Twitter if you found this post insightful or the template useful — I'm @optemization 👉</span></span></p><h3><span id="7eb481733824435d8164671e498f430b"></span><span><span>Want more DOPE content? Join </span><span><em>Digital Opsessions</em></span><span> 💌</span></span></h3></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/decision-journal-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983435</guid>
            <pubDate>Tue, 03 Nov 2020 20:07:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Psychology of Learning to Code]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982975">thread link</a>) | @dvoloschik
<br/>
November 3, 2020 | https://vasilishynkarenka.com/the-psychology-of-learning-to-code/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/the-psychology-of-learning-to-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png" alt="The psychology of learning to code">
            </figure>

            <section>
                <div>
                    <p>Two months ago, I started learning how to code. I’ve approached coding three times in the past seven years and always quit. This time, I decided to figure out <a href="https://vasilishynkarenka.com/learning/">how to learn</a> first and gave myself a word to not stop until I can make a simple web app myself.</p><p>Last week, I finished my first <a href="https://vasilishynkarenka.com/gpt-3/">useful React app</a> and decided to reflect on what I’ve learned in the past two months. I’ve seen many articles describing tips and tricks for studying coding, but very few cover the process of learning and the psychology behind it.</p><p>In summary, you need to build a habit of learning, find what you’re obsessed with, and crawl your way through The Suck. I also explain how drawing and spatial cognition help improve understanding, how you can enhance transfer by creating more hooks for recall, and how to design an environment for concentration instead of pushing yourself to focus.</p><p><em>P.s. If you aren’t learning to code, you’ll benefit from reading the habit part as well – the principles behind it apply to any routine.</em></p><p><em>P.p.s. If you haven’t seen my work on learning, I’d recommend reading both posts so that you form a complete picture of how to learn:</em></p><figure><a href="https://vasilishynkarenka.com/learning/"><div><p>How to remember what you learn</p><p>Make it time-based, apply metacognition &amp; active recall, and learn what you’re curious about.</p><p><img src="https://vasilishynkarenka.com/favicon.png"><span>Vasili Shynkarenka</span></p></div><p><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_1517.jpg"></p></a></figure><hr><p>Most people quit learning to code because they don’t get results. But results come after months of practice – there is no way to become a senior engineer after one hour of HTML tutorials. To get there, you can’t rely on fragile motivation that fades away quickly. You must build a habit of learning.</p><p>To build a habit, you need four things:</p><ol><li>Design your intention.</li><li>Make learning time-based instead of outcome-based.</li><li>Start small.</li><li>Do not make up for missed studies.</li></ol><h2 id="design-your-intention">Design your intention</h2><p>Most people never study because they don’t specify when and where learning will happen. They just keep snoozing it because “today was really busy but let’s see if I can make it tomorrow.” And tomorrow never comes.</p><p>Intention design is a trick to help with indefinite plans. When you want to do something, write it down in the following structure:</p><blockquote><em>“I, Vasili Shynkarenka, will study React course on Scrimba from 8:00 to 8:30 am tomorrow morning in my study room, right after I brush my teeth.” (Signature)</em></blockquote><p>Here’s why it works.</p><p><strong>First, you give yourself a word.</strong> When you promise yourself in writing that you will do something, you plant a seed for consistency. And humans naturally want to be consistent in their actions to not look stupid. But consistency works only if the action is present. And when you’re merely thinking about doing something, that’s not real yet. When you write the thing down, you make it real.</p><p><strong>Second, you get clarity.</strong> Suppose you omit essential details, such as where you will be studying or which material you will use. In that case, you’re less likely to do it because you will experience increased cognitive load at the moment. Because humans don’t like thinking, you will go for the easiest option possible – to put it off.</p><p>That’s why Eisenhower famously said that while plans are useless, planning is essential. The act of planning clarifies subtleties. Your plan may change, but clarity will lower cognitive load and increase the likelihood of taking action.</p><p><strong>Third, you specify the behavior after which learning should begin.</strong> Very often, our plans go sideways because we do not clarify <em>when</em> we will do the thing. Urgent stuff keeps popping up, and we never get to do what we wanted.</p><p>The easiest solution here is to choose a trigger that you already do every day, no matter what, and schedule your learning right after that act. Brushing your teeth, having breakfast, coming back home after work – all are excellent examples. If you approach intention design that way, you have less opportunity for failure because the “must-do” thing will always be there and serve as a reminder for the action you want to take.</p><h2 id="make-learning-time-based">Make learning time-based</h2><p>If you choose to study until you finish the chapter, you incentivize yourself to optimize for speed rather than understanding. As a result, you will skim the most valuable parts to hit your goal.</p><p>The second problem with goals like “finish such and such tutorial” is that you will underestimate how much time it will take to finish the thing. And when you run out of time, you will be frustrated with yourself because you didn’t hit your goal.</p><p>Instead, set time-based goals. “Study JS course for 1h” is a good example. Or “Read new CSS tutorial for 30 min”. </p><p>When you switch to time-based learning, three things happen:</p><p><strong>First, you take control of whether you succeed or not.</strong> When you are focused on the outcome, you have to rely on an unknown variable – how much time it will take for you to understand something new. This often leads to self-hatred – you will blame yourself for being stupid because you didn’t understand the material quickly. But if you focus on time, then you always succeed if you want to. You just need to focus.</p><p><strong>Second, you can fit the learning session into your busy schedule.</strong> When you know that you’ll be learning for thirty minutes no matter what, you know where to put the thing.</p><p><strong>Third, you build self-confidence.</strong> The time you spend on learning is a continuum, but the act of showing up is binary. It doesn’t care for how long you learn to mark it as “done.” And if you keep showing up for months, you become <em>the type of person</em> who shows up. And as most people quit in the first few months, you’ll have built immunity by the moment you will face The Suck.</p><h2 id="start-small">Start small</h2><p>When you’re just getting started, lower the time of your studies to a bare minimum. Make it negligible. Even ten minutes will do, given that you’re doing it every day.</p><p>I hear you saying: “How can I possibly learn something really complex as coding by spending ten minutes a day on it?” You can’t. But you can build discipline.</p><p>Also, you’ll procrastinate less. If you only have ten minutes to learn in a day, and there’s no opportunity to make up for it, your mind will be like: “Hell, I’ve got only ten minutes today – I better focus and not scroll Instagram.”</p><h2 id="do-not-make-up">Do not make up</h2><p>You must never, ever, make up for studies that you missed. </p><p>It’s incredibly easy to sell yourself on the idea that “Oh, I don’t really want to study this morning, I’ll do it later today when I have time.” </p><p>But snoozing is dangerous for two reasons:</p><ol><li>First, you’re unlikely to do it later because you won’t have triggers to remember the thing. You screw up your intention design.</li><li>Second, you set up bad incentives for yourself in the future. There will be moments when your habit will fail you and you will skip learning. And if you’ve trained yourself to snooze things for later when any inconvenience arises, you’ll tend to do it over and over again. You’ll just keep snoozing.</li></ol><p>So what do you do if you miss a session? Nothing. You don’t reschedule. You don’t blame yourself. It’s already in the past, so there’s no reason to do any of these things. You show up again tomorrow and do the work.</p><p>When you stop rescheduling, you become less likely to skip your learning sessions because you know you can’t make up for it. Your mind will remember the contract you have agreed on and stop offering opportunities for sloth.</p><p>After you make learning a habit, the next question is how to get more of it. That’s because learning is nonlinear: if you put in two hours every day instead of one, you don’t get a 2x outcome – you get 5-10x. </p><p>The best way to allocate more time to coding is not to squeeze more hours of study but to discover your obsession. </p><p>Obsession is a multiplier for results. When you’re obsessed with something, you cannot <em>not</em> do the thing. As a result, you don’t have to decide each time whether to study or not. You just do it.</p><p>I’m obsessed with building interfaces. I don’t really care about how beautiful the app’s architecture is or what algorithm we use for compression. All I’m thinking about is how to make the user experience great.</p><p>When I realized that interfaces make me tick, I optimized my learning program to build more of them. I created all sorts of forms, confirmation alerts, and buttons. I stopped counting minutes I had yet to study and began going way <em>beyond</em> what I initially allocated for learning just because I was so curious about it. And that’s where real progress began to happen.</p><p>To find what you’re obsessed with, ask yourself two questions:</p><ol><li>Why do I want to learn how to code in the first place?</li><li>Is there anything specific about coding that drives me?</li></ol><p>If you don’t have an answer now, it’s okay. Try many things broadly to find what makes you tick about coding, and then double down in that direction. If data is your thing, go ahead and study APIs first. If you sweat when you make beautiful CSS animations, go and pick up that. Follow your own obsession.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/image-7.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/image-7.png 600w, https://vasilishynkarenka.com/content/images/2020/10/image-7.png 790w" sizes="(min-width: 720px) 720px"><figcaption>"Andy crawled to freedom through five-hundred yards of shit smelling foulness I can't even imagine, or maybe I just don't want to. Five-Hundred yards... that's the length of five football fields, just shy of half a mile."</figcaption></figure><p>Everyone who learns something complex goes through The Suck.</p><p>That’s when things get tough. When you don’t see progress for weeks. When you wake up every day and question yourself if it’s worth it. When you are ready to quit. The difference between people who end up learning how to code and those who don’t is simple – those who succeed somehow manage to crawl their way through The Suck.</p><p>Because I knew how learning works, I was aware The Suck is coming. But it hit me hard anyway. To help you get through The Suck, I’ve documented what I did to pull myself from that shithole.</p><h2 id="understand-how-learning-works">Understand how learning works</h2><p>Learning is never linear and more like a giant exponential curve. It’s a weird one, with a flat part looking like a bumpy road. One day, you get a hit and go straight up. You learn something new. Another time, you spend many hours and get nothing.</p><p>Very often, it seems that you’re not making …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/the-psychology-of-learning-to-code/">https://vasilishynkarenka.com/the-psychology-of-learning-to-code/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/the-psychology-of-learning-to-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982975</guid>
            <pubDate>Tue, 03 Nov 2020 19:22:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker in 10 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24982719">thread link</a>) | @wheresvic4
<br/>
November 3, 2020 | https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  I've been exposed to docker on and off and every time I see it, I seem to need a refresher. In this article we will go
  through everything you need to know about Docker in order to either jump into an existing project or get started with
  it.
</p>

<h5>Basic concepts</h5>

<p>
  Docker is basically a system of running processes on the host machine in an isolated way, using several Linux kernel
  features. Thus, Docker is more lightweight than a full-blown virtual machine. The disadvantage of a Docker container
  vs. a virtual machine is that multiple containers share the same underlying OS kernel. While the concept of jailed
  processes is not new, Docker's popularity was essentially due to the tooling that it provided to which made it really
  straightforward to spin up and manage containers.
</p>

<p>
  Docker is made up of various components. The main component is the the docker engine, which consists of a lightweight
  runtime that manages containers, images, builds, and more. It runs natively on Linux systems and is made up of:
</p>

<ol>
  <li>Docker daemon that runs on the host machine.</li>
  <li>Docker client that communicates with the Docker daemon to execute commands.</li>
  <li>A REST API for interacting with the Docker daemon remotely.</li>
</ol>

<p>
  The Docker client is what you, as the end-user use to communicate with the Docker daemon, e.g.
  <code>docker run hello-world</code>.
</p>

<p>
  The Docker daemon is what actually executes commands like building and running containers on the host machine. The
  Docker Client can run on the same machine as well, but it does not have to. It can also communicate with the Docker
  Daemon running on a different host.
</p>

<p>We will look at other Docker components like the Docker hub, etc. later in this article.</p>

<h5>Images, containers and volumes</h5>

<p>
  A Docker image can be though of as a recipe for setting up a machine with all required software and dependencies
  installed. Apart from installing software, images can also define what processes to run when launched. Docker images
  are created via instructions written in a <code>Dockerfile</code>. Images are built on the concept of layers. There is
  always a base layer, potentially followed by additional layers that represent file changes. Each layer is stacked on
  top of the others, consisting of the differences between it and the previous layer. This is achieved via a
  <a href="https://en.wikipedia.org/wiki/UnionFS">Union file system</a>.
</p>

<!--
<p>Examples of instructions one can put into a <code>Dockerfile</code>:</p>

<ul>
  <li><code>RUN apt-get -y install some-package</code> # install a software package</li>
  <li><code>EXPOSE 8000</code> # expose a port</li>
  <li><code>ENV ANT_HOME /usr/local/apache-ant</code> # pass an environment variable</li>
</ul>
-->

<p>
  A Docker container is the running instance of an image. This includes the operating system, application code, runtime,
  system tools, system libraries, etc. A Docker image can be thought of as an executable and a container can be thought
  of as the running application. Note that in this analogy each running application is its own instance and independent
  of the others.
</p>

<p>
  The general idea is that once you have successfully created a container, you can then run it in any environment
  without having to make changes.
</p>

<p>
  A Docker volume is the "data" part of a container, initialized when a container is created. Volumes allow
  you to persist and share a container's data. Docker volumes are separate from the default Union File System and exist
  as normal directories and files on the host filesystem.
</p>

<h5>Docker comands</h5>

<p>
  As part of the docker installation process, a hello world image was downloaded and executed via:
  <code>docker run hello-world</code>
</p>

<p>List all images with <code>docker images</code>:</p>

<pre>$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
ubuntu              latest              94e814e2efa8        2 weeks ago         88.9MB
hello-world         latest              fce289e99eb9        2 months ago        1.84kB
</pre>

<p>Run a command interactively from an image in a new container: <code>docker run -it ubuntu bash</code></p>

<p>
  List all running containers: <code>docker ps</code>. To list all previously run containers use
  <code>docker ps -a</code>:
</p>

<pre>$ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                         PORTS               NAMES
d2d651741317        ubuntu              "bash"              45 minutes ago      Exited (0) 43 minutes ago                          suspicious_kalam
36813bdb6434        ubuntu              "bash"              About an hour ago   Exited (0) About an hour ago                       inspiring_banach
46f352a0cde9        hello-world         "/hello"            2 hours ago         Exited (0) 2 hours ago                             thirsty_clarke
</pre>

<p>
  Note that in the output above, for each docker <code>run</code> command, a new container was created. As mentioned
  previously, each container has it's own data volume and changes to one do not affect the others. To run an existing
  container: <code>docker run [container-name</code>. This will start the container and
  <code>docker attach [container-name]</code> will jump into it.
</p>

<p>
  At this point, you should have enough to get started with an existing docker project. Read on if you're looking to
  develop with docker.
</p>

<h5>Custom images</h5>

<p>
  As noted previously, Docker images are specified via a <code>Dockerfile</code>. Here's an extremely basic example that
  uses a ubuntu base image and copies an executable called <code>sysinfo</code> from the current directory into the
  container and executes it:
</p>

<pre>FROM ubuntu:18.04
COPY sysinfo /
CMD ["/sysinfo"]
</pre>

<p>
  Let's see how we can get this image up and running via the <code>docker build</code> command (note that gcc is
  required to compile the binary):
</p>

<pre>$ cd ~
$ mkdir -p docker/sysinfo
$ cd docker/sysinfo
$ vim sysinfo.cpp

#include &lt;iostream&gt;
#include &lt;sys/utsname.h&gt;

using namespace std;

int main() {
  struct utsname sysinfo;
  uname(&amp;sysinfo);
  
  cout &lt;&lt; "System Name: " &lt;&lt; sysinfo.sysname &lt;&lt; endl;
  cout &lt;&lt; "Host Name: " &lt;&lt; sysinfo.nodename &lt;&lt; endl;
  cout &lt;&lt; "Release(Kernel) Version: " &lt;&lt; sysinfo.release &lt;&lt; endl;
  cout &lt;&lt; "Kernel Build Timestamp: " &lt;&lt; sysinfo.version &lt;&lt; endl;
  cout &lt;&lt; "Machine Arch: " &lt;&lt; sysinfo.machine &lt;&lt; endl;
  cout &lt;&lt; "Domain Name: " &lt;&lt; sysinfo.domainname &lt;&lt; endl;
  
  return 0;
}

$ g++ sysinfo.cpp -o sysinfo
$ ./sysinfo

System Name: Linux
Host Name: coolbeans
Release(Kernel) Version: 4.18.0-16-generic
Kernel Build Timestamp: #17-Ubuntu SMP Fri Feb 8 00:06:57 UTC 2019
Machine Arch: x86_64
Domain Name: (none)


$ vim Dockerfile

FROM ubuntu:18.04
COPY sysinfo /
CMD ["/sysinfo"]

$ docker build . -t sysinfo
$ docker run sysinfo

System Name: Linux
Host Name: d8e53b009d72
Release(Kernel) Version: 4.18.0-16-generic
Kernel Build Timestamp: #17-Ubuntu SMP Fri Feb 8 00:06:57 UTC 2019
Machine Arch: x86_64
Domain Name: (none)
</pre>

<p>
  Note in the difference in hostname between local system (coolbeans) and the running container (d8e53b009d72) in the
  above output.
</p>

<p>
  If you make a mistake, you can remove an image via <code>docker rmi [image-name] --force</code>. Cleaning up unused
  containers and volumes related to the image can be accomplished via <code>docker system prune --volumes</code>.
</p>

<p>
  In the above example, we created a custom image using the standard Ubuntu image as our base image, before we go
  further with creating custom images it would be good to note that the docker
  <a href="https://hub.docker.com/search?q=&amp;type=image&amp;image_filter=official">hub</a> provides lots of free
  pre-configured images for various software. This is the second Docker component and is also sometimes called the
  Docker registry (one can also have private registries).
</p>

<h5>Networking</h5>

<p>
  In most cases, we would like to run a service via Docker. Let is look at how we can accomplish this by using a very
  simple web server as an example. Create the image as follows (note that the example below uses Go to create the
  binary):
</p>

<pre>$ cd ~
$ mkdir -p docker/webapp
$ cd docker/webapp
$ vim webapp.go

package main

import (
	"io"
	"net/http"
)

func hello(w http.ResponseWriter, r *http.Request) {
	io.WriteString(w, "Hello from webapp!")
}

func main() {
	http.HandleFunc("/", hello)
	http.ListenAndServe(":8000", nil)
}

$ go build webapp.go
$ vim Dockerfile

FROM ubuntu:18.04
COPY webapp /
CMD ["/webapp"]

$ docker build . -t webapp
$ docker run -d webapp
cfab907c828a40ce4cc53b88b26badabf8fa6672fd538d0c072fd0947f36d650
</pre>

<p>
  In the above example we built a webapp image and started the docker container with the <code>-d</code> flag. This
  started the container in detached mode and printed the container id so that we could interact with it. We can confirm
  it is running via <code>docker ps</code>:
</p>

<pre>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
cfab907c828a        webapp              "/webapp"           4 minutes ago       Up 4 minutes                            zealous_herschel    
</pre>

<p>
  At this point we have our web application running in a docker container but we have no way to communicate with it. Run
  <code>docker inspect cfab907c828a</code> to output the container configuration in json format. We are interested in
  the <code>NetworkSettings.Networks.bridge.IPAddress</code> property. Let's try connecting to the provided ip address,
  http://172.17.0.2:8000 (in my case) and we can see our web application in action!
</p>

<p>
  It is also possible to bind ports on from the docker container to the host machine so that we can access services as
  if they were running locally, <code>docker run -d -p3000:8000 webapp</code>. Thus our web application is now available
  on http://localhost:3000!
</p>

<h5>Persistent storage</h5>

<p>
  By default Docker containers come with their own storage which lives as long as the container is running. If we would
  like to persist data across containers, we can either bind a local file/directory to our container or create and mount
  a named Docker volume. The added benefit of using a Docker volume is that it does not necessarily have to be a
  resource on the host file system, it can also be an external cloud storage service depending upon the driver.
</p>

<p>
  A very practical example of using a postgres docker image with persistent data storage can be found
  <a href="https://smalldata.tech/blog/2018/02/23/dockerized-postgresql-with-local-data-storage-on-ubuntu">here</a>.
</p>

<h5>Summary</h5>

<p>
  We looked at Docker basic concepts, created a few containers, ran some services and even persisted data across machine
  restarts! This was longer than 10 minutes but it should be enough to get going with Docker.
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2019%2F06%2F08%2Fdocker-in-10-minutes&amp;t=Docker%20in%2010%20minutes">HackerNew…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes">https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes</a></em></p>]]>
            </description>
            <link>https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982719</guid>
            <pubDate>Tue, 03 Nov 2020 18:55:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: What would be an ideal developer stack for a Machine Learning engineer?]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982113">thread link</a>) | @krishnagade
<br/>
November 3, 2020 | https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/ | <a href="https://web.archive.org/web/*/https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
<p>In today’s world, data has played a huge role in the success of technology giants like Google, Amazon, and Facebook. All of these companies have built massively scalable infrastructure to process data and provide great product experiences for their users. In the last 5 years, we’ve seen a real emergence of AI as a new technology stack. For example, Facebook built an end-to-end platform called <a href="https://code.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/">FBLearner</a> that enables an ML Engineer or a Data Scientist build Machine Learning pipelines, run lots of experiments, share model architectures and datasets with team members, scale ML algorithms for billions of Facebook users worldwide. Since its inception, millions of models have been trained on FBLearner and every day these models answer billions of real-time queries to personalize News Feed, show relevant Ads, recommend Friend connections, etc. &nbsp;</p>



<p>However, for most other companies <strong>building AI applications remains extremely expensive</strong>. This is primarily due to<a href="https://venturebeat.com/2018/05/06/forget-agi-lets-build-really-useful-ai-tools/"> a lack of systems and tools</a><strong> </strong>for supporting end-to-end machine learning (ML) application development — from data preparation and labeling to operationalization and monitoring [1][9][10][11]<strong>.</strong></p>



<p>The goal of this post is 2-fold: </p>



<ol><li>List the challenges with adopting AI successfully: data management, model training, evaluation, deployment, and monitoring; </li><li>List the tools I think we need to create to allow developers to meet these challenges: a data-centric IDE with capabilities like explainable recommendations, robust dataset management, model-aware testing, model deployment, measurement, and monitoring capabilities.</li></ol>







<figure><img src="https://lh4.googleusercontent.com/eHHhzc1HYAh18oRETgjri9drWQpHZwF6OkyDRJ5E4r9YxSwqRViLC6LDTOt4UGLhdg0zMmTj7ScuMCOStrJk_jcmLqRrOkm5z7qIDjEIsyeIi8vpw3q8wAhltmiWA3LfUjDGcT3J" alt=""></figure>



<p>In order to build an end-to-end ML platform, a data scientist has to go through multiple hoops of the following workflow [3].</p>



<div><figure><img src="https://lh3.googleusercontent.com/O29ZMh7AatXlnuiH8_QAxbnpcxrVvl_ioNedmGNdks2QMDJbSWt-XpN757fu41qtdpoNgZ_kNYWBOV70s8LSGnMjA96sfW7A6FVX2naSq1Ukav1WlnmD3br_gw4ijLGnG8DDg1L9" alt=""></figure></div>



<p><strong>End-to-End ML Workflow</strong></p>



<p>A big challenge to building AI applications is that different stages of the workflow require new software abstractions that can accommodate complex interactions with the underlying data used in AI training or prediction. For example:</p>



<p><strong>Data Management</strong> requires a data scientist to build and operate systems like Hive, Hadoop, Airflow, Kafka, Spark etc to assemble data from different tables, clean datasets, procure labeling data, construct features and make them ready for training. In most companies, data scientists rely on their data engineering teams to maintain this infrastructure and help build ETL pipelines to get feature datasets ready. </p>



<p><strong>Training models</strong> is more of an art than science. It requires understanding which features work and what modeling algorithms are suitable to the problem at hand. Although there are libraries like PyTorch, TensorFlow, Scikit-Learn etc, there is a lot of manual work in feature selection, parameter optimization, and experimentation.</p>



<p><strong>Model evaluation</strong> is often performed as a team activity since it requires other people to review the model performance across a variety of metrics from AUC, ROC, Precision/Recall and ensure that model is calibrated well, etc. In the case of Facebook, this was built into FBLearner, where every model created on the platform would get an auto-generated dashboard showing all these statistics. &nbsp;</p>



<p><strong>Deploying models </strong>requires data scientists to first pick the optimal model and make it ready to be deployed to production. If the model is going to impact business metrics of the product and will be consumed in a realtime manner, we need to deploy it to only a small % of traffic and run an<strong> A/B test</strong> with an existing production model. Once the A/B test is positive in terms of business metrics, the model gets rolled out to 100% of production traffic.</p>



<p><strong>Inference of the models </strong>is closely tied with deployment, there can be 2 ways a model can be made available for consumption to make predictions. </p>



<ul><li><strong>batch inference</strong>, where a data pipeline is built to scan through a dataset and make predictions on each record or a batch of records.</li><li><strong>realtime inference</strong>, where a micro-service hosts the model and makes predictions in a low-latency manner.</li></ul>



<p><strong>Monitoring predictions </strong>is very important because unlike traditional applications, model performance is non-deterministic and depends on various factors such as seasonality, new user behavior trends, data pipeline unreliability leading to broken features. For example, a perfectly functioning Ads model might need to be updated when a new holiday season arrives or a model trained to show content recommendations in the US may not do very well for users signing up internationally. There is also a need for alerts and notifications to detect model degradation quickly and take action. </p>



<div><figure><img src="https://lh3.googleusercontent.com/4Km_x5ON36tuOWCwHEXI1pvbchanrGvk6ZZr0Zv789WO1g25Qo6T2_St-fnLKIwfitW_l6c304-ZVppb2iz6QRcvcq_cWoQAwrk2XWh26ZhgydZxjXKC0T140HnuJ5hyAMuY9qMt" alt=""></figure></div>



<p>As we can see, the workflow to build machine learning models is significantly different from building general software applications. If models are becoming first-class citizens in the modern enterprise stack, they need better tools. As Tesla’s Director of AI Andrej Karpathy succinctly puts it, <strong>AI is</strong><a href="https://medium.com/@karpathy/software-2-0-a64152b37c35"><strong> Software 2.0</strong></a><strong> and it needs new tools</strong> [2].<br></p>



<figure><img src="https://lh6.googleusercontent.com/ZN2xWg5G0-EYYH2iEQ7b_Vza4SO9wU8YFrKfQyl3NlWatWmz2Z2hMsKtprxOofb7PtwZAXHfeKBjvyF9tKqE4aLSLDOSS_OvaTV1PZ10CbY4N2NEdHogmhoFRVpC3rb2fot3GO9x" alt=""></figure>



<p>If we compare the stack of Software 1.0 with 2.0, I claim we require transformational thinking to build the new developer stack for AI.</p>







<p>In Software 1.0, we have seen a vast amount of tooling built in the past few decades to help developers write code, share it with other developers, get it reviewed, debug it, release it to production and monitor its performance. If we were to map these tools in the 2.0 stack, there is a big gap!<br></p>



<blockquote><p>What would an ideal Developer Toolkit look like for an AI engineer?</p></blockquote>



<p>To start with, we need to take a <strong>data-first approach</strong> as we build this toolkit because, unlike Software 1.0, the fundamental unit of input for 2.0 is data. </p>



<p><strong>Integrated Development Environment (IDE): </strong>Traditional IDEs focus on helping developers write code, focus on features like syntax highlighting, code checkpointing, unit testing, code refactoring, etc. </p>



<figure><img src="https://lh6.googleusercontent.com/ArLnwbA3Hkj2cjWIVDKgHGTjLaNidh98es1ZdDFfETtPEdQpsUiVwuay3LKdkkKVa3Q33TR5PIZPo1ggbI9H1g6ZSv4RuhX8utUkLLI_b40h509nBk7OR3a34oKZ4DZa2cFgJvXj" alt=""></figure>



<p>For machine learning, we need an IDE that allows easy import and exploration of data, cleaning and massaging of tables. Jupyter notebooks are somewhat useful, but they have their own problems, including the lack of versioning and review tools. A powerful 2.0 IDE would be more data-centric, starts with allowing the data scientist to slice and dice data, edit the model architecture either via code or UI and debug the model on egregious cases where it might be not performing well. I see traction in this space with products like StreamLit [13] reimagining IDEs for ML.  <br></p>



<p>Tools like Git, Jenkins, Puppet, Docker have been very successful in traditional software development by taking care of continuous integration and deployment of software. When it comes to machine learning, the following steps would constitute the release process. </p>



<p><strong>Model Versioning:</strong> As more models get into production, managing the various versions of them becomes important. Git can be reused for models, however, it won’t scale for large datasets. The reason to version datasets is that to be able to <strong>reproduce a model</strong>, we need the snapshot of the data the model was trained upon. Naive implementations of this could explode the amount of data we’re versioning, think 1-copy-of-dataset-per-model-version. DVC [12] which is an open-source version control system is a good start and is gaining momentum. </p>



<p><strong>Unit Testing </strong>is another important part of the build &amp; release cycle. For ML, we need unit tests that catch not only code quality bugs but also data quality bugs. </p>



<div><figure><img src="https://lh6.googleusercontent.com/I99g74dfzW1-4MoswbrjtOeSnw7aH0W8UpbwdumvSxN0FgshNyH-Jpa1WNmsJ-uoNScx6qRnw7IfnWSdcEuZekOwX-UMDliYVP69vDAyGpi4CiD0LQfE_lrfYVUWaHmYIwwBqXmS" alt=""></figure></div>



<p><strong>Canary Tests</strong> are minimal tests to quickly and automatically verify that the everything we depend on is ready. We typically run Canary tests before other time-consuming tests, and before wasting time investigating the code when the other tests are failing [8]. In Machine Learning, it means being able to <strong>replay a previous set of examples</strong> on the new Model and ensuring that it meets certain minimal set of conditions. </p>



<p><strong>A/B Testing </strong>is a method of comparing two versions of an application change to determine which one performs better [7]. For ML, AB testing is an experiment where two or more variations of the ML model are exposed to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal. For example in the dashboard below, we’re measuring click conversion on an A/B experiment dashboard that my team built at Pinterest, and it shows the performance of the ML experiments against business metrics like repins, likes, etc. CometML [14] lets data scientists keep track of ML experiments and collaborate with their team members. </p>



<figure><img loading="lazy" width="1024" height="736" src="https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-1024x736.png" alt="" srcset="https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-1024x736.png 1024w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-300x216.png 300w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-768x552.png 768w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-1200x863.png 1200w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2.png 1260w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>                                     </figcaption></figure>



<p><strong>Debugging: </strong>One of the main features of an IDE is the ability to debug the code and find exactly the line where the error occurred. For machine learning, this becomes a hard problem because models are often opaque and therefore exactly pinpointing why a particular example was misclassified is difficult. However, if we can understand the relationship between feature variables and the target variable in a consistent manner, it goes a long way in debugging models, also called<a href="https://christophm.github.io/interpretable-ml-book/"><strong> </strong>model interpretability</a>, which is an active area of research. At Fiddler, we’re working on a product offering that allows data scientists to debug any kind of models and perform root cause analysis. </p>



<p><strong>Profiling: </strong>Performance analysis is an important part of SDLC in 1.0 and profiling tools allow engineers to figure out slowness of an application and improve it. For models, it is also about improving performance metrics like AUC, log loss, etc. Often times, a given model could have a higher score on an aggregate metric but it can be performing poorly on certain instances or subsets of the dataset. This is where tools like &nbsp;Manifold [5] can enhance the capabilities of traditional performance analysis. </p>



<p><strong>Monitoring: </strong>While superficially, application monitoring might seem similar to model monitoring and could actually be a good place to start, we need to track a different class of metrics for machine learning. Monitoring is crucial for models that automatically incorporate new data in a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/">https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/</a></em></p>]]>
            </description>
            <link>https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982113</guid>
            <pubDate>Tue, 03 Nov 2020 17:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming R at native speed using Haskell (2015)]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24981356">thread link</a>) | @behnamoh
<br/>
November 3, 2020 | https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Most good data stories start with a interesting question. If the
average request latency went down by a further 100ms, by how much
could we expect user engagement to increase? How can we detect
evidence of corruption of government officials given a list of all
bids nationwide for the building of new roads and repair of existing
ones? Can we identify a new pandemic in the making given a timeline of
common search terms? Often though, we know we have the data, but we
don’t even know what questions the data might help answer, or how the
story will unfold. From the data scientist who scratched an itch on an
idle afternoon, to a low latency, high availability, real-time
analysis deployed on hundreds of machines, the story typically
involves lots of rewrites, meanderings and building out of a lot of
code and utilities to improve the precision, speed or scale of the
analysis.</p>
<!--more-->
<p>R provides a great interactive environment for poking at the dataset
<em>du jour</em> and find what answers might be lurking in there. It provides
a wealth of readily available libraries for banging out an initial
story to tell. But R is a special purpose scripting language. Its
strength in supporting throwaway “do what I mean” programming to test
and iterate on hypotheses quickly becomes a hindrance when a model is
to be built out into an industrial scale, performant and maintainable
product or service. By then, a more general purpose language
encouraging structured, modular programming, providing strong static
guarantees of correctness and that compiles down to native code for
maximum speed becomes more appropriate. Haskell is such a language.</p>
<p>Mind you, Haskell makes for a great language to support rapid
iteration, “in the small” exploratory programming too, but it as of
yet lacks the plethora of high quality libraries from machine learning
to visualization that R provides, and perhaps also some syntactic
facilities to play it fast and loose. Today we’re proud to announce
the first public release of the
<a href="https://tweag.github.io/HaskellR/">HaskellR</a> project, which includes
a library and two interactive environments for seamlessly programming
in <em>both</em> R and Haskell in the same source file, or indeed at the same
prompt.</p>
<p>At the heart of the project lies <code>inline-r</code> (whose design later
inspired
<a href="https://www.fpcomplete.com/blog/2015/05/inline-c">inline-c</a> - they
share a coauthor), which exports a few quasiquoters for expressing
calls to R functions and indeed arbitrary R code in R’s syntax. The
principles behind the design of <code>inline-r</code> are,</p>
<ul>
<li>use R libraries the way R intends them to be used: using R’s syntax
and calling conventions;</li>
<li>keep the overhead of crossing language boundaries as low as possible
to encourage fine grained interleaving of code in both languages;</li>
<li>zero marshalling overhead in the common case;</li>
<li>optional typing of R data as executable documentation of what
functions expect and return;</li>
<li>let the user stoop as low or jump as high as (s)he likes in the
abstraction stack: everything is under the user’s control control in
case (s)he needs it.</li>
</ul>
<p>We’ll touch upon each of the above points in more detail below and in
future posts. But first, let’s get a taste of this stuff. You may want
to consider the below setup as your go-to interactive shell if you
haven’t already: it reuses existing projects and works much like GHCi,
in an isolated sandbox if you like, except that you have inline
graphics and formulas out-of-the-box, as Shae Erisson first pioneered
in the Haskell world with <a href="https://github.com/shapr/ghclive/">ghclive</a>
and Manuel Chakravarty realized more recently on OS X with
<a href="http://haskellformac.com/">Haskell for Mac</a>.</p>
<h2>Charts, code, prose and formulas in a playground</h2>
<p>HaskellR features two interactive prompts:</p>
<ul>
<li>a bare bones REPL, called H. This is a thin wrapper around GHCi
initializing it with all the right extensions and imports to hit the
road running;</li>
<li>an all singing, all dancing interactive notebook, powered by
<a href="https://jupyter.org/">Jupyter</a> (formerly IPython) and Andrew
Gibiansky’s fantastic
<a href="https://github.com/gibiansky/IHaskell">IHaskell</a> kernel.</li>
</ul>
<p>In this post, we’ll talk mostly about the latter. Thanks to
<a href="https://github.com/commercialhaskell/stack">stack</a>, getting started
with <strong>HaskellR</strong> is pretty straightforward, and more importantly,
comparatively reliable. We put together
<a href="https://hub.docker.com/r/tweag/haskellr/">a Docker container</a> to get
you started hassle-free. It includes <strong>Jupyter</strong> and <strong>IHaskell</strong>
preinstalled. To build <strong>HaskellR</strong> inside it:</p>
<div data-language="bash"><pre><code>$ <span>git</span> clone http://github.com/tweag/HaskellR
$ <span>cd</span> HaskellR
$ stack --docker build
$ stack --docker <span>exec</span> ihaskell <span>install</span></code></pre></div>
<p>And get started in your browser:</p>
<div data-language="bash"><pre><code>$ stack --docker <span>exec</span> ipython notebook</code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c1b63/haskellr-jupyter.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HaskellR in Jupyter" title="HaskellR in Jupyter" src="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/fcda8/haskellr-jupyter.png" srcset="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/12f09/haskellr-jupyter.png 148w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/e4a3f/haskellr-jupyter.png 295w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/fcda8/haskellr-jupyter.png 590w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/efc66/haskellr-jupyter.png 885w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c83ae/haskellr-jupyter.png 1180w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c1b63/haskellr-jupyter.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Or remain in your terminal:</p>
<div data-language="bash"><pre><code>$ stack --docker <span>exec</span> ipython</code></pre></div>
<p>With <strong>IHaskell</strong>, you can keep your notes and formulas together with
your code in one place, called a notebook. With <strong>HaskellR</strong>’s plugin
for <strong>IHaskell</strong>, you can use widely acclaimed and very popular
R visualization packages such as <a href="http://ggplot2.org/">ggplot2</a> for
embedding plots in your notebook. Working in notebooks (aka
<a href="http://blog.haskellformac.com/blog/from-the-read-eval-print-loop-to-playgrounds">playgrounds</a>)
is convenient: they are self contained units that is easy to share
with colleagues, via email or
<a href="https://nbviewer.jupyter.org/">on the web</a>, and you can edit earlier
definitions while keeping the later ones in sync.</p>
<p>Here’s a simple example of using R’s data analysis facilities on data
generated in Haskell. Say you have a cluster of noisy data. We’ll use
the <code>random</code> package to generate a sample set:</p>
<div data-language="haskell"><pre><code><span><span>import</span> Control.Monad</span>
<span><span>import</span> System.Random.MWC <span>as</span> MWC</span>
<span><span>import</span> System.Random.MWC.Distributions</span>

<span>main</span> <span>=</span> <span>do</span>
  <span>gen</span> <span>&lt;-</span> <span>MWC.create</span>
  <span>xs</span> <span>&lt;-</span> <span>replicateM</span> <span>500</span> <span>$</span> <span>normal</span> <span>10</span> <span>3</span> <span>gen</span>
  <span>ys</span> <span>&lt;-</span> <span>replicateM</span> <span>500</span> <span>$</span> <span>normal</span> <span>10</span> <span>3</span> <span>gen</span>
  <span>...</span></code></pre></div>
<p>We can now plot the list of x-ordinates against the list of
y-ordinates using R’s standard library <code>plot()</code> function:</p>
<div data-language="haskell"><pre><code>  <span>[</span><span>r</span><span>|</span> <span>plot</span><span>(</span><span>xs_hs</span><span>,</span> <span>ys_hs</span><span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Randomly generated points" title="Randomly generated points" src="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png" srcset="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/12f09/haskellr-plot1.png 148w,
https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e4a3f/haskellr-plot1.png 295w,
https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>Better yet: say we want some kind of visualization of the density
estimation of these points. We can use R’s 2D kernel density
estimation function, available out-of-the-box:</p>
<div data-language="haskell"><pre><code><span>[</span><span>r</span><span>|</span> <span>k</span> <span>&lt;-</span> <span>kde2d</span><span>(</span><span>Xv</span><span>,</span> <span>Yv</span><span>,</span> <span>n</span><span>=</span><span>500</span><span>)</span>
    <span>image</span><span>(</span><span>k</span><span>,</span> <span>col</span><span>=</span><span>topo</span><span>.</span><span>colors</span><span>(</span><span>8</span><span>)</span><span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Density estimation for our random points" title="Density estimation for our random points" src="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png" srcset="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/12f09/haskellr-plot2.png 148w,
https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e4a3f/haskellr-plot2.png 295w,
https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>Notice how in the above, some code appears delineated in
quasiquotation blocks. This is a syntactic facility to tell the
Haskell compiler that any code inside the block should be understood
to be in R’s syntax, not Haskell’s syntax as is normally the case
outside of these blocks. We implemented a mechanism to get an embedded
instance of the R interpreter to parse that code for us, so that we
don’t have to grok R’s full surface syntax ourselves.</p>
<p>By convention, <code>_hs</code> suffixed variables don’t refer to bindings in the
R environment, but rather to bindings in the Haskell environment. In
technical terms, these variables are actually
<a href="https://downloads.haskell.org/~ghc/7.8.4/docs/html/users_guide/template-haskell.html">antiquotations</a>
(we use convention over extra syntax so that we can reuse R’s stock
parser as-is and not implement our own). Antiquotation is the
fundamental mechanism for communicating data between R and Haskell. In
common cases, we can do so with no marshalling at all, so you can
cross the language boundaries repeatedly in a tight loop with impunity
if you like.</p>
<h2>Elements of design</h2>
<p>The core idea behind <strong>HaskellR</strong> is that language interop should be
zero-cost, or close to. There should be no reason why you would
hesitate to dip into a little bit of R to get the job done, over
reimplementing the same thing in Haskell because you’re worried about
performance or the cost of sending large volumes of data to some
remote R interpreter instance. We believe that making foreign calls
practically as fast as native calls is the key to making the
experience programming with both <a href="https://cran.r-project.org/">CRAN</a>
and <a href="https://hackage.haskell.org/">Hackage</a> package functions at the
same time seamless.</p>
<p>To this end, we decided to embed the R interpreter instance, that is
to say link together in the same binary the C code of the
R interpreter with the Haskell code of Haskell programs. In this way,
we can communicate with the R interpreter in the same process address
space. Many R functions are actually written in C, for speed, and
compile down to native code. Some of these primitives can be called
from Haskell as cheaply as any other foreign function call.</p>
<p>But that’s not the end of the performance story. A typically vexing
issue in cross-language programming is that the one language insists
on one representation of the data, while the other language wants its
own representation. Therefore, data typically has to be marshalled
from one representation to another constantly. In <strong>HaskellR</strong>, we
solved that problem in the following way: just use R’s representation
throughout. It’s the form that R functions expect, so they can get
straight to computing on that data when called. The trouble is, R’s
data representation is foreign to Haskell, so you lose Haskell’s
extremely powerful language facilities that work with any native
algebraic datatype, such as pattern matching. Or do you?…</p>
<p>The trick to get the best of both worlds, zero marshalling but also
pattern matching, is to define so-called view functions that provide
you with a native view as an algebraic datatype of the foreign data.
Here’s a toy and contrived example, where we define the factorial
function in Haskell but over R integers:</p>
<div data-language="haskell"><pre><code><span>fact</span> <span>::</span> <span>SEXP</span> <span>s</span> '<span>R.Int</span> <span>-&gt;</span> <span>R</span> <span>s</span> <span>(</span><span>SEXP</span> <span>s</span> '<span>R.Int</span><span>)</span>
<span>fact</span> <span>(</span><span>hexp</span> <span>-&gt;</span> <span>Int</span> <span>[</span><span>0</span><span>]</span><span>)</span> <span>=</span> <span>R.cast</span> <span>sing</span> <span>&lt;$&gt;</span> <span>[</span><span>r</span><span>|</span> 1L <span>|</span><span>]</span>
<span>fact</span> <span>n</span><span>@</span><span>(</span><span>hexp</span> <span>-&gt;</span> <span>Int</span> <span>_</span><span>)</span> <span>=</span>
    <span>R.cast</span> <span>sing</span> <span>&lt;$&gt;</span> <span>[</span><span>r</span><span>|</span> <span>n_hs</span> <span>*</span> <span>fact_hs</span><span>(</span><span>n_hs</span> <span>-</span> 1L<span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><code>hexp</code> is a view function, mapping native R data (everything is
a <code>SEXP</code> internally in R) to a Haskell-native GADT. Thanks to the type
annotations (more on that in future posts), we know statically that
the R data can only be some kind of integer vector, so we pattern
match on that, check whether it’s the singleton zero vector or not,
and recurse.</p>
<p>Aren’t we now back to marshalling? Yes and no! We carefully engineered
these view functions to be non-recursive. Non-recursive functions can
be inlined. So that when you use a view function only to pattern match
on the result immediately afterwards, as is the case above, <strong>GHC</strong> is
smart enough to recognize that the view function is constructing
a datatype value only to destructure it later, so it simplifies the
allocation away! Yes this is marshalling of sorts, but it’s
marshalling for free: there is no trace of it at runtime.</p>
<p>There’s plenty more to talk about regarding the design of
<strong>HaskellR</strong>, but this post is already …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/">https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981356</guid>
            <pubDate>Tue, 03 Nov 2020 16:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got 10k post karma on Reddit with (and without) fast.ai]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 92 (<a href="https://news.ycombinator.com/item?id=24981153">thread link</a>) | @ameerkat
<br/>
November 3, 2020 | https://www.a8b.io/posts/10k-karma-reddit-bot/ | <a href="https://web.archive.org/web/*/https://www.a8b.io/posts/10k-karma-reddit-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

    

    
      

    

    
<p><a href="https://www.a8b.io/posts/10k-karma-reddit-bot/" title="How I got 10k post karma on reddit with (and without) fast.ai">
        <img src="">
    </a>
</p>



    <figure>
    <img src="https://www.a8b.io/images/reddit/reddit_badge.png#mid" alt="My reddit profile with 10,088 post karma">
    <figcaption>Profile image made by AI Gahaku</figcaption>
  </figure>

<p>Back in 2006-2007 my friend and I put together a spreadsheet of 20 or so high-level achievements called “Everything’s a Contest”. This included goals like “Photograph a live grizzly bear in the wild”, “Have something named after you”, and <em>“Get 10,000 (post) karma on Reddit”</em>. Despite our heated discussions about what should be on this list and the criteria for success none of us ever really did anything substantial to complete any of these goals. In early 2020 I decided to tackle one of these long-standing contests. <em>But I was going to do it with AI since I wanted to see how I could apply AI to more of my problems</em>. I’m a huge fan of <a href="https://www.fast.ai/">fast.ai</a> and I appreciate its high-level abstractions and simple interfaces. For someone trying to get into deep learning, I would highly recommend it and the associated courses. This is a post about how I built a bot to gain karma on Reddit with fast.ai.</p>
<h2 id="approach">Approach</h2>
<p>Content on Reddit, in general, falls into two categories which you might call original content and found content. Trying to automate generating original content to post would be implementing something like <a href="https://imgflip.com/ai-meme">imgflip’s AI meme generator</a> and posting the resulting content to r/memes. While the memes that are generated are an amusing juxtaposition of tropes, they generally aren’t as good as memes that are generated by human users skilled in the art of observational comedy. Try the meme generator out and you’ll see what I mean. At some point, I did try posting one of those just to see how well it did.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/3migr03n6m251.jpg#mid" alt="Drake meme with text Staying in the Server / Watching Anime">
    <figcaption>I went through about 100 auto generated memes before I got this. This post got ~35 points with the title 'An AI generated this meme. Good to know it's putting its sentience to good use.'</figcaption>
  </figure>

<p>The other approach would be finding content online and posting it. I chose this route for automation because while generating high-quality content is more interesting it’s also far more challenging and involved. Rather than being disadvantaged in trying to catch up to the “human quality” of content, a computer is at the advantage since the primary differentiator between posters is the ability to search through large amounts of content and speed (who finds and posts something first). In particular, I ended up looking at news based subreddits due to a few reasons:</p>
<ul>
<li>Little chances of content being a repost</li>
<li>Lots of content being generated frequently</li>
<li>Large member bases</li>
<li>A lot of the content comes from the same set of known sites</li>
</ul>
<figure>
    <img src="https://www.a8b.io/images/reddit/business_submissions_by_domain.png" alt="">
    <figcaption>Domains for all the &gt; 1 score articles from /r/business in the last week as of October 29th 2020, showing the top few sites supply the majority of content.</figcaption>
  </figure>

<p>Why use AI at all though? If I was going to automate posting why not just create a bot that submits all links and leaves it up to the masses to sort my fate. In general, spamming on Reddit is looked down upon, though I believe banning is up to the discretion of the subreddit moderators. While in theory I might have gotten away with it or used some sort of generic rate-limiting and hope for the best, I wanted my bot to be more like a productive member of the community submitting thoughtful content, an extension of myself, rather than a spam bot that would be the bane of its existence until forcibly removed.</p>
<p>I searched for and found many good news subreddits but I targeted initially /r/business and /r/worldnews, somewhat arbitrarily and somewhat because those areas seemed interesting to me. /r/business had a sizeable community (577k members) and relatively low frequency of posts for a news subreddit so it seemed approachable as a first target. I would build a web crawler to watch popular business news sites for new articles, and then leverage an NLP-based article classifier to determine if the article had a high chance of receiving upvotes.</p>
<h2 id="implementation">Implementation</h2>
<h3 id="finding-and-loading-posts">Finding and loading posts</h3>
<p>To train the NLP model that will classify articles I need the article text and their corresponding Reddit scores. Unfortunately, the official Reddit API limits the amount of historic post data you can retrieve to 1000 items. Luckily there is an alternative, you can grab historic post data from <a href="https://pushshift.io/">pushshift.io</a> using code I shamelessly adapted from <a href="https://www.osrsbox.com/blog/2019/03/18/watercooler-scraping-an-entire-subreddit-2007scape/">WaterCooler: Scraping an Entire Subreddit (/r/2007scape)</a>. The output file of the script has individual lines like the one below, containing a JSON object of a post per line:</p>
<pre><code>{"author": "CALIPHATEMEDIA", "author_flair_css_class": null, "author_flair_text": null, "brand_safe": true, "can_mod_post": false, "contest_mode": false, "created_utc": 1514767344, "domain": "caliphatemedia.info", "full_link": "https://www.reddit.com/r/business/comments/7nc5yf/south_korea_to_regulate_bitcoin_trading_further/", "id": "7nc5yf", "is_crosspostable": false, "is_reddit_media_domain": false, "is_self": false, "is_video": false, "locked": false, "num_comments": 0, "num_crossposts": 0, "over_18": false, "parent_whitelist_status": "all_ads", "permalink": "/r/business/comments/7nc5yf/south_korea_to_regulate_bitcoin_trading_further/", "pinned": false, "retrieved_on": 1514841750, "score": 1, "selftext": "", "spoiler": false, "stickied": false, "subreddit": "business", "subreddit_id": "t5_2qgzg", "subreddit_type": "public", "thumbnail": "default", "thumbnail_height": 140, "thumbnail_width": 140, "title": "South korea to regulate bitcoin trading further with tougher measures", "url": "http://www.caliphatemedia.info/2017/12/south-korea-govt-to-introduce-tougher.html", "whitelist_status": "all_ads"}
</code></pre><p>After generating a file with all the historic posts, I loaded the contents referenced by the “url” field of each JSON line into <a href="https://github.com/slaveofcode/boilerpipe3">boilerpipe3</a> which is a python library that simplifies HTML documents into their primary content text.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/reuters_article.jpg" alt="">
    <figcaption>boilerpipe3 simplifies this (mostly) down to what we really want which is 'By Jeffrey Dastin, Akanksha Rana 4 Min Read (Reuters) - Amazon.com INC AMZN.O on Thursday...'</figcaption>
  </figure>

<p>After loading the article text I did some processing to remove pages that didn’t load properly and to truncate page text to 10k characters at most.</p>
<h3 id="training-the-model">Training the model</h3>
<p>I trained the NLP model for /r/business over a few days on approximately 271k articles from 2018-01-01 to mid-April 2020. I used an <a href="https://docs.fast.ai/text.models.awdlstm">AWD_LSTM</a> (e.g. <code>language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)</code> and <code>text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)</code>) for the model with discrete labels based on the article score: neutral (0-10 points), okay (10-100), good (100-500), and great (500+). The classes are kind of arbitrary and I’ve changed them around for different iterations and subreddits. The only thing I ended up paying attention to at runtime was the non-neutral class score, so this could have been a binary classifier or even better a classifier that looks at an individual article as a candidate for multiple subreddits rather than training an individual model per subreddit. For world news I had around double the number of articles. In either case I trained in 100k article chunks due to memory limitations, reloading the existing model and tuning with the new data each time.</p>

<h3 id="building-the-bot">Building the bot</h3>
<p>I chose a few sites (Business Insider, Reuters, Bloomberg, CNN, CNBC, BBC, etc.) based on frequent sites for /r/business and put them into a script and built a crawler using requests and BeautifulSoup. Every minute or so I’d crawl the site root for new links and process the linked page with boilerpipe and pass it through the NLP model for scoring. New pages with a non-neutral score of greater than 0.25 (an arbitrary threshold I picked for this particular model) would be flagged and emailed to me using AWS SNS. Initially, I relied on filtering these incoming suggestions and submitting the articles myself using the Reddit app.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/example_email.png" alt="">
    <figcaption>An example email I received from my site poller that I called 'Reddit Postmaster'.</figcaption>
  </figure>

<h2 id="automation">Automation</h2>
<p>My site poller is acting as a personal news aggregator that I use to generate suggestions for things to post. To remove me from this loop there are a few “last mile” problems to solve. Coding up submitting via the Reddit API is easy enough, but I don’t just submit all the articles that get passed to me, I act as a quality filter choosing not to submit things which don’t seem appropriate. I also gather an appropriate title for the Reddit post. The page title is usually not good as a post title (for example containing redundancies like the site name) directly and needs to be reformatted or the title should instead be extracted from the content for example by picking the most appropriate h1 tag on the page. Rather than refining the model to be better at classifying articles and improve the accuracy of the scoring mechanism, and then coding a new component for extracting the title, I decided to try to encapsulate these tasks into a mechanical turk task and have humans as the final gate-keeper and title generator. I can take the results from these mechanical turk tasks and submit the articles to Reddit via the Reddit API utilizing those results.</p>
<h3 id="mechanical-turk">Mechanical Turk</h3>
<p>Mechanical turk is a service for leveraging humans to complete small tasks for your application. It’s great for augmenting AI applications and collecting data via labeling tasks for them. But using it effectively isn’t without difficulties. The important thing to know about mechanical turk is that many workers on the platform are (sensibly) optimizing for task completion quantity. When using a custom qualifier for tasks, ensure the qualification you’re looking for is not apparent from the question. Similarily a bad HIT (human intelligence task) would be one where you ask the user to read an article and check some box if they think it belongs in some category. For example, I did this with /r/worldnews candidates to ensure that among other things didn’t pertain to US news, however the first fully automated submission I made to /r/worldnews was “Johnson &amp; Johnson to stop selling baby powder in the United States” which was …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.a8b.io/posts/10k-karma-reddit-bot/">https://www.a8b.io/posts/10k-karma-reddit-bot/</a></em></p>]]>
            </description>
            <link>https://www.a8b.io/posts/10k-karma-reddit-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981153</guid>
            <pubDate>Tue, 03 Nov 2020 16:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Practical Introduction to Container Security]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24980928">thread link</a>) | @gbrindisi
<br/>
November 3, 2020 | https://cloudberry.engineering/article/practical-introduction-container-security/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/practical-introduction-container-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <p>Securing containers is a complex task.  The problem space is broad, vendors are on fire, there are tons of checklists and best practices and it’s hard to prioritize solutions. So if you had to <strong>implement a container security strategy</strong> where would you start?</p>

<p>I suggest to start from the basics: understanding <strong>what container security is about</strong> and build a model to navigate risks.</p>

<h2 id="follow-the-devops-life-cycle">Follow the DevOps Life Cycle</h2>

<p>Every security initiative is eventually constrained by where security controls can be implemented, so I find practical to just follow the standard DevOps life cycle to <em>surface patterns™</em> and <em>unlock synergies™</em>.</p>

<p>The DevOps Lifecycle is an infinite iteration of:</p>

<ul>
<li>Plan</li>
<li>Code</li>
<li>Build</li>
<li>Test</li>
<li>Release</li>
<li>Deploy</li>
<li>Operate</li>
<li>Monitor</li>
</ul>

<p><img src="https://cloudberry.engineering/devops-lifecycle.jpg" alt="DevOps Lifecycle - source: ryadel.com"></p>

<p>Containers are included in the application in the form of a Dockerfiles but are not really part of it. As such they don’t interest the planning and coding phase.</p>

<p><em>(no, writing Dockerfiles is not coding.)</em></p>

<p>Every other step is in scope from a security point of view, and I would group them like this:</p>

<ul>
<li><strong>Build Time</strong>: build, test and release.</li>
<li><strong>Container Infrastructure</strong>: deploy and operate.</li>
<li><strong>Runtime</strong>: monitor.</li>
</ul>

<p>Why? Every security strategy is only effective if it can be implemented. And every step in each group share a common facility where security controls can be injected without adding much friction:</p>

<ul>
<li>Build Time: The CI/CD infrastructure, the container registry</li>
<li>Container Infrastructure: the container orchestrator</li>
<li>Runtime: the production environment</li>
</ul>

<p>Now we have three macro areas we can use as a starting point to do our risk assessments.</p>

<h2 id="security-at-build-time">Security at Build Time</h2>

<p>At build time we have in input a bunch of source files and a Dockerfile, and we get as output a Docker image.</p>

<p>This is where most vendors tend to cluster while trying to sell you the narrative of the importance of scanning container images and calling it a day.  Container security scanning is important, yes, but it’s not enough.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>minimize the risk of supply chain attacks.</li>
</ul>
</div>


<h3 id="container-images-hygiene">Container Images Hygiene</h3>

<p>First, decide how your images should look like, with a focus on how software dependencies are introduced:</p>

<ul>
<li>what base images are developers allowed to use?</li>
<li>are software dependencies pinned? From where are they pulled?</li>
<li>are there any labels that are needed to simplify governance and compliance?</li>
<li>lint the Dockerfile</li>
<li>follow <a href="https://cloudberry.engineering/article/dockerfile-security-best-practices/">Dockerfile security best practices</a></li>
</ul>

<p>All of these checks are static and can be implemented for cheap as a step in the build pipelines.</p>

<h3 id="container-images-scanning">Container Images Scanning</h3>

<p>Then we can move into scanning the container image.</p>

<p><strong>Do not scan the image as a step in the build pipeline</strong>, instead setup continuous scanning in the container registry.</p>

<p>Why? Vulnerabilities are continuously discovered while your services are not necessarily continuously built. Secondly, builds are additive: every build will generate a new image. So, assuming  your container orchestrator trust your registry, every tag you publish can always be deployed and need to be assessed.</p>

<p><em>(It’s also very slow to scan at build time)</em></p>

<p>This is where you start thinking about defining <strong>patch management</strong> and <strong>shelf life</strong> processes:</p>

<ul>
<li>patch management: results from the scanning will feed a patching process that will result in a new version of the image</li>
<li>shelf life: unpatched/old/unsafe images are deleted from the registry</li>
</ul>

<p><em>(next article will be about how to choose a container scanning solution, if you are facing the dilemma right now feel free to <a href="mailto:hello@clouberry.engineering">ping me</a>)</em></p>

<h2 id="container-infrastructure-security">Container Infrastructure Security</h2>

<p>The container infrastructure is comprised of all the moving parts that are in charge of pulling your images from the registry and run them as containers in production.</p>

<p>It’s mostly going to be the container orchestrator – <em>*cough* kubernetes *cough*</em>.</p>


<div>
<p><strong>This stage goals</strong>:</p>

<ul>
<li>Avoid platform misconfigurations with security implications</li>
<li>Minimize the <strong>breadth</strong> of an attack from a compromised container</li>
</ul>
</div>


<h3 id="security-of-the-infrastructure-misconfigurations">Security OF the Infrastructure: Misconfigurations</h3>

<p>Container orchestrators are complex, Kubernetes in particular. As of now they fail the promise of DevOps and I think we are still an abstraction layer (or two) away from being a mainstream solution without too much operational overhead.</p>

<p>Every complex platforms is prone to be misconfigured, and this is the part you want to focus on.</p>

<p>You have to threat model your infrastructure to <strong>ensure it can’t be abused</strong>.
This particular thread model should focus on every actor but a compromised container (we will cover that next).</p>

<p>I can’t go into details here, because it really depends on what you are running. For Kubernetes a good starting point for threat modelling is <a href="https://www.marcolancini.it/2020/blog-kubernetes-threat-modelling/">this</a>.</p>

<p>Additionally, if you are not doing it yet, this is also a <strong>good argument in favour of using a managed platform</strong>: the complexity is reduced if you can leverage a shared responsibility model with your (trusted) provider.</p>

<h3 id="security-in-the-infrastructure-lateral-movements">Security IN the infrastructure: Lateral Movements</h3>

<p>Next we can talk about what happens when a container is compromised.</p>

<p>You want to minimize the <a href="https://cloudberry.engineering/article/lateral-movement-cloud/">attacker’s ability to move laterally</a>, focusing on these two layers:</p>

<ul>
<li>The network layer</li>
<li>The Identity and Access management (IAM) layer</li>
</ul>

<p><strong>The network should not be flat</strong>. You can start by brutally segment everything into subnetworks and work your way up to a full fledge service meshes.</p>

<p>On the IAM layer work your way toward having a <strong>single identity for each container</strong> in order to fine tune the authorization grants. This is particularly important in multi tenant platforms: without granular identities it’s impossible to achieve least privilege.</p>

<p><em>(Google Kubernetes Engine (GKE) has a nifty feature for this called <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a>)</em></p>

<p>Finally, since they are supposed to be immutable, a wonderful strategy would be to <strong>reduce the amount of time containers can run</strong>: the window of opportunity for attackers to move laterally and gain persistence is as long as the container running lifetime. Continously shut down and spin up your containers.</p>

<p>And this final consideration allow me to smoothly move into the next area.</p>

<h2 id="runtime-security">Runtime Security</h2>

<p>The last piece of the puzzle is the security of your running workloads.
At this point most of the hardening is done and here is when we move into the realm of reactive security controls, the grim land of <strong>post-fail</strong>.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>is to minimize the <strong>impact</strong> of an attack from a compromised container.</li>
</ul>
</div>


<h3 id="detection-and-incident-response">Detection and Incident Response</h3>

<p>The best way to control the impact of an attack is to minimize the time between the breach to when the security team is alerted.</p>

<p>Detecting an ongoing breach is another area where vendors are scrambling to find a silver bullet. There are many approaches, most of them will require side cars and/or daemon sets actively monitoring pod’s traffic and system calls.</p>

<p>Most solutions will provide some value but my advice is to start simple and iterate: use your existing SIEM, ingest your platform, application and audit logs.</p>

<p><strong>Incidents will happen</strong>, and it’s fine: have an incident response process.</p>

<p>The first bullet point of every post-mortem should be: <em>“how can we detect this quicker next time?”</em> answering will allow you to identify your blind spots, which you can then use to understand what signals you are missing and what makes sense to buy.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Container security is a broad problem and it is not just about scanning images.</p>

<p>This is the model I built and used to reason about container risks and solutions. It’s very high level and of course, as with every model, <strong>it’s not necessarily the right one</strong>.</p>

<p>We all know that in reality each infrastructure is a snowflake: so start with your own threat model and use this one <strong>as an inspiration</strong>.</p>
        </div>
        
    </div>
</section></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/practical-introduction-container-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980928</guid>
            <pubDate>Tue, 03 Nov 2020 16:15:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good news – The U.S. House Passes the IoT Cybersecurity bill]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980921">thread link</a>) | @Prototype_
<br/>
November 3, 2020 | https://mender.io/blog/good-news-the-u-s-house-passes-the-iot-cybersecurity-bill | <a href="https://web.archive.org/web/*/https://mender.io/blog/good-news-the-u-s-house-passes-the-iot-cybersecurity-bill">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>

              
    <div>
      
            
      <p>Recently, the House of Representatives in the United States passed the <a href="https://www.ssa.gov/legislation/legis_bulletin_092220.html" target="_blank">IoT Cybersecurity Improvement Act of 2020</a>. This is a landmark bill whose goal is to improve the security of IoT devices. Given the bi-partisan support for the bill, it is likely to pass the Senate and soon be put into action. This represents a powerful win for everyone who truly cares about security as we enter an increasingly digital world where the virtual command controls the physical space.</p>
<p><strong>What is this regulation?</strong></p>
<p>In short, this bill will require IoT device vendors to comply with a basic minimum set of security measures. These security measurements include things like vulnerability scanning and security patching, not using hard-coded passwords, and so on. If you want all the details on this new regulation, please check out the legislation pages on Congress.gov <a href="https://www.congress.gov/bill/116th-congress/house-bill/1668?q=%7B%22search%22%3A%5B%22H.R.%2B1668%22%5D%7D&amp;s=1&amp;r=1%3Ftarget%3D_blank">here</a>.</p>
<p>Once enacted, the US Federal government will only be allowed to purchase IoT devices from vendors that comply with this regulation. This means that unless a vendor can prove that it complies with the security measures, the US Federal Government is prohibited from purchasing from them. </p>
<p>The stakes have been raised for vendors as security compliance requirements to participate in the market have just been increased dramatically.</p>
<p><strong>Why is this good news?</strong></p>
<p>There are too many IoT vendors in the market today who are not serious enough in their attitude to address security concerns. These are often vendors with shiny websites and rock-bottom pricing, but who have a complete lack of understanding the very serious security needs of the market at hand. Highly insecure and fragile internet connected devices are being pushed into the market on a massive scale. Thankfully, this new regulation will put an end to much of this, or at least so in the US public sector.</p>
<p>Fortunately, there are vendors like <a href="https://mender.io/">Mender</a>, who take security as their prime directive and put you in an enviable position of being able to win more contracts, as you will have a distinct competitive advantage over others who would have to add security measures so playing catch up to you, or else find other marketplaces. </p>
<p>Mender users care inherently about the security of their IOT devices. This valiant and noble attitude has now become a competitive advantage to win deals with the US Federal Government, which is one of the largest purchasers in the world.</p>
<p>Finally, it is the hope that the purchasing power of the US Federal Government is so strong that it will positively impact the private market and buyers as well. </p>
<p>We are moving in the right direction, and the sooner you can ensure proper security measures on connected devices you provide to the market, the better prepared you will be for the future.</p>


              
      

              

        
          </div>


    
 
    

          </div>
        </div></div>]]>
            </description>
            <link>https://mender.io/blog/good-news-the-u-s-house-passes-the-iot-cybersecurity-bill</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980921</guid>
            <pubDate>Tue, 03 Nov 2020 16:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Color-balancing vote margins and vote totals in the US election map]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24979807">thread link</a>) | @mygo
<br/>
November 3, 2020 | https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/ | <a href="https://web.archive.org/web/*/https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

			<!-- start: #header -->

<!-- end: #header -->




			


<!-- start: #single -->
<main id="single" role="main">

    
    <!-- start: .center -->
    <div>


            <!-- start: .content -->
            <div>

                <article>

                        <header>
                            
                                <p><img src="https://stemlounge.com/content/images/size/w1500/2019/10/muddy_america_2016_weru_animated-1.gif">
                                    
                                </p>

                            <!-- start: .meta -->
                            
                            <!-- end: .meta -->

                            

                        </header>

                    <section>


                        <div><p>Graphs can inform, and informed discussions can be more civil than uninformed ones. But graphs can also mislead, so we need to understand what a graph is saying when we're using it. In 2015 I gave gave a TEDx talk on making clearer election maps. The original recording was lost, then recovered and <a href="https://www.youtube.com/watch?v=U5qn33KR7us">uploaded to Youtube</a> this summer. As election season ramps up, I'd like to continue the discussion by talking about this often-misleading map.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/countywinner_2016.png"><figcaption>2016 County-Level Winner-Takes-All map</figcaption></figure><!--kg-card-end: image--><p>Different graphs are designed for different purposes. The graph above is a county-level winner-takes-all map. I'll call it a County Winner map for short. Scientists use it to quickly see which way the counties went in an election. While there is arguably no better map for seeing who won in which county, this map can be misleading when used for other purposes. We need to be aware of two of its characteristics:</p><ol><li>It doesn’t express the <strong>relative voting populations</strong> between each county. Instead, it can make people feel like each county has the same population.</li><li>It’s not designed to express the <strong>margin of victory</strong> within each county. It shows who won in a county, even if they won by just one vote. It’s a winner-takes-all graph, after all.</li></ol><h3 id="relative-voting-population">Relative Voting Population</h3><p>Half of the US population lives in these counties:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/image-1.jpg"><figcaption>Half lives in blue. Half lives in gray. Census/Business Insider</figcaption></figure><!--kg-card-end: image--><p>America can be described as a collection of densely populated metros buffered by less densely populated communities. Here’s what the “population mountains” look like:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/where_we_live_pop_lg.jpg"><figcaption>This map of U.S. population density appeared in Time magazine Oct. 30, 2006 issue.</figcaption></figure><!--kg-card-end: image--><p>When we take the County Winner map and resize each county’s land-area to be proportionate to its population, here’s how the US looks.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/image-4.jpg"><figcaption>Mark Newman, University of Michigan</figcaption></figure><!--kg-card-end: image--><p>One downside to the cartogram, however, is that the shape and location of many territories are distorted beyond recognition. This is maybe one reason why the cartogram isn't very mainstream.</p><p>The County Winner map, however, doesn’t convey this relative population information. It's not designed to. But one might think it does. </p><h3 id="margin-of-victory">Margin of Victory</h3><p>In the general election, there are 50 concurrent presidential races, one for each state. In some of these states, the margin of victory turns out to be very small. In New Hampshire, <code>743,117 votes</code> were cast for the president in the 2016 general election. Hillary Clinton won New Hampshire by <code>2,701 votes</code>. We can seat as many people in a set of high school football bleachers.<br></p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/IMG_2944.jpeg"><figcaption>How New Hampshire was won.</figcaption></figure><!--kg-card-end: image--><p>There was a <code>75.03% turnout</code> in New Hampshire, so more people could have voted that didn’t. If just 2,702 more eligible voters in New Hampshire exercised their right to vote and voted for Trump, then New Hampshire would have gone to Trump instead. With such hair thin margins, New Hampshire is neither Blue nor Red in 2016. It’s <code>50:50</code> and leaning red or blue depending on traffic and dinner plans. It would be misleading to have all of New Hampshire colored as either blue or red to represent the statewide popularity of a presidential candidate. </p><p>This characteristic also holds true at the county level. The losing candidate in a county can receive a significant number of votes. In many counties the winner won by less than a 25% margin.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/2016_margin_histogram_rb.jpg"><figcaption>Kenneth Tay, Stanford University. Modified to add color to the scale and to highlight 25% range.</figcaption></figure><!--kg-card-end: image--><h6 id="a-margin-of-0-is-50-50-clinton-s-county-level-percent-win-margins-are-on-the-left-trump-s-county-level-percent-win-margins-are-on-the-right-the-yellow-area-highlights-counties-won-with-vote-margins-within-25-note-that-these-are-percent-vote-margins-not-absolute-vote-margins">A margin of 0 is 50:50. Clinton's county-level percent-win margins are on the left. Trump's county-level percent-win margins are on the right. The yellow area highlights counties won with vote margins within 25%. Note that these are percent vote margins, not absolute vote margins</h6><p>In general, smaller counties were won by larger percent margins. Larger counties were won by smaller percent margins. So in the counties with the most votes cast, the runner up got a lot of votes, too. </p><p>Here’s what the County Winner map looks like when we account for vote margins by blending each red and blue vote together within each county. Purple represents 50:50:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/purple-map-2016.png"><figcaption>2016 Purple Map</figcaption></figure><!--kg-card-end: image--><p>The neutralizing map is designed to express vote margins more clearly. It uses a grey intermediary, adjusting for <a href="https://www.fastcompany.com/3035951/the-glaring-design-flaw-in-us-election-maps">the way humans perceive purple</a>. Here’s the 2016 neutralizing map:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/2016_neutralizing_map.png"><figcaption>2016 Neutralizing Map</figcaption></figure><!--kg-card-end: image--><p>Rarely are all of the votes in a county cast for one candidate. The County Winner map, however, doesn’t convey this win margin information.</p><p>The contiguous United States aren't very contiguous. The County Winner map's inability to express vote population and margin of victory can be misleading. Cartograms account for population, but they distort the shape of the US, which can add confusion. The neutralizing map accounts for vote margin, but it doesn't account for population.</p><p><strong>Can we construct a single map that shows both vote margin and vote population without distorting the shape of the US?</strong></p><p>Here's one way:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_america_2016_weru_animated.gif"><figcaption>Animated GIF that goes from the County Winner map to old muddy.</figcaption></figure><!--kg-card-end: image--><p>Here's a less-distracting, static version of the graph:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_america_2016_static-1.png"></figure><!--kg-card-end: image--><p>The map leverages Color Theory to express <code>vote margins</code> and <code>vote populations</code> in a 2-dimensional scale. </p><p>Here's the key blown up:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_key_labeled_compressed.png"></figure><!--kg-card-end: image--><p>Horizontal scale represents vote margins. Vertical scale represents vote totals.</p><h4 id="lightness-vertical-scale-">Lightness (Vertical Scale)</h4><p>The lighter counties had fewer votes. The darker counties had more votes. </p><h4 id="hue-saturation-horizontal-scale-">Hue + Saturation (Horizontal Scale)</h4><p>The closer a county gets to gray, the closer the votes were 50:50. </p><p>A highly saturated red county was won by Trump with high percent vote margins. A highly saturated blue county was won by Hillary with high percent vote margins.</p><h2 id="the-mathematics-of-the-muddy-map">The mathematics of the muddy map</h2><h4 id="hsl">HSL</h4><p>All colors can be described as a combination of <code><u>H</u>ue(°)</code>, <code><u>S</u>aturation(%)</code>, and <code><u>L</u>ightness(%)</code>. </p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/640px-HSL_color_solid_cylinder_saturation_gray.png"><figcaption>The HSL color model.</figcaption></figure><!--kg-card-end: image--><p>We can leverage these individual components of the <code>HSL color model</code> to faithfully express 2-dimensional data such as vote totals vs margin on a 2d color scale.</p><h4 id="county-fill-colors">County Fill Colors</h4><p>The fill-color of each county is constructed using the MuddyColor algorithm, which is expressed as the following mathematical formula:</p><!--kg-card-begin: html--><!--
MuddyColor =

HSL \left (  

Hue \left (winner(D,R ) \right ), 

\frac{ \left |D-R \right | }{totalVote}, 

 \frac{ \left (1-\frac{totalVote}{upperFence}   \right )*100}{2} + 50

\right )
--><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddyColor_Formula-1.gif"><figcaption>Formula for county fill color</figcaption></figure><!--kg-card-end: image--><p>This produces the following two dimensional scale, which also doubles as a map key, with the upper fence labeled for the 2016 data set:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_key_labeled_compressed.png"><figcaption>Color scale produced by MuddyColor, used for county fill colors.</figcaption></figure><!--kg-card-end: image--><h4 id="county-border-colors">County Border Colors</h4><p>For the borders of each county, I use the same formula, but just give them a constant lightness (L) of 50%. </p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddyBorderColor_Formula.gif"><figcaption>Formula for county border color</figcaption></figure><!--kg-card-end: image--><p>This results in a 1-dimensional scale which we use for the county borders. It's the same color-scale scale used in the Neutralizing Map, which is designed to more-accurately express vote margins. &nbsp;<code>Left = higher DEM %margin</code>. <code>Right = higher GOP %margin</code>.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/neutralized_scale.png"><figcaption>Color scale produced by MuddyBorderColor, used for county border colors.</figcaption></figure><!--kg-card-end: image--><p>Giving each county an opaque border color allows even the lightest-filled counties to be recognized, including their vote margins.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_zoom.png"><figcaption>With opaque county borders, you can see the counties with even the lowest vote totals.</figcaption></figure><!--kg-card-end: image--><p>You don't need to look at the whole nation to see where one county's vote total lies on the overall lightness scale. The &nbsp;<code>county border color</code> and the &nbsp;<code>county fill color</code> differ only by lightness, so the greater the <code>contrast</code> between a county's border color and its fill color, the lower its vote total.</p><h4 id="upper-fence">Upper Fence</h4><p>A few counties have enough votes to skew the vote totals scale. Here's how the graph looks when the <code>vote totals</code> scale maxes out at <code>2,514,055</code>, the maximum number of votes in a county:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_no_upper_limit-1.jpg"><figcaption>A few counties have enough votes to skew the whole vote scale.</figcaption></figure><!--kg-card-end: image--><p>One may suggest using a logarithmic scale to bring the sky-high outliers down to Earth. However, this would be visually misleading. A logarithmic scale flattens the min:max vote totals proportion from <code>1:39,282</code> closer to<code>1:3.5</code>, visually equating population mountains with population plains.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/logarithmic_scale-16.png"><figcaption>In this log-scale graph of northwest Texas, can you distinguish a county with 1,000 votes from one with 50,000 votes?</figcaption></figure><!--kg-card-end: image--><p>We maintain a linear vote totals scale and use the statistical <code>upper fence</code> to account for outliers. The statistical upper fence can be calculated using the formula <code>Q3 + 1.5 * IQR</code>. Since the county vote margins are only concerned with %DEM|%GOP, county vote totals are DEM+GOP. For vote totals, we calculate the statistical upper fence to be <code>59,828 DEM+GOP votes</code>. We need to keep in mind that <code>432 counties</code> have vote totals ≥ <code>59,828 DEM+GOP</code> and are fully opaque in the Muddy Map. </p><h2 id="practical-uses-of-the-muddy-map">Practical uses of the Muddy Map</h2><p>The formulas give the Muddy Map graph some interesting characteristics. For each county, both the percent vote margin, as well as the vote totals (≤ the statistical upper fence), are embedded in the colors of the graph.</p><p>The Practical Characteristics of the Muddy Map Algorithm:</p><ul><li>There are only two hues, <code>red (hue#0 aka hue#360)</code> and <code>blue (hue#240)</code>. Red indicates GOP win, blue indicates DEM win.</li><li>A county with a <code><em>vote margin</em> of 100%</code> will have <code>100% saturation</code>. </li><li>A county with a <code><em>vote margin</em> of 0%</code> will have <code>0% saturation</code>. Such a county will be a pure gray, since gray appears at 0% saturation. So the closer a county gets to 50:50, the more gray it appears. No county in the 2016 election had a vote margin of 0%.</li><li>A county with <code>0 <em>total votes</em></code> will have <code>100% lightness</code>. Pure white appears at 100% lightness, so the closer the vote totals get to 0, the more white the counties appear. &nbsp;No county in the 2016 election had 0 votes. </li><li>A county with <code>≥ 59,828 <em>total votes</em></code> (the statistical upper fence) has <code>50% lightness</code>. &nbsp;432 counties in the 2016 election have this property.</li></ul><p>If a computer can faithfully render all of the colors described by the formula, then you can use a color picker to get …</p></div></section></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/">https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/</a></em></p>]]>
            </description>
            <link>https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979807</guid>
            <pubDate>Tue, 03 Nov 2020 14:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark’s new backend will be in F#]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 242 (<a href="https://news.ycombinator.com/item?id=24979578">thread link</a>) | @nikivi
<br/>
November 3, 2020 | https://blog.darklang.com/new-backend-fsharp/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/new-backend-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/El5FcMQWkAAnkTX.jpeg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/El5FcMQWkAAnkTX.jpeg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/El5FcMQWkAAnkTX.jpeg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/El5FcMQWkAAnkTX.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/El5FcMQWkAAnkTX.jpeg" alt="Dark's new backend will be in F#">
            </figure>

            <section>
                <div>
                    <p><em>Welcome HN! Dark is a programming language, structured editor, and infrastructure—all in one—whose goal is to make it 100x easier to build backend services. Check out the <a href="https://darklang.com/">website</a>, our <a href="https://blog.darklang.com/what-is-dark/">What is Dark</a> post, and <a href="https://blog.darklang.com/how-dark-deploys-code-in-50ms/">How Dark deploys in 50ms</a> for more. Thanks for checking us out!</em></p><hr><p><em>Part of a set with <a href="https://blog.darklang.com/leaving-ocaml/">Leaving OCaml</a> and <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Why Dark didn't choose Rust</a>.</em></p><p>Nothing in my life so far would have prepared me for the fact that I would be willfully choosing to move to .NET, but it's 2020, and nothing matters anymore.</p><p>I've been evaluating new languages for the Dark backend over the last 2 months or so. For a <a href="https://blog.darklang.com/leaving-ocaml/">bunch of reasons</a>, OCaml has been a little unsatisfactory.</p><p>Over the last few years we've always said "when we rewrite the backend", "at some point we'll rewrite and this will go away", etc. There's a lot of new code to be written on the backend, to meet our roadmap. Are we really going to write it once, and then rewrite it later? Or would it be faster to just port it now, and write the new code in the new stack?</p><p>Ultimately, I decided that if there was going to be a change, now was the time. And more importantly, if there wasn't going to be a change, now was an excellent time to fully commit to OCaml, and not be second guessing the choice.</p><p>Initially, I expected to go to Rust. <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">Rust has excellent tooling, great libraries, a delightful community, etc</a>. But after spending about a month on it, I can't say I like writing Rust. Especially, I don't like writing async code in Rust. I like a nice high level language, and that's kinda what you need when you have a project as big as Dark to build. And Rust is not that. I'll publish "Why Dark didn't choose Rust" next. Or I might call it "you'll never believe just how much a Garbage Collector does for you!", because that's the summary.</p><p>When I was working on <a href="https://github.com/darklang/fizzboom/">Async benchmarks</a> before, what I was really doing was evaluating "are any of these OCaml alternatives better? And if so are they also faster?". I evaluated and expected not to like F#. I actually quite like it. It's close enough to OCaml, has great library support, and tooling which so far has been a mix of great and terrible. The 90's Microsoft tooling is still there, and that bit isn't all that great, but overall it's a much better situation than OCaml or Rust.</p><h2 id="why-did-i-chose-f-">Why did I chose F#?</h2><p>Let's start with the obvious, F# is OCaml. It's OCaml backed by the world's largest and most experienced creators of programming languages. And in the areas that OCaml is great, F# is also great! Sum types, static typing, eager execution, pipelines, immutable values, all of this is really great.</p><p>It actually has a much better type system, in my opinion. One thing that sticks out is that OCaml made it really cumbersome to use maps. Like, hashtables, associative arrays, whatever you call them. It seems the old version of Real World OCaml has been taken down, so I can't show you how unpleasant they were at the start. Now, in the latest version, they are <a href="https://dev.realworldocaml.org/maps-and-hashtables.html">more moderately unpleasant</a> to use. Whereas in F#, you have a <code>Map&lt;OneType,AnotherType&gt;</code> and that's really it. Magic!</p><p>Of course, the main reason I chose .NET was the libraries. It has libraries for everything, what a surprise. While there aren't all that many F# first-party libraries, every vendor out there has a .NET SDK that you can use directly from F#. I look forward to finally having first-party support for <a href="https://honeycomb.io/">Honeycomb</a>, <a href="https://rollbar.io/">Rollbar</a>, and Google Cloud. I'm even finally going to get to use <a href="https://launchdarkly.com/">LaunchDarkly</a>, after <a href="https://www.heavybit.com/library/podcasts/to-be-continuous/">years of telling Edith</a> I would.</p><p>The other thing I've really enjoyed is how good the docs and community content are. A lot of OCaml community content is on the language and what you can do with it. F# developers seem to just want to get shit done. There's a million blog posts, youtube videos, etc, from enterprise software developers talking about the best way to build web software. And then of course the massively detailed and useful <a href="https://fsharpforfunandprofit.com/">FSharpForFunAndProfit</a>, as well as <a href="http://tomasp.net/">Tomas Petricek</a>'s work - it's really great.</p><p>I think most of this is due to the size of the community. I've heard people say that there are very few F# developers; something like there's 1M C# users, 100k VB users, and 10K F# users, or something like that. I'm not sure exactly what counts as user, but I would imagine that OCaml has fewer than 100 "users" in this metric, so it feels like I'm moving to a massive community.</p><p>Not everything is amazing though. The build system is attrocious. While <code>paket</code> is roughly on par with <code>esy</code>, msbuild is 1000 times worse than <code>dune</code>. An incremental build in dune is like 1s for me, and 6s in .NET, even if nothing is happening. I know they have fancy incremental compilers for .NET so this puzzles me; if anyone has tips on getting really fast compilation in F#, <a href="mailto:paul@darklang.com">I would appreciate them</a>.</p><p>An important thing to check was whether I could compile my code to JS. Dark's execution engine runs it the editor as well, and that's one of the core things that makes Dark special. Because of this, I want to take unaltered backend code and compile it directly to JS. This isn't like <a href="https://rescript-lang.org/">Rescript</a> (which is OCaml compiled to JS with slightly different semantics and ecosystem, or it's equivalent in F#, <a href="https://fable.io/">Fable</a>). Fortunately, F# code can be compiled to Wasm using <a href="https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor">Blazor</a>. Blazor compiles the .NET runtime to WASM and runs your code in that. It <a href="https://github.com/darklang/dark/tree/main/fsharp-backend/src/Wasm">barely took any code</a> to get working either (though figuring out the right incantation was not trivial).</p><h2 id="feedback-from-leaving-ocaml-blog-post">Feedback from "Leaving OCaml" blog post</h2><p><a href="https://blog.darklang.com/leaving-ocaml/">Yesterday's post</a> got a lot of people to add their opinions. In addition to some <a href="https://news.ycombinator.com/item?id=24976630">Scala</a> and <a href="https://twitter.com/fakenickels/status/1323304778089304070">Erlang</a> love, a lot of people pointed to F#:</p><blockquote>So...I think a decent choice to make here is to switch from OCaml to F#. You'll get almost all of the benefits and most of the drawbacks go away. And for the most part, you can directly translate the code from OCaml to F#. - <a href="https://news.ycombinator.com/item?id=24978526">darksaints</a></blockquote><blockquote>I've been using F# on GCP in production for 3 years now and it's fantastic and only getting better. You can leverage existing .NET libraries (for example, you get official GCP libraries from google) and if you use them enough it's easy enough to write a functional wrapper around them. - <a href="https://news.ycombinator.com/item?id=24978526">angio</a></blockquote><blockquote>We have considered OCaml but went for F# instead. I could not be happier. Great libraries, good tooling, in 2020 F# is a first class citizen in the cloud thanks to C# and .NET Core. You can develop on Linux, Windows, MacOS and without modification it works. Compilation times are great. Unless you want to deal with the low level nature and the C++ influence in Rust F# is a much more logical step to move from OCaml. There is dotnet fsi for REPL too. F# has access to C# libraries and it is relatively easy to write a thin wrapper that convert nulls to Nones, so you are null safe or C# style functions to ML style functions so you can use |&gt; or &lt;| etc. - <a href="https://lobste.rs/s/bcwbuw/leaving_ocaml#c_uoy61u">l1x</a></blockquote><h2 id="next-steps">Next steps</h2><p>I recently merged the <a href="https://github.com/darklang/dark/tree/main/fsharp-backend">first F# code into the codebase</a>. It's an async version of the core of the Dark interpreter, connected to Giraffe (F#'s low-level interface to .NET's Kestrel web server).</p><p>My plan is to reimplement the same language, but with some of the learnings that are in the <a href="https://roadmap.darklang.com/">roadmap</a>. For example:</p><ul><li><code>Result</code> and <code>Options</code> will be types, not special cased into the language</li><li><code>Int</code> will be infinite precision (this is technically a breaking change, but not a significant one AFAICT)</li><li>breaking out the API server, using F# builtin middleware libraries</li><li>refactoring the Dark public HTTP server into composable middleware, available from within Dark</li></ul><p>I'll be working on making the equivalent to the existing Dark interpreter, keeping the semantics the same. After that, I'll be making new features from the <a href="https://roadmap.darklang.com/">Dark Roadmap</a>.</p><h2 id="implementation-plan">Implementation plan</h2><p>Dark's backend is 37K lines of OCaml, of which 8K lines are tests, and 10K lines are the Dark standard library. So there's about 20K lines to port. Should be fun. My implementation plan is to get to parity - there's plenty of time after that to take advantage of the ecosytem:</p><ul><li>finish the interpreter</li><li>connect Dark's F# backend to Dark's DB, so it can read the same data</li><li><s>compile Dark's F# interpreter to JS</s> (done, see above)</li><li>make an OCaml library to deserialize the binary opcodes in the DB and covert them into F# (via, I presume, a JSON intermediary). This will allow incoming requests to (optionally) be routed to the F# service.</li><li>add a fuzzer to ensure the semantics of the OCaml and F# versions of Dark are the same (especially the library functions)</li><li>do all the devops (getting it into k8s, etc)</li><li>add the APIs we have available in OCaml</li><li>add a way for users to safely try their code in the new version</li><li>port over 170 or so functions we have in the standard library</li><li>start recording traces using <a href="https://blog.darklang.com/evolving-darks-tracing-system/">the new design</a> (this is actually the main thing driving the whole change, believe it or not!)</li><li>use <a href="https://www.honeycomb.io/">Honeycomb</a>, R<a href="http://rollbar.com/">ollbar</a>, and Google Cloud using their .NET native interfaces</li><li>port our <a href="https://github.com/darklang/dark/tree/main/services">various services</a> to F# (lower priority)</li><li>port our accounts to self-managed from Auth0</li><li>translate the <a href="https://docs.darklang.com/contributing/ocaml-for-dark-developers">contributor docs</a> to F#</li></ul><p>There's lots to do, and <a href="https://docs.darklang.com/contributing/getting-started">Dark contributors</a> are welcome to take part. Porting standard library functions might be an easy place to get started, as is adding language features. Most things are a straight port from OCaml, except as mentioned above. As always, feel free to ask in <a href="https://darklang.com/slack-invite">the Slack</a> or <a href="https://github.com/darklang/dark/issues">issues</a> if you've any questions.</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p><p><em>Thank you<a href="https://twitter.com/JaggerJo1/status/1323571699330260993"> JaggerJo</a> for the header image!</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/new-backend-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979578</guid>
            <pubDate>Tue, 03 Nov 2020 13:45:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Suzieq: Network Observability]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24979461">thread link</a>) | @gjvc
<br/>
November 3, 2020 | https://suzieq.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://suzieq.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <div role="main">
            <div>
              
                
<p><strong>Suzieq</strong> is both a framework and an application using that framework, that is focused on 
<strong>improving the observability of your network</strong>.  We define observaility as the ability of a system to 
answer either trivial or complex questions that you pose as you go about operating your network. How easily 
you can answer your questions is a measure of how good the system's observability is. A good observable 
system goes well beyond monitoring and alerting. Suzieq is primarily meant for use by network engineers and designers.</p>
<p>Suzieq does multiple things. It collects data from different devices and systems. It normalizes the data and 
then stores it in a vendor independent way. Then it allows analysis of that data. </p>
<p>We believe Suzieq is novel because it is a disaggregated framework that allows you to independently pick:</p>
<ul>
<li>how you gather your data (agentless or agent-based)</li>
<li>how you store your data</li>
<li>how you interact with the data i.e. how you ask the questions and how you see the answers.</li>
</ul>
<p>With the applications that we build on top of the framework we want to demonstrate a different and more 
systematic approach to thinking about networks. We want to show how useful it is to think of your network holistically.</p>
<p>In this very early release of Suzieq, we've chosen some answers for the framework to get the ball rolling. </p>
<ul>
<li>We gather data using an agentless model using either SSH or REST API as the transport. </li>
<li>We normalize the data into a vendor-agnostic format.</li>
<li>We store all data in files using the popular big data format, Parquet. </li>
<li>All the analysis are exposed either via a CLI or via Python objects. The output can be rendered in various formats from plain text to JSON and CSV.</li>
<li>The analysis engine used in this release is pandas.</li>
</ul>
<p><strong>We support gathering data from Cumulus, Arista, JunOS and NXOS routers, and Linux servers.</strong> We gather:</p>
<ul>
<li>Basic device info</li>
<li>Interfaces</li>
<li>LLDP</li>
<li>MAC address table</li>
<li>MLAG (only for Cumulus and EOS at this time)</li>
<li>Routing table</li>
<li>ARP/ND table</li>
<li>OSPFv2</li>
<li>BGP (v4 unicast, v6 unicast and evpn AFI/SAFI)</li>
<li>EVPN VNI info (not for EOS at this time)</li>
</ul>
<p>We are just getting started with Suzieq. As befitting an early release, what you see is only a brief 
demonstration of what this approach can bring about. We've many, many ideas to implement in our upcoming 
releases, but we wanted to get this out so that people can start using it. And start understanding their 
networks to solve problems, validate or to make changes.</p>
<p>You can join the conversation via <a href="https://netenglabs.slack.com/">slack</a>. Send email to Dinesh or Justin with the email address to send the Slack invitation to. </p>
<p>We're also looking for collaborators to help us make Suzieq a truly useful multi-vendor, open source platform 
for observing all aspects of networking. Please read the <a href="https://suzieq.readthedocs.io/en/latest/CONTRIBUTING.md">collaboration document</a> for 
ideas on how you can help. </p>
              
            </div>
          </div>
          
      
        </div>
      </div></div>]]>
            </description>
            <link>https://suzieq.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979461</guid>
            <pubDate>Tue, 03 Nov 2020 13:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Computer Unit” – A PDP-11/34 at my school (1979)]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24979179">thread link</a>) | @qmacro
<br/>
November 3, 2020 | https://qmacro.org/2020/11/03/computer-unit-1979/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2020/11/03/computer-unit-1979/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>I’ve transcribed an article about the arrival of the “Computer Unit” - a PDP-11/34 - at my school in 1979. The unit became the early focus of a fascination with computing that’s never left me.</em></p>

<p>I went to school in the late 1970s and early 1980s - the dawn of computing for everyone. My very first experience of computing was at a terminal connected to a timesharing minicomputer, rather than at the keyboard of one of the personal computers of the day.</p>

<p>There was an article in the 1979 edition of my school’s magazine “The Hulmeian”, written by our head of Mathematics Morris Loveland. It brings back many happy memories, and provides some insight into computing in the early days.</p>

<p>Below the article, I’ve included some pictures accompanied by brief descriptions.</p>

<p><em>COMPUTER UNIT</em></p>

<p><em>In 1974 the School purchased a single computer terminal, a TEXAS 733, and established the G.P.O. dial-up link to Salford University. This project, initially between School and the University, made available on-line computer time to us and later to other educational establishments. It proved to be a most useful and successful facility and reports have been given in this magazine of some of the work undertaken in the five years in which the link was used. The School had between ten and fifteen hours of on-line time each week, mainly during lunch hours and after school. Some time was available during teaching time and a large number of boys had experience of using the BASIC language to a large remote processor.</em></p>

<p><em>Computing was mainly organised for small groups or for individual users, although a certain amount of class teaching was undertaken. The limitations of a single terminal caused delays and frustration. Boys were foreced to wait to use the system and it was found to be extremely difficult to teach a class of thirty boys where the visual display was a single sheet of typed material. Salford University extended the computer facility to several other schools resulting in a considerable reduction in the on-line time available to us.</em></p>

<p><em>Early in 1978 it was decided to investigate the possibility of installing a complete on-site computer system at School. The searches took nearly a year and in that time a system which would satisfy the requirements of the School was determined. The financial aspects were agreed in November 1978 and the system was delivered in January 1979.</em></p>

<p><em>The computer which has been installed is a SYSTIME 3000 comprising a PDP11/34 processor with 196Kb of working memory, two 4.8Mb disc drives for data storage, three visual display terminals (one of which is used for system control), a Superterm paper printer and the necessary hardware to include the original Texas terminal into the system. Thus four terminals instead of one are available for use with no restriction on the time when a boy may use the computer.</em></p>

<p><em>The language used is BASIC PLUS which is a variant of the BASIC language used during the past five years. Very few problems have been experienced with this minor change of language and it is a most suitable language for teaching purposes. BASIC PLUS is interactive, that is, one which enables a two way ‘conversation’ between user and machine. If an error is made by the user, either in typing or in the logic of what is communicated to the machine, he is informed of that error immediately and can make the required corrections.</em></p>

<p><em>The processor and system control is housed in the careers room and is linked by cables running across the quadrangle and over the roof of the Science block to room 34. This room has been redesigned and redecorated to be a terminal room, housing at present the four computer terminals.</em></p>

<p><em>The system is a fairly standard computer package apart from one important modification. The signal from one visual display unit is taken and fed to a television monitor. Normally a single terminal is used by an individual or at most by a small group working on a particular project. The intention of having the signal from one terminal displayed on a large television monitor was to enable full classes of thirty boys to see a particular piece of computing. However, one monitor proved insufficient and by including a signal converter and amplifier the signal from one terminal can now be displayed on three domestic television sets. When a full class is taken into the terminal room teaching can be given to all by linking all four terminals together and displaying the data on them and on the three television sets. As far as is known this particular part of the system is an innovation as regards the teaching of computing in schools, particularly as part of the electronics required to convert the signals to be compatible with domestic television sets was designed and built in School.</em></p>

<p><em>The system is thus being used in two different ways: for individual and small group activity or with the system linked together for class teaching. So far no examination teaching has been undertaken and at present none is envisaged. The intention is to use the computer in the classroom as a tool to teach a computer language, which will enable boys to undertake projects on their own, and as an aid to enrich and extend the normal teaching of Mathematics. Boys will find that they are taken to the terminal room perhaps for a complete period or for only ten minotes of a Mathematics period during which some particular part of the subject matter being developed will be illustrated using the computer.</em></p>

<p><em>The system has been planned with future expansion in mind. When the wiring was installed two extra cables were taken into room 34; and therefore two more terminals can be added to the system fairly easily as and when they are required. Further expansion is possible; up to twenty-four terminals can be serviced by the processor! To achieve this additional memory will have to be added to the processor.</em></p>

<p><em>Following the delivery of the system in January 1979 and after all testing had been carried out by the suppliers the computer was in limited use in early March. Since then the number of users has increased considerably. The computer is available for general use from 8.00 am to 5.00 pm and is heavily used by boys from the first to the sixth form before morning school, during the lunch hour and after school. Considerable use has been made during teaching time for class sessions, and sixth formers are able to use the computer in their private study time. During the final three weeks of the summer term about nine hundred log-ins were recorded! As this period included the preparation for the Open Days when the system was out of general use, there appears to be a growing for the facility the computer now provides.</em></p>

<p><em>During the summer term three after-school courses were provided to each the BASIC language, two for juniors new to the system and one for those with considerable experience in computing. It is hoped that more of these courses will be provided for boys at all levels in the School in the coming years.</em></p>

<p><em>Looking back over the period of the installation of the computer and the enthusiasm it has generated with boys of all ages, I anticipate a growing demand for computer time and an enhancement of the teaching of Mathematics in the School.</em></p>

<p><em>M.L.</em></p>

<p><img src="https://qmacro.org/content/images/2020/11/computerunit.jpg" alt="A picture of schoolboys using the terminals of the computer unit">
<em>A photo that accompanied the article in the school magazine</em></p>

<p>Here’s a grainy photo that accompanied the article in the school magazine. You can see one of the “VDU” (Visual Display Unit) terminals, and you can see a better picture of one of these in the photo of the Systime unit at the end of this post, but can you also spot the <a href="http://vtda.org/docs/computing/IntertecDataSystems/1100500-00_SuperTermMaintenance_1978.pdf">Superterm</a> paper-based terminal (back right)?</p>

<p><img src="https://qmacro.org/content/images/2020/11/superterm.png" alt="A grainy photo of the &quot;Superterm Data Communications Terminal&quot;">
<em>A Superterm Data Communications Terminal</em></p>

<p>Moreover, furthest away from the camera, there’s the original Texas 733 terminal, also paper-based. Here’s a better picture of one, from the <a href="http://www.bitsavers.org/pdf/ti/terminal/brochures/TI-327-A-10M_Silent_700_Model_732_733_Brochure_Sep_1973.pdf">original brochure</a>.</p>

<p><img src="https://qmacro.org/content/images/2020/11/texas.png" alt="A Texas 733 terminal&quot;">
<em>A Texas 733 terminal</em></p>

<p>Here’s a picture of what the computer unit looked like - it’s a photo (courtesy of <a href="http://www.chilton-computing.org.uk/">Computing at Chilton</a>, thank you) of a Systime unit, and the terminal on the desk is the same as those that we had in the computer room.</p>

<p><img src="https://qmacro.org/content/images/2020/11/systime.png" alt="A picture of a very similar Systime unit">
<em>A Systime unit</em></p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2020/11/03/computer-unit-1979/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979179</guid>
            <pubDate>Tue, 03 Nov 2020 12:55:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We made our SaaS home page cookie-free]]>
            </title>
            <description>
<![CDATA[
Score 358 | Comments 178 (<a href="https://news.ycombinator.com/item?id=24979167">thread link</a>) | @jivings
<br/>
November 3, 2020 | https://blog.leavemealone.app/no-more-cookies/ | <a href="https://web.archive.org/web/*/https://blog.leavemealone.app/no-more-cookies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.leavemealone.app/content/images/size/w300/2020/11/cookies.jpg 300w,
                            https://blog.leavemealone.app/content/images/size/w600/2020/11/cookies.jpg 600w,
                            https://blog.leavemealone.app/content/images/size/w1000/2020/11/cookies.jpg 1000w,
                            https://blog.leavemealone.app/content/images/size/w2000/2020/11/cookies.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.leavemealone.app/content/images/size/w2000/2020/11/cookies.jpg" alt="How we made our SaaS homepage cookie-free 🍪">
            </figure>

            <section>
                <div>
                    <p>If you've browsed the web in the last 10 years then you'll have seen more than your fair share of cookie banners!</p><p>Intended as a workaround to the <a href="https://www.cookielaw.org/the-cookie-law/">2011 EU Cookie Law</a>, cookie consent banners have become so commonplace that most people <a href="https://www.amazeemetrics.com/en/blog/76-ignore-cookie-banners-the-user-behavior-after-30-days-of-gdpr/">don't even bother to look at them</a>, or just click accept on everything. </p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-10.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-9.png"></figure><!--kg-card-end: image--><p>As I see it, the purpose of the Cookie Law was to <strong>stop websites from storing data in your browser unless they absolutely needed to</strong>, by requiring them to prompt their visitors for consent. The end goal being to give you more control over your online privacy, stop needless tracking, and make website owners think twice about what they were doing. In short - a good intentioned idea.</p><p>However, basically every website in the world took the easier, less introspective approach - prompting for consent - creating an objectively worse web experience for everyone.</p><p>Since at <a href="https://leavemealone.app/">Leave Me Alone</a> we're trying to set an example of how to run a privacy friendly company, we decided to figure out how we could remove all the cookies from our landing page without sacrificing anything important. This means no more cookie banner, no more tracking! 🍪</p><p>We had three main cookie monsters that will be well known to SaaS companies;</p><ol><li>Web analytics</li><li>Live Chat</li><li>Security (DDOS protection etc)</li></ol><p>Before we start, I'm not neccessarily saying I distrust any of these companies and how they use cookies...so make your own judgement about them. We're just in this to get cookie free! </p><h2 id="web-analytics">Web Analytics</h2><p>To track our page views and general visitor behaviour, like <a href="https://trends.builtwith.com/analytics/Google-Analytics">most sites</a>, we were using Google Analytics. </p><p>Google Analytics sets a little cookie on page load to "remember" what a visitor has done on each page as they navigate around a site. This allows it to create a profile of the visitor so you can figure out exactly what it takes to get a visitor to sign up or convert, or whatever it is that you're trying to measure.</p><p>Realistically we never really use this information, so it's an easy one to get rid of. There are actually a handful of simpler web analytics platforms that don't use cookies, and we opted to try <a href="https://simpleanalytics.com/">Simple Analytics</a>. With this we get basically all the info we ever got out of Google Analytics (page views), so it seems like a great compromise.</p><p>You can even make your analytics pages public, which fits nicely with our "<a href="https://blog.leavemealone.app/how-we-share-company-stats-and-metrics-publicly/">open startup</a>" work ethic. For example you can view the stats for this <a href="https://simpleanalytics.com/blog.leavemealone.app">blog post here</a>!</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-1.png"><figcaption>The page view anaylitcs for Simple Analyics - meta!</figcaption></figure><!--kg-card-end: image--><p>🍪 Cookie Verdict = 5/5, no cookies, no problem.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="live-chat">Live Chat</h2><p>Having an annoying chat widget is another common thing for a SaaS homepage. We used to use Crisp for this, which uses a cookie to match a browser session to messages in their system. Their <a href="https://help.crisp.chat/en/article/crisp-chatbox-cookie-and-ip-policy-1147xor/">privacy policy</a> says this is "not used for tracking purposes", but given all the data they show in their UI about visitors that's not exactly much comfort. </p><p>(It even guesses a load of personal info from the visitors' email address like what company they work for and their job title using something called <a href="https://go.crisp.chat/notice/domain-enrich/">Crisp Enrich</a> which is apparently impossible to find any info about but sounds shady as hell).</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-6.png"><figcaption>I don't know why I would care about half of the stuff Crisp automatically collect on people who are just asking for help on my website 🤷‍♂️</figcaption></figure><!--kg-card-end: image--><p>So, this is a top priority since it looks like an absolute privacy and tracking nightmare.</p><p>I get that this is a difficult one, but there's literally no service we could find to do this cookieless (or even mildly privacy focused) so we ended up heavily modifying an open-source project called <a href="https://github.com/idoco/intergram">Intergram</a> to do what we wanted. Intergram works like a regular chat widget, but it communicates with the chat app Telegram via a self-hosted server - meaning at least we're in control of the code. Our modified chat widget now looks like this (and the code is <a href="https://github.com/squarecat/squarechat">open-source</a>);</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Group-54.png"></figure><!--kg-card-end: image--><p>Unfortunately it still requires some place to store the messages locally so that the visitor has a copy of them, but we still made this work by only storing anything <em>after</em> the chat has been opened. Unlike Crisp that injected it's cookies when it felt like it. We also don't collect any tracking crap like Crisp does, only chat messages!</p><p>We sweetened the deal by adding a consent prompt to the chat widget itself like this;</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Group-53.png"></figure><!--kg-card-end: image--><p>🍪 Cookie Verdict = 3/5 - fewer cookies, more privacy.</p><h2 id="security">Security</h2><p>This was a tricky one. We use Cloudflare as a security layer to protect the website from denial-of-service attacks. We also use their CDN to cache our assets so that the site loads extra fast, and use their DNS because it's hella convenient.</p><p>To perform their protection Cloudflare stores a cookie called <em><code>_cfduid</code></em>,<em> </em>which is used to track each client and somehow figure out if they're a malicious actor or something. I don't really know and <a href="https://support.cloudflare.com/hc/en-us/articles/200170156-Understanding-the-Cloudflare-Cookies">their description is clear as mud</a>. Whatever it does, it's got to go.</p><p>I didn't really know where to start with this one, so <a href="https://twitter.com/JamesIvings/status/1315945593471205376">I tweeted about it</a> and got a reply from a systems engineer that works there:</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Slice-1-1.png"></figure><!--kg-card-end: image--><p>Which is a bit of a non-answer, since the Enterprise plan costs $200/month and I'd end up with fewer features for my trouble.</p><p>Since we've never actually had to use Cloudflare protection, my solution was to disable Cloudflare forwarding completely and switch to a proper CDN provider. You can do this by clicking the cloud icon on the DNS settings switching to "DNS only":</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-11.png"></figure><!--kg-card-end: image--><p>This means we are now just using Cloudflare for DNS. But it's possible to hit this button again and <strong>re-enable</strong> Cloudflare forwarding temporarily if we find ourselves under attack, so I figure this is a good option.</p><p>For a CDN provider we decided on recommendation to check out <a href="https://bunnycdn.com/">BunnyCDN</a>. I'm actually really impressed by this service, compared to Cloudflare everything feels a bit faster and it's easier to know what's going on, which I like. Also since it's just a file CDN there are zero cookies of course!</p><p>🍪 Cookie Verdict = 6/5 - No cookies AND a faster website!</p><p>The website now has no cookies on load, with some storage being used if a visitor opens the chat widget, which I think is a pretty successful outcome! </p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-8.png"></figure><!--kg-card-end: image--><p>You can check it out <a href="https://leavemealone.app/">here</a>, you'll notice there's no cookie banner to annoy you, it's almost like stepping back in time ;)</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>PS.</p><p>If you enjoyed this post then check out <a href="https://twitter.com/JamesIvings">my Twitter</a>. I spend my free time tweeting about how much I hate anti-privacy web practices and crappy mailing list emails. See you there!</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Cover photo by <a href="https://unsplash.com/@clemono?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Clem Onojeghuo</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>

            <section>
                <h3>Subscribe to Leave Me Alone Blog</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.leavemealone.app/no-more-cookies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979167</guid>
            <pubDate>Tue, 03 Nov 2020 12:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Fundamentals: What I’m Learning]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24979103">thread link</a>) | @buaiscia
<br/>
November 3, 2020 | https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals | <a href="https://web.archive.org/web/*/https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="intro"><a href="#intro" aria-label="intro permalink"></a>Intro</h2>
<p>At this moment in my career, I’m a Javascript fullstack developer in the early stages. I’ve a good knowledge of Javascript, however React gives me sometimes a little more than a headache to understand deeply. I grew up in my learning with class based components, so later, when hooks were introduced, I found a little difficult to transition to this new way of writing React. That’s why I wanted this course. </p>
<p>As part of my learning process, I’m going to note down not everything, but what I learnt, for each section. Often my solution was, although working, more complicated and less elegant than Kent’s one. That’s another aspect I wish to improve in my coding. </p>
<p>Of course you will find many more details and, well, the workshop itself directly in <a href="https://epicreact.dev/">epicreact.dev</a>
I hope this will be useful to somebody else apart from me, and forgive my mistakes in English (not a native speaker).
<br></p>
<h2 id="01-basic-javascript-rendered"><a href="#01-basic-javascript-rendered" aria-label="01 basic javascript rendered permalink"></a>01: Basic JavaScript-rendered</h2>
<p>In the first exercise, it’s necessary to make some DOM manipulation with plain Javascript. As I’m using this method in my daily work, I had no difficulties in the first part. As a matter of fact, I’m learning a lot into transforming a codebase that is heavily relying on jQuery into plain Javascript.</p>
<p>However, I did have to do some thinking on the additional exercise, as I’m not used to work with the root element of the body. So I personally didn’t know -but now that I know, it makes sense - that there’s a body object inside the document object. I won’t give here the solution, but it’s an important reminder to always check the parent elements… what are they hiding inside :)
<br></p>
<h2 id="02-intro-to-raw-react-apis"><a href="#02-intro-to-raw-react-apis" aria-label="02 intro to raw react apis permalink"></a>02: Intro to raw React APIs</h2>
<p>The second exercise of the workshop was already trickier - which I was happy about because definitely I didn’t want to learn again the same stuff.
It’s not often, if ever, that we are using the React.createElement. Using JSX we just skip this part, but that’s how it works under the hood.
So after learning what jQuery is doing in Javascript, now it’s React in Javascript. </p>
<p>First thing I learnt here is that the famous property ‘children’, in React, corresponds to textContent in plain JS. It makes sense, of course, as a matter of fact we are rendering some text made visually in HTML.</p>
<p>The second thing is that createElement has three - or more - arguments that can be passed. </p>
<ol>
  <li>The type of element (span, div, etc)</li>
  <li>The object passed inside the element (class, children, etc)</li>
  <li>A n number of other objects, that will be rendered as additional children.</li>
</ol>
<p>As a matter of fact, the children property doesn’t even have to be defined inside the second argument of createElement, but can be listed at the end of the method.
<br></p>
<h2 id="03-using-jsx"><a href="#03-using-jsx" aria-label="03 using jsx permalink"></a>03: Using JSX</h2>
<p>The third exercise was about creating simple JSX elements that Babel will transform in normal JS with React.createElement. As it’s basically almost a reverse engineering of the previous exercises, it was not difficult. However, it was interesting the use of the spread operator inside a div element, which createElement puts in the correct position:</p>
<div data-language="text"><pre><code>const className = 'myClass';
const children = 'this is my text';
const props = { children, className }
element = &lt;div {...props}/&gt;</code></pre></div>
<p>It will create a div with its own class and the innertext as children.</p>
<p>Another interesting point in the video is about prioritazion of position using the spread operator. Supposing that we have the above props, but then we want to override the className with another name, we have to place the spread props before. In synthesis, the right argument will always override the left ones.</p>
<div data-language="text"><pre><code>&lt;div {...props, className='secondClass'} /&gt; // &lt;div className="secondClass"&gt;
&lt;div {className='secondClass', ...props} /&gt; // &lt;div className="myClass"&gt;</code></pre></div>
<h2 id="04-creating-custom-components"><a href="#04-creating-custom-components" aria-label="04 creating custom components permalink"></a>04: Creating custom components</h2>
<p>So here we go finally to start creating components. The first part consists in creating a function that basically returns a div, so instead of repeating div div in the rendered element, we just pass the function with the string as “children”. One thing that I knew but forgot explicitly is that if I pass a parameter to the function as an object, the argument must be an object as well. So:</p>
<div data-language="text"><pre><code>helloFunction = ({children}) =&gt; {
  return &lt;div&gt;{children}&lt;/div&gt;
}

helloFunction({ children: 'Hello' });</code></pre></div>
<p>The next point was to implement this function as an element:</p>
<p><code>const myElement = React.createElement(message, { children: 'Hello!' })</code></p>
<p>and finally incorporate it in the element itself, which will be taken into ReactDom.render:</p>
<div data-language="text"><pre><code>const element = (
  ...
  {myElement}
)</code></pre></div>
<p>Following that, it’s about referring the same helloFunction but make it directly compiled through Babel as an element, without needing to pass through createElement. This is possible thanks to JSX, and it’s enough to make the function name with first letter as capital, and reference it inside the element object as that.
<code>HelloFunction = () = {}</code></p>
<p><code>&lt;HelloFunction&gt;Hello!&lt;/HelloFunction&gt;</code></p>
<p>This is the equivalent of <code>React.createElement(HelloFunction, null, 'Hello!')</code></p>
<p>Next, it was the time of implementing propTypes for typechecking, giving the same above function to have two parameters, both strings. In the workshop, it’s explained how to make a propTypes function for checking manually the type. But it’s interesting that it’s not taking advantage of the prop-types library. It is true that for a simple check of two props, importing a whole library is excessive; but I don’t think I’ll ever just use two checks. </p>
<p><code>&lt;script src="https://unpkg.com/prop-types@15.6/prop-types.js"&gt;&lt;/script&gt;</code></p>
<div data-language="text"><pre><code>HelloFunction.propTypes = {
      greeting: PropTypes.string,
      subject: PropTypes.string,
    }</code></pre></div>
<p>I’m not getting either a personalized message, but the standard warning is understandable enough</p>
<div data-language="text"><pre><code>Invalid prop `subject` of type `number` supplied to `Message`, expected `string`. in HelloFunction</code></pre></div>
<p>Ah, here we go, in the next exercise there’s the implementation of the library… ooooops, I went a little over head. But good point, to implement also ‘isRequired’</p>
<div data-language="text"><pre><code>HelloFunction.propTypes = {
      greeting: PropTypes.string.isRequired,
      subject: PropTypes.string.isRequired,
    }</code></pre></div>
<p>Anyway, Typescript rules!
<br></p>
<h2 id="05-styling"><a href="#05-styling" aria-label="05 styling permalink"></a>05: Styling</h2>
<p>In this  exercise it was needed to apply style to a custom component in various ways. On a first part, just adding inline styling to a small div; then to a custom component passing its className prop; finally, passing only a string as a size prop and selecting dynamically the style inside the custom component.</p>
<p>First note: when making a reusable component, normally it’s good to place all defaults on the left and what the user is providing (spread operator) after, because we don’t want to enforce something.</p>
<p>Second note: as usual I overcomplicated things. As the size property passed would be only small, medium and large, and the classes are called box—small, box—medium, box—large, it’s enough to substitute the size with the size prop passed into the component.</p>
<p><code>box--${size}</code></p>
<p>adding that to a ternary operator in case it’s the prop is not present.
What I did instead was a nested ternary operator with an object created with the classes names inside. Much more complicated, although it was working 😁</p>
<div data-language="text"><pre><code>const sizes = {
  small: 'box--small',
  medium: 'box--medium',
  large: 'box--large'
}

className={`box ${size === 'small' ? sizes.small : size === 'medium' ? sizes.medium : sizes.large}`}</code></pre></div>
<h2 id="06-forms"><a href="#06-forms" aria-label="06 forms permalink"></a>06: Forms</h2>
<p>In the first exercise, the object is creating a submit listener/handler that will call the function in the main component, which is passed through as a prop.</p>
<p>We can put events (will be React synthetic events) on each element; however, the onSubmit goes inside the form to catch every field that is contained.
Synthetic events are objects that React creates that look and behave like regular DOM events.
It’s still possible to access the DOM event with <code>event.nativeEvent</code>, however, the synthetic one is optimized to work with React code, and the virtual DOM.</p>
<p>I created then a function inside the function (a callback), called once the submit button is clicked. And I’ve added the preventDefault() to that event to prevent the page to refresh (as default event for a form).</p>
<p>Another interesting thing is about accessibility. Screen readers need to associate the input with its label. So it’s needed to give the input an id and the label a htmlFor (the same for= parameter in normal HTML). Moreover, this gives the property of focusing on the input when clicking on it.</p>
<p>The second part of the exercise was about doing the same as above but using the useRef hook. UseRef are simply reference pointers to an element.
First, it’s needed to be imported from ‘react’ and not ‘react-dom’.</p>
<p>Then, adding the reference to our input
<code>&lt;input ref={usernameInput}&gt;</code>
In the main function (or custom component), we can call the hook: <code>const usernameInput = useRef(null);</code>
Why null? The argument of useRef is the initial value. But in this case we don’t need that, just what will be in usernameInput.</p>
<p>Finally, we can access all our referenced properties, like the input value, this way: <code>usernameInput.current.value</code></p>
<p>In the next credit, it was needed to create a controlled input. A controlled input is an input field that is controlled by the component state. That means setting the value of the input by the state: <code>&lt;input ref={usernameInput}  value={username} onChange={handleChange} /&gt;</code></p>
<p>Then, we can set the state at the top of the component: <code>const [username, setUsername] = useState('');</code>
And finally, use that state to change the value of the input in the handleChange function. In this case, transforming every key to lowercase:</p>
<div data-language="text"><pre><code>const { value } = event.target;
setUsername(value.toLowerCase());</code></pre></div>
<p>So the flow is the following:
input from user —&gt; update input state —&gt; transforming input state -&gt; sending the state as value of the input —&gt; input appears on screens.
<br></p>
<h2 id="07-rendering-arrays"><a href="#07-rendering-arrays" aria-label="07 rendering arrays permalink"></a>07: Rendering Arrays</h2>
<p>The exercises were just little demonstrations in this case, to show the importance of using a unique index key when showing elements in the DOM through a mapping. Not without, not with the pre-built index of the map function, but with a preset set of keys to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals">https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals</a></em></p>]]>
            </description>
            <link>https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979103</guid>
            <pubDate>Tue, 03 Nov 2020 12:44:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kingdom – The little known story of how Sikkim was annexed]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24978744">thread link</a>) | @yukiari
<br/>
November 3, 2020 | https://fiftytwo.in/story/kingdom/ | <a href="https://web.archive.org/web/*/https://fiftytwo.in/story/kingdom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-09b8f8d3="" data-v-20489b7b=""><div data-v-09b8f8d3=""><div data-v-df82986e=""><div data-v-df82986e=""><div data-v-df82986e=""><div data-v-df82986e=""><div data-v-df82986e=""><!----> <p>In the days leading up to 9 April 1975, the sedate capital of an autonomous Himalayan kingdom became a fortress. In and around Gangtok, troops belonging to neighbouring India were mobilised on a large scale. In the market squares, people gathered over chhang and chhurpi<a href="" onclick="return!1"><sup id="tgji9775pgb7">[1]</sup></a> and wondered if there was going to be another clash with China. </p></div></div></div></div>  <!----></div><section data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><!----> <div data-v-58180b62=""><p>In his hilltop palace, Palden Thondup Namgyal, the Chogyal of Sikkim,<a href="" onclick="return!1"><sup id="9v49egwa7d5a">[2]</sup></a> sensed a trap. The Indian Army claimed to be carrying out a routine exercise, but his guards were not convinced. They pleaded with him to escape to Nepal disguised as a monk. They were thinking, perhaps, of a day in 1959 when a 24-year-old from Tibet, anointed the Dalai Lama of his people, had made the opposite journey, fleeing the Chinese regime in soldier’s disguise. </p><p>The Chogyal rejected the plan, but his worst fears were confirmed. At 12.45pm on 9 April, a platoon of jeeps full of soldiers armed for battle surrounded the palace. A guard in the sentry box was shot dead after he raised his rifle. Inside the palace, the Chogyal called up Gurbachan Singh, the political officer who represented the Indian administration. </p><p>“What the hell are you doing?” he exploded. The line went dead. Indian soldiers had jammed the radio communication, and the palace had been cut off from the outside world.<a href="" onclick="return!1"><sup id="ntofy0k6kxgw">[3]</sup></a></p><p>The coup was over in twenty minutes. At the end of it, the Chogyal was placed under house arrest, bringing about the end of a regime that had ruled Sikkim for 333 years. Just over a month later, on 16 May 1975, Sikkim joined the union of India as its twenty-second state.</p></div></div></div></div></section><blockquote data-v-6f86352e=""><div data-v-6f86352e=""> <p data-v-6f86352e="">“What is the Indian obsession with annexing Sikkim?”</p>  </div></blockquote><section data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><!----> <div data-v-58180b62=""><div data-v-58180b62=""><p>
              T
            </p> <div data-v-58180b62=""><p>his year, the forty-fifth anniversary of Sikkim’s statehood passed unremarked. For a generation of young Sikkimese, 16 May is just another public holiday. But recent border clashes between India and China have re-established India’s eastern boundary as one of the world’s great fault lines, and also highlighted Sikkim’s historical role as a centrepiece of the dispute. </p><p>The last time lives were lost in the conflict between India and China was in 1967, the second and “forgotten” war<a href="" onclick="return!1"><sup id="1tqa643h1zcj">[4]</sup></a> along the border between Sikkim and Tibet.</p></div></div><p>Depending on which side is telling the story, the “Sikkim affair” is variously referred to as an ‘integration’, an ‘annexation’ or a ‘merger’. What we know about it is largely down to three books that differ in the detail about what transpired and why. </p><p>The first was actively suppressed by the Indian state for nearly three decades. Journalist Sunanda Datta-Ray’s book<em> Smash and Grab: The Annexation of Sikkim</em> was published in 1984, but was kept out of circulation with the aid of a defamation suit filed by the government. It was republished in 2014. The book, engrossing in its detail, paints a picture of the Chogyal—a close friend of Dutta-Ray’s—as a lonely bastion, valiantly resisting an expansionist India. </p><p>The Scottish journalist Andrew Duff was initially drawn to Sikkim by reading his grandfather’s account of a trek from Darjeeling to Pemayangtse Monastery in 1922. Duff’s book, S<em>ikkim: Requiem for a Himalayan Kingdom</em>, is largely based on the letters written home by two Scottish principals of a girls’ school in Gangtok.</p><p>In 2018, GBS Sidhu, a retired officer from India’s intelligence agency, the Research and Analysis Wing (R&amp;AW), published <em>Sikkim: Dawn of Democracy </em>(sub-titled “The Truth Behind The Merger With India”). Finally, it publicly owned up to the role played by the agency in Sikkim’s accession to India.</p><p>“What is the Indian obsession with annexing Sikkim?” asked US Secretary of State Henry Kissinger in bewilderment in a staff meeting in Washington when news of the coup reached the world.<a href="" onclick="return!1"><sup id="has0rjmcde0f">[5]</sup></a> It was a naïve question. The answer is inextricably tied to the tumultuous decade of the 1970s when Indira’s India (or India’s Indira) was consolidating its power within and around its borders in the near neighbourhood. It is also tied to the events of the 1960s, particularly the lingering effects of the 1962 war, which in turn was partly triggered by the Dalai Lama’s escape to India. It stretches further back in history to a century of colonial expansionism under British rule that had left Sikkim vulnerable in the first place.</p><p>Sikkim is a tiny, thumb-shaped state wedged between Nepal, Bhutan and Tibet.&nbsp;For centuries, it was the primary route into the two Buddhist kingdoms. When Tibet was occupied in 1950, the expansion of China was brought “almost up to our gates”, as a deeply-worried Sardar Patel wrote to India’s first prime minister, Jawaharlal Nehru.<a href="" onclick="return!1"><sup id="yp7sopkyrrl5">[6]</sup></a></p><p>The British had made Sikkim a protectorate in 1861, according it the same status as other princely states on the subcontinent. In 1950, three years after independence, Sikkim became a protectorate of the new republic. The kingdom had autonomy in domestic matters but India was responsible for defence, external affairs and communications. For Nehru, Sikkim’s autonomy was nearly sacred. “If we bring a small country like Sikkim within our fold by using force,” he said, “it would be like killing a fly with a bullet.” </p><p>Twenty-five years later, that was no longer the republic’s position. How the change came about is a story with multiple plots involving India’s greatest spymaster, a defiant king, his ambitious political rival, and two enigmatic foreign women. </p></div></div></div></div></section><section data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><p data-v-58180b62=""><header>On Her Majesty’s Secret Service</header></p> <div data-v-58180b62=""><div data-v-58180b62=""><p>
              I
            </p> <div data-v-58180b62=""><p>n December 1972, Indira Gandhi, fresh from victory in the 1971 war for Bangladesh’s liberation, summoned Rameshwar Nath Kao to her office. In 1968, she had handpicked this tall Kashmiri with a formidable intellect to set up the R&amp;AW. In three years’ time, Kao had delivered the agency’s first significant success, providing critical support for the covert training of the guerrilla army Mukti Bahini in what was then East Pakistan. </p><p>“Can you do something about Sikkim?” she asked him. </p></div></div><p>Relations between the Indian state and the kingdom had reached a stalemate. India wanted to create a treaty of Permanent Association, even dangling the carrot of sponsoring Sikkim’s membership to UN organisations in return. But over the 1960s, the Chogyal had been demanding full independence with increasing vigour.&nbsp; </p><p>In the Chogyal’s backyard, the demand for merger with India had originated from the first leader of the Sikkim State Congress,<a href="" onclick="return!1"><sup id="nm2f8pb9zyae">[7]</sup></a> Tashi Tshering, who had even gone to Delhi in 1948 to negotiate it. Patel, the man in charge of India’s integration, was keen on bringing Sikkim into the fold. Nehru chose to overrule him and sent Tshering back.<a href="" onclick="return!1"><sup id="0cyohtn1hkjm">[8]</sup></a></p><p>But Nehru’s India kept more than a watchful eye over Sikkim, much like the British had. “The Sikkimese kingdom became highly dependent on the political officers from the time that the British established direct control of Sikkim,” Saul Mullard, a researcher at  Oxford University and author of a book of Sikkimese history, explained. “Indians took over the role of political officers in Sikkim. They inherited the authority of the British and it weakened the ability of the king to set his own agenda.”</p><p>After Indira Gandhi asked him to “do something” about Sikkim, Kao concocted a plan with PN Banerjee, the joint secretary of the R&amp;AW’s eastern division and a fellow mastermind of the Bangladesh operation. He assured the prime minister that the R&amp;AW could handle Sikkim’s merger.<a href="" onclick="return!1"><sup id="03r32lzzepim">[9]</sup></a> A three-member special ops team was dispatched to Gangtok.</p><p>One of these men was GBS Sidhu, who maintained a meticulous diary of his time in Gangtok. He wrote his book at the prodding of his former boss, who had always been keen for the story of the R&amp;AW’s role in Sikkim to be made public someday. On his passing in 2002, Kao’s own notes on the operations in Sikkim and Bangladesh were handed over to the Nehru Memorial Museum and Library. These will be made public in 2027, according to his will.</p><p>To preserve its reputation as a country that respected the sovereignty of its smaller neighbours, India was keen to legitimize its takeover of Sikkim. It made common cause with the political movement started by Tashi Tshering. India would maintain that the merger was a natural consequence of the peoples’ desire for a democratic form of government. The denouement that came with the coup took more than two years of meticulous planning on the part of the Indian state. </p><p>Like its neighbours Tibet and Bhutan, Sikkim was a conservative Buddhist theocracy. The ruling elite came from two communities: the Bhutia, who migrated from Tibet in the thirteenth century, and the Lepcha, indigenous to Sikkim. The royal family of Namgyals were Bhutia who’d come from Tibet in the sixteenth century. The demographic dynamic of Sikkim started shifting in the late nineteenth century, when Jean Claude White, the first British political officer of Sikkim, began to bring in labour from Nepal to build roads and cultivate land.</p><p>There was another reason why the British encouraged Nepali immigration—to counteract Tibetan influence in Sikkim. There were close religious, cultural and political ties between the two kingdoms. White’s successors tried to undo the policy, but by the early twentieth century, the native population of Bhutia and Lepcha people was already a minority.</p><p>From the 1940s onwards, this, then, was the defining divide in Sikkim’s politics: the tension between its powerful minority and the landless and disenfranchised Nepalis, who had grown to 75 percent of the population by the 1970s. The Chogyal’s inability to provide political representation for the majority of his subjects became his Achilles heel. The R&amp;AW recognized this and surreptitiously worked to exploit it. </p><p>The Sikkim operation helped Kao cement his legacy and strengthen India’s position in relation to China. “It is a fantastic piece of work, handled in a way that it took place under the cover of democracy in process,” the former R&amp;AW officer Rana Banerji, who’s studied the Sikkim papers in the archives of the R&amp;AW’s Kolkata office, told me in a phone interview. “It showed a lot …</p></div></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fiftytwo.in/story/kingdom/">https://fiftytwo.in/story/kingdom/</a></em></p>]]>
            </description>
            <link>https://fiftytwo.in/story/kingdom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978744</guid>
            <pubDate>Tue, 03 Nov 2020 11:47:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing for the Internet Across a Human Lifetime]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24978738">thread link</a>) | @mooreds
<br/>
November 3, 2020 | http://len.falken.ink/misc/writing-for-the-internet-across-a-human-lifetime.txt | <a href="https://web.archive.org/web/*/http://len.falken.ink/misc/writing-for-the-internet-across-a-human-lifetime.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://len.falken.ink/misc/writing-for-the-internet-across-a-human-lifetime.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978738</guid>
            <pubDate>Tue, 03 Nov 2020 11:47:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Computers Were Cool]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24978637">thread link</a>) | @aphrax
<br/>
November 3, 2020 | https://datagubbe.se/coolcomp.html | <a href="https://web.archive.org/web/*/https://datagubbe.se/coolcomp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>
When I was a kid, computers were cool.</p><p>

Nowadays? Not so much.</p><p>

I know, I know. Grumpy old gits are a dime a dozen, and their views about the past are often filtered through a golden haze of blissful forgetfulness and nostalgia. This is of course the case for me, too, but I still think the point is valid: computers used to be much cooler - by orders of magnitude - than they are now.</p><p>

The situation can perhaps be explained by an analogy: You've got a rusty old 1994 FIAT Punto and there is a rather pressing need for you to invest in a new vehicle. Of course, you can dream big - maybe you'd like some kind of armoured personnel carrier, perhaps a souped-up, pimped-out Tesla with all the bells and whistles or why not a Ferrari? Realistically, though, you're probably considering something along the lines of a brand new Ford: the kind of sensible family car that would still be an upgrade to the withering piece of junk you're currently driving. And, as soon as you've amassed enough funds, that's probably what you're going to buy. That APC, though... Man, how sweet would it be to drive one of those? Just thundering through morning traffic, fist pumping in the air, shouting crude insults at that guy with the SUV who always cuts in front of you at the intersection down by the grocery store. Not so smug now, eh, Mr. Sports Utility?</p><p>

That's what it used to be like with computers.</p><p>

Don't get me wrong. You can spend nearly infinite amounts of money on a computer if you'd like to - it's always been like that and probably will be for the foreseeable future. This is especially true for supercomputer clusters used in science and the mainframes keeping the banks and stock markets ticking. But when dreaming about computer power, few of us imagine having access to a behemoth like that. The things we do with our machines can only go faster up to a certain point, unless we dabble in computational biology in our spare time. It would be like replacing our feeble FIAT with an aircraft carrier: sure, it's powerful, but it's not very practical for getting to and from work.</p><p>

No, the computer we dream about having on our desk is usually something a little bit faster, a little bit sleeker and just a little bit more expensive than what we can actually afford. If you're a dedicated games player, there's always the next graphics card, that extra gig of RAM, those extra few frames per second you can chase - but that's still the realistic dreaming, it's something within reach; perhaps not quite in line with a sensible Ford, but not as far out there as an APC.</p><p>

And, even if you are currently dreaming of the home computer equivalent of an APC (let's pretend that's a top of the line Mac Pro, just for the sake of argument), getting one won't make much of a difference in day to day use. Sure, the machine might be faster than your current one, but except for the rare few cases when you actually utilize all that power, it won't provide a profoundly different user experience compared to what an iMac will deliver at a fraction of the cost. It's the same OS, the same applications and the same basic architecture. This is true for Windows and Linux machines as well: you can add more RAM and disk and CPU cores, but the machine won't behave in a significantly different way from what you're used to.</p><p>

Now, when I was a kid... computers were cool.</p><p>

In 1994, I bought a second hand Amiga 1200 with a 120 megabyte hard drive. It was a low cost, capable home computer with good sound and graphics. It was more than enough for the kind of gaming and school work a kid my age wanted to do, but the 14 MHz processor was a tad slow when it came to heavy lifting. Applying just a hint of Gaussian blur to a very low resolution JPEG file took ages. Dabbling in animation, I frequently hit the barrier of the 2 megs of RAM it came with. However, it also had a motherboard connector for adding more memory and a faster CPU. This was the reasonable dream: it was within my reach, it was the sensible family Ford.</p><p>

Thus, in 1995, I got a CPU and RAM upgrade for it, making it roughly four times faster. In those days, that was a pretty hefty upgrade: speeding up from 10 to 40 MPH is more noticeable to a human compared to the difference between the 10000 and 40000 MPH speeds of today's machines. But the speed-up didn't profoundly change my user experience. I was still shuffling about with the same old software and I was still waiting around for that Gaussian blur calculation to finish - although not quite as many minutes as before.</p><p>

As I sat there, watching the Gaussian blur progress bar, I of course dreamt of the computing equivalent of an Armoured Personnel Carrier. It wasn't an Amiga 4000 or a Pentium PC or one of those new-fangled PowerMacs. It was something completely different, something that would have utterly changed my all-round user experience, from boot-up to shutdown. I wanted something the likes of which actually no longer exists: I dreamt of a Unix Workstation.</p><p>

Not just any old Unix box mind you, but a rather specific one: a Silicon Graphics Indy with a 24-bit frame buffer, 128 megabytes of memory and a 175 MHz MIPS R4400 CPU.</p><p>

It was, hands down, just about the most maxed-out piece of hardware that could grace the top of a desk. Design-wise, computers have always been kind of beige - literally and figuratively. Black computers became commonplace some time around, say, 2000, but that was hardly a giant leap in design. Depending on your tastes, you might think companies like Apple or Alienware produce attractive machines - but then again, perhaps you've never seen an SGI Indy.</p><p>

The teal blue pizza box case sports a horizontal, slightly diagonally skewed cut along the middle, shifting the top and bottom parts in a slight offset. The monitor was huge for its time: a 17" CRT cased in grey granite plastic, matching the mouse and keyboard. Both the computer and the screen were adorned with embossed SGI cube logos in a gleaming silver finish. It was over the top, maximalist 1990s more-is-more design in a strangely tasteful package and a far cry from the sleek, subdued designer machines of today. Yet, it wasn't an overstatement - it might've talked the talk, but it sure as hell could walk the walk.</p><p>

For example, it didn't even have a regular floppy drive - it had a bizarre floptical unit capable of storing 20 megabytes on a single, magneto-optical disk. On top of the giant screen a webcam was poised, surely one of the absolutely first computers to come with such a device as standard. In fact, it was called an IndyCam - the term webcam hadn't really caught on yet and was more commonly used to describe just about any camera that regularly uploaded a still image to a public web server.</p><p>

And that, of course, are all trivial oddities compared to the guts of the machine. Even though it was an entry-level workstation, SGI's custom hardware was capable of churning out both 2D and 3D graphics unmatched by any contemporaneous gaming PC, however expensive, and the CPU could run in circles around even the most outrageously-priced Pentium home computer available at the time.</p><p>

And then there was the operating system. And the software.</p><p>

IRIX, SGI's in-house Unix flavour, came with their own proprietary GUI and desktop. It was called Indigo Magic and, featuring things like scalable vector icons, animated desktop backgrounds and visual feedback cues, it was just about as outlandish as the name suggests. It should be noted that this was ten years before any PC owner had gotten the chance to grow tired of such pointless flash and that for the serious hacker, there was always a terminal emulator with a capable shell on hand.</p><p>

Apart from all the usual Unix-related niceties such as stability, pre-emptive multitasking, multi-user support, excellent command line utilities and a bunch of readily available programming languages, it had an impressive array of professional productivity software. Most of it was not available on my home computer, and even if it was, the Indy could run it both faster and in higher resolution. Apart from industry standards such as Photoshop and Netscape, there was a world of curious and wonderful applications written with nothing but SGI hardware in mind: web authoring, video editing, image manipulation and graphics creation unavailable on any other platform. It was a true digital media production workhorse, an overgrown distant cousin to the machines available on the then budding multimedia PC market.</p><p>

In short, it was a cool computer. Far too expensive for any home user, of course. But so. Damn. Cool.</p><p>

There are computers aimed at this kind of work today as well. One of the high-end Macs mentioned before, for example, or perhaps a suitably high-powered Windows machine. In fact, pretty much any dirt cheap home computer will, pixel for pixel, do what the Indy did - except faster, cheaper and in many cases better.</p><p>

Yet there isn't, today, an equivalent of the SGI Indy, or the Sun SPARCstation, or the DEC Alpha, or any of the other professional workstations. The only thing that's on offer is more of the same user experience, only slightly faster.</p><p>

That's why computers are so boring these days. Because even though IRIX, Indigo Magic and the Indy by no means was a perfect solution to all of my computational desires back then, it had the lure of the unknown and unattainable: it was a goal to strive for, a source of inspiration and aspiration and a promise that better things were possible.</p><p>

Today, we all know about the different quirks, mannerisms, privacy issues, drawbacks and occasional benefits of Windows update loops, overpriced Mac hardware and the tiresome fiddliness of Linux. Those are the choices we have and they're not going to change any time soon.</p><p>

I'd somehow be more okay with all of this if it wasn't for the fact that, to top it all off, we have no other platform left to dream of.</p><p>

That's just not cool.
</p></div></div>]]>
            </description>
            <link>https://datagubbe.se/coolcomp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978637</guid>
            <pubDate>Tue, 03 Nov 2020 11:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Concurrency – Understanding the Executor Framework & Thread Pool Management]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24978557">thread link</a>) | @turkogluc
<br/>
November 3, 2020 | https://turkogluc.com/java-concurrency-executor-services/ | <a href="https://web.archive.org/web/*/https://turkogluc.com/java-concurrency-executor-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>In the previous post, I was writing about the <a href="https://turkogluc.com/java-concurrency-basics-of-threads/">Basics of Threads</a>. This post is going to focus on a higher-level abstraction of thread creation and management.</p><p>Concurrent programs generally run a large number of tasks. Creating thread on demand for each task is not a good approach in terms of performance and usage of the resource as the thread creation and threads itself is very expensive. There is also a limitation for the maximum number of threads a program can create, couple of thousands depending on your machine (this is going to be changed with Project Loom).</p><p>A call center is one of the good example given to illustrate parallelisation; you can have bounded number of customer representatives in the call center and if there will be more customer calling than your employees, customers wait in the queue until one representative will be available to take the next call. So, hiring a new representative on each call would not make sense.</p><p>Therefore it is a better idea to have a thread pool containing a number of threads that would execute the tasks we are sending. Thread pool may create the threads statically (at the time of the creation of the pool), or dynamically (on demand), but it should have a reasonable upper bound. If you like to see a simple thread pool implementation that is queuing the submitted tasks and using the threads from the pool to execute them please check the example in the <a href="https://turkogluc.com/java-concurrency-basics-of-threads/">previous post</a>. </p><p>Using the low-level Thread API is also hard and it requires very much attention each time we need to use it. Java Executor framework helps us in this manner by decoupling the creation and management of the Threads from the rest of the application.</p><p>In the following sections, I will try to explain consecutively, the <code>ExecutorService</code> interface and its methods, implementations of the <code>ExecutorService</code>, and using the factory methods of <code>Executors</code> to simplify creation of <code>ExecutorService</code>.</p><h2 id="the-executor-service">The Executor Service</h2><p>At the heart of the executor framework, there is the <code>Executor</code> interface which has the single <code>execute</code> method:</p><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-01-at-22.10.39.png"></figure><p><code>ExecutorService</code> is the main interface extending the <code>Executor</code> and we are going to mostly interact with. It is an abstraction around a Thread Pool, and exposes the <code>submit</code> method that we use to send the tasks. It contains a number of threads in its pool depending its implementations which we will see in the following sections.</p><p>When we send the <code>Runnable</code> or <code>Callable</code> tasks by <code>submit</code> method, the threads from the pool are going to run them.</p><ul><li><strong>Runnable</strong>: So far we have mentioned only about runnable, which does not return anything or is not able to throw any exception.</li><li><strong>Callable</strong>: As similar to the Runnable, designed for classes whose<br>instances are potentially executed by another thread<em>,</em> &nbsp;but <em>returns a result</em> and <em>may throw exception</em>.</li></ul><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-01-at-23.28.44.png"><figcaption>Runnable vs Callable</figcaption></figure><p>Submit method returns a <code>Future</code> object that represents the result of an asynchronous computation. &nbsp;Future has methods to check if the task is complete, to wait for its completion, and to retrieve the result. Its <code>get</code> method returns the result but it is a <strong>blocking method</strong>, so we can postpone calling the get method as long as possible and do other operations. Once we need the result of the task, we call the get method and if the result is not ready the calling thread will be blocked and we need to wait the result. If we can not afford waiting for long time, we can call the method with a <strong>timeout</strong>.</p><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-01-at-22.55.06.png"><figcaption>Future interface</figcaption></figure><p>The <code>ExecutorService</code> also provides methods for sending collection of tasks all together. We can use <code>invokeAll</code> method to send multiple tasks, and it returns List of Futures. <code>InvokeAny</code> method can be used to run similar tasks, and it returns the fastest answer</p><p>Another important advantage executor service provides is that it has shutdown functionality to stop the pool and the threads. There is an important difference between <code>shutdown</code> and <code>shutdownNow</code> methods:</p><ul><li><strong>shutdown</strong>: Calling this method indicates that no new tasks will be accepted to the queue, and previously sent tasks are going to be waited to complete. Note that if the tasks are long running tasks (infinite loop) they will never complete.</li><li><strong>shutdownNow</strong>: This method interrupts all the active threads, stops the processing of new tasks from the queue and returns the list of those tasks that were waiting in the queue. </li></ul><p>Note that in order to stop the processing, we need to <em>handle the interruption</em> in our <code>Runnable/Callable</code> tasks. Otherwise <code>shutdownNow</code> will trigger interruption but no thread will show reaction to it, and it behaves same as <code>shutdown</code>.</p><p>We can also see the <code>ScheduledExecutorService</code> in the first diagram, as it extends the <code>ExecutorService</code> and provides methods to run scheduled tasks. It is an high-level abstraction for the <code>Timer</code>, and it is easier and better way to run periodic tasks.</p><h2 id="implementations-of-the-executorservice">Implementations of the ExecutorService</h2><p><code>ExecutorService</code> instances are mostly created by using <code>Executors</code> factory methods, and I will show it in the next section. <code>Executors</code> factory methods are easy way to generate Thread Pools, however before using that, I would like to show the important concrete classes that implements the <code>ExecutorService</code>, because the factory method internally retrieves one of these implementations, and I believe it is important to understand the internals. Knowing some of the concrete <code>ExecutorServices</code>, we can create custom pools in case we have specific needs.</p><p>If we look at the following diagram, we have <code>AbstractExecutorService</code> which provides default implementations of <code>submit</code>, <code>invokeAny</code> and <code>InvokeAll</code> methods of the <code>ExecutorService</code>. Concrete implementations overrides some of the implementation details.</p><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-02-at-17.22.20.png"><figcaption>Implementations of Executor interface</figcaption></figure><h3 id="1-threadpoolexecutor">1- ThreadPoolExecutor</h3><p>The <code>ThreadPoolExecutor</code> is a one of the core implementation of the <code>ExecutorService</code> and it executes each submitted task using one of possibly several pooled threads. This class provides many adjustable parameters and extensibility for configuring and managing the pool. We can configure the following parameters in this class:</p><ul><li><strong>corePoolSize</strong>: minimum number of Threads in the pool.</li><li><strong>maximumPoolSize</strong>: it is self explanatory, the upper bound of pool size. By setting the <code>corePoolSize</code> and <code>maximumPoolSize</code> the same number, we simple create a fixed size pool.</li><li><strong>ThreadFactory</strong>: New threads are created by using a <code>ThreadFactory</code> which is by default <code>Executors#defaultThreadFactory</code> that creates threads to all be in the same <code>ThreadGroup</code>, with the same <code>priority</code> and <code>non-daemon</code> status. If you like to customise it, you can set a different <code>ThreadFactory</code>.</li><li><strong>keepAliveTime</strong>: When the pool has more than minumum number and the threads are idle, exceeding ones are terminated after the <code>keepAliveTime</code>.</li><li><strong>Queue</strong>: A <code>BlockingQueue</code> can be configured to keep the submitted tasks. Example queues and the queueing strategies are as follows:</li></ul><ol><li><code>SynchronousQueue</code>: It is provides a <strong>direct handoff strategy</strong>, which means that tasks are delivered directly to the workers without storing them in a queue. If no threads are available to take the received task, then a new thread will be constructed. If a maximumPoolSize is set and that limit is reached, task will be rejected.</li><li><code>LinkedBlockingQueue</code>: It provides <strong>unbounded queue strategy</strong> which means, using a queue without a predefined capacity. This will cause new tasks to wait in the queue when all corePoolSize threads are busy. So no more than corePoolSize threads will be created and the value of maximumPoolSize does not have any effect.</li><li><code>ArrayBlockingQueue</code>: It provides <strong>bounded queue strategy </strong>which means, using a queue with a predefined capacity. It has a limited space in its queue therefore there should be enough number of threads to consume the tasks rapidly. When the queue is not full tasks are added to the queue. When queue becomes full, and the number of threads are less than maximumPoolSize a new thread is created. Finally when number of threads reaches the limit, the task is rejected.</li></ol><p>We can configure parameters mentioned above at the construction time or later with the setter methods.</p><pre><code>public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&lt;Runnable&gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
</code></pre><p>Example of running multiple tasks by <code>ThreadPoolExecutor</code>:</p><pre><code>public class Main {

    private static final int CORE_POOL_SIZE = 4;
    private static final int MAX_POOL_SIZE = 4;

    private static final AtomicInteger taskCounter = new AtomicInteger(0);
    private static final ThreadFactory threadFactory = (runnable) -&gt; new Thread(runnable,
        "thread " + taskCounter.incrementAndGet()); // name each thread

    public static void main(String[] args) throws InterruptedException {
        
        ThreadPoolExecutor pool = new ThreadPoolExecutor(CORE_POOL_SIZE,
            MAX_POOL_SIZE,
            0L, // No timeout.
            TimeUnit.MILLISECONDS,
            new LinkedBlockingQueue&lt;&gt;(),
            threadFactory);

        Collection&lt;Callable&lt;Long&gt;&gt; tasks = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 10; i++) {
            int var = i;
            tasks.add(() -&gt; {
                System.out.println("[" + Thread.currentThread().getName() + "]"
                    + " running the task: " + var);
                return Long.valueOf(var * var);
            });
        }

        List&lt;Future&lt;Long&gt;&gt; futures = pool.invokeAll(tasks);
        futures.forEach(longFuture -&gt; {
            try {
                Long result = longFuture.get();
                System.out.println("Result: " + result);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (ExecutionException e) {
                e.printStackTrace();
            }
        });

        pool.shutdown();
        pool.awaitTermination(1, TimeUnit.SECONDS);
    }
}</code></pre><p>It would give the following result:</p><pre><code>[thread 4] running the task: 3
[thread 2] running …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turkogluc.com/java-concurrency-executor-services/">https://turkogluc.com/java-concurrency-executor-services/</a></em></p>]]>
            </description>
            <link>https://turkogluc.com/java-concurrency-executor-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978557</guid>
            <pubDate>Tue, 03 Nov 2020 11:17:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[[Deleted]]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24978225">thread link</a>) | @midef
<br/>
November 3, 2020 | https://www.superhighway98.com/nvidia | <a href="https://web.archive.org/web/*/https://www.superhighway98.com/nvidia">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-310d23d06aadf10082e8"><div><p>If you work in technology, you've probably seen the Nvidia-powered "<a href="https://thispersondoesnotexist.com/">This Person Does Not Exist</a>.” It's a simple web interface that uses AI to generate human faces. It's also the tool that is used routinely to fool journalists into quoting sources who don't exist.</p><h2><strong>Meet the team</strong></h2></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604325790588_13792"><div><p>The screenshot above is taken from the masthead of a fast-growing affiliate website (i.e. a website that earns money by referring customers to make purchases on another website).</p><p>These seem like real people at first glance, but they aren't. Someone who is familiar with generative adversarial networks can spot the “tells” that give the technology away. For example, look at the distorted backgrounds and mismatched earrings. </p><p>These so-called "experts" might not exist, but the spammers behind them were able to fool reporters at legitimate publications like New York Magazine, Woman's Day, Business.com, Inverse, Reader's Digest, Lifehacker, The Simple Dollar, Score, Fatherly, Legal Zoom, Business News Daily and Cheapism.</p><p>On top of that, the stories that quoted these non-existent people were about topics like parenting, mental health and COVID-19.</p><h2><strong>Help a reporter out</strong></h2><p>When a reporter is writing a story that requires a source that he or she does not have, that reporter will likely turn to <a href="https://www.helpareporter.com/">HARO</a>, a service that "connects journalists seeking expertise to include in their content with sources who have that expertise." </p><p>It's no secret that <a href="https://www.superhighway98.com/seo">search engine optimization specialists</a> use the service to build links to content that profits them, but the rise of "deepfake" technology has made it easier than ever to exploit overworked and undertrained reporters who are <a href="https://www.superhighway98.com/google">hungry for clicks</a>.</p><p>Now, shady “SEOs” hide behind fake photos and personalities.</p><h2><strong>The “woman behind Superhighway 98”</strong></h2></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604325790588_27439"><div><p>I'm a caucasian male, but there is nothing (<a href="https://www.superhighway98.com/politics">other than my own morals</a>) to stop me from pretending that this website is published by a woman of color. The photo above isn’t real, but it’s real enough to fool a journalist on a deadline. To combat this fraud, newsrooms must quickly adopt new methods for verifying sources.</p><h2><strong>Trust, but verify</strong></h2><p>GAN renderings are realistic and those that are retouched in Photoshop are nearly perfect, but they are not readily extensible (yet). The upshot: Always ask for two photographs of your source.</p><p>Take those photographs and plug them into a reverse image lookup service like <a href="https://tineye.com/">Tineye</a> (or even Google Images). Have they appeared on the web before? Does the context make sense?</p><p>Ask for links to social media profiles. How long have the accounts been active? Do they tell a consistent story?</p><p>Deepfake technology will only get more advanced and prevalent. To rely on Big Tech to solve this problem is like relying on Big Tobacco to cure cancer. It’s up to each of us to fight for the truth.</p><p>###</p><p><a href="https://www.superhighway98.com/">&lt;- RETURN TO SUPERHIGHWAY 98</a></p></div></div></div>]]>
            </description>
            <link>https://www.superhighway98.com/nvidia</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978225</guid>
            <pubDate>Tue, 03 Nov 2020 10:21:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My game won't sell and that's ok]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24978084">thread link</a>) | @chr15m
<br/>
November 3, 2020 | https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok | <a href="https://web.archive.org/web/*/https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="game_devlog_post_page_85340"><div><div><section id="video_embed_widget_36633"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/7efdmAJAUVY"></iframe></section><section><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzYuZ2lm/original/HaqSXO.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzYuZ2lm/x200/lnOYDd.gif" data-image_id="4488836" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/original/0NaSBi.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/x200/ZLnRgb.gif" data-image_id="4493348" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0NDAxMDAuZ2lm/original/kTd%2Bi3.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0NDAxMDAuZ2lm/x200/kCBUJY.gif" data-image_id="4440100" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/original/tRRdDT.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/x200/bwgJDH.gif" data-image_id="4488835" height="200"></a></section><section><p>I discovered Nethack and Rogue some 25 years ago and ever since then I have wanted to make my own roguelike game. On Friday I followed through on that youthful dream and shipped Asterogue, yay!</p>
<p>This game won’t sell. I have been around the indie games scene long enough to know its a crap-shoot. To make a successful indie game you have to execute at peak performance, do everything right, and then you still roll the dice on success. I’ve seen stone cold geniuses build glorious works of art and watch them get zero downloads. A single tear rolls down their cheek one week after launch and tiny pixellated violins play a chiptune version of Mozart’s Requiem.</p>
<p>My game won’t sell and that’s ok. I am at peace with it after all of these years of game jams and side projects. It is the way of things. I’m just happy to have had the chance to fulfill this dream.</p>
<p>I had so much fun making Asterogue. I’ve never worked harder on a side project. I publically committed to an October 30th release, and I’ve done it. I built the thing I dreamed of making since I was a kid, and I am simply grateful to the universe that this opportunity was within my reach.</p>
<p>I want to thank the people who took a chance and bought the game. It’s amazing to me that our tiny club of people who like this kind of game has more than one member. You guys rock!</p>
<p>I also want to thank from the bottom of my heart the people who tested the game and gave me feedback. It’s an honor when somebody is willing to sacrifice their time to try out something you built, and I really appreciate it. It’s your feedback that made this the best possible game I could make in the time allocated. Thank you.</p>
</section><section><h2>Get Asterogue</h2></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978084</guid>
            <pubDate>Tue, 03 Nov 2020 09:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Untimely Demise of Workstations]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 180 (<a href="https://news.ycombinator.com/item?id=24977652">thread link</a>) | @ingve
<br/>
November 3, 2020 | https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Last month’s news that <a href="https://arstechnica.com/information-technology/2020/10/ibm-to-split-into-two-companies-by-the-end-of-2021/">IBM would do a Hewlett-Packard</a> and divide into two—an IT consultancy and a buzzword compliance unit—marks the end of “business as usual” for yet another of the great workstation companies.</p>
<p>A quick aside on computing history. You can imagine personal computing being driven by two distinct schools of thought. The “top down” school, represented by research-led organisations including Xerox PARC, Bell Labs,academia and the military, asked “what would the world be like if everyone had their own minicomputer”? They took large, time-sharing systems like UNIX and installed them first under, then on, employees’ desks for their own personal use.</p>
<p>The “bottom up” school was made up of hobbyists who asked “can we make an interesting computer out of inexpensive components”? Thus companies like Apple and MITS in the US, Acorn and Sinclair Radionics in the UK, and others took chips that were usually used as peripherals controllers in “real” computers and built interactive programming systems around them. The microcomputer revolution came from the bottom-up school, as they made home computing affordable. The workstation revolution came from the top-down school, as they made powerful on-demand computing feasible.</p>
<p>The two schools came into very close proximity in the 1980s, when the Motorola 68000 family of CPUs (along with the 68881/68882 FPU and 68851 MMU) were the processors of choice in everything from entry-level PCs like the Atari 520ST, through games consoles like the Sega Mega Drive (Genesis in the US), to the most expensive UNIX workstations from NeXT Computer, Sun Microsystems, and Apollo Computer.</p>
<p>But then the workstation makers invested heavily in their own CPU architectures based on RISC design principles and again the two diverged. The workstation market became highly differentiated: RS/6000 from IBM (later PowerPC), Alpha from Digital Equipment Corp, MIPS from, well, MIPS, SPARC from Sun, PA-RISC from HP. The software on these workstations, while superficially very similar, was also differentiated and surprisingly incompatible. Take a program from HP-UX and you’ll have difficulty running it on NeXTSTEP, unless the authors shared the source code and used the nascent GNU autotools to support portable building. As Yoda said: begun, the <a href="https://www.livinginternet.com/i/iw_unix_war.htm">UNIX wars</a> have.</p>
<p>Of course we know that the (desktop) computing world today is mostly Intel and that workstations are mostly fancy PCs, rather than bespoke designs by vertically-integrated companies, Apple being the two trillion dollar outlier. How we got here was that the commodity parts got good enough that there was no evident advantage to workstation-grade hardware. A high-end PC could easily run a workstation OS like System V UNIX (Solaris was an early example), BSD (386BSD which later became FreeBSD, or NeXTSTEP) or Windows NT.</p>
<p>Along the way, the workstation companies consolidated (Apollo and eventually DEC got absorbed into HP; MIPS into SGI) or disappeared altogether (Sun became Oracle Hardware; SGI went bankrupt and sold its assets to sgi; Symbolics did similar—incidentally Symbolics was the first company with a .com domain). IBM long ago stopped even making its own brand PCs, and the news of its split means that there are now very few workstation companies trading in the same form they had “back in the day”. The only ones I can think of that have not had major changes to their corporate structures are Xerox and Sony, whose management may not even have known that they sold workstations.</p>
<p>What’s got lost alongside the death of the workstation is the business model where you sell expensive computers as part of an integrated solution into a particular vertical market, where that expensive solution will cost a lot less than cobbling something together out of cheap PCs. Why? I think people have a lower expectation and higher pain threshold when using computers now; they expect an amount of friction based on their own experience and translate that expectation into realms where it doesn’t belong. As I described way back in issue 2, <a href="https://deprogrammaticaipsum.com/the-various-meanings-of-quality/" target="_blank" rel="noopener noreferrer">computing is a lemon market</a>.</p>
<p>Organisations would go to the workstation vendors because they solved particular problems very well. If you’re in AI, you need Symbolics. Computer graphics, SGI. Telecoms, that’d be Sun. If you want to write software in Ada for the military-industrial complex, you’ll be buying a Rational workstation. Yes, the first IDE was a completely integrated package of hardware and software. And, of course, Apple for Desktop Publishing, the Mac being a workstation of sorts itself. People would buy computers <em>because</em> applications like AutoCAD, Quark or Mathematica ran well on them. They wouldn’t buy the computer then browse the App Store to see whether it could do anything useful.</p>
<p>And the strange thing is that catering to those vertical markets with integrated solutions is easier than ever now. The wide availability of free software means that the basic job of “being a desktop computer” is taken care of at zero cost, so business can focus on contributing valuable bespoke behaviour. And hardware costs are lower than ever: the availability of high-capability SoCs and single-board computers like the Raspberry Pi and Rock64 should make it a no-brainer to sell the computers as accessories for the applications, not the other way around.</p>
<p>In high-tech domains, an engineer could readily have a toolchest of suitable computers in the same way that a mechanic has different tools for their tasks. This one has an FPGA connected by both PCI-E and JTAG to allow for quick hardware prototyping. This one is connected to a high-throughput GPU for visualisations; that one to a high-capacity GPU for scientific simulations.</p>
<p>The general purpose hardware vendors want us to believe that an okay-at-anything computer is the best for everything: you don’t need a truck, so here’s a car. But when you’re hauling a ton of goods, you’ll find it cheaper and more satisfying to shell out more for a truck. Okay-at-anything is good for nothing.</p>
<p>Cover photo by <a href="https://unsplash.com/@serejahh">Serhii Butenko</a> on <a href="https://unsplash.com/photos/zx2Vc1zPDIs">Unsplash</a>.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977652</guid>
            <pubDate>Tue, 03 Nov 2020 08:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust from a Gopher – Lessons 3 and 4]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24977373">thread link</a>) | @BookPage
<br/>
November 2, 2020 | https://levpaul.com/posts/rust-lesson-3-and-4/ | <a href="https://web.archive.org/web/*/https://levpaul.com/posts/rust-lesson-3-and-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><em>Update: There has been discussion on this post on <a href="https://news.ycombinator.com/item?id=24977373">Hacker News</a> - feel free to see the comments there</em></p><p><em>Warning: Incoming opinion monologue; feel free to skip to <a href="#give-me-the-lessons">The Lesson Review</a> review if that’s what you’re after</em></p><p>Hello and welcome to the third post in my series about learning Rust. In case you want to hit it from the start, <a href="https://levpaul.com/posts/rust-lesson-1/">here’s</a> a link to the first one! This entire series covers my journey from being a completely land-locked Gopher to becoming (hopefully) a hardened Rustacean, able to skitter the hazardous seabed of any application safely.</p><h4 id="how-rust-is-makin-me-feel">How Rust is Makin' Me Feel</h4><p>Let me begin not by thwacking loosely about in concepts I know little yet of, as there’s plenty of time for that, but instead allow me to paint the landscapes I see for both Rust and Go. At quite the visceral it occurred to me that these modern languages are built not just to make our coding lives more delightful - but instead to shepherd us into particular engineering and organizational goals.</p><p>The needs for new general purpose languages no longer stem from the “simple” software problems. Take the problems of using variables (Assembly), using custom data types (C), cross-platform, cross-architecture compatibility (JVM languages) or even being dead simple (Python). Today’s languages can instead choose features from all the preceding and <em>then</em> apply engineering and organizational direction.</p><h4 id="the-coercion-of-go">The Coercion of Go</h4><p>I’ve been writing in Go as a hobby since 2014 but professionally only since 2018. As a hobbyist I’ll admit I used to think “Go is <em>opinionated</em>”. That seemed cool, because opinions mean something! Right? But <em>why</em> was it opinionated Levi, WHY? WAKE UP MAN!</p><p>Well today I have a completely different look on it. Go is simply a language that is very <em>safe</em> to share across engineers. This is because engineers don’t need to make a lot of decisions when they use Go. If an application has had its design completed in theory then in Go it often really is just a matter of whacking out the code to make it a reality.</p><p>Just look at how much of Go’s development tooling Google owns. With Java, I remember choosing between Ant or Maven for your build tooling. Go doesn’t let you chose. The closest we got to having a choice was with <code>dep</code> for dependency management. But finally Google caved and <code>gomod</code> was brought about as the standard. Go does its best to take choices away from you. You don’t need to chose between Tomcat or Jetty - the Go <code>net/http</code> package will handle 10kRPS for you no problem. Hell I’ve looked at apps serving 50kRPS, whilst <em>logging</em> a third of said requests simply using <code>fmt.Println</code>. You just don’t need to stray far from the standard library to scale and that is a huge plus of the language. (A large part of this is also comes from the fact that webservers haven’t changed a heck of a lot in the past 10 years so Go didn’t have to “keep up” - on the other hand my experience with http2 in Go has been far from ideal).</p><h5 id="_anyone_-can-pick-up-your-code-and-fix-it"><em>Anyone</em> can pick up your code and fix it</h5><p>This is by far the biggest selling point of using Go <em>in a company</em>. If you need to hire help you can find basically <em>anyone</em> with backend experience, and they will pick up 90% of Go in a week or two. You don’t need to worry at all if they have experience with Struts, JUnit or Spring - what’s in the standard library is plenty. I mean it. Do they need to know about passing pointers or values? Not really - general software engineering practices like peer review and simple unit testing will uncover those types of issues with ease.</p><p>Now on the other hand - who in their right mind would hire <em>me</em> to join their Rust team right now? Nobody - because I would be a gigantic liability to that team.</p><h5 id="gos-purpose-is-for-dev-shops-to-crank-out-web-services-that-are-scalable-easy-to-develop-and-do-not-require-mission-critical-performance">Go’s purpose is for dev shops to crank out web services that are scalable, easy to develop and do not require mission critical performance.</h5><h4 id="rust-no-rust">Rust no Rust</h4><p>I’m a noob. 100%. But even so, in my feeble mind I can already see what Rust is. I see a very sharp knife; but this knife is completely and utterly shrouded and encased in tamper-proof, child-proof, thief-proof hardened and sealed plastic shells. Yes shells as in the plural of shell. These shells are even adult-proof too, where the adult is a generic engineer trained generally in other languages only. The compiler is the packaging, and it will let you wield the knife when it knows exactly what your action plan is. -But oh no, not just any plan will do, your plan <em>must</em> adhere to each and every rule and regulation from the Knife Safety Measurement Act of 1938 and its associated amendments!! (This may not be strictly true as I’ve heard about an <code>unsafe</code> keyword).</p><p><em>But why so much plastic broseidon?</em> You know, and I know that it’s to keep mild-minded people like myself exactly, from nicking fingers with that very sharp knife. Warping back to a meta-level, those fingers don’t even necessarily belong to me the coder, but to the end users of the code. It is no secret to anybody even slightly interested in Rust that a major driving factor for the language was to be able to replace C++ code with something <em>as</em> efficient but much less susceptible to security exploits. Thus, the safety plastic aims not to protect individual coders, but the <em>coding organization</em>.</p><p>Okay, you’ve probably heard enough of my opinion, let’s move on before this analogy implodes and actually hurts someone.</p><hr><h2 id="give-me-the-lessons">Give Me The Lessons!</h2><h4 id="3-common-programming-conceptshttpsdocrust-langorgbookch03-00-common-programming-conceptshtml">3. <a href="https://doc.rust-lang.org/book/ch03-00-common-programming-concepts.html">Common Programming Concepts</a></h4><p>One of the first ‘huh’ moments in this lesson was this compiler message:</p><div><pre><code data-lang="rust"><span>compiler</span><span> </span><span>error</span>:
<span>For</span><span> </span><span>more</span><span> </span><span>information</span><span> </span><span>about</span><span> </span><span>this</span><span> </span><span>error</span><span>,</span><span> </span><span>try</span><span> </span><span>`</span><span>rustc</span><span> </span><span>--</span><span>explain</span><span> </span><span>E0384</span><span>`</span><span>.</span><span>
</span></code></pre></div><p>Naturally I ran the command listed, which took me to a <code>less</code> window (buffer?) containing the following:</p><div><pre><code data-lang="fallback">An immutable variable was reassigned.
Erroneous code example:
'''
fn main() {
    let x = 3;
    x = 5; // error, reassignment of immutable variable
}
'''
By default, variables in Rust are immutable. To fix this error, add the keyword
`mut` after the keyword `let` when declaring the variable. For example:
'''
fn main() {
    let mut x = 3;
    x = 5;
}
'''
</code></pre></div><p>…and this slightly let me down. There isn’t a whole lot of information in this “explanation”. I proceeded to allow <code>rustc</code> to “explain” some more random error codes to me, most of them seemed also to be quite small or to have been deprecated. I am hoping either A) I don’t have to use this feature much or B) I can make rustc/cargo/intellij just tell me the detailed stuff by default.</p><hr><div><pre><code data-lang="rust"><span>const</span><span> </span><span>MAX_POINTS</span>: <span>u32</span> <span>=</span><span> </span><span>100_000</span><span>;</span><span> </span><span>// wtf is this ugly numeric shit
</span></code></pre></div><p>For some reason this irked me when I first saw it (the comment taken verbatim from my lesson notes). On second look it actually seems really, really helpful for readability.</p><hr><h4 id="shadowinghttpsdocrust-langorgbookch03-01-variables-and-mutabilityhtmlshadowing"><a href="https://doc.rust-lang.org/book/ch03-01-variables-and-mutability.html#shadowing">Shadowing</a></h4><p>This seems like a really handy trick. You get to write code as if your variable was immutable, but the compiler does the switching for you. What is really messing my head up though is that you learn about Shadowing before you learn about Ownership. So does my naive understanding of shadowing change after this? I don’t think so … at least. Here’s something I wrote to verify my learnings:</p><div><pre><code data-lang="rust"><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>String</span>::<span>from</span><span>(</span><span>"hello"</span><span>);</span><span>
</span><span>    </span><span>let</span><span> </span><span>r1</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>s</span><span>;</span><span>
</span><span>    </span><span>let</span><span> </span><span>r1</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>s</span><span>;</span><span>
</span><span>    </span><span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span><span> </span><span>r1</span><span>);</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>…and it works. It also answers a question I had when originally learning ownership. For some reason when reading the examples in the book I came away thinking Rust could infer when immutable references' scopes end, but not mutable ones. I was puzzled by this and had a follow-up item but this little example proves I was wrong. Happy days!</p><hr><h5 id="small-nit">Small Nit?</h5><p>The <a href="https://doc.rust-lang.org/book/ch03-02-data-types.html#invalid-array-element-access">Invalid array element access example</a> didn’t work - it was supposed to produce a runtime error but instead it failed to compile:</p><div><pre><code data-lang="rust"><span>   </span><span>Compiling</span><span> </span><span>variables</span><span> </span><span>v0</span><span>.</span><span>1.0</span><span> </span><span>(</span><span>/</span><span>home</span><span>/</span><span>levi</span><span>/</span><span>rustprojs</span><span>/</span><span>variables</span><span>)</span><span>
</span><span></span><span>error</span>: <span>this</span><span> </span><span>operation</span><span> </span><span>will</span><span> </span><span>panic</span><span> </span><span>at</span><span> </span><span>runtime</span><span>
</span><span> </span><span>-</span>-&gt; <span>src</span><span>/</span><span>main</span><span>.</span><span>rs</span>:<span>5</span>:<span>19</span><span>
</span><span>  </span><span>|</span><span>
</span><span></span><span>5</span><span> </span><span>|</span><span>     </span><span>let</span><span> </span><span>element</span><span> </span><span>=</span><span> </span><span>a</span><span>[</span><span>index</span><span>];</span><span>
</span><span>  </span><span>|</span><span>                   </span><span>^^^^^^^^</span><span> </span><span>index</span><span> </span><span>out</span><span> </span><span>of</span><span> </span><span>bounds</span>: <span>the</span><span> </span><span>len</span><span> </span><span>is</span><span> </span><span>5</span><span> </span><span>but</span><span> </span><span>the</span><span> </span><span>index</span><span> </span><span>is</span><span> </span><span>10</span><span>
</span><span>  </span><span>|</span><span>
</span><span>  </span><span>=</span><span> </span><span>note</span>: <span>`</span><span>#[deny(unconditional_panic)]</span><span>`</span><span> </span><span>on</span><span> </span><span>by</span><span> </span><span>default</span><span>
</span></code></pre></div><p>I don’t even know if I should call this a nit or just straight up be impressed. Did Rust <em>evolve</em> to the point the <em>book</em> can no longer trick me into making a runtime panic?! This is some straight-jacket level packaging I swear to god. Much applause.</p><hr><h4 id="_a-smol-walk-in-the-woods_"><em>A smol walk in the woods</em></h4><p>Having picked up many a good pointer during this lesson I figured I had bumped myself up a couple of notches. Maybe white-belt, double-yellow-tip or something along those lines… “<em>Let’s go for a wander</em>” I thought to myself with quiet confidence. Looking left, and then looking right, under the shelter of a single raised eye-brow I chose to descend toward the belly of Rust.</p><p><em><strong><code>Ctrl + *click*</code></strong></em></p><p>I chose a simple avenue. I chose something concrete to all beginners. I chose the pinnacle of <code>Hello_World</code>…</p><p>I chose to dive into <code>println!</code></p><p>… and dive I did. Straight into the ground after clanking my head into a hard iron post of this macro. My eyes but glimpsed Sauron directly and from then on and always, I am blind:</p><div><pre><code data-lang="rust"><span>#[macro_export]</span><span>
</span><span></span><span>#[stable(feature = </span><span>"rust1"</span><span>, since = </span><span>"1.0.0"</span><span>)]</span><span>
</span><span></span><span>#[allow_internal_unstable(print_internals, format_args_nl)]</span><span>
</span><span></span><span>macro_rules</span><span>!</span><span> </span><span>println</span><span> </span><span>{</span><span>
</span><span>    </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>$crate</span>::<span>print</span><span>!</span><span>(</span><span>"\n"</span><span>));</span><span>
</span><span>    </span><span>(</span><span>$($arg</span>:<span>tt</span><span>)</span><span>*</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>({</span><span>
</span><span>        </span><span>$crate</span>::<span>io</span>::<span>_print</span><span>(</span><span>$crate</span>::<span>format_args_nl</span><span>!</span><span>(</span><span>$($arg</span><span>)</span><span>*</span><span>));</span><span>
</span><span>    </span><span>})</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>What in God’s sweet name is this acrid assault on all of my senses?</p><p>I am going to be honest here. There is no way in hell I will understand this macro by the end of my twentieth lesson. Will I?
I’m not sure actually. I guess there’s hope? Chapters <a href="https://doc.rust-lang.org/book/ch10-00-generics.html">10</a>, <a href="https://doc.rust-lang.org/book/ch14-00-more-about-cargo.html">14</a> and <a href="https://doc.rust-lang.org/book/ch19-00-advanced-features.html">19</a> all look they will be mandatory. <em>Hoping Intensifies … ?</em></p><hr><h4 id="expressions-versus-statements">Expressions versus Statements</h4><blockquote><p>If you add a semicolon to the end of an expression, you turn it into a statement, which will then not return a value. Keep this in mind as you explore function return values and expressions next.</p></blockquote><p>This was a mind fuck - about 10 minutes before reading this I thought to myself that semi-colons seemed optional and kind of pointless in rust. Boy was I well outside the woods.</p><p>A later thought did have me wondering though; do Rustaceans really just write expressions at the end of their getter functions or is it more common to explicitly <code>return</code>?</p><hr><blockquote><p>In …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://levpaul.com/posts/rust-lesson-3-and-4/">https://levpaul.com/posts/rust-lesson-3-and-4/</a></em></p>]]>
            </description>
            <link>https://levpaul.com/posts/rust-lesson-3-and-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977373</guid>
            <pubDate>Tue, 03 Nov 2020 07:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nassim Taleb vs. Nate Silver: who is right about election forecasting?]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24976175">thread link</a>) | @probe
<br/>
November 2, 2020 | http://quant.am/statistics/2020/10/11/taleb-silver-feud/ | <a href="https://web.archive.org/web/*/http://quant.am/statistics/2020/10/11/taleb-silver-feud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Perhaps lost in the whirlwind of presidential name-calling, a lesser-known multi-year old feud has resurfaced on Twitter this election season. Nate Silver is the founder of <a href="https://fivethirtyeight.com/">FiveThirtyEight</a> and is a popular statistician frequently called upon by media members to give commentary and expertise on election forecasting. Nassim Taleb is a statistician/quant turned philosopher, perhaps most well known for authoring the book “The Black Swan”. He is second most well known for calling people names on Twitter. In this 2018 instance he seemed to take issue with FiveThirtyEight’s election forecasts, saying that <a href="https://twitter.com/nntaleb/status/1059202026184282113">“klueless Nate Silver” “doesn’t know how math works”</a>, among a host of other insults. Silver responded that Taleb was an <a href="https://twitter.com/NateSilver538/status/1062782704159256576">“intellectual-yet-idiot”</a>, an phrase coined by Taleb himself. Ouch. A litany of statisticans, mathematicians, and data scientists came out of the woodwork to take sides. Taleb himself <a href="https://twitter.com/nntaleb/status/1314902682570764288">doubled down</a> on Oct. 10, 2020, again calling Silver “totally clueless”.</p>

<p>In this article I take a look behind the mathematical premises of Taleb’s arguments, and give intuitive explanations of why or why not they hold up. In short, while Taleb’s math is sound, he still manages to miss the mark by ignoring the nuance of Silver’s forecasts.</p>

<p>Taleb’s main gripe is that forecasters change their opinion too much over time. Take a look at FiveThirtyEight’s forecast from the 2016 presidential election, where the probability of Clinton winning peaked at 90%, and hit a low of 50%. 
<img src="http://quant.am/assets/2016election.png" alt="2016 election"></p>

<p>Taleb insists that Clinton never should’ve received a probability of winning of 90%. Even if polls were heavily in favor of Clinton at the time, he says Silver should’ve taken into account the uncertainty that polls would change over the next few months leading up to the election, or the possibility of major news breaking. If Silver had factored in the “unknown unknowns” his forecast should’ve been closer to 50%. In essence, this single number should reflect all <em>current and future uncertainty</em>. Taleb constructs this argument by way of quantitative finance, which perhaps led to him and traditional statisticians talking past each other. In the following sections I step through his argument in intuitive terms.</p>


<p>A well known truth to economists, quants, and traders: if I tell you a number, I must be willing to transact at that number. If I tell you the fair value of this house is $500,000, I must be willing to buy AND sell at that price. Otherwise, the number I gave you is meaningless. Likewise, if I tell you the probability of Biden winning this election is 73%, I must be willing to pay $0.73 to make the following wager: if Biden wins I receive $1, if he loses I receive $0.</p>

<p>This is important because it turns the predicted probabilities into a tradeable financial instrument known as a binary option. If the prediction is 50%, I can buy the option at $0.50. If the prediction moves to 65%, I can now sell the option at $0.65, turning a $0.15 profit.</p>

<p>This brings us to another important principle known as the <em>no-arbitrage condition</em>. If the election predictions are accurate, there should be no way for a trader to make guaranteed money by trading this option. To give an illustrative example, let’s say that we live in an unchanging world where the probability of Candidate A winning is static at 50%. If a pollster does not report a static forecast day after day, he will create an arbitrage opportunity. We will sell when the prediction is above 50%, and buy below. 
<img src="http://quant.am/assets/arbitrage-pollster.jpeg" alt="Arbitrage condition"></p>

<p>OK, so now we’ve established that if an arbitrage condition exists, then the pollster is wrong and should not have made that prediction in the first place. Still, it’s not obvious that there’s an arbitrage condition within Silver’s predictions yet (remember, the trader doesn’t have access to an oracle, and only has the same information available to him as the pollster). There’s two more building blocks that we need in order to establish an arbitrage condition.</p>


<p>To paraphrase Taleb, if I tell you an event has a 0% chance of occurring, I cannot change my mind and tell you tomorrow it now has a 50% chance of occurring. Otherwise I shouldn’t have told you it has a 0% chance in the first place. Probability and confidence are inextricably linked, and the number a pollster predicts should encapsulate both. To go to the other extreme, if the uncertainty is extremely high (and therefore confidence low), <em>it does not matter what the polls today are saying</em>. I should give both candidates a 50% chance of winning, because I am admitting the extremely likely possibility that an external event will happen that will invalidate today’s polls. To put it in technical terms, maximum uncertainty implies maximum entropy, and the maximum entropy distribution on the [0, 1] interval is the uniform distribution, which has a mean at .5. The following figure (from <a href="https://arxiv.org/pdf/1703.06351.pdf">this paper</a>) shows the relationship between probability (x-axis) and volatility (y-axis) under a specific option pricing formulation.
<img src="http://quant.am/assets/confidence-probability.png" alt="Confidence vs volatility"></p>

<p>At this point we are suspecting something doesn’t look right with FiveThirtyEight’s predictions, as they seem to have both high volatility and high probability, which contradict each other. Where is the threshold though? How can we prove that the volatility is too high?</p>


<p>Now we’re going to go a little bit technical and show that a no-arbitrage condition was likely violated. The basic construction is as follows:</p>

<ol>
  <li>In order to satisfy the no-arbitrage condition, all information must be “priced in” into the pollster’s current prediction.</li>
  <li>Therefore, the time series of predictions must be a martingale.</li>
  <li>Martingales cannot show trending or mean-reverting behavior, therefore Silver’s predictions violated the martingale property, and therefore the no-arbitrage condition.</li>
</ol>

<p>The definition of a martingale is a stochastic process \(X_1, X_2, ... X_t\) that satisfies</p><p>

\[E[X_{t+1} | X_1, ... ,X_t] = X_t\]

</p><p>To quote <a href="https://www.researchgate.net/profile/Christopher_Wlezien/publication/344419648_Information_incentives_and_goals_in_election_forecasts/links/5f73c994a6fdcc0086484861/Information-incentives-and-goals-in-election-forecasts.pdf">Andrew Gelman</a>,</p>

<blockquote>
  <p>In non-technical terms, the martingale property says that knowledge of the past will be of no use in predicting the future…One implication of this is
that it should be unlikely for forecast probabilities to change too much during the campaign (Taleb, 2017). Big events can still lead to big changes in the forecast: for example, a series of polls with Biden or Trump doing much better than before will translate into an inference that public opinion has shifted in that candidate’s favor. The point of the martingale property is not that this cannot happen, but that the possibility of such shifts should be anticipated in the model, to an amount corresponding to their prior probability. If large opinion shifts are allowed with high probability, then there should be a correspondingly wide uncertainty in the vote share forecast a few months before the election, which in turn will lead to win probabilities closer to 50%.</p>
</blockquote>

<p>In other words, all information is already priced into the current market. If it were not so, a trader could make money by taking advantage of the information that is not priced in already. So last thing we need to check: is it likely that Silver’s predictions have the martingale property? It is not in dispute that the answer is no…it shows clear mean-reversion behavior and can be validated by a statistical test of the martingale hypothesis (for example, a <a href="http://www.planchet.net/EXT/ISFA/1226.nsf/9c8e3fd4d8874d60c1257052003eced6/35822efeb009804cc1257afe006b0063/$FILE/11park.pdf">Kolmogorov-Smirnov test</a>). It seems that Taleb’s math is sound here. So where did he go wrong?</p>


<p>I believe Nate Silver is answering a subtly different question with his election forecasts. Each data point that Silver produces is answering the question: <em>if the election were to happen today</em>, what is the probability of each candidate winning? I argue that this is a valid and useful formulation. To put it slightly differently: if the question is “Who will win the election on Nov. 3?”, which of the following answers is more satisfying?</p>

<ul>
  <li>“If nothing else changes between now and the election, Joe Biden has a 85% chance of winning.” (Silver’s argument)</li>
  <li>“I dunno, anything could happen between now and the election, I give neither candidate chances much more than 50%.” (Taleb’s argument)</li>
</ul>

<p>It is a valid criticism that perhaps Silver is not very clear on explaining what his numbers represent, and therefore the media misreports his predictions. Still, I wager that most people would find the first answer more useful. In this interpretation, the “financial instrument” is a binary option that expires every day. Thefore the time series of Silver’s predictions is not interpretable as a martingale, as it strings together the price of a completely different instrument every day.</p>

<p>It is also a valid criticism that Silver’s predictions prior to Nov. 3 mean absolutely nothing, whereas in the Taleb formulation it has a natural interpretation as the betting odds for each candidate. Silver has explicitly stated that he only judges his models based on his finalized prediction. To that end, his models are extremely well calibrated, i.e., when he says something has a 50% chance of happening it actually does happen 50% of the time.
<img src="http://quant.am/assets/538-calibration.png" alt="538 calibration"></p>

<p>In conclusion, Taleb and Silver should be having a philosophical debate on what pollsters’ numbers actually mean, and stay away from the useless distraction of calling each other names on Twitter.</p>

<h3 id="update-10122020">Update (10/12/2020)</h3>
<p>Andrew Gelman, Aubrey Clayton, Dhruv Madeka and many other statisticians respond and give their thoughts: <a href="https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/">https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/</a></p>

<h3 id="update-2-1132020">Update 2 (11/3/2020)</h3>
<ul>
  <li>Nassim Taleb responds to this post on <a href="https://twitter.com/nntaleb/status/1323594733797679104">Twitter</a></li>
  <li><a href="https://news.ycombinator.com/item?id=24976175">Hacker News discussion</a></li>
</ul>

		</div></div>]]>
            </description>
            <link>http://quant.am/statistics/2020/10/11/taleb-silver-feud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24976175</guid>
            <pubDate>Tue, 03 Nov 2020 04:04:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of ABAC on AWS]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975952">thread link</a>) | @arkadiyt
<br/>
November 2, 2020 | https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/ | <a href="https://web.archive.org/web/*/https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Two years ago, in November 2018, AWS <a href="https://aws.amazon.com/blogs/security/add-tags-to-manage-your-aws-iam-users-and-roles/">announced</a> new conditions keys <code>aws:PrincipalTag</code> and <code>aws:RequestTag</code>, and <a href="https://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/">started to push</a> the concept of Attribute Based Access Control (ABAC).  This post will describe what this is, the difficulties with implementing this strategy, and what AWS needs to do for customers to be successful with this concept.</p>


<p>A long standing problem with AWS security has been that if you had two projects in a single AWS account, it was often impossible to ensure that some principals (meaning the users and roles there) could only interact with the resources of one project and not the other.  In order to implement a least privilege strategy, you want to isolate the actions each principal can take to only certain resources to ensure they cannot impact or exfil data from the other project.</p>

<p>The solution many customers have been forced to adopt is to isolate their projects into separate AWS accounts, but that’s not always ideal. For example, it can be difficult to take an existing account and move resources into another account as an account grows.  So AWS started focusing on tagging resources and restricting access via tags.  Over time, many privileges started to be able to work with the condition key <code>aws:ResourceTag</code> so that you could restrict who could interact with an existing resource. But what if you wanted the principal to create new resources, but restrict what tags they could use, so they couldn’t create a resource with the tag of another project?  For this AWS <a href="https://aws.amazon.com/blogs/security/add-tags-to-manage-your-aws-iam-users-and-roles/">released</a> <code>aws:RequestTag</code>.</p>

<p>What if you had many principals and projects and you didn’t want to create separate IAM policies for each one? You want a single policy that you can apply to all principals that says “Only interact with resources that match the same tag as you have” or the common request of “You can only interact with resources you created.”  To implement this concept, AWS released <code>aws:PrincipalTag</code>, so you could now use a conditions such as:</p>

<pre><code>StringEquals: { "aws:RequestTag/project": "${aws:PrincipalTag/project}" }
</code></pre>

<p>Attribute-based access control (ABAC) is an authorization strategy that defines permissions based on attributes, which on AWS means tags.  Two of the best resources on this concept are <a href="https://twitter.com/bjohnso5y">Brigid Johnson’s</a> re:Inforce talk <a href="https://www.youtube.com/watch?v=Iq_hDc385t4">Scale Permissions Management in AWS w/ Attribute-Based Access Control</a> and <a href="https://twitter.com/mchancloud">Michael Chan</a>’s blog post <a href="https://aws.amazon.com/blogs/security/working-backward-from-iam-policies-and-principal-tags-to-standardized-names-and-tags-for-your-aws-resources/">Working backward: From IAM policies and principal tags to standardized names and tags for your AWS resources</a>.</p>



<h2 id="lack-of-privilege-support">Lack of privilege support</h2>
<p>The first issue people ran into with ABAC was that not all resources supported tags. Of those resources that did, not all supported IAM conditions to restrict these tags. Of those that did, not all supported tag on create, so you could only restrict access to tag existing resources, leaving resources untagged.  Let’s get some stats on how much coverage AWS has today.  Using the IAM data from <a href="https://github.com/duo-labs/parliament/blob/main/parliament/iam_definition.json">Parliament</a> (which is just the AWS <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_actions-resources-contextkeys.html">docs</a> scraped into a json file), we find there are 869 privileges that contain the word <code>create</code>, which we can assume to be the privileges that grant permission to create a resource.</p>

<pre><code>$ cat parliament/iam_definition.json | jq '.[]|.prefix as $prefix|.privileges[]|.privilege as $privilege|select($privilege|ascii_downcase|contains("create"))|$prefix+":"+$privilege'  | sort | uniq | wc -l
     869
</code></pre>

<p>Next, we’ll find all the privileges of these that allow the <code>RequestTag</code> condition key:</p>

<pre><code>$ cat parliament/iam_definition.json | jq '.[]|.prefix as $prefix|.privileges[]|.privilege as $privilege|select($privilege|ascii_downcase|contains("create")).resource_types[].condition_keys[]|select(.|ascii_downcase |contains("requesttag"))|$prefix+":"+$privilege' | sort | uniq | wc -l
     381
</code></pre>

<p>We find that 381 of 869 (43%) privileges for creating resources on AWS allows you to both tag the new resources and to restrict what tags are used for that.  This search does miss some privileges that are used to create resources but do not include the word <code>create</code>, such as <code>ec2:RunInstances</code> that lets you create an EC2 and <code>route53:ChangeResourceRecordSets</code> that lets you create a subdomain.  It also misses situations where AWS has two privileges for creating a resource, where one privilege is used for creating the resource with tags and one without, such as <code>cloudfront:CreateDistribution</code> and <code>cloudfront:CreateDistributionWithTags</code>.  However, 43% seems roughly correct.</p>

<p>One might try to argue that the more widely used resources do support tag on create and restricting those tags, but there are some popular resources that do not.  For example, the following privileges are all unable to restrict tag on create: <code>lambda:CreateFunction</code>, <code>dynamodb:CreateTable</code>, <code>kms:CreateKey</code>, <code>logs:CreateLogGroup</code>, <code>s3:CreateBucket</code>, <code>sqs:CreateQueue"</code>, and <code>iam:CreateRole</code>.</p>

<p>As a hack, for resources that don’t support tag on create, you can use the names of the resources in a similar way as a tag, but this is awkward.</p>


<p>Given a resource in an AWS account, there is not much tooling available that can tell you who all has access to it.  Some tools (ex. <a href="https://github.com/FSecureLABS/awspx">awspx</a>) will tell you who has certain privileges, but they don’t understand conditions, among other details.  So for example, they can tell you who has <code>secretsmanager:CreateSecret</code>, but they won’t tell you who can create a secret with the tag <code>foo</code>.</p>

<p>I built some functionality into <a href="https://github.com/duo-labs/cloudmapper">CloudMapper</a> through it’s <code>access_check</code> command that tries to understand more IAM logic. It has some understanding of conditions and will also take IAM Boundaries into consideration, but it does not understand the existing tags on a resource, and lacks a lot of other functionality.  Its answers will be more correct than other tools for some questions, but will still be incorrect for a lot of cases.  The project <a href="https://github.com/nccgroup/PMapper">PMapper</a> also has some additional logic in it.</p>

<h3 id="simulateprincipalpolicy">SimulatePrincipalPolicy</h3>
<p>There is an API called <a href="https://docs.aws.amazon.com/IAM/latest/APIReference/API_SimulatePrincipalPolicy.html">SimulatePrincipalPolicy</a> that can be used to understand who has access to resources, but it is missing a lot of functionality you would expect.  For example, you can pass it the ARN of a principal, the ARN of a resource, and associated privilege to check for, but if there are any conditions, you then have to also include the condition values that should be used when checking this.  This means you have to figure out the tags of the resource and the resource policy to then pass to this call.</p>

<p>So for example, assume we have a principal that can call <code>secretsmanager:GetSecretValue</code> only on secrets that have been tagged with a <code>project</code> key that has a value <code>foo</code>, and we have a secret with that tag.  In order to check if our principal can access this secret, we can run:</p>

<pre><code>aws iam simulate-principal-policy \
  --policy-source-arn arn:aws:iam::123456789012:user/testuser \
  --action-names secretsmanager:getsecretvalue \
  --resource-arns arn:aws:secretsmanager:us-east-1:123456789012:secret:test-abcdef \
  --context-entries ContextKeyName=secretsmanager:ResourceTag/project,ContextKeyValues=foo,ContextKeyType=string
</code></pre>

<p>Notice in the last line, I have to tell it the value of the tag for the resource that I want it to check. The policy simulator does not figure that out for you.  So if you were to try to automate this, you would have to make a describe call, knowing where in the response to find the tag value, and how to format the call to <code>SimulatePrincipalPolicy</code> with this value.  Also, if the IAM policy has unrelated condition keys for other privileges, you have to provide context keys for those too. Next, you have to provide the resource policy if one exists, the IAM boundary if one exists, and potentially other data.</p>

<p>Because of these limitations, this API is not as useful as you might hope.</p>

<h3 id="zelkova">Zelkova</h3>
<p>Zelkova is an automated reasoning solution for IAM policies that was announced by AWS in 2017 and available for private beta.  When I talk to people about the problem of understanding who has access what, this project often comes up as a possible option by those who aren’t familiar with what exactly it does. Unfortunately, Zelkova is an engine that you still have to figure out the inputs to.  It can answer some IAM related questions, but for our goals of understanding who has access to what, it has all the same limitations as iam:SimulatePrincipalPolicy.</p>

<h2 id="limited-capabilities-of-tag-policies">Limited capabilities of Tag Policies</h2>
<p>An AWS Organization feature called <a href="https://aws.amazon.com/blogs/aws/new-use-tag-policies-to-manage-tags-across-multiple-aws-accounts/">Tag Policies</a> was supposed to help enforce tagging, but it is critically limited by only being able to enforce what tag values may be used when defined tag keys are used.  This means you cannot enforce that a resource is tagged. You can only enforce that when someone attempts to tag a resource with a certain key, that the value is one of a defined set.  In order to enforce tagging actually be used in an organization, you have to use SCPs as described <a href="https://aws.amazon.com/blogs/security/securing-resource-tags-used-for-authorization-using-service-control-policy-in-aws-organizations/">here</a>.</p>

<p><a href="https://summitroute.com/img/tag_policies_limitation.png">
<img src="https://summitroute.com/img/tag_policies_limitation.png" alt="Enforcement has no effect on resources that are created without tags." title="Enforcement has no effect on resources that are created without tags."></a></p>
<p>This warning is from the docs <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_tag-policies-enforcement.html">here</a>.</p>

<p>Further, Tag Policies do not have coverage across all resources that support tags.  The list of supported resources is <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_supported-resources-enforcement.html">here</a>.  An example of a resource that supports tags, but is not supported by Tag Policies, is S3 objects.</p>

<p>AWS needs to extend the functionality of this feature to support enforcement of using tag keys, as there is little value in it in its current form.</p>

<h2 id="lack-of-support-for-working-with-multiple-tag-values">Lack of support for working with multiple tag values</h2>
<p>People often work on multiple projects, but there is no way to tag a principal with a key that has multiple tag values.  As an example, imagine you have two projects, <code>foo</code> and <code>bar</code>, and you want to allow a person to work on just <code>foo</code> and all the resources they create should have a <code>Project</code> tag with value <code>foo</code>, and likewise you have another person who should only work on the <code>bar</code> projects.  AWS <a href="https://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/">has shown</a> how to create a single IAM policy that can be applied to both people, and you’d just need to make sure to apply a <code>Project</code> tag to the principals to define which project they can work on.</p>

<p>Now imagine that one of these employees needs to work on both projects. You cannot tag a principal with both <code>foo</code> and <code>bar</code>.  One solution is to have the person assume different IAM roles depending on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/">https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/</a></em></p>]]>
            </description>
            <link>https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975952</guid>
            <pubDate>Tue, 03 Nov 2020 03:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a Git Diff in Markdown]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975629">thread link</a>) | @nilsandrey
<br/>
November 2, 2020 | https://blog.alispit.tel/create-a-git-diff-in-markdown/ | <a href="https://web.archive.org/web/*/https://blog.alispit.tel/create-a-git-diff-in-markdown/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of my favorite blogging tips is using diff formatting in GitHub flavored markdown. I use this to show what has changed in code snippets. This works for code snippets in most markdown packages and on Dev.to.</p>
<p>If I wanted to show that I was changing a function from one thing to another, I could add a snippet that looks like this!</p>
<div data-language="diff"><pre><code>function addTwoNumbers (num1, num2) {
<span><span>-</span><span>  return 1 + 2
</span></span><span><span>+</span><span>  return num1 + num2
</span></span>}</code></pre></div>
<p>First, instead of specifying the programming language, use <code>diff</code> after the backticks. Then at the beginning of any lines of code you want to show as removed, add a <code>-</code>. At the beginning of any lines of code you want to show as added, add a <code>+</code>.</p>
<p>The code would look like this:</p>
<div data-language="text"><pre><code>```diff
function addTwoNumbers (num1, num2) {
-  return 1 + 2
+  return num1 + num2
}
```</code></pre></div>
<p>I have used this in tons of my coding tutorials, such as <a href="https://welearncode.com/beginners-guide-react/" target="_blank" rel="nofollow noopener noreferrer">this</a> one. It makes it a lot easier for readers to see what is changing from snippet to snippet.</p>
</div></div>]]>
            </description>
            <link>https://blog.alispit.tel/create-a-git-diff-in-markdown/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975629</guid>
            <pubDate>Tue, 03 Nov 2020 02:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EME, CDM, AES, CENC, and Keys – Building Blocks of DRM]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24975487">thread link</a>) | @jayjohn436
<br/>
November 2, 2020 | https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/ | <a href="https://web.archive.org/web/*/https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" alt="eme cdm cenc keys" title="eme-cdm-cenc-featured-image" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>Anyone trying to understand DRM (Digital Rights Management) will be confronted with acronyms such as AES, CDM, CENC, EME, etc. This can get very confusing for a newcomer, but understanding them is important to get a good understanding of DRM. In this article, let’s take a gentle tour of the building blocks of DRM:- EME, CDM, AES, CENC, and the use of Keys &amp; Key Servers.</strong></p>








<h2 id="simplified-architecture-of-a-drm-system"><span id="Simplified_Architecture_of_a_DRM_System"></span>Simplified Architecture of a DRM System<span></span></h2>



<p>As we saw&nbsp;<a href="https://ottverse.com/what-is-drm-digital-rights-management/">in the previous article</a>,&nbsp;<strong>DRM is a combination of encryption and business rules to control access and consumption of digital content.</strong></p>



<p>Simply put, DRM is a system that,</p>



<ul><li>provides the tools and infrastructure to enable a content provider to encrypt their content, and</li><li>build an ecosystem around the encrypted content so that the content provider can control who/what can decrypt and consume their content.</li></ul>



<p><a href="https://ottverse.com/what-is-drm-digital-rights-management/">In the previous article of the series</a>, we saw Ram and Shyam sending coded messages to each other. At the same time, Hari maintained the codebooks and decided who got to read/write the notes – remember?</p>



<figure><img data-attachment-id="156" data-permalink="https://ottverse.com/with-drm/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1316%2C878&amp;ssl=1" data-orig-size="1316,878" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="with-drm" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1024%2C683&amp;ssl=1" loading="lazy" width="1024" height="683" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1200%2C801&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?w=1316&amp;ssl=1 1316w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Now, let’s take this simple system and replace it with the technology needed to secure and distribute video. What do we get?</p>



<figure><img data-attachment-id="138" data-permalink="https://ottverse.com/step-0/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1396%2C818&amp;ssl=1" data-orig-size="1396,818" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1024%2C600&amp;ssl=1" loading="lazy" width="1024" height="600" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=300%2C176&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=768%2C450&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1200%2C703&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?w=1396&amp;ssl=1 1396w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Let’s describe what we have here. There is a movie that we want to send to an authenticated user securely.</p>



<p>So,</p>



<ol><li>we ask a DRM company’s server for a codebook to encrypt our video,</li><li>then, we encrypt the video using that codebook</li><li>we send the movie to the user.</li><li>the user then asks the DRM company’s server for the codebook to unlock the video (decrypt it)</li><li>and then he watches the movie!</li></ol>



<p>Fantastic!</p>



<p>Is this all there is to know about DRM for video?</p>



<p>Nope! What we have here is a simple, toy-example of how to transfer movies securely using DRM. It captures the essence of DRM perfectly but wouldn’t work well in the real world.</p>



<p>In the rest of this article, let’s take each piece of this simple system, re-think it, re-design it, and see how it fits within the world of video delivery and DRM, shall we?</p>



<h2 id="step-0-lets-move-to-adaptive-bitrate-streaming"><span id="Step_0_Let%E2%80%99s_Move_to_Adaptive_Bitrate_Streaming"></span>Step 0: Let’s Move to Adaptive Bitrate Streaming<span></span></h2>



<p>Before we talk about the order, let’s modify our example to suit the ABR (<strong>A</strong>daptive&nbsp;<strong>B</strong>it<strong>R</strong>ate) model of video delivery.</p>



<p><strong>ABR Refresher:</strong>&nbsp;in ABR, a movie is encoded into different bitrate-resolution combinations&nbsp;<em>(a.k.a ladder)</em>&nbsp;and then split into&nbsp;<strong>chunks or segments</strong>. Each chunk represents a few seconds of video and it is independently decodable.</p>



<p><strong>“Packaging”</strong>&nbsp;refers to chunking or breaking up a movie into small pieces and describing it in a manifest or playlist document. When the user wants to play the movie, he needs to refer to this manifest.</p>



<p>Depending on the available bandwidth, the player requests a chunk/segment of a particular bitrate&nbsp;<em>(rendition, or rung of the ladder)</em>&nbsp;and a CDN (Content Delivery Network) responds with the requested chunk.</p>



<p>Popular methods of video delivery using ABR are MPEG DASH and HLS. For a deeper understanding, please refer to our articles on&nbsp;<a href="https://ottverse.com/what-is-ott-video-streaming/">OTT</a>&nbsp;and&nbsp;<a href="https://ottverse.com/what-is-abr-video-streaming/">ABR</a>&nbsp;video streaming.</p>



<p>Let’s change our block digram to reflect ABR video delivery.</p>



<figure><img data-attachment-id="139" data-permalink="https://ottverse.com/step-0-with-abr/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1476%2C868&amp;ssl=1" data-orig-size="1476,868" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0-with-abr" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1024%2C602&amp;ssl=1" loading="lazy" width="1024" height="602" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=768%2C452&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1200%2C706&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?w=1476&amp;ssl=1 1476w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The only changes here are the packaging and CDN-based delivery steps. That’s all.</p>



<p>Okay, let’s move on and start with the encryption process.</p>



<h2 id="step-1-video-encryption"><span id="Step_1_Video_Encryption"></span>Step 1: Video Encryption<span></span></h2>



<p>The whole idea of encryption is to ensure that when someone intercepts our data, they should not read it or watch it in the case of video.</p>



<p><strong>Encryption refresher:</strong>&nbsp;–&nbsp;<em>encryption is a technique used to keep data confidential and prevent unauthorized people from reading it. Encryption uses a “key” to convert input data (plaintext) into an alternate form called ciphertext. It is almost impossible to convert the ciphertext back to plaintext without the key.</em></p>



<p><em>However, practically speaking, decryption without the key is possible, and encryption algorithms are designed make reverse-engineering extremely expensive – in terms of time, money, and computing resources needed.</em></p>



<p>One of the most popular encryption techniques is the “Advanced Encryption Standard” or “AES” for short. It is also called Rijndael (after its inventor) and was established by the U.S. National Institute of Standards and Technology (NIST) in 2001 to encrypt electronic data.</p>



<p>Some important points to remember about AES:-</p>



<ul><li>It’s a&nbsp;<strong>symmetric-key algorithm</strong>: encryption and decryption are performed using the same key.</li><li>It has three variants based on the key-length: 128, 192, and 256 bits. The longer the key, the harder it is to crack.</li><li>Cracking the AES-128 without the key would require a “billion times a billion years” and a super-computer (<a href="https://www.eetimes.com/how-secure-is-aes-against-brute-force-attacks/" target="_blank" rel="noopener">source</a>).</li></ul>



<p>If you are interested in going deep into the AES standard, look at the&nbsp;<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" target="_blank" rel="noopener">AES’s Wikipedia page</a>.&nbsp;<em>I am not an expert in cryptography and won’t be able to do justice to the AES.</em></p>



<p><strong>Note:</strong>&nbsp;Please remember that&nbsp;<strong>encryption is not encoding, and decryption is not decoding in the video space</strong>. For videos, encoding and decoding are words used to refer to compression and decompression, respectively. To learn more about encoding, decoding, and video codecs, please read our articles on&nbsp;<a href="https://ottverse.com/need-for-video-compression/">the need for compression</a>&nbsp;and a&nbsp;<a href="https://ottverse.com/what-is-a-video-codec/">simple introduction to video codecs</a>.</p>



<h3 id="is-aes-128-the-only-encryption-technique"><span id="Is_AES128_The_Only_Encryption_Technique"></span>Is AES-128 The Only Encryption Technique?<span></span></h3>



<p>No, it isn’t, and let’s think about the implication of this for a minute.</p>



<p>If a content provider decides to engage with three different DRM companies, and all three use different encryption techniques, then it means that the content provider needs to encrypt their videos three times, resulting in a waste of storage space and other resources.</p>



<p>That is why the CENC specification came into being – to reduce this encryption-driven fragmentation of the market and to reduce storage requirements.</p>



<p>Let’s learn about this next.</p>



<h3 id="cenc-or-common-encryption"><span id="CENC_or_Common_Encryption"></span>CENC or Common Encryption<span></span></h3>



<p><strong>Actually, before we dive into CENC, let’s step back and take a look at the state of OTT streaming protocols and CMAF in particular.</strong></p>



<p>There are primarily two protocols in use today – MPEG-DASH and HLS.&nbsp;<em>There are others such as MSS (Microsoft Smooth Streaming) and HDS, but, we’ll leave them aside for this discussion.</em></p>



<p>MPEG-DASH uses the&nbsp;<code>mp4</code>&nbsp;container format for its videos and HLS uses the MPEG-TS (<code>ts</code>) container for its files. If a content provider uses both MPEG-DASH and HLS, then they need to store a copy of their videos in both&nbsp;<code>mp4</code>&nbsp;and&nbsp;<code>ts</code>&nbsp;file formats.</p>



<p>Now, let’s add the DRM encryption problem to it. If our three hypothetical DRM providers use three different encryption standards, then a content providers needs to store&nbsp;<code>2 * 3</code>&nbsp;… six copies of each video! What a waste of storage space!!</p>



<p><strong>To combat the first problem posed by video streaming protocols, the&nbsp;<a href="https://mpeg.chiariglione.org/standards/mpeg-a/common-media-application-format" target="_blank" rel="noopener">CMAF</a>&nbsp;specification was created</strong> which said that videos can be stored in the&nbsp;<strong>fragmented mp4</strong>&nbsp;container format (<code>fmp4</code>). With support from both MPEG-DASH and HLS, you can now create only one set of videos, store it in&nbsp;<code>fmp4</code>&nbsp;format, and use a common set of files for both protocols. </p>



<p><strong>Just make sure you create two manifests (sigh!).</strong></p>



<h3><span id="How_About_Unifying_the_Encryption"></span><strong>How About Unifying the Encryption?</strong><span></span></h3>



<p>We still need to store multiple copies of each file if different DRM technologies use different encryption standards, right?</p>



<p>For this purpose, the MPEG developed the&nbsp;<a href="https://www.iso.org/standard/68042.html" target="_blank" rel="noopener">CENC or Common Encryption specification</a>, specifying that videos can be encrypted using either&nbsp;<code>cenc</code>&nbsp;(AES-128 CTR) or&nbsp;<code>cbcs</code>&nbsp;(AES-128 CBC).&nbsp;<em>CTR stands for Counter; and CBC stands for Cipher Block Chaining.</em></p>



<p>The implication of CENC is that a content provider needs to encrypt his videos only once and any decryption module can decrypt it.&nbsp;<em>Note: Exposing the encryption algorithm is not a problem as long as the keys are strongly protected.</em></p>



<p><strong>Well, CENC might sound like a magic wand for DRM-unification, but it is not.</strong></p>



<p>There are three primary DRM technologies in the market – Apple FairPlay, Google Widevine, and Microsoft PlayReady.</p>



<ul><li>Apple FairPlay supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode.</li><li>HLS supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode (irrespective of CMAF)</li><li>Widevine and PlayReady support both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH with CMAF supports both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH without CMAF supports only AES-128 CTR&nbsp;<code>cenc</code>&nbsp;mode.</li></ul>



<p>As you can see, the CMAF and CENC specs have lead to confusion and fragmentation in the streaming space. </p>



<p><strong>A possible convergence point is the universal use of CMAF and AES-CBC&nbsp;cbcs&nbsp;mode, but, how will these impact legacy devices that support only CTR or only MPEG-TS?</strong></p>



<p>That’s a discussion for another time.</p>



<h2 id="step-2-key-keyid-and-the-license-server"><span id="Step_2_Key,_KeyID,_and_the_License_Server"></span>Step 2: Key, KeyID, and the License Server<span></span></h2>



<p>By now, we have established that we will be encrypting or videos using AES-128 bit encryption. At this stage, a few questions that come up are –</p>



<ol><li>Where do we get the AES-128 Encryption Keys?</li><li>How do we associate an Encryption Key with a movie?</li><li>Where do we store the Encryption Keys?</li></ol>



<p>Let’s answer them one at a time.</p>



<h3 id="where-do-we-get-the-aes-128-bit-encryption-keys"><span id="Where_do_we_get_the_AES128_bit_encryption_keys"></span>Where do we get the AES-128 bit encryption keys?<span></span></h3>



<p>Any content provider can generate the encryption keys manually using specialized software. Alternatively, several DRM vendors provide the necessary tools and software to generate these keys.</p>



<h3 id="how-do-we-associate-an-encryption-key-with-a-movie"><span id="How_do_we_associate_an_encryption_key_with_a_movie"></span>How do we associate an encryption key with a movie?<span></span></h3>



<p>Let’s understand the “why” first. When you go to a hotel, you ask the receptionist for the keys to a particular room by mentioning the room number – right? You’re providing the association here between a key and a room by telling her the room number.</p>



<p>Similarly, when we encrypt a movie with a particular key, we need to create that association and provide that to the DRM license server&nbsp;<em>(our receptionist, if you will)</em>.</p>



<p>In DRM, a “<strong>KeyID</strong>” provides the association between an encryption key and a movie. It is a&nbsp;<strong>unique</strong>&nbsp;string of characters generated at the time of creating an encryption key for a particular movie.</p>



<p><em>And finally,</em></p>



<h3 id="where-do-we-store-the-encryption-key--its-keyid"><span id="Where_do_we_store_the_Encryption_Key_its_KeyID"></span>Where do we store the Encryption Key &amp; its KeyID?<span></span></h3>



<p><strong>The Encryption Key and the KeyID are stored in a secure server (Key Store) that works alongside a DRM license server</strong>.</p>



<p>When a client needs to play an encrypted movie, it requests the DRM license server for the decryption key by providing that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975487</guid>
            <pubDate>Tue, 03 Nov 2020 01:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales as a Core Competency in Your Company]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24975300">thread link</a>) | @neinasaservice
<br/>
November 2, 2020 | https://21-lessons.com/sales-as-a-core-competency-in-your-company/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/sales-as-a-core-competency-in-your-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1361">
			
		<!-- .entry-media -->
	

	<div>

		<!-- .entry-header -->

		<div>
			
<p>Currently, you might not be actively selling (as in approaching leads). Or the product sells itself right now (people get in touch with you and buy).&nbsp;</p>



<p>You feel weird about cold-calling, approaching strangers about your offerings. It’s a valid concern.&nbsp;</p>



<p>When you look at your current customer base and revenues: Can you predict when you make a sale? Can you be confident if somebody will follow through with the purchase?&nbsp;</p>



<p>If you don’t have Sales People on staff, this is a challenge. Why should you care, though?</p>



<p>For starters, you might need to plan revenue for the next few months, to hire a new employee, or invest in that new project you’ve been anxious to kick off.</p>



<p>Whatever the motivation is in the end, you need to predict incoming revenue. And for that, you need to sell. As always, there are multiple approaches to this.</p>



<p>As a starting point, you can start to work off all inbound sales inquiries. Your Advantage: No cold outreach to anyone. You focus solely on incoming requests and work them off.&nbsp;</p>



<p>You increase your odds of closing deals with a well-defined sales process. A sales process helps you confidently walk a prospect through each step and increase the chance to become a paying customer.</p>



<p>It still might not allow you to increase revenue as you need it, but you can more effectively predict incoming revenue. This circumstance is already worth a lot because it provides you with a lot more financial stability.&nbsp;</p>



<p>Another circumstance should also make this process more comfortable for you: You are already selling to those who gave you permission. You are allowed to sell. These prospects got in touch with you because they need something from you. Now it’s on you to professionally handle the request and walk them through the process.</p>



<p>With this approach, you’re slowly building Sales Competency in your organization for a more stable revenue foundation.</p>

					</div><!-- .entry-content -->

		
			</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://21-lessons.com/sales-as-a-core-competency-in-your-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975300</guid>
            <pubDate>Tue, 03 Nov 2020 01:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLB hit: a podcast about systems and compilers – Episode 0: mov fp, sp]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975206">thread link</a>) | @matt_d
<br/>
November 2, 2020 | https://tlbh.it/000_mov_fp_sp.html | <a href="https://web.archive.org/web/*/https://tlbh.it/000_mov_fp_sp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<audio id="audioplayer" src="https://traffic.libsyn.com/secure/tlbhit/tlbhit0.mp3" controls="controls" preload="auto"></audio>
<h2>00:00:00 Intro</h2>
<ul>
<li>Website: <a href="https://tlbh.it/">tlbh.it</a></li>
<li>Twitter: <a href="https://twitter.com/tlbhit">@tlbhit</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/mov-fp-sp/id1538369465?i=1000496866078">This episode on Apple podcast</a></li>
<li>The stack pretty much always TLB hits!</li>
</ul>
<h2>00:00:59 Disclaimer</h2>
<ul>
<li>We're lifelong learners, only know so much!</li>
<li>Will put errata up on <a href="https://tlbh.it/">the TLB Hit website</a></li>
<li><a href="https://en.wikipedia.org/wiki/Covert_channel">"Sidechannels"</a> via Twitter</li>
</ul>
<h2>00:01:42 What's the stack?</h2>
<ul>
<li>Episode is named <code>mov fp sp</code></li>
<li><code>mov fp sp</code> in the prologue of functions</li>
<li>Epilogue has "reverse" <code>mov sp fp</code></li>
<li>Instructions that manipulate <em>the stack</em>!</li>
<li>Compiler spills values that registers can't hold onto the stack</li>
<li>Functions do it a lot -- have their own [local] state, call functions that
have their own state</li>
<li>Because subroutines can recurse without bounds would need unbounded number of
registers</li>
<li>Often different kinds of registers: arithmetic value registers, floating
point registers</li>
<li>Registers contain fairly arbitrary "stuff": pointers to data, pointers to
code, return addresses, etc.</li>
<li>Stack is <em>usually</em> contiguous and allocated on a per-thread basis</li>
<li>Idea of "GPRs": general purpose registers, though some machines have
dedicated registers for floating point values as well, or SIMD for really
wide</li>
<li>Prologue moves stack pointer to base pointer, epilogue moves base pointer
back to stack pointer, "undoing", locally manipulating the stack pointer then
rolling things back to where they previously were</li>
</ul>
<h2>00:03:50 Mechanisms in the processor</h2>
<ul>
<li>Frame pointer/base pointer (bp/fp), stack pointer (sp)</li>
<li>Usual convention is that the frame pointer doesn't change during the course
of the function's execution</li>
<li>Generated code addresses "slots" relative (at offsets from) the frame
pointer; e.g. <code>+4</code>, <code>+8</code>, etc.</li>
<li>Stack is kind of like a linked list! Pointer of the stack that says "this is
where the frame pointer <em>used to be</em> before we came into this routine".</li>
</ul>
<h2>00:05:10 Comparison to an abstract stack machine</h2>
<ul>
<li>In CS class you may learn about machines where you push two operands onto a
stack then do an add operation that consumes the top two things on the stack</li>
<li>Compare to traditional processor we use today: expanding the stack as a
single operation that makes a bunch of slots at once</li>
<li>The slots don't need to be consumed in a strictly stack-order fashion</li>
<li>Distinction of "stack machine" vs scratchpad-area style frame areas
that happen in stack-like fashion for subroutine calls</li>
</ul>
<h2>00:06:05 Some instruction set considerations</h2>
<ul>
<li>Considerations on modern machines for frequency of these operations and how
they fit in our instruction cache; e.g. on x86 <code>push</code>/<code>pop</code> are single byte
opcodes</li>
<li>On ARM we may have a "push multiple values" instruction; little CISC-y but you
do so commonly it may make some sense</li>
<li>ARMv7 had instruction allowed to push 16 registers (all GPRs) and increment
stack pointer. Yay RISC!</li>
</ul>
<h2>00:07:09 Compiler optimizations and stackiness</h2>
<ul>
<li>By moving things onto the stack -- code is constantly working with the things
in its stack frame</li>
<li>Locality, but also avoiding memory allocation subroutines (100s or 1000s of
cycle depending)</li>
<li>In scratchpad area values are tracked precisely in dataflow sort of style</li>
<li>Bring them "in" to the compiler, values becomes more trackable</li>
<li>SSA values vs arbitrary memory references</li>
<li>When structs are brought onto the stack the individual fields inside can be
broken apart and the component fields can be tracked as individual values</li>
<li>Often called "scalar replacement of aggregates" (e.g. in LLVM)</li>
<li>When we home them on the stack we can do our common optimizations, CSE, DCE;
if on the heap, may be a lot harder to to do</li>
<li>In managed languages (e.g. JavaScript, Java) would do escape analysis to show
it doesn't escape via heap to an unknown subroutine -- once placed on the
stack you can eliminate whole objects and just track sub-fields inside of it</li>
<li>Allows you to just "explode" the object itself and think about its component
fields individually and get rid of whatever doesn't matter in there</li>
</ul>
<h2>00:09:17 Eliding heap allocations in C++</h2>
<ul>
<li>Some compilers can also sometimes optimize local heap allocations, turn them
into stacky allocation</li>
<li>C++ explicitly allows you to do that as of a few years ago, Clang does that</li>
<li>If you new an object no guarantee that you're actually going to put it on the
heap / call the underlying allocator</li>
<li>Can be surprising to people -- can do SRoA, other stuff, might get rid of the
entire computation</li>
<li>Neat, unless it's not what you're trying to do</li>
<li>But seems like a key optimization to do</li>
<li>If you're thinking about things as objects instead of raw bytes having higher
level understanding you can optimize based off of is pretty key it seems?</li>
</ul>
<h2>00:10:18 Frame pointer omission</h2>
<ul>
<li>When JF started programming there was "frame pointer omission" (FPO) which
was cool because optmizers weren't as good as they are now</li>
<li>Back when you only had 8 registers for x86 the extra register could go a long
way potentially -- stack is hot in cache but doing stores and loads to memory
locations</li>
<li>Was known to some as "that flag that makes the debugger way worse" -- debug
information has to be a lot more prescriptive when you can't simply describe
where things are as an offset from a canonical (assumed unchanging) register</li>
<li>Modern CPUs doing register renaming under the hood against a much bigger
micro-architectural register set -- not as worried about saving that one
register as much of the time -- although in hot code you still might</li>
</ul>
<h2>00:11:49 "Leaf" functions</h2>
<ul>
<li>When you inline things you make bigger regions for analysis, ideally make big
fat leaf functions</li>
<li>How much of program time is generally spent in leaf functions over some set
of applications?</li>
<li>Function at the end of the call tree</li>
<li>If your subroutine doesn't call any other subroutines that's a nice property,
because now you know that everything at the end of the stack belongs to you,
you're just doing your work and popping back up to whoever called you</li>
<li>Inlining really unlocks power of leaf -- inlining into non-leaf-functions can
<em>make</em> them become the leaf</li>
<li>So long as you don't over-inline and the working set doesn't become too big
-- the compiler can know everything it does and have a good amount of work to
do</li>
<li>Small region in which you can analyze <em>everything</em>, like tiny little whole
program analysis</li>
</ul>
<h2>00:13:10 Why do we have a stack again?</h2>
<ul>
<li>Why can't we inline everything?</li>
<li>Two main issues: 1) don't necessarily know call graph for the whole program
2) recursion</li>
<li>If you knew where all the calls went (virtual/indirect/etc in your
translation unit and other ones in your program), and without recursion, you
wouldn't need a stack, you know a perfect call graph</li>
<li>For some of these you could avoid having a stack -- virtual functions but
only a few actually implementations of it, could change to test-and-branch</li>
<li>If you have a fully analyzable virtual dispatch it effectively just becomes a
switch, can potentially inline what the targets are</li>
<li>Control flow analysis takes indirect branch that can go anywhere and
enumerate the real set of possibilities (devirtualization within a
translation unit)</li>
<li>Fully analyzeable call graph is an interesting computer history topic:
FORTRAN77 classically able to do this (programs were restricted enough you
could analyze it)</li>
<li>XLA ML/array programming machine learning compiler has the same property
where the whole call graph is analyzeable so you can create a slab that's the
giant frame for the whole program you're optimizing and all allocations are
known-fixed size</li>
<li>Whole program call graph analyzeability lives on in these niche use cases!</li>
<li>In stark contrast, sometimes we need multiple different kinds of stacks at
the same time!</li>
<li>The JS engine would sometimes recur from JS calls through the VM runtime to
other JS code, and that would need to potentially create a sub-stack (!) --
multi stack problems exist beyond even just needing to analyze/manage a
single stack</li>
<li>Programming in FORTRAN is cool, for scientific code often trying to
solve a specific physics problem don't <em>usually</em> need those tools like
recursion or virtual functions</li>
<li>When everything is "monomorphized" -- you have big arrays of
fixed-value-types you can know everything about the world and really optimize
everything based off of it -- fun mode to be in for scientific computing code</li>
</ul>
<h2>00:16:34 Considerations beyond recursion and indirect calls?</h2>
<ul>
<li>Some languages use the stack for fast thread switching? Things like full
stackful coroutines?</li>
<li>Stacks in Go for example are not contiguous: more like C++ deque: linked list
of lists instead of one contiguous stack -- clever x86 code sequence that
makes it fast to find previous and next frame</li>
<li>Allows Go stacks to be distinct allocations -- each page-wise is one frame
and the next function has another frame -- can put multiple functions in one
allocation</li>
<li>Used to have really bad perf if you were in a hot loop and happened to
straddle that boundary</li>
<li>Coroutines in some languages ended up having some "stackless" stuff like
this, where the closure is heap allocated instead</li>
<li>C++ coroutines try to do away with all the heap allocations, but depends on
optimization level whether it can do that or not</li>
<li>Kind of similar for Objective-C blocks -- until recently always heap
allocated, started being stack allocated in last few years where they could</li>
<li>Language doesn't say whether stuff lives on the heap or not</li>
<li>Because stack is less constrained can live in different places, e.g. in Go</li>
<li>In some cases you remove the allocation entirely</li>
</ul>
<h2>00:18:25 Scaling to millions of threads?</h2>
<ul>
<li>If you want to be able to scale your concurrency assumptions to millions of
threads, you don't want to have huge stacks</li>
<li>Each thread has a stack, and if you have millions of threads you don't want
to be allocating too much</li>
<li>And need to be able to switch between those threads quickly</li>
<li>So raises the question: how do you usually size those stacks in the
per-thread context you have?</li>
<li>If you're doing tiny little operations; e.g. if every operation in your
program was conceptually a thread, you wouldn't want to allocate 512KiB every
time you did a tiny atomic operation</li>
</ul>
<h2>00:19:10 Managed languages putting frames on the heap</h2>
<ul>
<li>On the term "stackless": one of the <a href="https://greenlet.readthedocs.io/en/latest/">Python
"greenlet"</a> ("lightweight thread"
terminology) attempts was called <a href="https://github.com/stackless-dev/stackless/wiki">Stackless
Python</a></li>
<li>In managed languages like Python the frames can be allocated …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tlbh.it/000_mov_fp_sp.html">https://tlbh.it/000_mov_fp_sp.html</a></em></p>]]>
            </description>
            <link>https://tlbh.it/000_mov_fp_sp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975206</guid>
            <pubDate>Tue, 03 Nov 2020 00:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaving OCaml]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 172 (<a href="https://news.ycombinator.com/item?id=24974907">thread link</a>) | @rbanffy
<br/>
November 2, 2020 | https://blog.darklang.com/leaving-ocaml/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/leaving-ocaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/skeleton-camel.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/skeleton-camel.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/skeleton-camel.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg" alt="Leaving OCaml">
            </figure>

            <section>
                <div>
                    <p><em>Part of a 3 part series. Followups on <a href="https://blog.darklang.com/new-backend-fsharp/">F#</a>, <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Rust</a></em></p><p>I built the first demo of Dark in Python, in about two weeks. A few months later when I started productizing it, I rebuilt it in OCaml. Back in 2017, when I was considering the language and platform to use for Dark, OCaml was extremely compelling:</p><ul><li>it's a high-level language with static types, so easy to make large scale changes as we figure out what the language/product was</li><li>you mostly model data with sum types, which in my mind are the best way to model data</li><li>it's very similar to the language I wanted to build (in particular, we could reuse built-in immutable data structures for Dark's values)</li><li>it had a reputation for being high-performance, which meant that we could write an interpreter for Dark and not have it be terribly slow (vs writing an interpreter in python, which might be too slow)</li></ul><p>Unfortunately, as we've built Dark we've run into significant problems that have made it challenging to build in OCaml.</p><h2 id="lack-of-libraries">Lack of libraries</h2><p>When you bet on an off-mainstream language, one of the things you accept is that many libraries are not going to be available. When there is a small community, often there aren't enough people working in the language to make important libraries. This is especially true if few people are building business applications.</p><p>In OCaml there are many high quality libraries, especially for data structures and data manipulation. The annual<a href="https://opensource.janestreet.com/core/"> Jane Street code dump</a> has been quite useful and very high quality. However, we really felt the lack of several libraries. The most obvious of these is that we had to build a <a href="https://github.com/darklang/dark/blob/main/backend/libexecution/unicode_string.mli">Unicode string library</a> ourselves (built on top of the <a href="https://erratique.ch/software/uuseg">very impressive OCaml Unicode libraries</a> built by <a href="https://erratique.ch/contact.en">Daniel Bünzli</a>), but we needed many more libraries than that.</p><p>The lack of an SDK for Google Cloud has affected us greatly. When you're searching for product-market fit, you do the simplest, easiest thing. If you lack a good SDK for your cloud provider, the simplest, easiest thing is often a terrible architectural choice. We've built our own queue on top of our database rather than using the production-quality cloud queues available on GCP. Similarly, we barely use the Cloud Storage (GCP's version of S3), because we initially put things in the database <a href="https://blog.darklang.com/evolving-darks-tracing-system/">because it was easier</a>. We've built 3 services, 2 <a href="https://github.com/darklang/dark/tree/main/containers/stroller">in</a> <a href="https://github.com/darklang/dark/tree/main/containers/queue-scheduler">Rust</a>, and 1 in <a href="https://github.com/darklang/dark/tree/main/containers/postgres-honeytail">Go</a>, to workaround the challenges we've faced.</p><p>The biggest challenge here is our use of Postgres. Postgres is a great database and we're big fans, but Cloud SQL is not a great hosted database. GCP's position is that Cloud SQL is there to tick a box and we should be using Cloud Spanner. I would love to switch to Cloud Spanner, but we have no driver for it in OCaml. Given the Postgres driver in OCaml is not particularly mature, it's hard to expect that a Cloud Spanner driver would exist, and indeed it doesn't. We've had to contribute to the <a href="https://github.com/mmottl/postgresql-ocaml/commit/81a4ae5240decd8f483a90568257cfbc1558c7ed">OCaml Postgres driver</a>, and some parts of our codebase have been <a href="https://github.com/darklang/dark/blob/main/backend/libbackend/serialize.ml#L226">well and truly mangled</a> when working around features not supported in that driver.</p><p>We've also suffered from a lack of a high-level, production web stack (there are <a href="https://github.com/anmonteiro/ocaml-h2">low-level stacks with good reputations</a> that I've struggled to use, and a <a href="https://github.com/oxidizing/sihl">few</a> <a href="https://github.com/reason-native-web/morph">new</a> ones out there that look good), in particular lacking a user authentication module. We've been using <a href="https://auth0.com/">Auth0</a> to work around this for now, which has more moving pieces than I'd like, and a shockingly high cost (our 7000 users, most of whom never log in, costs us over $500/mo).</p><p>We've worked around other missing vendor SDKs by calling their HTTP endpoints directly and that's been mostly fine. However, for libraries like encryption we don't have that option - we <a href="https://github.com/darklang/dark/pull/1455/files">hacked around a missing encryption library</a>, but decided not to ship it to production until we audited it for security (which was never actually worth the cost).</p><p>At CircleCI, we bet on Clojure. That was also a non-mainstream language, but its ability to call Java SDKs meant we had a mature cloud library, which was essential for building CircleCI. Of course, in OCaml we could call C libraries (and <a href="https://github.com/darklang/dark/pull/1841">even Rust libraries</a>, perhaps), but it doesn't match having native libraries we can call directly.</p><h2 id="learnability">Learnability</h2><p>I'm mostly in the camp that anyone can learn any language, but I saw a team struggle with OCaml, and for good reason. Language tutorials are extremely poor in OCaml compared to other languages; they're mostly lecture notes from academic courses.</p><p>The compiler isn't particularly helpful, certainly compared to Rust or Elm (both of which have been in our stack at one point). Often it gives no information about an error. Syntax errors typically say "Syntax error"; though it will try to give a good error for a mismatched brace, often incorrectly. Type errors can be a real burden to read, even after 3 years of experience with it.</p><p>The docs in OCaml are often challenging to find. The <a href="https://ocaml.janestreet.com/ocaml-core/latest/doc/base/index.html">Jane Street docs</a> have improved significantly in the last few years, but it can be a challenge to even figure out what functions are available in a particular module for most libraries. Compare to the excellent <a href="https://docs.rs/">docs.rs</a> in Rust, which has comprehensive API docs for every package in Rust.</p><p>One of the ways I personally struggled in OCaml is around <code>Lwt</code>. Lwt is (one of!) OCaml's async implementations. I couldn't figure it out several years ago and so just built a single-threaded server. The amount of workarounds and downtime we've suffered from that single decision is immense. A tutorial around building high-performance (or even medium performance!) web servers would be very valuable. </p><p>Tooling is something I read would be good in OCaml. I remember reading there was a debugger that could go back in time! I don't know where that's gone but I've never heard of anyone using it.</p><p>We have struggled to make editor tooling work for us. This is partially because we also use ReasonML and this seems to break things. Unfortunately, this is common in programming, but even more so in small communities: you might be the first person to ever try to use a particular configuration.</p><p>Finally, the disconnect between the various tools is immense. You need to understand Opam, Dune, and Esy, to be able to get something working (you could also do it without Esy and just rely on Opam, but that's much worse). I talked about a bunch of these challenges <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">here</a>.</p><h2 id="language-problems">Language problems</h2><p>Multicore is coming Any Day Now™️, and while this wasn't a huge deal for us, it was annoying. </p><h2 id="minor-annoyances">Minor annoyances</h2><p>One of my biggest annoyances was how often OCaml folks talk about Fancy Type System problems, instead of how to actually build products and applications. In other communities for similar languages (ReasonML, Elm, F#), people talk about building apps and solving their problems. In OCaml, it feels like people spend an awful lot of time discussing Functors. It's not quite at the level that I perceived in the Haskell world, but it pointed out that the people building the core of the ecosystem do not have the same problems that I do (which is building web-y stuff).</p><p>I honestly think OCaml was a great choice at the start. Being able to quickly and safely make large-scale changes to your app is something that staticly-typed functional languages excel at. I'm happy that we made the choice, and in retrospect, it still seems like the best choice of those we had at the time.</p><p>I'm working on building the next version of the backend. We have about 20k lines to be replaced, and they'll be rewritten in a new language while keeping the semantics the same. I plan to leave keep the frontend in ReasonML: it doesn't suffer from the same library problems as it can interface nicely to JS, and it's nearly 50k lines of code so it would be a much bigger undertaking.</p><p>Read <a href="https://blog.darklang.com/new-backend-fsharp/">the followup</a> to see what we picked!</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/leaving-ocaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974907</guid>
            <pubDate>Tue, 03 Nov 2020 00:03:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Catch Breaking Changes by Watching API Traffic]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24974022">thread link</a>) | @jeanyang
<br/>
November 2, 2020 | https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f9f5e25ff6048551e680216" data-item-id="5f9f5e25ff6048551e680216">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1604279881824" id="item-5f9f5e25ff6048551e680216"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_142490"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604280685685-ZWFH7IB18XTYKDSWZNJW/ke17ZwdGBToddI8pDm48kAx-7VAVUrX83-TmKtI9GwFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzjxOd1QqWVSDMmGb_7RWR-xbrRIPXdQRvPw48mQHlcKeFmwpAiuBpxGlYDuvh8_jg/dog_washing_car.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604280685685-ZWFH7IB18XTYKDSWZNJW/ke17ZwdGBToddI8pDm48kAx-7VAVUrX83-TmKtI9GwFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzjxOd1QqWVSDMmGb_7RWR-xbrRIPXdQRvPw48mQHlcKeFmwpAiuBpxGlYDuvh8_jg/dog_washing_car.gif" data-image-dimensions="500x260" data-image-focal-point="0.5,0.5" alt="dog_washing_car.gif" data-load="false" data-image-id="5f9f6168ff6048551e687727" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-a2c285e8aefcd417da69"><div><p>As modern web apps shift to service-oriented architectures, it’s been getting more and more difficult to catch bugs before production. Because it’s hard to simulate production workloads beforehand, functionality that depends on service-service interactions often doesn’t get fully exercised until production. The result is that bugs don’t get uncovered until they are triggered by live user traffic.</p><p>As a developer who has also worked in devops, I understand the importance of finding and fixing bugs early in the development cycle. This is one of the reasons I’m excited to be working on change management at Akita. A few weeks ago, our team published a <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior">blog post talking about this at a high level</a>. In this blog post, I’m going to go into the nuts and bolts. I’ll show a bug that’s hard to catch with source diffs, linters, or static analysis. Then I’ll show how to use Akita to catch this bug, describing the entire setup from start to finish. Finally, I’ll explain how Akita works under the hood.</p><div><p>Something I’m particularly proud of about Akita is that you can use us without needing to proxy or to make any code changes—and we’ve been working hard so you can set up everything you need to catch breaking changes in just minutes. <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_11_2_howto">Try out our private beta</a> to see for yourself!</p></div><h2>🕵🏻‍♀️ A particularly sneaky bug</h2><p><em>You can find the Go source code for this example on </em><a href="https://github.com/akitasoftware/akita-change-management-demo"><em>GitHub here</em></a><em>.</em></p><p>Let’s say you’re working on an API that returns information about users. To comply with regulations, you omit user phone numbers from the response to prevent callers of your API from storing this information in a scattered fashion that makes it hard to service deletion requests.&nbsp;</p><p>For example, your API might look like:&nbsp;</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_65920"><div><!-- HTML generated using hilite.me --><div><pre><span>type</span> <span>User</span> <span>struct</span> <span>{</span>
  <span>ID</span> <span>string</span> <span>`json:”id”`</span>

  <span>// Don’t return phone number for regulation reasons!</span>
  <span>Phone</span> <span>string</span> <span>`json:”-”`</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>...</span>
  <span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/users/json"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
    <span>w</span><span>.</span><span>Header</span><span>().</span><span>Set</span><span>(</span><span>"Content-Type"</span><span>,</span> <span>"application/json"</span><span>)</span>
    <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>200</span><span>)</span>
    <span>enc</span> <span>:=</span> <span>json</span><span>.</span><span>NewEncoder</span><span>(</span><span>w</span><span>)</span>
    <span>enc</span><span>.</span><span>Encode</span><span>(</span><span>myUsers</span><span>)</span>
  <span>})</span>
  <span>...</span>
<span>}</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_65988"><p>Testing your endpoint shows that phone numbers are omitted as expected:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_70908"><div><!-- HTML generated using hilite.me --><div><pre><span>$</span> curl localhost:8080/users/json
<span>[{"id":"usr_295oDMFK8b1yS5dwlSTdgP"},{"id":"usr_6NiejyYEVpWfziUXJgovV6"}]</span>
</pre></div>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_70976"><p>One day, your colleague Aki adds a new version of the endpoint that returns YAML instead of JSON because they want to introduce some competition in the data serialization market.&nbsp; A very reasonable implementation of the YAML endpoint produces a PR <a href="https://github.com/akitasoftware/akita-change-management-demo/pull/4/files">like this</a>:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_76302"><div><!-- HTML generated using hilite.me --><div><pre>  <span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/users/yaml"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
    <span>w</span><span>.</span><span>Header</span><span>().</span><span>Set</span><span>(</span><span>"Content-Type"</span><span>,</span> <span>"application/x-yaml"</span><span>)</span>
    <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>200</span><span>)</span>
    <span>enc</span> <span>:=</span> <span>yaml</span><span>.</span><span>NewEncoder</span><span>(</span><span>w</span><span>)</span>
    <span>defer</span> <span>enc</span><span>.</span><span>Close</span><span>()</span>
    <span>enc</span><span>.</span><span>Encode</span><span>(</span><span>myUsers</span><span>)</span>
  <span>})</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_76370"><p>A code reviewer without insider knowledge is very likely to gloss over the fact that yaml.Encode(…) does something different than json.Encode. However, when someone actually uses this new endpoint, they get now users’ phone numbers in the response! 🙊</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_121010"><div><!-- HTML generated using hilite.me --><div><pre><span>$</span> curl localhost:8080/users/yaml
<span>- id: usr_295oDMFK8b1yS5dwlSTdgP</span>
<span>  phone: (123) 456-7890</span>
<span>- id: usr_6NiejyYEVpWfziUXJgovV6</span>
<span>  phone: (777) 888-9999</span>
</pre></div>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_121078"><div><p>It turns out that Aki forgot to add the YAML-specific struct tags to the User struct to omit phone numbers from serialization—and now your phone numbers are getting sent somewhere they’re not supposed to go! You don’t realize this until your security team alerts you that they detected this issue in production. By this time, you have to not only roll back the change, but also scrub logs and send out an apology to your users.</p><p>This was a particularly subtle bug because it’s very easy to miss by just looking at source diffs This is also something that linters and static analyses won’t be particularly helpful with, unless you’ve configured them with a rule for this exact change.</p><p>Akita’s change management would catch this by detecting a new data format:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_168191"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281011519-982FLZI37TQL9FETVZCA/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281011519-982FLZI37TQL9FETVZCA/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image-dimensions="928x520" data-image-focal-point="0.5,0.5" alt="Pull Request highlighted.png" data-load="false" data-image-id="5f9f62b30991472cc53a4cee" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281011519-982FLZI37TQL9FETVZCA/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_168490"><div><div><p>We’ll dig into this comment after we show you how to set this up for yourself. And this data leak is just one of <em>many</em> kinds of bugs that are hard to catch pre-production, but that you can catch if you have a better model of how your service is interacting with other services.</p></div><h2>⚡️ Setting up Akita to fix this bug</h2><p>To stop these bugs once and for all, we will show how to add Akita to your CI/CD pipeline, so that you get notified how every pull request changes our API. For our particular deployment, we are using CircleCI and GitHub to run Akita. You can easily modify the instructions for your CI/CD pipeline of choice.</p><p>The steps for getting up and running are:</p><ol data-rte-list="default"><li><p>Create a new service in Akita, if you don’t have one already.</p></li><li><p>Connect Akita to GitHub.</p></li><li><p>Update your CircleCI configuration.</p></li><li><p>Open a pull request with an API change.</p></li></ol><p>The first thing we need to do is head over to the Akita Console and create a new Akita service. You can do that by clicking on the “New Service” button on the left-hand menu. If you already have a service, you can skip this step.</p><p>Once we’ve created and named our new service, we need to connect Akita to Github. To do this, simply click on the “Integrations” menu and then “Integrate” under GitHub. This will take us to GitHub where we can give Akita permission to watch our pull requests.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_215681"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281630496-C2E9J66LNQ0NPLZVPV3K/ke17ZwdGBToddI8pDm48kLHWjF32f0_zzQbqWTWhXQMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dgxIn2RMiOtJF70cDEvBvW_7FUHZBSRsPBe9uEPsGX4HCjLISwBs8eEdxAxTptZAUg/dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604281630496-C2E9J66LNQ0NPLZVPV3K/ke17ZwdGBToddI8pDm48kLHWjF32f0_zzQbqWTWhXQMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dgxIn2RMiOtJF70cDEvBvW_7FUHZBSRsPBe9uEPsGX4HCjLISwBs8eEdxAxTptZAUg/dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png" data-image-dimensions="1556x645" data-image-focal-point="0.5,0.5" alt="dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png" data-load="false" data-image-id="5f9f651e5578154aa88f5d4b" data-type="image" src="https://www.akitasoftware.com/blog/2020/11/1/dd9e60a-Screen_Shot_2020-09-18_at_12.19.09_PM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_215980"><div><p>Now that Akita can post to our GitHub projects, we need to complete the loop by adding Akita to our CI Pipeline. This is relatively straightforward: we just need to add a step to start the Akita Client and another one that stops the client after our tests have completed.</p><p>The code to start our client is pretty simple:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_229396"><div><!-- HTML generated using hilite.me --><div><pre>  <span>-</span> <span>run</span><span>:</span>
    <span>name</span><span>:</span> <span>Start Akita Client</span>
    <span>command</span><span>:</span> <span>|</span>
      <span>docker run --rm -d \</span>
        <span>--env CI="${CI}" \</span>
        <span>--env CIRCLECI="${CIRCLECI}" \</span>
        <span>--env CIRCLE_REPOSITORY_URL="${CIRCLE_REPOSITORY_URL}" \</span>
        <span>--env CIRCLE_BRANCH="${CIRCLE_BRANCH}" \</span>
        <span>--env CIRCLE_SHA1="${CIRCLE_SHA1}" \</span>
        <span>--env CIRCLE_PULL_REQUEST="${CIRCLE_PULL_REQUEST}" \</span>
        <span>--env CIRCLE_BUILD_URL="${CIRCLE_BUILD_URL}" \</span>
        <span>--env AKITA_API_KEY_ID=${AKITA_API_KEY_ID} \</span>
        <span>--env AKITA_API_KEY_SECRET=${AKITA_API_KEY_SECRET} \</span>
        <span>--network=host \</span>
        <span>--name akita \</span>
        <span>akitasoftware/cli:latest learn \</span>
        <span>--service [YOUR SERVICE NAME HERE] \</span>
        <span>--port [YOUR SERVICE PORT HERE]</span>
    <span>background</span><span>:</span> <span>true</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_229464"><p>Then after you have run your integration test, simply add another step to stop the Akita Client, like this:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1604279471234_232955"><div><!-- HTML generated using hilite.me --><div><pre>  <span>-</span> <span>run</span><span>:</span>
    <span>name</span><span>:</span> <span>Stop Akita SuperLearn</span>
    <span>command</span><span>:</span> <span>docker kill --signal=SIGINT akita</span>
</pre></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_233023"><div><p>You can see a complete example of our CircleCI configuration <a href="https://github.com/akitasoftware/akita-change-management-demo/blob/master/.circleci/config.yml">here</a>.</p><p>Once you have merged in the CircleCI changes, you can now test things out by making a quick change to your codebase, commit the change and open a new pull request. If everything went according to plan, once your pipeline completes Akita will leave a comment detailing how your API has changed.</p><p>Below is the comment for the example we introduced in the last section.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604279471234_316511"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604283574162-FYJ8ODPDUEAIMJQSS72L/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604283574162-FYJ8ODPDUEAIMJQSS72L/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png" data-image-dimensions="928x520" data-image-focal-point="0.5,0.5" alt="Pull Request highlighted.png" data-load="false" data-image-id="5f9f6cb542433c0d822d70a4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1604283574162-FYJ8ODPDUEAIMJQSS72L/ke17ZwdGBToddI8pDm48kOfhBKcXkUJv4Y40JSZTrS1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIR2LMERMdn0vLCunBE33AJTKh9E5k17qCDnCsKwVXj_c/Pull+Request+highlighted.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_316810"><div><p>In this comment you can see:</p><ul data-rte-list="default"><li><p><strong>Endpoints Added by this pull request. </strong>In this case, we added the YAML endpoint.</p></li><li><p><strong>Endpoints Changed by this pull request. </strong>As we expected, we modified the JSON endpoint.</p></li><li><p><strong>Data Formats Added by this pull request. </strong>This is where the new US phone number data type appears. Akita <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">automatically detects precise data formats</a> to make this as useful as possible.</p></li><li><p>﻿<strong>The Baseline Specification that was used for this comparison.</strong> Akita gives you the flexibility to compare against any other test or production spec, so we also show what spec we diffed against.</p></li></ul><h2>🌎 Akita across test and production</h2><p>Now that you’ve supercharged your pull requests with Akita, you’re probably saying to yourself “This is great for testing, but what if my tests don’t cover everything you’d see in production?”&nbsp;</p><p>Good news: Akita also allows you to compare test behavior against actual production behavior. To do this, you can use the same start and stop learning commands from your CI in your production environment to create a model of your production behavior. To use it as a baseline for pull requests comparisons, simply mark the production spec as stable in the Akita Console.</p><div><p>Talk to us if this is something you’re interested in!</p></div><h2>🔩 Akita nuts and bolts</h2><p>Under the hood, Akita works by building models of API behavior by watching API traffic.</p><p>What I just showed you works by:</p><ol data-rte-list="default"><li><p><strong>Reconstructing HTTP requests/responses from live packet captures. </strong>No code changes or proxies. And we only send metadata back to the Akita cloud!</p></li><li><p><strong>Building models of your API behavior.</strong> Expressed in the form of an API spec, annotated with <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">data formats</a> and eventually, implicit API contracts.</p></li><li><p><strong>Diffing on API behavior.</strong> Once we have the API models, it’s straightforward to diff.</p></li></ol></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604279471234_374356"><div><div><p>And this doesn’t just have to be traffic that already exists in your environments. More on running Akita with automatically generated traffic in future blog posts!</p></div><h2>🐕 Try Akita for yourself!</h2><p>Akita is currently available in a private beta. And I’m working hard every day to help you catch problematic changes more easily. <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_11_2_howto">Sign up here</a> to try it out!</p></div></div></div></div></div>

    

    

    <section id="comments-5f9f5e25ff6048551e680216">
      
  


    </section>

  </article>





  <nav>

    

    
      <a href="https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion">
        <div>
          <p>Next</p>
      …</div></a></nav></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita">https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita</a></em></p>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/11/1/how-to-catch-breaking-changes-using-akita</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974022</guid>
            <pubDate>Mon, 02 Nov 2020 22:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DKIM: Show Your Privates]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24972609">thread link</a>) | @ryan-c
<br/>
November 2, 2020 | https://rya.nc/dkim-privates.html | <a href="https://web.archive.org/web/*/https://rya.nc/dkim-privates.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"> <p>If you’re like most people, there’s a good chance that it’s been years since you’ve sent an email that wasn’t cryptographically signed. You don’t use PGP, you say? Well, even if <em>you</em> are not signing your email, your provider is almost certainly doing it for you. Plausible deniability has been tossed aside in the name of stopping spam, but it doesn’t have to be.</p> <p><span data-title="DomainKeys Identified Mail"><abbr title="DomainKeys Identified Mail">DKIM</abbr></span>, originally standardized in 2007 by <a href="http://tools.ietf.org/html/rfc4871.html">RFC 4871</a>, now has near universal<a href="#id4" id="id1">[1]</a> adoption. To quote the RFC, the goal behind the protocol is to “permit a signing domain to assert responsibility for a message, thus protecting message signer identity and the integrity of the messages they convey”. It’s one of several technologies used prevent the sender identity information in email from being spoofed<a href="#id5" id="id2">[2]</a>. Anti-spam systems use it to help determine whether to consider the reputation of a domain name when making a processing decision.</p> <p>While <abbr title="DomainKeys Identified Mail">DKIM</abbr> was designed to be useful for spam prevention, the cryptographic signatures it uses have quietly made a property called “<a href="https://en.wikipedia.org/wiki/Non-repudiation">non-repudiation</a>” the new normal for email. The term is used in in contract law — for example if someone claims “that’s not my signature”, they could be said to be “repudiating” the authenticity of the document. In the case of email, the impact is that if you have a copy of an email in its original format including full headers (for example, an email spool dump) you can check the signature. The extent to which this is a reliable means of verification varies depending on the circumstances — keys short enough to be cracked used to be common, and in some cases straight-up theft of the private keys is plausible.</p> <p>Meanwhile, secure messaging tools like <a href="https://en.wikipedia.org/wiki/Off-the-Record_Messaging">OTR</a> and its successors have taken the approach of explicitly providing “deniable encryption”. The <a href="https://signal.org/blog/simplifying-otr-deniability/#potential-simplifications-and-improvements">state of the art</a> allows a sender, given a recipient’s public key, to craft a fake transcript apparently between the two of them that will pass cryptographic checks. This is generally fine for users of these apps because they know what they said. To the best of my knowledge, there is nowhere this creates a legal “get out of jail free” card. All it really does is ensure the users of these tools aren’t <em>reducing</em> their deniability by using the tool. This is an issue where <abbr title="DomainKeys Identified Mail">DKIM</abbr> really fails its users, and I’m apparently not the only one that feels this way.</p> <blockquote> <p>Apropos of nothing, I really wish Gmail would start publishing its expired DKIM secret keys.</p> <p>—<a href="https://twitter.com/matthew_d_green/status/1323011619069321216">Matthew Green</a></p> </blockquote> <p>A little over three years ago, I started doing exactly that for my domain. Since then, I’ve had a <a href="https://gist.github.com/ryancdotorg/a8f565b9e4f0902eb7b5cd4cdefeea0f">key rotation script</a> running every day, generating a new key and adding the appropriate record (called a “selector”).</p> <div><pre><span></span><code>20170829-<wbr>b29b2444f764c222c3faf5c.<wbr>_domainkey.<wbr>ryanc.<wbr>org.<wbr> 5 <wbr>IN <wbr>TXT <wbr>"<wbr>v=<wbr>DKIM1;<wbr>t=<wbr>s;<wbr>h=<wbr>sha256;<wbr>p=<wbr>MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDkOSIRW7R8a3e0J0lZqbBJSpHJYPk043/<wbr>OB3lcT2apKtnu7MLjIRqUAgRyYSVAGC10ID2Qlxmy1Ji3EBRB1qI2IsNKgC2C4qzGxx54ShpVR/<wbr>8yY9Qy1eyNtTF5Y/<wbr>XSoLWoRVO1oly+<wbr>WL+<wbr>4O2TRuyujEwoZcFUwXzuuuqJtzbI17wIDAQAB"<wbr>
</code></pre></div> <p>Each selector remains live for seven days, then is “revoked” by publishing an update blanking the public key portion of the record.</p> <div><pre><span></span><code>20170829-<wbr>b29b2444f764c222c3faf5c.<wbr>_domainkey.<wbr>ryanc.<wbr>org.<wbr> 5 <wbr>IN <wbr>TXT <wbr>"<wbr>v=<wbr>DKIM1;<wbr>t=<wbr>s;<wbr>p=<wbr>"<wbr>
</code></pre></div> <p>Once another three days pass, the minimal set of <a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)">RSA</a> parameters needed to recreate the public and private keys are published in the selector’s “notes” field.</p> <div><pre><span></span><code>20170829-<wbr>b29b2444f764c222c3faf5c.<wbr>_domainkey.<wbr>ryanc.<wbr>org.<wbr> 5 <wbr>IN <wbr>TXT <wbr>"<wbr>v=<wbr>DKIM1;<wbr>t=<wbr>s;<wbr>p=<wbr>;<wbr>n=<wbr>e:<wbr>AQAB,<wbr>p:<wbr>6o/<wbr>8upWykC5USot9Q2o5M89EO1qA7J/<wbr>ao/<wbr>FPc2TUJKat+<wbr>z4JXde2HWW/<wbr>8D3LJR4hGwSpgwLMq9drTzdjbzFTkQ=<wbr>=<wbr>,<wbr>q:<wbr>+<wbr>RTTux+<wbr>yMx0LPyXDkAQiEBcOt8xYrr60s1sXO/<wbr>5nQSQSZBlLtRJKHQpz65MnIxlOCB+<wbr>1umqLW8q78hHC3Asxfw=<wbr>=<wbr>"<wbr>
</code></pre></div> <p>The format here is non-standard, as a full RSA private key with all of the redundant data it includes would exceed the 255 character limit for strings stored in DNS<a href="#id6" id="id3">[3]</a>. A small Python script is enough to reconstitute everything, though.</p> <table><thead><tr><th colspan="2"><a href="https://rya.nc/dkim-privates_/attach/dkim-private.py" download="">dkim-private.py</a></th></tr></thead><tbody><tr><td unselectable="on">1</td><td> <code><span>import</span> <span>gmpy2</span><span>,</span> <span>sys</span><span>,</span> <span>dns.resolver</span></code> </td></tr><tr><td unselectable="on">2</td><td> <code><span>from</span> <span>Cryptodome.PublicKey</span> <span>import</span> <span>RSA</span></code> </td></tr><tr><td unselectable="on">3</td><td> <code><span>from</span> <span>base64</span> <span>import</span> <span>b64decode</span> <span>as</span> <span>b64d</span></code> </td></tr><tr><td unselectable="on">4</td><td> <code></code> </td></tr><tr><td unselectable="on">5</td><td> <code><span>def</span> <span>decode_dkim_private</span><span>(</span><span>txt</span><span>):</span></code> </td></tr><tr><td unselectable="on">6</td><td> <code>    <span>params</span> <span>=</span> <span>dict</span><span>()</span></code> </td></tr><tr><td unselectable="on">7</td><td> <code>    <span># Parse the DKIM selector record.</span></code> </td></tr><tr><td unselectable="on">8</td><td> <code>    <span>for</span> <span>key</span><span>,</span> <span>_</span><span>,</span> <span>val</span> <span>in</span> <span>map</span><span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>.</span><span>partition</span><span>(</span><span>'='</span><span>),</span> <span>txt</span><span>.</span><span>split</span><span>(</span><span>';'</span><span>)):</span></code> </td></tr><tr><td unselectable="on">9</td><td> <code>        <span>if</span> <span>key</span> <span>==</span> <span>'n'</span><span>:</span></code> </td></tr><tr><td unselectable="on">10</td><td> <code>            <span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>map</span><span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>.</span><span>split</span><span>(</span><span>':'</span><span>),</span> <span>val</span><span>.</span><span>split</span><span>(</span><span>','</span><span>)):</span></code> </td></tr><tr><td unselectable="on">11</td><td> <code>                <span>params</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>int</span><span>.</span><span>from_bytes</span><span>(</span><span>b64d</span><span>(</span><span>v</span><span>),</span> <span>'big'</span><span>)</span></code> </td></tr><tr><td unselectable="on">12</td><td> <code>    <span># Compute rest of RSA keypair parameters (if possible).</span></code> </td></tr><tr><td unselectable="on">13</td><td> <code>    <span>if</span> <span>all</span> <span>(</span><span>k</span> <span>in</span> <span>params</span> <span>for</span> <span>k</span> <span>in</span> <span>(</span><span>'e'</span><span>,</span> <span>'p'</span><span>,</span> <span>'q'</span><span>)):</span></code> </td></tr><tr><td unselectable="on">14</td><td> <code>        <span>params</span><span>[</span><span>'n'</span><span>]</span> <span>=</span> <span>params</span><span>[</span><span>'p'</span><span>]</span> <span>*</span> <span>params</span><span>[</span><span>'q'</span><span>]</span></code> </td></tr><tr><td unselectable="on">15</td><td> <code>        <span>phi</span> <span>=</span> <span>(</span><span>params</span><span>[</span><span>'p'</span><span>]</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>(</span><span>params</span><span>[</span><span>'q'</span><span>]</span> <span>-</span> <span>1</span><span>)</span></code> </td></tr><tr><td unselectable="on">16</td><td> <code>        <span>params</span><span>[</span><span>'d'</span><span>]</span> <span>=</span> <span>int</span><span>(</span><span>gmpy2</span><span>.</span><span>invert</span><span>(</span><span>params</span><span>[</span><span>'e'</span><span>],</span> <span>phi</span><span>))</span></code> </td></tr><tr><td unselectable="on">17</td><td> <code>        <span>rsa</span> <span>=</span> <span>map</span><span>(</span><span>lambda</span> <span>x</span><span>:</span> <span>params</span><span>[</span><span>x</span><span>],</span> <span>'nedpq'</span><span>)</span></code> </td></tr><tr><td unselectable="on">18</td><td> <code>        <span>return</span> <span>RSA</span><span>.</span><span>construct</span><span>(</span><span>tuple</span><span>(</span><span>rsa</span><span>))</span></code> </td></tr><tr><td unselectable="on">19</td><td> <code>    <span>else</span><span>:</span></code> </td></tr><tr><td unselectable="on">20</td><td> <code>        <span>return</span> <span>None</span></code> </td></tr><tr><td unselectable="on">21</td><td> <code></code> </td></tr><tr><td unselectable="on">22</td><td> <code><span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span> <span>and</span> <span>len</span><span>(</span><span>sys</span><span>.</span><span>argv</span><span>)</span> <span>==</span> <span>3</span><span>:</span></code> </td></tr><tr><td unselectable="on">23</td><td> <code>    <span>domain</span> <span>=</span> <span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]</span></code> </td></tr><tr><td unselectable="on">24</td><td> <code>    <span>selector</span> <span>=</span> <span>sys</span><span>.</span><span>argv</span><span>[</span><span>2</span><span>]</span></code> </td></tr><tr><td unselectable="on">25</td><td> <code>    <span>for</span> <span>answer</span> <span>in</span> <span>dns</span><span>.</span><span>resolver</span><span>.</span><span>query</span><span>(</span><span>selector</span> <span>+</span> <span>'._domainkey.'</span> <span>+</span> <span>domain</span><span>,</span> <span>'TXT'</span><span>):</span></code> </td></tr><tr><td unselectable="on">26</td><td> <code>        <span>txt</span> <span>=</span> <span>str</span><span>(</span><span>answer</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>'"'</span><span>)</span></code> </td></tr><tr><td unselectable="on">27</td><td> <code>        <span>print</span><span>(</span><span>decode_dkim_private</span><span>(</span><span>txt</span><span>)</span><span>.</span><span>exportKey</span><span>()</span><span>.</span><span>decode</span><span>())</span></code> </td></tr></tbody></table><p>An example run:</p> <div><pre><span></span><code><span>$</span> ./dkim-private.py <span>'ryanc.org'</span> <span>'20170829-b29b2444f764c222c3faf5c'</span>
<span>-----BEGIN RSA PRIVATE KEY-----</span>
<span>MIICXQIBAAKBgQDkOSIRW7R8a3e0J0lZqbBJSpHJYPk043/OB3lcT2apKtnu7MLj</span>
<span>IRqUAgRyYSVAGC10ID2Qlxmy1Ji3EBRB1qI2IsNKgC2C4qzGxx54ShpVR/8yY9Qy</span>
<span>1eyNtTF5Y/XSoLWoRVO1oly+WL+4O2TRuyujEwoZcFUwXzuuuqJtzbI17wIDAQAB</span>
<span>AoGBAKClArD7PzExKGJcIQqHIjqEzdfVdbVfyc+JfUiX72h2bE78wzXDUIUMYnrs</span>
<span>nJ7gJeaO5ycG5ST29sQtAkVRwn1KTLaU9fYmGpbkKyOWWfmztppZIvwi9l4tU5h2</span>
<span>GJVw+HbhcWO6tYbTqR9Bc8IelXyVibwmJwImr0AoD8sBLryhAkEA6o/8upWykC5U</span>
<span>Sot9Q2o5M89EO1qA7J/ao/FPc2TUJKat+z4JXde2HWW/8D3LJR4hGwSpgwLMq9dr</span>
<span>TzdjbzFTkQJBAPkU07sfsjMdCz8lw5AEIhAXDrfMWK6+tLNbFzv+Z0EkEmQZS7US</span>
<span>Sh0Kc+uTJyMZTggftbpqi1vKu/IRwtwLMX8CQFT/ABGMlTvxzdGFYkq/fyLrBEqN</span>
<span>rRIRiuTFWIj0DHuLepgEDtjWhcN5T2f6vFYi6NQliFdU+F18ngICjCGKukECQHse</span>
<span>ClIyJpkRQB/kgLfM8zFU1FeRUDx/0z3cRq3G4C7Yr6Z+wmcsNSoJoqbMw8mblnB5</span>
<span>jBAq3dtvaFsM4G53se0CQQC9ocR9eQdXvq5ibwZAmgYcMLEaq7NeX//l6zdxLd52</span>
<span>NcVcuaAUzf5KdTRwA9gJ4Qdzwntc+UB2ElpI2AOj7AFV</span>
<span>-----END RSA PRIVATE KEY-----</span>
</code></pre></div> <p>When I originally set this up, I was a bit concerned that I’d run into issues with filtering systems trying to validate my sent emails significantly after delivery. Per the RFC:</p> <blockquote> A signer should not sign with a private key when the selector containing the corresponding public key is expected to be revoked or removed before the verifier has an opportunity to validate the signature. The signer should anticipate that verifiers may choose to defer validation, perhaps until the message is actually read by the final recipient. In particular, when rotating to a new key pair, signing should immediately commence with the new private key and the old public key should be retained for a reasonable validation interval before being removed from the key server.</blockquote> <p>In the process of writing this up, I went through the 24 months of query logs I have. With very few exceptions (most of which were probably my own testing) there were no lookups against selectors other than on the day they were being used, so this doesn’t seem to be a problem in practice.</p> <p>I alluded to it earlier, but I want to be clear — publishing <abbr title="DomainKeys Identified Mail">DKIM</abbr> private keys like this mainly addresses leaks as a threat model. In a legal dispute, mail server logs and/or stored mail can be subpoenaed if the authenticity of messages is in question. Even in my case, where I have my own mail server on dedicated hardware with full disk encryption at an undisclosed location, most mail I send will be delivered to a server operated by a third party with no incentive to alter logs at the behest of the recipient.</p> <p>It would make for a fascinating experiment for one of the privacy focused email providers to try deploying a key management strategy similar to the one I’ve described in this post.</p> <table id="id4"> <colgroup><col><col></colgroup> <tbody> <tr><td><a href="#id1">[1]</a></td><td>I can’t find any recent public data on this, but Google reported that 87.6% of non-spam emails received by Gmail users had valid DKIM signatures as of Febuary 2016. <a href="https://security.googleblog.com/2013/12/internet-wide-efforts-to-fight-email.html">https://security.googleblog.com/2013/12/internet-wide-efforts-to-fight-email.html</a></td></tr> </tbody> </table> <table id="id5"> <colgroup><col><col></colgroup> <tbody> <tr><td><a href="#id2">[2]</a></td><td>The core protocol behind email, <span data-title="Simple Mail Transfer Protocol"><abbr title="Simple Mail Transfer Protocol">SMTP</abbr></span> was designed in the early eighties, and one of the terms it uses is “envelope sender”. This is apt because it originally was not much harder to fake than the return address on a physical envelope.</td></tr> </tbody> </table> <table id="id6"> <colgroup><col><col></colgroup> <tbody> <tr><td><a href="#id3">[3]</a></td><td>The DNS standards provide for storing values longer than 255 characters in a TXT record by simply storing multiple strings in the record, but such records can be annoying to work with in some software.</td></tr> </tbody> </table> </div></div>]]>
            </description>
            <link>https://rya.nc/dkim-privates.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24972609</guid>
            <pubDate>Mon, 02 Nov 2020 20:10:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Remember What You've Read?]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24972568">thread link</a>) | @victorbreder
<br/>
November 2, 2020 | https://breder.org/3/ | <a href="https://web.archive.org/web/*/https://breder.org/3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>2020-11-01</p>

<p>Of the books that you have read in full more than a year ago, how much of their content can you remember on top of your head right now? As discussed in the <a href="https://freakonomics.com/podcast/nsq-books-influence/">No Stupid Questions Podcast</a>, we are more likely to remember how a book made us feel, where we bought that book, or even some special circumstance related to it (such as being gifted), than <em>its actual main points</em>.</p>

<p>While remembering plot points is arguably not important for books read for entertainment (the quote "I envy the ones who have not read book X, because they get to experience it for the first time" comes to mind), I would argue that the whole point of reading non-fiction books is to become more knowledgeable. This requires us, at the very least, to retrieve the facts we've learned and, hopefully, being able to articulate them with other facts we know or come to know.</p>

<p>Upon reading the <a href="https://www.amazon.com/dp/B06WVYW33Y">How to Take Smart Notes</a> book by Sonke Ahrens, which outlines the <em>Zettelkasten</em> method of note-taking for academic and non-fiction writing, and the <a href="https://www.amazon.com/dp/B07K6MF8MD">Ultralearning</a> book by Scott Young, which lays out the author's principles for mastery of a given subject through intense effort and focus, I've come to believe that the most important thing to remember what we've read is <em>writing</em>.</p>

<p>As the research into deliberate practice by Anders Ericsson has shown, we're terrible judges for how well we are learning something. We usually equate ease with performing well, so activities that require less effort, such as passively rereading, <em>feel</em> more productive than activities that require more effort, such as testing yourself on what you've learned. Systematic testing afterwards show that the former kind of practice, the <em>effortful</em> practice, performs much better than the latter.</p>

<p>I would argue that while reading through a 200-page book may <em>feel</em> productive, the upside afterwards, for which we set retrieval as the lowest bar, may be small, or smaller than it can be if we adopt some complementary techniques. By simply passively reading, we may fall prey to the <em>illusion of fluency</em>, which means that, while the information is still fresh in our minds, we <em>feel</em> like we master it.</p>

<p>The antidote to the illusion of mastery is, of course, <em>testing</em> yourself. But we can't make this too hard (or we will likely end up not doing it at all or for long). The simplest form of testing is, after you read a chapter, to <em>retrieve</em> from memory the gist of it and the most important points <em>for you</em>, ultimately <em>writing those down in your own words</em>.</p>

<p>By retrieving from memory instead of looking up in the book we practice <em><a href="https://en.wikipedia.org/wiki/Active_recall">active recall</a></em>, which doubles as a self-testing method and a way to strengthen our ability to retrieve that information later. If we fail to recall the main points of a chapter after we've just read it, we likely weren't paying that much attention and we won't be able to recall anything at all in the future.</p>

<p>By focusing on the points that are personally important <em>to you</em>, we ensure that we are not simply becoming able to summarize everything about a book (like a encyclopedia that can be looked up), but we are compounding upon our existing knowledge in ways that interest us and that are more likely to be useful for us in the future.</p>

<p>Finally, and arguably the most important, by writing down in our own words, instead of highlighting or copying quotes, we ensure that we are actively engaged in the concepts we are reading and we test that we are able to articulate those concepts in a coherent manner. By doing this, it is very hard to fool ourselves about our level of competency in that subject (or at least harder than it would be by doing all of this in our own mind).</p>

<p>So what do you remember from this blog post? How this may be important to you by shaping your actions in the future? Don't skip writing it down. :)</p>

</div></div>]]>
            </description>
            <link>https://breder.org/3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24972568</guid>
            <pubDate>Mon, 02 Nov 2020 20:07:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Thoughts on Monorepo]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24971288">thread link</a>) | @shekhargulati
<br/>
November 2, 2020 | https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6395">
	<!-- .entry-header -->

	
	
	<div>
		
<p>Before we start let me give some context on my background so that you can better understand my thoughts on Monorepo.&nbsp;</p>



<p>I head technology at an IT services organization. Most of the products that I build are using Microservices architecture, have multiple frontends(web and mobile). The biggest product that I recently built had close to 30 microservices, 1 web client written in React,&nbsp; and native mobile app built using React Native. These numbers are nowhere near the numbers big product companies have shared.&nbsp;</p>



<blockquote><p>I prefer Macroservices over Microservices. I think most products don’t need more than 10 microservices.&nbsp;</p></blockquote>



<p>The reason I am clearly specifying I belong to the IT services world is because most of the stuff we consume on software development is written by engineers and senior tech people at the product companies. The stuff they write and share is based on the real problems and challenges they face at work. There are times when those problems resonate with problems other software engineers face at their work but there are times they are solutions to the problems we don’t have. So, we have to look at these solutions from the lens of our problems.</p>



<blockquote><p>The post is based on my experience building software, leading and managing software delivery teams, and learning from the great articles written by engineers using Monorepos. Please refer to the references section for good resources on monorepos.</p></blockquote>



<p>Let’s get back to the topic at hand.</p>



<h2>So, what is a Monorepo?</h2>



<p>A monorepo is a software development strategy where a single version control repository has source code for multiple projects, libraries, and applications irrespective of their programming language. Also, the organizations using Monorepo strategy often use a common build tool (like Bazel, Pants, Buck) to manage all the source code. Some of the popular examples of organizations that employ monorepo strategy are Google, Facebook, Twitter, Microsoft, and Uber.&nbsp;</p>



<p>The alternative to monorepo is polyrepo/multirepo. In multirepo, you have a separate version control repository for each component. This is the common strategy used by most organizations to structure their code. This in my view has been largely driven by Microservices architecture style and small modules movement.</p>



<p>As mentioned in the paper[1] (Advantages and Disadvantages of a Monolithic Repository – A case study at Google), Monorepos have following properties:</p>



<ul><li><strong>Centralization</strong>: The codebase is contained in a single repo encompassing multiple projects.</li><li><strong>Visibility</strong>: Code is viewable and searchable by all engineers in the organization.</li><li><strong>Synchronization</strong>: The development process is trunk-based; engineers commit to the head of the repo.</li><li><strong>Completeness</strong>: Any project in the repo can be built only from dependencies also checked into the repo. Dependencies are unversioned; projects must use whatever version of their dependency is at the repo head.</li><li><strong>Standardization</strong>: A shared set of tooling governs how engineers interact with the code, including building, testing, browsing, and reviewing code.</li></ul>



<p>My understanding is that to successfully use monorepo you will have to satisfy all the properties. Otherwise, you will not get benefits intended from monorepo.&nbsp;</p>



<h2>Advantages of Monorepos</h2>



<p>There are valid reasons why many big product organizations prefer Monorepo. Following are the main reasons:</p>



<h3>Reason 1: Simplified dependency management</h3>



<p>Monorepos make dependency management simple by:</p>



<ol><li>You can easily depend on other projects/modules in a monorepo without the need for artifact management tools like Nexus, Artifactory etc.</li><li>You avoid diamond dependency problem. Diamond dependences occur when a project has two dependencies which depend on the same underlying library. When a developer upgrades a dependency, they run the risk of breaking a diamond in the dependency graph.</li><li>It is easier to keep all dependencies on the same version by using a centralized way to manage version numbers.</li></ol>



<p>This is simplified further by using a single build tool. I have not used Bazel, Bucks, or Pants. I was watching a talk on Twitter monorepo journey where they talked about Gradle being too slow for their use case. For the size of applications I have built Gradle has worked just fine.</p>



<h3>Reason 2: Code sharing and reusability</h3>



<p>The second big benefit of Monorepo is that developers can share code across projects. It is easier to enforce best practices across the code base by using monorepo. Another related point is that with monorepo we don’t end up creating silos. This is important in an enterprise setup because it leads to passing the buck and bugs falling through the cracks of the boundaries. In my experience with multirepo setup people only care about their Microservice running fine. They miss the point that value is achieved by integrating the software and collaboration. In IT service organizations where there is more bureaucracy and uneven distribution of skilled developers the problem scales very quickly with multirepo setup. Yes, I know it is a culture problem but most IT service organizations can’t burn investor dollars to build the culture.</p>



<h3>Reason 3: Atomic changes</h3>



<p>This I didn’t realize before I read literature on Monorepo. There is a lot of benefit in seeing related changes in a single commit. If you are working on a story that requires changes in multiple components then in a multirepo scenario you will have to see changes in multiple repositories and merge the PRs in some sequence so that you are in a healthy state. WIth monorepo you save the pain of trying to coordinate commits across multiple repositories. Also, this leads to better code reviews as all the changes are in one place.</p>



<h3>Reason 4: Large-scale code refactoring</h3>



<p>This is related to reason 3. With a monorepo, you can refactor the API and all of its callers in one commit. You see all the usages of an API at a single place and it is much easier to do than with multirepo where you might not even have all the code checked out. In my experience with multirepo setup most developers don’t keep all the repos updated with the upstream changes. Monorepos enables continuous improvement on global level that multirepo you do at local level.</p>



<h3>Reason 5: Less bureaucracy</h3>



<p>With some organizations I have worked at, you have to create ServiceNow tickets to create a repository. It can take a couple of days before you get your empty repository. With monorepo you don’t have to go through this pain.&nbsp;</p>



<h2>Disadvantages of Monorepo</h2>



<p>Nothing comes for free. There are always trade offs involved. Your job as a software engineer is to figure out if advantages weigh more than trade offs or not.&nbsp;</p>



<p>In my view following are the downsides of monorepo:</p>



<ol><li>Monorepos could slow down developers because of slow build times, poor tooling, and merge conflicts.&nbsp;<ol><li>Most developers still in 2020 struggle to cleanly merge code.&nbsp;</li><li>Git is slow for projects with large numbers of files and history.</li></ol></li><li>There is cognitive overhead involved as developers have to get comfortable with a much larger code base than they would have with multirepo setup.</li><li>To do monorepo well require investment in tooling that most organization non-tech leadership will fail to understand</li></ol>



<h2>So, what’s my view on monorepos?</h2>



<p>Before I talk about my views on Monorepo let’s understand three main constraints of IT services organization.&nbsp;</p>



<ol><li>We work with multiple customers so we can’t keep code of all customers in the same repository even when we host their code in our version control for obvious reasons. Also, we can’t give access to all our repositories to all our developers because of security and IP related issues. So, we will keep our discussion focused on how to manage repos for a single customer.</li><li>IT services organizations have a high ratio of junior(&lt; 5 years) to senior engineers(&gt; 10 years) somewhere in the range of 10:1 to 100:1 or may be higher in bigger IT service organizations. The reason I am bringing this point is that monorepos requires discipline and it is tough to achieve without senior engineers driving it using a well-defined process.</li><li>People come and go at a faster rate.</li></ol>



<p>Given the above two constraints and the disadvantages of monorepos it might seem that monorepos will not work for us. But, I see real problems faced by software delivery teams that can be solved by monorepos.</p>



<p>We build products for different customers. These products usually follow Microservice architecture, have multiple frontends – web and mobile, functional tests, scripts for deployment automation. In the multirepo strategy, you will create at minimum 5 repositories – 1 for backend with all microservices, 1 for SPA frontend, 1 or 2 repo for mobile depending on whether you are building pure native or using some native framework like React Native or Flutter, 1 for functional tests, 1 for deployment automation scripts.&nbsp; More often than not your team will use one repo per Microservice then only god knows how many repos you end up creating.</p>



<blockquote><p>Let me tell you a real story. I was once working with a client that had more than 1000 repositories in their version control system. They were using the Gitlab version control platform. They had 5 products and each product was made up of multiple Microservices. The first question I asked them was to help us understand which all services and their respective code repositories were part of product A. Their chief architect had to spent a day figuring out all the repositories that made the product A. After spend a day still she was not sure if she has covered all the services.</p></blockquote>



<p>Let’s discuss problems that I face with software delivery teams using the multirepo strategy. Just to reiterate these problems are in the context of a single customer.</p>



<ol><li>Lack of accountability: Humans are good at creating boundaries and silos. They don’t care what happens outside those boundaries. They don’t care about the bigger picture.</li><li>Version drift. 10 different versions of Spring Boot, three different JDK versions, …</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/">https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/</a></em></p>]]>
            </description>
            <link>https://shekhargulati.com/2020/11/02/my-thoughts-on-monorepo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24971288</guid>
            <pubDate>Mon, 02 Nov 2020 18:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Submer MicroPod: Edge immersion cooled datacenter-in-a-box]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24970554">thread link</a>) | @polvs
<br/>
November 2, 2020 | https://submer.com/micropod | <a href="https://web.archive.org/web/*/https://submer.com/micropod">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"> <!-- End Google Tag Manager (noscript) -->   <!--[if IE]><div class="alert alert-warning"> You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div> <![endif]--> <a href="#content">Skip to content</a><!-- #masthead -->   <section id="id34947"><div><figure> <img uk-img="" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-video-pre-1024x576.jpg" alt="" src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-video-pre-1024x576.jpg"> </figure><div><h2>Computing and Cooling <span>Where you Need them!</span></h2><p>Our <b>Edge-ready, plug-and-play, datacenter-in-a-box</b> solution delivers unprecedented <b>high density</b> and <b>efficient infrastructure</b> anywhere. Be it a warehouse, office building, in the heart of a city or in a remote area with harsh-climate conditions and far from the grid, the <b>MicroPod</b> will be fit for the job.</p></div></div></section><section id="blockfreecontent-34026"></section><section uk-img="" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/07/5e2ecfd712d9359dcffb9443_thxpage-bg.jpg"><div><h2> The <span>benefits</span> of the MicroPod</h2><div uk-grid=""><ul><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="In a traditional datacenter, cooling is responsible for about 40% of the electricity consumption. With the MicroPod, Submer allows you to achieve a low energy footprint in any outdoor-only or outdoor-indoor configuration."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_pue.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Low energy footprint</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer allows you to save 25%-40% on your TCO, that translates into substantial savings on CAPEX (Design, Real Estate, Construction, IT hardware, Cables, Cooling, Piping, etc.) and OPEX (Electricity &amp; Maintenance)."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_tco.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Save 25-40% on TCO</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Thanks to their design and the use of a proprietary dielectric coolant specifically designed for single phase Immersion Cooling, Submer’s solutions guarantee unrivalled density. Deploying our MicroPod technology allows you to dissipate up to 6kW in an unprecedented compact space and with flexible IT gear (19-inch, 21-inch OCP, OpenEdge with depths up to 800 mm).
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_density.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>6 kW of compute density in a compact space</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Thanks to its modular design, Submer’s MicroPod can be deployed anywhere: in an already existing datacenter, at the Edge, in a warehouse, in an office or even outdoors. The all-in-one technology by Submer brings unprecedented IT density, high efficiency and low latency right were you need it. 
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_speed.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Reduce latency and increase speed deployment</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="One of the most immediate benefits of Submer’s Immersion Cooling solutions is the prolonged life-span of the hardware. The SmartCoolant cools and protects the servers in a particulate-free environment, with no whiskers, no moving parts, etc."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_life.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>+30% in HW life-span</p></div></li></ul><ul><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="The SmartCoolant, the dielectric proprietary fluid used in Submer’s solutions, apart from whisking heat away from the cores, protects the servers and their components from dust, particles, abrupt changes of temperature and moisture, prolonging the HW life-span."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_hwRate.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>-60% in HW failure rate</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s solutions are rapidly deployable in raw space without the need for raised floors. They can easily integrate into an already existing datacenter or warehouse or even in an office with minimum retrofitting. The MicroPod offers a self-contained, ruggedised and fully-sealed immersion enclosure.
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_buildingCosts.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Save 50% on CAPEX building costs</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="In a datacenter, about 40% of the electricity is used for the cooling system. Submer’s technology allows to save up to 95% on cooling OPEX (corresponding to about 50% of the electricity bill). With Submer’s solutions, you get highly efficient primary and secondary cooling systems. Besides, your servers consume less since they do not need fans. "><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_cooling.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Save 95% on cooling OPEX</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Water is an essential resource for any datacenter operations as important as electricity. Submer’s MicroPod system guarantees zero water consumption as it does not need any connection to the secondary cooling system."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_waterWaste.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Zero water consumption</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s solutions are designed to be easily integrated into already existing facilities and to help your datacenter be more efficient and environmentally friendly. Submer’s technology has been conceived to not simply dissipate heat, but also to smartly recapture and reuse the heat dissipated for other purposes such as the heating of the building hosting the datacenter or the surrounding urban and industrial areas."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/05/ic_heat.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Re-use of heat</p></div></li></ul></div></div></section><div id="icon-modal" uk-modal=""> <!----><div> <div><div> <p><img src="" alt=""></p></div></div></div></div>  <section id="technical-aspects-29863"><div><div><div><figure uk-sticky="media:768;bottom:true;offset:30"> <img uk-img="" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/10/pod-render_micropod_open_zenital-e1603708195705.png" alt="" src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/10/pod-render_micropod_open_zenital-e1603708195705.png"></figure></div><div><div><div><div><p><img data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/07/specsicon.svg" uk-img="" alt=""></p></div></div><table><tbody><tr><td><span>Heat dissipation capacity (kW)</span></td><td><span>Outdoor configuration: 5000 W (in direct sunlight)<br> Indoor configuration: 6600 W</span></td></tr><tr><td><span>IT gear capacity (U, OU) </span></td><td><span>19 inch / 6U ,  600 mm max depth</span></td></tr><tr><td><span>Dimensions, L x W x H (cm, in) </span></td><td><span>130 (L) x 65 (W) x 90 (H) cm<br> 51.18 (L) x 25.59 (W) x 35.43 (H) in<br> Maximum height with lid open:<br>155 (H) cm 61.02 (H) in<br> </span></td></tr><tr><td><span>SmartCoolant capacity (l, gal) </span></td><td><span>96 l / 25.3 gal</span></td></tr><tr><td><span>Weight, empty (kg, lb) </span></td><td><span>approx 227kg / 500 lb</span></td></tr><tr><td><span>Weight, full of SmartCoolant weight (kg, lb) </span></td><td><span>approx 303 kg / 669 lb</span></td></tr><tr><td><span>Weight, full of Servers (kg, lb)</span></td><td><span>approx 340 kg / 749 lb</span></td></tr><tr><td><span>Footprint, L x W (m2, f2) </span></td><td><span>0.845 m2 / 9.1 f2</span></td></tr><tr><td><span>Power supply options </span></td><td><span>(CE) 380-400 V 50 Hz / (UL) 208-230 V 60 Hz</span></td></tr><tr><td><span>Power supply connection options </span></td><td><span>(CE) Industrial connector three phase 3P+E+N 16A IEC 60309<br> (UL) 20A NEMA plug L2120</span></td></tr><tr><td><span>Water Requirement</span></td><td><span>None</span></td></tr><tr><td><span>Communications</span></td><td><span>Multiple options for integrated pass-through patch panel and cable management / Ethernet port</span></td></tr><tr><td><span>Backup Power</span></td><td><span>Multiple options for integrated Battery Backup Units with up 40min active critical power</span></td></tr><tr><td><span>Ambient air temperature range, recommended less or equal to (°C, °F)</span></td><td><span>0°C - 50°C, 32°F - 122°F</span></td></tr><tr><td><span>Works under direct solar load</span></td><td><span>Yes</span></td></tr></tbody></table></div></div></div></div></section> <!-- This is the modal --><div id="modal-download-technical-aspects-29863" uk-modal=""><div> <p><h3>Download <span>MicroPod</span> - Technical specs</h3></p> <!--[if lte IE 8]> <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/v2-legacy.js"></script> <![endif]-->   </div></div><section><div><h2><span>Compatible with any</span> IT hardware</h2></div></section><section id="blockfreecontent-90651"><div uk-img="" data-src=""><div><div><p><img loading="lazy" src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg" alt="" width="1024" height="576" srcset="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg 1024w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1800x1013.jpg 1800w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-768x432.jpg 768w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1536x864.jpg 1536w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-2048x1152.jpg 2048w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-scaled.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg 1024w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1800x1013.jpg 1800w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-768x432.jpg 768w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1536x864.jpg 1536w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-2048x1152.jpg 2048w, https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-scaled.jpg 2000w" data-src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/11/micropod-rooftop3-copy-1024x576.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><div><h2>Immersion Cooling at the Edge</h2><p>Submer’s MicroPod is the perfect Immersion Cooling solution for Edge applications, colocation datacenters, telcos and cloud computing. Thanks to its compact, <span>modular, plug-and-play, datacenter-in-a-box configuration</span>, the MicroPod allows for fast deployment in any location, including direct sunlight and an easy plug-and-play installation with an unrivalled energy footprint anywhere on the globe.</p></div></div></div></div></section><section uk-img="" data-src=""><div><h2> Submer <span>Services</span></h2><div uk-grid=""><ul><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s team can help you assess if your facility meets the basic requirements for the installation of our solutions. One of the aspects of our technology is that it can be deployed practically anywhere. Nevertheless, there are some fundamental requirements for the proper installation and functioning of Submer’s solutions.
"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_facility.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Facility Analysis</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Design together with our technicians your datacenter! Share with us your goals, and your facility characteristics, ask all your questions, and we will plan the best solution for your business needs."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_designPlanning.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Design &amp; Planning</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer’s solution can be deployed anywhere: from harsh climate regions to warehouses, from Edge installations to office buildings. Our team of experts will work with you to better understand how to adapt our solutions to your spatial and geographic needs. We will also walk you through the whole set-up and activation process."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_deployment.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Deployment &amp; Activation</p></div></li><li uk-parallax="x:-60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="We offer immersion ready servers through our partners. Clearly, this is optional: our solution is universal and open to any off-the-shelf server, so our customers can choose their preferred OEM."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_certifiedCoolant.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Certified Immersion Hardware</p></div></li></ul><ul><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer complies with all the safety and quality rules and policies, as stated by various certifications. When you become one of our customers, you do not just get a product like many others. We listen to you and we offer a solution fit for your needs. And since quality and safety are two funding values of Submer, we want to share them with you as well."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_certifications.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>All Necessary Certifications</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="Submer assists you in every step of your journey towards efficiency, better performance and sustainability. Our multi-talented team will guide you and support you sharing with you their experience in mechanics, engineering, thermodynamics, chemistry, etc. Before the installation of any Submer’s solution, during its operation and also after, Submer’s team will always be available for any preventive and corrective maintenance procedure. "><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_maintenance.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Preventive and Corrective Maintenance</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="We want our customers to be satisfied with our service and solutions. That’s why we guarantee that every single step of our customer’s journey toward a future of smart datacenters is taken having in mind all kinds of safety and quality measures. You will be in total control of the solution you decide to purchase and we will provide you with technical assistance and training and also with all the necessary warranties (from us, but also from our partners)."><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_control.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Control and Warranties</p></div></li><li uk-parallax="x:60,0;opacity:0,1;viewport:.35" uk-toggle="#icon-modal" data-desc="What if instead of just being one of our customers, you want to become a partner and share our vision of smart datacenters all over the globe? Get in touch with us and let’s build the basis for a solid, long-lasting partnership. And who knows, maybe along the way, we’ll also become best friends!"><div uk-grid=""><p><img src="https://mk0submer3q6awaxthm1.kinstacdn.com/wp-content/uploads/2020/06/ic_friendship.svg" width="auto" height="70" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Partnership and Friendship along the way (this is for free)</p></div></li></ul></div></div></section><div id="icon-modal" uk-modal=""> <!----><div> <div><div> <p><img src="" alt=""></p></div></div></div></div>  <section><div><p>Ask questions, tell us more about your upcoming datacenter/HPC or Hyperscale project. We're here to help.</p></div></section><main id="main"><!--  uk-container --></main><!-- #main --><!-- #colophon --> <!--googleoff: all--><div><div id="cookie-law-info-bar" data-cli-geo-loc="0"><p><span>This website uses cookies to improve your experience. We'll assume you're ok with this, but you can opt-out if you wish. <a href="https://submer.com/cookies-policy/" id="CONSTANT_OPEN_URL" target="_blank">Read More</a><a role="button" tabindex="0">Cookie settings</a> <a role="button" tabindex="0" data-cli_action="accept" id="cookie_action_close_header">ACCEPT</a> </span></p></div></div>  <!--googleon: all-->          <a uk-scroll="" href="#top" uk-icon="icon:arrow-up"></a> <!-- Start of HubSpot Embed Code -->  <!-- End of HubSpot Embed Code --></div>]]>
            </description>
            <link>https://submer.com/micropod</link>
            <guid isPermaLink="false">hacker-news-small-sites-24970554</guid>
            <pubDate>Mon, 02 Nov 2020 17:22:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 400 vs. ZX Spectrum]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969935">thread link</a>) | @DSpinellis
<br/>
November 2, 2020 | https://www.spinellis.gr/blog/20201102/ | <a href="https://web.archive.org/web/*/https://www.spinellis.gr/blog/20201102/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <!-- Left content -->
  <p>The release of the <a href="https://www.raspberrypi.org/products/raspberry-pi-400/?resellerType=home">Raspberry Pi 400 personal computer</a> reminded me of a wildly popular home computer that was launched in a similar computer-in-a-keyboard format almost 40 years ago: the Sinclair Research <a href="https://en.wikipedia.org/wiki/ZX_Spectrum">ZX Spectrum</a>. I decided to compare the two, following the steps of an <a href="https://www.spinellis.gr/blog/20151129/">earlier comparison</a> I performed between the 2015 Rapsberry Pi Zero and the 1957 Elliott 405.</p>
<p><img src="https://www.spinellis.gr/blog/20201102/ZXSpectrum.jpg" alt="The 1982 ZX Spectrum home computer"> <a href="https://commons.wikimedia.org/w/index.php?curid=170050">ZX Spectrum picture by Bill Bertram — Own work, CC BY-SA 2.5</a></p>
<h3 id="comparison-table">Comparison table</h3>
<table>
<thead>
<tr>
<th></th>
<th>ZX Spectrum</th>
<th>Raspberry Pi 400</th>
</tr>
</thead>
<tbody>
<tr>
<td>Launch year</td>
<td>1982</td>
<td>2020</td>
</tr>
<tr>
<td>Price</td>
<td>£125</td>
<td>£ 94</td>
</tr>
<tr>
<td></td>
<td>(<a href="https://www.officialdata.org/uk/inflation/1982?amount=125">£440 in 2020 prices</a>)</td>
<td></td>
</tr>
<tr>
<td>Processor</td>
<td>Z80A</td>
<td>BCM2711 Cortex-A72 (ARM v8)</td>
</tr>
<tr>
<td>CPU register width</td>
<td>8 bit</td>
<td>64 bit</td>
</tr>
<tr>
<td>Clock frequency</td>
<td>3.5MHz</td>
<td>1.8GHz</td>
</tr>
<tr>
<td>Number of cores</td>
<td>1</td>
<td>4</td>
</tr>
<tr>
<td>Main memory</td>
<td>16 kB</td>
<td>4GB</td>
</tr>
<tr>
<td>Networking</td>
<td>None</td>
<td>Gigabit Ethernet &amp; WiFi</td>
</tr>
<tr>
<td>Secondary storage</td>
<td>Audio cassette tapes</td>
<td>16GB microSD card</td>
</tr>
<tr>
<td></td>
<td>(not included)</td>
<td>(included)</td>
</tr>
<tr>
<td>Video output</td>
<td>TV RF modulator</td>
<td>Two micro HDMI ports</td>
</tr>
<tr>
<td>Video resolution</td>
<td>256×192</td>
<td>3840×2160</td>
</tr>
<tr>
<td>Output colors</td>
<td>16</td>
<td>16 million</td>
</tr>
<tr>
<td>Graphics support</td>
<td>PLOT, DRAW</td>
<td>OpenGL ES 3.0</td>
</tr>
<tr>
<td>Video support</td>
<td>None</td>
<td>H.265 (decode); H.264 (decode, encode)</td>
</tr>
<tr>
<td>Keyboard</td>
<td>40 keys</td>
<td>78 keys</td>
</tr>
<tr>
<td>Board chips</td>
<td>11 VLSI, 7 SSI</td>
<td>7 VLSI, 3 MSI</td>
</tr>
<tr>
<td>Dimensions</td>
<td>233×144×30 mm</td>
<td>286 × 122 × 23 mm</td>
</tr>
</tbody>
</table>
<p><img src="https://www.spinellis.gr/blog/20201102/rpi400.jpg" alt="The 2020 Raspberry Pi 400 personal computer"> Photo Credit: Raspberry Pi Foundation</p>
<h3 id="summing-up">Summing up</h3>
<p>The remarkable hardware improvements apparent in the comparison of the two products, combined with the rise of open source software, allow the Raspberry Pi 400 to come with an industrial-strength operating system offering internet connectivity and free access to around fifty thousand software packages. The Raspberry Pi 400 showcases the amazing progress personal computing technology has made over the past 40 years.</p>

<p>
<!-- COMMENTS --> <a href="https://www.spinellis.gr/cgi-bin/comment.pl?date=20201102#comments">Read and post comments</a>, or share through&nbsp;&nbsp;&nbsp;
<!-- Go to www.addthis.com/dashboard to customize your tools -->
</p>

</div></div>]]>
            </description>
            <link>https://www.spinellis.gr/blog/20201102/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969935</guid>
            <pubDate>Mon, 02 Nov 2020 16:36:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Litte Snitch 5 for macOS Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24969831">thread link</a>) | @lorenz_li
<br/>
November 2, 2020 | https://www.obdev.at/products/littlesnitch/whatsnew.html | <a href="https://web.archive.org/web/*/https://www.obdev.at/products/littlesnitch/whatsnew.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<section>
    <p><img src="https://www.obdev.at/Images/littlesnitch/whats-new/configuration.png" srcset="https://www.obdev.at/Images/littlesnitch/whats-new/configuration@2x.png 2x" width="1004" height="613" alt="Configuration Interface">
    </p>

    <p>
        <en>A beautiful new design, improved traffic statistics, a brand new command line interface, simplified Drag and Drop installation and the seamless compatibility with macOS Big Sur are setting Little&nbsp;Snitch&nbsp;5 apart from its predecessor.</en>
    </p>

    <h3><en>Redesigned for macOS Big Sur</en><!--de>Neu gestaltet für macOS Big Sur</de--></h3>
    <p>
        <en>The main focus in the development of Little Snitch 5 was on the integration of the new network filter technologies introduced by Apple in macOS Big Sur. The underlying filter engine was re-built from ground up to replace the previous kernel extension based approach which is no longer supported by macOS.</en>
    </p>
    <p>
        <en>Furthermore, Little Snitch was adapted to the new, elegant design language of the operating system with great attention to detail. New design features, like a prominent search bar and a newly structured sidebar go beyond aesthetic choice and add a level of simplicity and intuitiveness to the user experience.</en>
    </p>

    <h3><en>Drag and Drop Installation</en><!--de>Drag und Drop Installation</de--></h3>
    <p>
        <en>The simplified Drag and Drop installation has been eagerly awaited by many users. Now it’s no longer necessary to restart the computer in order to install or update Little Snitch.</en>
    </p>

    <h3><en>Improved Traffic Monitoring</en><!--de>Verbesserte Netzwerkverkehrsüberwachung</de--></h3>
    <p><img src="https://www.obdev.at/Images/littlesnitch/whats-new/monitor.png" srcset="https://www.obdev.at/Images/littlesnitch/whats-new/monitor@2x.png 2x" width="1095" height="627" alt="Network Monitor">
    </p>
    <p>
        <en>Little Snitch now captures connection information efficiently in the background. It no longer requires the Network Monitor application to be running in order to collect this information, resulting in reduced memory and CPU consumption.</en>
    </p>
    <p>
        <en>The improved monitoring system is now capable of holding traffic information from up to a whole year, instead of only the last hour as before.</en>
    </p>

    <h3><en>Command Line Interface</en><!--de>Kommandozeilen-Schnittstelle</de--></h3>
    <p>
        <en>System administrators now have the ability to configure a variety of program settings via a command line interface, making Little Snitch scriptable for the very first time.</en>
    </p>
    <p>
        <en>This interface now also offers the possibility to report network connections in a log-based format for detailed and versatile traffic analysis.</en>
    </p>

    <h3><en>Free Upgrade</en><!--de>Kostenloses Upgrade</de--></h3>
    <p>
        <en>If you have purchased Little Snitch 4 after November 1, 2019, you can upgrade to Little Snitch 5 for free – just use your existing license key. If you purchased Little Snitch 4 before that period, you can <a href="https://www.obdev.at/shop/index.html#upgrades">get the upgrade at a reduced price</a>.</en>
    </p>

</section>

<section id="download">
    <a href="https://www.obdev.at/products/littlesnitch/download.html">
        <p><img src="https://www.obdev.at/Images/product-icons/littlesnitch_128.png" srcset="https://www.obdev.at/Images/product-icons/littlesnitch_128@2x.png 2x" width="128" height="128" alt="Little Snitch App Icon">
        </p>
        
        
    </a>
</section>

			</div></div>]]>
            </description>
            <link>https://www.obdev.at/products/littlesnitch/whatsnew.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969831</guid>
            <pubDate>Mon, 02 Nov 2020 16:29:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launch HN: Fiddler – A Reliable Model Monitoring Tool for ML Operations]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969735">thread link</a>) | @krishnagade
<br/>
November 2, 2020 | https://blog.fiddler.ai/2020/07/announcing-ml-monitoring-capabilities/ | <a href="https://web.archive.org/web/*/https://blog.fiddler.ai/2020/07/announcing-ml-monitoring-capabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
<p><em><em>Today, at the VentureBeat Transform event, we launched our ML Monitoring feature set, inclusive of data drift detection, outlier detection, and data integrity. These capabilities are coupled with Fiddler’s industry-leading Explainable AI Platform to efficiently and effectively explain, analyze, and resolve MLOps production monitoring issues</em>.</em></p>



<h2><strong>Challenges in MLOps Monitoring&nbsp;</strong></h2>



<p>AI adoption is accelerating, with <a href="https://www.stateofai2019.com/">one in ten enterprises currently using ten or more AI applications</a> and <a href="https://www.gartner.com/document/3984974?ref=solrAll&amp;refval=256236044">75% of businesses expected to shift from piloting to operationalizing AI by 2024</a>. This trend has only been amplified by the pressure from Covid-19 to adopt automation to help cut costs. But the complexity of deploying ML has hindered the success of AI systems. Even beyond the challenge of amassing the right data to train models, model deployment and management present similar challenges to those that plagued software prior to the arrival of DevOps Monitoring.</p>



<h3><strong><strong>Challenge 1: Unreliable Inputs: feature drift, errors, and outliers</strong></strong></h3>



<p>Models are trained on historical data with the hope of generalizing to future examples. Unfortunately, trends and thus the data received by models often change, which in turn affect model performance. When such data drifts occur, data scientists must decide whether to act, often by retraining the model, or do nothing. Assessing the impact of a drift can help inform this decision, but today’s tools often inhibit the ability to attribute drift of one or more features to a shift in the model’s predictions.</p>



<p>Moreover, complex and brittle feature pipelines are liable to break at any moment. These breaks can range from virtually no effect to the model to a complete loss of functionality that causes the model to error out. Common types of feature pipeline errors include null or missing values, type mismatches, and range anomalies. Rapidly identifying and addressing these errors is paramount to ensuring reliability for deployed AI systems and the downstream applications and services they power.</p>



<p>Finally, deployed AI models may encounter seemingly valid data points containing values that fall outside the range of values within the training set. Detecting these outliers is important to ensure optimal performance of models and also best serve those who are impacted by these models. A decision to deny a loan to a fully viable applicant because the model detected this applicant as an outlier is bad for both the organization as well as the consumer.&nbsp; Today, such outliers often require anomaly detection systems on model inputs to identify.&nbsp;</p>



<h3><strong><strong><strong>Challenge 2: Uncertain feedback</strong></strong></strong></h3>



<p>After training a model, practitioners use the model’s target to assess the model’s performance. Production models, however, might not have access to the real-world results of their decisions until long after they’ve been made (for instance, a loan application system might not be notified of a default for months after the loan was approved). In this case, model metrics like AUC, precision, recall etc. cannot be calculated to assess real-time model performance. In the absence of live ground truth, ML practitioners must turn to proxy metrics, like prediction scores or intermediate model decisions, for model performance.&nbsp;</p>



<h3><strong><strong><strong><strong>Challenge 3: Tedious debugging&nbsp;</strong></strong></strong></strong></h3>



<p>In addition to merely tracking the aforementioned metrics and identifying when anomalies or issues arise, MLOps teams must then debug the issues as swiftly as possible. Given the complexity and black-box-nature of many AI systems, attribution of the symptom to its underlying cause–ie root cause analysis–is often incredibly difficult. If a specific feature is exhibiting issues, it may be straightforward to check the code and upstream systems used to generate that feature for changes or errors. But if the model’s overall performance begins to degrade, where do you start your investigation?</p>



<h2><strong><strong>Explainable AI + ML Monitoring = Comprehensive &amp; Actionable MLOps&nbsp;</strong></strong></h2>



<p>Today, at VB Transform, we launched our <a href="https://www.fiddler.ai/ml-monitoring">ML Monitoring suite</a>, to enable businesses of all sizes to monitor, explain, and analyze their AI in production and build more reliable, performant, and trustworthy AI models. Here’s an overview of capabilities available for use:&nbsp;</p>



<h3><strong><strong><strong><strong>Drift Detection</strong></strong></strong></strong></h3>



<p>With Fiddler’s drift detection capabilities, businesses are continuously alerted to changes in model feature or prediction distributions from their training baselines. This enables them to determine when it’s time to retrain models based on the impact of changes. Additionally, Fiddler attributes these changes to the underlying features causing them using AI Explainability. This enables practitioners to understand the ‘why’ and ‘how’ behind their model’s behavioral changes for faster problem resolution.&nbsp;</p>


	
	


<h3><strong><strong><strong><strong>Data Integrity</strong></strong></strong></strong></h3>



<p>Data inconsistencies can often go unnoticed in deployed AI systems. With Fiddler, teams can easily detect feature errors like missing values, type mismatch, and range anomalies, thereby reducing overall issue resolution time.</p>



<h3><strong><strong><strong><strong>Outlier Detection</strong></strong></strong></strong></h3>



<p>With the ability to detect outliers or anomalies in model predictions and features, users get a bird’s eye view into all anomalies to ensure they are catching these accurately and immediately. This can then be coupled with Fiddler’s AI explanations to quickly observe how the model is treating these outlying points.</p>


	
	


<h3><strong><strong><strong><strong><strong>Real-Time Alerting &amp; Explainable AI powered debugging</strong></strong></strong></strong></strong></h3>



<p>Alerts are critical to ensure teams catch things as they happen. Fiddler allows you to configure alerts for changes to model performance, prediction and feature drift, and service health, to be notified the moment something changes.&nbsp; When coupled with Explainable AI analytics, users can quickly identify the root cause of issues and troubleshoot them appropriately</p>



<p>If you’d like to learn more about the release and try it out today, <a href="https://www.fiddler.ai/learn-more?utm_campaign=Fiddler%20blog&amp;utm_source=monitoring-announce&amp;utm_medium=blog">sign-up for a demo</a>. </p>
</div>
    </div></div>]]>
            </description>
            <link>https://blog.fiddler.ai/2020/07/announcing-ml-monitoring-capabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969735</guid>
            <pubDate>Mon, 02 Nov 2020 16:20:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Darklang: Leaving OCaml]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24969352">thread link</a>) | @areski
<br/>
November 2, 2020 | https://blog.darklang.com/leaving-ocaml/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/leaving-ocaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/skeleton-camel.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/skeleton-camel.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/skeleton-camel.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg" alt="Leaving OCaml">
            </figure>

            <section>
                <div>
                    <p><em>Part of a 3 part series. Followups on <a href="https://blog.darklang.com/new-backend-fsharp/">F#</a>, <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Rust</a></em></p><p>I built the first demo of Dark in Python, in about two weeks. A few months later when I started productizing it, I rebuilt it in OCaml. Back in 2017, when I was considering the language and platform to use for Dark, OCaml was extremely compelling:</p><ul><li>it's a high-level language with static types, so easy to make large scale changes as we figure out what the language/product was</li><li>you mostly model data with sum types, which in my mind are the best way to model data</li><li>it's very similar to the language I wanted to build (in particular, we could reuse built-in immutable data structures for Dark's values)</li><li>it had a reputation for being high-performance, which meant that we could write an interpreter for Dark and not have it be terribly slow (vs writing an interpreter in python, which might be too slow)</li></ul><p>Unfortunately, as we've built Dark we've run into significant problems that have made it challenging to build in OCaml.</p><h2 id="lack-of-libraries">Lack of libraries</h2><p>When you bet on an off-mainstream language, one of the things you accept is that many libraries are not going to be available. When there is a small community, often there aren't enough people working in the language to make important libraries. This is especially true if few people are building business applications.</p><p>In OCaml there are many high quality libraries, especially for data structures and data manipulation. The annual<a href="https://opensource.janestreet.com/core/"> Jane Street code dump</a> has been quite useful and very high quality. However, we really felt the lack of several libraries. The most obvious of these is that we had to build a <a href="https://github.com/darklang/dark/blob/main/backend/libexecution/unicode_string.mli">Unicode string library</a> ourselves (built on top of the <a href="https://erratique.ch/software/uuseg">very impressive OCaml Unicode libraries</a> built by <a href="https://erratique.ch/contact.en">Daniel Bünzli</a>), but we needed many more libraries than that.</p><p>The lack of an SDK for Google Cloud has affected us greatly. When you're searching for product-market fit, you do the simplest, easiest thing. If you lack a good SDK for your cloud provider, the simplest, easiest thing is often a terrible architectural choice. We've built our own queue on top of our database rather than using the production-quality cloud queues available on GCP. Similarly, we barely use the Cloud Storage (GCP's version of S3), because we initially put things in the database <a href="https://blog.darklang.com/evolving-darks-tracing-system/">because it was easier</a>. We've built 3 services, 2 <a href="https://github.com/darklang/dark/tree/main/containers/stroller">in</a> <a href="https://github.com/darklang/dark/tree/main/containers/queue-scheduler">Rust</a>, and 1 in <a href="https://github.com/darklang/dark/tree/main/containers/postgres-honeytail">Go</a>, to workaround the challenges we've faced.</p><p>The biggest challenge here is our use of Postgres. Postgres is a great database and we're big fans, but Cloud SQL is not a great hosted database. GCP's position is that Cloud SQL is there to tick a box and we should be using Cloud Spanner. I would love to switch to Cloud Spanner, but we have no driver for it in OCaml. Given the Postgres driver in OCaml is not particularly mature, it's hard to expect that a Cloud Spanner driver would exist, and indeed it doesn't. We've had to contribute to the <a href="https://github.com/mmottl/postgresql-ocaml/commit/81a4ae5240decd8f483a90568257cfbc1558c7ed">OCaml Postgres driver</a>, and some parts of our codebase have been <a href="https://github.com/darklang/dark/blob/main/backend/libbackend/serialize.ml#L226">well and truly mangled</a> when working around features not supported in that driver.</p><p>We've also suffered from a lack of a high-level, production web stack (there are <a href="https://github.com/anmonteiro/ocaml-h2">low-level stacks with good reputations</a> that I've struggled to use, and a <a href="https://github.com/oxidizing/sihl">few</a> <a href="https://github.com/reason-native-web/morph">new</a> ones out there that look good), in particular lacking a user authentication module. We've been using <a href="https://auth0.com/">Auth0</a> to work around this for now, which has more moving pieces than I'd like, and a shockingly high cost (our 7000 users, most of whom never log in, costs us over $500/mo).</p><p>We've worked around other missing vendor SDKs by calling their HTTP endpoints directly and that's been mostly fine. However, for libraries like encryption we don't have that option - we <a href="https://github.com/darklang/dark/pull/1455/files">hacked around a missing encryption library</a>, but decided not to ship it to production until we audited it for security (which was never actually worth the cost).</p><p>At CircleCI, we bet on Clojure. That was also a non-mainstream language, but its ability to call Java SDKs meant we had a mature cloud library, which was essential for building CircleCI. Of course, in OCaml we could call C libraries (and <a href="https://github.com/darklang/dark/pull/1841">even Rust libraries</a>, perhaps), but it doesn't match having native libraries we can call directly.</p><h2 id="learnability">Learnability</h2><p>I'm mostly in the camp that anyone can learn any language, but I saw a team struggle with OCaml, and for good reason. Language tutorials are extremely poor in OCaml compared to other languages; they're mostly lecture notes from academic courses.</p><p>The compiler isn't particularly helpful, certainly compared to Rust or Elm (both of which have been in our stack at one point). Often it gives no information about an error. Syntax errors typically say "Syntax error"; though it will try to give a good error for a mismatched brace, often incorrectly. Type errors can be a real burden to read, even after 3 years of experience with it.</p><p>The docs in OCaml are often challenging to find. The <a href="https://ocaml.janestreet.com/ocaml-core/latest/doc/base/index.html">Jane Street docs</a> have improved significantly in the last few years, but it can be a challenge to even figure out what functions are available in a particular module for most libraries. Compare to the excellent <a href="https://docs.rs/">docs.rs</a> in Rust, which has comprehensive API docs for every package in Rust.</p><p>One of the ways I personally struggled in OCaml is around <code>Lwt</code>. Lwt is (one of!) OCaml's async implementations. I couldn't figure it out several years ago and so just built a single-threaded server. The amount of workarounds and downtime we've suffered from that single decision is immense. A tutorial around building high-performance (or even medium performance!) web servers would be very valuable. </p><p>Tooling is something I read would be good in OCaml. I remember reading there was a debugger that could go back in time! I don't know where that's gone but I've never heard of anyone using it.</p><p>We have struggled to make editor tooling work for us. This is partially because we also use ReasonML and this seems to break things. Unfortunately, this is common in programming, but even more so in small communities: you might be the first person to ever try to use a particular configuration.</p><p>Finally, the disconnect between the various tools is immense. You need to understand Opam, Dune, and Esy, to be able to get something working (you could also do it without Esy and just rely on Opam, but that's much worse). I talked about a bunch of these challenges <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">here</a>.</p><h2 id="language-problems">Language problems</h2><p>Multicore is coming Any Day Now™️, and while this wasn't a huge deal for us, it was annoying. </p><h2 id="minor-annoyances">Minor annoyances</h2><p>One of my biggest annoyances was how often OCaml folks talk about Fancy Type System problems, instead of how to actually build products and applications. In other communities for similar languages (ReasonML, Elm, F#), people talk about building apps and solving their problems. In OCaml, it feels like people spend an awful lot of time discussing Functors. It's not quite at the level that I perceived in the Haskell world, but it pointed out that the people building the core of the ecosystem do not have the same problems that I do (which is building web-y stuff).</p><p>I honestly think OCaml was a great choice at the start. Being able to quickly and safely make large-scale changes to your app is something that staticly-typed functional languages excel at. I'm happy that we made the choice, and in retrospect, it still seems like the best choice of those we had at the time.</p><p>I'm working on building the next version of the backend. We have about 20k lines to be replaced, and they'll be rewritten in a new language while keeping the semantics the same. I plan to leave keep the frontend in ReasonML: it doesn't suffer from the same library problems as it can interface nicely to JS, and it's nearly 50k lines of code so it would be a much bigger undertaking.</p><p>Read <a href="https://blog.darklang.com/new-backend-fsharp/">the followup</a> to see what we picked!</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/leaving-ocaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969352</guid>
            <pubDate>Mon, 02 Nov 2020 15:48:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Survey shows bipartisan support for stronger consumer protections]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24969163">thread link</a>) | @encorekt
<br/>
November 2, 2020 | https://fairshake.com/consumer-news/survey-analysis-bipartisan-support-consumer-protections/ | <a href="https://web.archive.org/web/*/https://fairshake.com/consumer-news/survey-analysis-bipartisan-support-consumer-protections/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <h3><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg" alt="Header Image: White House Image with Title of Page" width="2022" height="1166" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-300x173.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1024x590.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-768x443.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1536x886.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-300x173.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1024x590.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-768x443.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1-1536x886.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/00-Header-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></h3>
<h3>In this article:</h3>
<p><strong><a href="#survey-intro">Survey: Americans Agree on The Presidential Candidate They Think Will Protect Their Consumer Rights</a></strong></p>
<p><strong><a href="#survey-methodology">FairShake’s Survey Methodology</a></strong></p>
<p><strong><a href="#survey-consumer-protections">Across the Aisle, Americans Agree: We Need Stronger Consumer Protections</a></strong></p>
<p><strong><a href="#survey-biden-vs-trump">Respondents Think Joe Biden Cares More About Consumer Rights and Trump More About Corporate Rights</a></strong></p>
<p><strong><a href="#survey-trump-corporate-wrongdoing">President Donald Trump Voted “Most Likely” to Turn a Blind Eye to Corporate Wrongdoing</a></strong></p>
<h2><a id="survey-intro"></a>Survey: Americans Agree on The Presidential Candidate They Think Will Protect Their Consumer Rights</h2>
<p><span>With the ongoing threat of Coronavirus and all the difficulty it has introduced into day-to-day life, </span><a href="https://www.pewresearch.org/politics/2020/08/13/election-2020-voters-are-highly-engaged-but-nearly-half-expect-to-have-difficulties-voting/"><span>49% of registered voters in the U.S. report that they expect to have difficulties when it comes time to vote</span></a><span> for a presidential nominee. This is a major uptick from October 2018,&nbsp; when only 15% reported feeling the same way.&nbsp;</span></p>
<p><span>But, despite the uncertainties and hardships 2020 has wrought, the Pew Research Center found that engagement in this presidential election is the highest this country has seen in </span><i><span>decades</span></i><span>.&nbsp;</span></p>
<p><span>In fact, </span><a href="https://www.pewresearch.org/politics/2020/08/13/views-of-the-2020-campaign-and-voting-in-november/"><span>83% of voters say it “really matters” to them who wins the presidency</span></a><span> — the highest percentage since 2000.</span></p>
<p><span>And in a time when people feel more passionate about their politics than </span><i><span>ever</span></i><span>, it may come as a surprise that there is one very important issue upon which the majority of Americans agree: </span><b>Consumer rights</b><span>.&nbsp;</span></p>
<p><span>In this <a href="https://fairshake.com/consumer-news/survey-bipartisan-favor-stronger-consumer-protections/">representative survey of over 1,000 American adults that FairShake conducted in the fall of 2020</a>, we uncovered how the majority of U.S. citizens feel about their rights as consumers — and which of the leading presidential candidates they agree is more likely to protect these rights from being violated.</span></p>
<h2><span><a id="survey-methodology"></a>FairShake’s Survey Methodology</span></h2>
<p><span>For this survey, FairShake surveyed 1,003 American adults using a Pollfish.com survey that ran online from Sept. 21, 2020, to Oct. 5, 2020.</span></p>
<p><span>Results were stratified by Pollfish to match the gender and age distribution of the U.S. population, but before accounting for stratification…&nbsp;&nbsp;</span></p>
<p><span>Respondents were:</span></p>
<ul>
<li><span>60% female</span></li>
<li><span>40% male</span></li>
</ul>
<p><span>The age breakdown of survey respondents was:</span></p>
<ul>
<li><span>7% were aged 18-24</span></li>
<li><span>28% were aged 25-34</span></li>
<li><span>29% were aged 36-44</span></li>
<li><span>16% were aged 45-54</span></li>
<li><span>20% were aged 55 and up</span></li>
</ul>
<p><span>The self-identified party affiliation of respondents was:</span></p>
<ul>
<li><span>36% Democratic Party</span></li>
<li><span>33% Republican Party</span></li>
<li><span>31% reported “no party preference” or “other”</span></li>
</ul>
<p><span>Please keep in mind that totals may not add to 100% due to rounding and, finally, enjoy our synthesis of some of the most interesting results from our survey!&nbsp;</span></p>
<h2><span><a id="survey-consumer-protections"></a>Across the Aisle, Americans Agree: We Need Stronger Consumer Protections&nbsp;</span></h2>
<p><span>In the U.S., </span><a href="https://fairshake.com/guides/consumer-protection-laws/"><span>there are federal and state laws that outline consumer rights and protect customers</span></a><span> when they interact with companies that are in a position to take advantage of them.</span></p>
<p><span>Have you ever felt cornered into using the only </span><i><span>reasonable</span></i><span> internet service provider in your town? Or wished there was more you could’ve done to fight that unfair fee you had to pay before your provider would turn your cable back on?</span></p>
<p><span>If so, you’re not alone in feeling like your consumer rights have been violated by some of the companies that have the most impact on our lives.&nbsp;&nbsp;</span></p>
<p><span>In our survey, we found that — generally speaking — the majority of Americans don’t think the current consumer protections are strong enough when it comes to limiting monopolization by service providers, controlling companies that collect our personal data, and supporting people who work in the gig economy.&nbsp;</span></p>
<p><img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg" alt="Graph showing the split between democrats and republicans on consumer protection issues." width="2022" height="2106" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-288x300.jpg 288w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-983x1024.jpg 983w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-768x800.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1475x1536.jpg 1475w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1966x2048.jpg 1966w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-288x300.jpg 288w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-983x1024.jpg 983w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-768x800.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1475x1536.jpg 1475w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1-1966x2048.jpg 1966w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/03-Image-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>With the only plurality we’ll see when it comes to the section of our survey on consumer protections, 47% of Americans are in favor of stronger government laws and regulations around monopolization by service providers — such as cable and internet companies. Only 15% think government oversight should actively be made weaker here. To break it down further, 54% of respondents who identified as Democrats are in favor of more consumer rights protections while 37% of Republicans feel the same.&nbsp;</span></p>
<p><span>In our survey, Americans agree the most on stronger governance when it comes to companies that collect consumer data — think giants like Facebook and Google. In all, 63% of respondents favor stronger consumer rights laws for these companies while only 6% think such regulations should be weaker. This is the strongest area of bipartisan agreement in our entire survey, supported by 62% of Democrats and 59% of Republicans!&nbsp;</span></p>
<p><span>When it comes to government rules and regulations that protect workers who perform contracted “gig” jobs such as driving for Uber and food delivery services like Postmates, 54% of Americans support stronger legal protections for workers while 4% are for weakening these protections. With 60% of Democrats and only 42% of Republicans in favor of better safeguarding gig workers’ rights, this gap of 18 percentage points is the largest between parties when it comes to consumer rights protections.</span></p>
<h2><span><a id="survey-biden-vs-trump"></a>Respondents Think Former Vice President Joe Biden Cares More About Consumer Rights and President Donald Trump More About Corporate Rights</span></h2>
<p><span>Now, let’s drill down a little deeper to see how respondents feel about the leading presidential candidates — former Vice President Joe Biden and incumbent President Donald Trump — when it comes to protecting consumer rights.&nbsp;</span></p>
<p><span>Again, we see Americans reach across the aisle to agree: The majority opinion is that Joe Biden cares more about the rights of individual consumers while President Donald Trump cares more about the rights of corporations.&nbsp;</span></p>
<p><span>Specifically, 56% of all respondents say they perceive President Trump as caring more about corporations while 18% think he cares more about individual consumers.</span></p>
<p><span>Meanwhile, 39% of people say Joe Biden cares more about individual consumer rights while 31% think he cares more about corporations.<img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg" alt="Graph shows respondents believe Trump will protect corporations over consumers" width="2022" height="1032" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-300x153.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1024x523.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-768x392.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1536x784.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-300x153.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1024x523.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-768x392.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1-1536x784.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/02-Image-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></span></p>
<h2><span><a id="survey-trump-corporate-wrongdoing"></a>President Donald Trump Voted “Most Likely” to Turn a Blind Eye to Corporate Wrongdoing</span></h2>
<p><span>In light of the last section about consumer versus corporate rights, it shouldn’t be shocking to hear that the majority of Americans think Trump (51%) would be more likely than Biden (29%) to turn a blind eye if a corporation violated consumer rights. It’s interesting to note that a not-small percentage (20%) of Americans think both candidates would behave the same in this situation. <img src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg" alt="Graph shows respondents believe Trump is more likely to turn a blind eye to consumer rights violations" width="2022" height="1287" srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-300x191.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1024x652.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-768x489.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1536x978.jpg 1536w" sizes="(max-width: 2022px) 100vw, 2022px" data-srcset="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg 2022w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-300x191.jpg 300w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1024x652.jpg 1024w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-768x489.jpg 768w, https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1-1536x978.jpg 1536w" data-src="https://4bvihq1vzfw92gpacq41usu0-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/01-Image-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></span></p>
<p><span>Interestingly, respondents replied as expected along party lines when asked which of these two presidential candidates would better protect their individual rights.&nbsp;</span></p>
<p><span>As for protecting consumer rights, 85% of Democrats say Biden would do a better job and 79% of Republicans think Trump would excel. When it comes to worker rights, 83% of Democrats think Biden would better preserve worker rights while 79% of Republicans say Trump would best protect workers.&nbsp;</span></p>
<h2><span>Do You Need Help Defending Your Consumer Rights?&nbsp;</span></h2>
<p><span>In an election year racked by a worldwide pandemic and a heightened level of political division, it’s comforting to know that Americans can generally agree on one thing: The importance of protecting consumers from predatory practices carried out by service provider monopolies, data-collecting giants, and the contractor-supported companies that power today’s gig economy.&nbsp;</span></p>
<p><span>If you’ve personally been taken advantage of by one of these or any </span><i><span>other</span></i><span> company, there’s finally something you can do about it.&nbsp;</span></p>
<p><a href="https://fairshake.com/start/"><span>Get in touch with FairShake today</span></a><span> and let us handle the </span><a href="https://fairshake.com/about-arbitration/"><span>arbitration process to get you the justice and compensation</span></a><span> you deserve.</span></p>
                    
                </div></div>]]>
            </description>
            <link>https://fairshake.com/consumer-news/survey-analysis-bipartisan-support-consumer-protections/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24969163</guid>
            <pubDate>Mon, 02 Nov 2020 15:33:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Turn any web page into a Twitter thread]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968969">thread link</a>) | @kossnocorp
<br/>
November 2, 2020 | https://getchirrapp.com/extension | <a href="https://web.archive.org/web/*/https://getchirrapp.com/extension">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://getchirrapp.com/extension</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968969</guid>
            <pubDate>Mon, 02 Nov 2020 15:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Faster Than TensorFlow on the GPU with Clojure (GTX 1080Ti)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968394">thread link</a>) | @dragandj
<br/>
November 2, 2020 | https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>November 2, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
A few weeks ago I've shown you how simple Clojure's
<a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() is, even compared to Keras. I've also mentioned
that it's superfast. Here's how fast it is on the GPU!
</p>

<div id="outline-container-orgc0a2ae3">
<h2 id="orgc0a2ae3">TL;DR Much faster than Keras+TensorFlow on the GPU, too!</h2>
<div id="text-orgc0a2ae3">
<p>
In the <a href="https://dragan.rocks/articles/20/Going-faster-than-TensorFlow-with-Clojure">previous article</a>, we have only compared the libraries on the CPU.
Deep Diamond was considerably faster: 368 seconds vs 509 seconds. Most readers were intrigued,
but, being skeptical as they should be, they complained that CPU performance doesn't matter
anyway, since everybody uses GPU for training convolution networks;
let's do the GPU comparison then.
</p>

<p>
Both Deep Diamond, and Keras with TensorFlow, use <a href="https://developer.nvidia.com/cudnn">Nvidia's cuDNN</a> low level performance
library under the hood, and any difference is due to the higher-level implementation.
</p>

<p>
Deep Diamond completes this training in <b>21</b> seconds while Keras + TensorFlow takes <b>35</b> seconds.
The gap even increased in favor of Deep Diamond! Now the ratio is <b>1.67</b>, in place of 1.38 on the CPU.
</p>
</div>
</div>

<div id="outline-container-org0601d75">
<h2 id="org0601d75">Keras CNN in Python</h2>
<div id="text-org0601d75">
<p>
I repeat the relevant model code for reference. We're
interested in the running time of <code>model.fit</code>, with minimal verbosity,
for 12 epochs. I'm using Nvidia's GTX 1080Ti GPU. Keras code is taken from official Keras examples.
</p>

<div>
<pre>model = Sequential<span>()</span>
model.add<span>(</span>Conv2D<span>(</span>32, kernel_size=<span>(</span>3, 3<span>)</span>,
                 activation='relu',
                 input_shape=<span>(</span>28, 28, 1<span>)</span><span>)</span><span>)</span>
model.add<span>(</span>Conv2D<span>(</span>64, <span>(</span>3, 3<span>)</span>, activation='relu'<span>)</span><span>)</span>
model.add<span>(</span>MaxPooling2D<span>(</span>pool_size=<span>(</span>2, 2<span>)</span><span>)</span><span>)</span>
model.add<span>(</span>Dropout<span>(</span>0.25<span>)</span><span>)</span>
model.add<span>(</span>Flatten<span>()</span><span>)</span>
model.add<span>(</span>Dense<span>(</span>128, activation='relu'<span>)</span><span>)</span>
model.add<span>(</span>Dropout<span>(</span>0.5<span>)</span><span>)</span>
model.add<span>(</span>Dense<span>(</span>num_classes, activation='softmax'<span>)</span><span>)</span>

model.compile<span>(</span>loss=keras.losses.categorical_crossentropy,
              optimizer=Adam<span>(</span>learning_rate=0.01<span>)</span>,
              metrics=<span>[</span>'accuracy'<span>]</span><span>)</span>

s = time.time_ns<span>()</span>
model.fit<span>(</span>x_train, y_train,
          batch_size=128,
          verbose=2,
          epochs=12<span>)</span>
e = time.time_ns<span>()</span>
print<span>(</span><span>(</span>e-s<span>)</span>/<span>(</span>10**9<span>)</span>, <span>" seconds"</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org7c1e24e">
<h2 id="org7c1e24e">Deep Diamond CNN in Clojure</h2>
<div id="text-org7c1e24e">
<p>
In Clojure, we're measuring the runtime of the <code>train</code> function.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
            <span>(</span>dropout<span>)</span>
            <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
            <span>(</span>dropout<span>)</span>
            <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf9c6799">
<h2 id="orgf9c6799">The books</h2>
<div id="text-orgf9c6799">
<p>
The book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>, in interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Going-faster-than-Tensorflow-on-GPU-with-Clojure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968394</guid>
            <pubDate>Mon, 02 Nov 2020 14:25:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Done Than Perfect Podcast]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24968318">thread link</a>) | @daolf
<br/>
November 2, 2020 | https://userlist.com/podcast/ | <a href="https://web.archive.org/web/*/https://userlist.com/podcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<section>  <div>
    <div>
      

      <p>Welcome to Better Done Than Perfect — a podcast for SaaS founders and product people. In the first season we talk about user onboarding with fellow founders and guest experts.</p>

        


      
    </div>

    <p><img src="https://d33wubrfki0l68.cloudfront.net/0ed65308e1a87711e359afe19086b4c54ad8a837/f507a/assets/better-done-than-perfect-logo.png" alt="Better Done Than Perfect" title="Better Done Than Perfect">
    </p>
  </div>
</section>
<section>  <div id="episodes">
    <h2>Latest episodes 🎙</h2>

    <p>
      This season is dedicated to user onboarding. Tune in to hear real-life stories from seasoned SaaS founders and SaaS Experts.
    </p>

    <div>
        <article>
    <a href="https://userlist.com/podcast/jtbd-for-user-onboarding-with-ramli-john/"><img src="https://d33wubrfki0l68.cloudfront.net/7b6e78b825cad84c106aedfabe001c762f7ea595/109a3/assets/bdtp_ramli_john.png" alt="JTBD for User Onboarding with Ramli John" title="JTBD for User Onboarding with Ramli John"></a>

  <h3><a href="https://userlist.com/podcast/jtbd-for-user-onboarding-with-ramli-john/">JTBD for User Onboarding with Ramli John</a></h3>
  <p>You’ll hear about Ramli’s EUREKA user onboarding framework based on Jobs to Be Done, as well as his insights on segmentation, minimizing friction, success metrics, analytic tools, and more.</p>

  <a href="https://userlist.com/podcast/jtbd-for-user-onboarding-with-ramli-john/">View episode</a>
</article>

        <article>
    <a href="https://userlist.com/podcast/carrots-sticks-measuring-success-with-adii-pienaar/"><img src="https://d33wubrfki0l68.cloudfront.net/3a05d1826dd0958a0766b901ae417483e916faee/252d4/assets/bdtp_adii_pienaar.png" alt="Carrots, Sticks &amp; Measuring Success with Adii Pienaar" title="Carrots, Sticks &amp; Measuring Success with Adii Pienaar"></a>

  <h3><a href="https://userlist.com/podcast/carrots-sticks-measuring-success-with-adii-pienaar/">Carrots, Sticks &amp; Measuring Success with Adii Pienaar</a></h3>
  <p>You’ll hear about Adii’s successes and failures in user onboarding, as well as his views on email marketing, task simplification, concierge onboarding, success metrics, segmentation, and much more.
</p>

  <a href="https://userlist.com/podcast/carrots-sticks-measuring-success-with-adii-pienaar/">View episode</a>
</article>

        <article>
    <a href="https://userlist.com/podcast/value-paths-fireballs-with-samuel-hulick/"><img src="https://d33wubrfki0l68.cloudfront.net/1834ebc7385231ed1ace6e4ed3c9459f2137b586/0fdeb/assets/bdtp-samuel-hulick.png" alt="Value Paths &amp; Fireballs with Samuel Hulick" title="Value Paths &amp; Fireballs with Samuel Hulick"></a>

  <h3><a href="https://userlist.com/podcast/value-paths-fireballs-with-samuel-hulick/">Value Paths &amp; Fireballs with Samuel Hulick</a></h3>
  <p>You'll learn Samuel's take on the "ideal" user onboarding experience, as well as his Mario-fireball concept, Value Paths, success metrics, Jobs to Be Done, segmentation, and his invaluable advice for SaaS founders.
</p>

  <a href="https://userlist.com/podcast/value-paths-fireballs-with-samuel-hulick/">View episode</a>
</article>

    </div>

    
  </div>
</section>

        <section>  <div>
    <p><img src="https://d33wubrfki0l68.cloudfront.net/9eae0f5cf8899eef3658e01546feeb73cd36b556/eccac/assets/better-done-than-perfect-tshirt.png" lazy="true" width="426" alt="">
    </p>

    <div>
        <h2>Subscribe to win your free shirt</h2>

        <p>Join our mailing list below, learn about new episodes as they go live, and win one of our custom-designed shirts from Cotton Bureau.</p>

      

    </div>
  </div>
</section>

  </div></div>]]>
            </description>
            <link>https://userlist.com/podcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968318</guid>
            <pubDate>Mon, 02 Nov 2020 14:18:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cellular immunity to SARS-CoV2 found at 6 months in non-hospitalised individuals]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24968034">thread link</a>) | @ageitgey
<br/>
November 2, 2020 | https://www.uk-cic.org/news/cellular-immunity-sars-cov-2-found-six-months-non-hospitalised-individuals | <a href="https://web.archive.org/web/*/https://www.uk-cic.org/news/cellular-immunity-sars-cov-2-found-six-months-non-hospitalised-individuals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="UK-CIC logo" data-entity-type="file" data-entity-uuid="8a702f0f-0ed4-43c4-b10a-d98dba34a018" src="https://www.uk-cic.org/sites/default/files/inline-images/UK-CIC%20logo%20square%20300pix.jpg">Cellular (T cell) immunity against SARS-CoV-2 is likely to be present within most adults six months after primary infection, a new pre-print on bioRxiv suggests. The research from the UK Coronavirus Immunology Consortium (UK-CIC), Public Health England and Manchester University NHS Foundation Trust&nbsp;demonstrates robust T cell responses to SARS-CoV-2 virus peptides at this timepoint in all participants following asymptomatic or mild/moderate COVID-19 infection.</p>

<p>A key question is whether previous infection with SARS-CoV-2 results in immunity to reinfection, and if so for how long. The immune system is extremely complex and there are many different potential routes whereby it can generate immunity to a disease post-infection. This study examines the role of T cells in contributing to immunity against SARS-CoV-2 at six months post infection.</p>

<p>As part of UK-CIC, researchers from the University of Birmingham, Public Health England, Manchester University NHS Foundation Trust (MFT) and&nbsp;NIHR Manchester Clinical Research Facility collected serum and blood samples from a cohort of more than 2,000 clinical and non-clinical healthcare workers including 100 individuals who tested sero-positive for SARS-CoV-2 in March/April 2020 (average age 41 (range 22–65); 23 men, 77 women). All 100 individuals experienced either mild/moderate symptoms or were asymptomatic (56 versus 44 people) and none were hospitalised for COVID-19. Serum samples were collected monthly to measure antibody levels, and blood samples were taken after six months to assess the cellular (T cell) response. A range of analyses were carried out to assess different aspects of the T cell response including the magnitude of response and the response to different proteins from SARS-CoV-2. Carrying out these cellular analyses is much more complex than antibody studies – but this study of 100 individuals is one of the largest in the world to date in this field.</p>

<p>T cell responses were present in all individuals at six months after SARS-CoV-2 infection. The cellular immune response was directed against a range of proteins from the virus, including the Spike protein that is being used in most vaccine studies. However, comparable immunity was present against additional proteins, such as nucleoprotein, which suggests that these may be of value for incorporation in future vaccine protocols. This indicates that a robust cellular memory against the virus persists for at least six months.</p>

<p>The size of T cell response differed between individuals, being considerably (50%) higher in people who had experienced symptomatic disease at the time of infection six months previously. Further research will be needed to determine the significance of this finding. It is possible that heightened cellular immunity might provide increased protection against re-infection in people with initial symptomatic infection, or that asymptomatic individuals are simply able to fight off the virus without the need to generate a large immune response.</p>

<p>Antibodies are also a crucial component of immune defence and cellular immunity was strongly correlated with the peak level of the antibody response. Furthermore, larger cellular responses appeared to protect against antibody ‘waning’ over time, again suggesting the need to ensure that cellular immune responses are elicited in vaccine regimens.</p>

<p>Overall, these findings indicate a robust cellular (T cell) immune response against SARS-CoV-2 at six months post-infection. These findings will feed not only into our understanding of how immunity to SARS-CoV-2 works but also help inform future vaccine strategies. Further research is now needed to assess whether this immune response is maintained over the longer term and to better understand how strength of cellular immune response corresponds to likelihood of reinfection.</p>



<p><b>Professor Paul Moss, UK Coronavirus Immunology Consortium lead from University of Birmingham, said:</b></p>

<blockquote>
<p>“Understanding what constitutes effective immunity to SARS-CoV-2 is extremely important, both to allow us to understand how susceptible individuals are to reinfection and to help us develop more effective COVID-19 vaccines.</p>

<p>“To our knowledge, our study is the first in the world to show robust cellular immunity remains at six months after infection in individuals who experienced either mild/moderate or asymptomatic COVID-19. Interestingly, we found that cellular immunity is stronger at this time point in those people who had symptomatic infection compared with asymptomatic cases. We now need more research to find out if symptomatic individuals are better protected against reinfection in the future.</p>

<p>“Our knowledge of SARS-CoV-2 infection is increasing all the time. While our findings cause us to be cautiously optimistic about the strength and length of immunity generated after SARS-CoV-2 infection, this is just one piece of the puzzle. There is still a lot for us learn before we have a full understanding of how immunity to COVID-19 works. While we increase our understanding, whether we think we have previously had COVID-19 or not, we all should still follow Government guidelines on social distancing to ensure we play our part in minimising the spread of COVID-19 within our communities.”</p>
</blockquote>



<p><b>Dr Shamez Ladhani, Consultant epidemiologist at Public Health England and the study’s author, said:</b></p>

<blockquote>
<p>“Cellular immunity is a complex but potentially very significant piece of the COVID-19 puzzle, and it’s important that more research be done in this area. However, early results show that T-cell responses may outlast the initial antibody response, which could have a significant impact on COVID vaccine development and immunity research.</p>

<p>“Our thanks go to the more than 2,000 staff who have volunteered to provide monthly blood samples since the beginning of the pandemic. Recruiting donors so early in 2020 allowed us significantly longer follow-up than many similar studies have achieved so far.”</p>


</blockquote>

<p><b>Professor Fiona Watt, Executive Chair of the Medical Research Council, part of UKRI, said: </b></p>

<blockquote>
<p>“This study shows the benefit of funding world-leading immunologists through the UK Coronavirus Immunology Consortium. Researchers investigated whether previous infection with SARS-CoV-2 results in immunity to reinfection. They found that a robust cellular memory against the virus persists for at least six months. This is promising news – if natural infection with the virus can elicit a robust T cell response then this may mean that a vaccine could do the same.”</p>
</blockquote>



<p><strong>Dr Shazaad Ahmad, Consultant Virologist at Manchester University NHS Foundation Trust (MFT) and Principal Investigator for the study at MFT, said:&nbsp;</strong></p>

<blockquote>
<p>“As one of the leading NHS trusts for research and innovation, known for our strong track record of recruiting to studies, we were selected to rapidly enlist a cohort of healthcare workers to take part in this important research – and 1,200 MFT staff swiftly answered the call.</p>

<p>“The study was delivered at the NIHR Manchester Clinical Research Facilities at Manchester Royal Infirmary and Wythenshawe Hospital (both part of MFT), which provide dedicated research space and highly-trained staff. I would like to say how grateful I am to my colleagues for continuing to deliver and participate in this study, as without them we would not be able to report the findings, which could have a huge global impact."<br>
&nbsp;</p>


</blockquote>

<p>Please note, this paper is a pre-print reporting preliminary data that has not yet been peer-reviewed.</p>

<p>----------Ends----------</p>

<p><u><strong>Notes for editors</strong></u><br>
This press release reports on findings in the following pre-print which is <a href="http://biorxiv.org/cgi/content/short/2020.11.01.362319">available to read on bioRxiv</a>:<br>
Zuo <em>et al. </em>2020 Robust SARS-CoV-2-specific T-cell immunity is maintained at 6 months following primary infection<br>
Journalists - please contact the press team for a copy of the preprint, or use the link above to find it directly.&nbsp;</p>

<p>The UK Coronavirus Immunology Consortium brings together UK 19 immunology centres of excellence to research how the immune system interacts with SARS-CoV-2 to help us improve patient care and develop better diagnostics, treatments and vaccines against COVID-19. It is jointly funded by UK Research and Innovation (UKRI) and National Institute for Health Research (NIHR) and supported by the British Society for Immunology.<br>
Website: <a href="https://www.uk-cic.org/news/www.uk-cic.org">www.uk-cic.org</a>&nbsp;<br>
Twitter: <a href="https://www.uk-cic.org/news/www.twitter.com/UKCICstudy">@UKCICstudy</a><br>
Email: <a href="mailto:uk-cic@immunology.org">uk-cic@immunology.org</a></p>

<p><strong>Press contacts</strong><br>
Gabriela De Sousa<br>
Email: <a href="mailto:g.desousa@immunology.org%C2%A0">g.desousa@immunology.org&nbsp;</a><br>
Jennie Evans<br>
Tel: 07703 807 444<br>
Email: <a href="mailto:j.evans@immunology.org">j.evans@immunology.org</a></p>
</div></div>]]>
            </description>
            <link>https://www.uk-cic.org/news/cellular-immunity-sars-cov-2-found-six-months-non-hospitalised-individuals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24968034</guid>
            <pubDate>Mon, 02 Nov 2020 13:45:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get started with permaculture when all you have is a balcony]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24967225">thread link</a>) | @roboben
<br/>
November 2, 2020 | https://permapeople.org/blog/2020/10/12/get-started-with-permaculture-on-a-balcony.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/10/12/get-started-with-permaculture-on-a-balcony.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/permaculture-balcony.jpg" alt="Two potatoes in an Ikea bag"></p>

<p>First of all, thank you for everyone reaching out to me after my last blog post. It sparked many good conversations about permaculture in general and what people want to see on Permapeople specifically. This post is based on feedback I got, where someone reached out and asked: “I am interested in permaculture but only have a balcony!”</p>

<p>The idea of Permapeople is to create a better way to get information about growing your own plants in a <a href="https://medium.com/@designforsustainability/beyond-sustainability-we-are-living-in-the-century-of-regeneration-4f2b116a65d1"><del>sustainable</del>regenerative</a> way. Many people are hesitant because they live in apartments and don’t have access to some growing space.
When I got into permaculture, the available and actionable information was scattered and hard to use. Specific urban growing instructions on balconies or windowsills were almost nonexistent.
This is why I think it is a great idea to write about how you can start with permaculture, even if you only have a balcony.</p>

<p><strong>For this blog post, I used a new attribute in the database. If you <a href="https://permapeople.org/search?Good+for+containers=true">click here</a>, you’ll find all the plants that are great to be grown in a container and are perfect for the urban permaculture gardener.</strong></p>

<p>Permaculture is a design system with a few general principles, which you can use one a balcony too. I reinterpreted a few here and added some beginners’ tips. The goal is to get started, nothing more!</p>

<h3 id="observe-design--plan">Observe, Design &amp; Plan</h3>
<p>Every good project starts with a plan. The very first thing you want to think about is why you actually want to grow stuff: Is it because you want some fresh herbs or maybe you want to watch bees and butterflies on nice and beautiful smelling flowers, or maybe you want to grow for medicinal uses. Ensure you have a rough goal in mind, which will help you decide when designing your balcony.</p>

<p>Observe your balcony and look for light conditions, wind, and other factors, which might be important: Some plants don’t mind wind but need full sun so you can put them in front. Some cannot bear wind but need a lot of warmth, maybe but them in the back next to a wall, which can save heat overnight. Check if you have a drain to collect water or any other way to collect it. Think about how you can do the work you have to, where to get water from, etc.
Keep looking at your plants from day to day and try to understand: Do they need more water or less, more sun or less, or any other problems that may arise.</p>

<h3 id="keep-inputs-low">Keep Inputs Low</h3>
<p>When you can start setting up your baclony, please don’t check at first online all the things you need to buy. Rather check your basement and storage if you have old plastic boxes or anything else you can use to grow plants in. Garden tools can be lend from friends, family, or neighbors for the first time. Soil, compost, and seeds can be obtained from them too. Promise them a share of the yield if everything works out. Lookout for perennialplants, for example <a href="https://permapeople.org/plants/strawberry">Strawberries</a> since you only need to plant them one time. Only buy if you really have to.
Your own time and energy is another input most people forget, but you definitely want to keep it low. Only grow the plants you have the time to take care of and are resilient to a few days of neglect.</p>

<h3 id="chop-drop--only-add-to-the-top">Chop, Drop &amp; Only Add to the Top</h3>
<p>When it comes to the actual task of growing, I think this is the most and simple thing you can do to maintain good soil for your plants: Continuously add a lot of organic matter to the top of your containers.
Use your kitchen scraps, cut them small, and drop them directly on top of the soil. At the end of the season, chop away the old plants, cut them small, and drop them on top. Make sure to only cut away what is coming out of the soil and leave the soil undisturbed. Old roots in the soil are perfect organic matter when decomposing. <a href="https://permapeople.org/plants/tomato">Tomatoes</a> love being grown in the compost of old tomatoes.
Every organic matter you put on top of your containers will decompose by itself. There is no need to maintain a separate compost container.</p>

<h3 id="start-small">Start Small</h3>
<p>Another important thing is that you should start small not to get overwhelmed and drop everything before success. Even if you grow just a few plants initially, the amount of learning and reward will be huge. Go from there, learn from your experience, and extend your growing projects season by season.
It is more important to get any yield than a huge amount of yield at the end of the season, so focus on that!</p>

<h3 id="diversify-and-experiment">Diversify and Experiment</h3>
<p>While starting small is important, don’t only grow one plant and get disappointed when it fails. There can be many reasons why the plant didn’t grow. Remember to observe frequently and reiterate on your design. Start with 2-3 plants you like to eat or look at and see how they go. If you want, you can also try to grow one plant and different varieties and locations on your balcony. Remember: Always keep experimenting and maximize the learning!</p>

<p>I hope this helps a few people getting started with permaculture, even if they just have minimal space to grow in. If you have any questions or suggestions that you want to see in this blog, please reach out to hello at permaculture dot org. I will read and answer every email.
Also, make sure to join the newsletter below.</p>

<p>Happy growing 🌱✌️,</p>

<p>Ben</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/10/12/get-started-with-permaculture-on-a-balcony.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24967225</guid>
            <pubDate>Mon, 02 Nov 2020 12:11:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coral Griefs: Finding Hope Amidst Loss]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24966805">thread link</a>) | @dnetesn
<br/>
November 2, 2020 | http://oceans.nautil.us/feature/633/coral-griefs-finding-hope-amidst-loss | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/633/coral-griefs-finding-hope-amidst-loss">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>A</span>s smoke from the western North American megafires migrated across the Pacific in early September of 2020, Aziz Mulla flew with a small team of scientists to Lanyu, a remote island 40 miles off the southeastern coast of Taiwan. They were responding to reports of a different kind of wildfire. While no flames scorched forests, the hottest Northern Hemisphere summer on record caused dramatic increases in water temperature around the islandâ€™s renowned coral reefs.</p>

<p>Mulla and his team took a small diving boat out to a section of reef they have studied for years. He describes the location as one of the most gorgeous diving sites in the world. That morning the sea was as calm as a lake. Its turquoise waters glistened in the sunlight. In the distance, the steep hills of Lanyu, also known as Orchid Island, were covered in a shaggy emerald.</p>
<p>â€œI remember getting nervous about the dive while on the boat, which isnâ€™t something that usually happens,â€� says Mulla, a coral ecologist at Academia Sinica, Taiwanâ€™s national university, who has made thousands of dives all over the world. From the boat, Mulla says the destruction was obvious. Corals that should have been a palette of bright hues now glistened like bone. The heat had caused them to expel their color- and life-giving symbiotic algae, a phenomenon known as bleaching that can lead to the coralsâ€™ starvation and death.</p>
<p>Having developed an intimate bond with a particular species of coral, <em>Pocillopora verrucosa</em>, Mulla dove immediately to one of the animals for an up-close look. â€œThe tips of its branches were burnt,â€� he says.&nbsp; â€œIt was as if someone had taken a lighter to them.â€�</p>
<p>Lanyuâ€™s reef was bleached to depths as low as 100 feet. The shrimp, other crustaceans, and small fish who usually live on top of coral were noticeably absent. Larger fish like groupers and parrotfish were also eerily scarce. And the damage was not unique to just that section of reef. In fact, so many of Lanyuâ€™s formerly healthy reefs were bleached that a luminous halo had formed around the island.</p>

<p><span>T</span>he term <em>ecological grief</em> is relatively new in the scientific lexicon but the pain and despair it signifies have been heavily felt over the past few decades as climate change and destructive activities have erased ice shelves, forests, cherished species, and even killed humans. A related term is <em>solastalgia, </em>a neologism <a href="https://www.researchgate.net/publication/5820433_Solastalgia_The_Distress_Caused_by_Environmental_Change" target="_blank">coined by environmental philosopher Glenn Albrecht</a> to signify the existential distress caused by ecological destruction. Climate-induced changes cast a particularly dark shadow. Even as we look at beloved, still-intact landscapes and ecosystems, we know what could soon happen to them..&nbsp;</p>
<p>The terms ask us to consider not only the physical toll of climate change on the environment, but to assess how its decline affects our own mental health. Since scientists have a front-row seat, many bear the weight of this grief and anxiety; in response some communities of researchers have set up <a href="https://www.cbsnews.com/news/the-good-grief-network-support-group-helps-to-deal-with-psychological-effects-of-climate-change/" target="_blank">online support groups</a> to share their experiences and find comfort. Because the effects of climate change on corals can happen so quickly, as in the reefs off Lanyu, marine biologists may be especially traumatized.</p>
<p>â€œItâ€™s actually tragic,â€� says Charles Sheppard of the University of Warwick, who has studied coral reefs in the Chagos Archipelago for more than 40 years. â€œOn a dark night, I really grieve. In fact, some other scientists I know have actually shed tears underwater while scuba diving after seeing the rubble caused by a recent heat wave.â€�</p>
<p>The reefs he studies are some of the worldâ€™s finest. Due to their isolation and the territoryâ€™s ban on commercial fishing, Sheppard describes them as Earthâ€™s reef â€œlaboratoryâ€�—as close reefs now get to baseline perfection, that incredibly rare state of being unaffected by human interference. Sheppard recalls how, earlier in his career, he took other scientists diving for the first time in the Archipelago. They gushed about the reefsâ€™ nearly pristine condition, with thousands of species thriving alongside one another in a kaleidoscope of life.&nbsp;</p>
<p>Even so, many reefs in the Chagos Archipelago have been bleached, most recently during back-to-back extreme heat episodes in 2016 and 2017. In his latest paper, â€œ<a href="http://coralreefs.org/wp-content/uploads/2018/12/Reef_Encounter_Jul_2020_lo-res.pdf%252523page=28" target="_blank">Coral wreaths and the rise of phoenix coral</a>,â€�&nbsp;Sheppard describes a vicious feedback loop: not only are there fewer coral larvae, but less habitat for them to colonize. Much of the Archipelagoâ€™s reefs have turned into what he calls â€œliquid sandpaper.â€�&nbsp;â€œMy suggestion with this paper was that weâ€™ve reached a tipping point,â€� Sheppard says. â€œLess and less corals are being produced and they now have less space to settle on. Itâ€™s a slippery path to extinction, really.â€�</p>
<blockquote><strong>â€œ</strong>We can be optimistic, but we also have to be realistic.â€�</blockquote>
<p>Sheppard also grieves for the impact of coral deaths on humans. The people who are â€œgoing to suffer the most are not the tourists,â€� he says. â€œItâ€™s the people who harvest a living day by day and live a hand-to-mouth existence.â€� Nearly half a billion people rely on coral reefs for fish protein, says Sheppard, and climate change will kill many of them.</p>
<p>Nevertheless Sheppard finds ways to stay optimistic and keep moving. â€œI know Iâ€™ll be dead in 30 years,â€� he says, â€œbut I still will go to the doctor now if something is wrong with me. A human doesnâ€™t say, â€˜Well, whatâ€™s the point if Iâ€™m going to die anyway?â€™ Of course not, there are things to do!â€� He advocates for more research on reefs and outreach to the public—and despite his grim forecast, he wrote in that last paper that â€œa recovery is possible again.â€� It will require heat waves to be less extreme than predicted, and perhaps for people to take a hands-on approach to managing the reefs, and even then wonâ€™t be guaranteed, but thereâ€™s still a chance.&nbsp;</p>
<p>Back in Taiwan, Mulla deals with ecological grief primarily through teaching others, including the public but also friends and family, about what is happening to corals. â€œHaving them experience the same empathy I feel, helps a lot,â€� he says, â€œForest fires are extremely easy to see, but coral reefs are hidden below the surface—and most people think theyâ€™re rocks.â€� Education, Mulla believes, is a necessary step to decreasing greenhouse gases in the atmosphere.&nbsp;</p>
<p>Mulla still has hope. He points to a 2016 study, â€œ<a href="https://www.researchgate.net/publication/303980691_Bright_spots_among_the_world's_coral_reefs" target="_blank">Bright spots among the worldâ€™s coral reefs</a>,â€�&nbsp;which described 15 exceptionally vibrant reefs—some in remote, relatively pristine locations, but others flourishing near places where many people live. These reefs may hold lessons for protecting others, even in a rapidly changing world.&nbsp;</p>
<p>Among the bright spots were Taiwanâ€™s reefs, making this summerâ€™s catastrophic bleaching all the more tragic and also a pressing research subject for Mulla and his team, who are hurrying to understand which coral species will return and how they will respond to further warming events. Like Sheppard in the Indian Ocean, Mulla thinks Taiwanâ€™s reefs are reaching a tipping point. â€œIn 2050, I think weâ€™re going to be looking back at 2020 and think we had it pretty good,â€� he says. â€œWill we have coral reefs in 2050? Yes. Will they look the same? Probably not. We can be optimistic, but we also have to be realistic.â€�</p>

<p><span>I</span>tâ€™s difficult to imagine the grief Mulla and Sheppard must feel when witnessing the destruction of reefs theyâ€™ve studied so closely. I can, however, identify with their solastalgia, particularly this summer of 2020,&nbsp;as the West exploded into fires that <a href="https://www.nytimes.com/2020/09/15/us/oregon-fires-california.html" target="_blank">burned 5 million acres </a>and choked half the hemisphere with smoke.</p>
<p>Much of that smoke was the remnants of cherished trees, plants, animals, and fungi in places Iâ€™ve known well. While Iâ€™ve never been scuba diving, I imagine witnessing mass bleaching is like moping past the burn zone of a devastating wildfire, like I did after this yearâ€™s Dome Fire, which burned 43,248 acres in Californiaâ€™s Mojave National Preserve where stood the densest Joshua tree forest in the world. Instead of the bleached slopes of white Mulla described, I saw blackened stands of snags, charred ground cover, and the burnt corrals of a nearby ranch. Another fire this summer took a nearby canyon in my home state of Colorado, and I now breathe the smoke of one still aflame on treasured mountains above Los Angeles.</p>
<p>These forests will not regenerate in our lifetime. Perhaps they wonâ€™t even look the same for our great-great-grandchildren. It is a lot to take in: the worldâ€™s forests and oceans on fire at the same time. I find buoyancy, though, in every expert I interview who has dedicated their life to finding solutions. Itâ€™s proof that there are people who will put themselves on the front lines of environmental trauma to find knowledge that will help our planet and the people who rely upon it.</p>

<ul><li> is a freelance writer based in Los Angeles, California. His recent work has appeared in The New York Times,  Powder, and Outside. Follow him on Twitter <a href="https://twitter.com/mileswgriffis">@mileswgriffis</a> and see more of his work at <a href="http://www.confetti-westerns.com/">www.confetti-westerns.com</a>.
www.confetti-westerns.com</li></ul>
<p>Research by Charles Sheppard was funded by the Bertarelli Foundation.&nbsp;More information about its marine science programme can be found at&nbsp;<a href="http://www.marine.science/" target="_blank">www.marine.science</a></p>
<p>Lead image: At left, reefs in American Samoa in December 2014; at middle, those same reefs two months later, after a bleaching event; at right, the reefs in August 2015, after they've started to regenerate. Credit:&nbsp;The Ocean Agency / XL Catlin Seaview Survey</p>
    </article></div>]]>
            </description>
            <link>http://oceans.nautil.us/feature/633/coral-griefs-finding-hope-amidst-loss</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966805</guid>
            <pubDate>Mon, 02 Nov 2020 11:16:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 20kg hybrid drone that can fly at 50kmh for 4 hours]]>
            </title>
            <description>
<![CDATA[
Score 143 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24966540">thread link</a>) | @giuliomagnifico
<br/>
November 2, 2020 | https://www.quaternium.com/uav/hybrix-drone/ | <a href="https://web.archive.org/web/*/https://www.quaternium.com/uav/hybrix-drone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
	<div>
							
<article id="post-82" class="page">
	<div>
		<section><div><p><h2>The leader of hybrid multirotors</h2></p></div></section><section><div><div>
	<div>
		
		<figure>
			<p><img width="977" height="607" src="https://www.quaternium.com/wp-content/uploads/2017/08/hybrix-render03-1.jpg" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/hybrix-render03-1.jpg" alt="HYBRIX.20 IS THE FIRST HYBRID (PETROL-ELELTRIC) MULTIROTOR IN THE MARKET" data-srcset="https://www.quaternium.com/wp-content/uploads/2017/08/hybrix-render03-1.jpg 977w, https://www.quaternium.com/wp-content/uploads/2017/08/hybrix-render03-1-300x186.jpg 300w" data-sizes="(max-width: 977px) 100vw, 977px" srcset="https://www.quaternium.com/wp-content/uploads/2017/08/hybrix-render03-1.jpg 977w, https://www.quaternium.com/wp-content/uploads/2017/08/hybrix-render03-1-300x186.jpg 300w"></p>
		</figure>
	</div>
</div><div><h2>EMBRACE THE FUTURE</h2><p>HYBRiX 2.1 is a unique multirotor that provides up to 4 hours of operational flight time with only 25 kg MTOW.<br>
Its unique features make this hybrid drone a very versatile platform that will help you accomplish your missions faster than ever before.</p></div></div></section><section></section><section><div><div>
	<div>
		
		<figure>
			<p><img width="97" height="97" src="https://www.quaternium.com/wp-content/uploads/2017/08/fuel-electric.png" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/fuel-electric.png" alt="Hybrid technology with petrol accesible anywhere"></p>
		</figure>
	</div>
<h2>HYBRID TECHNOLOGY</h2><p>The advantages of batteries and fuel combined to maximize power and efficiency.</p></div><div>
	<div>
		
		<figure>
			<p><img width="97" height="97" src="https://www.quaternium.com/wp-content/uploads/2017/08/removable-arms.png" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/removable-arms.png" alt="for easy transport and quick deployment"></p>
		</figure>
	</div>
<h2>REMOVABLE ARMS</h2><p>Easy to set up for work, allows transportation and fast deployment by one person.</p></div><div>
	<div>
		
		<figure>
			<p><img width="97" height="97" src="https://www.quaternium.com/wp-content/uploads/2017/08/fast-petrol-recharging.png" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/fast-petrol-recharging.png" alt="No need to charge batteries, only petrol"></p>
		</figure>
	</div>
<h2>FAST PETROL RECHARGING</h2><p>No need to wait a long time to charge batteries, only refuel and you are ready to fly again.</p></div><div>
	<div>
		
		<figure>
			<p><img width="97" height="97" src="https://www.quaternium.com/wp-content/uploads/2017/08/longest-flight-time.png" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/longest-flight-time.png" alt="2 hours operative time with maximum payload"></p>
		</figure>
	</div>
<h2>THE LONGEST FLIGHT TIME</h2><p>2 hours of continuos aerial operation with max. payload even on adverse weather conditions.</p></div></div></section><section><div><div><h2>EXTREME ENDURANCE</h2><div><p>Thanks to its hybrid power system and its unique design, HYBRiX.20 outperforms any electric multicopter by 10 times on endurance, enabling longer and more ambitious aerial missions.</p>
<p>Even with maximum payload, this hybrid multirotor RPAS can get over 2 hours of flight time. Even&nbsp;more time required? Just re-fuel and get back aloft in less than 10 minutes.</p>
</div></div><div>
	<div>
		
		<figure>
			<p><img width="1920" height="1327" src="https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore.jpg" data-src="https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore.jpg" alt="hybrix long endurance drone" data-srcset="https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore.jpg 1920w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore-300x207.jpg 300w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore-1024x708.jpg 1024w" data-sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore.jpg 1920w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore-300x207.jpg 300w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-offshore-1024x708.jpg 1024w"></p>
		</figure>
	</div>
</div></div></section><section><div><div>
	<div>
		
		<figure>
			<p><img width="1290" height="861" src="https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019.jpg" data-src="https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019.jpg" alt="transport case for HYBRiX drone" data-srcset="https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019.jpg 1290w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019-300x200.jpg 300w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019-1024x683.jpg 1024w" data-sizes="(max-width: 1290px) 100vw, 1290px" srcset="https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019.jpg 1290w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019-300x200.jpg 300w, https://www.quaternium.com/wp-content/uploads/2020/02/HX-transport-case-2019-1024x683.jpg 1024w"></p>
		</figure>
	</div>
</div><div><h2>QUICK DEPLOYMENT</h2><div><p>HYBRiX has been developed for easy operation. The removable arms allow for comfortable shipment and deployment. It can be quickly set up and operated by two people, with independent controls for the drone and its payload.</p>
<p>Its transport case protects HYBRiX aircraft during during the trips to the area of operation and it fits in the trunk of a standard car.</p>
</div></div></div></section><section><div><div><h2>CONTROL STATION</h2><div><p>Take full control of your HYBRiX with its advanced Ground Control Station. Depending on the payload, it can include a second transmitter with video reception.</p>
<p>This professional GCS allows you to control the aircraft and its payload independently, both with digital communications. Its comfortable and light design is perfect for carrying long missions.</p>
</div></div><div>
	<div>
		
		<figure>
			<p><img width="1290" height="1109" src="https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS.jpg" data-src="https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS.jpg" alt="HYBRiX portable GCS" data-srcset="https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS.jpg 1290w, https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS-300x258.jpg 300w, https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS-1024x880.jpg 1024w" data-sizes="(max-width: 1290px) 100vw, 1290px" srcset="https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS.jpg 1290w, https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS-300x258.jpg 300w, https://www.quaternium.com/wp-content/uploads/2020/02/Horus-GCS-1024x880.jpg 1024w"></p>
		</figure>
	</div>
</div></div></section><section><div><div>
	<div>
		
		<figure>
			<p><img width="1280" height="800" src="https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner.jpg" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner.jpg" alt="automatic missions with ye first hybrid drone petrol electric" data-srcset="https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner.jpg 1280w, https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner-300x188.jpg 300w, https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner-1024x640.jpg 1024w" data-sizes="(max-width: 1280px) 100vw, 1280px" srcset="https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner.jpg 1280w, https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner-300x188.jpg 300w, https://www.quaternium.com/wp-content/uploads/2017/08/mission-planner-1024x640.jpg 1024w"></p>
		</figure>
	</div>
</div><div><h2>MISSION PLANNER</h2><div><p>With HYBRiX and its Mission Planner you will take full control of the aerial mission, setting an automatic flight plan with waypoints and emergency functions, retrieving relevant data on real time and shifting to manual pilot mode at any desired time.</p>
<p>HYBRiX carries an open-source Flight Controller based on Ardupilot and compatible with the most popular sensors and UAV accessories.</p>
</div></div></div></section><section></section><section><div><div>
	<div>
		
		<figure>
			<p><img width="603" height="762" src="https://www.quaternium.com/wp-content/uploads/2017/08/medidas-HYBRiX.png" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/medidas-HYBRiX.png" alt="Hybrix measurements, the first hybrid drone" data-srcset="https://www.quaternium.com/wp-content/uploads/2017/08/medidas-HYBRiX.png 603w, https://www.quaternium.com/wp-content/uploads/2017/08/medidas-HYBRiX-237x300.png 237w" data-sizes="(max-width: 603px) 100vw, 603px" srcset="https://www.quaternium.com/wp-content/uploads/2017/08/medidas-HYBRiX.png 603w, https://www.quaternium.com/wp-content/uploads/2017/08/medidas-HYBRiX-237x300.png 237w"></p>
		</figure>
	</div>
</div><div><div><h3>Hybrix 2.1</h3><div>
<table>
<tbody>
<tr>
<td>MTOW</td>
<td>20 Kg&nbsp; // 25 Kg</td>
</tr>
<tr>
<td>EMPTY WEIGHT</td>
<td>13 Kg</td>
</tr>
<tr>
<td>MAX PAYLOAD</td>
<td>5 Kg&nbsp; // 10 Kg</td>
</tr>
<tr>
<td>ENDURANCE (FULL LOAD)</td>
<td>2 h</td>
</tr>
<tr>
<td>MAX. ENDURANCE</td>
<td>4 h</td>
</tr>
<tr>
<td>CRUISE SPEED</td>
<td>50 Km/h</td>
</tr>
<tr>
<td>MAX. SPEED</td>
<td>80 Km/h</td>
</tr>
<tr>
<td>SIZE (MOTOR TO MOTOR)</td>
<td>1249 mm</td>
</tr>
<tr>
<td>PROPELLERS</td>
<td>30″&nbsp; //&nbsp; 32″</td>
</tr>
<tr>
<td>OPERATIONAL TEMPERATURE</td>
<td>-10ºC to 45ºC</td>
</tr>
<tr>
<td>PROPULSION SYSTEM</td>
<td>Hybrid fuel-electric</td>
</tr>
<tr>
<td>COMBUSTION ENGINE</td>
<td>2-Stroke</td>
</tr>
<tr>
<td>PETROL</td>
<td>95 Octane + 4% Oil</td>
</tr>
<tr>
<td>BATTERIES</td>
<td>LiPO 6S</td>
</tr>
</tbody>
</table>
</div></div></div></div></section><section><div><div><p><img src="https://www.quaternium.com/wp-content/uploads/2017/08/EC-H2020-1.jpg" data-src="https://www.quaternium.com/wp-content/uploads/2017/08/EC-H2020-1.jpg" width="50%" height="130" alt="" title=""></p><p>This project has received funding from the European Union’s <a href="https://ec.europa.eu/programmes/horizon2020/" target="_blank" rel="noopener noreferrer">Horizon 2020</a> research and innovation programme under grant agreement No 712667.</p></div></div></section><section><div><div>
	<div>
		<p>
			<iframe width="560" height="315" src="https://www.youtube.com/embed/0YnlBI5U1XI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
		</p>
	</div>
</div></div></section><section></section><section></section><section></section><section><div><div><h2>Ultimate hybrid technology</h2><p>Ten&nbsp;times more flight time than electric multirotors</p><p>Compact and powerful. This professional UAV can be quickly deployed and operated by just two people. HYBRiX 2.1 has removable arms for easy transport and it comes in a compact case to carry it comfortably in the trunk of a car.</p></div></div></section><section></section><section></section>
			</div>
</article><!-- #post-## -->
								</div>
</section></div>]]>
            </description>
            <link>https://www.quaternium.com/uav/hybrix-drone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966540</guid>
            <pubDate>Mon, 02 Nov 2020 10:35:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding hardcoded keys and Secrets in Mobile Apps for fun and profit]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24966263">thread link</a>) | @alaeddine
<br/>
November 2, 2020 | https://blog.ostorlab.co/hardcoded-secrets.html | <a href="https://web.archive.org/web/*/https://blog.ostorlab.co/hardcoded-secrets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Hardcoded secret keys are a convenient target to Bug Bounty hunters and Attackers. They are easy to spot and they can
open a wide gate to sensitive data and privileged access.</p>
<p>Hardcoded secrets caused several high profile breaches in the past, notable ones are:</p>
<ul>
<li>
<p><strong>MyCar</strong>: MyCar is a vehicle telematics systems. The maker  left hardcoded credentials inside its Android and iOS
mobile apps. This left tens of thousands of cars vulnerable to hackers, who could locate car, identify them, unlock them,
start the car or trigger the alarm.</p>
</li>
<li>
<p><strong>Uber</strong>: An Uber employee published plaintext credentials within source code that was then posted on Github. 
An attacker found the embedded credentials on GitHub, then used them to gain privileged access on Uber’s Amazon
AWS Instances. The attacker then demanded a 100k$ ransom, that Uber did pay.
 The Uber breach resulted in the exposure of information of 57 million customers, plus roughly 600,000 drivers. Once the
 story became public, Uber paid a settlement of 148M$ and had to delay its IPO.</p>
</li>
<li>
<p><strong>Uniguest</strong>: Uniguest provides kiosks (PC, iMac, tablet) available in hotel lobbies (and other places). User can use
them to run simple tasks, such as browsing the web or printing boarding passes.
The API credentials were hardcoded within the application and were used to dump all the data in the Uniguest
cloud database. The data included admin credentials, router and BIOS passwords, product keys and various other sensitive information.</p>
</li>
</ul>
<p>Hardcoded secrets are also commonly reported by Bug Bounty hunters. If you check any of the different Bug Bounty programs, you will
find many disclosed reports pointing to the hardcoded keys in the <code>AndroidManifest.xml</code>, <code>Info.plist</code> or some resource file. </p>
<p>Depending on the permissions and use of the key, these vulnerabilities might be awarded up to 1k$. The severity ranges from
elevating privileges, accessing sensitive information, over-bill/theft of a service or conducting a denial of service attack.</p>
<h2>How to find and validate secrets?</h2>
<p>Secrets can be found either statically or dynamically. A common static approach is to search known patterns, for instance
searching for strings matching the following regular expression <code>AIza[0-9A-Za-z\\-_]{35}</code>:</p>
<div><pre><span></span><code>$ app8 egrep -r <span>'AIza[0-9A-Za-z\\-_]{35}'</span> . 
Binary file ./resources.arsc correspondant
Binary file ./app.apk correspondant
Binary file ./classes.dex correspondant                                
./assets/google-services-desktop.json:          <span>"current_key"</span>: <span>"AIzaSy....................."</span>
</code></pre></div>
<p>You can find in this repo <a href="https://github.com/l4yton/RegHex">l4yton/RegHex</a> a list of regular expressions to use.</p>
<p>Because not all API keys and secrets are bad or dangerous, and not all pattern outputs are correct; the keys must be checked and the
permissions, roles, scopes, and restrictions (more on that latter) must be enumerated and verified.
<code>streaak</code> published a repo <a href="https://github.com/streaak/keyhacks">streaak/keyhacks</a> listing <code>curl</code> commands to check a wide range of keys.</p>
<p>Below are some examples for Firebase keys and Facebook secrets:</p>
<div><pre><span></span><code>$ curl -s -X POST --header <span>"Authorization: key=AIzaS........."</span> --header <span>"Content-Type:application/json"</span> <span>'https://fcm.googleapis.com/fcm/send'</span> -d <span>'{"registration_ids":["1"]}'</span>
&lt;HTML&gt;
&lt;HEAD&gt;
&lt;TITLE&gt;INVALID_KEY_TYPE&lt;/TITLE&gt;
&lt;/HEAD&gt;
&lt;BODY <span>BGCOLOR</span><span>=</span><span>"#FFFFFF"</span> <span>TEXT</span><span>=</span><span>"#000000"</span>&gt;
&lt;H1&gt;INVALID_KEY_TYPE&lt;/H1&gt;
&lt;H2&gt;Error <span>401</span>&lt;/H2&gt;
&lt;/BODY&gt;
&lt;/HTML&gt;
</code></pre></div>
<div><pre><span></span><code>$ curl https://graph.facebook.com/oauth/access_token<span>\?</span>client_id<span>\=</span>51XXXX<span>\&amp;</span>client_secret<span>\=</span>0cbd4XXXXX<span>\&amp;</span>redirect_uri<span>\=\&amp;</span>grant_type<span>\=</span>client_credentials
<span>{</span><span>"access_token"</span>:<span>"5181XXXXXXXXXXXXXX"</span>,<span>"token_type"</span>:<span>"bearer"</span><span>}</span>% 
</code></pre></div>
<p>Once a key is found, the API documentation should be your best-friend to determine what permissions does it have and what
sort of actions can be performed. Take for instance instance a facebook application, you can then use the <code>https://graph.facebook.com/v8.0/{applicationId}/permissions</code> endpoint to list permissions:</p>
<div><pre><span></span><code>$ curl <span>"https://graph.facebook.com/v8.0/51XXXXXXXX/permissions?access_token=51XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"</span>
<span>{</span><span>"data"</span>:<span>[{</span><span>"permission"</span>:<span>"email"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"pages_show_list"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"pages_messaging"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"groups_show_list"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"pages_read_engagement"</span>,<span>"status"</span>:<span>"live"</span><span>}</span>,<span>{</span><span>"permission"</span>:<span>"public_profile"</span>,<span>"status"</span>:<span>"live"</span><span>}]}</span>%   
</code></pre></div>
<p>Another CLI friendly tool is Yelp's <code>detect-secret</code>: <a href="https://github.com/Yelp/detect-secrets">Yelp/detect-secrets</a>.
The tool detects a smaller subset of keys and implements validation for some a well.</p>
<p>Ostorlab automates the process of finding and checking keys and secrets and covers 53 secret types at time this article is written. 
A secret agent collects keys matching patterns or used dynamically by specific APIs or intercepted over the wire. The agent
then checks these keys to confirm if valid by iterating over all known services. </p>
<p>This a screenshot showing an example confirming a valid key and the matching service**.</p>
<p><img alt="Hardcoded secrets" src="https://blog.ostorlab.co/static/img/hardcoded_secret_keys/secret_finding.png" title="Ostorlab's report: Hardcoded Secret"></p>
<p>Just out of the last 10k apps scanned, we have reported over 200 valid secrets granting access to highly sensitive data
or critical services, like Payment or Source Code. Below are some statistics of the number of keys found per service:</p>
<table>
<thead>
<tr>
<th>Service Name</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>Firebase</td>
<td>35/1000</td>
</tr>
<tr>
<td>Google Cloud Platform</td>
<td>31/1000</td>
</tr>
<tr>
<td>Twitter</td>
<td>22/1000</td>
</tr>
<tr>
<td>Facebook</td>
<td>21/1000</td>
</tr>
<tr>
<td>Instagram</td>
<td>18/1000</td>
</tr>
<tr>
<td>AWS</td>
<td>18/1000</td>
</tr>
<tr>
<td>GitHub</td>
<td>14/1000</td>
</tr>
<tr>
<td>PayPal</td>
<td>5/1000</td>
</tr>
<tr>
<td>slack</td>
<td>1/1000</td>
</tr>
</tbody>
</table>
<h2>How to fix it?</h2>
<ul>
<li><strong>Embedding is Acceptable, nothing to do here</strong>: Most services provide best practices for how to use the API or secret. Some APIs are acceptable if embedded in an application. Firebase is an example:</li>
</ul>
<div><pre><span></span><code>Unlike how API keys are typically used, API keys for Firebase services are not used to control access to backend resources; 
that can only be done with Firebase Security Rules. 
Usually, you need to fastidiously guard API keys (for example, by using a vault service or setting the keys as environment variables); 
however, API keys for Firebase services are ok to include in code or checked-in config files.
</code></pre></div>
<ul>
<li><strong>Alternatives are encouraged, I should switch</strong>: Some services offer more secure alternatives to embedding credentials (such as Amazon and Google, example from <a href="https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html">AWS recommendation</a>):</li>
</ul>
<div><pre><span></span><code>You have a mobile app. Do not embed access keys with the app, even in encrypted storage. 
Instead, use Amazon Cognito to manage user identities in your app. This service lets you authenticate users using Login with Amazon, Facebook, Google, or any OpenID Connect (OIDC)–compatible identity provider. 
You can then use the Amazon Cognito credentials provider to manage credentials that your app uses to make requests to AWS. For more information, see Using the Amazon Cognito Credentials Provider on the AWS Mobile Blog. 
</code></pre></div>
<ul>
<li><strong>Embedding is Dangerous, delegate the actions to the Server</strong>: For some services, embedding keys is an invitation to get hacked, see for instance <a href="https://stripe.com/docs/keys#safe-keys">Stripe documentation</a>. In these cases, having the server must perform the interaction with the service.</li>
</ul>
<div><pre><span></span><code>Your secret API key can be used to make any API call on behalf of your account, such as creating charges or performing refunds. 
Treat your secret API key as you would any other password. Grant access only to those who need it. 
Ensure it is kept out of any version control system you may be using. 
Control access to your key using a password manager or secrets management service.

In live mode, new secret keys are only visible the first time you access them. 
After that, the Dashboard redacts the API key. When the key is revealed, you can leave a note on the Dashboard describing the location on your own systems where you’ve copied it. 
If you lose your secret key, you can’t recover it from the Dashboard and must roll the key or create another one.
</code></pre></div>
<ul>
<li><strong>Hardening through Remote Key fetching and Key Pinning</strong>: For services that don't provide a per-user authentication service, and
need to be embedded in the application, it’s recommended to retrieve the
key from the server. It is also best practice to restrict the key's permissions (principle of least privilege).
Some service provide the possibility to PIN keys to an application or domain name. Because this 
protection is not perfect, rotating the keys is recommended to limit exposure.</li>
</ul>
<p><img alt="API Restrictions" src="https://blog.ostorlab.co/static/img/hardcoded_secret_keys/restrictions.png" title="API Restrictions"></p>
    </div></div>]]>
            </description>
            <link>https://blog.ostorlab.co/hardcoded-secrets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966263</guid>
            <pubDate>Mon, 02 Nov 2020 09:45:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HashiCorp Waypoint – End to end demo from Code to Kubernetes in minutes]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24966139">thread link</a>) | @saiyam911
<br/>
November 2, 2020 | https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem | <a href="https://web.archive.org/web/*/https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <h2 id="introduction-hashicorp-waypoint">
  <a href="#introduction-hashicorp-waypoint"><i></i></a>
  Introduction - HashiCorp Waypoint
</h2>


<p>Yesterday (15 October 2020) HashiCorp launched an open source tool named Waypoint. Let us try to understand the problem statement and see how Waypoint aims to fix those. </p>

<p>HashiCorp Co-Founder and CTO Mitchell Hashimoto very rightly said during the 2020 HashiConf keynote that traditional software developer lifecycle includes different phases: Code, Test, Build, Deploy, Release, Operate and Measure. Out of this list, commonly-accepted tools for Code, Test, Operate and Measure exist, but the three areas of Build, Deploy and Relese have some challenges that Waypoint aims to solve.</p>

<p>Before we get in to the guide,I've also put together a video walkthrough which is well worth checking out...</p>

<iframe width="100%" height="420" src="https://www.youtube.com/embed/_FRiBVY1ZXI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>On with the guide...</p>

<p>There are build systems that help you build and then deploy to specific platforms, but due to wide variety of platforms out there for application deployment, you will have to use and learn different build/deploy methods specific to the different platforms. The same goes for Release management. Now, in order to have a common workflow with ease of use across all platforms, Hashicorp has introduced <strong>Waypoint</strong>, with the aim of "providing a consistent workflow to build, deploy and release an application to any platform".</p>

<p>From the <a href="https://www.waypointproject.io/docs">docs</a> - "<strong>Waypoint</strong> is a tool that enables developers to describe how to get their applications from development to production in a single file and deploy using a single command: <code>waypoint up</code>".</p>

<p>Waypoint comes with logs and exec tools that helps you check if there are any issues with the proposed deployment. It is highly pluggable and extensible: in the image below below you can see some of the existing plugins for Docker and Kubernetes that are there by default - and the community can create and contribute more plugins.</p>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/950.blog.png?1602826943" alt="Waypoint Plugins"></p>

<p>So, based on the plugins and with minimal configuration, Waypoint lets you build, deploy and release applications across platforms, saving you the hassle of having to write more lines of configuration files in different languages for different platforms.
Here are some of the resources to get you started - 
<a href="https://www.waypointproject.io/docs">Docs</a> 
<a href="https://github.com/hashicorp/waypoint/">Github</a></p>

<p>In this post I will show you how you can install and use Waypoint to build, deploy and release a sample application to a Civo Kubernetes cluster. If you have not yet signed up, you can <a href="https://www.civo.com/kube100">do so here</a> - you'll get $70 a month credit while the service is in beta.</p>

<h2 id="demo">
  <a href="#demo"><i></i></a>
  Demo
</h2>


<h3 id="deploying-a-cluster">
  <a href="#deploying-a-cluster"><i></i></a>
  Deploying a cluster
</h3>


<p>First, let's create a Civo cluster. It's easiest using the Civo <a href="https://github.com/civo/cli#set-up">CLI tool</a>, but you can also use the Kubernetes web UI in your Civo account to create it.</p>

<p>Download civo cli from <a href="https://github.com/civo/cli#set-up">here</a> </p>

<p>Configure to use by providing your API key, which you will find <a href="https://www.civo.com/account/security">here</a>.</p>

<p>Create cluster using the below command:</p>

<pre><code>civo k3s create --wait --save                           
The cluster polished-tree (6c8d2b30-496a-46d0-91bf-22124fc14f21) has been created in 2 min 53 sec
</code></pre>

<h3 id="installing-waypoint-onto-our-machine">
  <a href="#installing-waypoint-onto-our-machine"><i></i></a>
  Installing Waypoint onto our machine
</h3>


<p>You can download and install Waypoint on any platform. from your local machine to a virtual machine in the cloud. This example shows Waypoint installation on a CentOS7 box running on Civo. </p>

<p>Installing git, docker, and kubectl. Make sure you have downloaded the cluster configuration in the previous step to ~/.kube/config (if you used the command-line tool above, it will be saved in the correct place).</p>

<pre><code>yum install git -y

yum install docker -y
systemctl start docker 

curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl 
mv kubectl /usr/local/bin/

#Check if cluster is runnning 
kubectl get nodes
NAME               STATUS     ROLES    AGE     VERSION
kube-node-1c23     Ready      &lt;none&gt;   110s    v1.18.6+k3s1
kube-node-3e04     Ready      &lt;none&gt;   110s    v1.18.6+k3s1
kube-master-5fdc   Ready      master   3m52s   v1.18.6+k3s1
</code></pre>

<p>Install and configure Waypoint for a sample repository:</p>

<pre><code>
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
sudo yum -y install waypoint

git clone https://github.com/saiyam1814/waypoint-demo.git
cd waypoint-demo

waypoint install --platform=kubernetes -accept-tos
service/waypoint created
statefulset.apps/waypoint-server created
Waypoint server successfully installed and configured!

The CLI has been configured to connect to the server automatically. This
connection information is saved in the CLI context named "install-1602830444".
Use the "waypoint context" CLI to manage CLI contexts.

The server has been configured to advertise the following address for
entrypoint communications. This must be a reachable address for all your
deployments. If this is incorrect, manually set it using the CLI command
"waypoint server config-set".

Advertise Address: 91.211.154.49:9701
HTTP UI Address: 91.211.154.49:9702
</code></pre>

<h4 id="check-that-waypoint-is-running">
  <a href="#check-that-waypoint-is-running"><i></i></a>
  Check that Waypoint is Running
</h4>


<pre><code>kubectl get pods 
NAME                   READY   STATUS    RESTARTS   AGE
svclb-waypoint-qltwk   2/2     Running   0          93s
svclb-waypoint-cgvdb   2/2     Running   0          93s
svclb-waypoint-d2m4v   2/2     Running   0          93s
waypoint-server-0      1/1     Running   0          93s

</code></pre>

<h3 id="deploying-our-application">
  <a href="#deploying-our-application"><i></i></a>
  Deploying our application
</h3>


<p>Now that we have Wavpoint installed, let's initiate if for the application that is to be installed. </p>

<pre><code> waypoint init
Initial Waypoint configuration created!
No Waypoint configuration was found in this directory.

A sample configuration has been created in the file "waypoint.hcl". This
file is heavily commented to help you get started.

Once you've setup your initial configuration, run "waypoint init" again to
validate the configuration and initialize your project.
</code></pre>

<p>This creates a waypoint.hcl file with basic structure that needs to be configured as per the application. Now for our current example project, there is already a waypoint.hcl present in <code>waypoint-demo</code>directory</p>

<pre><code>project = "saiyam-waypoint"

app "saiyam-waypoint" {
  labels = {
      "service" = "saiyam-waypoint",
      "env" = "dev"
  }

  build {
   use "docker" {}
    registry {
        use "docker" {
          image = "saiyam911/cd-demo"
          tag = "1"
  }
    }
 }

  deploy { 
    use "kubernetes" {
        probe_path = "/"
        service_port = 8080
}
  }

  release {
    use "kubernetes" {
      node_port = 31769
      port = 8080
    }
  }
}
</code></pre>

<p>Let's run waypoint init </p>

<pre><code>waypoint init
âœ“ Configuration file appears valid
âœ“ Connection to Waypoint server was successful
âœ“ Project "example-nodejs" and all apps are registered with the server.
âœ“ Plugins loaded and configured successfully
âœ“ Authentication requirements appear satisfied.

Project initialized!

You may now call 'waypoint up' to deploy your project or
commands such as 'waypoint build' to perform steps individually.
</code></pre>

<p>Three main steps to notice here are build, deploy and release that have to be created and configured in order to install the application onto the cluster. You can also do customizations like provide the kubeconfig file etc. by checking the <a href="https://www.waypointproject.io/plugins">plugins documentation</a>.</p>

<p>To run all these steps, there is a simple command:</p>

<pre><code>waypoint up

Â» Building...
âœ“ Initializing Docker client...
âœ“ Building image...
 â”‚  ---&gt; f520a8e63f23
 â”‚ Step 2/4 : COPY . ./
 â”‚  ---&gt; 645a76511ab0
 â”‚ Step 3/4 : ENV PORT 8080
 â”‚  ---&gt; Running in 96cb40982097
 â”‚  ---&gt; 7f4e3ebf149d
 â”‚ Step 4/4 : CMD python name.py
 â”‚  ---&gt; Running in cbe6b9b11306
 â”‚  ---&gt; 17cc424bc5cd
 â”‚ Successfully built 17cc424bc5cd
âœ“ Injecting Waypoint Entrypoint...
âœ“ Tagging Docker image: waypoint.local/saiyam-waypoint:latest =&gt; saiyam911/cd-demo:1
âœ“ Pushing Docker image...
 â”‚ 7e453511681f: Layer already exists
 â”‚ b544d7bb9107: Layer already exists
 â”‚ baf481fca4b7: Layer already exists
 â”‚ 3d3e92e98337: Layer already exists
 â”‚ 8967306e673e: Layer already exists
 â”‚ 9794a3b3ed45: Layer already exists
 â”‚ 5f77a51ade6a: Layer already exists
 â”‚ e40d297cf5f8: Layer already exists
 â”‚ 1: digest: sha256:70f7663523f3aedf044561e079fcb27726132f40227c2da0319c475ecb20cc
 â”‚ 5b size: 6178

Â» Deploying...
âœ“ Kubernetes client connected to https://91.211.154.49:6443 with namespace default
âœ“ Creating deployment...
âœ“ Deployment successfully rolled out!

Â» Releasing...
âœ“ Kubernetes client connected to https://91.211.154.49:6443 with namespace default
âœ“ Creating service...
âœ“ Service is ready!

The deploy was successful! A Waypoint deployment URL is shown below. This
can be used internally to check your deployment and is not meant for external
traffic. You can manage this hostname using "waypoint hostname."

 Release URL: http://172.31.3.114:31769
Deployment URL: https://freely-obliging-pigeon--v1.waypoint.run
</code></pre>

<p>Boom!! The application is deployed to the Kubernetes cluster </p>

<pre><code>kubectl get pods
NAME                                                         READY   STATUS    RESTARTS   AGE
saiyam-waypoint-01emsbpmqebmamd0dvfacebf2e-849b964bc-rcw2n   1/1     Running   0          69s

kubectl get svc
NAME              TYPE        CLUSTER-IP        EXTERNAL-IP   PORT(S)          AGE
kubernetes        ClusterIP   192.168.128.1     &lt;none&gt;        443/TCP          172m
saiyam-waypoint   NodePort    192.168.174.167   &lt;none&gt;        8080:31769/TCP   35s

</code></pre>

<p>Access the Service via the URL generated - <a href="https://freely-obliging-pigeon--v1.waypoint.run/">https://freely-obliging-pigeon--v1.waypoint.run</a>
<img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/965.blog.png?1602875025" alt="Your Alt Text">
<img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/962.blog.png?1602874998" alt="Your Alt Text"></p>

<p>In just a matter of minutes Application got deployed to the cluster, make some changes in the templates/name.html file and again do  <code>waypoint up</code> and you would be able to see a new revision created. 
Let's check the waypoint UI to see more info and this is also helpful for debugging purposes -&gt; <a href="https://91.211.154.49:9702/">https://91.211.154.49:9702</a></p>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/968.blog.png?1602876137" alt="Your Alt Text"></p>

<p>Click authenticate and generate temporary token:
<img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/971.blog.png?1602876238" alt="Your Alt Text"></p>

<pre><code>waypoint token new
bM152PWkXxfoy4vA51JFhR7LrQefsoZp5gRUr4j25i5Rrf8n3p9gceJg6WxDzXFpjqzY5Qda95b8T3zeBDaf2a38R3rZttABkeyDa
</code></pre>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/974.blog.png?1602876362" alt="Your Alt Text"></p>

<p><img src="https://civo-com-assets.ams3.digitaloceanspaces.com/content_images/977.blog.png?1602876397" alt="Your Alt Text"></p>

<p>You can see all the build logs, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem">https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem</a></em></p>]]>
            </description>
            <link>https://www.civo.com/learn/waypoint-solving-the-build-deploy-and-release-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966139</guid>
            <pubDate>Mon, 02 Nov 2020 09:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is a billion dollars worth of server lying on the ground?]]>
            </title>
            <description>
<![CDATA[
Score 325 | Comments 320 (<a href="https://news.ycombinator.com/item?id=24966028">thread link</a>) | @george3d6
<br/>
November 2, 2020 | https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground | <a href="https://web.archive.org/web/*/https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-11-02</p>
        
<p><em>Note: Some details of the stories in this article are slightly altered to protect the privacy of the companies I worked for</em></p>
<p>It's somewhat anecdotal, but in my work, I often encounter projects that seem to use highly inefficient infrastructure providers, from a cost perspective.</p>
<p>I usually point out that, based on a fairly unbiased hardware comparison, that they could save over half their budget by migrating, and am usually met with a series of almost canned answer about migrations being too difficult due to x,y,z.</p>
<h2>I - A representative comparison</h2>
<p>I will pick one of the "expensive" and one of the "cheap" server providers, chosen simply based on the fact that I've worked with them a lot, and compare two of their high~ish end servers.</p>
<p>I'm going to take 1 example from a cheap server provider OVH and a somewhat worst machine from AWS.</p>
<p>OVH offers <a href="https://us.ovh.com/us/order/dedicated/#/dedicated/configure-hg?product=~(dc~(gra~1)~planCode~%271901bhg~option~(~(planCode~%27cpu-2x6132-dual-2018v1~family~%27cpu~quantity~1)~(planCode~%27ram-768g-2666-dual-2018v1~family~%27ram~quantity~1)~(planCode~%27disk-960ssd-sata-2019~family~%27disk~quantity~8)))">this machine</a>:</p>
<ul>
<li>2x Intel Xeon Scalable Gold 6132 - 28c/56t - 2.6/3.7 GHz</li>
<li>768GB RAM DDR4 ECC 2666MHz</li>
<li>960GB SATA SSD</li>
<li>3 Gb/s internal and 1 Gb/s external free bandwidth</li>
</ul>
<p>For $15,800/year (though it can be paid monthly)</p>
<p>For a close comparison, AWS offers their <a href="https://aws.amazon.com/ec2/pricing/on-demand/">4.16xlarge</a>. I'll try to figure out the exact hardware specs on <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/memory-optimized-instances.html">this description</a>:</p>
<blockquote>
<p>R4 instances feature up to 64 vCPUs and are powered by two AWS-customized Intel XEON processors based on E5-2686v4 that feature high-memory bandwidth and larger L3 caches to boost the performance of in-memory applications.</p>
</blockquote>
<p>So basically let's call it 2x E5-2686v4, though the "real" E5-2686v4 seems to have more cores (both real and virtual) than the AWS version, I'll give AWS the benefit of the doubt and say that their version is more or less the same. I'll also assume AWS's RAM is the same 2666MHz DDR4 EEC2 (basically the best you can get right now) though they don't specify this, but I'll be generous here.</p>
<p>So we have:</p>
<ul>
<li>2x Intel Xeon E5-2686v4 - 36c/72t - 2.3/3.0 GHz</li>
<li>488GB RAM DDR4 ECC 2666MHz</li>
<li>Storage paid for separately</li>
<li>Bandwith paid for separately</li>
</ul>
<p>For $37,282/year (paid hourly) or $25,771/year (paid upfront)</p>
<p>The OVH server has more memory, it comes with 1TB of very fast storage, and adding more storage is much cheaper than AWS EBS prices (+ you get the option for NVME SSDs connected via PCIe on all servers).</p>
<p>I chose two processors which are <em>fairly</em> similar but running a comparison is still hard. Unlike e.g. RAM, processors are much more synergistic, you can't just look at parameters like nr cores, cache size, and frequency to figure out how well they perform.</p>
<p>Still, these two seem to be pretty close on those parameters and when looking at <a href="https://www.cpubenchmark.net/compare/Intel-Xeon-E5-2686-v4-vs-Intel-Xeon-Gold-6132/2870vs3227">the benchmarks</a>. It seems that the Gold 6132 is marginally better than the E5-2684-v4. Granted, benchmarking server CPUs is hard, but still, I think it's fair to say that the former has at least a tiny advantage, even if somehow the E5-2684 performs worst of benchmarks than on "real tasks".</p>
<p>So we have 2 servers:</p>
<ul>
<li>Both are in Paris</li>
<li>One has 768GB of RAM the other 488GB (58% of the first one) with the same specs</li>
<li>One has an extremely to slightly better CPU (let's say 10% better, a bit bellow the ~17% claimed by the benchmarks)</li>
<li>One has free bandwidth, the other one charges you for every single Kb of communication with the outside world (though at a fairly small sum)</li>
<li>One comes with 1TB of very fast NVME storage, for the other one you have to pay extra</li>
<li>One is paid monthly, the other one yearly or hourly.</li>
</ul>
<p>If the first server, the one that is better in literally every way, costs ~16k/year... how much should the other one cost? Well, maybe 10, maybe 12, maybe 14?</p>
<p>I don't know, but the answer certainly shouldn't be "Almost twice as much at 26k/year", that's the kind of answer that indicates something is broken.</p>
<p>In a worst-case scenario, AWS is ~1.6x times as expensive, but again, that's paid yearly. If we compare paid monthly to paid hourly (not exactly fair) we get 37k vs 16k, if we do some <a href="https://aws.amazon.com/ebs/pricing/">napkin math calculations</a> for equivalent storage cost (with equivalent speed via guaranteed iops) we easily get to ~3k/year extra. We have a 40k vs 16k difference, the AWS machine with the worst specs is 250% more expensive.</p>
<p>But whether the worst AWS machine is 160% or 250% as expensive as the OVH one is not the relevant question here, the question is why are we seeing those astronomical differences in terms of cost to being with.</p>
<p>We should consider there are hosting providers cheaper than OVH (e.g. scaleway, potentially online.net, and other such providers you never heard of). On the flip side of the coin, there are server providers such as digital oceans, GC, and Azure that can be more expensive than AWS.</p>
<p>Why?</p>
<h2>II - Vendor lock-in hypothesis</h2>
<p>The easiest thing to do here is to cry vendor lock-in.</p>
<p>The story goes that you end up using firebase for authentication, then you hire a sysadmin / DevOps guy that knows GC to create your infrastructure there. Then you make use of some fancy google ML service that integrates seamlessly with the GC storage... so on and so forth, until it would cost you a lot more manpower to move away from GC than to pay them a bit extra for whatever compute or storage you could get for less elsewhere.</p>
<hr>
<p>This is compounded by the fact that most of the time startups are oblivious to the cost of these services.</p>
<p>I switched my personal "infrastructure" from AWS since it ended up costing me over $100/month to maintain. Nowadays I pay $23/month and get a lot more leeway out of my current setup. But I haven't done that with some startups I've worked with or advised, even though the cost savings could have one or two additional zeros added to them. Why?</p>
<p>I can often call the shots regarding hardware at the startups I've worked with, yet I usually can't argue against using AWS or GC... because often enough, the first hit is free. AWS, GC, and Azure are throwing out 10k$ worth of credits like candy, and topping that off with 50-200k$ worth of credit for startups that they think have potential. The catch here is that the credits expire in 1 year, and once that year is done many are probably locked into the vendor.</p>
<p>The startup model is one of exponential growth, most fail and the winners have dozens or hundreds of millions from investments. So what is one or two hundred thousand a year on an IaaS bill?</p>
<p>Well, the answer is almost nothing. I believe the standard AWS offering for free credits is something like 100k$/year. So assuming a startup that uses that for a year gets 10mil in investment, it costs them 1% of their budget a year to maintain that.</p>
<p>The problem is that investment reflects future potential worth, a startup receiving a 10 mil investment is probably operating at a small fraction of the capacity those investors hope it will reach. For the shares to be worth 5x time that original investment, the company might have to scale its operations 20x or 50x, or 100x.</p>
<p>This becomes a problem since you can't run on investment forever, and scaling up 20x suddenly turns that 100k into 2 million a year spent on servers.</p>
<p>Of course, this is just a hypothetical, the numbers here are stand-ins to make a point, not a case-study. From my own experience, that the lock-in funnel looks something like:</p>
<ol>
<li>Free credits, let's use {expensive infrastructure provider}.</li>
<li>Loads of investment money, let's not waste time switching away from {expensive infrastructure provider}, it's &lt; 1% of our yearly budget.</li>
<li>Turns out that once the company grew, {expensive infrastructure provider} now consists of a double-digit percentage of our yearly expenditure, but it's too late to switch now.</li>
</ol>
<hr>
<p>This situation is exacerbated by consolidation (big fish buys little fish). I vividly remember a situation where I found an optimal hardware+software combination for a data processing platform, I think a conservative estimate would be that it was ~5 times cheaper than the vendor lock-in alternative being used at the time.</p>
<p>This happened to make it worth the switch since the startup lacked a generous credit offer for Google cloud. But, as soon as it was "consolidated", I was forced to switch the whole system back to Google cloud, granted a much better GC setup, but one that still involved costs ~2-3x times greater than the original solution.</p>
<p>Why? Well, boils down to the parent company using Google cloud, all their employees knowing how to work with GC, all their contracts having weird security-related clauses composed by many lawyers based on "official security audits" ran on their GC infrastructure, and so on.</p>
<p>However, this leads nicely into my second hypothesis.</p>
<h2>III - Employee lock-in hypothesis</h2>
<p>Employees end up deciding most of what a company is using internally, including infrastructure providers.</p>
<p>People aggregate <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/">along weird lines</a>, to the extent that it wouldn't surprise me if a CTO hired initial engineers that favored his preferred infrastructure provider, even if he didn't actively seek that trait out.</p>
<p>Once the first few employees are fans of a given infrastructure provider, it starts making it into the job specs, because onboarding someone familiar with AWS when you use Azure is a huge pain in the ass. All other things being equal you'd rather have someone familiar with the technology you are already using.</p>
<p>This is compounded by the kind of employees that permeate a given field. If you are developing mobile apps or web apps, for example, it's likely that many engineers you will find will be familiar with Heroku and Digital Oceans. If you are developing whatever the heck people use C# for, I'd bet you'll find people that know how to use Azure. If you are doing machine learning, most people will know a thing or two about google cloud's offers regarding TPUs.</p>
<p>More broadly, this leaves no room for people that want to have a "multi-cloud" infrastructure or use a very little known platform. Either you get engineers that are very versed in the subject, but that will cost extra. Or you consign to having a few experts on the subject handle everything, with the rest of the team having no idea how to boot up a new VM without calling someone up.</p>
<p>Of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground">https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/Is_a_billion-dollar_worth_of_server_lying_on_the_ground</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966028</guid>
            <pubDate>Mon, 02 Nov 2020 09:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Collaborative Chatbot with Google Sheets and TensorFlow]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24966013">thread link</a>) | @jonathanbgn
<br/>
November 2, 2020 | https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html | <a href="https://web.archive.org/web/*/https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://jonathanbgn.com/assets/images/taipei.jpg" alt="Taipei"></p>

<p>Currently living in Taiwan, I recently joined the <a href="https://github.com/taiwangoldcard/taiwan-bot">Taiwan Bot 🤖</a> project along with <a href="https://www.linkedin.com/in/shawn-lim-0a307550">Shawn</a> and <a href="https://erickhun.com/about/">Eric</a>. The idea is to build a go-to assistant to help foreigners answer their questions about moving to, working, and living in Taiwan (pro-tip: ask the bot where to find cheese or chocolate).</p>

<p>Building a functional and useful chatbot is a non-trivial project. Fortunately, there has been impressive progress in the fields of machine learning and <strong>natural language processing (NLP)</strong> in the past few years. Moreover, the democratization and open-source sharing of cutting-edge deep learning models from research work at large tech companies like Google or Facebook is making it possible for anyone to implement the latest state-of-the-art solutions.</p>

<p>The <a href="https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html">Universal Sentence Encoder</a>, recently released by Google AI, is one of these new models available via <a href="https://tfhub.dev/google/universal-sentence-encoder/4">Tensorflow Hub</a>. Trained in a <strong>multi-tasking</strong> fashion, the model can encode sentences into meaningful continuous representations that work well on a range of different tasks. It is thus ideal for <strong>transfer learning</strong> and performs competitively with more complex models like <a href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT</a>. Moreover, it can run much faster than BERT or other similar <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformer</a> models and is thus more applicable to real-world problems. There is even a <a href="https://tfhub.dev/google/universal-sentence-encoder-lite/2">Lite version</a> of the model, small enough to run in Javascript on the client-side.</p>

<h2 id="the-project">The project</h2>

<p>Despite being an amazing place to live, <strong>Taiwan is still misunderstood by most foreigners</strong>. We think that a fun and approachable chatbot could help people understand a lot more about all the great things this place has to offer, as well as answer most of the questions they might have about living here.</p>

<p>We decided to start with a limited scope first and to focus on answering practical questions about moving to and living in Taiwan. Specifically, we chose to focus on visa issues and the recently created <a href="https://taiwangoldcard.com/">Gold Card program</a>. We plan to expand the bot capabilities in future versions.</p>

<p>When it comes to chatbots, there are a lot of ways to go, and many tools and libraries out there to help you make your plan a reality. However, being just a small team of 3 doing this in our spare time, we didn’t have enough resources and time to build something very sophisticated. We also didn’t want to spend a lot of time to compile a large training dataset. So we looked for the best way to build a system that would be:</p>

<ul>
  <li>🧩 Easy and quick to build</li>
  <li>⚡️ Lightweight and runnable on a small server</li>
  <li>🔧 Iterable and easy to improve</li>
  <li>🧠 Focused on finding relevant answers</li>
</ul>

<p>We chose to build our bot with Microsoft’s <a href="https://github.com/microsoft/botframework-sdk">Bot Framework SDK</a> for easy development, user management and to be able to easily publish it to multiple platforms like Messenger or Line, the most popular messaging platform in Taiwan. <strong>The only thing remaining was to build the brain behind the messages.</strong></p>

<h2 id="understanding-the-meaning-behind-a-question">Understanding the meaning behind a question</h2>

<p>The main challenge when building a bot is <strong>relevancy</strong>, and this starts by having a clear understanding of what the user’s intention is. There are many approaches possible to make sense of what the user wants. At the most simple, one could simply look for some keywords such as <code>hello</code>, <code>restaurant</code>, or <code>visa</code>. However, this doesn’t take at all into account all the nuances of the language.</p>

<p>We didn’t have the resources to build a full-scale bot that could recognize the user intention among thousands of possibilities, yet we wanted to create something that could be relevant enough so that people would find it useful. So we needed to find an ideal middle ground between complexity and performance.</p>

<p>One of the most important concepts in NLP is one of <strong>distributed representations</strong>, inspired by the linguistic field of <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a>. The core idea is to encode linguistic items (words, sentences) into <strong>embeddings</strong> (vectors in a large dimensional space) such that items with similar properties should be closer in the resulting space.</p>

<blockquote>
  <p>You shall know a word by the company it keeps.</p>

  <p><em>- John Rupert Firth (1957)</em></p>
</blockquote>

<p>For example, similar words will cluster together in the vector space:</p>

<p><img src="https://jonathanbgn.com/assets/images/word-embeddings.png" alt="Word Embeddings"></p>

<p><em>Image from <a href="https://blog.tensorflow.org/2020/08/introducing-semantic-reactor-explore-nlp-sheets.html">TensorFlow Blog</a></em></p>

<p>You could do the same as the above but with sentences, effectively encoding them into large vectors which can be compared between themselves using <strong>similarity functions</strong>. Hence sentences with similar vector representations are sentences with similar meaning, topic, syntax…</p>

<h2 id="encoding-questions-with-the-universal-sentence-encoder">Encoding questions with the Universal Sentence Encoder</h2>

<p>The <a href="https://arxiv.org/abs/1803.11175">Universal Sentence Encoder</a> is a powerful Transformer model (in its large version) allowing to extract <a href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture">embeddings</a> directly from sentences instead of from individual words. It already powers some impressive Google projects such as <a href="https://books.google.com/talktobooks/">Talk to Books</a> or <a href="https://google.github.io/mysteryofthreebots/">Mystery of the Three Bots</a>.</p>

<p>For our chatbot project, we are first using the model to encode all the questions that we think users would want to ask to the bot. This can be done in a few lines of code thanks to the convenient TensorFlow Hub library:</p>

<div><div><pre><code><span>import</span> <span>tensorflow</span> <span>as</span> <span>tf</span>
<span>import</span> <span>tensorflow_hub</span> <span>as</span> <span>tfhub</span>

<span>model</span> <span>=</span> <span>tfhub</span><span>.</span><span>load</span><span>(</span><span>"https://tfhub.dev/google/universal-sentence-encoder/4"</span><span>)</span>

<span>questions</span> <span>=</span> <span>[</span> <span>...</span> <span>]</span>  <span># questions most likely to be asked to the bot
</span><span>answers</span> <span>=</span> <span>[</span> <span>....</span> <span>]</span>  <span># all answers to the questions above
</span>
<span>batch_size</span> <span>=</span> <span>10</span>
<span>embeddings</span> <span>=</span> <span>[]</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>len</span><span>(</span><span>questions</span><span>),</span> <span>batch_size</span><span>):</span>
    <span>embeddings</span><span>.</span><span>append</span><span>(</span><span>model</span><span>(</span><span>questions</span><span>[</span><span>i</span><span>:</span><span>i</span><span>+</span><span>batch_size</span><span>]))</span>
<span>questions_embeddings</span> <span>=</span> <span>tf</span><span>.</span><span>concat</span><span>(</span><span>embeddings</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
</code></pre></div></div>

<p>Then whenever a user asks a question, we can just extract its embedding and find the most similar question in our database of embeddings. In our case we use a simple vector dot product as a similary function:</p>

<div><div><pre><code><span>def</span> <span>find_best_answer</span><span>(</span><span>question</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>embedding</span> <span>=</span> <span>model</span><span>([</span><span>question</span><span>,])</span>
    <span># compute dot product with each question:
</span>    <span>scores</span> <span>=</span> <span>questions_embeddings</span> <span>@</span> <span>tf</span><span>.</span><span>transpose</span><span>(</span><span>embedding</span><span>)</span>

    <span>return</span> <span>answers</span><span>[</span><span>np</span><span>.</span><span>argmax</span><span>(</span><span>tf</span><span>.</span><span>squeeze</span><span>(</span><span>scores</span><span>).</span><span>numpy</span><span>())]</span>
</code></pre></div></div>

<h2 id="google-sheets-as-a-collaborative-database">Google Sheets as a collaborative database</h2>

<p>We built our dataset using a simple Google spreadsheet with 2 columns: questions and answers. Whenever a user asks a question, we just find the most relevant question and return the appropriate answer.</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-database.png" alt="Questions Answers Dataset"></p>

<p>This approach, while relatively simple, is a flexible enough for efficiently working together. Querying the data is done once during startup with a few lines of code:</p>

<div><div><pre><code><span>client</span> <span>=</span> <span>gspread</span><span>.</span><span>authorize</span><span>(</span>
    <span>ServiceAccountCredentials</span><span>.</span><span>from_json_keyfile_dict</span><span>(</span><span>SERVICE_ACCOUNT_INFO_DICT</span><span>,</span>
        <span>[</span><span>'https://spreadsheets.google.com/feeds'</span><span>,</span><span>'https://www.googleapis.com/auth/drive'</span><span>])</span>
<span>)</span>
<span>sheet</span> <span>=</span> <span>client</span><span>.</span><span>open</span><span>(</span><span>SPREADSHEET_FAQ_FILE</span><span>).</span><span>worksheet</span><span>(</span><span>SPREADSHEET_SHEET_NAME</span><span>)</span>
<span>questions</span> <span>=</span> <span>list</span><span>(</span><span>map</span><span>(</span><span>str</span><span>.</span><span>strip</span><span>,</span> <span>sheet</span><span>.</span><span>col_values</span><span>(</span><span>1</span><span>)[</span><span>1</span><span>:]))</span>
<span>answers</span> <span>=</span> <span>list</span><span>(</span><span>map</span><span>(</span><span>str</span><span>.</span><span>strip</span><span>,</span> <span>sheet</span><span>.</span><span>col_values</span><span>(</span><span>2</span><span>)[</span><span>1</span><span>:]))</span>
</code></pre></div></div>

<p>Here is an example of a conversation with the bot:</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-conversation.jpg" alt="Conversation with the bot"></p>

<h2 id="continuous-improvement">Continuous improvement</h2>

<p>We did our best to think about what would be the most commonly asked questions but, of course, we cannot predict everything people will ask. This is why if you ask a question that is not present in our database, the bot can answer with something completely unrelated. To prevent this, we built a small logging system to be able to track the questions asked to the bot and which question it thought was the most similar (along with the similarity score).</p>

<p>For example, here is what happened behind the scenes during the small conversation above. The first column is the user message. The second column is the most similar question (as based on the embeddings similarity). The third column is the best answer and the last column the computed similarity score. If the similarity score is not good enough, the bot will answer with a generic reply <em>” Sorry, I cannot help with that yet “</em>.</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-logs.png" alt="Conversation Logs"></p>

<p>This logging system will also help us improve our answers as more people use the bot and new edge cases are found. Still, no chatbot is perfect, and we think the bot will be most useful in a context where humans can take over when the bot fails. For example, on Slack, we added the bot to a general FAQ channel where people can get assistance from both the bot and humans for more specific information.</p>

<p><img src="https://jonathanbgn.com/assets/images/taiwan-bot-slack.png" alt="Chatbot on Slack"></p>

<h2 id="conclusion">Conclusion</h2>

<p>Building an effective chatbot doesn’t have to be a complex project. As long as the scope is relatively narrow, it is possible to use a general encoder model like the Universal Sentence Encoder to build something useful. The hard part is collecting enough questions/answers for the bot to be able to answer most questions. It is also important to regularly monitor what users are asking and complement new data whenever the bot can’t find a relevant answer.</p>

<p>If you are also living or considering to move to Taiwan, you can <a href="https://m.me/thetaiwanbot">chat with Taiwan bot on Messenger here</a>!</p>

<h3 id="read-next">Read next</h3>

<p><a href="https://jonathanbgn.com/nlp/2020/08/30/gpt2-gpt3-creativity.html">Unleash GPT-2 (and GPT-3) Creativity through Decoding Strategies</a></p>

<p><a href="https://jonathanbgn.com/speech/2020/10/31/emotion-recognition-transfer-learning-wav2vec.html">Detecting Emotions from Voice with Very Few Training Data</a></p>

  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24966013</guid>
            <pubDate>Mon, 02 Nov 2020 09:05:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You might not need to store plaintext email addresses]]>
            </title>
            <description>
<![CDATA[
Score 246 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24965671">thread link</a>) | @danielskogly
<br/>
November 2, 2020 | https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/ | <a href="https://web.archive.org/web/*/https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Earlier this year, when I went from having only Facebook-login on <a href="https://wishy.gift/">Wishy.gift</a> to allow registrations with email address and password, one of my concerns was how to implement this is a way that protects the data and privacy of my users. I don’t have any ads or analytics on the site, the users can select whatever display name they want, and I never stored the email addresses I got from Facebook when a user registered or logged in - only a hashed<sup><a href="#fn1" id="fnref1">[1]</a></sup> version of the ID. Email addresses and passwords, on the other hand, are a whole other beast, and the consequences of a database breach much worse.</p>
<p>Considering that the only kind of emails I ever need to send out are transactional - no newsletters or other kinds of notifications - the only thing I need to store them for are as identifiers, and can safely be hashed.</p>
<p>For every transactional email I need to send out - registration, account recovery, and email change verification - the user always initiates this by submitting their email address, and it will at that time be available to the backend to perform the needed action.</p>
<p>In conclusion, if you only use email addresses for transactional emails, you might be able to only store hashed versions of them. For <a href="https://wishy.gift/">Wishy.gift</a> I use SHA512 with a fixed salt, and this has been working perfectly since implementation in June.</p>
<p>Thank you for reading this! I would love to hear your thoughts and ideas too. Join the discussion on <a href="https://news.ycombinator.com/item?id=24959734">Hacker News</a>, or feel free to email me at <code>daniel</code> at the domain this blog is on.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>I discovered that, even though the ID was unique to my FB-app, it was still possible to go to <a href="http://facebook.com/%7Bid%7D">facebook.com/{id}</a> and be redirected to the user’s FB-profile. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965671</guid>
            <pubDate>Mon, 02 Nov 2020 08:11:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[As an older guy I've finally figured out weight-loss]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 115 (<a href="https://news.ycombinator.com/item?id=24965631">thread link</a>) | @RikNieu
<br/>
November 2, 2020 | https://www.riknieu.com/the-best-way-to-lose-weight/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/the-best-way-to-lose-weight/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>This post isn't really product or development related, but I think it applies to lots of us desk-job types. Hopefully it'll help someone else who's struggling just as much as I was.</p><h2 id="first-my-results-and-progress-so-far">First my results and progress so far</h2><p>I started getting serious about my diet at the end of September 2020. I weighed about 80kg/176lbs. </p><p>Today, on 1 Nov 2020, I weighed about 74kg/163lbs. </p><figure><img src="https://www.riknieu.com/content/images/2020/11/Screenshot-2020-11-01-at-17.09.12.png"><figcaption>My weight-loss chart 20 Sept - 1 Nov</figcaption></figure><p>That's a loss of 6kg/13lbs in a bit over a month! Insane! I would never have dreamt it possible for a middle-aged guy like me, who doesn't exercise too much and sits behind a computer all day to pull something like that off.</p><p>My journey is far from complete, but the progress I've had up to now is exciting enough to share. This would likely(hopefully) be the first in a series of posts detailing my weight-loss journey.</p><h2 id="the-backstory">The backstory</h2><p>I've never had a flat stomach in my entire life. Not when I was a kid, not when I was a young adult, and certainly not now, in my almost middle-age.</p><p>And I'm not even talking about having that shredded, six-pack look like the guys on the MensHealth covers, I'm just talking about a regular, flat tummy that doesn't bulge out in vague convex shape. I've always hovered between almost obese to dad-bod at best.</p><p>I've been self-conscious about my weight since forever. Being the fat kid in the 80s, when most kids weren't overweight yet left it's mark on my psyche and self-esteem. I got noticed and bullied for it, often. It also didn't help that my skin was pale enough to trip the sun when I took my shirt off on the beach.</p><p>All jokes aside, being able to swim in public without a shirt on has just never been in the realms of conceivability for me. The shame is too great.</p><p>Society, my community and my peers have made it very clear, since a young age, that nobody wants to see that shit. In fact, I don't think I've been in any form of public water without a shirt on since the age of 10. Maybe even earlier.</p><h2 id="when-the-dough-starts-to-rise">When the dough starts to rise</h2><p>I've learned to live with it, of course. The pale skin, the belly - it's not that bad. I mean, I've still managed to convince a poor, unsuspecting soul to be my wife. I still had fun outdoors. And getting older means nobody really cares about my appearance anymore, at least not to my face. Being doughy is not ideal but it's not that big a deal either.</p><p>I always assumed it's just the genetic cards I've been dealt, my unique biology or some sort of weird hormonal thing. This made sense to me because most of my extended family are overweight, and dangerously so. Maybe we're just built to look like this.</p><p>This idea might have a sliver of truth to it - I personally know people who look fit and fabulous without any seeming effort and who can eat whatever they like. </p><p>I, however, seem to gain weight by just looking at delicious food. But if I'm honest, declaring it impossible to slim down due to my genes might have just been a convenient excuse. </p><p>On my 38th birthday this year, I reflected on this, and the fact that my 40s were rapidly coming into view. I can see it emerging just over the horizon, arms and legs pumping as it's sprinting towards me. Soon.</p><p>I wasn't concerned with becoming unattractive with age(I've never been considered attractive anyway) but using my family history as a rough model for extrapolation suggested that the physical shape I was in then was past the point of good-as-it-would-ever-be. Other thoughts circled around, about getting older, about my losing my health, mobility and vitality. </p><p>And the signs were certainly there. My weight and pant size had already started creeping up over the last couple of years. </p><p>I wasn't obviously overweight, don't get me wrong. Most people would have considered my weight quite normal, perhaps even slim when compared to most of society. </p><p>But the trend in measurements suggested that my future would involve an ever-increasing waistline, with the eventual addition of tent-like shirts, feebly trying to conceal the obvious. </p><p>Yep, the coming years would see me getting rounder, wrinklier and unhealthier. Not paler though, that wouldn't be possible. This bun could never be baked, my genes won't allow for it.</p><h2 id="middle-age-is-looming-let-s-set-a-crazy-goal-">Middle-age is looming - let's set a crazy goal!</h2><p>To my credit though, I did realise that being middle-aged didn't mean it's game over yet. Perhaps I could still steer this ship around, if I just put my mind to it.</p><p>I won't ever become that tasty, handsome dish that turns heads, but perhaps I could aim for a relatively healthy, strong, utilitarian body? Like Sean Connery(RIP) in those first James Bond films. Old-school fit.</p><p>And with that musing, on the eve of my biological new year, I made the resolution to give it one last, genuine shot. </p><p>I would do my best to attempt a solid, last-ditch effort in getting my stomach flat. My goal is cultivating an appearance that I won't necessarily want to show off, but that I'd at least not feel the need to cover up and hide.</p><p>The idea is too sport, by the end of this year or early the next, a completely flat stomach without having to suck it in. And I would endeavour to keep it that way, perpetually, for the foreseeable future.</p><p>This will be hard, and I know it. I've been down this road before. Though I was comfortable plump my whole life, I am no stranger to diets and exercise. I know them well.</p><h2 id="the-revolving-door-of-fad-diets">The revolving door of fad diets </h2><p>In fact, I've tried almost every diet you can think of - keto, vegetarian, calorie counting, Fit-For-Life, caveman, paleo diet, slow carb... you name it, I probably tried it. And I've had various levels of success, but none left me with consistent, long-lasting results. Never mind washboard abs.</p><p>At best I'd maybe lose a couple of kilos, hit the inevitable plateau, and then give up out of frustration and resentment. Or I'd start feeling feeble and sick, suffer from weak concentration, or just feel generally miserable.</p><p>There was also the issue of inevitable birthdays and celebrations interfering, where I didn't want to be a party-pooper, or deny myself life's simple pleasures either, but which then would usually result in me falling off the bus. </p><p>And the cheat days too. Not often, maybe once or twice on weekends. Those, I told myself, would be needed to keep myself sane and motivated, to keep the cravings at bay. But they were a trap. Cheat day's may not add more weight, but they certainly stop any progress dead in its tracks.</p><p>Then there's exercise. Although my foray into the myriad of options available were not as extensive as with diets(due to some personal health limitations), my results - or lack thereof - were similar.</p><p>I tried to do some form of exercise at least 3 times a week. These included rollerblading with the wife, bodyweight routines, weight lifting, martial arts, walks and even the infernal torture that is running. </p><p>Exercise seemed to have <em>some</em> effect on sharpening my curves, but had no measurable effect on the scale.</p><p>Safe to say, it was pretty daunting to decide to commit to yet another version of this whole rigmarole again. When you feel you've tried everything before, you're skeptical this time would be different. Which diet would I be following this time, which training schedule?</p><p>I could feel that "it's just genetics" excuse looming just behind my shoulder, smugly waiting to tell me, "I told you so. It's pointless."</p><p>But this is what I wanted to do, so I decided to break it down and approach it from first principles, or at the very least keep it dead simple.</p><h2 id="best-way-of-losing-weight-science-simplicity-patience-and-discipline">Best way of losing weight? Science, simplicity, patience and discipline</h2><p>First principles suggested I stop faffing around with diets that operate on clever narratives, assumptions and "magic" rules, and just look at what the science said. And the science was pretty consistent - calories matter above all else. </p><p>The majority of studies suggested that for most people, the amount of calories consumed determines your weight. Hormonal factors exist, but they're either negligible or applicable to a very, very, VERY small part of the population. You're likely not it.</p><p>Exercise does help, but in the modern world with its convenient packaged foods one can easily consume way more calories in a single day than you could realistically burn off in a week of exercising. And if you're not cognisant of the calories in your meals and snacks, you won't even know it when you're over-consuming.</p><p>Now, of course I've tried calorie counting before, and it worked alright, but still lead to the inevitable plateau and quit cycle. This was something I'd need to be mindful of. I'd need to be strict to the max.</p><p>I decided that this time I was going to be <em>extremely</em> disciplined and committed. The only bending of rules would be cheat meals(not days) on birthdays or other rare and special occasions. Not weekly, like I weaselled about with before. No other cheating would be tolerated at all.</p><p>And for exercise it would be just as simple. I would do weight training 3x a week, ala <a href="https://startingstrength.com/">Starting Strength</a>, because it's the only form of exercise I actually enjoy doing. That's it. Beyond that would just be whatever recreational activities we did with friends over weekends.</p><h3 id="calories-energy-in-energy-out">Calories - energy in, energy out</h3><p>I'm not going to give you a lecture on calories and the intricacies behind their workings in this post, you can look it up yourself. </p><p>The <em>only</em> thing you need to know to successfully lose weight is that you need to consume less calories than your body requires to maintain its current weight. That's it. And, of course, you need to muster the discipline or come up with hacks to stick to it.</p><p>"Not all calories are equal!", I hear some of you seethe, and yes, I've considered that too. I took it into account for this experiment as well. It will be addressed below.</p><h2 id="weight-loss-plan">Weight-loss plan</h2><h4 id="5-steps-calculate-adjust-simplify-measure-patience">5 Steps - calculate, adjust, simplify, measure, patience</h4><p><strong>Calculate</strong> - Google and find a free calorie calculator online, enter your particular details, and calculate the amount of daily calories you need to maintain your current weight. </p><p><strong>Adjust</strong> - To lose weight you need to reduce the amount of daily calories you consume. Take the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.riknieu.com/the-best-way-to-lose-weight/">https://www.riknieu.com/the-best-way-to-lose-weight/</a></em></p>]]>
            </description>
            <link>https://www.riknieu.com/the-best-way-to-lose-weight/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965631</guid>
            <pubDate>Mon, 02 Nov 2020 08:02:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase.js 1.0 Released]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24965071">thread link</a>) | @awalias
<br/>
November 1, 2020 | https://supabase.io/blog/2020/10/30/improved-dx | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/10/30/improved-dx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p><time datetime="2020-10-30T00:00:00.000Z">October 30, 2020  · 3 min read</time></p><div><p><a href="https://github.com/kiwicopple" target="_blank" rel="noreferrer noopener"><img src="https://avatars2.githubusercontent.com/u/10214025?s=400&amp;u=c6775be2ae667e2acae3ccd347fed62bb3f5b3e7&amp;v=4" alt="Paul Copplestone"></a></p></div></header><section><p>Today we're releasing <a href="https://github.com/supabase/supabase-js" target="_blank" rel="noopener noreferrer">supabase-js</a> version 1.0, and it comes with some major Developer Experience improvements.</p><h3>New Docs</h3><p>Before digging into the improvements, we're excited to point out our new <a href="https://supabase.io/docs/client/supabase-client">developer docs</a>. While they're still a work in progress, here are some things we think you'll like:</p><ul><li>The <a href="https://supabase.io/docs/client/supabase-client">Reference Docs</a> are auto-generated from our Typescript definitions and then enriched with examples. This forces us to document our code and makes it easier to keep everything in sync.</li><li>We added placeholders for the other languages that the community is developing. They have already started with Python, C#, Dart, Rust, and Swift. Expect to see the docs filling up soon!</li><li>We've added sections for all of the open source tools we use, including <a href="https://supabase.io/docs/postgres/server/about">Postgres</a>, <a href="https://supabase.io/docs/postgrest/server/about">PostgREST</a>, <a href="https://supabase.io/docs/gotrue/server/about">GoTrue</a>, and <a href="https://supabase.io/docs/realtime/server/about">Realtime</a>. We'll be filling these with lots of valuable information including self-hosting, benchmarks, and simple guides.</li></ul><h3>Errors are returned, not thrown</h3><p>We attribute this improvement to community feedback. This has significantly improved the developer experience. Previously we would throw errors:</p><div><div><div><div><p><span>try</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> body </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>catch</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>error</span><span>)</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>And now we simply return them:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> data</span><span>,</span><span> error </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span><span></span></p><p><span></span><span>if</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>console</span><span>.</span><span>log</span><span>(</span><span>error</span><span>)</span><span></span></p></div></div></div></div><p>After testing this for a while we're very happy with this pattern. Errors are handled next to the offending function. Of course you can always rethrow the error if that's your preference.</p><h3>We created <code>gotrue-js</code></h3><p>Our goal for <code>supabase-js</code> is to tie together many sub-libaries. Each sub-library is a standalone implementation for a single external system. This is one of the ways we support existing open source tools.</p><p>To maintain this philosophy, we created <a href="https://github.com/supabase/gotrue-js" target="_blank" rel="noopener noreferrer"><code>gotrue-js</code></a>, a library for Netlify's GoTrue auth server. This libary includes a number of new additions, including third-party logins.</p><p>Previously:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span></span></p><p><span>  body</span><span>:</span><span> </span><span>{</span><span> user </span><span>}</span><span>,</span><span></span></p><p><span></span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> supabase</span><span>.</span><span>auth</span><span>.</span><span>signup</span><span>(</span><span></span></p><p><span>  </span><span>'someone@email.com'</span><span>,</span><span></span></p><p><span>  </span><span>'password'</span><span></span></p><p><span></span><span>)</span></p></div></div></div></div><p>Now:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> user</span><span>,</span><span> error </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> supabase</span><span>.</span><span>auth</span><span>.</span><span>signUp</span><span>(</span><span>{</span><span></span></p><p><span>  email</span><span>:</span><span> </span><span>'someone@email.com'</span><span>,</span><span></span></p><p><span>  password</span><span>:</span><span> </span><span>'password'</span><span></span></p><p><span></span><span>}</span><span>)</span></p></div></div></div></div><h3>Enhancements and fixes</h3><ul><li>Native Typescript. All of our libraries are now natively built with Typescript: <a href="https://github.com/supabase/supabase-js" target="_blank" rel="noopener noreferrer"><code>supabase-js</code></a>, <a href="https://github.com/supabase/postgrest-js" target="_blank" rel="noopener noreferrer"><code>postgrest-js</code></a>, <a href="https://github.com/supabase/gotrue-js" target="_blank" rel="noopener noreferrer"><code>gotrue-js</code></a>, and <a href="https://github.com/supabase/realtime-js" target="_blank" rel="noopener noreferrer"><code>realtime-js</code></a>.</li><li>Better realtime scalability: we only generate one socket connection per Supabase client. Previously we would create a connection for every subscription.</li><li>We've added support for OAuth providers.</li><li>60% of minor bugs outstanding for <code>supabase-js</code> have been <a href="https://github.com/supabase/supabase-js/pull/50" target="_blank" rel="noopener noreferrer">solved</a>.</li><li>You can use <code>select()</code> instead of <code>select(*)</code></li></ul><h3>Breaking changes</h3><p>We've bumped the major version because there are a number of breaking changes. We've detailed these in the <a href="https://github.com/supabase/supabase-js/releases/tag/v1.0.1" target="_blank" rel="noopener noreferrer">release notes</a>, but here are a few to be aware of:</p><ul><li><code>signup()</code> is now <code>signUp()</code> and <code>email</code> / <code>password</code> is passed as an object</li><li><code>logout()</code> is now <code>signOut()</code></li><li><code>login()</code> is now <code>signIn()</code></li><li><code>ova()</code> and <code>ovr()</code> are now just <code>ov()</code></li><li><code>body</code> is now <code>data</code></li></ul><p>Previously:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> body </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span></p></div></div></div></div><p>Now:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>)</span></p></div></div></div></div><h3>Upgrading</h3><p>We have documented all of the changes in the <a href="https://github.com/supabase/supabase-js/releases/tag/v1.0.1" target="_blank" rel="noopener noreferrer">release notes</a>. </p><p>To summarise the steps:</p><ol><li>Install the new version: <code>npm install @supabase/supabase-js@latest</code></li><li>Update all your <code>body</code> constants to <code>data</code></li><li>Update all your <code>supabase.auth</code> functions with the new <a href="https://supabase.io/docs/client/auth-signup">Auth interface</a></li></ol><h3>Get started</h3><ul><li>Start using Supabase today: <a href="https://app.supabase.io/" target="_blank" rel="noopener noreferrer">app.supabase.io</a></li><li>Make sure to <a href="https://github.com/supabase/supabase" target="_blank" rel="noopener noreferrer">star us on GitHub</a></li><li>Follow us <a href="https://twitter.com/supabase_io" target="_blank" rel="noopener noreferrer">on Twitter</a></li><li>Become a <a href="https://github.com/sponsors/supabase" target="_blank" rel="noopener noreferrer">sponsor</a></li></ul></section></article></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/10/30/improved-dx</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965071</guid>
            <pubDate>Mon, 02 Nov 2020 05:36:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Does It Take to Resolve a Hostname]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24965056">thread link</a>) | @todsacerdoti
<br/>
November 1, 2020 | https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname.jpg" alt="slide1"></p>

<ul>
  <li><a href="#resolving-a-name-is-complex">Resolving A Name Is Complex</a></li>
  <li><a href="#nih">NIH</a></li>
  <li><a href="#historic">Historic</a></li>
  <li><a href="#resolver3">resolver(3)</a></li>
  <li><a href="#gethostbyname3-and-getaddrinfo3">gethostbyname(3) and getaddrinfo(3)</a></li>
  <li><a href="#nss5">nss(5)</a></li>
  <li><a href="#resolvconf8">resolvconf(8)</a></li>
  <li><a href="#caching">Caching</a></li>
  <li><a href="#how-to-debug">How To Debug</a></li>
  <li><a href="#big-picture">Big Picture</a></li>
  <li><a href="#references">References</a></li>
</ul>

<p>Can also be found in presentation format <a href="https://youtu.be/Hd8Nc8ZRkNM">here</a></p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname2.jpg" alt="slide2"></p>

<p>Resolving a domain name is complex.  It’s not limited to the DNS, the
Domain Name System — A decentralized and hierarchical system to associate
names and other information to IP addresses.<br>
It’s not something we, as users, usually pay attention to.  We notice
it only when we’re facing an issue. It normally works out of the box
but really nobody get the crux.<br>
You search online for clarifications but they barely help and add more
confusion.</p>

<p>Here are some schemas trying to decipher the mystery that domain name
resolution came to be.</p>

<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname3.jpg" alt="slide3"></p>

<p>One, two, and three, I think you get me, it is not easy.  It’s never as
simple as taking a hostname as a string, getting the DNS address in the
<code>/etc/resolv.conf</code> config, then sending a request to the DNS on port 53
to be greeted back with the IP.<br>
Behind the scene there are ton of files and libraries involved, all of
this to get a domain name solved.</p>

<p>So in this talk we’ll try to create some order to try to understand thing
as an end-user. Let’s make sense and reason behind this mess even if I
have to say, I don’t get it much myself.<br>
I can’t assess I haven’t made mistakes but if I did, please correct me,
that would be great!</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname4.jpg" alt="slide4"></p>

<p>Let’s start with the misfits, the ones that don’t follow the rules,
the not-invented-here syndrome found within our tools.<br>
When it comes to DNS resolution, there’s no one-size fit all
solution. Obviously, many of us don’t want to deal with all the
complexity, so we say, “let’s pack these bytes ourselves, and forget
the hassle”.<br>
That’s pure heresy though. We’d prefer everything to work the same way,
so that it’s easier to follow. It would be preferable that they all use
the same lib, to all have the same behavior. That is, in our case to rely
on the C standard lib, or the POSIX API our savior.</p>

<p>In all cases, let’s note some software that don’t rely on it, as we said,
all the misfits.</p>

<ul>
  <li>The ISC/BSD BIND tools: from host, to dig, to drill, to nslookup,
and more, used for debugging chores.</li>
  <li>Firefox/Chrome/Chromium: There are the browsers, because they are one
of a kind, bypassing libc and POSIX mechanism, implementing their own
DNS API for performance reasons and perfectionism.</li>
  <li>Any applications needing advanced DNS features, other than simple name to IP.</li>
  <li>Language that don’t wrap around a libc: The Go programming language
comes to mind. It implements it’s own resolver API.</li>
</ul>

<p>Fortunately, I can ease your mind by letting you know that all
of these will at least respect <code>/etc/resolv.conf</code> and <code>/etc/hosts</code>
configurations. Files that we’ll see in the next sections.</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname5.jpg" alt="slide5"></p>

<p>I’ve taken a look at over a dozen different technologies and I think the
best way to understand them is through their archaeologies. There’s a
lot that can be explained about DNS resolution simply based on all the
historic reasons.<br>
The main thing you need to understand, is that there’s not a single
clean library call to resolve a hostname. Standards and new specs have
pilled up over the years, with some software that haven’t followed,
but risking to disappear.</p>

<p>Overall, libc and POSIX provide multiple resolution APIs:</p>

<ul>
  <li>There’s the historic, low level one provided by ISC/BSD BIND resolver
implementation within libc. Accessed though <code>libresolv/resolv.h</code>
incantation.</li>
  <li>The <code>gethostbyname(3)</code> and related functions, implementing an obsolete
POSIX C specification.</li>
  <li>The <code>getaddrinfo(3)</code>, that is the modern POSIX C API for name
resolution.</li>
</ul>

<p>All these combinations, ladies and gentlemen, are the standard ways
to resolve a name.<br>
Newer applications will use <code>getaddrinfo</code> while older ones will use
<code>gethostbyname</code>. Both of these 2 will often rely on something called
NSS and another part to manage <code>resolv.conf</code> access.</p>

<p>Now let’s dive into each of these and you’ll get them like a breeze.</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname6.jpg" alt="slide6"></p>

<p>The resolver layer is the oldest and most stable in our quest. It
originates from 1983, today almost 37 years ago, at Berkeley university.</p>

<p>It comes from a project called BIND, Berkely Internet Name Domain, which
was sponsored by a DARPA grants. And like the Berkeley socket that gave
rise to the internet, it has now turned into much much pain.<br>
It was the very first implementation of the DNS specifications. It got
released in BSD4.3 and today the BIND project is maintained by the
Internet Systems Consortium, aka ISC.</p>

<p>It not only offers servers and clients, and the debug tools which we
mentioned earlier, but also offers a library called “libbind”. This
library is the defacto implementation, the standard resolver, the one
of a kind. It is initially based on all the original RFC discussions,
namely RFC 881, 882, and 883.<br>
The BSD people wrote technical papers assessing its feasibility, and
went on recommending and implementing it within BSD.</p>

<p>At that point BIND wasn’t a standard yet, it was an optionally-compiled
code for those who wanted to get their feet wet, those who wanted to
try DNS.<br>
Then it got part of the C standard library interface through <code>resolver</code>,
<code>libresolv</code>, <code>-lresolv</code>, <code>resolv.h</code>, and closed the case</p>

<p>If you take a look at most Unix-like systems today, from MacOS, to
OpenBSD, to Linux, and company, you’ll see clearly in <code>resolv.h</code>, the
copyright going back to 1983, to that very date. But obviously, it depends
on the choice of the implementer, a case by case</p>

<p>So then the code diverged, there’s the libresolv provided
by the C standardization and the libbind provided by the BIND
implementation. However, most Unix only add small specific changes to
their needs. For example, resolver in glibc is baselined off libbind
from BIND version 8.2.3.</p>

<p>This layer is normally used for low level DNS interactions because it’s
missing the goodies we’ll see later in this presentation.</p>

<p>Now let’s talk about environments and configurations.</p>

<p>The resolver configuration file</p>

<p>The resolver configuration files were mentioned in BIND first release,
in section 4.2.2.2 of “The Design and Implementation of ‘Domain Name
Resolver’” by Mark Painter based on RFC883, part of the DNS RFC series.</p>

<p>This particular file being <code>/etc/resolv.conf</code>, you’ll see it hardcoded in
<code>resolv.h</code> and if that file is missing, it’ll fall back to the localhost
as the DNS, just to be safe.<br>
Additionally, there’s <code>/etc/host.conf</code>, according to the manpage also
“the resolver configuration file”, it’s so appropriately named. It’s a
conf that dictates the working of <code>/etc/hosts</code>, the “static table lookup
for hostsnames”.</p>

<p>So what’s in these files.<br>
<code>resolv.conf</code> takes care of how to resolve names and which <code>nameserver</code>
to use for that, while <code>hosts</code> simply has a list of known host aliases,
ip + name, as simple as that.</p>

<p>Within <code>resolv.conf</code> you can also have a <code>search</code> list for domains.
That’s if a name you’re searching for doesn’t have the minimum number
of dots in it then it’ll add one of these TLD to it, top-level-domains,
and keep searching until it finds something that fits.<br>
This can also be manipulated in an environment variable <code>LOCALDOMAIN</code>.</p>

<figure><pre><code data-lang="shell"><span>$ </span><span>echo</span> <span>'example www.example.com'</span> <span>&gt;</span> ./host_aliases
<span>$ HOSTALIASES</span><span>=</span><span>"./host_aliases"</span> getent hosts example
93.184.216.34   www.example.com</code></pre></figure>

<p>There can also be a sortlist IP netmask, for when there’s many results
to match but you don’t want to give priority to the cloud VPS that lives
only for cash.</p>

<p>Finally, there’s the <code>option</code> field, also overriden on the command
line by the <code>RES_OPTIONS</code> environment variable. It manipulates the minimum
number of dots we mentioned and also if you want can set debug as enabled.</p>

<p>Meanwhile, the <code>hosts</code> file is but a key-value db, simply made of domain
names and IPs.</p>

<p>Its config also lets you change the order of results and for the rest
you have <code>host.conf</code> to consult.</p>

<p>So remember, that all of these are mostly used everywhere because it’s
the lowest layer.  So it’s used by libbind and libresolv but also the
custom NIH syndrome</p>

<p>Alright, so far that’s all classic clean stuff. Let’s move on to the
next sections, you’ll scratch your head until there’s no dandruff.</p>



<p><img src="https://venam.nixers.net/blog/assets/resolving_hostname/What_Does_It_Take_To_Resolve_A_Hostname7.jpg" alt="slide7"></p>

<p>The C library POSIX specs create a superset over the C standard
library. They add a few simpler calls to resolve hostnames and make it
easy. These focus on returning A and AAAA records only, ipV4 and ipV6
respsectively.<br>
There’s <code>gethostbyname(3)</code> which is deprecated, and there’s the newer
<code>getaddrinfo(3)</code> defined in IEEE Std 1003.1g-2000, which mainly adds
RFC3493 aka ipV6 is now supported.  So applications are recommended to
use this updated version unless they want to divert from mainland.</p>

<p>There are functions to resolve IP addresses to host names, but let’s
focus only on name to ip for today, I know it’s lame.</p>

<p>Apart from ipV6 support being added, some internal structures have been
updated as they weren’t so safe between subsequent calls and thus could
be your demise and your fall.</p>

<p>Obviously they both return different structures.</p>

<p><code>hostent</code> struct is returned to <code>gethostbyname</code> function caller.
while <code>getaddrinfo</code> returns an <code>addrinfo</code> structure.
Both being defined in the <code>netdb.h</code> header.</p>

<figure><pre><code data-lang="c"><span>struct</span> <span>hostent</span> <span>{</span>
	<span>char</span>  <span>*</span><span>h_name</span><span>;</span>            <span>/* official name of host */</span>
	<span>char</span> <span>**</span><span>h_aliases</span><span>;</span>         <span>/* alias list */</span>
	<span>int</span>    <span>h_addrtype</span><span>;</span>        <span>/* host address type */</span>
	<span>int</span>    <span>h_length</span><span>;</span>          <span>/* length of address */</span>
	<span>char</span> <span>**</span><span>h_addr_list</span><span>;</span>       <span>/* list of addresses */</span>
<span>}</span></code></pre></figure>

<figure><pre><code data-lang="c"><span>struct</span> <span>addrinfo</span> <span>{</span>
	<span>int</span>              <span>ai_flags</span><span>;</span>
	<span>int</span>              <span>ai_family</span><span>;</span>
	<span>int</span>              <span>ai_socktype</span><span>;</span>
	<span>int</span>              <span>ai_protocol</span><span>;</span>
	<span>socklen_t</span>        <span>ai_addrlen</span><span>;</span>
	<span>struct</span> <span>sockaddr</span> <span>*</span><span>ai_addr</span><span>;</span>
	<span>char</span>            <span>*</span><span>ai_canonname</span><span>;</span>
	<span>struct</span> <span>addrinfo</span> <span>*</span><span>ai_next</span><span>;</span>
<span>};</span></code></pre></figure>

<p>Some libc implementations will get fancy and add their own modified
versions of <code>gethostbyname</code>. For instance in glibc they add support for
ipV6 in their modified <code>gethostbyname2</code> for backward compatibility.</p>

<p>Regarding configuration files, <code>getaddrinfo</code> will consult <code>/etc/gai.conf</code>
which takes care of the precedence of the addresses returned in the
results. And now, you’re going to brandish your …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html">https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/unix/2020/11/01/resolving-a-hostname.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965056</guid>
            <pubDate>Mon, 02 Nov 2020 05:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rendering photo-realistic glass in the browser]]>
            </title>
            <description>
<![CDATA[
Score 388 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24965005">thread link</a>) | @anonytrary
<br/>
November 1, 2020 | https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/ | <a href="https://web.archive.org/web/*/https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965005</guid>
            <pubDate>Mon, 02 Nov 2020 05:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Leaders Need to Learn the Skill of Writing]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24964730">thread link</a>) | @mooreds
<br/>
November 1, 2020 | https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/ | <a href="https://web.archive.org/web/*/https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

		
			<article id="post-6068">
	
	
		

	<div>
		<p><img data-attachment-id="6071" data-permalink="https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/shutterstock_55915930-e1415052560114-2/" data-orig-file="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?fit=3862%2C1974&amp;ssl=1" data-orig-size="3862,1974" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="shutterstock_55915930-e1415052560114-2" data-image-description="" data-medium-file="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?fit=300%2C153&amp;ssl=1" data-large-file="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?fit=723%2C369&amp;ssl=1" loading="lazy" src="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=715%2C365&amp;ssl=1" alt="" width="715" height="365" srcset="https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?w=3862&amp;ssl=1 3862w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=300%2C153&amp;ssl=1 300w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=1024%2C523&amp;ssl=1 1024w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=768%2C393&amp;ssl=1 768w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=1536%2C785&amp;ssl=1 1536w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?resize=2048%2C1047&amp;ssl=1 2048w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?w=1446&amp;ssl=1 1446w, https://i0.wp.com/fromthegreennotebook.com/wp-content/uploads/2020/10/shutterstock_55915930-e1415052560114-2.jpg?w=2169&amp;ssl=1 2169w" sizes="(max-width: 715px) 100vw, 715px" data-recalc-dims="1"></p>
<p>By Joe Byerly<span data-ez-name="fromthegreennotebook_com-box-3"></span></p>
<p>Anyone who has worked directly for a battalion commander or above probably has experience writing “ghost notes.” These are emails a subordinate writes and addresses for their boss to send to other people. Ghost notes can be weekly or monthly sitreps, updates on an ongoing situation or emails asking for additional resources. No matter the type, they are the “easy button” for the commander because all they have to do is hit “send.”</p>
<p>Recently, I worked for a senior Army leader who encouraged his subordinate commanders to own their communications—meaning, write their own emails. As I reflected on his guidance, I realized there are benefits to communications ownership. I witnessed many of these benefits firsthand as I watched him communicate with senior military leaders, senior civilian leaders and his own commanders.<span data-ez-name="fromthegreennotebook_com-medrectangle-3"></span></p>

<p><strong>Greatness and Writing</strong></p>
<p>One of the best ways to work through a problem is to write it down. Throughout history, leaders who found themselves in tough situations sat alone with their thoughts and worked through them using pen and paper.<span data-ez-name="fromthegreennotebook_com-medrectangle-4"></span></p>
<p>Marcus Aurelius, who served as Roman emperor for almost two decades, wrote his <em>Meditations</em> to work through daily leadership challenges, wars and a pandemic. In the week leading up to the D-Day landings, Gen. Dwight Eisenhower wrote himself letters to help work through risks, opportunities and necessities of operations.</p>
<p>Both Marcus and Eisenhower used writing to achieve clarity of thought. This point is underscored by author Stephen King, who has said writing is “refined thinking.” In our minds, our thoughts are clear, but real clarity doesn’t come until those thoughts are solidified in writing. The process of framing an email, capturing important points and discarding nonessential elements helps us gain more clarity.</p>
<p><strong>Sound Authentic</strong></p>
<p>Over the years, I have worked under multiple commanders while in staff positions, and the best ones never let me draft their intent for operations orders. They wanted to own those. At the time, I didn’t understand it—thinking it was one more staff drill I could handle for them. But as I gained experience, I realized they wanted that section of the operations order to reflect their voice.<span data-ez-name="fromthegreennotebook_com-box-4"></span></p>
<p>We all have a voice when we write. This voice is our certificate of authenticity. When commanders write their own correspondence, their voice comes through. When someone else drafts an email, using words and phrases the commander wouldn’t normally use, others can tell someone else wrote it.</p>
<p>Authenticity in communications is important for two reasons. First, subordinates will know if the intent, the guidance, the policy, etc., is the commander’s, or if it is another product produced by staff. They are more likely to follow it and adhere to it when they know it comes directly from the commander’s mind and is not a draft by a random staff officer.</p>
<p>Also, commanders who write their own communications tend to reinforce the message by repeating what they wrote. The senior Army leader I worked for occasionally wrote guidance that he sent out in an email. He then repeated key words and phrases from the document in meetings, during battlefield circulation and in one-on-one discussions. Everyone knew he wrote the email because he owned it and talked about it; his guidance didn’t become memorandums left on a bulletin board in a headquarters.</p>
<p>The second reason authenticity in communications is important is that it signals leader involvement in an issue. I have learned that many senior leaders can tell when a subordinate commander’s email is authentic or a staff-produced ghost note.</p>
<p>Every time there was a change or inflection point in the strategic situation, my boss would provide a one- or two-page update to his commanders. He always wrote these himself, for the reasons mentioned above. I found out from those commanders’ staff members that their bosses read these emails because they knew it was from him, and that if he took the time to write it, they should take the time to read it.</p>
<p>Communication can be frustrating. Sometimes it is like tapping out a song you have in your head and expecting another person to immediately know the tune. It is hard to convey an idea in your head to someone who may not have the same background or experiences as you, or who wasn’t in the same room when you had a conversation.</p>
<p>Communication is a skill that takes practice. We need repetition. Leaders who write their own emails gain needed communication experience when it matters. I have also learned that speed comes with practice. I can write in hours what used to take days.</p>
<p><strong>Honing the Skill</strong></p>
<p>I recognize that commanders have a lot on their plates, and it isn’t feasible for them to spend hours writing and responding to emails. There are many ghost notes best produced by staff in the interest of time. However, when it comes to communicating up or down the chain of command on key issues, or writing guidance on important topics, it is best for commanders to own those.</p>
<p>Great leaders are also great communicators, but the ability to communicate effectively and efficiently takes time to develop. By owning communications, commanders refine and hone this skill. They also have an opportunity to work through problems and refine their thinking through the process of writing. Finally, they gain authenticity in their communications—an important factor in ensuring that “message sent” is “message received.”</p>
<p>This article was first published in <a href="https://www.ausa.org/articles/leaders-subject-write-your-own-emails">ARMY Magazine</a> and reprinted with their permission.</p>



	





		
		
					</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article><!-- #post-## -->

			
<!-- #comments -->

		
		</main><!-- #main -->
	</section><!-- #primary -->

	<!-- #secondary --></div></div>]]>
            </description>
            <link>https://fromthegreennotebook.com/2020/10/03/why-leaders-need-to-learn-the-skill-of-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964730</guid>
            <pubDate>Mon, 02 Nov 2020 04:03:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewire: A New Approach to Dependency Injection in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24964122">thread link</a>) | @stephanos2k
<br/>
November 1, 2020 | https://blog.stephanbehnke.com/rewire-new-approach-to-dependency-injection-in-elixir/ | <a href="https://web.archive.org/web/*/https://blog.stephanbehnke.com/rewire-new-approach-to-dependency-injection-in-elixir/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        Stephan Behnke
        <br>
        <span>on&nbsp;</span><time datetime="2020-10-30 00:38:50 +0000 UTC">October 30, 2020</time>
</p>
		


		


		<p>I’ve been working with Elixir for 3 years full-time now and while I think it’s an exceptional language and development environment, the testing story always felt incomplete to me. Something was missing. In this post, I’ll explain what that is and how I attempted to fix it.</p>
<h2 id="injecting-mocks">Injecting Mocks</h2>
<p>While I strive to minimize the use of mocks, I find they are still quite useful in certain situations.</p>
<p>Before Elixir, I’ve mainly worked with Java. For better or worse, in Java you have a multitude of options to inject dependencies into your classes. Most notably, <code>@Autowired</code> that allows you to simply override annotated fields during testing with your mock. Could not be simpler.</p>
<p>In Elixir things are a little different. That’s because Elixir does not have classes or class fields. Modules are <em>stateless</em>. So how does one inject a dependency in Elixir?</p>
<p>Let’s look at this simplified example and explore our options:</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation</span> <span>do</span>
  <span>def</span> <span>start</span><span>(),</span> <span>do</span><span>:</span> <span>English</span><span>.</span><span>greet</span><span>()</span>
<span>end</span>
</code></pre></div><h2 id="-function-arguments">🛑 Function Arguments</h2>
<p>The easiest approach does not require any libraries: passing-in dependencies using the function arguments.</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation</span> <span>do</span>
  <span>def</span> <span>start</span><span>(</span><span>lang_mod</span> <span>\\</span> <span>English</span><span>),</span> <span>do</span><span>:</span> <span>lang_mod</span><span>.</span><span>greet</span><span>()</span>
<span>end</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>false</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>defmodule</span> <span>EnglishMock</span> <span>do</span>
      <span>def</span> <span>greet</span><span>(),</span> <span>do</span><span>:</span> <span>"g'day"</span>
    <span>end</span>
    <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>(</span><span>EnglishMock</span><span>)</span> <span>==</span> <span>"g'day"</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p>While many (including myself) find this to look “odd” at first, it is admittedly easy to do.</p>
<p>However, it comes with quite a few drawbacks:</p>
<ol>
<li>Your application code is now littered with testing concerns.</li>
<li>Navigation in your code editor doesn’t work as well.</li>
<li>Searches for usages of the module are more difficult.</li>
<li>The compiler is not able to warn you in case <code>greet/0</code> doesn’t exist on the <code>English</code> module.</li>
</ol>
<h2 id="-global-override">🛑 Global Override</h2>
<p>The Elixir library <a href="https://hex.pm/packages/mock">mock</a> (wrapping the Erlang library <a href="https://hex.pm/packages/meck">meck</a> under the hood) allows overriding any module globally.</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>false</span>   <span># not concurrently!</span>

  <span>import</span> <span>Mock</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>with_mock</span> <span>English</span><span>,</span> <span>[</span><span>greet</span><span>:</span> <span>fn</span><span>()</span> <span>-&gt;</span> <span>"g'day"</span> <span>end</span><span>]</span> <span>do</span>
      <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>()</span> <span>==</span> <span>"g'day"</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p>Here the <code>English</code> module is temporarily replaced with a mock that stubs out the <code>greet</code> function. So far so good - but it comes with a cost. One of ExUnit’s most valuable features is the ability to run tests <em>concurrently</em>. However, to stub out modules <em>globally</em> we have to exempt this test module from being run concurrently (notice the <code>async: false</code>). This might seem like a small price to pay but if your application grows you might soon find yourself with a slow test suite. This can easily be avoided!</p>
<h2 id="-configuration-lookup">🛑 Configuration Lookup</h2>
<p>The more or less official mocking library for Elixir is <a href="https://hex.pm/packages/mox">mox</a>.</p>
<div><pre><code data-lang="elixir"><span># in test_helper.exs</span>
<span>Mox</span><span>.</span><span>defmock</span><span>(</span><span>EnglishMock</span><span>,</span> <span>for</span><span>:</span> <span>English</span><span>)</span>
<span>Application</span><span>.</span><span>put_env</span><span>(</span><span>:myapp</span><span>,</span> <span>:english</span><span>,</span> <span>EnglishMock</span><span>)</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation</span> <span>do</span>
  <span>def</span> <span>start</span><span>(),</span> <span>do</span><span>:</span> <span>english</span><span>()</span><span>.</span><span>greet</span><span>()</span>
  <span>defp</span> <span>english</span><span>(),</span> <span>do</span><span>:</span> <span>Application</span><span>.</span><span>get</span><span>(</span><span>:myapp</span><span>,</span> <span>:english</span><span>,</span> <span>English</span><span>)</span>
<span>end</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>true</span>  <span># concurrently!</span>

  <span>import</span> <span>Mox</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>stub</span><span>(</span><span>English</span><span>,</span> <span>:greet</span><span>,</span> <span>fn</span> <span>-&gt;</span> <span>"g'day"</span> <span>end</span><span>)</span>
    <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>()</span> <span>==</span> <span>"g'day"</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p><code>mox</code> provides a mock that is “injected” into the module under test by doing a lookup in the app’s configuration.</p>
<p>The advantage is that the “odd” function parameter is gone, but all of the other issues are still there. But at least it can be run concurrently since the mock is set up <em>per process</em> (and each test module is its own process in ExUnit).</p>
<h2 id="-rewire">🎉 rewire</h2>
<p>I wasn’t satisfied with any of these options. So I experimented a little with Elixir metaprogramming and the result was <a href="https://hex.pm/packages/rewire">rewire</a>.</p>
<p>It focuses purely on dependency injection and can be used with any mocking library, like <code>mox</code>.</p>
<div><pre><code data-lang="elixir"><span># in test_helper.exs</span>
<span>Mox</span><span>.</span><span>defmock</span><span>(</span><span>EnglishMock</span><span>,</span> <span>for</span><span>:</span> <span>English</span><span>)</span>
</code></pre></div><div><pre><code data-lang="elixir"><span>defmodule</span> <span>MyTest</span> <span>do</span>
  <span>use</span> <span>ExUnit.Case</span><span>,</span> <span>async</span><span>:</span> <span>true</span>  <span># concurrently!</span>

  <span>import</span> <span>Rewire</span>
  <span>import</span> <span>Mox</span>

  <span>rewire</span> <span>Conversation</span><span>,</span> <span>English</span><span>:</span> <span>EnglishMock</span>  <span># inject!</span>

  <span>test</span> <span>"start/0"</span> <span>do</span>
    <span>stub</span><span>(</span><span>EnglishMock</span><span>,</span> <span>:greet</span><span>,</span> <span>fn</span> <span>-&gt;</span> <span>"g'day"</span> <span>end</span><span>)</span>
    <span>assert</span> <span>Conversation</span><span>.</span><span>start</span><span>()</span> <span>==</span> <span>"g'day"</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p>By following this approach, we keep our production code completely free of testing concerns and the test can still be run concurrently!</p>
<p>You can use it with any mocking library, not just <code>mox</code>. Or just stubs you defined yourself. It only cares about dependency injection.</p>
<h2 id="ehm-but-how-does-it-work">Ehm, But How Does it Work?</h2>
<p><code>rewire</code> is a macro, imported via <code>import Rewire</code>.</p>
<p>Let’s look at what code the macro generated here:</p>
<div><pre><code data-lang="elixir"><span>defmodule</span> <span>Conversation.R518</span> <span>do</span>
  <span>def</span> <span>start</span><span>(),</span> <span>do</span><span>:</span> <span>EnglishMock</span><span>.</span><span>greet</span><span>()</span>
<span>end</span>

<span>alias</span> <span>Conversation.R518</span><span>,</span> <span>as</span><span>:</span> <span>Conversation</span>
</code></pre></div><p>First, it generates a <em>copy</em> of the original module with the <code>English</code> reference <em>replaced</em> by <code>EnglishMock</code>. You might also notice that the module name has changed. Since the module might be rewired in multiple places, this is supposed to prevent naming collisions.</p>
<p>Then, it adds an alias to the rewired module under the <em>original</em> name.</p>
<p>You might wonder how it generates a new module from the original one. The library finds the module’s source file path by calling <code>module_info</code>, parses the code into an AST with <code>Code.string_to_quoted</code>, traverses the AST to replace any rewired dependencies using <code>Macro.traverse</code> and evaluates the result with <code>Code.eval_quoted</code>. Check out the <a href="https://github.com/stephanos/rewire/blob/master/lib/rewire">source code</a> for details.</p>
<h2 id="limitation">Limitation</h2>
<p>As far as I know, the only situation where you cannot use <code>rewire</code> to inject your dependencies is when you are dealing with a process that has been started <em>before</em> your test.</p>
<p>Take for example a <a href="https://www.phoenixframework.org/">Phoenix</a> controller test. Since you’ll be writing tests against the server (using <code>ConnCase</code>), a dependency in the controller cannot be rewired after the fact.</p>
<h2 id="la-fin">La Fin</h2>
<p>I hope you enjoyed this blog post. If you have any questions or feedback, please leave a comment. And if you’re curious, try out <a href="https://hex.pm/packages/rewire">rewire</a> yourself.</p>


		








<p><a href="https://disqus.com/">comments powered by </a>

	</p></div>

	
</div></div>]]>
            </description>
            <link>https://blog.stephanbehnke.com/rewire-new-approach-to-dependency-injection-in-elixir/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24964122</guid>
            <pubDate>Mon, 02 Nov 2020 01:31:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Developing a game using the tool I made]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24963979">thread link</a>) | @atum47
<br/>
November 1, 2020 | https://victorribeiro.com/kingdomClone/ | <a href="https://web.archive.org/web/*/https://victorribeiro.com/kingdomClone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://victorribeiro.com/kingdomClone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963979</guid>
            <pubDate>Mon, 02 Nov 2020 00:59:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Names are not type safety]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24963821">thread link</a>) | @azhenley
<br/>
November 1, 2020 | http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/ | <a href="https://web.archive.org/web/*/http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section role="main">
        <!-- Main column -->
        <div>



          <article>
  <header>
    
    
  </header>

<p>Haskell programmers spend a lot of time talking about <em>type safety</em>. The Haskell school of program construction advocates “capturing invariants in the type system” and “making illegal states unrepresentable,” both of which sound like compelling goals, but are rather vague on the techniques used to achieve them. Almost exactly one year ago, I published <a href="http://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, Don’t Validate</a> as an initial stab towards bridging that gap.</p>

<p>The ensuing discussions were largely productive and right-minded, but one particular source of confusion quickly became clear: Haskell’s <code>newtype</code> construct. The idea is simple enough—the <code>newtype</code> keyword declares a wrapper type, nominally distinct from but representationally equivalent to the type it wraps—and on the surface this <em>sounds</em> like a simple and straightforward path to type safety. For example, one might consider using a <code>newtype</code> declaration to define a type for an email address:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>EmailAddress</span> <span>=</span> <span>EmailAddress</span> <span>Text</span>
</pre></div>

</div>

<p>This technique can provide <em>some</em> value, and when coupled with a smart constructor and an encapsulation boundary, it can even provide some safety. But it is a meaningfully distinct <em>kind</em> of type safety from the one I highlighted a year ago, one that is far weaker. On its own, a newtype is just a name.</p>

<p>And names are not type safety.</p>
<!-- more-->



<p>To illustrate the difference between constructive data modeling (discussed at length in my <a href="http://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/">previous blog post</a>) and newtype wrappers, let’s consider an example. Suppose we want a type for “an integer between 1 and 5, inclusive.” The natural constructive modeling would be an enumeration with five cases:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>OneToFive</span>
  <span>=</span> <span>One</span>
  <span>|</span> <span>Two</span>
  <span>|</span> <span>Three</span>
  <span>|</span> <span>Four</span>
  <span>|</span> <span>Five</span>
</pre></div>

</div>

<p>We could then write some functions to convert between <code>Int</code> and our <code>OneToFive</code> type:</p>

<div>
 <div>
  <pre><span></span><span>toOneToFive</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Maybe</span> <span>OneToFive</span>
<span>toOneToFive</span> <span>1</span> <span>=</span> <span>Just</span> <span>One</span>
<span>toOneToFive</span> <span>2</span> <span>=</span> <span>Just</span> <span>Two</span>
<span>toOneToFive</span> <span>3</span> <span>=</span> <span>Just</span> <span>Three</span>
<span>toOneToFive</span> <span>4</span> <span>=</span> <span>Just</span> <span>Four</span>
<span>toOneToFive</span> <span>5</span> <span>=</span> <span>Just</span> <span>Five</span>
<span>toOneToFive</span> <span>_</span> <span>=</span> <span>Nothing</span>

<span>fromOneToFive</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Int</span>
<span>fromOneToFive</span> <span>One</span>   <span>=</span> <span>1</span>
<span>fromOneToFive</span> <span>Two</span>   <span>=</span> <span>2</span>
<span>fromOneToFive</span> <span>Three</span> <span>=</span> <span>3</span>
<span>fromOneToFive</span> <span>Four</span>  <span>=</span> <span>4</span>
<span>fromOneToFive</span> <span>Five</span>  <span>=</span> <span>5</span>
</pre></div>

</div>

<p>This would be perfectly sufficient for achieving our stated goal, but you’d be forgiven for finding it odd: it would be rather awkward to work with in practice. Because we’ve invented an entirely new type, we can’t reuse any of the usual numeric functions Haskell provides. Consequently, many programmers would gravitate towards a newtype wrapper, instead:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>OneToFive</span> <span>=</span> <span>OneToFive</span> <span>Int</span>
</pre></div>

</div>

<p>Just as before, we can provide <code>toOneToFive</code> and <code>fromOneToFive</code> functions, with identical types:</p>

<div>
 <div>
  <pre><span></span><span>toOneToFive</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Maybe</span> <span>OneToFive</span>
<span>toOneToFive</span> <span>n</span>
  <span>|</span> <span>n</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span> <span>&lt;=</span> <span>5</span> <span>=</span> <span>Just</span> <span>$</span> <span>OneToFive</span> <span>n</span>
  <span>|</span> <span>otherwise</span>        <span>=</span> <span>Nothing</span>

<span>fromOneToFive</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Int</span>
<span>fromOneToFive</span> <span>(</span><span>OneToFive</span> <span>n</span><span>)</span> <span>=</span> <span>n</span>
</pre></div>

</div>

<p>If we put these declarations in their own module and choose not to export the <code>OneToFive</code> constructor, these APIs might appear entirely interchangeable. Naïvely, it seems that the newtype version is both simpler and equally type-safe. However—perhaps surprisingly—this is not actually true.</p>

<p>To see why, suppose we write a function that consumes a <code>OneToFive</code> value as an argument. Under the constructive modeling, such a function need only pattern-match against each of the five constructors, and GHC will accept the definition as exhaustive:</p>

<div>
 <div>
  <pre><span></span><span>ordinal</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Text</span>
<span>ordinal</span> <span>One</span>   <span>=</span> <span>"first"</span>
<span>ordinal</span> <span>Two</span>   <span>=</span> <span>"second"</span>
<span>ordinal</span> <span>Three</span> <span>=</span> <span>"third"</span>
<span>ordinal</span> <span>Four</span>  <span>=</span> <span>"fourth"</span>
<span>ordinal</span> <span>Five</span>  <span>=</span> <span>"fifth"</span>
</pre></div>

</div>

<p>The same is not true given the newtype encoding. The newtype is opaque, so the only way to observe it is to convert it back to an <code>Int</code>—after all, it <em>is</em> an <code>Int</code>. An <code>Int</code> can of course contain many other values besides <code>1</code> through <code>5</code>, so we are forced to add an error case to satisfy the exhaustiveness checker:</p>

<div>
 <div>
  <pre><span></span><span>ordinal</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Text</span>
<span>ordinal</span> <span>n</span> <span>=</span> <span>case</span> <span>fromOneToFive</span> <span>n</span> <span>of</span>
  <span>1</span> <span>-&gt;</span> <span>"first"</span>
  <span>2</span> <span>-&gt;</span> <span>"second"</span>
  <span>3</span> <span>-&gt;</span> <span>"third"</span>
  <span>4</span> <span>-&gt;</span> <span>"fourth"</span>
  <span>5</span> <span>-&gt;</span> <span>"fifth"</span>
  <span>_</span> <span>-&gt;</span> <span>error</span> <span>"impossible: bad OneToFive value"</span>
</pre></div>

</div>

<p>In this highly contrived example, this may not seem like much of a problem to you. But it nonetheless illustrates a key difference in the guarantees afforded by the two approaches:</p>

<ul>
 <li>
  <p>The constructive datatype captures its invariants in such a way that they are <em>accessible</em> to downstream consumers. This frees our <code>ordinal</code> function from worrying about handling illegal values, as they have been made unutterable.</p></li>
 <li>
  <p>The newtype wrapper provides a smart constructor that <em>validates</em> the value, but the boolean result of that check is used only for control flow; it is not preserved in the function’s result. Accordingly, downstream consumers cannot take advantage of the restricted domain; they are functionally accepting <code>Int</code>s.</p></li></ul>

<p>Losing exhaustiveness checking might seem like small potatoes, but it absolutely is not: our use of <code>error</code> has punched a hole right through our type system. If we were to add another constructor to our <code>OneToFive</code> datatype,<sup><a href="#2020-11-01-names-are-not-type-safety-footnote-1-definition" name="2020-11-01-names-are-not-type-safety-footnote-1-return">1</a></sup> the version of <code>ordinal</code> that consumes a constructive datatype would be immediately detected non-exhaustive at compile-time, while the version that consumes a newtype wrapper would continue to compile yet fail at runtime, dropping through to the “impossible” case.</p>

<p>All of this is a consequence of the fact that the constructive modeling is <em>intrinsically</em> type-safe; that is, the safety properties are enforced by the type declaration itself. Illegal values truly are unrepresentable: there is simply no way to represent <code>6</code> using any of the five constructors. The same is not true of the newtype declaration, which has no intrinsic semantic distinction from that of an <code>Int</code>; its meaning is specified extrinsically via the <code>toOneToFive</code> smart constructor. Any semantic distinction intended by a newtype is thoroughly invisible to the type system; it exists only in the programmer’s mind.</p>

<h2 id="revisiting-non-empty-lists">Revisiting non-empty lists</h2>

<p>Our <code>OneToFive</code> datatype is rather artificial, but identical reasoning applies to other datatypes that are significantly more practical. Consider the <code>NonEmpty</code> datatype I’ve repeatedly highlighted in recent blog posts:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>a</span> <span>:|</span> <span>[</span><span>a</span><span>]</span>
</pre></div>

</div>

<p>It may be illustrative to imagine a version of <code>NonEmpty</code> represented as a newtype over ordinary lists. We can use the usual smart constructor strategy to enforce the desired non-emptiness property:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>NonEmpty</span> <span>[</span><span>a</span><span>]</span>

<span>nonEmpty</span> <span>::</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>Maybe</span> <span>(</span><span>NonEmpty</span> <span>a</span><span>)</span>
<span>nonEmpty</span> <span>[]</span> <span>=</span> <span>Nothing</span>
<span>nonEmpty</span> <span>xs</span> <span>=</span> <span>Just</span> <span>$</span> <span>NonEmpty</span> <span>xs</span>

<span>instance</span> <span>Foldable</span> <span>NonEmpty</span> <span>where</span>
  <span>toList</span> <span>(</span><span>NonEmpty</span> <span>xs</span><span>)</span> <span>=</span> <span>xs</span>
</pre></div>

</div>

<p>Just as with <code>OneToFive</code>, we quickly discover the consequences of failing to preserve this information in the type system. Our motivating use case for <code>NonEmpty</code> was the ability to write a safe version of <code>head</code>, but the newtype version requires another assertion:</p>

<div>
 <div>
  <pre><span></span><span>head</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>head</span> <span>xs</span> <span>=</span> <span>case</span> <span>toList</span> <span>xs</span> <span>of</span>
  <span>x</span><span>:</span><span>_</span> <span>-&gt;</span> <span>x</span>
  <span>[]</span>  <span>-&gt;</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>
</pre></div>

</div>

<p>This might not seem like a big deal, since it seems unlikely such a case would ever happen. But that reasoning hinges entirely on trusting the correctness of the module that defines <code>NonEmpty</code>, while the constructive definition only requires trusting the GHC typechecker. As we generally trust that the typechecker works correctly, the latter is a much more compelling proof.</p>



<p>If you are fond of newtypes, this whole argument may seem a bit troubling. It may seem like I’m implying newtypes are scarcely better than comments, albeit comments that happen to be meaningful to the typechecker. Fortunately, the situation is not quite that grim—newtypes <em>can</em> provide a sort of safety, just a weaker one.</p>

<p>The primary safety benefit of newtypes is derived from abstraction boundaries. If a newtype’s constructor is not exported, it becomes opaque to other modules. The module that defines the newtype—its “home module”—can take advantage of this to create a <em>trust boundary</em> where internal invariants are enforced by restricting clients to a safe API.</p>

<p>We can use the <code>NonEmpty</code> example from above to illustrate how this works. We refrain from exporting the <code>NonEmpty</code> constructor, and we provide <code>head</code> and <code>tail</code> operations that we trust to never actually fail:</p>

<div>
 <div>
  <pre><span></span><span>module</span> <span>Data.List.NonEmpty.Newtype</span>
  <span>(</span> <span>NonEmpty</span>
  <span>,</span> <span>cons</span>
  <span>,</span> <span>nonEmpty</span>
  <span>,</span> <span>head</span>
  <span>,</span> <span>tail</span>
  <span>)</span> <span>where</span>

<span>newtype</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>NonEmpty</span> <span>[</span><span>a</span><span>]</span>

<span>cons</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>NonEmpty</span> <span>a</span>
<span>cons</span> <span>x</span> <span>xs</span> <span>=</span> <span>NonEmpty</span> <span>(</span><span>x</span><span>:</span><span>xs</span><span>)</span>

<span>nonEmpty</span> <span>::</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>Maybe</span> <span>(</span><span>NonEmpty</span> <span>a</span><span>)</span>
<span>nonEmpty</span> <span>[]</span> <span>=</span> <span>Nothing</span>
<span>nonEmpty</span> <span>xs</span> <span>=</span> <span>Just</span> <span>$</span> <span>NonEmpty</span> <span>xs</span>

<span>head</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>head</span> <span>(</span><span>NonEmpty</span> <span>(</span><span>x</span><span>:</span><span>_</span><span>))</span> <span>=</span> <span>x</span>
<span>head</span> <span>(</span><span>NonEmpty</span> <span>[]</span><span>)</span>    <span>=</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>

<span>tail</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span>
<span>tail</span> <span>(</span><span>NonEmpty</span> <span>(</span><span>_</span><span>:</span><span>xs</span><span>))</span> <span>=</span> <span>xs</span>
<span>tail</span> <span>(</span><span>NonEmpty</span> <span>[]</span><span>)</span>     <span>=</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>
</pre></div>

</div>

<p>Since the only way to construct or consume <code>NonEmpty</code> values is to use the functions in <code>Data.List.NonEmpty.Newtype</code>’s exported API, the above implementation makes it impossible for clients to violate the non-emptiness invariant. In a sense, values of opaque newtypes are like <em>tokens</em>: the implementing module issues tokens via its constructor functions, and those tokens have no intrinsic value. The only way to do anything useful with them is to “redeem” them to the issuing module’s accessor functions, in this case <code>head</code> and <code>tail</code>, to obtain the values contained within.</p>

<p>This approach is significantly weaker than using a constructive datatype, since it is theoretically possible to screw up and accidentally provide a means to construct an invalid <code>NonEmpty []</code> value. For this reason, the newtype approach to type safety does not on its own constitute a <em>proof</em> that a desired invariant holds. However, it restricts the “surface area” where an invariant violation can occur to the defining module, so reasonable confidence the invariant really does hold can be achieved by thoroughly testing the module’s API using fuzzing or property-based testing techniques.<sup><a href="#2020-11-01-names-are-not-type-safety-footnote-2-definition" name="2020-11-01-names-are-not-type-safety-footnote-2-return">2</a></sup></p>

<p>This tradeoff may not seem all that bad, and indeed, it is often a very good one! Guaranteeing invariants using …</p></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/">http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/</a></em></p>]]>
            </description>
            <link>http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963821</guid>
            <pubDate>Mon, 02 Nov 2020 00:27:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservices – architecture nihilism in minimalism's clothes]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 198 (<a href="https://news.ycombinator.com/item?id=24963742">thread link</a>) | @zdw
<br/>
November 1, 2020 | https://vlfig.me/posts/microservices | <a href="https://web.archive.org/web/*/https://vlfig.me/posts/microservices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some recent <a href="https://twitter.com/gergelyorosz/status/1247132806041546754" target="_blank" rel="nofollow noopener noreferrer">backtracking</a> <a href="https://twitter.com/copyconstruct/status/1247130488667394049" target="_blank" rel="nofollow noopener noreferrer">from</a> what we have been calling “Microservices” has sparked anew the debate around that software architecture pattern. It turns out that for increasingly more software people, having a backend with (<a href="https://www.infoq.com/presentations/monzo-microservices/" target="_blank" rel="nofollow noopener noreferrer">sometimes several</a>) hundreds of services wasn’t that great an idea after all. The debate has <a href="https://riak.com/posts/technical/microservices-please-dont/" target="_blank" rel="nofollow noopener noreferrer">been going on for a while</a> and much has already been said, but there are still a couple of things I’d like to say.</p>
<p><strong>TL;DR</strong> “Microservices” was a good idea taken too far and applied too bluntly. The fix isn’t just to dial back the granularity knob but instead to 1) focus on the split-join criteria as opposed to size; and 2) differentiate between the project model and the deployment model when applying them.</p>
<p>I explain. Allow me to rant a bit first.</p>


<p>There were three main reasons for the initial success of <em>microservices</em> as an architectural pattern for software: 1) forced modularisation, 2) weakened dependencies, and 3) an excuse for having no architecture. In order:</p>
<ol>
<li>In the monoliths of old, you could in theory enforce module boundaries. You could say that your <code>acme-helpers</code> or <code>acme-data-tools</code> could not depend on <code>acme-domain</code>, say, and you even had some tooling to enforce that, but it was fallible. Especially in big companies where these monoliths spanned more than a team’s cognitive horizon, violations of those boundaries were often a simple <code>import</code> away, and of course rife. Angry architects saw in microservices the promise of making those a thing of the past: now the developer is forced to only deal with the API. Codebases parted ways and calls were made to go down the network stack and back.</li>
<li>
<p>So then, one wouldn’t depend on a fellow service at build time, only at runtime. Great. Method calls became http calls. “Now we don’t need to care about dependencies” — actual people said this, as if the dependency wasn’t fundamental and instead just an accidental artifact of the build setup. Everybody brushed up on their HTTP and different server and client implementations, read all about REST and Soap (and RPC, RMI and CORBA while at it) and merrily created a layer of indirection between modules — now <em>services</em> — that was <em>very</em> loose. Typed APIs, granular network policies and contract testing came much later.</p>
<p>It felt liberating until the complexities of API versioning, delivery semantics, error propagation, distributed transaction management and the sprawl of client code in all callers of a service began to show up. This was a gigantic <strong>shift right</strong>, but hey, the build process was simpler.</p>
</li>
<li>
<p>More insidious perhaps was the validation that “doing microservices” brought to organisations that lacked a thesis about how their architecture should be. There was now a sanctioned answer to most architectural dilemmas: another microservice. Another entry in the service catalog for any and all interested parties to call. This ecology of interacting parties, each acting in their own interest for the common good spoke to an underlying, tacit belief that the emergent mesh of services would approximate the latent natural architecture of the domain.</p>
<p>So soft and convenient was the lure of not having to draw hard architectural lines that we got lazy where we weren’t and accepted our lazyness where we already were. If you didn’t subscribe to that belief, the problem was you and your lack of understanding of complex systems, you objectivist cretin.</p>
</li>
</ol>
<p>Yes, there was real pain in managing monoliths and sure, many systems were too monolithic (i.e. had deployables too large) but the zealotry of a newfound purity swung the pendulum too far, as they always do. Not only do we not need to run so many services so small, we also don’t benefit from isolating their codebases so much. To summarise:</p>
<ol>
<li>having a big flat permissive build is no good reason to split deployables;</li>
<li>weakening dependencies between different parts of our systems is a “shift-right” loan with high interest; and</li>
<li>having a ready answer when the thinking gets tough is a soothing lie that just moves complexity about. There is no substitute to the effortful application of cognitive power to a problem.</li>
</ol>

<p>Two things: focus on the right criteria for splitting a service instead of on its size, and apply those criteria more thoughtfully.</p>
<h2 id="size-is-not-the-answer"><a href="#size-is-not-the-answer" aria-label="size is not the answer permalink"></a>Size is not the answer</h2>
<p>The <em>micro</em> in microservices ought to be at best a prediction, never a goal. We may predict services <em>will be</em> micro but they don’t <em>have to be</em>. <a href="https://kalele.io/microservices-and-microservices/" target="_blank" rel="nofollow noopener noreferrer">Vaugh Vernon is right</a> when he speaks about “cohesion for a reason”.</p>
<p>There should be no prescribed <em>a priori</em> granularity of services. There <em>is</em> no prescribed size of a service. There are instead <strong>good and bad reasons to split</strong> parts of a software system.</p>
<p>So the heuristic is:</p>
<div data-language="text"><pre><code>                      Start one, split with a reason.</code></pre></div>
<p>Conversely, if a reason ceases to exist, consider joining them.</p>
<h2 id="the-missing-hinge"><a href="#the-missing-hinge" aria-label="the missing hinge permalink"></a>The missing hinge</h2>
<p>There are however different realms in which “software systems” exist: they exist both as artifacts we interact with and as artifacts computers interact with. Code and binary. We organise them in different ways: the <strong>project model</strong> (repositories, projects, modules and their dependencies) and the <strong>deployment model</strong> (what production environments look like and how deployables run in them).</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A monolithic setup where one big repo builds one single big deployable." title="A monolithic setup where one big repo builds one single big deployable." src="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg" srcset="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/09b79/monolith.jpg 240w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/7cc5e/monolith.jpg 480w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg 960w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/644c5/monolith.jpg 1440w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg 1463w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A monolithic setup where one big repo builds one single big deployable.</p></figcaption>
  </figure>
<p>In the process of going from coarse to granular (i.e. from monolith to microservices) however, little attention was paid to the difference — and possible indirection — between those two models. The hammer hit both fairly indiscriminately and made us split codebases because of runtime concerns and split deployables due to project concerns.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A set of repositories each building their own self-contained independent service." title="Excessive mirroring between the project and deployment models." src="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg" srcset="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/09b79/stiff-1-1.jpg 240w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/7cc5e/stiff-1-1.jpg 480w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg 960w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg 1062w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Excessive mirroring between the project and deployment models.</p></figcaption>
  </figure>
<p>Much like stiffness in a part of the human spine can result in pain in another, <strong>stiffness in our build DAGs is causing excessive mirroring between our project and deployment models</strong>; between our repositories and our services; between the way we organise our code and the way our services run. That mirroring is on the one hand preventing us from shifting left concerns about the relationships between modules that have often been made weak and fragile runtime dependencies, while on the other hand encouraging us to have more services than what the runtime reality would call for. That brings pain.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The build DAG as a hinge between the project model and the deployment model." title="A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly." src="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg" srcset="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/09b79/hinge.jpg 240w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/7cc5e/hinge.jpg 480w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg 960w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg 1335w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly.</p></figcaption>
  </figure>
<p>Central to resolving this stiffness is the realisation that the build flow, at least conceptually, is a DAG – Directed Acyclic Graph – where the nodes are <em>jobs</em> and <em>versioned artifacts</em> and the edges connect either a job to a versioned artifact (“produces”) or a versioned artifact to a jobs (“dependency_of”). Deployables are by definition the versioned artifacts that are consumed by the deployment jobs.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." title="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." src="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg" srcset="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/09b79/dag.jpg 240w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/7cc5e/dag.jpg 480w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg 960w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg 1384w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A graph of two types of nodes, jobs and versioned artifacts, connected by edges ‘dependency_of’ and ‘produces’. Versioned artifacts can be further specialised.</p></figcaption>
  </figure>
<p>For too long we overlooked how much a flexible and frictionless build DAG allows us to improve our architecture on both sides. With moderately rich build patterns we can have our code where its intent is clearer and more constraints can be validated at build time and still have it deployed into its simplest viable form, running where its execution is cheaper, faster and safer.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cheesy cisgender, neurotypical westernised image of a wedding altar with the build dag marrying developer effectiveness with mechanical sympathy." title="Sorry. I had to." src="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" srcset="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/09b79/wedding-altar.jpg 240w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/7cc5e/wedding-altar.jpg 480w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg 612w" sizes="(max-width: 612px) 100vw, 612px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Sorry. I had to.</p></figcaption>
  </figure><p>.</p>
<h3 id="why-so-stiff-bro"><a href="#why-so-stiff-bro" aria-label="why so stiff bro permalink"></a>Why so stiff, bro?</h3>
<p>I’m not sure what the historically accurate account is that would explain the excessive simplicity of build patterns across the industry. I do know from experience that too many practices make do with very simple and linear flows where one repository builds independently one and only one service. Regardless of the legitimate argument about code duplication and its tradeoffs, there seems to be an aversion to build-time internal dependencies, even when these bring in clearly desirable data or logic such as message format definitions.</p>
<p>I suspect it might have something to do with how very few CI tools support composition natively (i.e. the outputs of jobs being able to be the inputs of others), how fallible semantic versioning in practice is and the difficulty of automating deterministic version propagation.</p>
<p>By that I mean keeping local copies in sync with CI, builds repeatable, and new upstream versions automatically used by their downstream dependents. It isn’t trivial and requires some versioning and build-fu that, to my knowledge, most practices end up shortcutting to either sacrifice repeatability by using <code>latest</code> or stifling the flow by requiring repeated manual work. Hence the pressure to have a simple build setup.</p>
<p>The exact cause is unimportant though. What is important is that overcoming this is crucial.</p>

<p>Many criteria for splitting or joining software systems, ranging from the social (teams, bounded contexts) to the mechanical (cpu or io boundedness) have been put forth, and they all make some form of sense. However, most of them are either a good reason to split projects or modules, or a good reason to split deployables, rarely both. Keeping that in mind will help us apply them more effectively.</p>
<p>Below are a few possible criteria and some comments about their application. I’m not trying to be exhaustive, just illustrating the kind of reasoning makes sense to me.</p>
<h2 id="runtime-deployment-side-criteria"><a href="#runtime-deployment-side-criteria" aria-label="runtime deployment side criteria permalink"></a>Runtime, deployment side criteria</h2>
<ul>
<li><strong>Different Runtime</strong> – If a part of the codebase compiles to a different runtime it becomes a different deployable and we call it a different service.</li>
<li><strong>Elasticity Profile</strong> – Some parts of the system may have a spikier load profile. It might pay off to have them scale in and out separately from the rest.</li>
<li><strong>Load Type</strong> – Some parts of a generally latency-oriented io-bound system may generate occasional peaks of cpu-bound load which can hurt response times. It might be better to put them in a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vlfig.me/posts/microservices">https://vlfig.me/posts/microservices</a></em></p>]]>
            </description>
            <link>https://vlfig.me/posts/microservices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963742</guid>
            <pubDate>Mon, 02 Nov 2020 00:16:23 GMT</pubDate>
        </item>
    </channel>
</rss>
