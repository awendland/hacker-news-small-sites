<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 06 Aug 2020 12:24:06 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 06 Aug 2020 12:24:06 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The best Parts of Visual Studio Code are proprietary]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 120 (<a href="https://news.ycombinator.com/item?id=24047638">thread link</a>) | @ingve
<br/>
August 4, 2020 | https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-08-03</small><!-- RSS:2020-08-03T07:25:00Z -->
<p>I've been very surprised and delighted over a number of years now by Microsoft's strong efforts in open
    source. I understand the skeptics, I was on Slashdot when they tried to sue Linux out of existence and I think only
    time will tell. I figure MS contributing is better than them hunting Linux distributions for sport. So I was mostly
    onboard for Microsofts efforts and I've especially found Visual Studio Code useful.</p>
<p>To settle a few things. When I tweeted on this subject I only got the response that I should use vim. Thanks. Great.
    I can and do on use vim. That misses a number of points. Visual Studio Code is an immensely popular editor and
    likely the most common recommendations to new developers. The primary reason I've used Visual Studio Code is
    that it has an incredibly compelling solution for remote pairing in the form of LiveShare. I've used that for a
    while with great success mentoring, coaching and generally working with other developers of varying experience and
    editor preferences. Most programmers can handle a "normal" editor like VS Code while something like Emacs
    or Vim depends a lot more on what they've learned.</p>
<p>I also ended up enjoying the Remote series of extensions for developing effectively inside remote servers or local
    containers.</p>
<h2>These things are proprietary</h2>
<p>At some point I read a piece of license that said that LiveShare could only be used with the Visual Studio family of
    products. "Huh, that sounds weird, VS Code is open source right?"</p>
<p>Sure enough. VS Code is fully MIT. The binary distribution has a separate license to allow telemetry and protect
    Microsoft trademarks and stuff. Nothing particularly weird, I can't really get worked up about telemetry, I know
    some can. But the extensions.. These extensions are in my book core differentiators that makes VS Code compelling.
    For me it is definitely part of what pushes it beyond the much leaner Sublime (paid, closed source) I was using
    before.</p>
<p>These extensions have a license limiting them and their online service parts to only be used with the Visual Studio
    family of products. This is the <a href="https://microsoftdocs.github.io/live-share/license/eula.html" title="License for LiveShare">license for LiveShare</a> and this is the <a href="https://code.visualstudio.com/preview-license" title="License for Remote">license for Remote</a>.</p>
<p>For me LiveShare is the most important thing. Google Docs style collaborative code editing, terminal sharing, port
    sharing and a bunch more features. I know Atom had an extension like this, I haven't checked the licensing there
    or tried it recently.</p>
<p>Remote is a very strong extension as well for anyone working on a server over SSH or in a container. It helps by
    installing extensions on the destination to allow language servers and such. I've seen it do terrible things to
    servers sometimes but it is very useful and generally works well.</p>
<p>It makes me uneasy to accept VS Code as an "open" project in any wider meaning of the word when compelling
    features are legally locked to only work inside the family of Visual Studio products. It makes me less certain that
    this isn't the Extend in Embrace, Extend, Extinguish. It also frustrates me that this prevents someone from
    building a compatible plugin for VIM or any other editor. This would be much more powerful if it could be in all the
    IntelliJs as well.</p>
<p>You'll find a repo for <a href="https://github.com/MicrosoftDocs/live-share" title="LiveShare on GitHub">LiveShare on GitHub</a> but it is only for documentation and issue tracking. There
    is no code. Same for <a href="https://github.com/microsoft/vscode-remote-release" title="Remote on GitHub">Remote</a>.</p>
<h2>The entire marketplace is proprietary</h2>
<p>Some additional salt in this particular wound is that the use of the Marketplace of VS Code extensions is also
    proprietarily licensed. So all these open source developers are shoving their extensions into a competitive
    advantage for one of the world's largest tech firms. And they disallow other uses of the marketplace. Even if
    the letter of open source is followed there is none of the openness, collaborative or community essence that I think
    exemplifies open source and free software projects.</p>
<p>What does this mean in practice? I guess it protects from the competition. Such as the <a href="https://github.com/VSCodium/vscodium" title="VS Codium">VS Codium</a> project which provides VS Code
    binaries without the proprietary parts. But also, as a consequence of this, without the Marketplace of extensions.
    There is an open source alternative called <a href="https://open-vsx.org/" title="Open VSX">Open VSX</a>, but since
    it isn't the canonical one it is missing a bunch of extensions and the big Liveshare and Remote ones are still
    not allowed.</p>
<p>This also blocks the <a href="https://github.com/cdr/code-server" title="code-server">code-server editor</a> that
    allows running VS Code in the browser from using it which otherwise would have been perfect for me to do development
    on an iPad Pro. I can still use that but a lot of packages are not in Open VSX.</p>
<h2>What about lock-in?</h2>
<p>Visual Studio Code is marketed with LiveShare and Remote as powerful extensions. VS Code is also marketed as open
    source. It is easy to use the editor, install the extensions and be under the impression that you are using an open
    source software suite where Microsoft simply hosts the peering service for identifying and connecting you and your
    collaborator.</p>
<p>But the peering service is not the only closed part. The extensions are not open source projects as far as I can find
    and they are licensed during distribution in a way that disallows using them with anything but Visual Studio
    products.</p>
<p>This leaves me with a sour taste in my mouth. I wasn't sold on having an Electron-based editor to begin with but
    VS Code was substantially leaner than Atom so I've been mostly accepting it.</p>
<p>If you have good suggestions for strong collaborative development tools that are open source, please let me know at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. If you want to follow my writing the RSS feed is
    right below. If you want more of my writing I have a tracking-free newsletter that I'd love for you to sign up for,
    also below.</p></div></div>]]>
            </description>
            <link>https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047638</guid>
            <pubDate>Tue, 04 Aug 2020 07:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Functional Programming Design from Redux]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24046631">thread link</a>) | @daiyanze
<br/>
August 3, 2020 | https://pitayan.com/posts/redux-fp-design/?ref=hackernews | <a href="https://web.archive.org/web/*/https://pitayan.com/posts/redux-fp-design/?ref=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Before I set my eyes on the Redux source code, I naively thought OOP is superior than FP(Functional Programming) as a programming paradigm. But this is not right. As we know that FP is dedicated to forming a easy to understand and clear workflow without those obscure abstracted objects and relations. It's much closer to human's procedural mode of thinking.</p><p>Now <code>React</code> has already got hooks which can handle the "states" properly event without <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>. The demand for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> could be declining but its code base is still worth learning. Especially for those who wants to enlighten themselves in functional programming. So, I guess it's never a bad idea to learn from a good example even though it is "obsolete" (not at all).</p><p>When I started reading the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> source code, I immediately felt the power of this unfamiliar usage of my familiar programming language. It feels like exploring an acient cave with a torch lighting up the paintings and found the great secret.</p><p>In order to know more about what Redux benefits from FP, I researched the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> source code and created a mini version of it.</p><blockquote><p>Never be afraid of reinventing the wheel.</p></blockquote><p><strong>Contents:</strong></p><ul><li><a href="#recap-how-redux-works">Recap How Redux Works</a></li><li><a href="#redux-approach-comparison-fp-vs-oop">Redux Approach Comparison: FP vs OOP</a></li><li><a href="#wonderful-redux-fp-design">Wonderful Redux FP Design</a><ul><li><a href="#createstore">createStore</a></li><li><a href="#combinereducers">combineReducers</a></li><li><a href="#applymiddleware">applyMiddleware</a></li></ul></li><li><a href="#redux-middlewares">Redux Middlewares</a><ul><li><a href="#redux-thunk">Redux Thunk</a></li><li><a href="#redux-logger">Redux Logger</a></li></ul></li><li><a href="#a-demo-app">A demo app</a></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#references">References</a></li></ul><h2 id="recap-how-redux-works"><a href="#recap-how-redux-works">Recap How Redux Works</a></h2><p>There are 4 basic key points for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>:</p><ol><li>Create a store for data and let the view subscribe to it</li><li>The view dispatches an action to submit the changs</li><li>The reducer changes the state based on the action type</li><li>Finally return the new state and triggers the view to change</li></ol><p>This is the classic diagram explaining how <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> works:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg" width="1088" alt="redux diagram" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1088 573' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-7e552fcbb64e466973e8c4226e516330'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-7e552fcbb64e466973e8c4226e516330)' width='1088' height='573' xlink:href='data:image/jpeg%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAiCAYAAADvVd%2bPAAAACXBIWXMAAAsSAAALEgHS3X78AAAEqklEQVRo3tWZ2U7sMAyG%2b/5vgcQ1V4C4AIkbQCAh9n3f931fc/RFco8n0zZOGEBEstppUrv%2bYzu2p3h5eXFvb2/u4%2bPDRO/v7453Xl9fy2sVhWus/KEY7yo5ufwLlL%2b5uXGnp6fu/PzcnZ2dVRJzrLm6uvKAWT5QwH18fIzy13IsAOv55%2bfnKF9NT09P5fsFyi8sLLjd3V23vb3dSKxZWlryHwmSMQuQ%2bdXVVbexseF2dnai/FnL/efnpwkALBLeFv7Mb25uehliyQU7g2DrQHkYMSwuwO4j0Dp4j/UAwM5aLGxxcdGlDDZRrLhAIdBhgEqT7zOOj489YDzjA2Wn6%2bjh4cGtrKyYfJNxd3fnAbDwl3kUAhBAa%2bLPPHosLy//BwCfEABkUTh4Js9PTk7c0dFRy/o6koF5VvENZTDu7%2b%2b9mVr4C2jwRyHNp44/77RYQAgAg127vLx019fX/l7PHR4eusnJSX/FFbCGOmJ%2bcHDQjY%2bPlx8BH3gTe25vb/2O4yYykDcxMeEODg6i/Pf29tzIyIgbGhpqUxbLFhkaFBMACMdMMEXu9Y6i%2bMzMjI%2bm3GMNIfEcV%2bEDu7q63OjoaPlhmCB8Cbx8CP5LHNIAADDPmvhDrOnp6XG9vb1tloqMtbU1737iviYAYiYUukDMp7/iAk0xqckF6tzYDECTMAmCEqVjQRCFJAhq362SIQDkBEEUCuOD5i0EqG0ApByDev13HIMolXoMolD2MUhmNz8/73cWfxfCzDF3/Yw1vMzVkgjJlXeIB/it5hcSMjHn9fV1MwDsKBZGwAz5I5OrPOfKM%2bJOmQiBBCAgHMVYROTs7%2b933d3dPkpLUGPNxcVFciqMWQv/GAG6KG5NhUltq/hwmqAw93oOqyxTYUFR/EWCydzcnBsbG/P3uljKKYZSiq1OFUNYENYEmGFMaCmGdN4ugQUlQQp/5z4MRqHwWC0QC5RVlGIBdTxwDayvak1pAVVMQWx/f9%2bbj/i6dUd%2bm8IiDACaXLaoehkAJJD8JQDCHQ4BqNKhqKqtUVpSTXGBFL/8LeXlqvMDgnhVg6bWArgyOBkgCYJ/xQLk%2byVtl991G1iERxaIkRcQQTEhzuSULtBPBsG6I3Fra8t/O7kBgRAdqDEaLUAmWMgJAAjS/dGRNMckwzQ1VuLmuJt2YUl6KNokh9FtMJMLSOLTZD7WRAhQJbO0JEI5FhDmBIBJNYjiZheQKww4BiGd8uZYgERjCi6CahMhD3O19gRjOUGYB0QtQOcB4TGYG5A60RPMjT3JeUAIADtSlQmmkABg7QlKOfxVudoCsgBAeXzS0ptrIoRLdVfXs9NNDD5Yym1AyJXLIAZ8yQJmZ2fLElJigpWkFOVImpqaauvKSL%2bOXdZz/B4YGHDDw8NlSZsiX9ZyRa6u/MwAiO/qOjqHiPzs5vT0dIuSXDmjqTjhr%2beQ39fX55up0qPIkQ0IFHNhXIgCkPt/W12bCz6pLiB/vDT1BFP/x6yjIrXETM3mdBBs6tl9RxAMdTFbQCfz8u/sCXaCip%2bozviPgaCke/pVhM/TEpc2%2bp8GIOwJStPTEjh/svz%2bEQuQYsgSNHOLoVz6Bye%2b7fLOqLjeAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg" data-srcset="https://d33wubrfki0l68.cloudfront.net/d23ede7d66304da8179f8bd5b5cb30d1a54c39df/29340/assets/static/redux.82a2fbd.ff6f3365031ebcab6ddfefc3aadeb376.jpg 480w, https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg 1088w"></p><p>From the diagram above, it's easy to find the keywords: <code>action</code><code>store</code><code>reducer</code><code>view</code><code>subscribe</code> and <code>dispatch</code>. And the next is to handle the relations among these keywords.</p><h2 id="redux-approach-comparison-fp-vs-oop"><a href="#redux-approach-comparison-fp-vs-oop">Redux Approach Comparison: FP vs OOP</a></h2><p>Example usage of <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a></p><pre><code><span>const</span> store <span>=</span> <span>createStore</span><span>(</span>
  <span>combineReducers</span><span>(</span><span>{</span>
    one<span>:</span> oneReducer<span>,</span>
    two<span>:</span> twoReducer
  <span>}</span><span>)</span><span>,</span>
  <span>applyMiddleware</span><span>(</span><span>ReduxThunk</span><span>,</span> <span>ReduxLogger</span><span>)</span>
<span>)</span><span>;</span></code></pre><p>Imagine if we do this in OOP, it may look like this:</p><p>(The following is just my imagination. Not how older <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> behaves)</p><pre><code><span>const</span> store <span>=</span> <span>new</span> <span>Store</span><span>(</span><span>)</span>
store<span>.</span><span>setReducers</span><span>(</span><span>{</span>
  one<span>:</span> oneReducer<span>,</span>
  two<span>:</span> twoReducer
<span>}</span><span>)</span>
store<span>.</span><span>setMiddlewares</span><span>(</span><span>{</span>
  <span>ReduxThunk</span><span>,</span>
  <span>ReduxLogger</span>
<span>}</span><span>)</span></code></pre><p>So, what are the differences? Both are good approaches IMO.</p><p>FP does a good job on combining the functions together without side-effects. The return value is consistent which made the program returnings foreseeable during or after the execution.</p><p>OOP made a solid structure which defined all the attributes a data model should contain. It makes it easy to modify or configure the data model.</p><p>In <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>, the <code>reduers</code> and <code>middlewares</code> are usually defined only once. It means, we don't need the ability to update these properties and we don't hope them to be altered during the runtime. As for FP approach, it utilizes the <code>closure</code> technique that kills the possbility of exposing the internal properties. With some fantastic FP techniques (curry, compose, pipe), it's even making the program much more human-readable than OOP.</p><p>I would say FP should be the best fit for such scenario. Of course, the FP I'm talking about here is far from the real functional programming like Haskell. But at least the idea of utilizing FP techniques in Javascript is something to follow.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg" width="1024" alt="haskell functional programming" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1024 576' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-52e08e1070b234d120b65ac6e29a8487'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-52e08e1070b234d120b65ac6e29a8487)' width='1024' height='576' xlink:href='data:image/jpeg%3bbase64%2c/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAkAEADASIAAhEBAxEB/8QAGwAAAgMBAQEAAAAAAAAAAAAAAAQCAwUGAQj/xAAwEAABBAEDAQYCCwAAAAAAAAABAAIDEQQSITFRBRMiQWFxJKEGFBUyQlKCkrHB8P/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/EABkRAQEBAAMAAAAAAAAAAAAAAAABERIhQf/aAAwDAQACEQMRAD8A%2bqSQASdgEvj5uLki8fIilHVjgf8AcFMEWCFz0oyIJ5ceETuhvTqPeucQR%2ba6vc8enRBuwzxTAGJ7XAixSsWFJmZ0DmiKLVDVNLoJHPqq8Vedp77R0yujdj5biDVtgdp46%2baUPoN0aFlUwTiV8je7kZoNW9tA%2b3VXEAgggEHyQcl2J9O%2bzO04JXd3kxSQl3eMEZk00au2WCPboVt9mdt4Pac7ocN0zntbrOqF7BV1y4BOY%2bLj44Ax4IogBpGhgbQ5rZXLVs8Hj70Oq7ralh4WaYXPgnleckGu7kna43WwsNA6LdSpzCL%2bHm29Bv8ANZGXDLKdDpZpmt2IrJa675/D0NrQfJDHGwPy5ACDTjyfkifID2lrsfII33Ya49QVWC173fD5Zo1es1x5eLhXlaupsxe9Z4M7KIIq2uA/rlMwwGN5cZpX7VTyK9%2bEnqD374uYC3TvrIu/1b15qyGNkkztUWSw/etzzp59/RXesQ8hQjibGXab8Rs2bU1kCX%2bpYodqGPFq330jzQhDQMLFHGPF%2b0dK/jZWxRRwgiJjWAmyGirKEIJoQhAIQhB//9k=' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg" data-srcset="https://d33wubrfki0l68.cloudfront.net/2c16467debebdf254444700dab6213bb45ece8a2/b30b3/assets/static/haskell.82a2fbd.82d9f5b0912290333a547a32e17d3642.jpg 480w, https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg 1024w"></p><h2 id="wonderful-redux-fp-design"><a href="#wonderful-redux-fp-design">Wonderful Redux FP Design</a></h2><p>In Redux, there is no class at all (In the earlier versions, it was once based on <code>Class</code>). All of its core APIs return either value or function (function factory). And this is exactly what FP expects a function to behave:</p><blockquote><p>Pure with no side effects.</p></blockquote><ul><li><strong>createStore</strong>: returns new <code>Object</code> { getState, dispatch, subscribe }</li><li><strong>combineReducers</strong>: returns new <code>Function</code></li><li><strong>applyMiddleware</strong>: returns new <code>Function</code></li></ul><p>To explain the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> design in an easy way, I implemented only the very core part of the APIs above. Since the latest version's core concept hasn't changed much, I wrote the source code based on very primitive version of <a href="https://github.com/reduxjs/redux/tree/v1.0.1/src" target="_blank" rel="nofollow noopener noreferrer">Redux v1.0.1</a>. Because I believe the very first related version would be the most comprehensive one to look at.</p><p>Let's have a look.</p><h4 id="createstore"><a href="#createstore">createStore</a></h4><p><code>createStore</code> defines those APIs that can be used within components. It's more like <code>setter</code> and <code>getter</code></p><ul><li>getState</li><li>dispatch</li><li>subscribe</li></ul><pre><code><span>export</span> <span>default</span> <span>function</span> <span>createStore</span> <span>(</span><span>reducer<span>,</span> enhancer</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>enhancer<span>)</span> <span>{</span>
    <span>return</span> <span>enhancer</span><span>(</span>createStore<span>)</span><span>(</span>reducer<span>)</span><span>;</span>
  <span>}</span>

  <span>let</span> currentState<span>;</span>
  
  
  <span>let</span> currentListeners <span>=</span> <span>[</span><span>]</span><span>;</span>

  <span>function</span> <span>getState</span> <span>(</span><span>)</span> <span>{</span>
    <span>return</span> currentState<span>;</span>
  <span>}</span>

  
  <span>function</span> <span>subscribe</span> <span>(</span><span>listener</span><span>)</span> <span>{</span>
    currentListeners<span>.</span><span>push</span><span>(</span>listener<span>)</span><span>;</span>

    <span>return</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      
      <span>const</span> index <span>=</span> currentListeners<span>.</span><span>indexOf</span><span>(</span>listener<span>)</span><span>;</span>
      currentListeners<span>.</span><span>splice</span><span>(</span>index<span>,</span> <span>1</span><span>)</span><span>;</span>
    <span>}</span><span>;</span>
  <span>}</span>

  <span>function</span> <span>dispatch</span> <span>(</span><span>action</span><span>)</span> <span>{</span>
    currentState <span>=</span> <span>reducer</span><span>(</span>currentState<span>,</span> action<span>)</span><span>;</span>
    
    currentListeners<span>.</span><span>forEach</span><span>(</span><span>listener</span> <span>=&gt;</span> <span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  
  <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>"MY-MINI-REDUX"</span> <span>}</span><span>)</span><span>;</span>

  <span>return</span> <span>{</span>
    getState<span>,</span>
    dispatch<span>,</span>
    subscribe
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="combinereducers"><a href="#combinereducers">combineReducers</a></h4><p>Returns a new function that can return the new state. Can't be any purer.</p><pre><code>
<span>function</span> <span>mapValues</span><span>(</span><span>obj<span>,</span> fn</span><span>)</span> <span>{</span>
  <span>return</span> <span>Object</span><span>.</span><span>keys</span><span>(</span>obj<span>)</span><span>.</span><span>reduce</span><span>(</span><span>(</span><span>result<span>,</span> key</span><span>)</span> <span>=&gt;</span> <span>{</span>
    result<span>[</span>key<span>]</span> <span>=</span> <span>fn</span><span>(</span>obj<span>[</span>key<span>]</span><span>,</span> key<span>)</span><span>;</span>
    <span>return</span> result<span>;</span>
  <span>}</span><span>,</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>default</span> <span>function</span> <span>combineReducers</span> <span>(</span><span>reducers</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span> <span>combination</span> <span>(</span><span>state <span>=</span> <span>{</span><span>}</span><span>,</span> action</span><span>)</span> <span>{</span>
    
    
    <span>return</span> <span>mapValues</span><span>(</span>reducers<span>,</span> <span>(</span><span>reducer<span>,</span> key</span><span>)</span> <span>=&gt;</span> <span>reducer</span><span>(</span>state<span>[</span>key<span>]</span><span>,</span> action<span>)</span><span>)</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="applymiddleware"><a href="#applymiddleware">applyMiddleware</a></h4><p>I personally think the <code>applyMiddleware</code> API is the most amazing part of Redux. It provides an optimal solution to apply 3rd party plugins.</p><p>The FP <code>compose</code> in the source code is corresponding to Math's <a href="https://en.wikipedia.org/wiki/Associative_property" target="_blank" rel="nofollow noopener noreferrer">associative law</a> in my understanding.</p><blockquote><p>( <em>x</em> ∗ ( <em>y</em> ∗ <em>z</em> ) ) = <em>x</em> ∗ <em>y</em> ∗ <em>z</em></p></blockquote><p>The usage of <code>applyMiddleware</code> is actually a form of a <code>pipe</code> that allows us to inject enhancement functions that returns the store Object. It's pretty similar to <code>Aspect Oriented Programming</code> which the most typical example is the annotation / decorator.</p><pre><code>

<span>function</span> <span>compose</span><span>(</span><span><span>...</span>funcs</span><span>)</span> <span>{</span>
  <span>return</span> funcs<span>.</span><span>reduceRight</span><span>(</span><span>(</span><span>composed<span>,</span> f</span><span>)</span> <span>=&gt;</span> <span>f</span><span>(</span>composed<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>default</span> <span>function</span> <span>applyMiddleware</span><span>(</span><span><span>...</span>middlewares</span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>(</span><span>reducer<span>,</span> initialState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>next</span><span>(</span>reducer<span>,</span> initialState<span>)</span><span>;</span>
    <span>let</span> dispatch <span>=</span> store<span>.</span><span>dispatch</span><span>;</span>
    <span>const</span> middlewareAPI <span>=</span> <span>{</span>
      getState<span>:</span> store<span>.</span><span>getState</span><span>,</span>
      <span>dispatch</span><span>:</span> <span>action</span> <span>=&gt;</span> <span>dispatch</span><span>(</span>action<span>)</span>
    <span>}</span><span>;</span>
    <span>const</span> chain <span>=</span> middlewares<span>.</span><span>map</span><span>(</span><span>middleware</span> <span>=&gt;</span> <span>middleware</span><span>(</span>middlewareAPI<span>)</span><span>)</span><span>;</span>

    
    dispatch <span>=</span> <span>compose</span><span>(</span><span>...</span>chain<span>,</span> store<span>.</span><span>dispatch</span><span>)</span><span>;</span>

    <span>return</span> <span>{</span>
      <span>...</span>store<span>,</span>
      dispatch
    <span>}</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h2 id="redux-middlewares"><a href="#redux-middlewares">Redux Middlewares</a></h2><p>There are some famous middlewares for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> like <a href="https://github.com/reduxjs/redux-thunk" target="_blank" rel="nofollow noopener noreferrer">redux-thunk</a> and [redux-logger(<a href="https://github.com/LogRocket/redux-logger" target="_blank" rel="nofollow noopener noreferrer">https://github.com/LogRocket/redux-logger</a>). These are the good examples using <code>applyMiddleware</code> API to enhance the functionalities. Furthermore, their code base is astonishingly small. The core part has only a few lines of code.</p><p>All of the middlewares are <code>curry</code> functions.</p><blockquote><p>funcA =&gt; funcB =&gt; funcC</p><p>funcB = funcA()</p><p>funcC = funcB()</p></blockquote><p> This is extremly helpful when I need other contexts to use within the code block. As of the examples, it's easy to find that <code>next</code> and <code>action</code> are passed in as context to help handle some complex cases.</p><h4 id="redux-thunk"><a href="#redux-thunk">Redux Thunk</a></h4><p><code>redux-thunk</code> allows to use function as <code>dispatch</code> parameter so that I could do something right before "dispatching".</p><pre><code>
<span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'action'</span><span>,</span> payload<span>:</span> <span>'value'</span> <span>}</span><span>)</span>



<span>dispatch</span><span>(</span><span>function</span> <span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>'redux-thunk'</span><span>)</span>
  <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'action'</span><span>,</span> payload<span>:</span> <span>'value'</span> <span>}</span><span>)</span>
<span>}</span><span>)</span></code></pre><p>Here is the core:</p><pre><code>
<span>export</span> <span>default</span> <span>function</span> <span>thunk</span><span>(</span><span><span>{</span> dispatch<span>,</span> getState <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>action</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>typeof</span> action <span>===</span> <span>"function"</span><span>)</span> <span>{</span>
      <span>return</span> <span>action</span><span>(</span>dispatch<span>,</span> getState<span>)</span><span>;</span>
    <span>}</span>

    <span>return</span> <span>next</span><span>(</span>action<span>)</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="redux-logger"><a href="#redux-logger">Redux Logger</a></h4><p>It's easy to guess what this middleware does. It simply outputs the state changes.</p><pre><code>
<span>export</span> <span>default</span> <span>function</span> <span>logger</span><span>(</span><span><span>{</span> getState <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>action</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"======== Redux Logger ========"</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Action Type: "</span><span>,</span> action<span>.</span><span>type</span><span>)</span><span>;</span>
    <span>const</span> prevState <span>=</span> <span>getState</span><span>(</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Prev: "</span><span>,</span> prevState<span>)</span><span>;</span>

    <span>const</span> returnValue <span>=</span> <span>next</span><span>(</span>action<span>)</span><span>;</span>

    <span>const</span> nextState <span>=</span> <span>getState</span><span>(</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Next: "</span><span>,</span> nextState<span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"=============================="</span><span>)</span><span>;</span>
    <span>return</span> returnValue<span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h2 id="a-demo-app"><a href="#a-demo-app">A demo app</a></h2><p>I implemented mini version of redux and a small counter application to demostrate the functions. The application will do four arithmetic operations: <strong>plus</strong>, <strong>minus</strong>, <strong>multiply</strong> and <strong>divide</strong>. The number will change after clicking the operation button. Meanwhile, <code>multiply</code> and <code>divide</code> will have 300ms' delay which is enabled by a custom middleware (a mini redux-thunk).</p><p><strong>Repository link of "mini-redux":</strong></p><p><a href="https://github.com/daiyanze/mini-redux" target="_blank" rel="nofollow noopener noreferrer">https://github.com/daiyanze/mini-redux</a></p><p><strong>Demo App link:</strong></p><p><a href="https://daiyanze.com/mini-redux/build/index.html" target="_blank" rel="nofollow noopener noreferrer">https://daiyanze.com/mini-redux/build/index.html</a></p><p><img src="https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png" width="1078" alt="app" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1078 586' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-b8a33714e79343718b882b0853556166'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-b8a33714e79343718b882b0853556166)' width='1078' height='586' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAjCAYAAAAkCQwqAAAACXBIWXMAABYlAAAWJQFJUiTwAAACzElEQVRo3u1YSWsyQRD1v/oHAgoKinqQHDyIHrwIKl7MRYRcvAsJiBcPbkRcEpO4JcZdca2PV9BhvmGci84YRxuKnunu6aGqX79aTKRR2%2b/3v/12u%2bVeKrvd7lfkc9JvtW4mLTc/RgE9lNfUAEKBn58fSqfT1Ov1aD6fs%2bC5Wq1SoVDgfjKZ0HQ65bnX11caj8eXjwBAG61cLpPVaqV4PE6BQIAeHh7o%2bfmZYrEYeTwecjqdFIlEyO/385pcLkcvLy//7XHRCFiv18wBo9GIOp0OIwKy2Wz4xDEOBLTbbR6H0pi7cYBROEDO/FKWFzCXzxnGCygZRShVLBZ1vetnNYAcDWilUok9gBQFekJfdwQcUlBvyJ8dAUqKqxno4g0gJTa4w%2bVyyYEOXB3eF4sFB0GGNoDocdf7/T69vb1xfAAjwPcjMlRChaEQgIYTh9JCeem78ASGJ8G/EPxoYgAlV6cU2KjJRSFAfreVIjr5s9KctC5wKCpUiiZPZSyT1rDWau9T/ftoBMCt1Wo1ZnK4M4S3w%2bGQMzwwPtZ1u12O/N7f32m1WnFWCMFpfnx88PPn5yfV63X2Cs1mk/eGu/z6%2buJ9sB/WYy%2bQ59kRIFgbSrlcLrLb7eTz%2bcjhcJDFYqFgMEg2m40ymQw9PT2R1%2bul%2b/t7ikajvNZsNtPj4yOlUimWRCLBa7LZLH%2bfTCYpHA5zLcHtdtPd3R2FQiGuGcDoZzeA1LUhr8dJiaoPEp3v72%2bu%2bOBkkfNDcKJAh/D9oh4A5KAegG%2bwZjAY8BrMYQw95vP5PLVarZO6zD/LAXr9%2byRe4BBTH2JzafqrxvhqVeQ/gYBjokJAWZDdOZGkezYoTh88cRX1ALWrcihyNCwC1MbPdQ10zwYRCCGoERkgXOBV1QNAfpVK5TcNbjQaHCtcTT1AVICEAWazGY/d6gFk0KKoYesBRmk3A1y7Af4BkCyMSb7bRvcAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png" data-srcset="https://d33wubrfki0l68.cloudfront.net/6cd10d41d4c5361482bb8734550719faaa7f13e9/0e513/assets/static/app.82a2fbd.42e70fdda76e9bc70c1818fe62939d86.png 480w, https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png 1078w"></p><p>The app has one child component: <code>MiniReduxComp</code>. In my mini-redux, I didn't create a context provider to trigger updates. Instead, I subscribe to the store changes within the component and  do <code>forceUpdate</code> to react to changes.</p><p>I also applied the custom middlewares <code>redux-thunk</code> and <code>redux-logger</code> to enrich the functions.</p><pre><code><span>import</span> <span>React</span><span>,</span> <span>{</span> <span>Component</span> <span>}</span> <span>from</span> <span>'react'</span><span>;</span>
<span>import</span> store <span>from</span> <span>'../store'</span>

<span>export</span> <span>default</span> <span>class</span> <span>MiniReduxComp</span> <span>extends</span> <span>Component</span> <span>{</span>

  <span>componentDidMount</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>unsubscribe</span> <span>=</span> store<span>.</span><span>subscribe</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>forceUpdate</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  <span>componentWillUnmount</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>unsubscribe</span> <span>&amp;&amp;</span> <span>this</span><span>.</span><span>unsubscribe</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>

  <span>plus</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>"PLUS"</span> <span>}</span><span>)</span>

  <span>minus</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'MINUS'</span> <span>}</span><span>)</span>

  <span>multiply</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'MULTIPLY'</span> <span>}</span><span>)</span>
    <span>}</span><span>,</span> <span>300</span><span>)</span>
  <span>}</span><span>)</span>

  <span>divide</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'DIVIDE'</span> <span>}</span><span>)</span>
    <span>}</span><span>,</span> <span>300</span><span>)</span>
  <span>}</span><span>)</span>

  <span>render</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>h4</span><span>&gt;</span></span><span>Plus / Minus 1</span><span><span><span>&lt;/</span>h4</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>store<span>.</span><span>getState</span><span>(</span><span>)</span><span>.</span><span>count</span><span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>plus</span><span>}</span></span><span>&gt;</span></span><span>+1</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>minus</span><span>}</span></span><span>&gt;</span></span><span>-1</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>
        </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>

        </span><span><span><span>&lt;</span>h4</span><span>&gt;</span></span><span>Multiply / Divide 2 (0.3s delay)</span><span><span><span>&lt;/</span>h4</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>store<span>.</span><span>getState</span><span>(</span><span>)</span><span>.</span><span>double</span><span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>mult…</span></span></span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pitayan.com/posts/redux-fp-design/?ref=hackernews">https://pitayan.com/posts/redux-fp-design/?ref=hackernews</a></em></p>]]>
            </description>
            <link>https://pitayan.com/posts/redux-fp-design/?ref=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24046631</guid>
            <pubDate>Tue, 04 Aug 2020 04:33:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Profitably Unemployed]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24045529">thread link</a>) | @hackernewsreadr
<br/>
August 3, 2020 | https://blogofjake.com/2020/08/03/profitably-unemployed/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/08/03/profitably-unemployed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><u>A Money Mystery</u></strong></p>



<p>I have been unemployed for 10 months now and my net worth is greater today than it was when I quit my job. The purpose of this piece is to explain how that has happened.</p>



<p>First, I want to be clear about a few ways in which I did not make money. I did not receive any government money through unemployment nor from the stimulus checks. Unemployment money is not for people who quit their jobs voluntarily and the stimulus checks were not for people who made more than $99,000 in 2019. I have not had any paid job at any point in the last 10 months. I did not start a profitable business at any point during that time. I have not made any money from this blog. My only material source of income has been through the appreciation of investments that I have made on my own, but that is not the part the matters most.</p>



<p><strong><u>The Water Bucket Analogy</u></strong></p>



<p>What matters most is how I have kept from losing money.</p>



<p>To explain, let me introduce a simple analogy. Think about a bucket of water with a hose that fills it and a hole near the bottom where the water leaks out. The water in the bucket represents your money and the speed at which it leaks out of the hole is the speed at which your money is spent. Most people have a paying job. That’s the hose.</p>



<p>People want to increase their net worth over time and so naturally they think about how they can get more water faster from the hose. The better place to start, however, is to focus on limiting the leakage. People’s general focus on the hose rather than the hole is well demonstrated by the fact that anyone you ask will be able to tell you how much money they make by some unit of time but almost no one will be able to tell you the same in terms of their costs. They probably know the cost of their rent or mortgage payments and a number of other standalone expenses (by varying units of time) but very few will be able to tell you how much money they spend on an average day including their monthly, annual, and other periodic expenses spread out over the course of the respective period. I certainly could not have answered that question myself a year ago but doing so seemed like the sensible place to start.</p>



<p><strong><u>Base Burn Rate</u></strong></p>



<p>I knew when I quit my job in banking that in order to keep my cash burn in check I would need to get my expenses in order. I had turned the hose off so I needed to manage the hole. I started with my subscriptions (monthly and annual payments). I looked at the recurring expenses on my credit card and bank statements. I cancelled almost all of them. I had to add one significant one, health insurance, which my employer had been paying previously. I went with the second cheapest plan I could find from Horizon Blue Cross Blue Shield for $287/month. Next time I would instead go with the second cheapest plan from Oscar for $293/month because I like newer companies in broken industries and they tend to offer a better customer experience.</p>



<p>My next largest recurring payment was my phone bill. I went into the Verizon store and asked what the differences were between my current plan and the cheapest one I could possibly have. The only difference of any significance was the inability with the lower plan to use a hotspot. That infrequently used function was not nearly worth the ~$80/month difference in plans. I cut my phone bill in half to $78/month.</p>



<p>Below are the rest of my monthly and annual expenses as they stand today. As you will see, if I didn’t actively spend any money, these passive expenses alone would result in only a $15/day average burn. I call this my <strong><em>base burn rate</em></strong>. <em>Note: this figure was closer to $60 when I was living in New York pre-covid (+ rent, WiFi, utilities) and between $30-$60 when I was traveling in Europe and Asia (+ hostels/Airbnbs), but right now I am fortunate to be living with my family for free</em>.</p>



<figure><img data-attachment-id="1253" data-permalink="https://blogofjake.com/image-2-4/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png" data-orig-size="515,213" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=515" src="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=515" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/08/image-2.png 515w, https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=300 300w" sizes="(max-width: 515px) 100vw, 515px"></figure>



<p>Not bad right? It gets better…</p>



<p><strong><u>Passive Income</u></strong></p>



<p>I think about my investments in terms of three categories – crypto, stocks, and real estate. Real estate is unique among the three in that it pretty predictably generates cash flows each month. This is because our monthly rents collected from tenants are more than enough to cover the monthly mortgage payments, the cost of our property manager (10% of rent), and any necessary maintenance and/or repairs that she facilitates on our behalf over the course of a given month. Subtracting those expenses from the total rent collected each month and splitting the balance with my good friend and co-owner Kyle leaves me to expect $319/month (assuming the average amount of monthly repairs) which comes out to about $10/day. This is a far cry from the passive income of a real estate magnate but it is solid for a first property and not insignificant for me when it is the only dependable income that I have. Most importantly, this passive income offsets two-thirds of my base burn rate at the moment.</p>



<p>With my base burn rate and passive income figured out, I can calculate what I call my <strong><em>net base burn rate</em></strong> which in this case is equal to $5/day,</p>



<p><strong><u>3 Basic Principles</u></strong></p>



<p>After minimizing my base burn rate and estimating my passive income to calculate my net base burn rate, the next category I considered was comprised of the regularly re-occurring but variable expenses that cost me the most. This includes food, drinks, transportation, and entertainment. I came up with a few principles to help myself spend less in these areas. That said, I believe one of the best things money can buy is the ability not to have to worry about money so rather than force any hard rules upon myself I mostly just keep these principles in mind and try to be reasonable most of the time. <em>Note: these principles were most applicable when I was traveling and then living in New York pre-covid.</em></p>



<ol type="1"><li>Food – don’t drink a lot at restaurants. You are there for the food and the company.</li><li>Drinks – drink less and mostly at yours or friends’ places. The lower your tolerance, the cheaper the fun.</li><li>Transportation – walk when you can. Subways are usually quicker and always cheaper than cars.</li></ol>



<p><strong><u>Exceeding Expectations</u></strong></p>



<p>The goal is not to be watching your wallet all the time. It is to figure it out, then forget about it. Knowing my net base burn rate of $5/day leads to an annual burn of less than $2,000 allows me to live and spend confidently because I know if I ever want to slow my burn I can basically do so simply by doing nothing (therefore slowing my active spending). I don’t <em>need</em> to drink alcohol or go golfing and I could easily eat for a few dollars per day if I was willing to eat less healthfully and not go out for a while. Fortunately, I have not had to sacrifice any of these things. If I did have to, I know that I could, but I would probably just go and get a job at that point and realistically well before that point ever came.</p>



<p>In order to quit my job in the first place, I had to be willing to endure some level of burn in exchange for the freedom of time that I was buying for myself. I was confident that I could offset some of it with my investments in crypto and stocks, and the non- cash flow part of my real estate investment (the appreciation of the value of my equity in the property). Never would I have anticipated what has happened to date. I am pleased to say that between Bitcoin’s surge this week, Amazon’s last month, the appreciation of my Kentucky property’s value, and some other smaller stock and crypto investments along the way, my investments have now offset the entirety of my burn over the last 10 months. My net worth is slightly greater today than it was the day I quit my job, and it is not because I’ve been a hermit or lived a miserably frugal life. Quite the contrary. I traveled the world for a few months, had a four-month lease in New York City and stayed in a couple hotels before that, got a month-long Airbnb in Georgia with Lauren, have eaten well, been golfing a lot lately, and the list goes on. Not every day is roses. I would be skeptical of anyone who says that is the case. But I have not often if ever but rarely felt restrained moneywise. I have been enjoying my time quite a bit.</p>



<p>When I quit my job, I figured I would burn a good chunk of my savings in a few months and expected I would feel the need to get a job after several if not before then. I thought it would be well worthwhile to burn that money in exchange for the time that I would buy for myself to do whatever I wanted. I was right in the sense that this time has proven valuable to me but wrong in another. It hasn’t cost me a dime.</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-08-03T16:13:48-04:00">August 3, 2020</time><time datetime="2020-08-03T16:17:10-04:00">August 3, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/08/03/profitably-unemployed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045529</guid>
            <pubDate>Tue, 04 Aug 2020 01:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harry Potter and the Mnemonic Major System]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24045475">thread link</a>) | @krisfris
<br/>
August 3, 2020 | https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html | <a href="https://web.archive.org/web/*/https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  <div itemprop="articleBody">
    <p>As most reasonable people are familiar with the Harry Potter books,
their content serves as ideal material for building a mnemonic system.
The mnemonic major system, in particular, is used to memorize number sequences.</p>

<p>In order to implement the steps outlined in this post you need the content of the Harry Potter books (or other book(s) if you prefer).
In a previous post I showed you how to
<a href="https://darkshadow.io/2020/06/29/building-a-fantasy-book-db.html">download fantasy books and extract their text</a>.
Among the downloaded data were the Harry Potter books which I will use in this post.</p>

<h3 id="step-1-learn-the-sound-number-mapping">Step 1: Learn the sound-number mapping</h3>

<p>In the mnemonic major system each number from 0 to 9 is associated with one or more
consonant sounds. Use the following table as a reference.</p>

<table>
  <thead>
    <tr>
      <th>Number</th>
      <th>Sounds (IPA)</th>
      <th>Letters with example words</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>s, z</td>
      <td>s (see), c (city), z (zero), x (xylophone)</td>
    </tr>
    <tr>
      <td>1</td>
      <td>t, d, ð, θ</td>
      <td>t (tee), d (dad), th (though), th (think)</td>
    </tr>
    <tr>
      <td>2</td>
      <td>n, ŋ</td>
      <td>n (nail)</td>
    </tr>
    <tr>
      <td>3</td>
      <td>m</td>
      <td>m (monster)</td>
    </tr>
    <tr>
      <td>4</td>
      <td>r</td>
      <td>r (right), l (colonel)</td>
    </tr>
    <tr>
      <td>5</td>
      <td>l</td>
      <td>l (left)</td>
    </tr>
    <tr>
      <td>6</td>
      <td>ʤ, ʧ, ʃ, ʒ</td>
      <td>ch (cheese), j (juice), g (ginger), sh (shell), c (cello, special),<br> cz (czech), s (tissue, vision), sc (fascist), sch (eschew),<br>t (ration), tsch (putsch), z (seizure)</td>
    </tr>
    <tr>
      <td>7</td>
      <td>k, ɡ</td>
      <td>k (kid), c (cake), q (quarter), g (good), ch (loch)</td>
    </tr>
    <tr>
      <td>8</td>
      <td>f, v</td>
      <td>f (face), ph (phone), v (alive), gh (laugh)</td>
    </tr>
    <tr>
      <td>9</td>
      <td>p, b</td>
      <td>p (power), b (baby)</td>
    </tr>
  </tbody>
</table>

<p>In English, letters are pronounced in different ways depending on the context,
that’s why some letters are repeated in different rows. But in the end,
only the sound matters, not the spelling.</p>

<p>Here are a few examples for words, their IPA representation and the number they encode.</p>

<table>
  <thead>
    <tr>
      <th>Word</th>
      <th>IPA</th>
      <th>Number</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>action</td>
      <td>ækʃən</td>
      <td>762</td>
    </tr>
    <tr>
      <td>muddy</td>
      <td>mədi</td>
      <td>31</td>
    </tr>
    <tr>
      <td>midday</td>
      <td>mɪddeɪ</td>
      <td>311</td>
    </tr>
    <tr>
      <td>accept</td>
      <td>æksɛpt</td>
      <td>7091</td>
    </tr>
    <tr>
      <td>fax</td>
      <td>fæks</td>
      <td>870</td>
    </tr>
    <tr>
      <td>exam</td>
      <td>ɪgzæm</td>
      <td>703</td>
    </tr>
    <tr>
      <td>anxious</td>
      <td>æŋkʃəs</td>
      <td>2760</td>
    </tr>
    <tr>
      <td>luxury</td>
      <td>ləgʒəri</td>
      <td>5764</td>
    </tr>
    <tr>
      <td>pizza</td>
      <td>pitsə</td>
      <td>910</td>
    </tr>
    <tr>
      <td>ghost</td>
      <td>goʊst</td>
      <td>701</td>
    </tr>
    <tr>
      <td>enough</td>
      <td>inəf</td>
      <td>28</td>
    </tr>
    <tr>
      <td>fear</td>
      <td>fɪr</td>
      <td>84</td>
    </tr>
  </tbody>
</table>

<p>To familiarize yourself with the IPA notation, try to read the following excerpt.</p>

<figure><pre><code data-lang="html">Sorting Hat: həm, dɪfəkəlt. vɛri dɪfəkəlt. plɛnti əv kərɪʤ, aɪ si.
             nɑt ə bæd maɪnd, iðər. ðɛrz tælənt, oʊ jɛs. ənd ə θərst tɪ pruv jʊrsɛlf.
             bət wɛr tɪ pʊt ju?
Harry:       nɑt slɪðərɪn. nɑt slɪðərɪn.
Sorting Hat: nɑt slɪðərɪn, ɛ? ər ju ʃʊr? ju kʊd bi greɪt, ju noʊ. ɪts ɔl hir ɪn jʊr hɛd.
             ənd slɪðərɪn wɪl hɛlp ju ɔn ðə weɪ tɪ greɪtnəs, ðɛrz noʊ daʊt əbaʊt ðət. noʊ?
Harry:       pliz, pliz. ɛniθɪŋ bət slɪðərɪn, ɛniθɪŋ bət slɪðərɪn.
Sorting Hat: wɛl ɪf jʊr ʃʊr, bɛtər bi... grɪfɪndɔː!</code></pre></figure>

<p>Consider the same lines converted to number sequences.</p>

<figure><pre><code data-lang="html">Sorting Hat: 3 18751 84 18751 9521 8 746 0 21 91 321 14 140 1521 0 21 8401 1 948 4058 91 4 1 91
Harry:       21 05142 21 05142
Sorting Hat: 21 05142 4 64 71 9 741 2 10 5 4 2 4 1 21 05142 5 59 2 1 1 74120 140 2 11 91 11 2
Harry:       950 950 282 91 05142 282 91 05142
Sorting Hat: 5 8 4 64 914 9 74821</code></pre></figure>

<p>I’m going to show you how to write a training program to internalize
the concept of mapping sounds to numbers in Step 4. But first, you need the ability
to convert text automatically to numbers. This happens in 2 steps. First, the text is converted
to IPA. Then, the IPA is converted to numbers.</p>

<h3 id="step-2-converting-ipa-to-numbers">Step 2: Converting IPA to numbers</h3>

<p>The process of converting IPA to numbers is very simple. I iterate through the IPA chars
and if there is a number associated with the char I append the number to the result.</p>

<figure><pre><code data-lang="python"><span># Mapping from number to sounds
</span><span>num_to_phones</span> <span>=</span> <span>{</span><span>0</span><span>:</span> <span>[</span><span>'s'</span><span>,</span> <span>'z'</span><span>],</span> <span>1</span><span>:</span> <span>[</span><span>'t'</span><span>,</span> <span>'d'</span><span>,</span> <span>'ð'</span><span>,</span> <span>'θ'</span><span>],</span> <span>2</span><span>:</span> <span>[</span><span>'n'</span><span>,</span> <span>'ŋ'</span><span>],</span> <span>3</span><span>:</span> <span>[</span><span>'m'</span><span>],</span> <span>4</span><span>:</span> <span>[</span><span>'r'</span><span>],</span>
                 <span>5</span><span>:</span> <span>[</span><span>'l'</span><span>],</span> <span>6</span><span>:</span> <span>[</span><span>'ʤ'</span><span>,</span> <span>'ʧ'</span><span>,</span> <span>'ʃ'</span><span>,</span> <span>'ʒ'</span><span>],</span> <span>7</span><span>:</span> <span>[</span><span>'k'</span><span>,</span> <span>'g'</span><span>],</span> <span>8</span><span>:</span> <span>[</span><span>'f'</span><span>,</span> <span>'v'</span><span>],</span>
                 <span>9</span><span>:</span> <span>[</span><span>'p'</span><span>,</span> <span>'b'</span><span>]}</span>

<span># Reverse mapping from sound to number
</span><span>phone_to_num</span> <span>=</span> <span>{</span><span>x</span><span>:</span> <span>k</span> <span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>num_to_phones</span><span>.</span><span>items</span><span>()</span> <span>for</span> <span>x</span> <span>in</span> <span>v</span><span>}</span>

<span>def</span> <span>major_decode_from_ipa</span><span>(</span><span>ipa</span><span>):</span>
    <span>"""Convert IPA to number sequence."""</span>
    <span>result</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>char</span> <span>in</span> <span>ipa</span><span>:</span>
        <span>if</span> <span>(</span><span>num</span> <span>:</span><span>=</span> <span>phone_to_num</span><span>.</span><span>get</span><span>(</span><span>char</span><span>))</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>result</span><span>.</span><span>append</span><span>(</span><span>num</span><span>)</span>
    <span>return</span> <span>result</span></code></pre></figure>

<p>For example, <code>major_decode_from_ipa('dɪfəkəlt')</code> yields <code>[1, 8, 7, 5, 1]</code>.</p>

<p>Additionally, I define a couple functions for converting number sequences to and from strings.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>numseq_to_str</span><span>(</span><span>numseq</span><span>):</span>
    <span>"""Convert number sequence to string."""</span>
    <span>return</span> <span>''</span><span>.</span><span>join</span><span>(</span><span>str</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>numseq</span><span>)</span>

<span>def</span> <span>str_to_numseq</span><span>(</span><span>s</span><span>):</span>
    <span>"""Convert string to number sequence."""</span>
    <span>return</span> <span>[</span><span>int</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>s</span> <span>if</span> <span>x</span><span>.</span><span>isdigit</span><span>()]</span></code></pre></figure>

<p>For example, <code>numseq_to_str([1, 8, 7, 5, 1])</code> yields <code>'18751'</code>.</p>

<h3 id="step-3-converting-text-to-ipa">Step 3: Converting text to IPA</h3>

<p>In order to automatically convert text to IPA (and then to numbers) you need to use an IPA
dictionary.</p>

<p>Python’s <a href="https://pypi.org/project/eng-to-ipa/">eng-to-ipa</a> package is able to convert text to
IPA using the <em>Carnegie-Mellon University Pronouncing Dictionary</em>.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>eng_to_ipa</span>

<span>s</span> <span>=</span> <span>'“I’ll bring up some sandwiches.”'</span>  <span># Sentence from the HP books
</span><span>ipa</span> <span>=</span> <span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>s</span><span>,</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>)</span>
<span>print</span><span>(</span><span>ipa</span><span>)</span></code></pre></figure>

<p>This yields:</p>

<figure><pre><code data-lang="html">['“i’ll* brɪŋ əp səm sandwiches.”*']</code></pre></figure>

<p>According to the docs, eng-to-ipa will reprint words that cannot be found in the CMU dictionary
with an asterisk. Thus, <code>“i’ll</code> and <code>sandwiches.”</code> have not been found. Clearly, the punctuation is the issue.
I preprocess the text in order to ease the conversion to IPA.</p>

<figure><pre><code data-lang="python"><span># Punctuation including unicode chars
</span><span>punctuation</span> <span>=</span> <span>''</span><span>.</span><span>join</span><span>(</span><span>chr</span><span>(</span><span>i</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>sys</span><span>.</span><span>maxunicode</span><span>)</span>
                      <span>if</span> <span>unicodedata</span><span>.</span><span>category</span><span>(</span><span>chr</span><span>(</span><span>i</span><span>)).</span><span>startswith</span><span>(</span><span>'P'</span><span>))</span>

<span>def</span> <span>preprocess</span><span>(</span><span>text</span><span>):</span>
    <span>"""Strip punctuation between words, normalize space, lowercase, replace unicode apostrophe."""</span>
    <span>return</span> <span>' '</span><span>.</span><span>join</span><span>(</span><span>x</span><span>.</span><span>strip</span><span>(</span><span>punctuation</span><span>).</span><span>lower</span><span>().</span><span>replace</span><span>(</span><span>'’'</span><span>,</span> <span>'</span><span>\'</span><span>'</span><span>)</span>
                    <span>for</span> <span>x</span> <span>in</span> <span>text</span><span>.</span><span>split</span><span>())</span>
                    
<span>print</span><span>(</span><span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>preprocess</span><span>(</span><span>s</span><span>),</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>))</span></code></pre></figure>

<p>And…</p>

<figure><pre><code data-lang="html">['aɪl brɪŋ əp səm sæmwɪʧɪz', 'aɪl brɪŋ əp səm sændwɪʧɪz', 'aɪl brɪŋ əp səm sænwɪʧɪz']</code></pre></figure>

<p>As you can see, there are 3 ways to pronounce this sentence depending on whether you like
to pronounce <code>sandwich</code> with <code>m</code>, <code>n</code> or <code>nd</code>. In order to use the major system effectively,
you should use the version that sounds most natural to you.</p>

<p>Let’s look at another example.</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>eng_to_ipa</span><span>(</span><span>preprocess</span><span>(</span><span>'Well, if you’re sure — better be GRYFFINDOR!'</span><span>),</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span>
                 <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>))</span></code></pre></figure>

<figure><pre><code data-lang="html">['wɛl ɪf jur ʃʊr bɛtər bi gryffindor*', 'wɛl ɪf jʊr ʃʊr bɛtər bi gryffindor*']</code></pre></figure>

<p>The word <code>gryffindor</code> was not found in the CMU dictionary, which can be expected.
After a quick search for the word’s pronunciation I found <a href="https://youglish.com/pronounce/gryffindor/english">YouGlish</a>
which uses YouTube videos to find IPAs. While their API is not free, a limited number of IPA’s can be scraped
for our purpose.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>time</span><span>,</span> <span>random</span><span>,</span> <span>requests</span><span>,</span> <span>lxml</span><span>.</span><span>html</span><span>.</span><span>soupparser</span>

<span>def</span> <span>ipa_from_youglish</span><span>(</span><span>word</span><span>):</span>
    <span>"""Scrape IPA for word from youglish.com."""</span>
    <span>url</span> <span>=</span> <span>f'https://youglish.com/pronounce/</span><span>{</span><span>word</span><span>}</span><span>/english?'</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>print</span><span>(</span><span>f'Scraping word "</span><span>{</span><span>word</span><span>}</span><span>" from youglish...'</span><span>,</span> <span>end</span><span>=</span><span>''</span><span>,</span> <span>flush</span><span>=</span><span>True</span><span>)</span>
        <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>
        <span>if</span> <span>'Usage limit exceeded'</span> <span>in</span> <span>response</span><span>.</span><span>text</span><span>:</span>
            <span>raise</span> <span>Exception</span><span>(</span><span>'YouGlish usage limit exceeded'</span><span>)</span>
        <span>root</span> <span>=</span> <span>lxml</span><span>.</span><span>html</span><span>.</span><span>soupparser</span><span>.</span><span>fromstring</span><span>(</span><span>response</span><span>.</span><span>text</span><span>)</span>
        <span>if</span> <span>root</span><span>.</span><span>xpath</span><span>(</span><span>'//div[@class="g-recaptcha"]'</span><span>):</span>
            <span>print</span><span>(</span><span>'RECAPTCHA'</span><span>)</span>
            <span>input</span><span>(</span><span>f'Open </span><span>{</span><span>url</span><span>}</span><span>, submit CAPTCHA challenge, press enter to continue.'</span><span>)</span>
        <span>else</span><span>:</span>
            <span>break</span>
    <span>time</span><span>.</span><span>sleep</span><span>(</span><span>random</span><span>.</span><span>random</span><span>()</span> <span>*</span> <span>3</span><span>)</span>
    <span>d</span> <span>=</span> <span>root</span><span>.</span><span>xpath</span><span>(</span><span>'//div[@id="phoneticPanel"]/div/ul[@class="transcript"]'</span>
                  <span>'/li/span[contains(text(), "Traditional IPA")]'</span>
                  <span>'/following-sibling::text()'</span><span>)</span>
    <span>if</span> <span>d</span><span>:</span>
        <span>print</span><span>(</span><span>'SUCCESS'</span><span>)</span>
        <span>return</span> <span>d</span><span>[</span><span>0</span><span>].</span><span>strip</span><span>(</span><span>' ˈ'</span><span>)</span>
    <span>print</span><span>(</span><span>'FAILED'</span><span>)</span></code></pre></figure>

<p>As you can see, this function is semi-interactive. Without user intervention it will
get stuck on a CAPTCHA. Even then, you’ll eventually reach their daily usage limit
and won’t be able to continue. For our purpose this shall be good enough though.</p>

<figure><pre><code data-lang="python"><span>&gt;</span> <span>ipa_from_youglish</span><span>(</span><span>'gryffindor'</span><span>)</span>
<span>Scraping</span> <span>word</span> <span>"gryffindor"</span> <span>from</span> <span>youglish</span><span>...</span><span>SUCCESS</span>
<span>grɪfɪndɔː</span></code></pre></figure>

<p>I have shown that for many words there are several possible pronunciations, from which you need to choose
your preferred one, and that some words are not in the CMU dictionary and
require scraping the IPA from another source or are not available at all.
For these 2 reasons, you will need to build your own personal IPA dictionary.</p>

<p>I’m going to build my IPA dictionary by iterating through the words of the Harry Potter books
and adding each word and the corresponding IPA to my dictionary.</p>

<p>First, I define
some functions for managing my dictionary (a simple JSON file in this case).</p>

<figure><pre><code data-lang="python"><span>import</span> <span>os</span><span>,</span> <span>glob</span><span>,</span> <span>json</span>

<span>ipa_dict_path</span> <span>=</span> <span>'data/ipa-dict.json'</span>

<span>def</span> <span>load_json_file_or_dict</span><span>(</span><span>filename</span><span>):</span>
    <span>"""Load data from json file if exists otherwise return empty dict."""</span>
    <span>if</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>isfile</span><span>(</span><span>filename</span><span>):</span>
        <span>with</span> <span>open</span><span>(</span><span>filename</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
            <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>f</span><span>)</span>
    <span>return</span> <span>dict</span><span>()</span>

<span>def</span> <span>save_to_json_file</span><span>(</span><span>data</span><span>,</span> <span>filename</span><span>):</span>
    <span>"""Save data to json file."""</span>
    <span>with</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>json</span><span>.</span><span>dump</span><span>(</span><span>data</span><span>,</span> <span>f</span><span>)</span>

<span>def</span> <span>load_ipa_dict</span><span>():</span>
    <span>"""Load IPA dict from json file."""</span>
    <span>return</span> <span>load_json_file_or_dict</span><span>(</span><span>ipa_dict_path</span><span>)</span>

<span>def</span> <span>save_ipa_dict</span><span>(</span><span>ipa_dict</span><span>):</span>
    <span>"""Save IPA dict to json file."""</span>
    <span>save_to_json_file</span><span>(</span><span>ipa_dict</span><span>,</span> <span>ipa_dict_path</span><span>)</span></code></pre></figure>

<p>Next, I iterate through the words of the books and enter
each word and whatever is returned by <em>eng-to-ipa</em> into my dictionary.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>harry_potter_text</span><span>():</span>
    <span>"""Return entire content of the Harry Potter books in a single string."""</span>
    <span>data</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>filename</span> <span>in</span> <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'data/json/Harry Potter*'</span><span>):</span>
        <span>with</span> <span>open</span><span>(</span><span>filename</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
            <span>data</span><span>.</span><span>append</span><span>(</span><span>json</span><span>.</span><span>load</span><span>(</span><span>f</span><span>)[</span><span>'text'</span><span>])</span>
    <span>return</span> <span>' '</span><span>.</span><span>join</span><span>(</span><span>data</span><span>)</span>
    
<span>def</span> <span>populate_ipa_dict_from_text</span><span>(</span><span>text</span><span>):</span>
    <span>"""Get all IPA information from eng_to_ipa and save to ipa_dict."""</span>
    <span>ipa_dict</span> <span>=</span> <span>load_ipa_dict</span><span>()</span>
    <span>words</span> <span>=</span> <span>preprocess</span><span>(</span><span>text</span><span>).</span><span>split</span><span>()</span>
    <span>for</span> <span>word</span> <span>in</span> <span>set</span><span>(</span><span>words</span><span>)</span> <span>-</span> <span>set</span><span>(</span><span>ipa_dict</span><span>.</span><span>keys</span><span>()):</span>
        <span>ipa</span> <span>=</span> <span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>word</span><span>,</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span>
                                 <span>stress_marks</span><span>=</span><span>False</span><span>)</span>
        <span>ipa_dict</span><span>[</span><span>word</span><span>]</span> <span>=</span> <span>ipa</span>
    <span>save_ipa_dict</span><span>(</span><span>ipa_dict</span><span>)</span>
    
<span>populate_ipa_dict_from_text</span><span>(</span><span>harry_potter_text</span><span>())</span></code></pre></figure>

<p>Each value in the dictionary is now a list of possible IPAs as that is what
<em>eng-to-ipa</em> returned. Before the dictionary can be used, we need to ensure
that each word …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html">https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html</a></em></p>]]>
            </description>
            <link>https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045475</guid>
            <pubDate>Tue, 04 Aug 2020 01:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physical attractiveness bias in the legal system (2017)]]>
            </title>
            <description>
<![CDATA[
Score 360 | Comments 322 (<a href="https://news.ycombinator.com/item?id=24044409">thread link</a>) | @simonebrunozzi
<br/>
August 3, 2020 | https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system | <a href="https://web.archive.org/web/*/https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">

      

      

      
        
          
            
              
                
              
            
          
        
      


      
      
      

      <main id="page" role="main">
        
        <!--
        --><!--
        --><div id="content" data-content-field="main-content" data-collection-id="5817e1ff3e00be2eafd0dec4" data-edit-main-image="">
         <div>

  
  <article id="article-58c757b5e4fcb5bd2d9613d5" data-item-id="58c757b5e4fcb5bd2d9613d5">

    

    <div>
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1489459192059" id="item-58c757b5e4fcb5bd2d9613d5"><div><div><div data-block-type="2" id="block-yui_3_17_2_3_1489466160916_36894"><div><blockquote><p><a href="http://bit.ly/2m8beq4" target="_blank">[Download for PDF/printable version of this article]</a><br></p></blockquote><p>When I started looking into this subject, I predicted a person’s physical attractiveness would only have minor advantages. I was wrong.</p><p>In fact, I was so wrong, that in one study, the effects of physical attractiveness on judges were so influential, they fined unattractive criminals 304.88% higher than attractive criminals.</p><p>Surprising, I know.</p><p>Before we proceed, I want to address a few concerns of mine. Firstly, the information that you will read may cause some readers to feel unsettled. This is not my intention. Yes, it is disheartening. But the purpose of this article is to inform lawyers and other decision makers so that they can use the attractiveness bias to their advantage or to counter it.</p><p>A second concern of mine is that I don’t want to over-emphasise the attractiveness bias. Judges and jurors are affected by all kinds of cognitive distortions, such as emotive evidence, time of day, remorse of the defendant, socioeconomic status, race, gender, anchoring effect, and the contrast bias.</p><p>In the first section of this article, I give a ‘straight-to-the-point’ summary of the research conducted by 27 studies. Next, I enter into greater depth on the attractiveness bias and its effects on judges, jurors, and lawyers. Lastly, I provide research on the attractiveness bias in everyday life. Arguably, the last section is the most interesting.</p><p>Enjoy!</p><p>* * *</p><ol data-rte-list="default"><li><p>Physical Attractiveness had a significant influence on judges sentencing. The more unattractive the criminal, the higher the sentence. Or conversely, the more attractive the criminal, the lower the sentence. The results of three studies show a minimum increase of 119.25% and a maximum increase of 304.88%.<br></p></li><li><p>Attractiveness had little to no effect on a judge’s verdict of guilt. Attractive and unattractive criminals were convicted equally.<br></p></li><li><p>Mock jurors generally sentenced unattractive criminals significantly higher than attractive criminals. However, as jurors do not determine sentencing in real court cases, these results are not directly applicable.<br></p></li><li><p>Attractiveness had minor effects on mock juror’s verdicts. Some studies reported minor effects and some studies reported no effects.<br></p></li><li><p>Generally, attractive people are perceived as more intelligent, more socially skilled, more appealing personalities, more moral, more altruistic, more likely to succeed, more hirable as managers, and more competent. Attractive people tend to have better physical health, better mental health, better dating experiences, earn more money, obtain higher career positions, chosen for jobs more often, promoted more often, receive better job evaluations, and chosen as business partners more often, than unattractive people.<br></p></li><li><p>I believe that the attractiveness bias is rarely conscious. I do not think people are consciously disfavouring unattractive people. I also do not place moral blame on the typical person for their unconscious bias.</p></li></ol><p>* * *</p><h2><strong>REAL JUDGES: SENTENCING</strong></h2><p><strong>THE MISDEMEANOUR STUDY </strong><em>[1]</em></p><p>The first study we will observe is the research conducted by Downs and Lyons.</p><p>The purpose of this study was to find a link between a criminal’s attractiveness and sentencing outcomes.</p><p>They gathered a group of police officers and students to rate the attractiveness of over 2000 criminals. A scale of 1 - 5 was used and their ratings were mostly similar.</p><p>Then, the judges sentencing decisions were divided into two main categories: misdemeanors and felonies. Misdemeanors were separated into to 3 classes, related to the severity of the crime.</p><p><em>The Results &amp; Key Takeaways</em></p><p>For misdemeanours, the judges fined unattractive criminals significantly more than attractive criminals. The fine incrementally increased as the attractiveness decreased.</p><p>1.&nbsp;&nbsp;&nbsp;&nbsp; Minor Misdemeanours = +224.87%</p><p>2.&nbsp;&nbsp;&nbsp;&nbsp; Moderate Misdemeanours = +304.88%</p><p>3.&nbsp;&nbsp;&nbsp;&nbsp; Serious Misdemeanours = + 174.78%</p><p>The results are graphed below.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_48500"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg" data-image-dimensions="1047x619" data-image-focal-point="0.5,0.5" alt="Image test 1.jpg" data-load="false" data-image-id="58c89366f7e0ab29642796d9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_48699"><div><p>Curiously, felony fines had no correlation with the attractiveness of the criminal. The study does not make it clear why this is the case.</p><p><em>Answers to Possible Objections</em></p><ul data-rte-list="default"><li><p>The judges varied in gender and race.</p></li><li><p>There was no correlation between sentencing outcomes and age, gender, and race.</p></li></ul><p><em>Weaknesses</em></p><p>For privacy reasons, the specific crime was not documented.</p><p>The direction of causation is not known. I enter into more depth in the section entitled ‘causation’.</p><p><strong>THE PENNSYLVANIAN STUDY<em> </em></strong><em>[2]</em></p><p>In Pennsylvanian and Philadelphian courts, the researcher’s gathered data on 67 defendants. The defendants were a mix of black, Hispanic, and white and there were 15 real judges in total.</p><p><em>Results &amp; Key Takeaways</em></p><p>On average (mean), criminals of low attractiveness were sentenced to 4.10 years in prison and criminals of high attractiveness were sentenced to 1.87 years in prison. This equals a 119.25% increase.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_71526"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png" data-image-dimensions="1095x642" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75991e6f2e16d0cb71613" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_71724"><div><p><em>Weaknesses</em></p><p>All observers were white.</p><p><strong>THE SECOND PENNSYLVANIAN STUDY</strong> <em>[3]</em></p><p>This study was similar to the previous study. The researchers recorded data from real court cases in Pennsylvania. They detailed the physical attractiveness of 60 defendants and their neatness, cleanliness, and quality of clothing. Then, they recorded the judge’s decisions.</p><p>The criminals were charged with a range of felonies, including ‘murder; manslaughter; rape; kidnapping; armed robbery; aggravated assault; indecent assault; arson; burglary; conspiracy to sell/delver heroin, cocaine, hashish, and other elicit drugs; extortion; fraud; theft; and firearms violation.’</p><p>They were also a mix of white, Hispanic and black.&nbsp;</p><p><em>Results &amp; Key Takeaways</em></p><p>The unattractive defendants were punished higher than the attractive defendants.</p><p><em>Weaknesses</em></p><p>The study did not give specific results. This is a major disappointment.</p><p><strong>CONCLUSIONS</strong></p><p>Unattractive criminals were punished higher than attractive criminals in three studies. The lowest increase was at 119.25% and the highest increase was at 304.88%.</p><h2><strong>REAL JUDGES: VERDICT, GUILTY OR NOT-GUILTY</strong></h2><p>There was no association between the defendant’s physical attractiveness and the judge’s verdict. Attractive and unattractive criminals were found guilty at equal rates. Zebrowitz and McDonald [4]&nbsp;also found that the plaintiff’s attractiveness had little to no effects on a judge’s verdict.</p><p><strong>THE BABY-FACED STUDY </strong><em>[5]</em></p><p>The following study is not directly related to physical attractiveness but it is related to physical appearance.</p><p>Zebrowitz and McDonald measured the effects of defendants with a ‘baby-face’ and the judge’s verdict decisions. This is a strange characteristic to measure, however, the results were significant enough to warrant attention.</p><p>‘Baby-faced adults tend to have larger eyes, thinner, higher eyebrows, a large forehead and a small chin, and a curved rather than an angular face.’<em>[6]</em>&nbsp;A team of participants sat in 421 cases in ‘6 branches of the Commonwealth of Massachusetts small claims courts. 3 judges heard 51% of the cases and the remaining 49% of the cases were presided over by 22 additional judges.’ ‘62% of the plaintiffs and 78% of the defendants were male. 96% of both plaintiffs and defendants were white, and 81% were between the ages of 21 and 50.’</p><p><em>Results &amp; Key Takeaways</em></p><p>The more baby-faced an adult was, the less likely he/she was found to be guilty for ‘intentional actions’ in civil claims. Observe the graph below.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_91414"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg" data-image-dimensions="2500x2137" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75a7ed482e9a66b47537e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_91612"><div><p>Interestingly, baby-faced adults had no effects in claims of negligent actions.</p><h2><strong>MOCK JURY: SENTENCING</strong></h2><p>Before I present the following research, I need to address a major limitation. Jurors do not decide upon sentencing, thus, the following results may not have direct application.</p><p><strong>THE META-ANALYSIS STUDY </strong><em>[7]</em></p><p>A meta-analysis examined 25 studies on the effects of physical attractiveness on mock jurors. They found that mock jurors gave higher sentences to unattractive criminals than attractive criminals. This was only for crimes of rape, robbery, and negligent homicide. For swindle, the punishment was equal. The physical attractiveness of the victim also had no effects on the jurors.</p><p><strong>THE BURGLARY STUDY </strong><em>[8]</em></p><p>In this study, the participants were given a burglary scenario along with an image of the criminal. Some received the unattractive criminal and others received the attractive criminal. 10 psychology students rated the attractiveness of the criminals prior to the study to determine attractiveness.</p><p>Then, they were asked to suggest a 1, 5, 10, 15, or 20 years imprisonment.</p><p>‘[The] participants consisted of 40 Euro-American men, 40 Euro-American women, 40 African- American men, and 40 African-American women.’ A strength of this study is the participants ranged in race, gender, and age.</p><p><em>Results &amp; Key Takeaways</em></p><p>The attractive criminal was given an average sentence of 9.7 years, and the unattractive criminal was given 14.7 years. That’s an increase of 51.55%.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_8_1489459079955_11521"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png" data-image-dimensions="1098x643" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75b829de4bb5cb740f698" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_8_1489459079955_11721"><div><p><em>Weaknesses</em></p><p>The researchers measured more items than simply attractiveness. This means that the 160 participants were not all measured on attractiveness. As they measured 8 different items and only two of them on attractiveness, I infer …</p></div></div></div></div></div></div></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system">https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system</a></em></p>]]>
            </description>
            <link>https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044409</guid>
            <pubDate>Mon, 03 Aug 2020 22:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go vs. Rust: Writing a CLI Tool]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24044043">thread link</a>) | @JeremyMorgan
<br/>
August 3, 2020 | https://cuchi.me/posts/go-vs-rust | <a href="https://web.archive.org/web/*/https://cuchi.me/posts/go-vs-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><img src="https://gist.githubusercontent.com/cuchi/59255d61717e2d469263eb86cf083067/raw/6ef1a42f335022adf481fb84cabc32ac47f18679/go-vs-rust.png" alt="Go vs. Rust"></p>
<p>This text is about my adventure writing a small CLI application (twice) using
two languages I had little experience with.</p>
<p>If you are eager to jump right into the code and compare it yourself, check it
out the <a href="https://github.com/cuchi/hashtrack/tree/master/cli-go">Go source</a> and
the <a href="https://github.com/cuchi/hashtrack/tree/master/cli-rust">Rust source</a>.</p>
<hr>
<h2>About the Project</h2>
<p>I have a <em>pet project</em> called Hashtrack, which is a full-stack web application I
wrote for a technical interview. This project is rather small and it is simple
to use:</p>
<ol>
<li>You authenticate - considering you already created your account</li>
<li>You input hashtags you want to track</li>
<li>You wait for the <em>captured</em> tweets to show on your screen</li>
</ol>
<p><a href="https://hashtrack.herokuapp.com/">Check it out here.</a></p>
<p>After my interview, I kept improving this project just for fun, and I noticed
that it could be a perfect place to test my skills by implementing a CLI tool. I
already had the server, so I just needed to pick a language to implement a small
set of features under my project's API.</p>
<h2>Features</h2>
<ul>
<li><code>hashtrack login</code> - Creates a session token and store it in the local
filesystem in a config file.</li>
<li><code>hashtrack logout</code> - Remove the locally stored session token.</li>
<li><code>hashtrack track &lt;hashtag&gt; [...]</code> - Tracks one or more hashtags.</li>
<li><code>hashtrack untrack &lt;hashtag&gt; [...]</code> - Untracks one or more previously tracked
hashtags.</li>
<li><code>hashtrack tracks</code> - Displays the hashtags you are tracking.</li>
<li><code>hashtrack list</code> - Displays the latest 50 captured tweets.</li>
<li><code>hashtrack watch</code> - Stream and display the captured tweets in real-time.</li>
<li><code>hashtrack status</code> - Displays who you are, if logged in.</li>
<li>Should have an <code>--endpoint</code> option to point the CLI to another server.</li>
<li>Should have a <code>--config</code> option to load a custom config file.</li>
<li>This config file could also share the <code>endpoint</code> property.</li>
</ul>
<p>What we have to know beforehand:</p>
<ul>
<li>The CLI should use the project's API, which is GraphQL under HTTP +
WebSockets.</li>
<li>The CLI should use the filesystem to store a config file.</li>
<li>The CLI should parse positional arguments and flags.</li>
</ul>
<h2>How did I end up using Go and Rust?</h2>
<p>There is a large set of languages you can use to write CLI tools.</p>
<p>In this case, I wanted a language I had little or no prior experience with, I
also wanted one that could easily compile to a native executable, which is a
nice perk to have on a CLI tool.</p>
<p>My first obvious choice was Go, maybe because a lot of CLI tools I use are
implemented using it. But I also had little experience with Rust, and I saw it
could also be a good fit for this project.</p>
<p>So... why not both? Since my main objective here is to learn, could be a great
opportunity to implement this project twice and find what are the <em>pros and
cons</em> of each one from my point of view.</p>
<blockquote>
<p>Honorable mentions to <a href="https://crystal-lang.org/">Crystal</a> and
<a href="https://nim-lang.org/">Nim</a>, those were very promising options too. I'm looking
forward to learn about them in another pet project.</p>
</blockquote>
<h2>Local environment</h2>
<p>The first thing I look when using a new toolset is whether it has an easy way to
make it available for my user, without using the distribution package manager to
install it system-wide. We are talking about version managers, they make our
life easier by installing the tools in a user-wide manner instead of
system-wide. <a href="https://github.com/nvm-sh/nvm">NVM</a> for Node.js does it very well.</p>
<p>When using Go, there is the <a href="https://github.com/moovweb/gvm">GVM</a> project which
handles the local install &amp; version management, and it is easy to setup:</p>
<pre><code>gvm install go1.14 -B
gvm use go1.14
</code></pre>
<p>There are also two environment variables we need to know, they are <code>GOROOT</code> and
<code>GOPATH</code> -- You can read more about them
<a href="https://www.jetbrains.com/help/go/configuring-goroot-and-gopath.html">here</a>.</p>
<p>The first <em>problem</em> I found using Go, was when I was figuring out how the module
resolution worked along with the <code>GOPATH</code>, it became quite frustrating to
set up a project structure with a functional local development environment.</p>
<p>In the end, I just used <code>GOPATH=$(pwd)</code> in my project's directory, the main perk
was to have a per-project dependency setup, like a <code>node_modules</code>. It worked
well.</p>
<blockquote>
<p>After finishing my project, I found out that
<a href="https://github.com/GetStream/vg">virtualgo</a> existed and would solve my problems
with <code>GOPATH</code>.</p>
</blockquote>
<p>Rust has an official project called <a href="https://rustup.rs/">rustup</a>, which manages
the Rust installation, also known as <em>toolchain</em>. It can be easily set up with a
one-liner. Also, there is a set of optional components using <code>rustup</code>,
such as the <a href="https://github.com/rust-lang/rls">rls</a> and
<a href="https://github.com/rust-lang/rustfmt">rustfmt</a>.
Many projects require a <em>nightly</em> version of the Rust toolchain, with <code>rustup</code>
there was no problem switching between the versions.</p>
<h3>Editor Support</h3>
<p>For both of the languages, editor tooling was flawless, as a VSCode user, I can
find extensions for both Go and Rust in the marketplace.</p>
<p>When debugging with Rust, I had to install the
<a href="https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb">CodeLLDB</a>
extension after following
<a href="https://www.forrestthewoods.com/blog/how-to-debug-rust-with-visual-studio-code/">this tutorial</a>.</p>
<h2>Package management</h2>
<p>Go doesn't have a package manager or even an official registry. Instead, its
module resolution works in a way you can import them from external URLs.</p>
<p>For dependency management, Rust uses the Cargo, which downloads and compiles
dependencies from <a href="https://crates.io/">crates.io</a>, which is the official
registry for Rust packages. Packages inside the Crates ecosystem can also have
their documentation available in <a href="https://docs.rs/">docs.rs</a></p>
<h2>Libraries</h2>
<p>My first objective was to see how easy could be to implement a simple GraphQL
query/mutation over HTTP.</p>
<p>For the Go language, I found some libraries, like
<a href="https://github.com/machinebox/graphql">machinebox/graphql</a> and
<a href="https://github.com/shurcooL/graphql">shurcooL/graphql</a>, the second one uses
structs for (un) marshaling the data, that is what made me stick to it.</p>
<blockquote>
<p>I used a fork of shurcooL/graphql, because I needed to set the
<code>Authorization</code> header in the client, the changes are in
<a href="https://github.com/shurcooL/graphql/pull/48">this pull request</a>.</p>
</blockquote>
<p>This is the Go example of an GraphQL mutation call:</p>
<pre><code><span>type</span> creationMutation <span>struct</span> {
    CreateSession <span>struct</span> {
        Token graphql.String
    } <span>`graphql:"createSession(email: $email, password: $password)"`</span>
}

<span>type</span> CreationPayload <span>struct</span> {
    Email    <span>string</span>
    Password <span>string</span>
}

<span><span>func</span> <span>Create</span><span>(client *graphql.Client, payload CreationPayload)</span> <span>(<span>string</span>, error)</span></span> {
    <span>var</span> mutation creationMutation
    variables := <span>map</span>[<span>string</span>]<span>interface</span>{}{
        <span>"email"</span>:    graphql.String(payload.Email),
        <span>"password"</span>: graphql.String(payload.Password),
    }
    err := client.Mutate(context.Background(), &amp;mutation, variables)

    <span>return</span> <span>string</span>(mutation.CreateSession.Token), err
}

</code></pre>
<p>In Rust, I had to use two libraries to make GraphQL calls. That is because
<code>graphql_client</code> is protocol-agnostic, it only focuses on code generation for
serializing and deserializing data. So I needed a second library (<code>reqwest</code>) to
take care of the HTTP requests.</p>
<pre><code><span>#[derive(GraphQLQuery)]</span>
<span>#[graphql(
    schema_path = <span>"graphql/schema.graphql"</span>,
    query_path = <span>"graphql/createSession.graphql"</span>
)]</span>
<span><span>struct</span> <span>CreateSession</span></span>;

<span>pub</span> <span><span>struct</span> <span>Session</span></span> {
    <span>pub</span> token: <span>String</span>,
}

<span>pub</span> <span><span>type</span> <span>Creation</span></span> = create_session::Variables;

<span>pub</span> <span>async</span> <span><span>fn</span> <span>create</span></span>(context: &amp;Context, creation: Creation) -&gt; <span>Result</span>&lt;Session, api::Error&gt; {
    <span>let</span> res = api::build_base_request(context)
        .json(&amp;CreateSession::build_query(creation))
        .send()
        .<span>await</span>?
        .json::&lt;Response&lt;create_session::ResponseData&gt;&gt;()
        .<span>await</span>?;
    <span>match</span> res.data {
        <span>Some</span>(data) =&gt; <span>Ok</span>(Session {
            token: data.create_session.token,
        }),
        _ =&gt; <span>Err</span>(api::Error(api::get_error_message(res).to_string())),
    }
}
</code></pre>
<p>Neither of the libraries for Go and Rust had any implementation for GraphQL via
WebSocket protocol.</p>
<p>In fact, <code>graphql_client</code> for Rust supports <em>Subscriptions</em>, but since it is
protocol-agnostic, I had to implement the whole GraphQL WebSocket communication
on my own,
<a href="https://github.com/cuchi/hashtrack/blob/b5a75f4368837cd51c621b6560a03e1835ec4e5b/cli-rust/src/tweet.rs#L90">check it out</a>.</p>
<p>To use WebSockets in the Go version, the library should be modified to support
the protocol. Since I was already using a fork of the library, I didn't feel
like doing it. Instead, I used a poor man's way of "watching" the new tweets,
which was to request the API every 5 seconds to retrieve them,
<a href="https://github.com/cuchi/hashtrack/blob/b5a75f4368837cd51c621b6560a03e1835ec4e5b/cli-go/src/hashtrack/tweets/tweets.go#L65">I'm not proud of it</a>.</p>
<p>Using Go, there is the <code>go</code> keyword to spawn a lightweight thread, also called
<em>goroutine</em>. In contrast, Rust uses operating system threads by calling a
<code>Thread::spawn</code>. Besides that, both implementations use channels to transfer
objects between their threads.</p>
<h2>Error handling</h2>
<p>In Go, errors are treated just like any other value. The common way to handle
errors in Go is to just check if they are present.</p>
<pre><code><span><span>func</span> <span>(config *Config)</span> <span>Save</span><span>()</span> <span>error</span></span> {
	contents, err := json.MarshalIndent(config, <span>""</span>, <span>"    "</span>)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}

	err = ioutil.WriteFile(config.path, contents, <span>0</span>o644)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}

	<span>return</span> <span>nil</span>
}
</code></pre>
<p>Rust has the <code>Result&lt;T, E&gt;</code> enum, which can encapsulate an <code>Ok(T)</code> for success,
or an <code>Err(E)</code> for errors. It also has the <code>Option&lt;T&gt;</code> enum, with <code>Some(T)</code> or
<code>None</code>. If you are familiar with Haskell, you may recognize
those as the <code>Either</code> and the <code>Maybe</code> monads.</p>
<p>There is also a syntactic sugar for error propagation (the <code>?</code> operator) that
resolves the value from the <code>Result</code> or <code>Option</code> structure, automatically
returning <code>Err(...)</code> or <code>None</code> when something goes bad.</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>save</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; io::<span>Result</span>&lt;()&gt; {
    <span>let</span> json = serde_json::to_string(&amp;<span>self</span>.contents)?;
    <span>let</span> <span>mut</span> file = File::create(&amp;<span>self</span>.path)?;
    file.write_all(json.as_bytes())
}
</code></pre>
<p>The code above is the equivalent of</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>save</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; io::<span>Result</span>&lt;()&gt; {
    <span>let</span> json = <span>match</span> serde_json::to_string(&amp;<span>self</span>.contents) {
        <span>Ok</span>(json) =&gt; json,
        <span>Err</span>(e) =&gt; <span>return</span> <span>Err</span>(e.into())
    };
    <span>let</span> <span>mut</span> file = <span>match</span> File::create(&amp;<span>self</span>.path) {
        <span>Ok</span>(file) =&gt; file,
        <span>Err</span>(e) =&gt; <span>return</span> <span>Err</span>(e.into())
    };
    file.write_all(json.as_bytes())
}
</code></pre>
<p>Rust has:</p>
<ul>
<li>monadic constructs (<code>Option</code> &amp; <code>Result</code>)</li>
<li>the error propagation operator</li>
<li>the <code>From</code> trait, to automatically convert errors on propagation</li>
</ul>
<p>The combination of the three features above makes up the best error handling
solution I saw in a language, being simple, sound, and maintainable at the same
time.</p>
<h2>Compilation time</h2>
<p>Go is built with fast compilation time as a critical requirement, let's see:</p>
<pre><code>&gt; time go get hashtrack 
go get hashtrack  1,39s user 0,41s system 43% cpu 4,122 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,80s user 0,12s system 152% cpu 0,603 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,19s user 0,07s system 400% cpu 0,065 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,94s user 0,13s …</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cuchi.me/posts/go-vs-rust">https://cuchi.me/posts/go-vs-rust</a></em></p>]]>
            </description>
            <link>https://cuchi.me/posts/go-vs-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044043</guid>
            <pubDate>Mon, 03 Aug 2020 22:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One year of automatic DB migrations from Git]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24043987">thread link</a>) | @awinter-py
<br/>
August 3, 2020 | https://abe-winter.github.io/2020/08/03/yr-of-git.html | <a href="https://web.archive.org/web/*/https://abe-winter.github.io/2020/08/03/yr-of-git.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For the last year-plus, for most of my solo work, I’ve used a tool called <a href="https://github.com/abe-winter/automigrate">automig</a> to automatically turn my SQL schema changes into deltas that can be applied to a DB
(plug – I wrote it).</p>

<p>I hate writing migrations because it feels like work a computer should know how to do,
and because in general there’s no guarantee that the migrations produce something equivalent to your ‘schema.sql’ or ORM definition.</p>

<p>(SQLAlchemy’s alembic has an <a href="https://alembic.sqlalchemy.org/en/latest/autogenerate.html">autogenerate feature</a> which compares a running DB to your ORM spec;
having a running DB in the loop for migration generation creates a different set of tradeoffs than automig, which analyzes the sql files directly).</p>

<p>This article is a pros and cons retrospective on that year.</p>

<ul id="markdown-toc">
  <li><a href="#pros" id="markdown-toc-pros">Pros</a></li>
  <li><a href="#cons" id="markdown-toc-cons">Cons</a></li>
</ul>

<h2 id="pros">Pros</h2>

<p><strong>I haven’t written a migration in 1+ years</strong>.
And I don’t love writing migrations.
My process to add a column has fewer steps.
This is a win.</p>

<p><strong>Simple and readable source of truth</strong>.
As long as you trust that the tool knows what it’s doing,
you can open up the <code>schema.sql</code> file (or whatever you choose to name yours) and get a schema that is <em>both</em>
a readable doc of what the database should have
and a reliable indicator of what the database actually has.</p>

<p><strong>Standard tool across different languages</strong>.
I’ve used automig on different python and golang projects and it doesn’t care.
It’s not linked to any design or tool decision inside the codebase.
Automig isn’t a standard tool, but if it were, it would be a portable skillset.</p>

<p><strong>No cluttered migrations dir</strong>.
More of a personal hygiene decision than a legit gripe, but migration directories aren’t my favorite; hundreds of files that do very little good.
Automig is also faster at reinitialization because you can start from git HEAD rather than applying hundreds of changes from the last 36 months.</p>

<p><strong>Turns something complicated into something simple and almost as good</strong>.
There are cons (see below) but there’s a bunch of migration-related work that I no longer think about.
I no longer dread adding a DB column or an index.
If my capabilities are less because the tool is simpler and declarative, that’s a tradeoff, but it’s one that I’ve lived with happily.</p>

<h2 id="cons">Cons</h2>

<p><strong>Data migrations not supported</strong>.
Automig is good at schema migrations but doesn’t have an easy way to transform columns or run code on your DB.
The tool has an answer to this in the roadmap.
For my own needs I’ve been able to work around this by doing two-step migrations with default values.</p>

<p>For larger users, data migrations involve lots of design (see for example github’s GH-OST tool).
In the future I think migrations should be a native feature in the DB –
you should upload a schema and specify whether migrations run up-front or on read.
And we shouldn’t tie type to storage locality.</p>

<p><strong>When something goes wrong, I have to fix it</strong>.
This is 50% a gripe about using a tool that I maintain and am the only user of.
But 50% a legit point that a ‘declarative diffing’ tool has more logic in it than migrations that you write yourself in SQL.
Running arbitrary SQL gives you a lot of flexibility and gives you infinite freedom to choose incompatible dialects.</p>

<p><strong>Extra lifting to integrate with ORMs</strong>.
Automig can generate SQLAlchemy definitions from your schema.sql, but that’s it.
If you use a single language / framework, defining your DB in an ORM is probably more useful than having it specified using SQL.</p>

<p><strong>Dialect support is no picnic</strong>.
When I switched from postgres to sqlite for some projects, it was a pain to support the different dialects.
I ran into things like different support for transactional DDL.</p>

<p>(Since I first wrote this I’ve seen comments from the skeema and migra committers.
Both of these tools support <em>only one</em> DB: mysql and postgres respectively, and rely on the DB to do the heavy lifting.
There are a lot of positives to this approach).</p>

<p><strong>Branch conflict issues + rebasing</strong>.
Any nonlinear git history can be a source of errors.
Automig has an <code>--opaque</code> switch to work around these, but manually-specified migrations are likely better at branches, especially if you need to support out-of-order changes.
I haven’t encountered these problems because I’m in solo codebases, but I can see there being issues in big teams who sometimes deploy from non-main branches.</p>

<p><strong>Migrating production involves up-front work</strong>.
If you use your main backend language / framework to run migrations, life is easy.
Automig has extra requirements: it needs to bundle the <code>.git</code> folder (i.e. whole history).
When I ran this on lambda, I had to also bundle a git binary, and my ubuntu binary <em>didn’t work</em>.
I spent a whole day learning how to build git statically before I realized I could just grab the centos one.
The good news is that this work only has to be done once per platform.</p>

<p><strong>Testing is annoying</strong>.
Because automig only works on committed changes, I sometimes have to do a few rounds of <code>git commit --amend</code> before things work.</p>

<p><strong>Column order</strong>.
Automig doesn’t guarantee column order (it does <code>add column</code> but not <code>add column b after a</code>).
This has caused issues with backup / restore.
It’s a problem with the tool but not necessarily with the approach of using git + sql as the source of truth.</p>

<p><strong>Weird parser</strong>.
My parser library is easily confused, especially by uppercase / lowercase and names that look like keywords.
And it’s multi-layer (I use python sqlparse and then wrap it), i.e. janky.
This isn’t an issue with the approach so much as the specific tools I use, but it causes problems.</p>






  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://abe-winter.github.io/2020/08/03/yr-of-git.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043987</guid>
            <pubDate>Mon, 03 Aug 2020 22:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PP-YOLO Surpasses YOLOv4 – State-of-the-art object detection techniques]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24043812">thread link</a>) | @rocauc
<br/>
August 3, 2020 | https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/ | <a href="https://web.archive.org/web/*/https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <div><p>Baidu publishes PP-YOLO and pushes the state of the art in object detection research by building on top of YOLOv3, the PaddlePaddle deep learning framework, and cutting edge computer vision research.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-1.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-1.png 600w, https://blog.roboflow.ai/content/images/2020/08/image-1.png 692w"><figcaption><a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO</a> evaluation shows faster inference (x-axis) with better accuracy (y-axis)</figcaption></figure><p>PP-YOLO evaluation metrics show improved performance over <a href="https://blog.roboflow.ai/a-thorough-breakdown-of-yolov4/">YOLOv4</a>, the incumbent state of the art object detection model. Yet, the Baidu authors write:</p><figure><pre><code>This paper is not intended to introduce a novel object detecotor. 
It is more like a recipe, which tell you how to build a better detector step by step.</code></pre><figcaption>Mysterious introduction in the <a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO paper</a></figcaption></figure><p>Let's unpack that.</p><h2 id="yolo-development-history">YOLO Development History</h2><p>YOLO was originally authored by Joseph Redmon to detect objects. Object detection is a computer vision technique that localizes and tags objects by drawing a bounding box around them and identifying the class label that a given box belongs too. Unlike massive NLP transformers, YOLO is designed to be tiny, enabling realtime inference speeds for deployment on device. &nbsp;</p><p>YOLO-9000 was the second "YOLOv2" object detector published by Joseph Redmon, improving the detector and emphasizing the detectors ability to generalize to any object in the world.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-2.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-2.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-2.png 1000w, https://blog.roboflow.ai/content/images/size/w1600/2020/08/image-2.png 1600w, https://blog.roboflow.ai/content/images/2020/08/image-2.png 1810w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://github.com/PaddlePaddle/PaddleDetection/blob/release/0.4/docs/tutorials/Custom_DataSet.md">PP-YOLO</a> is being trained to identify different fruit flies in this photo.</figcaption></figure><p>YOLOv3 made further improvements to the detection network and began to mainstream the object detection process. We began to publish tutorials on <a href="https://blog.roboflow.ai/releasing-a-new-yolov3-implementation/">how to train YOLOv3 in PyTorch</a>, <a href="https://blog.roboflow.ai/training-a-yolov3-object-detection-model-with-a-custom-dataset/">how to train YOLOv3 in Keras</a>, and <a href="https://blog.roboflow.ai/yolov3-versus-efficientdet-for-state-of-the-art-object-detection/">compared YOLOv3 performance to EfficientDet </a>(another state of the art detector).</p><p>Then Joseph Redmon stepped out of the object detection game due to ethical concerns. </p><p>Naturally, the open source community picked up the baton and continues to move YOLO technology forward. </p><p>YOLOv4 was published recently this spring by Alexey AB in his for of the YOLO Darknet repository. YOLOv4 was primarily an ensemble of other known computer vision technologies, combined and validated through the research process. See here for a <a href="https://blog.roboflow.ai/a-thorough-breakdown-of-yolov4/">deep dive on YOLOv4</a>. The YOLOv4 paper reads similarly to the PP-YOLO paper, as we will see below. We put together some great training tutorials on <a href="https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/">how to train YOLOv4 in Darknet</a>.</p><p>Then, just a few months ago <a href="https://blog.roboflow.ai/yolov5-is-here/">YOLOv5 was released</a>. YOLOv5 took the Darknet (C based) training environment and converted the network to PyTorch. Improved training techniques pushed performance of the model even further and created a great, easy to use, out of the box object detection model. Ever since, we have been encouraging developers using Roboflow to direct their attention to YOLOv5 for the formation of their custom object detectors via this <a href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/">YOLOv5 training tutorial</a>.</p><p>Enter PP-YOLO.</p><h2 id="what-does-pp-stand-for">What Does PP Stand For?</h2><p>PP is short for PaddlePaddle, a deep learning framework written by Baidu. </p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-9.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-9.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-9.png 1000w, https://blog.roboflow.ai/content/images/size/w1600/2020/08/image-9.png 1600w, https://blog.roboflow.ai/content/images/2020/08/image-9.png 1634w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.paddlepaddle.org.cn/">PaddlePaddle</a> distributions provided on their website.</figcaption></figure><p>If PaddlePaddle is new to you, then we are in the same boat. Primarily written in Python, PaddlePaddle seems akin to PyTorch and TensorFlow. A deep dive into the PaddlePaddle framework is intriguing, but beyond the scope of this article. </p><h2 id="pp-yolo-contributions">PP-YOLO Contributions</h2><p>The PP-YOLO paper reads much like the YOLOv4 paper in that it is a compilation of techniques that are known to work in computer vision. The novel contribution is to prove that the ensemble of these technologies improves performance, and to provide an ablation study of how much each step helps the model along the way.</p><p>Before we dive into the contributions of PP-YOLO, it will be useful to review the YOLO detector architecture.</p><h3 id="anatomy-of-the-yolo-detector">Anatomy of the YOLO Detector</h3><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image.png 1376w" sizes="(min-width: 720px) 720px"><figcaption>A graphical depiction of the <a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO</a> object detection network</figcaption></figure><p>The YOLO detector is broken into three main pieces.</p><p><strong>YOLO Backbone</strong> - The YOLO backbone is a convolutional neural network that pools image pixels to form features at different granularities. The Backbone is typically pretrained on a classification dataset, typically ImageNet.</p><p><strong>YOLO Neck - </strong>The YOLO neck (FPN is chosen above) combines and mixes the ConvNet layer representations before passing on to the prediction head.</p><p><strong>YOLO Head</strong> - This is the part of the network that makes the bounding box and class prediction. It is guided by the three YOLO loss functions for class, box, and objectness. </p><h2 id="now-let-s-dive-into-the-pp-yolo-contributions-">Now let's dive into the PP YOLO Contributions.</h2><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-10.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-10.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-10.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-10.png 1136w" sizes="(min-width: 720px) 720px"><figcaption>Marginal mAP accuracy performance increase from each technique in PP-YOLO</figcaption></figure><h3 id="replace-backbone">Replace Backbone</h3><p>The first PP YOLO technique is to replace the YOLOv3 Darknet53 backbone with the Resnet50-vd-dcn ConvNet backbone. Resnet is a more popular backbone, more frameworks are optimized for its execution, and it has fewer parameters than Darknet53. Seeing a mAP improvement by swapping this backbone is a huge win for PP YOLO. </p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-12.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-12.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-12.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-12.png 1422w" sizes="(min-width: 720px) 720px"><figcaption>Graphical depiction in <a href="https://arxiv.org/pdf/1603.05027.pdf">ResNet</a></figcaption></figure><h3 id="ema-of-model-parameters">EMA of Model Parameters</h3><p>PP YOLO tracks the Exponential Moving Average of network parameters to maintain a shadow of the models weights for prediction time. This has been shown to improve inference accuracy.</p><h3 id="larger-batch-size">Larger Batch Size</h3><p>PP-YOLO bumps the batch size up from 64 to 192. Of course, this is hard to implement if you have GPU memory constraints.</p><h3 id="dropblock-regularization">DropBlock Regularization</h3><p>PP YOLO implements DropBlock regularization in the FPN neck (in the past, this has usually occurred in the backbone). DropBlock randomly removes a block of the training features at a given step in the network to teach the model to not rely on key features for detection.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-16.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-16.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-16.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-16.png 1050w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://arxiv.org/pdf/1810.12890.pdf">Drop Block</a> regularization technique - features are hidden in blocks (c) not randomly (b)</figcaption></figure><h3 id="iou-loss">IoU Loss</h3><p>The YOLO loss function does not translate well to the <a href="https://blog.roboflow.ai/what-is-mean-average-precision-object-detection/">mAP metric</a>, which uses the Intersection over Union heavily in its calculation. Therefore, it is useful to edit the training loss function with this end prediction in mind. This edit was also present in YOLOv4.</p><h3 id="iou-aware">IoU Aware</h3><p>The PP-YOLO network adds a prediction branch to predict the model's estimated IOU with a given object. Including this IoU awareness when making the decision to predict an object or not improves performance.</p><h3 id="grid-sensitivity">Grid Sensitivity</h3><p>The old YOLO models do not do a good job of making predictions right around the boundaries of anchor box regions. It is useful to define box coordinates slightly differently to avoid this problem. This technique is also present in YOLOv4.</p><h3 id="matrix-nms">Matrix NMS </h3><p>Non-Maximum Suppression is a technique to remove over proposals of candidate objects for classification. Matrix NMS is a technique to sort through these candidate predictions in parallel, speeding up the calculation. </p><h3 id="coordconv">CoordConv</h3><p>CoordConv was motivated by the problems ConvNets were having with simply mapping (x,y) coordinates to a one-hot pixel space. The CoordConv solution gives the convolution network access to its own input coordinates. CoordConv interventions are marked with yellow diamonds above. More details are available in <a href="https://arxiv.org/pdf/1807.03247.pdf">the CordConv paper</a>.</p><h3 id="spp">SPP</h3><p>Spatial Pyramid Pooling is an extra block after the backbone layer to mix and pool spatial features. Also implemented in YOLOv4 and YOLOv5.</p><h3 id="better-pretrained-backbone">Better Pretrained Backbone</h3><p>The PP YOLO authors distilled down a larger ResNet model to serve as the backbone. A better pretrained model shows to improve downstream transfer learning as well. </p><h2 id="is-pp-yolo-state-of-the-art"><br>Is PP-YOLO State of the Art?</h2><p>PP-YOLO outperforms the results <a href="https://arxiv.org/pdf/2004.10934.pdf">YOLOv4 published</a> on April 23, 2020.</p><p>In fairness, the authors note this may be the wrong question to be asking. The authors' intent appears to not simply "introduce a new novel detector," rather to show the process of carefully tuning an object detector to maximize performance. Quoting the paper's introduction here:</p><blockquote>The focus of this paper is how to stack some effective tricks that hardly affect efficiency to get better performance... This paper is not intended to introduce a novel object detector. It is more like a recipe, which tell you how to build a better detector step by step. We have found some tricks that are effective for the YOLOv3 detector, which can save developers’ time of trial and error. <strong>The final PP-YOLO model improves the mAP on COCO from 43.5% to 45.2% at a speed faster than YOLOv4</strong></blockquote><p><em>(emphasis ours)</em></p><p>The PP-YOLO contributions reference above took the YOLOv3 model from 38.9 to 44.6 mAP on the COCO object detection task and increased inference FPS from 58 to 73. These metrics are shown in the paper to beat the currently published results for YOLOv4 and EfficientDet. </p><p>In benchmarking PP-YOLO against <a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5</a>, it appears <a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5</a> still has the fastest inference time-to-accuracy performance (AP vs FPS) tradeoff on a V100. However, a YOLOv5 paper still remains to be released. Furthermore, it has been shown that training the YOLOv4 architecture on the YOLOv5 Ultralytics repository outperforms YOLOv5 and, transitively, YOLOv4 trained using YOLOv5 contributions would outperform the PP-YOLO results posted here. These results are still to be formally published but can be traced to <a href="https://github.com/ultralytics/yolov5/issues/6">this GitHub discussion</a>.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-14.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-14.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-14.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-14.png 1354w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO evaluation</a> on COCO dataset on V100 GPU (note AP_50 column)</figcaption></figure><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-15.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-15.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-15.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-15.png 1304w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5 evaluation</a> on COCO dataset on V100 GPU (note AP_50 column)</figcaption></figure><p>It is worth noting that many of the techniques (such as architecture search and data augmentation) that were used in YOLOv4 were not used in PP YOLO. This means that there is still room for the state of the art in object detection to grow as more of these techniques are combined and integrated together. </p><p>Needless to say, is an exciting time to be implementing computer vision technologies.</p><h2 id="should-i-switch-from-yolov4-or-yolov5-to-pp-yolo">Should I Switch from YOLOv4 or YOLOv5 to PP-YOLO?</h2><p>The PP-YOLO model shows the promise of state of the art object detection, but the improvements are incremental over other object detectors and it is written in a new framework. At this stage, the best thing to do is to develop your own empirical result by training PP-YOLO on your own dataset. (To be notified when you can easily use PP-YOLO on your dataset, <a href="https://roboflow.us5.list-manage.com/subscribe?u=26126ade12b1dd890dbd7b07e&amp;id=3e926cf19a">subscribe to our newsletter</a>.)</p><p>In the meantime, I recommend checking out the following YOLO tutorials to get your object detector off the ground:</p><ul><li><a href="https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/">How to Train YOLOv4 in Darknet</a></li><li><a href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/">How to Train YOLOv5 in PyTorch</a></li></ul><p>As always - happy training! </p></div>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043812</guid>
            <pubDate>Mon, 03 Aug 2020 21:43:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your calendar should be a whitelist, not a blacklist]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24043175">thread link</a>) | @mcrittenden
<br/>
August 3, 2020 | https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-549">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Does your company have a culture of letting everyone see each other’s calendars? Do people often schedule meetings whenever there are openings, without asking?</p>



<p>If so, your calendar is a blocklist. The only time that isn’t available for someone to steal is time that’s already spoken for. This is a problem. A time slot that isn’t currently booked shouldn’t be free real estate. That’s my TIME! You can’t just take it without asking.</p>



<p>Instead, your calendars should be an allowlist. You should say “if you want to talk to me, this is when you can” instead of “this is when you CAN’T.” You shouldn’t have to defend our time like it’s gold and your coworkers are pirates. You should just assume that it’s yours to spend how you see fit.</p>



<p>Some people block time off to try to protect their calendars. They create big “GTD” blocks on their calendar and hope that nobody books meetings on top of them. I’ve even heard of people creating fake or vague meeting titles in hopes that others will assume there’s a real meeting at that time. This is a crappy workaround, and it isn’t enough. </p>



<p>The solution should be office hours. You should be able to say say “I’m free for meetings from 2-5pm on Tuesdays and Thursdays, and if you want to talk to me then that’s when you can.” In most companies, doing that would make you an annoyance. Those companies don’t respect Deep Work. </p>



<p>Scheduling meetings should be a little bit painful. You should have to really want it. You should be forced to question yourself. <em>Is this actually worth me going to the trouble of figuring out how to schedule this meeting? Or could it instead be an asynchronous discussion? </em>Office hours and calendars-as-allowlists have this added benefit.</p>



<p>Is your calendar an allowlist or a blocklist?</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043175</guid>
            <pubDate>Mon, 03 Aug 2020 20:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Tencent PCG Uses Apache Kafka to Handle 10T+ Messages per Day]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24042525">thread link</a>) | @rmoff
<br/>
August 3, 2020 | https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As one of the world’s biggest internet-based platform companies, Tencent uses technology to enrich the lives of users and assist the digital upgrade of enterprises. An example product is the popular WeChat application, which has over one billion active users worldwide. The Platform and Content Group (PCG) is responsible for integrating Tencent’s internet, social, and content platforms. PCG promotes the cross-platform and multi-modal development of IP, with the overall goal of creating more diversified premium digital content experiences. Since its inception, many major products—from the well-known QQ, QZone, video, App Store, news, and browser, to relatively new members of the ecosystem such as live broadcast, anime, and movies—have been evolving on top of consolidated infrastructure and a set of foundational technology components.</p>
<h2><a id="kafka-at-tencent-png"></a>Apache Kafka<sup>®</sup> at Tencent PCG</h2>
<p>At our center stands the real-time messaging system that connects data and computing. We have proudly built many essential data pipelines and messaging queues around Apache Kafka. Our application of Kafka is similar to other organizations: We build pipelines for cross-region log ingestion, machine learning platforms, and asynchronous communication among microservices. The unique challenges come from stretching our architecture along multiple dimensions, namely scalability, customization, and SLA. Here are some of the notable requirements:</p>
<ul>
<li><strong>Workload.</strong> It takes close and continuous observation to fully grasp the dynamics of data in complex apps. In a highly seasonal and eventful environment of consumer internet with over a billion monthly active users, product promotion and large-scale experimentations often cause volume to burst up 20x from one day to another. At the peak, our pipeline needs to transfer 4 million messages per second (or 64 gigabytes/second) for a single product. Our ops team, therefore, is challenged with managing and optimizing clusters with more than a thousand physical nodes in total.</li>
<li><strong>Low latency and high SLA.</strong> As the organization moves quickly toward leveraging real-time analytics for driving business decisions, the requirements of data accuracy and timeliness become more rigid than before. Imagine when a video-consuming event is fed to the recommendation algorithm or when discovering hot trends that guide the incentivisation of content supply—it is desirable that the data can be used within a few seconds since its emission and with an end-to-end loss rate as low as 0.01%.</li>
<li><strong>Flexibility.</strong> Nowadays real-time data processing architectures are componentized and configurable. Consequently, the messaging system needs to handle frequent changes in the number of consumers, access pattern, and topic distribution without impacting performance. We cannot simply optimize the system for a static topology as a traditional ingestion pipeline.</li>
</ul>
<p>Ideally, we need a multi-tenant, gigantic pub/sub system to satisfy all these requirements. At peak time, it should reliably support data transfer at hundreds of gigabits per second. It should be provisioned almost instantly without disrupting existing workload; it also needs to tolerate single-node and cluster failure. Considering interface concerns, we want it to be compatible with the Kafka SDK as much as possible. After exploring the limitations of a single Kafka cluster, we’ve moved forward with a series of developments.</p>
<h2 id="federated-kafka-design"><a id="federated-kafka-design"></a>Federated Kafka design</h2>
<p>We chose to develop in the Kafka ecosystem for its maturity, rich set of clients and connectors, as well as superb performance among alternatives. On the other hand, there are a few gaps in using Apache Kafka to meet the requirements above. For instance, more than expected, we found during heavy usage that multiple disk failures caused insufficient replica or even cluster-level reliability problems. Moreover, expanding the capacity of a cluster (i.e., adding brokers) requires significant data rebalancing, often imposing hours of operational latency. Without fully automated capacity management, this greatly limits how we can support a large business.</p>
<p>Given that we decided to focus our initial enhancement on scalability and failure tolerance, we started off building a proxy layer that federates multiple Kafka clusters and provides compatible interfaces to both providers and consumers. The proxy layer presents logical topics to Kafka clients and internally maps them to distinct physical topics in each Kafka cluster. In the figure below, a logical topic with eight partitions (<code>P0–P7</code>) is distributed to two physical clusters each with four partitions (<code>P0–P3</code>).</p>
<p><img src="https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic.png" alt="P0-P7 | P0-P3" width="1999" height="522" srcset="https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic.png 1999w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-300x78.png 300w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-1024x267.png 1024w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-768x201.png 768w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-1536x401.png 1536w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-350x91.png 350w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-600x157.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"></p>
<p>The extra layer of abstraction of logical topics allows us to achieve the following, desirable behavior. First, we can expand the capacity of the data pipeline with little (re)synchronization overhead. In case two clusters at their maximum size cannot handle the predicted peak volume, we can easily deploy two additional clusters without shuffling any existing data. Second, fault tolerance is easier to manage with smaller clusters, as we can provision extra capacity at fine granularity and redirect traffic at a low cost. Lastly, in the (not-so-rare) event of physical cluster migration, the transparent proxy eliminates the need for any code and configuration change on the application side. We would only need to set the old clusters in read-only mode before it is completely drained, while associating the proxy with the new clusters. Such maintenance is not visible from the perspective of logic topics.</p>
<h2 id="key-components-and-workflows"><a id="key-components-and-workflows"></a>Key components and workflows</h2>
<p>In this section, we get into more details of the new components we built and how they interact in essential scenarios, as shown in the figure below. Two proxy services, one for the producer (<code>pproxy</code>) and another for the consumer (<code>cproxy</code>), implement the core protocols of the Kafka broker. They are also responsible for mapping logical topics to their physical incarnation. The application uses the same Kafka SDK to connect directly to the proxy, which acts as a broker.</p>
<p>In order to address the set of proxy brokers, we built a lightweight name service that maintains this relationship between client ID and the collection of proxy servers. The SDK will request the list of proxy brokers using client ID once at the beginning of the communication. Internally, the most complicated and bulky part of our implementation involves managing the metadata of the federated cluster, including both the state of the topics as well as the lifecycle of the proxy nodes. We extract the logic of the Kafka controller node (such as topic metadata) into a separate service, which is also called “the controller,” but it is different from Kafka’s own controller functionality. This service is responsible for collecting the metadata of physical clusters, composing the partition information logical topics, and then publishing it to the proxy brokers.</p>
<p><img src="https://cdn.confluent.io/wp-content/uploads/kafka-name-service.png" alt="Name service" width="1999" height="639" srcset="https://cdn.confluent.io/wp-content/uploads/kafka-name-service.png 1999w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-300x96.png 300w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-1024x327.png 1024w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-768x245.png 768w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-1536x491.png 1536w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-350x112.png 350w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-600x192.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"></p>
<p>We see some examples of interactions among these components and the Kafka clusters underneath during the most common operations:</p>
<ul>
<li><strong>Logical topic metadata retrieval</strong><br>
<img src="https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval.png" alt="Logical topic metadata retrieval" width="1999" height="635" srcset="https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval.png 1999w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-300x95.png 300w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-1024x325.png 1024w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-768x244.png 768w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-1536x488.png 1536w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-350x111.png 350w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-600x191.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"><br>
1. Controller reads the mapping between logical topic and physical topic from the config database.<br>
2. Controller scans metadata of all physical topics from each Kafka cluster.<br>
3. Controller finds the list of available <code>pproxy</code> from heartbeat message.<br>
4. Controller composes the metadata for the logical topics.<br>
5. Controller pushes both the topic mapping and topic metadata to proxy brokers.<br>
6. The metadata is sent to the Kafka SDK.</li>
</ul>

<h2 id="federated-kafka-in-practice"><a id="federated-kafka-in-practice"></a>Federated Kafka in practice</h2>
<p>Over the past year, we have gradually onboard many products in Tencent PCG to use the federated Kafka solution. Alongside the cluster, we have also been developing better monitoring and automated management tools. Our design principles have been quickly validated by many critical business use cases such as real-time analytics, feature engineering, and more. Up to now, we have deployed a few hundreds of clusters of various sizes, which collectively handle more than 10 trillion messages every day. The following table summarizes our typical setup and operational benchmarks.</p>
<table>
<tbody>
<tr>
<td>Average time to initialize a federated cluster</td>
<td>10 minutes</td>
</tr>
<tr>
<td>Average time to scaling up a federated cluster<br>
(add one physical cluster)</td>
<td>2 minutes</td>
</tr>
<tr>
<td>Metadata refresh latency</td>
<td>~1 second</td>
</tr>
<tr>
<td>Maximum physical clusters per logical cluster</td>
<td>60</td>
</tr>
<tr>
<td>Brokers per physical cluster</td>
<td>10</td>
</tr>
<tr>
<td>Total number of brokers provisioned</td>
<td>~500</td>
</tr>
<tr>
<td>Max cluster bandwidth (CPU ~40%)</td>
<td>240 Gb/s</td>
</tr>
<tr>
<td>Proxy overhead</td>
<td>Same as Kafka broker</td>
</tr>
</tbody>
</table>
<p>There are two notable limitations of the first design composed of cluster federation with a proxy layer. First, the distribution of logical partitions is not transparent to clients who use a hash key to specify the partition when producing a message. Consequently, when we add a new cluster, messages with identical keys might be delivered to different partitions and hence get out of order. This did not turn out to be a blocker for our current use cases for two reasons. First, we surveyed the product teams and found that they only use keyed messages occasionally. Furthermore, when they face the trade-off between application-level fault tolerance and scalability, they typically prefer the latter and sometimes settle with a mechanism to briefly halt production when cluster membership is updated.</p>
<p>A more fundamental limitation is that we have to frequently evolve the interface of the proxy broker as more functionalities need to be exposed and as native Kafka evolves. This leads to unnecessary code duplication and makes the whole system harder to manage. In the future, we will explore implementing similar semantics inside Kafka, as described in the next section.</p>
<h2 id="next-steps"><a id="next-steps"></a>Next steps</h2>
<p>As we explained above, Tencent is one of the largest Kafka users in the world, processing trillions of messages every day. This also means that to power our many use cases, we have successfully pushed some of Kafka’s boundaries. We are aware of the ongoing development and proposals within the Kafka community, and we further find that some of our ideas, such as abstracting out the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/">https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24042525</guid>
            <pubDate>Mon, 03 Aug 2020 19:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V OS using Rust: Graphics]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24041869">thread link</a>) | @azhenley
<br/>
August 3, 2020 | https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041869</guid>
            <pubDate>Mon, 03 Aug 2020 18:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A gentle intro to assembly with Rust]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24041675">thread link</a>) | @lfn3
<br/>
August 3, 2020 | https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/ | <a href="https://web.archive.org/web/*/https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div>
  
  <p><span>Aug 3 2020</span></p><p>One of the things I’ve wanted to do for a while is really dig into
assembly and get into the weeds of how programs actually run.
A rework of the <code>asm</code> macro has <a href="https://blog.rust-lang.org/inside-rust/2020/06/08/new-inline-asm.html">recently landed</a> in nightly rust
so it seemed like a good time.</p>

<p>And compared to some other ways I’ve tried to approach this there’s a lot less
setup we need to do if we just use the <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018">rust playground</a> to
do all the heavy lifting.</p>

<p>My process for figuring things out has been pretty simple.
I write a tiny bit of rust code, look at the assembly output
and try to figure out what’s going on (with lots of googling).
I’m going to walk you through what I did, and what I figured
out.</p>

<p>Let’s start with the simplest possible thing I can think of:</p>

<pre><code>fn main() {
    1 + 2;
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=9500bb2bc3f638a4dd89e81fecafac0e">playground link</a></p>

<p>You can get the assembly output for this by clicking the three dots next to
<code>run</code> and selecting <code>asm</code> from the dropdown. You will probably also want
to change the flavour (often referred to as syntax elsewhere) of assembly to intel (rather than at&amp;t) <sup id="fnref:1"><a href="#fn:1">1</a></sup>
if it isn’t already, by clicking the toggle under the <code>config</code> menu.</p>

<p>The assembly output from this in debug mode is far more massive than you’d expect -
I get 157 lines. And most of it isn’t our program. The code we’ve written should
be fairly easy to find though, as the compiler helpfully labels all of the functions
with their crate and function names. In this case since we’re in the playground,
the create is implicitly <code>playground</code>, so we can find our code by searching with
<code>ctrl-f</code> for <code>playground::main</code>. Doing this gets me to:</p>

<pre><code>playground::main: # @playground::main
# %bb.0:
    ret
                                        # -- End function
</code></pre>

<p>So even though this is a debug build, evidently there’s still some optimization going on,
since there’s no numbers or anything that looks like it’s adding them together.
All that’s happening here is we’re returning (<code>ret</code>) back to the function that called <code>playground::main</code>.
Everything prefixed with <code>#</code> is a comment, and therefore ignored when we run this code.</p>

<p>The only other point of interest is the label <code>playground::main:</code> - anything suffixed with <code>:</code>
is a label we can jump to with various commands, and indeed if we continue searching for <code>playground::main</code>
we can find a rather indirected call to it in <code>main</code>. Hopefully by the end of this we’ll be understand that!</p>

<h3 id="avoiding-optimizations">Avoiding optimizations</h3>

<p>For now, let’s try and evade whatever’s doing the optimization:</p>

<pre><code>fn add() -&gt; usize {
    1 + 2
}

fn main() {
    add();
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=e06e9c1a6771d850be5e06abc6f70243">playground link</a></p>

<p>Again, searching for <code>playground::main</code> get us to:</p>

<pre><code>playground::add: # @playground::add
# %bb.0:
    mov eax, 3
    ret
                                        # -- End function

playground::main: # @playground::main
# %bb.0:
    push    rax
    call    playground::add
# %bb.1:
    pop rax
    ret
                                        # -- End function
</code></pre>

<p>So we’ve got a bit more progress here. Still some optimization going on, since we don’t see 1 or 2 in the code,
just 3. We can see that being moved (<code>mov</code>) into the <code>eax</code> register in <code>playground::add</code>.
This must be how we’re returning the value back up to <code>main</code>.</p>

<p>And indeed, inside <code>main</code> we can see <code>push rax</code> - saving the value in the register <code>rax</code> to the stack, then a
call to our <code>add</code> function, then we <code>pop rax</code> off the stack. The <code>push call pop</code> sequence is to preserve
whatever values are in the registers used in <code>add</code>. It also just throws away the value we saved in <code>eax</code> in <code>add</code>,
because <code>eax</code> and <code>rax</code> are the same register. The table <a href="https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture#General-Purpose_Registers_(GPR)_-_16-bit_naming_conventions">here</a>
shows how ‘skinnier’ registers overlap with their ‘wider’ counterparts.</p>

<h3 id="avoiding-optimizations-take-2">Avoiding optimizations, take 2</h3>

<p>So how can we make this actually do some math? Let’s try again:</p>

<pre><code>fn add(i: usize) -&gt; usize {
    1 + i
}

fn main() {
    add(2);
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=0d821a33f2375ecaf3671c825a415c83">playground link</a></p>

<p>So we’ve got a lot more going on this time:</p>

<pre><code>playground::add: # @playground::add
# %bb.0:
    sub rsp, 24
    mov qword ptr [rsp + 16], rdi
    add rdi, 1
    setb al
    test al, 1
    mov qword ptr [rsp + 8], rdi # 8-byte Spill
    jne .LBB8_2
# %bb.1:
    mov rax, qword ptr [rsp + 8] # 8-byte Reload
    add rsp, 24
    ret

.LBB8_2:
    lea rdi, [rip + str.0]
    lea rdx, [rip + .L__unnamed_2]
    mov rax, qword ptr [rip + core::panicking::panic@GOTPCREL]
    mov esi, 28
    call rax
    ud2
                                        # -- End function

playground::main: # @playground::main
# %bb.0:
    push rax
    mov edi, 2
    call playground::add
# %bb.1:
    pop rax
    ret
                                        # -- End function
</code></pre>

<p>The thing we were actually trying to produce is finally in there!
We can see <code>add rdi, 1</code> in the output, surrounded by a pile of other
stuff. So what is all this other code?</p>

<p>Let’s start from the top of the call stack in <code>main</code>.
First we can see <code>2</code> is stored in the <code>edi</code> register
before we call <code>playground::add</code>, so we know our argument must be in
the <code>edi</code> register. Again, we can see the <code>push</code>, <code>pop</code> on <code>rax</code>, so that
must be the return value.</p>

<h3 id="looking-inside-the-function">Looking inside the function</h3>

<p>Now, looking into <code>playground::add</code> we first see <code>sub rsp, 24</code>. <code>rsp</code> is
the register that holds the stack pointer, so this is growing the stack
(since the stack grows downwards in x86<sup id="fnref:2"><a href="#fn:2">2</a></sup>). Further down we can see
we shrink the stack by the corresponding amount with <code>add rsp, 24</code>.</p>

<p>Then we have <code>mov qword ptr [rsp + 16], rdi</code>. This is copying the
value from <code>rdi</code> onto the stack at <code>rsp + 16</code> - the top of the region we just grew the stack by.
The <code>qword ptr</code> (quadword (i.e. 64bit) pointer) bit is a hint to disambiguate the argument.
Why is that pushed that onto the stack? I <em>think</em> this is just to make it easier to debug,
since we don’t ever access that value again.</p>

<p>In any case, we then proceed on to actually adding 1 to <code>rdi</code>.
The value is stored back in <code>rdi</code>, and importantly for what comes next,
we may set some of the <a href="https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture#EFLAGS_Register">flags</a>.</p>

<p>Then it gets complicated again - we’ve got <code>setb al</code>. All of the <code>set*</code>
<a href="https://github.com/HJLebbink/asm-dude/wiki/SETcc">instructions</a>
deal with the flag register. The flag register is possibly the most magical
of registers, since it’s manipulated by a bunch of instructions as a side effect.</p>

<p>The last instruction we ran was <code>add</code>, which sets 6 of the the flags:
<a href="https://en.wikipedia.org/wiki/Carry_flag">carry</a>, <a href="https://en.wikipedia.org/wiki/Parity_flag">parity</a>,
<a href="https://en.wikipedia.org/wiki/Adjust_flag">adjust (aka auxiliary carry)</a>, <a href="https://en.wikipedia.org/wiki/Zero_flag">zero</a>,
<a href="https://en.wikipedia.org/wiki/Sign_flag">sign</a> and <a href="https://en.wikipedia.org/wiki/Overflow_flag">overflow</a></p>

<p>In this case we’re checking if the carry bit is set, and then setting the <code>al</code>
register to 1 if that’s the case. What is this actually doing though?
The carry bit gets set to 1 if there is a <code>carry</code> from the two numbers we add,
meaning the resulting number is too big to be stored in the register.
What should we do in that case? Let’s read on to find out.</p>

<p>Then in the next line (<code>test al, 1</code>) we’re checking if the value in <code>al</code> is equal to one.
(<code>test</code> does a a bitwise and operation on the two arguments - like <code>&amp;</code> in rust.)
This sets some more flags, notably the <code>zero</code> flag, which is then read by the following <code>jne</code> instruction.</p>

<p><code>jne</code> stands for jump if not equal (and again there’s a series of
<a href="https://en.wikibooks.org/wiki/X86_Assembly/Control_Flow#Jump_Instructions">other</a>
<code>j*</code> instructions). Since it uses flags, it just takes a single argument: where to jump to.</p>

<p>Looking at where that jumps to gives us a big hint about the intent of the
logic above: <code>core::panicking::panic@GOTPCREL</code> really gives it away.
Basically all of this chunk of assembly from <code>setb</code> to <code>jne</code> is checking if we’ve overflowed
the register and panicking if we have.</p>

<p>The one bit we didn’t discuss is <code>mov qword ptr [rsp + 8], rdi # 8-byte Spill</code>.
As the comment implies this is “spilling” the value from the <code>rdi</code> register
onto the stack, since the code we’re possibly about to jump to might
overwrite that register - immediately after the <code>jne</code> we load the value back off
the stack.</p>

<p>Finally we shuffle the stack pointer back to it’s starting point, and <code>ret</code>
back to the caller. <code>ret</code> uses the last value on the stack (which is pushed by <code>call</code>)
to figure out where to jump back to, so moving the stack pointer back is <em>very</em> important.</p>

<p>So maybe at this point we’ve seen enough to take a stab at replacing the guts of the <code>add</code>
function with the <code>asm!</code> macro. Since we’re interested in performance,
we’ll ignore those pesky overflow checks, and just assume that we’re within the bounds of <code>u64</code>.</p>

<p>The biggest new thing we’ll have to deal with here is specifying the <code>in</code> and <code>out</code> registers.
The <a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#guide-level-explanation">rfc</a>
has a very approachable explaination of these, so I’d recommend reading that.
There’s a skeleton you can start with <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=d511cf5e95ba5cdfbcffaebaf5f72300">here</a>,
if you want to have a go yourself.</p>

<p>The version I’ve cooked up looks like <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=669b4155a1d818cc5c73b117b9454d48">this</a>.
This is probably the “fanciest” possible version of this, since we’re using as many features of the asm macro as possible:</p>

<ul>
<li>we’re letting the rust compiler pick the register we use, and then writing it in using the
<a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#inputs-and-outputs"><code>format</code> string behaviour</a> of the <code>asm</code> macro.</li>
<li>we’re also using <a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#late-output-operands"><code>inlateout</code></a> to
hint that we can just use a single register.</li>
</ul>

<p>This seems like a reasonable point at which to break. We’ve covered a reasonable chunk of the instruction set in x64 assembly,
and seen examples of most of the classes of instructions. There’s tons more we can explore, like:</p>

<ul>
<li>How do loops work?</li>
<li>What happens when we use values that don’t just fit in registers?</li>
<li>How do we make a syscall?</li>
</ul>

<p>Hopefully the resources I’ve linked to from here are sufficent for you to continue digging in if you want,
and maybe I’ll manage to follow this up.</p>

</div>

      </div></div>]]>
            </description>
            <link>https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041675</guid>
            <pubDate>Mon, 03 Aug 2020 18:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing UFCS for C++ in Clang]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24041376">thread link</a>) | @foxhill
<br/>
August 3, 2020 | https://dancrn.com/2020/08/02/ufcs-in-clang.html | <a href="https://web.archive.org/web/*/https://dancrn.com/2020/08/02/ufcs-in-clang.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
        <p> 2020/08/02 </p>
        
<p>tldr; Unified function calling syntax (UFCS) is useful and elegant. I’ve implemented a variant of UFCS that resembles C#’s “extension methods”, in Clang, which you can check out at <a href="https://github.com/dancrn/llvm-project">https://github.com/dancrn/llvm-project</a>.</p>

<h2 id="outline">Outline</h2>
<p>Proposals for UFCS in C++ has been a somewhat perennial discussion (<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1585.pdf">N1585</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4165.pdf">N4165</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4174.pdf">N4174</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4474.pdf">N4474</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0079r0.pdf">P0079R0</a>), with seemingly positive discussion from many, including both Herb Sutter and Bjarne Stroustrup. C# has a take on UFCS called extension methods, and personally, I’ve found them to be overwhelmingly useful. If you’re unfamiliar C#’s extension methods, they look something like this:</p>

<div><div><pre><code><span>public</span> <span>static</span> <span>class</span> <span>Extensions</span>
<span>{</span>
  <span>public</span> <span>static</span> <span>string</span> <span>ValueOrDefault</span><span>(</span><span>this</span> <span>string</span> <span>input</span><span>,</span> <span>string</span> <span>defaultValue</span><span>)</span>
  <span>{</span>
    <span>return</span> <span>String</span><span>.</span><span>IsNullOrWhiteSpace</span><span>(</span><span>input</span><span>)</span> <span>switch</span> <span>{</span>
      <span>true</span> <span>=&gt;</span> <span>defaultValue</span><span>,</span>
      <span>false</span> <span>=&gt;</span> <span>input</span>
    <span>};</span>
  <span>}</span>
<span>}</span>

<span>public</span> <span>string</span> <span>GetValue</span><span>(</span><span>string</span> <span>str</span><span>)</span>
<span>{</span>
  <span>return</span> <span>str</span><span>.</span><span>ValueOrDefault</span><span>(</span><span>"No value provided"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Extension methods, when invoked, look like first class methods on the type they are defined on. The example provided doesn’t have much benefit over the existing free-form call (i.e. <code>Extensions.ValueOrDefault(str, "nothing")</code> - and this still is also a valid way of calling that method). However, static extension methods come into their own when viewed as generic approaches to extending already existing classes that cannot be modified. One such C# library is <a href="https://github.com/louthy/language-ext">LanguageExt</a>, which provides functional extensions to the base <code>IEnumerable</code> interface (amongst <em>many</em> other things), although there are a lot of other examples that extend other commonly used libraries.</p>

<p>Unfortunately, whilst proposals resurface every once in a while, activity on unified call syntax seem to have stagnated. I want to see what it takes to implement it, and who knows, if enough people like and use UFCS, it might make it into.. C++30, maybe?</p>

<h2 id="ufcs-models">UFCS models</h2>
<p><a href="https://brevzin.github.io/c++/2019/04/13/ufcs-history/">Revzin</a> has an excellent couple of articles that describe UFCS more generally. Essentially, UFCS can be split into two categories of behaviors: “candidate set” functionality describes which functions are considered for a particular invocation style, and “overload resolution” approaches that describe how to determine which member or function should be chosen when there is more than one candidate. Without repeating those descriptions, this model can be considered to be CS4 - the addition of syntax to indicate UFCS candidacy - and OR2 - perform overload resolution as normal with all candidates. I wont spend too much time going into why I’ve made these choices, but briefly:</p>

<h2 id="choice-of-cs4">Choice of CS4</h2>
<p>Whilst not strictly the “most pure” decision, I think that it’s sensible to allow users to specify which functions they intend to be used in overload resolution. And, whilst not <em>strictly</em> speaking a priority, keeping the candidate set as small as possible would be beneficial from the perspective of compilation times. It also allows UFCS to be backward compatible with existing code, means that I think this is the most sensible approach to take.</p>

<h3 id="ufcs-syntax-additions">UFCS syntax additions</h3>
<p>There are two obvious ways of using the <code>this</code> keyword to indicate UFCS candidacy, as a parameter qualifier, or as a parameter name - for anyone familiar with C#, it’s clear that CS4, along with a <code>this</code> parameter qualifier was style chosen when implementing its idea of UFCS. There are many sensible choices for syntax additions, but these where two I considered. These both look like:</p>

<div><div><pre><code><span>// 1. 'this' parameter name</span>
<span>int</span> <span>func</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>this</span><span>);</span>

<span>// 2. 'this' qualifier</span>
<span>int</span> <span>func</span><span>(</span><span>this</span> <span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>param</span><span>);</span>
</code></pre></div></div>

<p>There are some drawbacks to option 1.:</p>
<ul>
  <li>The implicit <code>this</code> value generally has access to private &amp; protected members of a class, members that UFCS functions would not have access to.</li>
  <li>The parameter type was chosen to demonstrate an inconsistency: <code>this</code>, when used in a member function is generally considered to be a pointer, i.e., we use <code>this-&gt;value</code> rather than <code>this.value</code>. What should we accept for UFCS functions?</li>
</ul>

<p>The alternative has a couple of (admittedly smaller) issues:</p>
<ul>
  <li>UFCS candidacy is most easily seen as a is a property of a function, not a parameter - why change the parameter?</li>
  <li><code>this</code> is a keyword that generally represents a value, and whilst C++ has repurposed keywords before - <code>auto</code> - this might not be desirable.</li>
</ul>

<p>In the end, the first option seemed to present more questions than it answered, so I opted for the second alternative.</p>

<h3 id="choice-of-or2">Choice of OR2</h3>
<p>I think the worst case scenario for UFCS would be one where the member functions of a class change, masking a UFCS call in a another part of the code that interacts with values of that type. For instance, consider the following case:</p>

<div><div><pre><code><span>// from include &lt;some/library.h&gt;,</span>
<span>// context is defined with a single "read from file" function.</span>
<span>class</span> <span>context</span> <span>{</span>
<span>public:</span>
  <span>int</span> <span>read_from_fd</span><span>(</span><span>int</span> <span>fd</span><span>);</span>
<span>};</span>

<span>// and in consuming code, has the following extension defined</span>
<span>int</span> <span>read_from_file</span><span>(</span><span>this</span> <span>context</span><span>&amp;</span> <span>ctx</span><span>,</span> <span>FILE</span> <span>*</span><span>fp</span><span>);</span>
</code></pre></div></div>

<p>Now, the library is updated to a later version, which includes its own <code>read_from_file</code> method:</p>

<div><div><pre><code><span>// from include &lt;some/library.h&gt;,</span>
<span>class</span> <span>context</span> <span>{</span>
<span>public:</span>
  <span>int</span> <span>read_from_fd</span><span>(</span><span>int</span> <span>fd</span><span>);</span>
  <span>int</span> <span>read_from_file</span><span>(</span><span>FILE</span> <span>*</span><span>fp</span><span>);</span>
<span>};</span>

<span>// this function can only be used with regular function call syntax</span>
<span>int</span> <span>read_from_file</span><span>(</span><span>this</span> <span>context</span><span>&amp;</span> <span>ctx</span><span>,</span> <span>FILE</span> <span>*</span><span>fp</span><span>);</span>
</code></pre></div></div>

<p>Preferring member calls over UFCS calls in this case would silently change behaviour of this code, without any obvious change to the <code>read_from_file</code> method. Broadly speaking, I don’t think it’s sensible to prefer one type of call over the other, so this would seem to rule out any form of overload resolution that has preference for one type of call over the other. Therefore OR1 and OR2+ don’t seem like the best approaches, and the choice of CS4 rules out OR3 from being an option. In my implementation, any ambiguity between calls is treated as an error, as it is now.</p>

<p>It should be noted that the choice of OR2 is in contrast with C#’s extension methods, where, in the case of ambiguity between a UFCS candidate and a member function, the member function is always chosen (i.e., C# uses OR2+).</p>

<h2 id="ufcs-for-c">UFCS for C++</h2>
<p>In summary, the following is what I’m going to be implementing:</p>

<ol>
  <li><code>this</code> precedes the declaration specifiers (<code>const</code>, <code>volatile</code>, etc.) of a file/namespace scoped function’s first parameter.</li>
  <li>Class methods cannot be defined to be UFCS candidates (although that could probably be relaxed for non-instance methods).</li>
  <li>Calls of the form <code>x.f(y)</code>, in addition to performing member lookup, also perform name lookup for functions of name <code>f</code>, and overload resolution with arguments <code>x</code>, and <code>y</code>.</li>
  <li>Overload resolution proceeds as normal, i.e., if the candidate set contains a class method and a UFCS candidate, then there is no preferential treatment of either, and this is an error.</li>
</ol>

<h3 id="an-example">An example</h3>
<p>In summary, we will be able to define functions that appear to be methods defined on a class as such:</p>

<div><div><pre><code><span>class</span> <span>foo</span> <span>{</span>
  <span>private:</span>
  <span>std</span><span>::</span><span>string</span> <span>m_bar</span><span>;</span>

  <span>public:</span>
  <span>foo</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>bar</span><span>)</span><span>:</span>
  <span>m_bar</span><span>(</span><span>bar</span><span>)</span>
  <span>{</span> <span>}</span>

  <span>std</span><span>::</span><span>string</span> <span>get_bar</span><span>()</span>
  <span>const</span> <span>noexcept</span>
  <span>{</span> <span>return</span> <span>m_bar</span><span>;</span> <span>}</span>
<span>};</span>

<span>int</span> <span>get_bar_length</span><span>(</span><span>this</span> <span>const</span> <span>foo</span><span>&amp;</span> <span>val</span><span>)</span> <span>{</span>
  <span>return</span> <span>val</span><span>.</span><span>get_bar</span><span>().</span><span>length</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>And using these methods looks like:</p>

<div><div><pre><code><span>void</span> <span>f1</span><span>()</span>
<span>{</span>
  <span>auto</span> <span>val</span> <span>=</span> <span>foo</span><span>(</span><span>"pasta"</span><span>);</span>

  <span>// the two calls are semantically identical</span>
  <span>assert</span><span>(</span><span>val</span><span>.</span><span>get_bar_length</span><span>()</span> <span>==</span> <span>get_bar_length</span><span>(</span><span>val</span><span>));</span>
<span>}</span>
</code></pre></div></div>

<h2 id="clang">Clang</h2>
<p>I’ll forgo an introduction to Clang here - I expect any readers will be familiar with it. I’ve been motivated to start with Clang rather than GCC primarily because of Saar Raz’s story on getting behind Clang’s <a href="https://www.youtube.com/watch?v=Y1o4rc9P1FQ">implementation of concepts</a>. In any case, Clang seems like a suitable basis for implementation:</p>

<ol>
  <li>Clang is actively maintained with hundreds of contributers,</li>
  <li>code quality in Clang is widely regarded to be clean and consistent,</li>
  <li>acceptance into Clang, if it were to happen, may encourage discussion on UFCS, and</li>
  <li>it could be fun :)</li>
</ol>

<h3 id="implementation">Implementation</h3>
<p>I started UFCS in clang “for real” in around April of this year, although I had been reading and thinking about it on and off probably since September of 2019. In general I thought the code quality in Clang was decent, and whilst the learning curve was probably the steepest I’ve ever encountered, I was impressed with how little you needed to fully understand to make something work - the code is truly quite modular. That said, getting something working versus something that is complete requires understanding very large regions of code. Parsing C++ is what a lot of people would consider to be exotic, and so small changes in one place can have effects in places that you would not expect.</p>

<p>As it stands, I have a working implementation that passes all the tests in <code>make clang-test</code>. Of course, ‘Parse’ and ‘SemaCXX’ tests have been added, <code>cxx-ufcs.cpp</code> and <code>unified-call-syntax.cpp</code> respectively. I’ve added appropriate additional diagnostic messages (albeit as parser errors, rather than semantic analysis errors), though there are some others that I would like to add in. I’ve tested my custom version of Clang on a few projects, and it seems to work as expected, too. Overall, I’m quite satisfied with how it’s turned out, and I (naively) hope someone other than myself will give it a go :)</p>

<h3 id="using-ufcs">Using UFCS</h3>
<p>If you want to try UFCS, then you can checkout and build Clang from <a href="https://github.com/dancrn/llvm-project">here</a>, there’s nothing extra to configure (although I recommend you don’t install it in the default prefix!). To enable UFCS, you’ll need to pass an additional argument to Clang when invoking it, <code>-fufcs</code>. The front end driver hasn’t been changed at all, so you’ll most likely need to pass it through to the compiler manually:</p>

<div><div><pre><code> $ /path/to/clang -Xclang -fufcs file.cpp
</code></pre></div></div>

<p>Again, given the design of this implementation, there shouldn’t be any issues with compiling existing code. If this is not a case, then feel free to create an issue on GitHub!</p>

<h2 id="remaining-work">Remaining Work</h2>
<p>Whilst I’m moderately confident that my changes work as intended, I do not consider this to be “done”. There are a few things that feel not quite right, and, even if this is never merged into clang (which …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dancrn.com/2020/08/02/ufcs-in-clang.html">https://dancrn.com/2020/08/02/ufcs-in-clang.html</a></em></p>]]>
            </description>
            <link>https://dancrn.com/2020/08/02/ufcs-in-clang.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041376</guid>
            <pubDate>Mon, 03 Aug 2020 18:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Years at Roblox]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24041338">thread link</a>) | @nabla9
<br/>
August 3, 2020 | https://zeux.io/2020/08/02/eight-years-at-roblox/ | <a href="https://web.archive.org/web/*/https://zeux.io/2020/08/02/eight-years-at-roblox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>

02 Aug 2020

</span></p><p>I joined Roblox at the end of 2012 as a rendering engineer; I had just spent more than a year working on various titles from FIFA franchise after years of console game development and was becoming a bit tired of the “big game development”. My work on FIFA was as a contractor and I got an offer for a full-time position, but I also had a friend who worked at Roblox reach out and offer me to move to California and work on Roblox. I knew absolutely nothing about Roblox, but California was nice and my friend told me it would be awesome. The platform was so different (and so strange!) that I decided to take a chance - here I am, 8 years later, still working at Roblox and enjoying it. I started on my first full time job in April 2007 so at this point I’ve worked for 13 years in game development and 8 of them were at Roblox.</p>

<!--more-->

<p>My memory works in interesting ways. I remember my interview pretty well, I remember having lunch at some place in San Mateo downtown near the Roblox HQ - a few people were at lunch including Roblox CEO David Baszucki and I remember him asking many questions about my thoughts about the engines and rendering, and distinctly remember not finishing most of my lunch because I talked most of the time. However I don’t really remember what was going through my head in regards to my perception of Roblox - why did I join besides just thinking I want to do something else for a change? Who knows, but I am glad I did.</p>

<p>I don’t really understand why Roblox is so successful - you can invent all sorts of reasons in retrospect but it’s hard to validate them, and if you came to anybody back in 2012 and asked for an investment to build a platform where all games are user generated and run on a custom engine with a custom toolset and all users participate in a giant virtual economy and …, I think you’d have gotten a blank stare.</p>

<p>But I do understand that I found the perfect place for me, especially at that point in my career - I enjoy working on game technology but I never liked working on actual games, and Roblox maximizes the number of developers who can use the technology you work on while maintaining a good autonomy and a very wide range of problems you’d need to solve. It’s very hard to get bored here.</p>

<p>I think I could talk for hours about Roblox - it somehow became a huge part of my life. I was very fortunate to join at the time when I did and witness the growth of our technology and business. I am really unsure of what the future holds but it’s hard to imagine what, if anything, comes after Roblox - I certainly don’t intend to leave any time soon…</p>

<p>So I thought it might be fun to do what I’ve planned to do for a year or more now, and to go over all decently sized projects I’ve ever worked on at Roblox. This is based on resummarizing and reliving the source control history, which tells me I’ve had 2752 changes that made it to our main branch, with merge commits counting as one, so, uh, this blog might be on a larger side. Hopefully this will be fun!</p>

<p>Before we begin, I just want to conclude this by saying that I’m very grateful to the Roblox leadership for treating me well, for all the friends and colleagues I made along the way, and for the wonderful Roblox community. The reason why I still enjoy what I do is because whenever I write about a new big thing I’m working on or a small feature or even a bug fix, it’s usually met with excitement which keeps me going. Thank you all from the bottom of my heart. I don’t think I could have done it without you and I hope this continues for as long as possible despite the current trying and uncertain times.</p>



<p>Notably including half-pixel offset fixes for Direct3D9 which I guess is a rite of passage for rendering engineers. The rendering code back then was based on OGRE rendering engine, so I had to learn that, and this was also my first time using OpenGL professionally - prior to that I’ve used Direct3D 9 and proprietary console APIs, and Direct3D 10/11 as a hobby.</p>



<p>Initially added for “100 player” project, in October it evolved to render all parts and continued to be used as part renderer until the introduction of instancing in 2018. Otherwise known as “featherweight parts”. This was further optimized and deployed around November 2012. Most of this code survived to this day but evolved over time, and is still used when instancing doesn’t apply.</p>

<p>The core idea in this system was to dynamically batch meshes together, for characters this would be based on the character model hierarchy, and for everything else the grouping is spatial. This allowed us to reduce the number of draw calls, which was a big concern due to both driver overhead and inefficiencies in OGRE.</p>

<p>This would pave the way for what eventually turned out to be a complete, but gradual, rewrite of the rendering stack. The main motivation for this was always performance - what we ended up let us port to mobile (the old rendering code was nowhere near fast enough even for relatively simple scenes), and break new grounds on the number of objects we could render in a frame.</p>



<p>One of a few OGRE upgrades we’ve needed to do, this one was to get better GLES support. It was pretty painful to do those, just like any other big middleware update is. Read further to learn what happened to OGRE eventually…</p>

<p>One thing I remember from doing these is that documentation in source code makes the upgrade process that much more painful. I had scripts that changed the copyright years in headers back to whatever they were in our tree just to make merging less painful, but there was some OGRE upgrade where 70% of the changes were documentation, and this was very hard to get through.</p>

<p>The reason why these were challenging in general is that whenever we did an upgrade we had to a) merge our plentiful changes with the new code, b) gate dangerous parts of the upgrade with flags. We’ve used the same system of feature flags (we call them fast flags) since I joined Roblox which allows us to dynamically disable parts of the release based on metrics, but this requires actually isolating changes behind if statements selectively - which for OGRE was sometimes necessary as we didn’t know what the impact of some low level change in OpenGL code would be.</p>



<p>Before this we had hand-translated shaders, which started to be painful to maintain. The first version of the pipeline used hlsl2glsl and glsl-optimizer (same as Unity back in the day). We are using version 3 today, see below!</p>

<p>Since this was done at the point where we used OGRE, the compiler would take HLSL files, preprocess and translate them to optimized GLSL, and save the resulting GLSL back to disk - which would then be loaded by OGRE directly through the material definition file. Eventually we replaced this with a binary shader pack that could store GLSL code for OpenGL and shader bytecode for other APIs, but back then we shipped HLSL and GLSL source and compiled HLSL code on device!</p>



<p>Our equivalent of “Steam Hardware Survey” that went through SQL databases and coalesced various system information bits to help us understand the hardware at the time. This was during my era of obsession with F#, so it was written in F# instead of something like Python. We don’t use this anymore and don’t even have the SQL database in question!</p>

<p>We never published the resulting data, and I’m not sure how often we used it to make decisions, but it was fun to look at the number of graphics cards from various vendors or amount of RAM or resolution a typical Roblox user has.</p>



<p>Although I was hired as a rendering engineer, I had a lot of really deep low-level systems experience and as a consequence ended up engaging in both optimization work and security related work from the very beginning. I don’t do this anymore these days but I was often involved in the security work for the first 3 or 4 years. Now we fortunately have people who can do this full time and better than I could :)</p>



<p>A second part of “100 player project”, necessary to render every character in one draw call (these were really expensive for us back in the day!). A side effect included some resolution sacrifices on character items that shirt creators aren’t fond of. The new system managed the atlas texture memory, rebaking humanoids far away to smaller textures to conserve texture memory. The compositor survived with minor changes to this day, although we’re now working on a new one.</p>

<p>The compositor was built in a very configurable fashion, allowing the high level code to specify the layout to bake, and managing all the complex asynchronous processing and budgeting by itself. This allowed us to switch the composit layout completely years later for R15.</p>



<p>At the end of 2012 we were actively working on the mobile port. Since then we’ve had to do a lot of work in a lot of different parts of the engine to make data structures smaller and algorithms - faster. Of course you’re never done with optimizations so we do this to this day. Curiously, our minimum spec on iOS stayed the same since the initial launch in 2012!</p>

<p>A fun fact is that even though we started with iPad 2 as the min. spec we discussed adding support to iPad 1 after launch. At the time there were a lot of people who couldn’t play Roblox on iOS on older hardware. However the performance characteristics of those devices were just… not good enough. You could touch the screen with the finger and pan the camera, and during panning you lost 30% of a single available core to the OS processing the touch. We decided to not add support for this, and 8 years later it seems like a great decision for sure :D</p>



<p>It was very hard to use Xcode Instruments to profile frame spikes on an iPad; to try to figure out how to get our performance to a better place on mobile, I wrote some ad-hoc code to dump all internal log events to a binary stream, and a desktop UI tool in F# and WPF to visualize it. This included a Lua profiler as well that could display profiles of Lua code in a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zeux.io/2020/08/02/eight-years-at-roblox/">https://zeux.io/2020/08/02/eight-years-at-roblox/</a></em></p>]]>
            </description>
            <link>https://zeux.io/2020/08/02/eight-years-at-roblox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041338</guid>
            <pubDate>Mon, 03 Aug 2020 18:18:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A super quick rundown on SEO]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24041239">thread link</a>) | @entreprenerd
<br/>
August 3, 2020 | https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial | <a href="https://web.archive.org/web/*/https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The two primary ways for people to find you on the internet are paid ads and search engines. We discussed paid ads <a href="https://www.entreprenerd.blog/live-streams/marketing-month-week-2">a few weeks ago</a>, now let's talk about search engines.</p><p>"SEO" is Search Engine Optimization - it's how Google and Bing and other search engines can tell whether or not your website should come up when someone searches for something.</p><p>The two main pieces of SEO are:</p><ul role="list"><li>Keywords / Content</li><li>Backlinks</li></ul><p>Keywords are just words and phrases you want to rank for - meaning you show up when someone googles them. For instance, I personally want to rank for words like "entrepreneurship" and phrases like "how to become an entrepreneur." So, if my website is full of articles and videos and information about those words and phrases, I'm more likely to pop up when someone types them into google.</p><p>So, how do you find keywords? I use a tool called <a href="https://ahrefs.com/">ahrefs</a> - it's not free, but it's close. They have "$7 for 7 Days" trial periods, and in order to assemble a solid list of keywords you can use for the next year, you'll really only need those 7 days. (Plus, you can always sign up for more trials using different emails in the future - just REMEMBER TO CANCEL your subscription)</p><p>After you sign up, go to "Keyword explorer" and start typing ideas in. Use each of the tabs on the left under "Keywords Ideas" - and create a list to add any keywords you find that make sense for your brand. Usually, I filter by "KD" (Keyword Difficulty) to anything lower than 25. Beyond 25, unless you're producing an incredible amount of content, you're going to have a lot of trouble.</p><p>After you compile a big fat list of keywords you like, go to the list page and export it to excel so you can use it after your trial period expires. Now you know what to target.</p><p>The next thing is content, and this is where things get to be a black box. Content is just articles and written posts on your website that contain the keywords we compiled. If a big keyword for me is "how to become an entrepreneur" then you bet I'm going to write an article with that title. However, I've talked to a good number of SEO professionals, and the best advice they can give is "Write well." It's tough to know what exactly you should put in your content that makes it rank higher, so the best thing you can do is use proper grammar, make it readable, and do what the title suggests the article will say.</p><p>A few tools I've seen that tend to help content get written well are <a href="http://grammarly.com/">Grammarly</a> and <a href="https://www.dashword.com/">Dashword</a>. Grammarly just helps you use proper grammar - it's free and awesome. Dashword is a new tool I found on ProductHunt that seems to help you position keywords nicely in your content so it ranks higher - though I haven't tested it and it is quite expensive.</p><p>So now you're writing content with the right keywords - but there's more you can do. You can use "backlinks" - links from other successful websites - to boost how well your website overall ranks. Basically, if google sees Entrepreneur Magazine (which ranks well in terms of "entrepreneurship" keywords) has an article or two that link to my website, then google will think my website is more important, and rank me higher. </p><p>So, we want other websites to suggest our website as a resource. We can do that by looking up the keywords we want to rank for - just type them in google - and see if any blogs pop up. If you find blogs or websites that rank well, use a simple email finder like <a href="https://hunter.io/">Hunter.io</a> to find whoever is in charge and reach out to them to ask to write a guest blog post. They get free content, and in the article you get to put a backlink to your website. Some blogs will even have a form just to submit guest post requests.</p><p>Lastly, you can use question-answer websites like <a href="https://www.quora.com/">Quora</a> to help push traffic in your direction. If, while you're googling your keywords, you find a few questions on Quora or WikiHow that you think you can answer, do it. For instance, if someone asks "what podcasts are great for learning entrepreneurship?" I might answer and reference my live stream content. That provides a backlink on a ranking question, and if people like that answer, they can also find you directly through it.</p><p>Beware, all of this sounds pretty great, but google takes anywhere between 4 to 6 months to actually see what you've created. If you post a bit of content now, you'll have to wait a while for the benefit to actually kick in, and for people to find your website through it. SEO is a long-term investment, so plan accordingly.</p><p>That's pretty much the basics. There are a lot more nuances like making sure your website is structured the right way and how to build your sitemap, but this should be all you need to know to get started!</p><p>If this was helpful at all, a retweet would be amazing. It really helps me spread the word - but of course, no pressure at all! :)</p></div></div>]]>
            </description>
            <link>https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041239</guid>
            <pubDate>Mon, 03 Aug 2020 18:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I've compiled a list of books on cryptocurrencies]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24040928">thread link</a>) | @vhpoet
<br/>
August 3, 2020 | https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn | <a href="https://web.archive.org/web/*/https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24040928</guid>
            <pubDate>Mon, 03 Aug 2020 17:47:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Not Thinking]]>
            </title>
            <description>
<![CDATA[
Score 452 | Comments 146 (<a href="https://news.ycombinator.com/item?id=24039887">thread link</a>) | @tmatthe
<br/>
August 3, 2020 | http://tiffanymatthe.com/not-thinking | <a href="https://web.archive.org/web/*/http://tiffanymatthe.com/not-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>03.08.2020</time> — <a href="http://tiffanymatthe.com/tags/productivity">Productivity</a> — <span>5<!-- --> min read</span></p><section><img src="http://tiffanymatthe.com/static/d758a9afd33cefb9ce3dc7bb83cc213d/a6c62/not-thinking.jpg"><p><em>After years of feeling guilty about not wanting to do everything, I realized I don't need motivation to get things done. Below, I describe how I use the concept of not thinking instead.</em></p><hr><p>It took me five years to get in the habit of exercising. I just didn't want to do it. I followed Youtube workouts, hopeful that the energetic trainer on the screen would help me get fitter. I swam laps in my pool. I followed my brother on 3K runs. And afterwards, I felt great! On top of the world. And then the next day came, and I remembered I had to do it all over again. I had to be sweaty, push through the pain, and breathe like I had an asthma attack.</p><p>So every morning, I woke up and inevitably started dreading my exercise. It would slink around in my thoughts, casting a dark mood until I got it done. At one point, I would dread exercising enough to stop, and a wave of relief would wash over me. This feeling of calm usually lasted a few months, and then my disappointment in my poor levels of fitness would take over. And the cycle would restart.</p><p><strong>Everyone has things they don't want to do.</strong> It's not limited to exercising. It can be anything from studying everyday for the entire school year to vacuuming the floor. Unless you can avoid that activity with no guilt or regrets, you usually have to do it. You know it will help in the long run, to study to prepare for finals and to have clean floors, but even with that in mind, it can still be incredibly hard to do those activities.</p><p>I realized that the hardest part of doing things I don't want to do is usually not the activity itself, but getting started. Once I get started, I get into a flow and rationalize that since I'm already doing it, I might as well finish.</p><h3>How much motivation do we need?</h3><p>I like to describe the amount of energy I need for a task I don't want to do as an exothermic reaction. In this reaction, the reactants (me) need a minimum activation energy (motivation) for the reaction (task) to occur. After the reaction is complete, the products then settle down into a lower energy state (since no more energy is needed to do the task or worry about it).</p><p><span>
      <span></span>
  <img alt="Motivation Energy Reaction" title="Motivation Energy Reaction" src="http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/18e3b/exothermic.jpg" srcset="http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/46946/exothermic.jpg 240w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/55489/exothermic.jpg 480w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/18e3b/exothermic.jpg 960w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/60e21/exothermic.jpg 1440w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/69b48/exothermic.jpg 1920w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/e1761/exothermic.jpg 3273w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>So how can we get this minimum activation energy? Well, if we don't want to do the activity, it is nearly impossible to gain enough motivation to do it. The good news is that we can avoid the need for such a high activation energy.</p><p>How is this possible? A simple answer: <strong>don't try to find motivation</strong>.</p><p>When you look for motivation, you usually start by reminding yourself about the advantages of getting the task done. But your brain is a stubborn toddler. If you strongly drag it towards one direction, it will fiercely pull you to the other side. The brain thinks there's a choice, and thus a possibility to argue. It will start pointing out all the disadvantages and instant gratification alternatives.</p><p>Since humans instinctively reach for easier things, now you have not only dredged up all the negative points about your task, but also discovered easier alternatives that require an additional amount of energy to resist. In short, you have increased the minimum activation energy required to start the task.</p><p>You will also remember this awful internal debate, and associate these negative feelings with the task itself. Naturally, this does not bode well in the long run.</p><p>On the other hand, if you don't think about the task, you can avoid the entire process of arguing with yourself and making decisions that you will feel guilty about. Instead, just do it. <strong>Become a mindless robot</strong> and don't think twice<sup id="fnref-1"><a href="#fn-1">1</a></sup>.</p><p>This is, of course, easy to say and a bit more difficult to do. It's hard to think about not thinking, because you'll inadvertently wonder what it is you were trying to not think about, and bam, you've failed. Not thinking is a process, and just like any other skill you learn, it improves with time and practice. Here are a few tips.</p><h3>Make the decision in advance</h3><p>If you are temporally removed from the thing you don't want to do, it's easier to make a rational decision. By making the decision beforehand, you remove the effort needed to choose before doing your task. This reduces friction and removes one factor that could have led you to think about your task when you start it.</p><p>There are a few ways of making decisions in advance. There's the two-minute rule, where you decide that for anything that takes less than two minutes, you do it. No thinking, no arguing, just swift action. For example, you see a pile of clothes on your bed. It takes less than two minutes to organize then in your drawer, so you do it. Here, you just avoided the trap of thinking about your clothes, feeling unmotivated to put them in order, and giving yourself the terrible alternative of doing it later.</p><p>Another method is planning out your days in advance. This does not always work, but it's a good idea to try it out. The night before, you plan out all of your activities to the minute. And, of course, as you're temporally distanced from these activities, you make rational decisions. Then when the morning comes, you can mindlessly follow the schedule you have made for yourself.</p><h3>Do a small part first</h3><p>Quickly pick a random small part of the activity you were dreading. And commit to only doing that one part. This helps you avoid overthinking by giving your brain a smaller task to easily execute<sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p><p>For example, if you need to complete a scholarship application and hate writing about yourself, tell yourself to just write bullet points of topics you might include in the application. Most of the time, after you have invested those first five minutes into the activity, you enter a flow and continue working.</p><p>After implementing these strategies, where I tell myself that I have to exercise every other day for a mere 5 minutes, I now consistently exercise for at least 15 minutes without overthinking it.</p><p>So next time you find yourself not wanting to do something, make yourself a clear rule of when to do it and do the easiest part first. That way, you can avoid making too many decisions and associating the internal turmoil that stems from that process to the activity itself.</p><p>Note, not thinking works wonderfully if your sole purpose is doing an activity you don't want to do. However, unless you don't have any goals to pursue, this is not the best way to go about everything in life. Make sure to take the time to reflect on the overall purpose of the activity and if it brings you closer to where you want to be. If the answer is yes, then feel free to become a mindless robot for any activities that have passed the reflection stage.</p><p>At the small risk of being sued by Nike, just do it.</p></section></div></div>]]>
            </description>
            <link>http://tiffanymatthe.com/not-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039887</guid>
            <pubDate>Mon, 03 Aug 2020 16:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Tell Your Data Team's ROI Story]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039794">thread link</a>) | @barrald
<br/>
August 3, 2020 | https://hex.tech/blog/data-team-roi | <a href="https://web.archive.org/web/*/https://hex.tech/blog/data-team-roi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I’m fortunate to be involved in a few awesome data-focused communities. Like clockwork, every few months a Data leader will pop up asking for advice on how to calculate the return-on-investment for their team. The question is usually in the context of a budget decision, where they need to justify expanding headcount or purchasing a new tool.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The name has been changed to protect the innocent" title="The name has been changed to protect the innocent" src="https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png" srcset="https://hex.tech/static/833b16929966b847168439d6df34e764/44569/slack-message.png 175w,
https://hex.tech/static/833b16929966b847168439d6df34e764/f8bcd/slack-message.png 350w,
https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png 493w" sizes="(max-width: 493px) 100vw, 493px" loading="lazy">
  </a>
    </span>
    <figcaption>The name has been changed to protect the innocent</figcaption>
  </figure>
<p>While there’s a subtle irony in the team responsible for quantification struggling to quantify their work, calculating a true “ROI” can be challenging because of the way data teams typically operate.</p>
<p>In some cases, the data team has a top-or-bottom-line impact that can be directly measured. For example, if the company sells data as their product, the Data team has a clearer, more obvious connection to value creation.</p>
<p>But for most teams, their impact is created indirectly: they are partners, acting in support of functions like Marketing, Operations, or Engineering to affect company performance.</p>
<p>In organizations like these, efforts for the Data team to come up with a standalone ROI will be underwhelming and unconvincing. Calculating a crisp “return” on an analysis project or model is difficult, and it’s even harder for infrastructure investments: how do you quantify the impact of a better schema, or a more reliable pipeline? An improvement in data quality can be objectively beneficial, but also quickly taken for granted.</p>
<p>The truth is that if you’re trying to quantify your impact by yourself, you have already lost. <strong>Instead, the best way to tell the ROI story is for other people to tell it.</strong></p>
<p>If your Data team is truly providing value, the leaders of other functions should be lining up to sing your song. Limitations or reductions in Data team headcount should elicit howls from functional stakeholders; the VP Marketing and Head of Ops should be the ones fighting for more Data resources.</p>
<p><strong>If your partners aren’t willing to go to bat for you like this, then it’s time to take a step back to rethink how you’re operating.</strong> Are other teams actually benefiting from your work, or are you detached from business outcomes? Is your team in the trenches with other functions, or only providing input from afar?</p>
<p>There are 3 key areas to examine:</p>
<h3>Organization</h3>
<p>Too many data teams operate in a centralized, siloed manner. “Ivory Tower” teams may be doing brilliant, insightful work, but they’re too far from the business to make a tangible impact.</p>
<p>I once worked with the “Advanced Analytics Group” at a major CPG company. They all sat together, in one area of one floor of one building, far from the teams they were supposed to be supporting. While they were all intelligent, earnest people, their work was academic at best, and they struggled to justify their existence. This “Center of Excellence” model rarely works, especially as a team grows.</p>
<p>There are other ways to organize a data team. <a href="https://medium.com/@djpardis/models-for-integrating-data-science-teams-within-organizations-7c5afa032ebd" target="_blank" rel="nofollow">Pardis Noorzad has an amazing overview here</a>, and I agree that the "Product Data Science" model is a strong option for most teams. <a href="https://medium.com/@itunpredictable/data-as-a-product-vs-data-as-a-service-d9f7e622dc55" target="_blank" rel="nofollow">Justin Gage's "Data as a Service" model</a> also provides a useful lens - is your Data team just providing data, or useful input to decisions? <strong>If not, stakeholder partners are unlikely to stand up and support your team’s ROI story.</strong></p>
<figure>
    <span>
      <a href="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/07220/justin-DaaS-image.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="From Justin Gage's 'Data as a Product vs. Data as a Service'" title="From Justin Gage's 'Data as a Product vs. Data as a Service'" src="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/a27c6/justin-DaaS-image.png" srcset="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/44569/justin-DaaS-image.png 175w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/f8bcd/justin-DaaS-image.png 350w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/a27c6/justin-DaaS-image.png 700w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/dd14e/justin-DaaS-image.png 1050w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/07220/justin-DaaS-image.png 1156w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
    <figcaption>From Justin Gage's 'Data as a Product vs. Data as a Service'</figcaption>
  </figure>
<p>Re-organization away from a centralized Data team model can be painful, and may feel like a loss of control or prestige. But it’s critical to keep an open mind — and set ego aside — if you want your stakeholders to feel the impact of your team, and advocate on your behalf.</p>
<h3>Planning</h3>
<p>Next, integrate your planning process. If your organization uses a system like OKRs, explicitly tie the Data objectives to support the goals of your stakeholders. This makes it clear exactly how your team is impacting functional outcomes.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="All together now" title="All together now" src="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png" srcset="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/44569/OKRs-for-blog.png 175w,
https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/f8bcd/OKRs-for-blog.png 350w,
https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png 700w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
    <figcaption>All together now</figcaption>
  </figure>
<p>Infrastructure-level objectives — like implementing a new data warehouse — can live separately, but should still have explicit callouts for how those investments are supporting the higher-level objectives.</p>
<p>Data Leaders should also push for their teams to be involved with other teams’ granular planning cycles. If the Marketing team has a weekly planning meeting or daily stand-ups, the Data analysts supporting that team should be in the room (or Zoom, or whatever).</p>
<p>If your team has its own planning cycles and sprints, involve stakeholders in an explicit prioritization exercise. This will give them more insight into Data activities, and when it comes time to speak to ROI they will already have thought through the upside and tradeoffs around your team’s time.</p>
<p>As a side benefit, by aligning priorities with the business, Data teams <strong>avoid the dreaded “find novel insights” mandate</strong>. If an Analyst is deeply embedded with the Marketing team, partnering on their hardest problems, it’s harder for the CFO to distract them with a one-off wild goose chase.</p>
<h3>Tools</h3>
<p>Even if they are well-integrated into the rest of the organization, <strong>the Data team’s work will underwhelm if it’s not actually useful for others</strong>. Today’s tools are a mixed bag here.</p>
<p>BI platforms are great for enabling self-serve and building dashboards. But they also have relatively low ceilings, and aren’t a medium where data scientists can do their most interesting work.</p>
<p>On the other hand, Code notebooks are amazing for deeper exploration and model iteration, but are single-player, hard to share, and inaccessible for less-technical folks. Even if a Data Scientist has developed something interesting, there’s no easy way to productize it or make it useful for the rest of the organization.</p>
<p>So Data teams often wind up screenshotting charts, exporting CSVs, and sharing through slide decks, spreadsheets, and Slack. While these tools meet stakeholders where they are, they’re severed from source data and have short half-lives; when a PM wants to update an assumption, they need to ping the analyst, who re-runs, re-exports, and re-sends.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="We can do better" title="We can do better" src="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png" srcset="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/44569/screenshot_hell.png 175w,
https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png 257w" sizes="(max-width: 257px) 100vw, 257px" loading="lazy">
  </a>
    </span>
    <figcaption>We can do better</figcaption>
  </figure>
<p>This gap in sharing and collaboration not only wastes Data teams’ time, but acts as a drag on their impact. Delivering a forecast model to the Finance team as a live, interactive data app is way more useful than a once-weekly static PDF; the CFO themself will understand the ROI every time they open it to run a new scenario.</p>
<p>I’m excited to see a new crop of tools emerge (disclaimer: <a href="https://hex.tech/" target="_blank" rel="nofollow">I’m working on one</a>) to help data teams more easily share their work, and create clearer, more tangible impact with the rest of the organization.</p>
<hr>
<p>It’s an exciting time in the Data world. Thousands of new people are entering the space as Data Scientists and Analysts. It’s easier than ever to source, transform, and store data. And the ML explosion is unlocking possibilities for insight and inference.</p>
<p>But gaining the budget and support needed to take advantage of all of this is an uphill battle without advocacy from functional stakeholders. By re-evaluating team organization, planning, and tooling, Data teams can ensure their impact is obvious and clear.</p>
<p>Done right, it means the next time a Data leader is asked to justify ROI, they won’t have to. They can sit back, and let others tell the story for them.</p></div></div>]]>
            </description>
            <link>https://hex.tech/blog/data-team-roi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039794</guid>
            <pubDate>Mon, 03 Aug 2020 16:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You May Finally Use JSHint for Evil]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039470">thread link</a>) | @jugglinmike
<br/>
August 3, 2020 | http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/ | <a href="https://web.archive.org/web/*/http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      
  
  <article>

    <header>
      <p>
          
        POSTS
      </p>
      
      
      <time datetime="2020-08-03T00:00:00Z">August 3, 2020</time>      
      
      
      
      
    </header>

    <section><p><a href="https://jshint.com/">JSHint</a> is a software tool designed to help developers
write JavaScript code. Since its creation in 2011, it has been encumbered by a
license which includes the following clause:</p>

<blockquote>
<p>The Software shall be used for Good, not Evil.</p>
</blockquote>

<p>That stipulation <a href="https://www.gnu.org/licenses/license-list.html#JSON">disqualifies JSHint from the distinction of “free”
software</a> and <a href="https://opensource.org/faq#evil">“open
source” software</a>.</p>

<p>Today, with a release 7 years in the making, we’re removing the clause. Support
for Evil is a new feature but not a breaking change, so in keeping with
<a href="http://semver.org/">Semantic Versioning</a>, we’ve incremented JSHint’s minor
version. <a href="https://jshint.com/blog/2020-08-02/release-2-12-0/">JSHint version
2.12.0</a> is licensed under
the terms of the MIT Expat license.</p>

<p>In this series of essays, I’ll discuss why this matters for the project, why it
matters to me personally, and how a large group of people came together to make
this possible.</p>

<ol>
<li><a href="http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/">Watching the Ship Sink</a> - how
the license hurt JSHint</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-dug-in/">Dug In</a> - why I stuck with JSHint and the
relicensing effort</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-asking-nicely/">Asking Nicely</a> - our inability to
relicense solely via contributor consent</li>
<li>Wrestling it Free - our success in relicensing through rewriting code
(coming tomorrow)</li>
</ol>

<p>Whether or not you care about any of that, the result is the same: JSHint is
now irrevocably free software.</p>

<p>Many thanks to <a href="https://github.com/jshint/jshint/graphs/contributors"><strong>all the people who’ve contributed to
JSHint</strong></a> for making this
project worth liberating and for enthusiastically participating in that
process. Thanks especially to <a href="https://anton.kovalyov.net/"><strong>Anton
Kovalyov</strong></a>, without whom there would be no JSHint
to relicense. <strong>Ethan Dorta</strong>, <a href="http://alexkritchevsky.com/"><strong>Alex
Kritchevsky</strong></a>, <a href="https://mattsurabian.com/"><strong>Matt
Surabian</strong></a>, and <strong><a href="http://tkellen.com/">Tyler
Kellen</a></strong> masterfully reimplemented code that they
couldn’t see. It’s tough to overstate the difficulty of the challenge and the
shrewdness required to overcome it. <a href="https://tbranyen.com/"><strong>Tim Branyen</strong></a>,
<strong>Isaac Carter</strong>, and <strong>Timon Lukas</strong> also volunteered time and energy toward
this end. <strong>Rick Waldron</strong> and <strong>Caitlin Potter</strong> gladly accepted the burden of
CLA enforcement in addition to their more traditional maintenance duties. The
relicensing effort was dead in the water until <strong>Simon Kaegi</strong> discovered the
free software version of JSLint; thank you, Simon, for catalyzing the campaign.
<strong>Joel Kinney</strong> and <strong>Steven M. Ayr</strong> provided much-needed legal perspective
(to be clear: <em>not</em> legal advice) when this all started, and they did so with
eagerness and passion that would make you think we’d paid them (to be clear: we
didn’t). When things seemed hopeless, <a href="https://pault.ag/"><strong>Paul
Tagliamonte</strong></a>, <a href="https://nadiaeghbal.com/"><strong>Nadia Eghbal</strong></a>
and <a href="http://punkrocklawyer.com/"><strong>Karen Sandler</strong></a> offered much-needed
encouragement and perspective. In addition to introducing me to Ethan, <a href="https://fsf.org/"><strong>the
Free Software Foundation</strong></a> continues to sponsor writing and
conferences that reinforce the importance of software freedom. By researching
legal concerns regarding software rewriting, <strong>Russell Hoover</strong> and <a href="https://kendraalbert.com/"><strong>Kendra
Albert</strong></a> at <a href="https://cyber.harvard.edu/teaching/cyberlawclinic"><strong>the Harvard Law School Cyberlaw
Clinic</strong></a> demonstrated
expertise and altruism. <a href="https://joryburson.com/"><strong>Jory Burson</strong></a>, <a href="https://www.lyza.com/"><strong>Lyza
Gardner</strong></a>, and <a href="https://matmarquis.com/"><strong>Mat
Marquis</strong></a> all helped me make sense of this story. The
warmth and dedication of these people can’t be overstated!</p>
<ul>
  
</ul>

    </section>

    

  </article>

    </div></div>]]>
            </description>
            <link>http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039470</guid>
            <pubDate>Mon, 03 Aug 2020 16:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SentiLink is first company in US to do real-time SSN verifications]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039393">thread link</a>) | @vivekahuja
<br/>
August 3, 2020 | https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c | <a href="https://web.archive.org/web/*/https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.sentilink.com/@press_51526?source=post_page-----2f71da5f280c----------------------" rel="noopener"><img alt="SentiLink" src="https://miro.medium.com/fit/c/96/96/2*kOctpPGgHUJshvf2fwu0pQ.png" width="48" height="48"></a></p></div></div></div></div><p id="1247"><em>By Naftali Harris, CEO</em></p><p id="ac29">All of us at SentiLink are extremely excited to announce that this Friday evening at 6:48pm PT, SentiLink became the first organization to go live with eCBSV! The first application in history was from a consumer who applied for a mortgage with one of our 20 eCBSV partners. The consumer consented to sharing their information with SentiLink, our partner, and the Social Security Administration, SentiLink submitted a request to the SSA, and the SSA determined that the information matched. This expedited the approval process for the consumer and the lender and saved them from having to fill out and sign a paper form.</p><p id="6f08">eCBSV (“Electronic Consent Based SSN Verification”) is a new service being offered by the SSA that allows permitted entities to electronically obtain consent from consumers and in real-time verify name/DOB/SSN combinations directly with the SSA. Until this evening, requests for SSA validation required a completed SSA89 form and a wet signature and took hours or even days to process, significantly limiting their use. eCBSV digitizes and dramatically expedites this process. While the stream of eCBSV requests we’re now processing are only the beginning, we believe that within several years there will be tens or hundreds of millions of requests, and eCBSV will be accepted as a major component in KYC and identity verification processes.</p><p id="21fe">The entire team at SentiLink has worked very hard to make eCBSV available for our partners and their customers. This includes getting up before 3:00AM last July in order to submit one of the <a target="_blank" rel="noopener" href="https://blog.sentilink.com/sentilink-and-ecbsv-5501d1db6360">first pilot applications</a> to the SSA, implementing all of the OIDC corner cases in the integration, doing <a href="https://research.sentilink.com/sentilink-ecbsv-whitepaper" target="_blank" rel="noopener">original research on match rates against the SSA’s source-of-truth Numindent file</a>, designing <a target="_blank" rel="noopener" href="https://blog.sentilink.com/the-ecbsv-product-guide-use-cases-f674b9905123">implementations and potential use-cases</a> with our financial institution partners, and <a target="_blank" rel="noopener" href="https://blog.sentilink.com/the-ecbsv-product-guide-consent-requirements-4fc897e87d44">working closely with the SSA to iron out the consent requirements</a>. I’d like to thank the entire team at SentiLink for sweating and hustling to push this over the line. I’d also like to thank our initial 20 partners; no first time implementation is perfect, and we’re lucky to work with 20 innovative, forward-thinking organizations whose feedback has been and continues to be critical to the success of this program. And lastly all of us would like to thank the SSA, whose hard work and late nights standing up eCBSV has made everything possible.</p><p id="02b5">We don’t believe eCBSV will be perfect or a stand-alone solution, but it is certainly a big step forward and a very useful new tool for financial services companies. We are humbled to help open a new chapter in identity verification in the United States.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039393</guid>
            <pubDate>Mon, 03 Aug 2020 15:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What RN is missing in order to be the default framework to build apps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24038136">thread link</a>) | @oscar_franco13
<br/>
August 3, 2020 | https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/ | <a href="https://web.archive.org/web/*/https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I was trying to develop app that runs on ALL platforms (iOS, android, windows, mac), I was encouraged by the announcement that react-native recently added support to macOS thanks to the guys at microsoft (facebook has now jumped on the bandwagon), so after a couple of months of development I have to call quits, there is just too much friction, I’m a one man team developing this on my freetime and I have rarely encountered so much problems developing a simple app.</p>

<p>React native promises this utopia, we’re you write once and gets executed everywhere, which is true when everything works, however when it doesn’t the pain starts, with the current jump into desktop environments there is a lot more friction than the more mature mobile counterparts.</p>



<p>I had assumed that despite it’s young age microsoft wouldn’t announce a “release” if the product was not ready, and I was willing to go the extra mile cutting slack here and there, ignoring the rough edges, I even patched some libraries myself, with my barely passable knowledge about the macOS toolchain, swift, obj-c and cocoapods, but I reached the point of break when trying to draw vector graphics.</p>

<p>Currently if you want to draw vector graphics on react-native the default choice is react-native-svg, surprise surprise it’s not supported on macos (or windows), support might come someday, but you are at the mercy of the react-native community until someone takes the time to port it to each platform, and let me tell you the react-native community does not have a great track record of producing well maintained software.</p>

<p>And this is a story that keeps repeating itself for me (and not only on macOS) I’ve been working with RN for some years now and everytime I reach the point where libraries are abandoned left and right, new functionality or patching requires deep knowledge of the platform and build systems.</p>

<p>Another current paint point React-navigation? you are stuck with version 2.X, which has no native dependencies and has been deprecated for years already, other libraries like camera, location, etc… you can forget them for a few months/years, it’s incredibly bold of microsoft to claim their “store” app is built with react-native, it’s basically a bunch of webviews cobled together, and it is basically a app that consists of some lists, if that is all your app will need, then you can safely use react-native on desktop.</p>



<p>Current windows and macos ports are being developed with the idea that all supported platforms should have 1 to 1 feature parity, this also includes behavior parity.</p>

<p>On the surface this sounds reasonable, <strong>it’s not</strong>, because mobile and desktop do not behave the same, the way you interact with an app using keyboard and mouse is not the same as with mobile, on desktop keyboard shortcut support is a must, being able to detect key combinations is a must, RN does not support any of this, even some of the default behavior with a digital keyboard does not translate well to physical machine, another thing is app lifecycle (focus/blur) are bound to different rules as on mobile</p>

<p>At best you will end up with an app that feels weird to use on desktop (UI not withstanding, just talking about UX here), so far my workaround has been to attach listeners on the native sides and transmit events to the rn side… you can imagine this is time consuming to get right, and sometimes you will just not get it right no matter what</p>

<h2 id="its-open-source">It’s open source!</h2>

<p>You want to patch this yourself? here are some of the problems in the order that I found them as I went along:</p>
<ul>
  <li>I barely learned Swift, I cannot justify learning obj-c, guess what rn is written in obj-c</li>
  <li>You have to learn the macOS specific APIs, most of the content in the internet is written for the iOS APIs</li>
  <li>Apple’s documentation is one of the worst I have seen so far</li>
  <li>You have to start digging into the more hardcore parts of the APIs, CoreGraphics?</li>
  <li>If somehow you manage to do all of that, repeat it for other platforms Android, Windows?</li>
  <li>Once you have your piece of native code you have to use the RN bridge, did you know it is also slow? now you have to do TurboModules, which is c++… also no (usable) documentation</li>
  <li>Oh yeah, add one more platform, react-native-web</li>
  <li>Don’t forget about each platform build system, I still don’t fully grasp everything Gradle does to build an Android app</li>
</ul>

<p>Now to be completely fair, some of these problems are not unique to react-native, the problem is… there is already a solution out there to run code on every architecture/machine that does not require you to learn a new API every 2 days or so, it’s called a web browser</p>



<p>As for react-native, besides the corporations with big pockets taking over the job the community is currently trying to fill, I see no good solution, the disparity of libraries, APIs, platforms makes this a really challenging problem to tackle in the typical OSS manner, and in the end, we are all re-creating chrome with a lesser memory footprint and some performance gains (which I still would debate)</p>

<p>As for my and my project I think the best path forward is web, I can still use react and the web APIs are good enough for what I need to do, electron gets a lot of flak for the size of installation and memory consumption, but chrome is an OS by itself, so much of this small details have been abstracted away and solved by a well paid cohesive team and with webassembly the possibilities are greater than ever, not saying it is perfect, but it sure beats holding your breath for the OSS community and a menage of companies/team (all with different incentives) to catch up</p>

<p>Creating shallow native apps that heavily use embedded webviews seems a good compromise when truly native functionality is needed, I remember I saw a couple of videos of the guys at basecamp, they have tiny native teams that only write small container apps but the bulk of the work is in the web and that can be reused inside the shallow containers, that seems to be the most reasonable thing (even if you have to learn the basic of each OS to create a container app, which you end up doing anyways with RN)</p>

  </div></div>]]>
            </description>
            <link>https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24038136</guid>
            <pubDate>Mon, 03 Aug 2020 14:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Email got us $5k in AWS Credits]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24037963">thread link</a>) | @CoreSet
<br/>
August 3, 2020 | https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits | <a href="https://web.archive.org/web/*/https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We recently went through the <a href="https://stripe.com/atlas">Stripe Atlas</a> program and <a href="https://formcake.com/blog/our-experience-with-stripe-atlas">loved it</a>.</p>
<p>But the one sour note was that we only got $1,000 AWS credits when <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">the copy seemed to promise $5,000</a>. Our <a href="https://formcake.com/blog/why-we-chose-a-marketing-and-app-monorepo">entire application infrastructure is on AWS</a> so those credits are pretty much straight-up cash to us. We don't have much of a digital footprint either, so $5,000 goes a long way.</p>
<p>That's why this weekend was such a surprise.</p>
<h3 id="the-email">The Email</h3>
<p>Here's how the timeline went.</p>
<ol>
<li><p>First <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">we posted an article</a> politely noticing that we hadn't been able to secure the full $5,000 and kinda wondering out loud why.</p>
</li>
<li><p><a href="https://formcake.com/blog/the-founders-guide-to-stripe-atlas">Stripe contacted us</a> and explained that the credit amount was more of a lifetime cap and that it was ultimately up to AWS what we got.</p>
</li>
<li><p>We send <em>one more</em> email just 'cause, even though it seems clear AWS only offers $1,000 for bootstrapped startups. The email is simple and amounts to: "Is there any way we could get the full five thousand in credits?"</p>
</li>
</ol>
<p>Stripe responds to this chain of events with yet another email, this one even kinder and more politely worded.</p>
<section>
Hey David,

<p>Thank you for sharing the details here. It sounds like we should be able to get this sorted out so that you receive the $5K in AWS credits for Stripe Atlas users.  </p>
<p>I believe it may be the case that you applied for AWS credits with a different link than the one shared for Stripe Atlas users to activate. We do not typically see users needing to answer the question regarding funding sources. I did check in with AWS on this and it sounds like they're currently processing your most recent application that you submitted through the Stripe Atlas link. They've let me know that they will email you directly with next steps, which may take up to 4 weeks. </p>
<p>Hopefully this will all soon be sorted! If you do have any questions on this or anything else, please feel free to reach out! I'll check back in a couple weeks on the AWS front, or feel free to share any updates as well!</p>
<p>Warm regards,
Taylor</p>
</section> 

<p>It looks like the funded/bootstrapped question indicated the process had gotten miffed somewhere and <em>Stripe reached out to AWS on our behalf</em> to make sure things got cleared up.</p>
<p>This weekend we saw $5,000 in credits enter our AWS account. Keep in mind that's actually <strong>in addition</strong> to the $1,000 we've already received, bringing out total up to $6,000 in AWS credits through the Stripe Atlas program.</p>
<p>For us this is a big injection. It basically funds our full application operations and lets us play around with putting money elsewhere - or just continuing to build features and mature without any kind of pressure.</p>
<h3 id="conclusion">Conclusion</h3>
<p>A couple of takeaways from the entire affair.</p>
<h4 id="1-send-that-one-last-email">1. Send that one last email</h4>
<p>Even if it seems like a bit much, or things are settled, just be sure you ask and give the other person a chance to help you in ways you can't predict. A hail mary "Is there anything I'm missing?" can sometimes land.</p>
<h4 id="2-stripe-is-truly-wonderful">2. Stripe is truly wonderful</h4>
<p>Stripe monitored the developer community enough to see our initial posts, proactively reached out to us, and then worked with AWS to ultimately get us a greater-than-even-promised payout. When people say Stripe is a company for developers, they often mean its great API or clear documentation, but this is I think one of the greatest testaments to their dev-first culture.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037963</guid>
            <pubDate>Mon, 03 Aug 2020 14:10:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Add video subtitles on the fly from plain text]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24037288">thread link</a>) | @011-video
<br/>
August 3, 2020 | https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/ | <a href="https://web.archive.org/web/*/https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2182">
	
	

	

	<div>
		<p><iframe title="How to Burn video subtitles on the fly from a plain text file" width="576" height="324" src="https://www.youtube.com/embed/voruErQe4JA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><em><strong>How to add permanent subtitles into video without using SRT file ?</strong></em></p>
<ol>
<li>
<h6>If you opt for a big font size make sure&nbsp; to choose a larger screen&nbsp; <img src="https://011.video/wp-content/uploads/2020/01/pixel.png" alt="">&nbsp; to display the whole phrase every time you turn the mouse wheel</h6>
</li>
<li>
<h6>Upload a video&nbsp; <img src="https://011.video/images/uploadV2.png" alt="">&nbsp; from your device</h6>
</li>
<li>
<h6>Copy subtitles from any text editor.</h6>
</li>
<li><span><em>Notice that to be processed as subtitles the text must start with&nbsp; a star&nbsp; ‘&nbsp; *&nbsp; ‘&nbsp; and each phrase must end with a punctuation character&nbsp; &nbsp;:&nbsp; &nbsp;‘&nbsp; !&nbsp; ‘&nbsp; &nbsp;or&nbsp; &nbsp;‘ ?&nbsp; ‘&nbsp; or&nbsp; ‘&nbsp; . ‘</em></span></li>
<li>
<h6>Double click inside the canvas. As you can only move the subtitles vertically make sure to click on the left far if your text got long phrases</h6>
</li>
<li>
<h6>paste the subtitles text&nbsp; <img src="https://011.video/images/text.gif"> inside the input text field</h6>
</li>
<li>
<h6>Change the text color&nbsp; <img src="https://011.video/wp-content/uploads/2019/10/color.png" alt="" width="207" height="22"></h6>
</li>
<li>
<h6>Click few times on&nbsp; <img src="https://011.video/wp-content/uploads/2019/09/effet.png" alt="" width="35" height="35">&nbsp; to make the text size bigger.</h6>
</li>
<li>
<h6>Start to record&nbsp; <img src="https://011.video/images/on2.png" alt="">&nbsp; &nbsp; your video</h6>
</li>
<li>
<h6>As soon as the video begin turn the mouse wheel&nbsp; <img src="https://011.video/images/mouse.png"> &nbsp;before the speech start and you should see the message “Ready to display… Turn wheel again “</h6>
</li>
<li>
<h6>Turn the mouse wheel and you should see&nbsp; “let’s Add subtitles” message displayed.</h6>
</li>
<li>
<h6>Continue to turn the mouse wheel to display each phrase on the fly, one by one.</h6>
</li>
<li>
<h6>To make the subtitles easier to read try to move the cursor vertically close to the video character who speak</h6>
</li>
<li>
<h6>When the speech is over pause&nbsp; <img src="https://011.video/images/pause.png" alt=""> and download <img src="https://011.video/images/d2.png" alt=""> your video</h6>
</li>
</ol>
<p><em>Here is a “French video clip song subtitled with English lyrics translation”</em></p>
<p><iframe title="French video clip song subtitled with English lyrics translation" width="576" height="324" src="https://www.youtube.com/embed/hDV0GrTlYSA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<!-- Rate my Post Plugin -->			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037288</guid>
            <pubDate>Mon, 03 Aug 2020 13:11:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LakeFS – atomic, versioned data lake on object storage]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037127">thread link</a>) | @pauldix
<br/>
August 3, 2020 | https://lakefs.io/2020/08/03/introducing-lakefs/ | <a href="https://web.archive.org/web/*/https://lakefs.io/2020/08/03/introducing-lakefs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1" itemtype="https://schema.org/CreativeWork" itemscope="itemscope"><div><div itemprop="text"><div><div><p><strong>TL;DR: </strong>we worked with an object-storage based data lake,  it’s an excellent data architecture but you have no systematic way of:</p><ul><li>Communicating between writers and readers (if you are thinking MetaStore as a solution, keep reading).</li><li>Avoiding the data Swamp everybody is warning you about.</li><li>Creating data pipelines that are resilient to changes in data and code</li></ul></div></div><p>We identified a way to provide a systematic solution for those pains by providing a data versioning schema over the data lake (if you are thinking Hudi or Delta lake, then no, we are not a format).</p><p><strong>The long version </strong>starts when we* finished a migration of our on-prem Hadoop clusters to AWS in mid 2017. Our architecture included a Kafka based ingest process of over hundreds of different sources, managed by the data collection group.  The data was saved to S3 and partitioned by arrival time. We had 4 different engineering groups on the consuming side:</p><ul><li><strong>Data science:</strong> converting raw data into estimations. The group consisted of data scientists, data engineering and DevOps teams to support a DAG of almost 1000 jobs running daily to produce our production data.</li><li><strong>Web application: </strong>mainly consuming the output of the data science group.</li><li><strong>Business intelligence:</strong> BI engineers and analysts, running counts on the amount of data we ingested by device, application, country, etc’,</li><li><strong>Professional services:</strong> analysts providing ad hoc reports to customers based on any data set that supports their analysis.</li></ul><p>We were happy. Finally throughput was not a problem, cost effectiveness of the storage (S3) was high, and with some <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance.html">tweaks on prefixes</a>, throughput on read was satisfactory.</p><p>In retrospect we still think we made the right choice with this architecture. Before the migration we were dealing with “this is not feasible” issues and afterwards transitioned to the “this is not manageable” kind. And when data is your product, “this is not manageable” means production issues due to error prone operations.</p><figure><img src="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png" alt="" width="819" height="461" srcset="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png 960w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-300x169.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-768x432.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-24x14.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-36x20.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-48x27.png 48w" sizes="(max-width: 819px) 100vw, 819px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png" data-srcset="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png 960w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-300x169.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-768x432.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-24x14.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-36x20.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-48x27.png 48w"><figcaption><em><span>Data Architecture </span></em></figcaption></figure><p>Here are some examples of the “this is not manageable” problem space:</p><h3>Fragile Writers and Readers: how to signal consumers the data is ready?</h3><p>Pain Point 1: The data science group starts running its <a href="https://airflow.apache.org/docs/stable/concepts.html#dags">DAG</a> only after data from several different sources (that were written independently) were complete. There’s no simple way for the writing teams to signal the completion of all writes to the reading teams. To work around this, we used time-based synchronization. At midnight, readers start consuming the data. Of course, this neglected late arrivals and in-flight writes. It was good enough most of the time, but a real pain when trying to reproduce results.</p><p>Pain Point 2: Consider the DAG of 1000 Spark jobs. Each job depends on several ancestor jobs’ output as its input. Basically the same as pain point #1, only with Airflow orchestrating a DAG of spark jobs. We used Spark SUCCESS files as a hook for Airflow. This doesn’t work in case the success file fails, or if for some reason someone intervenes manually.</p><p>Pain Point 3: In certain instances, correctness of the readers depends on a synchronization of several collections. For example, sometimes we needed the same data in two storage formats. ORC for AWS Athena, and Parquet for Spark. Another example: the professional services group have permission to access any data set serving their current ad hoc analysis. How do you make sure everything they access is synchronized to the same time/other parameters to maintain consistency? We used <a href="https://cwiki.apache.org/confluence/display/Hive/Home">Hive Metastore </a>as a workaround. Each write process updates the Metastore when completed, and the reader waiting on those inputs would wait until all updates were announced. In some cases it meant trading consistency for availability, but we weren’t the first to encounter this tradeoff :-).</p><p>A word about the workarounds: every time we introduce new data or analysis the solution needs to be implemented again. If you neglect to do so, you will suffer the consequences. There was no one systematic and easy solution for all these use-cases. In addition, each solution failed sometimes, causing a correctness issue later in the data pipeline.&nbsp;</p><h3>Data Swamp: how to ensure visibility and governance?</h3><p>Pain point 1: Many organizations avoid limiting data access using permissions as they want to democratize the data in the organization, and as long as regulation permits, allow data consumers to generate as much value as possible from the data. We hold this philosophy. The challenge is that there’s no systematic way to ensure isolation, i.e., to ensure no one changes the data while you’re using it. This is why copying is so common in object storage. The copy you create yourself usually has a very meaningful name, such as “Einat_final_final_V2”, or better yet “Prodcution_temp”. You don’t have lineage capabilities that indicate which data is behind that name, unless you enforce naming conventions…Good luck with that 🙂</p><p>Over time, your lake becomes a swamp, cost increases and you have no real control over your data from a compliance standpoint.</p><p>Pain point 2: If you are working to avoid the swamp, you’re probably running retention jobs to ensure stuff doesn’t get out of hand. Consider a home grown retention job running periodically over the lake. If it has a bug and  deletes valuable data, according to some logic it will start to spread across many collections. Although you have backups of all the objects in the lake,&nbsp; you don’t have a snapshot of the lake to revert to. Recovering fully from such an error may take weeks. Amazon’s S3 object-level versioning will not save you here.</p><h3>The need for Data CI/CD: how to ensure data quality?</h3><p>Pain point: Data is useless, unless it’s trustworthy. When your delivery is data, it is not enough to ensure the correctness of the code. It’s also critical to protect the properties of the data that you assumed you had when you developed the code. Now, remember the 1000 spark jobs orchestrated by Airflow that run every day?&nbsp; These run an algorithm, so each job includes assumptions on the data. If those assumptions are no longer valid, jobs may fail, or worse, the quality of the output data will decrease dramatically. Why is the second scenario worse? Because it’s harder to detect.&nbsp;</p><p>If we could run a job in isolation, test the results, and merge back automatically only after validating schema and data correctness, then it would be possible to identify issues earlier, putting us in a much better position to deliver quality data.</p><h3>We were thinking: Git interface with MVCC capabilities</h3><p>While each one of these challenges may have a workaround we can use, or a homegrown solution we can develop, there is no <strong><em>conceptual</em></strong> solution that simply makes the work manageable and hence resileant. We want a concept and a language that provides a solution for all of those challenges, and for the challenges that are yet to come.</p><p>On the one hand, database systems use transactions to provide systematic guarantees over the data. This is usually implemented using <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">Multi-Version Concurrency Control</a>.</p><p>On the other hand, there is a standard for code versioning. The Git terminology is a common language for developers to deal with versions of things. So we were thinking, if we build an MVCC management layer for Data Lakes, using a Git-like interface, we will have an intuitive way of getting the guarantees we want for our data lake, in the performance and reliability we need. The name “lakeFS” followed soon after.</p><h3>Introducing lakeFS: manageable and resilient data lake</h3><p><a href="http://www.lakefs.io/">lakeFS</a> is an open source platform that delivers resilience and manageability to your existing object-storage based data lake. With lakeFS you can build repeatable, atomic and versioned data lake operations – from complex ETL jobs to data science and analytics.</p><figure><img src="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png" alt="" width="743" height="258" srcset="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png 1024w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-300x104.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-768x267.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-24x8.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-36x12.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-48x17.png 48w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05.png 1161w" sizes="(max-width: 743px) 100vw, 743px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png" data-srcset="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png 1024w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-300x104.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-768x267.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-24x8.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-36x12.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-48x17.png 48w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05.png 1161w"><figcaption><em><span>Resilience and manageability layer for object-storage based data lakes</span></em></figcaption></figure><p>Main features include:</p><ul><li><strong>Cross-Lake Isolation </strong>– Creating a lakeFS branch provides you with a snapshot of the entire lake at a given point in time (no copying involved). Guaranteeing that all reads from that branch will always return the same results.</li><li><strong>Object-level Consistency</strong> – Ensuring all operations within a branch are strongly consistent (read-after-write, list-after-write, read-after-delete, etc).</li><li><strong>Cross-collection Consistency</strong> – Branches provide writers consistency guarantees across different logical collections. Merging to “main” is only done after several datasets are created successfully.</li><li><strong>Versioning</strong> – Retain commits for a configurable duration, so readers can query data from the latest commit or any other point in time. Writers can atomically and safely rollback changes to previous versions.</li><li><strong>Data CI/CD</strong> – Define automated rules and tests mandatory to pass before committing or merging changes to data.</li></ul><p><span><a href="http://docs.lakefs.io/">Try it out</a>!  It will solve the challenges you have now, and will prevent you from running into undesired issues in the future. </span></p><p><em>* referring to the amazing R&amp;D team at <a href="https://www.similarweb.com/">SimilarWeb</a></em>. <em>We are proud to have been a part of before embarking on the lakeFS adventure</em></p></div><!-- .entry-content .clear --></div></article></div>]]>
            </description>
            <link>https://lakefs.io/2020/08/03/introducing-lakefs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037127</guid>
            <pubDate>Mon, 03 Aug 2020 12:56:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analytics couldn’t get past 2013, it’s time to change that- A Manifesto]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036653">thread link</a>) | @hockeystack
<br/>
August 3, 2020 | https://hockeystack.com/manifesto | <a href="https://web.archive.org/web/*/https://hockeystack.com/manifesto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hey founders,</p><p>I am sorry to talk harsh but someone&nbsp;<b>had</b>&nbsp;to do it.</p><p>We are hustlers. We love freedom and passionate about our businesses.</p><p>We are doing everything we can to solve a problem, make people happy, and earn their trust.</p><p>We are in this to <b>make a difference</b>, to <b>leave a legacy behind</b>, and <b>to be happy</b>.</p><p>Thanks to our businesses, thousands of people are solving a problem, a problem that has been a pain point before us.</p><p>I am so grateful for this amazing community, to the things I learned from it, and to the friends I made.</p><p>To grow our businesses we hustle a lot which is invaluable from my perspective.</p><p>Aside from all the hustle, we have to use analytics to grow and scale our businesses. But the world of user analytics is built upon false premises and unfullfilled assurances my hustler friends:</p><p><b>Hey google analytics users,</b> it’s 2020 and you still need to manually ga(‘send’) everything</p><p><b>Hey fathom/plausible/simple-analytics users</b>, it’s 2020 and you can only see your referrers on your dashboard</p><p><b>Hey everyone who needs analytics,</b> it’s 2020 and you still have to do everything manually. The tools you pay for don’t give you enough data or make you work for it. The tools you don’t pay for harvest each data point and send it to 3rd parties.</p><p>Huh, in the age of artificial intelligence and literal flying cars, Mixpanel can still write that 10-30 hours of development time to track 60 events is a huge achievement, and funnily, get away with it.</p><p>HockeyStack is an analytics tool <b>delivered to you by another hustler</b> who struggled to understand his data with other tools. Let me tell you the differences between other tools and HockeyStack in two parts:</p><p>HockeyStack is different from simple data tools because they don't analyze your data <b>in-depth</b>. It is the main reason why they call themselves 'simple'.</p><p>On the other hand, we call our dashboard <b>easy to understand</b> because we present an in-depth analysis of your data on an easy-to-understand dashboard.</p><p>Tools like Mixpanel, Hotjar are great. However, you need to set up .track() functions and need coding skills to analyze your data.</p><p>Then you also need to spend a lot of time on your dashboard to understand what is going on there.</p><p>I hope you find HockeyStack useful and each one of you can achieve the <b>surging growth</b> with it.</p><p>Greetings to all hustlers,</p><p><em>Michael</em></p><p><a href="https://hockeystack.com/">Get Started</a></p></div></div>]]>
            </description>
            <link>https://hockeystack.com/manifesto</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036653</guid>
            <pubDate>Mon, 03 Aug 2020 12:08:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dan Ariely and Irrational Comparison]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24036403">thread link</a>) | @brendancahill
<br/>
August 3, 2020 | https://brendancahill.io/brensblog/danariely | <a href="https://web.archive.org/web/*/https://brendancahill.io/brensblog/danariely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-124866fbd20ff6e682de"><div><h4>Who is Dan Ariely?</h4><p>Dan Ariely is a Professor of Psychology and Behavioral Economics at Duke University whose writing merges psychology with economics. His book <a href="https://amzn.to/33pw3lh"><em>Predictably Irrational</em></a> explores why most of the smart decisions we think we make are actually quite irrational. Modern economics is based on the theory that the average person makes logical decisions. Ariely happily points out how wrong that notion is. </p><h4>Why Now?</h4><p>Comparison has always fascinated me. I grew up in Airmont, NY two minutes over the state line with Upper Saddle River, NJ. Since I didn’t like paying .50 more cents for gas, nor pumping it, I always got gas in NJ. Upper Saddle River is one of the wealthiest towns not only in America, but on the planet. The second you crossed the NY/NJ line it was like you were transported into an alternate reality where the worst car anyone drove was a BMW, every home a mansion and even the air smelled better (just kidding but I did wonder, if any town had the money to endlessly pump fabreeze into the air, they did). </p><p>When I crossed the NY/NJ state line back to my neighborhood of 3 bedroom raised ranches I felt poor by comparison. Then as a US Peace Corps Volunteer living in Ukraine in an ex-Soviet country, ridden with corruption, and the average salary being less than $100/mo I suddenly felt rich. Ukrainians were shocked that we owned two cars. That we had roads that worked. And that everyone was rich <em>to them. </em></p><h4>Why Comparison?</h4></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596450590223_8104"><div><p>Ariely uses this illustration to make his point about comparison. Which orange circle <em>appears</em> bigger? You’d likely say the one on the right, at least at first. But, both circles are the same size. The only thing that’s changed is what you’re comparing them to. Comparison depends on context. </p><blockquote><p>“…we are always looking at the things around us in relation to others…We always compare jobs with jobs, vacations with vacations, lovers with lovers and wines with wines.”</p></blockquote><p>Comparison is a survival skill that’s served us well our first 50 million years as a species: You need to know your status in the tribe compared to others’ to ensure your own safety. You need to compare how deadly a particular tiger looks compared to other live tigers you’ve seen in wild to assess your threat level. You need to compare how someone looks to other angry people you’ve seen to avoid a bar fight. You need to compare a date to other people you’ve dated in the past to evaluate how they might be as a future spouse for you. You need to know how to compare how fast your car is going relative to all the other cars on the street to stay within the speed limit. </p><p><strong>Comparison does hijack our rationality, however. </strong></p><h4>The Economist</h4><p>Ariely was trying to figure out what decision people made when given these three options for a subscription to <em>The Economist</em>: </p><ul data-rte-list="default"><li><p>59/yr online only</p></li><li><p>125/yr print only</p></li><li><p>125/yr print and online together</p></li></ul><p>Out of 100 people here is how many chose which options:</p><ul data-rte-list="default"><li><p>59/yr online only (16)</p></li><li><p>125/yr print only (0)</p></li><li><p>125/yr print and online together (84)</p></li></ul><p>But, when Ariely removed the print only option, here is what people chose:</p><ul data-rte-list="default"><li><p>59/yr online only (68)</p></li><li><p>125/yr print and online together (32)</p></li></ul><p><em>As a business, you want to nudge as many people to the high-end of your sales as possible. So why were people opting for the online only? </em></p><p>It turns out it is easier to compare things that are alike than are not alike. By presenting people with not one but <em>two</em> print options, you’ve now made it easier for them to compare two options that you, as a business, want them to focus on. The mind has now written-off the online only option because that is the hardest option to compare to the other two. </p><p>Inside the mind of your potential customer is now a simple question: What’s better? Print only or print AND an online subscription? Everyone in the first experiment opted for the “print + online” because isn’t print plus a little something extra better? </p><p><strong>We Can’t Make Decisions In A Vacuum</strong></p><p>The second case study Ariely looks at is <a href="https://journals.sagepub.com/doi/pdf/10.2307/41166755">Williams-Sonoma’s inability to sell a $275.00 bread baker</a>. Their marketing team finally figured out that if they created a second, bigger and even more expensive bread baker placed <em>next to</em> the $275.00 dollar one, their sales would take off. And they did. </p><blockquote><p>“…people didn’t have to make their decision in a vacuum. They could say: “Well, I don’t know much about bread makers, but I do know that if I were to buy one, I’d rather have the smaller one for less money.”</p></blockquote><p>Ariely then goes on to joke that if you want to have better luck socially finding someone to date you, you should find a decoy friend of similar physical characteristics but who is slightly less attractive than you. Although the morality of this is questionable. </p><p>If you are a business, the takeaway is simple: to make more profit, create a favorable context for the product you want your customer to buy. Create an ultra-premium ridiculously high-priced product that when placed next to the product you really want to sell, makes its price not seem so bad. </p><p>Tesla knows not everyone is paying $100K + for their Cyber Truck, but they do know that by having their ridiculous premium products, it makes the $60K price tag for their “lower models” not seem so crazy. </p><p><strong>Place vs. Person</strong></p><p>I have some of the best friendships I’ve had from my former football teammates. We go through experiences, games, high and lows like few others friend groups might. But would we all have been friends were it not for football? How about military veterans who are bonded together in combat - were it not for that experience, would they have chosen to be friends? </p><p>Ariely uses the example of meeting a fellow American in a foreign place and finding an uncanny connection in an airport. He met one fellow American overseas:</p><blockquote><p>…as cultural outsiders we were each other’s best alternative for companionships. But once we returned home to our beloved American families and friends, thebasis for comparison switched back to “normal” mode. </p></blockquote><p>Would that foreign exchange student you dates in high school have been as “cool” or “exotic” had they been from Germantown, PA instead of Germany? Was that experience teaching overseas in Peace Corps really <em>that</em> cool or am I just assigning extra romanticism to it because I was an “outsider” in a foreign land?</p><h4>Takeaways</h4><p>We’re very smart, but we’re also very irrational as people. We’d like to think logic and rationality governs most of our lives but Ariely has a knack for showing us just how reliant we are upon split second and irrational comparisons to the available yet limited information we have around us. </p><p>Morally speaking, as a business owner or person you have a duty to make decisions now with this comparison fallability in mind. While yes, you can structure your products in a way to extract <em>more</em> profit than normal from your customers, you need to do this only when you truly feel like that high-end product you’re directing them to is actually giving them more value. </p><p>Personally, don’t find the most repulsive personality to take out on a double date hoping that it makes you look good. This might even back fire since your double date might end up <em>comparing you</em> to the company you hang out with and irrationally judge you just as repulsive. </p><p>Comparison is a force of nature that can’t always be controlled, but it can be guided. Ariely shows us how. </p><p>Bren</p><p>P.S. Here is a fun video by Dan at a Ted Talk</p></div></div></div>]]>
            </description>
            <link>https://brendancahill.io/brensblog/danariely</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036403</guid>
            <pubDate>Mon, 03 Aug 2020 11:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL beginner guide]]>
            </title>
            <description>
<![CDATA[
Score 232 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24036132">thread link</a>) | @lukasbar
<br/>
August 3, 2020 | https://knowledgepill.it/posts/postgresql-basics-guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql-basics-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2 id="configure-remote-access---listen-address">Configure remote access - listen address</h2>
<p>By default after installation and creating database cluster PostgreSQL will listen only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP’s available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>##------------------------------------------------------------------------------</span>
<span>## CONNECTIONS AND AUTHENTICATION</span>
<span>##------------------------------------------------------------------------------</span>

<span>## - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span>## what IP address(es) to listen on;</span>
                                        <span>## comma-separated list of addresses;</span>
                                        <span>## defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span>## systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div><h2 id="configure-remote-access---pg_hbaconf">Configure remote access - pg_hba.conf</h2>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span>## TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span>## "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span>## IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span>## IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don’t want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h3 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h3>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span>## Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div><h2 id="connecting-to-postgresql">Connecting to PostgreSQL</h2>
<h3 id="local-from-server">Local from server</h3>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h3 id="remote-machine">Remote machine</h3>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span><span>##</span>
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h3 id="check-connected-database">Check connected database</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-current-user">Check current user</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-postgresql-version">Check PostgreSQL version</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-connection-info">Check connection info</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div><h2 id="executing-commands-from-shell">Executing commands from shell</h2>
<h3 id="execute-single-command-from-shell">Execute single command from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="exacute-sql-script-from-shell">Exacute sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h3 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>
<h3 id="check-all-available-metacommands">Check all available metacommands</h3>
<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h3 id="list-objects-in-psql">List objects in psql</h3>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql-basics-guide/">https://knowledgepill.it/posts/postgresql-basics-guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql-basics-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036132</guid>
            <pubDate>Mon, 03 Aug 2020 10:40:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX of Lego Interface Panels]]>
            </title>
            <description>
<![CDATA[
Score 334 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24035866">thread link</a>) | @george_cave
<br/>
August 3, 2020 | https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/ | <a href="https://web.archive.org/web/*/https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

   
   <time>August 2020</time>

   

   

   <p>Piloting an <a href="https://www.lego.com/en-de/product/ocean-exploration-ship-60266">ocean exploration ship</a> or <a href="https://www.lego.com/en-de/product/mars-research-shuttle-60226">Martian research shuttle</a> is serious business. Let’s hope the control panel is up to scratch. Two studs wide and angled at 45°, the ubiquitous “2x2 decorated slope” is a LEGO minifigure’s interface to the world.</p>

<p>These iconic, low-resolution designs are the perfect tool to learn the basics of physical interface design. Armed with 52 different bricks, let’s see what they can teach us about the design, layout and organisation of complex interfaces.</p>

<p>Welcome to the world of LEGO UX design.</p>

<p><img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/interfaces.jpg" alt="LEGO interfaces"></p>

<h2 id="organised-chaos">Organised chaos</h2>

<p>At a glance, the variety of these designs can be overwhelming, but it’s clear that some of these interfaces look far more chaotic than others. Most interfaces in our world contain a blend of digital screens and analog inputs like switches and dials. These LEGO panels are no different.</p>

<p>Plotting the panels across these two axes reveals a few different clusters. Screens with an accompanying row of buttons sit in the top left. A small cluster of very organised switch panels lies to the far right. The centre bottom is occupied by some wild concepts that are hard to understand, even after several glances.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/positioning.jpg" alt="Design positioning with LEGO, in LEGO">
    <figcaption>Design positioning with LEGO, in LEGO</figcaption>
  </figure>

<p>Designing a complex machine interface is a juggling act of many different factors from ergonomics to engineering. But we can break down the problem into two key questions:</p>

<ol>
  <li>How can we <em>differentiate</em> between the function of different inputs?</li>
  <li>How can we <em>organise</em> the many inputs and outputs so that we understand how they relate to each other?</li>
</ol>

<p>Let’s take a deeper look at tackling these two challenges in LEGO.</p>

<h2 id="differentiating-inputs">Differentiating inputs</h2>

<p>What could cause 400 WWII pilots to raise the landing gear on their B-17 bomber just before touchdown? Catastrophic pilot error, or something more fundamental?</p>

<p>It was the psychologist Alphonsis Chapanis who first suggested that the high rate of crash landings might be the fault of poor interface design. The adjacent landing gear and flap control knobs were identically shaped. The pilots never stood a chance.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/landing.jpg" alt="B-17 belly landing, and the shape coding that helped to irradiate the problem. Source: Wikipedia">
    <figcaption>B-17 belly landing, and the shape coding that helped to irradiate the problem. Source: Wikipedia</figcaption>
  </figure>

<p>His temporary solution was to glue differently shaped strips of rubber to each switch, enabling blind operation by touch alone. This gave rise to the idea of shape coding and a system of differentiation still being followed in aircraft cockpits today.</p>

<p>We can compare the three interfaces below to see this in action. Ignore the overall layout, it’s the differences between individual switches that matter here. Imagine trying to feel for one of these buttons without looking. The left panel (“Slope 45 2 x 2 with 12 Buttons”) would require careful hand-eye co-ordination. The right panel (“Aircraft Multiple Flight Controls”) clearly distinguishes between the throttle (large, linear vertical movement), toggle switches (round vertical flick) and the push buttons (square push-in).</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/differentiation.jpg" alt="Left to right: terrible, poor and better input differentiation">
    <figcaption>Left to right: terrible, poor and better input differentiation</figcaption>
  </figure>

<p>Differentiation like this is a still a very real problem today. In 2015, <a href="https://money.cnn.com/2015/01/06/autos/ford-push-button-ignition-recall/index.html">Ford recalled 13,500 Lincoln SUVs</a> because drivers speeding down the motorway were mistakenly shutting off the engine when they tried to activate sport mode. See if you can spot why:</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/ford-lincoln.jpg" alt="Ford Lincoln MKC before the Engine start/stop button was moved. Source: CNN">
    <figcaption>Ford Lincoln MKC before the Engine start/stop button was moved. Source: CNN</figcaption>
  </figure>

<p>Shape coding is one approach to differentiation, but there are many others. Colour coding is perhaps the only one to break into our everyday vocabulary, but we can add four more: size, texture, position and operation coding. Together these six are our allies in the design of error-proof interfaces.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/codings.jpg" alt="The 6 basic codings. Notice that many of these examples actually combine multiple codings in one.">
    <figcaption>The 6 basic codings. Notice that many of these examples actually combine multiple codings in one.</figcaption>
  </figure>

<p>Size, shape and colour-coding are the fundamentals: quick-wins that can fix a lot of interface problems. Texture is also a great differentiator for blind operation, particularly on small dials requiring precise control.</p>

<p>Position-coding is seemingly straightforward but is often under used. Products with a clear default ergonomic position (like binoculars or a gaming console) can exploit the natural position of the hand to differentiate between primary and secondary actions.</p>

<p>Finally, operation-coding ascribes different types of movements (like a twist or vertical slide) to different inputs. This can be immensely powerful when the switch motion reinforces the operation behind it, e.g. a crane lever which raises the crane when the lever is raised.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/lego-codings.jpg" alt="The six different codings in use in the LEGO interfaces: size, shape, colour, texture, position, operation">
    <figcaption>The six different codings in use in the LEGO interfaces: size, shape, colour, texture, position, operation</figcaption>
  </figure>

<p>Differentiation is a good first step that will avoid confusion between adjacent switches. But its only with organisation that we can create a clear and accurate mental model of the interface for the user.</p>

<h2 id="organising-inputs">Organising inputs</h2>

<p>Compare the three panels below. Identical layouts, but the blue one is much clearer than the white. This is the <a href="https://www.usertesting.com/blog/gestalt-principles">gestalt principles</a> at work, identifying related items with a common region.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/gestalt.jpg" alt="Basic differentiation by clustering">
    <figcaption>Basic differentiation by clustering</figcaption>
  </figure>

<p>Easy. But how are you going to decide which inputs to cluster together?</p>

<p>I like to use <a href="http://blog.presentandcorrect.com/27986-2">Soviet control panels</a> as a starting point. These beautiful walls of nonsensical dials and levers are brought to life when arranged in a giant factory schematic.  It would be hard to find a more literal organisation of the information.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/soviet-control-panels.jpg" alt="Soviet control panels in action. Source: Present and Correct">
    <figcaption>Soviet control panels in action. Source: Present and Correct</figcaption>
  </figure>

<p>These panels are what I’d called a consolidated interface. Every piece of input and feedback has been moved onto the same panel. This is the approach that <a href="https://www.thedrive.com/news/33847/the-defunct-dyson-evs-steering-wheel-looks-like-it-was-made-by-vacuum-cleaner-people">Dyson took with their car</a>. Now imagine the opposite, moving each of those lights and switches to the actual location of that valve in the factory. Sounds ludicrous, but these <a href="https://deeptread.com/blog/2016/11/21/audi-tt-air-vent-design">air vents in the Audi TT</a> show that this distributed approach can also be a great win for user experience. I wrote a lot more about these <a href="https://www.designedbycave.co.uk/2018/Interfaces/">distributed interfaces last year</a>.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/distributed.jpg" alt="Lego vehicle dashboard: distributed (left) vs. consolidated (right)">
    <figcaption>Lego vehicle dashboard: distributed (left) vs. consolidated (right)</figcaption>
  </figure>

<p>Back to the Soviet factories. Those interface panels were great for answering the question “does this valve let water into tank Б?”. But they’re very poor for answering “are all water valves closed?” or “where are all the switches I need to prepare for the shift changeover?”.</p>

<p>LEGO use the Soviet schematic approach for their <a href="https://www.bricklink.com/catalogItemIn.asp?P=3298pb005&amp;in=S">fantasy</a> <a href="https://www.bricklink.com/catalogItemIn.asp?P=3298px10&amp;in=S">orientated</a> designs, because schematics are superb at providing a mental model of the inner workings of an alien system. However for everyday use, there are some other approaches that work better.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/alien-interfaces.jpg" alt="LEGO Insectoid and UFO interfaces. I wonder what these buttons actually do?">
    <figcaption>LEGO Insectoid and UFO interfaces. I wonder what these buttons actually do?</figcaption>
  </figure>

<p><strong>Feature</strong> based organisation is the most common, perhaps even the “default” design philosophy. Group together all the inputs and outputs for each product feature. This <a href="https://www.cambridgeconsultants.com/press-releases/building-life-saving-ventilator-lightning-speed">COVID-19 ventilator from Cambridge Consultants</a> is a wonderful example but we also see this a lot in cars, with a cluster of switches for the airflow control and all of the lights on one control stick.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/covid-ventilator.jpg" alt="COVID-19 ventilator by Cambridge Consultants with clear feature-based organisation. Source: Cambridge Consultants">
    <figcaption>COVID-19 ventilator by Cambridge Consultants with clear feature-based organisation. Source: Cambridge Consultants</figcaption>
  </figure>

<p>Organising by <strong>operation</strong> means putting all the switches that function in a certain way in the same place. I’ve no idea what all the valves in the picture below do, but I bet they don’t all open things that relate to each other. Anytime you see a row of switches that look and function the same, but control disparate parts of the system, you’ve come across organisation by operation.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/valves.jpg" alt="Source: Twitter @aglushko">
    <figcaption>Source: Twitter @aglushko</figcaption>
  </figure>

<p>Today most interfaces are effectively <a href="https://en.wikipedia.org/wiki/Fly-by-wire">fly-by-wire</a>, but historically the levers that you pulled in, say, a tractor cabin would literally move the hydraulic pistons beneath the seat to a new position. Routing all these different electrical, mechanical and hydraulic systems efficiently can severely compromise your interface clustering, leading to organisation by <strong>technology</strong>.</p>

<p>The modern equivalent of this is surprisingly common. Any touchscreen with buttons by the side exhibits this technology-based split. In a <a href="https://www.chrisharrison.net/index.php/Research/PneumaticDisplays">future</a> <a href="https://vimeo.com/343640141">world</a>, SpaceX might embed <a href="https://www.space.com/spacex-crew-dragon-touchscreen-astronaut-thoughts.html">these physical controls</a> right inside the screen next to the information they affect, but for now they sit awkwardly by the side as if nothing is wrong.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/spacex-dragon.jpg" alt="Bob and Doug in the SpaceX Dragon capsule. Source: SpaceX">
    <figcaption>Bob and Doug in the SpaceX Dragon capsule. Source: SpaceX</figcaption>
  </figure>

<p>In LEGO we find the feature based organisation in the “Monitor with -19° pattern”. Two clear clusters, perhaps one for temperature control and another for vital signs monitoring. In the second panel below, I don’t know what all those switches do, but they seem to be clustered based on their operation, not because of what they will operate.</p>

<p>There are many LEGO panels with a technology split like the SpaceX Dragon capsule, but I like to imagine that this early 90s police control unit was forced to divide the audio and video playback because the newer tape reel technology was incompatible with the older analog phone line system. This is organisation by technology in action.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/organisation.jpg" alt="L-to-R: organisation by feature, operation, technology and use case">
    <figcaption>L-to-R: organisation by feature, operation, technology and use case</figcaption>
  </figure>

<p>All of our approaches so far: organisation by features, operation or technology, have been grounded in properties of the system, not of the user. Organisation by <strong>use-case</strong> is the antidote to this, a clustering based on the daily routines and tasks of the user.</p>

<p>Imagine arriving for work each day at the LEGO body scanner factory. Grouping the switches by task (prepare machine, load body, process scan…) would mean splitting up the radiation and scanner buttons into many different regions. More complex for the computer, but more streamlined for the operator. As the designer, only you and your users will be the judge of what works best.</p>

<h2 id="but-george-which-is-the-best-interface">But George, which is the best interface?</h2>

<p>I often say there’s no such thing as the best interface, but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/">https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/</a></em></p>]]>
            </description>
            <link>https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035866</guid>
            <pubDate>Mon, 03 Aug 2020 09:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive JavaScript Slide Rule]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24035379">thread link</a>) | @lebski88
<br/>
August 3, 2020 | https://adit.co.uk/sliderulev2.html | <a href="https://web.archive.org/web/*/https://adit.co.uk/sliderulev2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="dvText">
        <p>
            The rule cursor and central slide can be positioned using a mouse. Fine adjustment can be achieved using the keyboard left and right arrow buttons.
            The keyboard keys move the cursor or slide depending upon which had last been clicked or adjusted.
        </p>
        <p>
            The left hand display below the rule (“A on B” etc) shows the slide position. The central display shows the cursor position over each of the slide scales.
        </p>
        <p>
            Why is the cursor window a bit yellow? To find out, <a href="https://javascriptfunandgames.blogspot.com/2020/06/my-interactive-slide-rule.html" target="_blank">check my blog where some of the design decisions</a> that went into constructing this rule are described. Thats also
            a good place to comment if you come across any gross bugs (bugs are likely of course but so are edge cases that maybe should be treated kindly).
        </p>
        <h3>The Calculator</h3>
        <p>
            You can try using the virtual calculator just like a normal one although the choice of functions and the absence of plus and minus buttons might be a 
            little eccentric. Please remember though that calculations performed on a slide rule will not always be as accurate as those performed on an electronic 
            calculator. Results can and will differ.
        </p>
        <p>
            You can enter values using the “buttons” or from your keyboard (including the numeric keypad if “Num Lock” is set. The sum is executed by the virtual 
            slide rule and the result read back from the slide rule. The division function is executed in two stages with a 1.5 second delay between them. 
            An experienced slide rule user would probably skip the second stage as the result can be read from the end of the slider.
        </p>
        <p>
            You can calculate the tangent of angles (in degrees) between 6° and 84°. The S (sine) scale is also used to calculate cosines – both in the range 1° to 90°.
        </p>
        <h3>Background</h3>
        <p>
            I was looking through some bits and bobs that came from a draw in my Father’s house when it was being cleared for sale.
            One of the items was a slide rule and it was found alongside the early “Sinclair Executive” calculator that replaced it.
            It is small (nominally 6" probably) and pretty similar to the one I remember buying with my first student grant money in
            the very late 1960s when they were still pretty much the state of the art for calculators. Around that time though, I did
            come into contact with an <a href="https://en.wikipedia.org/wiki/Sumlock_ANITA_calculator" target="_blank">electronic Anita calculator</a> but they were staggeringly expensive and you could hardly slip one
            in your pocket or even carry one very far.
        </p>
        <p>
            The Sinclair Executive calculator came out in 1972 and cost £79.95 (over £1000 in 2020 money) and I probably paid £5 or £6 for the
            slide rule three or four years before that (still an appreciable cost that needed some internal debate to justify).
        </p>
        <p>
            The slide rule was invented sometime between 1620 and 1630 with new functions developed and added over time until the device became the tool
            of choice for the developing field of engineering.
        </p>
        <p>
            How do they work? It is pretty easy to see how two rulers could be used to do simple addition and subtraction. We can try adding 3 and 8.
        </p>
        <p><img src="https://adit.co.uk/Images/add3to8.png"></p><p>
            We position the start on the lower ruler’s scale at one of the two values (in this case 3) and read off the sum of 3 and 8 on the scale of the upper ruler (see the red line).
            It should also be obvious that the same positioning could be used to calculate 11 minus 8 or any other pair of values on the two ruler scales.
        </p>
        <div><p>
            Now such a simple mechanical device for adding two numbers together would not be terribly useful even if they were decimal fractions such as 3.4 and 8.7
            which would be easy to do with the rulers shown above. However being able to multiply (say) 1.65 by 3.45 would be more challenging mental arithmetic for most.
            When I was at school, we used logarithms for such calculations.
            </p><p>
            The logarithm (base 10) of a number is the number expressed as a power of 10.
            </p><p>
            1.65 = 10<sup>0.2175</sup>  so log(1.65) = 0.2175
            <br>
            3.45 = 10<sup>0.5378</sup> so log(3.45) = 0.5378
            <br>
            0.5378 + 0.2175 = 0.7553 (sum the logs)
            <br>
            10<sup>0.7553</sup> = 5.6925 which is the product of 1.65 and 3.45.
            </p><p>
            Thus simple addition can be used to multiply two decimal fractions expressed as logarithms.
        </p></div>
        <p>
            Fortunately, when I was at school, we did not need to calculate these powers of 10 – we were issued with books of tables for looking them up. 
            The tables included a host of trigonometric tables as well as the vital “antilogarithms” needed to establish that 10<sup>0.7553</sup> was 5.69 
            (which was about as accurate as the ones I had could get.
        </p>
        <p>
            If instead of having pages of tables we were to draw a logarithmic scale on a pair or rulers instead of the linear scale illustrated above we could 
            use them to multiply two values by adding the logs. Indeed we could also do division by subtracting one logarithmic scale position from another. 
            So, what does a logarithmic scale look like in action?
        </p>
        <p><img src="https://adit.co.uk/Images/logRules.png"></p><p>
            You will notice that as the values increase (from 1 to 10 in this instance) the distance between the log of those values decreases. 
            You can probably also see that two rules with logarithmic scales can be used to make our calculation (1.65 x 3.45). Slide rules were fast and accurate enough for most purposes.
        </p>
        <p>
            Why does the log scale start at 1? Well ten to the power of zero is 1 and zero is a good place to start. In fact any number to the power of zero is 1.
        </p>
    </div></div>]]>
            </description>
            <link>https://adit.co.uk/sliderulev2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035379</guid>
            <pubDate>Mon, 03 Aug 2020 08:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[United Airlines Plans to Resume Service on More Than 25 International Routes]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24035215">thread link</a>) | @cockpitherald
<br/>
August 3, 2020 | https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-scaled.jpeg" data-caption="United Airlines today announced it plans to resume service on nearly 30 international routes in September, including flights to Asia, India, Australia, Israel and Latin America and to continue to add ways to visit popular vacation destinations in the Caribbean, Hawaii and Mexico. 

Photo: United Airlines"><img width="696" height="463" src="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-696x463.jpeg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-696x463.jpeg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-300x200.jpeg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1024x682.jpeg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-768x511.jpeg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1536x1022.jpeg 1536w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-2048x1363.jpeg 2048w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1068x711.jpeg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1920x1278.jpeg 1920w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-631x420.jpeg 631w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="United Airlines Boeing 777-300"></a><figcaption>United Airlines today announced it plans to resume service on nearly 30 international routes in September, including flights to Asia, India, Australia, Israel and Latin America and to continue to add ways to visit popular vacation destinations in the Caribbean, Hawaii and Mexico. 

Photo: United Airlines</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p>United Airlines today announced it plans to resume service on nearly 30 international routes in September, including flights to Asia, India, Australia, Israel and Latin America and to continue to add ways to visit popular vacation destinations in the Caribbean, Hawaii and Mexico. The <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">airline</a> intends to fly 37% of its overall schedule in September as compared to the same period last year and is a 4% increase in capacity compared to what is planned for August 2020. United is also extending its waiver of change fees and award redeposit fees for reservations through August 31.&nbsp;</p>



<p>“We continue to be realistic in our approach to building back our international and domestic schedules by closely monitoring customer demand and flying where people want to go,” said Patrick Quayle, United’s vice president of International Network and Alliances. “In September, we’re adding even more options for leisure travelers or those who want to visit friends and relatives, whether that’s within the United States or around the world.”&nbsp;</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p>Domestically, United intends to fly 40% of its schedule. The airline plans to add more than 40 daily flights on 48 routes to locations including Austin, Texas; Colorado Springs, Colorado; and Santa Barbara, California. Additionally, United plans to resume service between the U.S. mainland and Hilo and Kauai and increase flying to Honolulu, Kona and Maui in the Hawaiian Islands.</p>



<p>Internationally, <a href="https://hub.united.com/2020-07-31-united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september-2646851493.html" target="_blank" aria-label="United  (opens in a new tab)" rel="noreferrer noopener">United </a>intends to fly 30% of its schedule as compared to September 2019, which is a 5-point increase compared to August. The airline expects to resume service on 20 routes in Latin America and the Caribbean, including to popular vacation destinations like Cabo San Lucas and Puerto Vallarta in Mexico and to San Jose and Liberia in Costa Rica. United intends to begin new nonstop service between Chicago and Tel Aviv and resume eight routes in the Atlantic and Pacific, including the return of European service from Houston with flights to Amsterdam and Frankfurt.</p>



<p><strong>U.S. Domestic&nbsp;</strong></p>



<p>Travelers in search of more socially distant vacation options like beach, mountain and national park destinations will continue to see opportunities for leisure travel including:&nbsp;</p>



<ul><li>Increasing opportunities to connect to more than 800 flights from United’s mid-continental hubs in Chicago, Denver and Houston.&nbsp;</li><li>Adding more than 40 daily flights on more than 48 routes across the United States.&nbsp;</li><li>Resuming service between the U.S. mainland and Hilo and Kauai in Hawaii&nbsp;</li><li>Increasing service between the U.S. mainland and Honolulu, Kona and Maui.</li></ul>



<p><strong>Atlantic</strong></p>



<p>Internationally, United is scheduled to fly 30% of its schedule in September compared to the same period in 2019. Across the Atlantic, United plans to offer customers more opportunities to get to Europe and beyond from Chicago, Houston, New York/Newark, and San Francisco. Highlights include:&nbsp;</p>



<ul><li>Launching brand-new service between Chicago and Tel Aviv&nbsp;<em>(subject to government approval)</em></li><li>Resuming service between Chicago and Amsterdam.&nbsp;</li><li>Resuming service between Houston and Amsterdam and Frankfurt.&nbsp;</li><li>Resuming service between San Francisco and Munich.&nbsp;</li><li>Increasing to daily service between Chicago and Frankfurt, and between San Francisco and London.&nbsp;</li><li>Continuing service between the United States and Delhi and Mumbai&nbsp;<em>(subject to government approval)</em>.&nbsp;</li></ul>



<p><strong>Pacific</strong></p>



<p>Across the Pacific in September, United plans to re-start three-times-weekly service between Los Angeles and Sydney and passenger service between Chicago and Hong Kong&nbsp;<em>(subject to government approval).</em></p>



<p><strong>Latin America/Caribbean</strong></p>



<p>Throughout Latin America and the Caribbean, United is expanding across each region by adding 20 new routes for September. Highlights of United’s schedule include:&nbsp;</p>



<ul><li>Starting new service between San Juan, Puerto Rico and Chicago and Washington-Dulles.&nbsp;</li><li>Resuming service from Houston to Aguascalientes, Tampico and Veracruz in Mexico.&nbsp;</li><li>Starting new service between New York/Newark and St. Thomas.&nbsp;</li><li>Resuming service between Costa Rica and Houston and New York/Newark.&nbsp;</li><li>Adding more ways to get to Puerto Vallarta, Mexico, including resuming service from Chicago, Denver and Los Angeles.&nbsp;</li><li>Resuming service between Denver and Cabo San Lucas.&nbsp;</li><li>Increasing the number of flights between Houston and Quito, Ecuador.</li></ul>



<figure><img src="https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1024x681.jpg" alt="united airlines" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1024x681.jpg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-300x199.jpg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-768x510.jpg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-696x463.jpg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1068x710.jpg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-632x420.jpg 632w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">airline</a> intends to fly 37% of its overall schedule in September as compared to the same period last year and is a 4% increase in capacity compared to what is planned for August 2020. United is also extending its waiver of change fees and award redeposit fees for reservations through August 31.&nbsp;Photo: United Airlines</figcaption></figure>



<h2>United Airlines Committed to Ensuring a Safe Journey</h2>



<p>United is committed to putting health and safety at the forefront of every customer’s journey, with the goal of delivering an industry-leading standard of cleanliness through its United CleanPlus program. United has teamed up with Clorox and Cleveland Clinic to redefine cleaning and health safety procedures from check-in to landing and has implemented more than a dozen new policies, protocols and innovations designed with the safety of customers and employees in mind, including:</p>



<ul><li>Requiring all travelers – including crew members – to wear face coverings and potentially revoking travel privileges for customers who do not follow these requirements, as underscored in a&nbsp;<a target="_blank" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2872972-1&amp;h=4181856673&amp;u=https%3A%2F%2Fwww.dropbox.com%2Fsh%2Fj9pc7ehab8xontd%2FAAAJJtjzuejK3-hhWY9DP50qa%2FScott%2520Kirby%2520Mask%2520Message%2F16x9%3Fdl%3D0%26preview%3D2020-06-17_UA_ScottMaskMessage_16x9_v2020-06-25-1_CP-ONLY_SRT.mp4%26subfolder_nav_tracking%3D1&amp;a=recent+video" rel="noreferrer noopener">recent video</a>&nbsp;from United CEO Scott Kirby.&nbsp;</li><li>Using state-of-the-art high-efficiency (HEPA) filters on most United mainline aircraft to circulate air and remove up to 99.97% of airborne particles.&nbsp;</li><li>Using electrostatic spraying on all mainline aircraft before departure for enhanced cabin sanitation.&nbsp;</li><li>Adding a step to the check-in process, based on a recommendation from the Cleveland Clinic, requiring customers to acknowledge they do not have symptoms for COVID-19 and agree to follow our policies, including wearing a mask on board.&nbsp;</li><li>Offering customers a touchless baggage check-in experience at more than 200 airports across the United States; United is the first and only U.S. airline to make this technology available.</li></ul>



<p>For more details on all the ways United is helping keep customers safe during their journey, please visit&nbsp;<a target="_blank" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2872972-1&amp;h=1790932703&amp;u=https%3A%2F%2Fwww.united.com%2Fual%2Fen%2Fus%2Ffly%2Ftravel%2Funited-cleanplus.html&amp;a=united.com%2Fcleanplus" rel="noreferrer noopener">united.com/cleanplus</a>.</p>



<h3>About United Airlines</h3>



<p>United’s shared purpose is “Connecting People. Uniting the World.” For more information, visit united.com, follow @United on Twitter and Instagram or connect on Facebook. The common stock of United’s parent, United Airlines Holdings, Inc., is traded on the Nasdaq under the symbol “UAL”.</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035215</guid>
            <pubDate>Mon, 03 Aug 2020 08:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KLM to Lay Off 5k Employees Due to Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24035132">thread link</a>) | @cockpitherald
<br/>
August 3, 2020 | https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg" data-caption="A total of 4,500 to 5,000 positions in the entire KLM Group will cease to exist.

Photo: KLM
"><img width="500" height="375" src="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg 500w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-300x225.jpeg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-80x60.jpeg 80w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-265x198.jpeg 265w" sizes="(max-width: 500px) 100vw, 500px" alt="" title="KLM pliots and cabin crew"></a><figcaption>A total of 4,500 to 5,000 positions in the entire KLM Group will cease to exist.

Photo: KLM
</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p><strong>KLM is in the throes of a crisis of unprecedented magnitude. Since the outbreak of the COVID-19 virus at the start of 2020, numerous measures have already been taken to deal with the current circumstances. Expectations are that the road to recovery will be long and fraught with uncertainty. This means that KLM’s structure and size must be rigorously adjusted even further in the years ahead. Consequently, a total of 4,500 to 5,000 positions in the entire KLM Group (expressed in FTEs) will cease to exist.</strong></p>



<p>In the wake of the coronavirus outbreak, KLM gradually began reducing the size of its network in February to operate less than 10% of its original number of <a href="https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/">flights</a> by the start of April. In the second quarter, only 15% of the original number of flights were operated. In July, 30% of the original flights were operated and load factors are lagging behind. As a result, while the network is again being gradually and carefully expanded, revenues are lagging far behind.</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p>Prospects for the airline industry – and KLM in particular – are uncertain. Different countries are now beginning to tighten their more relaxed travel restrictions. This is making customers more cautious when it comes to booking a ticket. In all scenarios, demand is only expected to recover by 2023 or 2024 at the earliest. The degree and speed of recovery will depend on a number of factors including the development of the virus, economic recovery and customer travel behaviour.</p>



<h2>KLM Adjusting to the New Reality</h2>



<p>Government support in the form of a direct state loan and guaranteed bank credit facilities amounting to a maximum of €3.4 billion will enable KLM to navigate the crisis in the forthcoming period. <a href="https://news.klm.com/klm-adapts-organisation-further-due-to-covid-19-crisis/" target="_blank" aria-label="KLM (opens in a new tab)" rel="noreferrer noopener">KLM</a> is extremely grateful for this support provided by means of the loan. In order to guarantee KLM’s existence in the longer term, the airline must adapt its size to the new reality. KLM therefore finds itself compelled to reduce its workforce down to the number needed for the planned operation in 2021/2022. Of the current total of 33,000 FTEs in the entire KLM Group, the workforce must be reduced by 4,500 to 5,000 FTEs to 28,000 FTEs in the course of 2021.</p>



<p>KLM’s size is already becoming smaller – and will continue to be reduced – based on the current measures, which include the non-renewal of temporary contracts (1,500 FTEs) and the Voluntarily Departure Scheme (2,000 FTEs). Additionally, natural attrition (500 FTEs) through retirement and the like in 2020 and 2021 will also contribute to the reduction needed.</p>



<p>Hence, despite the measures already taken, even fewer people will be needed at KLM in the years ahead. Additionally, for positions on the ground we also need to deal with some mismatch in functional skills and capabilities.</p>



<p>Unfortunately, for this reason and taking into account the mismatch, alternative solutions will have to be found for ca. 1,500 positions. This relates to up to 500 ground positions, 300 cabin crew positions and 300 cockpit positions and approximately 400 positions at KLM subsidiaries and Air France-KLM group functions.</p>



<p>Given the high level of uncertainty, KLM keeps open the possibility of further reductions in case the production levels will be revised further down for 2021/2022 than the -20% planned now.</p>



<figure><img src="https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew.jpg" alt="KLM" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew.jpg 500w, https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew-300x169.jpg 300w" sizes="(max-width: 500px) 100vw, 500px"><figcaption>KLM crew in Sydney Photo: KLM</figcaption></figure>



<h3>KLM to Cooperate with Trade unions and Works Council</h3>



<p>KLM’s reorganisation plans tie in with organisation-wide changes at Air France KLM. In the forthcoming period, KLM will be cooperating closely with the trade unions to draft a social plan for each collective labour agreement domain and subsidiary, as well as maintaining close consultation with the Works Council about further defining the reorganisation. This will include a more detailed specification of the conditions set by the Dutch government on issuing the financing package. Expectations are that this will be finished in its entirety in the course of October.“</p>



<blockquote><p><em>A great deal has already been done in recent months with respect to adjusting the size of our company in the face of a new reality. Unfortunately, more measures are needed in the short term to guarantee KLM’s continued existence in the future. For this reason, we are elaborating the reorganisation plan to emerge from this crisis in a stronger position, while retaining as many jobs as we can in a responsible manner and repaying the loans as quickly as possible.</em></p><p><em>KLM employees are loyal, professional and hard working. They are always ready to serve our customers, one another, the company and society at large. Recent developments have again served to prove that this is true. It is incredibly difficult and sad for KLM to now have to bid farewell to valuable, committed colleagues. Certainly in view of how much we have succeeded in achieving together in recent years. The forthcoming period will be devoted to saying goodbye to colleagues who have to leave with due care and to reconstructing KLM.</em></p></blockquote>



<p>KLM President-directeur &amp; CEO Pieter Elbers</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035132</guid>
            <pubDate>Mon, 03 Aug 2020 07:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT3 → Dataset → Task Model?]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24034542">thread link</a>) | @dsr12
<br/>
August 2, 2020 | https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc | <a href="https://web.archive.org/web/*/https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034542</guid>
            <pubDate>Mon, 03 Aug 2020 05:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MNT Reform open source laptop with trackball]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24034502">thread link</a>) | @brian_herman
<br/>
August 2, 2020 | https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html | <a href="https://web.archive.org/web/*/https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <date>Published: 2020-05-08 Updated: 2020-05-22 21:36:37 +0200</date>
        

<p><a href="https://mntre.com/media/reform_v2_images/product-mnt-reform.jpg"><img src="https://mntre.com/media/reform_v2_images/product-mnt-reform.jpg" alt="MNT Reform in 2020"></a></p>

<p>This page serves as a link index to all Reform content, both historical and recent.</p>

<p>On 2020-05-08, MNT Research launched the MNT Reform open source mobile computer:</p>

<p><strong><a href="https://www.crowdsupply.com/mnt/reform">→ Go to the Crowd Supply Campaign</a></strong></p>

<h2 id="mnt-reform-final-version">MNT Reform Final Version</h2>

<p>Internally called MNT Reform 2.0, this is a version with many improvements, full aluminum enclosure, HD display and NXP i.MX8MQ module.</p>

<ul>
<li>2020-05-22: <a href="https://mntre.com/reform2-handbook/system.html">MNT Reform Interactive System Diagram and Interactive PCBs</a>, first version, published.</li>
<li>2020-05-08: <a href="https://www.crowdsupply.com/mnt/reform">Crowd supply campaign is launched</a>, running until 2020-06-18.</li>
<li>2020-05-08: <a href="https://www.crowdsupply.com/mnt/reform/updates/the-campaign-is-live">Launch Announcement</a> of the campaign.</li>
<li>8 Beta versions (D-3 / D-4) were sold in late 2019/early 2020 and are shipped in May 2020.</li>
<li>2020-01-18: <a href="https://mntre.com/media/reform_md/2020-01-18-finishing-reform.html">Finishing Reform</a></li>
<li>2019-05-20: <a href="https://mntre.com/media/reform_md/2019-05-20-reintroducing-reform.html">Re-Introducing Reform</a></li>
<li>Handbook not yet available</li>
<li><a href="https://source.mntmn.com/MNT/reform">Sources of Reform 2.0 (KiCAD, various)</a></li>
</ul>

<h2 id="mnt-reform-prototype-version-s-internally-called-mnt-reform-0-1-1-0">MNT Reform Prototype Version(s) (internally called MNT Reform 0.1 - 1.0)</h2>

<p>This was the original version of Reform, based on NXP i.MX6QP.</p>

<ul>
<li>2019-01-14: <a href="https://mntre.com/media/reform_md/2019-01-14-status_update_on_reform.html">Status Update on MNT Reform</a></li>
<li><a href="https://mntre.com/media/reform_md/reform-1-handbook.pdf">Handbook for Reform 1.0 (PDF, historical)</a></li>
<li><a href="https://source.mntmn.com/MNT/reform/src/branch/master/historic-reform1">Sources of Reform 1.0 (KiCAD, various, historical)</a></li>
<li>10 prototype versions were shipped to early supporters in late 2018. 13 exist in total.</li>
<li><a href="https://mntre.com/media/reform_md/reform-historic/reform-beta-1.html">MNT Reform: The Original Story</a></li>
</ul>

<h2 id="talks-appearances">Talks / Appearances</h2>

<ul>
<li><a href="https://media.ccc.de/v/34c3-9257-lightning_talks_day_3#t=3512">Reform Lightning Talk from 34c3</a></li>
<li><a href="https://media.ccc.de/v/dg-90">Longer Reform talk in German from CCCB Datengarten 90</a></li>
</ul>

<h2 id="irc-channel">IRC Channel</h2>

<ul>
<li>Chat in #reform on irc.freenode.net</li>
</ul>



<ul>
<li><a href="https://mastodon.social/@mntmn">Mastodon</a></li>
<li><a href="https://twitter.com/mntmn">Twitter</a></li>
</ul>

<h2 id="crowdfunding-campaign">Crowdfunding Campaign</h2>

<p><strong><a href="https://www.crowdsupply.com/mnt/reform">→ Go to the Crowd Supply Campaign</a></strong></p>

      </section></div>]]>
            </description>
            <link>https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034502</guid>
            <pubDate>Mon, 03 Aug 2020 05:34:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Autodesk criticised by architects]]>
            </title>
            <description>
<![CDATA[
Score 289 | Comments 369 (<a href="https://news.ycombinator.com/item?id=24034211">thread link</a>) | @nsoonhui
<br/>
August 2, 2020 | http://extranetevolution.com/2020/07/autodesk-criticism-extends/ | <a href="https://web.archive.org/web/*/http://extranetevolution.com/2020/07/autodesk-criticism-extends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
                
                    
                                        
                    <div id="content-main">
                    
	
		
		        
<div id="post-14835">
		
	<div>
    	
                    	<p>
            	<span>Jul</span>
                <span>31</span>
                	                <span>2020</span>
                            </p>
            
		        
		
			    <ul>
	    		        <li>
	        	By  in <span><a href="http://extranetevolution.com/category/aec/">AEC</a>, <a href="http://extranetevolution.com/category/bim/">BIM</a>, <a href="http://extranetevolution.com/category/businessfinancial/">Business/Financial</a>, <a href="http://extranetevolution.com/category/collaboration/">Collaboration</a>, <a href="http://extranetevolution.com/category/digital-transformation/">Digital transformation</a>, <a href="http://extranetevolution.com/category/functionality/">Functionality</a>, <a href="http://extranetevolution.com/category/future/">Future</a>, <a href="http://extranetevolution.com/category/vendors/">Vendors</a></span>	        </li>
	        	        <li>
	        	<p><em>31 July 2020</em></p>	        </li>
	        	        <li>
	        	        <span>
            <i></i>
        </span>
    	        </li>
	        	    </ul>
    		
				<div>
							
										
						<div itemscope="" itemtype="http://schema.org/BlogPosting"><p><em><strong>Architectural unrest about Autodesk and its support for the industry’s design businesses is growing. Discontent has been simmering for a decade or more, and has led to calls for EU action.</strong></em></p>
<p><a href="https://www.autodesk.co.uk/"><img src="http://extranetevolution.com/files/2013/11/autodesk.logo2013.jpg" alt="autodesk logo" width="181" height="31"></a>The recent <a href="https://letters-to-autodesk.com/" target="_blank" rel="noopener noreferrer">open letter to Autodesk</a> from 17 named members of a 25-strong group of leading architects (28 July 2020: <a href="http://extranetevolution.com/2020/07/design-firms-demand-change-at-autodesk/"><em>Design firms demand change at Autodesk</em></a>) has been supported by more firms. They extend the geographical reach of those prepared to publicly criticise the US AEC software vendor over its support for architectural design businesses – many of them heavily reliant upon Autodesk’s Revit design software. An additional 18 practices now stand alongside the original letter’s signatories, bringing the total to 35. A further 10 practices are supportive, but have not gone public. In total, more than 50 firms have therefore backed the group’s grievances.</p>
<p><img src="http://extranetevolution.com/files/2020/07/Revit_2014_branding-150x150.png" alt="Autodesk Revit_2014_branding" width="150" height="150" srcset="http://extranetevolution.com/files/2020/07/Revit_2014_branding-150x150.png 150w, http://extranetevolution.com/files/2020/07/Revit_2014_branding-300x300.png 300w, http://extranetevolution.com/files/2020/07/Revit_2014_branding-160x160.png 160w, http://extranetevolution.com/files/2020/07/Revit_2014_branding.png 316w" sizes="(max-width: 150px) 100vw, 150px">The new signatories are: BC Architects and SAOTA (both from South Africa); Cooper Carry, Portman Architects, Idesign-solutions, Studio 3 Architecture, Goody Clancy, SGA, Bohlin, Cywinski, Jackson, and Workshop Collaborative (all from the US), Atelier Tisso (France),&nbsp;CGL,&nbsp;Shepheard Epstein Hunter, and PDPLondon (all from the UK); Vibes (Netherlands); MIZA (Canada); Oslo works (Norway); and Mochly-Eldar Architects (Israel).</p>
<p>It is clear that Iain Godwin has tapped into a growing sense of unease, though, to be fair, rumblings of discontent have been heard many times over the past decade or so from a variety of software commentators and end-users. For example:</p>
<ul>
<li><a href="https://www.worldcadaccess.com/blog/2009/12/solidworks-accuses-autodesk-of-attempting-to-monopolize-use-of-dwg-as-file-extension.html" target="_blank" rel="noopener noreferrer"><em><strong>SolidWorks accuses Autodesk of attempting to monopolize use of .dwg as file extension</strong></em></a> (Ralph Grabowski – WorldCADAccess, December 2009)</li>
<li><a href="https://gfxspeak.com/2011/04/28/is-the-european-commission-investigating-autodesk/" target="_blank" rel="noopener noreferrer"><em><strong>Is the European Commission investigating Autodesk?</strong></em></a> (Randall Newton – GraphicSpeak, April 2011)</li>
<li><a href="https://www.cadnauseam.com/2017/07/26/autodesk-confirms-its-own-unconscionable-conduct/" target="_blank" rel="noopener noreferrer"><em><strong>Autodesk confirms its own unconscionable conduct</strong></em></a> (Steve Johnson – CAD Nauseum, July 2017)</li>
<li><a href="http://debunkthebim.blogspot.com/2018/04/here-is-why-autodesks-monopoly-over.html" target="_blank" rel="noopener noreferrer"><em><strong>Here is why Autodesk’s monopoly over the Global AEC is not good, not even for Autodesk</strong></em></a> (Zolna Murray – Debunk the BIM, February 2018)</li>
<li><a href="https://www.linkedin.com/pulse/avoiding-carillions-mistakes-joining-autodesks-monopoly-john-ford/" target="_blank" rel="noopener noreferrer"><em><strong>Avoiding Carillion`s Mistakes of Joining Autodesk’s Monopoly Unnecessarily</strong></em></a> (John Ford – LinkedIn Pulse, May 2018)</li>
<li><a href="http://mes100.com/blog/the-state-of-bim-software-and-autodesk/" target="_blank" rel="noopener noreferrer"><em><strong>The state of BIM software and Autodesk</strong></em></a> (MES – MES blog, July 2018)</li>
<li><a href="https://thinkmoult.com/why-revit-is-shit.html" target="_blank" rel="noopener noreferrer"><em><strong>Why Revit is shit</strong></em></a> (Dion Moult – ThinkMoult, December 2018)</li>
</ul>
<p>Concerns about some software vendors’ monopolistic positions have also been raised internationally by industry organisations, including the <a href="http://www.fiec.eu/" target="_blank" rel="noopener noreferrer">European Construction Industry Federation (FIEC</a>).</p>
<h3>FIEC position paper</h3>
<p><a href="http://www.fiec.eu/"><img src="http://extranetevolution.com/files/2020/07/FIEC-logo-300x117.jpg" alt="FIEC logo" width="300" height="117" srcset="http://extranetevolution.com/files/2020/07/FIEC-logo-300x117.jpg 300w, http://extranetevolution.com/files/2020/07/FIEC-logo-160x62.jpg 160w, http://extranetevolution.com/files/2020/07/FIEC-logo.jpg 443w" sizes="(max-width: 300px) 100vw, 300px"></a>On 24 February 2020, the FIEC published a position paper on the relationship between users and software companies/ editors/ service providers (<em><a href="http://extranetevolution.com/files/2020/07/2020-02-24-FIEC_position_on_software_companies-Final.pdf" target="_blank" rel="noopener noreferrer">download</a></em>). No vendors are named, but, from the similarity of the claims, Autodesk is clearly one of the software providers that FIEC is sufficiently concerned about to urge the European Commission to review competition and data management regulations. Its paper discusses challenges and makes recommendations under four headings:</p>
<ol>
<li><strong>The dominant position of a few software companies/editors/providers raises major concerns.</strong> – The FIEC urges the European Commission to target competition issues relating to software user contracts</li>
<li><strong>The non-EU origin of these suppliers and their infrastructure is exacerbating the lack of autonomy in software capability in the EU.</strong> – The FIEC says EU software users should be allowed to decide where their data is stored (“EU companies should be able to have their data hosted on EU territory, by EU servers/companies, under EU legislation”), calls for the creation of a secure European Cloud, and says software services “should be required to meet EU standards for interoperability and open access”.</li>
<li><strong>Contracting authorities must remain software-neutral and promote open standards</strong>. – The FIEC calls for enforcement of EU public procurement rules, and urges promotion of open standards for data, protocols and file formats in public procurement.</li>
<li><strong>Rules need to be established for multiple-user-access platforms such as BIM models.</strong> – Similarly, the FIEC urges EU measures aimed at protecting the data owner while ensuring appropriate data access rights for other users.</li>
</ol>
<h3>Autodesk not alone in hosting, US dominance, interoperability issues</h3>
<p>Some of these issues are already familiar. Where project data is hosted has been a concern ever since Software-as-a-Service applications began to be deployed in the 1990s, and as use of construction collaboration platforms expanded in the early 2000s, most leading vendors have responded by creating localised hosting centres to serve different operational regions. Hosting&nbsp; project data in the United States, for example, has been resisted by most clients based in Europe and other parts of the world (eg: the Middle East, southeast Asia, etc; read <em>EE</em> August 2014 post <a href="http://extranetevolution.com/2014/08/no-saas-safe-harbor/"><em>No SaaS ‘Safe Harbor’</em></a>).</p>
<p>Concentration of large portions of the construction software industry through merger and acquisition activity has resulted in an increasingly dominant position for US software giants. By gobbling up strong players in Europe, Australasia and elsewhere, Autodesk, Bentley, Oracle and Trimble have assembled strong AEC software portfolios, while some of the more generic US software providers such as Microsoft and IBM have also developed applications, services and relationships that give them an increasingly strong foothold in the AEC space.</p>
<p>And software interoperability has been a perennial issue that <em>EE</em> has covered since it started in 2005 (eg: <a href="http://extranetevolution.com/2005/09/new_roi_return_/"><em>New ROI: Return on Interoperability</em></a>, September 2005). BuildingSmart (formerly the International Alliance for Interoperability) started out as an Autodesk initiative in the mid-1990s, but, over 25 years later, global shifts towards open standards are still proceeding almost glacially slowly, with Autodesk’s leading BIM authoring product “widely ridiculed” for its IFC import/export capabilities.</p>
<h3>Autodesk responds on key themes</h3>
<p><strong><a href="https://adsknews.autodesk.com/views/reply-to-open-letter-on-revit"><img src="http://extranetevolution.com/files/2020/07/Autodesk-reply-300x205.jpg" alt="Autodesk reply" width="400" height="273" srcset="http://extranetevolution.com/files/2020/07/Autodesk-reply-300x205.jpg 300w, http://extranetevolution.com/files/2020/07/Autodesk-reply-590x403.jpg 590w, http://extranetevolution.com/files/2020/07/Autodesk-reply-768x524.jpg 768w, http://extranetevolution.com/files/2020/07/Autodesk-reply-160x109.jpg 160w, http://extranetevolution.com/files/2020/07/Autodesk-reply.jpg 1157w" sizes="(max-width: 400px) 100vw, 400px"></a>Autodesk’s initial response</strong> (<a href="http://extranetevolution.com/2020/07/design-firms-demand-change-at-autodesk/"><em>see update to earlier EE post</em></a>) to the Godwin group’s open letter <strong>did not mention interoperability</strong> at all. However, a <a href="https://adsknews.autodesk.com/views/reply-to-open-letter-on-revit" target="_blank" rel="noopener noreferrer">follow-up blog post by Amy Bunzsel</a> published today (31 July 2020) addresses the main themes, and on openness and interoperability says: “<strong>We continue to invest in supporting IFC</strong> and based on customer feedback we’ve <strong>recently increased development for new industry requirements, focusing on IFCv4 certification</strong>.”</p>
<p>Bunzsel continues:</p>
<p>“Looking to the future, we believe that ways of working will evolve, from the direct modeling of today to outcome-based design driven by analysis…, to the convergence of manufacturing and construction, and that <strong>data needs to be unlocked from native formats and flow more readily throughout Autodesk and non-Autodesk products</strong>.”</p>
<h3>No more software silos</h3>
<p><a href="https://3drepo.com/"><img src="http://extranetevolution.com/files/2017/03/3DRepo-300x102.png" alt="" width="150" height="51" srcset="http://extranetevolution.com/files/2017/03/3DRepo-300x102.png 300w, http://extranetevolution.com/files/2017/03/3DRepo.png 385w" sizes="(max-width: 150px) 100vw, 150px"></a>Jozef Dobos is CEO and founder of London, UK-based technology vendor, <a href="https://3drepo.com/" target="_blank" rel="noopener noreferrer"><strong>3DRepo</strong></a>&nbsp;(which has been <a href="https://3drepo.com/4670-2/" target="_blank" rel="noopener noreferrer">a supporter of Open BIM since 2017</a>), and recently argued&nbsp;<a href="https://www.bimplus.co.uk/analysis/making-case-fair-competition-software-use/" target="_blank" rel="noopener noreferrer"><em>The case for fair competition in software use</em></a>, in a <em>BIM+</em> article. He writes:</p>
<p><img src="http://extranetevolution.com/files/2020/07/Jozef-Dobos-271x300.png" alt="Jozef Dobos" width="271" height="300" srcset="http://extranetevolution.com/files/2020/07/Jozef-Dobos-271x300.png 271w, http://extranetevolution.com/files/2020/07/Jozef-Dobos-145x160.png 145w, http://extranetevolution.com/files/2020/07/Jozef-Dobos-363x400.png 363w, http://extranetevolution.com/files/2020/07/Jozef-Dobos.png 502w" sizes="(max-width: 271px) 100vw, 271px">“<strong>All the issues raised by the FIEC must be addressed to enable the genuine digitisation of the construction industry</strong>.</p>
<p>3D Repo was created to enable the construction industry to work better together and to create better buildings. This is why projects like the&nbsp;<strong><a href="https://www.bimplus.co.uk/news/project-explores-faster-bim-data-transfer-between-/" target="_blank" rel="noopener noreferrer">AEC Delta Mobility</a></strong> [open-source] initiative in collaboration with BuroHappold Engineering and Speckle Systems are so important, creating a new standard for designers, integrators and fabricators to improve the flow of data.</p>
<p>The current method of sharing information as files of entire 3D models can hinder collaboration. Tracking changes can also be problematic and inefficient for design communication. AEC Delta Mobility breaks down the file barriers to enable small design changes, known as ‘Deltas’, to be shared faster, more openly and more efficiently.</p>
<p><strong>This is how the software industry should be working with the construction industry. Real solutions that involve working with customers and providing them with tools they will not want to walk away from, based on commercial terms that actually promote the collaborative behaviours we want to see, not divide us into software silos</strong>.”</p>
</div>								</div>
		
			    
    	</div>

</div>


<p><span><strong>Permanent link to this article: </strong><span>http://extranetevolution.com/2020/07/autodesk-criticism-extends/</span></span></p>











	
    

            
  

                </div><!-- #content-main -->
        
            
<!-- #sidebar1 -->        
        
    </div></div>]]>
            </description>
            <link>http://extranetevolution.com/2020/07/autodesk-criticism-extends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034211</guid>
            <pubDate>Mon, 03 Aug 2020 04:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web apps aren't tech. They're “tech”]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24034040">thread link</a>) | @AlchemistCamp
<br/>
August 2, 2020 | https://questinglog.com/web-apps-arent-tech | <a href="https://web.archive.org/web/*/https://questinglog.com/web-apps-arent-tech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><blockquote><p>I do hear sometimes from programmers who are kind of sad that they don't have the opportunity to write game engines from scratch like I did and have it matter or make an impact...</p> <p>-John Carmack</p></blockquote> <p>I was definitely a programmer who felt like I'd missed a golden era of opportunity. I didn't <em>really</em> start programming until my 30s. Just like many devs hoping to have an impact on the industry, it's sometimes felt like the golden era has already passed.</p> <p>Surveying the market from a more entreprenurial mindset and looking for a potential niche to fill with a SaaS app (or worse, a social network), the situation appears even more dire! News aggregators have been done and Reddit is thoroughly dominant. The professional social network is done and LinkedIn owns it. Market after market is done. <a href="https://questinglog.com/everything-is-done">Everything in tech is done.</a></p> <h2 id="technology-doesn-t-stay-technology"><a href="#technology-doesn-t-stay-technology">#</a> Technology doesn't stay technology</h2> <p>Part of the problem is the word "tech". There are two different—but overlapping—ideas that are both commonly referred to as "tech".</p> <p>By its literal definition, techonology is anything that involves <em>applying scientific knowledge for practical purposes</em>. In a literal sense, we're surrounded by tech. Some, such as the spoon are ancient and others, like the Kinesis keyboard I'm typing on are much newer.</p> <p>But people don't talk about ancient inventions like the fire bow, or Clovis points as "technology", outside of a historical context. Most people don't even call somewhat modern inventions like light bulbs, refrigerators or microwaves as technology either. When we call something technology, we generally mean something invented recently... <em>or</em> we mean something related to computers.</p> <p>Douglas Adams summed it up into three rules:</p> <ol><li>Anything that is in the world when you’re born is normal and ordinary and is just a natural part of the way the world works.</li> <li>Anything that's invented between when you’re fifteen and thirty-five is new and exciting and revolutionary and you can probably get a career in it.</li> <li>Anything invented after you're thirty-five is against the natural order of things.</li></ol> <p>Having a musician turned firmware hacker and then programmer for an uncle, I'm a bit more optimistic about aging and see the boundary as more about whether a given technology has been widespread for a decade or not.</p> <p>Cassette tapes and microwave ovens used to be fantastic new technologies in the late 60s and early 70s. Now they aren't. DVDs, the web and 3D video games used to be amazing technologies in the 90s. Now they're taken for granted. Smart phones were incredible in the late aughts. Now they're just phones.</p> <h2 id="when-pundits-say-tech-they-generally-mean-computing"><a href="#when-pundits-say-tech-they-generally-mean-computing">#</a> When pundits say "tech" they generally mean computing</h2> <p>The rapid advances in personal computing during the 80s, 90s and early 2000s was nothing short of breathtaking. Computers were gaining new powers every year or two and PCs were deprecating nearly 50% per year! The web took the boom to an exponentially growing number of users. [<a href="#1">1</a>]</p> <p>It's entirely natural that computer software dominated the discussion of technology for a generation. First journalists, and now many of us are referring to everything from web SaaS apps to mobile productivity apps as "tech".[<a href="#2">2</a>] Since the wider meaning of tech hasn't been abandoned, this makes it very easy to conflate the two.</p> <p>But not all technology is computing and not all computing is technology anymore.</p> <h2 id="where-is-the-edge"><a href="#where-is-the-edge">#</a> Where is the edge?</h2> <p>To an ambitious engineer looking for a market opportunity in "tech", things look crowded. Advances in programming languages, frameworks, open source collaboration, dev ops, visual site-building tools and more have made it <em>dramatically</em> easier to create both web apps and mobile apps than it was a decade ago. This has lead to a flood of competition and an increased importance of marketing and other skills an engineer might not have.</p> <p>But web apps aren't (necessarily) tech. They're "tech".</p> <p>But not all is lost for the aspiring engineer.</p> <p>There are newer technologies, closer to the frontier that aren't common in in 2020 but will be in 2030. Some of them are still wide open to people with more learning power than earning power. Bio-tech, blockchain, and VR <em>are</em> tech and the technical challenges to be solved are real. It's a lot harder to ship a product in those areas than to build yet another SaaS targeting small to medium sized businesses. But that's a <em>good</em> thing if technical skills are your strength.</p> <p>For those whose strengths lean more to the marketing, sales or design sides, the B2B SaaS may represent a better goal. This is good for everyone. There's vast landscape for different people with different comparative advantages to find their niches.</p> <h2 id="you-are-not-too-late"><a href="#you-are-not-too-late">#</a> You are not too late</h2> <blockquote><p>...here's where some perspective really helps - I can remember when I was a teenager, I thought I had missed the Golden Age of 8-bit Apple 2 gaming, that I was never going to be Richard Garriott...time went by, and I got to make my own marks in things after that. And, in that time, I also see so many opportunities that have come by.</p> <p>The 90s PC wave was great - I was happy to be there, and I'm glad I took a swing and knocked one out of the park with that. But since then, we've seen mobile games, and web games, and free-to-play games, the Steam revolution...and now virtual reality. And all of these are amazing!</p> <p>So, yeah, the opportunities that I had aren't there for people today - but there are new and better ones. And personally, I'm more excited about these than anything that's come before. So, thank you very much for this honor, but I'm just getting started.</p> <p>-John Carmack (BAFTA acceptance speech)</p></blockquote> <p>The speech John Carmack gave when accepting his BAFTA fellowship filled me more professional optimism than I've felt in quite a while. Even he felt like it was "too late" because of missing all the opportunities of the 80s.</p> <p>In retrospect, that seems crazy. The web was huge and just around the corner.</p> <h3 id="notes"><a href="#notes">#</a> Notes</h3> <p><a name="1">[1]</a> Well more of an S-curve, but it looked exponential then.</p> <div><p><a name="2">[2]</a> As one commenter on HN </p><a href="https://news.ycombinator.com/item?id=24034703" target="_blank" rel="noopener noreferrer">pointed out</a><p>, it's a spectrum. In Uber's early days, its technology was crucial to its business. Over time, they'll gradually become less of a tech company if they coast and stop innovating.
</p></div>  <br> <hr> <p><a href="https://news.ycombinator.com/item?id=24034040" target="_blank" rel="noopener noreferrer">Discussion on HN</a></p></div></div>]]>
            </description>
            <link>https://questinglog.com/web-apps-arent-tech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034040</guid>
            <pubDate>Mon, 03 Aug 2020 03:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Email Got Us $5k AWS Credits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24033037">thread link</a>) | @webappsecperson
<br/>
August 2, 2020 | https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits | <a href="https://web.archive.org/web/*/https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We recently went through the <a href="https://stripe.com/atlas">Stripe Atlas</a> program and <a href="https://formcake.com/blog/our-experience-with-stripe-atlas">loved it</a>.</p>
<p>But the one sour note was that we only got $1,000 AWS credits when <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">the copy seemed to promise $5,000</a>. Our <a href="https://formcake.com/blog/why-we-chose-a-marketing-and-app-monorepo">entire application infrastructure is on AWS</a> so those credits are pretty much straight-up cash to us. We don't have much of a digital footprint either, so $5,000 goes a long way.</p>
<p>That's why this weekend was such a surprise.</p>
<h3 id="the-email">The Email</h3>
<p>Here's how the timeline went.</p>
<ol>
<li><p>First <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">we posted an article</a> politely noticing that we hadn't been able to secure the full $5,000 and kinda wondering out loud why.</p>
</li>
<li><p><a href="https://formcake.com/blog/the-founders-guide-to-stripe-atlas">Stripe contacted us</a> and explained that the credit amount was more of a lifetime cap and that it was ultimately up to AWS what we got.</p>
</li>
<li><p>We send <em>one more</em> email just 'cause, even though it seems clear AWS only offers $1,000 for bootstrapped startups. The email is simple and amounts to: "Is there any way we could get the full five thousand in credits?"</p>
</li>
</ol>
<p>Stripe responds to this chain of events with yet another email, this one even kinder and more politely worded.</p>
<section>
Hey David,

<p>Thank you for sharing the details here. It sounds like we should be able to get this sorted out so that you receive the $5K in AWS credits for Stripe Atlas users.  </p>
<p>I believe it may be the case that you applied for AWS credits with a different link than the one shared for Stripe Atlas users to activate. We do not typically see users needing to answer the question regarding funding sources. I did check in with AWS on this and it sounds like they're currently processing your most recent application that you submitted through the Stripe Atlas link. They've let me know that they will email you directly with next steps, which may take up to 4 weeks. </p>
<p>Hopefully this will all soon be sorted! If you do have any questions on this or anything else, please feel free to reach out! I'll check back in a couple weeks on the AWS front, or feel free to share any updates as well!</p>
<p>Warm regards,
Taylor</p>
</section> 

<p>It looks like the funded/bootstrapped question indicated the process had gotten miffed somewhere and <em>Stripe reached out to AWS on our behalf</em> to make sure things got cleared up.</p>
<p>This weekend we saw $5,000 in credits enter our AWS account. Keep in mind that's actually <strong>in addition</strong> to the $1,000 we've already received, bringing out total up to $6,000 in AWS credits through the Stripe Atlas program.</p>
<p>For us this is a big injection. It basically funds our full application operations and lets us play around with putting money elsewhere - or just continuing to build features and mature without any kind of pressure.</p>
<h3 id="conclusion">Conclusion</h3>
<p>A couple of takeaways from the entire affair.</p>
<h4 id="1-send-that-one-last-email">1. Send that one last email</h4>
<p>Even if it seems like a bit much, or things are settled, just be sure you ask and give the other person a chance to help you in ways you can't predict. A hail mary "Is there anything I'm missing?" can sometimes land.</p>
<h4 id="2-stripe-is-truly-wonderful">2. Stripe is truly wonderful</h4>
<p>Stripe monitored the developer community enough to see our initial posts, proactively reached out to us, and then worked with AWS to ultimately get us a greater-than-even-promised payout. When people say Stripe is a company for developers, they often mean its great API or clear documentation, but this is I think one of the greatest testaments to their dev-first culture.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24033037</guid>
            <pubDate>Mon, 03 Aug 2020 00:39:42 GMT</pubDate>
        </item>
    </channel>
</rss>
